{"files":[{"patch":"@@ -27,1 +27,0 @@\n-#include \"gc\/shared\/threadLocalAllocBuffer.inline.hpp\"\n@@ -35,72 +34,0 @@\n-static THREAD_LOCAL int64_t _last_allocated_bytes = 0;\n-\n-inline void send_allocation_sample(const Klass* klass, int64_t allocated_bytes) {\n-  assert(allocated_bytes > 0, \"invariant\");\n-  EventObjectAllocationSample event;\n-  if (event.should_commit()) {\n-    const size_t weight = allocated_bytes - _last_allocated_bytes;\n-    assert(weight > 0, \"invariant\");\n-    event.set_objectClass(klass);\n-    event.set_weight(weight);\n-    event.commit();\n-    _last_allocated_bytes = allocated_bytes;\n-  }\n-}\n-\n-inline bool send_allocation_sample_with_result(const Klass* klass, int64_t allocated_bytes) {\n-  assert(allocated_bytes > 0, \"invariant\");\n-  EventObjectAllocationSample event;\n-  if (event.should_commit()) {\n-    const size_t weight = allocated_bytes - _last_allocated_bytes;\n-    assert(weight > 0, \"invariant\");\n-    event.set_objectClass(klass);\n-    event.set_weight(weight);\n-    event.commit();\n-    _last_allocated_bytes = allocated_bytes;\n-    return true;\n-  }\n-  return false;\n-}\n-\n-inline intptr_t estimate_tlab_size_bytes(Thread* thread) {\n-  assert(thread != NULL, \"invariant\");\n-  const size_t desired_tlab_size_bytes = thread->tlab().desired_size() * HeapWordSize;\n-  const size_t alignment_reserve_bytes = thread->tlab().alignment_reserve_in_bytes();\n-  assert(desired_tlab_size_bytes > alignment_reserve_bytes, \"invariant\");\n-  return static_cast<intptr_t>(desired_tlab_size_bytes - alignment_reserve_bytes);\n-}\n-\n-inline int64_t load_allocated_bytes(Thread* thread) {\n-  const int64_t allocated_bytes = thread->allocated_bytes();\n-  if (allocated_bytes < _last_allocated_bytes) {\n-    \/\/ A hw thread can detach and reattach to the VM, and when it does,\n-    \/\/ it gets a new JavaThread representation. The thread local variable\n-    \/\/ tracking _last_allocated_bytes is mapped to the existing hw thread,\n-    \/\/ so it needs to be reset.\n-    _last_allocated_bytes = 0;\n-  }\n-  return allocated_bytes == _last_allocated_bytes ? 0 : allocated_bytes;\n-}\n-\n-\/\/ To avoid large objects from being undersampled compared to the regular TLAB samples,\n-\/\/ the data amount is normalized as if it was a TLAB, giving a number of TLAB sampling attempts to the large object.\n-static void normalize_as_tlab_and_send_allocation_samples(Klass* klass, intptr_t obj_alloc_size_bytes, Thread* thread) {\n-  const int64_t allocated_bytes = load_allocated_bytes(thread);\n-  assert(allocated_bytes > 0, \"invariant\"); \/\/ obj_alloc_size_bytes is already attributed to allocated_bytes at this point.\n-  if (!UseTLAB) {\n-    send_allocation_sample(klass, allocated_bytes);\n-    return;\n-  }\n-  const intptr_t tlab_size_bytes = estimate_tlab_size_bytes(thread);\n-  if (allocated_bytes - _last_allocated_bytes < tlab_size_bytes) {\n-    return;\n-  }\n-  assert(obj_alloc_size_bytes > 0, \"invariant\");\n-  do {\n-    if (send_allocation_sample_with_result(klass, allocated_bytes)) {\n-      return;\n-    }\n-    obj_alloc_size_bytes -= tlab_size_bytes;\n-  } while (obj_alloc_size_bytes > 0);\n-}\n-\n@@ -108,1 +35,1 @@\n-  JFR_ONLY(JfrAllocationTracer tracer(obj, alloc_size, thread);)\n+  JFR_ONLY(JfrAllocationTracer tracer(klass, obj, alloc_size, true, thread);)\n@@ -115,1 +42,0 @@\n-  normalize_as_tlab_and_send_allocation_samples(klass, static_cast<intptr_t>(alloc_size), thread);\n@@ -119,1 +45,1 @@\n-  JFR_ONLY(JfrAllocationTracer tracer(obj, alloc_size, thread);)\n+  JFR_ONLY(JfrAllocationTracer tracer(klass, obj, alloc_size, false, thread);)\n@@ -127,5 +53,0 @@\n-  const int64_t allocated_bytes = load_allocated_bytes(thread);\n-  if (allocated_bytes == 0) {\n-    return;\n-  }\n-  send_allocation_sample(klass, allocated_bytes);\n","filename":"src\/hotspot\/share\/gc\/shared\/allocTracer.cpp","additions":2,"deletions":81,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"jfr\/support\/jfrObjectAllocationSample.hpp\"\n@@ -31,1 +32,2 @@\n-JfrAllocationTracer::JfrAllocationTracer(HeapWord* obj, size_t alloc_size, Thread* thread) : _tl(NULL) {\n+JfrAllocationTracer::JfrAllocationTracer(const Klass* klass, HeapWord* obj, size_t alloc_size, bool outside_tlab, Thread* thread) : _tl(NULL) {\n+  JfrObjectAllocationSample sample(klass, alloc_size, outside_tlab, thread);\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrAllocationTracer.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+class Klass;\n@@ -31,0 +32,1 @@\n+class Thread;\n@@ -36,1 +38,1 @@\n-  JfrAllocationTracer(HeapWord* obj, size_t alloc_size, Thread* thread);\n+  JfrAllocationTracer(const Klass* klass, HeapWord* obj, size_t alloc_size, bool outside_tlab, Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrAllocationTracer.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,114 @@\n+\/*\n+* Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+*\n+* This code is free software; you can redistribute it and\/or modify it\n+* under the terms of the GNU General Public License version 2 only, as\n+* published by the Free Software Foundation.\n+*\n+* This code is distributed in the hope that it will be useful, but WITHOUT\n+* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+* version 2 for more details (a copy is included in the LICENSE file that\n+* accompanied this code).\n+*\n+* You should have received a copy of the GNU General Public License version\n+* 2 along with this work; if not, write to the Free Software Foundation,\n+* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+*\n+* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+* or visit www.oracle.com if you need additional information or have any\n+* questions.\n+*\n+*\/\n+\n+#include \"precompiled.hpp\"\n+#include \"jfr\/jfrEvents.hpp\"\n+#include \"jfr\/support\/jfrObjectAllocationSample.hpp\"\n+#include \"gc\/shared\/threadLocalAllocBuffer.inline.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+static THREAD_LOCAL int64_t _last_allocated_bytes = 0;\n+\n+inline void send_allocation_sample(const Klass* klass, int64_t allocated_bytes) {\n+  assert(allocated_bytes > 0, \"invariant\");\n+  EventObjectAllocationSample event;\n+  if (event.should_commit()) {\n+    const size_t weight = allocated_bytes - _last_allocated_bytes;\n+    assert(weight > 0, \"invariant\");\n+    event.set_objectClass(klass);\n+    event.set_weight(weight);\n+    event.commit();\n+    _last_allocated_bytes = allocated_bytes;\n+  }\n+}\n+\n+inline bool send_allocation_sample_with_result(const Klass* klass, int64_t allocated_bytes) {\n+  assert(allocated_bytes > 0, \"invariant\");\n+  EventObjectAllocationSample event;\n+  if (event.should_commit()) {\n+    const size_t weight = allocated_bytes - _last_allocated_bytes;\n+    assert(weight > 0, \"invariant\");\n+    event.set_objectClass(klass);\n+    event.set_weight(weight);\n+    event.commit();\n+    _last_allocated_bytes = allocated_bytes;\n+    return true;\n+  }\n+  return false;\n+}\n+\n+inline intptr_t estimate_tlab_size_bytes(Thread* thread) {\n+  const size_t desired_tlab_size_bytes = thread->tlab().desired_size() * HeapWordSize;\n+  const size_t alignment_reserve_bytes = thread->tlab().alignment_reserve_in_bytes();\n+  assert(desired_tlab_size_bytes > alignment_reserve_bytes, \"invariant\");\n+  return static_cast<intptr_t>(desired_tlab_size_bytes - alignment_reserve_bytes);\n+}\n+\n+inline int64_t load_allocated_bytes(Thread* thread) {\n+  assert(thread != NULL, \"invariant\");\n+  const int64_t allocated_bytes = thread->allocated_bytes();\n+  if (allocated_bytes < _last_allocated_bytes) {\n+    \/\/ A hw thread can detach and reattach to the VM, and when it does,\n+    \/\/ it gets a new JavaThread representation. The thread local variable\n+    \/\/ tracking _last_allocated_bytes is mapped to the existing hw thread,\n+    \/\/ so it needs to be reset.\n+    _last_allocated_bytes = 0;\n+  }\n+  return allocated_bytes == _last_allocated_bytes ? 0 : allocated_bytes;\n+}\n+\n+\/\/ To avoid large objects from being undersampled compared to the regular TLAB samples,\n+\/\/ the data amount is normalized as if it was a TLAB, giving a number of TLAB sampling attempts to the large object.\n+static void normalize_as_tlab_and_send_allocation_samples(const Klass* klass, intptr_t obj_alloc_size_bytes, Thread* thread) {\n+  const int64_t allocated_bytes = load_allocated_bytes(thread);\n+  assert(allocated_bytes > 0, \"invariant\"); \/\/ obj_alloc_size_bytes is already attributed to allocated_bytes at this point.\n+  if (!UseTLAB) {\n+    send_allocation_sample(klass, allocated_bytes);\n+    return;\n+  }\n+  const intptr_t tlab_size_bytes = estimate_tlab_size_bytes(thread);\n+  if (allocated_bytes - _last_allocated_bytes < tlab_size_bytes) {\n+    return;\n+  }\n+  assert(obj_alloc_size_bytes > 0, \"invariant\");\n+  do {\n+    if (send_allocation_sample_with_result(klass, allocated_bytes)) {\n+      return;\n+    }\n+    obj_alloc_size_bytes -= tlab_size_bytes;\n+  } while (obj_alloc_size_bytes > 0);\n+}\n+\n+JfrObjectAllocationSample::JfrObjectAllocationSample(const Klass* klass, size_t alloc_size, bool outside_tlab, Thread* thread) {\n+  if (outside_tlab) {\n+    normalize_as_tlab_and_send_allocation_samples(klass, static_cast<intptr_t>(alloc_size), thread);\n+    return;\n+  }\n+  const int64_t allocated_bytes = load_allocated_bytes(thread);\n+  if (allocated_bytes == 0) {\n+    return;\n+  }\n+  send_allocation_sample(klass, allocated_bytes);\n+}\n+\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrObjectAllocationSample.cpp","additions":114,"deletions":0,"binary":false,"changes":114,"status":"added"},{"patch":"@@ -0,0 +1,38 @@\n+\/*\n+* Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+* DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+*\n+* This code is free software; you can redistribute it and\/or modify it\n+* under the terms of the GNU General Public License version 2 only, as\n+* published by the Free Software Foundation.\n+*\n+* This code is distributed in the hope that it will be useful, but WITHOUT\n+* ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+* FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+* version 2 for more details (a copy is included in the LICENSE file that\n+* accompanied this code).\n+*\n+* You should have received a copy of the GNU General Public License version\n+* 2 along with this work; if not, write to the Free Software Foundation,\n+* Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+*\n+* Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+* or visit www.oracle.com if you need additional information or have any\n+* questions.\n+*\n+*\/\n+\n+#ifndef SHARE_JFR_SUPPORT_JFROBJECTALLOCATIONSAMPLE_HPP\n+#define SHARE_JFR_SUPPORT_JFROBJECTALLOCATIONSAMPLE_HPP\n+\n+#include \"memory\/allocation.hpp\"\n+\n+class Klass;\n+class Thread;\n+\n+class JfrObjectAllocationSample : public StackObj {\n+  friend class JfrAllocationTracer;\n+  JfrObjectAllocationSample(const Klass* klass, size_t alloc_size, bool outside_tlab, Thread* thread);\n+};\n+\n+#endif\n","filename":"src\/hotspot\/share\/jfr\/support\/jfrObjectAllocationSample.hpp","additions":38,"deletions":0,"binary":false,"changes":38,"status":"added"}]}