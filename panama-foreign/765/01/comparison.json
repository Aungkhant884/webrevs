{"files":[{"patch":"@@ -159,0 +159,4 @@\n+        return primitiveLayoutForSize(size, useFloat).carrier();\n+    }\n+\n+    public static ValueLayout primitiveLayoutForSize(long size, boolean useFloat) {\n@@ -161,1 +165,1 @@\n-                return float.class;\n+                return JAVA_FLOAT;\n@@ -163,1 +167,1 @@\n-                return double.class;\n+                return JAVA_DOUBLE;\n@@ -167,1 +171,1 @@\n-                return byte.class;\n+                return JAVA_BYTE;\n@@ -169,1 +173,1 @@\n-                return short.class;\n+                return JAVA_SHORT;\n@@ -171,1 +175,1 @@\n-                return int.class;\n+                return JAVA_INT;\n@@ -173,1 +177,1 @@\n-                return long.class;\n+                return JAVA_LONG;\n@@ -177,1 +181,1 @@\n-        throw new IllegalArgumentException(\"No type for size: \" + size + \" isFloat=\" + useFloat);\n+        throw new IllegalArgumentException(\"No layout for size: \" + size + \" isFloat=\" + useFloat);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/SharedUtils.java","additions":11,"deletions":7,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+import java.lang.foreign.ValueLayout;\n@@ -68,0 +69,1 @@\n+    private static final int MAX_COPY_SIZE = 8;\n@@ -220,2 +222,2 @@\n-        void alignStack(long alignment) {\n-            stackOffset = Utils.alignUp(stackOffset, alignment);\n+        private boolean hasRegister(int type) {\n+            return hasEnoughRegisters(type, 1);\n@@ -224,11 +226,2 @@\n-        VMStorage stackAlloc(long size, long alignment) {\n-            assert forArguments : \"no stack returns\";\n-            long alignedStackOffset = Utils.alignUp(stackOffset, alignment);\n-\n-            short encodedSize = (short) size;\n-            assert (encodedSize & 0xFFFF) == size;\n-\n-            VMStorage storage =\n-                AArch64Architecture.stackStorage(encodedSize, (int)alignedStackOffset);\n-            stackOffset = alignedStackOffset + size;\n-            return storage;\n+        private boolean hasEnoughRegisters(int type, int count) {\n+            return nRegs[type] + count <= MAX_REGISTER_ARGUMENTS;\n@@ -237,5 +230,7 @@\n-        VMStorage stackAlloc(MemoryLayout layout) {\n-            long stackSlotAlignment = requiresSubSlotStackPacking() && !forVarArgs\n-                    ? layout.byteAlignment()\n-                    : Math.max(layout.byteAlignment(), STACK_SLOT_SIZE);\n-            return stackAlloc(layout.byteSize(), stackSlotAlignment);\n+        private static Class<?> adjustCarrierForStack(Class<?> carrier) {\n+            if (carrier == float.class) {\n+                carrier = int.class;\n+            } else if (carrier == double.class) {\n+                carrier = long.class;\n+            }\n+            return carrier;\n@@ -244,11 +239,46 @@\n-        VMStorage[] regAlloc(int type, int count) {\n-            if (nRegs[type] + count <= MAX_REGISTER_ARGUMENTS) {\n-                ABIDescriptor abiDescriptor = abiDescriptor();\n-                VMStorage[] source =\n-                    (forArguments ? abiDescriptor.inputStorage : abiDescriptor.outputStorage)[type];\n-                VMStorage[] result = new VMStorage[count];\n-                for (int i = 0; i < count; i++) {\n-                    result[i] = source[nRegs[type]++];\n-                }\n-                return result;\n-            } else {\n+        record StructStorage(long offset, Class<?> carrier, VMStorage storage) {}\n+\n+        \/*\n+        In the simplest case structs are copied in chunks. i.e. the fields don't matter, just the size.\n+        The struct is split into 8-byte chunks, and those chunks are either passed in registers and\/or on the stack.\n+\n+        Homogeneous float aggregates (HFAs) can be copied in a field-wise manner, i.e. the struct is split into it's\n+        fields and those fields are the chunks which are passed. For HFAs the rules are more complicated and ABI based:\n+\n+                        | enough registers | some registers, but not enough  | no registers\n+        ----------------+------------------+---------------------------------+-------------------------\n+        Linux           | FW in regs       | CW on the stack                 | CW on the stack\n+        MacOs, non-VA   | FW in regs       | FW on the stack                 | FW on the stack\n+        MacOs, VA       | FW in regs       | CW on the stack                 | CW on the stack\n+        Windows, non-VF | FW in regs       | CW on the stack                 | CW on the stack\n+        Windows, VF     | FW in regs       | CW split between regs and stack | CW on the stack\n+        (where FW = Field-wise copy, CW = Chunk-wise copy, VA is a variadic argument, and VF is a variadic function)\n+\n+        For regular structs, the rules are as follows:\n+\n+                        | enough registers | some registers, but not enough  | no registers\n+        ----------------+------------------+---------------------------------+-------------------------\n+        Linux           | CW in regs       | CW on the stack                 | CW on the stack\n+        MacOs           | CW in regs       | CW on the stack                 | CW on the stack\n+        Windows, non-VF | CW in regs       | CW on the stack                 | CW on the stack\n+        Windows, VF     | CW in regs       | CW split between regs and stack | CW on the stack\n+         *\/\n+        StructStorage[] structStorages(GroupLayout layout, boolean forHFA) {\n+            int regType = forHFA ? StorageType.VECTOR : StorageType.INTEGER;\n+            int numChunks = (int)Utils.alignUp(layout.byteSize(), MAX_COPY_SIZE) \/ MAX_COPY_SIZE;\n+            int requiredStorages = forHFA ? layout.memberLayouts().size() : numChunks;\n+            boolean hasEnoughRegisters = hasEnoughRegisters(regType, requiredStorages);\n+\n+            \/\/ For the ABI variants that pack arguments spilled to the\n+            \/\/ stack, HFA arguments are spilled as if their individual\n+            \/\/ fields had been allocated separately rather than as if the\n+            \/\/ struct had been spilled as a whole.\n+            boolean useFieldWiseSpill = requiresSubSlotStackPacking() && !forVarArgs;\n+            boolean isFieldWise = forHFA && (hasEnoughRegisters || useFieldWiseSpill);\n+            if (!isFieldWise) {\n+                requiredStorages = numChunks;\n+            }\n+\n+            boolean spillPartially = forVariadicFunction && spillsVariadicStructsPartially();\n+            boolean furtherAllocationFromTheStack = !hasEnoughRegisters && !spillPartially;\n+            if (furtherAllocationFromTheStack) {\n@@ -257,2 +287,1 @@\n-                nRegs[type] = MAX_REGISTER_ARGUMENTS;\n-                return null;\n+                nRegs[regType] = MAX_REGISTER_ARGUMENTS;\n@@ -260,1 +289,0 @@\n-        }\n@@ -262,2 +290,5 @@\n-        VMStorage[] regAlloc(int type, MemoryLayout layout) {\n-            boolean spillRegistersPartially = forVariadicFunction && spillsVariadicStructsPartially();\n+            if (requiresSubSlotStackPacking() && !isFieldWise) {\n+                \/\/ Pad to the next stack slot boundary instead of packing\n+                \/\/ additional arguments into the unused space.\n+                alignStack(STACK_SLOT_SIZE);\n+            }\n@@ -265,4 +296,13 @@\n-            return spillRegistersPartially ?\n-                regAllocPartial(type, layout) :\n-                regAlloc(type, requiredRegisters(layout));\n-        }\n+            StructStorage[] structStorages = new StructStorage[requiredStorages];\n+            long offset = 0;\n+            for (int i = 0; i < structStorages.length; i++) {\n+                ValueLayout copyLayout;\n+                if (isFieldWise) {\n+                    \/\/ We only expect to see fields here, no padding (the cast would fail)\n+                    copyLayout = (ValueLayout) layout.memberLayouts().get(i);\n+                } else {\n+                    \/\/ chunk-wise copy\n+                    long copySize = Math.min(layout.byteSize() - offset, MAX_COPY_SIZE);\n+                    boolean useFloat = false; \/\/ never use float for chunk-wise copies\n+                    copyLayout = SharedUtils.primitiveLayoutForSize(copySize, useFloat);\n+                }\n@@ -270,3 +310,10 @@\n-        int requiredRegisters(MemoryLayout layout) {\n-            return (int)Utils.alignUp(layout.byteSize(), 8) \/ 8;\n-        }\n+                VMStorage storage = nextStorage(regType, copyLayout);\n+                Class<?> carrier = copyLayout.carrier();\n+                if (isFieldWise && storage.type() == StorageType.STACK) {\n+                    \/\/ copyLayout is a field of an HFA\n+                    \/\/ Don't use floats on the stack\n+                    carrier = adjustCarrierForStack(carrier);\n+                }\n+                structStorages[i] = new StructStorage(offset, carrier, storage);\n+                offset += copyLayout.byteSize();\n+            }\n@@ -274,4 +321,4 @@\n-        VMStorage[] regAllocPartial(int type, MemoryLayout layout) {\n-            int availableRegisters = MAX_REGISTER_ARGUMENTS - nRegs[type];\n-            if (availableRegisters <= 0) {\n-                return null;\n+            if (requiresSubSlotStackPacking() && !isFieldWise) {\n+                \/\/ Pad to the next stack slot boundary instead of packing\n+                \/\/ additional arguments into the unused space.\n+                alignStack(STACK_SLOT_SIZE);\n@@ -280,2 +327,1 @@\n-            int requestRegisters = Math.min(requiredRegisters(layout), availableRegisters);\n-            return regAlloc(type, requestRegisters);\n+            return structStorages;\n@@ -284,9 +330,3 @@\n-        VMStorage nextStorage(int type, MemoryLayout layout) {\n-            if (type == StorageType.VECTOR) {\n-                boolean forVariadicFunctionArgs = forArguments && forVariadicFunction;\n-                boolean useIntRegsForFloatingPointArgs = forVariadicFunctionArgs && useIntRegsForVariadicFloatingPointArgs();\n-\n-                if (useIntRegsForFloatingPointArgs) {\n-                    type = StorageType.INTEGER;\n-                }\n-            }\n+        private void alignStack(long alignment) {\n+            stackOffset = Utils.alignUp(stackOffset, alignment);\n+        }\n@@ -294,4 +334,4 @@\n-            VMStorage[] storage = regAlloc(type, 1);\n-            if (storage == null) {\n-                return stackAlloc(layout);\n-            }\n+        \/\/ allocate a single ValueLayout, either in a register or on the stack\n+        VMStorage nextStorage(int type, ValueLayout layout) {\n+            return hasRegister(type) ? regAlloc(type) : stackAlloc(layout);\n+        }\n@@ -299,1 +339,4 @@\n-            return storage[0];\n+        private VMStorage regAlloc(int type) {\n+            ABIDescriptor abiDescriptor = abiDescriptor();\n+            VMStorage[] source = (forArguments ? abiDescriptor.inputStorage : abiDescriptor.outputStorage)[type];\n+            return source[nRegs[type]++];\n@@ -302,13 +345,6 @@\n-        VMStorage[] nextStorageForHFA(GroupLayout group) {\n-            final int nFields = group.memberLayouts().size();\n-            VMStorage[] regs = regAlloc(StorageType.VECTOR, nFields);\n-            if (regs == null && requiresSubSlotStackPacking() && !forVarArgs) {\n-                \/\/ For the ABI variants that pack arguments spilled to the\n-                \/\/ stack, HFA arguments are spilled as if their individual\n-                \/\/ fields had been allocated separately rather than as if the\n-                \/\/ struct had been spilled as a whole.\n-\n-                VMStorage[] slots = new VMStorage[nFields];\n-                for (int i = 0; i < nFields; i++) {\n-                    slots[i] = stackAlloc(group.memberLayouts().get(i));\n-                }\n+        private VMStorage stackAlloc(ValueLayout layout) {\n+            assert forArguments : \"no stack returns\";\n+            long stackSlotAlignment = requiresSubSlotStackPacking() && !forVarArgs\n+                    ? layout.byteAlignment()\n+                    : Math.max(layout.byteAlignment(), STACK_SLOT_SIZE);\n+            long alignedStackOffset = Utils.alignUp(stackOffset, stackSlotAlignment);\n@@ -316,4 +352,6 @@\n-                return slots;\n-            } else {\n-                return regs;\n-            }\n+            short encodedSize = (short) layout.byteSize();\n+            assert (encodedSize & 0xFFFF) == layout.byteSize();\n+\n+            VMStorage storage = AArch64Architecture.stackStorage(encodedSize, (int)alignedStackOffset);\n+            stackOffset = alignedStackOffset + layout.byteSize();\n+            return storage;\n@@ -338,55 +376,0 @@\n-        protected void spillStructUnbox(Binding.Builder bindings, MemoryLayout layout) {\n-            \/\/ If a struct has been assigned register or HFA class but\n-            \/\/ there are not enough free registers to hold the entire\n-            \/\/ struct, it must be passed on the stack. I.e. not split\n-            \/\/ between registers and stack.\n-\n-            spillPartialStructUnbox(bindings, layout, 0);\n-        }\n-\n-        protected void spillPartialStructUnbox(Binding.Builder bindings, MemoryLayout layout, long offset) {\n-            while (offset < layout.byteSize()) {\n-                long copy = Math.min(layout.byteSize() - offset, STACK_SLOT_SIZE);\n-                VMStorage storage =\n-                    storageCalculator.stackAlloc(copy, STACK_SLOT_SIZE);\n-                if (offset + STACK_SLOT_SIZE < layout.byteSize()) {\n-                    bindings.dup();\n-                }\n-                Class<?> type = SharedUtils.primitiveCarrierForSize(copy, false);\n-                bindings.bufferLoad(offset, type)\n-                        .vmStore(storage, type);\n-                offset += STACK_SLOT_SIZE;\n-            }\n-\n-            if (requiresSubSlotStackPacking()) {\n-                \/\/ Pad to the next stack slot boundary instead of packing\n-                \/\/ additional arguments into the unused space.\n-                storageCalculator.alignStack(STACK_SLOT_SIZE);\n-            }\n-        }\n-\n-        protected void spillStructBox(Binding.Builder bindings, MemoryLayout layout) {\n-            \/\/ If a struct has been assigned register or HFA class but\n-            \/\/ there are not enough free registers to hold the entire\n-            \/\/ struct, it must be passed on the stack. I.e. not split\n-            \/\/ between registers and stack.\n-\n-            long offset = 0;\n-            while (offset < layout.byteSize()) {\n-                long copy = Math.min(layout.byteSize() - offset, STACK_SLOT_SIZE);\n-                VMStorage storage =\n-                    storageCalculator.stackAlloc(copy, STACK_SLOT_SIZE);\n-                Class<?> type = SharedUtils.primitiveCarrierForSize(copy, false);\n-                bindings.dup()\n-                        .vmLoad(storage, type)\n-                        .bufferStore(offset, type);\n-                offset += STACK_SLOT_SIZE;\n-            }\n-\n-            if (requiresSubSlotStackPacking()) {\n-                \/\/ Pad to the next stack slot boundary instead of packing\n-                \/\/ additional arguments into the unused space.\n-                storageCalculator.alignStack(STACK_SLOT_SIZE);\n-            }\n-        }\n-\n@@ -422,1 +405,1 @@\n-                case STRUCT_REGISTER: {\n+                case STRUCT_REGISTER, STRUCT_HFA -> {\n@@ -424,16 +407,3 @@\n-                    VMStorage[] regs = storageCalculator.regAlloc(StorageType.INTEGER, layout);\n-\n-                    if (regs != null) {\n-                        int regIndex = 0;\n-                        long offset = 0;\n-                        while (offset < layout.byteSize() && regIndex < regs.length) {\n-                            final long copy = Math.min(layout.byteSize() - offset, 8);\n-                            VMStorage storage = regs[regIndex++];\n-                            Class<?> type = SharedUtils.primitiveCarrierForSize(copy, false);\n-                            if (offset + copy < layout.byteSize()) {\n-                                bindings.dup();\n-                            }\n-                            bindings.bufferLoad(offset, type)\n-                                    .vmStore(storage, type);\n-                            offset += copy;\n-                        }\n+                    boolean forHFA = argumentClass == TypeClass.STRUCT_HFA;\n+                    StorageCalculator.StructStorage[] structStorages\n+                            = storageCalculator.structStorages((GroupLayout) layout, forHFA);\n@@ -441,3 +411,4 @@\n-                        final long bytesLeft = Math.min(layout.byteSize() - offset, 8);\n-                        if (bytesLeft > 0) {\n-                            spillPartialStructUnbox(bindings, layout, offset);\n+                    for (int i = 0; i < structStorages.length; i++) {\n+                        StorageCalculator.StructStorage structStorage = structStorages[i];\n+                        if (i < structStorages.length - 1) {\n+                            bindings.dup();\n@@ -445,2 +416,2 @@\n-                    } else {\n-                        spillStructUnbox(bindings, layout);\n+                        bindings.bufferLoad(structStorage.offset(), structStorage.carrier())\n+                                .vmStore(structStorage.storage(), structStorage.carrier());\n@@ -448,1 +419,0 @@\n-                    break;\n@@ -450,1 +420,1 @@\n-                case STRUCT_REFERENCE: {\n+                case STRUCT_REFERENCE -> {\n@@ -454,2 +424,1 @@\n-                    VMStorage storage = storageCalculator.nextStorage(\n-                        StorageType.INTEGER, AArch64.C_POINTER);\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.INTEGER, AArch64.C_POINTER);\n@@ -457,24 +426,0 @@\n-                    break;\n-                }\n-                case STRUCT_HFA: {\n-                    assert carrier == MemorySegment.class;\n-                    GroupLayout group = (GroupLayout)layout;\n-                    VMStorage[] regs = storageCalculator.nextStorageForHFA(group);\n-                    if (regs != null) {\n-                        long offset = 0;\n-                        for (int i = 0; i < group.memberLayouts().size(); i++) {\n-                            VMStorage storage = regs[i];\n-                            final long size = group.memberLayouts().get(i).byteSize();\n-                            boolean useFloat = storage.type() == StorageType.VECTOR;\n-                            Class<?> type = SharedUtils.primitiveCarrierForSize(size, useFloat);\n-                            if (i + 1 < group.memberLayouts().size()) {\n-                                bindings.dup();\n-                            }\n-                            bindings.bufferLoad(offset, type)\n-                                    .vmStore(storage, type);\n-                            offset += size;\n-                        }\n-                    } else {\n-                        spillStructUnbox(bindings, layout);\n-                    }\n-                    break;\n@@ -482,1 +427,1 @@\n-                case POINTER: {\n+                case POINTER -> {\n@@ -484,2 +429,1 @@\n-                    VMStorage storage =\n-                        storageCalculator.nextStorage(StorageType.INTEGER, layout);\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.INTEGER, (ValueLayout) layout);\n@@ -487,1 +431,0 @@\n-                    break;\n@@ -489,3 +432,2 @@\n-                case INTEGER: {\n-                    VMStorage storage =\n-                        storageCalculator.nextStorage(StorageType.INTEGER, layout);\n+                case INTEGER -> {\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.INTEGER, (ValueLayout) layout);\n@@ -493,1 +435,0 @@\n-                    break;\n@@ -495,3 +436,6 @@\n-                case FLOAT: {\n-                    VMStorage storage =\n-                        storageCalculator.nextStorage(StorageType.VECTOR, layout);\n+                case FLOAT -> {\n+                    boolean forVariadicFunctionArgs = forArguments && forVariadicFunction;\n+                    boolean useIntReg = forVariadicFunctionArgs && useIntRegsForVariadicFloatingPointArgs();\n+\n+                    int type = useIntReg ? StorageType.INTEGER : StorageType.VECTOR;\n+                    VMStorage storage = storageCalculator.nextStorage(type, (ValueLayout) layout);\n@@ -499,1 +443,0 @@\n-                    break;\n@@ -501,2 +444,1 @@\n-                default:\n-                    throw new UnsupportedOperationException(\"Unhandled class \" + argumentClass);\n+                default -> throw new UnsupportedOperationException(\"Unhandled class \" + argumentClass);\n@@ -526,1 +468,1 @@\n-                case STRUCT_REGISTER -> {\n+                case STRUCT_REGISTER, STRUCT_HFA -> {\n@@ -528,0 +470,1 @@\n+                    boolean forHFA = argumentClass == TypeClass.STRUCT_HFA;\n@@ -529,17 +472,7 @@\n-                    VMStorage[] regs = storageCalculator.regAlloc(\n-                            StorageType.INTEGER, layout);\n-                    if (regs != null) {\n-                        int regIndex = 0;\n-                        long offset = 0;\n-                        while (offset < layout.byteSize()) {\n-                            final long copy = Math.min(layout.byteSize() - offset, 8);\n-                            VMStorage storage = regs[regIndex++];\n-                            bindings.dup();\n-                            boolean useFloat = storage.type() == StorageType.VECTOR;\n-                            Class<?> type = SharedUtils.primitiveCarrierForSize(copy, useFloat);\n-                            bindings.vmLoad(storage, type)\n-                                    .bufferStore(offset, type);\n-                            offset += copy;\n-                        }\n-                    } else {\n-                        spillStructBox(bindings, layout);\n+                    StorageCalculator.StructStorage[] structStorages\n+                            = storageCalculator.structStorages((GroupLayout) layout, forHFA);\n+\n+                    for (StorageCalculator.StructStorage structStorage : structStorages) {\n+                        bindings.dup();\n+                        bindings.vmLoad(structStorage.storage(), structStorage.carrier())\n+                                .bufferStore(structStorage.offset(), structStorage.carrier());\n@@ -550,2 +483,1 @@\n-                    VMStorage storage = storageCalculator.nextStorage(\n-                            StorageType.INTEGER, AArch64.C_POINTER);\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.INTEGER, AArch64.C_POINTER);\n@@ -555,21 +487,0 @@\n-                case STRUCT_HFA -> {\n-                    assert carrier == MemorySegment.class;\n-                    bindings.allocate(layout);\n-                    GroupLayout group = (GroupLayout) layout;\n-                    VMStorage[] regs = storageCalculator.nextStorageForHFA(group);\n-                    if (regs != null) {\n-                        long offset = 0;\n-                        for (int i = 0; i < group.memberLayouts().size(); i++) {\n-                            VMStorage storage = regs[i];\n-                            final long size = group.memberLayouts().get(i).byteSize();\n-                            boolean useFloat = storage.type() == StorageType.VECTOR;\n-                            Class<?> type = SharedUtils.primitiveCarrierForSize(size, useFloat);\n-                            bindings.dup()\n-                                    .vmLoad(storage, type)\n-                                    .bufferStore(offset, type);\n-                            offset += size;\n-                        }\n-                    } else {\n-                        spillStructBox(bindings, layout);\n-                    }\n-                }\n@@ -577,2 +488,1 @@\n-                    VMStorage storage =\n-                            storageCalculator.nextStorage(StorageType.INTEGER, layout);\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.INTEGER, (ValueLayout) layout);\n@@ -583,2 +493,1 @@\n-                    VMStorage storage =\n-                            storageCalculator.nextStorage(StorageType.INTEGER, layout);\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.INTEGER, (ValueLayout) layout);\n@@ -588,2 +497,1 @@\n-                    VMStorage storage =\n-                            storageCalculator.nextStorage(StorageType.VECTOR, layout);\n+                    VMStorage storage = storageCalculator.nextStorage(StorageType.VECTOR, (ValueLayout) layout);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/foreign\/abi\/aarch64\/CallArranger.java","additions":152,"deletions":244,"binary":false,"changes":396,"status":"modified"},{"patch":"@@ -283,0 +283,109 @@\n+\n+    \/\/ structs that are passed field-wise should not have padding after them\n+    @Test\n+    public void testMacArgsOnStack5() {\n+        StructLayout struct = MemoryLayout.structLayout(\n+            C_FLOAT\n+        );\n+        MethodType mt = MethodType.methodType(void.class,\n+                long.class, long.class, long.class, long.class,\n+                long.class, long.class, long.class, long.class,\n+                double.class, double.class, double.class, double.class,\n+                double.class, double.class, double.class, double.class,\n+                MemorySegment.class, int.class, MemorySegment.class);\n+        FunctionDescriptor fd = FunctionDescriptor.ofVoid(\n+                C_LONG_LONG, C_LONG_LONG, C_LONG_LONG, C_LONG_LONG,\n+                C_LONG_LONG, C_LONG_LONG, C_LONG_LONG, C_LONG_LONG,\n+                C_DOUBLE, C_DOUBLE, C_DOUBLE, C_DOUBLE,\n+                C_DOUBLE, C_DOUBLE, C_DOUBLE, C_DOUBLE,\n+                struct, C_INT, C_POINTER);\n+        CallArranger.Bindings bindings = CallArranger.MACOS.getBindings(mt, fd, false);\n+\n+        assertFalse(bindings.isInMemoryReturn());\n+        CallingSequence callingSequence = bindings.callingSequence();\n+        assertEquals(callingSequence.callerMethodType(), mt.insertParameterTypes(0, MemorySegment.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n+\n+        checkArgumentBindings(callingSequence, new Binding[][]{\n+            { unboxAddress(), vmStore(TARGET_ADDRESS_STORAGE, long.class) },\n+            { vmStore(r0, long.class) },\n+            { vmStore(r1, long.class) },\n+            { vmStore(r2, long.class) },\n+            { vmStore(r3, long.class) },\n+            { vmStore(r4, long.class) },\n+            { vmStore(r5, long.class) },\n+            { vmStore(r6, long.class) },\n+            { vmStore(r7, long.class) },\n+            { vmStore(v0, double.class) },\n+            { vmStore(v1, double.class) },\n+            { vmStore(v2, double.class) },\n+            { vmStore(v3, double.class) },\n+            { vmStore(v4, double.class) },\n+            { vmStore(v5, double.class) },\n+            { vmStore(v6, double.class) },\n+            { vmStore(v7, double.class) },\n+            {\n+                bufferLoad(0, int.class),\n+                vmStore(stackStorage((short) 4, 0), int.class),\n+            },\n+            { vmStore(stackStorage((short) 4, 4), int.class) },\n+            { unboxAddress(), vmStore(stackStorage((short) 8, 8), long.class) },\n+        });\n+\n+        checkReturnBindings(callingSequence, new Binding[]{});\n+    }\n+\n+    \/\/ structs that are passed chunk-wise should have padding before them, as well as after\n+    @Test\n+    public void testMacArgsOnStack6() {\n+        StructLayout struct = MemoryLayout.structLayout(\n+            C_INT\n+        );\n+        MethodType mt = MethodType.methodType(void.class,\n+                long.class, long.class, long.class, long.class,\n+                long.class, long.class, long.class, long.class,\n+                double.class, double.class, double.class, double.class,\n+                double.class, double.class, double.class, double.class,\n+                int.class, MemorySegment.class, double.class, MemorySegment.class);\n+        FunctionDescriptor fd = FunctionDescriptor.ofVoid(\n+                C_LONG_LONG, C_LONG_LONG, C_LONG_LONG, C_LONG_LONG,\n+                C_LONG_LONG, C_LONG_LONG, C_LONG_LONG, C_LONG_LONG,\n+                C_DOUBLE, C_DOUBLE, C_DOUBLE, C_DOUBLE,\n+                C_DOUBLE, C_DOUBLE, C_DOUBLE, C_DOUBLE,\n+                C_INT, struct, C_DOUBLE, C_POINTER);\n+        CallArranger.Bindings bindings = CallArranger.MACOS.getBindings(mt, fd, false);\n+\n+        assertFalse(bindings.isInMemoryReturn());\n+        CallingSequence callingSequence = bindings.callingSequence();\n+        assertEquals(callingSequence.callerMethodType(), mt.insertParameterTypes(0, MemorySegment.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n+\n+        checkArgumentBindings(callingSequence, new Binding[][]{\n+            { unboxAddress(), vmStore(TARGET_ADDRESS_STORAGE, long.class) },\n+            { vmStore(r0, long.class) },\n+            { vmStore(r1, long.class) },\n+            { vmStore(r2, long.class) },\n+            { vmStore(r3, long.class) },\n+            { vmStore(r4, long.class) },\n+            { vmStore(r5, long.class) },\n+            { vmStore(r6, long.class) },\n+            { vmStore(r7, long.class) },\n+            { vmStore(v0, double.class) },\n+            { vmStore(v1, double.class) },\n+            { vmStore(v2, double.class) },\n+            { vmStore(v3, double.class) },\n+            { vmStore(v4, double.class) },\n+            { vmStore(v5, double.class) },\n+            { vmStore(v6, double.class) },\n+            { vmStore(v7, double.class) },\n+            { vmStore(stackStorage((short) 4, 0), int.class) },\n+            {\n+                bufferLoad(0, int.class),\n+                vmStore(stackStorage((short) 4, 8), int.class),\n+            },\n+            { vmStore(stackStorage((short) 8, 16), double.class) },\n+            { unboxAddress(), vmStore(stackStorage((short) 8, 24), long.class) },\n+        });\n+\n+        checkReturnBindings(callingSequence, new Binding[]{});\n+    }\n","filename":"test\/jdk\/java\/foreign\/callarranger\/TestMacOsAArch64CallArranger.java","additions":109,"deletions":0,"binary":false,"changes":109,"status":"modified"}]}