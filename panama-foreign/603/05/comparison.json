{"files":[{"patch":"@@ -69,0 +69,3 @@\n+  abi._target_addr_reg = parse_vmstorage(abi_oop->obj_field(ABI.targetAddrStorage_offset))->as_Register();\n+  abi._ret_buf_addr_reg = parse_vmstorage(abi_oop->obj_field(ABI.retBufAddrStorage_offset))->as_Register();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/foreign_globals_aarch64.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -45,0 +45,3 @@\n+  Register _target_addr_reg;\n+  Register _ret_buf_addr_reg;\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/foreign_globals_aarch64.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"runtime\/stubCodeGenerator.hpp\"\n@@ -37,98 +38,0 @@\n-void ProgrammableInvoker::Generator::generate() {\n-  __ enter();\n-\n-  \/\/ Name registers used in the stub code. These are all caller-save so\n-  \/\/ may be clobbered by the call to the native function. Avoid using\n-  \/\/ rscratch1 here as it's r8 which is the indirect result register in\n-  \/\/ the standard ABI.\n-  Register Rctx = r10, Rstack_size = r11;\n-  Register Rwords = r12, Rtmp = r13;\n-  Register Rsrc_ptr = r14, Rdst_ptr = r15;\n-\n-  assert_different_registers(Rctx, Rstack_size, rscratch1, rscratch2);\n-\n-  \/\/ TODO: if the callee is not using the standard C ABI then we need to\n-  \/\/       preserve more registers here.\n-\n-  __ block_comment(\"init_and_alloc_stack\");\n-\n-  __ mov(Rctx, c_rarg0);\n-  __ str(Rctx, Address(__ pre(sp, -2 * wordSize)));\n-\n-  assert(_abi->_stack_alignment_bytes % 16 == 0, \"stack must be 16 byte aligned\");\n-\n-  __ block_comment(\"allocate_stack\");\n-  __ ldr(Rstack_size, Address(Rctx, (int) _layout->stack_args_bytes));\n-  __ add(rscratch2, Rstack_size, _abi->_stack_alignment_bytes - 1);\n-  __ andr(rscratch2, rscratch2, -_abi->_stack_alignment_bytes);\n-  __ sub(sp, sp, rscratch2);\n-\n-  __ block_comment(\"load_arguments\");\n-\n-  __ ldr(Rsrc_ptr, Address(Rctx, (int) _layout->stack_args));\n-  __ lsr(Rwords, Rstack_size, LogBytesPerWord);\n-  __ mov(Rdst_ptr, sp);\n-\n-  Label Ldone, Lnext;\n-  __ bind(Lnext);\n-  __ cbz(Rwords, Ldone);\n-  __ ldr(Rtmp, __ post(Rsrc_ptr, wordSize));\n-  __ str(Rtmp, __ post(Rdst_ptr, wordSize));\n-  __ sub(Rwords, Rwords, 1);\n-  __ b(Lnext);\n-  __ bind(Ldone);\n-\n-  for (int i = 0; i < _abi->_vector_argument_registers.length(); i++) {\n-    ssize_t offs = _layout->arguments_vector + i * float_reg_size;\n-    __ ldrq(_abi->_vector_argument_registers.at(i), Address(Rctx, offs));\n-  }\n-\n-  for (int i = 0; i < _abi->_integer_argument_registers.length(); i++) {\n-    ssize_t offs = _layout->arguments_integer + i * sizeof(uintptr_t);\n-    __ ldr(_abi->_integer_argument_registers.at(i), Address(Rctx, offs));\n-  }\n-\n-  assert(_abi->_shadow_space_bytes == 0, \"shadow space not supported on AArch64\");\n-\n-  \/\/ call target function\n-  __ block_comment(\"call target function\");\n-  __ ldr(rscratch2, Address(Rctx, (int) _layout->arguments_next_pc));\n-  __ blr(rscratch2);\n-\n-  __ ldr(Rctx, Address(rfp, -2 * wordSize));   \/\/ Might have clobbered Rctx\n-\n-  __ block_comment(\"store_registers\");\n-\n-  for (int i = 0; i < _abi->_integer_return_registers.length(); i++) {\n-    ssize_t offs = _layout->returns_integer + i * sizeof(uintptr_t);\n-    __ str(_abi->_integer_return_registers.at(i), Address(Rctx, offs));\n-  }\n-\n-  for (int i = 0; i < _abi->_vector_return_registers.length(); i++) {\n-    ssize_t offs = _layout->returns_vector + i * float_reg_size;\n-    __ strq(_abi->_vector_return_registers.at(i), Address(Rctx, offs));\n-  }\n-\n-  __ leave();\n-  __ ret(lr);\n-\n-  __ flush();\n-}\n-\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  ResourceMark rm;\n-  const ABIDescriptor abi = ForeignGlobals::parse_abi_descriptor(jabi);\n-  const BufferLayout layout = ForeignGlobals::parse_buffer_layout(jlayout);\n-\n-  BufferBlob* _invoke_native_blob = BufferBlob::create(\"invoke_native_blob\", native_invoker_size);\n-\n-  CodeBuffer code2(_invoke_native_blob);\n-  ProgrammableInvoker::Generator g2(&code2, &abi, &layout);\n-  g2.generate();\n-  code2.log_section_sizes(\"InvokeNativeBlob\");\n-\n-  return _invoke_native_blob->code_begin();\n-}\n-\n-\/\/ ---------------------------------------------------------------\n-\n@@ -139,1 +42,1 @@\n-  int _shadow_space_bytes;\n+  const ABIDescriptor& _abi;\n@@ -144,0 +47,2 @@\n+  bool _needs_return_buffer;\n+\n@@ -152,1 +57,1 @@\n-                         int shadow_space_bytes,\n+                         const ABIDescriptor& abi,\n@@ -154,1 +59,2 @@\n-                         const GrowableArray<VMReg>& output_registers)\n+                         const GrowableArray<VMReg>& output_registers,\n+                         bool needs_return_buffer)\n@@ -159,1 +65,1 @@\n-     _shadow_space_bytes(shadow_space_bytes),\n+     _abi(abi),\n@@ -162,0 +68,1 @@\n+     _needs_return_buffer(needs_return_buffer),\n@@ -165,2 +72,0 @@\n-    assert(_output_registers.length() <= 1\n-           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n@@ -182,7 +87,0 @@\n-\n-private:\n-#ifdef ASSERT\n-  bool target_uses_register(VMReg reg) {\n-    return _input_registers.contains(reg) || _output_registers.contains(reg);\n-  }\n-#endif\n@@ -196,1 +94,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -198,1 +96,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -201,1 +100,1 @@\n-  NativeInvokerGenerator g(&code, signature, num_args, ret_bt, shadow_space_bytes, input_registers, output_registers);\n+  NativeInvokerGenerator g(&code, signature, num_args, ret_bt, abi, input_registers, output_registers, needs_return_buffer);\n@@ -220,7 +119,0 @@\n-  \/\/ we can't use rscratch1 because it is r8, and used by the ABI\n-  Register tmp1 = r9;\n-  Register tmp2 = r10;\n-  assert(!target_uses_register(tmp1->as_VMReg()), \"conflict\");\n-  assert(!target_uses_register(tmp2->as_VMReg()), \"conflict\");\n-  assert(!target_uses_register(rthread->as_VMReg()), \"conflict\");\n-\n@@ -238,1 +130,4 @@\n-  Register input_addr_reg = tmp1;\n+  \/\/ we can't use rscratch1 because it is r8, and used by the ABI\n+  Register tmp1 = r9;\n+  Register tmp2 = r10;\n+\n@@ -241,1 +136,1 @@\n-  DowncallNativeCallConv out_conv(_input_registers, input_addr_reg->as_VMReg());\n+  NativeCallConv out_conv(_input_registers);\n@@ -253,0 +148,13 @@\n+  int allocated_frame_size = 0;\n+  if (_needs_return_buffer) {\n+    allocated_frame_size += 8; \/\/ for address spill\n+  }\n+  allocated_frame_size += arg_shuffle.out_arg_stack_slots() <<LogBytesPerInt;\n+  assert(_abi._shadow_space_bytes == 0, \"not expecting shadow space on AArch64\");\n+\n+  int ret_buf_addr_sp_offset = -1;\n+  if (_needs_return_buffer) {\n+     \/\/ in sync with the above\n+     ret_buf_addr_sp_offset = allocated_frame_size - 8;\n+  }\n+\n@@ -254,1 +162,9 @@\n-  int spill_offset = 0;\n+  int spill_offset = -1;\n+\n+  if (!_needs_return_buffer) {\n+    spill_offset = 0;\n+    \/\/ spill area can be shared with the above, so we take the max of the 2\n+    allocated_frame_size = out_reg_spiller.spill_size_bytes() > allocated_frame_size\n+      ? out_reg_spiller.spill_size_bytes()\n+      : allocated_frame_size;\n+  }\n@@ -256,1 +172,0 @@\n-  assert(_shadow_space_bytes == 0, \"not expecting shadow space on AArch64\");\n@@ -258,2 +173,1 @@\n-    + (out_reg_spiller.spill_size_bytes() >> LogBytesPerInt)\n-    + arg_shuffle.out_arg_stack_slots(), 4);\n+    + (allocated_frame_size >> LogBytesPerInt), 4);\n@@ -263,2 +177,0 @@\n-  MacroAssembler* masm = _masm;\n-\n@@ -285,1 +197,5 @@\n-  arg_shuffle.generate(_masm, shuffle_reg->as_VMReg(), 0, _shadow_space_bytes);\n+  arg_shuffle.generate(_masm, shuffle_reg->as_VMReg(), 0, _abi._shadow_space_bytes);\n+  if (_needs_return_buffer) {\n+    assert(ret_buf_addr_sp_offset != -1, \"no return buffer addr spill\");\n+    __ str(_abi._ret_buf_addr_reg, Address(sp, ret_buf_addr_sp_offset));\n+  }\n@@ -288,16 +204,35 @@\n-  __ blr(input_addr_reg);\n-\n-  \/\/ Unpack native results.\n-  switch (_ret_bt) {\n-    case T_BOOLEAN: __ c2bool(r0);                     break;\n-    case T_CHAR   : __ ubfx(r0, r0, 0, 16);            break;\n-    case T_BYTE   : __ sbfx(r0, r0, 0, 8);             break;\n-    case T_SHORT  : __ sbfx(r0, r0, 0, 16);            break;\n-    case T_INT    : __ sbfx(r0, r0, 0, 32);            break;\n-    case T_DOUBLE :\n-    case T_FLOAT  :\n-      \/\/ Result is in v0 we'll save as needed\n-      break;\n-    case T_VOID: break;\n-    case T_LONG: break;\n-    default       : ShouldNotReachHere();\n+  __ blr(_abi._target_addr_reg);\n+  \/\/ this call is assumed not to have killed rthread\n+\n+  if (!_needs_return_buffer) {\n+    \/\/ Unpack native results.\n+    switch (_ret_bt) {\n+      case T_BOOLEAN: __ c2bool(r0);                     break;\n+      case T_CHAR   : __ ubfx(r0, r0, 0, 16);            break;\n+      case T_BYTE   : __ sbfx(r0, r0, 0, 8);             break;\n+      case T_SHORT  : __ sbfx(r0, r0, 0, 16);            break;\n+      case T_INT    : __ sbfx(r0, r0, 0, 32);            break;\n+      case T_DOUBLE :\n+      case T_FLOAT  :\n+        \/\/ Result is in v0 we'll save as needed\n+        break;\n+      case T_VOID: break;\n+      case T_LONG: break;\n+      default       : ShouldNotReachHere();\n+    }\n+  } else {\n+    assert(ret_buf_addr_sp_offset != -1, \"no return buffer addr spill\");\n+    __ ldr(tmp1, Address(sp, ret_buf_addr_sp_offset));\n+    int offset = 0;\n+    for (int i = 0; i < _output_registers.length(); i++) {\n+      VMReg reg = _output_registers.at(i);\n+      if (reg->is_Register()) {\n+        __ str(reg->as_Register(), Address(tmp1, offset));\n+        offset += 8;\n+      } else if(reg->is_FloatRegister()) {\n+        __ strd(reg->as_FloatRegister(), Address(tmp1, offset));\n+        offset += 16;\n+      } else {\n+        ShouldNotReachHere();\n+      }\n+    }\n@@ -348,2 +283,4 @@\n-  \/\/ Need to save the native result registers around any runtime calls.\n-  out_reg_spiller.generate_spill(_masm, spill_offset);\n+  if (!_needs_return_buffer) {\n+    \/\/ Need to save the native result registers around any runtime calls.\n+    out_reg_spiller.generate_spill(_masm, spill_offset);\n+  }\n@@ -356,1 +293,3 @@\n-  out_reg_spiller.generate_fill(_masm, spill_offset);\n+  if (!_needs_return_buffer) {\n+    out_reg_spiller.generate_fill(_masm, spill_offset);\n+  }\n@@ -366,1 +305,3 @@\n-  out_reg_spiller.generate_spill(_masm, spill_offset);\n+  if (!_needs_return_buffer) {\n+    out_reg_spiller.generate_spill(_masm, spill_offset);\n+  }\n@@ -370,1 +311,3 @@\n-  out_reg_spiller.generate_fill(_masm, spill_offset);\n+  if (!_needs_return_buffer) {\n+    out_reg_spiller.generate_fill(_masm, spill_offset);\n+  }\n@@ -380,4 +323,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return true;\n-}\n","filename":"src\/hotspot\/cpu\/aarch64\/universalNativeInvoker_aarch64.cpp","additions":94,"deletions":155,"binary":false,"changes":249,"status":"modified"},{"patch":"@@ -28,5 +28,0 @@\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  Unimplemented();\n-  return nullptr;\n-}\n-\n@@ -36,1 +31,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -38,1 +33,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -42,4 +38,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return false;\n-}\n","filename":"src\/hotspot\/cpu\/arm\/universalNativeInvoker_arm.cpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -29,5 +29,0 @@\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  Unimplemented();\n-  return nullptr;\n-}\n-\n@@ -37,1 +32,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -39,1 +34,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -43,4 +39,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return false;\n-}\n","filename":"src\/hotspot\/cpu\/ppc\/universalNativeInvoker_ppc.cpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -28,5 +28,0 @@\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  Unimplemented();\n-  return nullptr;\n-}\n-\n@@ -36,1 +31,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -38,1 +33,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -42,4 +38,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return false;\n-}\n","filename":"src\/hotspot\/cpu\/s390\/universalNativeInvoker_s390.cpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -68,0 +68,3 @@\n+  abi._target_addr_reg = parse_vmstorage(abi_oop->obj_field(ABI.targetAddrStorage_offset))->as_Register();\n+  abi._ret_buf_addr_reg = parse_vmstorage(abi_oop->obj_field(ABI.retBufAddrStorage_offset))->as_Register();\n+\n@@ -106,4 +109,1 @@\n-    oop storage = arg_regs_oop->obj_at(i);\n-    jint index = storage->int_field(VMS.index_offset);\n-    jint type = storage->int_field(VMS.type_offset);\n-    result._arg_regs[i] = vmstorage_to_vmreg(type, index);\n+    result._arg_regs[i] = parse_vmstorage(arg_regs_oop->obj_at(i));\n@@ -113,4 +113,1 @@\n-    oop storage = ret_regs_oop->obj_at(i);\n-    jint index = storage->int_field(VMS.index_offset);\n-    jint type = storage->int_field(VMS.type_offset);\n-    result._ret_regs[i] = vmstorage_to_vmreg(type, index);\n+    result._ret_regs[i] = parse_vmstorage(ret_regs_oop->obj_at(i));\n","filename":"src\/hotspot\/cpu\/x86\/foreign_globals_x86.cpp","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -35,5 +35,5 @@\n-    GrowableArray<Register> _integer_argument_registers;\n-    GrowableArray<Register> _integer_return_registers;\n-    GrowableArray<XMMRegister> _vector_argument_registers;\n-    GrowableArray<XMMRegister> _vector_return_registers;\n-    size_t _X87_return_registers_noof;\n+  GrowableArray<Register> _integer_argument_registers;\n+  GrowableArray<Register> _integer_return_registers;\n+  GrowableArray<XMMRegister> _vector_argument_registers;\n+  GrowableArray<XMMRegister> _vector_return_registers;\n+  size_t _X87_return_registers_noof;\n@@ -41,2 +41,2 @@\n-    GrowableArray<Register> _integer_additional_volatile_registers;\n-    GrowableArray<XMMRegister> _vector_additional_volatile_registers;\n+  GrowableArray<Register> _integer_additional_volatile_registers;\n+  GrowableArray<XMMRegister> _vector_additional_volatile_registers;\n@@ -44,2 +44,2 @@\n-    int32_t _stack_alignment_bytes;\n-    int32_t _shadow_space_bytes;\n+  int32_t _stack_alignment_bytes;\n+  int32_t _shadow_space_bytes;\n@@ -47,2 +47,5 @@\n-    bool is_volatile_reg(Register reg) const;\n-    bool is_volatile_reg(XMMRegister reg) const;\n+  Register _target_addr_reg;\n+  Register _ret_buf_addr_reg;\n+\n+  bool is_volatile_reg(Register reg) const;\n+  bool is_volatile_reg(XMMRegister reg) const;\n","filename":"src\/hotspot\/cpu\/x86\/foreign_globals_x86.hpp","additions":14,"deletions":11,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -27,9 +27,0 @@\n-void ProgrammableInvoker::Generator::generate() {\n-  Unimplemented();\n-}\n-\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  Unimplemented();\n-  return nullptr;\n-}\n-\n@@ -39,1 +30,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -41,1 +32,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -45,4 +37,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return false;\n-}\n","filename":"src\/hotspot\/cpu\/x86\/universalNativeInvoker_x86_32.cpp","additions":3,"deletions":15,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/stubCodeGenerator.hpp\"\n@@ -36,119 +37,0 @@\n-void ProgrammableInvoker::Generator::generate() {\n-  __ enter();\n-\n-  \/\/ Put the context pointer in ebx\/rbx - it's going to be heavily used below both before and after the call\n-  Register ctxt_reg = rbx;\n-  Register used_regs[] = { ctxt_reg, rcx, rsi, rdi };\n-  GrowableArray<Register> preserved_regs;\n-\n-  for (size_t i = 0; i < sizeof(used_regs)\/sizeof(Register); i++) {\n-    Register used_reg = used_regs[i];\n-    if (!_abi->is_volatile_reg(used_reg)) {\n-      preserved_regs.push(used_reg);\n-    }\n-  }\n-\n-  __ block_comment(\"init_and_alloc_stack\");\n-\n-  for (int i = 0; i < preserved_regs.length(); i++) {\n-    __ push(preserved_regs.at(i));\n-  }\n-\n-  __ movptr(ctxt_reg, c_rarg0); \/\/ FIXME c args? or java?\n-\n-  __ block_comment(\"allocate_stack\");\n-  __ movptr(rcx, Address(ctxt_reg, (int) _layout->stack_args_bytes));\n-  __ subptr(rsp, rcx);\n-  __ andptr(rsp, -_abi->_stack_alignment_bytes);\n-\n-  \/\/ Note: rcx is used below!\n-\n-\n-  __ block_comment(\"load_arguments\");\n-\n-  __ shrptr(rcx, LogBytesPerWord); \/\/ bytes -> words\n-  __ movptr(rsi, Address(ctxt_reg, (int) _layout->stack_args));\n-  __ movptr(rdi, rsp);\n-  __ rep_mov();\n-\n-\n-  for (int i = 0; i < _abi->_vector_argument_registers.length(); i++) {\n-    \/\/ [1] -> 64 bit -> xmm\n-    \/\/ [2] -> 128 bit -> xmm\n-    \/\/ [4] -> 256 bit -> ymm\n-    \/\/ [8] -> 512 bit -> zmm\n-\n-    XMMRegister reg = _abi->_vector_argument_registers.at(i);\n-    size_t offs = _layout->arguments_vector + i * xmm_reg_size;\n-    __ movdqu(reg, Address(ctxt_reg, (int)offs));\n-  }\n-\n-  for (int i = 0; i < _abi->_integer_argument_registers.length(); i++) {\n-    size_t offs = _layout->arguments_integer + i * sizeof(uintptr_t);\n-    __ movptr(_abi->_integer_argument_registers.at(i), Address(ctxt_reg, (int)offs));\n-  }\n-\n-  if (_abi->_shadow_space_bytes != 0) {\n-    __ block_comment(\"allocate shadow space for argument register spill\");\n-    __ subptr(rsp, _abi->_shadow_space_bytes);\n-  }\n-\n-  \/\/ call target function\n-  __ block_comment(\"call target function\");\n-  __ call(Address(ctxt_reg, (int) _layout->arguments_next_pc));\n-\n-  if (_abi->_shadow_space_bytes != 0) {\n-    __ block_comment(\"pop shadow space\");\n-    __ addptr(rsp, _abi->_shadow_space_bytes);\n-  }\n-\n-  __ block_comment(\"store_registers\");\n-  for (int i = 0; i < _abi->_integer_return_registers.length(); i++) {\n-    ssize_t offs = _layout->returns_integer + i * sizeof(uintptr_t);\n-    __ movptr(Address(ctxt_reg, offs), _abi->_integer_return_registers.at(i));\n-  }\n-\n-  for (int i = 0; i < _abi->_vector_return_registers.length(); i++) {\n-    \/\/ [1] -> 64 bit -> xmm\n-    \/\/ [2] -> 128 bit -> xmm (SSE)\n-    \/\/ [4] -> 256 bit -> ymm (AVX)\n-    \/\/ [8] -> 512 bit -> zmm (AVX-512, aka AVX3)\n-\n-    XMMRegister reg = _abi->_vector_return_registers.at(i);\n-    size_t offs = _layout->returns_vector + i * xmm_reg_size;\n-    __ movdqu(Address(ctxt_reg, (int)offs), reg);\n-  }\n-\n-  for (size_t i = 0; i < _abi->_X87_return_registers_noof; i++) {\n-    size_t offs = _layout->returns_x87 + i * (sizeof(long double));\n-    __ fstp_x(Address(ctxt_reg, (int)offs)); \/\/pop ST(0)\n-  }\n-\n-  \/\/ Restore backed up preserved register\n-  for (int i = 0; i < preserved_regs.length(); i++) {\n-    __ movptr(preserved_regs.at(i), Address(rbp, -(int)(sizeof(uintptr_t) * (i + 1))));\n-  }\n-\n-  __ leave();\n-  __ ret(0);\n-\n-  __ flush();\n-}\n-\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  ResourceMark rm;\n-  const ABIDescriptor abi = ForeignGlobals::parse_abi_descriptor(jabi);\n-  const BufferLayout layout = ForeignGlobals::parse_buffer_layout(jlayout);\n-\n-  BufferBlob* _invoke_native_blob = BufferBlob::create(\"invoke_native_blob\", native_invoker_size);\n-\n-  CodeBuffer code2(_invoke_native_blob);\n-  ProgrammableInvoker::Generator g2(&code2, &abi, &layout);\n-  g2.generate();\n-  code2.log_section_sizes(\"InvokeNativeBlob\");\n-\n-  return _invoke_native_blob->code_begin();\n-}\n-\n-static const int native_invoker_code_size = 1024;\n-\n@@ -159,1 +41,0 @@\n-  int _shadow_space_bytes;\n@@ -161,0 +42,1 @@\n+  const ABIDescriptor& _abi;\n@@ -164,0 +46,2 @@\n+  bool _needs_return_buffer;\n+\n@@ -172,1 +56,1 @@\n-                         int shadow_space_bytes,\n+                         const ABIDescriptor& abi,\n@@ -174,1 +58,2 @@\n-                         const GrowableArray<VMReg>& output_registers)\n+                         const GrowableArray<VMReg>& output_registers,\n+                         bool needs_return_buffer)\n@@ -179,1 +64,1 @@\n-     _shadow_space_bytes(shadow_space_bytes),\n+     _abi(abi),\n@@ -182,0 +67,1 @@\n+     _needs_return_buffer(needs_return_buffer),\n@@ -185,3 +71,0 @@\n-    assert(_output_registers.length() <= 1\n-           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n-\n@@ -203,7 +86,0 @@\n-\n-private:\n-#ifdef ASSERT\n-bool target_uses_register(VMReg reg) {\n-  return _input_registers.contains(reg) || _output_registers.contains(reg);\n-}\n-#endif\n@@ -212,0 +88,2 @@\n+static const int native_invoker_code_size = 1024;\n+\n@@ -215,1 +93,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -217,1 +95,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -220,1 +99,1 @@\n-  NativeInvokerGenerator g(&code, signature, num_args, ret_bt, shadow_space_bytes, input_registers, output_registers);\n+  NativeInvokerGenerator g(&code, signature, num_args, ret_bt, abi, input_registers, output_registers, needs_return_buffer);\n@@ -239,2 +118,0 @@\n-  assert(!(target_uses_register(r15_thread->as_VMReg()) || target_uses_register(rscratch1->as_VMReg())), \"Register conflict\");\n-\n@@ -253,1 +130,0 @@\n-  Register input_addr_reg = rscratch1;\n@@ -256,1 +132,1 @@\n-  DowncallNativeCallConv out_conv(_input_registers, input_addr_reg->as_VMReg());\n+  NativeCallConv out_conv(_input_registers);\n@@ -270,0 +146,3 @@\n+  if (_needs_return_buffer) {\n+    allocated_frame_size += 8; \/\/ store address\n+  }\n@@ -271,1 +150,1 @@\n-  allocated_frame_size += _shadow_space_bytes;\n+  allocated_frame_size += _abi._shadow_space_bytes;\n@@ -273,2 +152,5 @@\n-  RegSpiller out_reg_spiller(_output_registers);\n-  int spill_rsp_offset = 0;\n+  int ret_buf_addr_rsp_offset = -1;\n+  if (_needs_return_buffer) {\n+    \/\/ the above\n+    ret_buf_addr_rsp_offset = allocated_frame_size - 8;\n+  }\n@@ -276,4 +158,12 @@\n-  \/\/ spill area can be shared with the above, so we take the max of the 2\n-  allocated_frame_size = out_reg_spiller.spill_size_bytes() > allocated_frame_size\n-    ? out_reg_spiller.spill_size_bytes()\n-    : allocated_frame_size;\n+  \/\/ when we don't use a return buffer we need to spill the return value around our slowpath calls\n+  \/\/ when we use a return buffer case this SHOULD be unused.\n+  RegSpiller out_reg_spiller(_output_registers);\n+  int spill_rsp_offset = -1;\n+\n+  if (!_needs_return_buffer) {\n+    spill_rsp_offset = 0;\n+    \/\/ spill area can be shared with the above, so we take the max of the 2\n+    allocated_frame_size = out_reg_spiller.spill_size_bytes() > allocated_frame_size\n+      ? out_reg_spiller.spill_size_bytes()\n+      : allocated_frame_size;\n+  }\n@@ -286,2 +176,0 @@\n-  MacroAssembler* masm = _masm;\n-\n@@ -309,1 +197,6 @@\n-  arg_shuffle.generate(_masm, shufffle_reg->as_VMReg(), 0, _shadow_space_bytes);\n+  arg_shuffle.generate(_masm, shufffle_reg->as_VMReg(), 0, _abi._shadow_space_bytes);\n+  if (_needs_return_buffer) {\n+    \/\/ spill our return buffer address\n+    assert(ret_buf_addr_rsp_offset != -1, \"no return buffer addr spill\");\n+    __ movptr(Address(rsp, ret_buf_addr_rsp_offset), _abi._ret_buf_addr_reg);\n+  }\n@@ -312,16 +205,36 @@\n-  __ call(input_addr_reg);\n-\n-  \/\/ Unpack native results.\n-  switch (_ret_bt) {\n-    case T_BOOLEAN: __ c2bool(rax);            break;\n-    case T_CHAR   : __ movzwl(rax, rax);       break;\n-    case T_BYTE   : __ sign_extend_byte (rax); break;\n-    case T_SHORT  : __ sign_extend_short(rax); break;\n-    case T_INT    : \/* nothing to do *\/        break;\n-    case T_DOUBLE :\n-    case T_FLOAT  :\n-      \/\/ Result is in xmm0 we'll save as needed\n-      break;\n-    case T_VOID: break;\n-    case T_LONG: break;\n-    default       : ShouldNotReachHere();\n+  __ call(_abi._target_addr_reg);\n+  \/\/ this call is assumed not to have killed r15_thread\n+\n+  if (!_needs_return_buffer) {\n+    \/\/ FIXME: this assumes we return in rax\/xmm0, which might not be the case\n+    \/\/ Unpack native results.\n+    switch (_ret_bt) {\n+      case T_BOOLEAN: __ c2bool(rax);            break;\n+      case T_CHAR   : __ movzwl(rax, rax);       break;\n+      case T_BYTE   : __ sign_extend_byte (rax); break;\n+      case T_SHORT  : __ sign_extend_short(rax); break;\n+      case T_INT    : \/* nothing to do *\/        break;\n+      case T_DOUBLE :\n+      case T_FLOAT  :\n+        \/\/ Result is in xmm0 we'll save as needed\n+        break;\n+      case T_VOID: break;\n+      case T_LONG: break;\n+      default       : ShouldNotReachHere();\n+    }\n+  } else {\n+    assert(ret_buf_addr_rsp_offset != -1, \"no return buffer addr spill\");\n+    __ movptr(rscratch1, Address(rsp, ret_buf_addr_rsp_offset));\n+    int offset = 0;\n+    for (int i = 0; i < _output_registers.length(); i++) {\n+      VMReg reg = _output_registers.at(i);\n+      if (reg->is_Register()) {\n+        __ movptr(Address(rscratch1, offset), reg->as_Register());\n+        offset += 8;\n+      } else if (reg->is_XMMRegister()) {\n+        __ movdqu(Address(rscratch1, offset), reg->as_XMMRegister());\n+        offset += 16;\n+      } else {\n+        ShouldNotReachHere();\n+      }\n+    }\n@@ -371,1 +284,3 @@\n-  out_reg_spiller.generate_spill(_masm, spill_rsp_offset);\n+  if(!_needs_return_buffer) {\n+    out_reg_spiller.generate_spill(_masm, spill_rsp_offset);\n+  }\n@@ -381,1 +296,3 @@\n-  out_reg_spiller.generate_fill(_masm, spill_rsp_offset);\n+  if(!_needs_return_buffer) {\n+    out_reg_spiller.generate_fill(_masm, spill_rsp_offset);\n+  }\n@@ -392,1 +309,3 @@\n-  out_reg_spiller.generate_spill(_masm, spill_rsp_offset);\n+  if(!_needs_return_buffer) {\n+    out_reg_spiller.generate_spill(_masm, spill_rsp_offset);\n+  }\n@@ -401,1 +320,3 @@\n-  out_reg_spiller.generate_fill(_masm, spill_rsp_offset);\n+  if(!_needs_return_buffer) {\n+    out_reg_spiller.generate_fill(_masm, spill_rsp_offset);\n+  }\n@@ -411,4 +332,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return true;\n-}\n","filename":"src\/hotspot\/cpu\/x86\/universalNativeInvoker_x86_64.cpp","additions":91,"deletions":174,"binary":false,"changes":265,"status":"modified"},{"patch":"@@ -318,1 +318,2 @@\n-  ArgumentShuffle arg_shuffle(in_sig_bt, total_in_args, out_sig_bt, total_out_args, &call_regs, &out_conv, shuffle_reg->as_VMReg());\n+  NativeCallConv in_conv(call_regs._arg_regs, call_regs._args_length);\n+  ArgumentShuffle arg_shuffle(in_sig_bt, total_in_args, out_sig_bt, total_out_args, &in_conv, &out_conv, shuffle_reg->as_VMReg());\n","filename":"src\/hotspot\/cpu\/x86\/universalUpcallHandler_x86_64.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,5 +27,0 @@\n-address ProgrammableInvoker::generate_adapter(jobject jabi, jobject jlayout) {\n-  ShouldNotCallThis();\n-  return nullptr;\n-}\n-\n@@ -35,1 +30,1 @@\n-                                                      int shadow_space_bytes,\n+                                                      const ABIDescriptor& abi,\n@@ -37,1 +32,2 @@\n-                                                      const GrowableArray<VMReg>& output_registers) {\n+                                                      const GrowableArray<VMReg>& output_registers,\n+                                                      bool needs_return_buffer) {\n@@ -41,4 +37,0 @@\n-\n-bool ProgrammableInvoker::supports_native_invoker() {\n-  return false;\n-}\n","filename":"src\/hotspot\/cpu\/zero\/universalNativeInvoker_zero.cpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -80,0 +80,4 @@\n+  const char* strVMS = \"L\" FOREIGN_ABI \"VMStorage;\";\n+  Symbol* symVMS = SymbolTable::new_symbol(strVMS);\n+  ABI.targetAddrStorage_offset = field_offset(k_ABI, \"targetAddrStorage\", symVMS);\n+  ABI.retBufAddrStorage_offset = field_offset(k_ABI, \"retBufAddrStorage\", symVMS);\n@@ -103,29 +107,4 @@\n-int CallRegs::calling_convention(BasicType* sig_bt, VMRegPair *regs, int num_args) const {\n-  int src_pos = 0;\n-  for (int i = 0; i < num_args; i++) {\n-    switch (sig_bt[i]) {\n-      case T_BOOLEAN:\n-      case T_CHAR:\n-      case T_BYTE:\n-      case T_SHORT:\n-      case T_INT:\n-      case T_FLOAT:\n-        assert(src_pos < _args_length, \"oob\");\n-        regs[i].set1(_arg_regs[src_pos++]);\n-        break;\n-      case T_LONG:\n-      case T_DOUBLE:\n-        assert((i + 1) < num_args && sig_bt[i + 1] == T_VOID, \"expecting half\");\n-        assert(src_pos < _args_length, \"oob\");\n-        regs[i].set2(_arg_regs[src_pos++]);\n-        break;\n-      case T_VOID: \/\/ Halves of longs and doubles\n-        assert(i != 0 && (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), \"expecting half\");\n-        regs[i].set_bad();\n-        break;\n-      default:\n-        ShouldNotReachHere();\n-        break;\n-    }\n-  }\n-  return 0; \/\/ assumed unused\n+VMReg ForeignGlobals::parse_vmstorage(oop storage) const {\n+  jint index = storage->int_field(VMS.index_offset);\n+  jint type = storage->int_field(VMS.type_offset);\n+  return vmstorage_to_vmreg(type, index);\n@@ -143,0 +122,1 @@\n+  assert(rsp_offset != -1, \"rsp_offset should be set\");\n@@ -177,4 +157,1 @@\n-int DowncallNativeCallConv::calling_convention(BasicType* sig_bt, VMRegPair* out_regs, int num_args) const {\n-  out_regs[0].set2(_input_addr_reg); \/\/ address\n-  out_regs[1].set_bad(); \/\/ upper half\n-\n+int NativeCallConv::calling_convention(BasicType* sig_bt, VMRegPair* out_regs, int num_args) const {\n@@ -183,1 +160,1 @@\n-  for (int i = 2; i < num_args; i++) { \/\/ skip address (2)\n+  for (int i = 0; i < num_args; i++) {\n@@ -191,1 +168,2 @@\n-        VMReg reg = _input_regs.at(src_pos++);\n+        assert(src_pos < _input_regs_length, \"oob\");\n+        VMReg reg = _input_regs[src_pos++];\n@@ -200,1 +178,2 @@\n-        VMReg reg = _input_regs.at(src_pos);\n+        assert(src_pos < _input_regs_length, \"oob\");\n+        VMReg reg = _input_regs[src_pos++];\n@@ -202,1 +181,0 @@\n-        src_pos += 2; \/\/ skip BAD as well\n","filename":"src\/hotspot\/share\/prims\/foreign_globals.cpp","additions":15,"deletions":37,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-struct CallRegs : public CallConvClosure {\n+struct CallRegs {\n@@ -46,2 +46,0 @@\n-\n-  int calling_convention(BasicType* sig_bt, VMRegPair* regs, int num_args) const override;\n@@ -58,0 +56,2 @@\n+    int targetAddrStorage_offset;\n+    int retBufAddrStorage_offset;\n@@ -89,0 +89,2 @@\n+\n+  VMReg parse_vmstorage(oop storage) const;\n@@ -106,3 +108,3 @@\n-class DowncallNativeCallConv : public CallConvClosure {\n-  const GrowableArray<VMReg>& _input_regs;\n-  VMReg _input_addr_reg;\n+class NativeCallConv : public CallConvClosure {\n+  const VMReg* _input_regs;\n+  int _input_regs_length;\n@@ -110,3 +112,6 @@\n-  DowncallNativeCallConv(const GrowableArray<VMReg>& input_regs, VMReg input_addr_reg)\n-   : _input_regs(input_regs),\n-   _input_addr_reg(input_addr_reg) {}\n+  NativeCallConv(const VMReg* input_regs, int input_regs_length) :\n+    _input_regs(input_regs),\n+    _input_regs_length(input_regs_length) {\n+  }\n+  NativeCallConv(const GrowableArray<VMReg>& input_regs)\n+   : NativeCallConv(input_regs.data(), input_regs.length()) {}\n","filename":"src\/hotspot\/share\/prims\/foreign_globals.hpp","additions":14,"deletions":9,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -41,2 +41,2 @@\n-JNI_ENTRY(jlong, NEP_makeInvoker(JNIEnv* env, jclass _unused, jobject method_type, jint shadow_space_bytes,\n-                                 jlongArray arg_moves, jlongArray ret_moves))\n+JNI_ENTRY(jlong, NEP_makeInvoker(JNIEnv* env, jclass _unused, jobject method_type, jobject jabi,\n+                                 jlongArray arg_moves, jlongArray ret_moves, jboolean needs_return_buffer))\n@@ -44,5 +44,1 @@\n-\n-  \/\/ Note: the method_type's first param is the target address, but we don't have\n-  \/\/ and entry for that in the arg_moves array.\n-  \/\/ we need an entry for that in the basic type at least, so we can later\n-  \/\/ generate the right argument shuffle\n+  const ABIDescriptor abi = ForeignGlobals::parse_abi_descriptor(jabi);\n@@ -51,1 +47,0 @@\n-  \/\/ does not contain entry for address:\n@@ -54,1 +49,0 @@\n-  \/\/ contains address:\n@@ -57,1 +51,0 @@\n-  \/\/ contains address:\n@@ -59,6 +52,0 @@\n-  \/\/ address\n-  basic_type[0] = T_LONG;\n-  basic_type[1] = T_VOID;\n-\n-  \/\/ does not contain entry for address:\n-  GrowableArray<VMReg> input_regs(pslots);\n@@ -66,2 +53,2 @@\n-  int num_args = 2;\n-  for (int i = 1; i < pcount; i++) { \/\/ skip addr\n+  GrowableArray<VMReg> input_regs(pcount);\n+  for (int i = 0, bt_idx = 0; i < pcount; i++) {\n@@ -71,3 +58,2 @@\n-    basic_type[num_args] = bt;\n-    input_regs.push(VMRegImpl::as_VMReg(arg_moves_oop->long_at(i - 1))); \/\/ address missing in moves\n-    num_args++;\n+    basic_type[bt_idx++] = bt;\n+    input_regs.push(VMRegImpl::as_VMReg(arg_moves_oop->long_at(i)));\n@@ -76,3 +62,4 @@\n-      basic_type[num_args] = T_VOID;\n-      input_regs.push(VMRegImpl::Bad()); \/\/ half of double\/long\n-      num_args++;\n+      basic_type[bt_idx++] = T_VOID;\n+      \/\/ we only need these in the basic type\n+      \/\/ NativeCallConv ignores them, but they are needed\n+      \/\/ for JavaCallConv\n@@ -82,1 +69,0 @@\n-  GrowableArray<VMReg> output_regs(pslots);\n@@ -85,10 +71,7 @@\n-  assert(outs <= 1, \"No multi-reg returns\");\n-  BasicType ret_bt = T_VOID;\n-  if (outs == 1) {\n-    oop type_oop = java_lang_invoke_MethodType::rtype(type);\n-    ret_bt = java_lang_Class::primitive_type(type_oop);\n-\n-    output_regs.push(VMRegImpl::as_VMReg(ret_moves_oop->long_at(0)));\n-    if (ret_bt == BasicType::T_DOUBLE || ret_bt == BasicType::T_LONG) {\n-      output_regs.push(VMRegImpl::Bad()); \/\/ half of double\/long\n-    }\n+  GrowableArray<VMReg> output_regs(outs);\n+  oop type_oop = java_lang_invoke_MethodType::rtype(type);\n+  BasicType  ret_bt = java_lang_Class::primitive_type(type_oop);\n+  for (int i = 0; i < outs; i++) {\n+    \/\/ note that we don't care about long\/double upper halfs here:\n+    \/\/ we are NOT moving Java values, we are moving register-sized values\n+    output_regs.push(VMRegImpl::as_VMReg(ret_moves_oop->long_at(i)));\n@@ -104,1 +87,1 @@\n-    for (int i = 0; i < num_args; i++) {\n+    for (int i = 0; i < pslots; i++) {\n@@ -108,1 +91,1 @@\n-    ls.print_cr(\"shadow_space_bytes = %d\", shadow_space_bytes);\n+    ls.print_cr(\"shadow_space_bytes = %d\", abi._shadow_space_bytes);\n@@ -126,1 +109,1 @@\n-    basic_type, num_args, ret_bt, shadow_space_bytes, input_regs, output_regs)->code_begin();\n+    basic_type, pslots, ret_bt, abi, input_regs, output_regs, needs_return_buffer)->code_begin();\n@@ -134,1 +117,1 @@\n-  {CC \"makeInvoker\", CC \"(Ljava\/lang\/invoke\/MethodType;I[J[J)J\", FN_PTR(NEP_makeInvoker)},\n+  {CC \"makeInvoker\", CC \"(Ljava\/lang\/invoke\/MethodType;Ljdk\/internal\/invoke\/ABIDescriptorProxy;[J[JZ)J\", FN_PTR(NEP_makeInvoker)},\n","filename":"src\/hotspot\/share\/prims\/nativeEntryPoint.cpp","additions":22,"deletions":39,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -224,1 +224,0 @@\n-  void JNICALL JVM_RegisterProgrammableInvokerMethods(JNIEnv *env, jclass unsafecls);\n@@ -243,1 +242,0 @@\n-  { CC\"Java_jdk_internal_foreign_abi_ProgrammableInvoker_registerNatives\",      NULL, FN_PTR(JVM_RegisterProgrammableInvokerMethods) },\n","filename":"src\/hotspot\/share\/prims\/nativeLookup.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1,72 +0,0 @@\n-\/*\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"prims\/universalNativeInvoker.hpp\"\n-#include \"runtime\/interfaceSupport.inline.hpp\"\n-\n-ProgrammableInvoker::Generator::Generator(CodeBuffer* code, const ABIDescriptor* abi, const BufferLayout* layout)\n-  : StubCodeGenerator(code),\n-    _abi(abi),\n-    _layout(layout) {}\n-\n-void ProgrammableInvoker::invoke_native(Stub stub, address buff, JavaThread* thread) {\n-  ThreadToNativeFromVM ttnfvm(thread);\n-  \/\/ We need WXExec because we are about to call a generated stub. Like in VM\n-  \/\/ entries, the thread state should be changed while we are still in WXWrite.\n-  \/\/ See JDK-8265292.\n-  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXExec, thread));\n-  stub(buff);\n-}\n-\n-JNI_ENTRY(void, PI_invokeNative(JNIEnv* env, jclass _unused, jlong adapter_stub, jlong buff))\n-  assert(thread->thread_state() == _thread_in_vm, \"thread state is: %d\", thread->thread_state());\n-  ProgrammableInvoker::Stub stub = (ProgrammableInvoker::Stub) adapter_stub;\n-  address c = (address) buff;\n-  ProgrammableInvoker::invoke_native(stub, c, thread);\n-JNI_END\n-\n-JNI_ENTRY(jlong, PI_generateAdapter(JNIEnv* env, jclass _unused, jobject abi, jobject layout))\n-  return (jlong) ProgrammableInvoker::generate_adapter(abi, layout);\n-JNI_END\n-\n-JVM_ENTRY(jboolean, PI_SupportsNativeInvoker(JNIEnv *env, jclass unused))\n-  return (jboolean) ProgrammableInvoker::supports_native_invoker();\n-JVM_END\n-\n-#define CC (char*)  \/*cast a literal from (const char*)*\/\n-#define FN_PTR(f) CAST_FROM_FN_PTR(void*, &f)\n-#define FOREIGN_ABI \"Ljdk\/internal\/foreign\/abi\"\n-\n-static JNINativeMethod PI_methods[] = {\n-  {CC \"invokeNative\",    CC \"(JJ)V\",                                                             FN_PTR(PI_invokeNative)   },\n-  {CC \"generateAdapter\", CC \"(\" FOREIGN_ABI \"\/ABIDescriptor;\" FOREIGN_ABI \"\/BufferLayout;\" \")J\", FN_PTR(PI_generateAdapter)},\n-  {CC \"supportsNativeInvoker\", CC \"()Z\", FN_PTR(PI_SupportsNativeInvoker)},\n-};\n-\n-JNI_ENTRY(void, JVM_RegisterProgrammableInvokerMethods(JNIEnv *env, jclass PI_class))\n-  ThreadToNativeFromVM ttnfv(thread);\n-  int status = env->RegisterNatives(PI_class, PI_methods, sizeof(PI_methods)\/sizeof(JNINativeMethod));\n-  guarantee(status == JNI_OK && !env->ExceptionOccurred(),\n-            \"register jdk.internal.foreign.abi.programmable.ProgrammableInvoker natives\");\n-JNI_END\n","filename":"src\/hotspot\/share\/prims\/universalNativeInvoker.cpp","additions":0,"deletions":72,"binary":false,"changes":72,"status":"deleted"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"runtime\/stubCodeGenerator.hpp\"\n@@ -31,10 +30,0 @@\n-class ProgrammableInvoker: AllStatic {\n-private:\n-  static constexpr CodeBuffer::csize_t native_invoker_size = 1024;\n-\n-  class Generator : StubCodeGenerator {\n-  private:\n-    const ABIDescriptor* _abi;\n-    const BufferLayout* _layout;\n-  public:\n-    Generator(CodeBuffer* code, const ABIDescriptor* abi, const BufferLayout* layout);\n@@ -42,2 +31,1 @@\n-    void generate();\n-  };\n+class ProgrammableInvoker: AllStatic {\n@@ -45,5 +33,0 @@\n-  using Stub = void(*)(address);\n-\n-  static void invoke_native(Stub stub, address buff, JavaThread* thread);\n-  static address generate_adapter(jobject abi, jobject layout);\n-\n@@ -53,1 +36,1 @@\n-                                          int shadow_space_bytes,\n+                                          const ABIDescriptor& abi,\n@@ -55,2 +38,2 @@\n-                                          const GrowableArray<VMReg>& output_registers);\n-  static bool supports_native_invoker();\n+                                          const GrowableArray<VMReg>& output_registers,\n+                                          bool needs_return_buffer);\n","filename":"src\/hotspot\/share\/prims\/universalNativeInvoker.hpp","additions":4,"deletions":21,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -73,3 +73,3 @@\n-                                        boolean needTransition, MethodType methodType) {\n-        if (returnMoves.length > 1) {\n-            throw new IllegalArgumentException(\"Multiple register return not supported\");\n+                                        boolean needTransition, MethodType methodType, boolean needsReturnBuffer) {\n+        if (returnMoves.length > 1 != needsReturnBuffer) {\n+            throw new IllegalArgumentException(\"Multiple register return, but needsReturnBuffer was false\");\n@@ -79,0 +79,1 @@\n+        assert (!needsReturnBuffer || methodType.parameterType(1) == long.class) : \"IMR address expected\";\n@@ -87,1 +88,1 @@\n-            makeInvoker(methodType, shadowSpaceBytes, encArgMoves, encRetMoves));\n+            makeInvoker(methodType, abi, encArgMoves, encRetMoves, needsReturnBuffer));\n@@ -103,1 +104,1 @@\n-    private static native long makeInvoker(MethodType methodType, int shadowSpaceBytes, long[] encArgMoves, long[] encRetMoves);\n+    private static native long makeInvoker(MethodType methodType, ABIDescriptorProxy abi, long[] encArgMoves, long[] encRetMoves, boolean needsReturnBuffer);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/invoke\/NativeEntryPoint.java","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -126,1 +126,13 @@\n-    public FunctionDescriptor withAppendedArgumentLayouts(MemoryLayout... addedLayouts) {\n+    public FunctionDescriptor appendArgumentLayouts(MemoryLayout... addedLayouts) {\n+        return insertArgumentLayouts(argLayouts.length, addedLayouts);\n+    }\n+\n+    \/**\n+     * Create a new function descriptor with the given argument layouts inserted at the given index, into the argument\n+     * layout array of this function descriptor.\n+     * @param index the index at which to insert the arguments\n+     * @param addedLayouts the argument layouts to append.\n+     * @return the new function descriptor.\n+     * @throws IllegalArgumentException if {@code index < 0 || index > argumentLayouts().size()}.\n+     *\/\n+    public FunctionDescriptor insertArgumentLayouts(int index, MemoryLayout... addedLayouts) {\n@@ -129,0 +141,2 @@\n+        if (index < 0 || index > argLayouts.length)\n+            throw new IllegalArgumentException(\"Index out of bounds: \" + index);\n@@ -130,1 +144,2 @@\n-        System.arraycopy(addedLayouts, 0, newLayouts, argLayouts.length, addedLayouts.length);\n+        System.arraycopy(newLayouts, index, newLayouts, index + addedLayouts.length, argLayouts.length - index);\n+        System.arraycopy(addedLayouts, 0, newLayouts, index, addedLayouts.length);\n@@ -230,1 +245,6 @@\n-        public FunctionDescriptor withAppendedArgumentLayouts(MemoryLayout... addedLayouts) {\n+        public FunctionDescriptor appendArgumentLayouts(MemoryLayout... addedLayouts) {\n+            throw new UnsupportedOperationException();\n+        }\n+\n+        @Override\n+        public FunctionDescriptor insertArgumentLayouts(int index, MemoryLayout... addedLayouts) {\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/incubator\/foreign\/FunctionDescriptor.java","additions":23,"deletions":3,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -40,0 +40,3 @@\n+    final VMStorage targetAddrStorage;\n+    final VMStorage retBufAddrStorage;\n+\n@@ -41,1 +44,2 @@\n-                         VMStorage[][] volatileStorage, int stackAlignment, int shadowSpace) {\n+                         VMStorage[][] volatileStorage, int stackAlignment, int shadowSpace,\n+                         VMStorage targetAddrStorage, VMStorage retBufAddrStorage) {\n@@ -48,0 +52,2 @@\n+        this.targetAddrStorage = targetAddrStorage;\n+        this.retBufAddrStorage = retBufAddrStorage;\n@@ -54,0 +60,8 @@\n+\n+    public VMStorage targetAddrStorage() {\n+        return targetAddrStorage;\n+    }\n+\n+    public VMStorage retBufAddrStorage() {\n+        return retBufAddrStorage;\n+    }\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/ABIDescriptor.java","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -37,0 +37,3 @@\n+    private final boolean needsReturnBuffer;\n+    private final long returnBufferSize;\n+    private final long allocationSize;\n@@ -42,1 +45,2 @@\n-                           boolean isTrivial, List<List<Binding>> argumentBindings, List<Binding> returnBindings) {\n+                           boolean isTrivial, boolean needsReturnBuffer, long returnBufferSize, long allocationSize,\n+                           List<List<Binding>> argumentBindings, List<Binding> returnBindings) {\n@@ -46,0 +50,3 @@\n+        this.needsReturnBuffer = needsReturnBuffer;\n+        this.returnBufferSize = returnBufferSize;\n+        this.allocationSize = allocationSize;\n@@ -95,0 +102,12 @@\n+\n+    public boolean needsReturnBuffer() {\n+        return needsReturnBuffer;\n+    }\n+\n+    public long returnBufferSize() {\n+        return returnBufferSize;\n+    }\n+\n+    public long allocationSize() {\n+        return allocationSize;\n+    }\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/CallingSequence.java","additions":20,"deletions":1,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -29,0 +29,4 @@\n+import jdk.incubator.foreign.MemorySegment;\n+import jdk.incubator.foreign.NativeSymbol;\n+import jdk.incubator.foreign.ValueLayout;\n+import jdk.internal.foreign.Utils;\n@@ -45,0 +49,2 @@\n+    private final ABIDescriptor abi;\n+\n@@ -53,1 +59,2 @@\n-    public CallingSequenceBuilder(boolean forUpcall) {\n+    public CallingSequenceBuilder(ABIDescriptor abi, boolean forUpcall) {\n+        this.abi = abi;\n@@ -59,4 +66,1 @@\n-        verifyBindings(true, carrier, bindings);\n-        inputBindings.add(bindings);\n-        mt = mt.appendParameterTypes(carrier);\n-        desc = desc.withAppendedArgumentLayouts(layout);\n+        addArgumentBinding(inputBindings.size(), carrier, layout, bindings);\n@@ -66,0 +70,7 @@\n+    private void addArgumentBinding(int index, Class<?> carrier, MemoryLayout layout, List<Binding> bindings) {\n+        verifyBindings(true, carrier, bindings);\n+        inputBindings.add(index, bindings);\n+        mt = mt.insertParameterTypes(index, carrier);\n+        desc = desc.insertArgumentLayouts(index, layout);\n+    }\n+\n@@ -80,0 +91,6 @@\n+    private boolean needsReturnBuffer() {\n+        return outputBindings.stream()\n+            .filter(Binding.Move.class::isInstance)\n+            .count() > 1;\n+    }\n+\n@@ -81,1 +98,42 @@\n-        return new CallingSequence(mt, desc, isTrivial, inputBindings, outputBindings);\n+        boolean needsReturnBuffer = needsReturnBuffer();\n+        long returnBufferSize = needsReturnBuffer ? computeReturnBuferSize() : 0;\n+        long allocationSize = computeAllocationSize() + returnBufferSize;\n+        if (!forUpcall) {\n+            addArgumentBinding(0, NativeSymbol.class, ValueLayout.ADDRESS, List.of(\n+                Binding.unboxAddress(NativeSymbol.class),\n+                Binding.vmStore(abi.targetAddrStorage(), long.class)));\n+            if (needsReturnBuffer) {\n+                addArgumentBinding(0, MemorySegment.class, ValueLayout.ADDRESS, List.of(\n+                    Binding.unboxAddress(MemorySegment.class),\n+                    Binding.vmStore(abi.retBufAddrStorage(), long.class)));\n+            }\n+        }\n+        return new CallingSequence(mt, desc, isTrivial, needsReturnBuffer, returnBufferSize, allocationSize, inputBindings, outputBindings);\n+    }\n+\n+    private long computeAllocationSize() {\n+        \/\/ FIXME: > 16 bytes alignment might need extra space since the\n+        \/\/ starting address of the allocator might be un-aligned.\n+        long size = 0;\n+        for (List<Binding> bindings : inputBindings) {\n+            for (Binding b : bindings) {\n+                if (b instanceof Binding.Copy copy) {\n+                    size = Utils.alignUp(size, copy.alignment());\n+                    size += copy.size();\n+                } else if (b instanceof Binding.Allocate allocate) {\n+                    size = Utils.alignUp(size, allocate.alignment());\n+                    size += allocate.size();\n+                }\n+            }\n+        }\n+        return size;\n+    }\n+\n+    private long computeReturnBuferSize() {\n+        return outputBindings.stream()\n+                .filter(Binding.Move.class::isInstance)\n+                .map(Binding.Move.class::cast)\n+                .map(Binding.Move::storage)\n+                .map(VMStorage::type)\n+                .mapToLong(abi.arch::typeSize)\n+                .sum();\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/CallingSequenceBuilder.java","additions":64,"deletions":6,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -27,1 +27,2 @@\n-import jdk.incubator.foreign.Addressable;\n+import jdk.incubator.foreign.MemoryHandles;\n+import jdk.incubator.foreign.MemoryLayout;\n@@ -30,1 +31,0 @@\n-import jdk.incubator.foreign.ResourceScope;\n@@ -43,0 +43,1 @@\n+import java.nio.ByteOrder;\n@@ -46,1 +47,0 @@\n-import java.util.concurrent.ConcurrentHashMap;\n@@ -51,1 +51,1 @@\n-import static java.lang.invoke.MethodHandles.filterArguments;\n+import static java.lang.invoke.MethodHandles.foldArguments;\n@@ -55,1 +55,0 @@\n-import static sun.security.action.GetBooleanAction.privilegedGetProperty;\n@@ -63,2 +62,0 @@\n-    private static final boolean DEBUG =\n-        privilegedGetProperty(\"jdk.internal.foreign.ProgrammableInvoker.DEBUG\");\n@@ -67,2 +64,0 @@\n-    private static final boolean USE_INTRINSICS = Boolean.parseBoolean(\n-        GetPropertyAction.privilegedGetProperty(\"jdk.internal.foreign.ProgrammableInvoker.USE_INTRINSICS\", \"true\"));\n@@ -72,3 +67,0 @@\n-    private static final VarHandle VH_LONG = ValueLayout.JAVA_LONG.varHandle();\n-\n-    private static final MethodHandle MH_INVOKE_MOVES;\n@@ -76,1 +68,0 @@\n-    private static final MethodHandle MH_ADDR_TO_LONG;\n@@ -78,2 +69,2 @@\n-\n-    private static final Map<ABIDescriptor, Long> adapterStubs = new ConcurrentHashMap<>();\n+    private static final MethodHandle MH_ALLOCATE_RETURN_BUFFER;\n+    private static final MethodHandle MH_CHECK_SYMBOL;\n@@ -86,2 +77,0 @@\n-            MH_INVOKE_MOVES = lookup.findVirtual(ProgrammableInvoker.class, \"invokeMoves\",\n-                    methodType(Object.class, long.class, Object[].class, Binding.VMStore[].class, Binding.VMLoad[].class));\n@@ -89,1 +78,1 @@\n-                    methodType(Object.class, NativeSymbol.class, SegmentAllocator.class, Object[].class, MethodHandle.class, Map.class, Map.class));\n+                    methodType(Object.class, SegmentAllocator.class, Object[].class, InvocationData.class));\n@@ -92,1 +81,4 @@\n-            MH_ADDR_TO_LONG = lookup.findStatic(ProgrammableInvoker.class, \"unboxTargetAddress\", methodType(long.class, NativeSymbol.class));\n+            MH_ALLOCATE_RETURN_BUFFER = lookup.findStatic(ProgrammableInvoker.class, \"allocateReturnBuffer\",\n+                    methodType(MemorySegment.class, Binding.Context.class, long.class));\n+            MH_CHECK_SYMBOL = lookup.findStatic(SharedUtils.class, \"checkSymbol\",\n+                    methodType(void.class, NativeSymbol.class));\n@@ -99,3 +91,0 @@\n-    private final BufferLayout layout;\n-    private final long stackArgsBytes;\n-\n@@ -104,4 +93,0 @@\n-    private final long stubAddress;\n-\n-    private final long bufferCopySize;\n-\n@@ -110,3 +95,0 @@\n-        this.layout = BufferLayout.of(abi);\n-        this.stubAddress = adapterStubs.computeIfAbsent(abi, key -> generateAdapter(key, layout));\n-\n@@ -114,8 +96,0 @@\n-\n-        this.stackArgsBytes = argMoveBindingsStream(callingSequence)\n-                .map(Binding.VMStore::storage)\n-                .filter(s -> abi.arch.isStackType(s.type()))\n-                .count()\n-                * abi.arch.typeSize(abi.arch.stackType());\n-\n-        this.bufferCopySize = SharedUtils.bufferCopySize(callingSequence);\n@@ -129,5 +103,1 @@\n-        Class<?> returnType = retMoves.length == 0\n-                ? void.class\n-                : retMoves.length == 1\n-                    ? retMoves[0].type()\n-                    : Object[].class;\n+        Class<?> returnType = retMoves.length == 1 ? retMoves[0].type() : void.class;\n@@ -136,23 +106,0 @@\n-        MethodType leafTypeWithAddress = leafType.insertParameterTypes(0, long.class);\n-\n-        MethodHandle handle;\n-\n-        boolean isSimple = !(retMoves.length > 1);\n-        if (USE_INTRINSICS && isSimple && supportsNativeInvoker()) {\n-            NativeEntryPoint nep = NativeEntryPoint.make(\n-                \"native_invoker_\" + leafType.descriptorString(),\n-                abi,\n-                toStorageArray(argMoves),\n-                toStorageArray(retMoves),\n-                !callingSequence.isTrivial(),\n-                leafTypeWithAddress\n-            );\n-\n-            handle = JLIA.nativeMethodHandle(nep);\n-        } else {\n-            handle = insertArguments(MH_INVOKE_MOVES.bindTo(this), 2, argMoves, retMoves);\n-            MethodHandle collector = makeCollectorHandle(leafType);\n-            handle = collectArguments(handle, 1, collector);\n-            handle = handle.asType(leafTypeWithAddress);\n-        }\n-        handle = filterArguments(handle, 0, MH_ADDR_TO_LONG);\n@@ -160,1 +107,12 @@\n-        if (USE_SPEC && isSimple) {\n+        NativeEntryPoint nep = NativeEntryPoint.make(\n+            \"native_invoker_\" + leafType.descriptorString(),\n+            abi,\n+            toStorageArray(argMoves),\n+            toStorageArray(retMoves),\n+            !callingSequence.isTrivial(),\n+            leafType,\n+            callingSequence.needsReturnBuffer()\n+        );\n+        MethodHandle handle = JLIA.nativeMethodHandle(nep);\n+\n+        if (USE_SPEC) {\n@@ -166,4 +124,11 @@\n-            handle = insertArguments(MH_INVOKE_INTERP_BINDINGS.bindTo(this), 3, handle, argIndexMap, retIndexMap);\n-            MethodHandle collectorInterp = makeCollectorHandle(callingSequence.methodType());\n-            handle = collectArguments(handle, 2, collectorInterp);\n-            handle = handle.asType(handle.type().changeReturnType(callingSequence.methodType().returnType()));\n+            InvocationData invData = new InvocationData(handle, argIndexMap, retIndexMap);\n+            handle = insertArguments(MH_INVOKE_INTERP_BINDINGS.bindTo(this), 2, invData);\n+            MethodType interpType = callingSequence.methodType();\n+            if (callingSequence.needsReturnBuffer()) {\n+                \/\/ Return buffer is supplied by invokeInterpBindings\n+                assert interpType.parameterType(0) == MemorySegment.class;\n+                interpType.dropParameterTypes(0, 1);\n+            }\n+            MethodHandle collectorInterp = makeCollectorHandle(interpType);\n+            handle = collectArguments(handle, 1, collectorInterp);\n+            handle = handle.asType(handle.type().changeReturnType(interpType.returnType()));\n@@ -172,0 +137,6 @@\n+        assert handle.type().parameterType(0) == SegmentAllocator.class;\n+        assert handle.type().parameterType(1) == NativeSymbol.class;\n+        handle = foldArguments(handle, 1, MH_CHECK_SYMBOL);\n+\n+        handle = SharedUtils.swapArguments(handle, 0, 1); \/\/ normalize parameter order\n+\n@@ -175,3 +146,2 @@\n-    private static long unboxTargetAddress(NativeSymbol addr) {\n-        SharedUtils.checkSymbol(addr);\n-        return addr.address().toRawLongValue();\n+    private static MemorySegment allocateReturnBuffer(Binding.Context context, long size) {\n+        return context.allocator().allocate(size);\n@@ -196,0 +166,4 @@\n+        return retMoveBindingsStream(callingSequence).toArray(Binding.VMLoad[]::new);\n+    }\n+\n+    private Stream<Binding.VMLoad> retMoveBindingsStream(CallingSequence callingSequence) {\n@@ -198,2 +172,1 @@\n-                .map(Binding.VMLoad.class::cast)\n-                .toArray(Binding.VMLoad[]::new);\n+                .map(Binding.VMLoad.class::cast);\n@@ -202,1 +175,0 @@\n-\n@@ -210,2 +182,2 @@\n-        int argInsertPos = 1;\n-        int argContextPos = 1;\n+        int argInsertPos = 0;\n+        int argContextPos = 0;\n@@ -214,1 +186,0 @@\n-\n@@ -231,0 +202,2 @@\n+            int retBufPos = -1;\n+            long retBufReadOffset = -1;\n@@ -233,0 +206,7 @@\n+            if (callingSequence.needsReturnBuffer()) {\n+                retBufPos = 0;\n+                retBufReadOffset = callingSequence.returnBufferSize();\n+                retContextPos++;\n+                retInsertPos++;\n+                returnFilter = dropArguments(returnFilter, retBufPos, MemorySegment.class);\n+            }\n@@ -237,1 +217,26 @@\n-                returnFilter = binding.specialize(returnFilter, retInsertPos, retContextPos);\n+                if (callingSequence.needsReturnBuffer() && binding.tag() == Binding.Tag.VM_LOAD) {\n+                    \/\/ spacial case this, since we need to update retBufReadOffset as well\n+                    Binding.VMLoad load = (Binding.VMLoad) binding;\n+                    ValueLayout layout = MemoryLayout.valueLayout(load.type(), ByteOrder.nativeOrder()).withBitAlignment(8);\n+                    \/\/ since we iterate the bindings in reverse, we have to compute the offset in reverse as well\n+                    retBufReadOffset -= abi.arch.typeSize(load.storage().type());\n+                    MethodHandle loadHandle = MemoryHandles.insertCoordinates(MemoryHandles.varHandle(layout), 1, retBufReadOffset)\n+                            .toMethodHandle(VarHandle.AccessMode.GET);\n+\n+                    returnFilter = MethodHandles.collectArguments(returnFilter, retInsertPos, loadHandle);\n+                    assert returnFilter.type().parameterType(retInsertPos - 1) == MemorySegment.class;\n+                    assert returnFilter.type().parameterType(retInsertPos - 2) == MemorySegment.class;\n+                    returnFilter = SharedUtils.mergeArguments(returnFilter, retBufPos, retInsertPos);\n+                    \/\/ to (... MemorySegment, MemorySegment, <primitive>, ...)\n+                    \/\/ from (... MemorySegment, MemorySegment, ...)\n+                    retInsertPos -= 2; \/\/ set insert pos back to the first MS (later DUP binding will merge the 2 MS)\n+                } else {\n+                    returnFilter = binding.specialize(returnFilter, retInsertPos, retContextPos);\n+                    if (callingSequence.needsReturnBuffer() && binding.tag() == Binding.Tag.BUFFER_STORE) {\n+                        \/\/ from (... MemorySegment, ...)\n+                        \/\/ to (... MemorySegment, MemorySegment, <primitive>, ...)\n+                        retInsertPos += 2; \/\/ set insert pos to <primitive>\n+                        assert returnFilter.type().parameterType(retInsertPos - 1) == MemorySegment.class;\n+                        assert returnFilter.type().parameterType(retInsertPos - 2) == MemorySegment.class;\n+                    }\n+                }\n@@ -239,2 +244,1 @@\n-            returnFilter = MethodHandles.filterArguments(returnFilter, retContextPos, MH_WRAP_ALLOCATOR);\n-            \/\/ (SegmentAllocator, Addressable, Context, ...) -> ...\n+            \/\/ (R, Context (ret)) -> (MemorySegment?, Context (ret), MemorySegment?, Context (arg), ...)\n@@ -242,2 +246,13 @@\n-            \/\/ (Addressable, SegmentAllocator, Context, ...) -> ...\n-            specializedHandle = SharedUtils.swapArguments(specializedHandle, 0, 1); \/\/ normalize parameter order\n+            if (callingSequence.needsReturnBuffer()) {\n+                \/\/ (MemorySegment, Context (ret), Context (arg), MemorySegment,  ...) -> (MemorySegment, Context (ret), Context (arg), ...)\n+                specializedHandle = SharedUtils.mergeArguments(specializedHandle, retBufPos, retBufPos + 3);\n+\n+                \/\/ allocate the return buffer from the binding context, and then merge the 2 allocator args\n+                MethodHandle retBufAllocHandle = MethodHandles.insertArguments(MH_ALLOCATE_RETURN_BUFFER, 1, callingSequence.returnBufferSize());\n+                \/\/ (MemorySegment, Context (ret), Context (arg), ...) -> (Context (arg), Context (ret), Context (arg), ...)\n+                specializedHandle = MethodHandles.filterArguments(specializedHandle, retBufPos, retBufAllocHandle);\n+                \/\/ (Context (arg), Context (ret), Context (arg), ...) -> (Context (ret), Context (arg), ...)\n+                specializedHandle = SharedUtils.mergeArguments(specializedHandle, argContextPos + 1, retBufPos); \/\/ +1 to skip return context\n+            }\n+            \/\/ (Context (ret), Context (arg), ...) -> (SegmentAllocator, Context (arg), ...)\n+            specializedHandle = MethodHandles.filterArguments(specializedHandle, 0, MH_WRAP_ALLOCATOR);\n@@ -245,1 +260,1 @@\n-            specializedHandle = MethodHandles.dropArguments(specializedHandle, 1, SegmentAllocator.class);\n+            specializedHandle = MethodHandles.dropArguments(specializedHandle, 0, SegmentAllocator.class);\n@@ -251,1 +266,1 @@\n-        specializedHandle = SharedUtils.wrapWithAllocator(specializedHandle, argContextPos, bufferCopySize, false);\n+        specializedHandle = SharedUtils.wrapWithAllocator(specializedHandle, argContextPos, callingSequence.allocationSize(), false);\n@@ -255,36 +270,1 @@\n-    \/**\n-     * Does a native invocation by moving primitive values from the arg array into an intermediate buffer\n-     * and calling the assembly stub that forwards arguments from the buffer to the target function\n-     *\n-     * @param args an array of primitive values to be copied in to the buffer\n-     * @param argBindings Binding.Move values describing how arguments should be copied\n-     * @param returnBindings Binding.Move values describing how return values should be copied\n-     * @return null, a single primitive value, or an Object[] of primitive values\n-     *\/\n-    Object invokeMoves(long addr, Object[] args, Binding.VMStore[] argBindings, Binding.VMLoad[] returnBindings) {\n-        MemorySegment stackArgsSeg = null;\n-        try (ResourceScope scope = ResourceScope.newConfinedScope()) {\n-            MemorySegment argBuffer = MemorySegment.allocateNative(layout.size, 64, scope);\n-            if (stackArgsBytes > 0) {\n-                stackArgsSeg = MemorySegment.allocateNative(stackArgsBytes, 8, scope);\n-            }\n-\n-            VH_LONG.set(argBuffer.asSlice(layout.arguments_next_pc), addr);\n-            VH_LONG.set(argBuffer.asSlice(layout.stack_args_bytes), stackArgsBytes);\n-            VH_LONG.set(argBuffer.asSlice(layout.stack_args), stackArgsSeg == null ? 0L : stackArgsSeg.address().toRawLongValue());\n-\n-            for (int i = 0; i < argBindings.length; i++) {\n-                Binding.VMStore binding = argBindings[i];\n-                VMStorage storage = binding.storage();\n-                MemorySegment ptr = abi.arch.isStackType(storage.type())\n-                    ? stackArgsSeg.asSlice(storage.index() * abi.arch.typeSize(abi.arch.stackType()))\n-                    : argBuffer.asSlice(layout.argOffset(storage));\n-                SharedUtils.writeOverSized(ptr, binding.type(), args[i]);\n-            }\n-\n-            if (DEBUG) {\n-                System.err.println(\"Buffer state before:\");\n-                layout.dump(abi.arch, argBuffer, System.err);\n-            }\n-\n-            invokeNative(stubAddress, argBuffer.address().toRawLongValue());\n+    private record InvocationData(MethodHandle leaf, Map<VMStorage, Integer> argIndexMap, Map<VMStorage, Integer> retIndexMap) {}\n@@ -292,28 +272,3 @@\n-            if (DEBUG) {\n-                System.err.println(\"Buffer state after:\");\n-                layout.dump(abi.arch, argBuffer, System.err);\n-            }\n-\n-            if (returnBindings.length == 0) {\n-                return null;\n-            } else if (returnBindings.length == 1) {\n-                Binding.VMLoad move = returnBindings[0];\n-                VMStorage storage = move.storage();\n-                return SharedUtils.read(argBuffer.asSlice(layout.retOffset(storage)), move.type());\n-            } else { \/\/ length > 1\n-                Object[] returns = new Object[returnBindings.length];\n-                for (int i = 0; i < returnBindings.length; i++) {\n-                    Binding.VMLoad move = returnBindings[i];\n-                    VMStorage storage = move.storage();\n-                    returns[i] = SharedUtils.read(argBuffer.asSlice(layout.retOffset(storage)), move.type());\n-                }\n-                return returns;\n-            }\n-        }\n-    }\n-\n-    Object invokeInterpBindings(NativeSymbol symbol, SegmentAllocator allocator, Object[] args, MethodHandle leaf,\n-                                Map<VMStorage, Integer> argIndexMap,\n-                                Map<VMStorage, Integer> retIndexMap) throws Throwable {\n-        Binding.Context unboxContext = bufferCopySize != 0\n-                ? Binding.Context.ofBoundedAllocator(bufferCopySize)\n+    Object invokeInterpBindings(SegmentAllocator allocator, Object[] args, InvocationData invData) throws Throwable {\n+        Binding.Context unboxContext = callingSequence.allocationSize() != 0\n+                ? Binding.Context.ofBoundedAllocator(callingSequence.allocationSize())\n@@ -322,0 +277,2 @@\n+            MemorySegment returnBuffer = null;\n+\n@@ -323,2 +280,9 @@\n-            Object[] leafArgs = new Object[leaf.type().parameterCount()];\n-            leafArgs[0] = symbol; \/\/ symbol\n+            Object[] leafArgs = new Object[invData.leaf.type().parameterCount()];\n+            if (callingSequence.needsReturnBuffer()) {\n+                \/\/ we supply the return buffer (argument array does not contain it)\n+                Object[] prefixedArgs = new Object[args.length + 1];\n+                returnBuffer = unboxContext.allocator().allocate(callingSequence.returnBufferSize());\n+                prefixedArgs[0] = returnBuffer;\n+                System.arraycopy(args, 0, prefixedArgs, 1, args.length);\n+                args = prefixedArgs;\n+            }\n@@ -329,1 +293,1 @@\n-                            leafArgs[argIndexMap.get(storage) + 1] = value; \/\/ +1 to skip symbol\n+                            leafArgs[invData.argIndexMap.get(storage)] = value;\n@@ -334,1 +298,1 @@\n-            Object o = leaf.invokeWithArguments(leafArgs);\n+            Object o = invData.leaf.invokeWithArguments(leafArgs);\n@@ -338,3 +302,4 @@\n-                return null;\n-            } else if (o instanceof Object[]) {\n-                Object[] oArr = (Object[]) o;\n+                if (!callingSequence.needsReturnBuffer()) {\n+                    return null;\n+                }\n+                MemorySegment finalReturnBuffer = returnBuffer;\n@@ -342,1 +307,9 @@\n-                        (storage, type) -> oArr[retIndexMap.get(storage)], Binding.Context.ofAllocator(allocator));\n+                        new BindingInterpreter.LoadFunc() {\n+                            int retBufReadOffset = 0;\n+                            @Override\n+                            public Object load(VMStorage storage, Class<?> type) {\n+                                Object result1 = SharedUtils.read(finalReturnBuffer.asSlice(retBufReadOffset), type);\n+                                retBufReadOffset += abi.arch.typeSize(storage.type());\n+                                return result1;\n+                            }\n+                        }, Binding.Context.ofAllocator(allocator));\n@@ -349,11 +322,0 @@\n-\n-    \/\/natives\n-\n-    static native void invokeNative(long adapterStub, long buff);\n-    static native long generateAdapter(ABIDescriptor abi, BufferLayout layout);\n-    static native boolean supportsNativeInvoker();\n-\n-    private static native void registerNatives();\n-    static {\n-        registerNatives();\n-    }\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/ProgrammableInvoker.java","additions":131,"deletions":169,"binary":false,"changes":300,"status":"modified"},{"patch":"@@ -103,1 +103,0 @@\n-        long bufferCopySize = SharedUtils.bufferCopySize(callingSequence);\n@@ -105,1 +104,1 @@\n-            doBindings = specializedBindingHandle(target, callingSequence, llReturn, bufferCopySize);\n+            doBindings = specializedBindingHandle(target, callingSequence, llReturn, callingSequence.allocationSize());\n@@ -112,1 +111,1 @@\n-                    bufferCopySize);\n+                    callingSequence.allocationSize());\n@@ -159,1 +158,1 @@\n-                                                         Class<?> llReturn, long bufferCopySize) {\n+                                                         Class<?> llReturn, long allocationSize) {\n@@ -195,1 +194,1 @@\n-        specializedHandle = SharedUtils.wrapWithAllocator(specializedHandle, argAllocatorPos, bufferCopySize, true);\n+        specializedHandle = SharedUtils.wrapWithAllocator(specializedHandle, argAllocatorPos, allocationSize, true);\n@@ -254,3 +253,3 @@\n-                                               long bufferCopySize) throws Throwable {\n-        Binding.Context allocator = bufferCopySize != 0\n-                ? Binding.Context.ofBoundedAllocator(bufferCopySize)\n+                                               long allocationSize) throws Throwable {\n+        Binding.Context allocator = allocationSize != 0\n+                ? Binding.Context.ofBoundedAllocator(allocationSize)\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/ProgrammableUpcallHandler.java","additions":7,"deletions":8,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -299,21 +299,0 @@\n-    static long bufferCopySize(CallingSequence callingSequence) {\n-        \/\/ FIXME: > 16 bytes alignment might need extra space since the\n-        \/\/ starting address of the allocator might be un-aligned.\n-        long size = 0;\n-        for (int i = 0; i < callingSequence.argumentCount(); i++) {\n-            List<Binding> bindings = callingSequence.argumentBindings(i);\n-            for (Binding b : bindings) {\n-                if (b instanceof Binding.Copy) {\n-                    Binding.Copy c = (Binding.Copy) b;\n-                    size = Utils.alignUp(size, c.alignment());\n-                    size += c.size();\n-                } else if (b instanceof Binding.Allocate) {\n-                    Binding.Allocate c = (Binding.Allocate) b;\n-                    size = Utils.alignUp(size, c.alignment());\n-                    size += c.size();\n-                }\n-            }\n-        }\n-        return size;\n-    }\n-\n@@ -336,1 +315,2 @@\n-        assert destIndex > sourceIndex;\n+        if (destIndex < sourceIndex)\n+            sourceIndex--;\n@@ -374,1 +354,1 @@\n-                                          int allocatorPos, long bufferCopySize,\n+                                          int allocatorPos, long allocationSize,\n@@ -396,1 +376,1 @@\n-        \/\/ downcalls get the leading NativeSymbol\/SegmentAllocator param as well\n+        \/\/ downcalls get the leading SegmentAllocator param as well\n@@ -398,2 +378,1 @@\n-            closer = collectArguments(closer, insertPos++, reachabilityFenceHandle(NativeSymbol.class));\n-            closer = dropArguments(closer, insertPos++, SegmentAllocator.class); \/\/ (Throwable, V?, NativeSymbol, SegmentAllocator) -> V\/void\n+            closer = dropArguments(closer, insertPos++, SegmentAllocator.class); \/\/ (Throwable, V?, SegmentAllocator, NativeSymbol) -> V\/void\n@@ -402,1 +381,1 @@\n-        closer = collectArguments(closer, insertPos++, MH_CLOSE_CONTEXT); \/\/ (Throwable, V?, NativeSymbol?, BindingContext) -> V\/void\n+        closer = collectArguments(closer, insertPos, MH_CLOSE_CONTEXT); \/\/ (Throwable, V?, SegmentAllocator?, BindingContext) -> V\/void\n@@ -406,2 +385,2 @@\n-        if (bufferCopySize > 0) {\n-            contextFactory = MethodHandles.insertArguments(MH_MAKE_CONTEXT_BOUNDED_ALLOCATOR, 0, bufferCopySize);\n+        if (allocationSize > 0) {\n+            contextFactory = MethodHandles.insertArguments(MH_MAKE_CONTEXT_BOUNDED_ALLOCATOR, 0, allocationSize);\n@@ -561,0 +540,8 @@\n+    public static MethodHandle maybeInsertAllocator(MethodHandle handle) {\n+        if (!handle.type().returnType().equals(MemorySegment.class)) {\n+            \/\/ not returning segment, just insert a throwing allocator\n+            handle = insertArguments(handle, 1, THROWING_ALLOCATOR);\n+        }\n+        return handle;\n+    }\n+\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/SharedUtils.java","additions":16,"deletions":29,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -151,1 +151,2 @@\n-                                       int shadowSpace) {\n+                                       int shadowSpace,\n+                                       VMStorage targetAddrStorage, VMStorage retBufAddrStorage) {\n@@ -167,2 +168,2 @@\n-            shadowSpace\n-        );\n+            shadowSpace,\n+                targetAddrStorage, retBufAddrStorage);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/aarch64\/AArch64Architecture.java","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -91,1 +91,3 @@\n-        0    \/\/ No shadow space\n+        0,   \/\/ No shadow space\n+        r9,  \/\/ target addr reg\n+        r10  \/\/ return buffer addr reg\n@@ -119,1 +121,1 @@\n-        CallingSequenceBuilder csb = new CallingSequenceBuilder(forUpcall);\n+        CallingSequenceBuilder csb = new CallingSequenceBuilder(C, forUpcall);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/aarch64\/CallArranger.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -65,4 +65,1 @@\n-        if (!type.returnType().equals(MemorySegment.class)) {\n-            \/\/ not returning segment, just insert a throwing allocator\n-            handle = MethodHandles.insertArguments(handle, 1, SharedUtils.THROWING_ALLOCATOR);\n-        }\n+        handle = SharedUtils.maybeInsertAllocator(handle);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/aarch64\/linux\/LinuxAArch64Linker.java","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -65,4 +65,1 @@\n-        if (!type.returnType().equals(MemorySegment.class)) {\n-            \/\/ not returning segment, just insert a throwing allocator\n-            handle = MethodHandles.insertArguments(handle, 1, SharedUtils.THROWING_ALLOCATOR);\n-        }\n+        handle = SharedUtils.maybeInsertAllocator(handle);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/aarch64\/macos\/MacOsAArch64Linker.java","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -137,1 +137,2 @@\n-                                       VMStorage[] volatileVectorRegs, int stackAlignment, int shadowSpace) {\n+                                       VMStorage[] volatileVectorRegs, int stackAlignment, int shadowSpace,\n+                                       VMStorage targetAddrStorage, VMStorage retBufAddrStorage) {\n@@ -154,2 +155,2 @@\n-            shadowSpace\n-        );\n+            shadowSpace,\n+                targetAddrStorage, retBufAddrStorage);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/x64\/X86_64Architecture.java","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -73,1 +73,3 @@\n-        0 \/\/no shadow space\n+        0, \/\/no shadow space\n+        r10, \/\/ target addr reg\n+        r11  \/\/ imr addr reg\n@@ -90,1 +92,1 @@\n-        CallingSequenceBuilder csb = new CallingSequenceBuilder(forUpcall);\n+        CallingSequenceBuilder csb = new CallingSequenceBuilder(CSysV, forUpcall);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/x64\/sysv\/CallArranger.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-import jdk.incubator.foreign.MemorySegment;\n@@ -38,1 +37,0 @@\n-import java.lang.invoke.MethodHandles;\n@@ -75,4 +73,1 @@\n-        if (!type.returnType().equals(MemorySegment.class)) {\n-            \/\/ not returning segment, just insert a throwing allocator\n-            handle = MethodHandles.insertArguments(handle, 1, SharedUtils.THROWING_ALLOCATOR);\n-        }\n+        handle = SharedUtils.maybeInsertAllocator(handle);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/x64\/sysv\/SysVx64Linker.java","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -71,1 +71,3 @@\n-        32\n+        32,\n+        r10, \/\/ target addr reg\n+        r11  \/\/ imr addr reg\n@@ -87,1 +89,1 @@\n-            final CallingSequenceBuilder csb = new CallingSequenceBuilder(forUpcall);\n+            final CallingSequenceBuilder csb = new CallingSequenceBuilder(CWindows, forUpcall);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/x64\/windows\/CallArranger.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -76,4 +76,1 @@\n-        if (!type.returnType().equals(MemorySegment.class)) {\n-            \/\/ not returning segment, just insert a throwing allocator\n-            handle = MethodHandles.insertArguments(handle, 1, SharedUtils.THROWING_ALLOCATOR);\n-        }\n+        handle = SharedUtils.maybeInsertAllocator(handle);\n","filename":"src\/jdk.incubator.foreign\/share\/classes\/jdk\/internal\/foreign\/abi\/x64\/windows\/Windowsx64Linker.java","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-import java.lang.constant.Constable;\n@@ -38,1 +37,0 @@\n-import java.util.stream.Collectors;\n@@ -70,1 +68,1 @@\n-        fd = fd.withAppendedArgumentLayouts(C_POINTER);\n+        fd = fd.appendArgumentLayouts(C_POINTER);\n","filename":"test\/jdk\/java\/foreign\/TestFunctionDescriptor.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+import jdk.incubator.foreign.NativeSymbol;\n@@ -46,0 +47,1 @@\n+import static jdk.incubator.foreign.ValueLayout.ADDRESS;\n@@ -63,2 +65,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -66,1 +68,3 @@\n-        checkArgumentBindings(callingSequence, new Binding[][]{});\n+        checkArgumentBindings(callingSequence, new Binding[][]{\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) }\n+        });\n@@ -85,2 +89,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -89,0 +93,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -114,2 +119,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -118,0 +123,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -135,2 +141,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -139,0 +145,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -194,2 +201,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -198,0 +205,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -224,2 +232,2 @@\n-        assertEquals(callingSequence.methodType(), MethodType.methodType(void.class, MemoryAddress.class));\n-        assertEquals(callingSequence.functionDesc(), FunctionDescriptor.ofVoid(C_POINTER));\n+        assertEquals(callingSequence.methodType(), MethodType.methodType(void.class, NativeSymbol.class, MemoryAddress.class));\n+        assertEquals(callingSequence.functionDesc(), FunctionDescriptor.ofVoid(ADDRESS, C_POINTER));\n@@ -228,0 +236,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -247,2 +256,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, MemorySegment.class, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS, ADDRESS));\n@@ -250,1 +259,4 @@\n-        checkArgumentBindings(callingSequence, new Binding[][]{});\n+        checkArgumentBindings(callingSequence, new Binding[][]{\n+            { unboxAddress(MemorySegment.class), vmStore(r10, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) }\n+        });\n@@ -273,2 +285,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, MemorySegment.class, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS, ADDRESS));\n@@ -277,0 +289,2 @@\n+            { unboxAddress(MemorySegment.class), vmStore(r10, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -309,2 +323,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -313,0 +327,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -362,2 +377,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -366,0 +381,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -385,0 +401,1 @@\n+        FunctionDescriptor fdExpected = FunctionDescriptor.ofVoid(ADDRESS, C_INT).asVariadic(C_INT, C_FLOAT);\n@@ -389,2 +406,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fdExpected);\n@@ -394,0 +411,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n@@ -406,0 +424,1 @@\n+        FunctionDescriptor fdExpected = FunctionDescriptor.ofVoid(ADDRESS, C_INT).asVariadic(C_INT, C_FLOAT);\n@@ -410,2 +429,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fdExpected);\n@@ -415,0 +434,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r9, long.class) },\n","filename":"test\/jdk\/java\/foreign\/callarranger\/TestAarch64CallArranger.java","additions":46,"deletions":26,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+import jdk.incubator.foreign.NativeSymbol;\n@@ -47,0 +48,1 @@\n+import static jdk.incubator.foreign.ValueLayout.ADDRESS;\n@@ -64,2 +66,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -68,0 +70,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -91,2 +94,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -95,3 +98,4 @@\n-                { dup(), bufferLoad(0, long.class), vmStore(rdi, long.class),\n-                  bufferLoad(8, int.class), vmStore(rsi, int.class)},\n-                { vmStore(rax, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n+            { dup(), bufferLoad(0, long.class), vmStore(rdi, long.class),\n+              bufferLoad(8, int.class), vmStore(rsi, int.class)},\n+            { vmStore(rax, long.class) },\n@@ -121,2 +125,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -125,3 +129,4 @@\n-                { dup(), bufferLoad(0, long.class), vmStore(rdi, long.class),\n-                        bufferLoad(8, long.class), vmStore(rsi, long.class)},\n-                { vmStore(rax, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n+            { dup(), bufferLoad(0, long.class), vmStore(rdi, long.class),\n+                    bufferLoad(8, long.class), vmStore(rsi, long.class)},\n+            { vmStore(rax, long.class) },\n@@ -150,2 +155,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -154,3 +159,4 @@\n-                { dup(), bufferLoad(0, long.class), vmStore(stackStorage(0), long.class),\n-                        bufferLoad(8, long.class), vmStore(stackStorage(1), long.class)},\n-                { vmStore(rax, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n+            { dup(), bufferLoad(0, long.class), vmStore(stackStorage(0), long.class),\n+                    bufferLoad(8, long.class), vmStore(stackStorage(1), long.class)},\n+            { vmStore(rax, long.class) },\n@@ -179,2 +185,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -183,3 +189,4 @@\n-                { dup(), bufferLoad(0, long.class), vmStore(stackStorage(0), long.class),\n-                        bufferLoad(8, int.class), vmStore(stackStorage(1), int.class)},\n-                { vmStore(rax, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n+            { dup(), bufferLoad(0, long.class), vmStore(stackStorage(0), long.class),\n+                    bufferLoad(8, int.class), vmStore(stackStorage(1), int.class)},\n+            { vmStore(rax, long.class) },\n@@ -203,2 +210,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -207,0 +214,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -233,2 +241,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -237,0 +245,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -267,2 +276,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -271,0 +280,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -323,2 +333,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -327,0 +337,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -365,2 +376,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -369,0 +380,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -386,2 +398,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS));\n@@ -390,0 +402,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -444,2 +457,2 @@\n-        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class));\n-        assertEquals(callingSequence.functionDesc(), fd.withAppendedArgumentLayouts(C_LONG));\n+        assertEquals(callingSequence.methodType(), mt.appendParameterTypes(long.class).insertParameterTypes(0, MemorySegment.class, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.appendArgumentLayouts(C_LONG).insertArgumentLayouts(0, ADDRESS, ADDRESS));\n@@ -448,0 +461,2 @@\n+            { unboxAddress(MemorySegment.class), vmStore(r11, long.class) },\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -474,2 +489,2 @@\n-        assertEquals(callingSequence.methodType(), MethodType.methodType(void.class, MemoryAddress.class, long.class));\n-        assertEquals(callingSequence.functionDesc(), FunctionDescriptor.ofVoid(C_POINTER, C_LONG));\n+        assertEquals(callingSequence.methodType(), MethodType.methodType(void.class, NativeSymbol.class, MemoryAddress.class, long.class));\n+        assertEquals(callingSequence.functionDesc(), FunctionDescriptor.ofVoid(ADDRESS, C_POINTER, C_LONG));\n@@ -478,0 +493,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n","filename":"test\/jdk\/java\/foreign\/callarranger\/TestSysVCallArranger.java","additions":54,"deletions":38,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+import jdk.incubator.foreign.NativeSymbol;\n@@ -46,0 +47,1 @@\n+import static jdk.incubator.foreign.ValueLayout.ADDRESS;\n@@ -62,2 +64,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -65,1 +67,3 @@\n-        checkArgumentBindings(callingSequence, new Binding[][]{});\n+        checkArgumentBindings(callingSequence, new Binding[][]{\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) }\n+        });\n@@ -77,2 +81,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -81,0 +85,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -98,2 +103,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -102,0 +107,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -121,2 +127,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -125,0 +131,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -151,2 +158,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -155,0 +162,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -181,0 +189,2 @@\n+        FunctionDescriptor fdExpected = FunctionDescriptor.ofVoid(\n+                ADDRESS, C_INT, C_DOUBLE).asVariadic(C_INT, C_DOUBLE, C_DOUBLE);\n@@ -185,2 +195,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fdExpected);\n@@ -189,0 +199,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -218,2 +229,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -222,0 +233,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -247,2 +259,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -251,0 +263,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -277,2 +290,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -281,0 +294,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -297,2 +311,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -300,1 +314,3 @@\n-        checkArgumentBindings(callingSequence, new Binding[][]{});\n+        checkArgumentBindings(callingSequence, new Binding[][]{\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n+        });\n@@ -319,2 +335,2 @@\n-        assertEquals(callingSequence.methodType(), MethodType.methodType(void.class, MemoryAddress.class));\n-        assertEquals(callingSequence.functionDesc(), FunctionDescriptor.ofVoid(C_POINTER));\n+        assertEquals(callingSequence.methodType(), MethodType.methodType(void.class, NativeSymbol.class, MemoryAddress.class));\n+        assertEquals(callingSequence.functionDesc(), FunctionDescriptor.ofVoid(ADDRESS, C_POINTER));\n@@ -323,0 +339,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n@@ -347,2 +364,2 @@\n-        assertEquals(callingSequence.methodType(), mt);\n-        assertEquals(callingSequence.functionDesc(), fd);\n+        assertEquals(callingSequence.methodType(), mt.insertParameterTypes(0, NativeSymbol.class));\n+        assertEquals(callingSequence.functionDesc(), fd.insertArgumentLayouts(0, ADDRESS));\n@@ -351,0 +368,1 @@\n+            { unboxAddress(NativeSymbol.class), vmStore(r10, long.class) },\n","filename":"test\/jdk\/java\/foreign\/callarranger\/TestWindowsCallArranger.java","additions":44,"deletions":26,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -127,1 +127,1 @@\n-                baseDesc.withAppendedArgumentLayouts(C_POINTER)\n+                baseDesc.appendArgumentLayouts(C_POINTER)\n","filename":"test\/micro\/org\/openjdk\/bench\/jdk\/incubator\/foreign\/Upcalls.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}