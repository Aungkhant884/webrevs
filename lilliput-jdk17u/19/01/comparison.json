{"files":[{"patch":"@@ -1915,12 +1915,0 @@\n-  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n-  if (UseFastLocking && max_monitors > 0) {\n-    C2CheckLockStackStub* stub = new (C->comp_arena()) C2CheckLockStackStub();\n-    C->output()->add_stub(stub);\n-    __ ldr(r9, Address(rthread, JavaThread::lock_stack_current_offset()));\n-    __ add(r9, r9, max_monitors * oopSize);\n-    __ ldr(r10, Address(rthread, JavaThread::lock_stack_limit_offset()));\n-    __ cmp(r9, r10);\n-    __ br(Assembler::GE, stub->entry());\n-    __ bind(stub->continuation());\n-  }\n-\n@@ -3845,5 +3833,4 @@\n-    if (UseFastLocking) {\n-      __ fast_lock(oop, disp_hdr, tmp, rscratch1, cont, false);\n-      \/\/ Indicate success at cont.\n-      __ cmp(oop, oop);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+      __ b(cont);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -3880,0 +3867,5 @@\n+      __ b(cont);\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ fast_lock(oop, disp_hdr, tmp, rscratch1, cont);\n+      __ b(cont);\n@@ -3881,1 +3873,0 @@\n-    __ b(cont);\n@@ -3894,1 +3885,1 @@\n-    if (!UseFastLocking) {\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n@@ -3931,1 +3922,1 @@\n-    if (!UseFastLocking) {\n+    if (LockingMode == LM_LEGACY) {\n@@ -3944,6 +3935,4 @@\n-\n-    if (UseFastLocking) {\n-      __ fast_unlock(oop, tmp, box, disp_hdr, cont);\n-      \/\/ Indicate success at cont.\n-      __ cmp(oop, oop);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ tst(oop, oop); \/\/ Set NE to indicate 'failure' -> take slow-path. We know that oop != 0.\n+      __ b(cont);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -3956,0 +3945,5 @@\n+      __ b(cont);\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ fast_unlock(oop, tmp, box, disp_hdr, cont);\n+      __ b(cont);\n@@ -3957,1 +3951,1 @@\n-    __ b(cont);\n+\n@@ -3965,1 +3959,1 @@\n-    if (UseFastLocking) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -3971,1 +3965,1 @@\n-      __ tst(tmp2, (uint64_t)(intptr_t) ANONYMOUS_OWNER);\n+      __ tst(tmp2, (uint64_t)ObjectMonitor::ANONYMOUS_OWNER);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":23,"deletions":29,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -245,1 +245,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n@@ -2542,1 +2542,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -92,2 +92,2 @@\n-  if (UseFastLocking) {\n-    fast_lock(obj, hdr, rscratch1, rscratch2, slow_case, false);\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    fast_lock(obj, hdr, rscratch1, rscratch2, slow_case);\n@@ -149,1 +149,9 @@\n-  if (UseFastLocking) {\n+  if (LockingMode != LM_LIGHTWEIGHT) {\n+    \/\/ load displaced header\n+    ldr(hdr, Address(disp_hdr, 0));\n+    \/\/ if the loaded hdr is null we had recursive locking\n+    \/\/ if we had recursive locking, we are done\n+    cbz(hdr, done);\n+  }\n+\n+  if (!UseBiasedLocking) {\n@@ -152,1 +160,4 @@\n-    verify_oop(obj);\n+  }\n+  verify_oop(obj);\n+\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -154,0 +165,4 @@\n+    \/\/ We cannot use tbnz here, the target might be too far away and cannot\n+    \/\/ be encoded.\n+    tst(hdr, markWord::monitor_value);\n+    br(Assembler::NE, slow_case);\n@@ -156,10 +171,0 @@\n-    \/\/ load displaced header\n-    ldr(hdr, Address(disp_hdr, 0));\n-    \/\/ if the loaded hdr is NULL we had recursive locking\n-    \/\/ if we had recursive locking, we are done\n-    cbz(hdr, done);\n-    if (!UseBiasedLocking) {\n-      \/\/ load object\n-      ldr(obj, Address(disp_hdr, BasicObjectLock::obj_offset_in_bytes()));\n-    }\n-    verify_oop(obj);\n@@ -177,0 +182,2 @@\n+    \/\/ done\n+    bind(done);\n@@ -178,2 +185,0 @@\n-  \/\/ done\n-  bind(done);\n@@ -336,1 +341,1 @@\n-void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes, int max_monitors) {\n+void C1_MacroAssembler::build_frame(int framesize, int bang_size_in_bytes) {\n@@ -343,13 +348,0 @@\n-  if (UseFastLocking && max_monitors > 0) {\n-    Label ok;\n-    ldr(r9, Address(rthread, JavaThread::lock_stack_current_offset()));\n-    add(r9, r9, max_monitors * oopSize);\n-    ldr(r10, Address(rthread, JavaThread::lock_stack_limit_offset()));\n-    cmp(r9, r10);\n-    br(Assembler::LT, ok);\n-    assert(StubRoutines::aarch64::check_lock_stack() != NULL, \"need runtime call stub\");\n-    movptr(rscratch1, (uintptr_t) StubRoutines::aarch64::check_lock_stack());\n-    blr(rscratch1);\n-    bind(ok);\n-  }\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_MacroAssembler_aarch64.cpp","additions":22,"deletions":30,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -52,12 +52,0 @@\n-int C2CheckLockStackStub::max_size() const {\n-  return 20;\n-}\n-\n-void C2CheckLockStackStub::emit(C2_MacroAssembler& masm) {\n-  __ bind(entry());\n-  assert(StubRoutines::aarch64::check_lock_stack() != NULL, \"need runtime call stub\");\n-  __ movptr(rscratch1, (uintptr_t) StubRoutines::aarch64::check_lock_stack());\n-  __ blr(rscratch1);\n-  __ b(continuation());\n-}\n-\n@@ -65,1 +53,4 @@\n-  return 20;\n+  \/\/ Max size of stub has been determined by testing with 0, in which case\n+  \/\/ C2CodeStubList::emit() will throw an assertion and report the actual size that\n+  \/\/ is needed.\n+  return 24;\n@@ -78,3 +69,6 @@\n-  __ ldr(t, Address(rthread, JavaThread::lock_stack_current_offset()));\n-  __ sub(t, t, oopSize);\n-  __ str(t, Address(rthread, JavaThread::lock_stack_current_offset()));\n+  __ ldrw(t, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  __ subw(t, t, oopSize);\n+#ifdef ASSERT\n+  __ str(zr, Address(rthread, t));\n+#endif\n+  __ strw(t, Address(rthread, JavaThread::lock_stack_top_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_CodeStubs_aarch64.cpp","additions":10,"deletions":16,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -729,1 +729,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -757,1 +757,1 @@\n-    if (UseFastLocking) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -835,3 +835,9 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            UseFastLocking ? obj_reg : lock_reg);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n+              obj_reg);\n+    } else {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+              lock_reg);\n+    }\n@@ -859,1 +865,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -870,2 +876,5 @@\n-    if (UseFastLocking) {\n-      Label slow_case;\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %r0\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    }\n@@ -873,2 +882,2 @@\n-      \/\/ Load oop into obj_reg(%c_rarg3)\n-      ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+    \/\/ Load oop into obj_reg(%c_rarg3)\n+    ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n@@ -876,2 +885,5 @@\n-      \/\/ Free entry\n-      str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+    \/\/ Free entry\n+    str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n+\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      Label slow_case;\n@@ -881,3 +893,8 @@\n-      Register tmp = header_reg;\n-      ldr(tmp, Address(rthread, JavaThread::lock_stack_current_offset()));\n-      ldr(tmp, Address(tmp, -oopSize));\n+      Register tmp = rscratch1;\n+      \/\/ First check for lock-stack underflow.\n+      ldrw(tmp, Address(rthread, JavaThread::lock_stack_top_offset()));\n+      cmpw(tmp, (unsigned)LockStack::start_offset());\n+      br(Assembler::LE, slow_case);\n+      \/\/ Then check if the top of the lock-stack matches the unlocked object.\n+      subw(tmp, tmp, oopSize);\n+      ldr(tmp, Address(rthread, tmp));\n@@ -888,0 +905,1 @@\n+      tbnz(header_reg, exact_log2(markWord::monitor_value), slow_case);\n@@ -892,10 +910,0 @@\n-      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-      \/\/ structure Store the BasicLock address into %r0\n-      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n-\n-      \/\/ Load oop into obj_reg(%c_rarg3)\n-      ldr(obj_reg, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n-      \/\/ Free entry\n-      str(zr, Address(lock_reg, BasicObjectLock::obj_offset_in_bytes()));\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":33,"deletions":25,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -5413,3 +5413,4 @@\n-\/\/ Attempt to fast-lock an object. Fall-through on success, branch to slow label\n-\/\/ on failure.\n-\/\/ Registers:\n+\/\/ Implements fast-locking.\n+\/\/ Branches to slow upon failure to lock the object, with ZF cleared.\n+\/\/ Falls through upon success with ZF set.\n+\/\/\n@@ -5418,3 +5419,3 @@\n-\/\/  - t1, t2, t3: temporary registers, will be destroyed\n-void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow, bool rt_check_stack) {\n-  assert(UseFastLocking, \"only used with fast-locking\");\n+\/\/  - t1, t2: temporary registers, will be destroyed\n+void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only used with new lightweight locking\");\n@@ -5423,7 +5424,4 @@\n-  if (rt_check_stack) {\n-    \/\/ Check if we would have space on lock-stack for the object.\n-    ldr(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n-    ldr(t2, Address(rthread, JavaThread::lock_stack_limit_offset()));\n-    cmp(t1, t2);\n-    br(Assembler::GE, slow);\n-  }\n+  \/\/ Check if we would have space on lock-stack for the object.\n+  ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  cmpw(t1, (unsigned)LockStack::end_offset() - 1);\n+  br(Assembler::GT, slow);\n@@ -5441,4 +5439,4 @@\n-  ldr(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n-  str(obj, Address(t1, 0));\n-  add(t1, t1, oopSize);\n-  str(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+  ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  str(obj, Address(rthread, t1));\n+  addw(t1, t1, oopSize);\n+  strw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n@@ -5447,0 +5445,7 @@\n+\/\/ Implements fast-unlocking.\n+\/\/ Branches to slow upon failure, with ZF cleared.\n+\/\/ Falls through upon success, with ZF set.\n+\/\/\n+\/\/ - obj: the object to be unlocked\n+\/\/ - hdr: the (pre-loaded) header of the object\n+\/\/ - t1, t2: temporary registers\n@@ -5448,1 +5453,1 @@\n-  assert(UseFastLocking, \"only used with fast-locking\");\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only used with new lightweight locking\");\n@@ -5451,2 +5456,33 @@\n-  \/\/ Load the expected old header (lock-bits cleared to indicate 'locked') into hdr\n-  andr(hdr, hdr, ~markWord::lock_mask_in_place);\n+#ifdef ASSERT\n+  {\n+    \/\/ The following checks rely on the fact that LockStack is only ever modified by\n+    \/\/ its owning thread, even if the lock got inflated concurrently; removal of LockStack\n+    \/\/ entries after inflation will happen delayed in that case.\n+\n+    \/\/ Check for lock-stack underflow.\n+    Label stack_ok;\n+    ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+    cmpw(t1, (unsigned)LockStack::start_offset());\n+    br(Assembler::GT, stack_ok);\n+    STOP(\"Lock-stack underflow\");\n+    bind(stack_ok);\n+  }\n+  {\n+    \/\/ Check if the top of the lock-stack matches the unlocked object.\n+    Label tos_ok;\n+    subw(t1, t1, oopSize);\n+    ldr(t1, Address(rthread, t1));\n+    cmpoop(t1, obj);\n+    br(Assembler::EQ, tos_ok);\n+    STOP(\"Top of lock-stack does not match the unlocked object\");\n+    bind(tos_ok);\n+  }\n+  {\n+    \/\/ Check that hdr is fast-locked.\n+    Label hdr_ok;\n+    tst(hdr, markWord::lock_mask_in_place);\n+    br(Assembler::EQ, hdr_ok);\n+    STOP(\"Header is not fast-locked\");\n+    bind(hdr_ok);\n+  }\n+#endif\n@@ -5463,3 +5499,6 @@\n-  ldr(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n-  sub(t1, t1, oopSize);\n-  str(t1, Address(rthread, JavaThread::lock_stack_current_offset()));\n+  ldrw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n+  subw(t1, t1, oopSize);\n+#ifdef ASSERT\n+  str(zr, Address(rthread, t1));\n+#endif\n+  strw(t1, Address(rthread, JavaThread::lock_stack_top_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":62,"deletions":23,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -1424,1 +1424,1 @@\n-  void fast_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow, bool rt_check_stack = true);\n+  void fast_lock(Register obj, Register hdr, Register t1, Register t2, Label& slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1776,4 +1776,3 @@\n-    if (UseFastLocking) {\n-      __ ldr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_lock(obj_reg, swap_reg, tmp, rscratch1, slow_path_lock);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ b(slow_path_lock);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -1814,0 +1813,4 @@\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ ldr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock(obj_reg, swap_reg, tmp, rscratch1, slow_path_lock);\n@@ -1936,1 +1939,1 @@\n-    if (!UseFastLocking) {\n+    if (LockingMode == LM_LEGACY) {\n@@ -1948,4 +1951,3 @@\n-    if (UseFastLocking) {\n-      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ b(slow_path_unlock);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -1961,0 +1963,5 @@\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n+      __ ldr(old_hdr, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ tbnz(old_hdr, exact_log2(markWord::monitor_value), slow_path_unlock);\n+      __ fast_unlock(obj_reg, old_hdr, swap_reg, rscratch1, slow_path_unlock);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":16,"deletions":9,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -5294,23 +5294,0 @@\n-  address generate_check_lock_stack() {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, \"StubRoutines\", \"check_lock_stack\");\n-\n-    address start = __ pc();\n-\n-    __ set_last_Java_frame(sp, rfp, lr, rscratch1);\n-    __ enter();\n-    __ push_call_clobbered_registers();\n-\n-    __ mov(c_rarg0, r9);\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, LockStack::ensure_lock_stack_size), 1);\n-\n-\n-    __ pop_call_clobbered_registers();\n-    __ leave();\n-    __ reset_last_Java_frame(true);\n-\n-    __ ret(lr);\n-\n-    return start;\n-  }\n-\n@@ -7625,3 +7602,0 @@\n-    if (UseFastLocking) {\n-      StubRoutines::aarch64::_check_lock_stack = generate_check_lock_stack();\n-    }\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":0,"deletions":26,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -60,1 +60,0 @@\n-address StubRoutines::aarch64::_check_lock_stack = NULL;\n","filename":"src\/hotspot\/cpu\/aarch64\/stubRoutines_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -75,2 +75,0 @@\n-  static address _check_lock_stack;\n-\n@@ -184,4 +182,0 @@\n-  static address check_lock_stack() {\n-    return _check_lock_stack;\n-  }\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/stubRoutines_aarch64.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -288,1 +288,1 @@\n-  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n+  __ build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n@@ -3491,1 +3491,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -3495,1 +3495,1 @@\n-    if (UseBiasedLocking || UseFastLocking) {\n+    if (UseBiasedLocking || LockingMode == LM_LIGHTWEIGHT) {\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRAssembler_x86.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -317,1 +317,1 @@\n-  if (UseBiasedLocking || UseFastLocking) {\n+  if (UseBiasedLocking || LockingMode == LM_LIGHTWEIGHT) {\n","filename":"src\/hotspot\/cpu\/x86\/c1_LIRGenerator_x86.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -63,1 +63,1 @@\n-  if (UseFastLocking) {\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -72,1 +72,1 @@\n-    fast_lock_impl(obj, hdr, thread, scratch, slow_case, LP64_ONLY(false) NOT_LP64(true));\n+    fast_lock_impl(obj, hdr, thread, scratch, slow_case);\n@@ -131,1 +131,1 @@\n-  if (UseFastLocking) {\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -171,0 +171,1 @@\n+\n@@ -344,1 +345,1 @@\n-void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors) {\n+void C1_MacroAssembler::build_frame(int frame_size_in_bytes, int bang_size_in_bytes) {\n@@ -365,13 +366,0 @@\n-#ifdef _LP64\n-  if (UseFastLocking && max_monitors > 0) {\n-    Label ok;\n-    movptr(rax, Address(r15_thread, JavaThread::lock_stack_current_offset()));\n-    addptr(rax, max_monitors * wordSize);\n-    cmpptr(rax, Address(r15_thread, JavaThread::lock_stack_limit_offset()));\n-    jcc(Assembler::less, ok);\n-    assert(StubRoutines::x86::check_lock_stack() != NULL, \"need runtime call stub\");\n-    call(RuntimeAddress(StubRoutines::x86::check_lock_stack()));\n-    bind(ok);\n-  }\n-#endif\n-\n","filename":"src\/hotspot\/cpu\/x86\/c1_MacroAssembler_x86.cpp","additions":5,"deletions":17,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -66,11 +66,0 @@\n-int C2CheckLockStackStub::max_size() const {\n-  return 10;\n-}\n-\n-void C2CheckLockStackStub::emit(C2_MacroAssembler& masm) {\n-  __ bind(entry());\n-  assert(StubRoutines::x86::check_lock_stack() != NULL, \"need runtime call stub\");\n-  __ call(RuntimeAddress(StubRoutines::x86::check_lock_stack()));\n-  __ jmp(continuation(), false \/* maybe_short *\/);\n-}\n-\n@@ -79,1 +68,4 @@\n-  return 18;\n+  \/\/ Max size of stub has been determined by testing with 0, in which case\n+  \/\/ C2CodeStubList::emit() will throw an assertion and report the actual size that\n+  \/\/ is needed.\n+  return DEBUG_ONLY(36) NOT_DEBUG(21);\n@@ -85,0 +77,1 @@\n+  Register t = tmp();\n@@ -86,1 +79,5 @@\n-  __ subptr(Address(r15_thread, JavaThread::lock_stack_current_offset()), oopSize);\n+  __ subl(Address(r15_thread, JavaThread::lock_stack_top_offset()), oopSize);\n+#ifdef ASSERT\n+  __ movl(t, Address(r15_thread, JavaThread::lock_stack_top_offset()));\n+  __ movptr(Address(r15_thread, t), 0);\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_CodeStubs_x86.cpp","additions":10,"deletions":13,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -520,17 +520,4 @@\n-  if (UseFastLocking) {\n-#ifdef _LP64\n-    fast_lock_impl(objReg, tmpReg, thread, scrReg, DONE_LABEL, false);\n-    xorl(tmpReg, tmpReg); \/\/ Set ZF=1 to indicate success\n-#else\n-    \/\/ We can not emit the lock-stack-check in verified_entry() because we don't have enough\n-    \/\/ registers (for thread ptr). Therefor we have to emit the lock-stack-check in\n-    \/\/ fast_lock_impl(). However, that check can take a slow-path with ZF=1, therefore\n-    \/\/ we need to handle it specially and force ZF=0 before taking the actual slow-path.\n-    Label slow;\n-    fast_lock_impl(objReg, tmpReg, thread, scrReg, slow);\n-    xorl(tmpReg, tmpReg);\n-    jmp(DONE_LABEL);\n-    bind(slow);\n-    testptr(objReg, objReg); \/\/ ZF=0 to indicate failure\n-#endif\n-  } else {\n+  if (LockingMode == LM_MONITOR) {\n+    \/\/ Clear ZF so that we take the slow path at the DONE label. objReg is known to be not 0.\n+    testptr(objReg, objReg);\n+  } else if (LockingMode == LM_LEGACY) {\n@@ -559,0 +546,4 @@\n+  } else {\n+    assert(LockingMode == LM_LIGHTWEIGHT, \"\");\n+    fast_lock_impl(objReg, tmpReg, thread, scrReg, DONE_LABEL);\n+    xorl(tmpReg, tmpReg); \/\/ Set ZF=1 to indicate success\n@@ -599,1 +590,1 @@\n-  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -601,0 +592,8 @@\n+  \/\/ If we weren't able to swing _owner from NULL to the BasicLock\n+  \/\/ then take the slow path.\n+  jccb  (Assembler::notZero, DONE_LABEL);\n+  \/\/ update _owner from BasicLock to thread\n+  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n+  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n+  xorptr(boxReg, boxReg);                 \/\/ set icc.ZFlag = 1 to indicate success\n+\n@@ -699,1 +698,1 @@\n-  if (!UseFastLocking) {\n+  if (LockingMode == LM_LEGACY) {\n@@ -704,2 +703,4 @@\n-  testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n-  jcc(Assembler::zero, Stacked);\n+  if (LockingMode != LM_MONITOR) {\n+    testptr(tmpReg, markWord::monitor_value);                         \/\/ Inflated?\n+    jcc(Assembler::zero, Stacked);\n+  }\n@@ -707,1 +708,2 @@\n-  if (UseFastLocking) {\n+  \/\/ It's inflated.\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -709,1 +711,1 @@\n-    testb(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int) (intptr_t) ANONYMOUS_OWNER);\n+    testb(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int) (intptr_t) ObjectMonitor::ANONYMOUS_OWNER);\n@@ -711,8 +713,6 @@\n-    C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmpReg);\n-    Compile::current()->output()->add_stub(stub);\n-    jcc(Assembler::notEqual, stub->entry());\n-    bind(stub->continuation());\n-#else\n-    \/\/ We can't easily implement this optimization on 32 bit because we don't have a thread register.\n-    \/\/ Call the slow-path instead.\n-    jcc(Assembler::notEqual, DONE_LABEL);\n+    if (!Compile::current()->output()->in_scratch_emit_size()) {\n+      C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmpReg, boxReg);\n+      Compile::current()->output()->add_stub(stub);\n+      jcc(Assembler::notEqual, stub->entry());\n+      bind(stub->continuation());\n+    } else\n@@ -720,0 +720,5 @@\n+    {\n+      \/\/ We can't easily implement this optimization on 32 bit because we don't have a thread register.\n+      \/\/ Call the slow-path instead.\n+      jcc(Assembler::notEqual, DONE_LABEL);\n+    }\n@@ -722,1 +727,0 @@\n-  \/\/ It's inflated.\n@@ -766,1 +770,1 @@\n-  jccb  (Assembler::notZero, CheckSucc);\n+  jccb  (Assembler::notZero, DONE_LABEL);\n@@ -770,15 +774,0 @@\n-  bind (Stacked);\n-  if (UseFastLocking) {\n-    mov(boxReg, tmpReg);\n-    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n-    xorl(tmpReg, tmpReg);\n-  } else {\n-    \/\/ It's not inflated and it's not recursively stack-locked and it's not biased.\n-    \/\/ It must be stack-locked.\n-    \/\/ Try to reset the header to displaced header.\n-    \/\/ The \"box\" value on the stack is stable, so we can reload\n-    \/\/ and be assured we observe the same value as above.\n-    movptr(tmpReg, Address(boxReg, 0));\n-    lock();\n-    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n-  }\n@@ -868,12 +857,0 @@\n-  bind  (Stacked);\n-\n-  if (UseFastLocking) {\n-    mov(boxReg, tmpReg);\n-    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n-    xorl(tmpReg, tmpReg);\n-  } else {\n-    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-    lock();\n-    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n-  }\n-\n@@ -881,0 +858,12 @@\n+  if (LockingMode != LM_MONITOR) {\n+    bind  (Stacked);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      mov(boxReg, tmpReg);\n+      fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n+      xorl(tmpReg, tmpReg);\n+    } else if (LockingMode == LM_LEGACY) {\n+      movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n+      lock();\n+      cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+    }\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":49,"deletions":60,"binary":false,"changes":109,"status":"modified"},{"patch":"@@ -1200,1 +1200,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -1234,1 +1234,1 @@\n-    if (UseFastLocking) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -1310,4 +1310,9 @@\n-    call_VM(noreg,\n-            CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n-            UseFastLocking ? obj_reg : lock_reg);\n-\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj),\n+              obj_reg);\n+    } else {\n+      call_VM(noreg,\n+              CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter),\n+              lock_reg);\n+    }\n@@ -1335,1 +1340,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -1346,0 +1351,6 @@\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n+      \/\/ structure Store the BasicLock address into %rax\n+      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n+    }\n+\n@@ -1352,1 +1363,1 @@\n-    if (UseFastLocking) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -1361,2 +1372,2 @@\n-      movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n-      cmpptr(obj_reg, Address(tmp, -oopSize));\n+      movl(tmp, Address(thread, JavaThread::lock_stack_top_offset()));\n+      cmpptr(obj_reg, Address(thread, tmp, Address::times_1,  -oopSize));\n@@ -1370,4 +1381,0 @@\n-      \/\/ Convert from BasicObjectLock structure to object and BasicLock\n-      \/\/ structure Store the BasicLock address into %rax\n-      lea(swap_reg, Address(lock_reg, BasicObjectLock::lock_offset_in_bytes()));\n-\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":21,"deletions":14,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -5209,1 +5209,1 @@\n-void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub, int max_monitors) {\n+void MacroAssembler::verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub) {\n@@ -5291,14 +5291,0 @@\n-#if defined(_LP64) && defined(COMPILER2)\n-  if (UseFastLocking && max_monitors > 0) {\n-    C2CheckLockStackStub* stub = new (Compile::current()->comp_arena()) C2CheckLockStackStub();\n-    Compile::current()->output()->add_stub(stub);\n-    assert(!is_stub, \"only methods have monitors\");\n-    Register thread = r15_thread;\n-    movptr(rax, Address(thread, JavaThread::lock_stack_current_offset()));\n-    addptr(rax, max_monitors * wordSize);\n-    cmpptr(rax, Address(thread, JavaThread::lock_stack_limit_offset()));\n-    jcc(Assembler::greaterEqual, stub->entry());\n-    bind(stub->continuation());\n-  }\n-#endif\n-\n@@ -8788,1 +8774,9 @@\n-void MacroAssembler::fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp, Label& slow, bool rt_check_stack) {\n+\/\/ Implements fast-locking.\n+\/\/ Branches to slow upon failure to lock the object, with ZF cleared.\n+\/\/ Falls through upon success with unspecified ZF.\n+\/\/\n+\/\/ obj: the object to be locked\n+\/\/ hdr: the (pre-loaded) header of the object, must be rax\n+\/\/ thread: the thread which attempts to lock obj\n+\/\/ tmp: a temporary register\n+void MacroAssembler::fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp, Label& slow) {\n@@ -8793,15 +8787,5 @@\n-  if (rt_check_stack) {\n-    movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n-    cmpptr(tmp, Address(thread, JavaThread::lock_stack_limit_offset()));\n-    jcc(Assembler::greaterEqual, slow);\n-  }\n-#ifdef ASSERT\n-  else {\n-    Label ok;\n-    movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n-    cmpptr(tmp, Address(thread, JavaThread::lock_stack_limit_offset()));\n-    jcc(Assembler::less, ok);\n-    stop(\"Not enough room in lock stack; should have been checked in the method prologue\");\n-    bind(ok);\n-  }\n-#endif\n+  \/\/ Note: we subtract 1 from the end-offset so that we can do a 'greater' comparison, instead\n+  \/\/ of 'greaterEqual' below, which readily clears the ZF. This makes C2 code a little simpler and\n+  \/\/ avoids one branch.\n+  cmpl(Address(thread, JavaThread::lock_stack_top_offset()), LockStack::end_offset() - 1);\n+  jcc(Assembler::greater, slow);\n@@ -8810,2 +8794,2 @@\n-  \/\/ Clear lowest two header bits (locked state).\n-  andptr(hdr, ~(int32_t )markWord::lock_mask_in_place);\n+  \/\/ Clear lock_mask bits (locked state).\n+  andptr(hdr, ~(int32_t)markWord::lock_mask_in_place);\n@@ -8813,1 +8797,1 @@\n-  \/\/ Set lowest bit (unlocked state).\n+  \/\/ Set unlocked_value bit.\n@@ -8820,4 +8804,4 @@\n-  movptr(tmp, Address(thread, JavaThread::lock_stack_current_offset()));\n-  movptr(Address(tmp, 0), obj);\n-  addptr(tmp, oopSize);\n-  movptr(Address(thread, JavaThread::lock_stack_current_offset()), tmp);\n+  movl(tmp, Address(thread, JavaThread::lock_stack_top_offset()));\n+  movptr(Address(thread, tmp), obj);\n+  incrementl(tmp, oopSize);\n+  movl(Address(thread, JavaThread::lock_stack_top_offset()), tmp);\n@@ -8826,0 +8810,7 @@\n+\/\/ Implements fast-unlocking.\n+\/\/ Branches to slow upon failure, with ZF cleared.\n+\/\/ Falls through upon success, with unspecified ZF.\n+\/\/\n+\/\/ obj: the object to be unlocked\n+\/\/ hdr: the (pre-loaded) header of the object, must be rax\n+\/\/ tmp: a temporary register\n@@ -8830,1 +8821,1 @@\n-  \/\/ Mark-word must be 00 now, try to swing it back to 01 (unlocked)\n+  \/\/ Mark-word must be lock_mask now, try to swing it back to unlocked_value.\n@@ -8841,1 +8832,6 @@\n-  get_thread(rax);\n+  get_thread(thread);\n+#endif\n+  subl(Address(thread, JavaThread::lock_stack_top_offset()), oopSize);\n+#ifdef ASSERT\n+  movl(tmp, Address(thread, JavaThread::lock_stack_top_offset()));\n+  movptr(Address(thread, tmp), 0);\n@@ -8843,1 +8839,0 @@\n-  subptr(Address(thread, JavaThread::lock_stack_current_offset()), oopSize);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":36,"deletions":41,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -1737,1 +1737,1 @@\n-  void verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub, int max_monitors);\n+  void verified_entry(int framesize, int stack_bang_size, bool fp_mode_24b, bool is_stub);\n@@ -1925,1 +1925,1 @@\n-  void fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp, Label& slow, bool rt_check_stack = true);\n+  void fast_lock_impl(Register obj, Register hdr, Register thread, Register tmp, Label& slow);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1826,5 +1826,3 @@\n-    if (UseFastLocking) {\n-     \/\/ Load object header\n-     __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-     __ fast_lock_impl(obj_reg, swap_reg, thread, lock_reg, slow_path_lock);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ jmp(slow_path_lock);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -1866,0 +1864,5 @@\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+     \/\/ Load object header\n+     __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+     __ fast_lock_impl(obj_reg, swap_reg, thread, lock_reg, slow_path_lock);\n@@ -2006,1 +2009,1 @@\n-    if (!UseFastLocking) {\n+    if (LockingMode == LM_LEGACY) {\n@@ -2018,5 +2021,3 @@\n-    if (UseFastLocking) {\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n-      __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ jmp(slow_path_unlock);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -2035,0 +2036,5 @@\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":17,"deletions":11,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -2075,5 +2075,3 @@\n-    if (UseFastLocking) {\n-      \/\/ Load object header\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ fast_lock_impl(obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ jmp(slow_path_lock);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -2115,0 +2113,5 @@\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      \/\/ Load object header\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ fast_lock_impl(obj_reg, swap_reg, r15_thread, rscratch1, slow_path_lock);\n@@ -2240,1 +2243,1 @@\n-    if (!UseFastLocking) {\n+    if (LockingMode == LM_LEGACY) {\n@@ -2252,5 +2255,3 @@\n-    if (UseFastLocking) {\n-      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n-      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n-      __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n-    } else {\n+    if (LockingMode == LM_MONITOR) {\n+      __ jmp(slow_path_unlock);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -2266,0 +2267,5 @@\n+    } else {\n+      assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+      __ movptr(swap_reg, Address(obj_reg, oopDesc::mark_offset_in_bytes()));\n+      __ andptr(swap_reg, ~(int32_t)markWord::lock_mask_in_place);\n+      __ fast_unlock_impl(obj_reg, swap_reg, lock_reg, slow_path_unlock);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":17,"deletions":11,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -6804,52 +6804,0 @@\n-  \/\/ Call runtime to ensure lock-stack size.\n-  \/\/ Arguments:\n-  \/\/ - c_rarg0: the required _limit pointer\n-  address generate_check_lock_stack() {\n-    __ align(CodeEntryAlignment);\n-    StubCodeMark mark(this, \"StubRoutines\", \"check_lock_stack\");\n-    address start = __ pc();\n-\n-    BLOCK_COMMENT(\"Entry:\");\n-    __ enter(); \/\/ save rbp\n-\n-    __ pusha();\n-\n-    \/\/ The method may have floats as arguments, and we must spill them before calling\n-    \/\/ the VM runtime.\n-    __ push_FPU_state();\n-    \/*\n-    assert(Argument::n_float_register_parameters_j == 8, \"Assumption\");\n-    const int xmm_size = wordSize * 2;\n-    const int xmm_spill_size = xmm_size * Argument::n_float_register_parameters_j;\n-    __ subptr(rsp, xmm_spill_size);\n-    __ movdqu(Address(rsp, xmm_size * 7), xmm7);\n-    __ movdqu(Address(rsp, xmm_size * 6), xmm6);\n-    __ movdqu(Address(rsp, xmm_size * 5), xmm5);\n-    __ movdqu(Address(rsp, xmm_size * 4), xmm4);\n-    __ movdqu(Address(rsp, xmm_size * 3), xmm3);\n-    __ movdqu(Address(rsp, xmm_size * 2), xmm2);\n-    __ movdqu(Address(rsp, xmm_size * 1), xmm1);\n-    __ movdqu(Address(rsp, xmm_size * 0), xmm0);\n-    *\/\n-    __ call_VM_leaf(CAST_FROM_FN_PTR(address, static_cast<void (*)(oop*)>(LockStack::ensure_lock_stack_size)), rax);\n-    \/*\n-    __ movdqu(xmm0, Address(rsp, xmm_size * 0));\n-    __ movdqu(xmm1, Address(rsp, xmm_size * 1));\n-    __ movdqu(xmm2, Address(rsp, xmm_size * 2));\n-    __ movdqu(xmm3, Address(rsp, xmm_size * 3));\n-    __ movdqu(xmm4, Address(rsp, xmm_size * 4));\n-    __ movdqu(xmm5, Address(rsp, xmm_size * 5));\n-    __ movdqu(xmm6, Address(rsp, xmm_size * 6));\n-    __ movdqu(xmm7, Address(rsp, xmm_size * 7));\n-    __ addptr(rsp, xmm_spill_size);\n-    *\/\n-    __ pop_FPU_state();\n-    __ popa();\n-\n-    __ leave();\n-\n-    __ ret(0);\n-\n-    return start;\n-  }\n-\n@@ -7776,3 +7724,0 @@\n-    if (UseFastLocking) {\n-      StubRoutines::x86::_check_lock_stack = generate_check_lock_stack();\n-    }\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":0,"deletions":55,"binary":false,"changes":55,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-address StubRoutines::x86::_check_lock_stack = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -134,2 +134,0 @@\n-  static address _check_lock_stack;\n-\n@@ -271,2 +269,0 @@\n-  static address check_lock_stack() { return _check_lock_stack; }\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -630,2 +630,1 @@\n-  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL, max_monitors);\n+  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -903,2 +903,1 @@\n-  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL, max_monitors);\n+  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -118,0 +118,5 @@\n+  if ((LockingMode != LM_LEGACY) && (LockingMode != LM_MONITOR)) {\n+    warning(\"Unsupported locking mode for this CPU.\");\n+    FLAG_SET_DEFAULT(LockingMode, LM_LEGACY);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/zero\/vm_version_zero.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -336,1 +336,1 @@\n-    bool call_vm = UseHeavyMonitors;\n+    bool call_vm = (LockingMode == LM_MONITOR);\n","filename":"src\/hotspot\/cpu\/zero\/zeroInterpreter_zero.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -385,4 +385,0 @@\n-  if (method()->is_synchronized()) {\n-    push_monitor();\n-  }\n-\n@@ -565,1 +561,0 @@\n-, _max_monitors(0)\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-  int                _max_monitors; \/\/ Max number of active monitors, for fast-locking\n@@ -141,1 +140,0 @@\n-  int max_monitors() const                       { return _max_monitors; }\n@@ -171,2 +169,0 @@\n-  void push_monitor()                            { _max_monitors++; }\n-\n","filename":"src\/hotspot\/share\/c1\/c1_Compilation.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2239,1 +2239,0 @@\n-  compilation()->push_monitor();\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -761,1 +761,1 @@\n-  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes(), compilation()->max_monitors());\n+  _masm->build_frame(initial_frame_size_in_bytes(), bang_size_in_bytes());\n","filename":"src\/hotspot\/share\/c1\/c1_LIRAssembler.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -639,1 +639,1 @@\n-  CodeStub* slow_path = new MonitorExitStub(lock, !UseHeavyMonitors, monitor_no);\n+  CodeStub* slow_path = new MonitorExitStub(lock, LockingMode != LM_MONITOR, monitor_no);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  void build_frame(int frame_size_in_bytes, int bang_size_in_bytes, int max_monitors);\n+  void build_frame(int frame_size_in_bytes, int bang_size_in_bytes);\n","filename":"src\/hotspot\/share\/c1\/c1_MacroAssembler.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -702,1 +702,1 @@\n-  if (UseHeavyMonitors) {\n+  if (LockingMode == LM_MONITOR) {\n@@ -705,2 +705,2 @@\n-  assert(UseFastLocking || obj == lock->obj(), \"must match\");\n-  SharedRuntime::monitor_enter_helper(obj, UseFastLocking ? NULL : lock->lock(), current);\n+  assert(LockingMode == LM_LIGHTWEIGHT || obj == lock->obj(), \"must match\");\n+  SharedRuntime::monitor_enter_helper(obj, LockingMode == LM_LIGHTWEIGHT ? NULL : lock->lock(), current);\n","filename":"src\/hotspot\/share\/c1\/c1_Runtime1.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -251,0 +251,3 @@\n+  develop(bool, UseFastLocking, true,                                       \\\n+          \"Use fast inlined locking code\")                                  \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/c1\/c1_globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -47,1 +47,0 @@\n-  assert(!mark.has_locker(), \"can not be stack-locked\");\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahObjectUtils.inline.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -727,9 +727,1 @@\n-  if (!UseHeavyMonitors && UseFastLocking) {\n-    \/\/ This is a hack to get around the limitation of registers in x86_32. We really\n-    \/\/ send an oopDesc* instead of a BasicObjectLock*.\n-    Handle h_obj(current, oop((reinterpret_cast<oopDesc*>(elem))));\n-    assert(Universe::heap()->is_in_or_null(h_obj()),\n-           \"must be NULL or an object\");\n-    ObjectSynchronizer::enter(h_obj, NULL, current);\n-    return;\n-  }\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"Should call monitorenter_obj() when using the new lightweight locking\");\n@@ -753,0 +745,16 @@\n+\/\/ NOTE: We provide a separate implementation for the new lightweight locking to workaround a limitation\n+\/\/ of registers in x86_32. This entry point accepts an oop instead of a BasicObjectLock*.\n+\/\/ The problem is that we would need to preserve the register that holds the BasicObjectLock,\n+\/\/ but we are using that register to hold the thread. We don't have enough registers to\n+\/\/ also keep the BasicObjectLock, but we don't really need it anyway, we only need\n+\/\/ the object. See also InterpreterMacroAssembler::lock_object().\n+\/\/ As soon as legacy stack-locking goes away we could remove the other monitorenter() entry\n+\/\/ point, and only use oop-accepting entries (same for monitorexit() below).\n+JRT_ENTRY_NO_ASYNC(void, InterpreterRuntime::monitorenter_obj(JavaThread* current, oopDesc* obj))\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"Should call monitorenter() when not using the new lightweight locking\");\n+  Handle h_obj(current, cast_to_oop(obj));\n+  assert(Universe::heap()->is_in_or_null(h_obj()),\n+         \"must be null or an object\");\n+  ObjectSynchronizer::enter(h_obj, NULL, current);\n+  return;\n+JRT_END\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":17,"deletions":9,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -109,0 +109,1 @@\n+  static void    monitorenter_obj(JavaThread* current, oopDesc* obj);\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -630,1 +630,1 @@\n-        bool call_vm = UseHeavyMonitors;\n+        bool call_vm = (LockingMode == LM_MONITOR);\n@@ -726,1 +726,1 @@\n-      bool call_vm = UseHeavyMonitors;\n+      bool call_vm = (LockingMode == LM_MONITOR);\n@@ -1636,1 +1636,1 @@\n-          bool call_vm = UseHeavyMonitors;\n+          bool call_vm = (LockingMode == LM_MONITOR);\n@@ -1668,1 +1668,1 @@\n-            bool call_vm = UseHeavyMonitors;\n+            bool call_vm = (LockingMode == LM_MONITOR);\n@@ -3151,1 +3151,1 @@\n-          } else if (UseHeavyMonitors) {\n+          } else if (LockingMode == LM_MONITOR) {\n","filename":"src\/hotspot\/share\/interpreter\/zero\/bytecodeInterpreter.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -87,1 +87,1 @@\n-\/\/    [ptr             | 10]  monitor            inflated lock (header is wapped out)\n+\/\/    [ptr             | 10]  monitor            inflated lock (header is swapped out)\n@@ -89,1 +89,1 @@\n-\/\/    [0 ............ 0| 00]  inflating          inflation in progress\n+\/\/    [0 ............ 0| 00]  inflating          inflation in progress (stack-locking in use)\n@@ -265,0 +265,1 @@\n+  \/\/ Fast-locking does not use INFLATING.\n@@ -296,1 +297,2 @@\n-    return !UseFastLocking && ((value() & lock_mask_in_place) == locked_value);\n+    assert(LockingMode == LM_LEGACY, \"should only be called with legacy stack locking\");\n+    return (value() & lock_mask_in_place) == locked_value;\n@@ -304,1 +306,2 @@\n-    return UseFastLocking && ((value() & lock_mask_in_place) == locked_value);\n+    assert(LockingMode == LM_LIGHTWEIGHT, \"should only be called with new lightweight locking\");\n+    return (value() & lock_mask_in_place) == locked_value;\n@@ -314,1 +317,1 @@\n-    assert(has_monitor(), \"check\");\n+   assert(has_monitor(), \"check\");\n@@ -320,2 +323,2 @@\n-    return UseFastLocking ? lockbits == monitor_value   \/\/ monitor?\n-                          : (lockbits & unlocked_value) == 0; \/\/ monitor | stack-locked?\n+    return LockingMode == LM_LIGHTWEIGHT  ? lockbits == monitor_value   \/\/ monitor?\n+                                          : (lockbits & unlocked_value) == 0; \/\/ monitor | stack-locked?\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -108,1 +108,1 @@\n-  \/\/ at a safepoint, it must not be zero.\n+  \/\/ at a safepoint, it must not be zero, except when using the new lightweight locking.\n@@ -111,1 +111,1 @@\n-  if (ignore_mark_word || UseFastLocking) {\n+  if (ignore_mark_word) {\n@@ -117,1 +117,1 @@\n-  return !SafepointSynchronize::is_at_safepoint();\n+  return LockingMode == LM_LIGHTWEIGHT || !SafepointSynchronize::is_at_safepoint();\n","filename":"src\/hotspot\/share\/oops\/oop.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -86,1 +86,1 @@\n-  assert(UseFastLocking, \"Only safe with fast-locking\");\n+  assert(LockingMode != LM_LEGACY, \"Not safe with legacy stack-locking\");\n","filename":"src\/hotspot\/share\/oops\/oop.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -996,1 +996,0 @@\n-  reset_max_monitors();\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -305,1 +305,0 @@\n-  uint                  _max_monitors;          \/\/ Keep track of maximum number of active monitors in this compilation\n@@ -600,4 +599,0 @@\n-  void          push_monitor() { _max_monitors++; }\n-  void          reset_max_monitors() { _max_monitors = 0; }\n-  uint          max_monitors() { return _max_monitors; }\n-\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -191,2 +191,0 @@\n-  C->push_monitor();\n-\n","filename":"src\/hotspot\/share\/opto\/locknode.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -426,5 +426,1 @@\n-  if (parse_method->is_synchronized()) {\n-    C->push_monitor();\n-  }\n-\n-   _tf = TypeFunc::make(method());\n+  _tf = TypeFunc::make(method());\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2006,0 +2006,16 @@\n+#if !defined(X86) && !defined(AARCH64)\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    FLAG_SET_CMDLINE(LockingMode, LM_LEGACY);\n+    warning(\"New lightweight locking not supported on this platform\");\n+  }\n+#endif\n+\n+  if (UseHeavyMonitors) {\n+    if (FLAG_IS_CMDLINE(LockingMode) && LockingMode != LM_MONITOR) {\n+      jio_fprintf(defaultStream::error_stream(),\n+                  \"Conflicting -XX:+UseHeavyMonitors and -XX:LockingMode=%d flags\", LockingMode);\n+      return false;\n+    }\n+    FLAG_SET_CMDLINE(LockingMode, LM_MONITOR);\n+  }\n+\n@@ -3162,8 +3178,5 @@\n-  if (UseCompactObjectHeaders) {\n-    if (!UseFastLocking) {\n-      \/\/ Lilliput requires fast-locking.\n-      FLAG_SET_DEFAULT(UseFastLocking, true);\n-    }\n-    if (UseBiasedLocking) {\n-      FLAG_SET_DEFAULT(UseBiasedLocking, false);\n-    }\n+  if (UseCompactObjectHeaders && LockingMode == LM_LEGACY) {\n+    FLAG_SET_DEFAULT(LockingMode, LM_LIGHTWEIGHT);\n+  }\n+  if (UseCompactObjectHeaders && UseBiasedLocking) {\n+    FLAG_SET_DEFAULT(UseBiasedLocking, false);\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":21,"deletions":8,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -1475,1 +1475,1 @@\n-          if (mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n+          if (LockingMode == LM_LEGACY && mark.has_locker() && fr.sp() > (intptr_t*)mark.locker()) {\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2106,2 +2106,6 @@\n-  product(bool, UseFastLocking, false, EXPERIMENTAL,                        \\\n-                \"Use fast-locking instead of stack-locking\")                \\\n+  product(int, LockingMode, LM_LEGACY, EXPERIMENTAL,                        \\\n+          \"Select locking mode: \"                                           \\\n+          \"0: monitors only (LM_MONITOR), \"                                 \\\n+          \"1: monitors & legacy stack-locking (LM_LEGACY, default), \"       \\\n+          \"2: monitors & new lightweight locking (LM_LIGHTWEIGHT)\")         \\\n+          range(0, 2)                                                       \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,2 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -27,1 +28,1 @@\n-#include \"runtime\/lockStack.hpp\"\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -29,0 +30,2 @@\n+#include \"runtime\/stackWatermark.hpp\"\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n@@ -33,5 +36,3 @@\n-LockStack::LockStack() :\n-        _base(UseHeavyMonitors ? NULL : NEW_C_HEAP_ARRAY(oop, INITIAL_CAPACITY, mtSynchronizer)),\n-        _limit(_base + INITIAL_CAPACITY),\n-        _current(_base) {\n-}\n+const int LockStack::lock_stack_offset =      in_bytes(JavaThread::lock_stack_offset());\n+const int LockStack::lock_stack_top_offset =  in_bytes(JavaThread::lock_stack_top_offset());\n+const int LockStack::lock_stack_base_offset = in_bytes(JavaThread::lock_stack_base_offset());\n@@ -39,3 +40,5 @@\n-LockStack::~LockStack() {\n-  if (!UseHeavyMonitors) {\n-    FREE_C_HEAP_ARRAY(oop, _base);\n+LockStack::LockStack(JavaThread* jt) :\n+  _top(lock_stack_base_offset), _base() {\n+#ifdef ASSERT\n+  for (int i = 0; i < CAPACITY; i++) {\n+    _base[i] = NULL;\n@@ -43,11 +46,0 @@\n-}\n-\n-#ifndef PRODUCT\n-void LockStack::validate(const char* msg) const {\n-  assert(!UseHeavyMonitors, \"never use lock-stack when fast-locking is disabled\");\n-  for (oop* loc1 = _base; loc1 < _current - 1; loc1++) {\n-    for (oop* loc2 = loc1 + 1; loc2 < _current; loc2++) {\n-      assert(*loc1 != *loc2, \"entries must be unique: %s\", msg);\n-    }\n-  }\n-}\n@@ -55,17 +47,0 @@\n-\n-void LockStack::grow(size_t min_capacity) {\n-  \/\/ Grow stack.\n-  assert(_limit > _base, \"invariant\");\n-  size_t capacity = _limit - _base;\n-  size_t index = _current - _base;\n-  size_t new_capacity = MAX2(min_capacity, capacity * 2);\n-  oop* new_stack = NEW_C_HEAP_ARRAY(oop, new_capacity, mtSynchronizer);\n-  for (size_t i = 0; i < index; i++) {\n-    *(new_stack + i) = *(_base + i);\n-  }\n-  FREE_C_HEAP_ARRAY(oop, _base);\n-  _base = new_stack;\n-  _limit = _base + new_capacity;\n-  _current = _base + index;\n-  assert(_current < _limit, \"must fit after growing\");\n-  assert((_limit - _base) >= (ptrdiff_t) min_capacity, \"must grow enough\");\n@@ -74,2 +49,4 @@\n-void LockStack::grow() {\n-  grow((_limit - _base) + 1);\n+uint32_t LockStack::start_offset() {\n+  int offset = lock_stack_base_offset;\n+  assert(offset > 0, \"must be positive offset\");\n+  return static_cast<uint32_t>(offset);\n@@ -78,2 +55,4 @@\n-void LockStack::grow(oop* required_limit) {\n-  grow(required_limit - _base);\n+uint32_t LockStack::end_offset() {\n+  int offset = lock_stack_base_offset + CAPACITY * oopSize;\n+  assert(offset > 0, \"must be positive offset\");\n+  return static_cast<uint32_t>(offset);\n@@ -82,3 +61,17 @@\n-void LockStack::ensure_lock_stack_size(oop* _required_limit) {\n-  JavaThread* jt = JavaThread::current();\n-  jt->lock_stack().grow(_required_limit);\n+#ifndef PRODUCT\n+void LockStack::verify(const char* msg) const {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"never use lock-stack when light weight locking is disabled\");\n+  assert((_top <= end_offset()), \"lockstack overflow: _top %d end_offset %d\", _top, end_offset());\n+  assert((_top >= start_offset()), \"lockstack underflow: _top %d end_offset %d\", _top, start_offset());\n+  if (SafepointSynchronize::is_at_safepoint() || (Thread::current()->is_Java_thread() && is_owning_thread())) {\n+    int top = to_index(_top);\n+    for (int i = 0; i < top; i++) {\n+      assert(_base[i] != NULL, \"no zapped before top\");\n+      for (int j = i + 1; j < top; j++) {\n+        assert(_base[i] != _base[j], \"entries must be unique: %s\", msg);\n+      }\n+    }\n+    for (int i = top; i < CAPACITY; i++) {\n+      assert(_base[i] == NULL, \"only zapped entries after top: i: %d, top: %d, entry: \" PTR_FORMAT, i, top, p2i(_base[i]));\n+    }\n+  }\n@@ -86,0 +79,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/lockStack.cpp","additions":39,"deletions":45,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -2,1 +2,2 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -38,4 +39,1 @@\n-  static const size_t INITIAL_CAPACITY = 1;\n-  oop* _base;\n-  oop* _limit;\n-  oop* _current;\n+  static const int CAPACITY = 8;\n@@ -43,3 +41,24 @@\n-  void grow();\n-  void grow(size_t min_capacity);\n-  void grow(oop* required_limit);\n+  \/\/ TODO: It would be very useful if JavaThread::lock_stack_offset() and friends were constexpr,\n+  \/\/ but this is currently not the case because we're using offset_of() which is non-constexpr,\n+  \/\/ GCC would warn about non-standard-layout types if we were using offsetof() (which *is* constexpr).\n+  static const int lock_stack_offset;\n+  static const int lock_stack_top_offset;\n+  static const int lock_stack_base_offset;\n+\n+  \/\/ The offset of the next element, in bytes, relative to the JavaThread structure.\n+  \/\/ We do this instead of a simple index into the array because this allows for\n+  \/\/ efficient addressing in generated code.\n+  uint32_t _top;\n+  oop _base[CAPACITY];\n+\n+  \/\/ Get the owning thread of this lock-stack.\n+  inline JavaThread* get_thread() const;\n+\n+  \/\/ Tests if the calling thread is the thread that owns this lock-stack.\n+  bool is_owning_thread() const;\n+\n+  \/\/ Verifies consistency of the lock-stack.\n+  void verify(const char* msg) const PRODUCT_RETURN;\n+\n+  \/\/ Given an offset (in bytes) calculate the index into the lock-stack.\n+  static inline int to_index(uint32_t offset);\n@@ -47,1 +66,0 @@\n-  void validate(const char* msg) const PRODUCT_RETURN;\n@@ -49,3 +67,4 @@\n-  static ByteSize current_offset()    { return byte_offset_of(LockStack, _current); }\n-  static ByteSize base_offset()       { return byte_offset_of(LockStack, _base); }\n-  static ByteSize limit_offset()      { return byte_offset_of(LockStack, _limit); }\n+  static ByteSize top_offset()  { return byte_offset_of(LockStack, _top); }\n+  static ByteSize base_offset() { return byte_offset_of(LockStack, _base); }\n+\n+  LockStack(JavaThread* jt);\n@@ -53,1 +72,3 @@\n-  static void ensure_lock_stack_size(oop* _required_limit);\n+  \/\/ The boundary indicies of the lock-stack.\n+  static uint32_t start_offset();\n+  static uint32_t end_offset();\n@@ -55,2 +76,2 @@\n-  LockStack();\n-  ~LockStack();\n+  \/\/ Return true if we have room to push onto this lock-stack, false otherwise.\n+  inline bool can_push() const;\n@@ -58,0 +79,1 @@\n+  \/\/ Pushes an oop on this lock-stack.\n@@ -59,0 +81,2 @@\n+\n+  \/\/ Pops an oop from this lock-stack.\n@@ -60,0 +84,2 @@\n+\n+  \/\/ Removes an oop from an arbitrary location of this lock-stack.\n@@ -62,0 +88,1 @@\n+  \/\/ Tests whether the oop is on this lock-stack.\n","filename":"src\/hotspot\/share\/runtime\/lockStack.hpp","additions":42,"deletions":15,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -2,1 +2,2 @@\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2022, Red Hat, Inc. All rights reserved.\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n@@ -30,0 +31,24 @@\n+#include \"runtime\/safepoint.hpp\"\n+#include \"runtime\/stackWatermark.hpp\"\n+#include \"runtime\/stackWatermarkSet.inline.hpp\"\n+#include \"runtime\/thread.hpp\"\n+\n+inline int LockStack::to_index(uint32_t offset) {\n+  return (offset - lock_stack_base_offset) \/ oopSize;\n+}\n+\n+JavaThread* LockStack::get_thread() const {\n+  char* addr = reinterpret_cast<char*>(const_cast<LockStack*>(this));\n+  return reinterpret_cast<JavaThread*>(addr - lock_stack_offset);\n+}\n+\n+inline bool LockStack::can_push() const {\n+  return to_index(_top) < CAPACITY;\n+}\n+\n+inline bool LockStack::is_owning_thread() const {\n+  JavaThread* thread = JavaThread::current();\n+  bool is_owning = &thread->lock_stack() == this;\n+  assert(is_owning == (get_thread() == thread), \"is_owning sanity\");\n+  return is_owning;\n+}\n@@ -32,1 +57,1 @@\n-  validate(\"pre-push\");\n+  verify(\"pre-push\");\n@@ -35,6 +60,5 @@\n-  if (_current >= _limit) {\n-    grow();\n-  }\n-  *_current = o;\n-  _current++;\n-  validate(\"post-push\");\n+  assert(can_push(), \"must have room\");\n+  assert(_base[to_index(_top)] == NULL, \"expect zapped entry\");\n+  _base[to_index(_top)] = o;\n+  _top += oopSize;\n+  verify(\"post-push\");\n@@ -44,7 +68,9 @@\n-  validate(\"pre-pop\");\n-  oop* new_loc = _current - 1;\n-  assert(new_loc < _current, \"underflow, probably unbalanced push\/pop\");\n-  _current = new_loc;\n-  oop o = *_current;\n-  assert(!contains(o), \"entries must be unique\");\n-  validate(\"post-pop\");\n+  verify(\"pre-pop\");\n+  assert(to_index(_top) > 0, \"underflow, probably unbalanced push\/pop\");\n+  _top -= oopSize;\n+  oop o = _base[to_index(_top)];\n+#ifdef ASSERT\n+  _base[to_index(_top)] = NULL;\n+#endif\n+  assert(!contains(o), \"entries must be unique: \" PTR_FORMAT, p2i(o));\n+  verify(\"post-pop\");\n@@ -55,7 +81,8 @@\n-  validate(\"pre-remove\");\n-  assert(contains(o), \"entry must be present\");\n-  for (oop* loc = _base; loc < _current; loc++) {\n-    if (*loc == o) {\n-      oop* last = _current - 1;\n-      for (; loc < last; loc++) {\n-        *loc = *(loc + 1);\n+  verify(\"pre-remove\");\n+  assert(contains(o), \"entry must be present: \" PTR_FORMAT, p2i(o));\n+  int end = to_index(_top);\n+  for (int i = 0; i < end; i++) {\n+    if (_base[i] == o) {\n+      int last = end - 1;\n+      for (; i < last; i++) {\n+        _base[i] = _base[i + 1];\n@@ -63,1 +90,4 @@\n-      _current--;\n+      _top -= oopSize;\n+#ifdef ASSERT\n+      _base[to_index(_top)] = NULL;\n+#endif\n@@ -68,1 +98,1 @@\n-  validate(\"post-remove\");\n+  verify(\"post-remove\");\n@@ -72,6 +102,15 @@\n-  validate(\"pre-contains\");\n-  bool found = false;\n-  size_t i = 0;\n-  size_t found_i = 0;\n-  for (oop* loc = _current - 1; loc >= _base; loc--) {\n-    if (*loc == o) {\n+  verify(\"pre-contains\");\n+  if (!SafepointSynchronize::is_at_safepoint() && !is_owning_thread()) {\n+    \/\/ When a foreign thread inspects this thread's lock-stack, it may see\n+    \/\/ bad references here when a concurrent collector has not gotten\n+    \/\/ to processing the lock-stack, yet. Call StackWaterMark::start_processing()\n+    \/\/ to ensure that all references are valid.\n+    StackWatermark* watermark = StackWatermarkSet::get(get_thread(), StackWatermarkKind::gc);\n+    if (watermark != NULL) {\n+      watermark->start_processing();\n+    }\n+  }\n+  int end = to_index(_top);\n+  for (int i = end - 1; i >= 0; i--) {\n+    if (_base[i] == o) {\n+      verify(\"post-contains\");\n@@ -81,1 +120,1 @@\n-  validate(\"post-contains\");\n+  verify(\"post-contains\");\n@@ -86,3 +125,4 @@\n-  validate(\"pre-oops-do\");\n-  for (oop* loc = _base; loc < _current; loc++) {\n-    cl->do_oop(loc);\n+  verify(\"pre-oops-do\");\n+  int end = to_index(_top);\n+  for (int i = 0; i < end; i++) {\n+    cl->do_oop(&_base[i]);\n@@ -90,1 +130,1 @@\n-  validate(\"post-oops-do\");\n+  verify(\"post-oops-do\");\n","filename":"src\/hotspot\/share\/runtime\/lockStack.inline.hpp","additions":75,"deletions":35,"binary":false,"changes":110,"status":"modified"},{"patch":"@@ -337,1 +337,1 @@\n-  if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n+  if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n@@ -1154,1 +1154,1 @@\n-    if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n+    if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n@@ -1374,1 +1374,1 @@\n-    if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n+    if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n@@ -1423,1 +1423,1 @@\n-  assert(cur != ANONYMOUS_OWNER, \"no anon owner here\");\n+  assert(cur != anon_owner_ptr(), \"no anon owner here\");\n@@ -1427,1 +1427,1 @@\n-  if (!UseFastLocking && current->is_lock_owned((address)cur)) {\n+  if (LockingMode != LM_LIGHTWEIGHT && current->is_lock_owned((address)cur)) {\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -151,1 +151,1 @@\n-  \/\/   we achieve this by using the lowest two bits\n+  \/\/   we achieve this by using the lowest two bits.\n@@ -153,1 +153,1 @@\n-  \/\/   and small values encode much better\n+  \/\/   and small values encode much better.\n@@ -157,1 +157,7 @@\n-  #define ANONYMOUS_OWNER reinterpret_cast<void*>(1)\n+public:\n+  \/\/ NOTE: Typed as uintptr_t so that we can pick it up in SA, via vmStructs.\n+  static const uintptr_t ANONYMOUS_OWNER = 1;\n+\n+private:\n+  static void* anon_owner_ptr() { return reinterpret_cast<void*>(ANONYMOUS_OWNER); }\n+\n@@ -255,1 +261,1 @@\n-  intptr_t  is_entered(JavaThread* current) const;\n+  bool is_entered(JavaThread* current) const;\n@@ -276,1 +282,1 @@\n-    set_owner_from(NULL, ANONYMOUS_OWNER);\n+    set_owner_from(NULL, anon_owner_ptr());\n@@ -280,1 +286,1 @@\n-    return owner_raw() == ANONYMOUS_OWNER;\n+    return owner_raw() == anon_owner_ptr();\n@@ -284,1 +290,1 @@\n-    set_owner_from(ANONYMOUS_OWNER, owner);\n+    set_owner_from(anon_owner_ptr(), owner);\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.hpp","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -36,2 +36,2 @@\n-inline intptr_t ObjectMonitor::is_entered(JavaThread* current) const {\n-  if (UseFastLocking) {\n+inline bool ObjectMonitor::is_entered(JavaThread* current) const {\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -39,1 +39,1 @@\n-      return current->lock_stack().contains(object()) ? 1 : 0;\n+      return current->lock_stack().contains(object());\n@@ -41,1 +41,1 @@\n-      return current == owner_raw() ? 1 : 0;\n+      return current == owner_raw();\n@@ -46,1 +46,1 @@\n-      return 1;\n+      return true;\n@@ -49,1 +49,1 @@\n-  return 0;\n+  return false;\n","filename":"src\/hotspot\/share\/runtime\/objectMonitor.inline.hpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -279,5 +279,12 @@\n-  if ((mark.is_fast_locked() && current->lock_stack().contains(oop(obj))) ||\n-      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n-    \/\/ Degenerate notify\n-    \/\/ stack-locked by caller so by definition the implied waitset is empty.\n-    return true;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (mark.is_fast_locked() && current->lock_stack().contains(cast_to_oop(obj))) {\n+      \/\/ Degenerate notify\n+      \/\/ fast-locked by caller so by definition the implied waitset is empty.\n+      return true;\n+    }\n+  } else if (LockingMode == LM_LEGACY) {\n+    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ Degenerate notify\n+      \/\/ stack-locked by caller so by definition the implied waitset is empty.\n+      return true;\n+    }\n@@ -353,11 +360,11 @@\n-    \/\/ This Java Monitor is inflated so obj's header will never be\n-    \/\/ displaced to this thread's BasicLock. Make the displaced header\n-    \/\/ non-NULL so this BasicLock is not seen as recursive nor as\n-    \/\/ being locked. We do this unconditionally so that this thread's\n-    \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n-    \/\/ performance reasons, stack walkers generally first check for\n-    \/\/ Biased Locking in the object's header, the second check is for\n-    \/\/ stack-locking in the object's header, the third check is for\n-    \/\/ recursive stack-locking in the displaced header in the BasicLock,\n-    \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n-    if (!UseFastLocking) {\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ This Java Monitor is inflated so obj's header will never be\n+      \/\/ displaced to this thread's BasicLock. Make the displaced header\n+      \/\/ non-NULL so this BasicLock is not seen as recursive nor as\n+      \/\/ being locked. We do this unconditionally so that this thread's\n+      \/\/ BasicLock cannot be mis-interpreted by any stack walkers. For\n+      \/\/ performance reasons, stack walkers generally first check for\n+      \/\/ Biased Locking in the object's header, the second check is for\n+      \/\/ stack-locking in the object's header, the third check is for\n+      \/\/ recursive stack-locking in the displaced header in the BasicLock,\n+      \/\/ and last are the inflated Java Monitor (ObjectMonitor) checks.\n@@ -432,0 +439,8 @@\n+static bool useHeavyMonitors() {\n+#if defined(X86) || defined(AARCH64) || defined(PPC64) || defined(RISCV64)\n+  return LockingMode == LM_MONITOR;\n+#else\n+  return false;\n+#endif\n+}\n+\n@@ -443,14 +458,16 @@\n-  if (UseFastLocking) {\n-    LockStack& lock_stack = current->lock_stack();\n-\n-    markWord header = obj()->mark_acquire();\n-    while (true) {\n-      if (header.is_neutral()) {\n-        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n-        \/\/ Try to swing into 'fast-locked' state without inflating.\n-        markWord locked_header = header.set_fast_locked();\n-        markWord witness = obj()->cas_set_mark(locked_header, header);\n-        if (witness == header) {\n-          \/\/ Successfully fast-locked, push object to lock-stack and return.\n-          lock_stack.push(obj());\n-          return;\n+  if (!useHeavyMonitors()) {\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      \/\/ Fast-locking does not use the 'lock' argument.\n+      LockStack& lock_stack = current->lock_stack();\n+      if (lock_stack.can_push()) {\n+        markWord mark = obj()->mark_acquire();\n+        if (mark.is_neutral()) {\n+          assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+          \/\/ Try to swing into 'fast-locked' state.\n+          markWord locked_mark = mark.set_fast_locked();\n+          markWord old_mark = obj()->cas_set_mark(locked_mark, mark);\n+          if (old_mark == mark) {\n+            \/\/ Successfully fast-locked, push object to lock-stack and return.\n+            lock_stack.push(obj());\n+            return;\n+          }\n@@ -458,5 +475,0 @@\n-        \/\/ Otherwise retry.\n-        header = witness;\n-      } else {\n-        \/\/ Fall-through to inflate-enter.\n-        break;\n@@ -464,5 +476,5 @@\n-    }\n-  } else {\n-    if (UseBiasedLocking) {\n-      BiasedLocking::revoke(current, obj);\n-    }\n+      \/\/ All other paths fall-through to inflate-enter.\n+    } else if (LockingMode == LM_LEGACY) {\n+      if (UseBiasedLocking) {\n+        BiasedLocking::revoke(current, obj);\n+      }\n@@ -470,6 +482,14 @@\n-    markWord mark = obj->mark();\n-    if (mark.is_neutral()) {\n-      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-      \/\/ be visible <= the ST performed by the CAS.\n-      lock->set_displaced_header(mark);\n-      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+      markWord mark = obj->mark();\n+      if (mark.is_neutral()) {\n+        \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n+        \/\/ be visible <= the ST performed by the CAS.\n+        lock->set_displaced_header(mark);\n+        if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+          return;\n+        }\n+        \/\/ Fall through to inflate() ...\n+      } else if (mark.has_locker() &&\n+                 current->is_lock_owned((address) mark.locker())) {\n+        assert(lock != mark.locker(), \"must not re-lock the same lock\");\n+        assert(lock != (BasicLock*) obj->mark().value(), \"don't relock with same BasicLock\");\n+        lock->set_displaced_header(markWord::from_pointer(NULL));\n@@ -478,8 +498,0 @@\n-      \/\/ Fall through to inflate() ...\n-    } else if (mark.has_locker() &&\n-               current->is_lock_owned((address) mark.locker())) {\n-      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-      assert(lock != (BasicLock*) obj->mark().value(), \"don't relock with same BasicLock\");\n-      lock->set_displaced_header(markWord::from_pointer(NULL));\n-      return;\n-    }\n@@ -487,5 +499,6 @@\n-    \/\/ The object header will never be displaced to this lock,\n-    \/\/ so it does not matter what the value is, except that it\n-    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-    \/\/ and must not look locked either.\n-    lock->set_displaced_header(markWord::unused_mark());\n+      \/\/ The object header will never be displaced to this lock,\n+      \/\/ so it does not matter what the value is, except that it\n+      \/\/ must be non-zero to avoid looking like a re-entrant lock,\n+      \/\/ and must not look locked either.\n+      lock->set_displaced_header(markWord::unused_mark());\n+    }\n@@ -506,2 +519,4 @@\n-  markWord mark = object->mark();\n-    if (UseFastLocking) {\n+  if (!useHeavyMonitors()) {\n+    markWord mark = object->mark();\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      \/\/ Fast-locking does not use the 'lock' argument.\n@@ -509,7 +524,9 @@\n-        markWord unlocked_header = mark.set_unlocked();\n-        markWord witness = object->cas_set_mark(unlocked_header, mark);\n-        if (witness != mark) {\n-          \/\/ Another thread beat us, it can only have installed an anonymously locked monitor at this point.\n-          \/\/ Fetch that monitor, set owner correctly to this thread, and exit it (allowing waiting threads to enter).\n-          assert(witness.has_monitor(), \"must have monitor\");\n-          ObjectMonitor* monitor = witness.monitor();\n+        markWord unlocked_mark = mark.set_unlocked();\n+        markWord old_mark = object->cas_set_mark(unlocked_mark, mark);\n+        if (old_mark != mark) {\n+          \/\/ Another thread won the CAS, it must have inflated the monitor.\n+          \/\/ It can only have installed an anonymously locked monitor at this point.\n+          \/\/ Fetch that monitor, set owner correctly to this thread, and\n+          \/\/ exit it (allowing waiting threads to enter).\n+          assert(old_mark.has_monitor(), \"must have monitor\");\n+          ObjectMonitor* monitor = old_mark.monitor();\n@@ -519,0 +536,4 @@\n+        }\n+        LockStack& lock_stack = current->lock_stack();\n+        lock_stack.remove(object);\n+        return;\n@@ -520,9 +541,5 @@\n-      LockStack& lock_stack = current->lock_stack();\n-      lock_stack.remove(object);\n-      return;\n-    }\n-  } else {\n-    markWord dhw = lock->displaced_header();\n-    if (dhw.value() == 0) {\n-      \/\/ If the displaced header is NULL, then this exit matches up with\n-      \/\/ a recursive enter. No real work to do here except for diagnostics.\n+    } else if (LockingMode == LM_LEGACY) {\n+      markWord dhw = lock->displaced_header();\n+      if (dhw.value() == 0) {\n+        \/\/ If the displaced header is NULL, then this exit matches up with\n+        \/\/ a recursive enter. No real work to do here except for diagnostics.\n@@ -530,19 +547,20 @@\n-      if (mark != markWord::INFLATING()) {\n-        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-        \/\/ exiting a recursive enter of a Java Monitor that is being\n-        \/\/ inflated is safe; see the has_monitor() comment below.\n-        assert(!mark.is_neutral(), \"invariant\");\n-        assert(!mark.has_locker() ||\n-               current->is_lock_owned((address)mark.locker()), \"invariant\");\n-        if (mark.has_monitor()) {\n-          \/\/ The BasicLock's displaced_header is marked as a recursive\n-          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-          \/\/ This is a special case where the Java Monitor was inflated\n-          \/\/ after this thread entered the stack-lock recursively. When a\n-          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-          \/\/ Monitor owner's stack and update the BasicLocks because a\n-          \/\/ Java Monitor can be asynchronously inflated by a thread that\n-          \/\/ does not own the Java Monitor.\n-          ObjectMonitor* m = mark.monitor();\n-          assert(m->object()->mark() == mark, \"invariant\");\n-          assert(m->is_entered(current), \"invariant\");\n+        if (mark != markWord::INFLATING()) {\n+          \/\/ Only do diagnostics if we are not racing an inflation. Simply\n+          \/\/ exiting a recursive enter of a Java Monitor that is being\n+          \/\/ inflated is safe; see the has_monitor() comment below.\n+          assert(!mark.is_neutral(), \"invariant\");\n+          assert(!mark.has_locker() ||\n+                 current->is_lock_owned((address)mark.locker()), \"invariant\");\n+          if (mark.has_monitor()) {\n+            \/\/ The BasicLock's displaced_header is marked as a recursive\n+            \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n+            \/\/ This is a special case where the Java Monitor was inflated\n+            \/\/ after this thread entered the stack-lock recursively. When a\n+            \/\/ Java Monitor is inflated, we cannot safely walk the Java\n+            \/\/ Monitor owner's stack and update the BasicLocks because a\n+            \/\/ Java Monitor can be asynchronously inflated by a thread that\n+            \/\/ does not own the Java Monitor.\n+            ObjectMonitor* m = mark.monitor();\n+            assert(m->object()->mark() == mark, \"invariant\");\n+            assert(m->is_entered(current), \"invariant\");\n+          }\n@@ -550,1 +568,0 @@\n-      }\n@@ -552,8 +569,0 @@\n-      return;\n-    }\n-\n-    if (mark == markWord::from_pointer(lock)) {\n-      \/\/ If the object is stack-locked by the current thread, try to\n-      \/\/ swing the displaced header from the BasicLock back to the mark.\n-      assert(dhw.is_neutral(), \"invariant\");\n-      if (object->cas_set_mark(dhw, mark) == mark) {\n@@ -562,0 +571,9 @@\n+\n+      if (mark == markWord::from_pointer(lock)) {\n+        \/\/ If the object is stack-locked by the current thread, try to\n+        \/\/ swing the displaced header from the BasicLock back to the mark.\n+        assert(dhw.is_neutral(), \"invariant\");\n+        if (object->cas_set_mark(dhw, mark) == mark) {\n+          return;\n+        }\n+      }\n@@ -569,1 +587,1 @@\n-  if (UseFastLocking && monitor->is_owner_anonymous()) {\n+  if (LockingMode == LM_LIGHTWEIGHT && monitor->is_owner_anonymous()) {\n@@ -740,4 +758,10 @@\n-  if ((mark.is_fast_locked() && current->lock_stack().contains(obj())) ||\n-      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n-    \/\/ Not inflated so there can't be any waiters to notify.\n-    return;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n+  } else if (LockingMode == LM_LEGACY) {\n+    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n@@ -760,4 +784,10 @@\n-  if ((mark.is_fast_locked() && current->lock_stack().contains(obj())) ||\n-      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n-    \/\/ Not inflated so there can't be any waiters to notify.\n-    return;\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if ((mark.is_fast_locked() && current->lock_stack().contains(obj()))) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n+  } else if (LockingMode == LM_LEGACY) {\n+    if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+      \/\/ Not inflated so there can't be any waiters to notify.\n+      return;\n+    }\n@@ -789,1 +819,2 @@\n-  if (!mark.is_being_inflated() || UseFastLocking) {\n+  if (!mark.is_being_inflated() || LockingMode == LM_LIGHTWEIGHT) {\n+    \/\/ New lightweight locking does not use the markWord::INFLATING() protocol.\n@@ -904,0 +935,2 @@\n+\/\/ Can be called from non JavaThreads (e.g., VMThread) for FastHashCode\n+\/\/ calculations as part of JVM\/TI tagging.\n@@ -905,1 +938,1 @@\n-  assert(UseFastLocking, \"only call this with fast-locking enabled\");\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only call this with new lightweight locking enabled\");\n@@ -982,1 +1015,1 @@\n-    } else if (mark.is_fast_locked() && is_lock_owned(current, obj)) {\n+    } else if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked() && is_lock_owned(current, obj)) {\n@@ -989,1 +1022,1 @@\n-    } else if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+    } else if (LockingMode == LM_LEGACY && mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n@@ -1066,2 +1099,2 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n+  if (LockingMode == LM_LEGACY && mark.has_locker()) {\n+    \/\/ stack-locked case, header points into owner's stack\n@@ -1071,2 +1104,2 @@\n-  \/\/ Fast-locking case.\n-  if (mark.is_fast_locked()) {\n+  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+    \/\/ fast-locking case, see if lock is in current's lock stack\n@@ -1102,2 +1135,3 @@\n-  \/\/ Uncontended case, header points to stack\n-  if (mark.has_locker()) {\n+  if (LockingMode == LM_LEGACY && mark.has_locker()) {\n+    \/\/ stack-locked so header points into owner's stack.\n+    \/\/ owning_thread_from_monitor_owner() may also return null here:\n@@ -1107,1 +1141,3 @@\n-  if (mark.is_fast_locked()) {\n+  if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n+    \/\/ fast-locked so get owner from the object.\n+    \/\/ owning_thread_from_object() may also return null here:\n@@ -1117,0 +1153,1 @@\n+    \/\/ owning_thread_from_monitor() may also return null here:\n@@ -1120,0 +1157,5 @@\n+  \/\/ Unlocked case, header in place\n+  \/\/ Cannot have assertion since this object may have been\n+  \/\/ locked by another thread when reaching here.\n+  \/\/ assert(mark.is_neutral(), \"sanity check\");\n+\n@@ -1316,2 +1358,8 @@\n-    \/\/ *  Inflated     - just return\n-    \/\/ *  Stack-locked - coerce it to inflated\n+    \/\/ *  inflated     - Just return if using stack-locking.\n+    \/\/                   If using fast-locking and the ObjectMonitor owner\n+    \/\/                   is anonymous and the current thread owns the\n+    \/\/                   object lock, then we make the current thread the\n+    \/\/                   ObjectMonitor owner and remove the lock from the\n+    \/\/                   current thread's lock stack.\n+    \/\/ *  fast-locked  - Coerce it to inflated from fast-locked.\n+    \/\/ *  stack-locked - Coerce it to inflated from stack-locked.\n@@ -1327,1 +1375,1 @@\n-      if (UseFastLocking && inf->is_owner_anonymous() && is_lock_owned(current, object)) {\n+      if (LockingMode == LM_LIGHTWEIGHT && inf->is_owner_anonymous() && is_lock_owned(current, object)) {\n@@ -1341,6 +1389,12 @@\n-    \/\/ NOTE: We need to check UseFastLocking here, because with fast-locking, the header\n-    \/\/ may legitimately be zero: cleared lock-bits and all upper header bits zero.\n-    \/\/ With fast-locking, the INFLATING protocol is not used.\n-    if (mark == markWord::INFLATING() && !UseFastLocking) {\n-      read_stable_mark(object);\n-      continue;\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ New lightweight locking does not use INFLATING.\n+      \/\/ CASE: inflation in progress - inflating over a stack-lock.\n+      \/\/ Some other thread is converting from stack-locked to inflated.\n+      \/\/ Only that thread can complete inflation -- other threads must wait.\n+      \/\/ The INFLATING value is transient.\n+      \/\/ Currently, we spin\/yield\/park and poll the markword, waiting for inflation to finish.\n+      \/\/ We could always eliminate polling by parking the thread on some auxiliary list.\n+      if (mark == markWord::INFLATING()) {\n+        read_stable_mark(object);\n+        continue;\n+      }\n@@ -1349,2 +1403,9 @@\n-    \/\/ CASE: stack-locked\n-    \/\/ Could be stack-locked either by this thread or by some other thread.\n+    \/\/ CASE: fast-locked\n+    \/\/ Could be fast-locked either by current or by some other thread.\n+    \/\/\n+    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_\n+    \/\/ attempting to set the object's mark to the new ObjectMonitor. If\n+    \/\/ this thread owns the monitor, then we set the ObjectMonitor's\n+    \/\/ owner to this thread. Otherwise, we set the ObjectMonitor's owner\n+    \/\/ to anonymous. If we lose the race to set the object's mark to the\n+    \/\/ new ObjectMonitor, then we just delete it and loop around again.\n@@ -1352,7 +1413,0 @@\n-    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n-    \/\/ to install INFLATING into the mark word.  We originally installed INFLATING,\n-    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n-    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n-    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n-    \/\/ the odds of inflation contention.\n-\n@@ -1360,2 +1414,1 @@\n-    if (mark.is_fast_locked()) {\n-      assert(UseFastLocking, \"can only happen with fast-locking\");\n+    if (LockingMode == LM_LIGHTWEIGHT && mark.is_fast_locked()) {\n@@ -1373,2 +1426,2 @@\n-      markWord witness = object->cas_set_mark(monitor_mark, mark);\n-      if (witness == mark) {\n+      markWord old_mark = object->cas_set_mark(monitor_mark, mark);\n+      if (old_mark == mark) {\n@@ -1377,1 +1430,1 @@\n-          assert(current->is_Java_thread(), \"must be: checked in is_lock_owned()\");\n+          assert(current->is_Java_thread(), \"must be Java thread\");\n@@ -1389,1 +1442,1 @@\n-          lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n+          lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n@@ -1399,1 +1452,1 @@\n-        continue;\n+        continue;  \/\/ Interference -- just retry\n@@ -1403,2 +1456,12 @@\n-    if (mark.has_locker()) {\n-      assert(!UseFastLocking, \"can not happen with fast-locking\");\n+    \/\/ CASE: stack-locked\n+    \/\/ Could be stack-locked either by this thread or by some other thread.\n+    \/\/\n+    \/\/ Note that we allocate the ObjectMonitor speculatively, _before_ attempting\n+    \/\/ to install INFLATING into the mark word.  We originally installed INFLATING,\n+    \/\/ allocated the ObjectMonitor, and then finally STed the address of the\n+    \/\/ ObjectMonitor into the mark.  This was correct, but artificially lengthened\n+    \/\/ the interval in which INFLATING appeared in the mark, thus increasing\n+    \/\/ the odds of inflation contention.\n+\n+    if (LockingMode == LM_LEGACY && mark.has_locker()) {\n+      assert(LockingMode != LM_LIGHTWEIGHT, \"cannot happen with new lightweight locking\");\n@@ -1477,1 +1540,1 @@\n-        lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n+        lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":216,"deletions":153,"binary":false,"changes":369,"status":"modified"},{"patch":"@@ -706,1 +706,1 @@\n-  assert(!UseFastLocking, \"maybe not call that?\");\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"should not be called with new lightweight locking\");\n@@ -1097,2 +1097,2 @@\n-  _lock_stack()\n-{\n+\n+  _lock_stack(this) {\n@@ -1575,1 +1575,1 @@\n-  assert(!UseFastLocking, \"should not be called with fast-locking\");\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"should not be called with new lightweight locking\");\n@@ -2027,1 +2027,1 @@\n-  if (!UseHeavyMonitors && UseFastLocking) {\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n@@ -3720,1 +3720,1 @@\n-  assert(!UseFastLocking, \"only with stack-locking\");\n+  assert(LockingMode != LM_LIGHTWEIGHT, \"Not with new lightweight locking\");\n@@ -3751,1 +3751,1 @@\n-  assert(UseFastLocking, \"Only with fast-locking\");\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"Only with new lightweight locking\");\n@@ -3761,3 +3761,2 @@\n-  if (UseFastLocking) {\n-    void* raw_owner = monitor->owner_raw();\n-    if (raw_owner == ANONYMOUS_OWNER) {\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    if (monitor->is_owner_anonymous()) {\n@@ -3765,2 +3764,0 @@\n-    } else if (raw_owner == DEFLATER_MARKER) {\n-      return NULL;\n@@ -3768,13 +3765,1 @@\n-      Thread* owner = reinterpret_cast<Thread*>(raw_owner);\n-#ifdef ASSERT\n-      if (owner != NULL) {\n-        bool found = false;\n-        DO_JAVA_THREADS(t_list, q) {\n-          if (q == owner) {\n-            found = true;;\n-            break;\n-          }\n-        }\n-        assert(found, \"owner is not a thread: \" PTR_FORMAT, p2i(owner));\n-      }\n-#endif\n+      Thread* owner = reinterpret_cast<Thread*>(monitor->owner());\n@@ -3785,1 +3770,2 @@\n-    return owning_thread_from_monitor_owner(t_list, (address)monitor->owner());\n+    address owner = (address)monitor->owner();\n+    return owning_thread_from_monitor_owner(t_list, owner);\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":12,"deletions":26,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -1621,3 +1621,6 @@\n-  static ByteSize lock_stack_current_offset()    { return byte_offset_of(JavaThread, _lock_stack) + LockStack::current_offset(); }\n-  static ByteSize lock_stack_limit_offset()    { return byte_offset_of(JavaThread, _lock_stack) + LockStack::limit_offset(); }\n-\n+  static ByteSize lock_stack_offset()      { return byte_offset_of(JavaThread, _lock_stack); }\n+  \/\/ Those offsets are used in code generators to access the LockStack that is embedded in this\n+  \/\/ JavaThread structure. Those accesses are relative to the current thread, which\n+  \/\/ is typically in a dedicated register.\n+  static ByteSize lock_stack_top_offset()  { return lock_stack_offset() + LockStack::top_offset(); }\n+  static ByteSize lock_stack_base_offset() { return lock_stack_offset() + LockStack::base_offset(); }\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -738,2 +738,2 @@\n-  nonstatic_field(LockStack,                   _current,                                      oop*)                                  \\\n-  nonstatic_field(LockStack,                   _base,                                         oop*)                                  \\\n+  nonstatic_field(LockStack,                   _top,                                          uint32_t)                              \\\n+  nonstatic_field(LockStack,                   _base[0],                                      oop)                                   \\\n@@ -2478,0 +2478,8 @@\n+  \/**********************************************\/                        \\\n+  \/* LockingMode enum (globalDefinitions.hpp) *\/                          \\\n+  \/**********************************************\/                        \\\n+                                                                          \\\n+  declare_constant(LM_MONITOR)                                            \\\n+  declare_constant(LM_LEGACY)                                             \\\n+  declare_constant(LM_LIGHTWEIGHT)                                        \\\n+                                                                          \\\n@@ -2677,2 +2685,4 @@\n-  declare_constant(InvocationCounter::count_shift)\n-\n+  declare_constant(InvocationCounter::count_shift)                        \\\n+                                                                          \\\n+  \/* ObjectMonitor constants *\/                                           \\\n+  declare_constant(ObjectMonitor::ANONYMOUS_OWNER)                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":14,"deletions":4,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -960,0 +960,9 @@\n+enum LockingMode {\n+  \/\/ Use only heavy monitors for locking\n+  LM_MONITOR     = 0,\n+  \/\/ Legacy stack-locking, with monitors as 2nd tier\n+  LM_LEGACY      = 1,\n+  \/\/ New lightweight locking, with monitors as 2nd tier\n+  LM_LIGHTWEIGHT = 2\n+};\n+\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -47,1 +47,1 @@\n-  private static long          lockStackCurrentOffset;\n+  private static long          lockStackTopOffset;\n@@ -103,2 +103,2 @@\n-    lockStackCurrentOffset = type.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_current\").getOffset();\n-    lockStackBaseOffset = type.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_base\").getOffset();\n+    lockStackTopOffset = type.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_top\").getOffset();\n+    lockStackBaseOffset = type.getField(\"_lock_stack\").getOffset() + typeLockStack.getField(\"_base[0]\").getOffset();\n@@ -404,4 +404,8 @@\n-    Address current = addr.getAddressAt(lockStackCurrentOffset);\n-    Address base = addr.getAddressAt(lockStackBaseOffset);\n-    while (base.lessThan(current)) {\n-      Address oop = base.getAddressAt(0);\n+    long current = lockStackBaseOffset;\n+    long end = addr.getJIntAt(lockStackTopOffset);\n+    if (Assert.ASSERTS_ENABLED) {\n+      Assert.that(current <= end, \"current stack offset must be above base offset\");\n+    }\n+\n+    while (current < end) {\n+      Address oop = addr.getAddressAt(current);\n@@ -411,1 +415,1 @@\n-      base = base.addOffsetTo(oopPtrSize);\n+      current += oopPtrSize;\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaThread.java","additions":12,"deletions":8,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -80,0 +80,3 @@\n+          \/\/ Owned anonymously means that we are not the owner of\n+          \/\/ the monitor and must be waiting for the owner to\n+          \/\/ exit it.\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/JavaVFrame.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,60 @@\n+\/*\n+ * Copyright Amazon.com Inc. or its affiliates. All Rights Reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+package sun.jvm.hotspot.runtime;\n+\n+import sun.jvm.hotspot.types.TypeDataBase;\n+\n+\n+\/** Encapsulates the LockingMode enum in globalDefinitions.hpp in\n+    the VM. *\/\n+\n+public class LockingMode {\n+  private static int monitor;\n+  private static int legacy;\n+  private static int lightweight;\n+\n+  static {\n+    VM.registerVMInitializedObserver(\n+        (o, d) -> initialize(VM.getVM().getTypeDataBase()));\n+  }\n+\n+  private static synchronized void initialize(TypeDataBase db) {\n+    monitor     = db.lookupIntConstant(\"LM_MONITOR\").intValue();\n+    legacy      = db.lookupIntConstant(\"LM_LEGACY\").intValue();\n+    lightweight = db.lookupIntConstant(\"LM_LIGHTWEIGHT\").intValue();\n+  }\n+\n+  public static int getMonitor() {\n+    return monitor;\n+  }\n+\n+  public static int getLegacy() {\n+    return legacy;\n+  }\n+\n+  public static int getLightweight() {\n+    return lightweight;\n+  }\n+}\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/LockingMode.java","additions":60,"deletions":0,"binary":false,"changes":60,"status":"added"},{"patch":"@@ -58,0 +58,2 @@\n+\n+    ANONYMOUS_OWNER = db.lookupLongConstant(\"ObjectMonitor::ANONYMOUS_OWNER\").longValue();\n@@ -83,1 +85,1 @@\n-    return addr.getAddressAt(ownerFieldOffset).asLongValue() == 1;\n+    return addr.getAddressAt(ownerFieldOffset).asLongValue() == ANONYMOUS_OWNER;\n@@ -121,0 +123,2 @@\n+  private static long          ANONYMOUS_OWNER;\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/ObjectMonitor.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -211,1 +211,1 @@\n-        assert(!VM.getVM().getCommandLineBooleanFlag(\"UseFastLocking\"));\n+        assert(VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() != LockingMode.getLightweight());\n@@ -229,1 +229,1 @@\n-        if (VM.getVM().getCommandLineBooleanFlag(\"UseFastLocking\")) {\n+        if (VM.getVM().getCommandLineFlag(\"LockingMode\").getInt() == LockingMode.getLightweight()) {\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/runtime\/Threads.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-        output.shouldContain(\"inflate(locked):\");\n+        output.shouldContain(\"inflate(has_locker):\");\n","filename":"test\/hotspot\/jtreg\/runtime\/logging\/MonitorInflationTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}