{"files":[{"patch":"@@ -8717,0 +8717,1 @@\n+  match(StoreStoreFence);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -826,1 +826,0 @@\n-          __ verify_oop(to_reg->as_register(), FILE_AND_LINE);\n@@ -857,1 +856,0 @@\n-        __ verify_oop(to_reg->as_register(), FILE_AND_LINE);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2139,0 +2139,8 @@\n+void C2_MacroAssembler::movsxl(BasicType typ, Register dst) {\n+  if (typ == T_BYTE) {\n+    movsbl(dst, dst);\n+  } else if (typ == T_SHORT) {\n+    movswl(dst, dst);\n+  }\n+}\n+\n@@ -2150,4 +2158,1 @@\n-      if (typ == T_BYTE)\n-        movsbl(dst, dst);\n-      else if (typ == T_SHORT)\n-        movswl(dst, dst);\n+      movsxl(typ, dst);\n@@ -2157,0 +2162,1 @@\n+    movsxl(typ, dst);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -135,0 +135,1 @@\n+  void movsxl(BasicType typ, Register dst);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -6652,0 +6652,1 @@\n+  match(StoreStoreFence);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -6795,0 +6795,1 @@\n+  match(StoreStoreFence);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -3156,0 +3156,3 @@\n+  case vmIntrinsics::_storeStoreFence:\n+    __ membar_storestore();\n+    break;\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2298,1 +2298,1 @@\n-  G1BarrierSet::enqueue(obj);\n+  G1BarrierSet::enqueue_preloaded(obj);\n@@ -3207,0 +3207,25 @@\n+\/\/ Special closure for enqueuing discovered fields: during enqueue the card table\n+\/\/ may not be in shape to properly handle normal barrier calls (e.g. card marks\n+\/\/ in regions that failed evacuation, scribbling of various values by card table\n+\/\/ scan code). Additionally the regular barrier enqueues into the \"global\"\n+\/\/ DCQS, but during GC we need these to-be-refined entries in the GC local queue\n+\/\/ so that after clearing the card table, the redirty cards phase will properly\n+\/\/ mark all dirty cards to be picked up by refinement.\n+class G1EnqueueDiscoveredFieldClosure : public EnqueueDiscoveredFieldClosure {\n+  G1CollectedHeap* _g1h;\n+  G1ParScanThreadState* _pss;\n+\n+public:\n+  G1EnqueueDiscoveredFieldClosure(G1CollectedHeap* g1h, G1ParScanThreadState* pss) : _g1h(g1h), _pss(pss) { }\n+\n+  virtual void enqueue(HeapWord* discovered_field_addr, oop value) {\n+    assert(_g1h->is_in(discovered_field_addr), PTR_FORMAT \" is not in heap \", p2i(discovered_field_addr));\n+    \/\/ Store the value first, whatever it is.\n+    RawAccess<>::oop_store(discovered_field_addr, value);\n+    if (value == NULL) {\n+      return;\n+    }\n+    _pss->write_ref_field_post(discovered_field_addr, value);\n+  }\n+};\n+\n@@ -3251,1 +3276,2 @@\n-    _rp_task->rp_work(worker_id, &is_alive, &keep_alive, &complete_gc);\n+    G1EnqueueDiscoveredFieldClosure enqueue(&_g1h, _pss.state_for_worker(index));\n+    _rp_task->rp_work(worker_id, &is_alive, &keep_alive, &enqueue, &complete_gc);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":28,"deletions":2,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -263,0 +263,1 @@\n+    BarrierEnqueueDiscoveredFieldClosure enqueue;\n@@ -264,1 +265,1 @@\n-    _rp_task->rp_work(worker_id, &is_alive, &keep_alive, complete_gc);\n+    _rp_task->rp_work(worker_id, &is_alive, &keep_alive, &enqueue, complete_gc);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -206,8 +206,1 @@\n-  assert(obj != NULL, \"Must be\");\n-  if (HeapRegion::is_in_same_region(p, obj)) {\n-    return;\n-  }\n-  HeapRegion* from = _g1h->heap_region_containing(p);\n-  if (!from->is_young()) {\n-    enqueue_card_if_tracked(_g1h->region_attr(obj), p, obj);\n-  }\n+  write_ref_field_post(p, obj);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":1,"deletions":8,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -131,0 +131,6 @@\n+  \/\/ Apply the post barrier to the given reference field. Enqueues the card of p\n+  \/\/ if the barrier does not filter out the reference for some reason (e.g.\n+  \/\/ p and q are in the same region, p is in survivor, p is in collection set)\n+  \/\/ To be called during GC if nothing particular about p and obj are known.\n+  template <class T> void write_ref_field_post(T* p, oop obj);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1747,14 +1747,2 @@\n-  while (true) {\n-    jbyte prev = _cancelled_gc.cmpxchg(CANCELLED, CANCELLABLE);\n-    if (prev == CANCELLABLE) return true;\n-    else if (prev == CANCELLED) return false;\n-    assert(ShenandoahSuspendibleWorkers, \"should not get here when not using suspendible workers\");\n-    assert(prev == NOT_CANCELLED, \"must be NOT_CANCELLED\");\n-    Thread* thread = Thread::current();\n-    if (thread->is_Java_thread()) {\n-      \/\/ We need to provide a safepoint here, otherwise we might\n-      \/\/ spin forever if a SP is pending.\n-      ThreadBlockInVM sp(thread->as_Java_thread());\n-      SpinPause();\n-    }\n-  }\n+  jbyte prev = _cancelled_gc.cmpxchg(CANCELLED, CANCELLABLE);\n+  return prev == CANCELLABLE;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":2,"deletions":14,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -333,6 +333,1 @@\n-    CANCELLED,\n-\n-    \/\/ GC has not been cancelled and must not be cancelled. At least\n-    \/\/ one worker thread checks for pending safepoint and may suspend\n-    \/\/ if a safepoint is pending.\n-    NOT_CANCELLED\n+    CANCELLED\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -166,6 +166,1 @@\n-  if (! (sts_active && ShenandoahSuspendibleWorkers)) {\n-    return cancelled_gc();\n-  }\n-\n-  jbyte prev = _cancelled_gc.cmpxchg(NOT_CANCELLED, CANCELLABLE);\n-  if (prev == CANCELLABLE || prev == NOT_CANCELLED) {\n+  if (sts_active && ShenandoahSuspendibleWorkers && !cancelled_gc()) {\n@@ -175,9 +170,1 @@\n-\n-    \/\/ Back to CANCELLABLE. The thread that poked NOT_CANCELLED first gets\n-    \/\/ to restore to CANCELLABLE.\n-    if (prev == CANCELLABLE) {\n-      _cancelled_gc.set(CANCELLABLE);\n-    }\n-    return false;\n-  } else {\n-    return true;\n+  return cancelled_gc();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":2,"deletions":15,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1038,3 +1038,4 @@\n-  Handle cause = java_lang_Throwable::get_cause_with_stack_trace(exception, THREAD);\n-  if (HAS_PENDING_EXCEPTION || cause.is_null()) {\n-    CLEAR_PENDING_EXCEPTION;\n+  Handle init_error = java_lang_Throwable::create_initialization_error(current, exception);\n+  ResourceMark rm(THREAD);\n+  if (init_error.is_null()) {\n+    log_trace(class, init)(\"Initialization error is null for class %s\", external_name());\n@@ -1045,2 +1046,2 @@\n-  OopHandle elem = OopHandle(Universe::vm_global(), cause());\n-  bool created = false;\n+  OopHandle elem = OopHandle(Universe::vm_global(), init_error());\n+  bool created;\n@@ -1049,1 +1050,0 @@\n-  ResourceMark rm(THREAD);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1657,0 +1657,1 @@\n+  init_req( ValidLengthTest    , topnode);\n@@ -1683,48 +1684,0 @@\n-\/\/=============================================================================\n-Node* AllocateArrayNode::Ideal(PhaseGVN *phase, bool can_reshape) {\n-  if (remove_dead_region(phase, can_reshape))  return this;\n-  \/\/ Don't bother trying to transform a dead node\n-  if (in(0) && in(0)->is_top())  return NULL;\n-\n-  const Type* type = phase->type(Ideal_length());\n-  if (type->isa_int() && type->is_int()->_hi < 0) {\n-    if (can_reshape) {\n-      PhaseIterGVN *igvn = phase->is_IterGVN();\n-      \/\/ Unreachable fall through path (negative array length),\n-      \/\/ the allocation can only throw so disconnect it.\n-      Node* proj = proj_out_or_null(TypeFunc::Control);\n-      Node* catchproj = NULL;\n-      if (proj != NULL) {\n-        for (DUIterator_Fast imax, i = proj->fast_outs(imax); i < imax; i++) {\n-          Node *cn = proj->fast_out(i);\n-          if (cn->is_Catch()) {\n-            catchproj = cn->as_Multi()->proj_out_or_null(CatchProjNode::fall_through_index);\n-            break;\n-          }\n-        }\n-      }\n-      if (catchproj != NULL && catchproj->outcnt() > 0 &&\n-          (catchproj->outcnt() > 1 ||\n-           catchproj->unique_out()->Opcode() != Op_Halt)) {\n-        assert(catchproj->is_CatchProj(), \"must be a CatchProjNode\");\n-        Node* nproj = catchproj->clone();\n-        igvn->register_new_node_with_optimizer(nproj);\n-\n-        Node *frame = new ParmNode( phase->C->start(), TypeFunc::FramePtr );\n-        frame = phase->transform(frame);\n-        \/\/ Halt & Catch Fire\n-        Node* halt = new HaltNode(nproj, frame, \"unexpected negative array length\");\n-        phase->C->root()->add_req(halt);\n-        phase->transform(halt);\n-\n-        igvn->replace_node(catchproj, phase->C->top());\n-        return this;\n-      }\n-    } else {\n-      \/\/ Can't correct it during regular GVN so register for IGVN\n-      phase->C->record_for_igvn(this);\n-    }\n-  }\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":1,"deletions":48,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2023, Oracle and\/or its affiliates. All rights reserved.\n@@ -956,0 +956,6 @@\n+#ifdef ASSERT\n+  _type_verify_symmetry = true;\n+  _phase_optimize_finished = false;\n+  _exception_backedge = false;\n+#endif\n+\n@@ -1059,6 +1065,0 @@\n-\n-#ifdef ASSERT\n-  _type_verify_symmetry = true;\n-  _phase_optimize_finished = false;\n-  _exception_backedge = false;\n-#endif\n@@ -2875,1 +2875,1 @@\n-void Compile::final_graph_reshaping_impl( Node *n, Final_Reshape_Counts &frc) {\n+void Compile::final_graph_reshaping_impl(Node *n, Final_Reshape_Counts& frc, Unique_Node_List& dead_nodes) {\n@@ -2926,1 +2926,1 @@\n-  bool gc_handled = BarrierSet::barrier_set()->barrier_set_c2()->final_graph_reshaping(this, n, nop);\n+  bool gc_handled = BarrierSet::barrier_set()->barrier_set_c2()->final_graph_reshaping(this, n, nop, dead_nodes);\n@@ -2928,1 +2928,1 @@\n-    final_graph_reshaping_main_switch(n, frc, nop);\n+    final_graph_reshaping_main_switch(n, frc, nop, dead_nodes);\n@@ -2937,1 +2937,1 @@\n-void Compile::final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts& frc, uint nop) {\n+void Compile::final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts& frc, uint nop, Unique_Node_List& dead_nodes) {\n@@ -3522,3 +3522,1 @@\n-      ResourceMark rm;\n-      Unique_Node_List wq;\n-      wq.push(n->in(MemBarNode::Precedent));\n+      dead_nodes.push(n->in(MemBarNode::Precedent));\n@@ -3526,12 +3524,0 @@\n-      while (wq.size() > 0) {\n-        Node* m = wq.pop();\n-        if (m->outcnt() == 0 && m != top()) {\n-          for (uint j = 0; j < m->req(); j++) {\n-            Node* in = m->in(j);\n-            if (in != NULL) {\n-              wq.push(in);\n-            }\n-          }\n-          m->disconnect_inputs(this);\n-        }\n-      }\n@@ -3610,1 +3596,1 @@\n-void Compile::final_graph_reshaping_walk( Node_Stack &nstack, Node *root, Final_Reshape_Counts &frc ) {\n+void Compile::final_graph_reshaping_walk(Node_Stack& nstack, Node* root, Final_Reshape_Counts& frc, Unique_Node_List& dead_nodes) {\n@@ -3636,1 +3622,1 @@\n-      final_graph_reshaping_impl( n, frc );\n+      final_graph_reshaping_impl(n, frc, dead_nodes);\n@@ -3736,1 +3722,2 @@\n-  final_graph_reshaping_walk(nstack, root(), frc);\n+  Unique_Node_List dead_nodes;\n+  final_graph_reshaping_walk(nstack, root(), frc, dead_nodes);\n@@ -3749,1 +3736,1 @@\n-          CallNode *call = n->in(0)->in(0)->as_Call();\n+          CallNode* call = n->in(0)->in(0)->as_Call();\n@@ -3758,1 +3745,1 @@\n-            Node *arg0 = call->in(TypeFunc::Parms);\n+            Node* arg0 = call->in(TypeFunc::Parms);\n@@ -3763,4 +3750,3 @@\n-          } else if (call->entry_point() == OptoRuntime::new_array_Java() &&\n-                     call->req() > TypeFunc::Parms+1 &&\n-                     call->is_CallStaticJava()) {\n-            \/\/ Check for negative array length. In such case, the optimizer has\n+          } else if (call->entry_point() == OptoRuntime::new_array_Java() ||\n+                     call->entry_point() == OptoRuntime::new_array_nozero_Java()) {\n+            \/\/ Check for illegal array length. In such case, the optimizer has\n@@ -3769,3 +3755,6 @@\n-            Node *arg1 = call->in(TypeFunc::Parms+1);\n-            if (arg1->is_Type() &&\n-                arg1->as_Type()->type()->join(TypeInt::POS)->empty()) {\n+            assert(call->is_CallStaticJava(), \"static call expected\");\n+            assert(call->req() == call->jvms()->endoff() + 1, \"missing extra input\");\n+            uint valid_length_test_input = call->req() - 1;\n+            Node* valid_length_test = call->in(valid_length_test_input);\n+            call->del_req(valid_length_test_input);\n+            if (valid_length_test->find_int_con(1) == 0) {\n@@ -3774,0 +3763,3 @@\n+            dead_nodes.push(valid_length_test);\n+            assert(n->outcnt() == required_outcnt, \"malformed control flow\");\n+            continue;\n@@ -3782,0 +3774,10 @@\n+    } else if (n->is_PCTable() && n->in(0) && n->in(0)->in(0) && n->in(0)->in(0)->is_Call()) {\n+      CallNode* call = n->in(0)->in(0)->as_Call();\n+      if (call->entry_point() == OptoRuntime::new_array_Java() ||\n+          call->entry_point() == OptoRuntime::new_array_nozero_Java()) {\n+        assert(call->is_CallStaticJava(), \"static call expected\");\n+        assert(call->req() == call->jvms()->endoff() + 1, \"missing extra input\");\n+        uint valid_length_test_input = call->req() - 1;\n+        dead_nodes.push(call->in(valid_length_test_input));\n+        call->del_req(valid_length_test_input); \/\/ valid length test useless now\n+      }\n@@ -3800,0 +3802,13 @@\n+  while (dead_nodes.size() > 0) {\n+    Node* m = dead_nodes.pop();\n+    if (m->outcnt() == 0 && m != top()) {\n+      for (uint j = 0; j < m->req(); j++) {\n+        Node* in = m->in(j);\n+        if (in != NULL) {\n+          dead_nodes.push(in);\n+        }\n+      }\n+      m->disconnect_inputs(this);\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":53,"deletions":38,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -929,1 +929,2 @@\n-  inline void       record_for_igvn(Node* n);   \/\/ Body is after class Unique_Node_List.\n+  inline void       record_for_igvn(Node* n);   \/\/ Body is after class Unique_Node_List in node.hpp.\n+  inline void       remove_for_igvn(Node* n);   \/\/ Body is after class Unique_Node_List in node.hpp.\n@@ -1121,3 +1122,3 @@\n-  void final_graph_reshaping_impl( Node *n, Final_Reshape_Counts &frc);\n-  void final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts& frc, uint nop);\n-  void final_graph_reshaping_walk( Node_Stack &nstack, Node *root, Final_Reshape_Counts &frc );\n+  void final_graph_reshaping_impl(Node *n, Final_Reshape_Counts& frc, Unique_Node_List& dead_nodes);\n+  void final_graph_reshaping_main_switch(Node* n, Final_Reshape_Counts& frc, uint nop, Unique_Node_List& dead_nodes);\n+  void final_graph_reshaping_walk(Node_Stack& nstack, Node* root, Final_Reshape_Counts& frc, Unique_Node_List& dead_nodes);\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -469,0 +469,1 @@\n+  case vmIntrinsics::_storeStoreFence:\n@@ -1222,1 +1223,1 @@\n-  Node* tgt         = argument(1); \/\/ tgt is int ch\n+  Node* int_ch      = argument(1);\n@@ -1234,0 +1235,9 @@\n+\n+  \/\/ Check for int_ch >= 0\n+  Node* int_ch_cmp = _gvn.transform(new CmpINode(int_ch, intcon(0)));\n+  Node* int_ch_bol = _gvn.transform(new BoolNode(int_ch_cmp, BoolTest::ge));\n+  {\n+    BuildCutout unless(this, int_ch_bol, PROB_MAX);\n+    uncommon_trap(Deoptimization::Reason_intrinsic,\n+                  Deoptimization::Action_maybe_recompile);\n+  }\n@@ -1241,1 +1251,1 @@\n-  Node* result = new StrIndexOfCharNode(control(), memory(TypeAryPtr::BYTES), src_start, src_count, tgt, ae);\n+  Node* result = new StrIndexOfCharNode(control(), memory(TypeAryPtr::BYTES), src_start, src_count, int_ch, ae);\n@@ -1290,4 +1300,7 @@\n-  const Type* src_type = src->Value(&_gvn);\n-  const Type* dst_type = dst->Value(&_gvn);\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType dst_elem = dst_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  const TypeAryPtr* src_type = src->Value(&_gvn)->isa_aryptr();\n+  const TypeAryPtr* dst_type = dst->Value(&_gvn)->isa_aryptr();\n+  if (src_type == nullptr || dst_type == nullptr) {\n+    return false;\n+  }\n+  BasicType src_elem = src_type->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType dst_elem = dst_type->klass()->as_array_klass()->element_type()->basic_type();\n@@ -1566,1 +1579,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -2349,1 +2362,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -2600,1 +2613,1 @@\n-  old_map->destruct(&_gvn);\n+  destruct_map_clone(old_map);\n@@ -2693,0 +2706,3 @@\n+    case vmIntrinsics::_storeStoreFence:\n+      insert_mem_bar(Op_StoreStoreFence);\n+      return true;\n@@ -4398,18 +4414,1 @@\n-        JVMState* old_jvms = alloc->jvms()->clone_shallow(C);\n-        uint size = alloc->req();\n-        SafePointNode* sfpt = new SafePointNode(size, old_jvms);\n-        old_jvms->set_map(sfpt);\n-        for (uint i = 0; i < size; i++) {\n-          sfpt->init_req(i, alloc->in(i));\n-        }\n-        \/\/ re-push array length for deoptimization\n-        sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), alloc->in(AllocateNode::ALength));\n-        old_jvms->set_sp(old_jvms->sp()+1);\n-        old_jvms->set_monoff(old_jvms->monoff()+1);\n-        old_jvms->set_scloff(old_jvms->scloff()+1);\n-        old_jvms->set_endoff(old_jvms->endoff()+1);\n-        old_jvms->set_should_reexecute(true);\n-\n-        sfpt->set_i_o(map()->i_o());\n-        sfpt->set_memory(map()->memory());\n-        sfpt->set_control(map()->control());\n+        SafePointNode* sfpt = create_safepoint_with_state_before_array_allocation(alloc);\n@@ -4430,0 +4429,24 @@\n+\/\/ Clone the JVMState of the array allocation and create a new safepoint with it. Re-push the array length to the stack\n+\/\/ such that uncommon traps can be emitted to re-execute the array allocation in the interpreter.\n+SafePointNode* LibraryCallKit::create_safepoint_with_state_before_array_allocation(const AllocateArrayNode* alloc) const {\n+  JVMState* old_jvms = alloc->jvms()->clone_shallow(C);\n+  uint size = alloc->req();\n+  SafePointNode* sfpt = new SafePointNode(size, old_jvms);\n+  old_jvms->set_map(sfpt);\n+  for (uint i = 0; i < size; i++) {\n+    sfpt->init_req(i, alloc->in(i));\n+  }\n+  \/\/ re-push array length for deoptimization\n+  sfpt->ins_req(old_jvms->stkoff() + old_jvms->sp(), alloc->in(AllocateNode::ALength));\n+  old_jvms->set_sp(old_jvms->sp()+1);\n+  old_jvms->set_monoff(old_jvms->monoff()+1);\n+  old_jvms->set_scloff(old_jvms->scloff()+1);\n+  old_jvms->set_endoff(old_jvms->endoff()+1);\n+  old_jvms->set_should_reexecute(true);\n+\n+  sfpt->set_i_o(map()->i_o());\n+  sfpt->set_memory(map()->memory());\n+  sfpt->set_control(map()->control());\n+  return sfpt;\n+}\n+\n@@ -4437,1 +4460,1 @@\n-void LibraryCallKit::arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms,\n+void LibraryCallKit::arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms_before_guards,\n@@ -4439,1 +4462,3 @@\n-  if (saved_jvms != NULL && !stopped()) {\n+  if (saved_jvms_before_guards != NULL && !stopped()) {\n+    replace_unrelated_uncommon_traps_with_alloc_state(alloc, saved_jvms_before_guards);\n+\n@@ -4442,3 +4467,3 @@\n-    saved_jvms->map()->set_control(map()->control());\n-    assert(saved_jvms->map()->memory() == map()->memory(), \"memory state changed?\");\n-    assert(saved_jvms->map()->i_o() == map()->i_o(), \"IO state changed?\");\n+    saved_jvms_before_guards->map()->set_control(map()->control());\n+    assert(saved_jvms_before_guards->map()->memory() == map()->memory(), \"memory state changed?\");\n+    assert(saved_jvms_before_guards->map()->i_o() == map()->i_o(), \"IO state changed?\");\n@@ -4447,2 +4472,2 @@\n-    map()->replaced_nodes().apply(saved_jvms->map(), new_idx);\n-    set_jvms(saved_jvms);\n+    map()->replaced_nodes().apply(saved_jvms_before_guards->map(), new_idx);\n+    set_jvms(saved_jvms_before_guards);\n@@ -4524,0 +4549,52 @@\n+\/\/ Unrelated UCTs between the array allocation and the array copy, which are considered safe by tightly_coupled_allocation(),\n+\/\/ need to be replaced by an UCT with a state before the array allocation (including the array length). This is necessary\n+\/\/ because we could hit one of these UCTs (which are executed before the emitted array copy guards and the actual array\n+\/\/ allocation which is moved down in arraycopy_move_allocation_here()). When later resuming execution in the interpreter,\n+\/\/ we would have wrongly skipped the array allocation. To prevent this, we resume execution at the array allocation in\n+\/\/ the interpreter similar to what we are doing for the newly emitted guards for the array copy.\n+void LibraryCallKit::replace_unrelated_uncommon_traps_with_alloc_state(AllocateArrayNode* alloc,\n+                                                                       JVMState* saved_jvms_before_guards) {\n+  if (saved_jvms_before_guards->map()->control()->is_IfProj()) {\n+    \/\/ There is at least one unrelated uncommon trap which needs to be replaced.\n+    SafePointNode* sfpt = create_safepoint_with_state_before_array_allocation(alloc);\n+\n+    JVMState* saved_jvms = jvms();\n+    const int saved_reexecute_sp = _reexecute_sp;\n+    set_jvms(sfpt->jvms());\n+    _reexecute_sp = jvms()->sp();\n+\n+    replace_unrelated_uncommon_traps_with_alloc_state(saved_jvms_before_guards);\n+\n+    \/\/ Restore state\n+    set_jvms(saved_jvms);\n+    _reexecute_sp = saved_reexecute_sp;\n+  }\n+}\n+\n+\/\/ Replace the unrelated uncommon traps with new uncommon trap nodes by reusing the action and reason. The new uncommon\n+\/\/ traps will have the state of the array allocation. Let the old uncommon trap nodes die.\n+void LibraryCallKit::replace_unrelated_uncommon_traps_with_alloc_state(JVMState* saved_jvms_before_guards) {\n+  Node* if_proj = saved_jvms_before_guards->map()->control(); \/\/ Start the search right before the newly emitted guards\n+  while (if_proj->is_IfProj()) {\n+    CallStaticJavaNode* uncommon_trap = get_uncommon_trap_from_success_proj(if_proj);\n+    if (uncommon_trap != nullptr) {\n+      create_new_uncommon_trap(uncommon_trap);\n+    }\n+    assert(if_proj->in(0)->is_If(), \"must be If\");\n+    if_proj = if_proj->in(0)->in(0);\n+  }\n+  assert(if_proj->is_Proj() && if_proj->in(0)->is_Initialize(),\n+         \"must have reached control projection of init node\");\n+}\n+\n+void LibraryCallKit::create_new_uncommon_trap(CallStaticJavaNode* uncommon_trap_call) {\n+  const int trap_request = uncommon_trap_call->uncommon_trap_request();\n+  assert(trap_request != 0, \"no valid UCT trap request\");\n+  PreserveJVMState pjvms(this);\n+  set_control(uncommon_trap_call->in(0));\n+  uncommon_trap(Deoptimization::trap_request_reason(trap_request),\n+                Deoptimization::trap_request_action(trap_request));\n+  assert(stopped(), \"Should be stopped\");\n+  _gvn.hash_delete(uncommon_trap_call);\n+  uncommon_trap_call->set_req(0, top()); \/\/ not used anymore, kill it\n+}\n@@ -4544,1 +4621,1 @@\n-  JVMState* saved_jvms = arraycopy_restore_alloc_state(alloc, saved_reexecute_sp);\n+  JVMState* saved_jvms_before_guards = arraycopy_restore_alloc_state(alloc, saved_reexecute_sp);\n@@ -4547,3 +4624,3 @@\n-  \/\/ if saved_jvms != NULL (then alloc != NULL) then we can handle guards and a tightly coupled allocation\n-  \/\/ if saved_jvms == NULL and alloc != NULL, we can't emit any guards\n-  bool can_emit_guards = (alloc == NULL || saved_jvms != NULL);\n+  \/\/ if saved_jvms_before_guards != NULL (then alloc != NULL) then we can handle guards and a tightly coupled allocation\n+  \/\/ if saved_jvms_before_guards == NULL and alloc != NULL, we can't emit any guards\n+  bool can_emit_guards = (alloc == NULL || saved_jvms_before_guards != NULL);\n@@ -4565,1 +4642,1 @@\n-  src  = saved_jvms != NULL ? null_check_oop(src, &null_ctl, true, true) : null_check(src,  T_ARRAY);\n+  src  = saved_jvms_before_guards != NULL ? null_check_oop(src, &null_ctl, true, true) : null_check(src, T_ARRAY);\n@@ -4570,1 +4647,1 @@\n-    \/\/ if saved_jvms == NULL and alloc != NULL, we don't emit any\n+    \/\/ if saved_jvms_before_guards == NULL and alloc != NULL, we don't emit any\n@@ -4684,1 +4761,1 @@\n-  if (saved_jvms != NULL) {\n+  if (saved_jvms_before_guards != NULL) {\n@@ -4756,0 +4833,1 @@\n+    arraycopy_move_allocation_here(alloc, dest, saved_jvms_before_guards, saved_reexecute_sp, new_idx);\n@@ -4758,2 +4836,0 @@\n-  arraycopy_move_allocation_here(alloc, dest, saved_jvms, saved_reexecute_sp, new_idx);\n-\n@@ -4824,20 +4900,8 @@\n-    if ((ctl->is_IfFalse() || ctl->is_IfTrue()) && ctl->in(0)->is_If()) {\n-      IfNode* iff = ctl->in(0)->as_If();\n-      Node* not_ctl = iff->proj_out_or_null(1 - ctl->as_Proj()->_con);\n-      assert(not_ctl != NULL && not_ctl != ctl, \"found alternate\");\n-      \/\/ One more try:  Various low-level checks bottom out in\n-      \/\/ uncommon traps.  If the debug-info of the trap omits\n-      \/\/ any reference to the allocation, as we've already\n-      \/\/ observed, then there can be no objection to the trap.\n-      bool found_trap = false;\n-      for (DUIterator_Fast jmax, j = not_ctl->fast_outs(jmax); j < jmax; j++) {\n-        Node* obs = not_ctl->fast_out(j);\n-        if (obs->in(0) == not_ctl && obs->is_Call() &&\n-            (obs->as_Call()->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point())) {\n-          found_trap = true; break;\n-        }\n-      }\n-      if (found_trap) {\n-        ctl = iff->in(0);       \/\/ This test feeds a harmless uncommon trap.\n-        continue;\n-      }\n+    \/\/ Various low-level checks bottom out in uncommon traps. These\n+    \/\/ are considered safe since we've already checked above that\n+    \/\/ there is no unexpected observer of this allocation.\n+    if (get_uncommon_trap_from_success_proj(ctl) != nullptr) {\n+      assert(ctl->in(0)->is_If(), \"must be If\");\n+      ctl = ctl->in(0)->in(0);\n+    } else {\n+      return nullptr;\n@@ -4845,1 +4909,0 @@\n-    return NULL;\n@@ -4856,0 +4919,14 @@\n+CallStaticJavaNode* LibraryCallKit::get_uncommon_trap_from_success_proj(Node* node) {\n+  if (node->is_IfProj()) {\n+    Node* other_proj = node->as_IfProj()->other_if_proj();\n+    for (DUIterator_Fast jmax, j = other_proj->fast_outs(jmax); j < jmax; j++) {\n+      Node* obs = other_proj->fast_out(j);\n+      if (obs->in(0) == other_proj && obs->is_CallStaticJava() &&\n+          (obs->as_CallStaticJava()->entry_point() == SharedRuntime::uncommon_trap_blob()->entry_point())) {\n+        return obs->as_CallStaticJava();\n+      }\n+    }\n+  }\n+  return nullptr;\n+}\n+\n@@ -4881,2 +4958,2 @@\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType dst_elem = dst_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType dst_elem = top_dest->klass()->as_array_klass()->element_type()->basic_type();\n@@ -4935,2 +5012,2 @@\n-  BasicType x_elem = x_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType y_elem = y_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType x_elem = top_x->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType y_elem = top_y->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5043,2 +5120,2 @@\n-  BasicType x_elem = x_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType z_elem = z_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType x_elem = top_x->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType z_elem = top_z->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5092,2 +5169,2 @@\n-  BasicType out_elem = out_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType in_elem = in_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType out_elem = top_out->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType in_elem = top_in->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5147,4 +5224,4 @@\n-  BasicType a_elem = a_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType b_elem = b_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType n_elem = n_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType m_elem = m_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType a_elem = top_a->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType b_elem = top_b->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType n_elem = top_n->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType m_elem = top_m->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5203,3 +5280,3 @@\n-  BasicType a_elem = a_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType n_elem = n_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType m_elem = m_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType a_elem = top_a->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType n_elem = top_n->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType m_elem = top_m->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5255,2 +5332,2 @@\n-  BasicType newArr_elem = newArr_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n-  BasicType oldArr_elem = oldArr_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType newArr_elem = top_newArr->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType oldArr_elem = top_oldArr->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5469,1 +5546,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5558,1 +5635,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();\n@@ -5651,1 +5728,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();\n@@ -6488,1 +6565,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();\n@@ -6580,1 +6657,1 @@\n-  BasicType src_elem = src_type->isa_aryptr()->klass()->as_array_klass()->element_type()->basic_type();\n+  BasicType src_elem = top_src->klass()->as_array_klass()->element_type()->basic_type();\n@@ -7119,0 +7196,8 @@\n+  \/\/ Blackhole node pinches only the control, not memory. This allows\n+  \/\/ the blackhole to be pinned in the loop that computes blackholed\n+  \/\/ values, but have no other side effects, like breaking the optimizations\n+  \/\/ across the blackhole.\n+\n+  Node* bh = _gvn.transform(new BlackholeNode(control()));\n+  set_control(_gvn.transform(new ProjNode(bh, TypeFunc::Control)));\n+\n@@ -7120,1 +7205,0 @@\n-  Node* bh = insert_mem_bar(Op_Blackhole);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":171,"deletions":87,"binary":false,"changes":258,"status":"modified"},{"patch":"@@ -256,0 +256,5 @@\n+  static CallStaticJavaNode* get_uncommon_trap_from_success_proj(Node* node);\n+  SafePointNode* create_safepoint_with_state_before_array_allocation(const AllocateArrayNode* alloc) const;\n+  void replace_unrelated_uncommon_traps_with_alloc_state(AllocateArrayNode* alloc, JVMState* saved_jvms_before_guards);\n+  void replace_unrelated_uncommon_traps_with_alloc_state(JVMState* saved_jvms_before_guards);\n+  void create_new_uncommon_trap(CallStaticJavaNode* uncommon_trap_call);\n@@ -257,1 +262,1 @@\n-  void arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms, int saved_reexecute_sp,\n+  void arraycopy_move_allocation_here(AllocateArrayNode* alloc, Node* dest, JVMState* saved_jvms_before_guards, int saved_reexecute_sp,\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1208,1 +1208,2 @@\n-            address slow_call_address  \/\/ Address of slow call\n+            address slow_call_address,  \/\/ Address of slow call\n+            Node* valid_length_test \/\/ whether length is valid or not\n@@ -1394,0 +1395,6 @@\n+  \/\/ For array allocations, copy the valid length check to the call node so Compile::final_graph_reshaping() can verify\n+  \/\/ that the call has the expected number of CatchProj nodes (in case the allocation always fails and the fallthrough\n+  \/\/ path dies).\n+  if (valid_length_test != NULL) {\n+    call->add_req(valid_length_test);\n+  }\n@@ -1878,1 +1885,1 @@\n-                         OptoRuntime::new_instance_Java());\n+                         OptoRuntime::new_instance_Java(), NULL);\n@@ -1883,0 +1890,1 @@\n+  Node* valid_length_test = alloc->in(AllocateNode::ValidLengthTest);\n@@ -1897,1 +1905,1 @@\n-                         slow_call_address);\n+                         slow_call_address, valid_length_test);\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -620,2 +620,0 @@\n-  C->set_default_node_notes(caller_nn);\n-\n@@ -632,0 +630,4 @@\n+  \/\/ Only reset this now, to make sure that debug information emitted\n+  \/\/ for exiting control flow still refers to the inlined method.\n+  C->set_default_node_notes(caller_nn);\n+\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -707,0 +707,7 @@\n+  \/* notice: the max range value here is max_jint, not max_intx  *\/         \\\n+  \/* because of overflow issue                                   *\/         \\\n+  product(intx, GuaranteedAsyncDeflationInterval, 60000, DIAGNOSTIC,        \\\n+          \"Async deflate idle monitors every so many milliseconds even \"    \\\n+          \"when MonitorUsedDeflationThreshold is NOT exceeded (0 is off).\") \\\n+          range(0, max_jint)                                                \\\n+                                                                            \\\n@@ -721,2 +728,3 @@\n-          \"off). The check is performed on GuaranteedSafepointInterval \"    \\\n-          \"or AsyncDeflationInterval.\")                                     \\\n+          \"off). The check is performed on GuaranteedSafepointInterval, \"   \\\n+          \"AsyncDeflationInterval or GuaranteedAsyncDeflationInterval, \"    \\\n+          \"whichever is lower.\")                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -218,0 +218,3 @@\n+\n+  \/\/ Start the timer for deflations, so it does not trigger immediately.\n+  _last_async_deflation_time_ns = os::javaTimeNanos();\n@@ -246,0 +249,1 @@\n+static bool _no_progress_skip_increment = false;\n@@ -1171,1 +1175,8 @@\n-  return int(monitor_usage) > MonitorUsedDeflationThreshold;\n+  if (int(monitor_usage) > MonitorUsedDeflationThreshold) {\n+    log_info(monitorinflation)(\"monitors_used=\" SIZE_FORMAT \", ceiling=\" SIZE_FORMAT\n+                               \", monitor_usage=\" SIZE_FORMAT \", threshold=\" INTX_FORMAT,\n+                               monitors_used, ceiling, monitor_usage, MonitorUsedDeflationThreshold);\n+    return true;\n+  }\n+\n+  return false;\n@@ -1193,0 +1204,1 @@\n+    log_info(monitorinflation)(\"Async deflation needed: explicit request\");\n@@ -1195,0 +1207,3 @@\n+\n+  jlong time_since_last = time_since_last_async_deflation_ms();\n+\n@@ -1196,1 +1211,1 @@\n-      time_since_last_async_deflation_ms() > AsyncDeflationInterval &&\n+      time_since_last > AsyncDeflationInterval &&\n@@ -1202,0 +1217,1 @@\n+    log_info(monitorinflation)(\"Async deflation needed: monitors used are above the threshold\");\n@@ -1204,0 +1220,27 @@\n+\n+  if (GuaranteedAsyncDeflationInterval > 0 &&\n+      time_since_last > GuaranteedAsyncDeflationInterval) {\n+    \/\/ It's been longer than our specified guaranteed deflate interval.\n+    \/\/ We need to clean up the used monitors even if the threshold is\n+    \/\/ not reached, to keep the memory utilization at bay when many threads\n+    \/\/ touched many monitors.\n+    log_info(monitorinflation)(\"Async deflation needed: guaranteed interval (\" INTX_FORMAT \" ms) \"\n+                               \"is greater than time since last deflation (\" JLONG_FORMAT \" ms)\",\n+                               GuaranteedAsyncDeflationInterval, time_since_last);\n+\n+    \/\/ If this deflation has no progress, then it should not affect the no-progress\n+    \/\/ tracking, otherwise threshold heuristics would think it was triggered, experienced\n+    \/\/ no progress, and needs to backoff more aggressively. In this \"no progress\" case,\n+    \/\/ the generic code would bump the no-progress counter, and we compensate for that\n+    \/\/ by telling it to skip the update.\n+    \/\/\n+    \/\/ If this deflation has progress, then it should let non-progress tracking\n+    \/\/ know about this, otherwise the threshold heuristics would kick in, potentially\n+    \/\/ experience no-progress due to aggressive cleanup by this deflation, and think\n+    \/\/ it is still in no-progress stride. In this \"progress\" case, the generic code would\n+    \/\/ zero the counter, and we allow it to happen.\n+    _no_progress_skip_increment = true;\n+\n+    return true;\n+  }\n+\n@@ -1664,0 +1707,2 @@\n+  } else if (_no_progress_skip_increment) {\n+    _no_progress_skip_increment = false;\n@@ -1752,0 +1797,1 @@\n+  log_info(monitorinflation)(\"Starting the final audit.\");\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":48,"deletions":2,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -62,1 +62,2 @@\n-  template(G1Concurrent)                          \\\n+  template(G1PauseRemark)                         \\\n+  template(G1PauseCleanup)                        \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1605,1 +1605,1 @@\n-  declare_c2_type(BlackholeNode, MemBarNode)                              \\\n+  declare_c2_type(BlackholeNode, MultiNode)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","additions":0,"deletions":0,"binary":false,"changes":0,"previous_filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.hotspot\/src\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","status":"renamed"},{"patch":"@@ -116,1 +116,0 @@\n-serviceability\/jvmti\/CompiledMethodLoad\/Zombie.java 8245877 linux-aarch64\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}