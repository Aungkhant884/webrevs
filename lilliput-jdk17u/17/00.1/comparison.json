{"files":[{"patch":"@@ -1915,0 +1915,12 @@\n+  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n+  if (UseFastLocking && max_monitors > 0) {\n+    C2CheckLockStackStub* stub = new (C->comp_arena()) C2CheckLockStackStub();\n+    C->output()->add_stub(stub);\n+    __ ldr(r9, Address(rthread, JavaThread::lock_stack_current_offset()));\n+    __ add(r9, r9, max_monitors * oopSize);\n+    __ ldr(r10, Address(rthread, JavaThread::lock_stack_limit_offset()));\n+    __ cmp(r9, r10);\n+    __ br(Assembler::GE, stub->entry());\n+    __ bind(stub->continuation());\n+  }\n+\n@@ -1989,1 +2001,3 @@\n-      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+      C2SafepointPollStub* stub = new (C->comp_arena()) C2SafepointPollStub(__ offset());\n+      C->output()->add_stub(stub);\n+      code_stub = &stub->entry();\n@@ -3831,31 +3845,36 @@\n-    \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n-    __ orr(tmp, disp_hdr, markWord::unlocked_value);\n-\n-    \/\/ Initialize the box. (Must happen before we update the object mark!)\n-    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n-    \/\/ Compare object markWord with an unlocked value (tmp) and if\n-    \/\/ equal exchange the stack address of our box with object markWord.\n-    \/\/ On failure disp_hdr contains the possibly locked markWord.\n-    __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n-               \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n-    __ br(Assembler::EQ, cont);\n-\n-    assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n-\n-    \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-    \/\/ object, will have now locked it will continue at label cont\n-\n-    __ bind(cas_failed);\n-    \/\/ We did not see an unlocked object so try the fast recursive case.\n-\n-    \/\/ Check if the owner is self by comparing the value in the\n-    \/\/ markWord of object (disp_hdr) with the stack pointer.\n-    __ mov(rscratch1, sp);\n-    __ sub(disp_hdr, disp_hdr, rscratch1);\n-    __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-    \/\/ If condition is true we are cont and hence we can store 0 as the\n-    \/\/ displaced header in the box, which indicates that it is a recursive lock.\n-    __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n-    __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n+    if (UseFastLocking) {\n+      __ fast_lock(oop, disp_hdr, tmp, rscratch1, cont, false);\n+      \/\/ Indicate success at cont.\n+      __ cmp(oop, oop);\n+    } else {\n+      \/\/ Set tmp to be (markWord of object | UNLOCK_VALUE).\n+      __ orr(tmp, disp_hdr, markWord::unlocked_value);\n+\n+      \/\/ Initialize the box. (Must happen before we update the object mark!)\n+      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+\n+      \/\/ Compare object markWord with an unlocked value (tmp) and if\n+      \/\/ equal exchange the stack address of our box with object markWord.\n+      \/\/ On failure disp_hdr contains the possibly locked markWord.\n+      __ cmpxchg(oop, tmp, box, Assembler::xword, \/*acquire*\/ true,\n+                 \/*release*\/ true, \/*weak*\/ false, disp_hdr);\n+      __ br(Assembler::EQ, cont);\n+\n+      assert(oopDesc::mark_offset_in_bytes() == 0, \"offset of _mark is not 0\");\n+\n+      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+      \/\/ object, will have now locked it will continue at label cont\n+\n+      __ bind(cas_failed);\n+      \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+      \/\/ Check if the owner is self by comparing the value in the\n+      \/\/ markWord of object (disp_hdr) with the stack pointer.\n+      __ mov(rscratch1, sp);\n+      __ sub(disp_hdr, disp_hdr, rscratch1);\n+      __ mov(tmp, (address) (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+      \/\/ If condition is true we are cont and hence we can store 0 as the\n+      \/\/ displaced header in the box, which indicates that it is a recursive lock.\n+      __ ands(tmp\/*==0?*\/, disp_hdr, tmp);   \/\/ Sets flags for result\n+      __ str(tmp\/*==0, perhaps*\/, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    }\n@@ -3875,7 +3894,8 @@\n-    \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n-    \/\/ lock. The fast-path monitor unlock code checks for\n-    \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n-    \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n-    __ mov(tmp, (address)markWord::unused_mark().value());\n-    __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n-\n+    if (!UseFastLocking) {\n+      \/\/ Store a non-null value into the box to avoid looking like a re-entrant\n+      \/\/ lock. The fast-path monitor unlock code checks for\n+      \/\/ markWord::monitor_value so use markWord::unused_mark which has the\n+      \/\/ relevant bit set, and also matches ObjectSynchronizer::enter.\n+      __ mov(tmp, (address)markWord::unused_mark().value());\n+      __ str(tmp, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    }\n@@ -3911,2 +3931,3 @@\n-    \/\/ Find the lock address and load the displaced header from the stack.\n-    __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n+    if (!UseFastLocking) {\n+      \/\/ Find the lock address and load the displaced header from the stack.\n+      __ ldr(disp_hdr, Address(box, BasicLock::displaced_header_offset_in_bytes()));\n@@ -3914,3 +3935,4 @@\n-    \/\/ If the displaced header is 0, we have a recursive unlock.\n-    __ cmp(disp_hdr, zr);\n-    __ br(Assembler::EQ, cont);\n+      \/\/ If the displaced header is 0, we have a recursive unlock.\n+      __ cmp(disp_hdr, zr);\n+      __ br(Assembler::EQ, cont);\n+    }\n@@ -3922,6 +3944,8 @@\n-    \/\/ Check if it is still a light weight lock, this is is true if we\n-    \/\/ see the stack address of the basicLock in the markWord of the\n-    \/\/ object.\n-    __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n-               \/*release*\/ true, \/*weak*\/ false, tmp);\n-    __ b(cont);\n+    if (UseFastLocking) {\n+      __ fast_unlock(oop, tmp, box, disp_hdr, cont);\n+      \/\/ Indicate success at cont.\n+      __ cmp(oop, oop);\n+    } else {\n+      \/\/ Check if it is still a light weight lock, this is is true if we\n+      \/\/ see the stack address of the basicLock in the markWord of the\n+      \/\/ object.\n@@ -3930,0 +3954,4 @@\n+      __ cmpxchg(oop, box, disp_hdr, Assembler::xword, \/*acquire*\/ false,\n+                 \/*release*\/ true, \/*weak*\/ false, tmp);\n+    }\n+    __ b(cont);\n@@ -3936,0 +3964,14 @@\n+\n+    if (UseFastLocking) {\n+      \/\/ If the owner is anonymous, we need to fix it -- in an outline stub.\n+      Register tmp2 = disp_hdr;\n+      __ ldr(tmp2, Address(tmp, ObjectMonitor::owner_offset_in_bytes()));\n+      \/\/ We cannot use tbnz here, the target might be too far away and cannot\n+      \/\/ be encoded.\n+      __ tst(tmp2, (uint64_t)(intptr_t) ANONYMOUS_OWNER);\n+      C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmp, tmp2);\n+      Compile::current()->output()->add_stub(stub);\n+      __ br(Assembler::NE, stub->entry());\n+      __ bind(stub->continuation());\n+    }\n+\n@@ -7442,1 +7484,1 @@\n-  predicate(!needs_acquiring_load(n));\n+  predicate(!needs_acquiring_load(n) && !UseCompactObjectHeaders);\n@@ -7452,0 +7494,26 @@\n+instruct loadNKlassLilliput(iRegNNoSp dst, memory4 mem, rFlagsReg cr)\n+%{\n+  match(Set dst (LoadNKlass mem));\n+  effect(TEMP_DEF dst, KILL cr);\n+  predicate(!needs_acquiring_load(n) && UseCompactObjectHeaders);\n+\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrw  $dst, $mem\\t# compressed class ptr\" %}\n+  ins_encode %{\n+    assert($mem$$disp == oopDesc::klass_offset_in_bytes(), \"expect correct offset\");\n+    assert($mem$$index$$Register == noreg, \"expect no index\");\n+    Register dst = $dst$$Register;\n+    Register obj = $mem$$base$$Register;\n+    C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+    Compile::current()->output()->add_stub(stub);\n+    __ ldr(dst, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    \/\/ NOTE: We can't use tbnz here, because the target is sometimes too far away\n+    \/\/ and cannot be encoded.\n+    __ tst(dst, markWord::monitor_value);\n+    __ br(Assembler::NE, stub->entry());\n+    __ bind(stub->continuation());\n+    __ lsr(dst, dst, markWord::klass_shift);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":119,"deletions":51,"binary":false,"changes":170,"status":"modified"},{"patch":"@@ -815,6 +815,1 @@\n-        if (offset == oopDesc::klass_offset_in_bytes() && UseCompressedClassPointers) {\n-          __ lwz(to_reg->as_register(), offset, base);\n-          __ decode_klass_not_null(to_reg->as_register());\n-        } else {\n-          __ ld(to_reg->as_register(), offset, base);\n-        }\n+        __ ld(to_reg->as_register(), offset, base);\n@@ -2736,0 +2731,22 @@\n+void LIR_Assembler::emit_load_klass(LIR_OpLoadKlass* op) {\n+  Register obj = op->obj()->as_pointer_register();\n+  Register result = op->result_opr()->as_pointer_register();\n+\n+  CodeEmitInfo* info = op->info();\n+  if (info != NULL) {\n+    if (info != NULL) {\n+      if (!os::zero_page_read_protected() || !ImplicitNullChecks) {\n+        explicit_null_check(obj, info);\n+      } else {\n+        add_debug_info_for_null_check_here(info);\n+      }\n+    }\n+  }\n+\n+  if (UseCompressedClassPointers) {\n+    __ lwz(result, oopDesc::klass_offset_in_bytes(), obj);\n+    __ decode_klass_not_null(result);\n+  } else {\n+    __ ld(result, oopDesc::klass_offset_in_bytes(), obj);\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":23,"deletions":6,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"opto\/c2_CodeStubs.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"opto\/output.hpp\"\n@@ -449,1 +451,1 @@\n-                                 Register scrReg, Register cx1Reg, Register cx2Reg,\n+                                 Register scrReg, Register cx1Reg, Register cx2Reg, Register thread,\n@@ -518,21 +520,39 @@\n-  \/\/ Attempt stack-locking ...\n-  orptr (tmpReg, markWord::unlocked_value);\n-  movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n-  lock();\n-  cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n-  if (counters != NULL) {\n-    cond_inc32(Assembler::equal,\n-               ExternalAddress((address)counters->fast_path_entry_count_addr()));\n-  }\n-  jcc(Assembler::equal, DONE_LABEL);           \/\/ Success\n-\n-  \/\/ Recursive locking.\n-  \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n-  \/\/ Locked by current thread if difference with current SP is less than one page.\n-  subptr(tmpReg, rsp);\n-  \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n-  andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n-  movptr(Address(boxReg, 0), tmpReg);\n-  if (counters != NULL) {\n-    cond_inc32(Assembler::equal,\n-               ExternalAddress((address)counters->fast_path_entry_count_addr()));\n+  if (UseFastLocking) {\n+#ifdef _LP64\n+    fast_lock_impl(objReg, tmpReg, thread, scrReg, DONE_LABEL, false);\n+    xorl(tmpReg, tmpReg); \/\/ Set ZF=1 to indicate success\n+#else\n+    \/\/ We can not emit the lock-stack-check in verified_entry() because we don't have enough\n+    \/\/ registers (for thread ptr). Therefor we have to emit the lock-stack-check in\n+    \/\/ fast_lock_impl(). However, that check can take a slow-path with ZF=1, therefore\n+    \/\/ we need to handle it specially and force ZF=0 before taking the actual slow-path.\n+    Label slow;\n+    fast_lock_impl(objReg, tmpReg, thread, scrReg, slow);\n+    xorl(tmpReg, tmpReg);\n+    jmp(DONE_LABEL);\n+    bind(slow);\n+    testptr(objReg, objReg); \/\/ ZF=0 to indicate failure\n+#endif\n+  } else {\n+    \/\/ Attempt stack-locking ...\n+    orptr (tmpReg, markWord::unlocked_value);\n+    movptr(Address(boxReg, 0), tmpReg);          \/\/ Anticipate successful CAS\n+    lock();\n+    cmpxchgptr(boxReg, Address(objReg, oopDesc::mark_offset_in_bytes()));      \/\/ Updates tmpReg\n+    if (counters != NULL) {\n+      cond_inc32(Assembler::equal,\n+                 ExternalAddress((address)counters->fast_path_entry_count_addr()));\n+    }\n+    jcc(Assembler::equal, DONE_LABEL);           \/\/ Success\n+\n+    \/\/ Recursive locking.\n+    \/\/ The object is stack-locked: markword contains stack pointer to BasicLock.\n+    \/\/ Locked by current thread if difference with current SP is less than one page.\n+    subptr(tmpReg, rsp);\n+    \/\/ Next instruction set ZFlag == 1 (Success) if difference is less then one page.\n+    andptr(tmpReg, (int32_t) (NOT_LP64(0xFFFFF003) LP64_ONLY(7 - os::vm_page_size())) );\n+    movptr(Address(boxReg, 0), tmpReg);\n+    if (counters != NULL) {\n+      cond_inc32(Assembler::equal,\n+                 ExternalAddress((address)counters->fast_path_entry_count_addr()));\n+    }\n@@ -579,1 +599,1 @@\n-  cmpxchgptr(scrReg, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n+  cmpxchgptr(thread, Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)));\n@@ -581,8 +601,0 @@\n-  \/\/ If we weren't able to swing _owner from NULL to the BasicLock\n-  \/\/ then take the slow path.\n-  jccb  (Assembler::notZero, DONE_LABEL);\n-  \/\/ update _owner from BasicLock to thread\n-  get_thread (scrReg);                    \/\/ beware: clobbers ICCs\n-  movptr(Address(boxReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), scrReg);\n-  xorptr(boxReg, boxReg);                 \/\/ set icc.ZFlag = 1 to indicate success\n-\n@@ -687,2 +699,4 @@\n-  cmpptr(Address(boxReg, 0), (int32_t)NULL_WORD);                   \/\/ Examine the displaced header\n-  jcc   (Assembler::zero, DONE_LABEL);                              \/\/ 0 indicates recursive stack-lock\n+  if (!UseFastLocking) {\n+    cmpptr(Address(boxReg, 0), (int32_t)NULL_WORD);                   \/\/ Examine the displaced header\n+    jcc   (Assembler::zero, DONE_LABEL);                              \/\/ 0 indicates recursive stack-lock\n+  }\n@@ -691,1 +705,16 @@\n-  jccb  (Assembler::zero, Stacked);\n+  jcc(Assembler::zero, Stacked);\n+\n+  if (UseFastLocking) {\n+    \/\/ If the owner is ANONYMOUS, we need to fix it.\n+    testb(Address(tmpReg, OM_OFFSET_NO_MONITOR_VALUE_TAG(owner)), (int) (intptr_t) ANONYMOUS_OWNER);\n+#ifdef _LP64\n+    C2HandleAnonOMOwnerStub* stub = new (Compile::current()->comp_arena()) C2HandleAnonOMOwnerStub(tmpReg);\n+    Compile::current()->output()->add_stub(stub);\n+    jcc(Assembler::notEqual, stub->entry());\n+    bind(stub->continuation());\n+#else\n+    \/\/ We can't easily implement this optimization on 32 bit because we don't have a thread register.\n+    \/\/ Call the slow-path instead.\n+    jcc(Assembler::notEqual, DONE_LABEL);\n+#endif\n+  }\n@@ -702,1 +731,1 @@\n-    jmpb(DONE_LABEL);\n+    jmp(DONE_LABEL);\n@@ -742,8 +771,14 @@\n-  \/\/ It's not inflated and it's not recursively stack-locked and it's not biased.\n-  \/\/ It must be stack-locked.\n-  \/\/ Try to reset the header to displaced header.\n-  \/\/ The \"box\" value on the stack is stable, so we can reload\n-  \/\/ and be assured we observe the same value as above.\n-  movptr(tmpReg, Address(boxReg, 0));\n-  lock();\n-  cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+  if (UseFastLocking) {\n+    mov(boxReg, tmpReg);\n+    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n+    xorl(tmpReg, tmpReg);\n+  } else {\n+    \/\/ It's not inflated and it's not recursively stack-locked and it's not biased.\n+    \/\/ It must be stack-locked.\n+    \/\/ Try to reset the header to displaced header.\n+    \/\/ The \"box\" value on the stack is stable, so we can reload\n+    \/\/ and be assured we observe the same value as above.\n+    movptr(tmpReg, Address(boxReg, 0));\n+    lock();\n+    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+  }\n@@ -834,3 +869,10 @@\n-  movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n-  lock();\n-  cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+\n+  if (UseFastLocking) {\n+    mov(boxReg, tmpReg);\n+    fast_unlock_impl(objReg, boxReg, tmpReg, DONE_LABEL);\n+    xorl(tmpReg, tmpReg);\n+  } else {\n+    movptr(tmpReg, Address (boxReg, 0));      \/\/ re-fetch\n+    lock();\n+    cmpxchgptr(tmpReg, Address(objReg, oopDesc::mark_offset_in_bytes())); \/\/ Uses RAX which is box\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":88,"deletions":46,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-                 Register scr, Register cx1, Register cx2,\n+                 Register scr, Register cx1, Register cx2, Register thread,\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -630,1 +630,2 @@\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL);\n+  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n+  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, C->in_24_bit_fp_mode(), C->stub_function() != NULL, max_monitors);\n@@ -724,1 +725,3 @@\n-      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+      C2SafepointPollStub* stub = new (C->comp_arena()) C2SafepointPollStub(__ offset());\n+      C->output()->add_stub(stub);\n+      code_stub = &stub->entry();\n@@ -13698,1 +13701,1 @@\n-instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2) %{\n+instruct cmpFastLockRTM(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eDXRegI scr, rRegI cx1, rRegI cx2, eRegP thread) %{\n@@ -13701,1 +13704,1 @@\n-  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box);\n+  effect(TEMP tmp, TEMP scr, TEMP cx1, TEMP cx2, USE_KILL box, TEMP thread);\n@@ -13705,0 +13708,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13706,1 +13710,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, $thread$$Register,\n@@ -13714,1 +13718,1 @@\n-instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr) %{\n+instruct cmpFastLock(eFlagsReg cr, eRegP object, eBXRegP box, eAXRegI tmp, eRegP scr, eRegP thread) %{\n@@ -13717,1 +13721,1 @@\n-  effect(TEMP tmp, TEMP scr, USE_KILL box);\n+  effect(TEMP tmp, TEMP scr, USE_KILL box, TEMP thread);\n@@ -13721,0 +13725,1 @@\n+    __ get_thread($thread$$Register);\n@@ -13722,1 +13727,1 @@\n-                 $scr$$Register, noreg, noreg, _counters, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, noreg, noreg, $thread$$Register, NULL, NULL, NULL, NULL, false, false);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":13,"deletions":8,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -903,1 +903,2 @@\n-  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL);\n+  int max_monitors = C->method() != NULL ? C->max_monitors() : 0;\n+  __ verified_entry(framesize, C->output()->need_stack_bang(bangsize)?bangsize:0, false, C->stub_function() != NULL, max_monitors);\n@@ -1001,1 +1002,3 @@\n-      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+      C2SafepointPollStub* stub = new (C->comp_arena()) C2SafepointPollStub(__ offset());\n+      C->output()->add_stub(stub);\n+      code_stub = &stub->entry();\n@@ -5193,0 +5196,1 @@\n+  predicate(!UseCompactObjectHeaders);\n@@ -5203,0 +5207,23 @@\n+instruct loadNKlassLilliput(rRegN dst, indOffset8 mem, rFlagsReg cr)\n+%{\n+  predicate(UseCompactObjectHeaders);\n+  match(Set dst (LoadNKlass mem));\n+  effect(TEMP_DEF dst, KILL cr);\n+  ins_cost(125); \/\/ XXX\n+  format %{ \"movl    $dst, $mem\\t# compressed klass ptr\" %}\n+  ins_encode %{\n+    assert($mem$$disp == oopDesc::klass_offset_in_bytes(), \"expect correct offset 4, but got: %d\", $mem$$disp);\n+    assert($mem$$index == 4, \"expect no index register: %d\", $mem$$index);\n+    Register dst = $dst$$Register;\n+    Register obj = $mem$$base$$Register;\n+    C2LoadNKlassStub* stub = new (Compile::current()->comp_arena()) C2LoadNKlassStub(dst);\n+    Compile::current()->output()->add_stub(stub);\n+    __ movq(dst, Address(obj, oopDesc::mark_offset_in_bytes()));\n+    __ testb(dst, markWord::monitor_value);\n+    __ jcc(Assembler::notZero, stub->entry());\n+    __ bind(stub->continuation());\n+    __ shrq(dst, markWord::klass_shift);\n+  %}\n+  ins_pipe(pipe_slow); \/\/ XXX\n+%}\n+\n@@ -12228,0 +12255,1 @@\n+  predicate(!UseCompactObjectHeaders);\n@@ -12926,1 +12954,1 @@\n-                 $scr$$Register, $cx1$$Register, $cx2$$Register,\n+                 $scr$$Register, $cx1$$Register, $cx2$$Register, r15_thread,\n@@ -12942,1 +12970,1 @@\n-                 $scr$$Register, $cx1$$Register, noreg, _counters, NULL, NULL, NULL, false, false);\n+                 $scr$$Register, $cx1$$Register, noreg, r15_thread, NULL, NULL, NULL, NULL, false, false);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -639,1 +639,1 @@\n-  CodeStub* slow_path = new MonitorExitStub(lock, UseFastLocking, monitor_no);\n+  CodeStub* slow_path = new MonitorExitStub(lock, !UseHeavyMonitors, monitor_no);\n@@ -1258,0 +1258,5 @@\n+void LIRGenerator::load_klass(LIR_Opr obj, LIR_Opr klass, CodeEmitInfo* null_check_info) {\n+  CodeStub* slow_path = UseCompactObjectHeaders ? new LoadKlassStub(klass) : NULL;\n+  __ load_klass(obj, klass, null_check_info, slow_path);\n+}\n+\n@@ -1264,1 +1269,1 @@\n-  LIR_Opr temp = new_register(T_METADATA);\n+  LIR_Opr temp = new_register(T_ADDRESS);\n@@ -1273,4 +1278,3 @@\n-  \/\/ FIXME T_ADDRESS should actually be T_METADATA but it can't because the\n-  \/\/ meaning of these two is mixed up (see JDK-8026837).\n-  __ move(new LIR_Address(rcvr.result(), oopDesc::klass_offset_in_bytes(), T_ADDRESS), temp, info);\n-  __ move_wide(new LIR_Address(temp, in_bytes(Klass::java_mirror_offset()), T_ADDRESS), temp);\n+  LIR_Opr klass = new_register(T_METADATA);\n+  load_klass(rcvr.result(), klass, info);\n+  __ move_wide(new LIR_Address(klass, in_bytes(Klass::java_mirror_offset()), T_ADDRESS), temp);\n@@ -1356,1 +1360,1 @@\n-  __ move(new LIR_Address(value.result(), oopDesc::klass_offset_in_bytes(), T_ADDRESS), klass, NULL);\n+  load_klass(value.result(), klass, NULL);\n@@ -3747,1 +3751,1 @@\n-  __ move(new LIR_Address(array, oopDesc::klass_offset_in_bytes(), T_ADDRESS), klass, null_check_info);\n+  load_klass(array, klass, null_check_info);\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":12,"deletions":8,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+#include \"gc\/shared\/slidingForwarding.inline.hpp\"\n@@ -1606,0 +1607,2 @@\n+  _forwarding = new SlidingForwarding(heap_rs.region(), HeapRegion::LogOfHRGrainBytes - LogHeapWordSize);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -312,0 +313,3 @@\n+\n+  _heap->forwarding()->clear();\n+\n@@ -315,0 +319,1 @@\n+  \/\/ TODO: Disabled for now because it violates sliding-forwarding assumption.\n@@ -316,3 +321,3 @@\n-  if (!task.has_freed_regions()) {\n-    task.prepare_serial_compaction();\n-  }\n+  \/\/ if (!task.has_freed_regions()) {\n+  \/\/   task.prepare_serial_compaction();\n+  \/\/ }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -200,1 +200,1 @@\n-    obj = cast_to_oop(m.decode_pointer());\n+    obj = obj->forwardee(m);\n@@ -214,1 +214,0 @@\n-  assert(from_obj->is_objArray(), \"must be obj array\");\n@@ -244,1 +243,0 @@\n-  assert(from_obj->is_objArray(), \"precondition\");\n@@ -363,1 +361,1 @@\n-                                                  oop const old, size_t word_sz, uint age,\n+                                                  oop const old, Klass* klass, size_t word_sz, uint age,\n@@ -367,1 +365,1 @@\n-    _g1h->_gc_tracer_stw->report_promotion_in_new_plab_event(old->klass(), word_sz * HeapWordSize, age,\n+    _g1h->_gc_tracer_stw->report_promotion_in_new_plab_event(klass, word_sz * HeapWordSize, age,\n@@ -371,1 +369,1 @@\n-    _g1h->_gc_tracer_stw->report_promotion_outside_plab_event(old->klass(), word_sz * HeapWordSize, age,\n+    _g1h->_gc_tracer_stw->report_promotion_outside_plab_event(klass, word_sz * HeapWordSize, age,\n@@ -379,0 +377,1 @@\n+                                                   Klass* klass,\n@@ -401,1 +400,1 @@\n-      report_promotion_event(*dest_attr, old, word_sz, age, obj_ptr, node_index);\n+      report_promotion_event(*dest_attr, old, klass, word_sz, age, obj_ptr, node_index);\n@@ -424,0 +423,4 @@\n+  if (old_mark.is_marked()) {\n+    \/\/ Already forwarded by somebody else, return forwardee.\n+    return old->forwardee(old_mark);\n+  }\n@@ -426,1 +429,9 @@\n-  Klass* klass = old->klass();\n+  Klass* klass;\n+#ifdef _LP64\n+  if (UseCompactObjectHeaders) {\n+    klass = old_mark.safe_klass();\n+  } else\n+#endif\n+  {\n+    klass = old->klass();\n+  }\n@@ -439,1 +450,1 @@\n-    obj_ptr = allocate_copy_slow(&dest_attr, old, word_sz, age, node_index);\n+    obj_ptr = allocate_copy_slow(&dest_attr, old, klass, word_sz, age, node_index);\n@@ -596,1 +607,1 @@\n-  oop forward_ptr = old->forward_to_atomic(old, m, memory_order_relaxed);\n+  oop forward_ptr = old->forward_to_self_atomic(m, memory_order_relaxed);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":21,"deletions":10,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -176,0 +176,1 @@\n+                               Klass* klass,\n@@ -208,1 +209,1 @@\n-                              oop const old, size_t word_sz, uint age,\n+                              oop const old, Klass* klass, size_t word_sz, uint age,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/slidingForwarding.hpp\"\n@@ -194,0 +195,2 @@\n+  _forwarding = new SlidingForwarding(_heap_region, ShenandoahHeapRegion::region_size_words_shift());\n+\n@@ -954,1 +957,1 @@\n-    if (!p->is_forwarded()) {\n+    if (!ShenandoahForwarding::is_forwarded(p)) {\n@@ -1242,1 +1245,1 @@\n-      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n+      obj = ShenandoahBarrierSet::barrier_set()->load_reference_barrier(obj);\n@@ -1298,0 +1301,1 @@\n+    shenandoah_assert_not_in_cset_except(NULL, obj, cancelled_gc());\n@@ -1351,1 +1355,1 @@\n-      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n+      obj = ShenandoahBarrierSet::barrier_set()->load_reference_barrier(obj);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -65,0 +65,1 @@\n+class SlidingForwarding;\n@@ -230,0 +231,1 @@\n+  SlidingForwarding* _forwarding;\n@@ -246,0 +248,2 @@\n+  SlidingForwarding* forwarding() const { return _forwarding; }\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"gc\/shenandoah\/shenandoahObjectUtils.inline.hpp\"\n@@ -205,1 +206,1 @@\n-  size_t size = p->size();\n+  size_t size = ShenandoahObjectUtils::size(p);\n@@ -422,1 +423,1 @@\n-    int size = obj->size();\n+    size_t size = ShenandoahObjectUtils::size(obj);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.inline.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2591,1 +2591,7 @@\n-    set_prototype_header(markWord::prototype());\n+    markWord prototype = markWord::prototype();\n+#ifdef _LP64\n+    if (UseCompactObjectHeaders) {\n+      prototype = prototype.set_klass(this);\n+    }\n+#endif\n+    set_prototype_header(prototype);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1678,9 +1678,3 @@\n-  Node* mark_node = NULL;\n-  \/\/ For now only enable fast locking for non-array types\n-  if (UseBiasedLocking && Opcode() == Op_Allocate) {\n-    Node* klass_node = in(AllocateNode::KlassNode);\n-    Node* proto_adr = phase->transform(new AddPNode(klass_node, klass_node, phase->MakeConX(in_bytes(Klass::prototype_header_offset()))));\n-    mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n-  } else {\n-    mark_node = phase->MakeConX(markWord::prototype().value());\n-  }\n+  Node* klass_node = in(AllocateNode::KlassNode);\n+  Node* proto_adr = phase->transform(new AddPNode(klass_node, klass_node, phase->MakeConX(in_bytes(Klass::prototype_header_offset()))));\n+  Node* mark_node = LoadNode::make(*phase, control, mem, proto_adr, TypeRawPtr::BOTTOM, TypeX_X, TypeX_X->basic_type(), MemNode::unordered);\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":3,"deletions":9,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -996,0 +996,1 @@\n+  reset_max_monitors();\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -305,0 +305,1 @@\n+  uint                  _max_monitors;          \/\/ Keep track of maximum number of active monitors in this compilation\n@@ -599,0 +600,4 @@\n+  void          push_monitor() { _max_monitors++; }\n+  void          reset_max_monitors() { _max_monitors = 0; }\n+  uint          max_monitors() { return _max_monitors; }\n+\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -6580,1 +6580,1 @@\n-    state = get_state_from_digest_object(digestBase_obj, \"[I\");\n+    state = get_state_from_digest_object(digestBase_obj, T_INT);\n@@ -6586,1 +6586,1 @@\n-    state = get_state_from_digest_object(digestBase_obj, \"[I\");\n+    state = get_state_from_digest_object(digestBase_obj, T_INT);\n@@ -6592,1 +6592,1 @@\n-    state = get_state_from_digest_object(digestBase_obj, \"[I\");\n+    state = get_state_from_digest_object(digestBase_obj, T_INT);\n@@ -6598,1 +6598,1 @@\n-    state = get_state_from_digest_object(digestBase_obj, \"[J\");\n+    state = get_state_from_digest_object(digestBase_obj, T_LONG);\n@@ -6604,1 +6604,1 @@\n-    state = get_state_from_digest_object(digestBase_obj, \"[B\");\n+    state = get_state_from_digest_object(digestBase_obj, T_BYTE);\n@@ -6668,1 +6668,1 @@\n-  const char* state_type = \"[I\";\n+  BasicType elem_type = T_INT;\n@@ -6697,1 +6697,1 @@\n-      state_type = \"[J\";\n+      elem_type = T_LONG;\n@@ -6705,1 +6705,1 @@\n-      state_type = \"[B\";\n+      elem_type = T_BYTE;\n@@ -6723,1 +6723,1 @@\n-    return inline_digestBase_implCompressMB(digestBase_obj, instklass_digestBase, state_type, stub_addr, stub_name, src_start, ofs, limit);\n+    return inline_digestBase_implCompressMB(digestBase_obj, instklass_digestBase, elem_type, stub_addr, stub_name, src_start, ofs, limit);\n@@ -6730,1 +6730,1 @@\n-                                                      const char* state_type, address stubAddr, const char *stubName,\n+                                                      BasicType elem_type, address stubAddr, const char *stubName,\n@@ -6737,1 +6737,1 @@\n-  Node* state = get_state_from_digest_object(digest_obj, state_type);\n+  Node* state = get_state_from_digest_object(digest_obj, elem_type);\n@@ -6768,1 +6768,8 @@\n-Node * LibraryCallKit::get_state_from_digest_object(Node *digest_object, const char *state_type) {\n+Node * LibraryCallKit::get_state_from_digest_object(Node *digest_object, BasicType elem_type) {\n+  const char* state_type;\n+  switch (elem_type) {\n+    case T_BYTE: state_type = \"[B\"; break;\n+    case T_INT:  state_type = \"[I\"; break;\n+    case T_LONG: state_type = \"[J\"; break;\n+    default: ShouldNotReachHere();\n+  }\n@@ -6774,1 +6781,1 @@\n-  Node* state = array_element_address(digest_state, intcon(0), T_INT);\n+  Node* state = array_element_address(digest_state, intcon(0), elem_type);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":20,"deletions":13,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -288,1 +288,1 @@\n-                                        const char* state_type, address stubAddr, const char *stubName,\n+                                        BasicType elem_type, address stubAddr, const char *stubName,\n@@ -290,1 +290,1 @@\n-  Node* get_state_from_digest_object(Node *digestBase_object, const char* state_type);\n+  Node* get_state_from_digest_object(Node *digestBase_object, BasicType elem_type);\n@@ -347,1 +347,1 @@\n-    if (UseAVX >= 2) {\n+    if (false && UseAVX >= 2) {\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1680,1 +1680,4 @@\n-  rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+  if (!UseCompactObjectHeaders) {\n+    rawmem = make_store(control, rawmem, object, oopDesc::klass_offset_in_bytes(), klass_node, T_METADATA);\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -426,1 +426,5 @@\n-  _tf = TypeFunc::make(method());\n+  if (parse_method->is_synchronized()) {\n+    C->push_monitor();\n+  }\n+\n+   _tf = TypeFunc::make(method());\n","filename":"src\/hotspot\/share\/opto\/parse1.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -128,1 +128,1 @@\n-  product(bool, UseCompressedClassPointers, false,                          \\\n+  product(bool, UseCompressedClassPointers, true,                           \\\n@@ -132,0 +132,3 @@\n+  product(bool, UseCompactObjectHeaders, true, EXPERIMENTAL,                \\\n+                \"Use 64-bit object headers instead of 96-bit headers\")      \\\n+                                                                            \\\n@@ -149,0 +152,1 @@\n+const bool UseCompactObjectHeaders = false;\n@@ -2096,0 +2100,9 @@\n+  product(bool, HeapObjectStats, false, DIAGNOSTIC,                         \\\n+             \"Enable gathering of heap object statistics\")                  \\\n+                                                                            \\\n+  product(size_t, HeapObjectStatsSamplingInterval, 500, DIAGNOSTIC,         \\\n+             \"Heap object statistics sampling interval (ms)\")               \\\n+                                                                            \\\n+  product(bool, UseFastLocking, false, EXPERIMENTAL,                        \\\n+                \"Use fast-locking instead of stack-locking\")                \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":14,"deletions":1,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n@@ -41,0 +42,1 @@\n+#include \"runtime\/lockStack.inline.hpp\"\n@@ -277,1 +279,2 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(oop(obj))) ||\n+      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n@@ -360,1 +363,3 @@\n-    lock->set_displaced_header(markWord::unused_mark());\n+    if (!UseFastLocking) {\n+      lock->set_displaced_header(markWord::unused_mark());\n+    }\n@@ -438,6 +443,26 @@\n-  if (UseBiasedLocking) {\n-    BiasedLocking::revoke(current, obj);\n-  }\n-\n-  markWord mark = obj->mark();\n-  assert(!mark.has_bias_pattern(), \"should not see bias pattern here\");\n+  if (UseFastLocking) {\n+    LockStack& lock_stack = current->lock_stack();\n+\n+    markWord header = obj()->mark_acquire();\n+    while (true) {\n+      if (header.is_neutral()) {\n+        assert(!lock_stack.contains(obj()), \"thread must not already hold the lock\");\n+        \/\/ Try to swing into 'fast-locked' state without inflating.\n+        markWord locked_header = header.set_fast_locked();\n+        markWord witness = obj()->cas_set_mark(locked_header, header);\n+        if (witness == header) {\n+          \/\/ Successfully fast-locked, push object to lock-stack and return.\n+          lock_stack.push(obj());\n+          return;\n+        }\n+        \/\/ Otherwise retry.\n+        header = witness;\n+      } else {\n+        \/\/ Fall-through to inflate-enter.\n+        break;\n+      }\n+    }\n+  } else {\n+    if (UseBiasedLocking) {\n+      BiasedLocking::revoke(current, obj);\n+    }\n@@ -445,5 +470,14 @@\n-  if (mark.is_neutral()) {\n-    \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n-    \/\/ be visible <= the ST performed by the CAS.\n-    lock->set_displaced_header(mark);\n-    if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+    markWord mark = obj->mark();\n+    if (mark.is_neutral()) {\n+      \/\/ Anticipate successful CAS -- the ST of the displaced mark must\n+      \/\/ be visible <= the ST performed by the CAS.\n+      lock->set_displaced_header(mark);\n+      if (mark == obj()->cas_set_mark(markWord::from_pointer(lock), mark)) {\n+        return;\n+      }\n+      \/\/ Fall through to inflate() ...\n+    } else if (mark.has_locker() &&\n+               current->is_lock_owned((address) mark.locker())) {\n+      assert(lock != mark.locker(), \"must not re-lock the same lock\");\n+      assert(lock != (BasicLock*) obj->mark().value(), \"don't relock with same BasicLock\");\n+      lock->set_displaced_header(markWord::from_pointer(NULL));\n@@ -452,7 +486,6 @@\n-    \/\/ Fall through to inflate() ...\n-  } else if (mark.has_locker() &&\n-             current->is_lock_owned((address)mark.locker())) {\n-    assert(lock != mark.locker(), \"must not re-lock the same lock\");\n-    assert(lock != (BasicLock*)obj->mark().value(), \"don't relock with same BasicLock\");\n-    lock->set_displaced_header(markWord::from_pointer(NULL));\n-    return;\n+\n+    \/\/ The object header will never be displaced to this lock,\n+    \/\/ so it does not matter what the value is, except that it\n+    \/\/ must be non-zero to avoid looking like a re-entrant lock,\n+    \/\/ and must not look locked either.\n+    lock->set_displaced_header(markWord::unused_mark());\n@@ -461,5 +494,0 @@\n-  \/\/ The object header will never be displaced to this lock,\n-  \/\/ so it does not matter what the value is, except that it\n-  \/\/ must be non-zero to avoid looking like a re-entrant lock,\n-  \/\/ and must not look locked either.\n-  lock->set_displaced_header(markWord::unused_mark());\n@@ -479,28 +507,12 @@\n-  \/\/ We cannot check for Biased Locking if we are racing an inflation.\n-  assert(mark == markWord::INFLATING() ||\n-         !mark.has_bias_pattern(), \"should not see bias pattern here\");\n-\n-  markWord dhw = lock->displaced_header();\n-  if (dhw.value() == 0) {\n-    \/\/ If the displaced header is NULL, then this exit matches up with\n-    \/\/ a recursive enter. No real work to do here except for diagnostics.\n-#ifndef PRODUCT\n-    if (mark != markWord::INFLATING()) {\n-      \/\/ Only do diagnostics if we are not racing an inflation. Simply\n-      \/\/ exiting a recursive enter of a Java Monitor that is being\n-      \/\/ inflated is safe; see the has_monitor() comment below.\n-      assert(!mark.is_neutral(), \"invariant\");\n-      assert(!mark.has_locker() ||\n-             current->is_lock_owned((address)mark.locker()), \"invariant\");\n-      if (mark.has_monitor()) {\n-        \/\/ The BasicLock's displaced_header is marked as a recursive\n-        \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n-        \/\/ This is a special case where the Java Monitor was inflated\n-        \/\/ after this thread entered the stack-lock recursively. When a\n-        \/\/ Java Monitor is inflated, we cannot safely walk the Java\n-        \/\/ Monitor owner's stack and update the BasicLocks because a\n-        \/\/ Java Monitor can be asynchronously inflated by a thread that\n-        \/\/ does not own the Java Monitor.\n-        ObjectMonitor* m = mark.monitor();\n-        assert(m->object()->mark() == mark, \"invariant\");\n-        assert(m->is_entered(current), \"invariant\");\n+    if (UseFastLocking) {\n+      if (mark.is_fast_locked()) {\n+        markWord unlocked_header = mark.set_unlocked();\n+        markWord witness = object->cas_set_mark(unlocked_header, mark);\n+        if (witness != mark) {\n+          \/\/ Another thread beat us, it can only have installed an anonymously locked monitor at this point.\n+          \/\/ Fetch that monitor, set owner correctly to this thread, and exit it (allowing waiting threads to enter).\n+          assert(witness.has_monitor(), \"must have monitor\");\n+          ObjectMonitor* monitor = witness.monitor();\n+          assert(monitor->is_owner_anonymous(), \"must be anonymous owner\");\n+          monitor->set_owner_from_anonymous(current);\n+          monitor->exit(current);\n@@ -508,0 +520,3 @@\n+      LockStack& lock_stack = current->lock_stack();\n+      lock_stack.remove(object);\n+      return;\n@@ -509,0 +524,27 @@\n+  } else {\n+    markWord dhw = lock->displaced_header();\n+    if (dhw.value() == 0) {\n+      \/\/ If the displaced header is NULL, then this exit matches up with\n+      \/\/ a recursive enter. No real work to do here except for diagnostics.\n+#ifndef PRODUCT\n+      if (mark != markWord::INFLATING()) {\n+        \/\/ Only do diagnostics if we are not racing an inflation. Simply\n+        \/\/ exiting a recursive enter of a Java Monitor that is being\n+        \/\/ inflated is safe; see the has_monitor() comment below.\n+        assert(!mark.is_neutral(), \"invariant\");\n+        assert(!mark.has_locker() ||\n+               current->is_lock_owned((address)mark.locker()), \"invariant\");\n+        if (mark.has_monitor()) {\n+          \/\/ The BasicLock's displaced_header is marked as a recursive\n+          \/\/ enter and we have an inflated Java Monitor (ObjectMonitor).\n+          \/\/ This is a special case where the Java Monitor was inflated\n+          \/\/ after this thread entered the stack-lock recursively. When a\n+          \/\/ Java Monitor is inflated, we cannot safely walk the Java\n+          \/\/ Monitor owner's stack and update the BasicLocks because a\n+          \/\/ Java Monitor can be asynchronously inflated by a thread that\n+          \/\/ does not own the Java Monitor.\n+          ObjectMonitor* m = mark.monitor();\n+          assert(m->object()->mark() == mark, \"invariant\");\n+          assert(m->is_entered(current), \"invariant\");\n+        }\n+      }\n@@ -510,8 +552,0 @@\n-    return;\n-  }\n-\n-  if (mark == markWord::from_pointer(lock)) {\n-    \/\/ If the object is stack-locked by the current thread, try to\n-    \/\/ swing the displaced header from the BasicLock back to the mark.\n-    assert(dhw.is_neutral(), \"invariant\");\n-    if (object->cas_set_mark(dhw, mark) == mark) {\n@@ -520,0 +554,9 @@\n+\n+    if (mark == markWord::from_pointer(lock)) {\n+      \/\/ If the object is stack-locked by the current thread, try to\n+      \/\/ swing the displaced header from the BasicLock back to the mark.\n+      assert(dhw.is_neutral(), \"invariant\");\n+      if (object->cas_set_mark(dhw, mark) == mark) {\n+        return;\n+      }\n+    }\n@@ -526,0 +569,7 @@\n+  if (UseFastLocking && monitor->is_owner_anonymous()) {\n+    \/\/ It must be us. Pop lock object from lock stack.\n+    LockStack& lock_stack = current->lock_stack();\n+    oop popped = lock_stack.pop();\n+    assert(popped == object, \"must be owned by this thread\");\n+    monitor->set_owner_from_anonymous(current);\n+  }\n@@ -690,1 +740,2 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(obj())) ||\n+      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n@@ -709,1 +760,2 @@\n-  if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n+  if ((mark.is_fast_locked() && current->lock_stack().contains(obj())) ||\n+      (mark.has_locker() && current->is_lock_owned((address)mark.locker()))) {\n@@ -737,1 +789,1 @@\n-  if (!mark.is_being_inflated()) {\n+  if (!mark.is_being_inflated() || UseFastLocking) {\n@@ -852,0 +904,5 @@\n+static bool is_lock_owned(Thread* thread, oop obj) {\n+  assert(UseFastLocking, \"only call this with fast-locking enabled\");\n+  return thread->is_Java_thread() ? reinterpret_cast<JavaThread*>(thread)->lock_stack().contains(obj) : false;\n+}\n+\n@@ -925,1 +982,8 @@\n-    } else if (current->is_lock_owned((address)mark.locker())) {\n+    } else if (mark.is_fast_locked() && is_lock_owned(current, obj)) {\n+      \/\/ This is a fast lock owned by the calling thread so use the\n+      \/\/ markWord from the object.\n+      hash = mark.hash();\n+      if (hash != 0) {                  \/\/ if it has a hash, just return it\n+        return hash;\n+      }\n+    } else if (mark.has_locker() && current->is_lock_owned((address)mark.locker())) {\n@@ -1006,0 +1070,6 @@\n+\n+  \/\/ Fast-locking case.\n+  if (mark.is_fast_locked()) {\n+    return current->lock_stack().contains(h_obj());\n+  }\n+\n@@ -1030,2 +1100,0 @@\n-  address owner = NULL;\n-\n@@ -1036,1 +1104,5 @@\n-    owner = (address) mark.locker();\n+    return Threads::owning_thread_from_monitor_owner(t_list, (address) mark.locker());\n+  }\n+\n+  if (mark.is_fast_locked()) {\n+    return Threads::owning_thread_from_object(t_list, h_obj());\n@@ -1040,1 +1112,1 @@\n-  else if (mark.has_monitor()) {\n+  if (mark.has_monitor()) {\n@@ -1045,6 +1117,1 @@\n-    owner = (address) monitor->owner();\n-  }\n-\n-  if (owner != NULL) {\n-    \/\/ owning_thread_from_monitor_owner() may also return NULL here\n-    return Threads::owning_thread_from_monitor_owner(t_list, owner);\n+    return Threads::owning_thread_from_monitor(t_list, monitor);\n@@ -1053,5 +1120,0 @@\n-  \/\/ Unlocked case, header in place\n-  \/\/ Cannot have assertion since this object may have been\n-  \/\/ locked by another thread when reaching here.\n-  \/\/ assert(mark.is_neutral(), \"sanity check\");\n-\n@@ -1265,0 +1327,5 @@\n+      if (UseFastLocking && inf->is_owner_anonymous() && is_lock_owned(current, object)) {\n+        inf->set_owner_from_anonymous(current);\n+        assert(current->is_Java_thread(), \"must be Java thread\");\n+        reinterpret_cast<JavaThread*>(current)->lock_stack().remove(object);\n+      }\n@@ -1274,1 +1341,4 @@\n-    if (mark == markWord::INFLATING()) {\n+    \/\/ NOTE: We need to check UseFastLocking here, because with fast-locking, the header\n+    \/\/ may legitimately be zero: cleared lock-bits and all upper header bits zero.\n+    \/\/ With fast-locking, the INFLATING protocol is not used.\n+    if (mark == markWord::INFLATING() && !UseFastLocking) {\n@@ -1290,0 +1360,42 @@\n+    if (mark.is_fast_locked()) {\n+      assert(UseFastLocking, \"can only happen with fast-locking\");\n+      ObjectMonitor* monitor = new ObjectMonitor(object);\n+      monitor->set_header(mark.set_unlocked());\n+      bool own = is_lock_owned(current, object);\n+      if (own) {\n+        \/\/ Owned by us.\n+        monitor->set_owner_from(NULL, current);\n+      } else {\n+        \/\/ Owned by somebody else.\n+        monitor->set_owner_anonymous();\n+      }\n+      markWord monitor_mark = markWord::encode(monitor);\n+      markWord witness = object->cas_set_mark(monitor_mark, mark);\n+      if (witness == mark) {\n+        \/\/ Success! Return inflated monitor.\n+        if (own) {\n+          assert(current->is_Java_thread(), \"must be: checked in is_lock_owned()\");\n+          reinterpret_cast<JavaThread*>(current)->lock_stack().remove(object);\n+        }\n+        \/\/ Once the ObjectMonitor is configured and object is associated\n+        \/\/ with the ObjectMonitor, it is safe to allow async deflation:\n+        _in_use_list.add(monitor);\n+\n+        \/\/ Hopefully the performance counters are allocated on distinct\n+        \/\/ cache lines to avoid false sharing on MP systems ...\n+        OM_PERFDATA_OP(Inflations, inc());\n+        if (log_is_enabled(Trace, monitorinflation)) {\n+          ResourceMark rm(current);\n+          lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n+                       INTPTR_FORMAT \", type='%s'\", p2i(object),\n+                       object->mark().value(), object->klass()->external_name());\n+        }\n+        if (event.should_commit()) {\n+          post_monitor_inflate_event(&event, object, cause);\n+        }\n+        return monitor;\n+      } else {\n+        delete monitor;\n+        continue;\n+      }\n+    }\n@@ -1292,0 +1404,1 @@\n+      assert(!UseFastLocking, \"can not happen with fast-locking\");\n@@ -1364,1 +1477,1 @@\n-        lsh.print_cr(\"inflate(has_locker): object=\" INTPTR_FORMAT \", mark=\"\n+        lsh.print_cr(\"inflate(locked): object=\" INTPTR_FORMAT \", mark=\"\n@@ -1484,0 +1597,10 @@\n+class VM_RendezvousGCThreads : public VM_Operation {\n+public:\n+  bool evaluate_at_safepoint() const override { return false; }\n+  VMOp_Type type() const override { return VMOp_RendezvousGCThreads; }\n+  void doit() override {\n+    SuspendibleThreadSet::synchronize();\n+    SuspendibleThreadSet::desynchronize();\n+  };\n+};\n+\n@@ -1536,0 +1659,3 @@\n+      \/\/ Also, we sync and desync GC threads around the handshake, so that they can\n+      \/\/ safely read the mark-word and look-through to the object-monitor, without\n+      \/\/ being afraid that the object-monitor is going away.\n@@ -1538,0 +1664,2 @@\n+      VM_RendezvousGCThreads sync_gc;\n+      VMThread::execute(&sync_gc);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":210,"deletions":82,"binary":false,"changes":292,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+  template(HeapObjectStatistics)                  \\\n@@ -94,0 +95,1 @@\n+  template(RendezvousGCThreads)                   \\\n","filename":"src\/hotspot\/share\/runtime\/vmOperation.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -737,0 +737,3 @@\n+  nonstatic_field(JavaThread,                  _lock_stack,                                   LockStack)                             \\\n+  nonstatic_field(LockStack,                   _current,                                      oop*)                                  \\\n+  nonstatic_field(LockStack,                   _base,                                         oop*)                                  \\\n@@ -1353,0 +1356,1 @@\n+  declare_toplevel_type(LockStack)                                        \\\n@@ -2641,0 +2645,1 @@\n+  LP64_ONLY(declare_constant(markWord::klass_shift))                      \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -76,1 +76,2 @@\n-    final int hubOffset = getFieldOffset(\"oopDesc::_metadata._klass\", Integer.class, \"Klass*\");\n+    \/\/ TODO: Lilliput. Probably ok.\n+    final int hubOffset = 4; \/\/ getFieldOffset(\"oopDesc::_metadata._klass\", Integer.class, \"Klass*\");\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk\/vm\/ci\/hotspot\/HotSpotVMConfig.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -173,0 +173,10 @@\n+\n+# Lilliput:\n+\n+# Disabled because Lilliput forces +UseCompressedClassPointers\n+gc\/arguments\/TestCompressedClassFlags.java 1234567 generic-all\n+\n+# Disabled because Lilliput forces -UseBiasedLocking\n+runtime\/logging\/BiasedLockingTest.java 1234567 generic-all\n+# Because of -UseBiasedLocking, too\n+compiler\/rtm\/cli\/TestUseRTMLockingOptionWithBiasedLocking.java 1234567 generic-x64,generic-i586\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"}]}