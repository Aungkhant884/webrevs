{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"logging\/log.hpp\"\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.inline.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -58,3 +58,0 @@\n-  \/\/ Loom support\n-  static bool requires_barriers(stackChunkOop obj);\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1BarrierSet.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -110,4 +109,0 @@\n-inline bool G1BarrierSet::requires_barriers(stackChunkOop obj) {\n-  return G1CollectedHeap::heap()->G1CollectedHeap::requires_barriers(obj);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1BarrierSet.inline.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -94,3 +94,0 @@\n-  \/\/ Loom support\n-  static bool requires_barriers(stackChunkOop obj);\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSet.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -62,4 +61,0 @@\n-inline bool BarrierSet::requires_barriers(stackChunkOop obj) {\n-  return Universe::heap()->requires_barriers(obj);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSet.inline.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -40,1 +40,0 @@\n-  static bool requires_barriers(stackChunkOop obj);\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"gc\/z\/zCollectedHeap.inline.hpp\"\n@@ -243,4 +242,0 @@\n-inline bool ZBarrierSet::requires_barriers(stackChunkOop obj) {\n-  return ZCollectedHeap::heap()->ZCollectedHeap::requires_barriers(obj);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrierSet.inline.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -125,0 +125,21 @@\n+bool ZCollectedHeap::requires_barriers(stackChunkOop obj) const {\n+  uintptr_t* cont_addr = obj->field_addr<uintptr_t>(jdk_internal_vm_StackChunk::cont_offset());\n+\n+  if (!_heap.is_allocating(cast_from_oop<uintptr_t>(obj))) {\n+    \/\/ An object that isn't allocating, is visible from GC tracing. Such\n+    \/\/ stack chunks require barriers.\n+    return true;\n+  }\n+\n+  if (!ZAddress::is_good_or_null(*cont_addr)) {\n+    \/\/ If a chunk is allocated after a GC started, but before relocate start\n+    \/\/ we can have an allocating chunk that isn't deeply good. That means that\n+    \/\/ the contained oops might be bad and require GC barriers.\n+    return true;\n+  }\n+\n+  \/\/ The chunk is allocating and its pointers are good. This chunk needs no\n+  \/\/ GC barriers\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zCollectedHeap.cpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -75,1 +75,1 @@\n-  virtual inline bool requires_barriers(stackChunkOop obj) const;\n+  virtual bool requires_barriers(stackChunkOop obj) const;\n","filename":"src\/hotspot\/share\/gc\/z\/zCollectedHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1,53 +0,0 @@\n-\/*\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#ifndef SHARE_GC_Z_ZCOLLECTEDHEAP_INLINE_HPP\n-#define SHARE_GC_Z_ZCOLLECTEDHEAP_INLINE_HPP\n-\n-#include \"gc\/z\/zCollectedHeap.hpp\"\n-\n-#include \"gc\/z\/zAddress.inline.hpp\"\n-#include \"gc\/z\/zHeap.inline.hpp\"\n-\n-inline bool ZCollectedHeap::requires_barriers(stackChunkOop obj) const {\n-  uintptr_t* cont_addr = obj->field_addr<uintptr_t>(jdk_internal_vm_StackChunk::cont_offset());\n-\n-  if (!_heap.is_allocating(cast_from_oop<uintptr_t>(obj))) {\n-    \/\/ An object that isn't allocating, is visible from GC tracing. Such\n-    \/\/ stack chunks require barriers.\n-    return true;\n-  }\n-\n-  if (!ZAddress::is_good_or_null(*cont_addr)) {\n-    \/\/ If a chunk is allocated after a GC started, but before relocate start\n-    \/\/ we can have an allocating chunk that isn't deeply good. That means that\n-    \/\/ the contained oops might be bad and require GC barriers.\n-    return true;\n-  }\n-\n-  \/\/ The chunk is allocating and its pointers are good. This chunk needs no\n-  \/\/ GC barriers\n-  return false;\n-}\n-\n-#endif \/\/ SHARE_GC_Z_ZCOLLECTEDHEAP_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/z\/zCollectedHeap.inline.hpp","additions":0,"deletions":53,"binary":false,"changes":53,"status":"deleted"},{"patch":"@@ -36,0 +36,2 @@\n+#include \"logging\/log.hpp\"\n+#include \"logging\/logStream.hpp\"\n","filename":"src\/hotspot\/share\/oops\/instanceStackChunkKlass.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -209,1 +209,1 @@\n-template<typename ConfigT> static inline int freeze0(JavaThread* current, intptr_t* const sp);\n+template<typename OopT> static inline int freeze0(JavaThread* current, intptr_t* const sp);\n@@ -218,1 +218,1 @@\n-template<typename ConfigT> static inline intptr_t* thaw0(JavaThread* thread, const thaw_kind kind);\n+template<typename OopT> static inline intptr_t* thaw0(JavaThread* thread, const thaw_kind kind);\n@@ -223,25 +223,0 @@\n-enum class oop_kind { NARROW, WIDE };\n-template <oop_kind oops, typename BarrierSetT>\n-class Config {\n-public:\n-  typedef Config<oops, BarrierSetT> SelfT;\n-  typedef typename Conditional<oops == oop_kind::NARROW, narrowOop, oop>::type OopT;\n-\n-  static int freeze(JavaThread* thread, intptr_t* const sp) {\n-    return freeze0<SelfT, false>(thread, sp);\n-  }\n-\n-  __COLD\n-  static int freeze_preempt(JavaThread* thread, intptr_t* const sp) {\n-    return freeze0<SelfT, true>(thread, sp);\n-  }\n-\n-  static intptr_t* thaw(JavaThread* thread, thaw_kind kind) {\n-    return thaw0<SelfT>(thread, kind);\n-  }\n-\n-  static bool requires_barriers(stackChunkOop obj) {\n-    return BarrierSetT::requires_barriers(obj);\n-  }\n-};\n-\n@@ -533,1 +508,1 @@\n-template<typename ConfigT>\n+template<typename OopT>\n@@ -541,1 +516,1 @@\n-  return ConfigT::freeze(current, sp);\n+  return freeze0<OopT, false>(current, sp);\n@@ -601,1 +576,1 @@\n-template<typename ConfigT>\n+template<typename OopT>\n@@ -608,1 +583,1 @@\n-  return ConfigT::thaw(thread, (thaw_kind)kind);\n+  return thaw0<OopT>(thread, (thaw_kind)kind);\n@@ -1019,1 +994,1 @@\n-template <typename ConfigT>\n+template <typename OopT>\n@@ -1125,1 +1100,1 @@\n-    if (chunk == nullptr || chunk->is_gc_mode() || ConfigT::requires_barriers(chunk) || chunk->has_mixed_frames()) {\n+    if (chunk == nullptr || chunk->is_gc_mode() || chunk->requires_barriers() || chunk->has_mixed_frames()) {\n@@ -1500,1 +1475,1 @@\n-    if (unextended_sp < _size || chunk->is_gc_mode() || (!_barriers && ConfigT::requires_barriers(chunk))) {\n+    if (unextended_sp < _size || chunk->is_gc_mode() || (!_barriers && chunk->requires_barriers())) {\n@@ -1843,1 +1818,1 @@\n-      _barriers = ConfigT::requires_barriers(chunk);\n+      _barriers = chunk->requires_barriers();\n@@ -1869,2 +1844,2 @@\n-    chunk->set_parent_raw<typename ConfigT::OopT>(chunk0);\n-    chunk->set_cont_raw<typename ConfigT::OopT>(_cont.mirror());\n+    chunk->set_parent_raw<OopT>(chunk0);\n+    chunk->set_cont_raw<OopT>(_cont.mirror());\n@@ -1874,1 +1849,1 @@\n-      assert(!ConfigT::requires_barriers(chunk), \"Unfamiliar GC requires barriers on TLAB allocation\");\n+      assert(!chunk->requires_barriers(), \"Unfamiliar GC requires barriers on TLAB allocation\");\n@@ -1876,1 +1851,1 @@\n-      _barriers = ConfigT::requires_barriers(chunk);\n+      _barriers = chunk->requires_barriers();\n@@ -1986,1 +1961,1 @@\n-template<typename ConfigT, bool preempt>\n+template<typename OopT, bool preempt>\n@@ -2029,1 +2004,1 @@\n-  Freeze<ConfigT> fr(current, cont, preempt);\n+  Freeze<OopT> fr(current, cont, preempt);\n@@ -2236,1 +2211,1 @@\n-template <typename ConfigT>\n+template <typename OopT>\n@@ -2287,1 +2262,1 @@\n-    _barriers = ConfigT::requires_barriers(chunk);\n+    _barriers = chunk->requires_barriers();\n@@ -2362,1 +2337,1 @@\n-    const bool is_last = empty && chunk->is_parent_null<typename ConfigT::OopT>();\n+    const bool is_last = empty && chunk->is_parent_null<OopT>();\n@@ -2612,2 +2587,2 @@\n-    chunk->bitmap().clear_range(chunk->bit_index_for((typename ConfigT::OopT*)start),\n-                                chunk->bit_index_for((typename ConfigT::OopT*)(start+range)));\n+    chunk->bitmap().clear_range(chunk->bit_index_for((OopT*)start),\n+                                chunk->bit_index_for((OopT*)(start+range)));\n@@ -2858,1 +2833,1 @@\n-template<typename ConfigT>\n+template<typename OopT>\n@@ -2893,1 +2868,1 @@\n-  Thaw<ConfigT> thw(thread, cont);\n+  Thaw<OopT> thw(thread, cont);\n@@ -3145,2 +3120,2 @@\n-    UseCompressedOops ? resolve_gc<true>()\n-                      : resolve_gc<false>();\n+    UseCompressedOops ? resolve<narrowOop>()\n+                      : resolve<oop>();\n@@ -3150,19 +3125,1 @@\n-  template <bool use_compressed>\n-  static void resolve_gc() {\n-    BarrierSet* bs = BarrierSet::barrier_set();\n-    assert(bs != NULL, \"freeze\/thaw invoked before BarrierSet is set\");\n-    switch (bs->kind()) {\n-#define BARRIER_SET_RESOLVE_BARRIER_CLOSURE(bs_name)                    \\\n-      case BarrierSet::bs_name: {                                       \\\n-        resolve<use_compressed, typename BarrierSet::GetType<BarrierSet::bs_name>::type>(); \\\n-      }                                                                 \\\n-        break;\n-      FOR_EACH_CONCRETE_BARRIER_SET_DO(BARRIER_SET_RESOLVE_BARRIER_CLOSURE)\n-#undef BARRIER_SET_RESOLVE_BARRIER_CLOSURE\n-\n-    default:\n-      fatal(\"BarrierSet resolving not implemented\");\n-    };\n-  }\n-\n-  template <bool use_compressed, typename BarrierSetT>\n+  template <typename OopT>\n@@ -3170,7 +3127,3 @@\n-    typedef Config<use_compressed ? oop_kind::NARROW : oop_kind::WIDE, BarrierSetT> SelectedConfigT;\n-\n-    freeze_entry = (address)freeze<SelectedConfigT>;\n-    preempt_freeze = SelectedConfigT::freeze_preempt;\n-\n-    \/\/ if we want, we could templatize by king and have three different that entries\n-    thaw_entry   = (address)thaw<SelectedConfigT>;\n+    freeze_entry = (address)freeze<OopT>;\n+    preempt_freeze = freeze0<OopT, true>;\n+    thaw_entry   = (address)thaw<OopT>;\n","filename":"src\/hotspot\/share\/runtime\/continuation.cpp","additions":29,"deletions":76,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"classfile\/javaClasses.inline.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/threadSMR.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}