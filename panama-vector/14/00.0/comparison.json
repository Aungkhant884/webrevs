{"files":[{"patch":"@@ -117,2 +117,2 @@\n-reg_def R18     ( SOC, SOC, Op_RegI, 18, r18->as_VMReg()        );\n-reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18->as_VMReg()->next());\n+reg_def R18     ( SOC, SOC, Op_RegI, 18, r18_tls->as_VMReg()        );\n+reg_def R18_H   ( SOC, SOC, Op_RegI, 18, r18_tls->as_VMReg()->next());\n@@ -250,2 +250,2 @@\n-  reg_def V8   ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()          );\n-  reg_def V8_H ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next()  );\n+  reg_def V8   ( SOC, SOE, Op_RegF, 8, v8->as_VMReg()          );\n+  reg_def V8_H ( SOC, SOE, Op_RegF, 8, v8->as_VMReg()->next()  );\n@@ -259,2 +259,2 @@\n-  reg_def V9   ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()          );\n-  reg_def V9_H ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next()  );\n+  reg_def V9   ( SOC, SOE, Op_RegF, 9, v9->as_VMReg()          );\n+  reg_def V9_H ( SOC, SOE, Op_RegF, 9, v9->as_VMReg()->next()  );\n@@ -268,2 +268,2 @@\n-  reg_def V10   ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()          );\n-  reg_def V10_H ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next()  );\n+  reg_def V10   ( SOC, SOE, Op_RegF, 10, v10->as_VMReg()          );\n+  reg_def V10_H ( SOC, SOE, Op_RegF, 10, v10->as_VMReg()->next()  );\n@@ -277,2 +277,2 @@\n-  reg_def V11   ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()          );\n-  reg_def V11_H ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next()  );\n+  reg_def V11   ( SOC, SOE, Op_RegF, 11, v11->as_VMReg()          );\n+  reg_def V11_H ( SOC, SOE, Op_RegF, 11, v11->as_VMReg()->next()  );\n@@ -286,2 +286,2 @@\n-  reg_def V12   ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()          );\n-  reg_def V12_H ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next()  );\n+  reg_def V12   ( SOC, SOE, Op_RegF, 12, v12->as_VMReg()          );\n+  reg_def V12_H ( SOC, SOE, Op_RegF, 12, v12->as_VMReg()->next()  );\n@@ -295,2 +295,2 @@\n-  reg_def V13   ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()          );\n-  reg_def V13_H ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next()  );\n+  reg_def V13   ( SOC, SOE, Op_RegF, 13, v13->as_VMReg()          );\n+  reg_def V13_H ( SOC, SOE, Op_RegF, 13, v13->as_VMReg()->next()  );\n@@ -304,2 +304,2 @@\n-  reg_def V14   ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()          );\n-  reg_def V14_H ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next()  );\n+  reg_def V14   ( SOC, SOE, Op_RegF, 14, v14->as_VMReg()          );\n+  reg_def V14_H ( SOC, SOE, Op_RegF, 14, v14->as_VMReg()->next()  );\n@@ -313,2 +313,2 @@\n-  reg_def V15   ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()          );\n-  reg_def V15_H ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next()  );\n+  reg_def V15   ( SOC, SOE, Op_RegF, 15, v15->as_VMReg()          );\n+  reg_def V15_H ( SOC, SOE, Op_RegF, 15, v15->as_VMReg()->next()  );\n@@ -719,0 +719,4 @@\n+#ifdef R18_RESERVED\n+    \/\/ See comment in register_aarch64.hpp\n+    R18,                        \/\/ tls on Windows\n+#endif\n@@ -726,0 +730,4 @@\n+#ifdef R18_RESERVED\n+    \/\/ See comment in register_aarch64.hpp\n+    R18, R18_H,                 \/\/ tls on Windows, platform register on macOS\n+#endif\n@@ -1961,3 +1969,4 @@\n-    st->print(\"# touch polling page\\n\\t\");\n-    st->print(\"ldr rscratch1, [rthread],#polling_page_offset\\n\\t\");\n-    st->print(\"ldr zr, [rscratch1]\");\n+    st->print(\"# test polling word\\n\\t\");\n+    st->print(\"ldr  rscratch1, [rthread],#%d\\n\\t\", in_bytes(JavaThread::polling_word_offset()));\n+    st->print(\"cmp  sp, rscratch1\\n\\t\");\n+    st->print(\"bhi #slow_path\");\n@@ -1980,1 +1989,7 @@\n-    __ fetch_and_read_polling_page(rscratch1, relocInfo::poll_return_type);\n+    Label dummy_label;\n+    Label* code_stub = &dummy_label;\n+    if (!C->output()->in_scratch_emit_size()) {\n+      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+    }\n+    __ relocate(relocInfo::poll_return_type);\n+    __ safepoint_poll(*code_stub, true \/* at_return *\/, false \/* acquire *\/, true \/* in_nmethod *\/);\n@@ -6355,1 +6370,1 @@\n-  max_instructions_per_bundle = 2;   \/\/ A53 = 2, A57 = 4\n+  max_instructions_per_bundle = 4;   \/\/ A53 = 2, A57 = 4\n@@ -16431,1 +16446,1 @@\n-instruct string_indexofU_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+instruct string_indexof_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n@@ -16436,0 +16451,1 @@\n+  predicate(((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U);\n@@ -16439,1 +16455,1 @@\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$ch -> $result\" %}\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result\" %}\n@@ -16449,0 +16465,19 @@\n+instruct stringL_indexof_char(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+                              iRegI_R0 result, iRegINoSp tmp1, iRegINoSp tmp2,\n+                              iRegINoSp tmp3, rFlagsReg cr)\n+%{\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  predicate(((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L);\n+  effect(USE_KILL str1, USE_KILL cnt1, USE_KILL ch,\n+         TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);\n+\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result\" %}\n+\n+  ins_encode %{\n+    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register,\n+                           $result$$Register, $tmp1$$Register, $tmp2$$Register,\n+                           $tmp3$$Register);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":60,"deletions":25,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1535,1 +1536,1 @@\n-    __ bang_stack_with_offset(JavaThread::stack_shadow_zone_size());\n+    __ bang_stack_with_offset(StackOverflow::stack_shadow_zone_size());\n@@ -1888,1 +1889,10 @@\n-    __ safepoint_poll_acquire(safepoint_in_progress);\n+    \/\/ We need an acquire here to ensure that any subsequent load of the\n+    \/\/ global SafepointSynchronize::_state flag is ordered after this load\n+    \/\/ of the thread-local polling word.  We don't want this poll to\n+    \/\/ return false (i.e. not safepointing) and a later poll of the global\n+    \/\/ SafepointSynchronize::_state spuriously to return true.\n+    \/\/\n+    \/\/ This is to avoid a race when we're in a native->Java transition\n+    \/\/ racing the code which wakes up from a safepoint.\n+\n+    __ safepoint_poll(safepoint_in_progress, true \/* at_return *\/, true \/* acquire *\/, false \/* in_nmethod *\/);\n@@ -1904,1 +1914,1 @@\n-  __ cmpw(rscratch1, JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpw(rscratch1, StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1249,1 +1250,1 @@\n-  __ cmp(R2, JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmp(R2, StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1430,1 +1430,1 @@\n-    int bang_end = JavaThread::stack_shadow_zone_size();\n+    int bang_end = StackOverflow::stack_shadow_zone_size();\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -2518,1 +2519,1 @@\n-  __ cmpwi(CCR0, r_temp_1, JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpwi(CCR0, r_temp_1, StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -2220,2 +2221,2 @@\n-  __ z_cli(Address(Z_thread, JavaThread::stack_guard_state_offset() + in_ByteSize(sizeof(JavaThread::StackGuardState) - 1)),\n-           JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ z_cli(Address(Z_thread, JavaThread::stack_guard_state_offset() + in_ByteSize(sizeof(StackOverflow::StackGuardState) - 1)),\n+           StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -1879,1 +1880,1 @@\n-    __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());\n+    __ bang_stack_with_offset((int)StackOverflow::stack_shadow_zone_size());\n@@ -2248,1 +2249,1 @@\n-    __ safepoint_poll(slow_path, thread, noreg);\n+    __ safepoint_poll(slow_path, thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -2290,1 +2291,1 @@\n-  __ cmpl(Address(thread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpl(Address(thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -2202,1 +2203,1 @@\n-    __ bang_stack_with_offset((int)JavaThread::stack_shadow_zone_size());\n+    __ bang_stack_with_offset((int)StackOverflow::stack_shadow_zone_size());\n@@ -2623,1 +2624,1 @@\n-    __ safepoint_poll(slow_path, r15_thread, rscratch1);\n+    __ safepoint_poll(slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -2666,1 +2667,1 @@\n-  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), JavaThread::stack_guard_yellow_reserved_disabled);\n+  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1470,18 +1470,2 @@\n-      \/\/ Copy 64-bytes per iteration\n-      if (UseAVX > 2) {\n-        Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;\n-\n-        __ BIND(L_copy_bytes);\n-        __ cmpptr(qword_count, (-1 * AVX3Threshold \/ 8));\n-        __ jccb(Assembler::less, L_above_threshold);\n-        __ jmpb(L_below_threshold);\n-\n-        __ bind(L_loop_avx512);\n-        __ evmovdqul(xmm0, Address(end_from, qword_count, Address::times_8, -56), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(end_to, qword_count, Address::times_8, -56), xmm0, Assembler::AVX_512bit);\n-        __ bind(L_above_threshold);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop_avx512);\n-        __ jmpb(L_32_byte_head);\n-\n-        __ bind(L_loop_avx2);\n+      __ BIND(L_loop);\n+      if (UseAVX >= 2) {\n@@ -1492,29 +1476,8 @@\n-        __ bind(L_below_threshold);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop_avx2);\n-\n-        __ bind(L_32_byte_head);\n-        __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n-        __ jccb(Assembler::greater, L_end);\n-        __ BIND(L_loop);\n-        if (UseAVX == 2) {\n-          __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n-          __ vmovdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n-          __ vmovdqu(xmm1, Address(end_from, qword_count, Address::times_8, -24));\n-          __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm1);\n-        } else {\n-          __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n-          __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);\n-          __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);\n-          __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);\n-        }\n-\n-        __ BIND(L_copy_bytes);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop);\n-        __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n-        __ jccb(Assembler::greater, L_end);\n+        __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n+        __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);\n+        __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);\n+        __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);\n@@ -1523,0 +1486,6 @@\n+\n+      __ BIND(L_copy_bytes);\n+      __ addptr(qword_count, 8);\n+      __ jcc(Assembler::lessEqual, L_loop);\n+      __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n+      __ jccb(Assembler::greater, L_end);\n@@ -1578,18 +1547,2 @@\n-      \/\/ Copy 64-bytes per iteration\n-      if (UseAVX > 2) {\n-        Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;\n-\n-        __ BIND(L_copy_bytes);\n-        __ cmpptr(qword_count, (AVX3Threshold \/ 8));\n-        __ jccb(Assembler::greater, L_above_threshold);\n-        __ jmpb(L_below_threshold);\n-\n-        __ BIND(L_loop_avx512);\n-        __ evmovdqul(xmm0, Address(from, qword_count, Address::times_8, 0), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(dest, qword_count, Address::times_8, 0), xmm0, Assembler::AVX_512bit);\n-        __ bind(L_above_threshold);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop_avx512);\n-        __ jmpb(L_32_byte_head);\n-\n-        __ bind(L_loop_avx2);\n+      __ BIND(L_loop);\n+      if (UseAVX >= 2) {\n@@ -1598,9 +1551,2 @@\n-        __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8, 0));\n-        __ vmovdqu(Address(dest, qword_count, Address::times_8, 0), xmm1);\n-        __ bind(L_below_threshold);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop_avx2);\n-\n-        __ bind(L_32_byte_head);\n-        __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n-        __ jccb(Assembler::less, L_end);\n+        __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));\n+        __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);\n@@ -1608,16 +1554,9 @@\n-        __ BIND(L_loop);\n-        if (UseAVX == 2) {\n-          __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 32));\n-          __ vmovdqu(Address(dest, qword_count, Address::times_8, 32), xmm0);\n-          __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));\n-          __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);\n-        } else {\n-          __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);\n-          __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);\n-          __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);\n-          __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));\n-          __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);\n-        }\n+        __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);\n+        __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);\n+        __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);\n+        __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));\n+        __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);\n+      }\n@@ -1625,3 +1564,3 @@\n-        __ BIND(L_copy_bytes);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop);\n+      __ BIND(L_copy_bytes);\n+      __ subptr(qword_count, 8);\n+      __ jcc(Assembler::greaterEqual, L_loop);\n@@ -1629,3 +1568,2 @@\n-        __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n-        __ jccb(Assembler::less, L_end);\n-      }\n+      __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n+      __ jccb(Assembler::less, L_end);\n@@ -1669,0 +1607,438 @@\n+#ifndef PRODUCT\n+    int& get_profile_ctr(int shift) {\n+      if ( 0 == shift)\n+        return SharedRuntime::_jbyte_array_copy_ctr;\n+      else if(1 == shift)\n+        return SharedRuntime::_jshort_array_copy_ctr;\n+      else if(2 == shift)\n+        return SharedRuntime::_jint_array_copy_ctr;\n+      else\n+        return SharedRuntime::_jlong_array_copy_ctr;\n+    }\n+#endif\n+\n+  void setup_argument_regs(BasicType type) {\n+    if (type == T_BYTE || type == T_SHORT) {\n+      setup_arg_regs(); \/\/ from => rdi, to => rsi, count => rdx\n+                        \/\/ r9 and r10 may be used to save non-volatile registers\n+    } else {\n+      setup_arg_regs_using_thread(); \/\/ from => rdi, to => rsi, count => rdx\n+                                     \/\/ r9 is used to save r15_thread\n+    }\n+  }\n+\n+  void restore_argument_regs(BasicType type) {\n+    if (type == T_BYTE || type == T_SHORT) {\n+      restore_arg_regs();\n+    } else {\n+      restore_arg_regs_using_thread();\n+    }\n+  }\n+\n+#if COMPILER2_OR_JVMCI\n+  \/\/ Note: Following rules apply to AVX3 optimized arraycopy stubs:-\n+  \/\/ - If target supports AVX3 features (BW+VL+F) then implementation uses 32 byte vectors (YMMs)\n+  \/\/   for both special cases (various small block sizes) and aligned copy loop. This is the\n+  \/\/   default configuration.\n+  \/\/ - If copy length is above AVX3Threshold, then implementation use 64 byte vectors (ZMMs)\n+  \/\/   for main copy loop (and subsequent tail) since bulk of the cycles will be consumed in it.\n+  \/\/ - If user forces MaxVectorSize=32 then above 4096 bytes its seen that REP MOVs shows a\n+  \/\/   better performance for disjoint copies. For conjoint\/backward copy vector based\n+  \/\/   copy performs better.\n+  \/\/ - If user sets AVX3Threshold=0, then special cases for small blocks sizes operate over\n+  \/\/   64 byte vector registers (ZMMs).\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source array address\n+  \/\/   c_rarg1   - destination array address\n+  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n+  \/\/\n+  \/\/\n+  \/\/ Side Effects:\n+  \/\/   disjoint_copy_avx3_masked is set to the no-overlap entry point\n+  \/\/   used by generate_conjoint_[byte\/int\/short\/long]_copy().\n+  \/\/\n+\n+  address generate_disjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n+                                             bool aligned, bool is_oop, bool dest_uninitialized) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+    Label L_main_loop, L_main_loop_64bytes, L_tail, L_tail64, L_exit, L_entry;\n+    Label L_repmovs, L_main_pre_loop, L_main_pre_loop_64bytes, L_pre_main_post_64;\n+    const Register from        = rdi;  \/\/ source array address\n+    const Register to          = rsi;  \/\/ destination array address\n+    const Register count       = rdx;  \/\/ elements count\n+    const Register temp1       = r8;\n+    const Register temp2       = r11;\n+    const Register temp3       = rax;\n+    const Register temp4       = rcx;\n+    \/\/ End pointers are inclusive, and if count is not zero they point\n+    \/\/ to the last unit copied:  end_to[0] := end_from[0]\n+\n+    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    assert_clean_int(c_rarg2, rax);    \/\/ Make sure 'count' is clean int.\n+\n+    if (entry != NULL) {\n+      *entry = __ pc();\n+       \/\/ caller can pass a 64-bit byte count here (from Unsafe.copyMemory)\n+      BLOCK_COMMENT(\"Entry:\");\n+    }\n+\n+    BasicType type_vec[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+    BasicType type = is_oop ? T_OBJECT : type_vec[shift];\n+\n+    setup_argument_regs(type);\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;\n+    if (dest_uninitialized) {\n+      decorators |= IS_DEST_UNINITIALIZED;\n+    }\n+    if (aligned) {\n+      decorators |= ARRAYCOPY_ALIGNED;\n+    }\n+    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n+\n+    {\n+      \/\/ Type(shift)           byte(0), short(1), int(2),   long(3)\n+      int loop_size[]        = { 192,     96,       48,      24};\n+      int threshold[]        = { 4096,    2048,     1024,    512};\n+\n+      \/\/ UnsafeCopyMemory page error: continue after ucm\n+      UnsafeCopyMemoryMark ucmm(this, !is_oop && !aligned, true);\n+      \/\/ 'from', 'to' and 'count' are now valid\n+\n+      \/\/ temp1 holds remaining count and temp4 holds running count used to compute\n+      \/\/ next address offset for start of to\/from addresses (temp4 * scale).\n+      __ mov64(temp4, 0);\n+      __ movq(temp1, count);\n+\n+      \/\/ Zero length check.\n+      __ BIND(L_tail);\n+      __ cmpq(temp1, 0);\n+      __ jcc(Assembler::lessEqual, L_exit);\n+\n+      \/\/ Special cases using 32 byte [masked] vector copy operations.\n+      __ arraycopy_avx3_special_cases(xmm1, k2, from, to, temp1, shift,\n+                                      temp4, temp3, use64byteVector, L_entry, L_exit);\n+\n+      \/\/ PRE-MAIN-POST loop for aligned copy.\n+      __ BIND(L_entry);\n+\n+      if (AVX3Threshold != 0) {\n+        __ cmpq(count, threshold[shift]);\n+        if (MaxVectorSize == 64) {\n+          \/\/ Copy using 64 byte vectors.\n+          __ jcc(Assembler::greaterEqual, L_pre_main_post_64);\n+        } else {\n+          assert(MaxVectorSize < 64, \"vector size should be < 64 bytes\");\n+          \/\/ REP MOVS offer a faster copy path.\n+          __ jcc(Assembler::greaterEqual, L_repmovs);\n+        }\n+      }\n+\n+      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+        \/\/ Partial copy to make dst address 32 byte aligned.\n+        __ movq(temp2, to);\n+        __ andq(temp2, 31);\n+        __ jcc(Assembler::equal, L_main_pre_loop);\n+\n+        __ negptr(temp2);\n+        __ addq(temp2, 32);\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ movq(temp3, temp2);\n+        __ copy32_masked_avx(to, from, xmm1, k2, temp3, temp4, temp1, shift);\n+        __ movq(temp4, temp2);\n+        __ movq(temp1, count);\n+        __ subq(temp1, temp2);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail);\n+\n+        __ BIND(L_main_pre_loop);\n+        __ subq(temp1, loop_size[shift]);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at 32 byte granularity.\n+        __ BIND(L_main_loop);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 0);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 64);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 128);\n+           __ addptr(temp4, loop_size[shift]);\n+           __ subq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop);\n+\n+        __ addq(temp1, loop_size[shift]);\n+\n+        \/\/ Tail loop.\n+        __ jmp(L_tail);\n+\n+        __ BIND(L_repmovs);\n+          __ movq(temp2, temp1);\n+          \/\/ Swap to(RSI) and from(RDI) addresses to comply with REP MOVs semantics.\n+          __ movq(temp3, to);\n+          __ movq(to,  from);\n+          __ movq(from, temp3);\n+          \/\/ Save to\/from for restoration post rep_mov.\n+          __ movq(temp1, to);\n+          __ movq(temp3, from);\n+          if(shift < 3) {\n+            __ shrq(temp2, 3-shift);     \/\/ quad word count\n+          }\n+          __ movq(temp4 , temp2);        \/\/ move quad ward count into temp4(RCX).\n+          __ rep_mov();\n+          __ shlq(temp2, 3);             \/\/ convert quad words into byte count.\n+          if(shift) {\n+            __ shrq(temp2, shift);       \/\/ type specific count.\n+          }\n+          \/\/ Restore original addresses in to\/from.\n+          __ movq(to, temp3);\n+          __ movq(from, temp1);\n+          __ movq(temp4, temp2);\n+          __ movq(temp1, count);\n+          __ subq(temp1, temp2);         \/\/ tailing part (less than a quad ward size).\n+          __ jmp(L_tail);\n+      }\n+\n+      if (MaxVectorSize > 32) {\n+        __ BIND(L_pre_main_post_64);\n+        \/\/ Partial copy to make dst address 64 byte aligned.\n+        __ movq(temp2, to);\n+        __ andq(temp2, 63);\n+        __ jcc(Assembler::equal, L_main_pre_loop_64bytes);\n+\n+        __ negptr(temp2);\n+        __ addq(temp2, 64);\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ movq(temp3, temp2);\n+        __ copy64_masked_avx(to, from, xmm1, k2, temp3, temp4, temp1, shift, 0 , true);\n+        __ movq(temp4, temp2);\n+        __ movq(temp1, count);\n+        __ subq(temp1, temp2);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail64);\n+\n+        __ BIND(L_main_pre_loop_64bytes);\n+        __ subq(temp1, loop_size[shift]);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at\n+        \/\/ 64 byte copy granularity.\n+        __ BIND(L_main_loop_64bytes);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 0 , true);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 64, true);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 128, true);\n+           __ addptr(temp4, loop_size[shift]);\n+           __ subq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop_64bytes);\n+\n+        __ addq(temp1, loop_size[shift]);\n+        \/\/ Zero length check.\n+        __ jcc(Assembler::lessEqual, L_exit);\n+\n+        __ BIND(L_tail64);\n+\n+        \/\/ Tail handling using 64 byte [masked] vector copy operations.\n+        use64byteVector = true;\n+        __ arraycopy_avx3_special_cases(xmm1, k2, from, to, temp1, shift,\n+                                        temp4, temp3, use64byteVector, L_entry, L_exit);\n+      }\n+      __ BIND(L_exit);\n+    }\n+\n+    address ucme_exit_pc = __ pc();\n+    \/\/ When called from generic_arraycopy r11 contains specific values\n+    \/\/ used during arraycopy epilogue, re-initializing r11.\n+    if (is_oop) {\n+      __ movq(r11, shift == 3 ? count : to);\n+    }\n+    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n+    restore_argument_regs(type);\n+    inc_counter_np(get_profile_ctr(shift)); \/\/ Update counter after rscratch1 is free\n+    __ xorptr(rax, rax); \/\/ return 0\n+    __ vzeroupper();\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+    return start;\n+  }\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source array address\n+  \/\/   c_rarg1   - destination array address\n+  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n+  \/\/\n+  \/\/\n+  address generate_conjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n+                                             address nooverlap_target, bool aligned, bool is_oop,\n+                                             bool dest_uninitialized) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    bool use64byteVector = MaxVectorSize > 32 && AVX3Threshold == 0;\n+\n+    Label L_main_pre_loop, L_main_pre_loop_64bytes, L_pre_main_post_64;\n+    Label L_main_loop, L_main_loop_64bytes, L_tail, L_tail64, L_exit, L_entry;\n+    const Register from        = rdi;  \/\/ source array address\n+    const Register to          = rsi;  \/\/ destination array address\n+    const Register count       = rdx;  \/\/ elements count\n+    const Register temp1       = r8;\n+    const Register temp2       = rcx;\n+    const Register temp3       = r11;\n+    const Register temp4       = rax;\n+    \/\/ End pointers are inclusive, and if count is not zero they point\n+    \/\/ to the last unit copied:  end_to[0] := end_from[0]\n+\n+    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    assert_clean_int(c_rarg2, rax);    \/\/ Make sure 'count' is clean int.\n+\n+    if (entry != NULL) {\n+      *entry = __ pc();\n+       \/\/ caller can pass a 64-bit byte count here (from Unsafe.copyMemory)\n+      BLOCK_COMMENT(\"Entry:\");\n+    }\n+\n+    array_overlap_test(nooverlap_target, (Address::ScaleFactor)(shift));\n+\n+    BasicType type_vec[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+    BasicType type = is_oop ? T_OBJECT : type_vec[shift];\n+\n+    setup_argument_regs(type);\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    if (dest_uninitialized) {\n+      decorators |= IS_DEST_UNINITIALIZED;\n+    }\n+    if (aligned) {\n+      decorators |= ARRAYCOPY_ALIGNED;\n+    }\n+    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n+    {\n+      \/\/ Type(shift)       byte(0), short(1), int(2),   long(3)\n+      int loop_size[]   = { 192,     96,       48,      24};\n+      int threshold[]   = { 4096,    2048,     1024,    512};\n+\n+      \/\/ UnsafeCopyMemory page error: continue after ucm\n+      UnsafeCopyMemoryMark ucmm(this, !is_oop && !aligned, true);\n+      \/\/ 'from', 'to' and 'count' are now valid\n+\n+      \/\/ temp1 holds remaining count.\n+      __ movq(temp1, count);\n+\n+      \/\/ Zero length check.\n+      __ BIND(L_tail);\n+      __ cmpq(temp1, 0);\n+      __ jcc(Assembler::lessEqual, L_exit);\n+\n+      __ mov64(temp2, 0);\n+      __ movq(temp3, temp1);\n+      \/\/ Special cases using 32 byte [masked] vector copy operations.\n+      __ arraycopy_avx3_special_cases_conjoint(xmm1, k2, from, to, temp2, temp3, temp1, shift,\n+                                               temp4, use64byteVector, L_entry, L_exit);\n+\n+      \/\/ PRE-MAIN-POST loop for aligned copy.\n+      __ BIND(L_entry);\n+\n+      if (MaxVectorSize > 32 && AVX3Threshold != 0) {\n+        __ cmpq(temp1, threshold[shift]);\n+        __ jcc(Assembler::greaterEqual, L_pre_main_post_64);\n+      }\n+\n+      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+        \/\/ Partial copy to make dst address 32 byte aligned.\n+        __ leaq(temp2, Address(to, temp1, (Address::ScaleFactor)(shift), 0));\n+        __ andq(temp2, 31);\n+        __ jcc(Assembler::equal, L_main_pre_loop);\n+\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ subq(temp1, temp2);\n+        __ copy32_masked_avx(to, from, xmm1, k2, temp2, temp1, temp3, shift);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail);\n+\n+        __ BIND(L_main_pre_loop);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at 32 byte granularity.\n+        __ BIND(L_main_loop);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -64);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -128);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -192);\n+           __ subptr(temp1, loop_size[shift]);\n+           __ cmpq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop);\n+\n+        \/\/ Tail loop.\n+        __ jmp(L_tail);\n+      }\n+\n+      if (MaxVectorSize > 32) {\n+        __ BIND(L_pre_main_post_64);\n+        \/\/ Partial copy to make dst address 64 byte aligned.\n+        __ leaq(temp2, Address(to, temp1, (Address::ScaleFactor)(shift), 0));\n+        __ andq(temp2, 63);\n+        __ jcc(Assembler::equal, L_main_pre_loop_64bytes);\n+\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ subq(temp1, temp2);\n+        __ copy64_masked_avx(to, from, xmm1, k2, temp2, temp1, temp3, shift, 0 , true);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail64);\n+\n+        __ BIND(L_main_pre_loop_64bytes);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at\n+        \/\/ 64 byte copy granularity.\n+        __ BIND(L_main_loop_64bytes);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -64 , true);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -128, true);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -192, true);\n+           __ subq(temp1, loop_size[shift]);\n+           __ cmpq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop_64bytes);\n+\n+        \/\/ Zero length check.\n+        __ cmpq(temp1, 0);\n+        __ jcc(Assembler::lessEqual, L_exit);\n+\n+        __ BIND(L_tail64);\n+\n+        \/\/ Tail handling using 64 byte [masked] vector copy operations.\n+        use64byteVector = true;\n+        __ mov64(temp2, 0);\n+        __ movq(temp3, temp1);\n+        __ arraycopy_avx3_special_cases_conjoint(xmm1, k2, from, to, temp2, temp3, temp1, shift,\n+                                                 temp4, use64byteVector, L_entry, L_exit);\n+      }\n+      __ BIND(L_exit);\n+    }\n+    address ucme_exit_pc = __ pc();\n+    \/\/ When called from generic_arraycopy r11 contains specific values\n+    \/\/ used during arraycopy epilogue, re-initializing r11.\n+    if(is_oop) {\n+      __ movq(r11, count);\n+    }\n+    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n+    restore_argument_regs(type);\n+    inc_counter_np(get_profile_ctr(shift)); \/\/ Update counter after rscratch1 is free\n+    __ xorptr(rax, rax); \/\/ return 0\n+    __ vzeroupper();\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+    return start;\n+  }\n+#endif \/\/ COMPILER2_OR_JVMCI\n+\n+\n@@ -1689,0 +2065,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jbyte_disjoint_arraycopy_avx3\", 0,\n+                                                 aligned, false, false);\n+    }\n+#endif\n@@ -1799,0 +2181,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jbyte_conjoint_arraycopy_avx3\", 0,\n+                                                 nooverlap_target, aligned, false, false);\n+    }\n+#endif\n@@ -1904,0 +2292,7 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jshort_disjoint_arraycopy_avx3\", 1,\n+                                                 aligned, false, false);\n+    }\n+#endif\n+\n@@ -2028,0 +2423,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jshort_conjoint_arraycopy_avx3\", 1,\n+                                                 nooverlap_target, aligned, false, false);\n+    }\n+#endif\n@@ -2126,0 +2527,7 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jint_disjoint_arraycopy_avx3\", 2,\n+                                                 aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n+\n@@ -2230,0 +2638,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jint_conjoint_arraycopy_avx3\", 2,\n+                                                 nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n@@ -2337,0 +2751,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jlong_disjoint_arraycopy_avx3\", 3,\n+                                                 aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n@@ -2441,0 +2861,6 @@\n+#if COMPILER2_OR_JVMCI\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jlong_conjoint_arraycopy_avx3\", 3,\n+                                                 nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    }\n+#endif\n@@ -2859,1 +3285,1 @@\n-    Label L_copy_bytes, L_copy_shorts, L_copy_ints, L_copy_longs;\n+    Label L_copy_shorts, L_copy_ints, L_copy_longs;\n@@ -2870,1 +3296,1 @@\n-    const Address  length(rsp, 6 * wordSize);  \/\/ elements count is on stack on Win64\n+    const Address  length(rsp, 7 * wordSize);  \/\/ elements count is on stack on Win64\n@@ -2892,0 +3318,4 @@\n+#ifdef _WIN64\n+    __ push(rklass_tmp); \/\/ rdi is callee-save on Windows\n+#endif\n+\n@@ -3022,0 +3452,4 @@\n+#ifdef _WIN64\n+    __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n+\n@@ -3030,1 +3464,0 @@\n-  __ BIND(L_copy_bytes);\n@@ -3091,0 +3524,3 @@\n+#ifdef _WIN64\n+    __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n@@ -3130,0 +3566,4 @@\n+#ifdef _WIN64\n+      __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n+\n@@ -3139,0 +3579,3 @@\n+#ifdef _WIN64\n+    __ pop(rklass_tmp); \/\/ Restore callee-save rdi\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":542,"deletions":99,"binary":false,"changes":641,"status":"modified"},{"patch":"@@ -11929,1 +11929,1 @@\n-instruct string_indexofU_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n+instruct string_indexof_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n@@ -11931,1 +11931,1 @@\n-  predicate(UseSSE42Intrinsics);\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U));\n@@ -11934,1 +11934,1 @@\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n@@ -11942,0 +11942,14 @@\n+instruct stringL_indexof_char(eDIRegP str1, eDXRegI cnt1, eAXRegI ch,\n+                              eBXRegI result, regD vec1, regD vec2, regD vec3, eCXRegI tmp, eFlagsReg cr) %{\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L));\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  effect(TEMP vec1, TEMP vec2, TEMP vec3, USE_KILL str1, USE_KILL cnt1, USE_KILL ch, TEMP tmp, KILL cr);\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  ins_encode %{\n+    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,\n+                           $vec1$$XMMRegister, $vec2$$XMMRegister, $vec3$$XMMRegister, $tmp$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":17,"deletions":3,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -935,2 +935,2 @@\n-    st->print_cr(\"movq    rscratch1, poll_offset[r15_thread] #polling_page_address\\n\\t\"\n-                 \"testl   rax, [rscratch1]\\t\"\n+    st->print_cr(\"cmpq    poll_offset[r15_thread], rsp\\n\\t\"\n+                 \"ja      #safepoint_stub\\t\"\n@@ -983,1 +983,5 @@\n-    __ movq(rscratch1, Address(r15_thread, Thread::polling_page_offset()));\n+    Label dummy_label;\n+    Label* code_stub = &dummy_label;\n+    if (!C->output()->in_scratch_emit_size()) {\n+      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+    }\n@@ -985,1 +989,1 @@\n-    __ testl(rax, Address(rscratch1, 0));\n+    __ safepoint_poll(*code_stub, r15_thread, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -2959,0 +2963,10 @@\n+operand immU7()\n+%{\n+  predicate((0 <= n->get_int()) && (n->get_int() <= 0x7F));\n+  match(ConI);\n+\n+  op_cost(5);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4300,10 +4314,0 @@\n-\/\/ Long ALU reg operation using big decoder\n-pipe_class ialu_reg_long_fat(rRegL dst)\n-%{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    dst    : S3(read);\n-    D0     : S0(2);     \/\/ big decoder only; twice\n-    ALU    : S3(2);     \/\/ any 2 alus\n-%}\n-\n@@ -4320,10 +4324,0 @@\n-\/\/ Long ALU reg-reg operation\n-pipe_class ialu_reg_reg_long(rRegL dst, rRegL src)\n-%{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    src    : S3(read);\n-    DECODE : S0(2);     \/\/ any 2 decoders\n-    ALU    : S3(2);     \/\/ both alus\n-%}\n-\n@@ -4340,10 +4334,0 @@\n-\/\/ Long ALU reg-reg operation\n-pipe_class ialu_reg_reg_long_fat(rRegL dst, rRegL src)\n-%{\n-    instruction_count(2);\n-    dst    : S4(write);\n-    src    : S3(read);\n-    D0     : S0(2);     \/\/ big decoder only; twice\n-    ALU    : S3(2);     \/\/ both alus\n-%}\n-\n@@ -11107,1 +11091,1 @@\n-instruct string_indexofU_char(rdi_RegP str1, rdx_RegI cnt1, rax_RegI ch,\n+instruct string_indexof_char(rdi_RegP str1, rdx_RegI cnt1, rax_RegI ch,\n@@ -11110,1 +11094,1 @@\n-  predicate(UseSSE42Intrinsics);\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U));\n@@ -11113,1 +11097,1 @@\n-  format %{ \"String IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n@@ -11121,0 +11105,14 @@\n+instruct stringL_indexof_char(rdi_RegP str1, rdx_RegI cnt1, rax_RegI ch,\n+                              rbx_RegI result, legRegD tmp_vec1, legRegD tmp_vec2, legRegD tmp_vec3, rcx_RegI tmp, rFlagsReg cr)\n+%{\n+  predicate(UseSSE42Intrinsics && (((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L));\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  effect(TEMP tmp_vec1, TEMP tmp_vec2, TEMP tmp_vec3, USE_KILL str1, USE_KILL cnt1, USE_KILL ch, TEMP tmp, KILL cr);\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result   \/\/ KILL all\" %}\n+  ins_encode %{\n+    __ stringL_indexof_char($str1$$Register, $cnt1$$Register, $ch$$Register, $result$$Register,\n+                           $tmp_vec1$$XMMRegister, $tmp_vec2$$XMMRegister, $tmp_vec3$$XMMRegister, $tmp$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -11847,1 +11845,1 @@\n-instruct testUB_mem_imm(rFlagsReg cr, memory mem, immU8 imm, immI_0 zero)\n+instruct testUB_mem_imm(rFlagsReg cr, memory mem, immU7 imm, immI_0 zero)\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":36,"deletions":38,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -52,0 +52,8 @@\n+  product(bool, StressIGVN, false, DIAGNOSTIC,                              \\\n+          \"Randomize worklist traversal in IGVN\")                           \\\n+                                                                            \\\n+  product(uint, StressSeed, 0, DIAGNOSTIC,                                  \\\n+          \"Seed for randomized stress testing (if unset, a random one is \"  \\\n+          \"generated)\")                                                     \\\n+          range(0, max_juint)                                               \\\n+                                                                            \\\n@@ -100,0 +108,4 @@\n+  notproduct(uintx, PrintIdealIndentThreshold, 0,                           \\\n+          \"A depth threshold of ideal graph. Indentation is disabled \"      \\\n+          \"when users attempt to dump an ideal graph deeper than it.\")      \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -465,1 +465,1 @@\n-      map->disconnect_inputs(NULL, C);\n+      map->disconnect_inputs(C);\n@@ -492,1 +492,0 @@\n-    C->set_has_loops(C->has_loops() || _inline_cg->method()->has_loops());\n@@ -744,1 +743,1 @@\n-      map->disconnect_inputs(NULL, C);\n+      map->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+#include \"runtime\/globals_extension.hpp\"\n@@ -579,0 +580,1 @@\n+                  _stress_seed(0),\n@@ -784,0 +786,12 @@\n+  \/\/ If LCM, GCM, or IGVN are randomized for stress testing, seed\n+  \/\/ random number generation and log the seed for repeatability.\n+  if (StressLCM || StressGCM || StressIGVN) {\n+    _stress_seed = FLAG_IS_DEFAULT(StressSeed) ?\n+      static_cast<uint>(Ticks::now().nanoseconds()) : StressSeed;\n+    if (_log != NULL) {\n+      _log->elem(\"stress_test seed='%u'\", _stress_seed);\n+    } else if (FLAG_IS_DEFAULT(StressSeed)) {\n+      tty->print_cr(\"Warning:  set +LogCompilation to log the seed.\");\n+    }\n+  }\n+\n@@ -866,0 +880,1 @@\n+    _stress_seed(0),\n@@ -964,1 +979,1 @@\n-  set_has_loops(has_method() && method()->has_loops()); \/\/ first approximation\n+  set_has_loops(false); \/\/ first approximation\n@@ -1064,0 +1079,1 @@\n+  _exception_backedge = false;\n@@ -2895,1 +2911,1 @@\n-        mem->disconnect_inputs(NULL, this);\n+        mem->disconnect_inputs(this);\n@@ -3179,1 +3195,1 @@\n-            addp->disconnect_inputs(NULL, this);\n+            addp->disconnect_inputs(this);\n@@ -3252,1 +3268,1 @@\n-        in1->disconnect_inputs(NULL, this);\n+        in1->disconnect_inputs(this);\n@@ -3257,1 +3273,1 @@\n-        n->disconnect_inputs(NULL, this);\n+        n->disconnect_inputs(this);\n@@ -3335,1 +3351,1 @@\n-          in1->disconnect_inputs(NULL, this);\n+          in1->disconnect_inputs(this);\n@@ -3338,1 +3354,1 @@\n-          in2->disconnect_inputs(NULL, this);\n+          in2->disconnect_inputs(this);\n@@ -3369,1 +3385,1 @@\n-      in1->disconnect_inputs(NULL, this);\n+      in1->disconnect_inputs(this);\n@@ -3529,1 +3545,1 @@\n-        in2->disconnect_inputs(NULL, this);\n+        in2->disconnect_inputs(this);\n@@ -3561,1 +3577,1 @@\n-          m->disconnect_inputs(NULL, this);\n+          m->disconnect_inputs(this);\n@@ -3704,1 +3720,1 @@\n-          in->disconnect_inputs(NULL, this);\n+          in->disconnect_inputs(this);\n@@ -4573,2 +4589,7 @@\n-\/\/ Auxiliary method to support randomized stressing\/fuzzing.\n-\/\/\n+\/\/ Auxiliary methods to support randomized stressing\/fuzzing.\n+\n+int Compile::random() {\n+  _stress_seed = os::next_random(_stress_seed);\n+  return static_cast<int>(_stress_seed);\n+}\n+\n@@ -4605,1 +4626,1 @@\n-  return (os::random() & RANDOMIZED_DOMAIN_MASK) < (RANDOMIZED_DOMAIN \/ count);\n+  return (random() & RANDOMIZED_DOMAIN_MASK) < (RANDOMIZED_DOMAIN \/ count);\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":35,"deletions":14,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -72,1 +72,0 @@\n-class PhaseCCP_DCE;\n@@ -304,0 +303,1 @@\n+  uint                  _stress_seed;           \/\/ Seed for stress testing\n@@ -434,0 +434,1 @@\n+  DEBUG_ONLY(bool _exception_backedge;)\n@@ -1157,2 +1158,3 @@\n-  \/\/ Auxiliary method for randomized fuzzing\/stressing\n-  static bool randomized_select(int count);\n+  \/\/ Auxiliary methods for randomized fuzzing\/stressing\n+  int random();\n+  bool randomized_select(int count);\n@@ -1185,0 +1187,2 @@\n+  void set_exception_backedge() { _exception_backedge = true; }\n+  bool has_exception_backedge() const { return _exception_backedge; }\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,0 +41,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -675,1 +676,0 @@\n-    C->set_has_loops(C->has_loops() || cg->method()->has_loops());\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -166,1 +166,1 @@\n-    dead_map->disconnect_inputs(NULL, C); \/\/ Mark the map as killed.\n+    dead_map->disconnect_inputs(C); \/\/ Mark the map as killed.\n@@ -1963,1 +1963,1 @@\n-  call->disconnect_inputs(NULL, C);\n+  call->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -452,1 +452,1 @@\n-      in->disconnect_inputs(NULL, C);\n+      in->disconnect_inputs(C);\n@@ -635,1 +635,1 @@\n-         ((StressLCM && Compile::randomized_select(cand_cnt)) ||\n+         ((StressLCM && C->randomized_select(cand_cnt)) ||\n@@ -1374,1 +1374,1 @@\n-    block->get_node(beg)->disconnect_inputs(NULL, C);\n+    block->get_node(beg)->disconnect_inputs(C);\n@@ -1387,1 +1387,1 @@\n-        n->disconnect_inputs(NULL, C);\n+        n->disconnect_inputs(C);\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -193,1 +193,1 @@\n-  bool inline_string_indexOfChar();\n+  bool inline_string_indexOfChar(StrIntrinsicNode::ArgEnc ae);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2016, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -333,0 +333,1 @@\n+  , _indent(0)\n@@ -353,0 +354,1 @@\n+  , _indent(0)\n@@ -366,0 +368,1 @@\n+  , _indent(0)\n@@ -381,0 +384,1 @@\n+  , _indent(0)\n@@ -398,0 +402,1 @@\n+  , _indent(0)\n@@ -417,0 +422,1 @@\n+  , _indent(0)\n@@ -439,0 +445,1 @@\n+  , _indent(0)\n@@ -463,0 +470,1 @@\n+  , _indent(0)\n@@ -585,1 +593,2 @@\n-  \/\/ Eagerly reclaim unique Node numberings\n+  \/\/ If this is the most recently created node, reclaim its index. Otherwise,\n+  \/\/ record the node as dead to keep liveness information accurate.\n@@ -589,0 +598,2 @@\n+  } else {\n+    compile->record_dead_node(_idx);\n@@ -893,9 +904,5 @@\n-\/\/ Return the number of edges between 'n' and 'this'\n-int Node::disconnect_inputs(Node *n, Compile* C) {\n-  int edges_to_n = 0;\n-\n-  uint cnt = req();\n-  for( uint i = 0; i < cnt; ++i ) {\n-    if( in(i) == 0 ) continue;\n-    if( in(i) == n ) ++edges_to_n;\n-    set_req(i, NULL);\n+void Node::disconnect_inputs(Compile* C) {\n+  for (uint i = 0; i < req(); ++i) {\n+    if (in(i) != nullptr) {\n+      set_req(i, nullptr);\n+    }\n@@ -903,0 +910,1 @@\n+\n@@ -905,7 +913,2 @@\n-  if( (req() != len()) && (in(req()) != NULL) ) {\n-    uint max = len();\n-    for( uint i = 0; i < max; ++i ) {\n-      if( in(i) == 0 ) continue;\n-      if( in(i) == n ) ++edges_to_n;\n-      set_prec(i, NULL);\n-    }\n+  for (uint i = req(); i < len(); ++i) {\n+    set_prec(i, nullptr);\n@@ -916,4 +919,1 @@\n-  if (edges_to_n == 0) {\n-    C->record_dead_node(_idx);\n-  }\n-  return edges_to_n;\n+  C->record_dead_node(_idx);\n@@ -1049,1 +1049,1 @@\n-  assert(_max_classes <= max_jushort, \"too many NodeProperty classes\");\n+  assert(_max_classes <= max_juint, \"too many NodeProperty classes\");\n@@ -1728,1 +1728,6 @@\n-  st->print(\"%c%d%s\\t%s\\t=== \", is_new ? ' ' : 'o', _idx, mark ? \" >\" : \"\", Name());\n+\n+  if (_indent > 0) {\n+    st->print(\"%*s\", (_indent << 1), \"  \");\n+  }\n+\n+  st->print(\"%c%d%s%s  === \", is_new ? ' ' : 'o', _idx, mark ? \" >\" : \"  \", Name());\n@@ -1853,1 +1858,1 @@\n-\/\/   nstack:        the nodes are collected into this array.\n+\/\/   queue:         the nodes are collected into this array.\n@@ -1861,1 +1866,2 @@\n-static void collect_nodes_i(GrowableArray<Node*> *nstack, const Node* start, int direction, uint depth, bool include_start, bool only_ctrl, bool only_data) {\n+static void collect_nodes_i(GrowableArray<Node*>* queue, const Node* start, int direction, uint depth, bool include_start, bool only_ctrl, bool only_data) {\n+  bool indent = depth <= PrintIdealIndentThreshold;\n@@ -1863,1 +1869,1 @@\n-  nstack->append(s);\n+  queue->append(s);\n@@ -1866,0 +1872,2 @@\n+\n+  s->set_indent(0);\n@@ -1867,1 +1875,1 @@\n-    end = nstack->length();\n+    end = queue->length();\n@@ -1869,1 +1877,1 @@\n-      Node* tp  = nstack->at(j);\n+      Node* tp  = queue->at(j);\n@@ -1879,4 +1887,4 @@\n-\n-        bool on_stack = nstack->contains(n);\n-        if (!on_stack) {\n-          nstack->append(n);\n+        bool in_queue = queue->contains(n);\n+        if (!in_queue) {\n+          queue->append(n);\n+          n->set_indent(indent ? (i + 1) : 0);\n@@ -1889,1 +1897,1 @@\n-    nstack->remove(s);\n+    queue->remove(s);\n@@ -1897,2 +1905,2 @@\n-  GrowableArray <Node *> nstack(Compile::current()->live_nodes());\n-  collect_nodes_i(&nstack, start, d, (uint) ABS(d), true, only_ctrl, false);\n+  GrowableArray <Node *> queue(Compile::current()->live_nodes());\n+  collect_nodes_i(&queue, start, d, (uint) ABS(d), true, only_ctrl, false);\n@@ -1900,1 +1908,1 @@\n-  int end = nstack.length();\n+  int end = queue.length();\n@@ -1903,1 +1911,1 @@\n-      nstack.at(j)->dump();\n+      queue.at(j)->dump();\n@@ -1907,1 +1915,1 @@\n-      nstack.at(j)->dump();\n+      queue.at(j)->dump();\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":47,"deletions":39,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -227,0 +227,66 @@\n+volatile int C2SafepointPollStubTable::_stub_size = 0;\n+\n+Label& C2SafepointPollStubTable::add_safepoint(uintptr_t safepoint_offset) {\n+  C2SafepointPollStub* entry = new (Compile::current()->comp_arena()) C2SafepointPollStub(safepoint_offset);\n+  _safepoints.append(entry);\n+  return entry->_stub_label;\n+}\n+\n+void C2SafepointPollStubTable::emit(CodeBuffer& cb) {\n+  MacroAssembler masm(&cb);\n+  for (int i = _safepoints.length() - 1; i >= 0; i--) {\n+    \/\/ Make sure there is enough space in the code buffer\n+    if (cb.insts()->maybe_expand_to_ensure_remaining(PhaseOutput::MAX_inst_size) && cb.blob() == NULL) {\n+      ciEnv::current()->record_failure(\"CodeCache is full\");\n+      return;\n+    }\n+\n+    C2SafepointPollStub* entry = _safepoints.at(i);\n+    emit_stub(masm, entry);\n+  }\n+}\n+\n+int C2SafepointPollStubTable::stub_size_lazy() const {\n+  int size = Atomic::load(&_stub_size);\n+\n+  if (size != 0) {\n+    return size;\n+  }\n+\n+  Compile* const C = Compile::current();\n+  BufferBlob* const blob = C->output()->scratch_buffer_blob();\n+  CodeBuffer cb(blob->content_begin(), C->output()->scratch_buffer_code_size());\n+  MacroAssembler masm(&cb);\n+  C2SafepointPollStub* entry = _safepoints.at(0);\n+  emit_stub(masm, entry);\n+  size += cb.insts_size();\n+\n+  Atomic::store(&_stub_size, size);\n+\n+  return size;\n+}\n+\n+int C2SafepointPollStubTable::estimate_stub_size() const {\n+  if (_safepoints.length() == 0) {\n+    return 0;\n+  }\n+\n+  int result = stub_size_lazy() * _safepoints.length();\n+\n+#ifdef ASSERT\n+  Compile* const C = Compile::current();\n+  BufferBlob* const blob = C->output()->scratch_buffer_blob();\n+  int size = 0;\n+\n+  for (int i = _safepoints.length() - 1; i >= 0; i--) {\n+    CodeBuffer cb(blob->content_begin(), C->output()->scratch_buffer_code_size());\n+    MacroAssembler masm(&cb);\n+    C2SafepointPollStub* entry = _safepoints.at(i);\n+    emit_stub(masm, entry);\n+    size += cb.insts_size();\n+  }\n+  assert(size == result, \"stubs should not have variable size\");\n+#endif\n+\n+  return result;\n+}\n@@ -1242,0 +1308,1 @@\n+  stub_req += safepoint_poll_table()->estimate_stub_size();\n@@ -1744,0 +1811,4 @@\n+  \/\/ Fill in stubs for calling the runtime from safepoint polls.\n+  safepoint_poll_table()->emit(*cb);\n+  if (C->failing())  return;\n+\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":71,"deletions":0,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -978,20 +978,5 @@\n-\/**\n- * Initialize worklist for each node.\n- *\/\n-void PhaseIterGVN::init_worklist(Node* first) {\n-  Unique_Node_List to_process;\n-  to_process.push(first);\n-\n-  while (to_process.size() > 0) {\n-    Node* n = to_process.pop();\n-    if (!_worklist.member(n)) {\n-      _worklist.push(n);\n-\n-      uint cnt = n->req();\n-      for(uint i = 0; i < cnt; i++) {\n-        Node* m = n->in(i);\n-        if (m != NULL) {\n-          to_process.push(m);\n-        }\n-      }\n-    }\n+void PhaseIterGVN::shuffle_worklist() {\n+  if (_worklist.size() < 2) return;\n+  for (uint i = _worklist.size() - 1; i >= 1; i--) {\n+    uint j = C->random() % (i + 1);\n+    swap(_worklist.adr()[i], _worklist.adr()[j]);\n@@ -1155,0 +1140,3 @@\n+  if (StressIGVN) {\n+    shuffle_worklist();\n+  }\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":8,"deletions":20,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+#include \"runtime\/stackWatermarkSet.hpp\"\n@@ -1308,1 +1309,0 @@\n-\n@@ -1366,1 +1366,1 @@\n-    bool force_unwind = !thread->reguard_stack();\n+    bool force_unwind = !thread->stack_overflow_state()->reguard_stack();\n@@ -1486,0 +1486,5 @@\n+  \/\/ The frame we rethrow the exception to might not have been processed by the GC yet.\n+  \/\/ The stack watermark barrier takes care of detecting that and ensuring the frame\n+  \/\/ has updated oops.\n+  StackWatermarkSet::after_unwind(thread);\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -44,2 +44,1 @@\n-#include \"runtime\/flags\/jvmFlagConstraintList.hpp\"\n-#include \"runtime\/flags\/jvmFlagRangeList.hpp\"\n+#include \"runtime\/flags\/jvmFlagAccess.hpp\"\n@@ -557,0 +556,1 @@\n+  { \"Debugging\",                     JDK_Version::undefined(), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n@@ -880,1 +880,1 @@\n-  if (JVMFlag::boolAtPut(flag, &value, origin) == JVMFlag::SUCCESS) {\n+  if (JVMFlagAccess::boolAtPut(flag, &value, origin) == JVMFlag::SUCCESS) {\n@@ -895,1 +895,1 @@\n-  if (JVMFlag::doubleAtPut(flag, &v, origin) == JVMFlag::SUCCESS) {\n+  if (JVMFlagAccess::doubleAtPut(flag, &v, origin) == JVMFlag::SUCCESS) {\n@@ -927,1 +927,1 @@\n-    return JVMFlag::intAtPut(flag, &int_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::intAtPut(flag, &int_v, origin) == JVMFlag::SUCCESS;\n@@ -930,1 +930,1 @@\n-    return JVMFlag::uintAtPut(flag, &uint_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::uintAtPut(flag, &uint_v, origin) == JVMFlag::SUCCESS;\n@@ -936,1 +936,1 @@\n-    return JVMFlag::intxAtPut(flag, &intx_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::intxAtPut(flag, &intx_v, origin) == JVMFlag::SUCCESS;\n@@ -939,1 +939,1 @@\n-    return JVMFlag::uintxAtPut(flag, &uintx_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::uintxAtPut(flag, &uintx_v, origin) == JVMFlag::SUCCESS;\n@@ -942,1 +942,1 @@\n-    return JVMFlag::uint64_tAtPut(flag, &uint64_t_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::uint64_tAtPut(flag, &uint64_t_v, origin) == JVMFlag::SUCCESS;\n@@ -945,1 +945,1 @@\n-    return JVMFlag::size_tAtPut(flag, &size_t_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::size_tAtPut(flag, &size_t_v, origin) == JVMFlag::SUCCESS;\n@@ -948,1 +948,1 @@\n-    return JVMFlag::doubleAtPut(flag, &double_v, origin) == JVMFlag::SUCCESS;\n+    return JVMFlagAccess::doubleAtPut(flag, &double_v, origin) == JVMFlag::SUCCESS;\n@@ -955,1 +955,1 @@\n-  if (JVMFlag::ccstrAtPut(flag, &value, origin) != JVMFlag::SUCCESS) return false;\n+  if (JVMFlagAccess::ccstrAtPut(flag, &value, origin) != JVMFlag::SUCCESS) return false;\n@@ -963,1 +963,1 @@\n-  if (JVMFlag::ccstrAt(flag, &old_value) != JVMFlag::SUCCESS) return false;\n+  if (JVMFlagAccess::ccstrAt(flag, &old_value) != JVMFlag::SUCCESS) return false;\n@@ -980,1 +980,1 @@\n-  (void) JVMFlag::ccstrAtPut(flag, &value, origin);\n+  (void) JVMFlagAccess::ccstrAtPut(flag, &value, origin);\n@@ -1358,1 +1358,1 @@\n-                  fuzzy_matched->_name,\n+                  fuzzy_matched->name(),\n@@ -3235,1 +3235,0 @@\n-  NOT_PRODUCT(UNSUPPORTED_OPTION(TraceProfileInterpreter));\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":15,"deletions":16,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -269,1 +269,0 @@\n-  static address native_method_throw_unsupported_operation_exception_entry();\n@@ -359,4 +358,0 @@\n-  static address clean_virtual_call_entry();\n-  static address clean_opt_virtual_call_entry();\n-  static address clean_static_call_entry();\n-\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -299,0 +299,1 @@\n+  AOT_ONLY(nonstatic_field(MethodCounters,     _method,                                       Method*))                              \\\n@@ -742,1 +743,1 @@\n-  nonstatic_field(NamedThread,                 _processed_thread,                             JavaThread*)                           \\\n+  nonstatic_field(NamedThread,                 _processed_thread,                             Thread*)                               \\\n@@ -1011,1 +1012,1 @@\n-  nonstatic_field(JVMFlag,                     _type,                                         const char*)                           \\\n+  nonstatic_field(JVMFlag,                     _type,                                         int)                                   \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -310,2 +310,2 @@\n-    tty->print(\"Growable Array \" INTPTR_FORMAT, this);\n-    tty->print(\": length %ld (_max %ld) { \", _len, _max);\n+    tty->print(\"Growable Array \" INTPTR_FORMAT, p2i(this));\n+    tty->print(\": length %d (_max %d) { \", _len, _max);\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-import jdk.internal.HotSpotIntrinsicCandidate;\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n@@ -147,1 +147,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -162,1 +162,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -175,1 +175,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -189,1 +189,1 @@\n-    \/\/FIXME @HotSpotIntrinsicCandidate\n+    \/\/FIXME @IntrinsicCandidate\n@@ -201,1 +201,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -217,1 +217,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -233,1 +233,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -245,1 +245,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -257,1 +257,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -273,1 +273,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -291,1 +291,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -308,1 +308,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -326,1 +326,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -344,1 +344,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -358,1 +358,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -374,1 +374,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -393,1 +393,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -413,1 +413,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -431,1 +431,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -451,1 +451,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -466,1 +466,1 @@\n-    @HotSpotIntrinsicCandidate\n+    @IntrinsicCandidate\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":22,"deletions":22,"binary":false,"changes":44,"status":"modified"},{"patch":"","filename":"test\/jdk\/jdk\/incubator\/vector\/templates\/Unit-Test.template","additions":0,"deletions":0,"binary":false,"changes":0,"status":"modified"}]}