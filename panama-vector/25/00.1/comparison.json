{"files":[{"patch":"@@ -1483,15 +1483,15 @@\n-generate(SpecialCases, [[\"ccmn\",   \"__ ccmn(zr, zr, 3u, Assembler::LE);\",                \"ccmn\\txzr, xzr, #3, LE\"],\n-                        [\"ccmnw\",  \"__ ccmnw(zr, zr, 5u, Assembler::EQ);\",               \"ccmn\\twzr, wzr, #5, EQ\"],\n-                        [\"ccmp\",   \"__ ccmp(zr, 1, 4u, Assembler::NE);\",                 \"ccmp\\txzr, 1, #4, NE\"],\n-                        [\"ccmpw\",  \"__ ccmpw(zr, 2, 2, Assembler::GT);\",                 \"ccmp\\twzr, 2, #2, GT\"],\n-                        [\"extr\",   \"__ extr(zr, zr, zr, 0);\",                            \"extr\\txzr, xzr, xzr, 0\"],\n-                        [\"stlxp\",  \"__ stlxp(r0, zr, zr, sp);\",                          \"stlxp\\tw0, xzr, xzr, [sp]\"],\n-                        [\"stlxpw\", \"__ stlxpw(r2, zr, zr, r3);\",                         \"stlxp\\tw2, wzr, wzr, [x3]\"],\n-                        [\"stxp\",   \"__ stxp(r4, zr, zr, r5);\",                           \"stxp\\tw4, xzr, xzr, [x5]\"],\n-                        [\"stxpw\",  \"__ stxpw(r6, zr, zr, sp);\",                          \"stxp\\tw6, wzr, wzr, [sp]\"],\n-                        [\"dup\",    \"__ dup(v0, __ T16B, zr);\",                           \"dup\\tv0.16b, wzr\"],\n-                        [\"mov\",    \"__ mov(v1, __ T1D, 0, zr);\",                         \"mov\\tv1.d[0], xzr\"],\n-                        [\"mov\",    \"__ mov(v1, __ T2S, 1, zr);\",                         \"mov\\tv1.s[1], wzr\"],\n-                        [\"mov\",    \"__ mov(v1, __ T4H, 2, zr);\",                         \"mov\\tv1.h[2], wzr\"],\n-                        [\"mov\",    \"__ mov(v1, __ T8B, 3, zr);\",                         \"mov\\tv1.b[3], wzr\"],\n-                        [\"ld1\",    \"__ ld1(v31, v0, __ T2D, Address(__ post(r1, r0)));\", \"ld1\\t{v31.2d, v0.2d}, [x1], x0\"],\n+generate(SpecialCases, [[\"ccmn\",    \"__ ccmn(zr, zr, 3u, Assembler::LE);\",                \"ccmn\\txzr, xzr, #3, LE\"],\n+                        [\"ccmnw\",   \"__ ccmnw(zr, zr, 5u, Assembler::EQ);\",               \"ccmn\\twzr, wzr, #5, EQ\"],\n+                        [\"ccmp\",    \"__ ccmp(zr, 1, 4u, Assembler::NE);\",                 \"ccmp\\txzr, 1, #4, NE\"],\n+                        [\"ccmpw\",   \"__ ccmpw(zr, 2, 2, Assembler::GT);\",                 \"ccmp\\twzr, 2, #2, GT\"],\n+                        [\"extr\",    \"__ extr(zr, zr, zr, 0);\",                            \"extr\\txzr, xzr, xzr, 0\"],\n+                        [\"stlxp\",   \"__ stlxp(r0, zr, zr, sp);\",                          \"stlxp\\tw0, xzr, xzr, [sp]\"],\n+                        [\"stlxpw\",  \"__ stlxpw(r2, zr, zr, r3);\",                         \"stlxp\\tw2, wzr, wzr, [x3]\"],\n+                        [\"stxp\",    \"__ stxp(r4, zr, zr, r5);\",                           \"stxp\\tw4, xzr, xzr, [x5]\"],\n+                        [\"stxpw\",   \"__ stxpw(r6, zr, zr, sp);\",                          \"stxp\\tw6, wzr, wzr, [sp]\"],\n+                        [\"dup\",     \"__ dup(v0, __ T16B, zr);\",                           \"dup\\tv0.16b, wzr\"],\n+                        [\"mov\",     \"__ mov(v1, __ T1D, 0, zr);\",                         \"mov\\tv1.d[0], xzr\"],\n+                        [\"mov\",     \"__ mov(v1, __ T2S, 1, zr);\",                         \"mov\\tv1.s[1], wzr\"],\n+                        [\"mov\",     \"__ mov(v1, __ T4H, 2, zr);\",                         \"mov\\tv1.h[2], wzr\"],\n+                        [\"mov\",     \"__ mov(v1, __ T8B, 3, zr);\",                         \"mov\\tv1.b[3], wzr\"],\n+                        [\"ld1\",     \"__ ld1(v31, v0, __ T2D, Address(__ post(r1, r0)));\", \"ld1\\t{v31.2d, v0.2d}, [x1], x0\"],\n@@ -1499,33 +1499,79 @@\n-                        [\"cpy\",    \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n-                        [\"inc\",    \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n-                        [\"dec\",    \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n-                        [\"lsl\",    \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n-                        [\"lsr\",    \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n-                        [\"lsr\",    \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n-                        [\"addvl\",  \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n-                        [\"addpl\",  \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n-                        [\"cntp\",   \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n-                        [\"dup\",    \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n-                        [\"dup\",    \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n-                        [\"dup\",    \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n-                        [\"dup\",    \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n-                        [\"ld1h\",   \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n-                        [\"ld1d\",   \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n-                        [\"st1w\",   \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n-                        [\"st1h\",   \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n-                        [\"st1d\",   \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n-                        [\"str\",    \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n+                        [\"cpy\",     \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n+                        [\"cpy\",     \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n+                        [\"cpy\",     \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n+                        [\"cpy\",     \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n+                        [\"inc\",     \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n+                        [\"dec\",     \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n+                        [\"lsl\",     \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n+                        [\"lsr\",     \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n+                        [\"addvl\",   \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n+                        [\"addpl\",   \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n+                        [\"cntp\",    \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n+                        [\"dup\",     \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n+                        [\"dup\",     \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n+                        [\"dup\",     \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n+                        [\"dup\",     \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n+                        [\"dup\",     \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n+                        [\"dup\",     \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n+                        [\"ld1h\",    \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n+                        [\"st1w\",    \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n+                        [\"st1h\",    \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n+                        [\"st1d\",    \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n+                        [\"str\",     \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"sel\",     \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n+                        [\"sel\",     \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p0, z0, z1);\",                \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, z3);\",                \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p2, z4, z5);\",                \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ D, p3, z6, z7);\",                \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmple\",   \"__ sve_cmpge(p2, __ B, p0, z10, z11);\",              \"cmple\\tp2.b, p0\/z, z11.b, z10.b\"],\n+                        [\"cmplt\",   \"__ sve_cmpgt(p3, __ S, p0, z16, z17);\",              \"cmplt\\tp3.s, p0\/z, z17.s, z16.s\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p4, z0, 15);\",                \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, -16);\",               \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n+                        [\"cmple\",   \"__ sve_cmple(p1, __ S, p1, z4, 0);\",                 \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n+                        [\"cmplt\",   \"__ sve_cmplt(p1, __ D, p2, z6, -1);\",                \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p3, z4, 5);\",                 \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ B, p4, z6, -2);\",                \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n+                        [\"fcmeq\",   \"__ sve_fcmeq(p1, __ S, p0, z0, z1);\",                \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n+                        [\"fcmne\",   \"__ sve_fcmne(p1, __ D, p0, z2, z3);\",                \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n+                        [\"fcmgt\",   \"__ sve_fcmgt(p1, __ S, p2, z4, z5);\",                \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"fcmge\",   \"__ sve_fcmge(p1, __ D, p3, z6, z7);\",                \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"fcmlt\",   \"__ sve_fcmgt(p2, __ S, p0, z10, z11);\",              \"fcmlt\\tp2.s, p0\/z, z11.s, z10.s\"],\n+                        [\"fcmle\",   \"__ sve_fcmge(p3, __ D, p0, z16, z17);\",              \"fcmle\\tp3.d, p0\/z, z17.d, z16.d\"],\n+                        [\"uunpkhi\", \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n+                        [\"uunpklo\", \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n+                        [\"sunpkhi\", \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n+                        [\"sunpklo\", \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n+                        [\"whilelt\", \"__ sve_whilelt(p0, __ B, r1, r2);\",                  \"whilelt\\tp0.b, x1, x2\"],\n+                        [\"whilelt\", \"__ sve_whileltw(p1, __ H, r3, r4);\",                 \"whilelt\\tp1.h, w3, w4\"],\n+                        [\"whilele\", \"__ sve_whilele(p2, __ S, r5, r6);\",                  \"whilele\\tp2.s, x5, x6\"],\n+                        [\"whilele\", \"__ sve_whilelew(p3, __ D, r10, r11);\",               \"whilele\\tp3.d, w10, w11\"],\n+                        [\"whilelo\", \"__ sve_whilelo(p4, __ B, r1, r2);\",                  \"whilelo\\tp4.b, x1, x2\"],\n+                        [\"whilelo\", \"__ sve_whilelow(p0, __ H, r3, r4);\",                 \"whilelo\\tp0.h, w3, w4\"],\n+                        [\"whilels\", \"__ sve_whilels(p1, __ S, r5, r6);\",                  \"whilels\\tp1.s, x5, x6\"],\n+                        [\"whilels\", \"__ sve_whilelsw(p2, __ D, r10, r11);\",               \"whilels\\tp2.d, w10, w11\"],\n@@ -1600,0 +1646,2 @@\n+                       [\"uzp1\", \"ZZZ\"],\n+                       [\"uzp2\", \"ZZZ\"],\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64-asmtest.py","additions":96,"deletions":48,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -2434,0 +2434,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n@@ -2478,0 +2492,4 @@\n+    if (bt == T_BOOLEAN) {\n+      \/\/ To support vector api load\/store mask.\n+      return MaxVectorSize \/ 8;\n+    }\n@@ -2505,1 +2523,1 @@\n-  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+  if (UseSVE > 0 && 2 <= len && len <= 256) {\n@@ -16576,1 +16594,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 4);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 4);\n@@ -16587,1 +16605,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 8);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 8);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":21,"deletions":3,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -104,0 +104,33 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static Assembler::SIMD_RegVariant elemBytes_to_regVariant(int esize) {\n+    switch(esize) {\n+      case 1:\n+        return Assembler::B;\n+      case 2:\n+        return Assembler::H;\n+      case 4:\n+        return Assembler::S;\n+      case 8:\n+        return Assembler::D;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+    }\n+    return Assembler::INVALID;\n+  }\n+\n+  static Assembler::SIMD_RegVariant elemType_to_regVariant(BasicType bt) {\n+    return elemBytes_to_regVariant(type2aelembytes(bt));\n+  }\n+\n@@ -108,2 +141,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n+  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                   PRegister pg, BasicType mem_elem_bt,\n+                                   Assembler::SIMD_RegVariant vector_elem_size,\n@@ -112,2 +146,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int esize = type2aelembytes(mem_elem_bt);\n@@ -119,1 +152,0 @@\n-        type = Assembler::B;\n@@ -123,1 +155,0 @@\n-        type = Assembler::H;\n@@ -127,1 +158,0 @@\n-        type = Assembler::S;\n@@ -131,1 +161,0 @@\n-        type = Assembler::D;\n@@ -137,1 +166,1 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      (masm.*insn)(reg, vector_elem_size, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n@@ -144,0 +173,30 @@\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n@@ -163,5 +222,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n@@ -170,1 +224,0 @@\n-      case Op_VectorBlend:\n@@ -180,2 +233,0 @@\n-      case Op_VectorLoadMask:\n-      case Op_VectorMaskCmp:\n@@ -185,1 +236,0 @@\n-      case Op_VectorStoreMask:\n@@ -201,1 +251,0 @@\n-\n@@ -206,1 +255,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -208,1 +257,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -214,0 +264,1 @@\n+    BasicType bt = vector_element_basic_type(this);\n@@ -215,1 +266,1 @@\n-                         vector_element_basic_type(this), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n@@ -222,1 +273,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -228,0 +280,1 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n@@ -229,1 +282,31 @@\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, iRegINoSp tmp1,\n+                       iRegINoSp tmp2, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_LoadVector()->memory_size() != MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, TEMP tmp1, TEMP tmp2, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp1, 0\\n\\t\"\n+            \"mov $tmp2, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, $tmp1, $tmp2\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp1$$reg), 0);\n+    __ mov(as_Register($tmp2$$reg), vector_length(this));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   as_Register($tmp1$$reg), as_Register($tmp2$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n@@ -235,0 +318,25 @@\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, iRegINoSp tmp1,\n+                          iRegINoSp tmp2, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_StoreVector()->memory_size() != MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, TEMP tmp1, TEMP tmp2, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp1, 0\\n\\t\"\n+            \"mov $tmp2, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, $tmp1, $tmp2\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp1$$reg), 0);\n+    __ mov(as_Register($tmp2$$reg), vector_length(this, $src));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   as_Register($tmp1$$reg), as_Register($tmp2$$reg));\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -865,1 +973,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -872,0 +980,255 @@\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ load\/store mask vector\n+\n+instruct vloadmask_loadV(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    Assembler::SIMD_RegVariant to_vect_size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_size, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask(vmemA mem, vReg src, vReg tmp, immI size) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= 2 &&\n+            n->as_StoreVector()->vect_type()->element_basic_type() == T_BOOLEAN);\n+  match(Set mem (StoreVector mem (VectorStoreMask src size)));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant from_vect_size =\n+              elemBytes_to_regVariant((int)$size$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_size, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -974,0 +1337,234 @@\n+\/\/ vector and reduction\n+\n+instruct reduce_andB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # and reduction B\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # and reduction H\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\t # and reduction S\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"andr  $dst, $dst, $src1\\t # and reduction D\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector or reduction\n+\n+instruct reduce_orB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # or reduction B\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # or reduction H\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\t # or reduction S\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"orr  $dst, $dst, $src1\\t # or reduction D\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector xor reduction\n+\n+instruct reduce_eorB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # eor reduction B\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # eor reduction H\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\t # eor reduction S\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"eor  $dst, $dst, $src1\\t # eor reduction D\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -976,0 +1573,80 @@\n+instruct reduce_maxB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction B\" %}\n+  ins_encode %{\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction H\" %}\n+  ins_encode %{\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction S\" %}\n+  ins_encode %{\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 GT\\t# max reduction D\" %}\n+  ins_encode %{\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -998,1 +1675,1 @@\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (D)\\n\\t\"\n@@ -1010,0 +1687,80 @@\n+instruct reduce_minB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction B\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction H\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction S\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 LT\\t# min reduction D\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -1032,1 +1789,1 @@\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (D)\\n\\t\"\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":784,"deletions":27,"binary":false,"changes":811,"status":"modified"},{"patch":"@@ -91,0 +91,33 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static Assembler::SIMD_RegVariant elemBytes_to_regVariant(int esize) {\n+    switch(esize) {\n+      case 1:\n+        return Assembler::B;\n+      case 2:\n+        return Assembler::H;\n+      case 4:\n+        return Assembler::S;\n+      case 8:\n+        return Assembler::D;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+    }\n+    return Assembler::INVALID;\n+  }\n+\n+  static Assembler::SIMD_RegVariant elemType_to_regVariant(BasicType bt) {\n+    return elemBytes_to_regVariant(type2aelembytes(bt));\n+  }\n+\n@@ -95,2 +128,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n+  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                   PRegister pg, BasicType mem_elem_bt,\n+                                   Assembler::SIMD_RegVariant vector_elem_size,\n@@ -99,2 +133,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int esize = type2aelembytes(mem_elem_bt);\n@@ -106,1 +139,0 @@\n-        type = Assembler::B;\n@@ -110,1 +142,0 @@\n-        type = Assembler::H;\n@@ -114,1 +145,0 @@\n-        type = Assembler::S;\n@@ -118,1 +148,0 @@\n-        type = Assembler::D;\n@@ -124,1 +153,1 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      (masm.*insn)(reg, vector_elem_size, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n@@ -131,0 +160,30 @@\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n@@ -150,5 +209,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n@@ -157,1 +211,0 @@\n-      case Op_VectorBlend:\n@@ -167,2 +220,0 @@\n-      case Op_VectorLoadMask:\n-      case Op_VectorMaskCmp:\n@@ -172,1 +223,0 @@\n-      case Op_VectorStoreMask:\n@@ -186,1 +236,0 @@\n-\n@@ -200,1 +249,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -202,1 +251,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -208,0 +258,1 @@\n+    BasicType bt = vector_element_basic_type(this);\n@@ -209,1 +260,1 @@\n-                         vector_element_basic_type(this), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n@@ -216,1 +267,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -222,0 +274,1 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n@@ -223,1 +276,1 @@\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n@@ -229,0 +282,56 @@\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, iRegINoSp tmp1,\n+                       iRegINoSp tmp2, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_LoadVector()->memory_size() != MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, TEMP tmp1, TEMP tmp2, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp1, 0\\n\\t\"\n+            \"mov $tmp2, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, $tmp1, $tmp2\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp1$$reg), 0);\n+    __ mov(as_Register($tmp2$$reg), vector_length(this));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   as_Register($tmp1$$reg), as_Register($tmp2$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, iRegINoSp tmp1,\n+                          iRegINoSp tmp2, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_StoreVector()->memory_size() != MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, TEMP tmp1, TEMP tmp2, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp1, 0\\n\\t\"\n+            \"mov $tmp2, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, $tmp1, $tmp2\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp1$$reg), 0);\n+    __ mov(as_Register($tmp2$$reg), vector_length(this, $src));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   as_Register($tmp1$$reg), as_Register($tmp2$$reg));\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n+\n@@ -530,1 +639,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -535,0 +644,255 @@\n+%}\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ load\/store mask vector\n+\n+instruct vloadmask_loadV(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    Assembler::SIMD_RegVariant to_vect_size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_size, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask(vmemA mem, vReg src, vReg tmp, immI size) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= 2 &&\n+            n->as_StoreVector()->vect_type()->element_basic_type() == T_BOOLEAN);\n+  match(Set mem (StoreVector mem (VectorStoreMask src size)));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant from_vect_size =\n+              elemBytes_to_regVariant((int)$size$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_size, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n@@ -598,1 +962,1 @@\n-REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE,  sxtb)\n+REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n@@ -604,0 +968,196 @@\n+dnl\n+dnl REDUCE_AND_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # and reduction $5\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_AND($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # and reduction $5\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector and reduction\n+REDUCE_AND_EXT(reduce_andB, AndReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_AND_EXT(reduce_andS, AndReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_AND(reduce_andI, AndReductionV, iRegINoSp, iRegIorL2I, S, T_INT, andw)\n+REDUCE_AND(reduce_andL, AndReductionV, iRegLNoSp, iRegL, D, T_LONG, andr)\n+dnl\n+dnl REDUCE_OR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_OR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector or reduction\n+REDUCE_OR_EXT(reduce_orB, OrReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_OR_EXT(reduce_orS, OrReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_OR(reduce_orI, OrReductionV, iRegINoSp, iRegIorL2I, S, T_INT, orrw)\n+REDUCE_OR(reduce_orL, OrReductionV, iRegLNoSp, iRegL, D, T_LONG, orr)\n+dnl\n+dnl REDUCE_XOR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_XOR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector xor reduction\n+REDUCE_XOR_EXT(reduce_eorB, XorReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_XOR_EXT(reduce_eorS, XorReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_XOR(reduce_eorI, XorReductionV, iRegINoSp, iRegIorL2I, S, T_INT, eorw)\n+REDUCE_XOR(reduce_eorL, XorReductionV, iRegLNoSp, iRegL, D, T_LONG, eor)\n+dnl\n+dnl REDUCE_MAXMIN_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7,  $8     )\n+dnl REDUCE_MAXMIN_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, cmp, min_max)\n+define(`REDUCE_MAXMIN_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_s$8v $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 $7\\t# $8 reduction $5\" %}\n+  ins_encode %{\n+    __ sve_s$8v(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$7);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN($1,        $2,      $3,      $4,      $5,   $6,        $7,    $8,    $9 , $10    )\n+dnl REDUCE_MAXMIN(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1, insn2, cmp, min_max)\n+define(`REDUCE_MAXMIN', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_s$10v $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $src1\\n\\t\"\n+            \"$8 $dst, $dst, $src1 $9\\t# $10 reduction $5\" %}\n+  ins_encode %{\n+    __ sve_s$10v(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $src1$$Register);\n+    __ $8(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$9);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n@@ -615,1 +1175,1 @@\n-  format %{ \"sve_f$1v $dst, $src2 # vector (sve) (S)\\n\\t\"\n+  format %{ \"sve_f$1v $dst, $src2 # vector (sve) ($4)\\n\\t\"\n@@ -625,0 +1185,4 @@\n+REDUCE_MAXMIN_EXT(reduce_maxB, MaxReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, GT, max)\n+REDUCE_MAXMIN_EXT(reduce_maxS, MaxReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, GT, max)\n+REDUCE_MAXMIN(reduce_maxI, MaxReductionV, iRegINoSp, iRegIorL2I, S, T_INT, cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxL, MaxReductionV, iRegLNoSp, iRegL, D, T_LONG, cmp, csel, GT, max)\n@@ -629,0 +1193,4 @@\n+REDUCE_MAXMIN_EXT(reduce_minB, MinReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, LT, min)\n+REDUCE_MAXMIN_EXT(reduce_minS, MinReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, LT, min)\n+REDUCE_MAXMIN(reduce_minI, MinReductionV, iRegINoSp, iRegIorL2I, S, T_INT, cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minL, MinReductionV, iRegLNoSp, iRegL, D, T_LONG, cmp, csel, LT, min)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":595,"deletions":27,"binary":false,"changes":622,"status":"modified"},{"patch":"@@ -778,0 +778,6 @@\n+    __ sve_cpy(z0, __ B, p0, 127, true);               \/\/       mov     z0.b, p0\/m, 127\n+    __ sve_cpy(z1, __ H, p0, -128, true);              \/\/       mov     z1.h, p0\/m, -128\n+    __ sve_cpy(z2, __ S, p0, 32512, true);             \/\/       mov     z2.s, p0\/m, 32512\n+    __ sve_cpy(z5, __ D, p0, -32768, false);           \/\/       mov     z5.d, p0\/z, -32768\n+    __ sve_cpy(z10, __ B, p0, -1, false);              \/\/       mov     z10.b, p0\/z, -1\n+    __ sve_cpy(z11, __ S, p0, -1, false);              \/\/       mov     z11.s, p0\/z, -1\n@@ -795,0 +801,2 @@\n+    __ sve_dup(z10, __ B, -1);                         \/\/       dup     z10.b, -1\n+    __ sve_dup(z11, __ S, -1);                         \/\/       dup     z11.s, -1\n@@ -796,0 +804,3 @@\n+    __ sve_ld1b(z0, __ H, p1, Address(sp));            \/\/       ld1b    {z0.h}, p1\/z, [sp]\n+    __ sve_ld1b(z0, __ S, p2, Address(sp, r8));        \/\/       ld1b    {z0.s}, p2\/z, [sp, x8]\n+    __ sve_ld1b(z0, __ D, p3, Address(sp, 7));         \/\/       ld1b    {z0.d}, p3\/z, [sp, #7, MUL VL]\n@@ -803,0 +814,3 @@\n+    __ sve_st1b(z0, __ H, p1, Address(sp));            \/\/       st1b    {z0.h}, p1, [sp]\n+    __ sve_st1b(z0, __ S, p2, Address(sp, r8));        \/\/       st1b    {z0.s}, p2, [sp, x8]\n+    __ sve_st1b(z0, __ D, p3, Address(sp));            \/\/       st1b    {z0.d}, p3, [sp]\n@@ -810,0 +824,32 @@\n+    __ sve_sel(z0, __ B, p0, z1, z2);                  \/\/       sel     z0.b, p0, z1.b, z2.b\n+    __ sve_sel(z4, __ D, p0, z5, z6);                  \/\/       sel     z4.d, p0, z5.d, z6.d\n+    __ sve_cmpeq(p1, __ B, p0, z0, z1);                \/\/       cmpeq   p1.b, p0\/z, z0.b, z1.b\n+    __ sve_cmpne(p1, __ H, p0, z2, z3);                \/\/       cmpne   p1.h, p0\/z, z2.h, z3.h\n+    __ sve_cmpge(p1, __ S, p2, z4, z5);                \/\/       cmpge   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_cmpgt(p1, __ D, p3, z6, z7);                \/\/       cmpgt   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_cmpge(p2, __ B, p0, z10, z11);              \/\/       cmple   p2.b, p0\/z, z11.b, z10.b\n+    __ sve_cmpgt(p3, __ S, p0, z16, z17);              \/\/       cmplt   p3.s, p0\/z, z17.s, z16.s\n+    __ sve_cmpeq(p1, __ B, p4, z0, 15);                \/\/       cmpeq   p1.b, p4\/z, z0.b, #15\n+    __ sve_cmpne(p1, __ H, p0, z2, -16);               \/\/       cmpne   p1.h, p0\/z, z2.h, #-16\n+    __ sve_cmple(p1, __ S, p1, z4, 0);                 \/\/       cmple   p1.s, p1\/z, z4.s, #0\n+    __ sve_cmplt(p1, __ D, p2, z6, -1);                \/\/       cmplt   p1.d, p2\/z, z6.d, #-1\n+    __ sve_cmpge(p1, __ S, p3, z4, 5);                 \/\/       cmpge   p1.s, p3\/z, z4.s, #5\n+    __ sve_cmpgt(p1, __ B, p4, z6, -2);                \/\/       cmpgt   p1.b, p4\/z, z6.b, #-2\n+    __ sve_fcmeq(p1, __ S, p0, z0, z1);                \/\/       fcmeq   p1.s, p0\/z, z0.s, z1.s\n+    __ sve_fcmne(p1, __ D, p0, z2, z3);                \/\/       fcmne   p1.d, p0\/z, z2.d, z3.d\n+    __ sve_fcmgt(p1, __ S, p2, z4, z5);                \/\/       fcmgt   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_fcmge(p1, __ D, p3, z6, z7);                \/\/       fcmge   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_fcmgt(p2, __ S, p0, z10, z11);              \/\/       fcmlt   p2.s, p0\/z, z11.s, z10.s\n+    __ sve_fcmge(p3, __ D, p0, z16, z17);              \/\/       fcmle   p3.d, p0\/z, z17.d, z16.d\n+    __ sve_uunpkhi(z0, __ H, z1);                      \/\/       uunpkhi z0.h, z1.b\n+    __ sve_uunpklo(z4, __ S, z5);                      \/\/       uunpklo z4.s, z5.h\n+    __ sve_sunpkhi(z6, __ D, z7);                      \/\/       sunpkhi z6.d, z7.s\n+    __ sve_sunpklo(z10, __ H, z11);                    \/\/       sunpklo z10.h, z11.b\n+    __ sve_whilelt(p0, __ B, r1, r2);                  \/\/       whilelt p0.b, x1, x2\n+    __ sve_whileltw(p1, __ H, r3, r4);                 \/\/       whilelt p1.h, w3, w4\n+    __ sve_whilele(p2, __ S, r5, r6);                  \/\/       whilele p2.s, x5, x6\n+    __ sve_whilelew(p3, __ D, r10, r11);               \/\/       whilele p3.d, w10, w11\n+    __ sve_whilelo(p4, __ B, r1, r2);                  \/\/       whilelo p4.b, x1, x2\n+    __ sve_whilelow(p0, __ H, r3, r4);                 \/\/       whilelo p0.h, w3, w4\n+    __ sve_whilels(p1, __ S, r5, r6);                  \/\/       whilels p1.s, x5, x6\n+    __ sve_whilelsw(p2, __ D, r10, r11);               \/\/       whilels p2.d, w10, w11\n@@ -946,0 +992,40 @@\n+    __ sve_add(z17, __ D, z12, z3);                    \/\/       add     z17.d, z12.d, z3.d\n+    __ sve_sub(z29, __ D, z28, z16);                   \/\/       sub     z29.d, z28.d, z16.d\n+    __ sve_fadd(z6, __ D, z9, z28);                    \/\/       fadd    z6.d, z9.d, z28.d\n+    __ sve_fmul(z7, __ S, z4, z7);                     \/\/       fmul    z7.s, z4.s, z7.s\n+    __ sve_fsub(z9, __ S, z22, z8);                    \/\/       fsub    z9.s, z22.s, z8.s\n+    __ sve_abs(z27, __ B, p5, z30);                    \/\/       abs     z27.b, p5\/m, z30.b\n+    __ sve_add(z26, __ H, p0, z16);                    \/\/       add     z26.h, p0\/m, z26.h, z16.h\n+    __ sve_asr(z3, __ D, p6, z8);                      \/\/       asr     z3.d, p6\/m, z3.d, z8.d\n+    __ sve_cnt(z21, __ D, p6, z26);                    \/\/       cnt     z21.d, p6\/m, z26.d\n+    __ sve_lsl(z22, __ B, p0, z4);                     \/\/       lsl     z22.b, p0\/m, z22.b, z4.b\n+    __ sve_lsr(z17, __ H, p0, z3);                     \/\/       lsr     z17.h, p0\/m, z17.h, z3.h\n+    __ sve_mul(z1, __ B, p2, z6);                      \/\/       mul     z1.b, p2\/m, z1.b, z6.b\n+    __ sve_neg(z9, __ S, p7, z7);                      \/\/       neg     z9.s, p7\/m, z7.s\n+    __ sve_not(z22, __ H, p5, z5);                     \/\/       not     z22.h, p5\/m, z5.h\n+    __ sve_smax(z8, __ B, p4, z30);                    \/\/       smax    z8.b, p4\/m, z8.b, z30.b\n+    __ sve_smin(z17, __ D, p0, z11);                   \/\/       smin    z17.d, p0\/m, z17.d, z11.d\n+    __ sve_sub(z28, __ S, p0, z26);                    \/\/       sub     z28.s, p0\/m, z28.s, z26.s\n+    __ sve_fabs(z28, __ D, p3, z13);                   \/\/       fabs    z28.d, p3\/m, z13.d\n+    __ sve_fadd(z16, __ S, p6, z5);                    \/\/       fadd    z16.s, p6\/m, z16.s, z5.s\n+    __ sve_fdiv(z13, __ S, p2, z15);                   \/\/       fdiv    z13.s, p2\/m, z13.s, z15.s\n+    __ sve_fmax(z26, __ S, p5, z11);                   \/\/       fmax    z26.s, p5\/m, z26.s, z11.s\n+    __ sve_fmin(z22, __ S, p4, z4);                    \/\/       fmin    z22.s, p4\/m, z22.s, z4.s\n+    __ sve_fmul(z19, __ S, p4, z17);                   \/\/       fmul    z19.s, p4\/m, z19.s, z17.s\n+    __ sve_fneg(z14, __ D, p3, z2);                    \/\/       fneg    z14.d, p3\/m, z2.d\n+    __ sve_frintm(z3, __ S, p5, z23);                  \/\/       frintm  z3.s, p5\/m, z23.s\n+    __ sve_frintn(z6, __ S, p1, z17);                  \/\/       frintn  z6.s, p1\/m, z17.s\n+    __ sve_frintp(z27, __ S, p4, z16);                 \/\/       frintp  z27.s, p4\/m, z16.s\n+    __ sve_fsqrt(z2, __ S, p7, z3);                    \/\/       fsqrt   z2.s, p7\/m, z3.s\n+    __ sve_fsub(z6, __ S, p4, z19);                    \/\/       fsub    z6.s, p4\/m, z6.s, z19.s\n+    __ sve_fmla(z12, __ D, p5, z8, z24);               \/\/       fmla    z12.d, p5\/m, z8.d, z24.d\n+    __ sve_fmls(z17, __ S, p0, z10, z23);              \/\/       fmls    z17.s, p0\/m, z10.s, z23.s\n+    __ sve_fnmla(z19, __ S, p7, z13, z16);             \/\/       fnmla   z19.s, p7\/m, z13.s, z16.s\n+    __ sve_fnmls(z0, __ D, p1, z14, z17);              \/\/       fnmls   z0.d, p1\/m, z14.d, z17.d\n+    __ sve_mla(z8, __ S, p2, z22, z20);                \/\/       mla     z8.s, p2\/m, z22.s, z20.s\n+    __ sve_mls(z27, __ S, p0, z3, z15);                \/\/       mls     z27.s, p0\/m, z3.s, z15.s\n+    __ sve_and(z20, z7, z4);                           \/\/       and     z20.d, z7.d, z4.d\n+    __ sve_eor(z7, z0, z8);                            \/\/       eor     z7.d, z0.d, z8.d\n+    __ sve_orr(z19, z22, z4);                          \/\/       orr     z19.d, z22.d, z4.d\n+    __ sve_uzp1(z9, __ D, z22, z11);                   \/\/       uzp1    z9.d, z22.d, z11.d\n+    __ sve_uzp2(z5, __ H, z30, z16);                   \/\/       uzp2    z5.h, z30.h, z16.h\n@@ -986,9 +1072,9 @@\n-    __ sve_andv(v25, __ S, p1, z30);                   \/\/       andv s25, p1, z30.s\n-    __ sve_orv(v13, __ B, p5, z11);                    \/\/       orv b13, p5, z11.b\n-    __ sve_eorv(v13, __ S, p2, z20);                   \/\/       eorv s13, p2, z20.s\n-    __ sve_smaxv(v25, __ B, p3, z4);                   \/\/       smaxv b25, p3, z4.b\n-    __ sve_sminv(v17, __ D, p2, z6);                   \/\/       sminv d17, p2, z6.d\n-    __ sve_fminv(v4, __ D, p7, z16);                   \/\/       fminv d4, p7, z16.d\n-    __ sve_fmaxv(v26, __ S, p2, z14);                  \/\/       fmaxv s26, p2, z14.s\n-    __ sve_fadda(v11, __ S, p7, z3);                   \/\/       fadda s11, p7, s11, z3.s\n-    __ sve_uaddv(v1, __ S, p6, z21);                   \/\/       uaddv d1, p6, z21.s\n+    __ sve_andv(v22, __ H, p3, z1);                    \/\/       andv h22, p3, z1.h\n+    __ sve_orv(v8, __ D, p5, z16);                     \/\/       orv d8, p5, z16.d\n+    __ sve_eorv(v15, __ S, p1, z4);                    \/\/       eorv s15, p1, z4.s\n+    __ sve_smaxv(v8, __ B, p1, z29);                   \/\/       smaxv b8, p1, z29.b\n+    __ sve_sminv(v28, __ D, p4, z29);                  \/\/       sminv d28, p4, z29.d\n+    __ sve_fminv(v9, __ S, p3, z2);                    \/\/       fminv s9, p3, z2.s\n+    __ sve_fmaxv(v28, __ S, p0, z7);                   \/\/       fmaxv s28, p0, z7.s\n+    __ sve_fadda(v26, __ S, p5, z17);                  \/\/       fadda s26, p5, s26, z17.s\n+    __ sve_uaddv(v8, __ D, p4, z21);                   \/\/       uaddv d8, p4, z21.d\n@@ -1013,7 +1099,7 @@\n-    0x14000000,     0x17ffffd7,     0x140002d0,     0x94000000,\n-    0x97ffffd4,     0x940002cd,     0x3400000a,     0x34fffa2a,\n-    0x3400594a,     0x35000008,     0x35fff9c8,     0x350058e8,\n-    0xb400000b,     0xb4fff96b,     0xb400588b,     0xb500001d,\n-    0xb5fff91d,     0xb500583d,     0x10000013,     0x10fff8b3,\n-    0x100057d3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36305756,     0x3758000c,     0x375ff7cc,     0x375856ec,\n+    0x14000000,     0x17ffffd7,     0x140002fd,     0x94000000,\n+    0x97ffffd4,     0x940002fa,     0x3400000a,     0x34fffa2a,\n+    0x34005eea,     0x35000008,     0x35fff9c8,     0x35005e88,\n+    0xb400000b,     0xb4fff96b,     0xb4005e2b,     0xb500001d,\n+    0xb5fff91d,     0xb5005ddd,     0x10000013,     0x10fff8b3,\n+    0x10005d73,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36305cf6,     0x3758000c,     0x375ff7cc,     0x37585c8c,\n@@ -1024,13 +1110,13 @@\n-    0x540054c0,     0x54000001,     0x54fff541,     0x54005461,\n-    0x54000002,     0x54fff4e2,     0x54005402,     0x54000002,\n-    0x54fff482,     0x540053a2,     0x54000003,     0x54fff423,\n-    0x54005343,     0x54000003,     0x54fff3c3,     0x540052e3,\n-    0x54000004,     0x54fff364,     0x54005284,     0x54000005,\n-    0x54fff305,     0x54005225,     0x54000006,     0x54fff2a6,\n-    0x540051c6,     0x54000007,     0x54fff247,     0x54005167,\n-    0x54000008,     0x54fff1e8,     0x54005108,     0x54000009,\n-    0x54fff189,     0x540050a9,     0x5400000a,     0x54fff12a,\n-    0x5400504a,     0x5400000b,     0x54fff0cb,     0x54004feb,\n-    0x5400000c,     0x54fff06c,     0x54004f8c,     0x5400000d,\n-    0x54fff00d,     0x54004f2d,     0x5400000e,     0x54ffefae,\n-    0x54004ece,     0x5400000f,     0x54ffef4f,     0x54004e6f,\n+    0x54005a60,     0x54000001,     0x54fff541,     0x54005a01,\n+    0x54000002,     0x54fff4e2,     0x540059a2,     0x54000002,\n+    0x54fff482,     0x54005942,     0x54000003,     0x54fff423,\n+    0x540058e3,     0x54000003,     0x54fff3c3,     0x54005883,\n+    0x54000004,     0x54fff364,     0x54005824,     0x54000005,\n+    0x54fff305,     0x540057c5,     0x54000006,     0x54fff2a6,\n+    0x54005766,     0x54000007,     0x54fff247,     0x54005707,\n+    0x54000008,     0x54fff1e8,     0x540056a8,     0x54000009,\n+    0x54fff189,     0x54005649,     0x5400000a,     0x54fff12a,\n+    0x540055ea,     0x5400000b,     0x54fff0cb,     0x5400558b,\n+    0x5400000c,     0x54fff06c,     0x5400552c,     0x5400000d,\n+    0x54fff00d,     0x540054cd,     0x5400000e,     0x54ffefae,\n+    0x5400546e,     0x5400000f,     0x54ffef4f,     0x5400540f,\n@@ -1068,1 +1154,1 @@\n-    0xbd1b1869,     0x58003ebb,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x5800445b,     0x1800000b,     0xf8945060,\n@@ -1124,27 +1210,29 @@\n-    0x2ebad738,     0x6ea2d420,     0x6efdd79b,     0x2e3fdfdd,\n-    0x6e27dcc5,     0x6e67dcc5,     0x0e7f97dd,     0x4e6d958b,\n-    0x0ebb9759,     0x4ea29420,     0x0e20cffe,     0x4e22cc20,\n-    0x4e73ce51,     0x2e7e97bc,     0x6e7b9759,     0x2eab9549,\n-    0x6ebb9759,     0x0eaecdac,     0x4eb1ce0f,     0x4eedcd8b,\n-    0x2e2cfd6a,     0x6e33fe51,     0x6e7aff38,     0x0e3766d5,\n-    0x4e396717,     0x0e626420,     0x4e726630,     0x0eac656a,\n-    0x4ea864e6,     0x0e3ef7bc,     0x4e28f4e6,     0x4e67f4c5,\n-    0x0e276cc5,     0x4e366eb4,     0x0e736e51,     0x4e716e0f,\n-    0x0eb36e51,     0x4ebf6fdd,     0x0ebcf77a,     0x4ebef7bc,\n-    0x4ee3f441,     0x2e3d8f9b,     0x6e228c20,     0x2e768eb4,\n-    0x6e7e8fbc,     0x2eb18e0f,     0x6eae8dac,     0x6eec8d6a,\n-    0x0e3ee7bc,     0x4e3ee7bc,     0x4e75e693,     0x0e3836f6,\n-    0x4e2c356a,     0x0e6634a4,     0x4e6037fe,     0x0eb636b4,\n-    0x4eaa3528,     0x4ee037fe,     0x2eb3e651,     0x6eace56a,\n-    0x6efde79b,     0x0e243c62,     0x4e3a3f38,     0x0e663ca4,\n-    0x4e653c83,     0x0eaa3d28,     0x4eb83ef6,     0x4ef33e51,\n-    0x2e2fe5cd,     0x6e26e4a4,     0x6e7ee7bc,     0xba5fd3e3,\n-    0x3a5f03e5,     0xfa411be4,     0x7a42cbe2,     0x93df03ff,\n-    0xc820ffff,     0x8822fc7f,     0xc8247cbf,     0x88267fff,\n-    0x4e010fe0,     0x4e081fe1,     0x4e0c1fe1,     0x4e0a1fe1,\n-    0x4e071fe1,     0x4cc0ac3f,     0x05a08020,     0x04b0e3e0,\n-    0x0470e7e1,     0x042f9c20,     0x043f9c35,     0x047f9c20,\n-    0x04ff9c20,     0x04299420,     0x04319160,     0x0461943e,\n-    0x04a19020,     0x042053ff,     0x047f5401,     0x25208028,\n-    0x2538cfe0,     0x2578d001,     0x25b8efe2,     0x25f8f007,\n-    0xa400a3e0,     0xa4a8a7ea,     0xa547a814,     0xa4084ffe,\n+    0x2e3adf38,     0x6e22dc20,     0x6e7ddf9b,     0x0e7f97dd,\n+    0x4e6794c5,     0x0ea794c5,     0x4ebf97dd,     0x0e2dcd8b,\n+    0x4e3bcf59,     0x4e62cc20,     0x2e6097fe,     0x6e629420,\n+    0x2eb39651,     0x6ebe97bc,     0x0ebbcf59,     0x4eabcd49,\n+    0x4efbcf59,     0x2e2efdac,     0x6e31fe0f,     0x6e6dfd8b,\n+    0x0e2c656a,     0x4e336651,     0x0e7a6738,     0x4e7766d5,\n+    0x0eb96717,     0x4ea26420,     0x0e32f630,     0x4e2cf56a,\n+    0x4e68f4e6,     0x0e3e6fbc,     0x4e286ce6,     0x0e676cc5,\n+    0x4e676cc5,     0x0eb66eb4,     0x4eb36e51,     0x0eb1f60f,\n+    0x4eb3f651,     0x4efff7dd,     0x2e3c8f7a,     0x6e3e8fbc,\n+    0x2e638c41,     0x6e7d8f9b,     0x2ea28c20,     0x6eb68eb4,\n+    0x6efe8fbc,     0x0e31e60f,     0x4e2ee5ac,     0x4e6ce56a,\n+    0x0e3e37bc,     0x4e3e37bc,     0x0e753693,     0x4e7836f6,\n+    0x0eac356a,     0x4ea634a4,     0x4ee037fe,     0x2eb6e6b4,\n+    0x6eaae528,     0x6ee0e7fe,     0x0e333e51,     0x4e2c3d6a,\n+    0x0e7d3f9b,     0x4e643c62,     0x0eba3f38,     0x4ea63ca4,\n+    0x4ee53c83,     0x2e2ae528,     0x6e38e6f6,     0x6e73e651,\n+    0xba5fd3e3,     0x3a5f03e5,     0xfa411be4,     0x7a42cbe2,\n+    0x93df03ff,     0xc820ffff,     0x8822fc7f,     0xc8247cbf,\n+    0x88267fff,     0x4e010fe0,     0x4e081fe1,     0x4e0c1fe1,\n+    0x4e0a1fe1,     0x4e071fe1,     0x4cc0ac3f,     0x05a08020,\n+    0x05104fe0,     0x05505001,     0x05906fe2,     0x05d03005,\n+    0x05101fea,     0x05901feb,     0x04b0e3e0,     0x0470e7e1,\n+    0x042f9c20,     0x043f9c35,     0x047f9c20,     0x04ff9c20,\n+    0x04299420,     0x04319160,     0x0461943e,     0x04a19020,\n+    0x042053ff,     0x047f5401,     0x25208028,     0x2538cfe0,\n+    0x2578d001,     0x25b8efe2,     0x25f8f007,     0x2538dfea,\n+    0x25b8dfeb,     0xa400a3e0,     0xa420a7e0,     0xa4484be0,\n+    0xa467afe0,     0xa4a8a7ea,     0xa547a814,     0xa4084ffe,\n@@ -1152,42 +1240,51 @@\n-    0xe547e400,     0xe4014be0,     0xe4a84fe0,     0xe5f15000,\n-    0x858043e0,     0x85a043ff,     0xe59f5d08,     0x1e601000,\n-    0x1e603000,     0x1e621000,     0x1e623000,     0x1e641000,\n-    0x1e643000,     0x1e661000,     0x1e663000,     0x1e681000,\n-    0x1e683000,     0x1e6a1000,     0x1e6a3000,     0x1e6c1000,\n-    0x1e6c3000,     0x1e6e1000,     0x1e6e3000,     0x1e701000,\n-    0x1e703000,     0x1e721000,     0x1e723000,     0x1e741000,\n-    0x1e743000,     0x1e761000,     0x1e763000,     0x1e781000,\n-    0x1e783000,     0x1e7a1000,     0x1e7a3000,     0x1e7c1000,\n-    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8388355,\n-    0xf8380303,     0xf83a11f7,     0xf8352303,     0xf8283299,\n-    0xf8305051,     0xf8214300,     0xf8247183,     0xf83f615c,\n-    0xf8ba8182,     0xf8b0003f,     0xf8ad101d,     0xf8b3222c,\n-    0xf8b6338d,     0xf8be503f,     0xf8ba409c,     0xf8be70c4,\n-    0xf8be61fa,     0xf8e98188,     0xf8e00034,     0xf8f81002,\n-    0xf8e92358,     0xf8f0307e,     0xf8ea5157,     0xf8e44050,\n-    0xf8eb7148,     0xf8ef6051,     0xf86a818c,     0xf86f004d,\n-    0xf8671354,     0xf8702044,     0xf86431ec,     0xf87551f0,\n-    0xf86b42f5,     0xf86c72fa,     0xf87c616e,     0xb8388181,\n-    0xb83f020a,     0xb8271062,     0xb82d2233,     0xb8303023,\n-    0xb82b50be,     0xb82843af,     0xb83e7280,     0xb82762f4,\n-    0xb8bc8375,     0xb8b90025,     0xb8b713f0,     0xb8a5212c,\n-    0xb8bc33af,     0xb8b6527f,     0xb8bf41c5,     0xb8b071ff,\n-    0xb8bb6214,     0xb8ec812b,     0xb8e6023e,     0xb8fb13dc,\n-    0xb8e7228a,     0xb8ea3304,     0xb8f152d1,     0xb8e341fd,\n-    0xb8f67273,     0xb8f661e2,     0xb866820c,     0xb86b02ed,\n-    0xb861127e,     0xb8652051,     0xb87031b6,     0xb86a53b5,\n-    0xb87b436c,     0xb86373e1,     0xb8786233,     0xce3a3b69,\n-    0xce167a86,     0xce7e8c58,     0xce8aba3a,     0xce718051,\n-    0xce798700,     0xcec08056,     0xce638991,     0x04bc03bb,\n-    0x04e904da,     0x658400f1,     0x6596092f,     0x65d40762,\n-    0x0496b805,     0x0440072e,     0x04d0975b,     0x041ab418,\n-    0x04139006,     0x0411812f,     0x04100b65,     0x0417b694,\n-    0x04deaa0a,     0x04481046,     0x04ca1c5d,     0x04411dd6,\n-    0x049cb2fb,     0x65c08d42,     0x658d9aca,     0x65869603,\n-    0x65c79201,     0x65828d8c,     0x04dda290,     0x65c2a4e5,\n-    0x65c0be0c,     0x6581a386,     0x65cda624,     0x65818e6d,\n-    0x65a01638,     0x65be2677,     0x65a74410,     0x65ea7911,\n-    0x04025774,     0x0407728f,     0x042030fc,     0x04b63270,\n-    0x0476312f,     0x049a27d9,     0x0418356d,     0x04992a8d,\n-    0x04082c99,     0x04ca28d1,     0x65c73e04,     0x658629da,\n-    0x65983c6b,     0x04813aa1,\n+    0xe420e7e0,     0xe4484be0,     0xe460efe0,     0xe547e400,\n+    0xe4014be0,     0xe4a84fe0,     0xe5f15000,     0x858043e0,\n+    0x85a043ff,     0xe59f5d08,     0x0522c020,     0x05e6c0a4,\n+    0x2401a001,     0x2443a051,     0x24858881,     0x24c78cd1,\n+    0x240b8142,     0x24918213,     0x250f9001,     0x25508051,\n+    0x25802491,     0x25df28c1,     0x25850c81,     0x251e10d1,\n+    0x65816001,     0x65c36051,     0x65854891,     0x65c74cc1,\n+    0x658b4152,     0x65d14203,     0x05733820,     0x05b238a4,\n+    0x05f138e6,     0x0570396a,     0x25221420,     0x25640461,\n+    0x25a614b2,     0x25eb0553,     0x25221c24,     0x25640c60,\n+    0x25a61cb1,     0x25eb0d52,     0x1e601000,     0x1e603000,\n+    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n+    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n+    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n+    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n+    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n+    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n+    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n+    0x1e7e1000,     0x1e7e3000,     0xf82d83a5,     0xf8380355,\n+    0xf8381303,     0xf83a21f7,     0xf8353303,     0xf8285299,\n+    0xf8304051,     0xf8217300,     0xf8246183,     0xf8bf815c,\n+    0xf8ba0182,     0xf8b0103f,     0xf8ad201d,     0xf8b3322c,\n+    0xf8b6538d,     0xf8be403f,     0xf8ba709c,     0xf8be60c4,\n+    0xf8fe81fa,     0xf8e90188,     0xf8e01034,     0xf8f82002,\n+    0xf8e93358,     0xf8f0507e,     0xf8ea4157,     0xf8e47050,\n+    0xf8eb6148,     0xf86f8051,     0xf86a018c,     0xf86f104d,\n+    0xf8672354,     0xf8703044,     0xf86451ec,     0xf87541f0,\n+    0xf86b72f5,     0xf86c62fa,     0xb83c816e,     0xb8380181,\n+    0xb83f120a,     0xb8272062,     0xb82d3233,     0xb8305023,\n+    0xb82b40be,     0xb82873af,     0xb83e6280,     0xb8a782f4,\n+    0xb8bc0375,     0xb8b91025,     0xb8b723f0,     0xb8a5312c,\n+    0xb8bc53af,     0xb8b6427f,     0xb8bf71c5,     0xb8b061ff,\n+    0xb8fb8214,     0xb8ec012b,     0xb8e6123e,     0xb8fb23dc,\n+    0xb8e7328a,     0xb8ea5304,     0xb8f142d1,     0xb8e371fd,\n+    0xb8f66273,     0xb87681e2,     0xb866020c,     0xb86b12ed,\n+    0xb861227e,     0xb8653051,     0xb87051b6,     0xb86a43b5,\n+    0xb87b736c,     0xb86363e1,     0xce312677,     0xce0e1b5b,\n+    0xce7e8ed4,     0xce9ed858,     0xce768151,     0xce718451,\n+    0xcec08300,     0xce628ad9,     0x04e30191,     0x04f0079d,\n+    0x65dc0126,     0x65870887,     0x658806c9,     0x0416b7db,\n+    0x0440021a,     0x04d09903,     0x04dabb55,     0x04138096,\n+    0x04518071,     0x041008c1,     0x0497bce9,     0x045eb4b6,\n+    0x040813c8,     0x04ca0171,     0x0481035c,     0x04dcadbc,\n+    0x658098b0,     0x658d89ed,     0x6586957a,     0x65879096,\n+    0x65829233,     0x04ddac4e,     0x6582b6e3,     0x6580a626,\n+    0x6581b21b,     0x658dbc62,     0x65819266,     0x65f8150c,\n+    0x65b72151,     0x65b05db3,     0x65f165c0,     0x04944ac8,\n+    0x048f607b,     0x042430f4,     0x04a83007,     0x046432d3,\n+    0x05eb6ac9,     0x05706fc5,     0x045a2c36,     0x04d83608,\n+    0x0499248f,     0x040827a8,     0x04ca33bc,     0x65872c49,\n+    0x658620fc,     0x6598363a,     0x04c132a8,\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.cpp","additions":196,"deletions":99,"binary":false,"changes":295,"status":"modified"},{"patch":"@@ -1538,1 +1538,1 @@\n-    B, H, S, D, Q\n+    B, H, S, D, Q, INVALID\n@@ -3203,1 +3203,1 @@\n-  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm8) {\n+  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm16) {\n@@ -3207,1 +3207,2 @@\n-    if (imm8 <= 127 && imm8 >= -128) {\n+    unsigned imm = imm16;\n+    if (imm16 <= 127 && imm16 >= -128) {\n@@ -3209,1 +3210,1 @@\n-    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n+    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n@@ -3211,1 +3212,1 @@\n-      imm8 = (imm8 >> 8);\n+      imm = (imm >> 8);\n@@ -3215,0 +3216,2 @@\n+    unsigned mask = (1U << 8) - 1;\n+    imm &= mask;\n@@ -3216,1 +3219,1 @@\n-    f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n+    f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n@@ -3225,0 +3228,124 @@\n+   \/\/ SVE cpy immediate\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm16, bool isMerge) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    int sh = 0;\n+    unsigned imm = imm16;\n+    if (imm16 <= 127 && imm16 >= -128) {\n+      sh = 0;\n+    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n+      sh = 1;\n+      imm = (imm >> 8);\n+    } else {\n+      guarantee(false, \"invalid immediate\");\n+    }\n+    unsigned mask = (1U << 8) - 1;\n+    imm &= mask;\n+    int m = isMerge ? 1 : 0;\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b01, 21, 20);\n+    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE vector sel\n+  void sve_sel(FloatRegister Zd,\n+               SIMD_RegVariant T,\n+               PRegister Pg,\n+               FloatRegister Zn,\n+               FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b11, 15, 14), prf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE compare vector\n+#define INSN(NAME, op, cond, fp)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, FloatRegister Zm)  { \\\n+    starti;                                                                                       \\\n+    if (fp == 0) {                                                                                \\\n+      assert(T != Q, \"invalid size\");                                                             \\\n+    } else {                                                                                      \\\n+      assert(T != B && T != Q, \"invalid size\");                                                   \\\n+    }                                                                                             \\\n+    f(op, 31, 24), f(T, 23, 22), f(0b0, 21), rf(Zm, 16), f((cond >> 1) & 0x7, 15, 13);            \\\n+    pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0);                                        \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b00100100, 0b1010, 0);\n+  INSN(sve_cmpne, 0b00100100, 0b1011, 0);\n+  INSN(sve_cmpge, 0b00100100, 0b1000, 0);\n+  INSN(sve_cmpgt, 0b00100100, 0b1001, 0);\n+  INSN(sve_fcmeq, 0b01100101, 0b0110, 1);\n+  INSN(sve_fcmne, 0b01100101, 0b0111, 1);\n+  INSN(sve_fcmgt, 0b01100101, 0b0101, 1);\n+  INSN(sve_fcmge, 0b01100101, 0b0100, 1);\n+#undef INSN\n+\n+\/\/ SVE compare vector with immediate\n+#define INSN(NAME, cond)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, int imm5) { \\\n+    starti;                                                                              \\\n+    assert(T != Q, \"invalid size\");                                                      \\\n+    if (imm5 > 15 || imm5 < -16) {                                                       \\\n+      guarantee(false, \"invalid immediate\");                                             \\\n+    }                                                                                    \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(0b0, 21), sf(imm5, 20, 16),                   \\\n+    f((cond >> 1) & 0x7, 15, 13), pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0); \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b1000);\n+  INSN(sve_cmpne, 0b1001);\n+  INSN(sve_cmpgt, 0b0001);\n+  INSN(sve_cmpge, 0b0000);\n+  INSN(sve_cmplt, 0b0010);\n+  INSN(sve_cmple, 0b0011);\n+#undef INSN\n+\n+\/\/ SVE unpack and extend\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn) { \\\n+    starti;                                                          \\\n+    assert(T != B && T != Q, \"invalid size\");                        \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1100, 21, 18);          \\\n+    f(op, 17, 16), f(0b001110, 15, 10), rf(Zn, 5), rf(Zd, 0);        \\\n+  }\n+\n+  INSN(sve_uunpkhi, 0b11);\n+  INSN(sve_uunpklo, 0b10);\n+  INSN(sve_sunpkhi, 0b01);\n+  INSN(sve_sunpklo, 0b00);\n+#undef INSN\n+\n+\/\/ SVE vector uzp1,uzp2\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) { \\\n+    starti;                                                                            \\\n+    assert(T != Q, \"invalid size\");                                                    \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);                       \\\n+    f(0b01101, 15, 11), f(op, 10), rf(Zn, 5), rf(Zd, 0);                               \\\n+  }\n+\n+  INSN(sve_uzp1, 0b0);\n+  INSN(sve_uzp2, 0b1);\n+#undef INSN\n+\n+\/\/ SVE while[cond]\n+#define INSN(NAME, decode, sf)                                            \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, Register Rn, Register Rm) {  \\\n+    starti;                                                               \\\n+    assert(T != Q, \"invalid register variant\");                           \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(1, 21),                        \\\n+    zrf(Rm, 16), f(0, 15, 13), f(sf, 12), f(decode >> 1, 11, 10),         \\\n+    zrf(Rn, 5), f(decode & 0b1, 4), prf(Pd, 0);                           \\\n+  }\n+\n+  INSN(sve_whilelt,  0b010, 1);\n+  INSN(sve_whileltw, 0b010, 0);\n+  INSN(sve_whilele,  0b011, 1);\n+  INSN(sve_whilelew, 0b011, 0);\n+  INSN(sve_whilelo,  0b110, 1);\n+  INSN(sve_whilelow, 0b110, 0);\n+  INSN(sve_whilels,  0b111, 1);\n+  INSN(sve_whilelsw, 0b111, 0);\n+#undef INSN\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":133,"deletions":6,"binary":false,"changes":139,"status":"modified"},{"patch":"@@ -855,0 +855,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1000,0 +1000,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -365,0 +365,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2147,0 +2147,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -927,0 +927,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1546,0 +1546,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -861,0 +861,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1031,0 +1031,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1122,0 +1122,25 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(num_bits == 64 || num_bits == 128 || num_bits == 256 || num_bits == 512,\n+         \"only certain vector sizes are supported for now\");\n+\n+  static const XMMRegister VEC_ArgReg[32] = {\n+     xmm0,  xmm1,  xmm2,  xmm3,  xmm4,  xmm5,  xmm6,  xmm7,\n+     xmm8,  xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15,\n+    xmm16, xmm17, xmm18, xmm19, xmm20, xmm21, xmm22, xmm23,\n+    xmm24, xmm25, xmm26, xmm27, xmm28, xmm29, xmm30, xmm31\n+  };\n+\n+  uint stk_args = 0;\n+  uint fp_args = 0;\n+\n+  for (uint i = 0; i < total_args_passed; i++) {\n+    VMReg vmreg = VEC_ArgReg[fp_args++]->as_VMReg();\n+    int next_val = num_bits == 64 ? 1 : (num_bits == 128 ? 3 : (num_bits  == 256 ? 7 : 15));\n+    regs[i].set_pair(vmreg->next(next_val), vmreg);\n+  }\n+\n+  return stk_args;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -53,0 +53,277 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+\/\/ Vector API SVML routines written in assembly\n+extern \"C\"\n+{\n+   float __svml_expf4_ha_ex(float a);\n+   double __svml_exp1_ha_ex(double a);\n+   double __svml_exp2_ha_ex(double a);\n+   float __svml_expf4_ha_l9(float a);\n+   float __svml_expf8_ha_l9(float a);\n+   float __svml_expf4_ha_e9(float a);\n+   float __svml_expf8_ha_e9(float a);\n+   float __svml_expf16_ha_z0(float a);\n+   double __svml_exp1_ha_l9(double a);\n+   double __svml_exp2_ha_l9(double a);\n+   double __svml_exp4_ha_l9(double a);\n+   double __svml_exp1_ha_e9(double a);\n+   double __svml_exp2_ha_e9(double a);\n+   double __svml_exp4_ha_e9(double a);\n+   double __svml_exp8_ha_z0(double a);\n+   float  __svml_expm1f4_ha_ex(float a);\n+   double __svml_expm11_ha_ex(double a);\n+   double __svml_expm12_ha_ex(double a);\n+   float  __svml_expm1f4_ha_l9(float a);\n+   float  __svml_expm1f8_ha_l9(float a);\n+   float  __svml_expm1f4_ha_e9(float a);\n+   float  __svml_expm1f8_ha_e9(float a);\n+   float __svml_expm1f16_ha_z0(float a);\n+   double __svml_expm11_ha_l9(double a);\n+   double __svml_expm12_ha_l9(double a);\n+   double __svml_expm14_ha_l9(double a);\n+   double __svml_expm11_ha_e9(double a);\n+   double __svml_expm12_ha_e9(double a);\n+   double __svml_expm14_ha_e9(double a);\n+   double __svml_expm18_ha_z0(double a);\n+   float __svml_log1pf4_ha_l9(float a);\n+   float __svml_log1pf8_ha_l9(float a);\n+   float __svml_log1pf4_ha_e9(float a);\n+   float __svml_log1pf8_ha_e9(float a);\n+   float __svml_log1pf16_ha_z0(float a);\n+   double __svml_log1p1_ha_l9(double a);\n+   double __svml_log1p2_ha_l9(double a);\n+   double __svml_log1p4_ha_l9(double a);\n+   double __svml_log1p1_ha_e9(double a);\n+   double __svml_log1p2_ha_e9(double a);\n+   double __svml_log1p4_ha_e9(double a);\n+   double __svml_log1p8_ha_z0(double a);\n+   float __svml_logf4_ha_l9(float a);\n+   float __svml_logf8_ha_l9(float a);\n+   float __svml_logf4_ha_e9(float a);\n+   float __svml_logf8_ha_e9(float a);\n+   float __svml_logf16_ha_z0(float a);\n+   double __svml_log1_ha_l9(double a);\n+   double __svml_log2_ha_l9(double a);\n+   double __svml_log4_ha_l9(double a);\n+   double __svml_log1_ha_e9(double a);\n+   double __svml_log2_ha_e9(double a);\n+   double __svml_log4_ha_e9(double a);\n+   double __svml_log8_ha_z0(double a);\n+   float __svml_log10f4_ha_l9(float a);\n+   float __svml_log10f8_ha_l9(float a);\n+   float __svml_log10f4_ha_e9(float a);\n+   float __svml_log10f8_ha_e9(float a);\n+   float __svml_log10f16_ha_z0(float a);\n+   double __svml_log101_ha_l9(double a);\n+   double __svml_log102_ha_l9(double a);\n+   double __svml_log104_ha_l9(double a);\n+   double __svml_log101_ha_e9(double a);\n+   double __svml_log102_ha_e9(double a);\n+   double __svml_log104_ha_e9(double a);\n+   double __svml_log108_ha_z0(double a);\n+   float __svml_sinf4_ha_l9(float a);\n+   float __svml_sinf8_ha_l9(float a);\n+   float __svml_sinf4_ha_e9(float a);\n+   float __svml_sinf8_ha_e9(float a);\n+   float __svml_sinf16_ha_z0(float a);\n+   double __svml_sin1_ha_l9(double a);\n+   double __svml_sin2_ha_l9(double a);\n+   double __svml_sin4_ha_l9(double a);\n+   double __svml_sin1_ha_e9(double a);\n+   double __svml_sin2_ha_e9(double a);\n+   double __svml_sin4_ha_e9(double a);\n+   double __svml_sin8_ha_z0(double a);\n+   float __svml_cosf4_ha_l9(float a);\n+   float __svml_cosf8_ha_l9(float a);\n+   float __svml_cosf4_ha_e9(float a);\n+   float __svml_cosf8_ha_e9(float a);\n+   float __svml_cosf16_ha_z0(float a);\n+   double  __svml_cos1_ha_l9(double a);\n+   double  __svml_cos2_ha_l9(double a);\n+   double __svml_cos4_ha_l9(double a);\n+   double  __svml_cos1_ha_e9(double a);\n+   double  __svml_cos2_ha_e9(double a);\n+   double __svml_cos4_ha_e9(double a);\n+   double  __svml_cos8_ha_z0(double a);\n+   float __svml_tanf4_ha_l9(float a);\n+   float __svml_tanf8_ha_l9(float a);\n+   float __svml_tanf4_ha_e9(float a);\n+   float __svml_tanf8_ha_e9(float a);\n+   float __svml_tanf16_ha_z0(float a);\n+   double __svml_tan1_ha_l9(double a);\n+   double __svml_tan2_ha_l9(double a);\n+   double __svml_tan4_ha_l9(double a);\n+   double __svml_tan1_ha_e9(double a);\n+   double __svml_tan2_ha_e9(double a);\n+   double __svml_tan4_ha_e9(double a);\n+   double __svml_tan8_ha_z0(double a);\n+   double __svml_sinh1_ha_l9(double a);\n+   double __svml_sinh2_ha_l9(double a);\n+   double __svml_sinh4_ha_l9(double a);\n+   double __svml_sinh1_ha_e9(double a);\n+   double __svml_sinh2_ha_e9(double a);\n+   double __svml_sinh4_ha_e9(double a);\n+   double __svml_sinh8_ha_z0(double a);\n+   float __svml_sinhf4_ha_l9(float a);\n+   float __svml_sinhf8_ha_l9(float a);\n+   float __svml_sinhf4_ha_e9(float a);\n+   float __svml_sinhf8_ha_e9(float a);\n+   float __svml_sinhf16_ha_z0(float a);\n+   double __svml_cosh1_ha_l9(double a);\n+   double __svml_cosh2_ha_l9(double a);\n+   double __svml_cosh4_ha_l9(double a);\n+   double __svml_cosh1_ha_e9(double a);\n+   double __svml_cosh2_ha_e9(double a);\n+   double __svml_cosh4_ha_e9(double a);\n+   double __svml_cosh8_ha_z0(double a);\n+   float __svml_coshf4_ha_l9(float a);\n+   float __svml_coshf8_ha_l9(float a);\n+   float __svml_coshf4_ha_e9(float a);\n+   float __svml_coshf8_ha_e9(float a);\n+   float __svml_coshf16_ha_z0(float a);\n+   double __svml_tanh1_ha_l9(double a);\n+   double __svml_tanh2_ha_l9(double a);\n+   double __svml_tanh4_ha_l9(double a);\n+   double __svml_tanh1_ha_e9(double a);\n+   double __svml_tanh2_ha_e9(double a);\n+   double __svml_tanh4_ha_e9(double a);\n+   double __svml_tanh8_ha_z0(double a);\n+   float __svml_tanhf4_ha_l9(float a);\n+   float __svml_tanhf8_ha_l9(float a);\n+   float __svml_tanhf4_ha_e9(float a);\n+   float __svml_tanhf8_ha_e9(float a);\n+   float __svml_tanhf16_ha_z0(float a);\n+   float __svml_acosf4_ha_ex(float a);\n+   float __svml_acosf4_ha_l9(float a);\n+   float __svml_acosf8_ha_l9(float a);\n+   float __svml_acosf4_ha_e9(float a);\n+   float __svml_acosf8_ha_e9(float a);\n+   float __svml_acosf16_ha_z0(float a);\n+   double __svml_acos1_ha_ex(double a);\n+   double __svml_acos2_ha_ex(double a);\n+   double __svml_acos1_ha_l9(double a);\n+   double __svml_acos2_ha_l9(double a);\n+   double __svml_acos4_ha_l9(double a);\n+   double __svml_acos1_ha_e9(double a);\n+   double __svml_acos2_ha_e9(double a);\n+   double __svml_acos4_ha_e9(double a);\n+   double __svml_acos8_ha_z0(double a);\n+   float __svml_asinf4_ha_ex(float a);\n+   double __svml_asin1_ha_ex(double a);\n+   double __svml_asin2_ha_ex(double a);\n+   double __svml_asin1_ha_l9(double a);\n+   double __svml_asin2_ha_l9(double a);\n+   double __svml_asin4_ha_l9(double a);\n+   double __svml_asin1_ha_e9(double a);\n+   double __svml_asin2_ha_e9(double a);\n+   double __svml_asin4_ha_e9(double a);\n+   double __svml_asin8_ha_z0(double a);\n+   float __svml_asinf4_ha_l9(float a);\n+   float __svml_asinf8_ha_l9(float a);\n+   float __svml_asinf4_ha_e9(float a);\n+   float __svml_asinf8_ha_e9(float a);\n+   float __svml_asinf16_ha_z0(float a);\n+   float __svml_atanf4_ha_ex(float a);\n+   double __svml_atan1_ha_ex(double a);\n+   double __svml_atan2_ha_ex(double a);\n+   double __svml_atan1_ha_l9(double a);\n+   double __svml_atan2_ha_l9(double a);\n+   double __svml_atan4_ha_l9(double a);\n+   double __svml_atan1_ha_e9(double a);\n+   double __svml_atan2_ha_e9(double a);\n+   double __svml_atan4_ha_e9(double a);\n+   double __svml_atan8_ha_z0(double a);\n+   float __svml_atanf4_ha_l9(float a);\n+   float __svml_atanf8_ha_l9(float a);\n+   float __svml_atanf4_ha_e9(float a);\n+   float __svml_atanf8_ha_e9(float a);\n+   float __svml_atanf16_ha_z0(float a);\n+   float __svml_powf4_ha_l9(float a, float b);\n+   float __svml_powf8_ha_l9(float a, float b);\n+   float __svml_powf4_ha_e9(float a, float b);\n+   float __svml_powf8_ha_e9(float a, float b);\n+   float __svml_powf16_ha_z0(float a, float b);\n+   double __svml_pow1_ha_l9(double a, double b);\n+   double __svml_pow2_ha_l9(double a, double b);\n+   double __svml_pow4_ha_l9(double a, double b);\n+   double __svml_pow1_ha_e9(double a, double b);\n+   double __svml_pow2_ha_e9(double a, double b);\n+   double __svml_pow4_ha_e9(double a, double b);\n+   double __svml_pow8_ha_z0(double a, double b);\n+   float __svml_hypotf4_ha_l9(float a, float b);\n+   float __svml_hypotf8_ha_l9(float a, float b);\n+   float __svml_hypotf4_ha_e9(float a, float b);\n+   float __svml_hypotf8_ha_e9(float a, float b);\n+   float __svml_hypotf16_ha_z0(float a, float b);\n+   double __svml_hypot1_ha_l9(double a, double b);\n+   double __svml_hypot2_ha_l9(double a, double b);\n+   double __svml_hypot4_ha_l9(double a, double b);\n+   double __svml_hypot1_ha_e9(double a, double b);\n+   double __svml_hypot2_ha_e9(double a, double b);\n+   double __svml_hypot4_ha_e9(double a, double b);\n+   double __svml_hypot8_ha_z0(double a, double b);\n+   float __svml_cbrtf4_ha_l9(float a);\n+   float __svml_cbrtf8_ha_l9(float a);\n+   float __svml_cbrtf4_ha_e9(float a);\n+   float __svml_cbrtf8_ha_e9(float a);\n+   float __svml_cbrtf16_ha_z0(float a);\n+   double __svml_cbrt1_ha_l9(double a);\n+   double __svml_cbrt2_ha_l9(double a);\n+   double __svml_cbrt4_ha_l9(double a);\n+   double __svml_cbrt1_ha_e9(double a);\n+   double __svml_cbrt2_ha_e9(double a);\n+   double __svml_cbrt4_ha_e9(double a);\n+   double __svml_cbrt8_ha_z0(double a);\n+   float __svml_atan2f4_ha_l9(float a, float b);\n+   float __svml_atan2f8_ha_l9(float a, float b);\n+   float __svml_atan2f4_ha_e9(float a, float b);\n+   float __svml_atan2f8_ha_e9(float a, float b);\n+   float __svml_atan2f16_ha_z0(float a, float b);\n+   double __svml_atan21_ha_l9(double a, double b);\n+   double __svml_atan22_ha_l9(double a, double b);\n+   double __svml_atan24_ha_l9(double a, double b);\n+   double __svml_atan28_ha_z0(double a, double b);\n+   double __svml_atan21_ha_e9(double a, double b);\n+   double __svml_atan22_ha_e9(double a, double b);\n+   double __svml_atan24_ha_e9(double a, double b);\n+   float __svml_sinf4_ha_ex(float a);\n+   double __svml_sin1_ha_ex(double a);\n+   double __svml_sin2_ha_ex(double a);\n+   float __svml_cosf4_ha_ex(float a);\n+   double __svml_cos1_ha_ex(double a);\n+   double __svml_cos2_ha_ex(double a);\n+   float __svml_tanf4_ha_ex(float a);\n+   double __svml_tan1_ha_ex(double a);\n+   double __svml_tan2_ha_ex(double a);\n+   float __svml_sinhf4_ha_ex(float a);\n+   double __svml_sinh1_ha_ex(double a);\n+   double __svml_sinh2_ha_ex(double a);\n+   float __svml_coshf4_ha_ex(float a);\n+   double __svml_cosh1_ha_ex(double a);\n+   double __svml_cosh2_ha_ex(double a);\n+   float __svml_tanhf4_ha_ex(float a);\n+   double __svml_tanh1_ha_ex(double a);\n+   double __svml_tanh2_ha_ex(double a);\n+   double __svml_log1_ha_ex(double a);\n+   double __svml_log2_ha_ex(double a);\n+   double __svml_log1p1_ha_ex(double a);\n+   double __svml_log1p2_ha_ex(double a);\n+   double __svml_log101_ha_ex(double a);\n+   double __svml_log102_ha_ex(double a);\n+   float __svml_logf4_ha_ex(float a);\n+   float __svml_log1pf4_ha_ex(float a);\n+   float __svml_log10f4_ha_ex(float a);\n+   double __svml_atan21_ha_ex(double a);\n+   double __svml_atan22_ha_ex(double a);\n+   float __svml_atan2f4_ha_ex(float a);\n+   float __svml_hypotf4_ha_ex(float a);\n+   double __svml_hypot1_ha_ex(double a);\n+   double __svml_hypot2_ha_ex(double a);\n+   double __svml_pow1_ha_ex(double a);\n+   double __svml_pow2_ha_ex(double a);\n+   float __svml_powf4_ha_ex(float a);\n+   double __svml_cbrt1_ha_ex(double a);\n+   double __svml_cbrt2_ha_ex(double a);\n+   float __svml_cbrtf4_ha_ex(float a);\n+}\n+#endif\n+\n@@ -6969,0 +7246,335 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+#ifdef __VECTOR_API_MATH_INTRINSICS_LINUX\n+    if (UseAVX > 2) {\n+      StubRoutines::_vector_exp_float512    = CAST_FROM_FN_PTR(address, __svml_expf16_ha_z0);\n+      StubRoutines::_vector_exp_double512   = CAST_FROM_FN_PTR(address, __svml_exp8_ha_z0);\n+      StubRoutines::_vector_expm1_float512  = CAST_FROM_FN_PTR(address, __svml_expm1f16_ha_z0);\n+      StubRoutines::_vector_expm1_double512 = CAST_FROM_FN_PTR(address, __svml_expm18_ha_z0);\n+      StubRoutines::_vector_log1p_float512  = CAST_FROM_FN_PTR(address, __svml_log1pf16_ha_z0);\n+      StubRoutines::_vector_log1p_double512 = CAST_FROM_FN_PTR(address, __svml_log1p8_ha_z0);\n+      StubRoutines::_vector_log_float512    = CAST_FROM_FN_PTR(address, __svml_logf16_ha_z0);\n+      StubRoutines::_vector_log_double512   = CAST_FROM_FN_PTR(address, __svml_log8_ha_z0);\n+      StubRoutines::_vector_log10_float512  = CAST_FROM_FN_PTR(address, __svml_log10f16_ha_z0);\n+      StubRoutines::_vector_log10_double512 = CAST_FROM_FN_PTR(address, __svml_log108_ha_z0);\n+      StubRoutines::_vector_sin_float512    = CAST_FROM_FN_PTR(address, __svml_sinf16_ha_z0);\n+      StubRoutines::_vector_sin_double512   = CAST_FROM_FN_PTR(address, __svml_sin8_ha_z0);\n+      StubRoutines::_vector_cos_float512    = CAST_FROM_FN_PTR(address, __svml_cosf16_ha_z0);\n+      StubRoutines::_vector_cos_double512   = CAST_FROM_FN_PTR(address, __svml_cos8_ha_z0);\n+      StubRoutines::_vector_tan_float512    = CAST_FROM_FN_PTR(address, __svml_tanf16_ha_z0);\n+      StubRoutines::_vector_tan_double512   = CAST_FROM_FN_PTR(address, __svml_tan8_ha_z0);\n+      StubRoutines::_vector_sinh_float512   = CAST_FROM_FN_PTR(address, __svml_sinhf16_ha_z0);\n+      StubRoutines::_vector_sinh_double512  = CAST_FROM_FN_PTR(address, __svml_sinh8_ha_z0);\n+      StubRoutines::_vector_cosh_float512   = CAST_FROM_FN_PTR(address, __svml_coshf16_ha_z0);\n+      StubRoutines::_vector_cosh_double512  = CAST_FROM_FN_PTR(address, __svml_cosh8_ha_z0);\n+      StubRoutines::_vector_tanh_float512   = CAST_FROM_FN_PTR(address, __svml_tanhf16_ha_z0);\n+      StubRoutines::_vector_tanh_double512  = CAST_FROM_FN_PTR(address, __svml_tanh8_ha_z0);\n+      StubRoutines::_vector_acos_float512   = CAST_FROM_FN_PTR(address, __svml_acosf16_ha_z0);\n+      StubRoutines::_vector_acos_double512  = CAST_FROM_FN_PTR(address, __svml_acos8_ha_z0);\n+      StubRoutines::_vector_asin_float512   = CAST_FROM_FN_PTR(address, __svml_asinf16_ha_z0);\n+      StubRoutines::_vector_asin_double512  = CAST_FROM_FN_PTR(address, __svml_asin8_ha_z0);\n+      StubRoutines::_vector_atan_float512   = CAST_FROM_FN_PTR(address, __svml_atanf16_ha_z0);\n+      StubRoutines::_vector_atan_double512  = CAST_FROM_FN_PTR(address, __svml_atan8_ha_z0);\n+      StubRoutines::_vector_pow_float512    = CAST_FROM_FN_PTR(address, __svml_powf16_ha_z0);\n+      StubRoutines::_vector_pow_double512   = CAST_FROM_FN_PTR(address, __svml_pow8_ha_z0);\n+      StubRoutines::_vector_hypot_float512  = CAST_FROM_FN_PTR(address, __svml_hypotf16_ha_z0);\n+      StubRoutines::_vector_hypot_double512 = CAST_FROM_FN_PTR(address, __svml_hypot8_ha_z0);\n+      StubRoutines::_vector_cbrt_float512   = CAST_FROM_FN_PTR(address, __svml_cbrtf16_ha_z0);\n+      StubRoutines::_vector_cbrt_double512  = CAST_FROM_FN_PTR(address, __svml_cbrt8_ha_z0);\n+      StubRoutines::_vector_atan2_float512  = CAST_FROM_FN_PTR(address, __svml_atan2f16_ha_z0);\n+      StubRoutines::_vector_atan2_double512 = CAST_FROM_FN_PTR(address, __svml_atan28_ha_z0);\n+    }\n+#endif\n+    if (UseAVX > 1) {\n+      StubRoutines::_vector_exp_float64     = CAST_FROM_FN_PTR(address, __svml_expf4_ha_l9);\n+      StubRoutines::_vector_exp_float128    = CAST_FROM_FN_PTR(address, __svml_expf4_ha_l9);\n+      StubRoutines::_vector_exp_float256    = CAST_FROM_FN_PTR(address, __svml_expf8_ha_l9);\n+      StubRoutines::_vector_exp_double64    = CAST_FROM_FN_PTR(address, __svml_exp1_ha_l9);\n+      StubRoutines::_vector_exp_double128   = CAST_FROM_FN_PTR(address, __svml_exp2_ha_l9);\n+      StubRoutines::_vector_exp_double256   = CAST_FROM_FN_PTR(address, __svml_exp4_ha_l9);\n+      StubRoutines::_vector_expm1_float64   = CAST_FROM_FN_PTR(address, __svml_expm1f4_ha_l9);\n+      StubRoutines::_vector_expm1_float128  = CAST_FROM_FN_PTR(address, __svml_expm1f4_ha_l9);\n+      StubRoutines::_vector_expm1_float256  = CAST_FROM_FN_PTR(address, __svml_expm1f8_ha_l9);\n+      StubRoutines::_vector_expm1_double64  = CAST_FROM_FN_PTR(address, __svml_expm11_ha_l9);\n+      StubRoutines::_vector_expm1_double128 = CAST_FROM_FN_PTR(address, __svml_expm12_ha_l9);\n+      StubRoutines::_vector_expm1_double256 = CAST_FROM_FN_PTR(address, __svml_expm14_ha_l9);\n+      StubRoutines::_vector_log1p_float64   = CAST_FROM_FN_PTR(address, __svml_log1pf4_ha_l9);\n+      StubRoutines::_vector_log1p_float128  = CAST_FROM_FN_PTR(address, __svml_log1pf4_ha_l9);\n+      StubRoutines::_vector_log1p_float256  = CAST_FROM_FN_PTR(address, __svml_log1pf8_ha_l9);\n+      StubRoutines::_vector_log1p_double64  = CAST_FROM_FN_PTR(address, __svml_log1p1_ha_l9);\n+      StubRoutines::_vector_log1p_double128 = CAST_FROM_FN_PTR(address, __svml_log1p2_ha_l9);\n+      StubRoutines::_vector_log1p_double256 = CAST_FROM_FN_PTR(address, __svml_log1p4_ha_l9);\n+      StubRoutines::_vector_log_float64     = CAST_FROM_FN_PTR(address, __svml_logf4_ha_l9);\n+      StubRoutines::_vector_log_float128    = CAST_FROM_FN_PTR(address, __svml_logf4_ha_l9);\n+      StubRoutines::_vector_log_float256    = CAST_FROM_FN_PTR(address, __svml_logf8_ha_l9);\n+      StubRoutines::_vector_log_double64    = CAST_FROM_FN_PTR(address, __svml_log1_ha_l9);\n+      StubRoutines::_vector_log_double128   = CAST_FROM_FN_PTR(address, __svml_log2_ha_l9);\n+      StubRoutines::_vector_log_double256   = CAST_FROM_FN_PTR(address, __svml_log4_ha_l9);\n+      StubRoutines::_vector_log10_float64   = CAST_FROM_FN_PTR(address, __svml_log10f4_ha_l9);\n+      StubRoutines::_vector_log10_float128  = CAST_FROM_FN_PTR(address, __svml_log10f4_ha_l9);\n+      StubRoutines::_vector_log10_float256  = CAST_FROM_FN_PTR(address, __svml_log10f8_ha_l9);\n+      StubRoutines::_vector_log10_double64  = CAST_FROM_FN_PTR(address, __svml_log101_ha_l9);\n+      StubRoutines::_vector_log10_double128 = CAST_FROM_FN_PTR(address, __svml_log102_ha_l9);\n+      StubRoutines::_vector_log10_double256 = CAST_FROM_FN_PTR(address, __svml_log104_ha_l9);\n+      StubRoutines::_vector_sin_float64     = CAST_FROM_FN_PTR(address, __svml_sinf4_ha_l9);\n+      StubRoutines::_vector_sin_float128    = CAST_FROM_FN_PTR(address, __svml_sinf4_ha_l9);\n+      StubRoutines::_vector_sin_float256    = CAST_FROM_FN_PTR(address, __svml_sinf8_ha_l9);\n+      StubRoutines::_vector_sin_double64    = CAST_FROM_FN_PTR(address, __svml_sin1_ha_l9);\n+      StubRoutines::_vector_sin_double128   = CAST_FROM_FN_PTR(address, __svml_sin2_ha_l9);\n+      StubRoutines::_vector_sin_double256   = CAST_FROM_FN_PTR(address, __svml_sin4_ha_l9);\n+      StubRoutines::_vector_cos_float64     = CAST_FROM_FN_PTR(address, __svml_cosf4_ha_l9);\n+      StubRoutines::_vector_cos_float128    = CAST_FROM_FN_PTR(address, __svml_cosf4_ha_l9);\n+      StubRoutines::_vector_cos_float256    = CAST_FROM_FN_PTR(address, __svml_cosf8_ha_l9);\n+      StubRoutines::_vector_cos_double64    = CAST_FROM_FN_PTR(address, __svml_cos1_ha_l9);\n+      StubRoutines::_vector_cos_double128   = CAST_FROM_FN_PTR(address, __svml_cos2_ha_l9);\n+      StubRoutines::_vector_cos_double256   = CAST_FROM_FN_PTR(address, __svml_cos4_ha_l9);\n+      StubRoutines::_vector_tan_float64     = CAST_FROM_FN_PTR(address, __svml_tanf4_ha_l9);\n+      StubRoutines::_vector_tan_float128    = CAST_FROM_FN_PTR(address, __svml_tanf4_ha_l9);\n+      StubRoutines::_vector_tan_float256    = CAST_FROM_FN_PTR(address, __svml_tanf8_ha_l9);\n+      StubRoutines::_vector_tan_double64    = CAST_FROM_FN_PTR(address, __svml_tan1_ha_l9);\n+      StubRoutines::_vector_tan_double128   = CAST_FROM_FN_PTR(address, __svml_tan2_ha_l9);\n+      StubRoutines::_vector_tan_double256   = CAST_FROM_FN_PTR(address, __svml_tan4_ha_l9);\n+      StubRoutines::_vector_sinh_float64    = CAST_FROM_FN_PTR(address, __svml_sinhf4_ha_l9);\n+      StubRoutines::_vector_sinh_float128   = CAST_FROM_FN_PTR(address, __svml_sinhf4_ha_l9);\n+      StubRoutines::_vector_sinh_float256   = CAST_FROM_FN_PTR(address, __svml_sinhf8_ha_l9);\n+      StubRoutines::_vector_sinh_double64   = CAST_FROM_FN_PTR(address, __svml_sinh1_ha_l9);\n+      StubRoutines::_vector_sinh_double128  = CAST_FROM_FN_PTR(address, __svml_sinh2_ha_l9);\n+      StubRoutines::_vector_sinh_double256  = CAST_FROM_FN_PTR(address, __svml_sinh4_ha_l9);\n+      StubRoutines::_vector_cosh_float64    = CAST_FROM_FN_PTR(address, __svml_coshf4_ha_l9);\n+      StubRoutines::_vector_cosh_float128   = CAST_FROM_FN_PTR(address, __svml_coshf4_ha_l9);\n+      StubRoutines::_vector_cosh_float256   = CAST_FROM_FN_PTR(address, __svml_coshf8_ha_l9);\n+      StubRoutines::_vector_cosh_double64   = CAST_FROM_FN_PTR(address, __svml_cosh1_ha_l9);\n+      StubRoutines::_vector_cosh_double128  = CAST_FROM_FN_PTR(address, __svml_cosh2_ha_l9);\n+      StubRoutines::_vector_cosh_double256  = CAST_FROM_FN_PTR(address, __svml_cosh4_ha_l9);\n+      StubRoutines::_vector_tanh_float64    = CAST_FROM_FN_PTR(address, __svml_tanhf4_ha_l9);\n+      StubRoutines::_vector_tanh_float128   = CAST_FROM_FN_PTR(address, __svml_tanhf4_ha_l9);\n+      StubRoutines::_vector_tanh_float256   = CAST_FROM_FN_PTR(address, __svml_tanhf8_ha_l9);\n+      StubRoutines::_vector_tanh_double64   = CAST_FROM_FN_PTR(address, __svml_tanh1_ha_l9);\n+      StubRoutines::_vector_tanh_double128  = CAST_FROM_FN_PTR(address, __svml_tanh2_ha_l9);\n+      StubRoutines::_vector_tanh_double256  = CAST_FROM_FN_PTR(address, __svml_tanh4_ha_l9);\n+      StubRoutines::_vector_acos_float64    = CAST_FROM_FN_PTR(address, __svml_acosf4_ha_l9);\n+      StubRoutines::_vector_acos_float128   = CAST_FROM_FN_PTR(address, __svml_acosf4_ha_l9);\n+      StubRoutines::_vector_acos_float256   = CAST_FROM_FN_PTR(address, __svml_acosf8_ha_l9);\n+      StubRoutines::_vector_acos_double64   = CAST_FROM_FN_PTR(address, __svml_acos1_ha_l9);\n+      StubRoutines::_vector_acos_double128  = CAST_FROM_FN_PTR(address, __svml_acos2_ha_l9);\n+      StubRoutines::_vector_acos_double256  = CAST_FROM_FN_PTR(address, __svml_acos4_ha_l9);\n+      StubRoutines::_vector_asin_float64    = CAST_FROM_FN_PTR(address, __svml_asinf4_ha_l9);\n+      StubRoutines::_vector_asin_float128   = CAST_FROM_FN_PTR(address, __svml_asinf4_ha_l9);\n+      StubRoutines::_vector_asin_float256   = CAST_FROM_FN_PTR(address, __svml_asinf8_ha_l9);\n+      StubRoutines::_vector_asin_double64   = CAST_FROM_FN_PTR(address, __svml_asin1_ha_l9);\n+      StubRoutines::_vector_asin_double128  = CAST_FROM_FN_PTR(address, __svml_asin2_ha_l9);\n+      StubRoutines::_vector_asin_double256  = CAST_FROM_FN_PTR(address, __svml_asin4_ha_l9);\n+      StubRoutines::_vector_atan_float64    = CAST_FROM_FN_PTR(address, __svml_atanf4_ha_l9);\n+      StubRoutines::_vector_atan_float128   = CAST_FROM_FN_PTR(address, __svml_atanf4_ha_l9);\n+      StubRoutines::_vector_atan_float256   = CAST_FROM_FN_PTR(address, __svml_atanf8_ha_l9);\n+      StubRoutines::_vector_atan_double64   = CAST_FROM_FN_PTR(address, __svml_atan1_ha_l9);\n+      StubRoutines::_vector_atan_double128  = CAST_FROM_FN_PTR(address, __svml_atan2_ha_l9);\n+      StubRoutines::_vector_atan_double256  = CAST_FROM_FN_PTR(address, __svml_atan4_ha_l9);\n+      StubRoutines::_vector_pow_float64     = CAST_FROM_FN_PTR(address, __svml_powf4_ha_l9);\n+      StubRoutines::_vector_pow_float128    = CAST_FROM_FN_PTR(address, __svml_powf4_ha_l9);\n+      StubRoutines::_vector_pow_float256    = CAST_FROM_FN_PTR(address, __svml_powf8_ha_l9);\n+      StubRoutines::_vector_pow_double64    = CAST_FROM_FN_PTR(address, __svml_pow1_ha_l9);\n+      StubRoutines::_vector_pow_double128   = CAST_FROM_FN_PTR(address, __svml_pow2_ha_l9);\n+      StubRoutines::_vector_pow_double256   = CAST_FROM_FN_PTR(address, __svml_pow4_ha_l9);\n+      StubRoutines::_vector_hypot_float64   = CAST_FROM_FN_PTR(address, __svml_hypotf4_ha_l9);\n+      StubRoutines::_vector_hypot_float128  = CAST_FROM_FN_PTR(address, __svml_hypotf4_ha_l9);\n+      StubRoutines::_vector_hypot_float256  = CAST_FROM_FN_PTR(address, __svml_hypotf8_ha_l9);\n+      StubRoutines::_vector_hypot_double64  = CAST_FROM_FN_PTR(address, __svml_hypot1_ha_l9);\n+      StubRoutines::_vector_hypot_double128 = CAST_FROM_FN_PTR(address, __svml_hypot2_ha_l9);\n+      StubRoutines::_vector_hypot_double256 = CAST_FROM_FN_PTR(address, __svml_hypot4_ha_l9);\n+      StubRoutines::_vector_cbrt_float64    = CAST_FROM_FN_PTR(address, __svml_cbrtf4_ha_l9);\n+      StubRoutines::_vector_cbrt_float128   = CAST_FROM_FN_PTR(address, __svml_cbrtf4_ha_l9);\n+      StubRoutines::_vector_cbrt_float256   = CAST_FROM_FN_PTR(address, __svml_cbrtf8_ha_l9);\n+      StubRoutines::_vector_cbrt_double64   = CAST_FROM_FN_PTR(address, __svml_cbrt1_ha_l9);\n+      StubRoutines::_vector_cbrt_double128  = CAST_FROM_FN_PTR(address, __svml_cbrt2_ha_l9);\n+      StubRoutines::_vector_cbrt_double256  = CAST_FROM_FN_PTR(address, __svml_cbrt4_ha_l9);\n+      StubRoutines::_vector_atan2_float64   = CAST_FROM_FN_PTR(address, __svml_atan2f4_ha_l9);\n+      StubRoutines::_vector_atan2_float128  = CAST_FROM_FN_PTR(address, __svml_atan2f4_ha_l9);\n+      StubRoutines::_vector_atan2_float256  = CAST_FROM_FN_PTR(address, __svml_atan2f8_ha_l9);\n+      StubRoutines::_vector_atan2_double64  = CAST_FROM_FN_PTR(address, __svml_atan21_ha_l9);\n+      StubRoutines::_vector_atan2_double128 = CAST_FROM_FN_PTR(address, __svml_atan22_ha_l9);\n+      StubRoutines::_vector_atan2_double256 = CAST_FROM_FN_PTR(address, __svml_atan24_ha_l9);\n+    } else if (UseAVX > 0) {\n+      StubRoutines::_vector_exp_float64     = CAST_FROM_FN_PTR(address, __svml_expf4_ha_e9);\n+      StubRoutines::_vector_exp_float128    = CAST_FROM_FN_PTR(address, __svml_expf4_ha_e9);\n+      StubRoutines::_vector_exp_float256    = CAST_FROM_FN_PTR(address, __svml_expf8_ha_e9);\n+      StubRoutines::_vector_exp_double64    = CAST_FROM_FN_PTR(address, __svml_exp1_ha_e9);\n+      StubRoutines::_vector_exp_double128   = CAST_FROM_FN_PTR(address, __svml_exp2_ha_e9);\n+      StubRoutines::_vector_exp_double256   = CAST_FROM_FN_PTR(address, __svml_exp4_ha_e9);\n+      StubRoutines::_vector_expm1_float64   = CAST_FROM_FN_PTR(address, __svml_expm1f4_ha_e9);\n+      StubRoutines::_vector_expm1_float128  = CAST_FROM_FN_PTR(address, __svml_expm1f4_ha_e9);\n+      StubRoutines::_vector_expm1_float256  = CAST_FROM_FN_PTR(address, __svml_expm1f8_ha_e9);\n+      StubRoutines::_vector_expm1_double64  = CAST_FROM_FN_PTR(address, __svml_expm11_ha_e9);\n+      StubRoutines::_vector_expm1_double128 = CAST_FROM_FN_PTR(address, __svml_expm12_ha_e9);\n+      StubRoutines::_vector_expm1_double256 = CAST_FROM_FN_PTR(address, __svml_expm14_ha_e9);\n+      StubRoutines::_vector_log1p_float64   = CAST_FROM_FN_PTR(address, __svml_log1pf4_ha_e9);\n+      StubRoutines::_vector_log1p_float128  = CAST_FROM_FN_PTR(address, __svml_log1pf4_ha_e9);\n+      StubRoutines::_vector_log1p_float256  = CAST_FROM_FN_PTR(address, __svml_log1pf8_ha_e9);\n+      StubRoutines::_vector_log1p_double64  = CAST_FROM_FN_PTR(address, __svml_log1p1_ha_e9);\n+      StubRoutines::_vector_log1p_double128 = CAST_FROM_FN_PTR(address, __svml_log1p2_ha_e9);\n+      StubRoutines::_vector_log1p_double256 = CAST_FROM_FN_PTR(address, __svml_log1p4_ha_e9);\n+      StubRoutines::_vector_log_float64     = CAST_FROM_FN_PTR(address, __svml_logf4_ha_e9);\n+      StubRoutines::_vector_log_float128    = CAST_FROM_FN_PTR(address, __svml_logf4_ha_e9);\n+      StubRoutines::_vector_log_float256    = CAST_FROM_FN_PTR(address, __svml_logf8_ha_e9);\n+      StubRoutines::_vector_log_double64    = CAST_FROM_FN_PTR(address, __svml_log1_ha_e9);\n+      StubRoutines::_vector_log_double128   = CAST_FROM_FN_PTR(address, __svml_log2_ha_e9);\n+      StubRoutines::_vector_log_double256   = CAST_FROM_FN_PTR(address, __svml_log4_ha_e9);\n+      StubRoutines::_vector_log10_float64   = CAST_FROM_FN_PTR(address, __svml_log10f4_ha_e9);\n+      StubRoutines::_vector_log10_float128  = CAST_FROM_FN_PTR(address, __svml_log10f4_ha_e9);\n+      StubRoutines::_vector_log10_float256  = CAST_FROM_FN_PTR(address, __svml_log10f8_ha_e9);\n+      StubRoutines::_vector_log10_double64  = CAST_FROM_FN_PTR(address, __svml_log101_ha_e9);\n+      StubRoutines::_vector_log10_double128 = CAST_FROM_FN_PTR(address, __svml_log102_ha_e9);\n+      StubRoutines::_vector_log10_double256 = CAST_FROM_FN_PTR(address, __svml_log104_ha_e9);\n+      StubRoutines::_vector_sin_float64     = CAST_FROM_FN_PTR(address, __svml_sinf4_ha_e9);\n+      StubRoutines::_vector_sin_float128    = CAST_FROM_FN_PTR(address, __svml_sinf4_ha_e9);\n+      StubRoutines::_vector_sin_float256    = CAST_FROM_FN_PTR(address, __svml_sinf8_ha_e9);\n+      StubRoutines::_vector_sin_double64    = CAST_FROM_FN_PTR(address, __svml_sin1_ha_e9);\n+      StubRoutines::_vector_sin_double128   = CAST_FROM_FN_PTR(address, __svml_sin2_ha_e9);\n+      StubRoutines::_vector_sin_double256   = CAST_FROM_FN_PTR(address, __svml_sin4_ha_e9);\n+      StubRoutines::_vector_cos_float64     = CAST_FROM_FN_PTR(address, __svml_cosf4_ha_e9);\n+      StubRoutines::_vector_cos_float128    = CAST_FROM_FN_PTR(address, __svml_cosf4_ha_e9);\n+      StubRoutines::_vector_cos_float256    = CAST_FROM_FN_PTR(address, __svml_cosf8_ha_e9);\n+      StubRoutines::_vector_cos_double64    = CAST_FROM_FN_PTR(address, __svml_cos1_ha_e9);\n+      StubRoutines::_vector_cos_double128   = CAST_FROM_FN_PTR(address, __svml_cos2_ha_e9);\n+      StubRoutines::_vector_cos_double256   = CAST_FROM_FN_PTR(address, __svml_cos4_ha_e9);\n+      StubRoutines::_vector_tan_float64     = CAST_FROM_FN_PTR(address, __svml_tanf4_ha_e9);\n+      StubRoutines::_vector_tan_float128    = CAST_FROM_FN_PTR(address, __svml_tanf4_ha_e9);\n+      StubRoutines::_vector_tan_float256    = CAST_FROM_FN_PTR(address, __svml_tanf8_ha_e9);\n+      StubRoutines::_vector_tan_double64    = CAST_FROM_FN_PTR(address, __svml_tan1_ha_e9);\n+      StubRoutines::_vector_tan_double128   = CAST_FROM_FN_PTR(address, __svml_tan2_ha_e9);\n+      StubRoutines::_vector_tan_double256   = CAST_FROM_FN_PTR(address, __svml_tan4_ha_e9);\n+      StubRoutines::_vector_sinh_float64    = CAST_FROM_FN_PTR(address, __svml_sinhf4_ha_e9);\n+      StubRoutines::_vector_sinh_float128   = CAST_FROM_FN_PTR(address, __svml_sinhf4_ha_e9);\n+      StubRoutines::_vector_sinh_float256   = CAST_FROM_FN_PTR(address, __svml_sinhf8_ha_e9);\n+      StubRoutines::_vector_sinh_double64   = CAST_FROM_FN_PTR(address, __svml_sinh1_ha_e9);\n+      StubRoutines::_vector_sinh_double128  = CAST_FROM_FN_PTR(address, __svml_sinh2_ha_e9);\n+      StubRoutines::_vector_sinh_double256  = CAST_FROM_FN_PTR(address, __svml_sinh4_ha_e9);\n+      StubRoutines::_vector_cosh_float64    = CAST_FROM_FN_PTR(address, __svml_coshf4_ha_e9);\n+      StubRoutines::_vector_cosh_float128   = CAST_FROM_FN_PTR(address, __svml_coshf4_ha_e9);\n+      StubRoutines::_vector_cosh_float256   = CAST_FROM_FN_PTR(address, __svml_coshf8_ha_e9);\n+      StubRoutines::_vector_cosh_double64   = CAST_FROM_FN_PTR(address, __svml_cosh1_ha_e9);\n+      StubRoutines::_vector_cosh_double128  = CAST_FROM_FN_PTR(address, __svml_cosh2_ha_e9);\n+      StubRoutines::_vector_cosh_double256  = CAST_FROM_FN_PTR(address, __svml_cosh4_ha_e9);\n+      StubRoutines::_vector_tanh_float64    = CAST_FROM_FN_PTR(address, __svml_tanhf4_ha_e9);\n+      StubRoutines::_vector_tanh_float128   = CAST_FROM_FN_PTR(address, __svml_tanhf4_ha_e9);\n+      StubRoutines::_vector_tanh_float256   = CAST_FROM_FN_PTR(address, __svml_tanhf8_ha_e9);\n+      StubRoutines::_vector_tanh_double64   = CAST_FROM_FN_PTR(address, __svml_tanh1_ha_e9);\n+      StubRoutines::_vector_tanh_double128  = CAST_FROM_FN_PTR(address, __svml_tanh2_ha_e9);\n+      StubRoutines::_vector_tanh_double256  = CAST_FROM_FN_PTR(address, __svml_tanh4_ha_e9);\n+      StubRoutines::_vector_acos_float64    = CAST_FROM_FN_PTR(address, __svml_acosf4_ha_e9);\n+      StubRoutines::_vector_acos_float128   = CAST_FROM_FN_PTR(address, __svml_acosf4_ha_e9);\n+      StubRoutines::_vector_acos_float256   = CAST_FROM_FN_PTR(address, __svml_acosf8_ha_e9);\n+      StubRoutines::_vector_acos_double64   = CAST_FROM_FN_PTR(address, __svml_acos1_ha_e9);\n+      StubRoutines::_vector_acos_double128  = CAST_FROM_FN_PTR(address, __svml_acos2_ha_e9);\n+      StubRoutines::_vector_acos_double256  = CAST_FROM_FN_PTR(address, __svml_acos4_ha_e9);\n+      StubRoutines::_vector_asin_float64    = CAST_FROM_FN_PTR(address, __svml_asinf4_ha_e9);\n+      StubRoutines::_vector_asin_float128   = CAST_FROM_FN_PTR(address, __svml_asinf4_ha_e9);\n+      StubRoutines::_vector_asin_float256   = CAST_FROM_FN_PTR(address, __svml_asinf8_ha_e9);\n+      StubRoutines::_vector_asin_double64   = CAST_FROM_FN_PTR(address, __svml_asin1_ha_e9);\n+      StubRoutines::_vector_asin_double128  = CAST_FROM_FN_PTR(address, __svml_asin2_ha_e9);\n+      StubRoutines::_vector_asin_double256  = CAST_FROM_FN_PTR(address, __svml_asin4_ha_e9);\n+      StubRoutines::_vector_atan_float64    = CAST_FROM_FN_PTR(address, __svml_atanf4_ha_e9);\n+      StubRoutines::_vector_atan_float128   = CAST_FROM_FN_PTR(address, __svml_atanf4_ha_e9);\n+      StubRoutines::_vector_atan_float256   = CAST_FROM_FN_PTR(address, __svml_atanf8_ha_e9);\n+      StubRoutines::_vector_atan_double64   = CAST_FROM_FN_PTR(address, __svml_atan1_ha_e9);\n+      StubRoutines::_vector_atan_double128  = CAST_FROM_FN_PTR(address, __svml_atan2_ha_e9);\n+      StubRoutines::_vector_atan_double256  = CAST_FROM_FN_PTR(address, __svml_atan4_ha_e9);\n+      StubRoutines::_vector_pow_float64     = CAST_FROM_FN_PTR(address, __svml_powf4_ha_e9);\n+      StubRoutines::_vector_pow_float128    = CAST_FROM_FN_PTR(address, __svml_powf4_ha_e9);\n+      StubRoutines::_vector_pow_float256    = CAST_FROM_FN_PTR(address, __svml_powf8_ha_e9);\n+      StubRoutines::_vector_pow_double64    = CAST_FROM_FN_PTR(address, __svml_pow1_ha_e9);\n+      StubRoutines::_vector_pow_double128   = CAST_FROM_FN_PTR(address, __svml_pow2_ha_e9);\n+      StubRoutines::_vector_pow_double256   = CAST_FROM_FN_PTR(address, __svml_pow4_ha_e9);\n+      StubRoutines::_vector_hypot_float64   = CAST_FROM_FN_PTR(address, __svml_hypotf4_ha_e9);\n+      StubRoutines::_vector_hypot_float128  = CAST_FROM_FN_PTR(address, __svml_hypotf4_ha_e9);\n+      StubRoutines::_vector_hypot_float256  = CAST_FROM_FN_PTR(address, __svml_hypotf8_ha_e9);\n+      StubRoutines::_vector_hypot_double64  = CAST_FROM_FN_PTR(address, __svml_hypot1_ha_e9);\n+      StubRoutines::_vector_hypot_double128 = CAST_FROM_FN_PTR(address, __svml_hypot2_ha_e9);\n+      StubRoutines::_vector_hypot_double256 = CAST_FROM_FN_PTR(address, __svml_hypot4_ha_e9);\n+      StubRoutines::_vector_cbrt_float64    = CAST_FROM_FN_PTR(address, __svml_cbrtf4_ha_e9);\n+      StubRoutines::_vector_cbrt_float128   = CAST_FROM_FN_PTR(address, __svml_cbrtf4_ha_e9);\n+      StubRoutines::_vector_cbrt_float256   = CAST_FROM_FN_PTR(address, __svml_cbrtf8_ha_e9);\n+      StubRoutines::_vector_cbrt_double64   = CAST_FROM_FN_PTR(address, __svml_cbrt1_ha_e9);\n+      StubRoutines::_vector_cbrt_double128  = CAST_FROM_FN_PTR(address, __svml_cbrt2_ha_e9);\n+      StubRoutines::_vector_cbrt_double256  = CAST_FROM_FN_PTR(address, __svml_cbrt4_ha_e9);\n+      StubRoutines::_vector_atan2_float64   = CAST_FROM_FN_PTR(address, __svml_atan2f4_ha_e9);\n+      StubRoutines::_vector_atan2_float128  = CAST_FROM_FN_PTR(address, __svml_atan2f4_ha_e9);\n+      StubRoutines::_vector_atan2_float256  = CAST_FROM_FN_PTR(address, __svml_atan2f8_ha_e9);\n+      StubRoutines::_vector_atan2_double64  = CAST_FROM_FN_PTR(address, __svml_atan21_ha_e9);\n+      StubRoutines::_vector_atan2_double128 = CAST_FROM_FN_PTR(address, __svml_atan22_ha_e9);\n+      StubRoutines::_vector_atan2_double256 = CAST_FROM_FN_PTR(address, __svml_atan24_ha_e9);\n+    } else {\n+      assert(UseAVX == 0 && UseSSE >= 2, \"\");\n+      StubRoutines::_vector_exp_float64     = CAST_FROM_FN_PTR(address, __svml_expf4_ha_ex);\n+      StubRoutines::_vector_exp_float128    = CAST_FROM_FN_PTR(address, __svml_expf4_ha_ex);\n+      StubRoutines::_vector_exp_double64    = CAST_FROM_FN_PTR(address, __svml_exp1_ha_ex);\n+      StubRoutines::_vector_exp_double128   = CAST_FROM_FN_PTR(address, __svml_exp2_ha_ex);\n+      StubRoutines::_vector_expm1_float64   = CAST_FROM_FN_PTR(address, __svml_expm1f4_ha_ex);\n+      StubRoutines::_vector_expm1_float128  = CAST_FROM_FN_PTR(address, __svml_expm1f4_ha_ex);\n+      StubRoutines::_vector_expm1_double64  = CAST_FROM_FN_PTR(address, __svml_expm11_ha_ex);\n+      StubRoutines::_vector_expm1_double128 = CAST_FROM_FN_PTR(address, __svml_expm12_ha_ex);\n+      StubRoutines::_vector_acos_float64    = CAST_FROM_FN_PTR(address, __svml_acosf4_ha_ex);\n+      StubRoutines::_vector_acos_float128   = CAST_FROM_FN_PTR(address, __svml_acosf4_ha_ex);\n+      StubRoutines::_vector_acos_double64   = CAST_FROM_FN_PTR(address, __svml_acos1_ha_ex);\n+      StubRoutines::_vector_acos_double128  = CAST_FROM_FN_PTR(address, __svml_acos2_ha_ex);\n+      StubRoutines::_vector_asin_float64    = CAST_FROM_FN_PTR(address, __svml_asinf4_ha_ex);\n+      StubRoutines::_vector_asin_float128   = CAST_FROM_FN_PTR(address, __svml_asinf4_ha_ex);\n+      StubRoutines::_vector_asin_double64   = CAST_FROM_FN_PTR(address, __svml_asin1_ha_ex);\n+      StubRoutines::_vector_asin_double128  = CAST_FROM_FN_PTR(address, __svml_asin2_ha_ex);\n+      StubRoutines::_vector_atan_float64    = CAST_FROM_FN_PTR(address, __svml_atanf4_ha_ex);\n+      StubRoutines::_vector_atan_float128   = CAST_FROM_FN_PTR(address, __svml_atanf4_ha_ex);\n+      StubRoutines::_vector_atan_double64   = CAST_FROM_FN_PTR(address, __svml_atan1_ha_ex);\n+      StubRoutines::_vector_atan_double128  = CAST_FROM_FN_PTR(address, __svml_atan2_ha_ex);\n+      StubRoutines::_vector_sin_float64     = CAST_FROM_FN_PTR(address, __svml_sinf4_ha_ex);\n+      StubRoutines::_vector_sin_float128    = CAST_FROM_FN_PTR(address, __svml_sinf4_ha_ex);\n+      StubRoutines::_vector_sin_double64    = CAST_FROM_FN_PTR(address, __svml_sin1_ha_ex);\n+      StubRoutines::_vector_sin_double128   = CAST_FROM_FN_PTR(address, __svml_sin2_ha_ex);\n+      StubRoutines::_vector_cos_float64     = CAST_FROM_FN_PTR(address, __svml_cosf4_ha_ex);\n+      StubRoutines::_vector_cos_float128    = CAST_FROM_FN_PTR(address, __svml_cosf4_ha_ex);\n+      StubRoutines::_vector_cos_double64    = CAST_FROM_FN_PTR(address, __svml_cos1_ha_ex);\n+      StubRoutines::_vector_cos_double128   = CAST_FROM_FN_PTR(address, __svml_cos2_ha_ex);\n+      StubRoutines::_vector_tan_float64     = CAST_FROM_FN_PTR(address, __svml_tanf4_ha_ex);\n+      StubRoutines::_vector_tan_float128    = CAST_FROM_FN_PTR(address, __svml_tanf4_ha_ex);\n+      StubRoutines::_vector_tan_double64    = CAST_FROM_FN_PTR(address, __svml_tan1_ha_ex);\n+      StubRoutines::_vector_tan_double128   = CAST_FROM_FN_PTR(address, __svml_tan2_ha_ex);\n+      StubRoutines::_vector_sinh_float64    = CAST_FROM_FN_PTR(address, __svml_sinhf4_ha_ex);\n+      StubRoutines::_vector_sinh_float128   = CAST_FROM_FN_PTR(address, __svml_sinhf4_ha_ex);\n+      StubRoutines::_vector_sinh_double64   = CAST_FROM_FN_PTR(address, __svml_sinh1_ha_ex);\n+      StubRoutines::_vector_sinh_double128  = CAST_FROM_FN_PTR(address, __svml_sinh2_ha_ex);\n+      StubRoutines::_vector_cosh_float64    = CAST_FROM_FN_PTR(address, __svml_coshf4_ha_ex);\n+      StubRoutines::_vector_cosh_float128   = CAST_FROM_FN_PTR(address, __svml_coshf4_ha_ex);\n+      StubRoutines::_vector_cosh_double64   = CAST_FROM_FN_PTR(address, __svml_cosh1_ha_ex);\n+      StubRoutines::_vector_cosh_double128  = CAST_FROM_FN_PTR(address, __svml_cosh2_ha_ex);\n+      StubRoutines::_vector_tanh_float64    = CAST_FROM_FN_PTR(address, __svml_tanhf4_ha_ex);\n+      StubRoutines::_vector_tanh_float128   = CAST_FROM_FN_PTR(address, __svml_tanhf4_ha_ex);\n+      StubRoutines::_vector_tanh_double64   = CAST_FROM_FN_PTR(address, __svml_tanh1_ha_ex);\n+      StubRoutines::_vector_tanh_double128  = CAST_FROM_FN_PTR(address, __svml_tanh2_ha_ex);\n+      StubRoutines::_vector_log_float64     = CAST_FROM_FN_PTR(address, __svml_logf4_ha_ex);\n+      StubRoutines::_vector_log_float128    = CAST_FROM_FN_PTR(address, __svml_logf4_ha_ex);\n+      StubRoutines::_vector_log_double64    = CAST_FROM_FN_PTR(address, __svml_log1_ha_ex);\n+      StubRoutines::_vector_log_double128   = CAST_FROM_FN_PTR(address, __svml_log2_ha_ex);\n+      StubRoutines::_vector_log10_float64   = CAST_FROM_FN_PTR(address, __svml_log10f4_ha_ex);\n+      StubRoutines::_vector_log10_float128  = CAST_FROM_FN_PTR(address, __svml_log10f4_ha_ex);\n+      StubRoutines::_vector_log10_double64  = CAST_FROM_FN_PTR(address, __svml_log101_ha_ex);\n+      StubRoutines::_vector_log10_double128 = CAST_FROM_FN_PTR(address, __svml_log102_ha_ex);\n+      StubRoutines::_vector_log1p_float64   = CAST_FROM_FN_PTR(address, __svml_log1pf4_ha_ex);\n+      StubRoutines::_vector_log1p_float128  = CAST_FROM_FN_PTR(address, __svml_log1pf4_ha_ex);\n+      StubRoutines::_vector_log1p_double64  = CAST_FROM_FN_PTR(address, __svml_log1p1_ha_ex);\n+      StubRoutines::_vector_log1p_double128 = CAST_FROM_FN_PTR(address, __svml_log1p2_ha_ex);\n+      StubRoutines::_vector_atan2_float64   = CAST_FROM_FN_PTR(address, __svml_atan2f4_ha_ex);\n+      StubRoutines::_vector_atan2_float128  = CAST_FROM_FN_PTR(address, __svml_atan2f4_ha_ex);\n+      StubRoutines::_vector_atan2_double64  = CAST_FROM_FN_PTR(address, __svml_atan21_ha_ex);\n+      StubRoutines::_vector_atan2_double128 = CAST_FROM_FN_PTR(address, __svml_atan22_ha_ex);\n+      StubRoutines::_vector_hypot_float64   = CAST_FROM_FN_PTR(address, __svml_hypotf4_ha_ex);\n+      StubRoutines::_vector_hypot_float128  = CAST_FROM_FN_PTR(address, __svml_hypotf4_ha_ex);\n+      StubRoutines::_vector_hypot_double64  = CAST_FROM_FN_PTR(address, __svml_hypot1_ha_ex);\n+      StubRoutines::_vector_hypot_double128 = CAST_FROM_FN_PTR(address, __svml_hypot2_ha_ex);\n+      StubRoutines::_vector_pow_float64     = CAST_FROM_FN_PTR(address, __svml_powf4_ha_ex);\n+      StubRoutines::_vector_pow_float128    = CAST_FROM_FN_PTR(address, __svml_powf4_ha_ex);\n+      StubRoutines::_vector_pow_double64    = CAST_FROM_FN_PTR(address, __svml_pow1_ha_ex);\n+      StubRoutines::_vector_pow_double128   = CAST_FROM_FN_PTR(address, __svml_pow2_ha_ex);\n+      StubRoutines::_vector_cbrt_float64    = CAST_FROM_FN_PTR(address, __svml_cbrtf4_ha_ex);\n+      StubRoutines::_vector_cbrt_float128   = CAST_FROM_FN_PTR(address, __svml_cbrtf4_ha_ex);\n+      StubRoutines::_vector_cbrt_double64   = CAST_FROM_FN_PTR(address, __svml_cbrt1_ha_ex);\n+      StubRoutines::_vector_cbrt_double128  = CAST_FROM_FN_PTR(address, __svml_cbrt2_ha_ex);\n+    }\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":612,"deletions":0,"binary":false,"changes":612,"status":"modified"},{"patch":"@@ -1617,0 +1617,5 @@\n+    case Op_CallLeafVector:\n+      if (size_in_bits == 512 && !VM_Version::supports_avx512vlbwdq()) {\n+        return false;\n+      }\n+      break;\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1376,0 +1376,14 @@\n+\/\/ Vector calling convention not supported.\n+const bool Matcher::supports_vector_calling_convention() {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1583,0 +1583,17 @@\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return true;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  int lo = XMM0_num;\n+  int hi = XMM0b_num;\n+  if (ideal_reg == Op_VecX) hi = XMM0d_num;\n+  else if (ideal_reg == Op_VecY) hi = XMM0h_num;\n+  else if (ideal_reg == Op_VecZ) hi = XMM0p_num;\n+  return OptoRegPair(hi, lo);\n+}\n+\n@@ -12403,0 +12420,12 @@\n+\/\/ Call runtime without safepoint and with vector arguments\n+instruct CallLeafDirectVector(method meth)\n+%{\n+  match(CallLeafVector);\n+  effect(USE meth);\n+\n+  ins_cost(300);\n+  format %{ \"call_leaf,vector \" %}\n+  ins_encode(Java_To_Runtime(meth));\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -139,0 +139,7 @@\n+\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  ShouldNotCallThis();\n+  return 0;\n+}\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -712,0 +712,3 @@\n+  product(bool, IncrementalInlineVirtual, true, DIAGNOSTIC,                 \\\n+          \"do post parse inlining of virtual calls\")                        \\\n+                                                                            \\\n@@ -752,0 +755,3 @@\n+  product(bool, UseVectorStubs, false, EXPERIMENTAL,                        \\\n+          \"Use stubs for vector transcendental operations\")                 \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -493,0 +493,1 @@\n+          iklass->nof_nonstatic_fields(); \/\/ FIXME: iklass->_nonstatic_fields == NULL\n@@ -620,1 +621,1 @@\n-  for (JVMState* p = this; p->_caller != NULL; p = p->_caller) {\n+  for (JVMState* p = this; p != NULL; p = p->_caller) {\n@@ -723,3 +724,5 @@\n-    OptoRegPair regs = is_CallRuntime()\n-      ? match->c_return_value(ideal_reg)  \/\/ Calls into C runtime\n-      : match->  return_value(ideal_reg); \/\/ Calls into compiled Java code\n+    OptoRegPair regs = Opcode() == Op_CallLeafVector\n+      ? match->vector_return_value(ideal_reg)      \/\/ Calls into assembly vector routine\n+      : is_CallRuntime()\n+        ? match->c_return_value(ideal_reg)  \/\/ Calls into C runtime\n+        : match->  return_value(ideal_reg); \/\/ Calls into compiled Java code\n@@ -727,0 +730,10 @@\n+\n+    \/\/ If the return is in vector, compute appropriate regmask taking into account the whole range\n+    if(ideal_reg >= Op_VecS && ideal_reg <= Op_VecZ) {\n+      if(OptoReg::is_valid(regs.second())) {\n+        for (OptoReg::Name r = regs.first(); r <= regs.second(); r = OptoReg::add(r, 1)) {\n+          rm.Insert(r);\n+        }\n+      }\n+    }\n+\n@@ -1104,0 +1117,42 @@\n+\n+Node* CallDynamicJavaNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  CallGenerator* cg = generator();\n+  if (can_reshape && cg != NULL) {\n+    assert(IncrementalInlineVirtual, \"required\");\n+    assert(cg->call_node() == this, \"mismatch\");\n+    assert(cg->is_virtual_late_inline(), \"not virtual\");\n+\n+    \/\/ Recover symbolic info for method resolution\n+    ciMethod* caller = jvms()->method();\n+    ciBytecodeStream iter(caller);\n+    iter.force_bci(jvms()->bci());\n+\n+    bool             not_used1;\n+    ciSignature*     not_used2;\n+    ciMethod*        orig_callee  = iter.get_method(not_used1, &not_used2);  \/\/ callee in the bytecode\n+    ciKlass*         holder       = iter.get_declared_method_holder();\n+    if (orig_callee->is_method_handle_intrinsic()) {\n+      assert(_override_symbolic_info, \"\");\n+      orig_callee = method();\n+      holder = method()->holder();\n+    }\n+\n+    ciInstanceKlass* klass = ciEnv::get_instance_klass_for_declared_method_holder(holder);\n+\n+    Node* receiver_node = in(TypeFunc::Parms);\n+    const TypeOopPtr* receiver_type = phase->type(receiver_node)->isa_oopptr();\n+\n+    int  not_used3;\n+    bool call_does_dispatch;\n+    ciMethod* callee = phase->C->optimize_virtual_call(caller, jvms()->bci(), klass, holder, orig_callee, receiver_type, true \/*is_virtual*\/,\n+                                                       call_does_dispatch, not_used3);  \/\/ out-parameters\n+    if (!call_does_dispatch) {\n+      \/\/ Register for late inlining\n+      cg->set_callee_method(callee);\n+      phase->C->prepend_late_inline(cg); \/\/ TODO prepend or append for virtual calls? MH late inlining prepends to the list.\n+      set_generator(NULL);\n+    }\n+  }\n+  return CallNode::Ideal(phase, can_reshape);\n+}\n+\n@@ -1124,0 +1179,5 @@\n+uint CallLeafVectorNode::size_of() const { return sizeof(*this); }\n+bool CallLeafVectorNode::cmp( const Node &n ) const {\n+  CallLeafVectorNode &call = (CallLeafVectorNode&)n;\n+  return CallLeafNode::cmp(call) && _num_bits == call._num_bits;\n+}\n@@ -1130,0 +1190,15 @@\n+void CallLeafVectorNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {\n+#ifdef ASSERT\n+  assert(tf()->range()->field_at(TypeFunc::Parms)->is_vect()->length_in_bytes() * BitsPerByte == _num_bits,\n+         \"return vector size must match\");\n+  const TypeTuple* d = tf()->domain();\n+  for (uint i = TypeFunc::Parms; i < d->cnt(); i++) {\n+    Node* arg = in(i);\n+    assert(arg->bottom_type()->is_vect()->length_in_bytes() * BitsPerByte == _num_bits,\n+           \"vector argument size must match\");\n+  }\n+#endif\n+\n+  Matcher::vector_calling_convention(parm_regs, _num_bits, argcnt);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":79,"deletions":4,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+class         CallLeafVectorNode;\n@@ -616,1 +617,1 @@\n-    if (C->needs_clone_jvms() && jvms() != NULL) {\n+    if (jvms() != NULL) {\n@@ -764,0 +765,1 @@\n+  virtual Node *Ideal(PhaseGVN *phase, bool can_reshape);\n@@ -772,0 +774,1 @@\n+protected:\n@@ -822,0 +825,18 @@\n+\/\/------------------------------CallLeafVectorNode-------------------------------\n+\/\/ CallLeafNode but calling with vector calling convention instead.\n+class CallLeafVectorNode : public CallLeafNode {\n+private:\n+  uint _num_bits;\n+protected:\n+  virtual bool cmp( const Node &n ) const;\n+  virtual uint size_of() const; \/\/ Size is bigger\n+public:\n+  CallLeafVectorNode(const TypeFunc* tf, address addr, const char* name,\n+                   const TypePtr* adr_type, uint num_bits)\n+    : CallLeafNode(tf, addr, name, adr_type), _num_bits(num_bits)\n+  {\n+  }\n+  virtual int   Opcode() const;\n+  virtual void  calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":22,"deletions":1,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -61,0 +61,1 @@\n+macro(CallLeafVector)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -349,0 +349,17 @@\n+void Compile::remove_useless_late_inlines(GrowableArray<CallGenerator*>* inlines, Node* dead) {\n+  assert(dead != NULL && dead->is_Call(), \"sanity\");\n+  int shift = 0;\n+  for (int i = 0; i < inlines->length(); i++) {\n+    CallGenerator* cg = inlines->at(i);\n+    CallNode* call = cg->call_node();\n+    if (shift > 0) {\n+      inlines->at_put(i - shift, cg);\n+    }\n+    if (call == dead) {\n+      shift++;\n+    }\n+  }\n+  inlines->trunc_to(inlines->length() - shift);\n+  assert(shift <= 1, \"sanity\");\n+}\n+\n@@ -1857,0 +1874,1 @@\n+\n@@ -1859,2 +1877,2 @@\n-  int i = 0;\n-  for (; i <_late_inlines.length() && !inlining_progress(); i++) {\n+\n+  for (int i = 0; i < _late_inlines.length(); i++) {\n@@ -1863,0 +1881,1 @@\n+    assert(inlining_incrementally() || cg->is_virtual_late_inline(), \"no inlining allowed\");\n@@ -1864,5 +1883,8 @@\n-    if (failing())  return false;\n-  }\n-  int j = 0;\n-  for (; i < _late_inlines.length(); i++, j++) {\n-    _late_inlines.at_put(j, _late_inlines.at(i));\n+    assert(_late_inlines.at(i) == cg, \"no insertions before current position allowed\");\n+    if (failing()) {\n+      return false;\n+    } else if (inlining_progress()) {\n+      _late_inlines_pos = i+1; \/\/ restore the position in case new elements were inserted\n+      print_method(PHASE_INCREMENTAL_INLINE_STEP, cg->call_node(), 3);\n+      break; \/\/ process one call site at a time\n+    }\n@@ -1870,2 +1892,5 @@\n-  _late_inlines.trunc_to(j);\n-  assert(inlining_progress() || _late_inlines.length() == 0, \"\");\n+  \/\/ Remove processed elements.\n+  _late_inlines.truncate_to(_late_inlines_pos);\n+  _late_inlines_pos = 0;\n+\n+  assert(inlining_progress() || _late_inlines.length() == 0, \"no progress\");\n@@ -1877,0 +1902,1 @@\n+\n@@ -1891,0 +1917,1 @@\n+  print_method(PHASE_INCREMENTAL_INLINE_CLEANUP, 3);\n@@ -1932,0 +1959,4 @@\n+\n+    if (_late_inlines.length() == 0) {\n+      break; \/\/ no more progress\n+    }\n@@ -2078,1 +2109,2 @@\n-    for_igvn()->clear();\n+    Unique_Node_List* old_worklist = for_igvn();\n+    old_worklist->clear();\n@@ -2088,1 +2120,1 @@\n-    set_for_igvn(save_for_igvn);\n+    set_for_igvn(old_worklist); \/\/ new_worklist is dead beyond this point\n@@ -2230,0 +2262,25 @@\n+\n+  assert(_late_inlines.length() == 0 || IncrementalInlineVirtual, \"not empty\");\n+\n+  while (_late_inlines.length() > 0) {\n+    \/\/ More opportunities to optimize virtual calls.\n+    \/\/ Though it's maybe too late for inlining, strength-reducing them to direct calls is still an option.\n+\n+    \/\/ \"inlining_incrementally() == false\" is used to signal that no inlining is allowed.\n+    \/\/ Tracking and verification of modified nodes is disabled by _modified_nodes == NULL as if inlining_incrementally() were set.\n+    assert(inlining_incrementally() == false, \"not allowed\");\n+\n+    for_igvn()->clear();\n+    initial_gvn()->replace_with(&igvn);\n+\n+    DEBUG_ONLY( int late_inlines_before = _late_inlines.length(); )\n+\n+    while (inline_incrementally_one()) {\n+      assert(!failing(), \"inconsistent\");\n+    }\n+    if (failing())  return;\n+\n+    inline_incrementally_cleanup(igvn);\n+\n+    assert(_late_inlines.length() < late_inlines_before, \"no progress\");\n+  }\n@@ -2904,0 +2961,1 @@\n+  case Op_CallLeafVector:\n@@ -3255,3 +3313,4 @@\n-    if (OptimizeStringConcat) {\n-      ProjNode* p = n->as_Proj();\n-      if (p->_is_io_use) {\n+    if (OptimizeStringConcat || IncrementalInline || IncrementalInlineVirtual) {\n+      ProjNode* proj = n->as_Proj();\n+      if (proj->_is_io_use) {\n+        assert(proj->_con == TypeFunc::I_O || proj->_con == TypeFunc::Memory, \"\");\n@@ -3261,13 +3320,4 @@\n-        \/\/ the original one.\n-        Node* proj = NULL;\n-        \/\/ Replace with just one\n-        for (SimpleDUIterator i(p->in(0)); i.has_next(); i.next()) {\n-          Node *use = i.get();\n-          if (use->is_Proj() && p != use && use->as_Proj()->_con == p->_con) {\n-            proj = use;\n-            break;\n-          }\n-        }\n-        assert(proj != NULL || p->_con == TypeFunc::I_O, \"io may be dropped at an infinite loop\");\n-        if (proj != NULL) {\n-          p->subsume_by(proj, this);\n+        \/\/ the original one. Merge them.\n+        Node* non_io_proj = proj->in(0)->as_Multi()->proj_out_or_null(proj->_con, false \/*is_io_use*\/);\n+        if (non_io_proj  != NULL) {\n+          proj->subsume_by(non_io_proj , this);\n@@ -4129,1 +4179,1 @@\n-    if (!cg->is_late_inline()) {\n+    if (!cg->is_late_inline() && !cg->is_virtual_late_inline()) {\n@@ -4183,1 +4233,3 @@\n-        const char* msg = \"live nodes > LiveNodeCountInliningCutoff\";\n+        bool is_virtual = cg->is_virtual_late_inline();\n+        const char* msg = (is_virtual ? \"virtual call\"\n+                                      : \"live nodes > LiveNodeCountInliningCutoff\");\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":81,"deletions":29,"binary":false,"changes":110,"status":"modified"},{"patch":"@@ -940,0 +940,1 @@\n+  void remove_useless_late_inlines(GrowableArray<CallGenerator*>* inlines, Node* dead);\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -277,1 +277,2 @@\n-            miss_cg = CallGenerator::for_virtual_call(callee, vtable_index);\n+            miss_cg = (IncrementalInlineVirtual ? CallGenerator::for_late_inline_virtual(callee, vtable_index, prof_factor)\n+                                                : CallGenerator::for_virtual_call(callee, vtable_index));\n@@ -345,8 +346,10 @@\n-  }\n-\n-  \/\/ Nothing claimed the intrinsic, we go with straight-forward inlining\n-  \/\/ for already discovered intrinsic.\n-  if (allow_inline && allow_intrinsics && cg_intrinsic != NULL) {\n-    assert(cg_intrinsic->does_virtual_dispatch(), \"sanity\");\n-    return cg_intrinsic;\n-  }\n+    \/\/ Nothing claimed the intrinsic, we go with straight-forward inlining\n+    \/\/ for already discovered intrinsic.\n+    if (allow_intrinsics && cg_intrinsic != NULL) {\n+      assert(cg_intrinsic->does_virtual_dispatch(), \"sanity\");\n+      return cg_intrinsic;\n+    }\n+    if (call_does_dispatch && IncrementalInlineVirtual) {\n+      return CallGenerator::for_late_inline_virtual(callee, vtable_index, prof_factor); \/\/ attempt to inline through virtual call later\n+    }\n+  } \/\/ allow_inline\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":12,"deletions":9,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -1014,0 +1014,1 @@\n+    case Op_CallLeafVector:\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -808,0 +808,1 @@\n+    RC_VECTOR = 64,             \/\/ CallLeafVectorNode\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -856,0 +856,1 @@\n+    case Op_CallLeafVector:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -330,0 +330,1 @@\n+  Node* gen_call_to_svml(int vector_api_op_id, BasicType bt, int num_elem, Node* opd1, Node* opd2);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1353,2 +1353,4 @@\n-      if( !parm_regs[i].first()->is_valid() &&\n-          !parm_regs[i].second()->is_valid() ) {\n+      VMReg first = parm_regs[i].first();\n+      VMReg second = parm_regs[i].second();\n+      if( !first->is_valid() &&\n+          !second->is_valid() ) {\n@@ -1357,0 +1359,9 @@\n+      \/\/ Handle case where arguments are in vector registers.\n+      if(call->in(TypeFunc::Parms + i)->bottom_type()->isa_vect()) {\n+        OptoReg::Name reg_fst = OptoReg::as_OptoReg(first);\n+        OptoReg::Name reg_snd = OptoReg::as_OptoReg(second);\n+        assert (reg_fst <= reg_snd, \"fst=%d snd=%d\", reg_fst, reg_snd);\n+        for (OptoReg::Name r = reg_fst; r <= reg_snd; r++) {\n+          rm->Insert(r);\n+        }\n+      }\n@@ -1358,1 +1369,1 @@\n-      OptoReg::Name reg1 = warp_outgoing_stk_arg(parm_regs[i].first(), begin_out_arg_area, out_arg_limit_per_call );\n+      OptoReg::Name reg1 = warp_outgoing_stk_arg(first, begin_out_arg_area, out_arg_limit_per_call );\n@@ -1362,1 +1373,1 @@\n-      OptoReg::Name reg2 = warp_outgoing_stk_arg(parm_regs[i].second(), begin_out_arg_area, out_arg_limit_per_call );\n+      OptoReg::Name reg2 = warp_outgoing_stk_arg(second, begin_out_arg_area, out_arg_limit_per_call );\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -426,0 +426,7 @@\n+  \/\/ Java-Native vector calling convention\n+  static const bool supports_vector_calling_convention();\n+  static void vector_calling_convention(VMRegPair *regs,\n+                                        uint num_bits,\n+                                        uint total_args_passed);\n+  static OptoRegPair vector_return_value(uint ideal_reg);\n+\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"opto\/callGenerator.hpp\"\n@@ -557,1 +558,1 @@\n-  \/\/ cloning CallNode may need to clone JVMState\n+    \/\/ cloning CallNode may need to clone JVMState\n@@ -560,0 +561,6 @@\n+    \/\/ CallGenerator is linked to the original node.\n+    CallGenerator* cg = n->as_Call()->generator();\n+    if (cg != NULL) {\n+      CallGenerator* cloned_cg = cg->with_call_node(n->as_Call());\n+      n->as_Call()->set_generator(cloned_cg);\n+    }\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1105,4 +1105,6 @@\n-  while (modified_list->size()) {\n-    Node* n = modified_list->pop();\n-    n->dump();\n-    assert(false, \"VerifyIterativeGVN: new modified node was added\");\n+  if (modified_list != NULL) {\n+    while (modified_list->size()) {\n+      Node* n = modified_list->pop();\n+      n->dump();\n+      assert(false, \"VerifyIterativeGVN: new modified node was added\");\n+    }\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -665,0 +665,19 @@\n+const TypeFunc *OptoRuntime::Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type) {\n+  \/\/ create input type (domain)\n+  const Type **fields = TypeTuple::fields(num_arg);\n+  \/\/ Symbol* name of class to be loaded\n+  assert(num_arg > 0, \"must have at least 1 input\");\n+  for (uint i = 0; i < num_arg; i++) {\n+    fields[TypeFunc::Parms+i] = in_type;\n+  }\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+num_arg, fields);\n+\n+  \/\/ create result type (range)\n+  const uint num_ret = 1;\n+  fields = TypeTuple::fields(num_ret);\n+  fields[TypeFunc::Parms+0] = out_type;\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+num_ret, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -259,0 +259,1 @@\n+  static const TypeFunc* Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type);\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -225,0 +225,15 @@\n+  if (opc == Op_CallLeafVector) {\n+    if (!UseVectorStubs) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** vector stubs support is disabled\");\n+      }\n+      return false;\n+    }\n+    if (!Matcher::supports_vector_calling_convention()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** no vector calling conventions supported\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -274,10 +289,22 @@\n-  const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n-  switch (n) {\n-    case 1:\n-    case 2: {\n-      operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, vt));\n-      break;\n-    }\n-    case 3: {\n-      operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, opd3, vt));\n-      break;\n+  if (sopc == Op_CallLeafVector) {\n+    assert(UseVectorStubs, \"sanity\");\n+    operation = gen_call_to_svml(opr->get_con(), elem_bt, num_elem, opd1, opd2);\n+    if (operation == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** svml call failed\");\n+      }\n+      return false;\n+     }\n+  } else {\n+    const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+    switch (n) {\n+      case 1:\n+      case 2: {\n+        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, vt));\n+        break;\n+      }\n+      case 3: {\n+        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, opd3, vt));\n+        break;\n+      }\n+      default: fatal(\"unsupported arity: %d\", n);\n@@ -285,1 +312,0 @@\n-    default: fatal(\"unsupported arity: %d\", n);\n@@ -333,0 +359,3 @@\n+  if (!arch_supports_vector(Op_VectorLoadConst, num_elem, elem_bt, VecMaskNotUsed)) {\n+    return false;\n+  }\n@@ -364,1 +393,1 @@\n-    ConINode* pred_node = (ConINode*)gvn().makecon(TypeInt::make(1));\n+    ConINode* pred_node = (ConINode*)gvn().makecon(TypeInt::make(BoolTest::ge));\n@@ -1176,0 +1205,417 @@\n+static void get_svml_address(int op, int bits, BasicType bt, const char** name_ptr, address* addr_ptr) {\n+  assert(UseVectorStubs, \"sanity\");\n+  assert(name_ptr != NULL, \"unexpected\");\n+  assert(addr_ptr != NULL, \"unexpected\");\n+\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+  \/\/ Since the addresses are resolved at runtime, using switch instead of table - otherwise might get NULL addresses.\n+  if (bt == T_FLOAT) {\n+    switch(op) {\n+      case VectorSupport::VECTOR_OP_EXP: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_exp_float64\";  *addr_ptr = StubRoutines::vector_exp_float64();  break;\n+            case 128: *name_ptr = \"vector_exp_float128\"; *addr_ptr = StubRoutines::vector_exp_float128(); break;\n+            case 256: *name_ptr = \"vector_exp_float256\"; *addr_ptr = StubRoutines::vector_exp_float256(); break;\n+            case 512: *name_ptr = \"vector_exp_float512\"; *addr_ptr = StubRoutines::vector_exp_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_LOG1P: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_log1p_float64\";  *addr_ptr = StubRoutines::vector_log1p_float64();  break;\n+            case 128: *name_ptr = \"vector_log1p_float128\"; *addr_ptr = StubRoutines::vector_log1p_float128(); break;\n+            case 256: *name_ptr = \"vector_log1p_float256\"; *addr_ptr = StubRoutines::vector_log1p_float256(); break;\n+            case 512: *name_ptr = \"vector_log1p_float512\"; *addr_ptr = StubRoutines::vector_log1p_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_LOG: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_log_float64\";  *addr_ptr = StubRoutines::vector_log_float64();  break;\n+            case 128: *name_ptr = \"vector_log_float128\"; *addr_ptr = StubRoutines::vector_log_float128(); break;\n+            case 256: *name_ptr = \"vector_log_float256\"; *addr_ptr = StubRoutines::vector_log_float256(); break;\n+            case 512: *name_ptr = \"vector_log_float512\"; *addr_ptr = StubRoutines::vector_log_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_LOG10: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_log10_float64\";  *addr_ptr = StubRoutines::vector_log10_float64();  break;\n+            case 128: *name_ptr = \"vector_log10_float128\"; *addr_ptr = StubRoutines::vector_log10_float128(); break;\n+            case 256: *name_ptr = \"vector_log10_float256\"; *addr_ptr = StubRoutines::vector_log10_float256(); break;\n+            case 512: *name_ptr = \"vector_log10_float512\"; *addr_ptr = StubRoutines::vector_log10_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_EXPM1: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_expm1_float64\";  *addr_ptr = StubRoutines::vector_expm1_float64();  break;\n+            case 128: *name_ptr = \"vector_expm1_float128\"; *addr_ptr = StubRoutines::vector_expm1_float128(); break;\n+            case 256: *name_ptr = \"vector_expm1_float256\"; *addr_ptr = StubRoutines::vector_expm1_float256(); break;\n+            case 512: *name_ptr = \"vector_expm1_float512\"; *addr_ptr = StubRoutines::vector_expm1_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_SIN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_sin_float64\";  *addr_ptr = StubRoutines::vector_sin_float64();  break;\n+            case 128: *name_ptr = \"vector_sin_float128\"; *addr_ptr = StubRoutines::vector_sin_float128(); break;\n+            case 256: *name_ptr = \"vector_sin_float256\"; *addr_ptr = StubRoutines::vector_sin_float256(); break;\n+            case 512: *name_ptr = \"vector_sin_float512\"; *addr_ptr = StubRoutines::vector_sin_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_COS: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_cos_float64\";  *addr_ptr = StubRoutines::vector_cos_float64();  break;\n+            case 128: *name_ptr = \"vector_cos_float128\"; *addr_ptr = StubRoutines::vector_cos_float128(); break;\n+            case 256: *name_ptr = \"vector_cos_float256\"; *addr_ptr = StubRoutines::vector_cos_float256(); break;\n+            case 512: *name_ptr = \"vector_cos_float512\"; *addr_ptr = StubRoutines::vector_cos_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_TAN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_tan_float64\";  *addr_ptr = StubRoutines::vector_tan_float64();  break;\n+            case 128: *name_ptr = \"vector_tan_float128\"; *addr_ptr = StubRoutines::vector_tan_float128(); break;\n+            case 256: *name_ptr = \"vector_tan_float256\"; *addr_ptr = StubRoutines::vector_tan_float256(); break;\n+            case 512: *name_ptr = \"vector_tan_float512\"; *addr_ptr = StubRoutines::vector_tan_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_SINH: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_sinh_float64\";  *addr_ptr = StubRoutines::vector_sinh_float64();  break;\n+            case 128: *name_ptr = \"vector_sinh_float128\"; *addr_ptr = StubRoutines::vector_sinh_float128(); break;\n+            case 256: *name_ptr = \"vector_sinh_float256\"; *addr_ptr = StubRoutines::vector_sinh_float256(); break;\n+            case 512: *name_ptr = \"vector_sinh_float512\"; *addr_ptr = StubRoutines::vector_sinh_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_COSH: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_cosh_float64\";  *addr_ptr = StubRoutines::vector_cosh_float64();  break;\n+            case 128: *name_ptr = \"vector_cosh_float128\"; *addr_ptr = StubRoutines::vector_cosh_float128(); break;\n+            case 256: *name_ptr = \"vector_cosh_float256\"; *addr_ptr = StubRoutines::vector_cosh_float256(); break;\n+            case 512: *name_ptr = \"vector_cosh_float512\"; *addr_ptr = StubRoutines::vector_cosh_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_TANH: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_tanh_float64\";  *addr_ptr = StubRoutines::vector_tanh_float64();  break;\n+            case 128: *name_ptr = \"vector_tanh_float128\"; *addr_ptr = StubRoutines::vector_tanh_float128(); break;\n+            case 256: *name_ptr = \"vector_tanh_float256\"; *addr_ptr = StubRoutines::vector_tanh_float256(); break;\n+            case 512: *name_ptr = \"vector_tanh_float512\"; *addr_ptr = StubRoutines::vector_tanh_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ASIN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_asin_float64\";  *addr_ptr = StubRoutines::vector_asin_float64();  break;\n+            case 128: *name_ptr = \"vector_asin_float128\"; *addr_ptr = StubRoutines::vector_asin_float128(); break;\n+            case 256: *name_ptr = \"vector_asin_float256\"; *addr_ptr = StubRoutines::vector_asin_float256(); break;\n+            case 512: *name_ptr = \"vector_asin_float512\"; *addr_ptr = StubRoutines::vector_asin_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ACOS: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_acos_float64\";  *addr_ptr = StubRoutines::vector_acos_float64();  break;\n+            case 128: *name_ptr = \"vector_acos_float128\"; *addr_ptr = StubRoutines::vector_acos_float128(); break;\n+            case 256: *name_ptr = \"vector_acos_float256\"; *addr_ptr = StubRoutines::vector_acos_float256(); break;\n+            case 512: *name_ptr = \"vector_acos_float512\"; *addr_ptr = StubRoutines::vector_acos_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ATAN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_atan_float64\";  *addr_ptr = StubRoutines::vector_atan_float64();  break;\n+            case 128: *name_ptr = \"vector_atan_float128\"; *addr_ptr = StubRoutines::vector_atan_float128(); break;\n+            case 256: *name_ptr = \"vector_atan_float256\"; *addr_ptr = StubRoutines::vector_atan_float256(); break;\n+            case 512: *name_ptr = \"vector_atan_float512\"; *addr_ptr = StubRoutines::vector_atan_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_CBRT: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_cbrt_float64\";  *addr_ptr = StubRoutines::vector_cbrt_float64();  break;\n+            case 128: *name_ptr = \"vector_cbrt_float128\"; *addr_ptr = StubRoutines::vector_cbrt_float128(); break;\n+            case 256: *name_ptr = \"vector_cbrt_float256\"; *addr_ptr = StubRoutines::vector_cbrt_float256(); break;\n+            case 512: *name_ptr = \"vector_cbrt_float512\"; *addr_ptr = StubRoutines::vector_cbrt_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+       case VectorSupport::VECTOR_OP_HYPOT: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_hypot_float64\";  *addr_ptr = StubRoutines::vector_hypot_float64();  break;\n+            case 128: *name_ptr = \"vector_hypot_float128\"; *addr_ptr = StubRoutines::vector_hypot_float128(); break;\n+            case 256: *name_ptr = \"vector_hypot_float256\"; *addr_ptr = StubRoutines::vector_hypot_float256(); break;\n+            case 512: *name_ptr = \"vector_hypot_float512\"; *addr_ptr = StubRoutines::vector_hypot_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_POW: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_pow_float64\";  *addr_ptr = StubRoutines::vector_pow_float64();  break;\n+            case 128: *name_ptr = \"vector_pow_float128\"; *addr_ptr = StubRoutines::vector_pow_float128(); break;\n+            case 256: *name_ptr = \"vector_pow_float256\"; *addr_ptr = StubRoutines::vector_pow_float256(); break;\n+            case 512: *name_ptr = \"vector_pow_float512\"; *addr_ptr = StubRoutines::vector_pow_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ATAN2: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_atan2_float64\";  *addr_ptr = StubRoutines::vector_atan2_float64();  break;\n+            case 128: *name_ptr = \"vector_atan2_float128\"; *addr_ptr = StubRoutines::vector_atan2_float128(); break;\n+            case 256: *name_ptr = \"vector_atan2_float256\"; *addr_ptr = StubRoutines::vector_atan2_float256(); break;\n+            case 512: *name_ptr = \"vector_atan2_float512\"; *addr_ptr = StubRoutines::vector_atan2_float512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      default:\n+        *name_ptr = \"invalid\";\n+        *addr_ptr = NULL;\n+        break;\n+    }\n+  } else {\n+    assert(bt == T_DOUBLE, \"must be FP type only\");\n+    switch(op) {\n+      case VectorSupport::VECTOR_OP_EXP: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_exp_double64\";  *addr_ptr = StubRoutines::vector_exp_double64();  break;\n+            case 128: *name_ptr = \"vector_exp_double128\"; *addr_ptr = StubRoutines::vector_exp_double128(); break;\n+            case 256: *name_ptr = \"vector_exp_double256\"; *addr_ptr = StubRoutines::vector_exp_double256(); break;\n+            case 512: *name_ptr = \"vector_exp_double512\"; *addr_ptr = StubRoutines::vector_exp_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_LOG1P: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_log1p_double64\";  *addr_ptr = StubRoutines::vector_log1p_double64();  break;\n+            case 128: *name_ptr = \"vector_log1p_double128\"; *addr_ptr = StubRoutines::vector_log1p_double128(); break;\n+            case 256: *name_ptr = \"vector_log1p_double256\"; *addr_ptr = StubRoutines::vector_log1p_double256(); break;\n+            case 512: *name_ptr = \"vector_log1p_double512\"; *addr_ptr = StubRoutines::vector_log1p_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_LOG: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_log_double64\";  *addr_ptr = StubRoutines::vector_log_double64();  break;\n+            case 128: *name_ptr = \"vector_log_double128\"; *addr_ptr = StubRoutines::vector_log_double128(); break;\n+            case 256: *name_ptr = \"vector_log_double256\"; *addr_ptr = StubRoutines::vector_log_double256(); break;\n+            case 512: *name_ptr = \"vector_log_double512\"; *addr_ptr = StubRoutines::vector_log_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_LOG10: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_log10_double64\";  *addr_ptr = StubRoutines::vector_log10_double64();  break;\n+            case 128: *name_ptr = \"vector_log10_double128\"; *addr_ptr = StubRoutines::vector_log10_double128(); break;\n+            case 256: *name_ptr = \"vector_log10_double256\"; *addr_ptr = StubRoutines::vector_log10_double256(); break;\n+            case 512: *name_ptr = \"vector_log10_double512\"; *addr_ptr = StubRoutines::vector_log10_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_EXPM1: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_expm1_double64\";  *addr_ptr = StubRoutines::vector_expm1_double64();  break;\n+            case 128: *name_ptr = \"vector_expm1_double128\"; *addr_ptr = StubRoutines::vector_expm1_double128(); break;\n+            case 256: *name_ptr = \"vector_expm1_double256\"; *addr_ptr = StubRoutines::vector_expm1_double256(); break;\n+            case 512: *name_ptr = \"vector_expm1_double512\"; *addr_ptr = StubRoutines::vector_expm1_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_SIN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_sin_double64\";  *addr_ptr = StubRoutines::vector_sin_double64();  break;\n+            case 128: *name_ptr = \"vector_sin_double128\"; *addr_ptr = StubRoutines::vector_sin_double128(); break;\n+            case 256: *name_ptr = \"vector_sin_double256\"; *addr_ptr = StubRoutines::vector_sin_double256(); break;\n+            case 512: *name_ptr = \"vector_sin_double512\"; *addr_ptr = StubRoutines::vector_sin_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_COS: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_cos_double64\";  *addr_ptr = StubRoutines::vector_cos_double64();  break;\n+            case 128: *name_ptr = \"vector_cos_double128\"; *addr_ptr = StubRoutines::vector_cos_double128(); break;\n+            case 256: *name_ptr = \"vector_cos_double256\"; *addr_ptr = StubRoutines::vector_cos_double256(); break;\n+            case 512: *name_ptr = \"vector_cos_double512\"; *addr_ptr = StubRoutines::vector_cos_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_TAN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_tan_double64\";  *addr_ptr = StubRoutines::vector_tan_double64();  break;\n+            case 128: *name_ptr = \"vector_tan_double128\"; *addr_ptr = StubRoutines::vector_tan_double128(); break;\n+            case 256: *name_ptr = \"vector_tan_double256\"; *addr_ptr = StubRoutines::vector_tan_double256(); break;\n+            case 512: *name_ptr = \"vector_tan_double512\"; *addr_ptr = StubRoutines::vector_tan_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_SINH: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_sinh_double64\";  *addr_ptr = StubRoutines::vector_sinh_double64();  break;\n+            case 128: *name_ptr = \"vector_sinh_double128\"; *addr_ptr = StubRoutines::vector_sinh_double128(); break;\n+            case 256: *name_ptr = \"vector_sinh_double256\"; *addr_ptr = StubRoutines::vector_sinh_double256(); break;\n+            case 512: *name_ptr = \"vector_sinh_double512\"; *addr_ptr = StubRoutines::vector_sinh_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_COSH: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_cosh_double64\";  *addr_ptr = StubRoutines::vector_cosh_double64();  break;\n+            case 128: *name_ptr = \"vector_cosh_double128\"; *addr_ptr = StubRoutines::vector_cosh_double128(); break;\n+            case 256: *name_ptr = \"vector_cosh_double256\"; *addr_ptr = StubRoutines::vector_cosh_double256(); break;\n+            case 512: *name_ptr = \"vector_cosh_double512\"; *addr_ptr = StubRoutines::vector_cosh_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_TANH: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_tanh_double64\";  *addr_ptr = StubRoutines::vector_tanh_double64();  break;\n+            case 128: *name_ptr = \"vector_tanh_double128\"; *addr_ptr = StubRoutines::vector_tanh_double128(); break;\n+            case 256: *name_ptr = \"vector_tanh_double256\"; *addr_ptr = StubRoutines::vector_tanh_double256(); break;\n+            case 512: *name_ptr = \"vector_tanh_double512\"; *addr_ptr = StubRoutines::vector_tanh_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ASIN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_asin_double64\";  *addr_ptr = StubRoutines::vector_asin_double64();  break;\n+            case 128: *name_ptr = \"vector_asin_double128\"; *addr_ptr = StubRoutines::vector_asin_double128(); break;\n+            case 256: *name_ptr = \"vector_asin_double256\"; *addr_ptr = StubRoutines::vector_asin_double256(); break;\n+            case 512: *name_ptr = \"vector_asin_double512\"; *addr_ptr = StubRoutines::vector_asin_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ACOS: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_acos_double64\";  *addr_ptr = StubRoutines::vector_acos_double64();  break;\n+            case 128: *name_ptr = \"vector_acos_double128\"; *addr_ptr = StubRoutines::vector_acos_double128(); break;\n+            case 256: *name_ptr = \"vector_acos_double256\"; *addr_ptr = StubRoutines::vector_acos_double256(); break;\n+            case 512: *name_ptr = \"vector_acos_double512\"; *addr_ptr = StubRoutines::vector_acos_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ATAN: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_atan_double64\";  *addr_ptr = StubRoutines::vector_atan_double64();  break;\n+            case 128: *name_ptr = \"vector_atan_double128\"; *addr_ptr = StubRoutines::vector_atan_double128(); break;\n+            case 256: *name_ptr = \"vector_atan_double256\"; *addr_ptr = StubRoutines::vector_atan_double256(); break;\n+            case 512: *name_ptr = \"vector_atan_double512\"; *addr_ptr = StubRoutines::vector_atan_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_CBRT: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_cbrt_double64\";  *addr_ptr = StubRoutines::vector_cbrt_double64();  break;\n+            case 128: *name_ptr = \"vector_cbrt_double128\"; *addr_ptr = StubRoutines::vector_cbrt_double128(); break;\n+            case 256: *name_ptr = \"vector_cbrt_double256\"; *addr_ptr = StubRoutines::vector_cbrt_double256(); break;\n+            case 512: *name_ptr = \"vector_cbrt_double512\"; *addr_ptr = StubRoutines::vector_cbrt_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_HYPOT: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_hypot_double64\";  *addr_ptr = StubRoutines::vector_hypot_double64();  break;\n+            case 128: *name_ptr = \"vector_hypot_double128\"; *addr_ptr = StubRoutines::vector_hypot_double128(); break;\n+            case 256: *name_ptr = \"vector_hypot_double256\"; *addr_ptr = StubRoutines::vector_hypot_double256(); break;\n+            case 512: *name_ptr = \"vector_hypot_double512\"; *addr_ptr = StubRoutines::vector_hypot_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_POW: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_pow_double64\";  *addr_ptr = StubRoutines::vector_pow_double64();  break;\n+            case 128: *name_ptr = \"vector_pow_double128\"; *addr_ptr = StubRoutines::vector_pow_double128(); break;\n+            case 256: *name_ptr = \"vector_pow_double256\"; *addr_ptr = StubRoutines::vector_pow_double256(); break;\n+            case 512: *name_ptr = \"vector_pow_double512\"; *addr_ptr = StubRoutines::vector_pow_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+      case VectorSupport::VECTOR_OP_ATAN2: {\n+          switch(bits) {\n+            case 64:  *name_ptr = \"vector_atan2_double64\";  *addr_ptr = StubRoutines::vector_atan2_double64();  break;\n+            case 128: *name_ptr = \"vector_atan2_double128\"; *addr_ptr = StubRoutines::vector_atan2_double128(); break;\n+            case 256: *name_ptr = \"vector_atan2_double256\"; *addr_ptr = StubRoutines::vector_atan2_double256(); break;\n+            case 512: *name_ptr = \"vector_atan2_double512\"; *addr_ptr = StubRoutines::vector_atan2_double512(); break;\n+            default: Unimplemented(); break;\n+          }\n+        }\n+        break;\n+\n+      default:\n+        *name_ptr = \"invalid\";\n+        *addr_ptr = NULL;\n+        break;\n+    }\n+  }\n+#else\n+  *name_ptr = \"invalid\";\n+  *addr_ptr = NULL;\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n+}\n+\n+Node* LibraryCallKit::gen_call_to_svml(int vector_api_op_id, BasicType bt, int num_elem, Node* opd1, Node* opd2) {\n+  assert(UseVectorStubs, \"sanity\");\n+  assert(vector_api_op_id >= VectorSupport::VECTOR_OP_SVML_START && vector_api_op_id <= VectorSupport::VECTOR_OP_SVML_END, \"need valid op id\");\n+  assert(opd1 != NULL, \"must not be null\");\n+  const TypeVect* vt = TypeVect::make(bt, num_elem);\n+  const TypeFunc* call_type = OptoRuntime::Math_Vector_Vector_Type(opd2 != NULL ? 2 : 1, vt, vt);\n+  const char* name = NULL;\n+  address addr = NULL;\n+\n+  \/\/ Get address for svml method.\n+  get_svml_address(vector_api_op_id, vt->length_in_bytes() * BitsPerByte, bt, &name, &addr);\n+\n+  if (addr == NULL) {\n+    return NULL;\n+  }\n+\n+  assert(name != NULL, \"name must not be null\");\n+  Node* operation = make_runtime_call(RC_VECTOR,\n+                                      call_type,\n+                                      addr,\n+                                      name,\n+                                      TypePtr::BOTTOM,\n+                                      opd1,\n+                                      opd2);\n+  return _gvn.transform(new ProjNode(_gvn.transform(operation), TypeFunc::Parms));\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":458,"deletions":12,"binary":false,"changes":470,"status":"modified"},{"patch":"@@ -4255,0 +4255,5 @@\n+\n+    if (!FLAG_IS_DEFAULT(UseVectorStubs) && UseVectorStubs) {\n+      warning(\"Disabling UseVectorStubs since EnableVectorSupport is turned off.\");\n+    }\n+    FLAG_SET_DEFAULT(UseVectorStubs, false);\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -390,0 +390,4 @@\n+  static int vector_calling_convention(VMRegPair *regs,\n+                                       uint num_bits,\n+                                       uint total_args_passed);\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -186,0 +186,147 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+address StubRoutines::_vector_exp_float64                = NULL;\n+address StubRoutines::_vector_exp_float128               = NULL;\n+address StubRoutines::_vector_exp_float256               = NULL;\n+address StubRoutines::_vector_exp_float512               = NULL;\n+address StubRoutines::_vector_exp_double64               = NULL;\n+address StubRoutines::_vector_exp_double128              = NULL;\n+address StubRoutines::_vector_exp_double256              = NULL;\n+address StubRoutines::_vector_exp_double512              = NULL;\n+address StubRoutines::_vector_expm1_float64              = NULL;\n+address StubRoutines::_vector_expm1_float128             = NULL;\n+address StubRoutines::_vector_expm1_float256             = NULL;\n+address StubRoutines::_vector_expm1_float512             = NULL;\n+address StubRoutines::_vector_expm1_double64             = NULL;\n+address StubRoutines::_vector_expm1_double128            = NULL;\n+address StubRoutines::_vector_expm1_double256            = NULL;\n+address StubRoutines::_vector_expm1_double512            = NULL;\n+address StubRoutines::_vector_log1p_float64              = NULL;\n+address StubRoutines::_vector_log1p_float128             = NULL;\n+address StubRoutines::_vector_log1p_float256             = NULL;\n+address StubRoutines::_vector_log1p_float512             = NULL;\n+address StubRoutines::_vector_log1p_double64             = NULL;\n+address StubRoutines::_vector_log1p_double128            = NULL;\n+address StubRoutines::_vector_log1p_double256            = NULL;\n+address StubRoutines::_vector_log1p_double512            = NULL;\n+address StubRoutines::_vector_log_float64                = NULL;\n+address StubRoutines::_vector_log_float128               = NULL;\n+address StubRoutines::_vector_log_float256               = NULL;\n+address StubRoutines::_vector_log_float512               = NULL;\n+address StubRoutines::_vector_log_double64               = NULL;\n+address StubRoutines::_vector_log_double128              = NULL;\n+address StubRoutines::_vector_log_double256              = NULL;\n+address StubRoutines::_vector_log_double512              = NULL;\n+address StubRoutines::_vector_log10_float64              = NULL;\n+address StubRoutines::_vector_log10_float128             = NULL;\n+address StubRoutines::_vector_log10_float256             = NULL;\n+address StubRoutines::_vector_log10_float512             = NULL;\n+address StubRoutines::_vector_log10_double64             = NULL;\n+address StubRoutines::_vector_log10_double128            = NULL;\n+address StubRoutines::_vector_log10_double256            = NULL;\n+address StubRoutines::_vector_log10_double512            = NULL;\n+address StubRoutines::_vector_sin_float64                = NULL;\n+address StubRoutines::_vector_sin_float128               = NULL;\n+address StubRoutines::_vector_sin_float256               = NULL;\n+address StubRoutines::_vector_sin_float512               = NULL;\n+address StubRoutines::_vector_sin_double64               = NULL;\n+address StubRoutines::_vector_sin_double128              = NULL;\n+address StubRoutines::_vector_sin_double256              = NULL;\n+address StubRoutines::_vector_sin_double512              = NULL;\n+address StubRoutines::_vector_cos_float64                = NULL;\n+address StubRoutines::_vector_cos_float128               = NULL;\n+address StubRoutines::_vector_cos_float256               = NULL;\n+address StubRoutines::_vector_cos_float512               = NULL;\n+address StubRoutines::_vector_cos_double64               = NULL;\n+address StubRoutines::_vector_cos_double128              = NULL;\n+address StubRoutines::_vector_cos_double256              = NULL;\n+address StubRoutines::_vector_cos_double512              = NULL;\n+address StubRoutines::_vector_tan_float64                = NULL;\n+address StubRoutines::_vector_tan_float128               = NULL;\n+address StubRoutines::_vector_tan_float256               = NULL;\n+address StubRoutines::_vector_tan_float512               = NULL;\n+address StubRoutines::_vector_tan_double64               = NULL;\n+address StubRoutines::_vector_tan_double128              = NULL;\n+address StubRoutines::_vector_tan_double256              = NULL;\n+address StubRoutines::_vector_tan_double512              = NULL;\n+address StubRoutines::_vector_sinh_float64               = NULL;\n+address StubRoutines::_vector_sinh_float128               = NULL;\n+address StubRoutines::_vector_sinh_float256               = NULL;\n+address StubRoutines::_vector_sinh_float512               = NULL;\n+address StubRoutines::_vector_sinh_double64               = NULL;\n+address StubRoutines::_vector_sinh_double128              = NULL;\n+address StubRoutines::_vector_sinh_double256              = NULL;\n+address StubRoutines::_vector_sinh_double512              = NULL;\n+address StubRoutines::_vector_cosh_float64                = NULL;\n+address StubRoutines::_vector_cosh_float128               = NULL;\n+address StubRoutines::_vector_cosh_float256               = NULL;\n+address StubRoutines::_vector_cosh_float512               = NULL;\n+address StubRoutines::_vector_cosh_double64               = NULL;\n+address StubRoutines::_vector_cosh_double128              = NULL;\n+address StubRoutines::_vector_cosh_double256              = NULL;\n+address StubRoutines::_vector_cosh_double512              = NULL;\n+address StubRoutines::_vector_tanh_float64                = NULL;\n+address StubRoutines::_vector_tanh_float128               = NULL;\n+address StubRoutines::_vector_tanh_float256               = NULL;\n+address StubRoutines::_vector_tanh_float512               = NULL;\n+address StubRoutines::_vector_tanh_double64               = NULL;\n+address StubRoutines::_vector_tanh_double128              = NULL;\n+address StubRoutines::_vector_tanh_double256              = NULL;\n+address StubRoutines::_vector_tanh_double512              = NULL;\n+address StubRoutines::_vector_acos_float64                = NULL;\n+address StubRoutines::_vector_acos_float128               = NULL;\n+address StubRoutines::_vector_acos_float256               = NULL;\n+address StubRoutines::_vector_acos_float512               = NULL;\n+address StubRoutines::_vector_acos_double64               = NULL;\n+address StubRoutines::_vector_acos_double128              = NULL;\n+address StubRoutines::_vector_acos_double256              = NULL;\n+address StubRoutines::_vector_acos_double512              = NULL;\n+address StubRoutines::_vector_asin_float64                = NULL;\n+address StubRoutines::_vector_asin_float128               = NULL;\n+address StubRoutines::_vector_asin_float256               = NULL;\n+address StubRoutines::_vector_asin_float512               = NULL;\n+address StubRoutines::_vector_asin_double64               = NULL;\n+address StubRoutines::_vector_asin_double128              = NULL;\n+address StubRoutines::_vector_asin_double256              = NULL;\n+address StubRoutines::_vector_asin_double512              = NULL;\n+address StubRoutines::_vector_atan_float64                = NULL;\n+address StubRoutines::_vector_atan_float128               = NULL;\n+address StubRoutines::_vector_atan_float256               = NULL;\n+address StubRoutines::_vector_atan_float512               = NULL;\n+address StubRoutines::_vector_atan_double64               = NULL;\n+address StubRoutines::_vector_atan_double128              = NULL;\n+address StubRoutines::_vector_atan_double256              = NULL;\n+address StubRoutines::_vector_atan_double512              = NULL;\n+address StubRoutines::_vector_pow_float64                 = NULL;\n+address StubRoutines::_vector_pow_float128                = NULL;\n+address StubRoutines::_vector_pow_float256                = NULL;\n+address StubRoutines::_vector_pow_float512                = NULL;\n+address StubRoutines::_vector_pow_double64                = NULL;\n+address StubRoutines::_vector_pow_double128               = NULL;\n+address StubRoutines::_vector_pow_double256               = NULL;\n+address StubRoutines::_vector_pow_double512               = NULL;\n+address StubRoutines::_vector_hypot_float64               = NULL;\n+address StubRoutines::_vector_hypot_float128              = NULL;\n+address StubRoutines::_vector_hypot_float256              = NULL;\n+address StubRoutines::_vector_hypot_float512              = NULL;\n+address StubRoutines::_vector_hypot_double64              = NULL;\n+address StubRoutines::_vector_hypot_double128             = NULL;\n+address StubRoutines::_vector_hypot_double256             = NULL;\n+address StubRoutines::_vector_hypot_double512             = NULL;\n+address StubRoutines::_vector_cbrt_float64                = NULL;\n+address StubRoutines::_vector_cbrt_float128               = NULL;\n+address StubRoutines::_vector_cbrt_float256               = NULL;\n+address StubRoutines::_vector_cbrt_float512               = NULL;\n+address StubRoutines::_vector_cbrt_double64               = NULL;\n+address StubRoutines::_vector_cbrt_double128              = NULL;\n+address StubRoutines::_vector_cbrt_double256              = NULL;\n+address StubRoutines::_vector_cbrt_double512              = NULL;\n+address StubRoutines::_vector_atan2_float64               = NULL;\n+address StubRoutines::_vector_atan2_float128              = NULL;\n+address StubRoutines::_vector_atan2_float256              = NULL;\n+address StubRoutines::_vector_atan2_float512              = NULL;\n+address StubRoutines::_vector_atan2_double64              = NULL;\n+address StubRoutines::_vector_atan2_double128             = NULL;\n+address StubRoutines::_vector_atan2_double256             = NULL;\n+address StubRoutines::_vector_atan2_double512             = NULL;\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":147,"deletions":0,"binary":false,"changes":147,"status":"modified"},{"patch":"@@ -268,0 +268,166 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+  \/\/ Vector Math Routines\n+  static address _vector_exp_float64;\n+  static address _vector_exp_float128;\n+  static address _vector_exp_float256;\n+  static address _vector_exp_float512;\n+  static address _vector_exp_double64;\n+  static address _vector_exp_double128;\n+  static address _vector_exp_double256;\n+  static address _vector_exp_double512;\n+\n+  static address _vector_expm1_float64;\n+  static address _vector_expm1_float128;\n+  static address _vector_expm1_float256;\n+  static address _vector_expm1_float512;\n+  static address _vector_expm1_double64;\n+  static address _vector_expm1_double128;\n+  static address _vector_expm1_double256;\n+  static address _vector_expm1_double512;\n+\n+  static address _vector_log1p_float64;\n+  static address _vector_log1p_float128;\n+  static address _vector_log1p_float256;\n+  static address _vector_log1p_float512;\n+  static address _vector_log1p_double64;\n+  static address _vector_log1p_double128;\n+  static address _vector_log1p_double256;\n+  static address _vector_log1p_double512;\n+\n+  static address _vector_log_float64;\n+  static address _vector_log_float128;\n+  static address _vector_log_float256;\n+  static address _vector_log_float512;\n+  static address _vector_log_double64;\n+  static address _vector_log_double128;\n+  static address _vector_log_double256;\n+  static address _vector_log_double512;\n+\n+  static address _vector_log10_float64;\n+  static address _vector_log10_float128;\n+  static address _vector_log10_float256;\n+  static address _vector_log10_float512;\n+  static address _vector_log10_double64;\n+  static address _vector_log10_double128;\n+  static address _vector_log10_double256;\n+  static address _vector_log10_double512;\n+\n+  static address _vector_sin_float64;\n+  static address _vector_sin_float128;\n+  static address _vector_sin_float256;\n+  static address _vector_sin_float512;\n+  static address _vector_sin_double64;\n+  static address _vector_sin_double128;\n+  static address _vector_sin_double256;\n+  static address _vector_sin_double512;\n+\n+  static address _vector_cos_float64;\n+  static address _vector_cos_float128;\n+  static address _vector_cos_float256;\n+  static address _vector_cos_float512;\n+  static address _vector_cos_double64;\n+  static address _vector_cos_double128;\n+  static address _vector_cos_double256;\n+  static address _vector_cos_double512;\n+\n+  static address _vector_tan_float64;\n+  static address _vector_tan_float128;\n+  static address _vector_tan_float256;\n+  static address _vector_tan_float512;\n+  static address _vector_tan_double64;\n+  static address _vector_tan_double128;\n+  static address _vector_tan_double256;\n+  static address _vector_tan_double512;\n+\n+  static address _vector_sinh_float64;\n+  static address _vector_sinh_float128;\n+  static address _vector_sinh_float256;\n+  static address _vector_sinh_float512;\n+  static address _vector_sinh_double64;\n+  static address _vector_sinh_double128;\n+  static address _vector_sinh_double256;\n+  static address _vector_sinh_double512;\n+\n+  static address _vector_cosh_float64;\n+  static address _vector_cosh_float128;\n+  static address _vector_cosh_float256;\n+  static address _vector_cosh_float512;\n+  static address _vector_cosh_double64;\n+  static address _vector_cosh_double128;\n+  static address _vector_cosh_double256;\n+  static address _vector_cosh_double512;\n+\n+  static address _vector_tanh_float64;\n+  static address _vector_tanh_float128;\n+  static address _vector_tanh_float256;\n+  static address _vector_tanh_float512;\n+  static address _vector_tanh_double64;\n+  static address _vector_tanh_double128;\n+  static address _vector_tanh_double256;\n+  static address _vector_tanh_double512;\n+\n+  static address _vector_acos_float64;\n+  static address _vector_acos_float128;\n+  static address _vector_acos_float256;\n+  static address _vector_acos_float512;\n+  static address _vector_acos_double64;\n+  static address _vector_acos_double128;\n+  static address _vector_acos_double256;\n+  static address _vector_acos_double512;\n+\n+  static address _vector_asin_float64;\n+  static address _vector_asin_float128;\n+  static address _vector_asin_float256;\n+  static address _vector_asin_float512;\n+  static address _vector_asin_double64;\n+  static address _vector_asin_double128;\n+  static address _vector_asin_double256;\n+  static address _vector_asin_double512;\n+\n+  static address _vector_atan_float64;\n+  static address _vector_atan_float128;\n+  static address _vector_atan_float256;\n+  static address _vector_atan_float512;\n+  static address _vector_atan_double64;\n+  static address _vector_atan_double128;\n+  static address _vector_atan_double256;\n+  static address _vector_atan_double512;\n+\n+  static address _vector_pow_float64;\n+  static address _vector_pow_float128;\n+  static address _vector_pow_float256;\n+  static address _vector_pow_float512;\n+  static address _vector_pow_double64;\n+  static address _vector_pow_double128;\n+  static address _vector_pow_double256;\n+  static address _vector_pow_double512;\n+\n+  static address _vector_hypot_float64;\n+  static address _vector_hypot_float128;\n+  static address _vector_hypot_float256;\n+  static address _vector_hypot_float512;\n+  static address _vector_hypot_double64;\n+  static address _vector_hypot_double128;\n+  static address _vector_hypot_double256;\n+  static address _vector_hypot_double512;\n+\n+  static address _vector_cbrt_float64;\n+  static address _vector_cbrt_float128;\n+  static address _vector_cbrt_float256;\n+  static address _vector_cbrt_float512;\n+  static address _vector_cbrt_double64;\n+  static address _vector_cbrt_double128;\n+  static address _vector_cbrt_double256;\n+  static address _vector_cbrt_double512;\n+\n+  static address _vector_atan2_float64;\n+  static address _vector_atan2_float128;\n+  static address _vector_atan2_float256;\n+  static address _vector_atan2_float512;\n+  static address _vector_atan2_double64;\n+  static address _vector_atan2_double128;\n+  static address _vector_atan2_double256;\n+  static address _vector_atan2_double512;\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n+\n+\n@@ -444,0 +610,165 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+  static address vector_exp_float64()   { return _vector_exp_float64;   }\n+  static address vector_exp_float128()  { return _vector_exp_float128;  }\n+  static address vector_exp_float256()  { return _vector_exp_float256;  }\n+  static address vector_exp_float512()  { return _vector_exp_float512;  }\n+  static address vector_exp_double64()  { return _vector_exp_double64;  }\n+  static address vector_exp_double128() { return _vector_exp_double128; }\n+  static address vector_exp_double256() { return _vector_exp_double256; }\n+  static address vector_exp_double512() { return _vector_exp_double512; }\n+\n+  static address vector_expm1_float64()   { return _vector_expm1_float64;   }\n+  static address vector_expm1_float128()  { return _vector_expm1_float128;  }\n+  static address vector_expm1_float256()  { return _vector_expm1_float256;  }\n+  static address vector_expm1_float512()  { return _vector_expm1_float512;  }\n+  static address vector_expm1_double64()  { return _vector_expm1_double64;  }\n+  static address vector_expm1_double128() { return _vector_expm1_double128; }\n+  static address vector_expm1_double256() { return _vector_expm1_double256; }\n+  static address vector_expm1_double512() { return _vector_expm1_double512; }\n+\n+  static address vector_log1p_float64()   { return _vector_log1p_float64;   }\n+  static address vector_log1p_float128()  { return _vector_log1p_float128;  }\n+  static address vector_log1p_float256()  { return _vector_log1p_float256;  }\n+  static address vector_log1p_float512()  { return _vector_log1p_float512;  }\n+  static address vector_log1p_double64()  { return _vector_log1p_double64;  }\n+  static address vector_log1p_double128() { return _vector_log1p_double128; }\n+  static address vector_log1p_double256() { return _vector_log1p_double256; }\n+  static address vector_log1p_double512() { return _vector_log1p_double512; }\n+\n+  static address vector_log_float64()   { return _vector_log_float64;   }\n+  static address vector_log_float128()  { return _vector_log_float128;  }\n+  static address vector_log_float256()  { return _vector_log_float256;  }\n+  static address vector_log_float512()  { return _vector_log_float512;  }\n+  static address vector_log_double64()  { return _vector_log_double64;  }\n+  static address vector_log_double128() { return _vector_log_double128; }\n+  static address vector_log_double256() { return _vector_log_double256; }\n+  static address vector_log_double512() { return _vector_log_double512; }\n+\n+  static address vector_log10_float64()   { return _vector_log10_float64;   }\n+  static address vector_log10_float128()  { return _vector_log10_float128;  }\n+  static address vector_log10_float256()  { return _vector_log10_float256;  }\n+  static address vector_log10_float512()  { return _vector_log10_float512;  }\n+  static address vector_log10_double64()  { return _vector_log10_double64;  }\n+  static address vector_log10_double128() { return _vector_log10_double128; }\n+  static address vector_log10_double256() { return _vector_log10_double256; }\n+  static address vector_log10_double512() { return _vector_log10_double512; }\n+\n+  static address vector_sin_float64()   { return _vector_sin_float64;   }\n+  static address vector_sin_float128()  { return _vector_sin_float128;  }\n+  static address vector_sin_float256()  { return _vector_sin_float256;  }\n+  static address vector_sin_float512()  { return _vector_sin_float512;  }\n+  static address vector_sin_double64()  { return _vector_sin_double64;  }\n+  static address vector_sin_double128() { return _vector_sin_double128; }\n+  static address vector_sin_double256() { return _vector_sin_double256; }\n+  static address vector_sin_double512() { return _vector_sin_double512; }\n+\n+  static address vector_cos_float64()    { return _vector_cos_float64;   }\n+  static address vector_cos_float128()   { return _vector_cos_float128;  }\n+  static address vector_cos_float256()   { return _vector_cos_float256;  }\n+  static address vector_cos_float512()   { return _vector_cos_float512;  }\n+  static address vector_cos_double64()   { return _vector_cos_double64;  }\n+  static address vector_cos_double128()  { return _vector_cos_double128; }\n+  static address vector_cos_double256()  { return _vector_cos_double256; }\n+  static address vector_cos_double512()  { return _vector_cos_double512; }\n+\n+  static address vector_tan_float64()   { return _vector_tan_float64;   }\n+  static address vector_tan_float128()  { return _vector_tan_float128;  }\n+  static address vector_tan_float256()  { return _vector_tan_float256;  }\n+  static address vector_tan_float512()  { return _vector_tan_float512;  }\n+  static address vector_tan_double64()  { return _vector_tan_double64;  }\n+  static address vector_tan_double128() { return _vector_tan_double128; }\n+  static address vector_tan_double256() { return _vector_tan_double256; }\n+  static address vector_tan_double512() { return _vector_tan_double512; }\n+\n+  static address vector_sinh_float64()   { return _vector_sinh_float64;   }\n+  static address vector_sinh_float128()  { return _vector_sinh_float128;  }\n+  static address vector_sinh_float256()  { return _vector_sinh_float256;  }\n+  static address vector_sinh_float512()  { return _vector_sinh_float512;  }\n+  static address vector_sinh_double64()  { return _vector_sinh_double64;  }\n+  static address vector_sinh_double128() { return _vector_sinh_double128; }\n+  static address vector_sinh_double256() { return _vector_sinh_double256; }\n+  static address vector_sinh_double512() { return _vector_sinh_double512; }\n+\n+  static address vector_cosh_float64()   { return _vector_cosh_float64;   }\n+  static address vector_cosh_float128()  { return _vector_cosh_float128;  }\n+  static address vector_cosh_float256()  { return _vector_cosh_float256;  }\n+  static address vector_cosh_float512()  { return _vector_cosh_float512;  }\n+  static address vector_cosh_double64()  { return _vector_cosh_double64;  }\n+  static address vector_cosh_double128() { return _vector_cosh_double128; }\n+  static address vector_cosh_double256() { return _vector_cosh_double256; }\n+  static address vector_cosh_double512() { return _vector_cosh_double512; }\n+\n+  static address vector_tanh_float64()   { return _vector_tanh_float64;   }\n+  static address vector_tanh_float128()  { return _vector_tanh_float128;  }\n+  static address vector_tanh_float256()  { return _vector_tanh_float256;  }\n+  static address vector_tanh_float512()  { return _vector_tanh_float512;  }\n+  static address vector_tanh_double64()  { return _vector_tanh_double64;  }\n+  static address vector_tanh_double128() { return _vector_tanh_double128; }\n+  static address vector_tanh_double256() { return _vector_tanh_double256; }\n+  static address vector_tanh_double512() { return _vector_tanh_double512; }\n+\n+  static address vector_asin_float64()   { return _vector_asin_float64;   }\n+  static address vector_asin_float128()  { return _vector_asin_float128;  }\n+  static address vector_asin_float256()  { return _vector_asin_float256;  }\n+  static address vector_asin_float512()  { return _vector_asin_float512;  }\n+  static address vector_asin_double64()  { return _vector_asin_double64;  }\n+  static address vector_asin_double128() { return _vector_asin_double128; }\n+  static address vector_asin_double256() { return _vector_asin_double256; }\n+  static address vector_asin_double512() { return _vector_asin_double512; }\n+\n+  static address vector_acos_float64()   { return _vector_acos_float64;   }\n+  static address vector_acos_float128()  { return _vector_acos_float128;  }\n+  static address vector_acos_float256()  { return _vector_acos_float256;  }\n+  static address vector_acos_float512()  { return _vector_acos_float512;  }\n+  static address vector_acos_double64()  { return _vector_acos_double64;  }\n+  static address vector_acos_double128() { return _vector_acos_double128; }\n+  static address vector_acos_double256() { return _vector_acos_double256; }\n+  static address vector_acos_double512() { return _vector_acos_double512; }\n+\n+  static address vector_atan_float64()   { return _vector_atan_float64;   }\n+  static address vector_atan_float128()  { return _vector_atan_float128;  }\n+  static address vector_atan_float256()  { return _vector_atan_float256;  }\n+  static address vector_atan_float512()  { return _vector_atan_float512;  }\n+  static address vector_atan_double64()  { return _vector_atan_double64;  }\n+  static address vector_atan_double128() { return _vector_atan_double128; }\n+  static address vector_atan_double256() { return _vector_atan_double256; }\n+  static address vector_atan_double512() { return _vector_atan_double512; }\n+\n+  static address vector_pow_float64()   { return _vector_pow_float64;   }\n+  static address vector_pow_float128()  { return _vector_pow_float128;  }\n+  static address vector_pow_float256()  { return _vector_pow_float256;  }\n+  static address vector_pow_float512()  { return _vector_pow_float512;  }\n+  static address vector_pow_double64()  { return _vector_pow_double64;  }\n+  static address vector_pow_double128() { return _vector_pow_double128; }\n+  static address vector_pow_double256() { return _vector_pow_double256; }\n+  static address vector_pow_double512() { return _vector_pow_double512; }\n+\n+  static address vector_hypot_float64()   { return _vector_hypot_float64;   }\n+  static address vector_hypot_float128()  { return _vector_hypot_float128;  }\n+  static address vector_hypot_float256()  { return _vector_hypot_float256;  }\n+  static address vector_hypot_float512()  { return _vector_hypot_float512;  }\n+  static address vector_hypot_double64()  { return _vector_hypot_double64;  }\n+  static address vector_hypot_double128() { return _vector_hypot_double128; }\n+  static address vector_hypot_double256() { return _vector_hypot_double256; }\n+  static address vector_hypot_double512() { return _vector_hypot_double512; }\n+\n+  static address vector_cbrt_float64()   { return _vector_cbrt_float64;   }\n+  static address vector_cbrt_float128()  { return _vector_cbrt_float128;  }\n+  static address vector_cbrt_float256()  { return _vector_cbrt_float256;  }\n+  static address vector_cbrt_float512()  { return _vector_cbrt_float512;  }\n+  static address vector_cbrt_double64()  { return _vector_cbrt_double64;  }\n+  static address vector_cbrt_double128() { return _vector_cbrt_double128; }\n+  static address vector_cbrt_double256() { return _vector_cbrt_double256; }\n+  static address vector_cbrt_double512() { return _vector_cbrt_double512; }\n+\n+  static address vector_atan2_float64()   { return _vector_atan2_float64;   }\n+  static address vector_atan2_float128()  { return _vector_atan2_float128;  }\n+  static address vector_atan2_float256()  { return _vector_atan2_float256;  }\n+  static address vector_atan2_float512()  { return _vector_atan2_float512;  }\n+  static address vector_atan2_double64()  { return _vector_atan2_double64;  }\n+  static address vector_atan2_double128() { return _vector_atan2_double128; }\n+  static address vector_atan2_double256() { return _vector_atan2_double256; }\n+  static address vector_atan2_double512() { return _vector_atan2_double512; }\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n+\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":331,"deletions":0,"binary":false,"changes":331,"status":"modified"},{"patch":"@@ -1527,0 +1527,1 @@\n+  declare_c2_type(CallLeafVectorNode, CallLeafNode)                       \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"utilities\/globalDefinitions_vecApi.hpp\"\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n- *      Vector64ConversionTests\n+ * Vector64ConversionTests\n","filename":"test\/jdk\/jdk\/incubator\/vector\/Vector64ConversionTests.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}