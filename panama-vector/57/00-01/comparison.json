{"files":[{"patch":"@@ -2077,1 +2077,1 @@\n-  if (src_hi != OptoReg::Bad && dst_hi != OptoReg::Bad) {\n+  if (src_hi != OptoReg::Bad) {\n@@ -2198,3 +2198,0 @@\n-      } else if (dst_lo_rc == rc_predicate) {\n-        __ unspill_sve_predicate(as_PRegister(Matcher::_regEncode[dst_lo]), ra_->reg2offset(src_lo),\n-                                 Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n@@ -2203,18 +2200,2 @@\n-        if (ideal_reg() == Op_RegVMask) {\n-          __ spill_copy_sve_predicate_stack_to_stack(src_offset, dst_offset,\n-                                                     Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n-        } else {\n-          __ unspill(rscratch1, is64, src_offset);\n-          __ spill(rscratch1, is64, dst_offset);\n-        }\n-      }\n-      break;\n-    case rc_predicate:\n-      if (dst_lo_rc == rc_predicate) {\n-        __ sve_mov(as_PRegister(Matcher::_regEncode[dst_lo]), as_PRegister(Matcher::_regEncode[src_lo]));\n-      } else if (dst_lo_rc == rc_stack) {\n-        __ spill_sve_predicate(as_PRegister(Matcher::_regEncode[src_lo]), ra_->reg2offset(dst_lo),\n-                               Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n-      } else {\n-        assert(false, \"bad src and dst rc_class combination.\");\n-        ShouldNotReachHere();\n+        __ unspill(rscratch1, is64, src_offset);\n+        __ spill(rscratch1, is64, dst_offset);\n@@ -2258,4 +2239,0 @@\n-    } else if (ideal_reg() == Op_RegVMask) {\n-      assert(Matcher::supports_scalable_vector(), \"bad register type for spill\");\n-      int vsize = Matcher::scalable_predicate_reg_slots() * 32;\n-      st->print(\"\\t# predicate spill size = %d\", vsize);\n@@ -2469,4 +2446,0 @@\n-const RegMask* Matcher::predicate_reg_mask(void) {\n-  return &_PR_REG_mask;\n-}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":3,"deletions":30,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -3235,22 +3235,1 @@\n-\/\/ SVE load\/store predicate register\n-#define INSN(NAME, op1)                                                  \\\n-  void NAME(PRegister Pt, const Address &a)  {                           \\\n-    starti;                                                              \\\n-    assert(a.index() == noreg, \"invalid address variant\");               \\\n-    f(op1, 31, 29), f(0b0010110, 28, 22), sf(a.offset() >> 3, 21, 16),   \\\n-    f(0b000, 15, 13), f(a.offset() & 0x7, 12, 10), srf(a.base(), 5),     \\\n-    f(0, 4), prf(Pt, 0);                                                 \\\n-  }\n-\n-  INSN(sve_ldr, 0b100); \/\/ LDR (predicate)\n-  INSN(sve_str, 0b111); \/\/ STR (predicate)\n-#undef INSN\n-\n-  \/\/ SVE move predicate register\n-  void sve_mov(PRegister Pd, PRegister Pn) {\n-    starti;\n-    f(0b001001011000, 31, 20), prf(Pn, 16), f(0b01, 15, 14), prf(Pn, 10);\n-    f(0, 9), prf(Pn, 5), f(0, 4), prf(Pd, 0);\n-  }\n-\n-  \/\/ SVE cpy immediate\n+   \/\/ SVE cpy immediate\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":1,"deletions":22,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -318,1 +318,0 @@\n-  PRegSet               _p_regs;\n@@ -332,2 +331,0 @@\n-        } else if (vm_reg->is_PRegister()) {\n-          _p_regs += PRegSet::of(vm_reg->as_PRegister());\n@@ -347,2 +344,1 @@\n-      _fp_regs(),\n-      _p_regs() {\n+      _fp_regs() {\n@@ -356,1 +352,0 @@\n-    __ push_p(_p_regs, sp);\n@@ -361,1 +356,0 @@\n-    __ pop_p(_p_regs, sp);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.cpp","additions":1,"deletions":7,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2215,76 +2215,0 @@\n-\/\/ Return the number of dwords pushed\n-int MacroAssembler::push_p(unsigned int bitset, Register stack) {\n-  bool use_sve = false;\n-  int sve_predicate_size_in_slots = 0;\n-\n-#ifdef COMPILER2\n-  use_sve = Matcher::supports_scalable_vector();\n-  if (use_sve) {\n-    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n-  }\n-#endif\n-\n-  if (!use_sve) {\n-    return 0;\n-  }\n-\n-  const int num_of_regs = PRegisterImpl::number_of_saved_registers;\n-  unsigned char regs[num_of_regs];\n-  int count = 0;\n-  for (int reg = 0; reg < num_of_regs; reg++) {\n-    if (1 & bitset)\n-      regs[count++] = reg;\n-    bitset >>= 1;\n-  }\n-\n-  if (count == 0) {\n-    return 0;\n-  }\n-\n-  int total_push_bytes = align_up(sve_predicate_size_in_slots *\n-                                  VMRegImpl::stack_slot_size * count, 16);\n-  sub(stack, stack, total_push_bytes);\n-  for (int i = 0; i < count; i++) {\n-    sve_str(as_PRegister(regs[i]), Address(stack, i));\n-  }\n-  return total_push_bytes \/ 8;\n-}\n-\n-\/\/ Return the number of dwords poped\n-int MacroAssembler::pop_p(unsigned int bitset, Register stack) {\n-  bool use_sve = false;\n-  int sve_predicate_size_in_slots = 0;\n-\n-#ifdef COMPILER2\n-  use_sve = Matcher::supports_scalable_vector();\n-  if (use_sve) {\n-    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n-  }\n-#endif\n-\n-  if (!use_sve) {\n-    return 0;\n-  }\n-\n-  const int num_of_regs = PRegisterImpl::number_of_saved_registers;\n-  unsigned char regs[num_of_regs];\n-  int count = 0;\n-  for (int reg = 0; reg < num_of_regs; reg++) {\n-    if (1 & bitset)\n-      regs[count++] = reg;\n-    bitset >>= 1;\n-  }\n-\n-  if (count == 0) {\n-    return 0;\n-  }\n-\n-  int total_pop_bytes = align_up(sve_predicate_size_in_slots *\n-                                 VMRegImpl::stack_slot_size * count, 16);\n-  for (int i = count - 1; i >= 0; i--) {\n-    sve_ldr(as_PRegister(regs[i]), Address(stack, i));\n-  }\n-  add(stack, stack, total_pop_bytes);\n-  return total_pop_bytes \/ 8;\n-}\n-\n@@ -2749,1 +2673,1 @@\n-                                    int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n+                                    int sve_vector_size_in_bytes) {\n@@ -2766,6 +2690,0 @@\n-  if (save_vectors && use_sve && total_predicate_in_bytes > 0) {\n-    sub(sp, sp, total_predicate_in_bytes);\n-    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n-      sve_str(as_PRegister(i), Address(sp, i));\n-    }\n-  }\n@@ -2775,7 +2693,1 @@\n-                                   int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n-  if (restore_vectors && use_sve && total_predicate_in_bytes > 0) {\n-    for (int i = PRegisterImpl::number_of_saved_registers - 1; i >= 0; i--) {\n-      sve_ldr(as_PRegister(i), Address(sp, i));\n-    }\n-    add(sp, sp, total_predicate_in_bytes);\n-  }\n+                                   int sve_vector_size_in_bytes) {\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":2,"deletions":90,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -471,3 +471,0 @@\n-  int push_p(unsigned int bitset, Register stack);\n-  int pop_p(unsigned int bitset, Register stack);\n-\n@@ -485,3 +482,0 @@\n-  void push_p(PRegSet regs, Register stack) { if (regs.bits()) push_p(regs.bits(), stack); }\n-  void pop_p(PRegSet regs, Register stack) { if (regs.bits()) pop_p(regs.bits(), stack); }\n-\n@@ -919,1 +913,1 @@\n-                      int sve_vector_size_in_bytes = 0, int total_predicate_in_bytes = 0);\n+                      int sve_vector_size_in_bytes = 0);\n@@ -921,1 +915,1 @@\n-                     int sve_vector_size_in_bytes = 0, int total_predicate_in_bytes = 0);\n+                      int sve_vector_size_in_bytes = 0);\n@@ -1393,1 +1387,0 @@\n-\n@@ -1397,4 +1390,0 @@\n-  void spill_sve_predicate(PRegister pr, int offset, int predicate_reg_size_in_bytes) {\n-    sve_str(pr, sve_spill_address(predicate_reg_size_in_bytes, offset));\n-  }\n-\n@@ -1411,1 +1400,0 @@\n-\n@@ -1415,4 +1403,0 @@\n-  void unspill_sve_predicate(PRegister pr, int offset, int predicate_reg_size_in_bytes) {\n-    sve_ldr(pr, sve_spill_address(predicate_reg_size_in_bytes, offset));\n-  }\n-\n@@ -1441,6 +1425,0 @@\n-  void spill_copy_sve_predicate_stack_to_stack(int src_offset, int dst_offset,\n-                                               int sve_predicate_reg_size_in_bytes) {\n-    sve_ldr(ptrue, sve_spill_address(sve_predicate_reg_size_in_bytes, src_offset));\n-    sve_str(ptrue, sve_spill_address(sve_predicate_reg_size_in_bytes, dst_offset));\n-    reinitialize_ptrue();\n-  }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":2,"deletions":24,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n@@ -37,2 +37,1 @@\n-  = ConcreteRegisterImpl::max_fpr +\n-    PRegisterImpl::number_of_registers * PRegisterImpl::max_slots_per_register;\n+  = ConcreteRegisterImpl::max_fpr + PRegisterImpl::number_of_registers;\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n@@ -245,5 +245,0 @@\n-    number_of_governing_registers = 8,\n-    \/\/ AArch64 has 8 governing predicate registers, but p7 is used as an\n-    \/\/ all-1s register so the predicates to save are from p0 to p6 if we\n-    \/\/ don't have non-governing predicate registers support.\n-    number_of_saved_registers = number_of_governing_registers - 1,\n@@ -383,1 +378,0 @@\n-typedef AbstractRegSet<PRegister> PRegSet;\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -102,4 +102,1 @@\n-  int v0_offset_in_bytes();\n-\n-  \/\/ Total stack size in bytes for saving sve predicate registers.\n-  int total_sve_predicate_in_bytes();\n+  int v0_offset_in_bytes(void)   { return 0; }\n@@ -143,1 +140,1 @@\n-  int r0_offset = v0_offset_in_bytes() + (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n@@ -147,20 +144,0 @@\n-int RegisterSaver::v0_offset_in_bytes() {\n-  \/\/ The floating point registers are located above the predicate registers if\n-  \/\/ they are present in the stack frame pushed by save_live_registers(). So the\n-  \/\/ offset depends on the saved total predicate vectors in the stack frame.\n-  return (total_sve_predicate_in_bytes() \/ VMRegImpl::stack_slot_size) * BytesPerInt;\n-}\n-\n-int RegisterSaver::total_sve_predicate_in_bytes() {\n-#if COMPILER2\n-  if (_save_vectors && Matcher::supports_scalable_vector()) {\n-    \/\/ The number of total predicate bytes is unlikely to be a multiple\n-    \/\/ of 16 bytes so we manually align it up.\n-    return align_up(Matcher::scalable_predicate_reg_slots() *\n-                    VMRegImpl::stack_slot_size *\n-                    PRegisterImpl::number_of_saved_registers, 16);\n-  }\n-#endif\n-  return 0;\n-}\n-\n@@ -171,3 +148,0 @@\n-  int sve_predicate_size_in_slots = 0;\n-  int total_predicate_in_bytes = total_sve_predicate_in_bytes();\n-  int total_predicate_in_slots = total_predicate_in_bytes \/ VMRegImpl::stack_slot_size;\n@@ -177,5 +151,2 @@\n-  if (use_sve) {\n-    sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n-    sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n-    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n-  }\n+  sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+  sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n@@ -186,0 +157,1 @@\n+    int vect_words = 0;\n@@ -193,4 +165,3 @@\n-    int extra_vector_bytes = extra_save_slots_per_register *\n-                             VMRegImpl::stack_slot_size *\n-                             FloatRegisterImpl::number_of_registers;\n-    additional_frame_words += ((extra_vector_bytes + total_predicate_in_bytes) \/ wordSize);\n+    vect_words = FloatRegisterImpl::number_of_registers * extra_save_slots_per_register \/\n+                 VMRegImpl::slots_per_word;\n+    additional_frame_words += vect_words;\n@@ -214,1 +185,1 @@\n-  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes, total_predicate_in_bytes);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n@@ -231,1 +202,2 @@\n-      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots), r->as_VMReg());\n+      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots),\n+                                r->as_VMReg());\n@@ -239,1 +211,1 @@\n-      sp_offset = use_sve ? (total_predicate_in_slots + sve_vector_size_in_slots * i) :\n+      sp_offset = use_sve ? (sve_vector_size_in_slots * i) :\n@@ -244,9 +216,2 @@\n-    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n-  }\n-\n-  if (_save_vectors && use_sve) {\n-    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n-      PRegister r = as_PRegister(i);\n-      int sp_offset = sve_predicate_size_in_slots * i;\n-      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n-    }\n+    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset),\n+                              r->as_VMReg());\n@@ -261,1 +226,1 @@\n-                   Matcher::scalable_vector_reg_size(T_BYTE), total_sve_predicate_in_bytes());\n+                   Matcher::scalable_vector_reg_size(T_BYTE));\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":15,"deletions":50,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -42,1 +42,2 @@\n-  assert(is_Register(), \"must be\");\n+  assert( is_Register(), \"must be\");\n+  \/\/ Yuk\n@@ -47,1 +48,2 @@\n-  assert(is_FloatRegister() && is_even(value()), \"must be\");\n+  assert( is_FloatRegister() && is_even(value()), \"must be\" );\n+  \/\/ Yuk\n@@ -53,1 +55,1 @@\n-  assert(is_PRegister(), \"must be\");\n+  assert( is_PRegister(), \"must be\" );\n","filename":"src\/hotspot\/cpu\/aarch64\/vmreg_aarch64.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1000,4 +1000,0 @@\n-const RegMask* Matcher::predicate_reg_mask(void) {\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2167,4 +2167,0 @@\n-const RegMask* Matcher::predicate_reg_mask(void) {\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1553,4 +1553,0 @@\n-const RegMask* Matcher::predicate_reg_mask(void) {\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1843,4 +1843,0 @@\n-const RegMask* Matcher::predicate_reg_mask(void) {\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -949,1 +949,1 @@\n-    return \"TypeVMask::VMASK\";\n+    return \"Type::BOTTOM\";\n","filename":"src\/hotspot\/share\/adlc\/archDesc.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2012, Oracle and\/or its affiliates. All rights reserved.\n@@ -273,1 +273,0 @@\n-  if( strcmp(opType,\"LoadVectorMask\")==0 )  return Form::idealV;\n@@ -292,1 +291,0 @@\n-  if( strcmp(opType,\"StoreVectorMask\")==0 )  return Form::idealV;\n","filename":"src\/hotspot\/share\/adlc\/forms.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -786,2 +786,1 @@\n-       !strcmp(_matrule->_rChild->_opType,\"VectorMaskGen\") ||\n-       !strcmp(_matrule->_rChild->_opType,\"VectorCmpMaskGen\") ||\n+       !strcmp(_matrule->_rChild->_opType,\"VectorMaskGen\")||\n@@ -2278,1 +2277,0 @@\n-  if (strcmp(name, \"RegVMask\") == 0) size = 1;\n@@ -3512,1 +3510,1 @@\n-    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorMasked\", \"StoreVectorMasked\", \"LoadVectorMask\", \"StoreVectorMask\",\n+    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n@@ -4087,1 +4085,0 @@\n-        strcmp(opType,\"MaskToVector\")==0 ||\n@@ -4205,1 +4202,1 @@\n-    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\", \"LoadVectorMasked\",\"StoreVectorMasked\",\n+    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\",\"LoadVectorMasked\",\"StoreVectorMasked\",\n@@ -4209,2 +4206,1 @@\n-    \"ExtractB\",\"ExtractUB\",\"ExtractC\",\"ExtractS\",\"ExtractI\",\"ExtractL\",\"ExtractF\",\"ExtractD\",\n-    \"MaskToVector\", \"LoadVectorMask\", \"StoreVectorMask\"\n+    \"ExtractB\",\"ExtractUB\",\"ExtractC\",\"ExtractS\",\"ExtractI\",\"ExtractL\",\"ExtractF\",\"ExtractD\"\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":5,"deletions":9,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -80,1 +80,0 @@\n-  if( _is_predicate ) tty->print(\"Predicate \");\n@@ -488,1 +487,0 @@\n-\n@@ -643,1 +641,1 @@\n-      } else if (lrg.num_regs() == 1 && !lrg.is_scalable()) {\n+      } else if (lrg.num_regs() == 1) {\n@@ -658,13 +656,9 @@\n-          if (num_regs > 1) {\n-            OptoReg::Name lo = OptoReg::add(hi, (1-num_regs)); \/\/ Find lo\n-            \/\/ We have to use pair [lo,lo+1] even for wide vectors\/vmasks because\n-            \/\/ the rest of code generation works only with pairs. It is safe\n-            \/\/ since for registers encoding only 'lo' is used.\n-            \/\/ Second reg from pair is used in ScheduleAndBundle on SPARC where\n-            \/\/ vector max size is 8 which corresponds to registers pair.\n-            \/\/ It is also used in BuildOopMaps but oop operations are not\n-            \/\/ vectorized.\n-            set2(i, lo);\n-          } else {\n-            set1(i, hi);\n-          }\n+          OptoReg::Name lo = OptoReg::add(hi, (1-num_regs)); \/\/ Find lo\n+          \/\/ We have to use pair [lo,lo+1] even for wide vectors because\n+          \/\/ the rest of code generation works only with pairs. It is safe\n+          \/\/ since for registers encoding only 'lo' is used.\n+          \/\/ Second reg from pair is used in ScheduleAndBundle on SPARC where\n+          \/\/ vector max size is 8 which corresponds to registers pair.\n+          \/\/ It is also used in BuildOopMaps but oop operations are not\n+          \/\/ vectorized.\n+          set2(i, lo);\n@@ -833,13 +827,0 @@\n-        if (ireg == Op_RegVMask) {\n-          assert(Matcher::has_predicated_vectors(), \"predicated vector should be supported\");\n-          lrg._is_predicate = 1;\n-          if (Matcher::supports_scalable_vector()) {\n-            lrg._is_scalable = 1;\n-            \/\/ For scalable predicate, when it is allocated in physical register,\n-            \/\/ num_regs is RegMask::SlotsPerRegVmask for reg mask,\n-            \/\/ which may not be the actual physical register size.\n-            \/\/ If it is allocated in stack, we need to get the actual\n-            \/\/ physical length of scalable predicate register.\n-            lrg.set_scalable_reg_slots(Matcher::scalable_predicate_reg_slots());\n-          }\n-        }\n@@ -988,6 +969,0 @@\n-        case Op_RegVMask:\n-          assert(Matcher::has_predicated_vectors(), \"sanity\");\n-          assert(RegMask::num_registers(Op_RegVMask) == RegMask::SlotsPerRegVmask, \"sanity\");\n-          lrg.set_num_regs(RegMask::SlotsPerRegVmask);\n-          lrg.set_reg_pressure(0);\n-          break;\n@@ -1394,5 +1369,0 @@\n-    } else if (lrg._is_predicate) {\n-      assert(num_regs == RegMask::SlotsPerRegVmask, \"scalable predicate register\");\n-      num_regs = lrg.scalable_reg_slots();\n-      mask.clear_to_sets(num_regs);\n-      return mask.find_first_set(lrg, num_regs);\n@@ -1445,1 +1415,1 @@\n-  if (lrg._is_vector || lrg.num_regs() == 2 || lrg.is_scalable()) {\n+  if (lrg._is_vector || lrg.num_regs() == 2) {\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":12,"deletions":42,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -166,2 +166,2 @@\n-      assert(_is_vector && (_num_regs == RegMask::SlotsPerVecA) ||\n-             _is_predicate && (_num_regs == RegMask::SlotsPerRegVmask), \"unexpected scalable reg\");\n+      \/\/ Should only be a vector for now, but it could also be a RegVMask in future.\n+      assert(_is_vector && (_num_regs == RegMask::SlotsPerVecA), \"unexpected scalable reg\");\n@@ -198,1 +198,0 @@\n-         _is_predicate:1,       \/\/ True if in mask\/predicate registers\n","filename":"src\/hotspot\/share\/opto\/chaitin.hpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -414,1 +414,0 @@\n-macro(LoadVectorMask)\n@@ -416,1 +415,0 @@\n-macro(StoreVectorMask)\n@@ -450,1 +448,0 @@\n-macro(VectorMask)\n@@ -469,4 +466,0 @@\n-macro(VectorToMask)\n-macro(VectorCmpMaskGen)\n-macro(MaskAll)\n-macro(MaskToVector)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -3465,2 +3465,0 @@\n-  case Op_LoadVectorMask:\n-  case Op_StoreVectorMask:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -691,1 +691,0 @@\n-        case Op_StoreVectorMask:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -97,1 +97,0 @@\n-  idealreg2spillmask  [Op_RegVMask] = NULL;\n@@ -112,1 +111,0 @@\n-  idealreg2debugmask  [Op_RegVMask] = NULL;\n@@ -127,1 +125,0 @@\n-  idealreg2mhdebugmask[Op_RegVMask] = NULL;\n@@ -436,19 +433,1 @@\n-const int Matcher::scalable_predicate_reg_slots() {\n-  assert(Matcher::has_predicated_vectors() && Matcher::supports_scalable_vector(),\n-        \"scalable predicate vector should be supported\");\n-  int vector_reg_bit_size = Matcher::scalable_vector_reg_size(T_BYTE) << LogBitsPerByte;\n-  \/\/ We assume each predicate register is one-eighth of the size of\n-  \/\/ scalable vector register, one mask bit per vector byte.\n-  int predicate_reg_bit_size = vector_reg_bit_size >> 3;\n-  \/\/ Compute number of slots which is required when scalable predicate\n-  \/\/ register is spilled. E.g. if scalable vector register is 640 bits,\n-  \/\/ predicate register is 80 bits, which is 2.5 * slots.\n-  \/\/ We will round up the slot number to power of 2, which is required\n-  \/\/ by find_first_set().\n-  int slots = predicate_reg_bit_size & (BitsPerInt - 1)\n-              ? (predicate_reg_bit_size >> LogBitsPerInt) + 1\n-              : predicate_reg_bit_size >> LogBitsPerInt;\n-  return round_up_power_of_2(slots);\n-}\n-\n-#define NOF_STACK_MASKS (3*13)\n+#define NOF_STACK_MASKS (3*12)\n@@ -496,17 +475,14 @@\n-  idealreg2spillmask  [Op_RegVMask] = &rms[24];\n-\n-  idealreg2debugmask  [Op_VecA] = &rms[25];\n-  idealreg2debugmask  [Op_VecS] = &rms[26];\n-  idealreg2debugmask  [Op_VecD] = &rms[27];\n-  idealreg2debugmask  [Op_VecX] = &rms[28];\n-  idealreg2debugmask  [Op_VecY] = &rms[29];\n-  idealreg2debugmask  [Op_VecZ] = &rms[30];\n-  idealreg2debugmask  [Op_RegVMask] = &rms[31];\n-\n-  idealreg2mhdebugmask[Op_VecA] = &rms[32];\n-  idealreg2mhdebugmask[Op_VecS] = &rms[33];\n-  idealreg2mhdebugmask[Op_VecD] = &rms[34];\n-  idealreg2mhdebugmask[Op_VecX] = &rms[35];\n-  idealreg2mhdebugmask[Op_VecY] = &rms[36];\n-  idealreg2mhdebugmask[Op_VecZ] = &rms[37];\n-  idealreg2mhdebugmask[Op_RegVMask] = &rms[38];\n+\n+  idealreg2debugmask  [Op_VecA] = &rms[24];\n+  idealreg2debugmask  [Op_VecS] = &rms[25];\n+  idealreg2debugmask  [Op_VecD] = &rms[26];\n+  idealreg2debugmask  [Op_VecX] = &rms[27];\n+  idealreg2debugmask  [Op_VecY] = &rms[28];\n+  idealreg2debugmask  [Op_VecZ] = &rms[29];\n+\n+  idealreg2mhdebugmask[Op_VecA] = &rms[30];\n+  idealreg2mhdebugmask[Op_VecS] = &rms[31];\n+  idealreg2mhdebugmask[Op_VecD] = &rms[32];\n+  idealreg2mhdebugmask[Op_VecX] = &rms[33];\n+  idealreg2mhdebugmask[Op_VecY] = &rms[34];\n+  idealreg2mhdebugmask[Op_VecZ] = &rms[35];\n@@ -628,13 +604,0 @@\n-    \/\/ Exclude last input arg stack slots to avoid spilling vector register there,\n-    \/\/ otherwise RegVMask spills could stomp over stack slots in caller frame.\n-    for (; (in >= init_in) && (k < scalable_predicate_reg_slots()); k++) {\n-      scalable_stack_mask.Remove(in);\n-      in = OptoReg::add(in, -1);\n-    }\n-\n-    \/\/ For RegVMask\n-    scalable_stack_mask.clear_to_sets(scalable_predicate_reg_slots());\n-    assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n-    *idealreg2spillmask[Op_RegVMask] = *idealreg2regmask[Op_RegVMask];\n-    idealreg2spillmask[Op_RegVMask]->OR(scalable_stack_mask);\n-\n@@ -655,1 +618,0 @@\n-    *idealreg2spillmask[Op_RegVMask] = RegMask::Empty;\n@@ -697,1 +659,0 @@\n-  *idealreg2debugmask[Op_RegVMask] = *idealreg2spillmask[Op_RegVMask];\n@@ -712,1 +673,0 @@\n-  *idealreg2mhdebugmask[Op_RegVMask] = *idealreg2spillmask[Op_RegVMask];\n@@ -733,1 +693,0 @@\n-  idealreg2debugmask[Op_RegVMask]->SUBTRACT(*caller_save_mask);\n@@ -748,1 +707,0 @@\n-  idealreg2mhdebugmask[Op_RegVMask]->SUBTRACT(*mh_caller_save_mask);\n@@ -1010,1 +968,0 @@\n-  idealreg2regmask[Op_RegVMask] = regmask_for_ideal_register(Op_RegVMask, ret);\n@@ -2317,11 +2274,0 @@\n-  if (n->is_Vector() && (n->req() == 4) && n->in(3)->is_VectorMask()) {\n-    \/\/ TODO: unary op\n-    \/\/ Handle op with mask\n-    Node* pair = new BinaryNode(n->in(1), n->in(2));\n-    Node* mask = n->in(3);\n-    n->set_req(1, pair);\n-    n->set_req(2, mask);\n-    n->del_req(3);\n-    return;\n-  }\n-\n@@ -2467,2 +2413,1 @@\n-    case Op_VectorMaskCmp:\n-    case Op_VectorCmpMaskGen: {\n+    case Op_VectorMaskCmp: {\n@@ -2605,1 +2550,1 @@\n-    assert(ideal_reg >= Op_VecA && ideal_reg <= Op_RegVMask, \"not a vector: %d\", ideal_reg);\n+    assert(ideal_reg >= Op_VecA && ideal_reg <= Op_VecZ, \"not a vector: %d\", ideal_reg);\n@@ -2628,1 +2573,0 @@\n-    case Op_RegVMask: return Matcher::predicate_reg_mask();\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":18,"deletions":74,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -325,2 +325,0 @@\n-  static const RegMask* predicate_reg_mask(void);\n-\n@@ -348,2 +346,0 @@\n-  \/\/ Actual max scalable predicate register length.\n-  static const int scalable_predicate_reg_slots();\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -166,0 +166,1 @@\n+class StoreVectorMaskedNode;\n@@ -168,1 +169,0 @@\n-class StoreVectorMaskedNode;\n@@ -171,1 +171,0 @@\n-class VectorMaskNode;\n@@ -696,1 +695,0 @@\n-      DEFINE_CLASS_ID(VectorMask, Type, 7)\n@@ -927,1 +925,0 @@\n-  DEFINE_CLASS_QUERY(VectorMask)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -312,1 +312,1 @@\n-      assert(val->ideal_reg() == Op_VecA || val->ideal_reg() == Op_RegVMask, \"scalable register\");\n+      assert(val->ideal_reg() == Op_VecA, \"scalable vector register\");\n@@ -316,1 +316,1 @@\n-        n_regs = lrgs(val_idx)._is_predicate ? RegMask::SlotsPerRegVmask : RegMask::SlotsPerVecA;\n+        n_regs = RegMask::SlotsPerVecA;\n@@ -321,1 +321,2 @@\n-      if (lrgs(val_idx).is_scalable() && val->ideal_reg() == Op_VecA) {\n+      if (lrgs(val_idx).is_scalable()) {\n+        assert(val->ideal_reg() == Op_VecA, \"scalable vector register\");\n","filename":"src\/hotspot\/share\/opto\/postaloc.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -231,1 +231,1 @@\n-  if (lrg.is_scalable() && lrg._is_vector) {\n+  if (lrg.is_scalable()) {\n","filename":"src\/hotspot\/share\/opto\/regmask.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -108,1 +108,1 @@\n-         SlotsPerRegVmask = X86_ONLY(2) NOT_X86(1) };\n+         };\n","filename":"src\/hotspot\/share\/opto\/regmask.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -87,1 +87,0 @@\n-  { Bad,             T_ILLEGAL,    \"vmask:\",        false, Op_RegVMask,          relocInfo::none          },  \/\/ VMask\n@@ -683,4 +682,0 @@\n-  if (Matcher::has_predicated_vectors()) {\n-    TypeVMask::VMASK = TypeVMask::make(T_BYTE, Matcher::max_vector_size(T_BYTE));\n-  }\n-\n@@ -693,1 +688,0 @@\n-  mreg2type[Op_RegVMask] = TypeVMask::VMASK;\n@@ -1015,1 +1009,0 @@\n-  Bad,          \/\/ VMask - handled in v-call\n@@ -1316,49 +1309,0 @@\n-\/\/===============================TypeVMask=====================================\n-bool TypeVMask::empty(void) const {\n-  return false;\n-}\n-\n-\/\/------------------------------eq---------------------------------\n-\/\/ Structural equality check for Type representations\n-bool TypeVMask::eq(const Type *t) const {\n-  const TypeVMask* vt = t->is_vmask();\n-  return (_elem_size == vt->_elem_size) && (_length == vt->_length);\n-}\n-\n-\/\/------------------------------hash-------------------------------\n-\/\/ Type-specific hashing function.\n-int TypeVMask::hash(void) const {\n-  return _elem_size + _length * _elem_size;\n-}\n-\n-bool TypeVMask::singleton(void) const {\n-  return false;\n-}\n-\n-const TypeVMask* TypeVMask::VMASK = NULL;\n-\n-\/\/------------------------------xdual-------------------------------\n-\/\/ Dual: compute field-by-field dual\n-const Type* TypeVMask::xdual() const {\n-  return this;\n-}\n-\n-\/\/ Compute the MEET of two types. It returns a new Type object.\n-const Type* TypeVMask::xmeet(const Type* t) const {\n-  if (this == t) return this;  \/\/ Meeting same type-rep?\n-  switch (t->base()) {          \/\/ switch on original type\n-  case Bottom:                  \/\/ Ye Olde Default\n-    return t;\n-  case VMask: {                 \/\/ Meeting 2 vmask?\n-    const TypeVMask* vmask = t->is_vmask();\n-    assert(base() == vmask->base(), \"basic type\");\n-    return TypeVMask::make(_elem_size, _length);\n-  }\n-  case Top:\n-    return this;\n-  default:                      \/\/ All else is a mistake\n-    typerr(t);\n-  }\n-  return this;\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":0,"deletions":56,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -63,1 +63,0 @@\n-class   TypeVMask;\n@@ -99,1 +98,0 @@\n-    VMask,                      \/\/ Vector mask\/predicate\n@@ -304,2 +302,0 @@\n-  const TypeVMask  *is_vmask() const;            \/\/ VMask\n-  const TypeVMask  *isa_vmask() const;           \/\/ Returns NULL if not a VMask\n@@ -852,33 +848,0 @@\n-class TypeVMask : public Type {\n-  const uint _elem_size;  \/\/ Element size in bytes of the masked vector\n-  const uint _length;     \/\/ Number of elements in the masked vector\n-public:\n-  TypeVMask(uint elem_size, uint length) :\n-    Type(VMask), _elem_size(elem_size), _length(length) {}\n-  TypeVMask(const BasicType elem_bt, uint length) : Type(VMask),\n-    _elem_size(type2aelembytes(elem_bt)), _length(length) {}\n-\n-  static const TypeVMask* make(const BasicType elem_bt, uint length) {\n-    return (TypeVMask*)(new TypeVMask(elem_bt, length))->hashcons();\n-  }\n-\n-  static const TypeVMask* make(uint elem_size, uint length) {\n-    return (TypeVMask*)(new TypeVMask(elem_size, length))->hashcons();\n-  }\n-\n-  static const TypeVMask* VMASK;\n-\n-  uint element_size_in_bytes(void) const {\n-    return _elem_size;\n-  }\n-  uint length(void) const {\n-    return _length;\n-  }\n-  virtual bool empty(void) const;\n-  virtual bool eq(const Type* t) const;\n-  virtual int hash() const;  \/\/ Type specific hashing\n-  virtual bool singleton(void) const;\n-  virtual const Type* xdual() const;\n-  virtual const Type* xmeet(const Type* t) const;\n-};\n-\n@@ -1731,9 +1694,0 @@\n-inline const TypeVMask* Type::is_vmask() const {\n-  assert( _base == VMask, \"Not a VectorMask\" );\n-  return (TypeVMask*)this;\n-}\n-\n-inline const TypeVMask* Type::isa_vmask() const {\n-  return (_base == VMask) ? (TypeVMask*)this : NULL;\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":0,"deletions":46,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -451,1 +451,1 @@\n-  bool use_mask = gvn().type(argument(n + 5)) != TypePtr::NULL_PTR;\n+  bool is_masked_op = gvn().type(argument(n + 5)) != TypePtr::NULL_PTR;\n@@ -453,1 +453,1 @@\n-    assert(!use_mask, \"mask operations do not need mask to control\");\n+    assert(!is_masked_op, \"mask operations do not need mask to control\");\n@@ -456,1 +456,1 @@\n-  if (use_mask && !is_klass_initialized(mask_klass)) {\n+  if (is_masked_op && !is_klass_initialized(mask_klass)) {\n@@ -487,1 +487,1 @@\n-                                      : use_mask ? VecMaskUseLoad : VecMaskNotUsed;\n+                                      : is_masked_op ? VecMaskUseLoad : VecMaskNotUsed;\n@@ -536,1 +536,2 @@\n-  if (use_mask) {\n+  bool use_predicate = false;\n+  if (is_masked_op) {\n@@ -542,5 +543,3 @@\n-        if (C->print_intrinsics()) {\n-          tty->print_cr(\"  ** unbox failed mask=%s\",\n-                        NodeClassNames[argument(n + 5)->Opcode()]);\n-        }\n-        return false;\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                      NodeClassNames[argument(n + 5)->Opcode()]);\n@@ -548,0 +547,8 @@\n+      return false;\n+    }\n+\n+    \/\/ Return true if current platform has implemented the masked operation with predicate feature.\n+    use_predicate = sopc != 0 && Matcher::match_rule_supported_masked_vector(sopc, num_elem, elem_bt);\n+    if (!use_predicate && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+      return false;\n+    }\n@@ -576,8 +583,3 @@\n-  \/\/ Currently just focus on binary mask operation.\n-  if (n == 2 && mask != NULL) {\n-    if (sopc != 0 &&\n-        Matcher::match_rule_supported_masked_vector(sopc, num_elem, elem_bt) &&\n-        Matcher::match_rule_supported(Op_VectorToMask)) {\n-      const TypeVMask* vmask_type = TypeVMask::make(elem_bt, num_elem);\n-      mask = gvn().transform(new VectorToMaskNode(mask, vmask_type));\n-      operation->add_req(mask);\n+  if (is_masked_op && mask != NULL) {\n+    if (use_predicate) {\n+      \/\/ TODO: add predicate implementation for masked operation.\n@@ -585,2 +587,1 @@\n-      \/\/ TODO: arch match rule support check for \"Op_VectorBlend\"\n-      operation = VectorBlendNode::make(gvn(), opd1, operation, mask);\n+      operation = new VectorBlendNode(opd1, operation, mask);\n@@ -588,2 +589,0 @@\n-  } else {\n-    assert(mask == NULL, \"unsupported mask operation\");\n@@ -685,1 +684,1 @@\n-    res = gvn().transform(VectorBlendNode::make(gvn(), biased_val, res, mask));\n+    res = gvn().transform(new VectorBlendNode(biased_val, res, mask));\n@@ -806,37 +805,0 @@\n-  Node* node = NULL;\n-  const TypeLong* value = gvn().type(bits)->is_long();\n-  if (is_vector_mask(vbox_klass) &&\n-     value->is_con() && (value->get_con() == -1 || value->get_con() == 0) &&\n-     arch_supports_vector(Op_MaskAll, num_elem, elem_bt, VecMaskNotUsed)) {\n-     ConLNode* con = (ConLNode*)gvn().makecon(value);\n-     node = gvn().transform(new MaskAllNode(con, TypeVMask::make(elem_bt, num_elem)));\n-     \/\/ TODO: remove the conversion once reboxing for predicate is supported.\n-     node = gvn().transform(new MaskToVectorNode(node, TypeVect::make(elem_bt, num_elem)));\n-  }\n-\n-  if (node == NULL) {\n-    Node* elem = NULL;\n-    switch (elem_bt) {\n-      case T_BOOLEAN: \/\/ fall-through\n-      case T_BYTE:    \/\/ fall-through\n-      case T_SHORT:   \/\/ fall-through\n-      case T_CHAR:    \/\/ fall-through\n-      case T_INT: {\n-        elem = gvn().transform(new ConvL2INode(bits));\n-        break;\n-      }\n-      case T_DOUBLE: {\n-        elem = gvn().transform(new MoveL2DNode(bits));\n-        break;\n-      }\n-      case T_FLOAT: {\n-        bits = gvn().transform(new ConvL2INode(bits));\n-        elem = gvn().transform(new MoveI2FNode(bits));\n-        break;\n-      }\n-      case T_LONG: {\n-        elem = bits; \/\/ no conversion needed\n-        break;\n-      }\n-      default: fatal(\"%s\", type2name(elem_bt));\n-    }\n@@ -844,2 +806,24 @@\n-    node = VectorNode::scalar2vector(elem, num_elem, Type::get_const_basic_type(elem_bt));\n-    node = gvn().transform(node);\n+  Node* elem = NULL;\n+  switch (elem_bt) {\n+    case T_BOOLEAN: \/\/ fall-through\n+    case T_BYTE:    \/\/ fall-through\n+    case T_SHORT:   \/\/ fall-through\n+    case T_CHAR:    \/\/ fall-through\n+    case T_INT: {\n+      elem = gvn().transform(new ConvL2INode(bits));\n+      break;\n+    }\n+    case T_DOUBLE: {\n+      elem = gvn().transform(new MoveL2DNode(bits));\n+      break;\n+    }\n+    case T_FLOAT: {\n+      bits = gvn().transform(new ConvL2INode(bits));\n+      elem = gvn().transform(new MoveI2FNode(bits));\n+      break;\n+    }\n+    case T_LONG: {\n+      elem = bits; \/\/ no conversion needed\n+      break;\n+    }\n+    default: fatal(\"%s\", type2name(elem_bt));\n@@ -848,1 +832,4 @@\n-  Node* box = box_vector(node, vbox_type, elem_bt, num_elem);\n+  Node* broadcast = VectorNode::scalar2vector(elem, num_elem, Type::get_const_basic_type(elem_bt));\n+  broadcast = gvn().transform(broadcast);\n+\n+  Node* box = box_vector(broadcast, vbox_type, elem_bt, num_elem);\n@@ -1147,5 +1134,0 @@\n-    if (Matcher::match_rule_supported(Op_VectorToMask)) {\n-      const TypeVMask* vmask_type = TypeVMask::make(elem_bt, num_elem);\n-      mask = gvn().transform(new VectorToMaskNode(mask, vmask_type));\n-    }\n-\n@@ -1157,1 +1139,1 @@\n-    assert(is_store, \"unimplemented load mask\");\n+    assert(false, \"unimplemented masked memory operation\");\n@@ -1512,1 +1494,1 @@\n-  Node* blend = gvn().transform(VectorBlendNode::make(gvn(), v1, v2, mask));\n+  Node* blend = gvn().transform(new VectorBlendNode(v1, v2, mask));\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":52,"deletions":70,"binary":false,"changes":122,"status":"modified"},{"patch":"@@ -723,17 +723,0 @@\n-Node* StoreVectorNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n-  \/\/ StoreVectorNode (VectorStoreMask src)  ==>  (StoreVectorMask src).\n-  Node* value = in(MemNode::ValueIn);\n-  if (value->Opcode() == Op_VectorStoreMask) {\n-    assert(this->vect_type()->element_basic_type() == T_BOOLEAN, \"Invalid basic type to store mask\");\n-    if (Matcher::match_rule_supported(Op_StoreVectorMask)) {\n-      const TypeVect* type = value->in(1)->bottom_type()->is_vect();\n-      const TypeVect* mem_type = TypeVect::make(T_BOOLEAN, type->length());\n-      return new StoreVectorMaskNode(in(MemNode::Control),\n-                                     in(MemNode::Memory),\n-                                     in(MemNode::Address),\n-                                     adr_type(), value->in(1), mem_type);\n-    }\n-  }\n-  return StoreNode::Ideal(phase, can_reshape);\n-}\n-\n@@ -784,17 +767,0 @@\n-Node* VectorToMaskNode::Identity(PhaseGVN* phase) {\n-  \/\/ VectorToMask (MaskToVector mask)  ==>  mask\n-  if (in(1)->Opcode() == Op_MaskToVector) {\n-    return in(1)->in(1);\n-  }\n-  return this;\n-}\n-\n-VectorBlendNode* VectorBlendNode::make(PhaseGVN& gvn, Node* vec1, Node* vec2, Node* mask) {\n-  if (Matcher::match_rule_supported(Op_VectorToMask) && !mask->is_VectorMask()) {\n-    const TypeVect* vtype = mask->bottom_type()->is_vect();\n-    const TypeVMask* vmask_type = TypeVMask::make(vtype->element_basic_type(), vtype->length());\n-    mask = gvn.transform(new VectorToMaskNode(mask, vmask_type));\n-  }\n-  return new VectorBlendNode(vec1, vec2, mask);\n-}\n-\n@@ -1017,15 +983,0 @@\n-Node* VectorLoadMaskNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n-  \/\/ VectorLoadMask (LoadVector src)  ==>  (LoadVectorMask src).\n-  LoadVectorNode* load = this->in(1)->isa_LoadVector();\n-  BasicType out_bt = type()->is_vect()->element_basic_type();\n-  if (load != NULL && Matcher::match_rule_supported(Op_LoadVectorMask)) {\n-    const TypeVect* mem_type = TypeVect::make(T_BOOLEAN, length());\n-    const TypeVect* type = TypeVect::make(out_bt, length());\n-    return new LoadVectorMaskNode(load->in(MemNode::Control),\n-                                  load->in(MemNode::Memory),\n-                                  load->in(MemNode::Address),\n-                                  load->adr_type(), type, mem_type);\n-  }\n-  return NULL;\n-}\n-\n@@ -1250,13 +1201,0 @@\n-Node* VectorMaskCmpNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n-  \/\/ Generate the mask specific compare node if backend supported.\n-  \/\/ (VectorMaskCmp src1 src2 cond)  ==> MaskToVector (VectorCmpMaskGen src1 src2 cond)\n-  if (Matcher::match_rule_supported(Op_VectorCmpMaskGen) &&\n-      Matcher::match_rule_supported(Op_MaskToVector)) {\n-    const TypeVect* vtype = vect_type();\n-    const TypeVMask* vmask_type = TypeVMask::make(vtype->element_basic_type(), vtype->length());\n-    Node* cmp = phase->transform(new VectorCmpMaskGenNode(in(1), in(2), (ConINode*) in(3), vmask_type));\n-    return new MaskToVectorNode(cmp, vtype);\n-  }\n-  return NULL;\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":0,"deletions":62,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -761,1 +761,0 @@\n-  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -788,1 +787,2 @@\n-    assert(mask->bottom_type()->isa_long() != NULL || mask->is_Vector() || mask->is_VectorMask(), \"sanity\");\n+    \/\/ TDOO: Use mask type as the assertion\n+    \/\/ assert(mask->bottom_type()->is_long(), \"sanity\");\n@@ -835,116 +835,0 @@\n-\/\/ ==========================Mask feature specific==============================\n-\n-class LoadVectorMaskNode : public LoadVectorNode {\n- private:\n-  \/**\n-   * The type of the accessed memory, whose basic element type is T_BOOLEAN for mask vector.\n-   * It is different with the basic element type of the node, which can be T_BYTE, T_SHORT,\n-   * T_INT, T_LONG, T_FLOAT or T_DOUBLE.\n-   **\/\n-  const TypeVect* _mem_type;\n-\n- public:\n-  LoadVectorMaskNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt, const TypeVect* mt)\n-   : LoadVectorNode(c, mem, adr, at, vt), _mem_type(mt) {\n-    assert(_mem_type->element_basic_type() == T_BOOLEAN, \"Memory type must be T_BOOLEAN\");\n-    init_class_id(Class_LoadVector);\n-  }\n-\n-  virtual int Opcode() const;\n-  virtual int memory_size() const { return _mem_type->length_in_bytes(); }\n-  virtual int store_Opcode() const { return Op_StoreVectorMask; }\n-  virtual uint ideal_reg() const  { return Matcher::vector_ideal_reg(vect_type()->length_in_bytes()); }\n-  virtual uint size_of() const { return sizeof(LoadVectorMaskNode); }\n-};\n-\n-class StoreVectorMaskNode : public StoreVectorNode {\n- private:\n-  \/**\n-   * The type of the accessed memory, whose basic element type is T_BOOLEAN for mask vector.\n-   * It is different with the basic element type of the src value, which can be T_BYTE, T_SHORT,\n-   * T_INT, T_LONG, T_FLOAT or T_DOUBLE.\n-   **\/\n-  const TypeVect* _mem_type;\n-\n- public:\n-  StoreVectorMaskNode(Node* c, Node* mem, Node* adr, const TypePtr* at, Node* src, const TypeVect* mt)\n-   : StoreVectorNode(c, mem, adr, at, src), _mem_type(mt) {\n-    assert(_mem_type->element_basic_type() == T_BOOLEAN, \"Memory type must be T_BOOLEAN\");\n-    init_class_id(Class_StoreVector);\n-  }\n-\n-  virtual int Opcode() const;\n-  virtual int memory_size() const { return _mem_type->length_in_bytes(); }\n-  virtual uint ideal_reg() const  { return Matcher::vector_ideal_reg(vect_type()->length_in_bytes()); }\n-  virtual uint size_of() const { return sizeof(StoreVectorMaskNode); }\n-};\n-\n-class VectorMaskNode : public TypeNode {\n- public:\n-  VectorMaskNode(Node* in1, const TypeVMask* vmask_type) :\n-    TypeNode(vmask_type, 2) {\n-    init_class_id(Class_VectorMask);\n-    init_req(1, in1);\n-  }\n-\n-  VectorMaskNode(Node* in1, Node* in2, Node* in3, const TypeVMask* vmask_type) :\n-    TypeNode(vmask_type, 4) {\n-    init_class_id(Class_VectorMask);\n-    init_req(1, in1);\n-    init_req(2, in2);\n-    init_req(3, in3);\n-  }\n-\n-  virtual int Opcode() const;\n-};\n-\n-class VectorToMaskNode : public VectorMaskNode {\n- public:\n-  VectorToMaskNode(Node* in, const TypeVMask* vmask_type) : VectorMaskNode(in, vmask_type) {\n-    assert(in->bottom_type()->is_vect()->length_in_bytes() ==\n-           vmask_type->length() * vmask_type->element_size_in_bytes(), \"wrong type\");\n-  }\n-\n-  virtual int Opcode() const;\n-  virtual Node* Identity(PhaseGVN* phase);\n-};\n-\n-class MaskAllNode : public VectorMaskNode {\n- public:\n-  MaskAllNode(ConLNode* in, const TypeVMask* vmask_type) : VectorMaskNode(in, vmask_type) {\n-    assert(in->get_long() == 0 || in->get_long() == -1, \"Unsupported value to mask all\");\n-  }\n-\n-  virtual int Opcode() const;\n-};\n-\n-\/\/ Vector compare node with a TypeVMask bottom_type. It is specially generated for platforms\n-\/\/ that have mask hardware feature. The main difference with \"VectorMaskCmpNode\" is that this\n-\/\/ is a kind of mask node, while \"VectorMaskCmpNode\" is a vector node.\n-class VectorCmpMaskGenNode : public VectorMaskNode {\n- public:\n-  VectorCmpMaskGenNode(Node* in1, Node* in2, ConINode* predicate_node, const TypeVMask* vmask_type) :\n-    VectorMaskNode(in1, in2, predicate_node, vmask_type) {\n-    assert(in1->bottom_type()->is_vect()->element_basic_type() == in2->bottom_type()->is_vect()->element_basic_type(),\n-           \"VectorCmpMaskGen inputs must have the same type for elements\");\n-    assert(in1->bottom_type()->is_vect()->length() == in2->bottom_type()->is_vect()->length(),\n-           \"VectorCmpMaskGen inputs must have the same number of elements\");\n-    assert(in1->bottom_type()->is_vect()->length_in_bytes() ==\n-           vmask_type->length() * vmask_type->element_size_in_bytes(), \"wrong type\");\n-  }\n-\n-  virtual int Opcode() const;\n-};\n-\n-class MaskToVectorNode : public VectorNode {\n- public:\n-  MaskToVectorNode(Node* mask, const TypeVect* vt) : VectorNode(mask, vt) {\n-    assert(mask->is_VectorMask(), \"input must be a VectorMask\");\n-    const TypeVMask* vmask_type = mask->as_VectorMask()->bottom_type()->is_vmask();\n-    assert(vmask_type->length() * vmask_type->element_size_in_bytes() ==\n-           vt->length_in_bytes(), \"wrong type\");\n-  }\n-\n-  virtual int Opcode() const;\n-};\n-\n@@ -1242,1 +1126,0 @@\n-  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -1284,1 +1167,1 @@\n- protected:\n+ public:\n@@ -1287,3 +1170,1 @@\n-    if (Matcher::match_rule_supported(Op_VectorToMask)) {\n-      assert(mask->is_VectorMask(), \"VectorBlendNode requires that third argument be a mask\");\n-    }\n+    \/\/ assert(mask->is_VectorMask(), \"VectorBlendNode requires that third argument be a mask\");\n@@ -1292,2 +1173,0 @@\n- public:\n-  static VectorBlendNode* make(PhaseGVN& gvn, Node* vec1, Node* vec2, Node* mask);\n@@ -1330,1 +1209,0 @@\n-  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":4,"deletions":126,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -1868,2 +1868,0 @@\n-  declare_c2_type(LoadVectorMaskNode, LoadVectorNode)                     \\\n-  declare_c2_type(StoreVectorMaskNode, StoreVectorNode)                   \\\n@@ -1887,1 +1885,0 @@\n-  declare_c2_type(MaskToVectorNode, VectorNode)                           \\\n@@ -1891,4 +1888,0 @@\n-  declare_c2_type(VectorMaskNode, TypeNode)                               \\\n-  declare_c2_type(VectorCmpMaskGenNode, VectorMaskNode)                   \\\n-  declare_c2_type(VectorToMaskNode, VectorMaskNode)                       \\\n-  declare_c2_type(MaskAllNode, VectorMaskNode)                            \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":7,"binary":false,"changes":7,"status":"modified"}]}