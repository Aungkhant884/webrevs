{"files":[{"patch":"@@ -812,8 +812,4 @@\n-  do_intrinsic(_VectorUnaryOp, jdk_internal_vm_vector_VectorSupport, vector_unary_op_name, vector_unary_op_sig, F_S)                           \\\n-   do_signature(vector_unary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/util\/function\/Function;)Ljava\/lang\/Object;\") \\\n-   do_name(vector_unary_op_name,     \"unaryOp\")                                                                                                \\\n-                                                                                                                                               \\\n-  do_intrinsic(_VectorBinaryOp, jdk_internal_vm_vector_VectorSupport, vector_binary_op_name, vector_binary_op_sig, F_S)                        \\\n-   do_signature(vector_binary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                              \\\n-                                       \"Ljava\/util\/function\/BiFunction;)Ljava\/lang\/Object;\")                                                   \\\n-   do_name(vector_binary_op_name,     \"binaryOp\")                                                                                              \\\n+  do_intrinsic(_VectorUnaryMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_unary_masked_op_name, vector_unary_masked_op_sig, F_S)       \\\n+   do_signature(vector_unary_masked_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"       \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$UnaryMaskedOperation;)Ljava\/lang\/Object;\")                 \\\n+   do_name(vector_unary_masked_op_name,     \"unaryMaskedOp\")                                                                                   \\\n@@ -823,1 +819,1 @@\n-                                            \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$BinaryMaskedOperation;)Ljava\/lang\/Object;\") \\\n+                                              \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$BinaryMaskedOperation;)Ljava\/lang\/Object;\") \\\n@@ -826,4 +822,4 @@\n-  do_intrinsic(_VectorTernaryOp, jdk_internal_vm_vector_VectorSupport, vector_ternary_op_name, vector_ternary_op_sig, F_S)                     \\\n-   do_signature(vector_ternary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                             \\\n-                                        \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryOperation;)Ljava\/lang\/Object;\")        \\\n-   do_name(vector_ternary_op_name,     \"ternaryOp\")                                                                                            \\\n+  do_intrinsic(_VectorTernaryMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_ternary_masked_op_name, vector_ternary_masked_op_sig, F_S) \\\n+   do_signature(vector_ternary_masked_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;\" \\\n+                                               \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryMaskedOperation;)Ljava\/lang\/Object;\") \\\n+   do_name(vector_ternary_masked_op_name,     \"ternaryMaskedOp\")                                                                               \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":9,"deletions":13,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -660,3 +660,1 @@\n-  case vmIntrinsics::_VectorUnaryOp:\n-  case vmIntrinsics::_VectorBinaryOp:\n-  case vmIntrinsics::_VectorTernaryOp:\n+  case vmIntrinsics::_VectorUnaryMaskedOp:\n@@ -664,0 +662,1 @@\n+  case vmIntrinsics::_VectorTernaryMaskedOp:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -630,6 +630,2 @@\n-  case vmIntrinsics::_VectorUnaryOp:\n-    return inline_vector_nary_operation(1);\n-  case vmIntrinsics::_VectorBinaryOp:\n-    return inline_vector_nary_operation(2);\n-  case vmIntrinsics::_VectorTernaryOp:\n-    return inline_vector_nary_operation(3);\n+  case vmIntrinsics::_VectorUnaryMaskedOp:\n+    return inline_vector_nary_masked_operation(1);\n@@ -638,0 +634,2 @@\n+  case vmIntrinsics::_VectorTernaryMaskedOp:\n+    return inline_vector_nary_masked_operation(3);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -312,1 +312,0 @@\n-  bool inline_vector_nary_operation(int n);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -207,10 +207,4 @@\n-\/\/ <VM>\n-\/\/ VM unaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/            VM vm,\n-\/\/            Function<VM, VM> defaultImpl) {\n-\/\/\n-\/\/ public static\n-\/\/ <VM>\n-\/\/ VM binaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/             VM vm1, VM vm2,\n-\/\/             BiFunction<VM, VM, VM> defaultImpl) {\n+\/\/ <V, M>\n+\/\/ V unaryMaskedOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<?> elementType,\n+\/\/                 int length, V v, M m,\n+\/\/                 UnaryMaskedOperation<V, M> defaultImpl) {\n@@ -218,161 +212,0 @@\n-\/\/ public static\n-\/\/ <VM>\n-\/\/ VM ternaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/              VM vm1, VM vm2, VM vm3,\n-\/\/              TernaryOperation<VM> defaultImpl) {\n-\/\/\n-bool LibraryCallKit::inline_vector_nary_operation(int n) {\n-  const TypeInt*     opr          = gvn().type(argument(0))->isa_int();\n-  const TypeInstPtr* vector_klass = gvn().type(argument(1))->isa_instptr();\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n-\n-  if (opr == NULL || vector_klass == NULL || elem_klass == NULL || vlen == NULL ||\n-      !opr->is_con() || vector_klass->const_oop() == NULL || elem_klass->const_oop() == NULL || !vlen->is_con()) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** missing constant: opr=%s vclass=%s etype=%s vlen=%s\",\n-                    NodeClassNames[argument(0)->Opcode()],\n-                    NodeClassNames[argument(1)->Opcode()],\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n-    }\n-    return false; \/\/ not enough info for intrinsification\n-  }\n-  ciType* elem_type = elem_klass->const_oop()->as_instance()->java_mirror_type();\n-  if (!elem_type->is_primitive_type()) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not a primitive bt=%d\", elem_type->basic_type());\n-    }\n-    return false; \/\/ should be primitive type\n-  }\n-  if (!is_klass_initialized(vector_klass)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** klass argument not initialized\");\n-    }\n-    return false;\n-  }\n-  BasicType elem_bt = elem_type->basic_type();\n-  int num_elem = vlen->get_con();\n-  int opc = VectorSupport::vop2ideal(opr->get_con(), elem_bt);\n-  int sopc = VectorNode::opcode(opc, elem_bt);\n-  if ((opc != Op_CallLeafVector) && (sopc == 0)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** operation not supported: opc=%s bt=%s\", NodeClassNames[opc], type2name(elem_bt));\n-    }\n-    return false; \/\/ operation not supported\n-  }\n-  if (num_elem == 1) {\n-    if (opc != Op_CallLeafVector || elem_bt != T_DOUBLE) {\n-      if (C->print_intrinsics()) {\n-        tty->print_cr(\"  ** not a svml call: arity=%d opc=%d vlen=%d etype=%s\",\n-                      n, opc, num_elem, type2name(elem_bt));\n-      }\n-      return false;\n-    }\n-  }\n-  ciKlass* vbox_klass = vector_klass->const_oop()->as_instance()->java_lang_Class_klass();\n-  const TypeInstPtr* vbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, vbox_klass);\n-\n-  if (opc == Op_CallLeafVector) {\n-    if (!UseVectorStubs) {\n-      if (C->print_intrinsics()) {\n-        tty->print_cr(\"  ** vector stubs support is disabled\");\n-      }\n-      return false;\n-    }\n-    if (!Matcher::supports_vector_calling_convention()) {\n-      if (C->print_intrinsics()) {\n-        tty->print_cr(\"  ** no vector calling conventions supported\");\n-      }\n-      return false;\n-    }\n-    if (!Matcher::vector_size_supported(elem_bt, num_elem)) {\n-      if (C->print_intrinsics()) {\n-        tty->print_cr(\"  ** vector size (vlen=%d, etype=%s) is not supported\",\n-                      num_elem, type2name(elem_bt));\n-      }\n-      return false;\n-    }\n-  }\n-\n-  \/\/ TODO When mask usage is supported, VecMaskNotUsed needs to be VecMaskUseLoad.\n-  if ((sopc != 0) &&\n-      !arch_supports_vector(sopc, num_elem, elem_bt, is_vector_mask(vbox_klass) ? VecMaskUseAll : VecMaskNotUsed)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=%d\",\n-                    n, sopc, num_elem, type2name(elem_bt),\n-                    is_vector_mask(vbox_klass) ? 1 : 0);\n-    }\n-    return false; \/\/ not supported\n-  }\n-\n-  Node* opd1 = NULL; Node* opd2 = NULL; Node* opd3 = NULL;\n-  switch (n) {\n-    case 3: {\n-      opd3 = unbox_vector(argument(6), vbox_type, elem_bt, num_elem);\n-      if (opd3 == NULL) {\n-        if (C->print_intrinsics()) {\n-          tty->print_cr(\"  ** unbox failed v3=%s\",\n-                        NodeClassNames[argument(6)->Opcode()]);\n-        }\n-        return false;\n-      }\n-      \/\/ fall-through\n-    }\n-    case 2: {\n-      opd2 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n-      if (opd2 == NULL) {\n-        if (C->print_intrinsics()) {\n-          tty->print_cr(\"  ** unbox failed v2=%s\",\n-                        NodeClassNames[argument(5)->Opcode()]);\n-        }\n-        return false;\n-      }\n-      \/\/ fall-through\n-    }\n-    case 1: {\n-      opd1 = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n-      if (opd1 == NULL) {\n-        if (C->print_intrinsics()) {\n-          tty->print_cr(\"  ** unbox failed v1=%s\",\n-                        NodeClassNames[argument(4)->Opcode()]);\n-        }\n-        return false;\n-      }\n-      break;\n-    }\n-    default: fatal(\"unsupported arity: %d\", n);\n-  }\n-\n-  Node* operation = NULL;\n-  if (opc == Op_CallLeafVector) {\n-    assert(UseVectorStubs, \"sanity\");\n-    operation = gen_call_to_svml(opr->get_con(), elem_bt, num_elem, opd1, opd2);\n-    if (operation == NULL) {\n-      if (C->print_intrinsics()) {\n-        tty->print_cr(\"  ** svml call failed\");\n-      }\n-      return false;\n-     }\n-  } else {\n-    const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n-    switch (n) {\n-      case 1:\n-      case 2: {\n-        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, vt));\n-        break;\n-      }\n-      case 3: {\n-        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, opd3, vt));\n-        break;\n-      }\n-      default: fatal(\"unsupported arity: %d\", n);\n-    }\n-  }\n-  \/\/ Wrap it up in VectorBox to keep object type information.\n-  Node* vbox = box_vector(operation, vbox_type, elem_bt, num_elem);\n-  set_result(vbox);\n-  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n-  return true;\n-}\n-\n@@ -385,11 +218,0 @@\n-\/\/ TODO: add the mask support for unary\/ternay mask op. After then, the original intrinsics and above method\n-\/\/ \"LibraryCallKit::inline_vector_nary_operation\" could be removed.\n-\/\/\n-\/\/ The prototype intrinsics might be:\n-\/\/\n-\/\/ public static\n-\/\/ <V, M>\n-\/\/ V unaryMaskedOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<?> elementType,\n-\/\/                 int length, V v, M m,\n-\/\/                 UnaryMaskedOperation<V, M> defaultImpl) {\n-\/\/\n@@ -472,0 +294,9 @@\n+  if (num_elem == 1) {\n+    if (opc != Op_CallLeafVector || elem_bt != T_DOUBLE) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not a svml call: arity=%d opc=%d vlen=%d etype=%s\",\n+                      n, opc, num_elem, type2name(elem_bt));\n+      }\n+      return false;\n+    }\n+  }\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":13,"deletions":182,"binary":false,"changes":195,"status":"modified"},{"patch":"@@ -249,4 +249,4 @@\n-    <VM>\n-    VM unaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-               VM vm,\n-               Function<VM, VM> defaultImpl) {\n+    <V, M>\n+    V unaryMaskedOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass,\n+                    Class<?> elementType, int length, V v, M m,\n+                    UnaryMaskedOperation<V, M> defaultImpl) {\n@@ -254,1 +254,1 @@\n-        return defaultImpl.apply(vm);\n+        return defaultImpl.apply(v, m);\n@@ -257,10 +257,2 @@\n-    \/* ============================================================================ *\/\n-\n-    @IntrinsicCandidate\n-    public static\n-    <VM>\n-    VM binaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-                VM vm1, VM vm2,\n-                BiFunction<VM, VM, VM> defaultImpl) {\n-        assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n-        return defaultImpl.apply(vm1, vm2);\n+    public interface UnaryMaskedOperation<V, M> {\n+        V apply(V v, M mask);\n@@ -269,0 +261,2 @@\n+    \/* ============================================================================ *\/\n+\n@@ -285,4 +279,0 @@\n-    public interface TernaryOperation<V> {\n-        V apply(V v1, V v2, V v3);\n-    }\n-\n@@ -291,4 +281,4 @@\n-    <VM>\n-    VM ternaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-                 VM vm1, VM vm2, VM vm3,\n-                 TernaryOperation<VM> defaultImpl) {\n+    <V, M>\n+    V ternaryMaskedOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass,\n+                      Class<?> elementType, int length, V v1, V v2, V v3, M m,\n+                      TernaryMaskedOperation<V, M> defaultImpl) {\n@@ -296,1 +286,5 @@\n-        return defaultImpl.apply(vm1, vm2, vm3);\n+        return defaultImpl.apply(v1, v2, v3, m);\n+    }\n+\n+    public interface TernaryMaskedOperation<V, M> {\n+        V apply(V v1, V v2, V v3, M mask);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":18,"deletions":24,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte128Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte128Vector) super.lanewiseTemplate(op, Byte128Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte128Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte128Vector) super.lanewiseTemplate(op, Byte128Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -664,3 +678,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte128Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Byte128Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -674,3 +688,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte128Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Byte128Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -684,3 +698,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte128Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Byte128Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte128Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte256Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte256Vector) super.lanewiseTemplate(op, Byte256Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte256Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte256Vector) super.lanewiseTemplate(op, Byte256Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -696,3 +710,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte256Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Byte256Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -706,3 +720,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte256Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Byte256Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -716,3 +730,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte256Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Byte256Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte256Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte512Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte512Vector) super.lanewiseTemplate(op, Byte512Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte512Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte512Vector) super.lanewiseTemplate(op, Byte512Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -760,3 +774,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte512Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Byte512Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -770,3 +784,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte512Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Byte512Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -780,3 +794,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte512Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Byte512Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte512Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte64Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte64Vector) super.lanewiseTemplate(op, Byte64Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte64Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte64Vector) super.lanewiseTemplate(op, Byte64Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -648,3 +662,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte64Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Byte64Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -658,3 +672,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte64Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Byte64Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -668,3 +682,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte64Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Byte64Mask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte64Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public ByteMaxVector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (ByteMaxVector) super.lanewiseTemplate(op, ByteMaxMask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    ByteMaxVector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (ByteMaxVector) super.lanewiseTemplate(op, ByteMaxMask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -634,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, ByteMaxMask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, ByteMaxMask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, ByteMaxMask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, ByteMaxMask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -654,3 +668,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, ByteMaxMask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, ByteMaxMask.class, null, byte.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteMaxVector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -269,0 +272,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -562,11 +568,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), byte.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (byte) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (byte) Math.abs(a));\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, byte.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, ByteVector::unaryOperations));\n@@ -574,3 +573,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<ByteVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, ByteVector.class);\n@@ -581,2 +577,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -584,2 +580,34 @@\n-                                  VectorMask<Byte> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    ByteVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Byte>> maskClass,\n+                                          VectorMask<Byte> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, ByteVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<ByteVector, VectorMask<Byte>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, ByteVector.class);\n+\n+    private static UnaryMaskedOperation<ByteVector, VectorMask<Byte>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (byte) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (byte) Math.abs(a));\n+            default: return null;\n+        }\n@@ -936,7 +964,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), byte.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, byte.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, ByteVector::ternaryOperations));\n@@ -944,3 +969,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<ByteVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, ByteVector.class);\n@@ -954,2 +976,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -959,2 +981,37 @@\n-                                  VectorMask<Byte> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    ByteVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Byte>> maskClass,\n+                                          Vector<Byte> v1,\n+                                          Vector<Byte> v2,\n+                                          VectorMask<Byte> m) {\n+        ByteVector that = (ByteVector) v1;\n+        ByteVector tother = (ByteVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, ByteVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<ByteVector, VectorMask<Byte>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, ByteVector.class);\n+\n+    private static TernaryMaskedOperation<ByteVector, VectorMask<Byte>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -1017,1 +1074,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1075,1 +1132,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1132,1 +1189,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":92,"deletions":35,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double128Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double128Vector) super.lanewiseTemplate(op, Double128Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double128Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double128Vector) super.lanewiseTemplate(op, Double128Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -632,3 +646,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Double128Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -642,3 +656,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Double128Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -652,3 +666,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double128Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Double128Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double128Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double256Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double256Vector) super.lanewiseTemplate(op, Double256Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double256Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double256Vector) super.lanewiseTemplate(op, Double256Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -636,3 +650,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Double256Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -646,3 +660,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Double256Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -656,3 +670,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double256Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Double256Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double256Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double512Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double512Vector) super.lanewiseTemplate(op, Double512Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double512Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double512Vector) super.lanewiseTemplate(op, Double512Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Double512Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -654,3 +668,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Double512Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -664,3 +678,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double512Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Double512Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double512Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double64Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double64Vector) super.lanewiseTemplate(op, Double64Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double64Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double64Vector) super.lanewiseTemplate(op, Double64Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -630,3 +644,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Double64Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -640,3 +654,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Double64Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -650,3 +664,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double64Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Double64Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double64Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public DoubleMaxVector lanewise(Unary op, VectorMask<Double> m) {\n+        return (DoubleMaxVector) super.lanewiseTemplate(op, DoubleMaxMask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    DoubleMaxVector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (DoubleMaxVector) super.lanewiseTemplate(op, DoubleMaxMask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -629,3 +643,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, DoubleMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, DoubleMaxMask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -639,3 +653,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, DoubleMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, DoubleMaxMask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -649,3 +663,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, DoubleMaxMask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, DoubleMaxMask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleMaxVector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -269,0 +272,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -556,43 +562,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), double.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (double) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.abs(a));\n-                case VECTOR_OP_SIN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.sin(a));\n-                case VECTOR_OP_COS: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.cos(a));\n-                case VECTOR_OP_TAN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.tan(a));\n-                case VECTOR_OP_ASIN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.asin(a));\n-                case VECTOR_OP_ACOS: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.acos(a));\n-                case VECTOR_OP_ATAN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.atan(a));\n-                case VECTOR_OP_EXP: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.exp(a));\n-                case VECTOR_OP_LOG: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.log(a));\n-                case VECTOR_OP_LOG10: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.log10(a));\n-                case VECTOR_OP_SQRT: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.sqrt(a));\n-                case VECTOR_OP_CBRT: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.cbrt(a));\n-                case VECTOR_OP_SINH: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.sinh(a));\n-                case VECTOR_OP_COSH: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.cosh(a));\n-                case VECTOR_OP_TANH: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.tanh(a));\n-                case VECTOR_OP_EXPM1: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.expm1(a));\n-                case VECTOR_OP_LOG1P: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.log1p(a));\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, double.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, DoubleVector::unaryOperations));\n@@ -600,3 +567,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<DoubleVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, DoubleVector.class);\n@@ -607,2 +571,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -610,2 +574,63 @@\n-                                  VectorMask<Double> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    DoubleVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Double>> maskClass,\n+                                          VectorMask<Double> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, DoubleVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<DoubleVector, VectorMask<Double>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, DoubleVector.class);\n+\n+    private static UnaryMaskedOperation<DoubleVector, VectorMask<Double>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.abs(a));\n+            case VECTOR_OP_SIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.sin(a));\n+            case VECTOR_OP_COS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.cos(a));\n+            case VECTOR_OP_TAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.tan(a));\n+            case VECTOR_OP_ASIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.asin(a));\n+            case VECTOR_OP_ACOS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.acos(a));\n+            case VECTOR_OP_ATAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.atan(a));\n+            case VECTOR_OP_EXP: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.exp(a));\n+            case VECTOR_OP_LOG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.log(a));\n+            case VECTOR_OP_LOG10: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.log10(a));\n+            case VECTOR_OP_SQRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.sqrt(a));\n+            case VECTOR_OP_CBRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.cbrt(a));\n+            case VECTOR_OP_SINH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.sinh(a));\n+            case VECTOR_OP_COSH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.cosh(a));\n+            case VECTOR_OP_TANH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.tanh(a));\n+            case VECTOR_OP_EXPM1: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.expm1(a));\n+            case VECTOR_OP_LOG1P: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.log1p(a));\n+            default: return null;\n+        }\n@@ -853,9 +878,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), double.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_FMA: return (v0, v1_, v2_) ->\n-                        v0.tOp(v1_, v2_, (i, a, b, c) -> Math.fma(a, b, c));\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, double.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, DoubleVector::ternaryOperations));\n@@ -863,3 +883,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<DoubleVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, DoubleVector.class);\n@@ -873,2 +890,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -878,2 +895,34 @@\n-                                  VectorMask<Double> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    DoubleVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Double>> maskClass,\n+                                          Vector<Double> v1,\n+                                          Vector<Double> v2,\n+                                          VectorMask<Double> m) {\n+        DoubleVector that = (DoubleVector) v1;\n+        DoubleVector tother = (DoubleVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, DoubleVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<DoubleVector, VectorMask<Double>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, DoubleVector.class);\n+\n+    private static TernaryMaskedOperation<DoubleVector, VectorMask<Double>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_FMA: return (v0, v1_, v2_, m) ->\n+                    v0.tOp(v1_, v2_, m, (i, a, b, c) -> Math.fma(a, b, c));\n+            default: return null;\n+        }\n@@ -936,1 +985,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -994,1 +1043,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1051,1 +1100,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":118,"deletions":69,"binary":false,"changes":187,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float128Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float128Vector) super.lanewiseTemplate(op, Float128Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float128Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float128Vector) super.lanewiseTemplate(op, Float128Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -636,3 +650,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Float128Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -646,3 +660,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Float128Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -656,3 +670,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float128Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Float128Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float128Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float256Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float256Vector) super.lanewiseTemplate(op, Float256Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float256Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float256Vector) super.lanewiseTemplate(op, Float256Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Float256Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -654,3 +668,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Float256Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -664,3 +678,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float256Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Float256Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float256Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float512Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float512Vector) super.lanewiseTemplate(op, Float512Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float512Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float512Vector) super.lanewiseTemplate(op, Float512Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -660,3 +674,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Float512Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -670,3 +684,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Float512Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -680,3 +694,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float512Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Float512Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float512Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float64Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float64Vector) super.lanewiseTemplate(op, Float64Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float64Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float64Vector) super.lanewiseTemplate(op, Float64Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -632,3 +646,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Float64Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -642,3 +656,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Float64Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -652,3 +666,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float64Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Float64Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float64Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public FloatMaxVector lanewise(Unary op, VectorMask<Float> m) {\n+        return (FloatMaxVector) super.lanewiseTemplate(op, FloatMaxMask.class, m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -298,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    FloatMaxVector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (FloatMaxVector) super.lanewiseTemplate(op, FloatMaxMask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -629,3 +643,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, FloatMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, FloatMaxMask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -639,3 +653,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, FloatMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, FloatMaxMask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -649,3 +663,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, FloatMaxMask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, FloatMaxMask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatMaxVector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -269,0 +272,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -556,43 +562,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), float.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (float) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.abs(a));\n-                case VECTOR_OP_SIN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.sin(a));\n-                case VECTOR_OP_COS: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.cos(a));\n-                case VECTOR_OP_TAN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.tan(a));\n-                case VECTOR_OP_ASIN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.asin(a));\n-                case VECTOR_OP_ACOS: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.acos(a));\n-                case VECTOR_OP_ATAN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.atan(a));\n-                case VECTOR_OP_EXP: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.exp(a));\n-                case VECTOR_OP_LOG: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.log(a));\n-                case VECTOR_OP_LOG10: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.log10(a));\n-                case VECTOR_OP_SQRT: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.sqrt(a));\n-                case VECTOR_OP_CBRT: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.cbrt(a));\n-                case VECTOR_OP_SINH: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.sinh(a));\n-                case VECTOR_OP_COSH: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.cosh(a));\n-                case VECTOR_OP_TANH: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.tanh(a));\n-                case VECTOR_OP_EXPM1: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.expm1(a));\n-                case VECTOR_OP_LOG1P: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.log1p(a));\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, float.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, FloatVector::unaryOperations));\n@@ -600,3 +567,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<FloatVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, FloatVector.class);\n@@ -607,2 +571,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -610,2 +574,63 @@\n-                                  VectorMask<Float> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    FloatVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Float>> maskClass,\n+                                          VectorMask<Float> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, FloatVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<FloatVector, VectorMask<Float>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, FloatVector.class);\n+\n+    private static UnaryMaskedOperation<FloatVector, VectorMask<Float>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.abs(a));\n+            case VECTOR_OP_SIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.sin(a));\n+            case VECTOR_OP_COS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.cos(a));\n+            case VECTOR_OP_TAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.tan(a));\n+            case VECTOR_OP_ASIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.asin(a));\n+            case VECTOR_OP_ACOS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.acos(a));\n+            case VECTOR_OP_ATAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.atan(a));\n+            case VECTOR_OP_EXP: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.exp(a));\n+            case VECTOR_OP_LOG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.log(a));\n+            case VECTOR_OP_LOG10: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.log10(a));\n+            case VECTOR_OP_SQRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.sqrt(a));\n+            case VECTOR_OP_CBRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.cbrt(a));\n+            case VECTOR_OP_SINH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.sinh(a));\n+            case VECTOR_OP_COSH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.cosh(a));\n+            case VECTOR_OP_TANH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.tanh(a));\n+            case VECTOR_OP_EXPM1: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.expm1(a));\n+            case VECTOR_OP_LOG1P: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.log1p(a));\n+            default: return null;\n+        }\n@@ -853,9 +878,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), float.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_FMA: return (v0, v1_, v2_) ->\n-                        v0.tOp(v1_, v2_, (i, a, b, c) -> Math.fma(a, b, c));\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, float.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, FloatVector::ternaryOperations));\n@@ -863,3 +883,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<FloatVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, FloatVector.class);\n@@ -873,2 +890,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -878,2 +895,34 @@\n-                                  VectorMask<Float> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    FloatVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Float>> maskClass,\n+                                          Vector<Float> v1,\n+                                          Vector<Float> v2,\n+                                          VectorMask<Float> m) {\n+        FloatVector that = (FloatVector) v1;\n+        FloatVector tother = (FloatVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, FloatVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<FloatVector, VectorMask<Float>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, FloatVector.class);\n+\n+    private static TernaryMaskedOperation<FloatVector, VectorMask<Float>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_FMA: return (v0, v1_, v2_, m) ->\n+                    v0.tOp(v1_, v2_, m, (i, a, b, c) -> Math.fma(a, b, c));\n+            default: return null;\n+        }\n@@ -936,1 +985,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -994,1 +1043,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1051,1 +1100,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":118,"deletions":69,"binary":false,"changes":187,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int128Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int128Vector) super.lanewiseTemplate(op, Int128Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int128Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int128Vector) super.lanewiseTemplate(op, Int128Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -640,3 +654,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Int128Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -650,3 +664,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Int128Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -660,3 +674,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int128Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Int128Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int128Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int256Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int256Vector) super.lanewiseTemplate(op, Int256Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int256Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int256Vector) super.lanewiseTemplate(op, Int256Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -648,3 +662,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Int256Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -658,3 +672,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Int256Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -668,3 +682,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int256Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Int256Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int256Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int512Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int512Vector) super.lanewiseTemplate(op, Int512Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int512Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int512Vector) super.lanewiseTemplate(op, Int512Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -664,3 +678,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Int512Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -674,3 +688,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Int512Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -684,3 +698,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int512Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Int512Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int512Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int64Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int64Vector) super.lanewiseTemplate(op, Int64Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int64Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int64Vector) super.lanewiseTemplate(op, Int64Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -636,3 +650,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Int64Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -646,3 +660,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Int64Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -656,3 +670,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int64Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Int64Mask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int64Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public IntMaxVector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (IntMaxVector) super.lanewiseTemplate(op, IntMaxMask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    IntMaxVector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (IntMaxVector) super.lanewiseTemplate(op, IntMaxMask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -634,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, IntMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, IntMaxMask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, IntMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, IntMaxMask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -654,3 +668,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, IntMaxMask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, IntMaxMask.class, null, int.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntMaxVector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -269,0 +272,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -562,11 +568,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), int.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (int) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (int) Math.abs(a));\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, int.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, IntVector::unaryOperations));\n@@ -574,3 +573,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<IntVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, IntVector.class);\n@@ -581,2 +577,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -584,2 +580,34 @@\n-                                  VectorMask<Integer> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    IntVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Integer>> maskClass,\n+                                          VectorMask<Integer> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, IntVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<IntVector, VectorMask<Integer>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, IntVector.class);\n+\n+    private static UnaryMaskedOperation<IntVector, VectorMask<Integer>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (int) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (int) Math.abs(a));\n+            default: return null;\n+        }\n@@ -935,7 +963,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), int.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, int.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, IntVector::ternaryOperations));\n@@ -943,3 +968,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<IntVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, IntVector.class);\n@@ -953,2 +975,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -958,2 +980,37 @@\n-                                  VectorMask<Integer> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    IntVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Integer>> maskClass,\n+                                          Vector<Integer> v1,\n+                                          Vector<Integer> v2,\n+                                          VectorMask<Integer> m) {\n+        IntVector that = (IntVector) v1;\n+        IntVector tother = (IntVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, IntVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<IntVector, VectorMask<Integer>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, IntVector.class);\n+\n+    private static TernaryMaskedOperation<IntVector, VectorMask<Integer>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -1016,1 +1073,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1074,1 +1131,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1131,1 +1188,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":92,"deletions":35,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long128Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long128Vector) super.lanewiseTemplate(op, Long128Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -295,1 +301,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -299,0 +305,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long128Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long128Vector) super.lanewiseTemplate(op, Long128Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -626,3 +640,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Long128Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -636,3 +650,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Long128Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -646,3 +660,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long128Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Long128Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long128Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long256Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long256Vector) super.lanewiseTemplate(op, Long256Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -295,1 +301,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -299,0 +305,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long256Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long256Vector) super.lanewiseTemplate(op, Long256Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -630,3 +644,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Long256Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -640,3 +654,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Long256Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -650,3 +664,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long256Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Long256Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long256Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long512Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long512Vector) super.lanewiseTemplate(op, Long512Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -295,1 +301,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -299,0 +305,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long512Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long512Vector) super.lanewiseTemplate(op, Long512Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -638,3 +652,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Long512Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -648,3 +662,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Long512Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -658,3 +672,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long512Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Long512Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long512Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long64Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long64Vector) super.lanewiseTemplate(op, Long64Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -295,1 +301,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -299,0 +305,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long64Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long64Vector) super.lanewiseTemplate(op, Long64Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -624,3 +638,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Long64Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -634,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Long64Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long64Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Long64Mask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long64Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public LongMaxVector lanewise(Unary op, VectorMask<Long> m) {\n+        return (LongMaxVector) super.lanewiseTemplate(op, LongMaxMask.class, m);  \/\/ specialize\n+    }\n+\n@@ -295,1 +301,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -299,0 +305,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    LongMaxVector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (LongMaxVector) super.lanewiseTemplate(op, LongMaxMask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -624,3 +638,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, LongMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, LongMaxMask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -634,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, LongMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, LongMaxMask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, LongMaxMask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, LongMaxMask.class, null, long.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongMaxVector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -269,0 +272,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -520,11 +526,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), long.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (long) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (long) Math.abs(a));\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, long.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, LongVector::unaryOperations));\n@@ -532,3 +531,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<LongVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, LongVector.class);\n@@ -539,2 +535,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -542,2 +538,34 @@\n-                                  VectorMask<Long> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    LongVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Long>> maskClass,\n+                                          VectorMask<Long> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, LongVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<LongVector, VectorMask<Long>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, LongVector.class);\n+\n+    private static UnaryMaskedOperation<LongVector, VectorMask<Long>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (long) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (long) Math.abs(a));\n+            default: return null;\n+        }\n@@ -848,7 +876,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), long.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, long.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, LongVector::ternaryOperations));\n@@ -856,3 +881,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<LongVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, LongVector.class);\n@@ -866,2 +888,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -871,2 +893,37 @@\n-                                  VectorMask<Long> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    LongVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Long>> maskClass,\n+                                          Vector<Long> v1,\n+                                          Vector<Long> v2,\n+                                          VectorMask<Long> m) {\n+        LongVector that = (LongVector) v1;\n+        LongVector tother = (LongVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, LongVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<LongVector, VectorMask<Long>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, LongVector.class);\n+\n+    private static TernaryMaskedOperation<LongVector, VectorMask<Long>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -929,1 +986,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -987,1 +1044,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1044,1 +1101,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":92,"deletions":35,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short128Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short128Vector) super.lanewiseTemplate(op, Short128Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short128Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short128Vector) super.lanewiseTemplate(op, Short128Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -648,3 +662,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short128Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Short128Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -658,3 +672,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short128Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Short128Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -668,3 +682,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short128Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Short128Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short128Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short256Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short256Vector) super.lanewiseTemplate(op, Short256Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short256Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short256Vector) super.lanewiseTemplate(op, Short256Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -664,3 +678,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short256Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Short256Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -674,3 +688,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short256Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Short256Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -684,3 +698,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short256Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Short256Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short256Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short512Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short512Vector) super.lanewiseTemplate(op, Short512Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short512Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short512Vector) super.lanewiseTemplate(op, Short512Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -696,3 +710,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short512Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Short512Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -706,3 +720,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short512Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Short512Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -716,3 +730,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short512Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Short512Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short512Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short64Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short64Vector) super.lanewiseTemplate(op, Short64Mask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short64Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short64Vector) super.lanewiseTemplate(op, Short64Mask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -640,3 +654,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short64Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, Short64Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -650,3 +664,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short64Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, Short64Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -660,3 +674,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short64Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, Short64Mask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short64Vector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public ShortMaxVector lanewise(Unary op, VectorMask<Short> m) {\n+        return (ShortMaxVector) super.lanewiseTemplate(op, ShortMaxMask.class, m);  \/\/ specialize\n+    }\n+\n@@ -300,1 +306,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -304,0 +310,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    ShortMaxVector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (ShortMaxVector) super.lanewiseTemplate(op, ShortMaxMask.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -634,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, ShortMaxMask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, ShortMaxMask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -644,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, ShortMaxMask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, ShortMaxMask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -654,3 +668,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, ShortMaxMask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, ShortMaxMask.class, null, short.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortMaxVector.java","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -174,0 +174,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -269,0 +272,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -562,11 +568,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), short.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (short) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (short) Math.abs(a));\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, short.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, ShortVector::unaryOperations));\n@@ -574,3 +573,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<ShortVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, ShortVector.class);\n@@ -581,2 +577,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -584,2 +580,34 @@\n-                                  VectorMask<Short> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    ShortVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Short>> maskClass,\n+                                          VectorMask<Short> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, ShortVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<ShortVector, VectorMask<Short>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, ShortVector.class);\n+\n+    private static UnaryMaskedOperation<ShortVector, VectorMask<Short>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) Math.abs(a));\n+            default: return null;\n+        }\n@@ -936,7 +964,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), short.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, short.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, ShortVector::ternaryOperations));\n@@ -944,3 +969,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<ShortVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, ShortVector.class);\n@@ -954,2 +976,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -959,2 +981,37 @@\n-                                  VectorMask<Short> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    ShortVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Short>> maskClass,\n+                                          Vector<Short> v1,\n+                                          Vector<Short> v2,\n+                                          VectorMask<Short> m) {\n+        ShortVector that = (ShortVector) v1;\n+        ShortVector tother = (ShortVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, ShortVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<ShortVector, VectorMask<Short>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, ShortVector.class);\n+\n+    private static TernaryMaskedOperation<ShortVector, VectorMask<Short>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -1017,1 +1074,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1075,1 +1132,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1132,1 +1189,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":92,"deletions":35,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -178,0 +178,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -273,0 +276,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -576,45 +582,4 @@\n-        return VectorSupport.unaryOp(\n-            opc, getClass(), $type$.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.abs(a));\n-#if[FP]\n-                case VECTOR_OP_SIN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.sin(a));\n-                case VECTOR_OP_COS: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.cos(a));\n-                case VECTOR_OP_TAN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.tan(a));\n-                case VECTOR_OP_ASIN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.asin(a));\n-                case VECTOR_OP_ACOS: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.acos(a));\n-                case VECTOR_OP_ATAN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.atan(a));\n-                case VECTOR_OP_EXP: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.exp(a));\n-                case VECTOR_OP_LOG: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.log(a));\n-                case VECTOR_OP_LOG10: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.log10(a));\n-                case VECTOR_OP_SQRT: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.sqrt(a));\n-                case VECTOR_OP_CBRT: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.cbrt(a));\n-                case VECTOR_OP_SINH: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.sinh(a));\n-                case VECTOR_OP_COSH: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.cosh(a));\n-                case VECTOR_OP_TANH: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.tanh(a));\n-                case VECTOR_OP_EXPM1: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.expm1(a));\n-                case VECTOR_OP_LOG1P: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.log1p(a));\n-#end[FP]\n-                default: return null;\n-              }}));\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), null, $type$.class, length(),\n+            this, null,\n+            UN_MASKED_IMPL.find(op, opc, $abstractvectortype$::unaryOperations));\n@@ -622,3 +587,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<$abstractvectortype$>> UN_IMPL\n-        = new ImplCache<>(Unary.class, $Type$Vector.class);\n@@ -629,2 +591,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -632,2 +594,70 @@\n-                                  VectorMask<$Boxtype$> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    $abstractvectortype$ lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<$Boxtype$>> maskClass,\n+                                          VectorMask<$Boxtype$> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+#if[BITWISE]\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+#end[BITWISE]\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryMaskedOp(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, m,\n+            UN_MASKED_IMPL.find(op, opc, $abstractvectortype$::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryMaskedOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        UN_MASKED_IMPL = new ImplCache<>(Unary.class, $Type$Vector.class);\n+\n+    private static UnaryMaskedOperation<$abstractvectortype$, VectorMask<$Boxtype$>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.abs(a));\n+#if[FP]\n+            case VECTOR_OP_SIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.sin(a));\n+            case VECTOR_OP_COS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.cos(a));\n+            case VECTOR_OP_TAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.tan(a));\n+            case VECTOR_OP_ASIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.asin(a));\n+            case VECTOR_OP_ACOS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.acos(a));\n+            case VECTOR_OP_ATAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.atan(a));\n+            case VECTOR_OP_EXP: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.exp(a));\n+            case VECTOR_OP_LOG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.log(a));\n+            case VECTOR_OP_LOG10: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.log10(a));\n+            case VECTOR_OP_SQRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.sqrt(a));\n+            case VECTOR_OP_CBRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.cbrt(a));\n+            case VECTOR_OP_SINH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.sinh(a));\n+            case VECTOR_OP_COSH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.cosh(a));\n+            case VECTOR_OP_TANH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.tanh(a));\n+            case VECTOR_OP_EXPM1: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.expm1(a));\n+            case VECTOR_OP_LOG1P: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.log1p(a));\n+#end[FP]\n+            default: return null;\n+        }\n@@ -1036,11 +1066,4 @@\n-        return VectorSupport.ternaryOp(\n-            opc, getClass(), $type$.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-#if[FP]\n-                case VECTOR_OP_FMA: return (v0, v1_, v2_) ->\n-                        v0.tOp(v1_, v2_, (i, a, b, c) -> Math.fma(a, b, c));\n-#end[FP]\n-                default: return null;\n-                }}));\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), null, $type$.class, length(),\n+            this, that, tother, null,\n+            TERN_MASKED_IMPL.find(op, opc, $abstractvectortype$::ternaryOperations));\n@@ -1048,3 +1071,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<$abstractvectortype$>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, $Type$Vector.class);\n@@ -1058,2 +1078,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -1063,2 +1083,43 @@\n-                                  VectorMask<$Boxtype$> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    $abstractvectortype$ lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<$Boxtype$>> maskClass,\n+                                          Vector<$Boxtype$> v1,\n+                                          Vector<$Boxtype$> v2,\n+                                          VectorMask<$Boxtype$> m) {\n+        $abstractvectortype$ that = ($abstractvectortype$) v1;\n+        $abstractvectortype$ tother = ($abstractvectortype$) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+#if[BITWISE]\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+#end[BITWISE]\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryMaskedOp(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, that, tother, m,\n+            TERN_MASKED_IMPL.find(op, opc, $abstractvectortype$::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryMaskedOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        TERN_MASKED_IMPL = new ImplCache<>(Ternary.class, $Type$Vector.class);\n+\n+    private static TernaryMaskedOperation<$abstractvectortype$, VectorMask<$Boxtype$>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+#if[FP]\n+            case VECTOR_OP_FMA: return (v0, v1_, v2_, m) ->\n+                    v0.tOp(v1_, v2_, m, (i, a, b, c) -> Math.fma(a, b, c));\n+#end[FP]\n+            default: return null;\n+        }\n@@ -1121,1 +1182,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1179,1 +1240,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1236,1 +1297,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":134,"deletions":73,"binary":false,"changes":207,"status":"modified"},{"patch":"@@ -278,0 +278,6 @@\n+    @Override\n+    @ForceInline\n+    public $vectortype$ lanewise(Unary op, VectorMask<$Boxtype$> m) {\n+        return ($vectortype$) super.lanewiseTemplate(op, $masktype$.class, m);  \/\/ specialize\n+    }\n+\n@@ -304,1 +310,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<$Boxtype$> v1, Vector<$Boxtype$> v2) {\n+    lanewise(Ternary op, Vector<$Boxtype$> v1, Vector<$Boxtype$> v2) {\n@@ -308,0 +314,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    $vectortype$\n+    lanewise(Ternary op, Vector<$Boxtype$> v1, Vector<$Boxtype$> v2, VectorMask<$Boxtype$> m) {\n+        return ($vectortype$) super.lanewiseTemplate(op, $masktype$.class, v1, v2, m);  \/\/ specialize\n+    }\n+\n@@ -907,3 +921,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, $masktype$.class, $bitstype$.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_AND, $masktype$.class, null, $bitstype$.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -917,3 +931,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, $masktype$.class, $bitstype$.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_OR, $masktype$.class, null, $bitstype$.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -927,3 +941,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, $masktype$.class, $bitstype$.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryMaskedOp(VECTOR_OP_XOR, $masktype$.class, null, $bitstype$.class, VLENGTH,\n+                                                this, m, null,\n+                                                (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-VectorBits.java.template","additions":24,"deletions":10,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -525,1 +525,0 @@\n-                                \"jdk\/internal\/vm\/vector\/VectorSupport.binaryOp(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/util\/function\/BiFunction;)Ljava\/lang\/Object;\",\n@@ -542,3 +541,1 @@\n-                                \"jdk\/internal\/vm\/vector\/VectorSupport.ternaryOp(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryOperation;)Ljava\/lang\/Object;\",\n-                                \"jdk\/internal\/vm\/vector\/VectorSupport.test(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/util\/function\/BiFunction;)Z\",\n-                                \"jdk\/internal\/vm\/vector\/VectorSupport.unaryOp(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/util\/function\/Function;)Ljava\/lang\/Object;\");\n+                                \"jdk\/internal\/vm\/vector\/VectorSupport.test(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/util\/function\/BiFunction;)Z\");\n","filename":"src\/jdk.internal.vm.compiler\/share\/classes\/org.graalvm.compiler.hotspot.test\/src\/org\/graalvm\/compiler\/hotspot\/test\/CheckGraalIntrinsics.java","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"}]}