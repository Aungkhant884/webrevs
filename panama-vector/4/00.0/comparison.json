{"files":[{"patch":"@@ -72,1 +72,1 @@\n-\/\/   r8-r9 invisible to the allocator (so we can use them as scratch regs)\n+\/\/   r8-r9 non-allocatable (so we can use them as scratch regs)\n@@ -97,0 +97,4 @@\n+reg_def R8      ( NS,  SOC, Op_RegI,  8, r8->as_VMReg()         ); \/\/ rscratch1, non-allocatable\n+reg_def R8_H    ( NS,  SOC, Op_RegI,  8, r8->as_VMReg()->next() );\n+reg_def R9      ( NS,  SOC, Op_RegI,  9, r9->as_VMReg()         ); \/\/ rscratch2, non-allocatable\n+reg_def R9_H    ( NS,  SOC, Op_RegI,  9, r9->as_VMReg()->next() );\n@@ -143,1 +147,1 @@\n-\/\/ Float\/Double Registers\n+\/\/ Float\/Double\/Vector Registers\n@@ -164,159 +168,318 @@\n-  reg_def V0   ( SOC, SOC, Op_RegF,  0, v0->as_VMReg()          );\n-  reg_def V0_H ( SOC, SOC, Op_RegF,  0, v0->as_VMReg()->next()  );\n-  reg_def V0_J ( SOC, SOC, Op_RegF,  0, v0->as_VMReg()->next(2) );\n-  reg_def V0_K ( SOC, SOC, Op_RegF,  0, v0->as_VMReg()->next(3) );\n-\n-  reg_def V1   ( SOC, SOC, Op_RegF,  1, v1->as_VMReg()          );\n-  reg_def V1_H ( SOC, SOC, Op_RegF,  1, v1->as_VMReg()->next()  );\n-  reg_def V1_J ( SOC, SOC, Op_RegF,  1, v1->as_VMReg()->next(2) );\n-  reg_def V1_K ( SOC, SOC, Op_RegF,  1, v1->as_VMReg()->next(3) );\n-\n-  reg_def V2   ( SOC, SOC, Op_RegF,  2, v2->as_VMReg()          );\n-  reg_def V2_H ( SOC, SOC, Op_RegF,  2, v2->as_VMReg()->next()  );\n-  reg_def V2_J ( SOC, SOC, Op_RegF,  2, v2->as_VMReg()->next(2) );\n-  reg_def V2_K ( SOC, SOC, Op_RegF,  2, v2->as_VMReg()->next(3) );\n-\n-  reg_def V3   ( SOC, SOC, Op_RegF,  3, v3->as_VMReg()          );\n-  reg_def V3_H ( SOC, SOC, Op_RegF,  3, v3->as_VMReg()->next()  );\n-  reg_def V3_J ( SOC, SOC, Op_RegF,  3, v3->as_VMReg()->next(2) );\n-  reg_def V3_K ( SOC, SOC, Op_RegF,  3, v3->as_VMReg()->next(3) );\n-\n-  reg_def V4   ( SOC, SOC, Op_RegF,  4, v4->as_VMReg()          );\n-  reg_def V4_H ( SOC, SOC, Op_RegF,  4, v4->as_VMReg()->next()  );\n-  reg_def V4_J ( SOC, SOC, Op_RegF,  4, v4->as_VMReg()->next(2) );\n-  reg_def V4_K ( SOC, SOC, Op_RegF,  4, v4->as_VMReg()->next(3) );\n-\n-  reg_def V5   ( SOC, SOC, Op_RegF,  5, v5->as_VMReg()          );\n-  reg_def V5_H ( SOC, SOC, Op_RegF,  5, v5->as_VMReg()->next()  );\n-  reg_def V5_J ( SOC, SOC, Op_RegF,  5, v5->as_VMReg()->next(2) );\n-  reg_def V5_K ( SOC, SOC, Op_RegF,  5, v5->as_VMReg()->next(3) );\n-\n-  reg_def V6   ( SOC, SOC, Op_RegF,  6, v6->as_VMReg()          );\n-  reg_def V6_H ( SOC, SOC, Op_RegF,  6, v6->as_VMReg()->next()  );\n-  reg_def V6_J ( SOC, SOC, Op_RegF,  6, v6->as_VMReg()->next(2) );\n-  reg_def V6_K ( SOC, SOC, Op_RegF,  6, v6->as_VMReg()->next(3) );\n-\n-  reg_def V7   ( SOC, SOC, Op_RegF,  7, v7->as_VMReg()          );\n-  reg_def V7_H ( SOC, SOC, Op_RegF,  7, v7->as_VMReg()->next()  );\n-  reg_def V7_J ( SOC, SOC, Op_RegF,  7, v7->as_VMReg()->next(2) );\n-  reg_def V7_K ( SOC, SOC, Op_RegF,  7, v7->as_VMReg()->next(3) );\n-\n-  reg_def V8   ( SOC, SOC, Op_RegF,  8, v8->as_VMReg()          );\n-  reg_def V8_H ( SOC, SOC, Op_RegF,  8, v8->as_VMReg()->next()  );\n-  reg_def V8_J ( SOC, SOC, Op_RegF,  8, v8->as_VMReg()->next(2) );\n-  reg_def V8_K ( SOC, SOC, Op_RegF,  8, v8->as_VMReg()->next(3) );\n-\n-  reg_def V9   ( SOC, SOC, Op_RegF,  9, v9->as_VMReg()          );\n-  reg_def V9_H ( SOC, SOC, Op_RegF,  9, v9->as_VMReg()->next()  );\n-  reg_def V9_J ( SOC, SOC, Op_RegF,  9, v9->as_VMReg()->next(2) );\n-  reg_def V9_K ( SOC, SOC, Op_RegF,  9, v9->as_VMReg()->next(3) );\n-\n-  reg_def V10  ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()         );\n-  reg_def V10_H( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next() );\n-  reg_def V10_J( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(2));\n-  reg_def V10_K( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(3));\n-\n-  reg_def V11  ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()         );\n-  reg_def V11_H( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next() );\n-  reg_def V11_J( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(2));\n-  reg_def V11_K( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(3));\n-\n-  reg_def V12  ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()         );\n-  reg_def V12_H( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next() );\n-  reg_def V12_J( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(2));\n-  reg_def V12_K( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(3));\n-\n-  reg_def V13  ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()         );\n-  reg_def V13_H( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next() );\n-  reg_def V13_J( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(2));\n-  reg_def V13_K( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(3));\n-\n-  reg_def V14  ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()         );\n-  reg_def V14_H( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next() );\n-  reg_def V14_J( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(2));\n-  reg_def V14_K( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(3));\n-\n-  reg_def V15  ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()         );\n-  reg_def V15_H( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next() );\n-  reg_def V15_J( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(2));\n-  reg_def V15_K( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(3));\n-\n-  reg_def V16  ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()         );\n-  reg_def V16_H( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next() );\n-  reg_def V16_J( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(2));\n-  reg_def V16_K( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(3));\n-\n-  reg_def V17  ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()         );\n-  reg_def V17_H( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next() );\n-  reg_def V17_J( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(2));\n-  reg_def V17_K( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(3));\n-\n-  reg_def V18  ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()         );\n-  reg_def V18_H( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next() );\n-  reg_def V18_J( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(2));\n-  reg_def V18_K( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(3));\n-\n-  reg_def V19  ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()         );\n-  reg_def V19_H( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next() );\n-  reg_def V19_J( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(2));\n-  reg_def V19_K( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(3));\n-\n-  reg_def V20  ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()         );\n-  reg_def V20_H( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next() );\n-  reg_def V20_J( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(2));\n-  reg_def V20_K( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(3));\n-\n-  reg_def V21  ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()         );\n-  reg_def V21_H( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next() );\n-  reg_def V21_J( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(2));\n-  reg_def V21_K( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(3));\n-\n-  reg_def V22  ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()         );\n-  reg_def V22_H( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next() );\n-  reg_def V22_J( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(2));\n-  reg_def V22_K( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(3));\n-\n-  reg_def V23  ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()         );\n-  reg_def V23_H( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next() );\n-  reg_def V23_J( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(2));\n-  reg_def V23_K( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(3));\n-\n-  reg_def V24  ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()         );\n-  reg_def V24_H( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next() );\n-  reg_def V24_J( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(2));\n-  reg_def V24_K( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(3));\n-\n-  reg_def V25  ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()         );\n-  reg_def V25_H( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next() );\n-  reg_def V25_J( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(2));\n-  reg_def V25_K( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(3));\n-\n-  reg_def V26  ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()         );\n-  reg_def V26_H( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next() );\n-  reg_def V26_J( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(2));\n-  reg_def V26_K( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(3));\n-\n-  reg_def V27  ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()         );\n-  reg_def V27_H( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next() );\n-  reg_def V27_J( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(2));\n-  reg_def V27_K( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(3));\n-\n-  reg_def V28  ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()         );\n-  reg_def V28_H( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next() );\n-  reg_def V28_J( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(2));\n-  reg_def V28_K( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(3));\n-\n-  reg_def V29  ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()         );\n-  reg_def V29_H( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next() );\n-  reg_def V29_J( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(2));\n-  reg_def V29_K( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(3));\n-\n-  reg_def V30  ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()         );\n-  reg_def V30_H( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next() );\n-  reg_def V30_J( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(2));\n-  reg_def V30_K( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(3));\n-\n-  reg_def V31  ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()         );\n-  reg_def V31_H( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next() );\n-  reg_def V31_J( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(2));\n-  reg_def V31_K( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(3));\n+\/\/ For SVE vector registers, we simply extend vector register size to 8\n+\/\/ 'logical' slots. This is nominally 256 bits but it actually covers\n+\/\/ all possible 'physical' SVE vector register lengths from 128 ~ 2048\n+\/\/ bits. The 'physical' SVE vector register length is detected during\n+\/\/ startup, so the register allocator is able to identify the correct\n+\/\/ number of bytes needed for an SVE spill\/unspill.\n+\/\/ Note that a vector register with 4 slots denotes a 128-bit NEON\n+\/\/ register allowing it to be distinguished from the corresponding SVE\n+\/\/ vector register when the SVE vector length is 128 bits.\n+\n+  reg_def V0   ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()          );\n+  reg_def V0_H ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next()  );\n+  reg_def V0_J ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(2) );\n+  reg_def V0_K ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(3) );\n+  reg_def V0_L ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(4) );\n+  reg_def V0_M ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(5) );\n+  reg_def V0_N ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(6) );\n+  reg_def V0_O ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(7) );\n+\n+  reg_def V1   ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()          );\n+  reg_def V1_H ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next()  );\n+  reg_def V1_J ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(2) );\n+  reg_def V1_K ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(3) );\n+  reg_def V1_L ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(4) );\n+  reg_def V1_M ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(5) );\n+  reg_def V1_N ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(6) );\n+  reg_def V1_O ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(7) );\n+\n+  reg_def V2   ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()          );\n+  reg_def V2_H ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next()  );\n+  reg_def V2_J ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(2) );\n+  reg_def V2_K ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(3) );\n+  reg_def V2_L ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(4) );\n+  reg_def V2_M ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(5) );\n+  reg_def V2_N ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(6) );\n+  reg_def V2_O ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(7) );\n+\n+  reg_def V3   ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()          );\n+  reg_def V3_H ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next()  );\n+  reg_def V3_J ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(2) );\n+  reg_def V3_K ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(3) );\n+  reg_def V3_L ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(4) );\n+  reg_def V3_M ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(5) );\n+  reg_def V3_N ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(6) );\n+  reg_def V3_O ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(7) );\n+\n+  reg_def V4   ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()          );\n+  reg_def V4_H ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next()  );\n+  reg_def V4_J ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(2) );\n+  reg_def V4_K ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(3) );\n+  reg_def V4_L ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(4) );\n+  reg_def V4_M ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(5) );\n+  reg_def V4_N ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(6) );\n+  reg_def V4_O ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(7) );\n+\n+  reg_def V5   ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()          );\n+  reg_def V5_H ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next()  );\n+  reg_def V5_J ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(2) );\n+  reg_def V5_K ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(3) );\n+  reg_def V5_L ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(4) );\n+  reg_def V5_M ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(5) );\n+  reg_def V5_N ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(6) );\n+  reg_def V5_O ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(7) );\n+\n+  reg_def V6   ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()          );\n+  reg_def V6_H ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next()  );\n+  reg_def V6_J ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(2) );\n+  reg_def V6_K ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(3) );\n+  reg_def V6_L ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(4) );\n+  reg_def V6_M ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(5) );\n+  reg_def V6_N ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(6) );\n+  reg_def V6_O ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(7) );\n+\n+  reg_def V7   ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()          );\n+  reg_def V7_H ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next()  );\n+  reg_def V7_J ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(2) );\n+  reg_def V7_K ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(3) );\n+  reg_def V7_L ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(4) );\n+  reg_def V7_M ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(5) );\n+  reg_def V7_N ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(6) );\n+  reg_def V7_O ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(7) );\n+\n+  reg_def V8   ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()          );\n+  reg_def V8_H ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next()  );\n+  reg_def V8_J ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(2) );\n+  reg_def V8_K ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(3) );\n+  reg_def V8_L ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(4) );\n+  reg_def V8_M ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(5) );\n+  reg_def V8_N ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(6) );\n+  reg_def V8_O ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(7) );\n+\n+  reg_def V9   ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()          );\n+  reg_def V9_H ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next()  );\n+  reg_def V9_J ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(2) );\n+  reg_def V9_K ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(3) );\n+  reg_def V9_L ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(4) );\n+  reg_def V9_M ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(5) );\n+  reg_def V9_N ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(6) );\n+  reg_def V9_O ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(7) );\n+\n+  reg_def V10   ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()          );\n+  reg_def V10_H ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next()  );\n+  reg_def V10_J ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(2) );\n+  reg_def V10_K ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(3) );\n+  reg_def V10_L ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(4) );\n+  reg_def V10_M ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(5) );\n+  reg_def V10_N ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(6) );\n+  reg_def V10_O ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(7) );\n+\n+  reg_def V11   ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()          );\n+  reg_def V11_H ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next()  );\n+  reg_def V11_J ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(2) );\n+  reg_def V11_K ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(3) );\n+  reg_def V11_L ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(4) );\n+  reg_def V11_M ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(5) );\n+  reg_def V11_N ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(6) );\n+  reg_def V11_O ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(7) );\n+\n+  reg_def V12   ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()          );\n+  reg_def V12_H ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next()  );\n+  reg_def V12_J ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(2) );\n+  reg_def V12_K ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(3) );\n+  reg_def V12_L ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(4) );\n+  reg_def V12_M ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(5) );\n+  reg_def V12_N ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(6) );\n+  reg_def V12_O ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(7) );\n+\n+  reg_def V13   ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()          );\n+  reg_def V13_H ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next()  );\n+  reg_def V13_J ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(2) );\n+  reg_def V13_K ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(3) );\n+  reg_def V13_L ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(4) );\n+  reg_def V13_M ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(5) );\n+  reg_def V13_N ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(6) );\n+  reg_def V13_O ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(7) );\n+\n+  reg_def V14   ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()          );\n+  reg_def V14_H ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next()  );\n+  reg_def V14_J ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(2) );\n+  reg_def V14_K ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(3) );\n+  reg_def V14_L ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(4) );\n+  reg_def V14_M ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(5) );\n+  reg_def V14_N ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(6) );\n+  reg_def V14_O ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(7) );\n+\n+  reg_def V15   ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()          );\n+  reg_def V15_H ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next()  );\n+  reg_def V15_J ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(2) );\n+  reg_def V15_K ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(3) );\n+  reg_def V15_L ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(4) );\n+  reg_def V15_M ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(5) );\n+  reg_def V15_N ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(6) );\n+  reg_def V15_O ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(7) );\n+\n+  reg_def V16   ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()          );\n+  reg_def V16_H ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next()  );\n+  reg_def V16_J ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(2) );\n+  reg_def V16_K ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(3) );\n+  reg_def V16_L ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(4) );\n+  reg_def V16_M ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(5) );\n+  reg_def V16_N ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(6) );\n+  reg_def V16_O ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(7) );\n+\n+  reg_def V17   ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()          );\n+  reg_def V17_H ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next()  );\n+  reg_def V17_J ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(2) );\n+  reg_def V17_K ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(3) );\n+  reg_def V17_L ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(4) );\n+  reg_def V17_M ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(5) );\n+  reg_def V17_N ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(6) );\n+  reg_def V17_O ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(7) );\n+\n+  reg_def V18   ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()          );\n+  reg_def V18_H ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next()  );\n+  reg_def V18_J ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(2) );\n+  reg_def V18_K ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(3) );\n+  reg_def V18_L ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(4) );\n+  reg_def V18_M ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(5) );\n+  reg_def V18_N ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(6) );\n+  reg_def V18_O ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(7) );\n+\n+  reg_def V19   ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()          );\n+  reg_def V19_H ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next()  );\n+  reg_def V19_J ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(2) );\n+  reg_def V19_K ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(3) );\n+  reg_def V19_L ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(4) );\n+  reg_def V19_M ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(5) );\n+  reg_def V19_N ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(6) );\n+  reg_def V19_O ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(7) );\n+\n+  reg_def V20   ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()          );\n+  reg_def V20_H ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next()  );\n+  reg_def V20_J ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(2) );\n+  reg_def V20_K ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(3) );\n+  reg_def V20_L ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(4) );\n+  reg_def V20_M ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(5) );\n+  reg_def V20_N ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(6) );\n+  reg_def V20_O ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(7) );\n+\n+  reg_def V21   ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()          );\n+  reg_def V21_H ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next()  );\n+  reg_def V21_J ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(2) );\n+  reg_def V21_K ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(3) );\n+  reg_def V21_L ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(4) );\n+  reg_def V21_M ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(5) );\n+  reg_def V21_N ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(6) );\n+  reg_def V21_O ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(7) );\n+\n+  reg_def V22   ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()          );\n+  reg_def V22_H ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next()  );\n+  reg_def V22_J ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(2) );\n+  reg_def V22_K ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(3) );\n+  reg_def V22_L ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(4) );\n+  reg_def V22_M ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(5) );\n+  reg_def V22_N ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(6) );\n+  reg_def V22_O ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(7) );\n+\n+  reg_def V23   ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()          );\n+  reg_def V23_H ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next()  );\n+  reg_def V23_J ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(2) );\n+  reg_def V23_K ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(3) );\n+  reg_def V23_L ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(4) );\n+  reg_def V23_M ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(5) );\n+  reg_def V23_N ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(6) );\n+  reg_def V23_O ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(7) );\n+\n+  reg_def V24   ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()          );\n+  reg_def V24_H ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next()  );\n+  reg_def V24_J ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(2) );\n+  reg_def V24_K ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(3) );\n+  reg_def V24_L ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(4) );\n+  reg_def V24_M ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(5) );\n+  reg_def V24_N ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(6) );\n+  reg_def V24_O ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(7) );\n+\n+  reg_def V25   ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()          );\n+  reg_def V25_H ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next()  );\n+  reg_def V25_J ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(2) );\n+  reg_def V25_K ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(3) );\n+  reg_def V25_L ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(4) );\n+  reg_def V25_M ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(5) );\n+  reg_def V25_N ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(6) );\n+  reg_def V25_O ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(7) );\n+\n+  reg_def V26   ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()          );\n+  reg_def V26_H ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next()  );\n+  reg_def V26_J ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(2) );\n+  reg_def V26_K ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(3) );\n+  reg_def V26_L ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(4) );\n+  reg_def V26_M ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(5) );\n+  reg_def V26_N ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(6) );\n+  reg_def V26_O ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(7) );\n+\n+  reg_def V27   ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()          );\n+  reg_def V27_H ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next()  );\n+  reg_def V27_J ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(2) );\n+  reg_def V27_K ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(3) );\n+  reg_def V27_L ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(4) );\n+  reg_def V27_M ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(5) );\n+  reg_def V27_N ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(6) );\n+  reg_def V27_O ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(7) );\n+\n+  reg_def V28   ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()          );\n+  reg_def V28_H ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next()  );\n+  reg_def V28_J ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(2) );\n+  reg_def V28_K ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(3) );\n+  reg_def V28_L ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(4) );\n+  reg_def V28_M ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(5) );\n+  reg_def V28_N ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(6) );\n+  reg_def V28_O ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(7) );\n+\n+  reg_def V29   ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()          );\n+  reg_def V29_H ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next()  );\n+  reg_def V29_J ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(2) );\n+  reg_def V29_K ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(3) );\n+  reg_def V29_L ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(4) );\n+  reg_def V29_M ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(5) );\n+  reg_def V29_N ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(6) );\n+  reg_def V29_O ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(7) );\n+\n+  reg_def V30   ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()          );\n+  reg_def V30_H ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next()  );\n+  reg_def V30_J ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(2) );\n+  reg_def V30_K ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(3) );\n+  reg_def V30_L ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(4) );\n+  reg_def V30_M ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(5) );\n+  reg_def V30_N ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(6) );\n+  reg_def V30_O ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(7) );\n+\n+  reg_def V31   ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()          );\n+  reg_def V31_H ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next()  );\n+  reg_def V31_J ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(2) );\n+  reg_def V31_K ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(3) );\n+  reg_def V31_L ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(4) );\n+  reg_def V31_M ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(5) );\n+  reg_def V31_N ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(6) );\n+  reg_def V31_O ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(7) );\n+\n+\n+\/\/ ----------------------------\n+\/\/ SVE Predicate Registers\n+\/\/ ----------------------------\n+  reg_def P0 (SOC, SOC, Op_RegVMask, 0, p0->as_VMReg());\n+  reg_def P1 (SOC, SOC, Op_RegVMask, 1, p1->as_VMReg());\n+  reg_def P2 (SOC, SOC, Op_RegVMask, 2, p2->as_VMReg());\n+  reg_def P3 (SOC, SOC, Op_RegVMask, 3, p3->as_VMReg());\n+  reg_def P4 (SOC, SOC, Op_RegVMask, 4, p4->as_VMReg());\n+  reg_def P5 (SOC, SOC, Op_RegVMask, 5, p5->as_VMReg());\n+  reg_def P6 (SOC, SOC, Op_RegVMask, 6, p6->as_VMReg());\n+  reg_def P7 (SOC, SOC, Op_RegVMask, 7, p7->as_VMReg());\n+  reg_def P8 (SOC, SOC, Op_RegVMask, 8, p8->as_VMReg());\n+  reg_def P9 (SOC, SOC, Op_RegVMask, 9, p9->as_VMReg());\n+  reg_def P10 (SOC, SOC, Op_RegVMask, 10, p10->as_VMReg());\n+  reg_def P11 (SOC, SOC, Op_RegVMask, 11, p11->as_VMReg());\n+  reg_def P12 (SOC, SOC, Op_RegVMask, 12, p12->as_VMReg());\n+  reg_def P13 (SOC, SOC, Op_RegVMask, 13, p13->as_VMReg());\n+  reg_def P14 (SOC, SOC, Op_RegVMask, 14, p14->as_VMReg());\n+  reg_def P15 (SOC, SOC, Op_RegVMask, 15, p15->as_VMReg());\n@@ -336,1 +499,0 @@\n-\n@@ -384,0 +546,2 @@\n+    R8, R8_H,   \/\/ rscratch1\n+    R9, R9_H,   \/\/ rscratch2\n@@ -389,16 +553,16 @@\n-    V16, V16_H, V16_J, V16_K,\n-    V17, V17_H, V17_J, V17_K,\n-    V18, V18_H, V18_J, V18_K,\n-    V19, V19_H, V19_J, V19_K,\n-    V20, V20_H, V20_J, V20_K,\n-    V21, V21_H, V21_J, V21_K,\n-    V22, V22_H, V22_J, V22_K,\n-    V23, V23_H, V23_J, V23_K,\n-    V24, V24_H, V24_J, V24_K,\n-    V25, V25_H, V25_J, V25_K,\n-    V26, V26_H, V26_J, V26_K,\n-    V27, V27_H, V27_J, V27_K,\n-    V28, V28_H, V28_J, V28_K,\n-    V29, V29_H, V29_J, V29_K,\n-    V30, V30_H, V30_J, V30_K,\n-    V31, V31_H, V31_J, V31_K,\n+    V16, V16_H, V16_J, V16_K, V16_L, V16_M, V16_N, V16_O,\n+    V17, V17_H, V17_J, V17_K, V17_L, V17_M, V17_N, V17_O,\n+    V18, V18_H, V18_J, V18_K, V18_L, V18_M, V18_N, V18_O,\n+    V19, V19_H, V19_J, V19_K, V19_L, V19_M, V19_N, V19_O,\n+    V20, V20_H, V20_J, V20_K, V20_L, V20_M, V20_N, V20_O,\n+    V21, V21_H, V21_J, V21_K, V21_L, V21_M, V21_N, V21_O,\n+    V22, V22_H, V22_J, V22_K, V22_L, V22_M, V22_N, V22_O,\n+    V23, V23_H, V23_J, V23_K, V23_L, V23_M, V23_N, V23_O,\n+    V24, V24_H, V24_J, V24_K, V24_L, V24_M, V24_N, V24_O,\n+    V25, V25_H, V25_J, V25_K, V25_L, V25_M, V25_N, V25_O,\n+    V26, V26_H, V26_J, V26_K, V26_L, V26_M, V26_N, V26_O,\n+    V27, V27_H, V27_J, V27_K, V27_L, V27_M, V27_N, V27_O,\n+    V28, V28_H, V28_J, V28_K, V28_L, V28_M, V28_N, V28_O,\n+    V29, V29_H, V29_J, V29_K, V29_L, V29_M, V29_N, V29_O,\n+    V30, V30_H, V30_J, V30_K, V30_L, V30_M, V30_N, V30_O,\n+    V31, V31_H, V31_J, V31_K, V31_L, V31_M, V31_N, V31_O,\n@@ -407,8 +571,8 @@\n-    V0, V0_H, V0_J, V0_K,\n-    V1, V1_H, V1_J, V1_K,\n-    V2, V2_H, V2_J, V2_K,\n-    V3, V3_H, V3_J, V3_K,\n-    V4, V4_H, V4_J, V4_K,\n-    V5, V5_H, V5_J, V5_K,\n-    V6, V6_H, V6_J, V6_K,\n-    V7, V7_H, V7_J, V7_K,\n+    V0, V0_H, V0_J, V0_K, V0_L, V0_M, V0_N, V0_O,\n+    V1, V1_H, V1_J, V1_K, V1_L, V1_M, V1_N, V1_O,\n+    V2, V2_H, V2_J, V2_K, V2_L, V2_M, V2_N, V2_O,\n+    V3, V3_H, V3_J, V3_K, V3_L, V3_M, V3_N, V3_O,\n+    V4, V4_H, V4_J, V4_K, V4_L, V4_M, V4_N, V4_O,\n+    V5, V5_H, V5_J, V5_K, V5_L, V5_M, V5_N, V5_O,\n+    V6, V6_H, V6_J, V6_K, V6_L, V6_M, V6_N, V6_O,\n+    V7, V7_H, V7_J, V7_K, V7_L, V7_M, V7_N, V7_O,\n@@ -417,8 +581,8 @@\n-    V8, V8_H, V8_J, V8_K,\n-    V9, V9_H, V9_J, V9_K,\n-    V10, V10_H, V10_J, V10_K,\n-    V11, V11_H, V11_J, V11_K,\n-    V12, V12_H, V12_J, V12_K,\n-    V13, V13_H, V13_J, V13_K,\n-    V14, V14_H, V14_J, V14_K,\n-    V15, V15_H, V15_J, V15_K,\n+    V8, V8_H, V8_J, V8_K, V8_L, V8_M, V8_N, V8_O,\n+    V9, V9_H, V9_J, V9_K, V9_L, V9_M, V9_N, V9_O,\n+    V10, V10_H, V10_J, V10_K, V10_L, V10_M, V10_N, V10_O,\n+    V11, V11_H, V11_J, V11_K, V11_L, V11_M, V11_N, V11_O,\n+    V12, V12_H, V12_J, V12_K, V12_L, V12_M, V12_N, V12_O,\n+    V13, V13_H, V13_J, V13_K, V13_L, V13_M, V13_N, V13_O,\n+    V14, V14_H, V14_J, V14_K, V14_L, V14_M, V14_N, V14_O,\n+    V15, V15_H, V15_J, V15_K, V15_L, V15_M, V15_N, V15_O,\n@@ -427,1 +591,21 @@\n-alloc_class chunk2(RFLAGS);\n+alloc_class chunk2 (\n+    P0,\n+    P1,\n+    P2,\n+    P3,\n+    P4,\n+    P5,\n+    P6,\n+    P7,\n+\n+    P8,\n+    P9,\n+    P10,\n+    P11,\n+    P12,\n+    P13,\n+    P14,\n+    P15,\n+);\n+\n+alloc_class chunk3(RFLAGS);\n@@ -711,0 +895,36 @@\n+\/\/ Class for all SVE vector registers.\n+reg_class vectora_reg (\n+    V0, V0_H, V0_J, V0_K, V0_L, V0_M, V0_N, V0_O,\n+    V1, V1_H, V1_J, V1_K, V1_L, V1_M, V1_N, V1_O,\n+    V2, V2_H, V2_J, V2_K, V2_L, V2_M, V2_N, V2_O,\n+    V3, V3_H, V3_J, V3_K, V3_L, V3_M, V3_N, V3_O,\n+    V4, V4_H, V4_J, V4_K, V4_L, V4_M, V4_N, V4_O,\n+    V5, V5_H, V5_J, V5_K, V5_L, V5_M, V5_N, V5_O,\n+    V6, V6_H, V6_J, V6_K, V6_L, V6_M, V6_N, V6_O,\n+    V7, V7_H, V7_J, V7_K, V7_L, V7_M, V7_N, V7_O,\n+    V8, V8_H, V8_J, V8_K, V8_L, V8_M, V8_N, V8_O,\n+    V9, V9_H, V9_J, V9_K, V9_L, V9_M, V9_N, V9_O,\n+    V10, V10_H, V10_J, V10_K, V10_L, V10_M, V10_N, V10_O,\n+    V11, V11_H, V11_J, V11_K, V11_L, V11_M, V11_N, V11_O,\n+    V12, V12_H, V12_J, V12_K, V12_L, V12_M, V12_N, V12_O,\n+    V13, V13_H, V13_J, V13_K, V13_L, V13_M, V13_N, V13_O,\n+    V14, V14_H, V14_J, V14_K, V14_L, V14_M, V14_N, V14_O,\n+    V15, V15_H, V15_J, V15_K, V15_L, V15_M, V15_N, V15_O,\n+    V16, V16_H, V16_J, V16_K, V16_L, V16_M, V16_N, V16_O,\n+    V17, V17_H, V17_J, V17_K, V17_L, V17_M, V17_N, V17_O,\n+    V18, V18_H, V18_J, V18_K, V18_L, V18_M, V18_N, V18_O,\n+    V19, V19_H, V19_J, V19_K, V19_L, V19_M, V19_N, V19_O,\n+    V20, V20_H, V20_J, V20_K, V20_L, V20_M, V20_N, V20_O,\n+    V21, V21_H, V21_J, V21_K, V21_L, V21_M, V21_N, V21_O,\n+    V22, V22_H, V22_J, V22_K, V22_L, V22_M, V22_N, V22_O,\n+    V23, V23_H, V23_J, V23_K, V23_L, V23_M, V23_N, V23_O,\n+    V24, V24_H, V24_J, V24_K, V24_L, V24_M, V24_N, V24_O,\n+    V25, V25_H, V25_J, V25_K, V25_L, V25_M, V25_N, V25_O,\n+    V26, V26_H, V26_J, V26_K, V26_L, V26_M, V26_N, V26_O,\n+    V27, V27_H, V27_J, V27_K, V27_L, V27_M, V27_N, V27_O,\n+    V28, V28_H, V28_J, V28_K, V28_L, V28_M, V28_N, V28_O,\n+    V29, V29_H, V29_J, V29_K, V29_L, V29_M, V29_N, V29_O,\n+    V30, V30_H, V30_J, V30_K, V30_L, V30_M, V30_N, V30_O,\n+    V31, V31_H, V31_J, V31_K, V31_L, V31_M, V31_N, V31_O,\n+);\n+\n@@ -943,0 +1163,33 @@\n+\/\/ Class for all SVE predicate registers.\n+reg_class pr_reg (\n+    P0,\n+    P1,\n+    P2,\n+    P3,\n+    P4,\n+    P5,\n+    P6,\n+    \/\/ P7, non-allocatable, preserved with all elements preset to TRUE.\n+    P8,\n+    P9,\n+    P10,\n+    P11,\n+    P12,\n+    P13,\n+    P14,\n+    P15\n+);\n+\n+\/\/ Class for SVE governing predicate registers, which are used\n+\/\/ to determine the active elements of a predicated instruction.\n+reg_class gov_pr (\n+    P0,\n+    P1,\n+    P2,\n+    P3,\n+    P4,\n+    P5,\n+    P6,\n+    \/\/ P7, non-allocatable, preserved with all elements preset to TRUE.\n+);\n+\n@@ -1647,0 +1900,4 @@\n+  if (UseSVE > 0 && C->max_vector_size() >= 16) {\n+    __ reinitialize_ptrue();\n+  }\n+\n@@ -1745,1 +2002,1 @@\n-enum RC { rc_bad, rc_int, rc_float, rc_stack };\n+enum RC { rc_bad, rc_int, rc_float, rc_predicate, rc_stack };\n@@ -1753,3 +2010,2 @@\n-  \/\/ we have 30 int registers * 2 halves\n-  \/\/ (rscratch1 and rscratch2 are omitted)\n-  int slots_of_int_registers = RegisterImpl::max_slots_per_register * (RegisterImpl::number_of_registers - 2);\n+  \/\/ we have 32 int registers * 2 halves\n+  int slots_of_int_registers = RegisterImpl::max_slots_per_register * RegisterImpl::number_of_registers;\n@@ -1761,2 +2017,3 @@\n-  \/\/ we have 32 float register * 4 halves\n-  if (reg < slots_of_int_registers + FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers) {\n+  \/\/ we have 32 float register * 8 halves\n+  int slots_of_float_registers = FloatRegisterImpl::max_slots_per_register * FloatRegisterImpl::number_of_registers;\n+  if (reg < slots_of_int_registers + slots_of_float_registers) {\n@@ -1766,1 +2023,6 @@\n-  \/\/ Between float regs & stack is the flags regs.\n+  int slots_of_predicate_registers = PRegisterImpl::max_slots_per_register * PRegisterImpl::number_of_registers;\n+  if (reg < slots_of_int_registers + slots_of_float_registers + slots_of_predicate_registers) {\n+    return rc_predicate;\n+  }\n+\n+  \/\/ Between predicate regs & stack is the flags.\n@@ -1805,2 +2067,22 @@\n-    assert(ireg == Op_VecD || ireg == Op_VecX, \"must be 64 bit or 128 bit vector\");\n-    if (cbuf) {\n+    if (ireg == Op_VecA && cbuf) {\n+      C2_MacroAssembler _masm(cbuf);\n+      int sve_vector_reg_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+      if (src_lo_rc == rc_stack && dst_lo_rc == rc_stack) {\n+        \/\/ stack->stack\n+        __ spill_copy_sve_vector_stack_to_stack(src_offset, dst_offset,\n+                                                sve_vector_reg_size_in_bytes);\n+      } else if (src_lo_rc == rc_float && dst_lo_rc == rc_stack) {\n+        __ spill_sve_vector(as_FloatRegister(Matcher::_regEncode[src_lo]), ra_->reg2offset(dst_lo),\n+                            sve_vector_reg_size_in_bytes);\n+      } else if (src_lo_rc == rc_stack && dst_lo_rc == rc_float) {\n+        __ unspill_sve_vector(as_FloatRegister(Matcher::_regEncode[dst_lo]), ra_->reg2offset(src_lo),\n+                              sve_vector_reg_size_in_bytes);\n+      } else if (src_lo_rc == rc_float && dst_lo_rc == rc_float) {\n+        __ sve_orr(as_FloatRegister(Matcher::_regEncode[dst_lo]),\n+                   as_FloatRegister(Matcher::_regEncode[src_lo]),\n+                   as_FloatRegister(Matcher::_regEncode[src_lo]));\n+      } else {\n+        ShouldNotReachHere();\n+      }\n+    } else if (cbuf) {\n+      assert(ireg == Op_VecD || ireg == Op_VecX, \"must be 64 bit or 128 bit vector\");\n@@ -1824,2 +2106,2 @@\n-                       ireg == Op_VecD ? __ D : __ Q,\n-                       ra_->reg2offset(dst_lo));\n+                 ireg == Op_VecD ? __ D : __ Q,\n+                 ra_->reg2offset(dst_lo));\n@@ -1828,2 +2110,2 @@\n-                       ireg == Op_VecD ? __ D : __ Q,\n-                       ra_->reg2offset(src_lo));\n+                   ireg == Op_VecD ? __ D : __ Q,\n+                   ra_->reg2offset(src_lo));\n@@ -1914,1 +2196,16 @@\n-      st->print(\"\\t# vector spill size = %d\", ideal_reg()==Op_VecD ? 64:128);\n+      int vsize = 0;\n+      switch (ideal_reg()) {\n+      case Op_VecD:\n+        vsize = 64;\n+        break;\n+      case Op_VecX:\n+        vsize = 128;\n+        break;\n+      case Op_VecA:\n+        vsize = Matcher::scalable_vector_reg_size(T_BYTE) * 8;\n+        break;\n+      default:\n+        assert(false, \"bad register type for spill\");\n+        ShouldNotReachHere();\n+      }\n+      st->print(\"\\t# vector spill size = %d\", vsize);\n@@ -1916,1 +2213,1 @@\n-      st->print(\"\\t# spill size = %d\", is64 ? 64:32);\n+      st->print(\"\\t# spill size = %d\", is64 ? 64 : 32);\n@@ -2085,5 +2382,11 @@\n-\n-  \/\/ Special cases which require vector length\n-  switch (opcode) {\n-    case Op_MulAddVS2VI: {\n-      if (vlen != 4) {\n+  int bit_size = vlen * type2aelembytes(bt) * 8;\n+  if (UseSVE == 0 && bit_size > 128) {\n+    return false;\n+  }\n+  if (UseSVE > 0) {\n+    return op_sve_supported(opcode);\n+  } else { \/\/ NEON\n+    \/\/ Special cases\n+    switch (opcode) {\n+    case Op_MulAddVS2VI:\n+      if (bit_size < 128) {\n@@ -2093,1 +2396,2 @@\n-    }\n+    case Op_MulVL:\n+      return false;\n@@ -2100,0 +2404,3 @@\n+    default:\n+      break;\n+    }\n@@ -2101,1 +2408,0 @@\n-\n@@ -2106,1 +2412,1 @@\n-  return false;\n+  return UseSVE > 0;\n@@ -2160,1 +2466,2 @@\n-  int size = MIN2(16,(int)MaxVectorSize);\n+  \/\/ The MaxVectorSize should have been set by detecting SVE max vector register size.\n+  int size = MIN2((UseSVE > 0) ? 256 : 16, (int)MaxVectorSize);\n@@ -2174,8 +2481,15 @@\n-  \/\/ Limit the vector size to 8 bytes\n-  int size = 8 \/ type2aelembytes(bt);\n-  if (bt == T_BYTE) {\n-    \/\/ To support vector api shuffle\/rearrange.\n-    size = 4;\n-  } else if (bt == T_BOOLEAN) {\n-    \/\/ To support vector api load\/store mask.\n-    size = 2;\n+  if ((UseSVE > 0) && (MaxVectorSize >= 16)) {\n+    \/\/ Currently vector length less than SVE vector register size is not supported.\n+    return max_size;\n+  } else { \/\/ NEON\n+    \/\/ Limit the vector size to 8 bytes\n+    int size = 8 \/ type2aelembytes(bt);\n+    if (bt == T_BYTE) {\n+      \/\/ To support vector api shuffle\/rearrange.\n+      size = 4;\n+    } else if (bt == T_BOOLEAN) {\n+      \/\/ To support vector api load\/store mask.\n+      size = 2;\n+    }\n+    if (size < 2) size = 2;\n+    return MIN2(size,max_size);\n@@ -2183,2 +2497,9 @@\n-  if (size < 2) size = 2;\n-  return MIN2(size,max_size);\n+}\n+\n+const bool Matcher::supports_scalable_vector() {\n+  return UseSVE > 0;\n+}\n+\n+\/\/ Actual max scalable vector register length.\n+const int Matcher::scalable_vector_reg_size(const BasicType bt) {\n+  return Matcher::max_vector_size(bt);\n@@ -2189,0 +2510,3 @@\n+  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+    return Op_VecA;\n+  }\n@@ -3472,0 +3796,5 @@\n+    } else if (UseSVE > 0 && Compile::current()->max_vector_size() >= 16) {\n+      \/\/ Only non uncommon_trap calls need to reinitialize ptrue.\n+      if (uncommon_trap_request() == 0) {\n+        __ reinitialize_ptrue();\n+      }\n@@ -3482,0 +3811,2 @@\n+    } else if (UseSVE > 0 && Compile::current()->max_vector_size() >= 16) {\n+      __ reinitialize_ptrue();\n@@ -3518,0 +3849,3 @@\n+    if (UseSVE > 0 && Compile::current()->max_vector_size() >= 16) {\n+      __ reinitialize_ptrue();\n+    }\n@@ -3527,0 +3861,5 @@\n+#ifdef ASSERT\n+    if (UseSVE > 0 && Compile::current()->max_vector_size() >= 16) {\n+      __ verify_ptrue();\n+    }\n+#endif\n@@ -4317,0 +4656,35 @@\n+\/\/ 8 bit signed value.\n+operand immI8()\n+%{\n+  predicate(n->get_int() <= 127 && n->get_int() >= -128);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n+\/\/ 8 bit signed value (simm8), or #simm8 LSL 8.\n+operand immI8_shift8()\n+%{\n+  predicate((n->get_int() <= 127 && n->get_int() >= -128) ||\n+            (n->get_int() <= 32512 && n->get_int() >= -32768 && (n->get_int() & 0xff) == 0));\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n+\/\/ 8 bit signed value (simm8), or #simm8 LSL 8.\n+operand immL8_shift8()\n+%{\n+  predicate((n->get_long() <= 127 && n->get_long() >= -128) ||\n+            (n->get_long() <= 32512 && n->get_long() >= -32768 && (n->get_long() & 0xff) == 0));\n+  match(ConL);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4935,0 +5309,12 @@\n+\/\/ Generic vector class. This will be used for\n+\/\/ all vector operands, including NEON and SVE,\n+\/\/ but currently only used for SVE VecA.\n+operand vReg()\n+%{\n+  constraint(ALLOC_IN_RC(vectora_reg));\n+  match(VecA);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n@@ -5243,0 +5629,9 @@\n+operand pRegGov()\n+%{\n+  constraint(ALLOC_IN_RC(gov_pr));\n+  match(RegVMask);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n@@ -13656,0 +14051,71 @@\n+instruct copySignD_reg(vRegD dst, vRegD src1, vRegD src2, vRegD zero) %{\n+  match(Set dst (CopySignD src1 (Binary src2 zero)));\n+  effect(TEMP_DEF dst, USE src1, USE src2, USE zero);\n+  format %{ \"CopySignD  $dst $src1 $src2\" %}\n+  ins_encode %{\n+    FloatRegister dst = as_FloatRegister($dst$$reg),\n+                  src1 = as_FloatRegister($src1$$reg),\n+                  src2 = as_FloatRegister($src2$$reg),\n+                  zero = as_FloatRegister($zero$$reg);\n+    __ fnegd(dst, zero);\n+    __ bsl(dst, __ T8B, src2, src1);\n+  %}\n+  ins_pipe(fp_uop_d);\n+%}\n+\n+instruct copySignF_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (CopySignF src1 src2));\n+  effect(TEMP_DEF dst, USE src1, USE src2);\n+  format %{ \"CopySignF  $dst $src1 $src2\" %}\n+  ins_encode %{\n+    FloatRegister dst = as_FloatRegister($dst$$reg),\n+                  src1 = as_FloatRegister($src1$$reg),\n+                  src2 = as_FloatRegister($src2$$reg);\n+    __ movi(dst, __ T2S, 0x80, 24);\n+    __ bsl(dst, __ T8B, src2, src1);\n+  %}\n+  ins_pipe(fp_uop_d);\n+%}\n+\n+instruct signumD_reg(vRegD dst, vRegD src, vRegD zero, vRegD one) %{\n+  match(Set dst (SignumD src (Binary zero one)));\n+  effect(TEMP_DEF dst, USE src, USE zero, USE one);\n+  format %{ \"signumD  $dst, $src\" %}\n+  ins_encode %{\n+    FloatRegister src = as_FloatRegister($src$$reg),\n+                  dst = as_FloatRegister($dst$$reg),\n+                  zero = as_FloatRegister($zero$$reg),\n+                  one = as_FloatRegister($one$$reg);\n+    __ facgtd(dst, src, zero); \/\/ dst=0 for +-0.0 and NaN. 0xFFF..F otherwise\n+    __ ushrd(dst, dst, 1);     \/\/ dst=0 for +-0.0 and NaN. 0x7FF..F otherwise\n+    \/\/ Bit selection instruction gets bit from \"one\" for each enabled bit in\n+    \/\/ \"dst\", otherwise gets a bit from \"src\". For \"src\" that contains +-0.0 or\n+    \/\/ NaN the whole \"src\" will be copied because \"dst\" is zero. For all other\n+    \/\/ \"src\" values dst is 0x7FF..F, which means only the sign bit is copied\n+    \/\/ from \"src\", and all other bits are copied from 1.0.\n+    __ bsl(dst, __ T8B, one, src);\n+  %}\n+  ins_pipe(fp_uop_d);\n+%}\n+\n+instruct signumF_reg(vRegF dst, vRegF src, vRegF zero, vRegF one) %{\n+  match(Set dst (SignumF src (Binary zero one)));\n+  effect(TEMP_DEF dst, USE src, USE zero, USE one);\n+  format %{ \"signumF  $dst, $src\" %}\n+  ins_encode %{\n+    FloatRegister src = as_FloatRegister($src$$reg),\n+                  dst = as_FloatRegister($dst$$reg),\n+                  zero = as_FloatRegister($zero$$reg),\n+                  one = as_FloatRegister($one$$reg);\n+    __ facgts(dst, src, zero);    \/\/ dst=0 for +-0.0 and NaN. 0xFFF..F otherwise\n+    __ ushr(dst, __ T2S, dst, 1); \/\/ dst=0 for +-0.0 and NaN. 0x7FF..F otherwise\n+    \/\/ Bit selection instruction gets bit from \"one\" for each enabled bit in\n+    \/\/ \"dst\", otherwise gets a bit from \"src\". For \"src\" that contains +-0.0 or\n+    \/\/ NaN the whole \"src\" will be copied because \"dst\" is zero. For all other\n+    \/\/ \"src\" values dst is 0x7FF..F, which means only the sign bit is copied\n+    \/\/ from \"src\", and all other bits are copied from 1.0.\n+    __ bsl(dst, __ T8B, one, src);\n+  %}\n+  ins_pipe(fp_uop_d);\n+%}\n+\n@@ -16168,1 +16634,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 16);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 16);\n@@ -16224,1 +16690,1 @@\n-  predicate(n->as_Vector()->length() == 16);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 16);\n@@ -16249,1 +16715,1 @@\n-  predicate(n->as_Vector()->length() == 16);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 16);\n@@ -16274,1 +16740,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 8);\n@@ -16299,1 +16765,1 @@\n-  predicate(n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 8);\n@@ -16323,1 +16789,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 4);\n@@ -16347,1 +16813,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 4);\n@@ -16359,1 +16825,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -16371,1 +16837,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -16398,1 +16864,1 @@\n-  predicate(n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 4);\n@@ -16411,1 +16877,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":706,"deletions":240,"binary":false,"changes":946,"status":"modified"},{"patch":"@@ -118,0 +118,10 @@\n+  bool use_sve = false;\n+  int sve_vector_size_in_bytes = 0;\n+  int sve_vector_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+  sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+#endif\n+\n@@ -120,0 +130,2 @@\n+    int vect_words = 0;\n+    int extra_save_slots_per_register = 0;\n@@ -121,2 +133,7 @@\n-    int vect_words = FloatRegisterImpl::number_of_registers * FloatRegisterImpl::extra_save_slots_per_register \/\n-                     VMRegImpl::slots_per_word;\n+    if (use_sve) {\n+      extra_save_slots_per_register = sve_vector_size_in_slots - FloatRegisterImpl::save_slots_per_register;\n+    } else {\n+      extra_save_slots_per_register = FloatRegisterImpl::extra_save_slots_per_neon_register;\n+    }\n+    vect_words = FloatRegisterImpl::number_of_registers * extra_save_slots_per_register \/\n+                 VMRegImpl::slots_per_word;\n@@ -141,1 +158,1 @@\n-  __ push_CPU_state(save_vectors);\n+  __ push_CPU_state(save_vectors, use_sve, sve_vector_size_in_bytes);\n@@ -165,2 +182,7 @@\n-    int sp_offset = save_vectors ? (FloatRegisterImpl::max_slots_per_register * i) :\n-                                   (FloatRegisterImpl::save_slots_per_register * i);\n+    int sp_offset = 0;\n+    if (save_vectors) {\n+      sp_offset = use_sve ? (sve_vector_size_in_slots * i) :\n+                            (FloatRegisterImpl::slots_per_neon_register * i);\n+    } else {\n+      sp_offset = FloatRegisterImpl::save_slots_per_register * i;\n+    }\n@@ -175,1 +197,5 @@\n-#if !COMPILER2_OR_JVMCI\n+#ifdef COMPILER2\n+  __ pop_CPU_state(restore_vectors, Matcher::supports_scalable_vector(),\n+                   Matcher::scalable_vector_reg_size(T_BYTE));\n+#else\n+#if !INCLUDE_JVMCI\n@@ -179,0 +205,1 @@\n+#endif\n@@ -1853,0 +1880,5 @@\n+  if (UseSVE > 0) {\n+    \/\/ Make sure that jni code does not change SVE vector length.\n+    __ verify_sve_vector_length();\n+  }\n+\n@@ -2785,0 +2817,6 @@\n+  if (UseSVE > 0 && save_vectors) {\n+    \/\/ Reinitialize the ptrue predicate register, in case the external runtime\n+    \/\/ call clobbers ptrue reg, as we may return to SVE compiled code.\n+    __ reinitialize_ptrue();\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":44,"deletions":6,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -1027,0 +1027,8 @@\n+const bool Matcher::supports_scalable_vector() {\n+  return false;\n+}\n+\n+const int Matcher::scalable_vector_reg_size(const BasicType bt) {\n+  return -1;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2400,0 +2400,8 @@\n+const bool Matcher::supports_scalable_vector() {\n+  return false;\n+}\n+\n+const int Matcher::scalable_vector_reg_size(const BasicType bt) {\n+  return -1;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1631,0 +1631,8 @@\n+const bool Matcher::supports_scalable_vector() {\n+  return false;\n+}\n+\n+const int Matcher::scalable_vector_reg_size(const BasicType bt) {\n+  return -1;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2011, 2019, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2011, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -1880,0 +1880,8 @@\n+const bool Matcher::supports_scalable_vector() {\n+  return false;\n+}\n+\n+const int Matcher::scalable_vector_reg_size(const BasicType bt) {\n+  return -1;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2854,1 +2854,1 @@\n-    assert(ARRAY_SIZE(hi) == _last_machine_leaf - 6, \"missing type\");\n+    assert(ARRAY_SIZE(hi) == _last_machine_leaf - 8, \"missing type\");\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3948,0 +3948,2 @@\n+         strcmp(opType,\"RegVMask\")==0 ||\n+         strcmp(opType,\"VecA\")==0 ||\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -296,0 +296,4 @@\n+macro(CopySignD)\n+macro(CopySignF)\n+macro(SignumD)\n+macro(SignumF)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -91,0 +91,1 @@\n+  idealreg2spillmask  [Op_VecA] = NULL;\n@@ -104,0 +105,1 @@\n+  idealreg2debugmask  [Op_VecA] = NULL;\n@@ -117,0 +119,1 @@\n+  idealreg2mhdebugmask[Op_VecA] = NULL;\n@@ -430,1 +433,1 @@\n-#define NOF_STACK_MASKS (3*11)\n+#define NOF_STACK_MASKS (3*12)\n@@ -466,17 +469,20 @@\n-  idealreg2spillmask  [Op_VecS] = &rms[18];\n-  idealreg2spillmask  [Op_VecD] = &rms[19];\n-  idealreg2spillmask  [Op_VecX] = &rms[20];\n-  idealreg2spillmask  [Op_VecY] = &rms[21];\n-  idealreg2spillmask  [Op_VecZ] = &rms[22];\n-\n-  idealreg2debugmask  [Op_VecS] = &rms[23];\n-  idealreg2debugmask  [Op_VecD] = &rms[24];\n-  idealreg2debugmask  [Op_VecX] = &rms[25];\n-  idealreg2debugmask  [Op_VecY] = &rms[26];\n-  idealreg2debugmask  [Op_VecZ] = &rms[27];\n-\n-  idealreg2mhdebugmask[Op_VecS] = &rms[28];\n-  idealreg2mhdebugmask[Op_VecD] = &rms[29];\n-  idealreg2mhdebugmask[Op_VecX] = &rms[30];\n-  idealreg2mhdebugmask[Op_VecY] = &rms[31];\n-  idealreg2mhdebugmask[Op_VecZ] = &rms[32];\n+  idealreg2spillmask  [Op_VecA] = &rms[18];\n+  idealreg2spillmask  [Op_VecS] = &rms[19];\n+  idealreg2spillmask  [Op_VecD] = &rms[20];\n+  idealreg2spillmask  [Op_VecX] = &rms[21];\n+  idealreg2spillmask  [Op_VecY] = &rms[22];\n+  idealreg2spillmask  [Op_VecZ] = &rms[23];\n+\n+  idealreg2debugmask  [Op_VecA] = &rms[24];\n+  idealreg2debugmask  [Op_VecS] = &rms[25];\n+  idealreg2debugmask  [Op_VecD] = &rms[26];\n+  idealreg2debugmask  [Op_VecX] = &rms[27];\n+  idealreg2debugmask  [Op_VecY] = &rms[28];\n+  idealreg2debugmask  [Op_VecZ] = &rms[29];\n+\n+  idealreg2mhdebugmask[Op_VecA] = &rms[30];\n+  idealreg2mhdebugmask[Op_VecS] = &rms[31];\n+  idealreg2mhdebugmask[Op_VecD] = &rms[32];\n+  idealreg2mhdebugmask[Op_VecX] = &rms[33];\n+  idealreg2mhdebugmask[Op_VecY] = &rms[34];\n+  idealreg2mhdebugmask[Op_VecZ] = &rms[35];\n@@ -509,0 +515,1 @@\n+  RegMask scalable_stack_mask = aligned_stack_mask;\n@@ -594,7 +601,26 @@\n-   if (UseFPUForSpilling) {\n-     \/\/ This mask logic assumes that the spill operations are\n-     \/\/ symmetric and that the registers involved are the same size.\n-     \/\/ On sparc for instance we may have to use 64 bit moves will\n-     \/\/ kill 2 registers when used with F0-F31.\n-     idealreg2spillmask[Op_RegI]->OR(*idealreg2regmask[Op_RegF]);\n-     idealreg2spillmask[Op_RegF]->OR(*idealreg2regmask[Op_RegI]);\n+  if (Matcher::supports_scalable_vector()) {\n+    int k = 1;\n+    OptoReg::Name in = OptoReg::add(_in_arg_limit, -1);\n+    \/\/ Exclude last input arg stack slots to avoid spilling vector register there,\n+    \/\/ otherwise vector spills could stomp over stack slots in caller frame.\n+    for (; (in >= init_in) && (k < scalable_vector_reg_size(T_FLOAT)); k++) {\n+      scalable_stack_mask.Remove(in);\n+      in = OptoReg::add(in, -1);\n+    }\n+\n+    \/\/ For VecA\n+     scalable_stack_mask.clear_to_sets(RegMask::SlotsPerVecA);\n+     assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n+    *idealreg2spillmask[Op_VecA] = *idealreg2regmask[Op_VecA];\n+     idealreg2spillmask[Op_VecA]->OR(scalable_stack_mask);\n+  } else {\n+    *idealreg2spillmask[Op_VecA] = RegMask::Empty;\n+  }\n+\n+  if (UseFPUForSpilling) {\n+    \/\/ This mask logic assumes that the spill operations are\n+    \/\/ symmetric and that the registers involved are the same size.\n+    \/\/ On sparc for instance we may have to use 64 bit moves will\n+    \/\/ kill 2 registers when used with F0-F31.\n+    idealreg2spillmask[Op_RegI]->OR(*idealreg2regmask[Op_RegF]);\n+    idealreg2spillmask[Op_RegF]->OR(*idealreg2regmask[Op_RegI]);\n@@ -602,4 +628,4 @@\n-     idealreg2spillmask[Op_RegN]->OR(*idealreg2regmask[Op_RegF]);\n-     idealreg2spillmask[Op_RegL]->OR(*idealreg2regmask[Op_RegD]);\n-     idealreg2spillmask[Op_RegD]->OR(*idealreg2regmask[Op_RegL]);\n-     idealreg2spillmask[Op_RegP]->OR(*idealreg2regmask[Op_RegD]);\n+    idealreg2spillmask[Op_RegN]->OR(*idealreg2regmask[Op_RegF]);\n+    idealreg2spillmask[Op_RegL]->OR(*idealreg2regmask[Op_RegD]);\n+    idealreg2spillmask[Op_RegD]->OR(*idealreg2regmask[Op_RegL]);\n+    idealreg2spillmask[Op_RegP]->OR(*idealreg2regmask[Op_RegD]);\n@@ -607,1 +633,1 @@\n-     idealreg2spillmask[Op_RegP]->OR(*idealreg2regmask[Op_RegF]);\n+    idealreg2spillmask[Op_RegP]->OR(*idealreg2regmask[Op_RegF]);\n@@ -609,4 +635,4 @@\n-     \/\/ ARM has support for moving 64bit values between a pair of\n-     \/\/ integer registers and a double register\n-     idealreg2spillmask[Op_RegL]->OR(*idealreg2regmask[Op_RegD]);\n-     idealreg2spillmask[Op_RegD]->OR(*idealreg2regmask[Op_RegL]);\n+    \/\/ ARM has support for moving 64bit values between a pair of\n+    \/\/ integer registers and a double register\n+    idealreg2spillmask[Op_RegL]->OR(*idealreg2regmask[Op_RegD]);\n+    idealreg2spillmask[Op_RegD]->OR(*idealreg2regmask[Op_RegL]);\n@@ -615,1 +641,1 @@\n-   }\n+  }\n@@ -627,0 +653,1 @@\n+  *idealreg2debugmask  [Op_VecA] = *idealreg2spillmask[Op_VecA];\n@@ -640,0 +667,1 @@\n+  *idealreg2mhdebugmask[Op_VecA] = *idealreg2spillmask[Op_VecA];\n@@ -659,0 +687,1 @@\n+  idealreg2debugmask[Op_VecA]->SUBTRACT(*caller_save_mask);\n@@ -672,0 +701,1 @@\n+  idealreg2mhdebugmask[Op_VecA]->SUBTRACT(*mh_caller_save_mask);\n@@ -932,0 +962,1 @@\n+  idealreg2regmask[Op_VecA] = regmask_for_ideal_register(Op_VecA, ret);\n@@ -1628,1 +1659,0 @@\n-\n@@ -2337,0 +2367,17 @@\n+    case Op_MulAddS2I: {\n+      Node* pair1 = new BinaryNode(n->in(1), n->in(2));\n+      Node* pair2 = new BinaryNode(n->in(3), n->in(4));\n+      n->set_req(1, pair1);\n+      n->set_req(2, pair2);\n+      n->del_req(4);\n+      n->del_req(3);\n+      break;\n+    }\n+    case Op_CopySignD:\n+    case Op_SignumF:\n+    case Op_SignumD: {\n+      Node* pair = new BinaryNode(n->in(2), n->in(3));\n+      n->set_req(2, pair);\n+      n->del_req(3);\n+      break;\n+    }\n@@ -2351,9 +2398,0 @@\n-    case Op_MulAddS2I: {\n-      Node* pair1 = new BinaryNode(n->in(1), n->in(2));\n-      Node* pair2 = new BinaryNode(n->in(3), n->in(4));\n-      n->set_req(1, pair1);\n-      n->set_req(2, pair2);\n-      n->del_req(4);\n-      n->del_req(3);\n-      break;\n-    }\n@@ -2365,1 +2403,0 @@\n-    }\n@@ -2368,0 +2405,1 @@\n+    }\n@@ -2497,1 +2535,1 @@\n-    assert(ideal_reg >= Op_VecS && ideal_reg <= Op_VecZ, \"not a vector: %d\", ideal_reg);\n+    assert(ideal_reg >= Op_VecA && ideal_reg <= Op_VecZ, \"not a vector: %d\", ideal_reg);\n@@ -2514,0 +2552,1 @@\n+    case Op_VecA: \/\/ fall-through\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":86,"deletions":47,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -341,0 +341,4 @@\n+  static const bool supports_scalable_vector();\n+  \/\/ Actual max scalable vector register length.\n+  static const int scalable_vector_reg_size(const BasicType bt);\n+\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1853,0 +1853,4 @@\n+  declare_c2_type(CopySignDNode, Node)                                    \\\n+  declare_c2_type(CopySignFNode, Node)                                    \\\n+  declare_c2_type(SignumDNode, Node)                                      \\\n+  declare_c2_type(SignumFNode, Node)                                      \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}