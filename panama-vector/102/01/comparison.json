{"files":[{"patch":"@@ -2086,1 +2086,1 @@\n-  if (src_hi != OptoReg::Bad) {\n+  if (src_hi != OptoReg::Bad && !bottom_type()->isa_vectmask()) {\n@@ -2101,1 +2101,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -2207,0 +2207,3 @@\n+      } else if (dst_lo_rc == rc_predicate) {\n+        __ unspill_sve_predicate(as_PRegister(Matcher::_regEncode[dst_lo]), ra_->reg2offset(src_lo),\n+                                 Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n@@ -2209,2 +2212,18 @@\n-        __ unspill(rscratch1, is64, src_offset);\n-        __ spill(rscratch1, is64, dst_offset);\n+        if (ideal_reg() == Op_RegVectMask) {\n+          __ spill_copy_sve_predicate_stack_to_stack(src_offset, dst_offset,\n+                                                     Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n+        } else {\n+          __ unspill(rscratch1, is64, src_offset);\n+          __ spill(rscratch1, is64, dst_offset);\n+        }\n+      }\n+      break;\n+    case rc_predicate:\n+      if (dst_lo_rc == rc_predicate) {\n+        __ sve_mov(as_PRegister(Matcher::_regEncode[dst_lo]), as_PRegister(Matcher::_regEncode[src_lo]));\n+      } else if (dst_lo_rc == rc_stack) {\n+        __ spill_sve_predicate(as_PRegister(Matcher::_regEncode[src_lo]), ra_->reg2offset(dst_lo),\n+                               Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n+      } else {\n+        assert(false, \"bad src and dst rc_class combination.\");\n+        ShouldNotReachHere();\n@@ -2231,1 +2250,1 @@\n-    if (bottom_type()->isa_vect() != NULL) {\n+    if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -2248,0 +2267,4 @@\n+    } else if (ideal_reg() == Op_RegVectMask) {\n+      assert(Matcher::supports_scalable_vector(), \"bad register type for spill\");\n+      int vsize = Matcher::scalable_predicate_reg_slots() * 32;\n+      st->print(\"\\t# predicate spill size = %d\", vsize);\n@@ -2475,0 +2498,4 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":32,"deletions":5,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -3225,0 +3225,21 @@\n+\/\/ SVE load\/store predicate register\n+#define INSN(NAME, op1)                                                  \\\n+  void NAME(PRegister Pt, const Address &a)  {                           \\\n+    starti;                                                              \\\n+    assert(a.index() == noreg, \"invalid address variant\");               \\\n+    f(op1, 31, 29), f(0b0010110, 28, 22), sf(a.offset() >> 3, 21, 16),   \\\n+    f(0b000, 15, 13), f(a.offset() & 0x7, 12, 10), srf(a.base(), 5),     \\\n+    f(0, 4), prf(Pt, 0);                                                 \\\n+  }\n+\n+  INSN(sve_ldr, 0b100); \/\/ LDR (predicate)\n+  INSN(sve_str, 0b111); \/\/ STR (predicate)\n+#undef INSN\n+\n+  \/\/ SVE move predicate register\n+  void sve_mov(PRegister Pd, PRegister Pn) {\n+    starti;\n+    f(0b001001011000, 31, 20), prf(Pn, 16), f(0b01, 15, 14), prf(Pn, 10);\n+    f(0, 9), prf(Pn, 5), f(0, 4), prf(Pd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -318,0 +318,1 @@\n+  PRegSet               _p_regs;\n@@ -331,0 +332,2 @@\n+        } else if (vm_reg->is_PRegister()) {\n+          _p_regs += PRegSet::of(vm_reg->as_PRegister());\n@@ -344,1 +347,2 @@\n-      _fp_regs() {\n+      _fp_regs(),\n+      _p_regs() {\n@@ -352,0 +356,1 @@\n+    __ push_p(_p_regs, sp);\n@@ -356,0 +361,1 @@\n+    __ pop_p(_p_regs, sp);\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2048,0 +2048,76 @@\n+\/\/ Return the number of dwords pushed\n+int MacroAssembler::push_p(unsigned int bitset, Register stack) {\n+  bool use_sve = false;\n+  int sve_predicate_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  if (use_sve) {\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n+#endif\n+\n+  if (!use_sve) {\n+    return 0;\n+  }\n+\n+  const int num_of_regs = PRegisterImpl::number_of_saved_registers;\n+  unsigned char regs[num_of_regs];\n+  int count = 0;\n+  for (int reg = 0; reg < num_of_regs; reg++) {\n+    if (1 & bitset)\n+      regs[count++] = reg;\n+    bitset >>= 1;\n+  }\n+\n+  if (count == 0) {\n+    return 0;\n+  }\n+\n+  int total_push_bytes = align_up(sve_predicate_size_in_slots *\n+                                  VMRegImpl::stack_slot_size * count, 16);\n+  sub(stack, stack, total_push_bytes);\n+  for (int i = 0; i < count; i++) {\n+    sve_str(as_PRegister(regs[i]), Address(stack, i));\n+  }\n+  return total_push_bytes \/ 8;\n+}\n+\n+\/\/ Return the number of dwords poped\n+int MacroAssembler::pop_p(unsigned int bitset, Register stack) {\n+  bool use_sve = false;\n+  int sve_predicate_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  if (use_sve) {\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n+#endif\n+\n+  if (!use_sve) {\n+    return 0;\n+  }\n+\n+  const int num_of_regs = PRegisterImpl::number_of_saved_registers;\n+  unsigned char regs[num_of_regs];\n+  int count = 0;\n+  for (int reg = 0; reg < num_of_regs; reg++) {\n+    if (1 & bitset)\n+      regs[count++] = reg;\n+    bitset >>= 1;\n+  }\n+\n+  if (count == 0) {\n+    return 0;\n+  }\n+\n+  int total_pop_bytes = align_up(sve_predicate_size_in_slots *\n+                                 VMRegImpl::stack_slot_size * count, 16);\n+  for (int i = count - 1; i >= 0; i--) {\n+    sve_ldr(as_PRegister(regs[i]), Address(stack, i));\n+  }\n+  add(stack, stack, total_pop_bytes);\n+  return total_pop_bytes \/ 8;\n+}\n+\n@@ -2506,1 +2582,1 @@\n-                                    int sve_vector_size_in_bytes) {\n+                                    int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n@@ -2523,0 +2599,6 @@\n+  if (save_vectors && use_sve && total_predicate_in_bytes > 0) {\n+    sub(sp, sp, total_predicate_in_bytes);\n+    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n+      sve_str(as_PRegister(i), Address(sp, i));\n+    }\n+  }\n@@ -2526,1 +2608,7 @@\n-                                   int sve_vector_size_in_bytes) {\n+                                   int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n+  if (restore_vectors && use_sve && total_predicate_in_bytes > 0) {\n+    for (int i = PRegisterImpl::number_of_saved_registers - 1; i >= 0; i--) {\n+      sve_ldr(as_PRegister(i), Address(sp, i));\n+    }\n+    add(sp, sp, total_predicate_in_bytes);\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":90,"deletions":2,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -458,0 +458,3 @@\n+  int push_p(unsigned int bitset, Register stack);\n+  int pop_p(unsigned int bitset, Register stack);\n+\n@@ -469,0 +472,3 @@\n+  void push_p(PRegSet regs, Register stack) { if (regs.bits()) push_p(regs.bits(), stack); }\n+  void pop_p(PRegSet regs, Register stack) { if (regs.bits()) pop_p(regs.bits(), stack); }\n+\n@@ -868,1 +874,1 @@\n-                      int sve_vector_size_in_bytes = 0);\n+                      int sve_vector_size_in_bytes = 0, int total_predicate_in_bytes = 0);\n@@ -870,1 +876,1 @@\n-                      int sve_vector_size_in_bytes = 0);\n+                     int sve_vector_size_in_bytes = 0, int total_predicate_in_bytes = 0);\n@@ -1343,0 +1349,1 @@\n+\n@@ -1346,0 +1353,4 @@\n+  void spill_sve_predicate(PRegister pr, int offset, int predicate_reg_size_in_bytes) {\n+    sve_str(pr, sve_spill_address(predicate_reg_size_in_bytes, offset));\n+  }\n+\n@@ -1356,0 +1367,1 @@\n+\n@@ -1359,0 +1371,4 @@\n+  void unspill_sve_predicate(PRegister pr, int offset, int predicate_reg_size_in_bytes) {\n+    sve_ldr(pr, sve_spill_address(predicate_reg_size_in_bytes, offset));\n+  }\n+\n@@ -1381,0 +1397,6 @@\n+  void spill_copy_sve_predicate_stack_to_stack(int src_offset, int dst_offset,\n+                                               int sve_predicate_reg_size_in_bytes) {\n+    sve_ldr(ptrue, sve_spill_address(sve_predicate_reg_size_in_bytes, src_offset));\n+    sve_str(ptrue, sve_spill_address(sve_predicate_reg_size_in_bytes, dst_offset));\n+    reinitialize_ptrue();\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":24,"deletions":2,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n@@ -37,1 +37,2 @@\n-  = ConcreteRegisterImpl::max_fpr + PRegisterImpl::number_of_registers;\n+  = ConcreteRegisterImpl::max_fpr +\n+    PRegisterImpl::number_of_registers * PRegisterImpl::max_slots_per_register;\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n@@ -246,0 +246,4 @@\n+    \/\/ AArch64 has 8 governing predicate registers, but p7 is used as an\n+    \/\/ all-1s register so the predicates to save are from p0 to p6 if we\n+    \/\/ don't have non-governing predicate registers support.\n+    number_of_saved_registers = number_of_governing_registers - 1,\n@@ -380,0 +384,1 @@\n+typedef AbstractRegSet<PRegister> PRegSet;\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -104,1 +104,4 @@\n-  int v0_offset_in_bytes(void)   { return 0; }\n+  int v0_offset_in_bytes();\n+\n+  \/\/ Total stack size in bytes for saving sve predicate registers.\n+  int total_sve_predicate_in_bytes();\n@@ -142,1 +145,1 @@\n-  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  int r0_offset = v0_offset_in_bytes() + (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n@@ -146,0 +149,20 @@\n+int RegisterSaver::v0_offset_in_bytes() {\n+  \/\/ The floating point registers are located above the predicate registers if\n+  \/\/ they are present in the stack frame pushed by save_live_registers(). So the\n+  \/\/ offset depends on the saved total predicate vectors in the stack frame.\n+  return (total_sve_predicate_in_bytes() \/ VMRegImpl::stack_slot_size) * BytesPerInt;\n+}\n+\n+int RegisterSaver::total_sve_predicate_in_bytes() {\n+#if COMPILER2\n+  if (_save_vectors && Matcher::supports_scalable_vector()) {\n+    \/\/ The number of total predicate bytes is unlikely to be a multiple\n+    \/\/ of 16 bytes so we manually align it up.\n+    return align_up(Matcher::scalable_predicate_reg_slots() *\n+                    VMRegImpl::stack_slot_size *\n+                    PRegisterImpl::number_of_saved_registers, 16);\n+  }\n+#endif\n+  return 0;\n+}\n+\n@@ -150,0 +173,3 @@\n+  int sve_predicate_size_in_slots = 0;\n+  int total_predicate_in_bytes = total_sve_predicate_in_bytes();\n+  int total_predicate_in_slots = total_predicate_in_bytes \/ VMRegImpl::stack_slot_size;\n@@ -153,2 +179,5 @@\n-  sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n-  sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+  if (use_sve) {\n+    sve_vector_size_in_bytes = Matcher::scalable_vector_reg_size(T_BYTE);\n+    sve_vector_size_in_slots = Matcher::scalable_vector_reg_size(T_FLOAT);\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n@@ -159,1 +188,0 @@\n-    int vect_words = 0;\n@@ -167,3 +195,4 @@\n-    vect_words = FloatRegisterImpl::number_of_registers * extra_save_slots_per_register \/\n-                 VMRegImpl::slots_per_word;\n-    additional_frame_words += vect_words;\n+    int extra_vector_bytes = extra_save_slots_per_register *\n+                             VMRegImpl::stack_slot_size *\n+                             FloatRegisterImpl::number_of_registers;\n+    additional_frame_words += ((extra_vector_bytes + total_predicate_in_bytes) \/ wordSize);\n@@ -187,1 +216,1 @@\n-  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes, total_predicate_in_bytes);\n@@ -204,2 +233,1 @@\n-      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots),\n-                                r->as_VMReg());\n+      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset + additional_frame_slots), r->as_VMReg());\n@@ -213,1 +241,1 @@\n-      sp_offset = use_sve ? (sve_vector_size_in_slots * i) :\n+      sp_offset = use_sve ? (total_predicate_in_slots + sve_vector_size_in_slots * i) :\n@@ -218,2 +246,9 @@\n-    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset),\n-                              r->as_VMReg());\n+    oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n+  }\n+\n+  if (_save_vectors && use_sve) {\n+    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n+      PRegister r = as_PRegister(i);\n+      int sp_offset = sve_predicate_size_in_slots * i;\n+      oop_map->set_callee_saved(VMRegImpl::stack2reg(sp_offset), r->as_VMReg());\n+    }\n@@ -228,1 +263,1 @@\n-                   Matcher::scalable_vector_reg_size(T_BYTE));\n+                   Matcher::scalable_vector_reg_size(T_BYTE), total_sve_predicate_in_bytes());\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":50,"deletions":15,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -42,2 +42,1 @@\n-  assert( is_Register(), \"must be\");\n-  \/\/ Yuk\n+  assert(is_Register(), \"must be\");\n@@ -48,2 +47,1 @@\n-  assert( is_FloatRegister() && is_even(value()), \"must be\" );\n-  \/\/ Yuk\n+  assert(is_FloatRegister() && is_even(value()), \"must be\");\n@@ -55,1 +53,1 @@\n-  assert( is_PRegister(), \"must be\" );\n+  assert(is_PRegister(), \"must be\");\n","filename":"src\/hotspot\/cpu\/aarch64\/vmreg_aarch64.hpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -986,0 +986,4 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2180,0 +2180,4 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1539,0 +1539,4 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1847,0 +1847,4 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2012, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -272,0 +272,1 @@\n+  if( strcmp(opType,\"LoadVectorGatherMasked\")==0 )  return Form::idealV;\n@@ -273,0 +274,1 @@\n+  if( strcmp(opType,\"LoadVectorMask\")==0 )  return Form::idealV;\n@@ -290,0 +292,1 @@\n+  if( strcmp(opType,\"StoreVectorScatterMasked\")==0 )  return Form::idealV;\n@@ -291,0 +294,1 @@\n+  if( strcmp(opType,\"StoreVectorMask\")==0 )  return Form::idealV;\n","filename":"src\/hotspot\/share\/adlc\/forms.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2284,0 +2284,1 @@\n+  if (strcmp(name, \"RegVectMask\") == 0) size = globalAD->get_preproc_def(\"AARCH64\") ? 1 : 2;\n@@ -3517,1 +3518,3 @@\n-    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n+    \"StoreVector\", \"LoadVector\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n+    \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorGatherMasked\", \"StoreVectorScatterMasked\",\n+    \"LoadVectorMask\", \"StoreVectorMask\",\n@@ -3821,1 +3824,1 @@\n-\/\/-------------------------- has_commutative_op -------------------------------\n+\/\/-------------------------- count_commutative_op -------------------------------\n@@ -3827,1 +3830,0 @@\n-    \"AddVB\",\"AddVS\",\"AddVI\",\"AddVL\",\"AddVF\",\"AddVD\",\n@@ -3829,1 +3831,0 @@\n-    \"AndV\",\n@@ -3831,1 +3832,0 @@\n-    \"MaxV\", \"MinV\",\n@@ -3833,1 +3833,0 @@\n-    \"MulVB\",\"MulVS\",\"MulVI\",\"MulVL\",\"MulVF\",\"MulVD\",\n@@ -3835,3 +3834,1 @@\n-    \"OrV\",\n-    \"XorI\",\"XorL\",\n-    \"XorV\"\n+    \"XorI\",\"XorL\"\n@@ -3839,1 +3836,0 @@\n-  int cnt = sizeof(commut_op_list)\/sizeof(char*);\n@@ -3841,1 +3837,8 @@\n-  if( _lChild && _rChild && (_lChild->_lChild || _rChild->_lChild) ) {\n+  static const char *commut_vector_op_list[] = {\n+    \"AddVB\", \"AddVS\", \"AddVI\", \"AddVL\", \"AddVF\", \"AddVD\",\n+    \"MulVB\", \"MulVS\", \"MulVI\", \"MulVL\", \"MulVF\", \"MulVD\",\n+    \"AndV\", \"OrV\", \"XorV\",\n+    \"MaxV\", \"MinV\"\n+  };\n+\n+  if (_lChild && _rChild && (_lChild->_lChild || _rChild->_lChild)) {\n@@ -3844,1 +3847,1 @@\n-    if( _rChild->_lChild == NULL && _rChild->_rChild == NULL ) {\n+    if (_rChild->_lChild == NULL && _rChild->_rChild == NULL) {\n@@ -3847,3 +3850,3 @@\n-      if ( form ) {\n-        OperandForm  *oper = form->is_operand();\n-        if( oper && oper->interface_type(globals) == Form::constant_interface )\n+      if (form) {\n+        OperandForm *oper = form->is_operand();\n+        if (oper && oper->interface_type(globals) == Form::constant_interface)\n@@ -3853,5 +3856,19 @@\n-    if( !is_const ) {\n-      for( int i=0; i<cnt; i++ ) {\n-        if( strcmp(_opType, commut_op_list[i]) == 0 ) {\n-          count++;\n-          _commutative_id = count; \/\/ id should be > 0\n+\n+    if (!is_const) {\n+      int scalar_cnt = sizeof(commut_op_list)\/sizeof(char*);\n+      int vector_cnt = sizeof(commut_vector_op_list)\/sizeof(char*);\n+      bool matched = false;\n+\n+      \/\/ Check the commutative vector op first. It's noncommutative if\n+      \/\/ the current node is a masked vector op, since a mask value\n+      \/\/ is added to the original vector node's input list and the original\n+      \/\/ first two inputs are packed into one BinaryNode. So don't swap\n+      \/\/ if one of the operands is a BinaryNode.\n+      for (int i = 0; i < vector_cnt; i++) {\n+        if (strcmp(_opType, commut_vector_op_list[i]) == 0) {\n+          if (strcmp(_lChild->_opType, \"Binary\") != 0 &&\n+              strcmp(_rChild->_opType, \"Binary\") != 0) {\n+            count++;\n+            _commutative_id = count; \/\/ id should be > 0\n+          }\n+          matched = true;\n@@ -3861,0 +3878,12 @@\n+\n+      \/\/ Then check the scalar op if the current op is not in\n+      \/\/ the commut_vector_op_list.\n+      if (!matched) {\n+        for (int i = 0; i < scalar_cnt; i++) {\n+          if (strcmp(_opType, commut_op_list[i]) == 0) {\n+            count++;\n+            _commutative_id = count; \/\/ id should be > 0\n+            break;\n+          }\n+        }\n+      }\n@@ -3863,1 +3892,1 @@\n-  if( _lChild )\n+  if (_lChild)\n@@ -3865,1 +3894,1 @@\n-  if( _rChild )\n+  if (_rChild)\n@@ -4091,0 +4120,1 @@\n+        strcmp(opType,\"MaskAll\")==0 ||\n@@ -4202,1 +4232,1 @@\n-    \"LoadVectorGather\", \"StoreVectorScatter\",\n+    \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorGatherMasked\", \"StoreVectorScatterMasked\",\n@@ -4209,0 +4239,3 @@\n+    \"LoadVectorMask\", \"StoreVectorMask\",\n+    \/\/ Next are vector mask ops.\n+    \"MaskAll\", \"AndVMask\", \"OrVMask\", \"XorVMask\", \"VectorMaskCast\",\n@@ -4211,2 +4244,1 @@\n-    \"ExtractB\",\"ExtractUB\",\"ExtractC\",\"ExtractS\",\"ExtractI\",\"ExtractL\",\"ExtractF\",\"ExtractD\",\n-    \"VectorMaskCast\"\n+    \"ExtractB\",\"ExtractUB\",\"ExtractC\",\"ExtractS\",\"ExtractI\",\"ExtractL\",\"ExtractF\",\"ExtractD\"\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":57,"deletions":25,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -812,1 +812,2 @@\n-   do_signature(vector_unary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/util\/function\/Function;)Ljava\/lang\/Object;\") \\\n+   do_signature(vector_unary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"              \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$UnaryOperation;)Ljava\/lang\/Object;\")                              \\\n@@ -816,2 +817,2 @@\n-   do_signature(vector_binary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                              \\\n-                                       \"Ljava\/util\/function\/BiFunction;)Ljava\/lang\/Object;\")                                                   \\\n+   do_signature(vector_binary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"             \\\n+                                       \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$BinaryOperation;)Ljava\/lang\/Object;\")          \\\n@@ -821,1 +822,1 @@\n-   do_signature(vector_ternary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                             \\\n+   do_signature(vector_ternary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/lang\/Object;\" \\\n@@ -845,0 +846,6 @@\n+  do_intrinsic(_VectorLoadMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_load_masked_op_name, vector_load_masked_op_sig, F_S)          \\\n+   do_signature(vector_load_masked_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\" \\\n+                                            \"Ljava\/lang\/Object;ILjdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                          \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$LoadVectorMaskedOperation;)Ljava\/lang\/Object;\")             \\\n+   do_name(vector_load_masked_op_name,     \"loadMasked\")                                                                                       \\\n+                                                                                                                                               \\\n@@ -850,2 +857,9 @@\n-  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S) \\\n-   do_signature(vector_reduction_coerced_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljava\/util\/function\/Function;)J\") \\\n+  do_intrinsic(_VectorStoreMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_store_masked_op_name, vector_store_masked_op_sig, F_S)       \\\n+   do_signature(vector_store_masked_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjdk\/internal\/vm\/vector\/VectorSupport$Vector;\"  \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;Ljava\/lang\/Object;I\"                            \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorMaskedOperation;)V\")                            \\\n+   do_name(vector_store_masked_op_name,     \"storeMasked\")                                                                                     \\\n+                                                                                                                                               \\\n+  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S)\\\n+   do_signature(vector_reduction_coerced_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"     \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$ReductionOperation;)J\")                                  \\\n@@ -889,2 +903,2 @@\n-   do_signature(vector_broadcast_int_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;I\"                                                              \\\n-                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;I\"                                                    \\\n+   do_signature(vector_broadcast_int_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                             \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;ILjava\/lang\/Object;\"                                  \\\n@@ -903,1 +917,1 @@\n-    do_signature(vector_gather_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                                    \\\n+    do_signature(vector_gather_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                   \\\n@@ -906,1 +920,1 @@\n-                                     \"Ljava\/lang\/Object;I[II\"                                                                                  \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;Ljava\/lang\/Object;I[II\"                                 \\\n@@ -913,1 +927,1 @@\n-    do_signature(vector_scatter_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                                   \\\n+    do_signature(vector_scatter_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                  \\\n@@ -916,1 +930,1 @@\n-                                      \"Ljava\/lang\/Object;I[II\"                                                                                 \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;Ljava\/lang\/Object;I[II\"                                \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":26,"deletions":12,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -681,0 +681,1 @@\n+  case vmIntrinsics::_VectorLoadMaskedOp:\n@@ -682,0 +683,1 @@\n+  case vmIntrinsics::_VectorStoreMaskedOp:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -80,0 +80,1 @@\n+  if( _is_predicate ) tty->print(\"Predicate \");\n@@ -641,1 +642,2 @@\n-      } else if (lrg.num_regs() == 1) {\n+      } else if ((lrg.num_regs() == 1 && !lrg.is_scalable()) ||\n+                 (lrg.is_scalable() && lrg.scalable_reg_slots() == 1)) {\n@@ -657,1 +659,1 @@\n-          \/\/ We have to use pair [lo,lo+1] even for wide vectors because\n+          \/\/ We have to use pair [lo,lo+1] even for wide vectors\/vmasks because\n@@ -827,0 +829,14 @@\n+\n+        if (ireg == Op_RegVectMask) {\n+          assert(Matcher::has_predicated_vectors(), \"predicated vector should be supported\");\n+          lrg._is_predicate = 1;\n+          if (Matcher::supports_scalable_vector()) {\n+            lrg._is_scalable = 1;\n+            \/\/ For scalable predicate, when it is allocated in physical register,\n+            \/\/ num_regs is RegMask::SlotsPerRegVectMask for reg mask,\n+            \/\/ which may not be the actual physical register size.\n+            \/\/ If it is allocated in stack, we need to get the actual\n+            \/\/ physical length of scalable predicate register.\n+            lrg.set_scalable_reg_slots(Matcher::scalable_predicate_reg_slots());\n+          }\n+        }\n@@ -828,1 +844,1 @@\n-               ireg == Op_RegD || ireg == Op_RegL  || ireg == Op_RegVectMask,\n+               ireg == Op_RegD || ireg == Op_RegL || ireg == Op_RegVectMask,\n@@ -922,0 +938,2 @@\n+          assert(Matcher::has_predicated_vectors(), \"sanity\");\n+          assert(RegMask::num_registers(Op_RegVectMask) == RegMask::SlotsPerRegVectMask, \"sanity\");\n@@ -1374,0 +1392,5 @@\n+    } else if (lrg._is_predicate) {\n+      assert(num_regs == RegMask::SlotsPerRegVectMask, \"scalable predicate register\");\n+      num_regs = lrg.scalable_reg_slots();\n+      mask.clear_to_sets(num_regs);\n+      return mask.find_first_set(lrg, num_regs);\n@@ -1420,1 +1443,1 @@\n-  if (lrg._is_vector || lrg.num_regs() == 2) {\n+  if (lrg._is_vector || lrg.num_regs() == 2 || lrg.is_scalable()) {\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":27,"deletions":4,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -166,2 +166,2 @@\n-      \/\/ Should only be a vector for now, but it could also be a RegVectMask in future.\n-      assert(_is_vector && (_num_regs == RegMask::SlotsPerVecA), \"unexpected scalable reg\");\n+      assert(_is_vector && (_num_regs == RegMask::SlotsPerVecA) ||\n+             _is_predicate && (_num_regs == RegMask::SlotsPerRegVectMask), \"unexpected scalable reg\");\n@@ -198,0 +198,1 @@\n+         _is_predicate:1,       \/\/ True if in mask\/predicate registers\n","filename":"src\/hotspot\/share\/opto\/chaitin.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -416,0 +416,1 @@\n+macro(LoadVectorGatherMasked)\n@@ -418,0 +419,2 @@\n+macro(StoreVectorScatterMasked)\n+macro(LoadVectorMask)\n@@ -419,0 +422,1 @@\n+macro(StoreVectorMask)\n@@ -476,0 +480,4 @@\n+macro(MaskAll)\n+macro(AndVMask)\n+macro(OrVMask)\n+macro(XorVMask)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -3425,0 +3425,2 @@\n+  case Op_LoadVectorGatherMasked:\n+  case Op_StoreVectorScatterMasked:\n@@ -3427,0 +3429,2 @@\n+  case Op_LoadVectorMask:\n+  case Op_StoreVectorMask:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -705,1 +705,1 @@\n-        case Op_StoreVectorScatter:\n+        case Op_StoreVectorMask:\n@@ -707,0 +707,2 @@\n+        case Op_StoreVectorScatter:\n+        case Op_StoreVectorScatterMasked:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -650,0 +650,2 @@\n+  case vmIntrinsics::_VectorLoadMaskedOp:\n+    return inline_vector_mem_masked_operation(\/*is_store*\/false);\n@@ -652,0 +654,2 @@\n+  case vmIntrinsics::_VectorStoreMaskedOp:\n+    return inline_vector_mem_masked_operation(\/*is_store=*\/true);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -319,0 +319,1 @@\n+  bool inline_vector_mem_masked_operation(bool is_store);\n@@ -332,4 +333,5 @@\n-    VecMaskUseLoad,\n-    VecMaskUseStore,\n-    VecMaskUseAll,\n-    VecMaskNotUsed\n+    VecMaskUseLoad  = 1 << 0,\n+    VecMaskUseStore = 1 << 1,\n+    VecMaskUseAll   = VecMaskUseLoad | VecMaskUseStore,\n+    VecMaskUsePred  = 1 << 2,\n+    VecMaskNotUsed  = 1 << 3\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -437,0 +437,18 @@\n+const int Matcher::scalable_predicate_reg_slots() {\n+  assert(Matcher::has_predicated_vectors() && Matcher::supports_scalable_vector(),\n+        \"scalable predicate vector should be supported\");\n+  int vector_reg_bit_size = Matcher::scalable_vector_reg_size(T_BYTE) << LogBitsPerByte;\n+  \/\/ We assume each predicate register is one-eighth of the size of\n+  \/\/ scalable vector register, one mask bit per vector byte.\n+  int predicate_reg_bit_size = vector_reg_bit_size >> 3;\n+  \/\/ Compute number of slots which is required when scalable predicate\n+  \/\/ register is spilled. E.g. if scalable vector register is 640 bits,\n+  \/\/ predicate register is 80 bits, which is 2.5 * slots.\n+  \/\/ We will round up the slot number to power of 2, which is required\n+  \/\/ by find_first_set().\n+  int slots = predicate_reg_bit_size & (BitsPerInt - 1)\n+              ? (predicate_reg_bit_size >> LogBitsPerInt) + 1\n+              : predicate_reg_bit_size >> LogBitsPerInt;\n+  return round_up_power_of_2(slots);\n+}\n+\n@@ -545,0 +563,2 @@\n+  } else {\n+    *idealreg2spillmask[Op_RegVectMask] = RegMask::Empty;\n@@ -617,0 +637,12 @@\n+    \/\/ Exclude last input arg stack slots to avoid spilling vector register there,\n+    \/\/ otherwise RegVectMask spills could stomp over stack slots in caller frame.\n+    for (; (in >= init_in) && (k < scalable_predicate_reg_slots()); k++) {\n+      scalable_stack_mask.Remove(in);\n+      in = OptoReg::add(in, -1);\n+    }\n+\n+    \/\/ For RegVectMask\n+    scalable_stack_mask.clear_to_sets(scalable_predicate_reg_slots());\n+    assert(scalable_stack_mask.is_AllStack(), \"should be infinite stack\");\n+    idealreg2spillmask[Op_RegVectMask]->OR(scalable_stack_mask);\n+\n@@ -2276,0 +2308,15 @@\n+  if (n->is_predicated_vector()) {\n+    \/\/ Restructure into binary trees for Matching.\n+    if (n->req() == 4) {\n+      n->set_req(1, new BinaryNode(n->in(1), n->in(2)));\n+      n->set_req(2, n->in(3));\n+      n->del_req(3);\n+    } else if (n->req() == 5) {\n+      n->set_req(1, new BinaryNode(n->in(1), n->in(2)));\n+      n->set_req(2, new BinaryNode(n->in(3), n->in(4)));\n+      n->del_req(4);\n+      n->del_req(3);\n+    }\n+    return;\n+  }\n+\n@@ -2415,0 +2462,1 @@\n+    case Op_LoadVectorGatherMasked:\n@@ -2421,0 +2469,9 @@\n+    case Op_StoreVectorScatterMasked: {\n+      Node* pair = new BinaryNode(n->in(MemNode::ValueIn+1), n->in(MemNode::ValueIn+2));\n+      n->set_req(MemNode::ValueIn+1, pair);\n+      n->del_req(MemNode::ValueIn+2);\n+      pair = new BinaryNode(n->in(MemNode::ValueIn), n->in(MemNode::ValueIn+1));\n+      n->set_req(MemNode::ValueIn, pair);\n+      n->del_req(MemNode::ValueIn+1);\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":57,"deletions":0,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -332,0 +332,2 @@\n+  static const bool match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt);\n+\n@@ -348,0 +350,2 @@\n+  \/\/ Actual max scalable predicate register length.\n+  static const int scalable_predicate_reg_slots();\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1137,1 +1137,1 @@\n-      if (store_Opcode() == Op_StoreVector) {\n+      if (st->is_StoreVector()) {\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -779,1 +779,2 @@\n-    Flag_for_post_loop_opts_igvn     = 1 << 15,\n+    Flag_is_predicated_vector        = 1 << 15,\n+    Flag_for_post_loop_opts_igvn     = 1 << 16,\n@@ -988,0 +989,2 @@\n+  bool is_predicated_vector() const { return (_flags & Flag_is_predicated_vector) != 0; }\n+\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -312,1 +312,1 @@\n-      assert(val->ideal_reg() == Op_VecA, \"scalable vector register\");\n+      assert(val->ideal_reg() == Op_VecA || val->ideal_reg() == Op_RegVectMask, \"scalable register\");\n@@ -316,1 +316,1 @@\n-        n_regs = RegMask::SlotsPerVecA;\n+        n_regs = lrgs(val_idx)._is_predicate ? RegMask::SlotsPerRegVectMask : RegMask::SlotsPerVecA;\n@@ -321,2 +321,1 @@\n-      if (lrgs(val_idx).is_scalable()) {\n-        assert(val->ideal_reg() == Op_VecA, \"scalable vector register\");\n+      if (lrgs(val_idx).is_scalable() && val->ideal_reg() == Op_VecA) {\n","filename":"src\/hotspot\/share\/opto\/postaloc.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -240,1 +240,1 @@\n-  if (lrg.is_scalable()) {\n+  if (lrg.is_scalable() && lrg._is_vector) {\n","filename":"src\/hotspot\/share\/opto\/regmask.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -996,1 +996,0 @@\n-\n@@ -2348,1 +2347,4 @@\n-const TypeVect* TypeVect::make(const Type *elem, uint length) {\n+const TypeVect* TypeVect::make(const Type *elem, uint length, bool is_mask) {\n+  if (is_mask) {\n+    return makemask(elem, length);\n+  }\n@@ -2374,1 +2376,5 @@\n-  if (Matcher::has_predicated_vectors()) {\n+  if (Matcher::has_predicated_vectors() &&\n+      \/\/ TODO: remove this condition once the backend is supported.\n+      \/\/ Workround to make tests pass on AVX-512\/SVE when predicate is not supported.\n+      \/\/ Could be removed once the backend is supported.\n+      Matcher::match_rule_supported_vector_masked(Op_StoreVectorMasked, MaxVectorSize, T_BOOLEAN)) {\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -799,1 +799,1 @@\n-  static const TypeVect *make(const BasicType elem_bt, uint length) {\n+  static const TypeVect *make(const BasicType elem_bt, uint length, bool is_mask = false) {\n@@ -801,1 +801,1 @@\n-    return make(get_const_basic_type(elem_bt), length);\n+    return make(get_const_basic_type(elem_bt), length, is_mask);\n@@ -804,1 +804,1 @@\n-  static const TypeVect *make(const Type* elem, uint length);\n+  static const TypeVect *make(const Type* elem, uint length, bool is_mask = false);\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -457,1 +457,1 @@\n-      vec_val_load = gvn.transform(new VectorLoadMaskNode(vec_val_load, TypeVect::make(masktype, num_elem)));\n+      vec_val_load = gvn.transform(new VectorLoadMaskNode(vec_val_load, TypeVect::makemask(masktype, num_elem)));\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -62,0 +62,8 @@\n+static bool is_vector_mask(ciKlass* klass) {\n+  return klass->is_subclass_of(ciEnv::current()->vector_VectorMask_klass());\n+}\n+\n+static bool is_vector_shuffle(ciKlass* klass) {\n+  return klass->is_subclass_of(ciEnv::current()->vector_VectorShuffle_klass());\n+}\n+\n@@ -76,1 +84,1 @@\n-  const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+  const TypeVect* vt = TypeVect::make(elem_bt, num_elem, is_vector_mask(vbox_type->klass()));\n@@ -91,1 +99,1 @@\n-  const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+  const TypeVect* vt = TypeVect::make(elem_bt, num_elem, is_vector_mask(vbox_type->klass()));\n@@ -162,1 +170,1 @@\n-  if (mask_use_type == VecMaskUseAll || mask_use_type == VecMaskUseLoad) {\n+  if ((mask_use_type & VecMaskUseLoad) != 0) {\n@@ -175,1 +183,1 @@\n-  if (mask_use_type == VecMaskUseAll || mask_use_type == VecMaskUseStore) {\n+  if ((mask_use_type & VecMaskUseStore) != 0) {\n@@ -187,6 +195,12 @@\n-  return true;\n-}\n-\n-static bool is_vector_mask(ciKlass* klass) {\n-  return klass->is_subclass_of(ciEnv::current()->vector_VectorMask_klass());\n-}\n+  if ((mask_use_type & VecMaskUsePred) != 0) {\n+    if (!Matcher::has_predicated_vectors() ||\n+        !Matcher::match_rule_supported_vector_masked(sopc, num_elem, type)) {\n+    #ifndef PRODUCT\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"Rejected vector mask predicate using (%s,%s,%d) because architecture does not support it\",\n+                      NodeClassNames[sopc], type2name(type), num_elem);\n+      }\n+    #endif\n+      return false;\n+    }\n+  }\n@@ -194,2 +208,1 @@\n-static bool is_vector_shuffle(ciKlass* klass) {\n-  return klass->is_subclass_of(ciEnv::current()->vector_VectorShuffle_klass());\n+  return true;\n@@ -208,4 +221,4 @@\n-\/\/ <VM>\n-\/\/ VM unaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/            VM vm,\n-\/\/            Function<VM, VM> defaultImpl) {\n+\/\/ <V, M>\n+\/\/ V unaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<?> elementType,\n+\/\/           int length, V v, M m,\n+\/\/           UnaryOperation<V, M> defaultImpl) {\n@@ -214,4 +227,4 @@\n-\/\/ <VM>\n-\/\/ VM binaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/             VM vm1, VM vm2,\n-\/\/             BiFunction<VM, VM, VM> defaultImpl) {\n+\/\/ <V, M>\n+\/\/ V binaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<?> elementType,\n+\/\/            int length, V v1, V v2, M m,\n+\/\/            BinaryOperation<V, M> defaultImpl) {\n@@ -220,4 +233,4 @@\n-\/\/ <VM>\n-\/\/ VM ternaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/              VM vm1, VM vm2, VM vm3,\n-\/\/              TernaryOperation<VM> defaultImpl) {\n+\/\/ <V, M>\n+\/\/ V ternaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<?> elementType,\n+\/\/             int length, V v1, V v2, V v3, M m,\n+\/\/             TernaryOperation<V, M> defaultImpl) {\n@@ -228,2 +241,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -237,2 +251,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -242,0 +256,1 @@\n+\n@@ -255,0 +270,28 @@\n+\n+  \/\/ \"argument(n + 5)\" should be the mask object. We assume it is \"null\" when no mask\n+  \/\/ is used to control this operation.\n+  const Type* vmask_type = gvn().type(argument(n + 5));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -277,0 +320,4 @@\n+  if (is_vector_mask(vbox_klass)) {\n+    assert(!is_masked_op, \"mask operations do not need mask to control\");\n+  }\n+\n@@ -299,3 +346,4 @@\n-  \/\/ TODO When mask usage is supported, VecMaskNotUsed needs to be VecMaskUseLoad.\n-  if ((sopc != 0) &&\n-      !arch_supports_vector(sopc, num_elem, elem_bt, is_vector_mask(vbox_klass) ? VecMaskUseAll : VecMaskNotUsed)) {\n+  \/\/ When using mask, mask use type needs to be VecMaskUseLoad.\n+  VectorMaskUseType mask_use_type = is_vector_mask(vbox_klass) ? VecMaskUseAll\n+                                      : is_masked_op ? VecMaskUseLoad : VecMaskNotUsed;\n+  if ((sopc != 0) && !arch_supports_vector(sopc, num_elem, elem_bt, mask_use_type)) {\n@@ -303,1 +351,1 @@\n-      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=%d\",\n+      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=%d is_masked_op=%d\",\n@@ -305,1 +353,1 @@\n-                    is_vector_mask(vbox_klass) ? 1 : 0);\n+                    is_vector_mask(vbox_klass) ? 1 : 0, is_masked_op ? 1 : 0);\n@@ -310,0 +358,10 @@\n+  \/\/ Return true if current platform has implemented the masked operation with predicate feature.\n+  bool use_predicate = is_masked_op && sopc != 0 && arch_supports_vector(sopc, num_elem, elem_bt, VecMaskUsePred);\n+  if (is_masked_op && !use_predicate && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=0 is_masked_op=1\",\n+                    n, sopc, num_elem, type2name(elem_bt));\n+    }\n+    return false;\n+  }\n+\n@@ -313,1 +371,1 @@\n-      opd3 = unbox_vector(argument(6), vbox_type, elem_bt, num_elem);\n+      opd3 = unbox_vector(argument(7), vbox_type, elem_bt, num_elem);\n@@ -317,1 +375,1 @@\n-                        NodeClassNames[argument(6)->Opcode()]);\n+                        NodeClassNames[argument(7)->Opcode()]);\n@@ -324,1 +382,1 @@\n-      opd2 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n+      opd2 = unbox_vector(argument(6), vbox_type, elem_bt, num_elem);\n@@ -328,1 +386,1 @@\n-                        NodeClassNames[argument(5)->Opcode()]);\n+                        NodeClassNames[argument(6)->Opcode()]);\n@@ -335,1 +393,1 @@\n-      opd1 = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n+      opd1 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n@@ -339,1 +397,1 @@\n-                        NodeClassNames[argument(4)->Opcode()]);\n+                        NodeClassNames[argument(5)->Opcode()]);\n@@ -348,0 +406,15 @@\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    assert(is_vector_mask(mbox_klass), \"argument(2) should be a mask class\");\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(n + 5), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                      NodeClassNames[argument(n + 5)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -366,1 +439,1 @@\n-        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, vt));\n+        operation = VectorNode::make(sopc, opd1, opd2, vt, is_vector_mask(vbox_klass));\n@@ -370,1 +443,1 @@\n-        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, opd3, vt));\n+        operation = VectorNode::make(sopc, opd1, opd2, opd3, vt);\n@@ -376,0 +449,11 @@\n+\n+  if (is_masked_op && mask != NULL) {\n+    if (use_predicate) {\n+      operation->add_req(mask);\n+      operation->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      operation = new VectorBlendNode(opd1, operation, mask);\n+    }\n+  }\n+  operation = gvn().transform(operation);\n+\n@@ -461,1 +545,2 @@\n-    Node* mask = gvn().transform(new VectorMaskCmpNode(BoolTest::ge, bcast_lane_cnt, res, pred_node, vt));\n+    const TypeVect* vmask_type = TypeVect::makemask(elem_bt, num_elem);\n+    Node* mask = gvn().transform(new VectorMaskCmpNode(BoolTest::ge, bcast_lane_cnt, res, pred_node, vmask_type));\n@@ -644,1 +729,0 @@\n-\n@@ -671,1 +755,1 @@\n-  Node* broadcast = VectorNode::scalar2vector(elem, num_elem, Type::get_const_basic_type(elem_bt));\n+  Node* broadcast = VectorNode::scalar2vector(elem, num_elem, Type::get_const_basic_type(elem_bt), is_vector_mask(vbox_klass));\n@@ -861,2 +945,1 @@\n-        const TypeVect* to_vect_type = TypeVect::make(elem_bt, num_elem);\n-        vload = gvn().transform(new VectorLoadMaskNode(vload, to_vect_type));\n+        vload = gvn().transform(new VectorLoadMaskNode(vload, TypeVect::makemask(elem_bt, num_elem)));\n@@ -881,6 +964,177 @@\n-\/\/   <C, V extends Vector<?>, W extends IntVector, E, S extends VectorSpecies<E>>\n-\/\/   void loadWithMap(Class<?> vectorClass, Class<E> E, int length, Class<?> vectorIndexClass,\n-\/\/                    Object base, long offset, \/\/ Unsafe addressing\n-\/\/                    W index_vector,\n-\/\/                    C container, int index, int[] indexMap, int indexM, S s, \/\/ Arguments for default implementation\n-\/\/                    LoadVectorOperationWithMap<C, V, E, S> defaultImpl)\n+\/\/    <C, V, E, S extends VectorSpecies<E>,\n+\/\/     M extends VectorMask<E>>\n+\/\/    V loadMasked(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType,\n+\/\/                 int length, Object base, long offset, M m\n+\/\/                 C container, int index, S s,  \/\/ Arguments for default implementation\n+\/\/                 LoadVectorMaskedOperation<C, V, E, S, M> defaultImpl) {\n+\/\/\n+\/\/    <C, V extends Vector<?>,\n+\/\/     M extends VectorMask<?>>\n+\/\/    void storeMasked(Class<?> vectorClass, Class<M> maskClass, Class<?> elementType,\n+\/\/                     int length, Object base, long offset,\n+\/\/                     V v, M m,\n+\/\/                     C container, int index,  \/\/ Arguments for default implementation\n+\/\/                     StoreVectorMaskedOperation<C, V, M> defaultImpl) {\n+\/\/\n+\/\/    TODO: Handle special cases where load\/store happens from\/to byte array but element type\n+\/\/    is not byte.\n+\/\/\n+bool LibraryCallKit::inline_vector_mem_masked_operation(bool is_store) {\n+  const TypeInstPtr* vector_klass = gvn().type(argument(0))->isa_instptr();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(1))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+\n+  if (vector_klass == NULL || mask_klass == NULL || elem_klass == NULL || vlen == NULL ||\n+      vector_klass->const_oop() == NULL || mask_klass->const_oop() == NULL ||\n+      elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** missing constant: vclass=%s mclass=%s etype=%s vlen=%s\",\n+                    NodeClassNames[argument(0)->Opcode()],\n+                    NodeClassNames[argument(1)->Opcode()],\n+                    NodeClassNames[argument(2)->Opcode()],\n+                    NodeClassNames[argument(3)->Opcode()]);\n+    }\n+    return false; \/\/ not enough info for intrinsification\n+  }\n+  if (!is_klass_initialized(vector_klass)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** klass argument not initialized\");\n+    }\n+    return false;\n+  }\n+\n+  if (!is_klass_initialized(mask_klass)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** mask klass argument not initialized\");\n+    }\n+    return false;\n+  }\n+\n+  ciType* elem_type = elem_klass->const_oop()->as_instance()->java_mirror_type();\n+  if (!elem_type->is_primitive_type()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not a primitive bt=%d\", elem_type->basic_type());\n+    }\n+    return false; \/\/ should be primitive type\n+  }\n+  BasicType elem_bt = elem_type->basic_type();\n+  int num_elem = vlen->get_con();\n+\n+  bool use_predicate = arch_supports_vector(is_store ? Op_StoreVectorMasked : Op_LoadVectorMasked,\n+                                            num_elem, elem_bt, (VectorMaskUseType) (VecMaskUseLoad | VecMaskUsePred));\n+  \/\/ Masked vector store operation needs the architecture predicate feature. We need to check\n+  \/\/ whether the predicated vector operation is supported by backend.\n+  if (is_store && !use_predicate) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: op=storeMasked vlen=%d etype=%s\",\n+                    num_elem, type2name(elem_bt));\n+    }\n+    return false;\n+  }\n+\n+  \/\/ This only happens for masked vector load. If predicate is not supported, then check whether\n+  \/\/ the normal vector load and blend operations are supported by backend.\n+  if (!use_predicate && (!arch_supports_vector(Op_LoadVector, num_elem, elem_bt, VecMaskNotUsed) ||\n+      !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad))) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: op=loadMasked vlen=%d etype=%s\",\n+                    num_elem, type2name(elem_bt));\n+    }\n+    return false;\n+  }\n+\n+  Node* base = argument(4);\n+  Node* offset = ConvL2X(argument(5));\n+\n+  \/\/ Save state and restore on bailout\n+  uint old_sp = sp();\n+  SafePointNode* old_map = clone_map();\n+\n+  Node* addr = make_unsafe_address(base, offset, elem_bt, true);\n+  const TypePtr *addr_type = gvn().type(addr)->isa_ptr();\n+  const TypeAryPtr* arr_type = addr_type->isa_aryptr();\n+  if (arr_type != NULL && !elem_consistent_with_arr(elem_bt, arr_type)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s atype=%s\",\n+                    is_store, is_store ? \"storeMasked\" : \"loadMasked\",\n+                    num_elem, type2name(elem_bt), type2name(arr_type->elem()->array_element_basic_type()));\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  \/\/ Can base be NULL? Otherwise, always on-heap access.\n+  bool can_access_non_heap = TypePtr::NULL_PTR->higher_equal(gvn().type(base));\n+  if (can_access_non_heap) {\n+    insert_mem_bar(Op_MemBarCPUOrder);\n+  }\n+\n+  ciKlass* vbox_klass = vector_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+  ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+  assert(!is_vector_mask(vbox_klass) && is_vector_mask(mbox_klass), \"Invalid class type\");\n+  const TypeInstPtr* vbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, vbox_klass);\n+  const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+\n+  Node* mask = unbox_vector(is_store ? argument(8) : argument(7), mbox_type, elem_bt, num_elem);\n+  if (mask == NULL) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** unbox failed mask=%s\",\n+                    is_store ? NodeClassNames[argument(8)->Opcode()]\n+                             : NodeClassNames[argument(7)->Opcode()]);\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  if (is_store) {\n+    Node* val = unbox_vector(argument(7), vbox_type, elem_bt, num_elem);\n+    if (val == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed vector=%s\",\n+                      NodeClassNames[argument(7)->Opcode()]);\n+      }\n+      set_map(old_map);\n+      set_sp(old_sp);\n+      return false; \/\/ operand unboxing failed\n+    }\n+    set_all_memory(reset_memory());\n+    Node* vstore = gvn().transform(new StoreVectorMaskedNode(control(), memory(addr), addr, val, addr_type, mask));\n+    set_memory(vstore, addr_type);\n+  } else {\n+    Node* vload = NULL;\n+    if (use_predicate) {\n+      \/\/ Generate masked load vector node if predicate feature is supported.\n+      const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+      vload = gvn().transform(new LoadVectorMaskedNode(control(), memory(addr), addr, addr_type, vt, mask));\n+    } else {\n+      \/\/ Use the vector blend to implement the masked load vector. The biased elements are zeros.\n+      Node* zero = gvn().transform(gvn().zerocon(elem_bt));\n+      zero = gvn().transform(VectorNode::scalar2vector(zero, num_elem, Type::get_const_basic_type(elem_bt)));\n+      vload = gvn().transform(LoadVectorNode::make(0, control(), memory(addr), addr, addr_type, num_elem, elem_bt));\n+      vload = gvn().transform(new VectorBlendNode(zero, vload, mask));\n+    }\n+    Node* box = box_vector(vload, vbox_type, elem_bt, num_elem);\n+    set_result(box);\n+  }\n+\n+  old_map->destruct(&_gvn);\n+\n+  if (can_access_non_heap) {\n+    insert_mem_bar(Op_MemBarCPUOrder);\n+  }\n+\n+  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n+  return true;\n+}\n+\n+\/\/   <C, V extends Vector<?>, W extends Vector<Integer>, E,\n+\/\/    S extends VectorSpecies<E>, M extends VectorMask<E>>\n+\/\/   V loadWithMap(Class<?> vectorClass, Class<M> maskClass, Class<E> E, int length,\n+\/\/                 Class<?> vectorIndexClass,\n+\/\/                 Object base, long offset, \/\/ Unsafe addressing\n+\/\/                 W index_vector, M m,\n+\/\/                 C container, int index, int[] indexMap, int indexM, S s, \/\/ Arguments for default implementation\n+\/\/                 LoadVectorOperationWithMap<C, V, E, S, M> defaultImpl)\n@@ -888,4 +1142,4 @@\n-\/\/    <C, V extends Vector<?>, W extends IntVector>\n-\/\/    void storeWithMap(Class<?> vectorClass, Class<?> elementType, int length, Class<?> vectorIndexClass,\n-\/\/                      Object base, long offset,    \/\/ Unsafe addressing\n-\/\/                      W index_vector, V v,\n+\/\/    <C, V extends Vector<?>, W extends Vector<Integer>, M extends VectorMask<?>>\n+\/\/    void storeWithMap(Class<?> vectorClass, Class<M> maskClass, Class<?> elementType,\n+\/\/                      int length, Class<?> vectorIndexClass, Object base, long offset,    \/\/ Unsafe addressing\n+\/\/                      W index_vector, V v, M m,\n@@ -893,1 +1147,1 @@\n-\/\/                      StoreVectorOperationWithMap<C, V> defaultImpl) {\n+\/\/                      StoreVectorOperationWithMap<C, V, M> defaultImpl)\n@@ -897,3 +1151,4 @@\n-  const TypeInstPtr* elem_klass       = gvn().type(argument(1))->isa_instptr();\n-  const TypeInt*     vlen             = gvn().type(argument(2))->isa_int();\n-  const TypeInstPtr* vector_idx_klass = gvn().type(argument(3))->isa_instptr();\n+  const TypeInstPtr* mask_klass       = gvn().type(argument(1))->isa_instptr();\n+  const TypeInstPtr* elem_klass       = gvn().type(argument(2))->isa_instptr();\n+  const TypeInt*     vlen             = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* vector_idx_klass = gvn().type(argument(4))->isa_instptr();\n@@ -906,1 +1161,0 @@\n-                    NodeClassNames[argument(1)->Opcode()],\n@@ -908,1 +1162,2 @@\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -919,0 +1174,1 @@\n+\n@@ -926,0 +1182,1 @@\n+\n@@ -929,5 +1186,43 @@\n-  if (!arch_supports_vector(is_scatter ? Op_StoreVectorScatter : Op_LoadVectorGather, num_elem, elem_bt, VecMaskNotUsed)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s ismask=no\",\n-                    is_scatter, is_scatter ? \"scatter\" : \"gather\",\n-                    num_elem, type2name(elem_bt));\n+  const Type* vmask_type = gvn().type(is_scatter ? argument(10) : argument(9));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(1)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+\n+    \/\/ Check whether the predicated gather\/scatter node is supported by architecture.\n+    if (!arch_supports_vector(is_scatter ? Op_StoreVectorScatterMasked : Op_LoadVectorGatherMasked, num_elem, elem_bt,\n+                              (VectorMaskUseType) (VecMaskUseLoad | VecMaskUsePred))) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s is_masked_op=1\",\n+                      is_scatter, is_scatter ? \"scatterMasked\" : \"gatherMasked\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n+    }\n+  } else {\n+    \/\/ Check whether the normal gather\/scatter node is supported for non-masked operation.\n+    if (!arch_supports_vector(is_scatter ? Op_StoreVectorScatter : Op_LoadVectorGather, num_elem, elem_bt, VecMaskNotUsed)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s is_masked_op=0\",\n+                      is_scatter, is_scatter ? \"scatter\" : \"gather\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n@@ -935,1 +1230,0 @@\n-    return false; \/\/ not supported\n@@ -941,1 +1235,1 @@\n-        tty->print_cr(\"  ** not supported: arity=%d op=%s\/loadindex vlen=%d etype=int ismask=no\",\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s\/loadindex vlen=%d etype=int is_masked_op=%d\",\n@@ -943,1 +1237,1 @@\n-                      num_elem);\n+                      num_elem, is_masked_op ? 1 : 0);\n@@ -946,1 +1240,1 @@\n-    }\n+  }\n@@ -948,2 +1242,2 @@\n-  Node* base = argument(4);\n-  Node* offset = ConvL2X(argument(5));\n+  Node* base = argument(5);\n+  Node* offset = ConvL2X(argument(6));\n@@ -971,0 +1265,1 @@\n+\n@@ -973,1 +1268,0 @@\n-\n@@ -975,1 +1269,0 @@\n-\n@@ -983,2 +1276,1 @@\n-\n-  Node* index_vect = unbox_vector(argument(7), vbox_idx_type, T_INT, num_elem);\n+  Node* index_vect = unbox_vector(argument(8), vbox_idx_type, T_INT, num_elem);\n@@ -990,0 +1282,18 @@\n+\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(is_scatter ? argument(10) : argument(9), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                    is_scatter ? NodeClassNames[argument(10)->Opcode()]\n+                               : NodeClassNames[argument(9)->Opcode()]);\n+      }\n+      set_map(old_map);\n+      set_sp(old_sp);\n+      return false;\n+    }\n+  }\n+\n@@ -992,1 +1302,1 @@\n-    Node* val = unbox_vector(argument(8), vbox_type, elem_bt, num_elem);\n+    Node* val = unbox_vector(argument(9), vbox_type, elem_bt, num_elem);\n@@ -1000,1 +1310,6 @@\n-    Node* vstore = gvn().transform(new StoreVectorScatterNode(control(), memory(addr), addr, addr_type, val, index_vect));\n+    Node* vstore = NULL;\n+    if (mask != NULL) {\n+      vstore = gvn().transform(new StoreVectorScatterMaskedNode(control(), memory(addr), addr, addr_type, val, index_vect, mask));\n+    } else {\n+      vstore = gvn().transform(new StoreVectorScatterNode(control(), memory(addr), addr, addr_type, val, index_vect));\n+    }\n@@ -1003,2 +1318,6 @@\n-    Node* vload = gvn().transform(new LoadVectorGatherNode(control(), memory(addr), addr, addr_type, vector_type, index_vect));\n-\n+    Node* vload = NULL;\n+    if (mask != NULL) {\n+      vload = gvn().transform(new LoadVectorGatherMaskedNode(control(), memory(addr), addr, addr_type, vector_type, index_vect, mask));\n+    } else {\n+      vload = gvn().transform(new LoadVectorGatherNode(control(), memory(addr), addr, addr_type, vector_type, index_vect));\n+    }\n@@ -1015,5 +1334,5 @@\n-\/\/ <V extends Vector<?,?>>\n-\/\/ long reductionCoerced(int oprId, Class<?> vectorClass, Class<?> elementType, int vlen,\n-\/\/                       V v,\n-\/\/                       Function<V,Long> defaultImpl)\n-\n+\/\/ <V, M>\n+\/\/ long reductionCoerced(int oprId, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+\/\/                       Class<?> elementType, int length, V v, M m,\n+\/\/                       ReductionOperation<V, M> defaultImpl) {\n+\/\/\n@@ -1023,2 +1342,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -1032,2 +1352,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -1050,0 +1370,26 @@\n+\n+  const Type* vmask_type = gvn().type(argument(6));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1052,1 +1398,0 @@\n-\n@@ -1056,2 +1401,2 @@\n-  \/\/ TODO When mask usage is supported, VecMaskNotUsed needs to be VecMaskUseLoad.\n-  if (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed)) {\n+  \/\/ When using mask, mask use type needs to be VecMaskUseLoad.\n+  if (!arch_supports_vector(sopc, num_elem, elem_bt, is_masked_op ? VecMaskUseLoad : VecMaskNotUsed)) {\n@@ -1059,1 +1404,11 @@\n-      tty->print_cr(\"  ** not supported: arity=1 op=%d\/reduce vlen=%d etype=%s ismask=no\",\n+      tty->print_cr(\"  ** not supported: arity=1 op=%d\/reduce vlen=%d etype=%s is_masked_op=%d\",\n+                    sopc, num_elem, type2name(elem_bt), is_masked_op ? 1 : 0);\n+    }\n+    return false;\n+  }\n+\n+  \/\/ Return true if current platform has implemented the masked operation with predicate feature.\n+  bool use_predicate = is_masked_op && arch_supports_vector(sopc, num_elem, elem_bt, VecMaskUsePred);\n+  if (is_masked_op && !use_predicate && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=1 op=%d\/reduce vlen=%d etype=%s is_masked_op=1\",\n@@ -1068,1 +1423,1 @@\n-  Node* opd = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n+  Node* opd = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n@@ -1073,0 +1428,15 @@\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    assert(is_vector_mask(mbox_klass), \"argument(2) should be a mask class\");\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(6), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                      NodeClassNames[argument(6)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1074,1 +1444,16 @@\n-  Node* rn = gvn().transform(ReductionNode::make(opc, NULL, init, opd, elem_bt));\n+  Node* value = NULL;\n+  if (mask == NULL) {\n+    assert(!is_masked_op, \"Masked op needs the mask value never null\");\n+    value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+  } else {\n+    if (use_predicate) {\n+      value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+      value->add_req(mask);\n+      value->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n+      value = gvn().transform(new VectorBlendNode(reduce_identity, opd, mask));\n+      value = ReductionNode::make(opc, NULL, init, value, elem_bt);\n+    }\n+  }\n+  value = gvn().transform(value);\n@@ -1081,1 +1466,1 @@\n-      bits = gvn().transform(new ConvI2LNode(rn));\n+      bits = gvn().transform(new ConvI2LNode(value));\n@@ -1085,2 +1470,2 @@\n-      rn   = gvn().transform(new MoveF2INode(rn));\n-      bits = gvn().transform(new ConvI2LNode(rn));\n+      value = gvn().transform(new MoveF2INode(value));\n+      bits  = gvn().transform(new ConvI2LNode(value));\n@@ -1090,1 +1475,1 @@\n-      bits = gvn().transform(new MoveD2LNode(rn));\n+      bits = gvn().transform(new MoveD2LNode(value));\n@@ -1094,1 +1479,1 @@\n-      bits = rn; \/\/ no conversion needed\n+      bits = value; \/\/ no conversion needed\n@@ -1318,2 +1703,2 @@\n-  const TypeVect* vt = TypeVect::make(mask_bt, num_elem);\n-  Node* operation = gvn().transform(new VectorMaskCmpNode(pred, v1, v2, pred_node, vt));\n+  const TypeVect* vmask_type = TypeVect::makemask(mask_bt, num_elem);\n+  Node* operation = gvn().transform(new VectorMaskCmpNode(pred, v1, v2, pred_node, vmask_type));\n@@ -1463,3 +1848,4 @@\n-\/\/  <V extends Vector<?,?>>\n-\/\/  V broadcastInt(int opr, Class<V> vectorClass, Class<?> elementType, int vlen,\n-\/\/                 V v, int i,\n+\/\/  <V extends Vector<?>, M>\n+\/\/  V broadcastInt(int opr, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+\/\/                 Class<?> elementType, int length,\n+\/\/                 V v, int n, M m,\n@@ -1471,2 +1857,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -1482,2 +1869,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -1493,0 +1880,26 @@\n+\n+  const Type* vmask_type = gvn().type(argument(7));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1519,4 +1932,16 @@\n-  if (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed, true \/*has_scalar_args*\/)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=0 op=int\/%d vlen=%d etype=%s ismask=no\",\n-                    sopc, num_elem, type2name(elem_bt));\n+  bool use_predicate = is_masked_op &&\n+                       arch_supports_vector(sopc, num_elem, elem_bt, (VectorMaskUseType) (VecMaskUseLoad | VecMaskUsePred), true);\n+  if (!use_predicate) {\n+    if (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed, true \/*has_scalar_args*\/)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=0 op=int\/%d vlen=%d etype=%s is_masked_op=%d\",\n+                      sopc, num_elem, type2name(elem_bt), is_masked_op ? 1 : 0);\n+      }\n+      return false; \/\/ not supported\n+    }\n+    if (is_masked_op && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=0 op=int\/%d vlen=%d etype=%s is_masked_op=1\",\n+                      sopc, num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n@@ -1524,1 +1949,0 @@\n-    return false; \/\/ not supported\n@@ -1526,2 +1950,3 @@\n-  Node* opd1 = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n-  Node* opd2 = vector_shift_count(argument(5), opc, elem_bt, num_elem);\n+\n+  Node* opd1 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n+  Node* opd2 = vector_shift_count(argument(6), opc, elem_bt, num_elem);\n@@ -1531,1 +1956,0 @@\n-  Node* operation = gvn().transform(VectorNode::make(opc, opd1, opd2, num_elem, elem_bt));\n@@ -1533,0 +1957,23 @@\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(7), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\", NodeClassNames[argument(7)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n+  Node* operation = VectorNode::make(opc, opd1, opd2, num_elem, elem_bt);\n+  if (is_masked_op && mask != NULL) {\n+    if (use_predicate) {\n+      operation->add_req(mask);\n+      operation->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      operation = new VectorBlendNode(opd1, operation, mask);\n+    }\n+  }\n+  operation = gvn().transform(operation);\n@@ -1655,2 +2102,2 @@\n-  const TypeVect* src_type = TypeVect::make(elem_bt_from, num_elem_from);\n-  const TypeVect* dst_type = TypeVect::make(elem_bt_to,   num_elem_to);\n+  const TypeVect* src_type = TypeVect::make(elem_bt_from, num_elem_from, is_mask);\n+  const TypeVect* dst_type = TypeVect::make(elem_bt_to, num_elem_to, is_mask);\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":567,"deletions":120,"binary":false,"changes":687,"status":"modified"},{"patch":"@@ -426,0 +426,25 @@\n+VectorNode* VectorNode::make_mask_node(int vopc, Node* n1, Node* n2, uint vlen, BasicType bt) {\n+  guarantee(vopc > 0, \"vopc must be > 0\");\n+  const TypeVect* vmask_type = TypeVect::makemask(bt, vlen);\n+  switch (vopc) {\n+    case Op_AndV:\n+      if (Matcher::match_rule_supported_vector(Op_AndVMask, vlen, bt)) {\n+        return new AndVMaskNode(n1, n2, vmask_type);\n+      }\n+      return new AndVNode(n1, n2, vmask_type);\n+    case Op_OrV:\n+      if (Matcher::match_rule_supported_vector(Op_OrVMask, vlen, bt)) {\n+        return new OrVMaskNode(n1, n2, vmask_type);\n+      }\n+      return new OrVNode(n1, n2, vmask_type);\n+    case Op_XorV:\n+      if (Matcher::match_rule_supported_vector(Op_XorVMask, vlen, bt)) {\n+        return new XorVMaskNode(n1, n2, vmask_type);\n+      }\n+      return new XorVNode(n1, n2, vmask_type);\n+    default:\n+      fatal(\"Unsupported mask vector creation for '%s'\", NodeClassNames[vopc]);\n+      return NULL;\n+  }\n+}\n+\n@@ -427,1 +452,1 @@\n-VectorNode* VectorNode::make(int vopc, Node* n1, Node* n2, const TypeVect* vt) {\n+VectorNode* VectorNode::make(int vopc, Node* n1, Node* n2, const TypeVect* vt, bool is_mask) {\n@@ -430,0 +455,5 @@\n+\n+  if (is_mask) {\n+    return make_mask_node(vopc, n1, n2, vt->length(), vt->element_basic_type());\n+  }\n+\n@@ -536,1 +566,1 @@\n-VectorNode* VectorNode::scalar2vector(Node* s, uint vlen, const Type* opd_t) {\n+VectorNode* VectorNode::scalar2vector(Node* s, uint vlen, const Type* opd_t, bool is_mask) {\n@@ -538,2 +568,7 @@\n-  const TypeVect* vt = opd_t->singleton() ? TypeVect::make(opd_t, vlen)\n-                                          : TypeVect::make(bt, vlen);\n+  const TypeVect* vt = opd_t->singleton() ? TypeVect::make(opd_t, vlen, is_mask)\n+                                          : TypeVect::make(bt, vlen, is_mask);\n+\n+  if (is_mask && Matcher::match_rule_supported_vector(Op_MaskAll, vlen, bt)) {\n+    return new MaskAllNode(s, vt);\n+  }\n+\n@@ -723,0 +758,17 @@\n+Node* StoreVectorNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  \/\/ StoreVector (VectorStoreMask src)  ==>  (StoreVectorMask src).\n+  Node* value = in(MemNode::ValueIn);\n+  if (value->Opcode() == Op_VectorStoreMask) {\n+    assert(vect_type()->element_basic_type() == T_BOOLEAN, \"Invalid basic type to store mask\");\n+    const TypeVect* type = value->in(1)->bottom_type()->is_vect();\n+    if (Matcher::match_rule_supported_vector(Op_StoreVectorMask, type->length(), type->element_basic_type())) {\n+      const TypeVect* mem_type = TypeVect::make(T_BOOLEAN, type->length());\n+      return new StoreVectorMaskNode(in(MemNode::Control),\n+                                     in(MemNode::Memory),\n+                                     in(MemNode::Address),\n+                                     adr_type(), value->in(1), mem_type);\n+    }\n+  }\n+  return StoreNode::Ideal(phase, can_reshape);\n+}\n+\n@@ -978,0 +1030,15 @@\n+Node* VectorLoadMaskNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  \/\/ (VectorLoadMask (LoadVector mem))  ==> (LoadVectorMask mem)\n+  LoadVectorNode* load = this->in(1)->isa_LoadVector();\n+  BasicType out_bt = vect_type()->element_basic_type();\n+  if (load != NULL &&\n+      Matcher::match_rule_supported_vector(Op_LoadVectorMask, length(), out_bt)) {\n+    const TypeVect* mem_type = TypeVect::make(T_BOOLEAN, length());\n+    return new LoadVectorMaskNode(load->in(MemNode::Control),\n+                                  load->in(MemNode::Memory),\n+                                  load->in(MemNode::Address),\n+                                  load->adr_type(), vect_type(), mem_type);\n+  }\n+  return NULL;\n+}\n+\n@@ -1079,0 +1146,1 @@\n+          return gvn.makecon(TypeInt::make(max_jbyte));\n@@ -1080,0 +1148,1 @@\n+          return gvn.makecon(TypeInt::make(max_jshort));\n@@ -1094,0 +1163,1 @@\n+          return gvn.makecon(TypeInt::make(min_jbyte));\n@@ -1095,0 +1165,1 @@\n+          return gvn.makecon(TypeInt::make(min_jshort));\n@@ -1239,0 +1310,1 @@\n+          const TypeVect* vmask_type = TypeVect::makemask(out_vt->element_basic_type(), out_vt->length());\n@@ -1244,1 +1316,1 @@\n-            return new VectorMaskCastNode(value, out_vt);\n+            return new VectorMaskCastNode(value, vmask_type);\n@@ -1248,1 +1320,1 @@\n-          return new VectorLoadMaskNode(value, out_vt);\n+          return new VectorLoadMaskNode(value, vmask_type);\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":78,"deletions":6,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -69,1 +69,6 @@\n-  virtual uint ideal_reg() const { return Matcher::vector_ideal_reg(vect_type()->length_in_bytes()); }\n+  virtual uint ideal_reg() const {\n+    if (vect_type()->isa_vectmask()) {\n+      return Op_RegVectMask;\n+    }\n+    return Matcher::vector_ideal_reg(vect_type()->length_in_bytes());\n+  }\n@@ -71,1 +76,1 @@\n-  static VectorNode* scalar2vector(Node* s, uint vlen, const Type* opd_t);\n+  static VectorNode* scalar2vector(Node* s, uint vlen, const Type* opd_t, bool is_mask = false);\n@@ -74,1 +79,1 @@\n-  static VectorNode* make(int vopc, Node* n1, Node* n2, const TypeVect* vt);\n+  static VectorNode* make(int vopc, Node* n1, Node* n2, const TypeVect* vt, bool is_mask = false);\n@@ -77,0 +82,1 @@\n+  static VectorNode* make_mask_node(int vopc, Node* n1, Node* n2, uint vlen, BasicType bt);\n@@ -774,0 +780,1 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -799,2 +806,2 @@\n-                                                     idx == MemNode::ValueIn ||\n-                                                     idx == MemNode::ValueIn + 1; }\n+                                                    idx == MemNode::ValueIn ||\n+                                                    idx == MemNode::ValueIn + 1; }\n@@ -809,1 +816,1 @@\n-    assert(mask->bottom_type()->is_vectmask(), \"sanity\");\n+    assert(mask->bottom_type()->isa_vectmask(), \"sanity\");\n@@ -829,1 +836,1 @@\n-    assert(mask->bottom_type()->is_vectmask(), \"sanity\");\n+    assert(mask->bottom_type()->isa_vectmask(), \"sanity\");\n@@ -843,0 +850,39 @@\n+\/\/-------------------------------LoadVectorGatherMaskedNode---------------------------------\n+\/\/ Load Vector from memory via index map under the influence of a predicate register(mask).\n+class LoadVectorGatherMaskedNode : public LoadVectorNode {\n+ public:\n+  LoadVectorGatherMaskedNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt, Node* indices, Node* mask)\n+    : LoadVectorNode(c, mem, adr, at, vt) {\n+    init_class_id(Class_LoadVector);\n+    assert(indices->bottom_type()->is_vect(), \"indices must be in vector\");\n+    assert(mask->bottom_type()->isa_vectmask(), \"sanity\");\n+    add_req(indices);\n+    add_req(mask);\n+    assert(req() == MemNode::ValueIn + 2, \"match_edge expects that last input is in MemNode::ValueIn+1\");\n+  }\n+\n+  virtual int Opcode() const;\n+  virtual uint match_edge(uint idx) const { return idx == MemNode::Address ||\n+                                                   idx == MemNode::ValueIn ||\n+                                                   idx == MemNode::ValueIn + 1; }\n+};\n+\n+\/\/------------------------------StoreVectorScatterMaskedNode--------------------------------\n+\/\/ Store Vector into memory via index map under the influence of a predicate register(mask).\n+class StoreVectorScatterMaskedNode : public StoreVectorNode {\n+  public:\n+   StoreVectorScatterMaskedNode(Node* c, Node* mem, Node* adr, const TypePtr* at, Node* val, Node* indices, Node* mask)\n+     : StoreVectorNode(c, mem, adr, at, val) {\n+     init_class_id(Class_StoreVector);\n+     assert(indices->bottom_type()->is_vect(), \"indices must be in vector\");\n+     assert(mask->bottom_type()->isa_vectmask(), \"sanity\");\n+     add_req(indices);\n+     add_req(mask);\n+     assert(req() == MemNode::ValueIn + 3, \"match_edge expects that last input is in MemNode::ValueIn+2\");\n+   }\n+   virtual int Opcode() const;\n+   virtual uint match_edge(uint idx) const { return idx == MemNode::Address ||\n+                                                    idx == MemNode::ValueIn ||\n+                                                    idx == MemNode::ValueIn + 1 ||\n+                                                    idx == MemNode::ValueIn + 2; }\n+};\n@@ -857,1 +903,0 @@\n-\n@@ -914,0 +959,72 @@\n+class LoadVectorMaskNode : public LoadVectorNode {\n+ private:\n+  \/**\n+   * The type of the accessed memory, whose basic element type is T_BOOLEAN for mask vector.\n+   * It is different with the basic element type of the node, which can be T_BYTE, T_SHORT,\n+   * T_INT, T_LONG, T_FLOAT or T_DOUBLE.\n+   **\/\n+  const TypeVect* _mem_type;\n+\n+ public:\n+  LoadVectorMaskNode(Node* c, Node* mem, Node* adr, const TypePtr* at, const TypeVect* vt, const TypeVect* mt)\n+   : LoadVectorNode(c, mem, adr, at, vt), _mem_type(mt) {\n+    assert(_mem_type->element_basic_type() == T_BOOLEAN, \"Memory type must be T_BOOLEAN\");\n+    init_class_id(Class_LoadVector);\n+  }\n+\n+  virtual int Opcode() const;\n+  virtual int memory_size() const { return _mem_type->length_in_bytes(); }\n+  virtual int store_Opcode() const { return Op_StoreVectorMask; }\n+  virtual uint ideal_reg() const  { return vect_type()->ideal_reg(); }\n+  virtual uint size_of() const { return sizeof(LoadVectorMaskNode); }\n+};\n+\n+class StoreVectorMaskNode : public StoreVectorNode {\n+ private:\n+  \/**\n+   * The type of the accessed memory, whose basic element type is T_BOOLEAN for mask vector.\n+   * It is different with the basic element type of the src value, which can be T_BYTE, T_SHORT,\n+   * T_INT, T_LONG, T_FLOAT or T_DOUBLE.\n+   **\/\n+  const TypeVect* _mem_type;\n+\n+ public:\n+  StoreVectorMaskNode(Node* c, Node* mem, Node* adr, const TypePtr* at, Node* src, const TypeVect* mt)\n+   : StoreVectorNode(c, mem, adr, at, src), _mem_type(mt) {\n+    assert(_mem_type->element_basic_type() == T_BOOLEAN, \"Memory type must be T_BOOLEAN\");\n+    init_class_id(Class_StoreVector);\n+  }\n+\n+  virtual int Opcode() const;\n+  virtual int memory_size() const { return _mem_type->length_in_bytes(); }\n+  virtual uint size_of() const { return sizeof(StoreVectorMaskNode); }\n+};\n+\n+\/\/-------------------------- Vector mask broadcast -----------------------------------\n+class MaskAllNode : public VectorNode {\n+ public:\n+  MaskAllNode(Node* in, const TypeVect* vt) : VectorNode(in, vt) {}\n+  virtual int Opcode() const;\n+};\n+\n+\/\/--------------------------- Vector mask logical and --------------------------------\n+class AndVMaskNode : public VectorNode {\n+ public:\n+  AndVMaskNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1, in2, vt) {}\n+  virtual int Opcode() const;\n+};\n+\n+\/\/--------------------------- Vector mask logical or ---------------------------------\n+class OrVMaskNode : public VectorNode {\n+ public:\n+  OrVMaskNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1, in2, vt) {}\n+  virtual int Opcode() const;\n+};\n+\n+\/\/--------------------------- Vector mask logical xor --------------------------------\n+class XorVMaskNode : public VectorNode {\n+ public:\n+  XorVMaskNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1, in2, vt) {}\n+  virtual int Opcode() const;\n+};\n+\n@@ -1288,0 +1405,1 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":126,"deletions":8,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -1829,0 +1829,2 @@\n+  declare_c2_type(LoadVectorMaskNode, LoadVectorNode)                     \\\n+  declare_c2_type(StoreVectorMaskNode, StoreVectorNode)                   \\\n@@ -1847,0 +1849,4 @@\n+  declare_c2_type(MaskAllNode, VectorNode)                                \\\n+  declare_c2_type(AndVMaskNode, VectorNode)                               \\\n+  declare_c2_type(OrVMaskNode, VectorNode)                                \\\n+  declare_c2_type(XorVMaskNode, VectorNode)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -215,4 +215,4 @@\n-    <V extends Vector<?>>\n-    long reductionCoerced(int oprId, Class<?> vectorClass, Class<?> elementType, int length,\n-                          V v,\n-                          Function<V,Long> defaultImpl) {\n+    <V, M>\n+    long reductionCoerced(int oprId, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+                          Class<?> elementType, int length, V v, M m,\n+                          ReductionOperation<V, M> defaultImpl) {\n@@ -220,1 +220,5 @@\n-        return defaultImpl.apply(v);\n+        return defaultImpl.apply(v, m);\n+    }\n+\n+    public interface ReductionOperation<V, M> {\n+        long apply(V v, M mask);\n@@ -223,0 +227,1 @@\n+\n@@ -259,4 +264,4 @@\n-    <VM>\n-    VM unaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-               VM vm,\n-               Function<VM, VM> defaultImpl) {\n+    <V, M>\n+    V unaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass,\n+              Class<?> elementType, int length, V v, M m,\n+              UnaryOperation<V, M> defaultImpl) {\n@@ -264,1 +269,5 @@\n-        return defaultImpl.apply(vm);\n+        return defaultImpl.apply(v, m);\n+    }\n+\n+    public interface UnaryOperation<V, M> {\n+        V apply(V v, M mask);\n@@ -271,4 +280,4 @@\n-    <VM>\n-    VM binaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-                VM vm1, VM vm2,\n-                BiFunction<VM, VM, VM> defaultImpl) {\n+    <V, M>\n+    V binaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass,\n+               Class<?> elementType, int length, V v1, V v2, M m,\n+               BinaryOperation<V, M> defaultImpl) {\n@@ -276,1 +285,1 @@\n-        return defaultImpl.apply(vm1, vm2);\n+        return defaultImpl.apply(v1, v2, m);\n@@ -279,4 +288,2 @@\n-    \/* ============================================================================ *\/\n-\n-    public interface TernaryOperation<V> {\n-        V apply(V v1, V v2, V v3);\n+    public interface BinaryOperation<V, M> {\n+        V apply(V v1, V v2, M mask);\n@@ -285,0 +292,2 @@\n+    \/* ============================================================================ *\/\n+\n@@ -287,4 +296,4 @@\n-    <VM>\n-    VM ternaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-                 VM vm1, VM vm2, VM vm3,\n-                 TernaryOperation<VM> defaultImpl) {\n+    <V, M>\n+    V ternaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass,\n+                Class<?> elementType, int length, V v1, V v2, V v3, M m,\n+                TernaryOperation<V, M> defaultImpl) {\n@@ -292,1 +301,5 @@\n-        return defaultImpl.apply(vm1, vm2, vm3);\n+        return defaultImpl.apply(v1, v2, v3, m);\n+    }\n+\n+    public interface TernaryOperation<V, M> {\n+        V apply(V v1, V v2, V v3, M mask);\n@@ -316,2 +329,2 @@\n-    public interface LoadVectorOperationWithMap<C, V extends Vector<?>, E, S extends VectorSpecies<E>> {\n-        V loadWithMap(C container, int index, int[] indexMap, int indexM, S s);\n+    public interface LoadVectorMaskedOperation<C, V, E, S extends VectorSpecies<E>, M extends VectorMask<E>> {\n+        V load(C container, int index, S s, M m);\n@@ -322,2 +335,23 @@\n-    <C, V extends Vector<?>, W extends Vector<Integer>, E, S extends VectorSpecies<E>>\n-    V loadWithMap(Class<?> vectorClass, Class<E> E, int length, Class<?> vectorIndexClass,\n+    <C, V, E, S extends VectorSpecies<E>,\n+     M extends VectorMask<E>>\n+    V loadMasked(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType,\n+                 int length, Object base, long offset, M m,\n+                 C container, int index, S s,  \/\/ Arguments for default implementation\n+                 LoadVectorMaskedOperation<C, V, E, S, M> defaultImpl) {\n+        assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n+        return defaultImpl.load(container, index, s, m);\n+    }\n+\n+    \/* ============================================================================ *\/\n+\n+    public interface LoadVectorOperationWithMap<C, V extends Vector<?>, E, S extends VectorSpecies<E>,\n+                                                M extends VectorMask<E>> {\n+        V loadWithMap(C container, int index, int[] indexMap, int indexM, S s, M m);\n+    }\n+\n+    @IntrinsicCandidate\n+    public static\n+    <C, V extends Vector<?>, W extends Vector<Integer>, E,\n+     S extends VectorSpecies<E>, M extends VectorMask<E>>\n+    V loadWithMap(Class<?> vectorClass, Class<M> maskClass, Class<E> E, int length,\n+                  Class<?> vectorIndexClass,\n@@ -325,1 +359,1 @@\n-                  W index_vector,\n+                  W index_vector, M m,\n@@ -327,1 +361,1 @@\n-                  LoadVectorOperationWithMap<C, V, E, S> defaultImpl) {\n+                  LoadVectorOperationWithMap<C, V, E, S, M> defaultImpl) {\n@@ -329,1 +363,1 @@\n-        return defaultImpl.loadWithMap(container, index, indexMap, indexM, s);\n+        return defaultImpl.loadWithMap(container, index, indexMap, indexM, s, m);\n@@ -350,0 +384,17 @@\n+    public interface StoreVectorMaskedOperation<C, V extends Vector<?>, M extends VectorMask<?>> {\n+        void store(C container, int index, V v, M m);\n+    }\n+\n+    @IntrinsicCandidate\n+    public static\n+    <C, V extends Vector<?>,\n+     M extends VectorMask<?>>\n+    void storeMasked(Class<?> vectorClass, Class<M> maskClass, Class<?> elementType,\n+                     int length, Object base, long offset,   \/\/ Unsafe addressing\n+                     V v, M m,\n+                     C container, int index,      \/\/ Arguments for default implementation\n+                     StoreVectorMaskedOperation<C, V, M> defaultImpl) {\n+        assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n+        defaultImpl.store(container, index, v, m);\n+    }\n+\n@@ -352,2 +403,2 @@\n-    public interface StoreVectorOperationWithMap<C, V extends Vector<?>> {\n-        void storeWithMap(C container, int index, V v, int[] indexMap, int indexM);\n+    public interface StoreVectorOperationWithMap<C, V extends Vector<?>, M extends VectorMask<?>> {\n+        void storeWithMap(C container, int index, V v, int[] indexMap, int indexM, M m);\n@@ -358,4 +409,4 @@\n-    <C, V extends Vector<?>, W extends Vector<Integer>>\n-    void storeWithMap(Class<?> vectorClass, Class<?> elementType, int length, Class<?> vectorIndexClass,\n-                      Object base, long offset,    \/\/ Unsafe addressing\n-                      W index_vector, V v,\n+    <C, V extends Vector<?>, W extends Vector<Integer>, M extends VectorMask<?>>\n+    void storeWithMap(Class<?> vectorClass, Class<M> maskClass, Class<?> elementType,\n+                      int length, Class<?> vectorIndexClass, Object base, long offset,    \/\/ Unsafe addressing\n+                      W index_vector, V v, M m,\n@@ -363,1 +414,1 @@\n-                      StoreVectorOperationWithMap<C, V> defaultImpl) {\n+                      StoreVectorOperationWithMap<C, V, M> defaultImpl) {\n@@ -365,1 +416,1 @@\n-        defaultImpl.storeWithMap(container, index, v, indexMap, indexM);\n+        defaultImpl.storeWithMap(container, index, v, indexMap, indexM, m);\n@@ -439,2 +490,2 @@\n-    public interface VectorBroadcastIntOp<V extends Vector<?>> {\n-        V apply(V v, int n);\n+    public interface VectorBroadcastIntOp<V extends Vector<?>, M> {\n+        V apply(V v, int n, M m);\n@@ -445,4 +496,5 @@\n-    <V extends Vector<?>>\n-    V broadcastInt(int opr, Class<? extends V> vectorClass, Class<?> elementType, int length,\n-                   V v, int n,\n-                   VectorBroadcastIntOp<V> defaultImpl) {\n+    <V extends Vector<?>, M>\n+    V broadcastInt(int opr, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+                   Class<?> elementType, int length,\n+                   V v, int n, M m,\n+                   VectorBroadcastIntOp<V, M> defaultImpl) {\n@@ -450,1 +502,1 @@\n-        return defaultImpl.apply(v, n);\n+        return defaultImpl.apply(v, n, m);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":98,"deletions":46,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -117,0 +117,18 @@\n+    @Override\n+    @ForceInline\n+    @SuppressWarnings(\"unchecked\")\n+    public\n+    <F> VectorMask<F> check(Class<? extends VectorMask<F>> maskClass, Vector<F> vector) {\n+        if (!sameSpecies(maskClass, vector)) {\n+            throw AbstractSpecies.checkFailed(this, vector);\n+        }\n+        return (VectorMask<F>) this;\n+    }\n+\n+    @ForceInline\n+    private <F> boolean sameSpecies(Class<? extends VectorMask<F>> maskClass, Vector<F> vector) {\n+        boolean same = getClass() == maskClass;\n+        assert (same == (vectorSpecies() == vector.species())) : same;\n+        return same;\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractMask.java","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte128Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte128Vector) super.lanewiseTemplate(op, Byte128Mask.class, (Byte128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte128Vector lanewise(Binary op, Vector<Byte> v, VectorMask<Byte> m) {\n+        return (Byte128Vector) super.lanewiseTemplate(op, Byte128Mask.class, v, (Byte128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Byte128Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Byte> m) {\n+        return (Byte128Vector) super.lanewiseShiftTemplate(op, Byte128Mask.class, e, (Byte128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte128Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte128Vector) super.lanewiseTemplate(op, Byte128Mask.class, v1, v2, (Byte128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte128Mask.class, (Byte128Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte128Mask.class, (Byte128Mask) m);  \/\/ specialized\n@@ -650,3 +677,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte128Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte128Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -660,3 +687,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte128Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte128Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -670,3 +697,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte128Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte128Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -806,0 +833,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromArray0Template(Byte128Mask.class, a, offset, (Byte128Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -814,0 +849,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromBooleanArray0Template(Byte128Mask.class, a, offset, (Byte128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -835,0 +877,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        super.intoArray0Template(Byte128Mask.class, a, offset, (Byte128Mask) m);\n+    }\n+\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        super.intoBooleanArray0Template(Byte128Mask.class, a, offset, (Byte128Mask) m);\n+    }\n+\n@@ -842,0 +899,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte128Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte256Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte256Vector) super.lanewiseTemplate(op, Byte256Mask.class, (Byte256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte256Vector lanewise(Binary op, Vector<Byte> v, VectorMask<Byte> m) {\n+        return (Byte256Vector) super.lanewiseTemplate(op, Byte256Mask.class, v, (Byte256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Byte256Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Byte> m) {\n+        return (Byte256Vector) super.lanewiseShiftTemplate(op, Byte256Mask.class, e, (Byte256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte256Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte256Vector) super.lanewiseTemplate(op, Byte256Mask.class, v1, v2, (Byte256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte256Mask.class, (Byte256Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte256Mask.class, (Byte256Mask) m);  \/\/ specialized\n@@ -682,3 +709,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte256Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte256Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -692,3 +719,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte256Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte256Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -702,3 +729,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte256Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte256Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -838,0 +865,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromArray0Template(Byte256Mask.class, a, offset, (Byte256Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -846,0 +881,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromBooleanArray0Template(Byte256Mask.class, a, offset, (Byte256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -867,0 +909,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        super.intoArray0Template(Byte256Mask.class, a, offset, (Byte256Mask) m);\n+    }\n+\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        super.intoBooleanArray0Template(Byte256Mask.class, a, offset, (Byte256Mask) m);\n+    }\n+\n@@ -874,0 +931,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte256Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte512Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte512Vector) super.lanewiseTemplate(op, Byte512Mask.class, (Byte512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte512Vector lanewise(Binary op, Vector<Byte> v, VectorMask<Byte> m) {\n+        return (Byte512Vector) super.lanewiseTemplate(op, Byte512Mask.class, v, (Byte512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Byte512Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Byte> m) {\n+        return (Byte512Vector) super.lanewiseShiftTemplate(op, Byte512Mask.class, e, (Byte512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte512Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte512Vector) super.lanewiseTemplate(op, Byte512Mask.class, v1, v2, (Byte512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte512Mask.class, (Byte512Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte512Mask.class, (Byte512Mask) m);  \/\/ specialized\n@@ -746,3 +773,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte512Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte512Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -756,3 +783,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte512Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte512Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -766,3 +793,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte512Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte512Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -902,0 +929,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromArray0Template(Byte512Mask.class, a, offset, (Byte512Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -910,0 +945,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromBooleanArray0Template(Byte512Mask.class, a, offset, (Byte512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -931,0 +973,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        super.intoArray0Template(Byte512Mask.class, a, offset, (Byte512Mask) m);\n+    }\n+\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        super.intoBooleanArray0Template(Byte512Mask.class, a, offset, (Byte512Mask) m);\n+    }\n+\n@@ -938,0 +995,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte512Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte64Vector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (Byte64Vector) super.lanewiseTemplate(op, Byte64Mask.class, (Byte64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Byte64Vector lanewise(Binary op, Vector<Byte> v, VectorMask<Byte> m) {\n+        return (Byte64Vector) super.lanewiseTemplate(op, Byte64Mask.class, v, (Byte64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Byte64Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Byte> m) {\n+        return (Byte64Vector) super.lanewiseShiftTemplate(op, Byte64Mask.class, e, (Byte64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Byte64Vector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (Byte64Vector) super.lanewiseTemplate(op, Byte64Mask.class, v1, v2, (Byte64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte64Mask.class, (Byte64Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte64Mask.class, (Byte64Mask) m);  \/\/ specialized\n@@ -634,3 +661,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte64Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Byte64Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -644,3 +671,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte64Mask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Byte64Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -654,3 +681,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte64Mask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Byte64Mask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -790,0 +817,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromArray0Template(Byte64Mask.class, a, offset, (Byte64Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -798,0 +833,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromBooleanArray0Template(Byte64Mask.class, a, offset, (Byte64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -819,0 +861,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        super.intoArray0Template(Byte64Mask.class, a, offset, (Byte64Mask) m);\n+    }\n+\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        super.intoBooleanArray0Template(Byte64Mask.class, a, offset, (Byte64Mask) m);\n+    }\n+\n@@ -826,0 +883,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte64Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public ByteMaxVector lanewise(Unary op, VectorMask<Byte> m) {\n+        return (ByteMaxVector) super.lanewiseTemplate(op, ByteMaxMask.class, (ByteMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public ByteMaxVector lanewise(Binary op, Vector<Byte> v, VectorMask<Byte> m) {\n+        return (ByteMaxVector) super.lanewiseTemplate(op, ByteMaxMask.class, v, (ByteMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline ByteMaxVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Byte> m) {\n+        return (ByteMaxVector) super.lanewiseShiftTemplate(op, ByteMaxMask.class, e, (ByteMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    ByteMaxVector\n+    lanewise(Ternary op, Vector<Byte> v1, Vector<Byte> v2, VectorMask<Byte> m) {\n+        return (ByteMaxVector) super.lanewiseTemplate(op, ByteMaxMask.class, v1, v2, (ByteMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, ByteMaxMask.class, (ByteMaxMask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, ByteMaxMask.class, (ByteMaxMask) m);  \/\/ specialized\n@@ -620,3 +647,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, ByteMaxMask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, ByteMaxMask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -630,3 +657,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, ByteMaxMask.class, byte.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, ByteMaxMask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -640,3 +667,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, ByteMaxMask.class, byte.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, ByteMaxMask.class, null, byte.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -776,0 +803,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromArray0Template(ByteMaxMask.class, a, offset, (ByteMaxMask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -784,0 +819,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ByteVector fromBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        return super.fromBooleanArray0Template(ByteMaxMask.class, a, offset, (ByteMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -805,0 +847,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(byte[] a, int offset, VectorMask<Byte> m) {\n+        super.intoArray0Template(ByteMaxMask.class, a, offset, (ByteMaxMask) m);\n+    }\n+\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m) {\n+        super.intoBooleanArray0Template(ByteMaxMask.class, a, offset, (ByteMaxMask) m);\n+    }\n+\n@@ -812,0 +869,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteMaxVector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -176,0 +175,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -219,0 +221,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -268,0 +273,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -283,1 +291,16 @@\n-    byte rOp(byte v, FBinOp f);\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    byte rOpTemplate(byte v, VectorMask<Byte> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        byte[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Byte>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -540,1 +563,1 @@\n-                return broadcast(-1).lanewiseTemplate(XOR, this);\n+                return broadcast(-1).lanewise(XOR, this);\n@@ -543,1 +566,1 @@\n-                return broadcast(0).lanewiseTemplate(SUB, this);\n+                return broadcast(0).lanewise(SUB, this);\n@@ -548,10 +571,3 @@\n-            opc, getClass(), byte.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (byte) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (byte) Math.abs(a));\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, byte.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, ByteVector::unaryOperations));\n@@ -559,3 +575,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<ByteVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, ByteVector.class);\n@@ -566,2 +579,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -569,2 +582,34 @@\n-                                  VectorMask<Byte> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    ByteVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Byte>> maskClass,\n+                                          VectorMask<Byte> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, ByteVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<ByteVector, VectorMask<Byte>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, ByteVector.class);\n+\n+    private static UnaryOperation<ByteVector, VectorMask<Byte>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (byte) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (byte) Math.abs(a));\n+            default: return null;\n+        }\n@@ -590,0 +635,1 @@\n+\n@@ -613,1 +659,1 @@\n-                VectorMask<Byte> eqz = that.eq((byte)0);\n+                VectorMask<Byte> eqz = that.eq((byte) 0);\n@@ -619,0 +665,1 @@\n+\n@@ -621,30 +668,3 @@\n-            opc, getClass(), byte.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)Math.min(a, b));\n-                case VECTOR_OP_AND: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a & b));\n-                case VECTOR_OP_OR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a | b));\n-                case VECTOR_OP_XOR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (byte)(a ^ b));\n-                case VECTOR_OP_LSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (byte)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (byte)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (byte)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, byte.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, ByteVector::binaryOperations));\n@@ -652,3 +672,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<ByteVector>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, ByteVector.class);\n@@ -660,2 +677,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -664,1 +681,6 @@\n-                                  VectorMask<Byte> m) {\n+                                  VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    ByteVector lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<Byte>> maskClass,\n+                                          Vector<Byte> v, VectorMask<Byte> m) {\n@@ -666,4 +688,29 @@\n-        if (op == DIV) {\n-            VectorMask<Byte> eqz = that.eq((byte)0);\n-            if (eqz.and(m).anyTrue()) {\n-                throw that.divZeroException();\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL  | VO_SHIFT)) {\n+            if (op == FIRST_NONZERO) {\n+                \/\/ FIXME: Support this in the JIT.\n+                VectorMask<Byte> thisNZ\n+                    = this.viewAsIntegralLanes().compare(NE, (byte) 0);\n+                that = that.blend((byte) 0, thisNZ.cast(vspecies()));\n+                op = OR_UNCHECKED;\n+            }\n+            if (opKind(op, VO_SHIFT)) {\n+                \/\/ As per shift specification for Java, mask the shift count.\n+                \/\/ This allows the JIT to ignore some ISA details.\n+                that = that.lanewise(AND, SHIFT_MASK);\n+            }\n+            if (op == ROR || op == ROL) {\n+                return blend(lanewise(op, v), m);\n+            } else if (op == AND_NOT) {\n+                \/\/ FIXME: Support this in the JIT.\n+                that = that.lanewise(NOT);\n+                op = AND;\n+            } else if (op == DIV) {\n+                VectorMask<Byte> eqz = that.eq((byte)0);\n+                if (eqz.and(m).anyTrue()) {\n+                    throw that.divZeroException();\n+                }\n+                \/\/ suppress div\/0 exceptions in unset lanes\n+                that = that.lanewise(NOT, eqz);\n@@ -671,3 +718,0 @@\n-            \/\/ suppress div\/0 exceptions in unset lanes\n-            that = that.lanewise(NOT, eqz);\n-            return blend(lanewise(DIV, that), m);\n@@ -675,1 +719,40 @@\n-        return blend(lanewise(op, v), m);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, ByteVector::binaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<ByteVector, VectorMask<Byte>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, ByteVector.class);\n+\n+    private static BinaryOperation<ByteVector, VectorMask<Byte>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)Math.min(a, b));\n+            case VECTOR_OP_AND: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a & b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a | b));\n+            case VECTOR_OP_XOR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (byte)(a ^ b));\n+            case VECTOR_OP_LSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (byte)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (byte)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (byte)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n@@ -677,0 +760,1 @@\n+\n@@ -739,1 +823,7 @@\n-        return blend(lanewise(op, e), m);\n+        if (opKind(op, VO_SHIFT) && (byte)(int)e == e) {\n+            return lanewiseShift(op, (int) e, m);\n+        }\n+        if (op == AND_NOT) {\n+            op = AND; e = (byte) ~e;\n+        }\n+        return lanewise(op, broadcast(e), m);\n@@ -759,2 +849,1 @@\n-            && !(opKind(op, VO_SHIFT) && (int)e1 == e)\n-            ) {\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n@@ -780,1 +869,7 @@\n-        return blend(lanewise(op, e), m);\n+        byte e1 = (byte) e;\n+        if ((long)e1 != e\n+            \/\/ allow shift ops to clip down their int parameters\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n+            vspecies().checkValue(e);  \/\/ for exception\n+        }\n+        return lanewise(op, e1, m);\n@@ -802,12 +897,27 @@\n-            opc, getClass(), byte.class, length(),\n-            this, e,\n-            BIN_INT_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_LSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (byte)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (byte)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (byte)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, byte.class, length(),\n+            this, e, null,\n+            BIN_INT_IMPL.find(op, opc, ByteVector::broadcastIntOperations));\n+    }\n+\n+    \/*package-private*\/\n+    abstract ByteVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Byte> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final ByteVector\n+    lanewiseShiftTemplate(VectorOperators.Binary op,\n+                          Class<? extends VectorMask<Byte>> maskClass,\n+                          int e, VectorMask<Byte> m) {\n+        m.check(maskClass, this);\n+        assert(opKind(op, VO_SHIFT));\n+        \/\/ As per shift specification for Java, mask the shift count.\n+        e &= SHIFT_MASK;\n+        if (op == ROR || op == ROL) {\n+            return blend(lanewiseShift(op, e), m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.broadcastInt(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, e, m,\n+            BIN_INT_IMPL.find(op, opc, ByteVector::broadcastIntOperations));\n@@ -815,0 +925,1 @@\n+\n@@ -816,1 +927,1 @@\n-    ImplCache<Binary,VectorBroadcastIntOp<ByteVector>> BIN_INT_IMPL\n+    ImplCache<Binary,VectorBroadcastIntOp<ByteVector, VectorMask<Byte>>> BIN_INT_IMPL\n@@ -819,0 +930,12 @@\n+    private static VectorBroadcastIntOp<ByteVector, VectorMask<Byte>> broadcastIntOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_LSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (byte)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (byte)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (byte)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n+    }\n+\n@@ -871,6 +994,3 @@\n-            opc, getClass(), byte.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, byte.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, ByteVector::ternaryOperations));\n@@ -878,3 +998,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<ByteVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, ByteVector.class);\n@@ -888,2 +1005,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -893,2 +1010,37 @@\n-                                  VectorMask<Byte> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    ByteVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Byte>> maskClass,\n+                                          Vector<Byte> v1,\n+                                          Vector<Byte> v2,\n+                                          VectorMask<Byte> m) {\n+        ByteVector that = (ByteVector) v1;\n+        ByteVector tother = (ByteVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, ByteVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<ByteVector, VectorMask<Byte>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, ByteVector.class);\n+\n+    private static TernaryOperation<ByteVector, VectorMask<Byte>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -951,1 +1103,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1009,1 +1161,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1066,1 +1218,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2426,0 +2578,1 @@\n+                               Class<? extends VectorMask<Byte>> maskClass,\n@@ -2427,2 +2580,10 @@\n-        ByteVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            ByteVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, ByteVector::reductionOperations)));\n@@ -2443,20 +2604,3 @@\n-            opc, getClass(), byte.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((byte)0, (i, a, b) -> (byte)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((byte)1, (i, a, b) -> (byte)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (byte) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (byte) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((byte)-1, (i, a, b) -> (byte)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((byte)0, (i, a, b) -> (byte)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((byte)0, (i, a, b) -> (byte)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, byte.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, ByteVector::reductionOperations)));\n@@ -2464,0 +2608,1 @@\n+\n@@ -2465,2 +2610,22 @@\n-    ImplCache<Associative,Function<ByteVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, ByteVector.class);\n+    ImplCache<Associative, ReductionOperation<ByteVector, VectorMask<Byte>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, ByteVector.class);\n+\n+    private static ReductionOperation<ByteVector, VectorMask<Byte>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((byte)0, m, (i, a, b) -> (byte)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((byte)1, m, (i, a, b) -> (byte)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (byte) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (byte) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((byte)-1, m, (i, a, b) -> (byte)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((byte)0, m, (i, a, b) -> (byte)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((byte)0, m, (i, a, b) -> (byte)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n@@ -2756,2 +2921,1 @@\n-            ByteVector zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -2914,1 +3078,1 @@\n-            return zero.blend(zero.fromBooleanArray0(a, offset), m);\n+            return vsp.dummyVector().fromBooleanArray0(a, offset, m);\n@@ -3166,1 +3330,0 @@\n-            \/\/ FIXME: optimize\n@@ -3169,1 +3332,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -3322,1 +3485,0 @@\n-            \/\/ FIXME: optimize\n@@ -3325,1 +3487,1 @@\n-            stOp(a, offset, m, (arr, off, i, e) -> arr[off+i] = (e & 1) != 0);\n+            intoBooleanArray0(a, offset, m);\n@@ -3526,0 +3688,18 @@\n+    \/*package-private*\/\n+    abstract\n+    ByteVector fromArray0(byte[] a, int offset, VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Byte>>\n+    ByteVector fromArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n+        m.check(species());\n+        ByteSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+\n@@ -3542,0 +3722,17 @@\n+    \/*package-private*\/\n+    abstract\n+    ByteVector fromBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Byte>>\n+    ByteVector fromBooleanArray0Template(Class<M> maskClass, boolean[] a, int offset, M m) {\n+        m.check(species());\n+        ByteSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, booleanArrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> (byte) (arr_[off_ + i] ? 1 : 0)));\n+    }\n+\n@@ -3595,0 +3792,36 @@\n+    abstract\n+    void intoArray0(byte[] a, int offset, VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Byte>>\n+    void intoArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n+        m.check(species());\n+        ByteSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+\n+    abstract\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<Byte> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Byte>>\n+    void intoBooleanArray0Template(Class<M> maskClass, boolean[] a, int offset, M m) {\n+        m.check(species());\n+        ByteSpecies vsp = vspecies();\n+        ByteVector normalized = this.and((byte) 1);\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, booleanArrayAddress(a, offset),\n+            normalized, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = (e & 1) != 0));\n+    }\n+\n@@ -3626,0 +3859,1 @@\n+\n@@ -3952,1 +4186,1 @@\n-                                      AbstractMask<Byte> m,\n+                                      VectorMask<Byte> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":365,"deletions":131,"binary":false,"changes":496,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double128Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double128Vector) super.lanewiseTemplate(op, Double128Mask.class, (Double128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Double128Vector lanewise(Binary op, Vector<Double> v, VectorMask<Double> m) {\n+        return (Double128Vector) super.lanewiseTemplate(op, Double128Mask.class, v, (Double128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double128Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double128Vector) super.lanewiseTemplate(op, Double128Mask.class, v1, v2, (Double128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double128Mask.class, (Double128Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double128Mask.class, (Double128Mask) m);  \/\/ specialized\n@@ -618,3 +638,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Double128Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -628,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Double128Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -638,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double128Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double128Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -774,0 +794,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double128Mask.class, a, offset, (Double128Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double128Mask.class, a, offset, indexMap, mapOffset, (Double128Mask) m);\n+    }\n+\n@@ -797,0 +831,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double128Mask.class, a, offset, (Double128Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double128Mask.class, a, offset, indexMap, mapOffset, (Double128Mask) m);\n+    }\n+\n+\n@@ -804,0 +853,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double128Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double256Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double256Vector) super.lanewiseTemplate(op, Double256Mask.class, (Double256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Double256Vector lanewise(Binary op, Vector<Double> v, VectorMask<Double> m) {\n+        return (Double256Vector) super.lanewiseTemplate(op, Double256Mask.class, v, (Double256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double256Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double256Vector) super.lanewiseTemplate(op, Double256Mask.class, v1, v2, (Double256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double256Mask.class, (Double256Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double256Mask.class, (Double256Mask) m);  \/\/ specialized\n@@ -622,3 +642,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Double256Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -632,3 +652,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Double256Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -642,3 +662,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double256Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double256Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -778,0 +798,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double256Mask.class, a, offset, (Double256Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double256Mask.class, a, offset, indexMap, mapOffset, (Double256Mask) m);\n+    }\n+\n@@ -801,0 +835,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double256Mask.class, a, offset, (Double256Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double256Mask.class, a, offset, indexMap, mapOffset, (Double256Mask) m);\n+    }\n+\n+\n@@ -808,0 +857,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double256Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double512Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double512Vector) super.lanewiseTemplate(op, Double512Mask.class, (Double512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Double512Vector lanewise(Binary op, Vector<Double> v, VectorMask<Double> m) {\n+        return (Double512Vector) super.lanewiseTemplate(op, Double512Mask.class, v, (Double512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double512Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double512Vector) super.lanewiseTemplate(op, Double512Mask.class, v1, v2, (Double512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double512Mask.class, (Double512Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double512Mask.class, (Double512Mask) m);  \/\/ specialized\n@@ -630,3 +650,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Double512Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -640,3 +660,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Double512Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -650,3 +670,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double512Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double512Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -786,0 +806,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double512Mask.class, a, offset, (Double512Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double512Mask.class, a, offset, indexMap, mapOffset, (Double512Mask) m);\n+    }\n+\n@@ -809,0 +843,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double512Mask.class, a, offset, (Double512Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double512Mask.class, a, offset, indexMap, mapOffset, (Double512Mask) m);\n+    }\n+\n+\n@@ -816,0 +865,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double512Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Double64Vector lanewise(Unary op, VectorMask<Double> m) {\n+        return (Double64Vector) super.lanewiseTemplate(op, Double64Mask.class, (Double64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Double64Vector lanewise(Binary op, Vector<Double> v, VectorMask<Double> m) {\n+        return (Double64Vector) super.lanewiseTemplate(op, Double64Mask.class, v, (Double64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Double64Vector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (Double64Vector) super.lanewiseTemplate(op, Double64Mask.class, v1, v2, (Double64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double64Mask.class, (Double64Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double64Mask.class, (Double64Mask) m);  \/\/ specialized\n@@ -616,3 +636,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Double64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Double64Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -626,3 +646,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Double64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Double64Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -636,3 +656,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double64Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Double64Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -772,0 +792,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double64Mask.class, a, offset, (Double64Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        return super.fromArray0Template(Double64Mask.class, a, offset, indexMap, mapOffset, (Double64Mask) m);\n+    }\n+\n@@ -795,0 +829,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double64Mask.class, a, offset, (Double64Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        super.intoArray0Template(Double64Mask.class, a, offset, indexMap, mapOffset, (Double64Mask) m);\n+    }\n+\n+\n@@ -802,0 +851,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double64Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public DoubleMaxVector lanewise(Unary op, VectorMask<Double> m) {\n+        return (DoubleMaxVector) super.lanewiseTemplate(op, DoubleMaxMask.class, (DoubleMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public DoubleMaxVector lanewise(Binary op, Vector<Double> v, VectorMask<Double> m) {\n+        return (DoubleMaxVector) super.lanewiseTemplate(op, DoubleMaxMask.class, v, (DoubleMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Double> v1, Vector<Double> v2) {\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    DoubleMaxVector\n+    lanewise(Ternary op, Vector<Double> v1, Vector<Double> v2, VectorMask<Double> m) {\n+        return (DoubleMaxVector) super.lanewiseTemplate(op, DoubleMaxMask.class, v1, v2, (DoubleMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, DoubleMaxMask.class, (DoubleMaxMask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, DoubleMaxMask.class, (DoubleMaxMask) m);  \/\/ specialized\n@@ -615,3 +635,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, DoubleMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, DoubleMaxMask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -625,3 +645,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, DoubleMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, DoubleMaxMask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -635,3 +655,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, DoubleMaxMask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, DoubleMaxMask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -771,0 +791,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, VectorMask<Double> m) {\n+        return super.fromArray0Template(DoubleMaxMask.class, a, offset, (DoubleMaxMask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    DoubleVector fromArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        return super.fromArray0Template(DoubleMaxMask.class, a, offset, indexMap, mapOffset, (DoubleMaxMask) m);\n+    }\n+\n@@ -794,0 +828,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, VectorMask<Double> m) {\n+        super.intoArray0Template(DoubleMaxMask.class, a, offset, (DoubleMaxMask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(double[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Double> m) {\n+        super.intoArray0Template(DoubleMaxMask.class, a, offset, indexMap, mapOffset, (DoubleMaxMask) m);\n+    }\n+\n+\n@@ -801,0 +850,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleMaxVector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -176,0 +175,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -219,0 +221,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -268,0 +273,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -283,1 +291,16 @@\n-    double rOp(double v, FBinOp f);\n+    double rOp(double v, VectorMask<Double> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    double rOpTemplate(double v, VectorMask<Double> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        double[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Double>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -542,42 +565,3 @@\n-            opc, getClass(), double.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (double) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.abs(a));\n-                case VECTOR_OP_SIN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.sin(a));\n-                case VECTOR_OP_COS: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.cos(a));\n-                case VECTOR_OP_TAN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.tan(a));\n-                case VECTOR_OP_ASIN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.asin(a));\n-                case VECTOR_OP_ACOS: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.acos(a));\n-                case VECTOR_OP_ATAN: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.atan(a));\n-                case VECTOR_OP_EXP: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.exp(a));\n-                case VECTOR_OP_LOG: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.log(a));\n-                case VECTOR_OP_LOG10: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.log10(a));\n-                case VECTOR_OP_SQRT: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.sqrt(a));\n-                case VECTOR_OP_CBRT: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.cbrt(a));\n-                case VECTOR_OP_SINH: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.sinh(a));\n-                case VECTOR_OP_COSH: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.cosh(a));\n-                case VECTOR_OP_TANH: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.tanh(a));\n-                case VECTOR_OP_EXPM1: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.expm1(a));\n-                case VECTOR_OP_LOG1P: return v0 ->\n-                        v0.uOp((i, a) -> (double) Math.log1p(a));\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, double.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, DoubleVector::unaryOperations));\n@@ -585,3 +569,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<DoubleVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, DoubleVector.class);\n@@ -592,2 +573,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -595,2 +576,63 @@\n-                                  VectorMask<Double> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    DoubleVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Double>> maskClass,\n+                                          VectorMask<Double> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, DoubleVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<DoubleVector, VectorMask<Double>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, DoubleVector.class);\n+\n+    private static UnaryOperation<DoubleVector, VectorMask<Double>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.abs(a));\n+            case VECTOR_OP_SIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.sin(a));\n+            case VECTOR_OP_COS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.cos(a));\n+            case VECTOR_OP_TAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.tan(a));\n+            case VECTOR_OP_ASIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.asin(a));\n+            case VECTOR_OP_ACOS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.acos(a));\n+            case VECTOR_OP_ATAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.atan(a));\n+            case VECTOR_OP_EXP: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.exp(a));\n+            case VECTOR_OP_LOG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.log(a));\n+            case VECTOR_OP_LOG10: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.log10(a));\n+            case VECTOR_OP_SQRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.sqrt(a));\n+            case VECTOR_OP_CBRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.cbrt(a));\n+            case VECTOR_OP_SINH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.sinh(a));\n+            case VECTOR_OP_COSH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.cosh(a));\n+            case VECTOR_OP_TANH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.tanh(a));\n+            case VECTOR_OP_EXPM1: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.expm1(a));\n+            case VECTOR_OP_LOG1P: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (double) Math.log1p(a));\n+            default: return null;\n+        }\n@@ -616,0 +658,1 @@\n+\n@@ -629,0 +672,1 @@\n+\n@@ -631,24 +675,3 @@\n-            opc, getClass(), double.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double)Math.min(a, b));\n-                case VECTOR_OP_ATAN2: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double) Math.atan2(a, b));\n-                case VECTOR_OP_POW: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double) Math.pow(a, b));\n-                case VECTOR_OP_HYPOT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (double) Math.hypot(a, b));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, double.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, DoubleVector::binaryOperations));\n@@ -656,3 +679,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<DoubleVector>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, DoubleVector.class);\n@@ -664,2 +684,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -668,2 +688,21 @@\n-                                  VectorMask<Double> m) {\n-        return blend(lanewise(op, v), m);\n+                                  VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    DoubleVector lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<Double>> maskClass,\n+                                          Vector<Double> v, VectorMask<Double> m) {\n+        DoubleVector that = (DoubleVector) v;\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL )) {\n+            if (op == FIRST_NONZERO) {\n+                return blend(lanewise(op, v), m);\n+            }\n+        }\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, DoubleVector::binaryOperations));\n@@ -671,0 +710,31 @@\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<DoubleVector, VectorMask<Double>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, DoubleVector.class);\n+\n+    private static BinaryOperation<DoubleVector, VectorMask<Double>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double)Math.min(a, b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> fromBits(toBits(a) | toBits(b)));\n+            case VECTOR_OP_ATAN2: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double) Math.atan2(a, b));\n+            case VECTOR_OP_POW: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double) Math.pow(a, b));\n+            case VECTOR_OP_HYPOT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (double) Math.hypot(a, b));\n+            default: return null;\n+        }\n+    }\n+\n@@ -727,1 +797,1 @@\n-        return blend(lanewise(op, e), m);\n+        return lanewise(op, broadcast(e), m);\n@@ -745,2 +815,1 @@\n-        if ((long)e1 != e\n-            ) {\n+        if ((long)e1 != e) {\n@@ -766,1 +835,5 @@\n-        return blend(lanewise(op, e), m);\n+        double e1 = (double) e;\n+        if ((long)e1 != e) {\n+            vspecies().checkValue(e);  \/\/ for exception\n+        }\n+        return lanewise(op, e1, m);\n@@ -808,8 +881,3 @@\n-            opc, getClass(), double.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_FMA: return (v0, v1_, v2_) ->\n-                        v0.tOp(v1_, v2_, (i, a, b, c) -> Math.fma(a, b, c));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, double.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, DoubleVector::ternaryOperations));\n@@ -817,3 +885,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<DoubleVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, DoubleVector.class);\n@@ -827,2 +892,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -832,2 +897,34 @@\n-                                  VectorMask<Double> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    DoubleVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Double>> maskClass,\n+                                          Vector<Double> v1,\n+                                          Vector<Double> v2,\n+                                          VectorMask<Double> m) {\n+        DoubleVector that = (DoubleVector) v1;\n+        DoubleVector tother = (DoubleVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, DoubleVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<DoubleVector, VectorMask<Double>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, DoubleVector.class);\n+\n+    private static TernaryOperation<DoubleVector, VectorMask<Double>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_FMA: return (v0, v1_, v2_, m) ->\n+                    v0.tOp(v1_, v2_, m, (i, a, b, c) -> Math.fma(a, b, c));\n+            default: return null;\n+        }\n@@ -890,1 +987,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -948,1 +1045,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1005,1 +1102,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2311,0 +2408,1 @@\n+                               Class<? extends VectorMask<Double>> maskClass,\n@@ -2312,2 +2410,10 @@\n-        DoubleVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            DoubleVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, DoubleVector::reductionOperations)));\n@@ -2328,14 +2434,3 @@\n-            opc, getClass(), double.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((double)0, (i, a, b) -> (double)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((double)1, (i, a, b) -> (double)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (double) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (double) Math.max(a, b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, double.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, DoubleVector::reductionOperations)));\n@@ -2343,0 +2438,1 @@\n+\n@@ -2344,2 +2440,16 @@\n-    ImplCache<Associative,Function<DoubleVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, DoubleVector.class);\n+    ImplCache<Associative, ReductionOperation<DoubleVector, VectorMask<Double>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, DoubleVector.class);\n+\n+    private static ReductionOperation<DoubleVector, VectorMask<Double>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((double)0, m, (i, a, b) -> (double)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((double)1, m, (i, a, b) -> (double)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (double) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (double) Math.max(a, b)));\n+            default: return null;\n+        }\n+    }\n@@ -2615,2 +2725,1 @@\n-            DoubleVector zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -2692,3 +2801,3 @@\n-            vectorType, double.class, vsp.laneCount(),\n-            IntVector.species(vsp.indexShape()).vectorType(),\n-            a, ARRAY_BASE, vix,\n+            vectorType, null, double.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, null,\n@@ -2696,1 +2805,1 @@\n-            (double[] c, int idx, int[] iMap, int idy, DoubleSpecies s) ->\n+            (c, idx, iMap, idy, s, vm) ->\n@@ -2698,1 +2807,1 @@\n-        }\n+    }\n@@ -2746,1 +2855,0 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n@@ -2748,1 +2856,1 @@\n-            return vsp.vOp(m, n -> a[offset + indexMap[mapOffset + n]]);\n+            return vsp.dummyVector().fromArray0(a, offset, indexMap, mapOffset, m);\n@@ -2916,1 +3024,0 @@\n-            \/\/ FIXME: optimize\n@@ -2919,1 +3026,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -2982,1 +3089,1 @@\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n+            vsp.vectorType(), null, vsp.elementType(), vsp.laneCount(),\n@@ -2985,1 +3092,1 @@\n-            this,\n+            this, null,\n@@ -2987,1 +3094,1 @@\n-            (arr, off, v, map, mo)\n+            (arr, off, v, map, mo, vm)\n@@ -3034,6 +3141,1 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n-            stOp(a, offset, m,\n-                 (arr, off, i, e) -> {\n-                     int j = indexMap[mapOffset + i];\n-                     arr[off + j] = e;\n-                 });\n+            intoArray0(a, offset, indexMap, mapOffset, m);\n@@ -3151,0 +3253,69 @@\n+    \/*package-private*\/\n+    abstract\n+    DoubleVector fromArray0(double[] a, int offset, VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Double>>\n+    DoubleVector fromArray0Template(Class<M> maskClass, double[] a, int offset, M m) {\n+        m.check(species());\n+        DoubleSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+    \/*package-private*\/\n+    abstract\n+    DoubleVector fromArray0(double[] a, int offset,\n+                                    int[] indexMap, int mapOffset,\n+                                    VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Double>>\n+    DoubleVector fromArray0Template(Class<M> maskClass, double[] a, int offset,\n+                                            int[] indexMap, int mapOffset, M m) {\n+        DoubleSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        Objects.requireNonNull(a);\n+        Objects.requireNonNull(indexMap);\n+        m.check(vsp);\n+        Class<? extends DoubleVector> vectorType = vsp.vectorType();\n+\n+        if (vsp.laneCount() == 1) {\n+          return DoubleVector.fromArray(vsp, a, offset + indexMap[mapOffset], m);\n+        }\n+\n+        \/\/ Index vector: vix[0:n] = k -> offset + indexMap[mapOffset + k]\n+        IntVector vix;\n+        if (isp.laneCount() != vsp.laneCount()) {\n+            \/\/ For DoubleMaxVector,  if vector length is non-power-of-two or\n+            \/\/ 2048 bits, indexShape of Double species is S_MAX_BIT.\n+            \/\/ Assume that vector length is 2048, then the lane count of Double\n+            \/\/ vector is 32. When converting Double species to int species,\n+            \/\/ indexShape is still S_MAX_BIT, but the lane count of int vector\n+            \/\/ is 64. So when loading index vector (IntVector), only lower half\n+            \/\/ of index data is needed.\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset, IntMaxVector.IntMaxMask.LOWER_HALF_TRUE_MASK)\n+                .add(offset);\n+        } else {\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset)\n+                .add(offset);\n+        }\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        return VectorSupport.loadWithMap(\n+            vectorType, maskClass, double.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, m,\n+            a, offset, indexMap, mapOffset, vsp,\n+            (c, idx, iMap, idy, s, vm) ->\n+            s.vOp(vm, n -> c[idx + iMap[idy+n]]));\n+    }\n+\n@@ -3206,0 +3377,71 @@\n+    abstract\n+    void intoArray0(double[] a, int offset, VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Double>>\n+    void intoArray0Template(Class<M> maskClass, double[] a, int offset, M m) {\n+        m.check(species());\n+        DoubleSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+    abstract\n+    void intoArray0(double[] a, int offset,\n+                    int[] indexMap, int mapOffset,\n+                    VectorMask<Double> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Double>>\n+    void intoArray0Template(Class<M> maskClass, double[] a, int offset,\n+                            int[] indexMap, int mapOffset, M m) {\n+        m.check(species());\n+        DoubleSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        if (vsp.laneCount() == 1) {\n+            intoArray(a, offset + indexMap[mapOffset], m);\n+            return;\n+        }\n+\n+        \/\/ Index vector: vix[0:n] = i -> offset + indexMap[mo + i]\n+        IntVector vix;\n+        if (isp.laneCount() != vsp.laneCount()) {\n+            \/\/ For DoubleMaxVector,  if vector length  is 2048 bits, indexShape\n+            \/\/ of Double species is S_MAX_BIT. and the lane count of Double\n+            \/\/ vector is 32. When converting Double species to int species,\n+            \/\/ indexShape is still S_MAX_BIT, but the lane count of int vector\n+            \/\/ is 64. So when loading index vector (IntVector), only lower half\n+            \/\/ of index data is needed.\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset, IntMaxVector.IntMaxMask.LOWER_HALF_TRUE_MASK)\n+                .add(offset);\n+        } else {\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset)\n+                .add(offset);\n+        }\n+\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        VectorSupport.storeWithMap(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            isp.vectorType(),\n+            a, arrayAddress(a, 0), vix,\n+            this, m,\n+            a, offset, indexMap, mapOffset,\n+            (arr, off, v, map, mo, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> {\n+                          int j = map[mo + i];\n+                          arr[off + j] = e;\n+                      }));\n+    }\n+\n+\n@@ -3237,0 +3479,1 @@\n+\n@@ -3554,1 +3797,1 @@\n-                                      AbstractMask<Double> m,\n+                                      VectorMask<Double> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":386,"deletions":143,"binary":false,"changes":529,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float128Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float128Vector) super.lanewiseTemplate(op, Float128Mask.class, (Float128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Float128Vector lanewise(Binary op, Vector<Float> v, VectorMask<Float> m) {\n+        return (Float128Vector) super.lanewiseTemplate(op, Float128Mask.class, v, (Float128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float128Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float128Vector) super.lanewiseTemplate(op, Float128Mask.class, v1, v2, (Float128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float128Mask.class, (Float128Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float128Mask.class, (Float128Mask) m);  \/\/ specialized\n@@ -622,3 +642,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Float128Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -632,3 +652,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Float128Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -642,3 +662,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float128Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float128Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -778,0 +798,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float128Mask.class, a, offset, (Float128Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float128Mask.class, a, offset, indexMap, mapOffset, (Float128Mask) m);\n+    }\n+\n@@ -801,0 +835,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float128Mask.class, a, offset, (Float128Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float128Mask.class, a, offset, indexMap, mapOffset, (Float128Mask) m);\n+    }\n+\n+\n@@ -808,0 +857,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float128Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float256Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float256Vector) super.lanewiseTemplate(op, Float256Mask.class, (Float256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Float256Vector lanewise(Binary op, Vector<Float> v, VectorMask<Float> m) {\n+        return (Float256Vector) super.lanewiseTemplate(op, Float256Mask.class, v, (Float256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float256Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float256Vector) super.lanewiseTemplate(op, Float256Mask.class, v1, v2, (Float256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float256Mask.class, (Float256Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float256Mask.class, (Float256Mask) m);  \/\/ specialized\n@@ -630,3 +650,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Float256Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -640,3 +660,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Float256Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -650,3 +670,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float256Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float256Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -786,0 +806,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float256Mask.class, a, offset, (Float256Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float256Mask.class, a, offset, indexMap, mapOffset, (Float256Mask) m);\n+    }\n+\n@@ -809,0 +843,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float256Mask.class, a, offset, (Float256Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float256Mask.class, a, offset, indexMap, mapOffset, (Float256Mask) m);\n+    }\n+\n+\n@@ -816,0 +865,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float256Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float512Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float512Vector) super.lanewiseTemplate(op, Float512Mask.class, (Float512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Float512Vector lanewise(Binary op, Vector<Float> v, VectorMask<Float> m) {\n+        return (Float512Vector) super.lanewiseTemplate(op, Float512Mask.class, v, (Float512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float512Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float512Vector) super.lanewiseTemplate(op, Float512Mask.class, v1, v2, (Float512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float512Mask.class, (Float512Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float512Mask.class, (Float512Mask) m);  \/\/ specialized\n@@ -646,3 +666,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Float512Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -656,3 +676,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Float512Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -666,3 +686,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float512Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float512Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -802,0 +822,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float512Mask.class, a, offset, (Float512Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float512Mask.class, a, offset, indexMap, mapOffset, (Float512Mask) m);\n+    }\n+\n@@ -825,0 +859,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float512Mask.class, a, offset, (Float512Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float512Mask.class, a, offset, indexMap, mapOffset, (Float512Mask) m);\n+    }\n+\n+\n@@ -832,0 +881,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float512Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Float64Vector lanewise(Unary op, VectorMask<Float> m) {\n+        return (Float64Vector) super.lanewiseTemplate(op, Float64Mask.class, (Float64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Float64Vector lanewise(Binary op, Vector<Float> v, VectorMask<Float> m) {\n+        return (Float64Vector) super.lanewiseTemplate(op, Float64Mask.class, v, (Float64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Float64Vector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (Float64Vector) super.lanewiseTemplate(op, Float64Mask.class, v1, v2, (Float64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float64Mask.class, (Float64Mask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float64Mask.class, (Float64Mask) m);  \/\/ specialized\n@@ -618,3 +638,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Float64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Float64Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -628,3 +648,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Float64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Float64Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -638,3 +658,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float64Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Float64Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -774,0 +794,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float64Mask.class, a, offset, (Float64Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        return super.fromArray0Template(Float64Mask.class, a, offset, indexMap, mapOffset, (Float64Mask) m);\n+    }\n+\n@@ -797,0 +831,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float64Mask.class, a, offset, (Float64Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        super.intoArray0Template(Float64Mask.class, a, offset, indexMap, mapOffset, (Float64Mask) m);\n+    }\n+\n+\n@@ -804,0 +853,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float64Vector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public FloatMaxVector lanewise(Unary op, VectorMask<Float> m) {\n+        return (FloatMaxVector) super.lanewiseTemplate(op, FloatMaxMask.class, (FloatMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public FloatMaxVector lanewise(Binary op, Vector<Float> v, VectorMask<Float> m) {\n+        return (FloatMaxVector) super.lanewiseTemplate(op, FloatMaxMask.class, v, (FloatMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -288,1 +300,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Float> v1, Vector<Float> v2) {\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2) {\n@@ -292,0 +304,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    FloatMaxVector\n+    lanewise(Ternary op, Vector<Float> v1, Vector<Float> v2, VectorMask<Float> m) {\n+        return (FloatMaxVector) super.lanewiseTemplate(op, FloatMaxMask.class, v1, v2, (FloatMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -311,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, FloatMaxMask.class, (FloatMaxMask) m);  \/\/ specialized\n@@ -324,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, FloatMaxMask.class, (FloatMaxMask) m);  \/\/ specialized\n@@ -615,3 +635,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, FloatMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, FloatMaxMask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -625,3 +645,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, FloatMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, FloatMaxMask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -635,3 +655,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, FloatMaxMask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, FloatMaxMask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -771,0 +791,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, VectorMask<Float> m) {\n+        return super.fromArray0Template(FloatMaxMask.class, a, offset, (FloatMaxMask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    FloatVector fromArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        return super.fromArray0Template(FloatMaxMask.class, a, offset, indexMap, mapOffset, (FloatMaxMask) m);\n+    }\n+\n@@ -794,0 +828,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, VectorMask<Float> m) {\n+        super.intoArray0Template(FloatMaxMask.class, a, offset, (FloatMaxMask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(float[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Float> m) {\n+        super.intoArray0Template(FloatMaxMask.class, a, offset, indexMap, mapOffset, (FloatMaxMask) m);\n+    }\n+\n+\n@@ -801,0 +850,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatMaxVector.java","additions":64,"deletions":14,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -176,0 +175,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -219,0 +221,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -268,0 +273,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -283,1 +291,16 @@\n-    float rOp(float v, FBinOp f);\n+    float rOp(float v, VectorMask<Float> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    float rOpTemplate(float v, VectorMask<Float> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        float[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Float>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -542,42 +565,3 @@\n-            opc, getClass(), float.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (float) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.abs(a));\n-                case VECTOR_OP_SIN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.sin(a));\n-                case VECTOR_OP_COS: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.cos(a));\n-                case VECTOR_OP_TAN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.tan(a));\n-                case VECTOR_OP_ASIN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.asin(a));\n-                case VECTOR_OP_ACOS: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.acos(a));\n-                case VECTOR_OP_ATAN: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.atan(a));\n-                case VECTOR_OP_EXP: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.exp(a));\n-                case VECTOR_OP_LOG: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.log(a));\n-                case VECTOR_OP_LOG10: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.log10(a));\n-                case VECTOR_OP_SQRT: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.sqrt(a));\n-                case VECTOR_OP_CBRT: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.cbrt(a));\n-                case VECTOR_OP_SINH: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.sinh(a));\n-                case VECTOR_OP_COSH: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.cosh(a));\n-                case VECTOR_OP_TANH: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.tanh(a));\n-                case VECTOR_OP_EXPM1: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.expm1(a));\n-                case VECTOR_OP_LOG1P: return v0 ->\n-                        v0.uOp((i, a) -> (float) Math.log1p(a));\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, float.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, FloatVector::unaryOperations));\n@@ -585,3 +569,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<FloatVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, FloatVector.class);\n@@ -592,2 +573,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -595,2 +576,63 @@\n-                                  VectorMask<Float> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    FloatVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Float>> maskClass,\n+                                          VectorMask<Float> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, FloatVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<FloatVector, VectorMask<Float>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, FloatVector.class);\n+\n+    private static UnaryOperation<FloatVector, VectorMask<Float>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.abs(a));\n+            case VECTOR_OP_SIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.sin(a));\n+            case VECTOR_OP_COS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.cos(a));\n+            case VECTOR_OP_TAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.tan(a));\n+            case VECTOR_OP_ASIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.asin(a));\n+            case VECTOR_OP_ACOS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.acos(a));\n+            case VECTOR_OP_ATAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.atan(a));\n+            case VECTOR_OP_EXP: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.exp(a));\n+            case VECTOR_OP_LOG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.log(a));\n+            case VECTOR_OP_LOG10: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.log10(a));\n+            case VECTOR_OP_SQRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.sqrt(a));\n+            case VECTOR_OP_CBRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.cbrt(a));\n+            case VECTOR_OP_SINH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.sinh(a));\n+            case VECTOR_OP_COSH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.cosh(a));\n+            case VECTOR_OP_TANH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.tanh(a));\n+            case VECTOR_OP_EXPM1: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.expm1(a));\n+            case VECTOR_OP_LOG1P: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (float) Math.log1p(a));\n+            default: return null;\n+        }\n@@ -616,0 +658,1 @@\n+\n@@ -629,0 +672,1 @@\n+\n@@ -631,24 +675,3 @@\n-            opc, getClass(), float.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float)Math.min(a, b));\n-                case VECTOR_OP_ATAN2: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float) Math.atan2(a, b));\n-                case VECTOR_OP_POW: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float) Math.pow(a, b));\n-                case VECTOR_OP_HYPOT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (float) Math.hypot(a, b));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, float.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, FloatVector::binaryOperations));\n@@ -656,3 +679,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<FloatVector>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, FloatVector.class);\n@@ -664,2 +684,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -668,2 +688,21 @@\n-                                  VectorMask<Float> m) {\n-        return blend(lanewise(op, v), m);\n+                                  VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    FloatVector lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<Float>> maskClass,\n+                                          Vector<Float> v, VectorMask<Float> m) {\n+        FloatVector that = (FloatVector) v;\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL )) {\n+            if (op == FIRST_NONZERO) {\n+                return blend(lanewise(op, v), m);\n+            }\n+        }\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, FloatVector::binaryOperations));\n@@ -671,0 +710,31 @@\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<FloatVector, VectorMask<Float>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, FloatVector.class);\n+\n+    private static BinaryOperation<FloatVector, VectorMask<Float>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float)Math.min(a, b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> fromBits(toBits(a) | toBits(b)));\n+            case VECTOR_OP_ATAN2: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float) Math.atan2(a, b));\n+            case VECTOR_OP_POW: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float) Math.pow(a, b));\n+            case VECTOR_OP_HYPOT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (float) Math.hypot(a, b));\n+            default: return null;\n+        }\n+    }\n+\n@@ -727,1 +797,1 @@\n-        return blend(lanewise(op, e), m);\n+        return lanewise(op, broadcast(e), m);\n@@ -745,2 +815,1 @@\n-        if ((long)e1 != e\n-            ) {\n+        if ((long)e1 != e) {\n@@ -766,1 +835,5 @@\n-        return blend(lanewise(op, e), m);\n+        float e1 = (float) e;\n+        if ((long)e1 != e) {\n+            vspecies().checkValue(e);  \/\/ for exception\n+        }\n+        return lanewise(op, e1, m);\n@@ -808,8 +881,3 @@\n-            opc, getClass(), float.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_FMA: return (v0, v1_, v2_) ->\n-                        v0.tOp(v1_, v2_, (i, a, b, c) -> Math.fma(a, b, c));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, float.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, FloatVector::ternaryOperations));\n@@ -817,3 +885,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<FloatVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, FloatVector.class);\n@@ -827,2 +892,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -832,2 +897,34 @@\n-                                  VectorMask<Float> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    FloatVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Float>> maskClass,\n+                                          Vector<Float> v1,\n+                                          Vector<Float> v2,\n+                                          VectorMask<Float> m) {\n+        FloatVector that = (FloatVector) v1;\n+        FloatVector tother = (FloatVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, FloatVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<FloatVector, VectorMask<Float>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, FloatVector.class);\n+\n+    private static TernaryOperation<FloatVector, VectorMask<Float>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_FMA: return (v0, v1_, v2_, m) ->\n+                    v0.tOp(v1_, v2_, m, (i, a, b, c) -> Math.fma(a, b, c));\n+            default: return null;\n+        }\n@@ -890,1 +987,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -948,1 +1045,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1005,1 +1102,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2331,0 +2428,1 @@\n+                               Class<? extends VectorMask<Float>> maskClass,\n@@ -2332,2 +2430,10 @@\n-        FloatVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            FloatVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, FloatVector::reductionOperations)));\n@@ -2348,14 +2454,3 @@\n-            opc, getClass(), float.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((float)0, (i, a, b) -> (float)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((float)1, (i, a, b) -> (float)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (float) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (float) Math.max(a, b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, float.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, FloatVector::reductionOperations)));\n@@ -2363,0 +2458,1 @@\n+\n@@ -2364,2 +2460,16 @@\n-    ImplCache<Associative,Function<FloatVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, FloatVector.class);\n+    ImplCache<Associative, ReductionOperation<FloatVector, VectorMask<Float>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, FloatVector.class);\n+\n+    private static ReductionOperation<FloatVector, VectorMask<Float>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((float)0, m, (i, a, b) -> (float)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((float)1, m, (i, a, b) -> (float)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (float) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (float) Math.max(a, b)));\n+            default: return null;\n+        }\n+    }\n@@ -2639,2 +2749,1 @@\n-            FloatVector zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -2698,3 +2807,3 @@\n-            vectorType, float.class, vsp.laneCount(),\n-            IntVector.species(vsp.indexShape()).vectorType(),\n-            a, ARRAY_BASE, vix,\n+            vectorType, null, float.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, null,\n@@ -2702,1 +2811,1 @@\n-            (float[] c, int idx, int[] iMap, int idy, FloatSpecies s) ->\n+            (c, idx, iMap, idy, s, vm) ->\n@@ -2704,1 +2813,1 @@\n-        }\n+    }\n@@ -2752,1 +2861,0 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n@@ -2754,1 +2862,1 @@\n-            return vsp.vOp(m, n -> a[offset + indexMap[mapOffset + n]]);\n+            return vsp.dummyVector().fromArray0(a, offset, indexMap, mapOffset, m);\n@@ -2922,1 +3030,0 @@\n-            \/\/ FIXME: optimize\n@@ -2925,1 +3032,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -2969,1 +3076,1 @@\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n+            vsp.vectorType(), null, vsp.elementType(), vsp.laneCount(),\n@@ -2972,1 +3079,1 @@\n-            this,\n+            this, null,\n@@ -2974,1 +3081,1 @@\n-            (arr, off, v, map, mo)\n+            (arr, off, v, map, mo, vm)\n@@ -3021,6 +3128,1 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n-            stOp(a, offset, m,\n-                 (arr, off, i, e) -> {\n-                     int j = indexMap[mapOffset + i];\n-                     arr[off + j] = e;\n-                 });\n+            intoArray0(a, offset, indexMap, mapOffset, m);\n@@ -3138,0 +3240,51 @@\n+    \/*package-private*\/\n+    abstract\n+    FloatVector fromArray0(float[] a, int offset, VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Float>>\n+    FloatVector fromArray0Template(Class<M> maskClass, float[] a, int offset, M m) {\n+        m.check(species());\n+        FloatSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+    \/*package-private*\/\n+    abstract\n+    FloatVector fromArray0(float[] a, int offset,\n+                                    int[] indexMap, int mapOffset,\n+                                    VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Float>>\n+    FloatVector fromArray0Template(Class<M> maskClass, float[] a, int offset,\n+                                            int[] indexMap, int mapOffset, M m) {\n+        FloatSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        Objects.requireNonNull(a);\n+        Objects.requireNonNull(indexMap);\n+        m.check(vsp);\n+        Class<? extends FloatVector> vectorType = vsp.vectorType();\n+\n+        \/\/ Index vector: vix[0:n] = k -> offset + indexMap[mapOffset + k]\n+        IntVector vix = IntVector\n+            .fromArray(isp, indexMap, mapOffset)\n+            .add(offset);\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        return VectorSupport.loadWithMap(\n+            vectorType, maskClass, float.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, m,\n+            a, offset, indexMap, mapOffset, vsp,\n+            (c, idx, iMap, idy, s, vm) ->\n+            s.vOp(vm, n -> c[idx + iMap[idy+n]]));\n+    }\n+\n@@ -3193,0 +3346,52 @@\n+    abstract\n+    void intoArray0(float[] a, int offset, VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Float>>\n+    void intoArray0Template(Class<M> maskClass, float[] a, int offset, M m) {\n+        m.check(species());\n+        FloatSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+    abstract\n+    void intoArray0(float[] a, int offset,\n+                    int[] indexMap, int mapOffset,\n+                    VectorMask<Float> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Float>>\n+    void intoArray0Template(Class<M> maskClass, float[] a, int offset,\n+                            int[] indexMap, int mapOffset, M m) {\n+        m.check(species());\n+        FloatSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        \/\/ Index vector: vix[0:n] = i -> offset + indexMap[mo + i]\n+        IntVector vix = IntVector\n+            .fromArray(isp, indexMap, mapOffset)\n+            .add(offset);\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        VectorSupport.storeWithMap(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            isp.vectorType(),\n+            a, arrayAddress(a, 0), vix,\n+            this, m,\n+            a, offset, indexMap, mapOffset,\n+            (arr, off, v, map, mo, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> {\n+                          int j = map[mo + i];\n+                          arr[off + j] = e;\n+                      }));\n+    }\n+\n+\n@@ -3224,0 +3429,1 @@\n+\n@@ -3541,1 +3747,1 @@\n-                                      AbstractMask<Float> m,\n+                                      VectorMask<Float> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":349,"deletions":143,"binary":false,"changes":492,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int128Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int128Vector) super.lanewiseTemplate(op, Int128Mask.class, (Int128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Int128Vector lanewise(Binary op, Vector<Integer> v, VectorMask<Integer> m) {\n+        return (Int128Vector) super.lanewiseTemplate(op, Int128Mask.class, v, (Int128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Int128Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Integer> m) {\n+        return (Int128Vector) super.lanewiseShiftTemplate(op, Int128Mask.class, e, (Int128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int128Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int128Vector) super.lanewiseTemplate(op, Int128Mask.class, v1, v2, (Int128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int128Mask.class, (Int128Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int128Mask.class, (Int128Mask) m);  \/\/ specialized\n@@ -626,3 +653,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Int128Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -636,3 +663,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int128Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Int128Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -646,3 +673,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int128Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int128Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -782,0 +809,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int128Mask.class, a, offset, (Int128Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int128Mask.class, a, offset, indexMap, mapOffset, (Int128Mask) m);\n+    }\n+\n@@ -805,0 +846,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int128Mask.class, a, offset, (Int128Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int128Mask.class, a, offset, indexMap, mapOffset, (Int128Mask) m);\n+    }\n+\n+\n@@ -812,0 +868,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int128Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int256Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int256Vector) super.lanewiseTemplate(op, Int256Mask.class, (Int256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Int256Vector lanewise(Binary op, Vector<Integer> v, VectorMask<Integer> m) {\n+        return (Int256Vector) super.lanewiseTemplate(op, Int256Mask.class, v, (Int256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Int256Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Integer> m) {\n+        return (Int256Vector) super.lanewiseShiftTemplate(op, Int256Mask.class, e, (Int256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int256Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int256Vector) super.lanewiseTemplate(op, Int256Mask.class, v1, v2, (Int256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int256Mask.class, (Int256Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int256Mask.class, (Int256Mask) m);  \/\/ specialized\n@@ -634,3 +661,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Int256Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -644,3 +671,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int256Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Int256Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -654,3 +681,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int256Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int256Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -790,0 +817,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int256Mask.class, a, offset, (Int256Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int256Mask.class, a, offset, indexMap, mapOffset, (Int256Mask) m);\n+    }\n+\n@@ -813,0 +854,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int256Mask.class, a, offset, (Int256Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int256Mask.class, a, offset, indexMap, mapOffset, (Int256Mask) m);\n+    }\n+\n+\n@@ -820,0 +876,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int256Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int512Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int512Vector) super.lanewiseTemplate(op, Int512Mask.class, (Int512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Int512Vector lanewise(Binary op, Vector<Integer> v, VectorMask<Integer> m) {\n+        return (Int512Vector) super.lanewiseTemplate(op, Int512Mask.class, v, (Int512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Int512Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Integer> m) {\n+        return (Int512Vector) super.lanewiseShiftTemplate(op, Int512Mask.class, e, (Int512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int512Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int512Vector) super.lanewiseTemplate(op, Int512Mask.class, v1, v2, (Int512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int512Mask.class, (Int512Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int512Mask.class, (Int512Mask) m);  \/\/ specialized\n@@ -650,3 +677,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Int512Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -660,3 +687,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int512Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Int512Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -670,3 +697,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int512Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int512Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -806,0 +833,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int512Mask.class, a, offset, (Int512Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int512Mask.class, a, offset, indexMap, mapOffset, (Int512Mask) m);\n+    }\n+\n@@ -829,0 +870,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int512Mask.class, a, offset, (Int512Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int512Mask.class, a, offset, indexMap, mapOffset, (Int512Mask) m);\n+    }\n+\n+\n@@ -836,0 +892,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int512Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Int64Vector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (Int64Vector) super.lanewiseTemplate(op, Int64Mask.class, (Int64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Int64Vector lanewise(Binary op, Vector<Integer> v, VectorMask<Integer> m) {\n+        return (Int64Vector) super.lanewiseTemplate(op, Int64Mask.class, v, (Int64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Int64Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Integer> m) {\n+        return (Int64Vector) super.lanewiseShiftTemplate(op, Int64Mask.class, e, (Int64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Int64Vector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (Int64Vector) super.lanewiseTemplate(op, Int64Mask.class, v1, v2, (Int64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int64Mask.class, (Int64Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int64Mask.class, (Int64Mask) m);  \/\/ specialized\n@@ -622,3 +649,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Int64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Int64Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -632,3 +659,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Int64Mask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Int64Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -642,3 +669,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int64Mask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Int64Mask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -778,0 +805,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int64Mask.class, a, offset, (Int64Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(Int64Mask.class, a, offset, indexMap, mapOffset, (Int64Mask) m);\n+    }\n+\n@@ -801,0 +842,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int64Mask.class, a, offset, (Int64Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        super.intoArray0Template(Int64Mask.class, a, offset, indexMap, mapOffset, (Int64Mask) m);\n+    }\n+\n+\n@@ -808,0 +864,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int64Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public IntMaxVector lanewise(Unary op, VectorMask<Integer> m) {\n+        return (IntMaxVector) super.lanewiseTemplate(op, IntMaxMask.class, (IntMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public IntMaxVector lanewise(Binary op, Vector<Integer> v, VectorMask<Integer> m) {\n+        return (IntMaxVector) super.lanewiseTemplate(op, IntMaxMask.class, v, (IntMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline IntMaxVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Integer> m) {\n+        return (IntMaxVector) super.lanewiseShiftTemplate(op, IntMaxMask.class, e, (IntMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    IntMaxVector\n+    lanewise(Ternary op, Vector<Integer> v1, Vector<Integer> v2, VectorMask<Integer> m) {\n+        return (IntMaxVector) super.lanewiseTemplate(op, IntMaxMask.class, v1, v2, (IntMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, IntMaxMask.class, (IntMaxMask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, IntMaxMask.class, (IntMaxMask) m);  \/\/ specialized\n@@ -620,3 +647,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, IntMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, IntMaxMask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -630,3 +657,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, IntMaxMask.class, int.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, IntMaxMask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -640,3 +667,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, IntMaxMask.class, int.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, IntMaxMask.class, null, int.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -787,0 +814,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(IntMaxMask.class, a, offset, (IntMaxMask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    IntVector fromArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        return super.fromArray0Template(IntMaxMask.class, a, offset, indexMap, mapOffset, (IntMaxMask) m);\n+    }\n+\n@@ -810,0 +851,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, VectorMask<Integer> m) {\n+        super.intoArray0Template(IntMaxMask.class, a, offset, (IntMaxMask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(int[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Integer> m) {\n+        super.intoArray0Template(IntMaxMask.class, a, offset, indexMap, mapOffset, (IntMaxMask) m);\n+    }\n+\n+\n@@ -817,0 +873,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntMaxVector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -176,0 +175,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -219,0 +221,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -268,0 +273,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -283,1 +291,16 @@\n-    int rOp(int v, FBinOp f);\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    int rOpTemplate(int v, VectorMask<Integer> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        int[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Integer>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -540,1 +563,1 @@\n-                return broadcast(-1).lanewiseTemplate(XOR, this);\n+                return broadcast(-1).lanewise(XOR, this);\n@@ -543,1 +566,1 @@\n-                return broadcast(0).lanewiseTemplate(SUB, this);\n+                return broadcast(0).lanewise(SUB, this);\n@@ -548,10 +571,3 @@\n-            opc, getClass(), int.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (int) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (int) Math.abs(a));\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, int.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, IntVector::unaryOperations));\n@@ -559,3 +575,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<IntVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, IntVector.class);\n@@ -566,2 +579,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -569,2 +582,34 @@\n-                                  VectorMask<Integer> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    IntVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Integer>> maskClass,\n+                                          VectorMask<Integer> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, IntVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<IntVector, VectorMask<Integer>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, IntVector.class);\n+\n+    private static UnaryOperation<IntVector, VectorMask<Integer>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (int) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (int) Math.abs(a));\n+            default: return null;\n+        }\n@@ -590,0 +635,1 @@\n+\n@@ -613,1 +659,1 @@\n-                VectorMask<Integer> eqz = that.eq((int)0);\n+                VectorMask<Integer> eqz = that.eq((int) 0);\n@@ -619,0 +665,1 @@\n+\n@@ -621,30 +668,3 @@\n-            opc, getClass(), int.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)Math.min(a, b));\n-                case VECTOR_OP_AND: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a & b));\n-                case VECTOR_OP_OR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a | b));\n-                case VECTOR_OP_XOR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (int)(a ^ b));\n-                case VECTOR_OP_LSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (int)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (int)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (int)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, int.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, IntVector::binaryOperations));\n@@ -652,3 +672,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<IntVector>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, IntVector.class);\n@@ -660,2 +677,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -664,1 +681,6 @@\n-                                  VectorMask<Integer> m) {\n+                                  VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    IntVector lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<Integer>> maskClass,\n+                                          Vector<Integer> v, VectorMask<Integer> m) {\n@@ -666,4 +688,29 @@\n-        if (op == DIV) {\n-            VectorMask<Integer> eqz = that.eq((int)0);\n-            if (eqz.and(m).anyTrue()) {\n-                throw that.divZeroException();\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL  | VO_SHIFT)) {\n+            if (op == FIRST_NONZERO) {\n+                \/\/ FIXME: Support this in the JIT.\n+                VectorMask<Integer> thisNZ\n+                    = this.viewAsIntegralLanes().compare(NE, (int) 0);\n+                that = that.blend((int) 0, thisNZ.cast(vspecies()));\n+                op = OR_UNCHECKED;\n+            }\n+            if (opKind(op, VO_SHIFT)) {\n+                \/\/ As per shift specification for Java, mask the shift count.\n+                \/\/ This allows the JIT to ignore some ISA details.\n+                that = that.lanewise(AND, SHIFT_MASK);\n+            }\n+            if (op == ROR || op == ROL) {\n+                return blend(lanewise(op, v), m);\n+            } else if (op == AND_NOT) {\n+                \/\/ FIXME: Support this in the JIT.\n+                that = that.lanewise(NOT);\n+                op = AND;\n+            } else if (op == DIV) {\n+                VectorMask<Integer> eqz = that.eq((int)0);\n+                if (eqz.and(m).anyTrue()) {\n+                    throw that.divZeroException();\n+                }\n+                \/\/ suppress div\/0 exceptions in unset lanes\n+                that = that.lanewise(NOT, eqz);\n@@ -671,3 +718,0 @@\n-            \/\/ suppress div\/0 exceptions in unset lanes\n-            that = that.lanewise(NOT, eqz);\n-            return blend(lanewise(DIV, that), m);\n@@ -675,1 +719,40 @@\n-        return blend(lanewise(op, v), m);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, IntVector::binaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<IntVector, VectorMask<Integer>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, IntVector.class);\n+\n+    private static BinaryOperation<IntVector, VectorMask<Integer>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)Math.min(a, b));\n+            case VECTOR_OP_AND: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a & b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a | b));\n+            case VECTOR_OP_XOR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (int)(a ^ b));\n+            case VECTOR_OP_LSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (int)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (int)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (int)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n@@ -677,0 +760,1 @@\n+\n@@ -739,1 +823,7 @@\n-        return blend(lanewise(op, e), m);\n+        if (opKind(op, VO_SHIFT) && (int)(int)e == e) {\n+            return lanewiseShift(op, (int) e, m);\n+        }\n+        if (op == AND_NOT) {\n+            op = AND; e = (int) ~e;\n+        }\n+        return lanewise(op, broadcast(e), m);\n@@ -759,2 +849,1 @@\n-            && !(opKind(op, VO_SHIFT) && (int)e1 == e)\n-            ) {\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n@@ -780,1 +869,7 @@\n-        return blend(lanewise(op, e), m);\n+        int e1 = (int) e;\n+        if ((long)e1 != e\n+            \/\/ allow shift ops to clip down their int parameters\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n+            vspecies().checkValue(e);  \/\/ for exception\n+        }\n+        return lanewise(op, e1, m);\n@@ -802,12 +897,27 @@\n-            opc, getClass(), int.class, length(),\n-            this, e,\n-            BIN_INT_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_LSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (int)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (int)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (int)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, int.class, length(),\n+            this, e, null,\n+            BIN_INT_IMPL.find(op, opc, IntVector::broadcastIntOperations));\n+    }\n+\n+    \/*package-private*\/\n+    abstract IntVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Integer> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final IntVector\n+    lanewiseShiftTemplate(VectorOperators.Binary op,\n+                          Class<? extends VectorMask<Integer>> maskClass,\n+                          int e, VectorMask<Integer> m) {\n+        m.check(maskClass, this);\n+        assert(opKind(op, VO_SHIFT));\n+        \/\/ As per shift specification for Java, mask the shift count.\n+        e &= SHIFT_MASK;\n+        if (op == ROR || op == ROL) {\n+            return blend(lanewiseShift(op, e), m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.broadcastInt(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, e, m,\n+            BIN_INT_IMPL.find(op, opc, IntVector::broadcastIntOperations));\n@@ -815,0 +925,1 @@\n+\n@@ -816,1 +927,1 @@\n-    ImplCache<Binary,VectorBroadcastIntOp<IntVector>> BIN_INT_IMPL\n+    ImplCache<Binary,VectorBroadcastIntOp<IntVector, VectorMask<Integer>>> BIN_INT_IMPL\n@@ -819,0 +930,12 @@\n+    private static VectorBroadcastIntOp<IntVector, VectorMask<Integer>> broadcastIntOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_LSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (int)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (int)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (int)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n+    }\n+\n@@ -870,6 +993,3 @@\n-            opc, getClass(), int.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, int.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, IntVector::ternaryOperations));\n@@ -877,3 +997,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<IntVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, IntVector.class);\n@@ -887,2 +1004,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -892,2 +1009,37 @@\n-                                  VectorMask<Integer> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    IntVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Integer>> maskClass,\n+                                          Vector<Integer> v1,\n+                                          Vector<Integer> v2,\n+                                          VectorMask<Integer> m) {\n+        IntVector that = (IntVector) v1;\n+        IntVector tother = (IntVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, IntVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<IntVector, VectorMask<Integer>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, IntVector.class);\n+\n+    private static TernaryOperation<IntVector, VectorMask<Integer>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -950,1 +1102,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1008,1 +1160,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1065,1 +1217,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2425,0 +2577,1 @@\n+                               Class<? extends VectorMask<Integer>> maskClass,\n@@ -2426,2 +2579,10 @@\n-        IntVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            IntVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, IntVector::reductionOperations)));\n@@ -2442,20 +2603,3 @@\n-            opc, getClass(), int.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((int)0, (i, a, b) -> (int)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((int)1, (i, a, b) -> (int)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (int) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (int) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((int)-1, (i, a, b) -> (int)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((int)0, (i, a, b) -> (int)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((int)0, (i, a, b) -> (int)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, int.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, IntVector::reductionOperations)));\n@@ -2463,0 +2607,1 @@\n+\n@@ -2464,2 +2609,22 @@\n-    ImplCache<Associative,Function<IntVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, IntVector.class);\n+    ImplCache<Associative, ReductionOperation<IntVector, VectorMask<Integer>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, IntVector.class);\n+\n+    private static ReductionOperation<IntVector, VectorMask<Integer>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((int)0, m, (i, a, b) -> (int)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((int)1, m, (i, a, b) -> (int)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (int) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (int) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((int)-1, m, (i, a, b) -> (int)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((int)0, m, (i, a, b) -> (int)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((int)0, m, (i, a, b) -> (int)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n@@ -2748,2 +2913,1 @@\n-            IntVector zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -2807,3 +2971,3 @@\n-            vectorType, int.class, vsp.laneCount(),\n-            IntVector.species(vsp.indexShape()).vectorType(),\n-            a, ARRAY_BASE, vix,\n+            vectorType, null, int.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, null,\n@@ -2811,1 +2975,1 @@\n-            (int[] c, int idx, int[] iMap, int idy, IntSpecies s) ->\n+            (c, idx, iMap, idy, s, vm) ->\n@@ -2813,1 +2977,1 @@\n-        }\n+    }\n@@ -2861,1 +3025,0 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n@@ -2863,1 +3026,1 @@\n-            return vsp.vOp(m, n -> a[offset + indexMap[mapOffset + n]]);\n+            return vsp.dummyVector().fromArray0(a, offset, indexMap, mapOffset, m);\n@@ -3031,1 +3194,0 @@\n-            \/\/ FIXME: optimize\n@@ -3034,1 +3196,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -3078,1 +3240,1 @@\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n+            vsp.vectorType(), null, vsp.elementType(), vsp.laneCount(),\n@@ -3081,1 +3243,1 @@\n-            this,\n+            this, null,\n@@ -3083,1 +3245,1 @@\n-            (arr, off, v, map, mo)\n+            (arr, off, v, map, mo, vm)\n@@ -3130,6 +3292,1 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n-            stOp(a, offset, m,\n-                 (arr, off, i, e) -> {\n-                     int j = indexMap[mapOffset + i];\n-                     arr[off + j] = e;\n-                 });\n+            intoArray0(a, offset, indexMap, mapOffset, m);\n@@ -3247,0 +3404,51 @@\n+    \/*package-private*\/\n+    abstract\n+    IntVector fromArray0(int[] a, int offset, VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Integer>>\n+    IntVector fromArray0Template(Class<M> maskClass, int[] a, int offset, M m) {\n+        m.check(species());\n+        IntSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+    \/*package-private*\/\n+    abstract\n+    IntVector fromArray0(int[] a, int offset,\n+                                    int[] indexMap, int mapOffset,\n+                                    VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Integer>>\n+    IntVector fromArray0Template(Class<M> maskClass, int[] a, int offset,\n+                                            int[] indexMap, int mapOffset, M m) {\n+        IntSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        Objects.requireNonNull(a);\n+        Objects.requireNonNull(indexMap);\n+        m.check(vsp);\n+        Class<? extends IntVector> vectorType = vsp.vectorType();\n+\n+        \/\/ Index vector: vix[0:n] = k -> offset + indexMap[mapOffset + k]\n+        IntVector vix = IntVector\n+            .fromArray(isp, indexMap, mapOffset)\n+            .add(offset);\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        return VectorSupport.loadWithMap(\n+            vectorType, maskClass, int.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, m,\n+            a, offset, indexMap, mapOffset, vsp,\n+            (c, idx, iMap, idy, s, vm) ->\n+            s.vOp(vm, n -> c[idx + iMap[idy+n]]));\n+    }\n+\n@@ -3302,0 +3510,52 @@\n+    abstract\n+    void intoArray0(int[] a, int offset, VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Integer>>\n+    void intoArray0Template(Class<M> maskClass, int[] a, int offset, M m) {\n+        m.check(species());\n+        IntSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+    abstract\n+    void intoArray0(int[] a, int offset,\n+                    int[] indexMap, int mapOffset,\n+                    VectorMask<Integer> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Integer>>\n+    void intoArray0Template(Class<M> maskClass, int[] a, int offset,\n+                            int[] indexMap, int mapOffset, M m) {\n+        m.check(species());\n+        IntSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        \/\/ Index vector: vix[0:n] = i -> offset + indexMap[mo + i]\n+        IntVector vix = IntVector\n+            .fromArray(isp, indexMap, mapOffset)\n+            .add(offset);\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        VectorSupport.storeWithMap(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            isp.vectorType(),\n+            a, arrayAddress(a, 0), vix,\n+            this, m,\n+            a, offset, indexMap, mapOffset,\n+            (arr, off, v, map, mo, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> {\n+                          int j = map[mo + i];\n+                          arr[off + j] = e;\n+                      }));\n+    }\n+\n+\n@@ -3333,0 +3593,1 @@\n+\n@@ -3650,1 +3911,1 @@\n-                                      AbstractMask<Integer> m,\n+                                      VectorMask<Integer> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":405,"deletions":144,"binary":false,"changes":549,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long128Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long128Vector) super.lanewiseTemplate(op, Long128Mask.class, (Long128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -277,0 +283,6 @@\n+    @Override\n+    @ForceInline\n+    public Long128Vector lanewise(Binary op, Vector<Long> v, VectorMask<Long> m) {\n+        return (Long128Vector) super.lanewiseTemplate(op, Long128Mask.class, v, (Long128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -284,0 +296,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Long128Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Long> m) {\n+        return (Long128Vector) super.lanewiseShiftTemplate(op, Long128Mask.class, e, (Long128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,1 +308,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -293,0 +312,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long128Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long128Vector) super.lanewiseTemplate(op, Long128Mask.class, v1, v2, (Long128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -312,1 +339,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long128Mask.class, (Long128Mask) m);  \/\/ specialized\n@@ -325,1 +352,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long128Mask.class, (Long128Mask) m);  \/\/ specialized\n@@ -612,3 +639,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Long128Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -622,3 +649,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long128Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Long128Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -632,3 +659,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long128Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long128Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -768,0 +795,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long128Mask.class, a, offset, (Long128Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long128Mask.class, a, offset, indexMap, mapOffset, (Long128Mask) m);\n+    }\n+\n@@ -791,0 +832,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long128Mask.class, a, offset, (Long128Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long128Mask.class, a, offset, indexMap, mapOffset, (Long128Mask) m);\n+    }\n+\n+\n@@ -798,0 +854,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long128Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long256Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long256Vector) super.lanewiseTemplate(op, Long256Mask.class, (Long256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -277,0 +283,6 @@\n+    @Override\n+    @ForceInline\n+    public Long256Vector lanewise(Binary op, Vector<Long> v, VectorMask<Long> m) {\n+        return (Long256Vector) super.lanewiseTemplate(op, Long256Mask.class, v, (Long256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -284,0 +296,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Long256Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Long> m) {\n+        return (Long256Vector) super.lanewiseShiftTemplate(op, Long256Mask.class, e, (Long256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,1 +308,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -293,0 +312,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long256Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long256Vector) super.lanewiseTemplate(op, Long256Mask.class, v1, v2, (Long256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -312,1 +339,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long256Mask.class, (Long256Mask) m);  \/\/ specialized\n@@ -325,1 +352,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long256Mask.class, (Long256Mask) m);  \/\/ specialized\n@@ -616,3 +643,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Long256Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -626,3 +653,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long256Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Long256Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -636,3 +663,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long256Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long256Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -772,0 +799,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long256Mask.class, a, offset, (Long256Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long256Mask.class, a, offset, indexMap, mapOffset, (Long256Mask) m);\n+    }\n+\n@@ -795,0 +836,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long256Mask.class, a, offset, (Long256Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long256Mask.class, a, offset, indexMap, mapOffset, (Long256Mask) m);\n+    }\n+\n+\n@@ -802,0 +858,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long256Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long512Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long512Vector) super.lanewiseTemplate(op, Long512Mask.class, (Long512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -277,0 +283,6 @@\n+    @Override\n+    @ForceInline\n+    public Long512Vector lanewise(Binary op, Vector<Long> v, VectorMask<Long> m) {\n+        return (Long512Vector) super.lanewiseTemplate(op, Long512Mask.class, v, (Long512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -284,0 +296,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Long512Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Long> m) {\n+        return (Long512Vector) super.lanewiseShiftTemplate(op, Long512Mask.class, e, (Long512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,1 +308,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -293,0 +312,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long512Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long512Vector) super.lanewiseTemplate(op, Long512Mask.class, v1, v2, (Long512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -312,1 +339,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long512Mask.class, (Long512Mask) m);  \/\/ specialized\n@@ -325,1 +352,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long512Mask.class, (Long512Mask) m);  \/\/ specialized\n@@ -624,3 +651,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Long512Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -634,3 +661,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long512Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Long512Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -644,3 +671,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long512Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long512Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -780,0 +807,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long512Mask.class, a, offset, (Long512Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long512Mask.class, a, offset, indexMap, mapOffset, (Long512Mask) m);\n+    }\n+\n@@ -803,0 +844,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long512Mask.class, a, offset, (Long512Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long512Mask.class, a, offset, indexMap, mapOffset, (Long512Mask) m);\n+    }\n+\n+\n@@ -810,0 +866,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long512Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public Long64Vector lanewise(Unary op, VectorMask<Long> m) {\n+        return (Long64Vector) super.lanewiseTemplate(op, Long64Mask.class, (Long64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -277,0 +283,6 @@\n+    @Override\n+    @ForceInline\n+    public Long64Vector lanewise(Binary op, Vector<Long> v, VectorMask<Long> m) {\n+        return (Long64Vector) super.lanewiseTemplate(op, Long64Mask.class, v, (Long64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -284,0 +296,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Long64Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Long> m) {\n+        return (Long64Vector) super.lanewiseShiftTemplate(op, Long64Mask.class, e, (Long64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,1 +308,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -293,0 +312,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Long64Vector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (Long64Vector) super.lanewiseTemplate(op, Long64Mask.class, v1, v2, (Long64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -312,1 +339,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long64Mask.class, (Long64Mask) m);  \/\/ specialized\n@@ -325,1 +352,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long64Mask.class, (Long64Mask) m);  \/\/ specialized\n@@ -610,3 +637,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Long64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Long64Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -620,3 +647,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Long64Mask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Long64Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -630,3 +657,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long64Mask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Long64Mask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -766,0 +793,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long64Mask.class, a, offset, (Long64Mask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        return super.fromArray0Template(Long64Mask.class, a, offset, indexMap, mapOffset, (Long64Mask) m);\n+    }\n+\n@@ -789,0 +830,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long64Mask.class, a, offset, (Long64Mask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        super.intoArray0Template(Long64Mask.class, a, offset, indexMap, mapOffset, (Long64Mask) m);\n+    }\n+\n+\n@@ -796,0 +852,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long64Vector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -271,0 +271,6 @@\n+    @Override\n+    @ForceInline\n+    public LongMaxVector lanewise(Unary op, VectorMask<Long> m) {\n+        return (LongMaxVector) super.lanewiseTemplate(op, LongMaxMask.class, (LongMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -277,0 +283,6 @@\n+    @Override\n+    @ForceInline\n+    public LongMaxVector lanewise(Binary op, Vector<Long> v, VectorMask<Long> m) {\n+        return (LongMaxVector) super.lanewiseTemplate(op, LongMaxMask.class, v, (LongMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -284,0 +296,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline LongMaxVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Long> m) {\n+        return (LongMaxVector) super.lanewiseShiftTemplate(op, LongMaxMask.class, e, (LongMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -289,1 +308,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Long> v1, Vector<Long> v2) {\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2) {\n@@ -293,0 +312,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    LongMaxVector\n+    lanewise(Ternary op, Vector<Long> v1, Vector<Long> v2, VectorMask<Long> m) {\n+        return (LongMaxVector) super.lanewiseTemplate(op, LongMaxMask.class, v1, v2, (LongMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -312,1 +339,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, LongMaxMask.class, (LongMaxMask) m);  \/\/ specialized\n@@ -325,1 +352,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, LongMaxMask.class, (LongMaxMask) m);  \/\/ specialized\n@@ -610,3 +637,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, LongMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, LongMaxMask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -620,3 +647,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, LongMaxMask.class, long.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, LongMaxMask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -630,3 +657,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, LongMaxMask.class, long.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, LongMaxMask.class, null, long.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -766,0 +793,14 @@\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, VectorMask<Long> m) {\n+        return super.fromArray0Template(LongMaxMask.class, a, offset, (LongMaxMask) m);  \/\/ specialize\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    LongVector fromArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        return super.fromArray0Template(LongMaxMask.class, a, offset, indexMap, mapOffset, (LongMaxMask) m);\n+    }\n+\n@@ -789,0 +830,15 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, VectorMask<Long> m) {\n+        super.intoArray0Template(LongMaxMask.class, a, offset, (LongMaxMask) m);\n+    }\n+\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(long[] a, int offset, int[] indexMap, int mapOffset, VectorMask<Long> m) {\n+        super.intoArray0Template(LongMaxMask.class, a, offset, indexMap, mapOffset, (LongMaxMask) m);\n+    }\n+\n+\n@@ -796,0 +852,1 @@\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongMaxVector.java","additions":71,"deletions":14,"binary":false,"changes":85,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -176,0 +175,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -219,0 +221,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -268,0 +273,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -283,1 +291,16 @@\n-    long rOp(long v, FBinOp f);\n+    long rOp(long v, VectorMask<Long> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    long rOpTemplate(long v, VectorMask<Long> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        long[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Long>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -498,1 +521,1 @@\n-                return broadcast(-1).lanewiseTemplate(XOR, this);\n+                return broadcast(-1).lanewise(XOR, this);\n@@ -501,1 +524,1 @@\n-                return broadcast(0).lanewiseTemplate(SUB, this);\n+                return broadcast(0).lanewise(SUB, this);\n@@ -506,10 +529,3 @@\n-            opc, getClass(), long.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (long) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (long) Math.abs(a));\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, long.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, LongVector::unaryOperations));\n@@ -517,3 +533,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<LongVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, LongVector.class);\n@@ -524,2 +537,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -527,2 +540,34 @@\n-                                  VectorMask<Long> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    LongVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Long>> maskClass,\n+                                          VectorMask<Long> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, LongVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<LongVector, VectorMask<Long>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, LongVector.class);\n+\n+    private static UnaryOperation<LongVector, VectorMask<Long>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (long) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (long) Math.abs(a));\n+            default: return null;\n+        }\n@@ -548,0 +593,1 @@\n+\n@@ -571,1 +617,1 @@\n-                VectorMask<Long> eqz = that.eq((long)0);\n+                VectorMask<Long> eqz = that.eq((long) 0);\n@@ -577,0 +623,1 @@\n+\n@@ -579,30 +626,3 @@\n-            opc, getClass(), long.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)Math.min(a, b));\n-                case VECTOR_OP_AND: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a & b));\n-                case VECTOR_OP_OR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a | b));\n-                case VECTOR_OP_XOR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (long)(a ^ b));\n-                case VECTOR_OP_LSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (long)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (long)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (long)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, long.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, LongVector::binaryOperations));\n@@ -610,3 +630,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<LongVector>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, LongVector.class);\n@@ -618,2 +635,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -622,1 +639,6 @@\n-                                  VectorMask<Long> m) {\n+                                  VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    LongVector lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<Long>> maskClass,\n+                                          Vector<Long> v, VectorMask<Long> m) {\n@@ -624,4 +646,10 @@\n-        if (op == DIV) {\n-            VectorMask<Long> eqz = that.eq((long)0);\n-            if (eqz.and(m).anyTrue()) {\n-                throw that.divZeroException();\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL  | VO_SHIFT)) {\n+            if (op == FIRST_NONZERO) {\n+                \/\/ FIXME: Support this in the JIT.\n+                VectorMask<Long> thisNZ\n+                    = this.viewAsIntegralLanes().compare(NE, (long) 0);\n+                that = that.blend((long) 0, thisNZ.cast(vspecies()));\n+                op = OR_UNCHECKED;\n@@ -629,3 +657,59 @@\n-            \/\/ suppress div\/0 exceptions in unset lanes\n-            that = that.lanewise(NOT, eqz);\n-            return blend(lanewise(DIV, that), m);\n+            if (opKind(op, VO_SHIFT)) {\n+                \/\/ As per shift specification for Java, mask the shift count.\n+                \/\/ This allows the JIT to ignore some ISA details.\n+                that = that.lanewise(AND, SHIFT_MASK);\n+            }\n+            if (op == ROR || op == ROL) {\n+                return blend(lanewise(op, v), m);\n+            } else if (op == AND_NOT) {\n+                \/\/ FIXME: Support this in the JIT.\n+                that = that.lanewise(NOT);\n+                op = AND;\n+            } else if (op == DIV) {\n+                VectorMask<Long> eqz = that.eq((long)0);\n+                if (eqz.and(m).anyTrue()) {\n+                    throw that.divZeroException();\n+                }\n+                \/\/ suppress div\/0 exceptions in unset lanes\n+                that = that.lanewise(NOT, eqz);\n+            }\n+        }\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, LongVector::binaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<LongVector, VectorMask<Long>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, LongVector.class);\n+\n+    private static BinaryOperation<LongVector, VectorMask<Long>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)Math.min(a, b));\n+            case VECTOR_OP_AND: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a & b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a | b));\n+            case VECTOR_OP_XOR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (long)(a ^ b));\n+            case VECTOR_OP_LSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (long)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (long)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (long)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n@@ -633,1 +717,0 @@\n-        return blend(lanewise(op, v), m);\n@@ -635,0 +718,1 @@\n+\n@@ -697,1 +781,7 @@\n-        return blend(lanewise(op, e), m);\n+        if (opKind(op, VO_SHIFT) && (long)(int)e == e) {\n+            return lanewiseShift(op, (int) e, m);\n+        }\n+        if (op == AND_NOT) {\n+            op = AND; e = (long) ~e;\n+        }\n+        return lanewise(op, broadcast(e), m);\n@@ -720,12 +810,3 @@\n-            opc, getClass(), long.class, length(),\n-            this, e,\n-            BIN_INT_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_LSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (long)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (long)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (long)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, long.class, length(),\n+            this, e, null,\n+            BIN_INT_IMPL.find(op, opc, LongVector::broadcastIntOperations));\n@@ -733,0 +814,25 @@\n+\n+    \/*package-private*\/\n+    abstract LongVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Long> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final LongVector\n+    lanewiseShiftTemplate(VectorOperators.Binary op,\n+                          Class<? extends VectorMask<Long>> maskClass,\n+                          int e, VectorMask<Long> m) {\n+        m.check(maskClass, this);\n+        assert(opKind(op, VO_SHIFT));\n+        \/\/ As per shift specification for Java, mask the shift count.\n+        e &= SHIFT_MASK;\n+        if (op == ROR || op == ROL) {\n+            return blend(lanewiseShift(op, e), m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.broadcastInt(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, e, m,\n+            BIN_INT_IMPL.find(op, opc, LongVector::broadcastIntOperations));\n+    }\n+\n@@ -734,1 +840,1 @@\n-    ImplCache<Binary,VectorBroadcastIntOp<LongVector>> BIN_INT_IMPL\n+    ImplCache<Binary,VectorBroadcastIntOp<LongVector, VectorMask<Long>>> BIN_INT_IMPL\n@@ -737,0 +843,12 @@\n+    private static VectorBroadcastIntOp<LongVector, VectorMask<Long>> broadcastIntOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_LSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (long)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (long)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (long)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n+    }\n+\n@@ -788,6 +906,3 @@\n-            opc, getClass(), long.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, long.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, LongVector::ternaryOperations));\n@@ -795,3 +910,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<LongVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, LongVector.class);\n@@ -805,2 +917,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -810,2 +922,37 @@\n-                                  VectorMask<Long> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    LongVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Long>> maskClass,\n+                                          Vector<Long> v1,\n+                                          Vector<Long> v2,\n+                                          VectorMask<Long> m) {\n+        LongVector that = (LongVector) v1;\n+        LongVector tother = (LongVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, LongVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<LongVector, VectorMask<Long>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, LongVector.class);\n+\n+    private static TernaryOperation<LongVector, VectorMask<Long>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -868,1 +1015,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -926,1 +1073,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -983,1 +1130,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2296,0 +2443,1 @@\n+                               Class<? extends VectorMask<Long>> maskClass,\n@@ -2297,2 +2445,10 @@\n-        LongVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            LongVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, LongVector::reductionOperations)));\n@@ -2313,20 +2469,3 @@\n-            opc, getClass(), long.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((long)0, (i, a, b) -> (long)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((long)1, (i, a, b) -> (long)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (long) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (long) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((long)-1, (i, a, b) -> (long)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((long)0, (i, a, b) -> (long)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((long)0, (i, a, b) -> (long)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, long.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, LongVector::reductionOperations)));\n@@ -2334,0 +2473,1 @@\n+\n@@ -2335,2 +2475,22 @@\n-    ImplCache<Associative,Function<LongVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, LongVector.class);\n+    ImplCache<Associative, ReductionOperation<LongVector, VectorMask<Long>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, LongVector.class);\n+\n+    private static ReductionOperation<LongVector, VectorMask<Long>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((long)0, m, (i, a, b) -> (long)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((long)1, m, (i, a, b) -> (long)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (long) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (long) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((long)-1, m, (i, a, b) -> (long)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((long)0, m, (i, a, b) -> (long)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((long)0, m, (i, a, b) -> (long)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n@@ -2614,2 +2774,1 @@\n-            LongVector zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -2691,3 +2850,3 @@\n-            vectorType, long.class, vsp.laneCount(),\n-            IntVector.species(vsp.indexShape()).vectorType(),\n-            a, ARRAY_BASE, vix,\n+            vectorType, null, long.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, null,\n@@ -2695,1 +2854,1 @@\n-            (long[] c, int idx, int[] iMap, int idy, LongSpecies s) ->\n+            (c, idx, iMap, idy, s, vm) ->\n@@ -2697,1 +2856,1 @@\n-        }\n+    }\n@@ -2745,1 +2904,0 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n@@ -2747,1 +2905,1 @@\n-            return vsp.vOp(m, n -> a[offset + indexMap[mapOffset + n]]);\n+            return vsp.dummyVector().fromArray0(a, offset, indexMap, mapOffset, m);\n@@ -2915,1 +3073,0 @@\n-            \/\/ FIXME: optimize\n@@ -2918,1 +3075,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -2981,1 +3138,1 @@\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n+            vsp.vectorType(), null, vsp.elementType(), vsp.laneCount(),\n@@ -2984,1 +3141,1 @@\n-            this,\n+            this, null,\n@@ -2986,1 +3143,1 @@\n-            (arr, off, v, map, mo)\n+            (arr, off, v, map, mo, vm)\n@@ -3033,6 +3190,1 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n-            stOp(a, offset, m,\n-                 (arr, off, i, e) -> {\n-                     int j = indexMap[mapOffset + i];\n-                     arr[off + j] = e;\n-                 });\n+            intoArray0(a, offset, indexMap, mapOffset, m);\n@@ -3150,0 +3302,69 @@\n+    \/*package-private*\/\n+    abstract\n+    LongVector fromArray0(long[] a, int offset, VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Long>>\n+    LongVector fromArray0Template(Class<M> maskClass, long[] a, int offset, M m) {\n+        m.check(species());\n+        LongSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+    \/*package-private*\/\n+    abstract\n+    LongVector fromArray0(long[] a, int offset,\n+                                    int[] indexMap, int mapOffset,\n+                                    VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Long>>\n+    LongVector fromArray0Template(Class<M> maskClass, long[] a, int offset,\n+                                            int[] indexMap, int mapOffset, M m) {\n+        LongSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        Objects.requireNonNull(a);\n+        Objects.requireNonNull(indexMap);\n+        m.check(vsp);\n+        Class<? extends LongVector> vectorType = vsp.vectorType();\n+\n+        if (vsp.laneCount() == 1) {\n+          return LongVector.fromArray(vsp, a, offset + indexMap[mapOffset], m);\n+        }\n+\n+        \/\/ Index vector: vix[0:n] = k -> offset + indexMap[mapOffset + k]\n+        IntVector vix;\n+        if (isp.laneCount() != vsp.laneCount()) {\n+            \/\/ For LongMaxVector,  if vector length is non-power-of-two or\n+            \/\/ 2048 bits, indexShape of Long species is S_MAX_BIT.\n+            \/\/ Assume that vector length is 2048, then the lane count of Long\n+            \/\/ vector is 32. When converting Long species to int species,\n+            \/\/ indexShape is still S_MAX_BIT, but the lane count of int vector\n+            \/\/ is 64. So when loading index vector (IntVector), only lower half\n+            \/\/ of index data is needed.\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset, IntMaxVector.IntMaxMask.LOWER_HALF_TRUE_MASK)\n+                .add(offset);\n+        } else {\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset)\n+                .add(offset);\n+        }\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        return VectorSupport.loadWithMap(\n+            vectorType, maskClass, long.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, m,\n+            a, offset, indexMap, mapOffset, vsp,\n+            (c, idx, iMap, idy, s, vm) ->\n+            s.vOp(vm, n -> c[idx + iMap[idy+n]]));\n+    }\n+\n@@ -3205,0 +3426,71 @@\n+    abstract\n+    void intoArray0(long[] a, int offset, VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Long>>\n+    void intoArray0Template(Class<M> maskClass, long[] a, int offset, M m) {\n+        m.check(species());\n+        LongSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+    abstract\n+    void intoArray0(long[] a, int offset,\n+                    int[] indexMap, int mapOffset,\n+                    VectorMask<Long> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Long>>\n+    void intoArray0Template(Class<M> maskClass, long[] a, int offset,\n+                            int[] indexMap, int mapOffset, M m) {\n+        m.check(species());\n+        LongSpecies vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        if (vsp.laneCount() == 1) {\n+            intoArray(a, offset + indexMap[mapOffset], m);\n+            return;\n+        }\n+\n+        \/\/ Index vector: vix[0:n] = i -> offset + indexMap[mo + i]\n+        IntVector vix;\n+        if (isp.laneCount() != vsp.laneCount()) {\n+            \/\/ For LongMaxVector,  if vector length  is 2048 bits, indexShape\n+            \/\/ of Long species is S_MAX_BIT. and the lane count of Long\n+            \/\/ vector is 32. When converting Long species to int species,\n+            \/\/ indexShape is still S_MAX_BIT, but the lane count of int vector\n+            \/\/ is 64. So when loading index vector (IntVector), only lower half\n+            \/\/ of index data is needed.\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset, IntMaxVector.IntMaxMask.LOWER_HALF_TRUE_MASK)\n+                .add(offset);\n+        } else {\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset)\n+                .add(offset);\n+        }\n+\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        VectorSupport.storeWithMap(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            isp.vectorType(),\n+            a, arrayAddress(a, 0), vix,\n+            this, m,\n+            a, offset, indexMap, mapOffset,\n+            (arr, off, v, map, mo, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> {\n+                          int j = map[mo + i];\n+                          arr[off + j] = e;\n+                      }));\n+    }\n+\n+\n@@ -3236,0 +3528,1 @@\n+\n@@ -3544,1 +3837,1 @@\n-                                      AbstractMask<Long> m,\n+                                      VectorMask<Long> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":434,"deletions":141,"binary":false,"changes":575,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short128Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short128Vector) super.lanewiseTemplate(op, Short128Mask.class, (Short128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Short128Vector lanewise(Binary op, Vector<Short> v, VectorMask<Short> m) {\n+        return (Short128Vector) super.lanewiseTemplate(op, Short128Mask.class, v, (Short128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Short128Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Short> m) {\n+        return (Short128Vector) super.lanewiseShiftTemplate(op, Short128Mask.class, e, (Short128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short128Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short128Vector) super.lanewiseTemplate(op, Short128Mask.class, v1, v2, (Short128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short128Mask.class, (Short128Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short128Mask.class, (Short128Mask) m);  \/\/ specialized\n@@ -634,3 +661,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short128Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Short128Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -644,3 +671,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short128Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Short128Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -654,3 +681,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short128Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short128Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -790,0 +817,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromArray0(short[] a, int offset, VectorMask<Short> m) {\n+        return super.fromArray0Template(Short128Mask.class, a, offset, (Short128Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -797,0 +832,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        return super.fromCharArray0Template(Short128Mask.class, a, offset, (Short128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -819,0 +861,9 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(short[] a, int offset, VectorMask<Short> m) {\n+        super.intoArray0Template(Short128Mask.class, a, offset, (Short128Mask) m);\n+    }\n+\n+\n+\n@@ -826,0 +877,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        super.intoCharArray0Template(Short128Mask.class, a, offset, (Short128Mask) m);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short128Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short256Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short256Vector) super.lanewiseTemplate(op, Short256Mask.class, (Short256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Short256Vector lanewise(Binary op, Vector<Short> v, VectorMask<Short> m) {\n+        return (Short256Vector) super.lanewiseTemplate(op, Short256Mask.class, v, (Short256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Short256Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Short> m) {\n+        return (Short256Vector) super.lanewiseShiftTemplate(op, Short256Mask.class, e, (Short256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short256Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short256Vector) super.lanewiseTemplate(op, Short256Mask.class, v1, v2, (Short256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short256Mask.class, (Short256Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short256Mask.class, (Short256Mask) m);  \/\/ specialized\n@@ -650,3 +677,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short256Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Short256Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -660,3 +687,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short256Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Short256Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -670,3 +697,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short256Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short256Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -806,0 +833,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromArray0(short[] a, int offset, VectorMask<Short> m) {\n+        return super.fromArray0Template(Short256Mask.class, a, offset, (Short256Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -813,0 +848,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        return super.fromCharArray0Template(Short256Mask.class, a, offset, (Short256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -835,0 +877,9 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(short[] a, int offset, VectorMask<Short> m) {\n+        super.intoArray0Template(Short256Mask.class, a, offset, (Short256Mask) m);\n+    }\n+\n+\n+\n@@ -842,0 +893,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        super.intoCharArray0Template(Short256Mask.class, a, offset, (Short256Mask) m);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short256Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short512Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short512Vector) super.lanewiseTemplate(op, Short512Mask.class, (Short512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Short512Vector lanewise(Binary op, Vector<Short> v, VectorMask<Short> m) {\n+        return (Short512Vector) super.lanewiseTemplate(op, Short512Mask.class, v, (Short512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Short512Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Short> m) {\n+        return (Short512Vector) super.lanewiseShiftTemplate(op, Short512Mask.class, e, (Short512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short512Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short512Vector) super.lanewiseTemplate(op, Short512Mask.class, v1, v2, (Short512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short512Mask.class, (Short512Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short512Mask.class, (Short512Mask) m);  \/\/ specialized\n@@ -682,3 +709,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short512Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Short512Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -692,3 +719,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short512Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Short512Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -702,3 +729,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short512Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short512Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -838,0 +865,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromArray0(short[] a, int offset, VectorMask<Short> m) {\n+        return super.fromArray0Template(Short512Mask.class, a, offset, (Short512Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -845,0 +880,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        return super.fromCharArray0Template(Short512Mask.class, a, offset, (Short512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -867,0 +909,9 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(short[] a, int offset, VectorMask<Short> m) {\n+        super.intoArray0Template(Short512Mask.class, a, offset, (Short512Mask) m);\n+    }\n+\n+\n+\n@@ -874,0 +925,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        super.intoCharArray0Template(Short512Mask.class, a, offset, (Short512Mask) m);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short512Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public Short64Vector lanewise(Unary op, VectorMask<Short> m) {\n+        return (Short64Vector) super.lanewiseTemplate(op, Short64Mask.class, (Short64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public Short64Vector lanewise(Binary op, Vector<Short> v, VectorMask<Short> m) {\n+        return (Short64Vector) super.lanewiseTemplate(op, Short64Mask.class, v, (Short64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline Short64Vector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Short> m) {\n+        return (Short64Vector) super.lanewiseShiftTemplate(op, Short64Mask.class, e, (Short64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    Short64Vector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (Short64Vector) super.lanewiseTemplate(op, Short64Mask.class, v1, v2, (Short64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short64Mask.class, (Short64Mask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short64Mask.class, (Short64Mask) m);  \/\/ specialized\n@@ -626,3 +653,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, Short64Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, Short64Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -636,3 +663,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, Short64Mask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, Short64Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -646,3 +673,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short64Mask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, Short64Mask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -782,0 +809,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromArray0(short[] a, int offset, VectorMask<Short> m) {\n+        return super.fromArray0Template(Short64Mask.class, a, offset, (Short64Mask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -789,0 +824,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        return super.fromCharArray0Template(Short64Mask.class, a, offset, (Short64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -811,0 +853,9 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(short[] a, int offset, VectorMask<Short> m) {\n+        super.intoArray0Template(Short64Mask.class, a, offset, (Short64Mask) m);\n+    }\n+\n+\n+\n@@ -818,0 +869,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        super.intoCharArray0Template(Short64Mask.class, a, offset, (Short64Mask) m);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short64Vector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -276,0 +276,6 @@\n+    @Override\n+    @ForceInline\n+    public ShortMaxVector lanewise(Unary op, VectorMask<Short> m) {\n+        return (ShortMaxVector) super.lanewiseTemplate(op, ShortMaxMask.class, (ShortMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -282,0 +288,6 @@\n+    @Override\n+    @ForceInline\n+    public ShortMaxVector lanewise(Binary op, Vector<Short> v, VectorMask<Short> m) {\n+        return (ShortMaxVector) super.lanewiseTemplate(op, ShortMaxMask.class, v, (ShortMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -289,0 +301,7 @@\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline ShortMaxVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Short> m) {\n+        return (ShortMaxVector) super.lanewiseShiftTemplate(op, ShortMaxMask.class, e, (ShortMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -294,1 +313,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<Short> v1, Vector<Short> v2) {\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2) {\n@@ -298,0 +317,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    ShortMaxVector\n+    lanewise(Ternary op, Vector<Short> v1, Vector<Short> v2, VectorMask<Short> m) {\n+        return (ShortMaxVector) super.lanewiseTemplate(op, ShortMaxMask.class, v1, v2, (ShortMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -317,1 +344,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, ShortMaxMask.class, (ShortMaxMask) m);  \/\/ specialized\n@@ -330,1 +357,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, ShortMaxMask.class, (ShortMaxMask) m);  \/\/ specialized\n@@ -620,3 +647,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, ShortMaxMask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, ShortMaxMask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -630,3 +657,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, ShortMaxMask.class, short.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, ShortMaxMask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -640,3 +667,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, ShortMaxMask.class, short.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, ShortMaxMask.class, null, short.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -776,0 +803,8 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromArray0(short[] a, int offset, VectorMask<Short> m) {\n+        return super.fromArray0Template(ShortMaxMask.class, a, offset, (ShortMaxMask) m);  \/\/ specialize\n+    }\n+\n+\n@@ -783,0 +818,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    ShortVector fromCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        return super.fromCharArray0Template(ShortMaxMask.class, a, offset, (ShortMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -805,0 +847,9 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0(short[] a, int offset, VectorMask<Short> m) {\n+        super.intoArray0Template(ShortMaxMask.class, a, offset, (ShortMaxMask) m);\n+    }\n+\n+\n+\n@@ -812,0 +863,7 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoCharArray0(char[] a, int offset, VectorMask<Short> m) {\n+        super.intoCharArray0Template(ShortMaxMask.class, a, offset, (ShortMaxMask) m);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortMaxVector.java","additions":72,"deletions":14,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -176,0 +175,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -219,0 +221,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -268,0 +273,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -283,1 +291,16 @@\n-    short rOp(short v, FBinOp f);\n+    short rOp(short v, VectorMask<Short> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    short rOpTemplate(short v, VectorMask<Short> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        short[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Short>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -540,1 +563,1 @@\n-                return broadcast(-1).lanewiseTemplate(XOR, this);\n+                return broadcast(-1).lanewise(XOR, this);\n@@ -543,1 +566,1 @@\n-                return broadcast(0).lanewiseTemplate(SUB, this);\n+                return broadcast(0).lanewise(SUB, this);\n@@ -548,10 +571,3 @@\n-            opc, getClass(), short.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> (short) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> (short) Math.abs(a));\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, short.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, ShortVector::unaryOperations));\n@@ -559,3 +575,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<ShortVector>> UN_IMPL\n-        = new ImplCache<>(Unary.class, ShortVector.class);\n@@ -566,2 +579,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -569,2 +582,34 @@\n-                                  VectorMask<Short> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    ShortVector lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<Short>> maskClass,\n+                                          VectorMask<Short> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, ShortVector::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<ShortVector, VectorMask<Short>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, ShortVector.class);\n+\n+    private static UnaryOperation<ShortVector, VectorMask<Short>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) Math.abs(a));\n+            default: return null;\n+        }\n@@ -590,0 +635,1 @@\n+\n@@ -613,1 +659,1 @@\n-                VectorMask<Short> eqz = that.eq((short)0);\n+                VectorMask<Short> eqz = that.eq((short) 0);\n@@ -619,0 +665,1 @@\n+\n@@ -621,30 +668,3 @@\n-            opc, getClass(), short.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)Math.min(a, b));\n-                case VECTOR_OP_AND: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a & b));\n-                case VECTOR_OP_OR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a | b));\n-                case VECTOR_OP_XOR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> (short)(a ^ b));\n-                case VECTOR_OP_LSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (short)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (short)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> (short)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, short.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, ShortVector::binaryOperations));\n@@ -652,3 +672,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<ShortVector>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, ShortVector.class);\n@@ -660,2 +677,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -664,1 +681,6 @@\n-                                  VectorMask<Short> m) {\n+                                  VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    ShortVector lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<Short>> maskClass,\n+                                          Vector<Short> v, VectorMask<Short> m) {\n@@ -666,4 +688,29 @@\n-        if (op == DIV) {\n-            VectorMask<Short> eqz = that.eq((short)0);\n-            if (eqz.and(m).anyTrue()) {\n-                throw that.divZeroException();\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL  | VO_SHIFT)) {\n+            if (op == FIRST_NONZERO) {\n+                \/\/ FIXME: Support this in the JIT.\n+                VectorMask<Short> thisNZ\n+                    = this.viewAsIntegralLanes().compare(NE, (short) 0);\n+                that = that.blend((short) 0, thisNZ.cast(vspecies()));\n+                op = OR_UNCHECKED;\n+            }\n+            if (opKind(op, VO_SHIFT)) {\n+                \/\/ As per shift specification for Java, mask the shift count.\n+                \/\/ This allows the JIT to ignore some ISA details.\n+                that = that.lanewise(AND, SHIFT_MASK);\n+            }\n+            if (op == ROR || op == ROL) {\n+                return blend(lanewise(op, v), m);\n+            } else if (op == AND_NOT) {\n+                \/\/ FIXME: Support this in the JIT.\n+                that = that.lanewise(NOT);\n+                op = AND;\n+            } else if (op == DIV) {\n+                VectorMask<Short> eqz = that.eq((short)0);\n+                if (eqz.and(m).anyTrue()) {\n+                    throw that.divZeroException();\n+                }\n+                \/\/ suppress div\/0 exceptions in unset lanes\n+                that = that.lanewise(NOT, eqz);\n@@ -671,3 +718,0 @@\n-            \/\/ suppress div\/0 exceptions in unset lanes\n-            that = that.lanewise(NOT, eqz);\n-            return blend(lanewise(DIV, that), m);\n@@ -675,1 +719,40 @@\n-        return blend(lanewise(op, v), m);\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, ShortVector::binaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<ShortVector, VectorMask<Short>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, ShortVector.class);\n+\n+    private static BinaryOperation<ShortVector, VectorMask<Short>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)Math.min(a, b));\n+            case VECTOR_OP_AND: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a & b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a | b));\n+            case VECTOR_OP_XOR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> (short)(a ^ b));\n+            case VECTOR_OP_LSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (short)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (short)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> (short)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n@@ -677,0 +760,1 @@\n+\n@@ -739,1 +823,7 @@\n-        return blend(lanewise(op, e), m);\n+        if (opKind(op, VO_SHIFT) && (short)(int)e == e) {\n+            return lanewiseShift(op, (int) e, m);\n+        }\n+        if (op == AND_NOT) {\n+            op = AND; e = (short) ~e;\n+        }\n+        return lanewise(op, broadcast(e), m);\n@@ -759,2 +849,1 @@\n-            && !(opKind(op, VO_SHIFT) && (int)e1 == e)\n-            ) {\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n@@ -780,1 +869,7 @@\n-        return blend(lanewise(op, e), m);\n+        short e1 = (short) e;\n+        if ((long)e1 != e\n+            \/\/ allow shift ops to clip down their int parameters\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n+            vspecies().checkValue(e);  \/\/ for exception\n+        }\n+        return lanewise(op, e1, m);\n@@ -802,12 +897,27 @@\n-            opc, getClass(), short.class, length(),\n-            this, e,\n-            BIN_INT_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_LSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (short)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (short)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> (short)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, short.class, length(),\n+            this, e, null,\n+            BIN_INT_IMPL.find(op, opc, ShortVector::broadcastIntOperations));\n+    }\n+\n+    \/*package-private*\/\n+    abstract ShortVector\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<Short> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final ShortVector\n+    lanewiseShiftTemplate(VectorOperators.Binary op,\n+                          Class<? extends VectorMask<Short>> maskClass,\n+                          int e, VectorMask<Short> m) {\n+        m.check(maskClass, this);\n+        assert(opKind(op, VO_SHIFT));\n+        \/\/ As per shift specification for Java, mask the shift count.\n+        e &= SHIFT_MASK;\n+        if (op == ROR || op == ROL) {\n+            return blend(lanewiseShift(op, e), m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.broadcastInt(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, e, m,\n+            BIN_INT_IMPL.find(op, opc, ShortVector::broadcastIntOperations));\n@@ -815,0 +925,1 @@\n+\n@@ -816,1 +927,1 @@\n-    ImplCache<Binary,VectorBroadcastIntOp<ShortVector>> BIN_INT_IMPL\n+    ImplCache<Binary,VectorBroadcastIntOp<ShortVector, VectorMask<Short>>> BIN_INT_IMPL\n@@ -819,0 +930,12 @@\n+    private static VectorBroadcastIntOp<ShortVector, VectorMask<Short>> broadcastIntOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_LSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (short)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (short)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> (short)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n+    }\n+\n@@ -871,6 +994,3 @@\n-            opc, getClass(), short.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, short.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, ShortVector::ternaryOperations));\n@@ -878,3 +998,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<ShortVector>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, ShortVector.class);\n@@ -888,2 +1005,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -893,2 +1010,37 @@\n-                                  VectorMask<Short> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    ShortVector lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<Short>> maskClass,\n+                                          Vector<Short> v1,\n+                                          Vector<Short> v2,\n+                                          VectorMask<Short> m) {\n+        ShortVector that = (ShortVector) v1;\n+        ShortVector tother = (ShortVector) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, ShortVector::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<ShortVector, VectorMask<Short>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, ShortVector.class);\n+\n+    private static TernaryOperation<ShortVector, VectorMask<Short>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+            default: return null;\n+        }\n@@ -951,1 +1103,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1009,1 +1161,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1066,1 +1218,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2426,0 +2578,1 @@\n+                               Class<? extends VectorMask<Short>> maskClass,\n@@ -2427,2 +2580,10 @@\n-        ShortVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            ShortVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, ShortVector::reductionOperations)));\n@@ -2443,20 +2604,3 @@\n-            opc, getClass(), short.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((short)0, (i, a, b) -> (short)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((short)1, (i, a, b) -> (short)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (short) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (short) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((short)-1, (i, a, b) -> (short)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((short)0, (i, a, b) -> (short)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((short)0, (i, a, b) -> (short)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, short.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, ShortVector::reductionOperations)));\n@@ -2464,0 +2608,1 @@\n+\n@@ -2465,2 +2610,22 @@\n-    ImplCache<Associative,Function<ShortVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, ShortVector.class);\n+    ImplCache<Associative, ReductionOperation<ShortVector, VectorMask<Short>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, ShortVector.class);\n+\n+    private static ReductionOperation<ShortVector, VectorMask<Short>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((short)0, m, (i, a, b) -> (short)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((short)1, m, (i, a, b) -> (short)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (short) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (short) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((short)-1, m, (i, a, b) -> (short)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((short)0, m, (i, a, b) -> (short)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((short)0, m, (i, a, b) -> (short)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n@@ -2756,2 +2921,1 @@\n-            ShortVector zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -2906,2 +3070,1 @@\n-            ShortVector zero = vsp.zero();\n-            return zero.blend(zero.fromCharArray0(a, offset), m);\n+            return vsp.dummyVector().fromCharArray0(a, offset, m);\n@@ -3166,1 +3329,0 @@\n-            \/\/ FIXME: optimize\n@@ -3169,1 +3331,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -3314,1 +3476,0 @@\n-            \/\/ FIXME: optimize\n@@ -3317,1 +3478,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = (char) v);\n+            intoCharArray0(a, offset, m);\n@@ -3513,0 +3674,18 @@\n+    \/*package-private*\/\n+    abstract\n+    ShortVector fromArray0(short[] a, int offset, VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Short>>\n+    ShortVector fromArray0Template(Class<M> maskClass, short[] a, int offset, M m) {\n+        m.check(species());\n+        ShortSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+\n@@ -3528,0 +3707,17 @@\n+    \/*package-private*\/\n+    abstract\n+    ShortVector fromCharArray0(char[] a, int offset, VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Short>>\n+    ShortVector fromCharArray0Template(Class<M> maskClass, char[] a, int offset, M m) {\n+        m.check(species());\n+        ShortSpecies vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+                vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+                a, charArrayAddress(a, offset), m,\n+                a, offset, vsp,\n+                (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                            (arr_, off_, i) -> (short) arr_[off_ + i]));\n+    }\n+\n@@ -3582,0 +3778,19 @@\n+    abstract\n+    void intoArray0(short[] a, int offset, VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Short>>\n+    void intoArray0Template(Class<M> maskClass, short[] a, int offset, M m) {\n+        m.check(species());\n+        ShortSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+\n+\n@@ -3613,0 +3828,18 @@\n+    \/*package-private*\/\n+    abstract\n+    void intoCharArray0(char[] a, int offset, VectorMask<Short> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Short>>\n+    void intoCharArray0Template(Class<M> maskClass, char[] a, int offset, M m) {\n+        m.check(species());\n+        ShortSpecies vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, charArrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = (char) e));\n+    }\n+\n@@ -3947,1 +4180,1 @@\n-                                      AbstractMask<Short> m,\n+                                      VectorMask<Short> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":365,"deletions":132,"binary":false,"changes":497,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -556,0 +556,18 @@\n+    \/**\n+     * Checks that this mask has the same class with the given mask class,\n+     * and it has the same species with given vector's species,\n+     * and returns this mask unchanged.\n+     * The effect is similar to this pseudocode:\n+     * {@code getClass() == maskClass &&\n+     *        vectorSpecies() == vector.species()\n+     *        ? this\n+     *        : throw new ClassCastException()}.\n+     *\n+     * @param maskClass the class required for this mask\n+     * @param vector its species required for this mask\n+     * @param <F> the boxed element type of the required species\n+     * @return the same mask\n+     * @throws ClassCastException if the species is wrong\n+     *\/\n+    public abstract <F> VectorMask<F> check(Class<? extends VectorMask<F>> maskClass, Vector<F> vector);\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/VectorMask.java","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-import java.util.function.BinaryOperator;\n@@ -180,0 +179,3 @@\n+        if (m == null) {\n+            return uOpTemplate(f);\n+        }\n@@ -223,0 +225,3 @@\n+        if (m == null) {\n+            return bOpTemplate(o, f);\n+        }\n@@ -272,0 +277,3 @@\n+        if (m == null) {\n+            return tOpTemplate(o1, o2, f);\n+        }\n@@ -287,1 +295,16 @@\n-    $type$ rOp($type$ v, FBinOp f);\n+    $type$ rOp($type$ v, VectorMask<$Boxtype$> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    $type$ rOpTemplate($type$ v, VectorMask<$Boxtype$> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        $type$[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<$Boxtype$>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -553,1 +576,1 @@\n-                return broadcast(-1).lanewiseTemplate(XOR, this);\n+                return broadcast(-1).lanewise(XOR, this);\n@@ -556,1 +579,1 @@\n-                return broadcast(0).lanewiseTemplate(SUB, this);\n+                return broadcast(0).lanewise(SUB, this);\n@@ -562,44 +585,3 @@\n-            opc, getClass(), $type$.class, length(),\n-            this,\n-            UN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_NEG: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) -a);\n-                case VECTOR_OP_ABS: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.abs(a));\n-#if[FP]\n-                case VECTOR_OP_SIN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.sin(a));\n-                case VECTOR_OP_COS: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.cos(a));\n-                case VECTOR_OP_TAN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.tan(a));\n-                case VECTOR_OP_ASIN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.asin(a));\n-                case VECTOR_OP_ACOS: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.acos(a));\n-                case VECTOR_OP_ATAN: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.atan(a));\n-                case VECTOR_OP_EXP: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.exp(a));\n-                case VECTOR_OP_LOG: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.log(a));\n-                case VECTOR_OP_LOG10: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.log10(a));\n-                case VECTOR_OP_SQRT: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.sqrt(a));\n-                case VECTOR_OP_CBRT: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.cbrt(a));\n-                case VECTOR_OP_SINH: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.sinh(a));\n-                case VECTOR_OP_COSH: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.cosh(a));\n-                case VECTOR_OP_TANH: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.tanh(a));\n-                case VECTOR_OP_EXPM1: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.expm1(a));\n-                case VECTOR_OP_LOG1P: return v0 ->\n-                        v0.uOp((i, a) -> ($type$) Math.log1p(a));\n-#end[FP]\n-                default: return null;\n-              }}));\n+            opc, getClass(), null, $type$.class, length(),\n+            this, null,\n+            UN_IMPL.find(op, opc, $abstractvectortype$::unaryOperations));\n@@ -607,3 +589,0 @@\n-    private static final\n-    ImplCache<Unary,UnaryOperator<$abstractvectortype$>> UN_IMPL\n-        = new ImplCache<>(Unary.class, $Type$Vector.class);\n@@ -614,2 +593,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -617,2 +596,70 @@\n-                                  VectorMask<$Boxtype$> m) {\n-        return blend(lanewise(op), m);\n+                                  VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    $abstractvectortype$ lanewiseTemplate(VectorOperators.Unary op,\n+                                          Class<? extends VectorMask<$Boxtype$>> maskClass,\n+                                          VectorMask<$Boxtype$> m) {\n+        m.check(maskClass, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            if (op == ZOMO) {\n+                return blend(broadcast(-1), compare(NE, 0).and(m));\n+            }\n+#if[BITWISE]\n+            if (op == NOT || op == NEG) {\n+                return blend(lanewise(op), m);\n+            }\n+#end[BITWISE]\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.unaryOp(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, m,\n+            UN_IMPL.find(op, opc, $abstractvectortype$::unaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Unary, UnaryOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        UN_IMPL = new ImplCache<>(Unary.class, $Type$Vector.class);\n+\n+    private static UnaryOperation<$abstractvectortype$, VectorMask<$Boxtype$>> unaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_NEG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) -a);\n+            case VECTOR_OP_ABS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.abs(a));\n+#if[FP]\n+            case VECTOR_OP_SIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.sin(a));\n+            case VECTOR_OP_COS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.cos(a));\n+            case VECTOR_OP_TAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.tan(a));\n+            case VECTOR_OP_ASIN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.asin(a));\n+            case VECTOR_OP_ACOS: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.acos(a));\n+            case VECTOR_OP_ATAN: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.atan(a));\n+            case VECTOR_OP_EXP: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.exp(a));\n+            case VECTOR_OP_LOG: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.log(a));\n+            case VECTOR_OP_LOG10: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.log10(a));\n+            case VECTOR_OP_SQRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.sqrt(a));\n+            case VECTOR_OP_CBRT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.cbrt(a));\n+            case VECTOR_OP_SINH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.sinh(a));\n+            case VECTOR_OP_COSH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.cosh(a));\n+            case VECTOR_OP_TANH: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.tanh(a));\n+            case VECTOR_OP_EXPM1: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.expm1(a));\n+            case VECTOR_OP_LOG1P: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) Math.log1p(a));\n+#end[FP]\n+            default: return null;\n+        }\n@@ -638,0 +685,1 @@\n+\n@@ -670,1 +718,1 @@\n-                VectorMask<$Boxtype$> eqz = that.eq(($type$)0);\n+                VectorMask<$Boxtype$> eqz = that.eq(($type$) 0);\n@@ -677,0 +725,1 @@\n+\n@@ -679,40 +728,3 @@\n-            opc, getClass(), $type$.class, length(),\n-            this, that,\n-            BIN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_ADD: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a + b));\n-                case VECTOR_OP_SUB: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a - b));\n-                case VECTOR_OP_MUL: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a * b));\n-                case VECTOR_OP_DIV: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a \/ b));\n-                case VECTOR_OP_MAX: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)Math.max(a, b));\n-                case VECTOR_OP_MIN: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)Math.min(a, b));\n-#if[BITWISE]\n-                case VECTOR_OP_AND: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a & b));\n-                case VECTOR_OP_OR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a | b));\n-                case VECTOR_OP_XOR: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$)(a ^ b));\n-                case VECTOR_OP_LSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> ($type$)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> ($type$)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, n) -> ($type$)((a & LSHR_SETUP_MASK) >>> n));\n-#end[BITWISE]\n-#if[FP]\n-                case VECTOR_OP_ATAN2: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$) Math.atan2(a, b));\n-                case VECTOR_OP_POW: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$) Math.pow(a, b));\n-                case VECTOR_OP_HYPOT: return (v0, v1) ->\n-                        v0.bOp(v1, (i, a, b) -> ($type$) Math.hypot(a, b));\n-#end[FP]\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, $type$.class, length(),\n+            this, that, null,\n+            BIN_IMPL.find(op, opc, $abstractvectortype$::binaryOperations));\n@@ -720,3 +732,0 @@\n-    private static final\n-    ImplCache<Binary,BinaryOperator<$abstractvectortype$>> BIN_IMPL\n-        = new ImplCache<>(Binary.class, $Type$Vector.class);\n@@ -728,2 +737,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -732,2 +741,6 @@\n-                                  VectorMask<$Boxtype$> m) {\n-#if[BITWISE]\n+                                  VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    $abstractvectortype$ lanewiseTemplate(VectorOperators.Binary op,\n+                                          Class<? extends VectorMask<$Boxtype$>> maskClass,\n+                                          Vector<$Boxtype$> v, VectorMask<$Boxtype$> m) {\n@@ -735,4 +748,36 @@\n-        if (op == DIV) {\n-            VectorMask<$Boxtype$> eqz = that.eq(($type$)0);\n-            if (eqz.and(m).anyTrue()) {\n-                throw that.divZeroException();\n+        that.check(this);\n+        m.check(maskClass, this);\n+\n+        if (opKind(op, VO_SPECIAL {#if[!FP]? | VO_SHIFT})) {\n+            if (op == FIRST_NONZERO) {\n+#if[FP]\n+                return blend(lanewise(op, v), m);\n+#else[FP]\n+                \/\/ FIXME: Support this in the JIT.\n+                VectorMask<$Boxbitstype$> thisNZ\n+                    = this.viewAsIntegralLanes().compare(NE, ($bitstype$) 0);\n+                that = that.blend(($type$) 0, thisNZ.cast(vspecies()));\n+                op = OR_UNCHECKED;\n+#end[FP]\n+            }\n+#if[BITWISE]\n+#if[!FP]\n+            if (opKind(op, VO_SHIFT)) {\n+                \/\/ As per shift specification for Java, mask the shift count.\n+                \/\/ This allows the JIT to ignore some ISA details.\n+                that = that.lanewise(AND, SHIFT_MASK);\n+            }\n+#end[!FP]\n+            if (op == ROR || op == ROL) {\n+                return blend(lanewise(op, v), m);\n+            } else if (op == AND_NOT) {\n+                \/\/ FIXME: Support this in the JIT.\n+                that = that.lanewise(NOT);\n+                op = AND;\n+            } else if (op == DIV) {\n+                VectorMask<$Boxtype$> eqz = that.eq(($type$)0);\n+                if (eqz.and(m).anyTrue()) {\n+                    throw that.divZeroException();\n+                }\n+                \/\/ suppress div\/0 exceptions in unset lanes\n+                that = that.lanewise(NOT, eqz);\n@@ -740,3 +785,1 @@\n-            \/\/ suppress div\/0 exceptions in unset lanes\n-            that = that.lanewise(NOT, eqz);\n-            return blend(lanewise(DIV, that), m);\n+#end[BITWISE]\n@@ -744,0 +787,39 @@\n+\n+        int opc = opCode(op);\n+        return VectorSupport.binaryOp(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, that, m,\n+            BIN_IMPL.find(op, opc, $abstractvectortype$::binaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Binary, BinaryOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        BIN_IMPL = new ImplCache<>(Binary.class, $Type$Vector.class);\n+\n+    private static BinaryOperation<$abstractvectortype$, VectorMask<$Boxtype$>> binaryOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a + b));\n+            case VECTOR_OP_SUB: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a - b));\n+            case VECTOR_OP_MUL: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a * b));\n+            case VECTOR_OP_DIV: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a \/ b));\n+            case VECTOR_OP_MAX: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)Math.max(a, b));\n+            case VECTOR_OP_MIN: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)Math.min(a, b));\n+#if[BITWISE]\n+            case VECTOR_OP_AND: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a & b));\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a | b));\n+            case VECTOR_OP_XOR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$)(a ^ b));\n+            case VECTOR_OP_LSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> ($type$)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> ($type$)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> ($type$)((a & LSHR_SETUP_MASK) >>> n));\n@@ -745,1 +827,12 @@\n-        return blend(lanewise(op, v), m);\n+#if[FP]\n+            case VECTOR_OP_OR: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> fromBits(toBits(a) | toBits(b)));\n+            case VECTOR_OP_ATAN2: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$) Math.atan2(a, b));\n+            case VECTOR_OP_POW: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$) Math.pow(a, b));\n+            case VECTOR_OP_HYPOT: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, b) -> ($type$) Math.hypot(a, b));\n+#end[FP]\n+            default: return null;\n+        }\n@@ -747,0 +840,1 @@\n+\n@@ -811,1 +905,9 @@\n-        return blend(lanewise(op, e), m);\n+#if[BITWISE]\n+        if (opKind(op, VO_SHIFT) && ($type$)(int)e == e) {\n+            return lanewiseShift(op, (int) e, m);\n+        }\n+        if (op == AND_NOT) {\n+            op = AND; e = ($type$) ~e;\n+        }\n+#end[BITWISE]\n+        return lanewise(op, broadcast(e), m);\n@@ -830,1 +932,0 @@\n-        if ((long)e1 != e\n@@ -832,0 +933,1 @@\n+        if ((long)e1 != e\n@@ -833,1 +935,3 @@\n-            && !(opKind(op, VO_SHIFT) && (int)e1 == e)\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n+#else[BITWISE]\n+        if ((long)e1 != e) {\n@@ -835,1 +939,0 @@\n-            ) {\n@@ -855,1 +958,11 @@\n-        return blend(lanewise(op, e), m);\n+        $type$ e1 = ($type$) e;\n+#if[BITWISE]\n+        if ((long)e1 != e\n+            \/\/ allow shift ops to clip down their int parameters\n+            && !(opKind(op, VO_SHIFT) && (int)e1 == e)) {\n+#else[BITWISE]\n+        if ((long)e1 != e) {\n+#end[BITWISE]\n+            vspecies().checkValue(e);  \/\/ for exception\n+        }\n+        return lanewise(op, e1, m);\n@@ -879,12 +992,3 @@\n-            opc, getClass(), $type$.class, length(),\n-            this, e,\n-            BIN_INT_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-                case VECTOR_OP_LSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> ($type$)(a << n));\n-                case VECTOR_OP_RSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> ($type$)(a >> n));\n-                case VECTOR_OP_URSHIFT: return (v, n) ->\n-                        v.uOp((i, a) -> ($type$)((a & LSHR_SETUP_MASK) >>> n));\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, $type$.class, length(),\n+            this, e, null,\n+            BIN_INT_IMPL.find(op, opc, $abstractvectortype$::broadcastIntOperations));\n@@ -892,0 +996,25 @@\n+\n+    \/*package-private*\/\n+    abstract $abstractvectortype$\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<$Boxtype$> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final $abstractvectortype$\n+    lanewiseShiftTemplate(VectorOperators.Binary op,\n+                          Class<? extends VectorMask<$Boxtype$>> maskClass,\n+                          int e, VectorMask<$Boxtype$> m) {\n+        m.check(maskClass, this);\n+        assert(opKind(op, VO_SHIFT));\n+        \/\/ As per shift specification for Java, mask the shift count.\n+        e &= SHIFT_MASK;\n+        if (op == ROR || op == ROL) {\n+            return blend(lanewiseShift(op, e), m);\n+        }\n+        int opc = opCode(op);\n+        return VectorSupport.broadcastInt(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, e, m,\n+            BIN_INT_IMPL.find(op, opc, $abstractvectortype$::broadcastIntOperations));\n+    }\n+\n@@ -893,1 +1022,1 @@\n-    ImplCache<Binary,VectorBroadcastIntOp<$abstractvectortype$>> BIN_INT_IMPL\n+    ImplCache<Binary,VectorBroadcastIntOp<$abstractvectortype$, VectorMask<$Boxtype$>>> BIN_INT_IMPL\n@@ -896,0 +1025,12 @@\n+    private static VectorBroadcastIntOp<$abstractvectortype$, VectorMask<$Boxtype$>> broadcastIntOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_LSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> ($type$)(a << n));\n+            case VECTOR_OP_RSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> ($type$)(a >> n));\n+            case VECTOR_OP_URSHIFT: return (v, n, m) ->\n+                    v.uOp(m, (i, a) -> ($type$)((a & LSHR_SETUP_MASK) >>> n));\n+            default: return null;\n+        }\n+    }\n+\n@@ -955,10 +1096,3 @@\n-            opc, getClass(), $type$.class, length(),\n-            this, that, tother,\n-            TERN_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-#if[FP]\n-                case VECTOR_OP_FMA: return (v0, v1_, v2_) ->\n-                        v0.tOp(v1_, v2_, (i, a, b, c) -> Math.fma(a, b, c));\n-#end[FP]\n-                default: return null;\n-                }}));\n+            opc, getClass(), null, $type$.class, length(),\n+            this, that, tother, null,\n+            TERN_IMPL.find(op, opc, $abstractvectortype$::ternaryOperations));\n@@ -966,3 +1100,0 @@\n-    private static final\n-    ImplCache<Ternary,TernaryOperation<$abstractvectortype$>> TERN_IMPL\n-        = new ImplCache<>(Ternary.class, $Type$Vector.class);\n@@ -976,2 +1107,2 @@\n-    @ForceInline\n-    public final\n+    @Override\n+    public abstract\n@@ -981,2 +1112,43 @@\n-                                  VectorMask<$Boxtype$> m) {\n-        return blend(lanewise(op, v1, v2), m);\n+                                  VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    $abstractvectortype$ lanewiseTemplate(VectorOperators.Ternary op,\n+                                          Class<? extends VectorMask<$Boxtype$>> maskClass,\n+                                          Vector<$Boxtype$> v1,\n+                                          Vector<$Boxtype$> v2,\n+                                          VectorMask<$Boxtype$> m) {\n+        $abstractvectortype$ that = ($abstractvectortype$) v1;\n+        $abstractvectortype$ tother = ($abstractvectortype$) v2;\n+        \/\/ It's a word: https:\/\/www.dictionary.com\/browse\/tother\n+        \/\/ See also Chapter 11 of Dickens, Our Mutual Friend:\n+        \/\/ \"Totherest Governor,\" replied Mr Riderhood...\n+        that.check(this);\n+        tother.check(this);\n+        m.check(maskClass, this);\n+\n+#if[BITWISE]\n+        if (op == BITWISE_BLEND) {\n+            \/\/ FIXME: Support this in the JIT.\n+            that = this.lanewise(XOR, that).lanewise(AND, tother);\n+            return this.lanewise(XOR, that, m);\n+        }\n+#end[BITWISE]\n+        int opc = opCode(op);\n+        return VectorSupport.ternaryOp(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, that, tother, m,\n+            TERN_IMPL.find(op, opc, $abstractvectortype$::ternaryOperations));\n+    }\n+\n+    private static final\n+    ImplCache<Ternary, TernaryOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        TERN_IMPL = new ImplCache<>(Ternary.class, $Type$Vector.class);\n+\n+    private static TernaryOperation<$abstractvectortype$, VectorMask<$Boxtype$>> ternaryOperations(int opc_) {\n+        switch (opc_) {\n+#if[FP]\n+            case VECTOR_OP_FMA: return (v0, v1_, v2_, m) ->\n+                    v0.tOp(v1_, v2_, m, (i, a, b, c) -> Math.fma(a, b, c));\n+#end[FP]\n+            default: return null;\n+        }\n@@ -1039,1 +1211,1 @@\n-        return blend(lanewise(op, e1, e2), m);\n+        return lanewise(op, broadcast(e1), broadcast(e2), m);\n@@ -1097,1 +1269,1 @@\n-        return blend(lanewise(op, v1, e2), m);\n+        return lanewise(op, v1, broadcast(e2), m);\n@@ -1154,1 +1326,1 @@\n-        return blend(lanewise(op, e1, v2), m);\n+        return lanewise(op, broadcast(e1), v2, m);\n@@ -2822,0 +2994,1 @@\n+                               Class<? extends VectorMask<$Boxtype$>> maskClass,\n@@ -2823,2 +2996,10 @@\n-        $abstractvectortype$ v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            $abstractvectortype$ v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, $abstractvectortype$::reductionOperations)));\n@@ -2839,12 +3020,19 @@\n-            opc, getClass(), $type$.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp(($type$)0, (i, a, b) -> ($type$)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp(($type$)1, (i, a, b) -> ($type$)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> ($type$) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> ($type$) Math.max(a, b)));\n+            opc, getClass(), null, $type$.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, $abstractvectortype$::reductionOperations)));\n+    }\n+\n+    private static final\n+    ImplCache<Associative, ReductionOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, $Type$Vector.class);\n+\n+    private static ReductionOperation<$abstractvectortype$, VectorMask<$Boxtype$>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp(($type$)0, m, (i, a, b) -> ($type$)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp(($type$)1, m, (i, a, b) -> ($type$)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> ($type$) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> ($type$) Math.max(a, b)));\n@@ -2852,6 +3040,6 @@\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp(($type$)-1, (i, a, b) -> ($type$)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp(($type$)0, (i, a, b) -> ($type$)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp(($type$)0, (i, a, b) -> ($type$)(a ^ b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp(($type$)-1, m, (i, a, b) -> ($type$)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp(($type$)0, m, (i, a, b) -> ($type$)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp(($type$)0, m, (i, a, b) -> ($type$)(a ^ b)));\n@@ -2859,2 +3047,2 @@\n-              default: return null;\n-              }})));\n+            default: return null;\n+        }\n@@ -2862,3 +3050,0 @@\n-    private static final\n-    ImplCache<Associative,Function<$abstractvectortype$,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, $Type$Vector.class);\n@@ -3222,2 +3407,1 @@\n-            $abstractvectortype$ zero = vsp.zero();\n-            return zero.blend(zero.fromArray0(a, offset), m);\n+            return vsp.dummyVector().fromArray0(a, offset, m);\n@@ -3316,3 +3500,3 @@\n-            vectorType, $type$.class, vsp.laneCount(),\n-            IntVector.species(vsp.indexShape()).vectorType(),\n-            a, ARRAY_BASE, vix,\n+            vectorType, null, $type$.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, null,\n@@ -3320,1 +3504,1 @@\n-            ($type$[] c, int idx, int[] iMap, int idy, $Type$Species s) ->\n+            (c, idx, iMap, idy, s, vm) ->\n@@ -3322,1 +3506,1 @@\n-        }\n+    }\n@@ -3382,1 +3566,0 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n@@ -3384,1 +3567,1 @@\n-            return vsp.vOp(m, n -> a[offset + indexMap[mapOffset + n]]);\n+            return vsp.dummyVector().fromArray0(a, offset, indexMap, mapOffset, m);\n@@ -3445,2 +3628,1 @@\n-            $abstractvectortype$ zero = vsp.zero();\n-            return zero.blend(zero.fromCharArray0(a, offset), m);\n+            return vsp.dummyVector().fromCharArray0(a, offset, m);\n@@ -3606,1 +3788,1 @@\n-            return zero.blend(zero.fromBooleanArray0(a, offset), m);\n+            return vsp.dummyVector().fromBooleanArray0(a, offset, m);\n@@ -3871,1 +4053,0 @@\n-            \/\/ FIXME: optimize\n@@ -3874,1 +4055,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = v);\n+            intoArray0(a, offset, m);\n@@ -3956,1 +4137,1 @@\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n+            vsp.vectorType(), null, vsp.elementType(), vsp.laneCount(),\n@@ -3959,1 +4140,1 @@\n-            this,\n+            this, null,\n@@ -3961,1 +4142,1 @@\n-            (arr, off, v, map, mo)\n+            (arr, off, v, map, mo, vm)\n@@ -4022,6 +4203,1 @@\n-            \/\/ FIXME: Cannot vectorize yet, if there's a mask.\n-            stOp(a, offset, m,\n-                 (arr, off, i, e) -> {\n-                     int j = indexMap[mapOffset + i];\n-                     arr[off + j] = e;\n-                 });\n+            intoArray0(a, offset, indexMap, mapOffset, m);\n@@ -4095,1 +4271,0 @@\n-            \/\/ FIXME: optimize\n@@ -4098,1 +4273,1 @@\n-            stOp(a, offset, m, (arr, off, i, v) -> arr[off+i] = (char) v);\n+            intoCharArray0(a, offset, m);\n@@ -4258,1 +4433,0 @@\n-            \/\/ FIXME: optimize\n@@ -4261,1 +4435,1 @@\n-            stOp(a, offset, m, (arr, off, i, e) -> arr[off+i] = (e & 1) != 0);\n+            intoBooleanArray0(a, offset, m);\n@@ -4463,0 +4637,78 @@\n+    \/*package-private*\/\n+    abstract\n+    $abstractvectortype$ fromArray0($type$[] a, int offset, VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    $abstractvectortype$ fromArray0Template(Class<M> maskClass, $type$[] a, int offset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> arr_[off_ + i]));\n+    }\n+\n+#if[!byteOrShort]\n+    \/*package-private*\/\n+    abstract\n+    $abstractvectortype$ fromArray0($type$[] a, int offset,\n+                                    int[] indexMap, int mapOffset,\n+                                    VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    $abstractvectortype$ fromArray0Template(Class<M> maskClass, $type$[] a, int offset,\n+                                            int[] indexMap, int mapOffset, M m) {\n+        $Type$Species vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+        Objects.requireNonNull(a);\n+        Objects.requireNonNull(indexMap);\n+        m.check(vsp);\n+        Class<? extends $abstractvectortype$> vectorType = vsp.vectorType();\n+\n+#if[longOrDouble]\n+        if (vsp.laneCount() == 1) {\n+          return $abstractvectortype$.fromArray(vsp, a, offset + indexMap[mapOffset], m);\n+        }\n+\n+        \/\/ Index vector: vix[0:n] = k -> offset + indexMap[mapOffset + k]\n+        IntVector vix;\n+        if (isp.laneCount() != vsp.laneCount()) {\n+            \/\/ For $Type$MaxVector,  if vector length is non-power-of-two or\n+            \/\/ 2048 bits, indexShape of $Type$ species is S_MAX_BIT.\n+            \/\/ Assume that vector length is 2048, then the lane count of $Type$\n+            \/\/ vector is 32. When converting $Type$ species to int species,\n+            \/\/ indexShape is still S_MAX_BIT, but the lane count of int vector\n+            \/\/ is 64. So when loading index vector (IntVector), only lower half\n+            \/\/ of index data is needed.\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset, IntMaxVector.IntMaxMask.LOWER_HALF_TRUE_MASK)\n+                .add(offset);\n+        } else {\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset)\n+                .add(offset);\n+        }\n+#else[longOrDouble]\n+        \/\/ Index vector: vix[0:n] = k -> offset + indexMap[mapOffset + k]\n+        IntVector vix = IntVector\n+            .fromArray(isp, indexMap, mapOffset)\n+            .add(offset);\n+#end[longOrDouble]\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        return VectorSupport.loadWithMap(\n+            vectorType, maskClass, $type$.class, vsp.laneCount(),\n+            isp.vectorType(),\n+            a, ARRAY_BASE, vix, m,\n+            a, offset, indexMap, mapOffset, vsp,\n+            (c, idx, iMap, idy, s, vm) ->\n+            s.vOp(vm, n -> c[idx + iMap[idy+n]]));\n+    }\n+#end[!byteOrShort]\n+\n@@ -4478,0 +4730,17 @@\n+\n+    \/*package-private*\/\n+    abstract\n+    $abstractvectortype$ fromCharArray0(char[] a, int offset, VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    $abstractvectortype$ fromCharArray0Template(Class<M> maskClass, char[] a, int offset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+                vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+                a, charArrayAddress(a, offset), m,\n+                a, offset, vsp,\n+                (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                            (arr_, off_, i) -> (short) arr_[off_ + i]));\n+    }\n@@ -4495,0 +4764,17 @@\n+\n+    \/*package-private*\/\n+    abstract\n+    $abstractvectortype$ fromBooleanArray0(boolean[] a, int offset, VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    $abstractvectortype$ fromBooleanArray0Template(Class<M> maskClass, boolean[] a, int offset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        return VectorSupport.loadMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, booleanArrayAddress(a, offset), m,\n+            a, offset, vsp,\n+            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                                        (arr_, off_, i) -> (byte) (arr_[off_ + i] ? 1 : 0)));\n+    }\n@@ -4550,0 +4836,99 @@\n+    abstract\n+    void intoArray0($type$[] a, int offset, VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    void intoArray0Template(Class<M> maskClass, $type$[] a, int offset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, arrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = e));\n+    }\n+\n+#if[!byteOrShort]\n+    abstract\n+    void intoArray0($type$[] a, int offset,\n+                    int[] indexMap, int mapOffset,\n+                    VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    void intoArray0Template(Class<M> maskClass, $type$[] a, int offset,\n+                            int[] indexMap, int mapOffset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        IntVector.IntSpecies isp = IntVector.species(vsp.indexShape());\n+#if[longOrDouble]\n+        if (vsp.laneCount() == 1) {\n+            intoArray(a, offset + indexMap[mapOffset], m);\n+            return;\n+        }\n+\n+        \/\/ Index vector: vix[0:n] = i -> offset + indexMap[mo + i]\n+        IntVector vix;\n+        if (isp.laneCount() != vsp.laneCount()) {\n+            \/\/ For $Type$MaxVector,  if vector length  is 2048 bits, indexShape\n+            \/\/ of $Type$ species is S_MAX_BIT. and the lane count of $Type$\n+            \/\/ vector is 32. When converting $Type$ species to int species,\n+            \/\/ indexShape is still S_MAX_BIT, but the lane count of int vector\n+            \/\/ is 64. So when loading index vector (IntVector), only lower half\n+            \/\/ of index data is needed.\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset, IntMaxVector.IntMaxMask.LOWER_HALF_TRUE_MASK)\n+                .add(offset);\n+        } else {\n+            vix = IntVector\n+                .fromArray(isp, indexMap, mapOffset)\n+                .add(offset);\n+        }\n+\n+#else[longOrDouble]\n+        \/\/ Index vector: vix[0:n] = i -> offset + indexMap[mo + i]\n+        IntVector vix = IntVector\n+            .fromArray(isp, indexMap, mapOffset)\n+            .add(offset);\n+#end[longOrDouble]\n+\n+        \/\/ FIXME: Check index under mask controlling.\n+        vix = VectorIntrinsics.checkIndex(vix, a.length);\n+\n+        VectorSupport.storeWithMap(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            isp.vectorType(),\n+            a, arrayAddress(a, 0), vix,\n+            this, m,\n+            a, offset, indexMap, mapOffset,\n+            (arr, off, v, map, mo, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> {\n+                          int j = map[mo + i];\n+                          arr[off + j] = e;\n+                      }));\n+    }\n+#end[!byteOrShort]\n+\n+#if[byte]\n+    abstract\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    void intoBooleanArray0Template(Class<M> maskClass, boolean[] a, int offset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        ByteVector normalized = this.and((byte) 1);\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, booleanArrayAddress(a, offset),\n+            normalized, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = (e & 1) != 0));\n+    }\n+#end[byte]\n+\n@@ -4581,0 +4966,20 @@\n+#if[short]\n+    \/*package-private*\/\n+    abstract\n+    void intoCharArray0(char[] a, int offset, VectorMask<$Boxtype$> m);\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    void intoCharArray0Template(Class<M> maskClass, char[] a, int offset, M m) {\n+        m.check(species());\n+        $Type$Species vsp = vspecies();\n+        VectorSupport.storeMasked(\n+            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n+            a, charArrayAddress(a, offset),\n+            this, m, a, offset,\n+            (arr, off, v, vm)\n+            -> v.stOp(arr, off, vm,\n+                      (arr_, off_, i, e) -> arr_[off_ + i] = (char) e));\n+    }\n+#end[short]\n+\n@@ -4956,1 +5361,1 @@\n-                                      AbstractMask<$Boxtype$> m,\n+                                      VectorMask<$Boxtype$> m,\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":607,"deletions":202,"binary":false,"changes":809,"status":"modified"},{"patch":"@@ -241,2 +241,2 @@\n-    $type$ rOp($type$ v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    $type$ rOp($type$ v, VectorMask<$Boxtype$> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -278,0 +278,6 @@\n+    @Override\n+    @ForceInline\n+    public $vectortype$ lanewise(Unary op, VectorMask<$Boxtype$> m) {\n+        return ($vectortype$) super.lanewiseTemplate(op, $masktype$.class, ($masktype$) m);  \/\/ specialize\n+    }\n+\n@@ -284,0 +290,6 @@\n+    @Override\n+    @ForceInline\n+    public $vectortype$ lanewise(Binary op, Vector<$Boxtype$> v, VectorMask<$Boxtype$> m) {\n+        return ($vectortype$) super.lanewiseTemplate(op, $masktype$.class, v, ($masktype$) m);  \/\/ specialize\n+    }\n+\n@@ -291,0 +303,7 @@\n+\n+    \/*package-private*\/\n+    @Override\n+    @ForceInline $vectortype$\n+    lanewiseShift(VectorOperators.Binary op, int e, VectorMask<$Boxtype$> m) {\n+        return ($vectortype$) super.lanewiseShiftTemplate(op, $masktype$.class, e, ($masktype$) m);  \/\/ specialize\n+    }\n@@ -298,1 +317,1 @@\n-    lanewise(VectorOperators.Ternary op, Vector<$Boxtype$> v1, Vector<$Boxtype$> v2) {\n+    lanewise(Ternary op, Vector<$Boxtype$> v1, Vector<$Boxtype$> v2) {\n@@ -302,0 +321,8 @@\n+    @Override\n+    @ForceInline\n+    public final\n+    $vectortype$\n+    lanewise(Ternary op, Vector<$Boxtype$> v1, Vector<$Boxtype$> v2, VectorMask<$Boxtype$> m) {\n+        return ($vectortype$) super.lanewiseTemplate(op, $masktype$.class, v1, v2, ($masktype$) m);  \/\/ specialize\n+    }\n+\n@@ -321,1 +348,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, $masktype$.class, ($masktype$) m);  \/\/ specialized\n@@ -334,1 +361,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, $masktype$.class, ($masktype$) m);  \/\/ specialized\n@@ -893,3 +920,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_AND, $masktype$.class, $bitstype$.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a & b));\n+            return VectorSupport.binaryOp(VECTOR_OP_AND, $masktype$.class, null, $bitstype$.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a & b));\n@@ -903,3 +930,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_OR, $masktype$.class, $bitstype$.class, VLENGTH,\n-                                             this, m,\n-                                             (m1, m2) -> m1.bOp(m2, (i, a, b) -> a | b));\n+            return VectorSupport.binaryOp(VECTOR_OP_OR, $masktype$.class, null, $bitstype$.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a | b));\n@@ -913,3 +940,3 @@\n-            return VectorSupport.binaryOp(VECTOR_OP_XOR, $masktype$.class, $bitstype$.class, VLENGTH,\n-                                          this, m,\n-                                          (m1, m2) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n+            return VectorSupport.binaryOp(VECTOR_OP_XOR, $masktype$.class, null, $bitstype$.class, VLENGTH,\n+                                          this, m, null,\n+                                          (m1, m2, vm) -> m1.bOp(m2, (i, a, b) -> a ^ b));\n@@ -1064,0 +1091,16 @@\n+    @ForceInline\n+    @Override\n+    final\n+    $abstractvectortype$ fromArray0($type$[] a, int offset, VectorMask<$Boxtype$> m) {\n+        return super.fromArray0Template($masktype$.class, a, offset, ($masktype$) m);  \/\/ specialize\n+    }\n+\n+#if[!byteOrShort]\n+    @ForceInline\n+    @Override\n+    final\n+    $abstractvectortype$ fromArray0($type$[] a, int offset, int[] indexMap, int mapOffset, VectorMask<$Boxtype$> m) {\n+        return super.fromArray0Template($masktype$.class, a, offset, indexMap, mapOffset, ($masktype$) m);\n+    }\n+#end[!byteOrShort]\n+\n@@ -1071,0 +1114,7 @@\n+\n+    @ForceInline\n+    @Override\n+    final\n+    $abstractvectortype$ fromCharArray0(char[] a, int offset, VectorMask<$Boxtype$> m) {\n+        return super.fromCharArray0Template($masktype$.class, a, offset, ($masktype$) m);  \/\/ specialize\n+    }\n@@ -1080,0 +1130,7 @@\n+\n+    @ForceInline\n+    @Override\n+    final\n+    $abstractvectortype$ fromBooleanArray0(boolean[] a, int offset, VectorMask<$Boxtype$> m) {\n+        return super.fromBooleanArray0Template($masktype$.class, a, offset, ($masktype$) m);  \/\/ specialize\n+    }\n@@ -1103,0 +1160,25 @@\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0($type$[] a, int offset, VectorMask<$Boxtype$> m) {\n+        super.intoArray0Template($masktype$.class, a, offset, ($masktype$) m);\n+    }\n+\n+#if[!byteOrShort]\n+    @ForceInline\n+    @Override\n+    final\n+    void intoArray0($type$[] a, int offset, int[] indexMap, int mapOffset, VectorMask<$Boxtype$> m) {\n+        super.intoArray0Template($masktype$.class, a, offset, indexMap, mapOffset, ($masktype$) m);\n+    }\n+#end[!byteOrShort]\n+\n+#if[byte]\n+    @ForceInline\n+    @Override\n+    final\n+    void intoBooleanArray0(boolean[] a, int offset, VectorMask<$Boxtype$> m) {\n+        super.intoBooleanArray0Template($masktype$.class, a, offset, ($masktype$) m);\n+    }\n+#end[byte]\n+\n@@ -1110,0 +1192,9 @@\n+#if[short]\n+    @ForceInline\n+    @Override\n+    final\n+    void intoCharArray0(char[] a, int offset, VectorMask<$Boxtype$> m) {\n+        super.intoCharArray0Template($masktype$.class, a, offset, ($masktype$) m);\n+    }\n+#end[short]\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-VectorBits.java.template","additions":105,"deletions":14,"binary":false,"changes":119,"status":"modified"}]}