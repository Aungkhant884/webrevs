{"files":[{"patch":"@@ -377,1 +377,1 @@\n-    C_FLAG_DEPS=\"-MMD -MF\"\n+    GENDEPS_FLAGS=\"-MMD -MF\"\n@@ -379,1 +379,1 @@\n-    C_FLAG_DEPS=\"-MMD -MF\"\n+    GENDEPS_FLAGS=\"-MMD -MF\"\n@@ -381,1 +381,1 @@\n-    C_FLAG_DEPS=\"-qmakedep=gcc -MF\"\n+    GENDEPS_FLAGS=\"-qmakedep=gcc -MF\"\n@@ -383,3 +383,1 @@\n-  CXX_FLAG_DEPS=\"$C_FLAG_DEPS\"\n-  AC_SUBST(C_FLAG_DEPS)\n-  AC_SUBST(CXX_FLAG_DEPS)\n+  AC_SUBST(GENDEPS_FLAGS)\n","filename":"make\/autoconf\/flags.m4","additions":4,"deletions":6,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -480,2 +480,1 @@\n-C_FLAG_DEPS:=@C_FLAG_DEPS@\n-CXX_FLAG_DEPS:=@CXX_FLAG_DEPS@\n+GENDEPS_FLAGS := @GENDEPS_FLAGS@\n","filename":"make\/autoconf\/spec.gmk.in","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -699,2 +699,7 @@\n-    # On windows, the assember is \"ml.exe\"\n-    UTIL_LOOKUP_TOOLCHAIN_PROGS(AS, ml)\n+    if test \"x$OPENJDK_TARGET_CPU_BITS\" = \"x64\"; then\n+      # On 64 bit windows, the assember is \"ml64.exe\"\n+      UTIL_LOOKUP_TOOLCHAIN_PROGS(AS, ml64)\n+    else\n+      # otherwise, the assember is \"ml.exe\"\n+      UTIL_LOOKUP_TOOLCHAIN_PROGS(AS, ml)\n+    fi\n@@ -882,1 +887,7 @@\n-      UTIL_LOOKUP_PROGS(BUILD_AS, ml, [$VS_PATH])\n+      if test \"x$OPENJDK_TARGET_CPU_BITS\" = \"x64\"; then\n+        # On 64 bit windows, the assember is \"ml64.exe\"\n+        UTIL_LOOKUP_PROGS(BUILD_AS, ml64, [$VS_PATH])\n+      else\n+        # otherwise the assember is \"ml.exe\"\n+        UTIL_LOOKUP_PROGS(BUILD_AS, ml, [$VS_PATH])\n+      fi\n","filename":"make\/autoconf\/toolchain.m4","additions":14,"deletions":3,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -352,1 +352,1 @@\n-      $1_DEP_FLAG := $(C_FLAG_DEPS)\n+      $1_DEP_FLAG := $(GENDEPS_FLAGS)\n@@ -358,3 +358,8 @@\n-      $1_DEP_FLAG := $(C_FLAG_DEPS)\n-    else ifneq ($$(filter %.s %.S, $$($1_FILENAME)), )\n-      # Compile as assembler file\n+      $1_DEP_FLAG := $(GENDEPS_FLAGS)\n+    else ifneq ($$(filter %.S, $$($1_FILENAME)), )\n+      # Compile as preprocessed assembler file\n+      $1_FLAGS := $$($1_BASE_ASFLAGS)\n+      $1_COMPILER := $(AS)\n+      $1_DEP_FLAG := $(GENDEPS_FLAGS)\n+    else ifneq ($$(filter %.s, $$($1_FILENAME)), )\n+      # Compile as non-preprocessed assembler file\n@@ -369,1 +374,1 @@\n-      $1_DEP_FLAG := $(CXX_FLAG_DEPS)\n+      $1_DEP_FLAG := $(GENDEPS_FLAGS)\n@@ -374,1 +379,1 @@\n-    ifeq ($$(filter %.s %.S, $$($1_FILENAME)), )\n+    ifeq ($$(filter %.s, $$($1_FILENAME)), )\n@@ -427,9 +432,17 @@\n-\t  $$(call ExecuteWithLog, $$@, $$(call MakeCommandRelative, \\\n-\t      $$($1_COMPILER) -showIncludes $$($1_COMPILE_OPTIONS))) \\\n-\t      | $(TR) -d '\\r' | $(GREP) -v -e \"^Note: including file:\" \\\n-\t          -e \"^$$($1_FILENAME)$$$$\" || test \"$$$$?\" = \"1\" ; \\\n-\t  $(ECHO) $$@: \\\\ > $$($1_DEPS_FILE) ; \\\n-\t  $(SED) $(WINDOWS_SHOWINCLUDE_SED_PATTERN) $$($1_OBJ).log \\\n-\t      | $(SORT) -u >> $$($1_DEPS_FILE) ; \\\n-\t  $(ECHO) >> $$($1_DEPS_FILE) ; \\\n-\t  $(SED) $(DEPENDENCY_TARGET_SED_PATTERN) $$($1_DEPS_FILE) > $$($1_DEPS_TARGETS_FILE)\n+          ifeq ($$(filter %.S, $$($1_FILENAME)), )\n+\t    $$(call ExecuteWithLog, $$@, $$(call MakeCommandRelative, \\\n+\t        $$($1_COMPILER) -showIncludes $$($1_COMPILE_OPTIONS))) \\\n+\t        | $(TR) -d '\\r' | $(GREP) -v -e \"^Note: including file:\" \\\n+\t            -e \"^$$($1_FILENAME)$$$$\" || test \"$$$$?\" = \"1\" ; \\\n+\t    $(ECHO) $$@: \\\\ > $$($1_DEPS_FILE) ; \\\n+\t    $(SED) $(WINDOWS_SHOWINCLUDE_SED_PATTERN) $$($1_OBJ).log \\\n+\t        | $(SORT) -u >> $$($1_DEPS_FILE) ; \\\n+\t    $(ECHO) >> $$($1_DEPS_FILE) ; \\\n+\t    $(SED) $(DEPENDENCY_TARGET_SED_PATTERN) $$($1_DEPS_FILE) > $$($1_DEPS_TARGETS_FILE)\n+          else\n+            # For assembler calls, no need to build dependency list.\n+\t    $$(call ExecuteWithLog, $$@, $$(call MakeCommandRelative, \\\n+\t        $$($1_COMPILER) $$($1_FLAGS) \\\n+\t          $(CC_OUT_OPTION)$$($1_OBJ) -nologo -c -Ta $$($1_SRC_FILE) 2>&1 \\\n+\t            | $(TR) -d '\\r' | $(GREP) -v -e \"Assembling:\" || test \"$$$$?\" = \"1\" ;))\n+          endif\n@@ -817,1 +830,1 @@\n-            $$($1_OPT_CFLAGS) -x c++-header -c $(C_FLAG_DEPS) \\\n+            $$($1_OPT_CFLAGS) -x c++-header -c $(GENDEPS_FLAGS) \\\n","filename":"make\/common\/NativeCompilation.gmk","additions":29,"deletions":16,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -2454,0 +2454,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n@@ -2502,0 +2516,4 @@\n+    if (bt == T_BOOLEAN) {\n+      \/\/ To support vector api load\/store mask.\n+      return MaxVectorSize \/ 8;\n+    }\n@@ -2529,1 +2547,1 @@\n-  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+  if (UseSVE > 0 && 2 <= len && len <= 256) {\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":19,"deletions":1,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -3766,0 +3766,66 @@\n+\/\/ Load Vector (32 bits)\n+instruct loadV4(vecD dst, vmem4 mem)\n+%{\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 4);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8(vecD dst, vmem8 mem)\n+%{\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 8);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16(vecX dst, vmem16 mem)\n+%{\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 16);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(vload_reg_mem128);\n+%}\n+\n+\/\/ Store Vector (32 bits)\n+instruct storeV4(vecD src, vmem4 mem)\n+%{\n+  predicate(n->as_StoreVector()->memory_size() == 4);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8(vecD src, vmem8 mem)\n+%{\n+  predicate(n->as_StoreVector()->memory_size() == 8);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16(vecX src, vmem16 mem)\n+%{\n+  predicate(n->as_StoreVector()->memory_size() == 16);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(vstore_reg_mem128);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":66,"deletions":0,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -1505,0 +1505,7 @@\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst, UseSVE == 0 && )\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst, UseSVE == 0 && )\n+VLoadStore(ldrq, Q, load, 16,  X, 128, dst, UseSVE == 0 && )\n+VLoadStore(strs, S, store, 4,  D, 32,  src, )\n+VLoadStore(strd, D, store, 8,  D, 64,  src, )\n+VLoadStore(strq, Q, store, 16, X, 128, src, )\n+dnl\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -102,0 +102,24 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n@@ -127,2 +151,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n+  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                   PRegister pg, BasicType mem_elem_bt,\n+                                   Assembler::SIMD_RegVariant vector_elem_size,\n@@ -131,2 +156,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int esize = type2aelembytes(mem_elem_bt);\n@@ -138,1 +162,0 @@\n-        type = Assembler::B;\n@@ -142,1 +165,0 @@\n-        type = Assembler::H;\n@@ -146,1 +168,0 @@\n-        type = Assembler::S;\n@@ -150,1 +171,0 @@\n-        type = Assembler::D;\n@@ -156,1 +176,1 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      (masm.*insn)(reg, vector_elem_size, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n@@ -163,0 +183,30 @@\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n@@ -172,7 +222,0 @@\n-      case Op_Extract:\n-      case Op_ExtractB:\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -182,5 +225,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n@@ -189,14 +227,0 @@\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadMask:\n-      case Op_VectorMaskCmp:\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n@@ -222,1 +246,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -224,1 +248,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -230,0 +255,1 @@\n+    BasicType bt = vector_element_basic_type(this);\n@@ -231,1 +257,1 @@\n-                         vector_element_basic_type(this), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n@@ -238,1 +264,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -244,0 +271,1 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n@@ -245,1 +273,51 @@\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, iRegINoSp tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_LoadVector()->memory_size() != MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, $tmp\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp$$reg), vector_length(this));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   zr, as_Register($tmp$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, iRegINoSp tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_StoreVector()->memory_size() != MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, $tmp\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp$$reg), vector_length(this, $src));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   zr, as_Register($tmp$$reg));\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n@@ -251,0 +329,39 @@\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->as_Vector()->length_in_bytes() ==\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \" # reinterpret $dst\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpretResize(vReg dst, vReg src, iRegINoSp tmp, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->as_Vector()->length_in_bytes() !=\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, TEMP tmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \" # reinterpretResize $dst,$src\\t\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                            length_in_bytes_src : length_in_bytes_dst;\n+    __ mov(as_Register($tmp$$reg), length_in_bytes_resize);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), __ B,\n+                   zr, as_Register($tmp$$reg));\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -868,1 +985,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -875,0 +992,255 @@\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ load\/store mask vector\n+\n+instruct vloadmask_loadV(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    Assembler::SIMD_RegVariant to_vect_size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_size, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask(vmemA mem, vReg src, vReg tmp, immI size) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= 2 &&\n+            n->as_StoreVector()->vect_type()->element_basic_type() == T_BOOLEAN);\n+  match(Set mem (StoreVector mem (VectorStoreMask src size)));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant from_vect_size =\n+              elemBytes_to_regVariant((int)$size$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_size, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -977,1 +1349,1 @@\n-\/\/ vector max reduction\n+\/\/ vector and reduction\n@@ -979,8 +1351,10 @@\n-instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n+instruct reduce_andB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # and reduction B\" %}\n@@ -988,1 +1362,1 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ B,\n@@ -990,1 +1364,3 @@\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -995,8 +1371,10 @@\n-instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n+instruct reduce_andS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # and reduction H\" %}\n@@ -1004,1 +1382,1 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ H,\n@@ -1006,1 +1384,3 @@\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1011,10 +1391,9 @@\n-\/\/ vector min reduction\n-\n-instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\t # and reduction S\" %}\n@@ -1022,1 +1401,1 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ S,\n@@ -1024,1 +1403,2 @@\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1029,8 +1409,9 @@\n-instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"andr  $dst, $dst, $src1\\t # and reduction D\" %}\n@@ -1038,1 +1419,1 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ D,\n@@ -1040,1 +1421,2 @@\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1045,1 +1427,1 @@\n-\/\/ vector Math.rint, floor, ceil\n+\/\/ vector or reduction\n@@ -1047,5 +1429,10 @@\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct reduce_orB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # or reduction B\" %}\n@@ -1053,14 +1440,5 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-    }\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1071,5 +1449,5 @@\n-\/\/ vector replicate\n-\n-instruct replicateB(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB src));\n+instruct reduce_orS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1077,1 +1455,4 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # or reduction H\" %}\n@@ -1079,1 +1460,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1084,3 +1469,5 @@\n-instruct replicateS(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS src));\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1088,1 +1475,3 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\t # or reduction S\" %}\n@@ -1090,1 +1479,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1095,3 +1487,5 @@\n-instruct replicateI(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI src));\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1099,1 +1493,3 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"orr  $dst, $dst, $src1\\t # or reduction D\" %}\n@@ -1101,1 +1497,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1106,10 +1505,1 @@\n-instruct replicateL(vReg dst, iRegL src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL src));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n-  ins_encode %{\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n+\/\/ vector xor reduction\n@@ -1117,3 +1507,5 @@\n-instruct replicateB_imm8(vReg dst, immI8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB con));\n+instruct reduce_eorB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1121,1 +1513,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # eor reduction B\" %}\n@@ -1123,1 +1518,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1128,3 +1527,5 @@\n-instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS con));\n+instruct reduce_eorS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1132,1 +1533,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # eor reduction H\" %}\n@@ -1134,1 +1538,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1139,3 +1547,5 @@\n-instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI con));\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1143,1 +1553,3 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\t # eor reduction S\" %}\n@@ -1145,1 +1557,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1150,3 +1565,5 @@\n-instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL con));\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1154,1 +1571,3 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"eor  $dst, $dst, $src1\\t # eor reduction D\" %}\n@@ -1156,1 +1575,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1161,3 +1583,7 @@\n-instruct replicateF(vReg dst, vRegF src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateF src));\n+\/\/ vector max reduction\n+\n+instruct reduce_maxB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1165,1 +1591,4 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction B\" %}\n@@ -1167,2 +1596,5 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1173,3 +1605,5 @@\n-instruct replicateD(vReg dst, vRegD src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateD src));\n+instruct reduce_maxS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1177,1 +1611,4 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction H\" %}\n@@ -1179,2 +1616,5 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1185,5 +1625,5 @@\n-\/\/ vector shift\n-\n-instruct vasrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB dst shift));\n+instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1191,1 +1631,4 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction S\" %}\n@@ -1193,2 +1636,5 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1199,3 +1645,5 @@\n-instruct vasrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS dst shift));\n+instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1203,1 +1651,4 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 GT\\t# max reduction D\" %}\n@@ -1205,2 +1656,5 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1211,5 +1665,8 @@\n-instruct vasrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI dst shift));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n@@ -1217,2 +1674,3 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1223,5 +1681,8 @@\n-instruct vasrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL dst shift));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n@@ -1229,2 +1690,3 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1235,3 +1697,7 @@\n-instruct vlslB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB dst shift));\n+\/\/ vector min reduction\n+\n+instruct reduce_minB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1239,1 +1705,4 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction B\" %}\n@@ -1241,2 +1710,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n@@ -1247,3 +1719,5 @@\n-instruct vlslS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS dst shift));\n+instruct reduce_minS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1251,1 +1725,4 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction H\" %}\n@@ -1253,2 +1730,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n@@ -1259,3 +1739,5 @@\n-instruct vlslI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI dst shift));\n+instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1263,1 +1745,4 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction S\" %}\n@@ -1265,2 +1750,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n@@ -1271,3 +1759,5 @@\n-instruct vlslL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL dst shift));\n+instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1275,1 +1765,4 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 LT\\t# min reduction D\" %}\n@@ -1277,2 +1770,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n@@ -1283,5 +1779,8 @@\n-instruct vlsrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB dst shift));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n@@ -1289,2 +1788,3 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1295,5 +1795,8 @@\n-instruct vlsrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS dst shift));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n@@ -1301,2 +1804,3 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1307,8 +1811,22 @@\n-instruct vlsrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI dst shift));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n-  ins_encode %{\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+    }\n@@ -1319,1 +1837,36 @@\n-instruct vlsrL(vReg dst, vReg shift) %{\n+\/\/ vector replicate\n+\n+instruct replicateB(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (ReplicateB src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (ReplicateS src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (ReplicateI src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL(vReg dst, iRegL src) %{\n@@ -1321,1 +1874,1 @@\n-  match(Set dst (URShiftVL dst shift));\n+  match(Set dst (ReplicateL src));\n@@ -1323,1 +1876,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n@@ -1325,2 +1878,1 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n@@ -1331,1 +1883,2 @@\n-instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+\n+instruct replicateB_imm8(vReg dst, immI8 con) %{\n@@ -1333,1 +1886,1 @@\n-  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (ReplicateB con));\n@@ -1335,1 +1888,72 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (ReplicateS con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (ReplicateI con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (ReplicateL con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct replicateF(vReg dst, vRegF src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (ReplicateF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateD(vReg dst, vRegD src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (ReplicateD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift\n+\n+instruct vasrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (RShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n@@ -1337,8 +1961,1 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) con = 7;\n-         as_FloatRegister($src$$reg), con);\n+         ptrue, as_FloatRegister($shift$$reg));\n@@ -1350,1 +1967,1 @@\n-instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrS(vReg dst, vReg shift) %{\n@@ -1352,1 +1969,1 @@\n-  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  match(Set dst (RShiftVS dst shift));\n@@ -1354,1 +1971,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n@@ -1356,8 +1973,1 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) con = 15;\n-         as_FloatRegister($src$$reg), con);\n+         ptrue, as_FloatRegister($shift$$reg));\n@@ -1369,1 +1979,1 @@\n-instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrI(vReg dst, vReg shift) %{\n@@ -1371,1 +1981,1 @@\n-  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  match(Set dst (RShiftVI dst shift));\n@@ -1373,1 +1983,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n@@ -1375,7 +1985,1 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-         as_FloatRegister($src$$reg), con);\n+         ptrue, as_FloatRegister($shift$$reg));\n@@ -1387,1 +1991,1 @@\n-instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+instruct vasrL(vReg dst, vReg shift) %{\n@@ -1389,1 +1993,1 @@\n-  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  match(Set dst (RShiftVL dst shift));\n@@ -1391,1 +1995,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n@@ -1393,7 +1997,861 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-         as_FloatRegister($src$$reg), con);\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (LShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (LShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (LShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (LShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (URShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (URShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (URShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (URShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) con = 7;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) con = 15;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sqrt\n+\n+instruct vsqrtF(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (SqrtVF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (SqrtVD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sub\n+\n+instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (SubVB src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (SubVS src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (SubVI src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (SubVL src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (SubVF src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (SubVD src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector cast -------------------------------\n+\n+instruct vcvtBtoS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\t# convert B to S vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\t# convert S to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\t# convert I to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastB2X src));\n+  effect(TEMP_DEF dst);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\t# convert B to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP_DEF dst);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert S to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+\t    n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastB2X src));\n+  effect(TEMP_DEF dst);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert B to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtStoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, B, 0\\n\\t\"\n+            \"sve_uzp1  $dst, B, $src, tmp\\t# convert S to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\t# convert I to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\t# convert L to I vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtItoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert I to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert L to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtLtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert L to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert B to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert S to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert B to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtLtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert L to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvt  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert D to F vector\" %}\n+  ins_encode %{\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtItoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, S\\t# convert I to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastL2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, D, $src, D\\t# convert L to D vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\t# convert F to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\t# convert D to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtItoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert I to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert S to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_fcvt  $dst, D, $dst, S\\t# convert F to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ S);\n@@ -1405,5 +2863,11 @@\n-instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+\n+instruct vcvtFtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\t# convert F to S vector\" %}\n@@ -1411,13 +2875,3 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1428,5 +2882,10 @@\n-instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+instruct vcvtDtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\t# convert D to I vector\" %}\n@@ -1434,13 +2893,3 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1451,5 +2900,13 @@\n-instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+\n+\n+instruct vcvtFtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert F to B vector\" %}\n@@ -1457,8 +2914,4 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1469,5 +2922,11 @@\n-instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct vcvtDtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert D to S vector\" %}\n@@ -1475,8 +2934,4 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1487,5 +2942,10 @@\n-instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+\n+\n+instruct vcvtFtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert F to L vector\" %}\n@@ -1493,8 +2953,2 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n@@ -1505,5 +2959,13 @@\n-instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+\n+instruct vcvtDtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 8 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert D to B vector\" %}\n@@ -1511,8 +2973,5 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1523,5 +2982,12 @@\n-instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+\n+instruct extractB(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractB src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, B, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, B, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 7U\\t# extract from vector(B)\" %}\n@@ -1529,3 +2995,4 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ B, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 7U);\n@@ -1536,5 +3003,10 @@\n-instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct extractS(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractS src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, H, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, H, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 15U\\t# extract from vector(S)\" %}\n@@ -1542,3 +3014,4 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ H, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ H, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);\n@@ -1549,6 +3022,10 @@\n-instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+\n+instruct extractI(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractI src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, S, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, S, $pTmp, $src\\t# extract from vector(I)\" %}\n@@ -1556,1 +3033,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ S, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n@@ -1561,7 +3040,9 @@\n-instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+instruct extractL(iRegLNoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractL src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, D, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, D, $pTmp, $src\\t# extract from vector(L)\" %}\n@@ -1569,1 +3050,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ D, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n@@ -1574,6 +3057,9 @@\n-instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+instruct extractF(vRegF dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractF src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, S, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, S, $pTmp, $src\\t# extract from vector(F)\" %}\n@@ -1581,1 +3067,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ S, zr, rscratch1);\n+    __ sve_lastb(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n@@ -1586,6 +3074,9 @@\n-instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+instruct extractD(vRegD dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractD src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, D, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, D, $pTmp, $src\\t# extract from vector(D)\" %}\n@@ -1593,1 +3084,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ D, zr, rscratch1);\n+    __ sve_lastb(as_FloatRegister($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n@@ -1598,1 +3091,1 @@\n-\/\/ vector sqrt\n+\/\/ ------------------------------- VectorTest ----------------------------------\n@@ -1600,3 +3093,6 @@\n-instruct vsqrtF(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVF src));\n+instruct vtest_alltrue(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1604,1 +3100,2 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_cmpeq $pTmp, $src1, 0\\n\\t\"\n+            \"csetw $dst, EQ\\t# VectorTest (sve) - alltrue\" %}\n@@ -1606,2 +3103,6 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n@@ -1612,3 +3113,6 @@\n-instruct vsqrtD(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVD src));\n+instruct vtest_anytrue(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1616,1 +3120,2 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_cmpeq $pTmp, $src1, -1\\n\\t\"\n+            \"csetw $dst, NE\\t# VectorTest (sve) - anytrue\" %}\n@@ -1618,2 +3123,6 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -1624,5 +3133,6 @@\n-\/\/ vector sub\n-\n-instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (SubVB src1 src2));\n+instruct vtest_alltrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1630,1 +3140,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+  format %{ \"vtest_alltrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - alltrue\" %}\n@@ -1632,3 +3142,8 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n@@ -1639,3 +3154,6 @@\n-instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (SubVS src1 src2));\n+instruct vtest_anytrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1643,1 +3161,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  format %{ \"vtest_anytrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - anytrue\" %}\n@@ -1645,3 +3163,8 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -1652,9 +3175,30 @@\n-instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVI src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n-  ins_encode %{\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+\n+instruct insertB(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp, vReg tmp2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP tmp2, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp, B, 0, 1\\n\\t\"\n+            \"sve_dup $tmp2, B, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp, $tmp2\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\n\\t# insert into vector (B)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_index(as_FloatRegister($tmp$$reg), __ B, 0, 1);\n+    __ sve_dup(as_FloatRegister($tmp2$$reg), __ B, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($tmp$$reg), as_FloatRegister($tmp2$$reg));\n+    \/\/ If src and dst are the same reg, this move is not needed.\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src$$reg),\n+             as_FloatRegister($src$$reg));\n+    }\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+\n@@ -1665,9 +3209,28 @@\n-instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVL src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n-  ins_encode %{\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+instruct insertS(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp, vReg tmp2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP tmp2, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp, H, 0, 1\\n\\t\"\n+            \"sve_dup $tmp2, H, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp, $tmp2\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\n\\t# insert into vector (S)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_index(as_FloatRegister($tmp$$reg), __ H, 0, 1);\n+    __ sve_dup(as_FloatRegister($tmp2$$reg), __ H, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($tmp$$reg), as_FloatRegister($tmp2$$reg));\n+    \/\/ If src and dst are the same reg, this move is not needed.\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src$$reg),\n+             as_FloatRegister($src$$reg));\n+    }\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+\n@@ -1678,9 +3241,28 @@\n-instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVF src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n-  ins_encode %{\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+instruct insertI(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp, vReg tmp2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP tmp2, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp, S, 0, 1\\n\\t\"\n+            \"sve_dup $tmp2, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp, $tmp2\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\n\\t# insert into vector (I)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_index(as_FloatRegister($tmp$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($tmp2$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($tmp$$reg), as_FloatRegister($tmp2$$reg));\n+    \/\/ If src and dst are the same reg, this move is not needed.\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src$$reg),\n+             as_FloatRegister($src$$reg));\n+    }\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+\n@@ -1691,9 +3273,28 @@\n-instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVD src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n-  ins_encode %{\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+instruct insertL(vReg dst, vReg src, iRegL val, immI idx, vReg tmp, vReg tmp2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP tmp2, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp, D, 0, 1\\n\\t\"\n+            \"sve_dup $tmp2, D, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp, $tmp2\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\n\\t# insert into vector (L)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_index(as_FloatRegister($tmp$$reg), __ D, 0, 1);\n+    __ sve_dup(as_FloatRegister($tmp2$$reg), __ D, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($tmp$$reg), as_FloatRegister($tmp2$$reg));\n+    \/\/ If src and dst are the same reg, this move is not needed.\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src$$reg),\n+             as_FloatRegister($src$$reg));\n+    }\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":2083,"deletions":482,"binary":false,"changes":2565,"status":"modified"},{"patch":"@@ -35,0 +35,9 @@\n+define(`TYPE2DATATYPE',\n+`ifelse($1, `B', `BYTE',\n+        $1, `S', `SHORT',\n+        $1, `I', `INT',\n+        $1, `L', `LONG',\n+        $1, `F', `FLOAT',\n+        $1, `D', `DOUBLE',\n+        `error($1)')')dnl\n+dnl\n@@ -89,0 +98,24 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n@@ -114,2 +147,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n+  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                   PRegister pg, BasicType mem_elem_bt,\n+                                   Assembler::SIMD_RegVariant vector_elem_size,\n@@ -118,2 +152,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int esize = type2aelembytes(mem_elem_bt);\n@@ -125,1 +158,0 @@\n-        type = Assembler::B;\n@@ -129,1 +161,0 @@\n-        type = Assembler::H;\n@@ -133,1 +164,0 @@\n-        type = Assembler::S;\n@@ -137,1 +167,0 @@\n-        type = Assembler::D;\n@@ -143,1 +172,1 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      (masm.*insn)(reg, vector_elem_size, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n@@ -150,0 +179,30 @@\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n@@ -159,7 +218,0 @@\n-      case Op_Extract:\n-      case Op_ExtractB:\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -169,5 +221,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n@@ -176,14 +223,0 @@\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadMask:\n-      case Op_VectorMaskCmp:\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n@@ -217,1 +250,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -219,1 +252,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -225,0 +259,1 @@\n+    BasicType bt = vector_element_basic_type(this);\n@@ -226,1 +261,1 @@\n-                         vector_element_basic_type(this), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n@@ -233,1 +268,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -239,0 +275,1 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n@@ -240,1 +277,51 @@\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n+                         bt, elemType_to_regVariant(bt), $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, iRegINoSp tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_LoadVector()->memory_size() != MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, $tmp\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp$$reg), vector_length(this));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   zr, as_Register($tmp$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, iRegINoSp tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= MaxVectorSize \/ 8 &&\n+            n->as_StoreVector()->memory_size() != MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"mov $tmp, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, $tmp\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(as_Register($tmp$$reg), vector_length(this, $src));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size,\n+                   zr, as_Register($tmp$$reg));\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n+                         as_PRegister($pTmp$$reg), bt, size, $mem->opcode(),\n@@ -244,0 +331,16 @@\n+%}dnl\n+\n+\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->as_Vector()->length_in_bytes() ==\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \" # reinterpret $dst\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n@@ -246,0 +349,23 @@\n+instruct reinterpretResize(vReg dst, vReg src, iRegINoSp tmp, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->as_Vector()->length_in_bytes() !=\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, TEMP tmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \" # reinterpretResize $dst,$src\\t\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                            length_in_bytes_src : length_in_bytes_dst;\n+    __ mov(as_Register($tmp$$reg), length_in_bytes_resize);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), __ B,\n+                   zr, as_Register($tmp$$reg));\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -566,1 +692,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -571,0 +697,255 @@\n+%}\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ load\/store mask vector\n+\n+instruct vloadmask_loadV(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16 &&\n+            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    Assembler::SIMD_RegVariant to_vect_size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_size, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask(vmemA mem, vReg src, vReg tmp, immI size) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= 2 &&\n+            n->as_StoreVector()->vect_type()->element_basic_type() == T_BOOLEAN);\n+  match(Set mem (StoreVector mem (VectorStoreMask src size)));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant from_vect_size =\n+              elemBytes_to_regVariant((int)$size$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_size, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_size, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n@@ -634,1 +1015,1 @@\n-REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE,  sxtb)\n+REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n@@ -640,0 +1021,196 @@\n+dnl\n+dnl REDUCE_AND_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # and reduction $5\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_AND($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # and reduction $5\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector and reduction\n+REDUCE_AND_EXT(reduce_andB, AndReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_AND_EXT(reduce_andS, AndReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_AND(reduce_andI, AndReductionV, iRegINoSp, iRegIorL2I, S, T_INT, andw)\n+REDUCE_AND(reduce_andL, AndReductionV, iRegLNoSp, iRegL, D, T_LONG, andr)\n+dnl\n+dnl REDUCE_OR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_OR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector or reduction\n+REDUCE_OR_EXT(reduce_orB, OrReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_OR_EXT(reduce_orS, OrReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_OR(reduce_orI, OrReductionV, iRegINoSp, iRegIorL2I, S, T_INT, orrw)\n+REDUCE_OR(reduce_orL, OrReductionV, iRegLNoSp, iRegL, D, T_LONG, orr)\n+dnl\n+dnl REDUCE_XOR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_XOR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector xor reduction\n+REDUCE_XOR_EXT(reduce_eorB, XorReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_XOR_EXT(reduce_eorS, XorReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_XOR(reduce_eorI, XorReductionV, iRegINoSp, iRegIorL2I, S, T_INT, eorw)\n+REDUCE_XOR(reduce_eorL, XorReductionV, iRegLNoSp, iRegL, D, T_LONG, eor)\n+dnl\n+dnl REDUCE_MAXMIN_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7,  $8     )\n+dnl REDUCE_MAXMIN_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, cmp, min_max)\n+define(`REDUCE_MAXMIN_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_s$8v $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 $7\\t# $8 reduction $5\" %}\n+  ins_encode %{\n+    __ sve_s$8v(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$7);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN($1,        $2,      $3,      $4,      $5,   $6,        $7,    $8,    $9 , $10    )\n+dnl REDUCE_MAXMIN(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1, insn2, cmp, min_max)\n+define(`REDUCE_MAXMIN', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_s$10v $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $src1\\n\\t\"\n+            \"$8 $dst, $dst, $src1 $9\\t# $10 reduction $5\" %}\n+  ins_encode %{\n+    __ sve_s$10v(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $src1$$Register);\n+    __ $8(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$9);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n@@ -651,1 +1228,1 @@\n-  format %{ \"sve_f$1v $dst, $src2 # vector (sve) (S)\\n\\t\"\n+  format %{ \"sve_f$1v $dst, $src2 # vector (sve) ($4)\\n\\t\"\n@@ -661,0 +1238,4 @@\n+REDUCE_MAXMIN_EXT(reduce_maxB, MaxReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, GT, max)\n+REDUCE_MAXMIN_EXT(reduce_maxS, MaxReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, GT, max)\n+REDUCE_MAXMIN(reduce_maxI, MaxReductionV, iRegINoSp, iRegIorL2I, S, T_INT, cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxL, MaxReductionV, iRegLNoSp, iRegL, D, T_LONG, cmp, csel, GT, max)\n@@ -665,0 +1246,4 @@\n+REDUCE_MAXMIN_EXT(reduce_minB, MinReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, LT, min)\n+REDUCE_MAXMIN_EXT(reduce_minS, MinReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, LT, min)\n+REDUCE_MAXMIN(reduce_minI, MinReductionV, iRegINoSp, iRegIorL2I, S, T_INT, cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minL, MinReductionV, iRegLNoSp, iRegL, D, T_LONG, cmp, csel, LT, min)\n@@ -856,0 +1441,479 @@\n+\n+\/\/ ------------------------------ Vector cast -------------------------------\n+dnl\n+define(`VECTOR_CAST_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4\n+VECTOR_CAST_EXTEND1(B, S, sunpklo, H)\n+VECTOR_CAST_EXTEND1(S, I, sunpklo, S)\n+VECTOR_CAST_EXTEND1(I, L, sunpklo, D)\n+\n+dnl\n+define(`VECTOR_CAST_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4 $5\n+VECTOR_CAST_EXTEND2(B, I, sunpklo, H, S)\n+VECTOR_CAST_EXTEND2(S, L, sunpklo, S, D)\n+\n+dnl\n+define(`VECTOR_CAST_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+\t    n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4 $5 $6\n+VECTOR_CAST_EXTEND3(B, L, sunpklo, H, S, D)\n+\n+dnl\n+define(`VECTOR_CAST_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5\n+VECTOR_CAST_NARROW1(S, B, dup, B, uzp1)\n+VECTOR_CAST_NARROW1(I, S, dup, H, uzp1)\n+VECTOR_CAST_NARROW1(L, I, dup, S, uzp1)\n+\n+dnl\n+define(`VECTOR_CAST_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5    $6\n+VECTOR_CAST_NARROW2(I, B, dup, H, uzp1, B)\n+VECTOR_CAST_NARROW2(L, S, dup, S, uzp1, H)\n+\n+dnl\n+define(`VECTOR_CAST_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$5  $dst, $7, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5    $6 $7\n+VECTOR_CAST_NARROW3(L, B, dup, S, uzp1, H, B)\n+\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$6  $dst, $5, $dst, $5\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$6(as_FloatRegister($dst$$reg), __ $5, ptrue, as_FloatRegister($dst$$reg), __ $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5 $6\n+VECTOR_CAST_I2F_EXTEND2(B, F, sunpklo, H, S, scvtf)\n+VECTOR_CAST_I2F_EXTEND2(S, D, sunpklo, S, D, scvtf)\n+\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5 $6 $7\n+VECTOR_CAST_I2F_EXTEND3(B, D, sunpklo, H, S, D, scvtf)\n+\n+dnl\n+define(`VECTOR_CAST_X2F_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $5\\n\\t\"\n+            \"sve_$6  $tmp, $7, 0\\n\\t\"\n+            \"sve_$8  $dst, $7, $dst, $tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $5);\n+    __ sve_$6(as_FloatRegister($tmp$$reg), __ $7, 0);\n+    __ sve_$8(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3     $4 $5 $6   $7 $8\n+VECTOR_CAST_X2F_NARROW1(L, F, scvtf, S, D, dup, S, uzp1)\n+VECTOR_CAST_X2F_NARROW1(D, F, fcvt,  S, D, dup, S, uzp1)\n+\n+dnl\n+define(`VECTOR_CAST_X2X', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl             $1 $2 $3      $4\n+VECTOR_CAST_X2X(I, F, scvtf,  S)\n+VECTOR_CAST_X2X(L, D, scvtf,  D)\n+VECTOR_CAST_X2X(F, I, fcvtzs, S)\n+VECTOR_CAST_X2X(D, L, fcvtzs, D)\n+\n+dnl\n+define(`VECTOR_CAST_X2F_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$5  $dst, $4, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5     $6\n+VECTOR_CAST_X2F_EXTEND1(I, D, sunpklo, D, scvtf, D)\n+VECTOR_CAST_X2F_EXTEND1(S, F, sunpklo, S, scvtf, S)\n+VECTOR_CAST_X2F_EXTEND1(F, D, sunpklo, D, fcvt,  S)\n+\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7\n+VECTOR_CAST_F2X_NARROW1(F, S, fcvtzs, S, dup, H, uzp1)\n+VECTOR_CAST_F2X_NARROW1(D, I, fcvtzs, D, dup, S, uzp1)\n+\n+\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7    $8\n+VECTOR_CAST_F2X_NARROW2(F, B, fcvtzs, S, dup, H, uzp1, B)\n+VECTOR_CAST_F2X_NARROW2(D, S, fcvtzs, D, dup, S, uzp1, H)\n+\n+\n+dnl\n+define(`VECTOR_CAST_F2X_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5       $6\n+VECTOR_CAST_F2X_EXTEND1(F, L, fcvtzs, S, sunpklo, D)\n+\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length_in_bytes() >= 8 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $9, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $9, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7    $8 $9\n+VECTOR_CAST_F2X_NARROW3(D, B, fcvtzs, D, dup, S, uzp1, H, B)\n+\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+define(`VECTOR_EXTRACT_SXT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, $3, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, $3, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, $5\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ $3, zr, rscratch1);\n+    __ sve_lastb(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_$4($dst$$reg), as_$4($dst$$reg), 0U, $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                $1 $2         $3 $4        $5\n+VECTOR_EXTRACT_SXT(B, iRegINoSp, B, Register, 7U)\n+VECTOR_EXTRACT_SXT(S, iRegINoSp, H, Register, 15U)\n+\n+dnl\n+define(`VECTOR_EXTRACT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, $3, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, $3, $pTmp, $src\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ $3, zr, rscratch1);\n+    __ sve_lastb(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl            $1 $2         $3 $4\n+VECTOR_EXTRACT(I, iRegINoSp, S, Register)\n+VECTOR_EXTRACT(L, iRegLNoSp, D, Register)\n+VECTOR_EXTRACT(F, vRegF,     S, FloatRegister)\n+VECTOR_EXTRACT(D, vRegD,     D, FloatRegister)\n+\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+dnl\n+dnl VTEST($1,      $2,   $3,  $4  )\n+dnl VTEST(op_name, pred, imm, cond)\n+define(`VTEST', `\n+instruct vtest_$1`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, $3\\n\\t\"\n+            \"csetw $dst, $4\\t# VectorTest (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST(alltrue, overflow, 0, EQ)\n+VTEST(anytrue, ne,      -1, NE)\n+dnl\n+dnl\n+dnl VTEST_PARTIAL($1,      $2,   $3,  $4  )\n+dnl VTEST_PARTIAL(op_name, pred, imm, cond)\n+define(`VTEST_PARTIAL', `\n+instruct vtest_$1_partial`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vtest_$1_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST_PARTIAL(alltrue, overflow, 0, EQ)\n+VTEST_PARTIAL(anytrue, ne,      -1, NE)\n+\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+define(`VECTOR_INSERT', `\n+instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, vReg tmp, vReg tmp2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP tmp2, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp, $3, 0, 1\\n\\t\"\n+            \"sve_dup $tmp2, $3, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp, $tmp2\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\n\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_index(as_FloatRegister($tmp$$reg), __ $3, 0, 1);\n+    __ sve_dup(as_FloatRegister($tmp2$$reg), __ $3, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($tmp$$reg), as_FloatRegister($tmp2$$reg));\n+    \/\/ If src and dst are the same reg, this move is not needed.\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src$$reg),\n+             as_FloatRegister($src$$reg));\n+    }\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl           $1 $2          $3 $4\n+VECTOR_INSERT(B, iRegIorL2I, B, Register)\n+VECTOR_INSERT(S, iRegIorL2I, H, Register)\n+VECTOR_INSERT(I, iRegIorL2I, S, Register)\n+VECTOR_INSERT(L, iRegL,      D, Register)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":1107,"deletions":43,"binary":false,"changes":1150,"status":"modified"},{"patch":"@@ -3211,1 +3211,1 @@\n-  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm8) {\n+  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm16) {\n@@ -3215,1 +3215,2 @@\n-    if (imm8 <= 127 && imm8 >= -128) {\n+    unsigned imm = imm16;\n+    if (imm16 <= 127 && imm16 >= -128) {\n@@ -3217,1 +3218,1 @@\n-    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n+    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n@@ -3219,1 +3220,1 @@\n-      imm8 = (imm8 >> 8);\n+      imm = (imm >> 8);\n@@ -3223,0 +3224,2 @@\n+    unsigned mask = (1U << 8) - 1;\n+    imm &= mask;\n@@ -3224,1 +3227,1 @@\n-    f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n+    f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n@@ -3233,0 +3236,312 @@\n+   \/\/ SVE cpy immediate\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm16, bool isMerge) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    int sh = 0;\n+    unsigned imm = imm16;\n+    if (imm16 <= 127 && imm16 >= -128) {\n+      sh = 0;\n+    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n+      sh = 1;\n+      imm = (imm >> 8);\n+    } else {\n+      guarantee(false, \"invalid immediate\");\n+    }\n+    unsigned mask = (1U << 8) - 1;\n+    imm &= mask;\n+    int m = isMerge ? 1 : 0;\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b01, 21, 20);\n+    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE vector sel\n+  void sve_sel(FloatRegister Zd,\n+               SIMD_RegVariant T,\n+               PRegister Pg,\n+               FloatRegister Zn,\n+               FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b11, 15, 14), prf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE compare vector\n+#define INSN(NAME, op, cond, fp)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, FloatRegister Zm)  { \\\n+    starti;                                                                                       \\\n+    if (fp == 0) {                                                                                \\\n+      assert(T != Q, \"invalid size\");                                                             \\\n+    } else {                                                                                      \\\n+      assert(T != B && T != Q, \"invalid size\");                                                   \\\n+    }                                                                                             \\\n+    f(op, 31, 24), f(T, 23, 22), f(0b0, 21), rf(Zm, 16), f((cond >> 1) & 0x7, 15, 13);            \\\n+    pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0);                                        \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b00100100, 0b1010, 0);\n+  INSN(sve_cmpne, 0b00100100, 0b1011, 0);\n+  INSN(sve_cmpge, 0b00100100, 0b1000, 0);\n+  INSN(sve_cmpgt, 0b00100100, 0b1001, 0);\n+  INSN(sve_fcmeq, 0b01100101, 0b0110, 1);\n+  INSN(sve_fcmne, 0b01100101, 0b0111, 1);\n+  INSN(sve_fcmgt, 0b01100101, 0b0101, 1);\n+  INSN(sve_fcmge, 0b01100101, 0b0100, 1);\n+#undef INSN\n+\n+\/\/ SVE compare vector with immediate\n+#define INSN(NAME, cond)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, int imm5) { \\\n+    starti;                                                                              \\\n+    assert(T != Q, \"invalid size\");                                                      \\\n+    if (imm5 > 15 || imm5 < -16) {                                                       \\\n+      guarantee(false, \"invalid immediate\");                                             \\\n+    }                                                                                    \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(0b0, 21), sf(imm5, 20, 16),                   \\\n+    f((cond >> 1) & 0x7, 15, 13), pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0); \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b1000);\n+  INSN(sve_cmpne, 0b1001);\n+  INSN(sve_cmpgt, 0b0001);\n+  INSN(sve_cmpge, 0b0000);\n+  INSN(sve_cmplt, 0b0010);\n+  INSN(sve_cmple, 0b0011);\n+#undef INSN\n+\n+\/\/ SVE unpack and extend\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn) { \\\n+    starti;                                                          \\\n+    assert(T != B && T != Q, \"invalid size\");                        \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1100, 21, 18);          \\\n+    f(op, 17, 16), f(0b001110, 15, 10), rf(Zn, 5), rf(Zd, 0);        \\\n+  }\n+\n+  INSN(sve_uunpkhi, 0b11);\n+  INSN(sve_uunpklo, 0b10);\n+  INSN(sve_sunpkhi, 0b01);\n+  INSN(sve_sunpklo, 0b00);\n+#undef INSN\n+\n+\/\/ SVE vector uzp1,uzp2\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) { \\\n+    starti;                                                                            \\\n+    assert(T != Q, \"invalid size\");                                                    \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);                       \\\n+    f(0b01101, 15, 11), f(op, 10), rf(Zn, 5), rf(Zd, 0);                               \\\n+  }\n+\n+  INSN(sve_uzp1, 0b0);\n+  INSN(sve_uzp2, 0b1);\n+#undef INSN\n+\n+\/\/ SVE while[cond]\n+#define INSN(NAME, decode, sf)                                            \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, Register Rn, Register Rm) {  \\\n+    starti;                                                               \\\n+    assert(T != Q, \"invalid register variant\");                           \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(1, 21),                        \\\n+    zrf(Rm, 16), f(0, 15, 13), f(sf, 12), f(decode >> 1, 11, 10),         \\\n+    zrf(Rn, 5), f(decode & 0b1, 4), prf(Pd, 0);                           \\\n+  }\n+\n+  INSN(sve_whilelt,  0b010, 1);\n+  INSN(sve_whileltw, 0b010, 0);\n+  INSN(sve_whilele,  0b011, 1);\n+  INSN(sve_whilelew, 0b011, 0);\n+  INSN(sve_whilelo,  0b110, 1);\n+  INSN(sve_whilelow, 0b110, 0);\n+  INSN(sve_whilels,  0b111, 1);\n+  INSN(sve_whilelsw, 0b111, 0);\n+#undef INSN\n+\n+private:\n+\n+  void encode_cvtf_T(SIMD_RegVariant T_dst, SIMD_RegVariant T_src,\n+                     unsigned& opc, unsigned& opc2) {\n+    assert(T_src != B && T_dst != B &&\n+           T_src != Q && T_dst != Q, \"invalid register variant\");\n+    if (T_dst != D) {\n+      assert(T_dst <= T_src, \"invalid register variant\");\n+    } else {\n+      assert(T_src != H, \"invalid register variant\");\n+    }\n+    \/\/ In most cases we can treat T_dst,T_src as opc,opc2\n+    \/\/ except following four cases. These cases should be converted\n+    \/\/ according to Arm's architecture reference manual:\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ | opc | opc2 | U |        Instruction Details         |\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ |  11 |   00 | 0 | SCVTF — 32-bit to double-precision |\n+    \/\/ |  11 |   00 | 1 | UCVTF — 32-bit to double-precision |\n+    \/\/ |  11 |   10 | 0 | SCVTF — 64-bit to single-precision |\n+    \/\/ |  11 |   10 | 1 | UCVTF — 64-bit to single-precision |\n+    \/\/ +-----+------+---+------------------------------------+\n+    if (T_dst == S && T_src == D) { \/\/ 64-bit to single-precision\n+      T_dst = D;\n+      T_src = S;\n+    } else if (T_dst == D && T_src == S) { \/\/ 32-bit to double-precision\n+      T_dst = D;\n+      T_src = B;\n+    }\n+    opc = T_dst;\n+    opc2 = T_src;\n+  }\n+public:\n+\n+\/\/ SVE convert integer to floating-point (predicated)\n+#define INSN(NAME, sign)                                                \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,      \\\n+            FloatRegister Zn, SIMD_RegVariant T_src) {                  \\\n+    starti;                                                             \\\n+    unsigned opc, opc2;                                                 \\\n+    encode_cvtf_T(T_dst, T_src, opc, opc2);                             \\\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b010, 21, 19);            \\\n+    f(opc2, 18, 17), f(sign, 16), f(0b101, 15, 13);                     \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);                                 \\\n+  }\n+\n+  INSN(sve_scvtf, 0b0);\n+  INSN(sve_ucvtf, 0b1);\n+#undef INSN\n+\n+private:\n+\n+  void encode_fcvt_T(SIMD_RegVariant T_src,SIMD_RegVariant T_dst,\n+                     unsigned& opc, unsigned& opc2) {\n+    assert(T_src != B && T_dst != B &&\n+           T_src != Q && T_dst != Q, \"invalid register variant\");\n+    assert(T_src != T_dst, \"invalid register variant\");\n+    if (T_src == S) {\n+      if (T_dst == H) {\n+        opc = 0b10;\n+        opc2 = 0b00;\n+      } else if (T_dst == D) {\n+        opc = 0b11;\n+        opc2 = 0b11;\n+      }\n+    } else if (T_src == H) {\n+      if (T_dst == S) {\n+        opc = 0b10;\n+        opc2 = 0b01;\n+      } else if (T_dst == D) {\n+        opc = 0b11;\n+        opc2 = 0b01;\n+      }\n+    } else if (T_src == D) {\n+      if (T_dst == H) {\n+        opc = 0b11;\n+        opc2 = 0b00;\n+      } else if (T_dst == S) {\n+        opc = 0b11;\n+        opc2 = 0b10;\n+      }\n+    }\n+  }\n+public:\n+\n+\/\/ SVE floating-point convert precision (predicated)\n+  void sve_fcvt(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+            FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    unsigned opc, opc2;\n+    encode_fcvt_T(T_src, T_dst, opc, opc2);\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b0010, 21, 18);\n+    f(opc2, 17, 16), f(0b101, 15, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+private:\n+\n+  void encode_fcvtz_T (SIMD_RegVariant T_dst, SIMD_RegVariant T_src,\n+                       unsigned& opc, unsigned& opc2) {\n+    assert(T_src != B && T_dst != B &&\n+           T_src != Q && T_dst != Q, \"invalid register variant\");\n+    if (T_src != D) {\n+      assert(T_src <= T_dst, \"invalid register variant\");\n+    } else {\n+      assert(T_dst != H, \"invalid register variant\");\n+    }\n+    \/\/ In most cases we can treat T_dst,T_src as opc2,opc\n+    \/\/ except following four cases. These cases should be converted\n+    \/\/ according to Arm's architecture reference manual:\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ | opc | opc2 | U |        Instruction Details          |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ |  11 |   10 | 0 | FCVTZS — Single-precision to 64-bit |\n+    \/\/ |  11 |   10 | 1 | FCVTZU — Single-precision to 64-bit |\n+    \/\/ |  11 |   00 | 0 | FCVTZS — Double-precision to 32-bit |\n+    \/\/ |  11 |   00 | 1 | FCVTZU — Double-precision to 32-bit |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    if (T_dst == D && T_src == S) { \/\/ Single-precision to 64-bit\n+      T_dst = S;\n+      T_src = D;\n+    } else if (T_dst == S && T_src == D) { \/\/ Double-precision to 32-bit\n+      T_dst = B;\n+      T_src = D;\n+    }\n+    opc = T_src;\n+    opc2 = T_dst;\n+  }\n+public:\n+\n+\/\/ SVE floating-point convert to integer (predicated)\n+#define INSN(NAME, sign)                                                \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,      \\\n+            FloatRegister Zn, SIMD_RegVariant T_src) {                  \\\n+    starti;                                                             \\\n+    unsigned opc, opc2;                                                 \\\n+    encode_fcvtz_T(T_dst, T_src, opc, opc2);                            \\\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b011, 21, 19);            \\\n+    f(opc2, 18, 17), f(sign, 16), f(0b101, 15, 13);                     \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);                                 \\\n+  }\n+\n+  INSN(sve_fcvtzs, 0b0);\n+  INSN(sve_fcvtzu, 0b1);\n+#undef INSN\n+\n+\/\/ SVE conditionally extract element to general-purpose register\n+#define INSN(NAME, before)                                                      \\\n+  void NAME(Register Rd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                     \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10000, 21, 17);                    \\\n+    f(before, 16), f(0b101, 15, 13);                                            \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Rd, 0);                                         \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+#define INSN(NAME, before)                                                           \\\n+  void NAME(FloatRegister Vd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                          \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10001, 21, 17);                         \\\n+    f(before, 16), f(0b100, 15, 13);                                                 \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Vd, 0);                                              \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+\/\/ SVE cpy general-purpose register\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, Register Rn) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b101000101, 21, 13);\n+    pgrf(Pg, 10), srf(Rn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE INDEX (immediates)\n+  void sve_index(FloatRegister Zd, SIMD_RegVariant T,\n+                 int imm1, int imm2) {\n+    starti;\n+    f(0b00000100, 31, 24), f(T, 23, 22), f(0b1, 21);\n+    f(imm2, 20, 16), f(0b010000, 15, 10);\n+    f(imm1, 9, 5), rf(Zd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":320,"deletions":5,"binary":false,"changes":325,"status":"modified"},{"patch":"@@ -866,0 +866,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1008,0 +1008,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -357,0 +357,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2171,0 +2171,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -919,0 +919,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1561,0 +1561,14 @@\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -854,0 +854,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1041,0 +1041,8 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(!Matcher::supports_vector_calling_convention(), \"not implemented\");\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1165,0 +1165,25 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(num_bits == 64 || num_bits == 128 || num_bits == 256 || num_bits == 512,\n+         \"only certain vector sizes are supported for now\");\n+\n+  static const XMMRegister VEC_ArgReg[32] = {\n+     xmm0,  xmm1,  xmm2,  xmm3,  xmm4,  xmm5,  xmm6,  xmm7,\n+     xmm8,  xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15,\n+    xmm16, xmm17, xmm18, xmm19, xmm20, xmm21, xmm22, xmm23,\n+    xmm24, xmm25, xmm26, xmm27, xmm28, xmm29, xmm30, xmm31\n+  };\n+\n+  uint stk_args = 0;\n+  uint fp_args = 0;\n+\n+  for (uint i = 0; i < total_args_passed; i++) {\n+    VMReg vmreg = VEC_ArgReg[fp_args++]->as_VMReg();\n+    int next_val = num_bits == 64 ? 1 : (num_bits == 128 ? 3 : (num_bits  == 256 ? 7 : 15));\n+    regs[i].set_pair(vmreg->next(next_val), vmreg);\n+  }\n+\n+  return stk_args;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -1689,0 +1689,5 @@\n+    case Op_CallLeafVector:\n+      if (size_in_bits == 512 && !VM_Version::supports_avx512vlbwdq()) {\n+        return false;\n+      }\n+      break;\n@@ -1956,0 +1961,4 @@\n+  \/\/ Support for calling svml double64 vectors\n+  if (bt == T_DOUBLE) {\n+    size = 1;\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1401,0 +1401,14 @@\n+\/\/ Vector calling convention not supported.\n+const bool Matcher::supports_vector_calling_convention() {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -466,1 +466,3 @@\n-  offset += clear_avx_size();\n+  if (this->ideal_Opcode() != Op_CallLeafVector) {\n+    offset += clear_avx_size();\n+  }\n@@ -1695,0 +1697,17 @@\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return true;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  int lo = XMM0_num;\n+  int hi = XMM0b_num;\n+  if (ideal_reg == Op_VecX) hi = XMM0d_num;\n+  else if (ideal_reg == Op_VecY) hi = XMM0h_num;\n+  else if (ideal_reg == Op_VecZ) hi = XMM0p_num;\n+  return OptoRegPair(hi, lo);\n+}\n+\n@@ -12906,0 +12925,12 @@\n+\/\/ Call runtime without safepoint and with vector arguments\n+instruct CallLeafDirectVector(method meth)\n+%{\n+  match(CallLeafVector);\n+  effect(USE meth);\n+\n+  ins_cost(300);\n+  format %{ \"call_leaf,vector \" %}\n+  ins_encode(Java_To_Runtime(meth));\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":32,"deletions":1,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -129,0 +129,7 @@\n+\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  ShouldNotCallThis();\n+  return 0;\n+}\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -422,0 +422,2 @@\n+  if(_matrule->find_type(\"CallLeafVector\",idx))   return Form::JAVA_LEAF;\n+  idx = 0;\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -467,0 +467,3 @@\n+    if (EnableVectorSupport && FLAG_IS_DEFAULT(UseVectorStubs)) {\n+      FLAG_SET_DEFAULT(UseVectorStubs, true);\n+    }\n@@ -470,0 +473,1 @@\n+    log_info(compilation)(\"UseVectorStubs=%s\",                 (UseVectorStubs                 ? \"true\" : \"false\"));\n","filename":"src\/hotspot\/share\/classfile\/modules.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -739,3 +739,5 @@\n-    OptoRegPair regs = is_CallRuntime()\n-      ? match->c_return_value(ideal_reg)  \/\/ Calls into C runtime\n-      : match->  return_value(ideal_reg); \/\/ Calls into compiled Java code\n+    OptoRegPair regs = Opcode() == Op_CallLeafVector\n+      ? match->vector_return_value(ideal_reg)      \/\/ Calls into assembly vector routine\n+      : is_CallRuntime()\n+        ? match->c_return_value(ideal_reg)  \/\/ Calls into C runtime\n+        : match->  return_value(ideal_reg); \/\/ Calls into compiled Java code\n@@ -743,0 +745,10 @@\n+\n+    \/\/ If the return is in vector, compute appropriate regmask taking into account the whole range\n+    if(ideal_reg >= Op_VecS && ideal_reg <= Op_VecZ) {\n+      if(OptoReg::is_valid(regs.second())) {\n+        for (OptoReg::Name r = regs.first(); r <= regs.second(); r = OptoReg::add(r, 1)) {\n+          rm.Insert(r);\n+        }\n+      }\n+    }\n+\n@@ -1198,0 +1210,5 @@\n+uint CallLeafVectorNode::size_of() const { return sizeof(*this); }\n+bool CallLeafVectorNode::cmp( const Node &n ) const {\n+  CallLeafVectorNode &call = (CallLeafVectorNode&)n;\n+  return CallLeafNode::cmp(call) && _num_bits == call._num_bits;\n+}\n@@ -1269,0 +1286,15 @@\n+void CallLeafVectorNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {\n+#ifdef ASSERT\n+  assert(tf()->range()->field_at(TypeFunc::Parms)->is_vect()->length_in_bytes() * BitsPerByte == _num_bits,\n+         \"return vector size must match\");\n+  const TypeTuple* d = tf()->domain();\n+  for (uint i = TypeFunc::Parms; i < d->cnt(); i++) {\n+    Node* arg = in(i);\n+    assert(arg->bottom_type()->is_vect()->length_in_bytes() * BitsPerByte == _num_bits,\n+           \"vector argument size must match\");\n+  }\n+#endif\n+\n+  Matcher::vector_calling_convention(parm_regs, _num_bits, argcnt);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":35,"deletions":3,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+class         CallLeafVectorNode;\n@@ -782,0 +783,1 @@\n+protected:\n@@ -869,0 +871,18 @@\n+\/\/------------------------------CallLeafVectorNode-------------------------------\n+\/\/ CallLeafNode but calling with vector calling convention instead.\n+class CallLeafVectorNode : public CallLeafNode {\n+private:\n+  uint _num_bits;\n+protected:\n+  virtual bool cmp( const Node &n ) const;\n+  virtual uint size_of() const; \/\/ Size is bigger\n+public:\n+  CallLeafVectorNode(const TypeFunc* tf, address addr, const char* name,\n+                   const TypePtr* adr_type, uint num_bits)\n+    : CallLeafNode(tf, addr, name, adr_type), _num_bits(num_bits)\n+  {\n+  }\n+  virtual int   Opcode() const;\n+  virtual void  calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2195,1 +2195,2 @@\n-    for_igvn()->clear();\n+    Unique_Node_List* old_worklist = for_igvn();\n+    old_worklist->clear();\n@@ -2205,1 +2206,1 @@\n-    set_for_igvn(save_for_igvn);\n+    set_for_igvn(old_worklist); \/\/ new_worklist is dead beyond this point\n@@ -3038,0 +3039,1 @@\n+  case Op_CallLeafVector:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1027,0 +1027,1 @@\n+    case Op_CallLeafVector:\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2507,0 +2507,3 @@\n+  } else  if (flags & RC_VECTOR){\n+    uint num_bits = call_type->range()->field_at(TypeFunc::Parms)->is_vect()->length_in_bytes() * BitsPerByte;\n+    call = new CallLeafVectorNode(call_type, call_addr, call_name, adr_type, num_bits);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -327,0 +327,1 @@\n+  Node* gen_call_to_svml(int vector_api_op_id, BasicType bt, int num_elem, Node* opd1, Node* opd2);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1381,2 +1381,4 @@\n-      if( !parm_regs[i].first()->is_valid() &&\n-          !parm_regs[i].second()->is_valid() ) {\n+      VMReg first = parm_regs[i].first();\n+      VMReg second = parm_regs[i].second();\n+      if( !first->is_valid() &&\n+          !second->is_valid() ) {\n@@ -1385,0 +1387,9 @@\n+      \/\/ Handle case where arguments are in vector registers.\n+      if(call->in(TypeFunc::Parms + i)->bottom_type()->isa_vect()) {\n+        OptoReg::Name reg_fst = OptoReg::as_OptoReg(first);\n+        OptoReg::Name reg_snd = OptoReg::as_OptoReg(second);\n+        assert (reg_fst <= reg_snd, \"fst=%d snd=%d\", reg_fst, reg_snd);\n+        for (OptoReg::Name r = reg_fst; r <= reg_snd; r++) {\n+          rm->Insert(r);\n+        }\n+      }\n@@ -1386,1 +1397,1 @@\n-      OptoReg::Name reg1 = warp_outgoing_stk_arg(parm_regs[i].first(), begin_out_arg_area, out_arg_limit_per_call );\n+      OptoReg::Name reg1 = warp_outgoing_stk_arg(first, begin_out_arg_area, out_arg_limit_per_call );\n@@ -1390,1 +1401,1 @@\n-      OptoReg::Name reg2 = warp_outgoing_stk_arg(parm_regs[i].second(), begin_out_arg_area, out_arg_limit_per_call );\n+      OptoReg::Name reg2 = warp_outgoing_stk_arg(second, begin_out_arg_area, out_arg_limit_per_call );\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -431,0 +431,7 @@\n+  \/\/ Java-Native vector calling convention\n+  static const bool supports_vector_calling_convention();\n+  static void vector_calling_convention(VMRegPair *regs,\n+                                        uint num_bits,\n+                                        uint total_args_passed);\n+  static OptoRegPair vector_return_value(uint ideal_reg);\n+\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -667,0 +667,19 @@\n+const TypeFunc *OptoRuntime::Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type) {\n+  \/\/ create input type (domain)\n+  const Type **fields = TypeTuple::fields(num_arg);\n+  \/\/ Symbol* name of class to be loaded\n+  assert(num_arg > 0, \"must have at least 1 input\");\n+  for (uint i = 0; i < num_arg; i++) {\n+    fields[TypeFunc::Parms+i] = in_type;\n+  }\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+num_arg, fields);\n+\n+  \/\/ create result type (range)\n+  const uint num_ret = 1;\n+  fields = TypeTuple::fields(num_ret);\n+  fields[TypeFunc::Parms+0] = out_type;\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+num_ret, fields);\n+\n+  return TypeFunc::make(domain, range);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1137,0 +1137,1 @@\n+    assert((BoolTest::mask)predicate_node->get_int() == predicate, \"Unmatched predicates\");\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -365,0 +365,19 @@\n+    case VECTOR_OP_TAN:\n+    case VECTOR_OP_TANH:\n+    case VECTOR_OP_SIN:\n+    case VECTOR_OP_SINH:\n+    case VECTOR_OP_COS:\n+    case VECTOR_OP_COSH:\n+    case VECTOR_OP_ASIN:\n+    case VECTOR_OP_ACOS:\n+    case VECTOR_OP_ATAN:\n+    case VECTOR_OP_ATAN2:\n+    case VECTOR_OP_CBRT:\n+    case VECTOR_OP_LOG:\n+    case VECTOR_OP_LOG10:\n+    case VECTOR_OP_LOG1P:\n+    case VECTOR_OP_POW:\n+    case VECTOR_OP_EXP:\n+    case VECTOR_OP_EXPM1:\n+    case VECTOR_OP_HYPOT:\n+      return Op_CallLeafVector;\n","filename":"src\/hotspot\/share\/prims\/vectorSupport.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -4084,0 +4084,5 @@\n+\n+    if (!FLAG_IS_DEFAULT(UseVectorStubs) && UseVectorStubs) {\n+      warning(\"Disabling UseVectorStubs since EnableVectorSupport is turned off.\");\n+    }\n+    FLAG_SET_DEFAULT(UseVectorStubs, false);\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -391,0 +391,4 @@\n+  static int vector_calling_convention(VMRegPair *regs,\n+                                       uint num_bits,\n+                                       uint total_args_passed);\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -185,0 +185,147 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+address StubRoutines::_vector_exp_float64                = NULL;\n+address StubRoutines::_vector_exp_float128               = NULL;\n+address StubRoutines::_vector_exp_float256               = NULL;\n+address StubRoutines::_vector_exp_float512               = NULL;\n+address StubRoutines::_vector_exp_double64               = NULL;\n+address StubRoutines::_vector_exp_double128              = NULL;\n+address StubRoutines::_vector_exp_double256              = NULL;\n+address StubRoutines::_vector_exp_double512              = NULL;\n+address StubRoutines::_vector_expm1_float64              = NULL;\n+address StubRoutines::_vector_expm1_float128             = NULL;\n+address StubRoutines::_vector_expm1_float256             = NULL;\n+address StubRoutines::_vector_expm1_float512             = NULL;\n+address StubRoutines::_vector_expm1_double64             = NULL;\n+address StubRoutines::_vector_expm1_double128            = NULL;\n+address StubRoutines::_vector_expm1_double256            = NULL;\n+address StubRoutines::_vector_expm1_double512            = NULL;\n+address StubRoutines::_vector_log1p_float64              = NULL;\n+address StubRoutines::_vector_log1p_float128             = NULL;\n+address StubRoutines::_vector_log1p_float256             = NULL;\n+address StubRoutines::_vector_log1p_float512             = NULL;\n+address StubRoutines::_vector_log1p_double64             = NULL;\n+address StubRoutines::_vector_log1p_double128            = NULL;\n+address StubRoutines::_vector_log1p_double256            = NULL;\n+address StubRoutines::_vector_log1p_double512            = NULL;\n+address StubRoutines::_vector_log_float64                = NULL;\n+address StubRoutines::_vector_log_float128               = NULL;\n+address StubRoutines::_vector_log_float256               = NULL;\n+address StubRoutines::_vector_log_float512               = NULL;\n+address StubRoutines::_vector_log_double64               = NULL;\n+address StubRoutines::_vector_log_double128              = NULL;\n+address StubRoutines::_vector_log_double256              = NULL;\n+address StubRoutines::_vector_log_double512              = NULL;\n+address StubRoutines::_vector_log10_float64              = NULL;\n+address StubRoutines::_vector_log10_float128             = NULL;\n+address StubRoutines::_vector_log10_float256             = NULL;\n+address StubRoutines::_vector_log10_float512             = NULL;\n+address StubRoutines::_vector_log10_double64             = NULL;\n+address StubRoutines::_vector_log10_double128            = NULL;\n+address StubRoutines::_vector_log10_double256            = NULL;\n+address StubRoutines::_vector_log10_double512            = NULL;\n+address StubRoutines::_vector_sin_float64                = NULL;\n+address StubRoutines::_vector_sin_float128               = NULL;\n+address StubRoutines::_vector_sin_float256               = NULL;\n+address StubRoutines::_vector_sin_float512               = NULL;\n+address StubRoutines::_vector_sin_double64               = NULL;\n+address StubRoutines::_vector_sin_double128              = NULL;\n+address StubRoutines::_vector_sin_double256              = NULL;\n+address StubRoutines::_vector_sin_double512              = NULL;\n+address StubRoutines::_vector_cos_float64                = NULL;\n+address StubRoutines::_vector_cos_float128               = NULL;\n+address StubRoutines::_vector_cos_float256               = NULL;\n+address StubRoutines::_vector_cos_float512               = NULL;\n+address StubRoutines::_vector_cos_double64               = NULL;\n+address StubRoutines::_vector_cos_double128              = NULL;\n+address StubRoutines::_vector_cos_double256              = NULL;\n+address StubRoutines::_vector_cos_double512              = NULL;\n+address StubRoutines::_vector_tan_float64                = NULL;\n+address StubRoutines::_vector_tan_float128               = NULL;\n+address StubRoutines::_vector_tan_float256               = NULL;\n+address StubRoutines::_vector_tan_float512               = NULL;\n+address StubRoutines::_vector_tan_double64               = NULL;\n+address StubRoutines::_vector_tan_double128              = NULL;\n+address StubRoutines::_vector_tan_double256              = NULL;\n+address StubRoutines::_vector_tan_double512              = NULL;\n+address StubRoutines::_vector_sinh_float64               = NULL;\n+address StubRoutines::_vector_sinh_float128               = NULL;\n+address StubRoutines::_vector_sinh_float256               = NULL;\n+address StubRoutines::_vector_sinh_float512               = NULL;\n+address StubRoutines::_vector_sinh_double64               = NULL;\n+address StubRoutines::_vector_sinh_double128              = NULL;\n+address StubRoutines::_vector_sinh_double256              = NULL;\n+address StubRoutines::_vector_sinh_double512              = NULL;\n+address StubRoutines::_vector_cosh_float64                = NULL;\n+address StubRoutines::_vector_cosh_float128               = NULL;\n+address StubRoutines::_vector_cosh_float256               = NULL;\n+address StubRoutines::_vector_cosh_float512               = NULL;\n+address StubRoutines::_vector_cosh_double64               = NULL;\n+address StubRoutines::_vector_cosh_double128              = NULL;\n+address StubRoutines::_vector_cosh_double256              = NULL;\n+address StubRoutines::_vector_cosh_double512              = NULL;\n+address StubRoutines::_vector_tanh_float64                = NULL;\n+address StubRoutines::_vector_tanh_float128               = NULL;\n+address StubRoutines::_vector_tanh_float256               = NULL;\n+address StubRoutines::_vector_tanh_float512               = NULL;\n+address StubRoutines::_vector_tanh_double64               = NULL;\n+address StubRoutines::_vector_tanh_double128              = NULL;\n+address StubRoutines::_vector_tanh_double256              = NULL;\n+address StubRoutines::_vector_tanh_double512              = NULL;\n+address StubRoutines::_vector_acos_float64                = NULL;\n+address StubRoutines::_vector_acos_float128               = NULL;\n+address StubRoutines::_vector_acos_float256               = NULL;\n+address StubRoutines::_vector_acos_float512               = NULL;\n+address StubRoutines::_vector_acos_double64               = NULL;\n+address StubRoutines::_vector_acos_double128              = NULL;\n+address StubRoutines::_vector_acos_double256              = NULL;\n+address StubRoutines::_vector_acos_double512              = NULL;\n+address StubRoutines::_vector_asin_float64                = NULL;\n+address StubRoutines::_vector_asin_float128               = NULL;\n+address StubRoutines::_vector_asin_float256               = NULL;\n+address StubRoutines::_vector_asin_float512               = NULL;\n+address StubRoutines::_vector_asin_double64               = NULL;\n+address StubRoutines::_vector_asin_double128              = NULL;\n+address StubRoutines::_vector_asin_double256              = NULL;\n+address StubRoutines::_vector_asin_double512              = NULL;\n+address StubRoutines::_vector_atan_float64                = NULL;\n+address StubRoutines::_vector_atan_float128               = NULL;\n+address StubRoutines::_vector_atan_float256               = NULL;\n+address StubRoutines::_vector_atan_float512               = NULL;\n+address StubRoutines::_vector_atan_double64               = NULL;\n+address StubRoutines::_vector_atan_double128              = NULL;\n+address StubRoutines::_vector_atan_double256              = NULL;\n+address StubRoutines::_vector_atan_double512              = NULL;\n+address StubRoutines::_vector_pow_float64                 = NULL;\n+address StubRoutines::_vector_pow_float128                = NULL;\n+address StubRoutines::_vector_pow_float256                = NULL;\n+address StubRoutines::_vector_pow_float512                = NULL;\n+address StubRoutines::_vector_pow_double64                = NULL;\n+address StubRoutines::_vector_pow_double128               = NULL;\n+address StubRoutines::_vector_pow_double256               = NULL;\n+address StubRoutines::_vector_pow_double512               = NULL;\n+address StubRoutines::_vector_hypot_float64               = NULL;\n+address StubRoutines::_vector_hypot_float128              = NULL;\n+address StubRoutines::_vector_hypot_float256              = NULL;\n+address StubRoutines::_vector_hypot_float512              = NULL;\n+address StubRoutines::_vector_hypot_double64              = NULL;\n+address StubRoutines::_vector_hypot_double128             = NULL;\n+address StubRoutines::_vector_hypot_double256             = NULL;\n+address StubRoutines::_vector_hypot_double512             = NULL;\n+address StubRoutines::_vector_cbrt_float64                = NULL;\n+address StubRoutines::_vector_cbrt_float128               = NULL;\n+address StubRoutines::_vector_cbrt_float256               = NULL;\n+address StubRoutines::_vector_cbrt_float512               = NULL;\n+address StubRoutines::_vector_cbrt_double64               = NULL;\n+address StubRoutines::_vector_cbrt_double128              = NULL;\n+address StubRoutines::_vector_cbrt_double256              = NULL;\n+address StubRoutines::_vector_cbrt_double512              = NULL;\n+address StubRoutines::_vector_atan2_float64               = NULL;\n+address StubRoutines::_vector_atan2_float128              = NULL;\n+address StubRoutines::_vector_atan2_float256              = NULL;\n+address StubRoutines::_vector_atan2_float512              = NULL;\n+address StubRoutines::_vector_atan2_double64              = NULL;\n+address StubRoutines::_vector_atan2_double128             = NULL;\n+address StubRoutines::_vector_atan2_double256             = NULL;\n+address StubRoutines::_vector_atan2_double512             = NULL;\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n+\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":147,"deletions":0,"binary":false,"changes":147,"status":"modified"},{"patch":"@@ -1530,0 +1530,1 @@\n+  declare_c2_type(CallLeafVectorNode, CallLeafNode)                       \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"utilities\/globalDefinitions_vecApi.hpp\"\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1514,33 +1514,90 @@\n-                        [\"cpy\",    \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n-                        [\"inc\",    \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n-                        [\"dec\",    \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n-                        [\"lsl\",    \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n-                        [\"lsr\",    \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n-                        [\"lsr\",    \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n-                        [\"addvl\",  \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n-                        [\"addpl\",  \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n-                        [\"cntp\",   \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n-                        [\"dup\",    \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n-                        [\"dup\",    \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n-                        [\"dup\",    \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n-                        [\"dup\",    \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n-                        [\"ld1h\",   \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n-                        [\"ld1d\",   \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n-                        [\"st1w\",   \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n-                        [\"st1h\",   \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n-                        [\"st1d\",   \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n-                        [\"str\",    \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n+                        [\"cpy\",     \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n+                        [\"cpy\",     \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n+                        [\"cpy\",     \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n+                        [\"cpy\",     \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n+                        [\"inc\",     \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n+                        [\"dec\",     \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n+                        [\"lsl\",     \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n+                        [\"lsr\",     \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n+                        [\"addvl\",   \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n+                        [\"addpl\",   \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n+                        [\"cntp\",    \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n+                        [\"dup\",     \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n+                        [\"dup\",     \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n+                        [\"dup\",     \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n+                        [\"dup\",     \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n+                        [\"dup\",     \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n+                        [\"dup\",     \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n+                        [\"ld1h\",    \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n+                        [\"st1w\",    \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n+                        [\"st1h\",    \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n+                        [\"st1d\",    \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n+                        [\"str\",     \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"sel\",     \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n+                        [\"sel\",     \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p0, z0, z1);\",                \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, z3);\",                \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p2, z4, z5);\",                \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ D, p3, z6, z7);\",                \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmple\",   \"__ sve_cmpge(p2, __ B, p0, z10, z11);\",              \"cmple\\tp2.b, p0\/z, z11.b, z10.b\"],\n+                        [\"cmplt\",   \"__ sve_cmpgt(p3, __ S, p0, z16, z17);\",              \"cmplt\\tp3.s, p0\/z, z17.s, z16.s\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p4, z0, 15);\",                \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, -16);\",               \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n+                        [\"cmple\",   \"__ sve_cmple(p1, __ S, p1, z4, 0);\",                 \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n+                        [\"cmplt\",   \"__ sve_cmplt(p1, __ D, p2, z6, -1);\",                \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p3, z4, 5);\",                 \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ B, p4, z6, -2);\",                \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n+                        [\"fcmeq\",   \"__ sve_fcmeq(p1, __ S, p0, z0, z1);\",                \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n+                        [\"fcmne\",   \"__ sve_fcmne(p1, __ D, p0, z2, z3);\",                \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n+                        [\"fcmgt\",   \"__ sve_fcmgt(p1, __ S, p2, z4, z5);\",                \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"fcmge\",   \"__ sve_fcmge(p1, __ D, p3, z6, z7);\",                \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"fcmlt\",   \"__ sve_fcmgt(p2, __ S, p0, z10, z11);\",              \"fcmlt\\tp2.s, p0\/z, z11.s, z10.s\"],\n+                        [\"fcmle\",   \"__ sve_fcmge(p3, __ D, p0, z16, z17);\",              \"fcmle\\tp3.d, p0\/z, z17.d, z16.d\"],\n+                        [\"uunpkhi\", \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n+                        [\"uunpklo\", \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n+                        [\"sunpkhi\", \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n+                        [\"sunpklo\", \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n+                        [\"whilelt\", \"__ sve_whilelt(p0, __ B, r1, r2);\",                  \"whilelt\\tp0.b, x1, x2\"],\n+                        [\"whilelt\", \"__ sve_whileltw(p1, __ H, r3, r4);\",                 \"whilelt\\tp1.h, w3, w4\"],\n+                        [\"whilele\", \"__ sve_whilele(p2, __ S, r5, r6);\",                  \"whilele\\tp2.s, x5, x6\"],\n+                        [\"whilele\", \"__ sve_whilelew(p3, __ D, r10, r11);\",               \"whilele\\tp3.d, w10, w11\"],\n+                        [\"whilelo\", \"__ sve_whilelo(p4, __ B, r1, r2);\",                  \"whilelo\\tp4.b, x1, x2\"],\n+                        [\"whilelo\", \"__ sve_whilelow(p0, __ H, r3, r4);\",                 \"whilelo\\tp0.h, w3, w4\"],\n+                        [\"whilels\", \"__ sve_whilels(p1, __ S, r5, r6);\",                  \"whilels\\tp1.s, x5, x6\"],\n+                        [\"whilels\", \"__ sve_whilelsw(p2, __ D, r10, r11);\",               \"whilels\\tp2.d, w10, w11\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z1, __ D, p0, z0, __ S);\",              \"scvtf\\tz1.d, p0\/m, z0.s\"],\n+                        [\"ucvtf\",   \"__ sve_ucvtf(z3, __ D, p1, z2, __ S);\",              \"ucvtf\\tz3.d, p1\/m, z2.s\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z5, __ D, p3, z4, __ S);\",               \"fcvt\\tz5.d, p3\/m, z4.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z18, __ D);\",           \"fcvtzs\\tz19.d, p2\/m, z18.d\"],\n+                        [\"fcvtzu\",  \"__ sve_fcvtzu(z19, __ D, p2, z18, __ D);\",           \"fcvtzu\\tz19.d, p2\/m, z18.d\"],\n+                        [\"lasta\",   \"__ sve_lasta(r0, __ B, p0, z15);\",                   \"lasta\\tw0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(r1, __ B, p1, z16);\",                   \"lastb\\tw1, p1, z16.b\"],\n+                        [\"lasta\",   \"__ sve_lasta(v0, __ B, p0, z15);\",                   \"lasta\\tb0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(v1, __ B, p1, z16);\",                   \"lastb\\tb1, p1, z16.b\"],\n+                        [\"index\",   \"__ sve_index(z6, __ S, 1, 1);\",                      \"index\\tz6.s, #1, #1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z7, __ H, p3, r5);\",                      \"cpy\\tz7.h, p3\/m, w5\"],\n@@ -1615,0 +1672,2 @@\n+                       [\"uzp1\", \"ZZZ\"],\n+                       [\"uzp2\", \"ZZZ\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":92,"deletions":33,"binary":false,"changes":125,"status":"modified"},{"patch":"@@ -702,0 +702,6 @@\n+    __ sve_cpy(z0, __ B, p0, 127, true);               \/\/       mov     z0.b, p0\/m, 127\n+    __ sve_cpy(z1, __ H, p0, -128, true);              \/\/       mov     z1.h, p0\/m, -128\n+    __ sve_cpy(z2, __ S, p0, 32512, true);             \/\/       mov     z2.s, p0\/m, 32512\n+    __ sve_cpy(z5, __ D, p0, -32768, false);           \/\/       mov     z5.d, p0\/z, -32768\n+    __ sve_cpy(z10, __ B, p0, -1, false);              \/\/       mov     z10.b, p0\/z, -1\n+    __ sve_cpy(z11, __ S, p0, -1, false);              \/\/       mov     z11.s, p0\/z, -1\n@@ -719,0 +725,2 @@\n+    __ sve_dup(z10, __ B, -1);                         \/\/       dup     z10.b, -1\n+    __ sve_dup(z11, __ S, -1);                         \/\/       dup     z11.s, -1\n@@ -720,0 +728,3 @@\n+    __ sve_ld1b(z0, __ H, p1, Address(sp));            \/\/       ld1b    {z0.h}, p1\/z, [sp]\n+    __ sve_ld1b(z0, __ S, p2, Address(sp, r8));        \/\/       ld1b    {z0.s}, p2\/z, [sp, x8]\n+    __ sve_ld1b(z0, __ D, p3, Address(sp, 7));         \/\/       ld1b    {z0.d}, p3\/z, [sp, #7, MUL VL]\n@@ -727,0 +738,3 @@\n+    __ sve_st1b(z0, __ H, p1, Address(sp));            \/\/       st1b    {z0.h}, p1, [sp]\n+    __ sve_st1b(z0, __ S, p2, Address(sp, r8));        \/\/       st1b    {z0.s}, p2, [sp, x8]\n+    __ sve_st1b(z0, __ D, p3, Address(sp));            \/\/       st1b    {z0.d}, p3, [sp]\n@@ -734,0 +748,43 @@\n+    __ sve_sel(z0, __ B, p0, z1, z2);                  \/\/       sel     z0.b, p0, z1.b, z2.b\n+    __ sve_sel(z4, __ D, p0, z5, z6);                  \/\/       sel     z4.d, p0, z5.d, z6.d\n+    __ sve_cmpeq(p1, __ B, p0, z0, z1);                \/\/       cmpeq   p1.b, p0\/z, z0.b, z1.b\n+    __ sve_cmpne(p1, __ H, p0, z2, z3);                \/\/       cmpne   p1.h, p0\/z, z2.h, z3.h\n+    __ sve_cmpge(p1, __ S, p2, z4, z5);                \/\/       cmpge   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_cmpgt(p1, __ D, p3, z6, z7);                \/\/       cmpgt   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_cmpge(p2, __ B, p0, z10, z11);              \/\/       cmple   p2.b, p0\/z, z11.b, z10.b\n+    __ sve_cmpgt(p3, __ S, p0, z16, z17);              \/\/       cmplt   p3.s, p0\/z, z17.s, z16.s\n+    __ sve_cmpeq(p1, __ B, p4, z0, 15);                \/\/       cmpeq   p1.b, p4\/z, z0.b, #15\n+    __ sve_cmpne(p1, __ H, p0, z2, -16);               \/\/       cmpne   p1.h, p0\/z, z2.h, #-16\n+    __ sve_cmple(p1, __ S, p1, z4, 0);                 \/\/       cmple   p1.s, p1\/z, z4.s, #0\n+    __ sve_cmplt(p1, __ D, p2, z6, -1);                \/\/       cmplt   p1.d, p2\/z, z6.d, #-1\n+    __ sve_cmpge(p1, __ S, p3, z4, 5);                 \/\/       cmpge   p1.s, p3\/z, z4.s, #5\n+    __ sve_cmpgt(p1, __ B, p4, z6, -2);                \/\/       cmpgt   p1.b, p4\/z, z6.b, #-2\n+    __ sve_fcmeq(p1, __ S, p0, z0, z1);                \/\/       fcmeq   p1.s, p0\/z, z0.s, z1.s\n+    __ sve_fcmne(p1, __ D, p0, z2, z3);                \/\/       fcmne   p1.d, p0\/z, z2.d, z3.d\n+    __ sve_fcmgt(p1, __ S, p2, z4, z5);                \/\/       fcmgt   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_fcmge(p1, __ D, p3, z6, z7);                \/\/       fcmge   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_fcmgt(p2, __ S, p0, z10, z11);              \/\/       fcmlt   p2.s, p0\/z, z11.s, z10.s\n+    __ sve_fcmge(p3, __ D, p0, z16, z17);              \/\/       fcmle   p3.d, p0\/z, z17.d, z16.d\n+    __ sve_uunpkhi(z0, __ H, z1);                      \/\/       uunpkhi z0.h, z1.b\n+    __ sve_uunpklo(z4, __ S, z5);                      \/\/       uunpklo z4.s, z5.h\n+    __ sve_sunpkhi(z6, __ D, z7);                      \/\/       sunpkhi z6.d, z7.s\n+    __ sve_sunpklo(z10, __ H, z11);                    \/\/       sunpklo z10.h, z11.b\n+    __ sve_whilelt(p0, __ B, r1, r2);                  \/\/       whilelt p0.b, x1, x2\n+    __ sve_whileltw(p1, __ H, r3, r4);                 \/\/       whilelt p1.h, w3, w4\n+    __ sve_whilele(p2, __ S, r5, r6);                  \/\/       whilele p2.s, x5, x6\n+    __ sve_whilelew(p3, __ D, r10, r11);               \/\/       whilele p3.d, w10, w11\n+    __ sve_whilelo(p4, __ B, r1, r2);                  \/\/       whilelo p4.b, x1, x2\n+    __ sve_whilelow(p0, __ H, r3, r4);                 \/\/       whilelo p0.h, w3, w4\n+    __ sve_whilels(p1, __ S, r5, r6);                  \/\/       whilels p1.s, x5, x6\n+    __ sve_whilelsw(p2, __ D, r10, r11);               \/\/       whilels p2.d, w10, w11\n+    __ sve_scvtf(z1, __ D, p0, z0, __ S);              \/\/       scvtf   z1.d, p0\/m, z0.s\n+    __ sve_ucvtf(z3, __ D, p1, z2, __ S);              \/\/       ucvtf   z3.d, p1\/m, z2.s\n+    __ sve_fcvt(z5, __ D, p3, z4, __ S);               \/\/       fcvt    z5.d, p3\/m, z4.s\n+    __ sve_fcvtzs(z19, __ D, p2, z18, __ D);           \/\/       fcvtzs  z19.d, p2\/m, z18.d\n+    __ sve_fcvtzu(z19, __ D, p2, z18, __ D);           \/\/       fcvtzu  z19.d, p2\/m, z18.d\n+    __ sve_lasta(r0, __ B, p0, z15);                   \/\/       lasta   w0, p0, z15.b\n+    __ sve_lastb(r1, __ B, p1, z16);                   \/\/       lastb   w1, p1, z16.b\n+    __ sve_lasta(v0, __ B, p0, z15);                   \/\/       lasta   b0, p0, z15.b\n+    __ sve_lastb(v1, __ B, p1, z16);                   \/\/       lastb   b1, p1, z16.b\n+    __ sve_index(z6, __ S, 1, 1);                      \/\/       index   z6.s, #1, #1\n+    __ sve_cpy(z7, __ H, p3, r5);                      \/\/       cpy     z7.h, p3\/m, w5\n@@ -870,0 +927,53 @@\n+<<<<<<< HEAD\n+    __ sve_add(z26, __ D, z6, z9);                     \/\/       add     z26.d, z6.d, z9.d\n+    __ sve_sub(z17, __ B, z7, z4);                     \/\/       sub     z17.b, z7.b, z4.b\n+    __ sve_fadd(z15, __ S, z9, z22);                   \/\/       fadd    z15.s, z9.s, z22.s\n+    __ sve_fmul(z2, __ D, z27, z20);                   \/\/       fmul    z2.d, z27.d, z20.d\n+    __ sve_fsub(z5, __ D, z26, z0);                    \/\/       fsub    z5.d, z26.d, z0.d\n+    __ sve_abs(z14, __ H, p1, z25);                    \/\/       abs     z14.h, p1\/m, z25.h\n+    __ sve_add(z27, __ D, p5, z26);                    \/\/       add     z27.d, p5\/m, z27.d, z26.d\n+    __ sve_asr(z24, __ B, p5, z0);                     \/\/       asr     z24.b, p5\/m, z24.b, z0.b\n+    __ sve_cnt(z6, __ B, p4, z0);                      \/\/       cnt     z6.b, p4\/m, z0.b\n+    __ sve_lsl(z15, __ B, p0, z9);                     \/\/       lsl     z15.b, p0\/m, z15.b, z9.b\n+    __ sve_lsr(z5, __ B, p2, z27);                     \/\/       lsr     z5.b, p2\/m, z5.b, z27.b\n+    __ sve_mul(z20, __ B, p5, z20);                    \/\/       mul     z20.b, p5\/m, z20.b, z20.b\n+    __ sve_neg(z10, __ D, p2, z16);                    \/\/       neg     z10.d, p2\/m, z16.d\n+    __ sve_not(z6, __ H, p4, z2);                      \/\/       not     z6.h, p4\/m, z2.h\n+    __ sve_smax(z29, __ D, p7, z2);                    \/\/       smax    z29.d, p7\/m, z29.d, z2.d\n+    __ sve_smin(z22, __ H, p7, z14);                   \/\/       smin    z22.h, p7\/m, z22.h, z14.h\n+    __ sve_sub(z27, __ B, p4, z23);                    \/\/       sub     z27.b, p4\/m, z27.b, z23.b\n+    __ sve_fabs(z2, __ D, p3, z10);                    \/\/       fabs    z2.d, p3\/m, z10.d\n+    __ sve_fadd(z10, __ S, p6, z22);                   \/\/       fadd    z10.s, p6\/m, z10.s, z22.s\n+    __ sve_fdiv(z3, __ S, p5, z16);                    \/\/       fdiv    z3.s, p5\/m, z3.s, z16.s\n+    __ sve_fmax(z1, __ D, p4, z16);                    \/\/       fmax    z1.d, p4\/m, z1.d, z16.d\n+    __ sve_fmin(z12, __ S, p3, z12);                   \/\/       fmin    z12.s, p3\/m, z12.s, z12.s\n+    __ sve_fmul(z16, __ D, p0, z20);                   \/\/       fmul    z16.d, p0\/m, z16.d, z20.d\n+    __ sve_fneg(z5, __ D, p1, z7);                     \/\/       fneg    z5.d, p1\/m, z7.d\n+    __ sve_frintm(z12, __ D, p7, z16);                 \/\/       frintm  z12.d, p7\/m, z16.d\n+    __ sve_frintn(z6, __ S, p0, z28);                  \/\/       frintn  z6.s, p0\/m, z28.s\n+    __ sve_frintp(z4, __ D, p1, z17);                  \/\/       frintp  z4.d, p1\/m, z17.d\n+    __ sve_fsqrt(z13, __ S, p3, z19);                  \/\/       fsqrt   z13.s, p3\/m, z19.s\n+    __ sve_fsub(z24, __ S, p5, z17);                   \/\/       fsub    z24.s, p5\/m, z24.s, z17.s\n+    __ sve_fmla(z10, __ D, p6, z6, z19);               \/\/       fmla    z10.d, p6\/m, z6.d, z19.d\n+    __ sve_fmls(z13, __ S, p4, z6, z0);                \/\/       fmls    z13.s, p4\/m, z6.s, z0.s\n+    __ sve_fnmla(z14, __ S, p4, z25, z8);              \/\/       fnmla   z14.s, p4\/m, z25.s, z8.s\n+    __ sve_fnmls(z22, __ S, p5, z22, z27);             \/\/       fnmls   z22.s, p5\/m, z22.s, z27.s\n+    __ sve_mla(z3, __ B, p3, z17, z20);                \/\/       mla     z3.b, p3\/m, z17.b, z20.b\n+    __ sve_mls(z4, __ H, p7, z7, z0);                  \/\/       mls     z4.h, p7\/m, z7.h, z0.h\n+    __ sve_and(z16, z19, z22);                         \/\/       and     z16.d, z19.d, z22.d\n+    __ sve_eor(z15, z9, z22);                          \/\/       eor     z15.d, z9.d, z22.d\n+    __ sve_orr(z25, z5, z30);                          \/\/       orr     z25.d, z5.d, z30.d\n+    __ sve_uzp1(z13, __ B, z22, z11);                  \/\/       uzp1    z13.b, z22.b, z11.b\n+    __ sve_uzp2(z13, __ S, z8, z20);                   \/\/       uzp2    z13.s, z8.s, z20.s\n+\n+\/\/ SVEReductionOp\n+    __ sve_andv(v25, __ B, p3, z4);                    \/\/       andv b25, p3, z4.b\n+    __ sve_orv(v17, __ D, p2, z6);                     \/\/       orv d17, p2, z6.d\n+    __ sve_eorv(v4, __ D, p7, z16);                    \/\/       eorv d4, p7, z16.d\n+    __ sve_smaxv(v26, __ B, p2, z14);                  \/\/       smaxv b26, p2, z14.b\n+    __ sve_sminv(v11, __ B, p7, z3);                   \/\/       sminv b11, p7, z3.b\n+    __ sve_fminv(v1, __ D, p6, z21);                   \/\/       fminv d1, p6, z21.d\n+    __ sve_fmaxv(v14, __ D, p2, z17);                  \/\/       fmaxv d14, p2, z17.d\n+    __ sve_fadda(v24, __ D, p1, z19);                  \/\/       fadda d24, p1, d24, z19.d\n+    __ sve_uaddv(v17, __ D, p5, z16);                  \/\/       uaddv d17, p5, z16.d\n+=======\n@@ -919,0 +1029,1 @@\n+>>>>>>> master\n@@ -937,0 +1048,9 @@\n+<<<<<<< HEAD\n+    0x14000000,     0x17ffffd7,     0x14000316,     0x94000000,\n+    0x97ffffd4,     0x94000313,     0x3400000a,     0x34fffa2a,\n+    0x3400620a,     0x35000008,     0x35fff9c8,     0x350061a8,\n+    0xb400000b,     0xb4fff96b,     0xb400614b,     0xb500001d,\n+    0xb5fff91d,     0xb50060fd,     0x10000013,     0x10fff8b3,\n+    0x10006093,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36306016,     0x3758000c,     0x375ff7cc,     0x37585fac,\n+=======\n@@ -944,0 +1064,1 @@\n+>>>>>>> master\n@@ -948,0 +1069,15 @@\n+<<<<<<< HEAD\n+    0x54005d80,     0x54000001,     0x54fff541,     0x54005d21,\n+    0x54000002,     0x54fff4e2,     0x54005cc2,     0x54000002,\n+    0x54fff482,     0x54005c62,     0x54000003,     0x54fff423,\n+    0x54005c03,     0x54000003,     0x54fff3c3,     0x54005ba3,\n+    0x54000004,     0x54fff364,     0x54005b44,     0x54000005,\n+    0x54fff305,     0x54005ae5,     0x54000006,     0x54fff2a6,\n+    0x54005a86,     0x54000007,     0x54fff247,     0x54005a27,\n+    0x54000008,     0x54fff1e8,     0x540059c8,     0x54000009,\n+    0x54fff189,     0x54005969,     0x5400000a,     0x54fff12a,\n+    0x5400590a,     0x5400000b,     0x54fff0cb,     0x540058ab,\n+    0x5400000c,     0x54fff06c,     0x5400584c,     0x5400000d,\n+    0x54fff00d,     0x540057ed,     0x5400000e,     0x54ffefae,\n+    0x5400578e,     0x5400000f,     0x54ffef4f,     0x5400572f,\n+=======\n@@ -961,0 +1097,1 @@\n+>>>>>>> master\n@@ -992,0 +1129,3 @@\n+<<<<<<< HEAD\n+    0xbd1b1869,     0x5800477b,     0x1800000b,     0xf8945060,\n+=======\n@@ -993,0 +1133,1 @@\n+>>>>>>> master\n@@ -1034,0 +1175,63 @@\n+<<<<<<< HEAD\n+    0x0e31ab38,     0x4e31ab17,     0x0e71a8a4,     0x4e71aa93,\n+    0x4eb1aa0f,     0x6eb0f820,     0x7e30f8a4,     0x7e70fab4,\n+    0x7eb0f98b,     0x7ef0fbdd,     0x0e20ba0f,     0x4e20bad5,\n+    0x0e60b8a4,     0x4e60b9ee,     0x0ea0baf6,     0x4ea0bb59,\n+    0x4ee0b8e6,     0x0ea0f9ac,     0x4ea0f9ee,     0x4ee0f9cd,\n+    0x2ea0f9ee,     0x6ea0f949,     0x6ee0fb59,     0x2ea1fbbc,\n+    0x6ea1f96a,     0x6ee1fa93,     0x2e20598b,     0x6e205a51,\n+    0x0e371ed5,     0x4e311e0f,     0x0eb61eb4,     0x4eb91f17,\n+    0x2e3c1f7a,     0x6e271cc5,     0x0e2884e6,     0x4e31860f,\n+    0x0e71860f,     0x4e7b8759,     0x0eb28630,     0x4ebd879b,\n+    0x4efa8738,     0x0e31d60f,     0x4e3bd759,     0x4e70d5ee,\n+    0x2e2c856a,     0x6e2f85cd,     0x2e7085ee,     0x6e7686b4,\n+    0x2ea38441,     0x6eb886f6,     0x6ee087fe,     0x0eb0d5ee,\n+    0x4ea4d462,     0x4ee8d4e6,     0x0e259c83,     0x4e299d07,\n+    0x0e7a9f38,     0x4e629c20,     0x0ebd9f9b,     0x4ebf9fdd,\n+    0x2ea7d4c5,     0x6ea7d4c5,     0x6effd7dd,     0x2e2ddd8b,\n+    0x6e3bdf59,     0x6e62dc20,     0x0e6097fe,     0x4e629420,\n+    0x0eb39651,     0x4ebe97bc,     0x0e3bcf59,     0x4e2bcd49,\n+    0x4e7bcf59,     0x2e6e95ac,     0x6e71960f,     0x2ead958b,\n+    0x6eac956a,     0x0eb3ce51,     0x4ebacf38,     0x4ef7ced5,\n+    0x2e39ff17,     0x6e22fc20,     0x6e72fe30,     0x0e2c656a,\n+    0x4e2864e6,     0x0e7e67bc,     0x4e6864e6,     0x0ea764c5,\n+    0x4ea764c5,     0x0e36f6b4,     0x4e33f651,     0x4e71f60f,\n+    0x0e336e51,     0x4e3f6fdd,     0x0e7c6f7a,     0x4e7e6fbc,\n+    0x0ea36c41,     0x4ebd6f9b,     0x0ea2f420,     0x4eb6f6b4,\n+    0x4efef7bc,     0x2e318e0f,     0x6e2e8dac,     0x2e6c8d6a,\n+    0x6e7e8fbc,     0x2ebe8fbc,     0x6eb58e93,     0x6ef88ef6,\n+    0x0e2ce56a,     0x4e26e4a4,     0x4e60e7fe,     0x0e3636b4,\n+    0x4e2a3528,     0x0e6037fe,     0x4e733651,     0x0eac356a,\n+    0x4ebd379b,     0x4ee43462,     0x2ebae738,     0x6ea6e4a4,\n+    0x6ee5e483,     0x0e2a3d28,     0x4e383ef6,     0x0e733e51,\n+    0x4e6f3dcd,     0x0ea63ca4,     0x4ebe3fbc,     0x4ef93f17,\n+    0x2e37e6d5,     0x6e3be759,     0x6e7ae738,     0xba5fd3e3,\n+    0x3a5f03e5,     0xfa411be4,     0x7a42cbe2,     0x93df03ff,\n+    0xc820ffff,     0x8822fc7f,     0xc8247cbf,     0x88267fff,\n+    0x4e010fe0,     0x4e081fe1,     0x4e0c1fe1,     0x4e0a1fe1,\n+    0x4e071fe1,     0x4e042c20,     0x4e062c20,     0x4e052c20,\n+    0x4e083c20,     0x0e0c3c20,     0x0e0a3c20,     0x0e073c20,\n+    0x4cc0ac3f,     0x05a08020,     0x05104fe0,     0x05505001,\n+    0x05906fe2,     0x05d03005,     0x05101fea,     0x05901feb,\n+    0x04b0e3e0,     0x0470e7e1,     0x042f9c20,     0x043f9c35,\n+    0x047f9c20,     0x04ff9c20,     0x04299420,     0x04319160,\n+    0x0461943e,     0x04a19020,     0x042053ff,     0x047f5401,\n+    0x25208028,     0x2538cfe0,     0x2578d001,     0x25b8efe2,\n+    0x25f8f007,     0x2538dfea,     0x25b8dfeb,     0xa400a3e0,\n+    0xa420a7e0,     0xa4484be0,     0xa467afe0,     0xa4a8a7ea,\n+    0xa547a814,     0xa4084ffe,     0xa55c53e0,     0xa5e1540b,\n+    0xe400fbf6,     0xe408ffff,     0xe420e7e0,     0xe4484be0,\n+    0xe460efe0,     0xe547e400,     0xe4014be0,     0xe4a84fe0,\n+    0xe5f15000,     0x858043e0,     0x85a043ff,     0xe59f5d08,\n+    0x0522c020,     0x05e6c0a4,     0x2401a001,     0x2443a051,\n+    0x24858881,     0x24c78cd1,     0x240b8142,     0x24918213,\n+    0x250f9001,     0x25508051,     0x25802491,     0x25df28c1,\n+    0x25850c81,     0x251e10d1,     0x65816001,     0x65c36051,\n+    0x65854891,     0x65c74cc1,     0x658b4152,     0x65d14203,\n+    0x05733820,     0x05b238a4,     0x05f138e6,     0x0570396a,\n+    0x25221420,     0x25640461,     0x25a614b2,     0x25eb0553,\n+    0x25221c24,     0x25640c60,     0x25a61cb1,     0x25eb0d52,\n+    0x65d0a001,     0x65d1a443,     0x65cbac85,     0x65deaa53,\n+    0x65dfaa53,     0x0520a1e0,     0x0521a601,     0x052281e0,\n+    0x05238601,     0x04a14026,     0x0568aca7,     0x1e601000,\n+=======\n@@ -1082,0 +1286,1 @@\n+>>>>>>> master\n@@ -1089,0 +1294,36 @@\n+<<<<<<< HEAD\n+    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8238358,\n+    0xf83702af,     0xf8231118,     0xf8392214,     0xf8313022,\n+    0xf8205098,     0xf82343ec,     0xf83c734a,     0xf82261ec,\n+    0xf8bf81a1,     0xf8bd0260,     0xf8ac12d1,     0xf8ad23dc,\n+    0xf8bf3341,     0xf8bc53c4,     0xf8a443c6,     0xf8ba7130,\n+    0xf8a8600c,     0xf8f48301,     0xf8e20120,     0xf8f8121a,\n+    0xf8fe2143,     0xf8f7308a,     0xf8f05162,     0xf8e841ea,\n+    0xf8f17142,     0xf8ec61ec,     0xf86d80e2,     0xf874021a,\n+    0xf8641082,     0xf86c22b0,     0xf8703170,     0xf8755197,\n+    0xf87a4397,     0xf86e730b,     0xf86163ec,     0xb82a80f0,\n+    0xb82201a3,     0xb8331211,     0xb8232161,     0xb83e3105,\n+    0xb82f53dd,     0xb82040f4,     0xb8347397,     0xb835633b,\n+    0xb8a582e1,     0xb8b000bf,     0xb8ac1389,     0xb8af22dd,\n+    0xb8bf33f3,     0xb8a551ee,     0xb8bf4370,     0xb8b47190,\n+    0xb8ab60c9,     0xb8fe8371,     0xb8fc00fe,     0xb8ea1154,\n+    0xb8e42238,     0xb8f13076,     0xb8fd52cf,     0xb8f342d3,\n+    0xb8e270cf,     0xb8ec6170,     0xb86d8037,     0xb87e00b3,\n+    0xb8711202,     0xb876214d,     0xb875337d,     0xb86c507b,\n+    0xb861431f,     0xb8737131,     0xb87c61fb,     0xce367a86,\n+    0xce1e6858,     0xce768d51,     0xce910451,     0xce768338,\n+    0xce6c8622,     0xcec08363,     0xce708b9d,     0x04e900da,\n+    0x042404f1,     0x6596012f,     0x65d40b62,     0x65c00745,\n+    0x0456a72e,     0x04c0175b,     0x04109418,     0x041ab006,\n+    0x0413812f,     0x04118b65,     0x04101694,     0x04d7aa0a,\n+    0x045eb046,     0x04c81c5d,     0x044a1dd6,     0x040112fb,\n+    0x04dcad42,     0x65809aca,     0x658d9603,     0x65c69201,\n+    0x65878d8c,     0x65c28290,     0x04dda4e5,     0x65c2be0c,\n+    0x6580a386,     0x65c1a624,     0x658dae6d,     0x65819638,\n+    0x65f318ca,     0x65a030cd,     0x65a8532e,     0x65bb76d6,\n+    0x04144e23,     0x04407ce4,     0x04363270,     0x04b6312f,\n+    0x047e30b9,     0x052b6acd,     0x05b46d0d,     0x041a2c99,\n+    0x04d828d1,     0x04d93e04,     0x040829da,     0x040a3c6b,\n+    0x65c73aa1,     0x65c62a2e,     0x65d82678,     0x04c13611,\n+\n+=======\n@@ -1122,0 +1363,1 @@\n+>>>>>>> master\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":242,"deletions":0,"binary":false,"changes":242,"status":"modified"}]}