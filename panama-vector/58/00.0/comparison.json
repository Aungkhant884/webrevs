{"files":[{"patch":"@@ -128,0 +128,3 @@\n+    # The expected format for <version> is either nn.n.n or nn.nn.nn. See\n+    # \/Applications\/Xcode.app\/Contents\/Developer\/Platforms\/MacOSX.platform\/Developer\/SDKs\/MacOSX.sdk\/usr\/include\/AvailabilityVersions.h\n+\n@@ -133,1 +136,5 @@\n-    MACOSX_VERSION_MIN=10.12.0\n+    if test \"x$OPENJDK_TARGET_CPU_ARCH\" = xaarch64; then\n+      MACOSX_VERSION_MIN=11.00.00\n+    else\n+      MACOSX_VERSION_MIN=10.12.0\n+    fi\n@@ -139,2 +146,1 @@\n-    # link to macosx APIs that are newer than the given OS version. The expected\n-    # format for <version> is either nn.n.n or nn.nn.nn. See \/usr\/include\/AvailabilityMacros.h.\n+    # link to macosx APIs that are newer than the given OS version.\n@@ -262,0 +268,8 @@\n+  if test \"x$OPENJDK_TARGET_OS\" = xmacosx; then\n+    if test \"x$OPENJDK_TARGET_CPU\" = xaarch64; then\n+      MACHINE_FLAG=\"$MACHINE_FLAG -arch arm64\"\n+    elif test \"x$OPENJDK_TARGET_CPU\" = xx86_64; then\n+      MACHINE_FLAG=\"$MACHINE_FLAG -arch x86_64\"\n+    fi\n+  fi\n+\n","filename":"make\/autoconf\/flags.m4","additions":17,"deletions":3,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -352,0 +352,2 @@\n+ENABLE_COMPATIBLE_CDS_ALIGNMENT := @ENABLE_COMPATIBLE_CDS_ALIGNMENT@\n+\n@@ -576,0 +578,2 @@\n+METAL := @METAL@\n+METALLIB := @METALLIB@\n","filename":"make\/autoconf\/spec.gmk.in","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -731,0 +731,26 @@\n+\n+    UTIL_LOOKUP_TOOLCHAIN_PROGS(METAL, metal)\n+    if test \"x$METAL\" = x; then\n+      AC_MSG_CHECKING([if metal can be run using xcrun])\n+      METAL=\"xcrun -sdk macosx metal\"\n+      test_metal=`$METAL --version 2>&1`\n+      if test $? -ne 0; then\n+        AC_MSG_RESULT([no])\n+        AC_MSG_ERROR([XCode tool 'metal' neither found in path nor with xcrun])\n+      else\n+        AC_MSG_RESULT([yes, will be using '$METAL'])\n+      fi\n+    fi\n+\n+    UTIL_LOOKUP_TOOLCHAIN_PROGS(METALLIB, metallib)\n+    if test \"x$METALLIB\" = x; then\n+      AC_MSG_CHECKING([if metallib can be run using xcrun])\n+      METALLIB=\"xcrun -sdk macosx metallib\"\n+      test_metallib=`$METALLIB --version 2>&1`\n+      if test $? -ne 0; then\n+        AC_MSG_RESULT([no])\n+        AC_MSG_ERROR([XCode tool 'metallib' neither found in path nor with xcrun])\n+      else\n+        AC_MSG_RESULT([yes, will be using '$METALLIB'])\n+      fi\n+    fi\n","filename":"make\/autoconf\/toolchain.m4","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -1193,1 +1193,1 @@\n-\t\t  $(CODESIGN) -s \"$(MACOSX_CODESIGN_IDENTITY)\" --timestamp --options runtime \\\n+\t\t  $(CODESIGN) -f -s \"$(MACOSX_CODESIGN_IDENTITY)\" --timestamp --options runtime \\\n","filename":"make\/common\/NativeCompilation.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -470,16 +470,16 @@\n-  reg_def P0 (SOC, SOC, Op_RegVMask, 0, p0->as_VMReg());\n-  reg_def P1 (SOC, SOC, Op_RegVMask, 1, p1->as_VMReg());\n-  reg_def P2 (SOC, SOC, Op_RegVMask, 2, p2->as_VMReg());\n-  reg_def P3 (SOC, SOC, Op_RegVMask, 3, p3->as_VMReg());\n-  reg_def P4 (SOC, SOC, Op_RegVMask, 4, p4->as_VMReg());\n-  reg_def P5 (SOC, SOC, Op_RegVMask, 5, p5->as_VMReg());\n-  reg_def P6 (SOC, SOC, Op_RegVMask, 6, p6->as_VMReg());\n-  reg_def P7 (SOC, SOC, Op_RegVMask, 7, p7->as_VMReg());\n-  reg_def P8 (SOC, SOC, Op_RegVMask, 8, p8->as_VMReg());\n-  reg_def P9 (SOC, SOC, Op_RegVMask, 9, p9->as_VMReg());\n-  reg_def P10 (SOC, SOC, Op_RegVMask, 10, p10->as_VMReg());\n-  reg_def P11 (SOC, SOC, Op_RegVMask, 11, p11->as_VMReg());\n-  reg_def P12 (SOC, SOC, Op_RegVMask, 12, p12->as_VMReg());\n-  reg_def P13 (SOC, SOC, Op_RegVMask, 13, p13->as_VMReg());\n-  reg_def P14 (SOC, SOC, Op_RegVMask, 14, p14->as_VMReg());\n-  reg_def P15 (SOC, SOC, Op_RegVMask, 15, p15->as_VMReg());\n+  reg_def P0 (SOC, SOC, Op_RegVectMask, 0, p0->as_VMReg());\n+  reg_def P1 (SOC, SOC, Op_RegVectMask, 1, p1->as_VMReg());\n+  reg_def P2 (SOC, SOC, Op_RegVectMask, 2, p2->as_VMReg());\n+  reg_def P3 (SOC, SOC, Op_RegVectMask, 3, p3->as_VMReg());\n+  reg_def P4 (SOC, SOC, Op_RegVectMask, 4, p4->as_VMReg());\n+  reg_def P5 (SOC, SOC, Op_RegVectMask, 5, p5->as_VMReg());\n+  reg_def P6 (SOC, SOC, Op_RegVectMask, 6, p6->as_VMReg());\n+  reg_def P7 (SOC, SOC, Op_RegVectMask, 7, p7->as_VMReg());\n+  reg_def P8 (SOC, SOC, Op_RegVectMask, 8, p8->as_VMReg());\n+  reg_def P9 (SOC, SOC, Op_RegVectMask, 9, p9->as_VMReg());\n+  reg_def P10 (SOC, SOC, Op_RegVectMask, 10, p10->as_VMReg());\n+  reg_def P11 (SOC, SOC, Op_RegVectMask, 11, p11->as_VMReg());\n+  reg_def P12 (SOC, SOC, Op_RegVectMask, 12, p12->as_VMReg());\n+  reg_def P13 (SOC, SOC, Op_RegVectMask, 13, p13->as_VMReg());\n+  reg_def P14 (SOC, SOC, Op_RegVectMask, 14, p14->as_VMReg());\n+  reg_def P15 (SOC, SOC, Op_RegVectMask, 15, p15->as_VMReg());\n@@ -2442,0 +2442,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return &_PR_REG_mask;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return new TypeVectMask(elemTy, length);\n+}\n+\n@@ -5622,1 +5630,1 @@\n-  match(RegVMask);\n+  match(RegVectMask);\n@@ -6281,0 +6289,1 @@\n+opclass vmem2(indirect, indIndex, indOffI2, indOffL2);\n@@ -9246,1 +9255,0 @@\n-\n@@ -9260,0 +9268,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9261,0 +9271,1 @@\n+\n@@ -9276,0 +9287,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9277,0 +9290,1 @@\n+\n@@ -9292,0 +9306,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9293,0 +9309,1 @@\n+\n@@ -9307,0 +9324,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9308,0 +9327,1 @@\n+\n@@ -9322,0 +9342,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9323,0 +9345,1 @@\n+\n@@ -9337,0 +9360,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9353,0 +9378,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9370,0 +9397,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9387,1 +9416,2 @@\n-\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9404,0 +9434,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9420,1 +9452,2 @@\n-\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9437,0 +9470,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9453,0 +9488,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9454,0 +9491,1 @@\n+\n@@ -9470,0 +9508,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9471,0 +9511,1 @@\n+\n@@ -9487,0 +9528,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9488,0 +9531,1 @@\n+\n@@ -9504,0 +9548,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9505,0 +9551,1 @@\n+\n@@ -9521,0 +9568,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9522,0 +9571,1 @@\n+\n@@ -9538,0 +9588,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9556,0 +9608,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9574,0 +9628,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9592,0 +9648,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9610,0 +9668,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9628,0 +9688,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9646,0 +9708,2 @@\n+\/\/ This pattern is generated automatically from cas.m4.\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n@@ -9647,1 +9711,1 @@\n-  match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));\n+  match(Set res (WeakCompareAndSwapP mem (Binary oldval newval)));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":85,"deletions":21,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-instruct loadV2(vecD dst, memory mem)\n+instruct loadV2(vecD dst, vmem2 mem)\n@@ -44,0 +44,33 @@\n+\/\/ Load Vector (32 bits)\n+instruct loadV4(vecD dst, vmem4 mem)\n+%{\n+  predicate(n->as_LoadVector()->memory_size() == 4);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8(vecD dst, vmem8 mem)\n+%{\n+  predicate(n->as_LoadVector()->memory_size() == 8);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16(vecX dst, vmem16 mem)\n+%{\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 16);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(vload_reg_mem128);\n+%}\n+\n@@ -45,1 +78,1 @@\n-instruct storeV2(vecD src, memory mem)\n+instruct storeV2(vecD src, vmem2 mem)\n@@ -55,0 +88,33 @@\n+\/\/ Store Vector (32 bits)\n+instruct storeV4(vecD src, vmem4 mem)\n+%{\n+  predicate(n->as_StoreVector()->memory_size() == 4);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8(vecD src, vmem8 mem)\n+%{\n+  predicate(n->as_StoreVector()->memory_size() == 8);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16(vecX src, vmem16 mem)\n+%{\n+  predicate(n->as_StoreVector()->memory_size() == 16);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(vstore_reg_mem128);\n+%}\n+\n@@ -3463,1 +3529,1 @@\n-  format %{ \"addv  $tmp, T8B, $src1\\t# src1 and src2 are the same\\n\\t\"\n+  format %{ \"addv  $tmp, T8B, $src1\\n\\t\"\n@@ -3466,1 +3532,1 @@\n-            \"cset  $dst\" %}\n+            \"cset  $dst\\t# anytrue 8B\" %}\n@@ -3468,0 +3534,1 @@\n+    \/\/ No need to use src2.\n@@ -3482,1 +3549,1 @@\n-  format %{ \"addv  $tmp, T16B, $src1\\t# src1 and src2 are the same\\n\\t\"\n+  format %{ \"addv  $tmp, T16B, $src1\\n\\t\"\n@@ -3485,1 +3552,1 @@\n-            \"cset  $dst\" %}\n+            \"cset  $dst\\t# anytrue 16B\" %}\n@@ -3487,0 +3554,1 @@\n+    \/\/ No need to use src2.\n@@ -3501,3 +3569,1 @@\n-  format %{ \"andr  $tmp, T8B, $src1, $src2\\t# src2 is maskAllTrue\\n\\t\"\n-            \"notr  $tmp, T8B, $tmp\\n\\t\"\n-            \"addv  $tmp, T8B, $tmp\\n\\t\"\n+  format %{ \"uminv $tmp, T8B, $src1\\n\\t\"\n@@ -3505,2 +3571,2 @@\n-            \"cmp   $dst, 0\\n\\t\"\n-            \"cset  $dst\" %}\n+            \"cmp   $dst, 0xff\\n\\t\"\n+            \"cset  $dst\\t# alltrue 8B\" %}\n@@ -3508,4 +3574,2 @@\n-    __ andr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));\n-    __ notr(as_FloatRegister($tmp$$reg), __ T8B, as_FloatRegister($tmp$$reg));\n-    __ addv(as_FloatRegister($tmp$$reg), __ T8B, as_FloatRegister($tmp$$reg));\n+    \/\/ No need to use src2.\n+    __ uminv(as_FloatRegister($tmp$$reg), __ T8B, as_FloatRegister($src1$$reg));\n@@ -3513,1 +3577,1 @@\n-    __ cmpw($dst$$Register, zr);\n+    __ cmpw($dst$$Register, 0xff);\n@@ -3525,3 +3589,1 @@\n-  format %{ \"andr  $tmp, T16B, $src1, $src2\\t# src2 is maskAllTrue\\n\\t\"\n-            \"notr  $tmp, T16B, $tmp\\n\\t\"\n-            \"addv  $tmp, T16B, $tmp\\n\\t\"\n+  format %{ \"uminv $tmp, T16B, $src1\\n\\t\"\n@@ -3529,2 +3591,2 @@\n-            \"cmp   $dst, 0\\n\\t\"\n-            \"cset  $dst\" %}\n+            \"cmp   $dst, 0xff\\n\\t\"\n+            \"cset  $dst\\t# alltrue 16B\" %}\n@@ -3532,4 +3594,2 @@\n-    __ andr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));\n-    __ notr(as_FloatRegister($tmp$$reg), __ T16B, as_FloatRegister($tmp$$reg));\n-    __ addv(as_FloatRegister($tmp$$reg), __ T16B, as_FloatRegister($tmp$$reg));\n+    \/\/ No need to use src2.\n+    __ uminv(as_FloatRegister($tmp$$reg), __ T16B, as_FloatRegister($src1$$reg));\n@@ -3537,1 +3597,1 @@\n-    __ cmpw($dst$$Register, zr);\n+    __ cmpw($dst$$Register, 0xff);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":86,"deletions":26,"binary":false,"changes":112,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-instruct $3V$4`'(vec$5 $7, ifelse($4, 2, memory, vmem$4) mem)\n+instruct $3V$4`'(vec$5 $7, vmem$4 mem)\n@@ -73,0 +73,3 @@\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst, )\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst, )\n+VLoadStore(ldrq, Q, load, 16,  X, 128, dst, UseSVE == 0 && )\n@@ -74,0 +77,3 @@\n+VLoadStore(strs, S, store, 4,  D, 32,  src, )\n+VLoadStore(strd, D, store, 8,  D, 64,  src, )\n+VLoadStore(strq, Q, store, 16, X, 128, src, )\n@@ -1412,1 +1418,1 @@\n-  format %{ \"addv  $tmp, T$1B, $src1\\t# src1 and src2 are the same\\n\\t\"\n+  format %{ \"addv  $tmp, T$1B, $src1\\n\\t\"\n@@ -1415,1 +1421,1 @@\n-            \"cset  $dst\" %}\n+            \"cset  $dst\\t# anytrue $1B\" %}\n@@ -1417,0 +1423,1 @@\n+    \/\/ No need to use src2.\n@@ -1435,3 +1442,1 @@\n-  format %{ \"andr  $tmp, T$1B, $src1, $src2\\t# src2 is maskAllTrue\\n\\t\"\n-            \"notr  $tmp, T$1B, $tmp\\n\\t\"\n-            \"addv  $tmp, T$1B, $tmp\\n\\t\"\n+  format %{ \"uminv $tmp, T$1B, $src1\\n\\t\"\n@@ -1439,2 +1444,2 @@\n-            \"cmp   $dst, 0\\n\\t\"\n-            \"cset  $dst\" %}\n+            \"cmp   $dst, 0xff\\n\\t\"\n+            \"cset  $dst\\t# alltrue $1B\" %}\n@@ -1442,4 +1447,2 @@\n-    __ andr(as_FloatRegister($tmp$$reg), __ T$1B,\n-            as_FloatRegister($src1$$reg), as_FloatRegister($src2$$reg));\n-    __ notr(as_FloatRegister($tmp$$reg), __ T$1B, as_FloatRegister($tmp$$reg));\n-    __ addv(as_FloatRegister($tmp$$reg), __ T$1B, as_FloatRegister($tmp$$reg));\n+    \/\/ No need to use src2.\n+    __ uminv(as_FloatRegister($tmp$$reg), __ T$1B, as_FloatRegister($src1$$reg));\n@@ -1447,1 +1450,1 @@\n-    __ cmpw($dst$$Register, zr);\n+    __ cmpw($dst$$Register, 0xff);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":16,"deletions":13,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -55,1 +55,0 @@\n-\n@@ -91,1 +90,0 @@\n-\n@@ -237,1 +235,0 @@\n-\n@@ -245,1 +242,0 @@\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -32,0 +32,2 @@\n+\n+\/\/ 4 bit signed offset -- for predicated load\/store\n@@ -54,3 +56,1 @@\n-%}')\n-dnl\n-\/\/ 4 bit signed offset -- for predicated load\/store\n+%}')dnl\n@@ -75,2 +75,1 @@\n-%}')\n-dnl\n+%}')dnl\n@@ -87,1 +86,0 @@\n-\n@@ -233,1 +231,0 @@\n-\n@@ -246,1 +243,1 @@\n-   `($2->bottom_type()->is_vect()->element_basic_type() == $1)')')\n+   `($2->bottom_type()->is_vect()->element_basic_type() == $1)')')dnl\n@@ -391,1 +388,1 @@\n-\n+dnl\n@@ -1330,1 +1327,0 @@\n-\n@@ -1335,1 +1331,0 @@\n-\n@@ -1354,3 +1349,3 @@\n-dnl VSHIFT_IMM_UNPREDICATE($1,        $2,      $3,       $4,   $5,          $6  )\n-dnl VSHIFT_IMM_UNPREDICATE(insn_name, op_name, op_name2, size, min_vec_len, insn)\n-define(`VSHIFT_IMM_UNPREDICATE', `\n+dnl VSHIFT_IMM_UNPREDICATED($1,        $2,      $3,       $4,   $5,          $6  )\n+dnl VSHIFT_IMM_UNPREDICATED(insn_name, op_name, op_name2, size, min_vec_len, insn)\n+define(`VSHIFT_IMM_UNPREDICATED', `\n@@ -1418,12 +1413,12 @@\n-VSHIFT_IMM_UNPREDICATE(vasrB_imm, RShiftVB,  RShiftCntV, B, 16, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vasrS_imm, RShiftVS,  RShiftCntV, H,  8, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vasrI_imm, RShiftVI,  RShiftCntV, S,  4, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vasrL_imm, RShiftVL,  RShiftCntV, D,  2, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vlsrB_imm, URShiftVB, RShiftCntV, B, 16, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlsrS_imm, URShiftVS, RShiftCntV, H,  8, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlsrI_imm, URShiftVI, RShiftCntV, S,  4, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlsrL_imm, URShiftVL, RShiftCntV, D,  2, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlslB_imm, LShiftVB,  LShiftCntV, B, 16, sve_lsl)\n-VSHIFT_IMM_UNPREDICATE(vlslS_imm, LShiftVS,  LShiftCntV, H,  8, sve_lsl)\n-VSHIFT_IMM_UNPREDICATE(vlslI_imm, LShiftVI,  LShiftCntV, S,  4, sve_lsl)\n-VSHIFT_IMM_UNPREDICATE(vlslL_imm, LShiftVL,  LShiftCntV, D,  2, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vasrB_imm, RShiftVB,  RShiftCntV, B, 16, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vasrS_imm, RShiftVS,  RShiftCntV, H,  8, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vasrI_imm, RShiftVI,  RShiftCntV, S,  4, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vasrL_imm, RShiftVL,  RShiftCntV, D,  2, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vlsrB_imm, URShiftVB, RShiftCntV, B, 16, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlsrS_imm, URShiftVS, RShiftCntV, H,  8, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlsrI_imm, URShiftVI, RShiftCntV, S,  4, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlsrL_imm, URShiftVL, RShiftCntV, D,  2, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlslB_imm, LShiftVB,  LShiftCntV, B, 16, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vlslS_imm, LShiftVS,  LShiftCntV, H,  8, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vlslI_imm, LShiftVI,  LShiftCntV, S,  4, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vlslL_imm, LShiftVL,  LShiftCntV, D,  2, sve_lsl)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":21,"deletions":26,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -2430,0 +2430,1 @@\n+  INSN(uminv,  1, 0b110001101010, 1); \/\/ accepted arrangements: T8B, T16B, T4H, T8H,      T4S\n@@ -2690,1 +2691,1 @@\n-    assert(!isSHR || (isSHR && (shift != 0)), \"Zero right shift\");      \\\n+    guarantee(!isSHR || (isSHR && (shift != 0)), \"impossible encoding\");\\\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -4,0 +4,1 @@\n+ * Copyright (c) 2021, Azul Systems, Inc. All rights reserved.\n@@ -243,9 +244,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return 16;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  __ mov(rscratch1, destination);\n-  __ br(rscratch1);\n-}\n-\n@@ -785,1 +777,1 @@\n-int SharedRuntime::c_calling_convention(const BasicType *sig_bt,\n+static int c_calling_convention_priv(const BasicType *sig_bt,\n@@ -816,0 +808,5 @@\n+#ifdef __APPLE__\n+          \/\/ Less-than word types are stored one after another.\n+          \/\/ The code is unable to handle this so bailout.\n+          return -1;\n+#endif\n@@ -838,0 +835,5 @@\n+#ifdef __APPLE__\n+          \/\/ Less-than word types are stored one after another.\n+          \/\/ The code is unable to handle this so bailout.\n+          return -1;\n+#endif\n@@ -872,0 +874,10 @@\n+int SharedRuntime::c_calling_convention(const BasicType *sig_bt,\n+                                         VMRegPair *regs,\n+                                         VMRegPair *regs2,\n+                                         int total_args_passed)\n+{\n+  int result = c_calling_convention_priv(sig_bt, regs, regs2, total_args_passed);\n+  guarantee(result >= 0, \"Unsupported arguments configuration\");\n+  return result;\n+}\n+\n@@ -1377,1 +1389,5 @@\n-  out_arg_slots = c_calling_convention(out_sig_bt, out_regs, NULL, total_c_args);\n+  out_arg_slots = c_calling_convention_priv(out_sig_bt, out_regs, NULL, total_c_args);\n+\n+  if (out_arg_slots < 0) {\n+    return NULL;\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":27,"deletions":11,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2008, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2008, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -996,0 +996,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return NULL;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -254,10 +254,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return 16;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  InlinedAddress dest(destination);\n-  __ indirect_jump(dest, Rtemp);\n-  __ bind_literal(dest);\n-}\n-\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n-\/\/ Copyright (c) 2012, 2020 SAP SE. All rights reserved.\n+\/\/ Copyright (c) 2012, 2021 SAP SE. All rights reserved.\n@@ -1565,1 +1565,1 @@\n-    st->print(\"touch polling page\\n\\t\");\n+    st->print(\"safepoint poll\\n\\t\");\n@@ -1580,1 +1580,1 @@\n-  const Register polling_page     = R12;\n+  const Register temp             = R12;\n@@ -1585,7 +1585,0 @@\n-  }\n-\n-  if (method_needs_polling) {\n-    __ ld(polling_page, in_bytes(JavaThread::polling_page_offset()), R16_thread);\n-  }\n-\n-  if (!method_is_frameless) {\n@@ -1603,4 +1596,7 @@\n-    \/\/ We need to mark the code position where the load from the safepoint\n-    \/\/ polling page was emitted as relocInfo::poll_return_type here.\n-    __ relocate(relocInfo::poll_return_type);\n-    __ load_from_polling_page(polling_page);\n+    Label dummy_label;\n+    Label* code_stub = &dummy_label;\n+    if (!UseSIGTRAP && !C->output()->in_scratch_emit_size()) {\n+      code_stub = &C->output()->safepoint_poll_table()->add_safepoint(__ offset());\n+      __ relocate(relocInfo::poll_return_type);\n+    }\n+    __ safepoint_poll(*code_stub, temp, true \/* at_return *\/, true \/* in_nmethod *\/);\n@@ -2163,0 +2159,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return NULL;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":18,"deletions":14,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -567,11 +567,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return Assembler::load_const_size + 8;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  Register Rtemp = R12;\n-  __ load_const(Rtemp, destination);\n-  __ mtctr(Rtemp);\n-  __ bctr();\n-}\n-\n@@ -2284,1 +2273,4 @@\n-    __ safepoint_poll(needs_safepoint, sync_state);\n+    \/\/ Note: We should not reach here with active stack watermark. There's no safepoint between\n+    \/\/       start of the native wrapper and this check where it could have been added.\n+    \/\/       We don't check the watermark in the fast path.\n+    __ safepoint_poll(needs_safepoint, sync_state, false \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -2331,1 +2323,1 @@\n-    __ safepoint_poll(sync, sync_state);\n+    __ safepoint_poll(sync, sync_state, true \/* at_return *\/, false \/* in_nmethod *\/);\n@@ -3030,1 +3022,1 @@\n-    return_pc_location = RegisterSaver::return_pc_is_lr;\n+    return_pc_location = RegisterSaver::return_pc_is_pre_saved;\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":6,"deletions":14,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1549,0 +1549,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return NULL;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -559,10 +559,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return MacroAssembler::load_const_size() + 2;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  \/\/ Think about using pc-relative branch.\n-  __ load_const(Z_R1_scratch, destination);\n-  __ z_br(Z_R1_scratch);\n-}\n-\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -134,0 +134,1 @@\n+  int opmask_state_bytes = KRegisterImpl::number_of_registers * 8;\n@@ -142,0 +143,1 @@\n+      additional_frame_words += opmask_state_bytes \/ wordSize;\n@@ -232,0 +234,5 @@\n+      __ subptr(rsp, opmask_state_bytes);\n+      \/\/ Save opmask registers\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(Address(rsp, n*8), as_KRegister(n));\n+      }\n@@ -254,0 +261,1 @@\n+\n@@ -278,0 +286,2 @@\n+  int opmask_state_bytes = 0;\n+  int additional_frame_bytes = 0;\n@@ -282,1 +292,0 @@\n-  int additional_frame_bytes = 0;\n@@ -292,0 +301,2 @@\n+      opmask_state_bytes = KRegisterImpl::number_of_registers * 8;\n+      additional_frame_bytes += opmask_state_bytes;\n@@ -325,1 +336,0 @@\n-\n@@ -328,0 +338,1 @@\n+      off = opmask_state_bytes;\n@@ -329,1 +340,4 @@\n-        __ vinsertf64x4_high(as_XMMRegister(n), Address(rsp, n*32));\n+        __ vinsertf64x4_high(as_XMMRegister(n), Address(rsp, n*32+off));\n+      }\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(as_KRegister(n), Address(rsp, n*8));\n@@ -374,8 +388,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return 16;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  __ jump(RuntimeAddress(destination));\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":17,"deletions":11,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -93,0 +93,1 @@\n+#define XSAVE_AREA_OPMASK_BEGIN 1088\n@@ -98,0 +99,1 @@\n+#define DEF_OPMASK_OFFS(regnum)    opmask ## regnum ## _off = opmask_off + (regnum)*8\/BytesPerInt,     opmask ## regnum ## H_off\n@@ -109,0 +111,4 @@\n+    opmask_off         = xmm_off + (XSAVE_AREA_OPMASK_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_OPMASK_OFFS(0),\n+    DEF_OPMASK_OFFS(1),\n+    \/\/ 2..7 are implied in range usage\n@@ -216,0 +222,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(Address(rsp, base_addr+(off++*8)), as_KRegister(n));\n+      }\n+#endif\n@@ -225,0 +238,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(Address(rsp, base_addr+(off++*8)), as_KRegister(n));\n+      }\n+#endif\n@@ -384,0 +404,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(as_KRegister(n), Address(rsp, base_addr+(off++*8)));\n+      }\n+#endif\n@@ -393,0 +420,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmov(as_KRegister(n), Address(rsp, base_addr+(off++*8)));\n+      }\n+#endif\n@@ -426,8 +460,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  return 16;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  __ jump(RuntimeAddress(destination));\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":34,"deletions":8,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -631,0 +631,23 @@\n+\/\/ AVX3 Mask Registers.\n+reg_def K1   (SOC, SOC, Op_RegI,  1, k1->as_VMReg());\n+reg_def K1_H (SOC, SOC, Op_RegI,  1, k1->as_VMReg()->next());\n+\n+reg_def K2   (SOC, SOC, Op_RegI,  2, k2->as_VMReg());\n+reg_def K2_H (SOC, SOC, Op_RegI,  2, k2->as_VMReg()->next());\n+\n+reg_def K3   (SOC, SOC, Op_RegI,  3, k3->as_VMReg());\n+reg_def K3_H (SOC, SOC, Op_RegI,  3, k3->as_VMReg()->next());\n+\n+reg_def K4   (SOC, SOC, Op_RegI,  4, k4->as_VMReg());\n+reg_def K4_H (SOC, SOC, Op_RegI,  4, k4->as_VMReg()->next());\n+\n+reg_def K5   (SOC, SOC, Op_RegI,  5, k5->as_VMReg());\n+reg_def K5_H (SOC, SOC, Op_RegI,  5, k5->as_VMReg()->next());\n+\n+reg_def K6   (SOC, SOC, Op_RegI,  6, k6->as_VMReg());\n+reg_def K6_H (SOC, SOC, Op_RegI,  6, k6->as_VMReg()->next());\n+\n+reg_def K7   (SOC, SOC, Op_RegI,  7, k7->as_VMReg());\n+reg_def K7_H (SOC, SOC, Op_RegI,  7, k7->as_VMReg()->next());\n+\n+\n@@ -667,0 +690,24 @@\n+alloc_class chunk2(K7, K7_H,\n+                   K6, K6_H,\n+                   K5, K5_H,\n+                   K4, K4_H,\n+                   K3, K3_H,\n+                   K2, K2_H,\n+                   K1, K1_H);\n+\n+reg_class  vectmask_reg(K1, K1_H,\n+                        K2, K2_H,\n+                        K3, K3_H,\n+                        K4, K4_H,\n+                        K5, K5_H,\n+                        K6, K6_H,\n+                        K7, K7_H);\n+\n+reg_class vectmask_reg_K1(K1, K1_H);\n+reg_class vectmask_reg_K2(K2, K2_H);\n+reg_class vectmask_reg_K3(K3, K3_H);\n+reg_class vectmask_reg_K4(K4, K4_H);\n+reg_class vectmask_reg_K5(K5, K5_H);\n+reg_class vectmask_reg_K6(K6, K6_H);\n+reg_class vectmask_reg_K7(K7, K7_H);\n+\n@@ -668,1 +715,2 @@\n-alloc_class chunk2(RFLAGS);\n+alloc_class chunk3(RFLAGS);\n+\n@@ -1371,0 +1419,1 @@\n+  const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);\n@@ -1527,0 +1576,1 @@\n+\n@@ -1530,1 +1580,1 @@\n-      if (UseAVX < 3 || !VM_Version::supports_bmi2()) {\n+      if (!is_LP64  || UseAVX < 3 || !VM_Version::supports_bmi2()) {\n@@ -1561,0 +1611,1 @@\n+  const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);\n@@ -1611,1 +1662,1 @@\n-      if (!VM_Version::supports_avx512bw()) {\n+      if (!is_LP64 || !VM_Version::supports_avx512bw()) {\n@@ -1839,0 +1890,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return &_VECTMASK_REG_mask;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return new TypeVectMask(TypeInt::BOOL, length);\n+}\n+\n@@ -2564,3 +2623,7 @@\n-\n-instruct setMask(rRegI dst, rRegI src) %{\n-  predicate(Matcher::has_predicated_vectors());\n+\/\/ Existing partial implementation for post-loop multi-versioning computes\n+\/\/ the mask corresponding to tail loop in K1 opmask register. This may then be\n+\/\/ used for predicating instructions in loop body during last post-loop iteration.\n+\/\/ TODO: Remove hard-coded K1 usage while fixing existing post-loop\n+\/\/ multiversioning support.\n+instruct setMask(rRegI dst, rRegI src, kReg_K1 mask) %{\n+  predicate(PostLoopMultiversioning && Matcher::has_predicated_vectors());\n@@ -2571,1 +2634,1 @@\n-    __ setvectmask($dst$$Register, $src$$Register);\n+    __ setvectmask($dst$$Register, $src$$Register, $mask$$KRegister);\n@@ -3244,25 +3307,3 @@\n-instruct sqrtF_reg(regF dst, regF src) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (SqrtF src));\n-\n-  format %{ \"sqrtss  $dst, $src\" %}\n-  ins_cost(150);\n-  ins_encode %{\n-    __ sqrtss($dst$$XMMRegister, $src$$XMMRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct sqrtF_mem(regF dst, memory src) %{\n-  predicate(UseSSE>=1);\n-  match(Set dst (SqrtF (LoadF src)));\n-\n-  format %{ \"sqrtss  $dst, $src\" %}\n-  ins_cost(150);\n-  ins_encode %{\n-    __ sqrtss($dst$$XMMRegister, $src$$Address);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct sqrtF_imm(regF dst, immF con) %{\n+\/\/ sqrtss instruction needs destination register to be pre initialized for best performance\n+\/\/ Therefore only the instruct rule where the input is pre-loaded into dst register is defined below\n+instruct sqrtF_reg(regF dst) %{\n@@ -3270,28 +3311,2 @@\n-  match(Set dst (SqrtF con));\n-\n-  format %{ \"sqrtss  $dst, [$constantaddress]\\t# load from constant table: float=$con\" %}\n-  ins_cost(150);\n-  ins_encode %{\n-    __ sqrtss($dst$$XMMRegister, $constantaddress($con));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct sqrtD_reg(regD dst, regD src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (SqrtD src));\n-\n-  format %{ \"sqrtsd  $dst, $src\" %}\n-  ins_cost(150);\n-  ins_encode %{\n-    __ sqrtsd($dst$$XMMRegister, $src$$XMMRegister);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct sqrtD_mem(regD dst, memory src) %{\n-  predicate(UseSSE>=2);\n-  match(Set dst (SqrtD (LoadD src)));\n-\n-  format %{ \"sqrtsd  $dst, $src\" %}\n-  ins_cost(150);\n+  match(Set dst (SqrtF dst));\n+  format %{ \"sqrtss  $dst, $dst\" %}\n@@ -3299,1 +3314,1 @@\n-    __ sqrtsd($dst$$XMMRegister, $src$$Address);\n+    __ sqrtss($dst$$XMMRegister, $dst$$XMMRegister);\n@@ -3304,1 +3319,3 @@\n-instruct sqrtD_imm(regD dst, immD con) %{\n+\/\/ sqrtsd instruction needs destination register to be pre initialized for best performance\n+\/\/ Therefore only the instruct rule where the input is pre-loaded into dst register is defined below\n+instruct sqrtD_reg(regD dst) %{\n@@ -3306,3 +3323,2 @@\n-  match(Set dst (SqrtD con));\n-  format %{ \"sqrtsd  $dst, [$constantaddress]\\t# load from constant table: double=$con\" %}\n-  ins_cost(150);\n+  match(Set dst (SqrtD dst));\n+  format %{ \"sqrtsd  $dst, $dst\" %}\n@@ -3310,1 +3326,1 @@\n-    __ sqrtsd($dst$$XMMRegister, $constantaddress($con));\n+    __ sqrtsd($dst$$XMMRegister, $dst$$XMMRegister);\n@@ -3611,1 +3627,1 @@\n-instruct evgather(vec dst, memory mem, vec idx, rRegP tmp) %{\n+instruct evgather(vec dst, memory mem, vec idx, rRegP tmp, kReg ktmp) %{\n@@ -3614,1 +3630,1 @@\n-  effect(TEMP dst, TEMP tmp);\n+  effect(TEMP dst, TEMP tmp, TEMP ktmp);\n@@ -3624,2 +3640,1 @@\n-    KRegister ktmp = k2;\n-    __ kmovwl(k2, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n+    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n@@ -3627,1 +3642,1 @@\n-    __ evgather(elem_bt, $dst$$XMMRegister, ktmp, $tmp$$Register, $idx$$XMMRegister, vlen_enc);\n+    __ evgather(elem_bt, $dst$$XMMRegister, $ktmp$$KRegister, $tmp$$Register, $idx$$XMMRegister, vlen_enc);\n@@ -3636,1 +3651,2 @@\n-instruct scatter(memory mem, vec src, vec idx, rRegP tmp) %{\n+instruct scatter(memory mem, vec src, vec idx, rRegP tmp, kReg ktmp) %{\n+  predicate(UseAVX > 2);\n@@ -3638,1 +3654,1 @@\n-  effect(TEMP tmp);\n+  effect(TEMP tmp, TEMP ktmp);\n@@ -3641,2 +3657,0 @@\n-    assert(UseAVX > 2, \"sanity\");\n-\n@@ -3649,2 +3663,1 @@\n-    KRegister ktmp = k2;\n-    __ kmovwl(k2, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n+    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n@@ -3652,1 +3665,1 @@\n-    __ evscatter(elem_bt, $tmp$$Register, $idx$$XMMRegister, ktmp, $src$$XMMRegister, vlen_enc);\n+    __ evscatter(elem_bt, $tmp$$Register, $idx$$XMMRegister, $ktmp$$KRegister, $src$$XMMRegister, vlen_enc);\n@@ -5753,1 +5766,1 @@\n-instruct evminmaxFP_reg_eavx(vec dst, vec a, vec b, vec atmp, vec btmp) %{\n+instruct evminmaxFP_reg_eavx(vec dst, vec a, vec b, vec atmp, vec btmp, kReg ktmp) %{\n@@ -5758,1 +5771,1 @@\n-  effect(TEMP dst, USE a, USE b, TEMP atmp, TEMP btmp);\n+  effect(TEMP dst, USE a, USE b, TEMP atmp, TEMP btmp, TEMP ktmp);\n@@ -5767,1 +5780,0 @@\n-    KRegister ktmp = k1;\n@@ -5770,1 +5782,1 @@\n-                   ktmp, $atmp$$XMMRegister , $btmp$$XMMRegister, vlen_enc);\n+                   $ktmp$$KRegister, $atmp$$XMMRegister , $btmp$$XMMRegister, vlen_enc);\n@@ -6835,1 +6847,1 @@\n-instruct evcmpFD(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch) %{\n+instruct evcmpFD(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n@@ -6839,1 +6851,1 @@\n-  effect(TEMP scratch);\n+  effect(TEMP scratch, TEMP ktmp);\n@@ -6844,1 +6856,0 @@\n-    KRegister ktmp = k2; \/\/ Use a hardcoded temp due to no k register allocation.\n@@ -6847,2 +6858,2 @@\n-      __ evcmpps(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-      __ evmovdqul($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n+      __ evcmpps($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+      __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n@@ -6850,2 +6861,2 @@\n-      __ evcmppd(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-      __ evmovdquq($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n+      __ evcmppd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+      __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n@@ -6873,1 +6884,1 @@\n-instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch) %{\n+instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n@@ -6877,1 +6888,1 @@\n-  effect(TEMP scratch);\n+  effect(TEMP scratch, TEMP ktmp);\n@@ -6884,1 +6895,0 @@\n-    KRegister ktmp = k2; \/\/ Use a hardcoded temp due to no k register allocation.\n@@ -6891,2 +6901,2 @@\n-        __ evpcmpb(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdqub($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpb($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdqub($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -6896,2 +6906,2 @@\n-        __ evpcmpw(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdquw($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpw($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdquw($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -6901,2 +6911,2 @@\n-        __ evpcmpd(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdqul($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -6906,2 +6916,2 @@\n-        __ evpcmpq(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdquq($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpq($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -7085,1 +7095,1 @@\n-instruct evblendvp64(vec dst, vec src1, vec src2, vec mask, rRegP scratch) %{\n+instruct evblendvp64(vec dst, vec src1, vec src2, vec mask, rRegP scratch, kReg ktmp) %{\n@@ -7089,1 +7099,1 @@\n-  effect(TEMP scratch);\n+  effect(TEMP scratch, TEMP ktmp);\n@@ -7093,3 +7103,2 @@\n-     KRegister ktmp = k2;\n-    __ evpcmp(elem_bt, ktmp, k0, $mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), Assembler::eq, vlen_enc, $scratch$$Register);\n-    __ evpblend(elem_bt, $dst$$XMMRegister, ktmp, $src1$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+    __ evpcmp(elem_bt, $ktmp$$KRegister, k0, $mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), Assembler::eq, vlen_enc, $scratch$$Register);\n+    __ evpblend(elem_bt, $dst$$XMMRegister, $ktmp$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n@@ -7238,0 +7247,1 @@\n+            vector_length_in_bytes(n->in(1)) <  64 &&\n@@ -7244,1 +7254,16 @@\n-    __ vectortest(BoolTest::overflow, vlen, $src1$$XMMRegister, $src2$$XMMRegister); \n+    __ vectortest(BoolTest::overflow, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, knoreg);\n+    __ setb(Assembler::carrySet, $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vptest_alltrue_evex(rRegI dst, legVec src1, legVec src2, kReg ktmp, rFlagsReg cr) %{\n+  predicate(vector_length_in_bytes(n->in(1)) == 64 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2 ));\n+  effect(KILL cr, TEMP ktmp);\n+  format %{ \"vector_test $dst,$src1, $src2\\t! using $cr as TEMP\" %}\n+  ins_encode %{\n+    int vlen = vector_length_in_bytes(this, $src1);\n+    __ vectortest(BoolTest::overflow, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n@@ -7269,0 +7294,1 @@\n+            vector_length_in_bytes(n->in(1)) < 64  &&\n@@ -7275,1 +7301,16 @@\n-    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister);\n+    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, knoreg);\n+    __ setb(Assembler::notZero, $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vptest_anytrue_evex(rRegI dst, legVec src1, legVec src2, kReg ktmp, rFlagsReg cr) %{\n+  predicate(vector_length_in_bytes(n->in(1)) == 64 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2 ));\n+  effect(KILL cr, TEMP ktmp);\n+  format %{ \"vector_test_any_true $dst,$src1,$src2\\t! using $cr as TEMP\" %}\n+  ins_encode %{\n+    int vlen = vector_length_in_bytes(this, $src1);\n+    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n@@ -7298,0 +7339,1 @@\n+            vector_length_in_bytes(n->in(1)->in(1)) <  64 &&\n@@ -7303,1 +7345,14 @@\n-    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister);\n+    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct cmpvptest_anytrue_evex(rFlagsReg cr, legVec src1, legVec src2, immI_0 zero, kReg ktmp) %{\n+  predicate(vector_length_in_bytes(n->in(1)->in(1)) == 64 &&\n+            static_cast<const VectorTestNode*>(n->in(1))->get_predicate() == BoolTest::ne);\n+  match(Set cr (CmpI (VectorTest src1 src2) zero));\n+  effect(TEMP ktmp);\n+  format %{ \"cmp_vector_test_any_true $src1,$src2\\t!\" %}\n+  ins_encode %{\n+    int vlen = vector_length_in_bytes(this, $src1);\n+    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n@@ -7956,2 +8011,1 @@\n-\n-instruct vmasked_load64(vec dst, memory mem, rRegL mask) %{\n+instruct vmasked_load64(vec dst, memory mem, kReg mask) %{\n@@ -7963,2 +8017,1 @@\n-    __ kmovql(k2, $mask$$Register);\n-    __ evmovdqu(elmType, k2, $dst$$XMMRegister, $mem$$Address, vector_len);\n+    __ evmovdqu(elmType, $mask$$KRegister, $dst$$XMMRegister, $mem$$Address, vector_len);\n@@ -7969,1 +8022,1 @@\n-instruct vmask_gen(rRegL dst, rRegL len, rRegL tempLen) %{\n+instruct vmask_gen(kReg dst, rRegL len, rRegL temp) %{\n@@ -7971,2 +8024,2 @@\n-  effect(TEMP_DEF dst, TEMP tempLen);\n-  format %{ \"vector_mask_gen $len \\t! vector mask generator\" %}\n+  effect(TEMP temp);\n+  format %{ \"vector_mask_gen32 $dst, $len \\t! vector mask generator\" %}\n@@ -7974,1 +8027,1 @@\n-    __ genmask($dst$$Register, $len$$Register, $tempLen$$Register);\n+    __ genmask($dst$$KRegister, $len$$Register, $temp$$Register);\n@@ -7979,1 +8032,1 @@\n-instruct vmask_gen_imm(rRegL dst, immL len) %{\n+instruct vmask_gen_imm(kReg dst, immL len, rRegL temp) %{\n@@ -7982,0 +8035,1 @@\n+  effect(TEMP temp);\n@@ -7983,1 +8037,2 @@\n-    __ mov64($dst$$Register, (0xFFFFFFFFFFFFFFFFUL >> (64 -$len$$constant)));\n+    __ mov64($temp$$Register, (0xFFFFFFFFFFFFFFFFUL >> (64 -$len$$constant)));\n+    __ kmovql($dst$$KRegister, $temp$$Register);\n@@ -7988,1 +8043,1 @@\n-instruct vmasked_store64(memory mem, vec src, rRegL mask) %{\n+instruct vmasked_store64(memory mem, vec src, kReg mask) %{\n@@ -7995,2 +8050,1 @@\n-    __ kmovql(k2, $mask$$Register);\n-    __ evmovdqu(elmType, k2, $mem$$Address, $src$$XMMRegister, vector_len);\n+    __ evmovdqu(elmType, $mask$$KRegister, $mem$$Address, $src$$XMMRegister, vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":175,"deletions":121,"binary":false,"changes":296,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -263,0 +263,12 @@\n+void reg_mask_init() {\n+  if (Matcher::has_predicated_vectors()) {\n+    \/\/ Post-loop multi-versioning expects mask to be present in K1 register, till the time\n+    \/\/ its fixed, RA should not be allocting K1 register, this shall prevent any accidental\n+    \/\/ curruption of value held in K1 register.\n+    if (PostLoopMultiversioning) {\n+      const_cast<RegMask*>(&_VECTMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()));\n+      const_cast<RegMask*>(&_VECTMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()->next()));\n+    }\n+  }\n+}\n+\n@@ -734,1 +746,1 @@\n-enum RC { rc_bad, rc_int, rc_float, rc_xmm, rc_stack };\n+enum RC { rc_bad, rc_int, rc_kreg, rc_float, rc_xmm, rc_stack };\n@@ -1053,1 +1065,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() != NULL && bottom_type()->isa_vectmask() == NULL) {\n@@ -1106,1 +1118,1 @@\n-  if( dst_first_rc == rc_int && src_first_rc == rc_stack )\n+  if( src_first_rc == rc_stack && dst_first_rc == rc_int )\n@@ -1195,1 +1207,1 @@\n-    return impl_x_helper(cbuf,do_size,false,ra_->reg2offset(dst_first),src_first, src_second, size, st);\n+    return impl_x_helper(cbuf,do_size,false,ra_->reg2offset(dst_first), src_first, src_second, size, st);\n@@ -1199,1 +1211,1 @@\n-  if( dst_first_rc == rc_xmm && src_first_rc == rc_stack ) {\n+  if( src_first_rc == rc_stack && dst_first_rc == rc_xmm ) {\n@@ -1204,1 +1216,1 @@\n-  if( dst_first_rc == rc_xmm && src_first_rc == rc_float ) {\n+  if( src_first_rc == rc_float && dst_first_rc == rc_xmm ) {\n@@ -1260,0 +1272,36 @@\n+  \/\/ AVX-512 opmask specific spilling.\n+  if (src_first_rc == rc_stack && dst_first_rc == rc_kreg) {\n+    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n+    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n+    MacroAssembler _masm(cbuf);\n+    int offset = ra_->reg2offset(src_first);\n+    __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), Address(rsp, offset));\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_kreg && dst_first_rc == rc_stack) {\n+    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n+    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n+    MacroAssembler _masm(cbuf);\n+    int offset = ra_->reg2offset(dst_first);\n+    __ kmov(Address(rsp, offset), as_KRegister(Matcher::_regEncode[src_first]));\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_kreg && dst_first_rc == rc_int) {\n+    Unimplemented();\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_int && dst_first_rc == rc_kreg) {\n+    Unimplemented();\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_kreg && dst_first_rc == rc_kreg) {\n+    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n+    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n+    MacroAssembler _masm(cbuf);\n+    __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n+    return 0;\n+  }\n@@ -3591,0 +3639,66 @@\n+operand kReg()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K1()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K1));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K2()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K2));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K3()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K3));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K4()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K4));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K5()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K5));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K6()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K6));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K7()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K7));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n@@ -11427,0 +11541,1 @@\n+\/\/ Small ClearArray non-AVX512.\n@@ -11428,1 +11543,2 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && !n->in(2)->bottom_type()->is_int()->is_con());\n+  predicate(!((ClearArrayNode*)n)->is_large() &&\n+              (UseAVX <= 2 || !VM_Version::supports_avx512vlbw()));\n@@ -11481,1 +11597,1 @@\n-                 $tmp$$XMMRegister, false);\n+                 $tmp$$XMMRegister, false, knoreg);\n@@ -11486,0 +11602,63 @@\n+\/\/ Small ClearArray AVX512 non-constant length.\n+instruct rep_stos_evex(eCXRegI cnt, eDIRegP base, regD tmp, kReg ktmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n+  predicate(!((ClearArrayNode*)n)->is_large() &&\n+               UseAVX > 2 && VM_Version::supports_avx512vlbw() &&\n+               !n->in(2)->bottom_type()->is_int()->is_con());\n+  match(Set dummy (ClearArray cnt base));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+\n+  format %{ $$template\n+    $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n+    $$emit$$\"CMP    InitArrayShortSize,rcx\\n\\t\"\n+    $$emit$$\"JG     LARGE\\n\\t\"\n+    $$emit$$\"SHL    ECX, 1\\n\\t\"\n+    $$emit$$\"DEC    ECX\\n\\t\"\n+    $$emit$$\"JS     DONE\\t# Zero length\\n\\t\"\n+    $$emit$$\"MOV    EAX,(EDI,ECX,4)\\t# LOOP\\n\\t\"\n+    $$emit$$\"DEC    ECX\\n\\t\"\n+    $$emit$$\"JGE    LOOP\\n\\t\"\n+    $$emit$$\"JMP    DONE\\n\\t\"\n+    $$emit$$\"# LARGE:\\n\\t\"\n+    if (UseFastStosb) {\n+       $$emit$$\"SHL    ECX,3\\t# Convert doublewords to bytes\\n\\t\"\n+       $$emit$$\"REP STOSB\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n+    } else if (UseXMMForObjInit) {\n+       $$emit$$\"MOV     RDI,RAX\\n\\t\"\n+       $$emit$$\"VPXOR    YMM0,YMM0,YMM0\\n\\t\"\n+       $$emit$$\"JMPQ    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n+       $$emit$$\"VMOVDQU YMM0,0x20(RAX)\\n\\t\"\n+       $$emit$$\"ADD     0x40,RAX\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"SUB     0x8,RCX\\n\\t\"\n+       $$emit$$\"JGE     L_loop\\n\\t\"\n+       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n+       $$emit$$\"JL      L_tail\\n\\t\"\n+       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n+       $$emit$$\"ADD     0x20,RAX\\n\\t\"\n+       $$emit$$\"SUB     0x4,RCX\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n+       $$emit$$\"JLE     L_end\\n\\t\"\n+       $$emit$$\"DEC     RCX\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"VMOVQ   XMM0,(RAX)\\n\\t\"\n+       $$emit$$\"ADD     0x8,RAX\\n\\t\"\n+       $$emit$$\"DEC     RCX\\n\\t\"\n+       $$emit$$\"JGE     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"SHL    ECX,1\\t# Convert doublewords to words\\n\\t\"\n+       $$emit$$\"REP STOS\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n+    }\n+    $$emit$$\"# DONE\"\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n+                 $tmp$$XMMRegister, false, $ktmp$$KRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\/\/ Large ClearArray non-AVX512.\n@@ -11487,1 +11666,1 @@\n-  predicate(((ClearArrayNode*)n)->is_large());\n+  predicate(UseAVX <= 2 && ((ClearArrayNode*)n)->is_large());\n@@ -11530,1 +11709,51 @@\n-                 $tmp$$XMMRegister, true);\n+                 $tmp$$XMMRegister, true, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\/\/ Large ClearArray AVX512.\n+instruct rep_stos_large_evex(eCXRegI cnt, eDIRegP base, regD tmp, kReg ktmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n+  predicate(UseAVX > 2 && ((ClearArrayNode*)n)->is_large());\n+  match(Set dummy (ClearArray cnt base));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+  format %{ $$template\n+    if (UseFastStosb) {\n+       $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n+       $$emit$$\"SHL    ECX,3\\t# Convert doublewords to bytes\\n\\t\"\n+       $$emit$$\"REP STOSB\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n+    } else if (UseXMMForObjInit) {\n+       $$emit$$\"MOV     RDI,RAX\\t# ClearArray:\\n\\t\"\n+       $$emit$$\"VPXOR   YMM0,YMM0,YMM0\\n\\t\"\n+       $$emit$$\"JMPQ    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n+       $$emit$$\"VMOVDQU YMM0,0x20(RAX)\\n\\t\"\n+       $$emit$$\"ADD     0x40,RAX\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"SUB     0x8,RCX\\n\\t\"\n+       $$emit$$\"JGE     L_loop\\n\\t\"\n+       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n+       $$emit$$\"JL      L_tail\\n\\t\"\n+       $$emit$$\"VMOVDQU YMM0,(RAX)\\n\\t\"\n+       $$emit$$\"ADD     0x20,RAX\\n\\t\"\n+       $$emit$$\"SUB     0x4,RCX\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"ADD     0x4,RCX\\n\\t\"\n+       $$emit$$\"JLE     L_end\\n\\t\"\n+       $$emit$$\"DEC     RCX\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"VMOVQ   XMM0,(RAX)\\n\\t\"\n+       $$emit$$\"ADD     0x8,RAX\\n\\t\"\n+       $$emit$$\"DEC     RCX\\n\\t\"\n+       $$emit$$\"JGE     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"XOR    EAX,EAX\\t# ClearArray:\\n\\t\"\n+       $$emit$$\"SHL    ECX,1\\t# Convert doublewords to words\\n\\t\"\n+       $$emit$$\"REP STOS\\t# store EAX into [EDI++] while ECX--\\n\\t\"\n+    }\n+    $$emit$$\"# DONE\"\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n+                 $tmp$$XMMRegister, true, $ktmp$$KRegister);\n@@ -11535,1 +11764,2 @@\n-instruct rep_stos_im(immI cnt, eRegP base, regD tmp, rRegI zero, Universe dummy, eFlagsReg cr)\n+\/\/ Small ClearArray AVX512 constant length.\n+instruct rep_stos_im(immI cnt, kReg ktmp, eRegP base, regD tmp, rRegI zero, Universe dummy, eFlagsReg cr)\n@@ -11537,1 +11767,3 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && n->in(2)->bottom_type()->is_int()->is_con());\n+  predicate(!((ClearArrayNode*)n)->is_large() &&\n+               (UseAVX > 2 && VM_Version::supports_avx512vlbw() &&\n+                 n->in(2)->bottom_type()->is_int()->is_con()));\n@@ -11539,1 +11771,1 @@\n-  effect(TEMP tmp, TEMP zero, KILL cr);\n+  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n@@ -11542,1 +11774,1 @@\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister);\n+   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n@@ -11549,1 +11781,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n@@ -11557,1 +11789,16 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareL_evex(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n+                              eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, $ktmp$$KRegister);\n@@ -11564,1 +11811,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n@@ -11572,1 +11819,16 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareU_evex(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n+                              eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare char[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, $ktmp$$KRegister);\n@@ -11579,1 +11841,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n@@ -11587,1 +11849,16 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareLU_evex(eDIRegP str1, eCXRegI cnt1, eSIRegP str2, eDXRegI cnt2,\n+                               eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, $ktmp$$KRegister);\n@@ -11594,1 +11871,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n@@ -11602,1 +11879,16 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareUL_evex(eSIRegP str1, eDXRegI cnt1, eDIRegP str2, eCXRegI cnt2,\n+                               eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str2$$Register, $str1$$Register,\n+                      $cnt2$$Register, $cnt1$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, $ktmp$$KRegister);\n@@ -11610,0 +11902,1 @@\n+  predicate(UseAVX <= 2);\n@@ -11617,1 +11910,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, knoreg);\n@@ -11623,0 +11916,17 @@\n+instruct string_equals_evex(eDIRegP str1, eSIRegP str2, eCXRegI cnt, eAXRegI result,\n+                            regD tmp1, regD tmp2, kReg ktmp, eBXRegI tmp3, eFlagsReg cr) %{\n+  predicate(UseAVX > 2);\n+  match(Set result (StrEquals (Binary str1 str2) cnt));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n+\n+  format %{ \"String Equals $str1,$str2,$cnt -> $result    \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n+  ins_encode %{\n+    __ arrays_equals(false, $str1$$Register, $str2$$Register,\n+                     $cnt$$Register, $result$$Register, $tmp3$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n+  %}\n+\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\n@@ -11786,1 +12096,1 @@\n-  predicate(((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  predicate(UseAVX <= 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n@@ -11795,1 +12105,18 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct array_equalsB_evex(eDIRegP ary1, eSIRegP ary2, eAXRegI result,\n+                       regD tmp1, regD tmp2, kReg ktmp, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  match(Set result (AryEq ary1 ary2));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+  \/\/ins_cost(300);\n+\n+  format %{ \"Array Equals byte[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n+  ins_encode %{\n+    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n+                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11803,1 +12130,1 @@\n-  predicate(((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  predicate(UseAVX <= 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n@@ -11812,1 +12139,18 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct array_equalsC_evex(eDIRegP ary1, eSIRegP ary2, eAXRegI result,\n+                            regD tmp1, regD tmp2, kReg ktmp, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  match(Set result (AryEq ary1 ary2));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+  \/\/ins_cost(300);\n+\n+  format %{ \"Array Equals char[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n+  ins_encode %{\n+    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n+                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, $ktmp$$KRegister);\n@@ -11820,0 +12164,1 @@\n+  predicate(UseAVX <= 2);\n@@ -11827,1 +12172,17 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, knoreg, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct has_negatives_evex(eSIRegP ary1, eCXRegI len, eAXRegI result,\n+                           regD tmp1, regD tmp2, kReg ktmp1, kReg ktmp2, eBXRegI tmp3, eFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2);\n+  match(Set result (HasNegatives ary1 len));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp1, TEMP ktmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n+\n+  format %{ \"has negatives byte[] $ary1,$len -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n+  ins_encode %{\n+    __ has_negatives($ary1$$Register, $len$$Register,\n+                     $result$$Register, $tmp3$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11832,0 +12193,1 @@\n+\n@@ -11833,2 +12195,3 @@\n-instruct string_compress(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2, regD tmp3, regD tmp4,\n-                         eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n+instruct string_compress(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2,\n+                         regD tmp3, regD tmp4, eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n+  predicate(UseAVX <= 2);\n@@ -11842,1 +12205,18 @@\n-                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register);\n+                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n+                           knoreg, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compress_evex(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2,\n+                              regD tmp3, regD tmp4, kReg ktmp1, kReg ktmp2, eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n+  predicate(UseAVX > 2);\n+  match(Set result (StrCompressedCopy src (Binary dst len)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ktmp1, TEMP ktmp2, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n+\n+  format %{ \"String Compress $src,$dst -> $result    \/\/ KILL RAX, RCX, RDX\" %}\n+  ins_encode %{\n+    __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,\n+                           $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n+                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n+                           $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11850,0 +12230,1 @@\n+  predicate(UseAVX <= 2);\n@@ -11856,1 +12237,15 @@\n-                          $tmp1$$XMMRegister, $tmp2$$Register);\n+                          $tmp1$$XMMRegister, $tmp2$$Register, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_inflate_evex(Universe dummy, eSIRegP src, eDIRegP dst, eDXRegI len,\n+                             regD tmp1, kReg ktmp, eCXRegI tmp2, eFlagsReg cr) %{\n+  predicate(UseAVX > 2);\n+  match(Set dummy (StrInflatedCopy src (Binary dst len)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n+\n+  format %{ \"String Inflate $src,$dst    \/\/ KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,\n+                          $tmp1$$XMMRegister, $tmp2$$Register, $ktmp$$KRegister);\n@@ -12284,2 +12679,4 @@\n-instruct jmpLoopEnd_and_restoreMask(cmpOp cop, eFlagsReg cr, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEnd_and_restoreMask(cmpOp cop, kReg_K1 ktmp, eFlagsReg cr, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12287,1 +12684,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12296,1 +12693,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12302,2 +12699,4 @@\n-instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, eFlagsRegU cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, kReg_K1 ktmp, eFlagsRegU cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12305,1 +12704,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12314,1 +12713,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12319,2 +12718,4 @@\n-instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, eFlagsRegUCF cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, kReg_K1 ktmp, eFlagsRegUCF cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12322,1 +12723,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12331,1 +12732,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":446,"deletions":45,"binary":false,"changes":491,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -427,0 +427,10 @@\n+\n+  if (Matcher::has_predicated_vectors()) {\n+    \/\/ Post-loop multi-versioning expects mask to be present in K1 register, till the time\n+    \/\/ its fixed, RA should not be allocting K1 register, this shall prevent any accidental\n+    \/\/ curruption of value held in K1 register.\n+    if (PostLoopMultiversioning) {\n+      const_cast<RegMask*>(&_VECTMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()));\n+      const_cast<RegMask*>(&_VECTMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()->next()));\n+    }\n+  }\n@@ -1019,0 +1029,1 @@\n+  rc_kreg,\n@@ -1033,0 +1044,2 @@\n+  if (r->is_KRegister()) return rc_kreg;\n+\n@@ -1146,1 +1159,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() != NULL && bottom_type()->isa_vectmask() == NULL) {\n@@ -1276,0 +1289,18 @@\n+#endif\n+        }\n+      }\n+      return 0;\n+    } else if (dst_first_rc == rc_kreg) {\n+      \/\/ mem -> kreg\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        int offset = ra_->reg2offset(src_first);\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), Address(rsp, offset));\n+#ifndef PRODUCT\n+        } else {\n+          st->print(\"kmovq   %s, [rsp + #%d]\\t# spill\",\n+                     Matcher::regName[dst_first],\n+                     offset);\n@@ -1381,0 +1412,17 @@\n+    } else if (dst_first_rc == rc_kreg) {\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));\n+  #ifndef PRODUCT\n+        } else {\n+           st->print(\"kmovq   %s, %s\\t# spill\",\n+                       Matcher::regName[dst_first],\n+                       Matcher::regName[src_first]);\n+  #endif\n+        }\n+      }\n+      Unimplemented();\n+      return 0;\n@@ -1481,0 +1529,59 @@\n+    } else if (dst_first_rc == rc_kreg) {\n+      assert(false, \"Illegal spilling\");\n+      return 0;\n+    }\n+  } else if (src_first_rc == rc_kreg) {\n+    if (dst_first_rc == rc_stack) {\n+      \/\/ mem -> kreg\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        int offset = ra_->reg2offset(dst_first);\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmov(Address(rsp, offset), as_KRegister(Matcher::_regEncode[src_first]));\n+#ifndef PRODUCT\n+        } else {\n+          st->print(\"kmovq   [rsp + #%d] , %s\\t# spill\",\n+                     offset,\n+                     Matcher::regName[src_first]);\n+#endif\n+        }\n+      }\n+      return 0;\n+    } else if (dst_first_rc == rc_int) {\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmov(as_Register(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n+#ifndef PRODUCT\n+        } else {\n+         st->print(\"kmovq   %s, %s\\t# spill\",\n+                     Matcher::regName[dst_first],\n+                     Matcher::regName[src_first]);\n+#endif\n+        }\n+      }\n+      Unimplemented();\n+      return 0;\n+    } else if (dst_first_rc == rc_kreg) {\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmov(as_KRegister(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n+#ifndef PRODUCT\n+        } else {\n+         st->print(\"kmovq   %s, %s\\t# spill\",\n+                     Matcher::regName[dst_first],\n+                     Matcher::regName[src_first]);\n+#endif\n+        }\n+      }\n+      return 0;\n+    } else if (dst_first_rc == rc_float) {\n+      assert(false, \"Illegal spill\");\n+      return 0;\n@@ -1670,1 +1777,1 @@\n-  return true;\n+  return false;\n@@ -3198,0 +3305,12 @@\n+\/\/ Int Immediate: 2^n-1, postive\n+operand immI_Pow2M1()\n+%{\n+  predicate((n->get_int() > 0)\n+            && is_power_of_2(n->get_int() + 1));\n+  match(ConI);\n+\n+  op_cost(20);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -3301,0 +3420,66 @@\n+operand kReg()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K1()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K1));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K2()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K2));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K3()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K3));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K4()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K4));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K5()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K5));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K6()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K6));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K7()\n+%{\n+  constraint(ALLOC_IN_RC(vectmask_reg_K7));\n+  match(RegVectMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n@@ -4711,1 +4896,0 @@\n-\n@@ -9175,0 +9359,15 @@\n+\/\/ Can skip int2long conversions after AND with small bitmask\n+instruct convI2LAndI_reg_immIbitmask(rRegL dst, rRegI src,  immI_Pow2M1 mask, rRegI tmp, rFlagsReg cr)\n+%{\n+  predicate(VM_Version::supports_bmi2());\n+  ins_cost(125);\n+  effect(TEMP tmp, KILL cr);\n+  match(Set dst (ConvI2L (AndI src mask)));\n+  format %{ \"bzhiq $dst, $src, $mask \\t# using $tmp as TEMP, int &  immI_Pow2M1 -> long\" %}\n+  ins_encode %{\n+    __ movl($tmp$$Register, exact_log2($mask$$constant + 1));\n+    __ bzhiq($dst$$Register, $src$$Register, $tmp$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n@@ -10763,3 +10962,2 @@\n-\n-\/\/ =======================================================================\n-\/\/ fast clearing of an array\n+\/\/ Fast clearing of an array\n+\/\/ Small ClearArray non-AVX512.\n@@ -10769,1 +10967,2 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && !n->in(2)->bottom_type()->is_long()->is_con());\n+  predicate(!((ClearArrayNode*)n)->is_large() &&\n+              (UseAVX <= 2 || !VM_Version::supports_avx512vlbw()));\n@@ -10820,1 +11019,1 @@\n-                 $tmp$$XMMRegister, false);\n+                 $tmp$$XMMRegister, false, knoreg);\n@@ -10825,0 +11024,63 @@\n+\/\/ Small ClearArray AVX512 non-constant length.\n+instruct rep_stos_evex(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegI zero,\n+                       Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(!((ClearArrayNode*)n)->is_large() &&\n+               UseAVX > 2 && VM_Version::supports_avx512vlbw() &&\n+               !n->in(2)->bottom_type()->is_long()->is_con());\n+  match(Set dummy (ClearArray cnt base));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+\n+  format %{ $$template\n+    $$emit$$\"xorq    rax, rax\\t# ClearArray:\\n\\t\"\n+    $$emit$$\"cmp     InitArrayShortSize,rcx\\n\\t\"\n+    $$emit$$\"jg      LARGE\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"js      DONE\\t# Zero length\\n\\t\"\n+    $$emit$$\"mov     rax,(rdi,rcx,8)\\t# LOOP\\n\\t\"\n+    $$emit$$\"dec     rcx\\n\\t\"\n+    $$emit$$\"jge     LOOP\\n\\t\"\n+    $$emit$$\"jmp     DONE\\n\\t\"\n+    $$emit$$\"# LARGE:\\n\\t\"\n+    if (UseFastStosb) {\n+       $$emit$$\"shlq    rcx,3\\t# Convert doublewords to bytes\\n\\t\"\n+       $$emit$$\"rep     stosb\\t# Store rax to *rdi++ while rcx--\\n\\t\"\n+    } else if (UseXMMForObjInit) {\n+       $$emit$$\"mov     rdi,rax\\n\\t\"\n+       $$emit$$\"vpxor   ymm0,ymm0,ymm0\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu ymm0,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\\n\\t\"\n+    }\n+    $$emit$$\"# DONE\"\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n+                 $tmp$$XMMRegister, false, $ktmp$$KRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Large ClearArray non-AVX512.\n@@ -10828,1 +11090,1 @@\n-  predicate(((ClearArrayNode*)n)->is_large());\n+  predicate(UseAVX <=2 && ((ClearArrayNode*)n)->is_large());\n@@ -10870,1 +11132,52 @@\n-                 $tmp$$XMMRegister, true);\n+                 $tmp$$XMMRegister, true, knoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Large ClearArray AVX512.\n+instruct rep_stos_large_evex(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegI zero,\n+                             Universe dummy, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((ClearArrayNode*)n)->is_large());\n+  match(Set dummy (ClearArray cnt base));\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n+\n+  format %{ $$template\n+    if (UseFastStosb) {\n+       $$emit$$\"xorq    rax, rax\\t# ClearArray:\\n\\t\"\n+       $$emit$$\"shlq    rcx,3\\t# Convert doublewords to bytes\\n\\t\"\n+       $$emit$$\"rep     stosb\\t# Store rax to *rdi++ while rcx--\"\n+    } else if (UseXMMForObjInit) {\n+       $$emit$$\"mov     rdi,rax\\t# ClearArray:\\n\\t\"\n+       $$emit$$\"vpxor   ymm0,ymm0,ymm0\\n\\t\"\n+       $$emit$$\"jmpq    L_zero_64_bytes\\n\\t\"\n+       $$emit$$\"# L_loop:\\t# 64-byte LOOP\\n\\t\"\n+       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n+       $$emit$$\"vmovdqu ymm0,0x20(rax)\\n\\t\"\n+       $$emit$$\"add     0x40,rax\\n\\t\"\n+       $$emit$$\"# L_zero_64_bytes:\\n\\t\"\n+       $$emit$$\"sub     0x8,rcx\\n\\t\"\n+       $$emit$$\"jge     L_loop\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jl      L_tail\\n\\t\"\n+       $$emit$$\"vmovdqu ymm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x20,rax\\n\\t\"\n+       $$emit$$\"sub     0x4,rcx\\n\\t\"\n+       $$emit$$\"# L_tail:\\t# Clearing tail bytes\\n\\t\"\n+       $$emit$$\"add     0x4,rcx\\n\\t\"\n+       $$emit$$\"jle     L_end\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"# L_sloop:\\t# 8-byte short loop\\n\\t\"\n+       $$emit$$\"vmovq   xmm0,(rax)\\n\\t\"\n+       $$emit$$\"add     0x8,rax\\n\\t\"\n+       $$emit$$\"dec     rcx\\n\\t\"\n+       $$emit$$\"jge     L_sloop\\n\\t\"\n+       $$emit$$\"# L_end:\\n\\t\"\n+    } else {\n+       $$emit$$\"xorq    rax, rax\\t# ClearArray:\\n\\t\"\n+       $$emit$$\"rep     stosq\\t# Store rax to *rdi++ while rcx--\"\n+    }\n+  %}\n+  ins_encode %{\n+    __ clear_mem($base$$Register, $cnt$$Register, $zero$$Register,\n+                 $tmp$$XMMRegister, true, $ktmp$$KRegister);\n@@ -10875,1 +11188,2 @@\n-instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rRegI zero, Universe dummy, rFlagsReg cr)\n+\/\/ Small ClearArray AVX512 constant length.\n+instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rRegI zero, kReg ktmp, Universe dummy, rFlagsReg cr)\n@@ -10877,1 +11191,3 @@\n-  predicate(!((ClearArrayNode*)n)->is_large() && n->in(2)->bottom_type()->is_long()->is_con());\n+  predicate(!((ClearArrayNode*)n)->is_large() &&\n+              (UseAVX > 2 && VM_Version::supports_avx512vlbw() &&\n+               n->in(2)->bottom_type()->is_long()->is_con()));\n@@ -10879,1 +11195,1 @@\n-  effect(TEMP tmp, TEMP zero, KILL cr);\n+  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n@@ -10882,1 +11198,1 @@\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister);\n+   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n@@ -10890,1 +11206,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n@@ -10898,1 +11214,17 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareL_evex(rdi_RegP str1, rcx_RegI cnt1, rsi_RegP str2, rdx_RegI cnt2,\n+                              rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, $ktmp$$KRegister);\n@@ -10906,1 +11238,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n@@ -10914,1 +11246,17 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareU_evex(rdi_RegP str1, rcx_RegI cnt1, rsi_RegP str2, rdx_RegI cnt2,\n+                              rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare char[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, $ktmp$$KRegister);\n@@ -10922,1 +11270,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n@@ -10930,1 +11278,17 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareLU_evex(rdi_RegP str1, rcx_RegI cnt1, rsi_RegP str2, rdx_RegI cnt2,\n+                               rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, $ktmp$$KRegister);\n@@ -10938,1 +11302,1 @@\n-  predicate(((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n+  predicate(UseAVX <= 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n@@ -10946,1 +11310,17 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_compareUL_evex(rsi_RegP str1, rdx_RegI cnt1, rdi_RegP str2, rcx_RegI cnt2,\n+                               rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL);\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare byte[] $str1,$cnt1,$str2,$cnt2 -> $result   \/\/ KILL $tmp1\" %}\n+  ins_encode %{\n+    __ string_compare($str2$$Register, $str1$$Register,\n+                      $cnt2$$Register, $cnt1$$Register, $result$$Register,\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, $ktmp$$KRegister);\n@@ -11121,0 +11501,1 @@\n+  predicate(UseAVX <= 2);\n@@ -11128,1 +11509,17 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_equals_evex(rdi_RegP str1, rsi_RegP str2, rcx_RegI cnt, rax_RegI result,\n+                           legRegD tmp1, legRegD tmp2, kReg ktmp, rbx_RegI tmp3, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2);\n+  match(Set result (StrEquals (Binary str1 str2) cnt));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n+\n+  format %{ \"String Equals $str1,$str2,$cnt -> $result    \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n+  ins_encode %{\n+    __ arrays_equals(false, $str1$$Register, $str2$$Register,\n+                     $cnt$$Register, $result$$Register, $tmp3$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11137,1 +11534,1 @@\n-  predicate(((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  predicate(UseAVX <= 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n@@ -11145,1 +11542,17 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct array_equalsB_evex(rdi_RegP ary1, rsi_RegP ary2, rax_RegI result,\n+                            legRegD tmp1, legRegD tmp2, kReg ktmp, rcx_RegI tmp3, rbx_RegI tmp4, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::LL);\n+  match(Set result (AryEq ary1 ary2));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+\n+  format %{ \"Array Equals byte[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n+  ins_encode %{\n+    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n+                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11153,1 +11566,1 @@\n-  predicate(((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  predicate(UseAVX <= 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n@@ -11161,1 +11574,17 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct array_equalsC_evex(rdi_RegP ary1, rsi_RegP ary2, rax_RegI result,\n+                            legRegD tmp1, legRegD tmp2, kReg ktmp, rcx_RegI tmp3, rbx_RegI tmp4, rFlagsReg cr)\n+%{\n+  predicate(UseAVX > 2 && ((AryEqNode*)n)->encoding() == StrIntrinsicNode::UU);\n+  match(Set result (AryEq ary1 ary2));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+\n+  format %{ \"Array Equals char[] $ary1,$ary2 -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3, $tmp4\" %}\n+  ins_encode %{\n+    __ arrays_equals(true, $ary1$$Register, $ary2$$Register,\n+                     $tmp3$$Register, $result$$Register, $tmp4$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, $ktmp$$KRegister);\n@@ -11167,1 +11596,1 @@\n-                       legRegD tmp1, legRegD tmp2, rbx_RegI tmp3, rFlagsReg cr)\n+                       legRegD tmp1, legRegD tmp2, rbx_RegI tmp3, rFlagsReg cr,)\n@@ -11169,0 +11598,1 @@\n+  predicate(UseAVX <= 2);\n@@ -11176,1 +11606,17 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, knoreg, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct has_negatives_evex(rsi_RegP ary1, rcx_RegI len, rax_RegI result,\n+                            legRegD tmp1, legRegD tmp2, kReg ktmp1, kReg ktmp2, rbx_RegI tmp3, rFlagsReg cr,)\n+%{\n+  predicate(UseAVX > 2);\n+  match(Set result (HasNegatives ary1 len));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp1, TEMP ktmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n+\n+  format %{ \"has negatives byte[] $ary1,$len -> $result   \/\/ KILL $tmp1, $tmp2, $tmp3\" %}\n+  ins_encode %{\n+    __ has_negatives($ary1$$Register, $len$$Register,\n+                     $result$$Register, $tmp3$$Register,\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11182,2 +11628,3 @@\n-instruct string_compress(rsi_RegP src, rdi_RegP dst, rdx_RegI len, legRegD tmp1, legRegD tmp2, legRegD tmp3, legRegD tmp4,\n-                         rcx_RegI tmp5, rax_RegI result, rFlagsReg cr) %{\n+instruct string_compress(rsi_RegP src, rdi_RegP dst, rdx_RegI len, legRegD tmp1, legRegD tmp2, legRegD tmp3,\n+                         legRegD tmp4, rcx_RegI tmp5, rax_RegI result, rFlagsReg cr) %{\n+  predicate(UseAVX <= 2);\n@@ -11185,1 +11632,2 @@\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst,\n+         USE_KILL len, KILL tmp5, KILL cr);\n@@ -11191,1 +11639,2 @@\n-                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register);\n+                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n+                           knoreg, knoreg);\n@@ -11196,0 +11645,16 @@\n+instruct string_compress_evex(rsi_RegP src, rdi_RegP dst, rdx_RegI len, legRegD tmp1, legRegD tmp2, legRegD tmp3,\n+                              legRegD tmp4, kReg ktmp1, kReg ktmp2, rcx_RegI tmp5, rax_RegI result, rFlagsReg cr) %{\n+  predicate(UseAVX > 2);\n+  match(Set result (StrCompressedCopy src (Binary dst len)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ktmp1, TEMP ktmp2, USE_KILL src, USE_KILL dst,\n+         USE_KILL len, KILL tmp5, KILL cr);\n+\n+  format %{ \"String Compress $src,$dst -> $result    \/\/ KILL RAX, RCX, RDX\" %}\n+  ins_encode %{\n+    __ char_array_compress($src$$Register, $dst$$Register, $len$$Register,\n+                           $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n+                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n+                           $ktmp1$$KRegister, $ktmp2$$KRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -11199,0 +11664,1 @@\n+  predicate(UseAVX <= 2);\n@@ -11205,1 +11671,15 @@\n-                          $tmp1$$XMMRegister, $tmp2$$Register);\n+                          $tmp1$$XMMRegister, $tmp2$$Register, knoreg);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct string_inflate_evex(Universe dummy, rsi_RegP src, rdi_RegP dst, rdx_RegI len,\n+                             legRegD tmp1, kReg ktmp, rcx_RegI tmp2, rFlagsReg cr) %{\n+  predicate(UseAVX > 2);\n+  match(Set dummy (StrInflatedCopy src (Binary dst len)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n+\n+  format %{ \"String Inflate $src,$dst    \/\/ KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    __ byte_array_inflate($src$$Register, $dst$$Register, $len$$Register,\n+                          $tmp1$$XMMRegister, $tmp2$$Register, $ktmp$$KRegister);\n@@ -11997,1 +12477,3 @@\n-instruct jmpLoopEnd_and_restoreMask(cmpOp cop, rFlagsReg cr, label labl)\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEnd_and_restoreMask(cmpOp cop, kReg_K1 ktmp, rFlagsReg cr, label labl)\n@@ -11999,1 +12481,1 @@\n-  predicate(n->has_vector_mask_set());\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12001,1 +12483,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12010,1 +12492,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12016,2 +12498,4 @@\n-instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, rFlagsRegU cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, kReg_K1 ktmp, rFlagsRegU cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12019,1 +12503,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12028,1 +12512,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12033,2 +12517,4 @@\n-instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, rFlagsRegUCF cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, kReg_K1 ktmp, rFlagsRegUCF cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12036,1 +12522,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12045,1 +12531,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":533,"deletions":47,"binary":false,"changes":580,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2015, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -122,10 +122,0 @@\n-size_t SharedRuntime::trampoline_size() {\n-  ShouldNotCallThis();\n-  return 0;\n-}\n-\n-void SharedRuntime::generate_trampoline(MacroAssembler *masm, address destination) {\n-  ShouldNotCallThis();\n-  return;\n-}\n-\n","filename":"src\/hotspot\/cpu\/zero\/sharedRuntime_zero.cpp","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -786,0 +786,1 @@\n+       !strcmp(_matrule->_rChild->_opType,\"StrInflatedCopy\") ||\n@@ -3827,1 +3828,0 @@\n-    \"MinV\",\"MaxV\",\n@@ -3969,1 +3969,1 @@\n-         strcmp(opType,\"RegVMask\")==0 ||\n+         strcmp(opType,\"RegVectMask\")==0 ||\n@@ -4178,1 +4178,0 @@\n-    \"MinV\",\"MaxV\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -103,3 +103,2 @@\n-static ModuleEntry* get_module_entry(jobject module, TRAPS) {\n-  oop m = JNIHandles::resolve_non_null(module);\n-  if (!java_lang_Module::is_instance(m)) {\n+static ModuleEntry* get_module_entry(Handle module, TRAPS) {\n+  if (!java_lang_Module::is_instance(module())) {\n@@ -109,1 +108,1 @@\n-  return java_lang_Module::module_entry(m);\n+  return java_lang_Module::module_entry(module());\n@@ -113,1 +112,1 @@\n-static PackageEntry* get_locked_package_entry(ModuleEntry* module_entry, const char* package_name, int len, TRAPS) {\n+static PackageEntry* get_locked_package_entry(ModuleEntry* module_entry, const char* package_name, int len) {\n@@ -124,3 +123,1 @@\n-static PackageEntry* get_package_entry_by_name(Symbol* package,\n-                                               Handle h_loader,\n-                                               TRAPS) {\n+static PackageEntry* get_package_entry_by_name(Symbol* package, Handle h_loader) {\n@@ -136,2 +133,2 @@\n-bool Modules::is_package_defined(Symbol* package, Handle h_loader, TRAPS) {\n-  PackageEntry* res = get_package_entry_by_name(package, h_loader, CHECK_false);\n+bool Modules::is_package_defined(Symbol* package, Handle h_loader) {\n+  PackageEntry* res = get_package_entry_by_name(package, h_loader);\n@@ -275,1 +272,1 @@\n-void Modules::define_module(jobject module, jboolean is_open, jstring version,\n+void Modules::define_module(Handle module, jboolean is_open, jstring version,\n@@ -280,1 +277,1 @@\n-  if (module == NULL) {\n+  if (module.is_null()) {\n@@ -284,2 +281,1 @@\n-  Handle module_handle(THREAD, JNIHandles::resolve_non_null(module));\n-  if (!java_lang_Module::is_instance(module_handle())) {\n+  if (!java_lang_Module::is_instance(module())) {\n@@ -291,1 +287,1 @@\n-  char* module_name = get_module_name(module_handle(), module_name_len, CHECK);\n+  char* module_name = get_module_name(module(), module_name_len, CHECK);\n@@ -304,1 +300,1 @@\n-    define_javabase_module(module_handle, version, location, packages_h, num_packages, CHECK);\n+    define_javabase_module(module, version, location, packages_h, num_packages, CHECK);\n@@ -308,1 +304,1 @@\n-  oop loader = java_lang_Module::loader(module_handle());\n+  oop loader = java_lang_Module::loader(module());\n@@ -405,1 +401,1 @@\n-        ModuleEntry* module_entry = module_table->locked_create_entry(module_handle,\n+        ModuleEntry* module_entry = module_table->locked_create_entry(module,\n@@ -422,1 +418,1 @@\n-        java_lang_Module::set_module_entry(module_handle(), module_entry);\n+        java_lang_Module::set_module_entry(module(), module_entry);\n@@ -456,1 +452,1 @@\n-    ClassLoader::add_to_exploded_build_list(module_symbol, CHECK);\n+    ClassLoader::add_to_exploded_build_list(THREAD, module_symbol);\n@@ -483,1 +479,1 @@\n-void Modules::define_archived_modules(jobject platform_loader, jobject system_loader, TRAPS) {\n+void Modules::define_archived_modules(Handle h_platform_loader, Handle h_system_loader, TRAPS) {\n@@ -497,1 +493,1 @@\n-  if (platform_loader == NULL) {\n+  if (h_platform_loader.is_null()) {\n@@ -501,1 +497,1 @@\n-  if (system_loader == NULL) {\n+  if (h_system_loader.is_null()) {\n@@ -505,1 +501,0 @@\n-  Handle h_platform_loader(THREAD, JNIHandles::resolve_non_null(platform_loader));\n@@ -509,1 +504,0 @@\n-  Handle h_system_loader(THREAD, JNIHandles::resolve_non_null(system_loader));\n@@ -522,1 +516,1 @@\n-void Modules::set_bootloader_unnamed_module(jobject module, TRAPS) {\n+void Modules::set_bootloader_unnamed_module(Handle module, TRAPS) {\n@@ -525,1 +519,1 @@\n-  if (module == NULL) {\n+  if (module.is_null()) {\n@@ -528,2 +522,1 @@\n-  Handle module_handle(THREAD, JNIHandles::resolve(module));\n-  if (!java_lang_Module::is_instance(module_handle())) {\n+  if (!java_lang_Module::is_instance(module())) {\n@@ -535,1 +528,1 @@\n-  oop name = java_lang_Module::name(module_handle());\n+  oop name = java_lang_Module::name(module());\n@@ -542,1 +535,1 @@\n-  oop loader = java_lang_Module::loader(module_handle());\n+  oop loader = java_lang_Module::loader(module());\n@@ -554,1 +547,1 @@\n-  unnamed_module->set_module(boot_loader_data->add_handle(module_handle));\n+  unnamed_module->set_module(boot_loader_data->add_handle(module));\n@@ -556,1 +549,1 @@\n-  java_lang_Module::set_module_entry(module_handle(), unnamed_module);\n+  java_lang_Module::set_module_entry(module(), unnamed_module);\n@@ -559,1 +552,1 @@\n-void Modules::add_module_exports(jobject from_module, jstring package_name, jobject to_module, TRAPS) {\n+void Modules::add_module_exports(Handle from_module, jstring package_name, Handle to_module, TRAPS) {\n@@ -566,1 +559,1 @@\n-  if (from_module == NULL) {\n+  if (from_module.is_null()) {\n@@ -580,1 +573,1 @@\n-  if (to_module == NULL) {\n+  if (to_module.is_null()) {\n@@ -598,1 +591,1 @@\n-    package_entry = get_locked_package_entry(from_module_entry, pkg, package_len, CHECK);\n+    package_entry = get_locked_package_entry(from_module_entry, pkg, package_len);\n@@ -626,2 +619,2 @@\n-void Modules::add_module_exports_qualified(jobject from_module, jstring package,\n-                                           jobject to_module, TRAPS) {\n+void Modules::add_module_exports_qualified(Handle from_module, jstring package,\n+                                           Handle to_module, TRAPS) {\n@@ -629,1 +622,1 @@\n-  if (to_module == NULL) {\n+  if (to_module.is_null()) {\n@@ -636,1 +629,1 @@\n-void Modules::add_reads_module(jobject from_module, jobject to_module, TRAPS) {\n+void Modules::add_reads_module(Handle from_module, Handle to_module, TRAPS) {\n@@ -638,1 +631,1 @@\n-  if (from_module == NULL) {\n+  if (from_module.is_null()) {\n@@ -650,1 +643,1 @@\n-  if (to_module != NULL) {\n+  if (!to_module.is_null()) {\n@@ -720,1 +713,1 @@\n-jobject Modules::get_named_module(Handle h_loader, const char* package_name, TRAPS) {\n+oop Modules::get_named_module(Handle h_loader, const char* package_name) {\n@@ -732,1 +725,1 @@\n-    get_package_entry_by_name(package_sym, h_loader, THREAD);\n+    get_package_entry_by_name(package_sym, h_loader);\n@@ -736,1 +729,1 @@\n-    return JNIHandles::make_local(THREAD, module_entry->module());\n+    return module_entry->module();\n@@ -742,1 +735,1 @@\n-void Modules::add_module_exports_to_all_unnamed(jobject module, jstring package_name, TRAPS) {\n+void Modules::add_module_exports_to_all_unnamed(Handle module, jstring package_name, TRAPS) {\n@@ -744,1 +737,1 @@\n-  if (module == NULL) {\n+  if (module.is_null()) {\n@@ -769,1 +762,1 @@\n-    package_entry = get_locked_package_entry(module_entry, pkg, pkg_len, CHECK);\n+    package_entry = get_locked_package_entry(module_entry, pkg, pkg_len);\n","filename":"src\/hotspot\/share\/classfile\/modules.cpp","additions":42,"deletions":49,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -2093,1 +2093,1 @@\n-    \/\/ If we are locking an unescaped object, the lock\/unlock is unnecessary\n+    \/\/ If we are locking an non-escaped object, the lock\/unlock is unnecessary\n@@ -2261,1 +2261,1 @@\n-    \/\/ If we are unlocking an unescaped object, the lock\/unlock is unnecessary.\n+    \/\/ If we are unlocking an non-escaped object, the lock\/unlock is unnecessary.\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -620,2 +620,3 @@\n-  virtual void clone_jvms(Compile* C) {\n-    if (C->needs_clone_jvms() && jvms() != NULL) {\n+  virtual bool needs_clone_jvms(Compile* C) { return C->needs_clone_jvms(); }\n+  void clone_jvms(Compile* C) {\n+    if ((jvms() != NULL) && needs_clone_jvms(C)) {\n@@ -741,5 +742,2 @@\n-  virtual void  clone_jvms(Compile* C) {\n-    if ((jvms() != NULL) && is_boxing_method()) {\n-      set_jvms(jvms()->clone_deep(C));\n-      jvms()->set_map_deep(this);\n-    }\n+  virtual bool needs_clone_jvms(Compile* C) {\n+    return is_boxing_method() || CallNode::needs_clone_jvms(C);\n@@ -770,5 +768,2 @@\n-  virtual void clone_jvms(Compile* C) {\n-    if ((jvms() != NULL) && IncrementalInlineVirtual) {\n-      set_jvms(jvms()->clone_deep(C));\n-      jvms()->set_map_deep(this);\n-    }\n+  virtual bool needs_clone_jvms(Compile* C) {\n+    return IncrementalInlineVirtual || CallNode::needs_clone_jvms(C);\n@@ -946,6 +941,1 @@\n-  virtual void  clone_jvms(Compile* C) {\n-    if (jvms() != NULL) {\n-      set_jvms(jvms()->clone_deep(C));\n-      jvms()->set_map_deep(this);\n-    }\n-  }\n+  virtual bool needs_clone_jvms(Compile* C) { return true; }\n@@ -1165,6 +1155,1 @@\n-  virtual void  clone_jvms(Compile* C) {\n-    if (jvms() != NULL) {\n-      set_jvms(jvms()->clone_deep(C));\n-      jvms()->set_map_deep(this);\n-    }\n-  }\n+  virtual bool needs_clone_jvms(Compile* C) { return true; }\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":9,"deletions":24,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2349,0 +2349,2 @@\n+ check_no_dead_use();\n+\n@@ -2364,0 +2366,19 @@\n+#ifdef ASSERT\n+void Compile::check_no_dead_use() const {\n+  ResourceMark rm;\n+  Unique_Node_List wq;\n+  wq.push(root());\n+  for (uint i = 0; i < wq.size(); ++i) {\n+    Node* n = wq.at(i);\n+    for (DUIterator_Fast jmax, j = n->fast_outs(jmax); j < jmax; j++) {\n+      Node* u = n->fast_out(j);\n+      if (u->outcnt() == 0 && !u->is_Con()) {\n+        u->dump();\n+        fatal(\"no reachable node should have no use\");\n+      }\n+      wq.push(u);\n+    }\n+  }\n+}\n+#endif\n+\n@@ -2423,1 +2444,1 @@\n-  if (!is_vector_bitwise_op(n)) {\n+  if (n->bottom_type()->isa_vectmask() || !is_vector_bitwise_op(n)) {\n@@ -2737,1 +2758,0 @@\n-    print_method(PHASE_AFTER_MATCHING, 3);\n@@ -3498,1 +3518,1 @@\n-    assert(!n->as_Loop()->is_transformed_long_loop() || _loop_opts_cnt == 0, \"should have been turned into a counted loop\");\n+    assert(!n->as_Loop()->is_transformed_long_inner_loop() || _loop_opts_cnt == 0, \"should have been turned into a counted loop\");\n@@ -4166,1 +4186,1 @@\n-Node* Compile::constrained_convI2L(PhaseGVN* phase, Node* value, const TypeInt* itype, Node* ctrl) {\n+Node* Compile::constrained_convI2L(PhaseGVN* phase, Node* value, const TypeInt* itype, Node* ctrl, bool carry_dependency) {\n@@ -4169,1 +4189,1 @@\n-    value = new CastIINode(value, itype, false, true \/* range check dependency *\/);\n+    value = new CastIINode(value, itype, carry_dependency, true \/* range check dependency *\/);\n@@ -4670,1 +4690,1 @@\n-void Compile::print_method(CompilerPhaseType cpt, const char *name, int level, int idx) {\n+void Compile::print_method(CompilerPhaseType cpt, const char *name, int level) {\n@@ -4692,1 +4712,1 @@\n-  print_method(cpt, output, level, idx);\n+  print_method(cpt, output, level);\n@@ -4758,1 +4778,1 @@\n-  Compile::current()->print_method(PHASE_DEBUG, 0, 0);\n+  Compile::current()->print_method(PHASE_DEBUG, 0);\n@@ -4781,1 +4801,1 @@\n-  _debug_file_printer->print_method(phase_name, 0);\n+  _debug_file_printer->print(phase_name, (Node*)C->root());\n@@ -4791,1 +4811,1 @@\n-  _debug_network_printer->print_method(phase_name, 0);\n+  _debug_network_printer->print(phase_name, (Node*)C->root());\n@@ -4798,0 +4818,24 @@\n+\n+Node* Compile::narrow_value(BasicType bt, Node* value, const Type* type, PhaseGVN* phase, bool transform_res) {\n+  if (type != NULL && phase->type(value)->higher_equal(type)) {\n+    return value;\n+  }\n+  Node* result = NULL;\n+  if (bt == T_BYTE) {\n+    result = phase->transform(new LShiftINode(value, phase->intcon(24)));\n+    result = new RShiftINode(result, phase->intcon(24));\n+  } else if (bt == T_BOOLEAN) {\n+    result = new AndINode(value, phase->intcon(0xFF));\n+  } else if (bt == T_CHAR) {\n+    result = new AndINode(value,phase->intcon(0xFFFF));\n+  } else {\n+    assert(bt == T_SHORT, \"unexpected narrow type\");\n+    result = phase->transform(new LShiftINode(value, phase->intcon(16)));\n+    result = new RShiftINode(result, phase->intcon(16));\n+  }\n+  if (transform_res) {\n+    result = phase->transform(result);\n+  }\n+  return result;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":54,"deletions":10,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -66,2 +66,0 @@\n-  _pcmp_neq = NULL; \/\/ Should be initialized\n-  _pcmp_eq  = NULL;\n@@ -76,1 +74,1 @@\n-    if (n->is_Allocate())\n+    if (n->is_Allocate()) {\n@@ -78,0 +76,1 @@\n+    }\n@@ -80,1 +79,1 @@\n-      if (!(obj->is_Parm() || obj->is_Con()))\n+      if (!(obj->is_Parm() || obj->is_Con())) {\n@@ -82,0 +81,1 @@\n+      }\n@@ -106,1 +106,1 @@\n-  if (oop_null->outcnt() == 0)\n+  if (oop_null->outcnt() == 0) {\n@@ -108,1 +108,2 @@\n-  if (noop_null->outcnt() == 0)\n+  }\n+  if (noop_null->outcnt() == 0) {\n@@ -110,0 +111,1 @@\n+  }\n@@ -124,1 +126,1 @@\n-  GrowableArray<JavaObjectNode*> non_escaped_worklist;\n+  GrowableArray<JavaObjectNode*> non_escaped_allocs_worklist;\n@@ -156,1 +158,1 @@\n-          non_escaped_worklist.append(ptn->as_JavaObject());\n+          non_escaped_allocs_worklist.append(ptn->as_JavaObject());\n@@ -196,1 +198,1 @@\n-  if (non_escaped_worklist.length() == 0) {\n+  if (non_escaped_allocs_worklist.length() == 0) {\n@@ -205,1 +207,0 @@\n-  int ptnodes_length = ptnodes_worklist.length();\n@@ -212,0 +213,1 @@\n+    int ptnodes_length = ptnodes_worklist.length();\n@@ -231,1 +233,1 @@\n-  if (!complete_connection_graph(ptnodes_worklist, non_escaped_worklist,\n+  if (!complete_connection_graph(ptnodes_worklist, non_escaped_allocs_worklist,\n@@ -241,1 +243,1 @@\n-  int non_escaped_length = non_escaped_worklist.length();\n+  int non_escaped_length = non_escaped_allocs_worklist.length();\n@@ -243,1 +245,1 @@\n-    JavaObjectNode* ptn = non_escaped_worklist.at(next);\n+    JavaObjectNode* ptn = non_escaped_allocs_worklist.at(next);\n@@ -260,1 +262,1 @@\n-    verify_connection_graph(ptnodes_worklist, non_escaped_worklist,\n+    verify_connection_graph(ptnodes_worklist, non_escaped_allocs_worklist,\n@@ -275,1 +277,1 @@\n-  bool has_non_escaping_obj = (non_escaped_worklist.length() > 0);\n+  bool has_non_escaping_obj = (non_escaped_allocs_worklist.length() > 0);\n@@ -286,1 +288,0 @@\n-  bool has_scalar_replaceable_candidates = (alloc_worklist.length() > 0);\n@@ -299,0 +300,1 @@\n+  bool has_scalar_replaceable_candidates = (alloc_worklist.length() > 0);\n@@ -311,1 +313,1 @@\n-    if(!EliminateAllocations) {\n+    if (!EliminateAllocations) {\n@@ -431,1 +433,1 @@\n-  if (n_ptn != NULL)\n+  if (n_ptn != NULL) {\n@@ -433,1 +435,1 @@\n-\n+  }\n@@ -452,1 +454,1 @@\n-        if (name != NULL && strcmp(name, \"uncommon_trap\") == 0)\n+        if (name != NULL && strcmp(name, \"uncommon_trap\") == 0) {\n@@ -454,0 +456,1 @@\n+        }\n@@ -469,1 +472,1 @@\n-  if (n_ptn == phantom_obj || n_ptn == null_obj)\n+  if (n_ptn == phantom_obj || n_ptn == null_obj) {\n@@ -471,1 +474,1 @@\n-\n+  }\n@@ -588,1 +591,1 @@\n-      \/\/ fallthrough\n+      \/\/ fall-through\n@@ -676,1 +679,1 @@\n-        if (in == NULL)\n+        if (in == NULL) {\n@@ -678,0 +681,1 @@\n+        }\n@@ -679,1 +683,1 @@\n-        if (uncast_in->is_top() || uncast_in == n)\n+        if (uncast_in->is_top() || uncast_in == n) {\n@@ -681,0 +685,1 @@\n+        }\n@@ -707,1 +712,1 @@\n-          if (in == NULL)\n+          if (in == NULL) {\n@@ -709,0 +714,1 @@\n+          }\n@@ -710,1 +716,1 @@\n-          if (uncast_in->is_top() || uncast_in == n)\n+          if (uncast_in->is_top() || uncast_in == n) {\n@@ -712,0 +718,1 @@\n+          }\n@@ -949,1 +956,1 @@\n-      \/\/ Returns a newly allocated unescaped object.\n+      \/\/ Returns a newly allocated non-escaped object.\n@@ -968,1 +975,1 @@\n-        \/\/ Returns a newly allocated unescaped object, simply\n+        \/\/ Returns a newly allocated non-escaped object, simply\n@@ -1033,1 +1040,1 @@\n-        if (arg->is_top() || !at->isa_ptr() || !aat->isa_ptr())\n+        if (arg->is_top() || !at->isa_ptr() || !aat->isa_ptr()) {\n@@ -1035,0 +1042,1 @@\n+        }\n@@ -1225,1 +1233,1 @@\n-                         GrowableArray<JavaObjectNode*>& non_escaped_worklist,\n+                         GrowableArray<JavaObjectNode*>& non_escaped_allocs_worklist,\n@@ -1233,1 +1241,1 @@\n-#define CG_BUILD_ITER_LIMIT 20\n+#define GRAPH_BUILD_ITER_LIMIT 20\n@@ -1238,1 +1246,1 @@\n-  if (!find_non_escaped_objects(ptnodes_worklist, non_escaped_worklist)) {\n+  if (!find_non_escaped_objects(ptnodes_worklist, non_escaped_allocs_worklist)) {\n@@ -1243,0 +1251,2 @@\n+  elapsedTimer build_time;\n+  build_time.start();\n@@ -1249,1 +1259,1 @@\n-           (iterations++ < CG_BUILD_ITER_LIMIT)) {\n+           (iterations++ < GRAPH_BUILD_ITER_LIMIT)) {\n@@ -1284,1 +1294,1 @@\n-        if (!find_non_escaped_objects(ptnodes_worklist, non_escaped_worklist)) {\n+        if (!find_non_escaped_objects(ptnodes_worklist, non_escaped_allocs_worklist)) {\n@@ -1294,1 +1304,1 @@\n-    if ((iterations < CG_BUILD_ITER_LIMIT) && !timeout) {\n+    if ((iterations < GRAPH_BUILD_ITER_LIMIT) && !timeout) {\n@@ -1316,0 +1326,4 @@\n+  build_time.stop();\n+  _build_time = build_time.seconds();\n+  _build_iterations = iterations;\n+\n@@ -1317,1 +1331,1 @@\n-  if ((iterations >= CG_BUILD_ITER_LIMIT) || timeout) {\n+  if ((iterations >= GRAPH_BUILD_ITER_LIMIT) || timeout) {\n@@ -1325,1 +1339,1 @@\n-           time.seconds(), iterations, nodes_size(), ptnodes_worklist.length());\n+           _build_time, _build_iterations, nodes_size(), ptnodes_worklist.length());\n@@ -1332,2 +1346,2 @@\n-    tty->print_cr(\"EA: %d iterations to build connection graph with %d nodes and worklist size %d\",\n-                  iterations, nodes_size(), ptnodes_worklist.length());\n+    tty->print_cr(\"EA: %d iterations and %f sec to build connection graph with %d nodes and worklist size %d\",\n+                  _build_iterations, _build_time, nodes_size(), ptnodes_worklist.length());\n@@ -1337,1 +1351,1 @@\n-#undef CG_BUILD_ITER_LIMIT\n+#undef GRAPH_BUILD_ITER_LIMIT\n@@ -1340,1 +1354,1 @@\n-  int non_escaped_length = non_escaped_worklist.length();\n+  int non_escaped_length = non_escaped_allocs_worklist.length();\n@@ -1342,1 +1356,1 @@\n-    JavaObjectNode* ptn = non_escaped_worklist.at(next);\n+    JavaObjectNode* ptn = non_escaped_allocs_worklist.at(next);\n@@ -1346,1 +1360,1 @@\n-      if (find_init_values(ptn, null_obj, _igvn) > 0) {\n+      if (find_init_values_null(ptn, _igvn) > 0) {\n@@ -1368,1 +1382,1 @@\n-                                               GrowableArray<JavaObjectNode*>& non_escaped_worklist) {\n+                                               GrowableArray<JavaObjectNode*>& non_escaped_allocs_worklist) {\n@@ -1431,2 +1445,2 @@\n-  for (int next = non_escaped_worklist.length()-1; next >= 0 ; --next) {\n-    JavaObjectNode* ptn = non_escaped_worklist.at(next);\n+  for (int next = non_escaped_allocs_worklist.length()-1; next >= 0 ; --next) {\n+    JavaObjectNode* ptn = non_escaped_allocs_worklist.at(next);\n@@ -1434,1 +1448,1 @@\n-      non_escaped_worklist.delete_at(next);\n+      non_escaped_allocs_worklist.delete_at(next);\n@@ -1438,1 +1452,1 @@\n-      find_init_values(ptn, phantom_obj, NULL);\n+      find_init_values_phantom(ptn);\n@@ -1441,1 +1455,1 @@\n-  return (non_escaped_worklist.length() > 0);\n+  return (non_escaped_allocs_worklist.length() > 0);\n@@ -1451,1 +1465,1 @@\n-      if (use->is_Arraycopy())\n+      if (use->is_Arraycopy()) {\n@@ -1453,0 +1467,1 @@\n+      }\n@@ -1473,1 +1488,1 @@\n-      if (jobj == null_obj) \/\/ NULL object does not have field edges\n+      if (jobj == null_obj) { \/\/ NULL object does not have field edges\n@@ -1475,0 +1490,1 @@\n+      }\n@@ -1483,1 +1499,1 @@\n-    if (!add_edge(use, jobj))\n+    if (!add_edge(use, jobj)) {\n@@ -1485,0 +1501,1 @@\n+    }\n@@ -1492,1 +1509,1 @@\n-            if (jobj == null_obj) \/\/ NULL object does not have field edges\n+            if (jobj == null_obj) { \/\/ NULL object does not have field edges\n@@ -1494,0 +1511,1 @@\n+            }\n@@ -1552,1 +1570,1 @@\n-        if (f == field || !f->as_Field()->is_oop())\n+        if (f == field || !f->as_Field()->is_oop()) {\n@@ -1554,0 +1572,1 @@\n+        }\n@@ -1575,1 +1594,1 @@\n-        if (f == field || !f->as_Field()->is_oop())\n+        if (f == field || !f->as_Field()->is_oop()) {\n@@ -1577,0 +1596,1 @@\n+        }\n@@ -1595,1 +1615,1 @@\n-      if (base->ideal_node()->is_Allocate())\n+      if (base->ideal_node()->is_Allocate()) {\n@@ -1597,0 +1617,1 @@\n+      }\n@@ -1609,1 +1630,1 @@\n-int ConnectionGraph::find_init_values(JavaObjectNode* pta, PointsToNode* init_val, PhaseTransform* phase) {\n+int ConnectionGraph::find_init_values_phantom(JavaObjectNode* pta) {\n@@ -1611,7 +1632,7 @@\n-  int new_edges = 0;\n-  if (init_val == phantom_obj) {\n-    \/\/ Do nothing for Allocate nodes since its fields values are\n-    \/\/ \"known\" unless they are initialized by arraycopy\/clone.\n-    if (alloc->is_Allocate() && !pta->arraycopy_dst())\n-      return 0;\n-    assert(pta->arraycopy_dst() || alloc->as_CallStaticJava(), \"sanity\");\n+\n+  \/\/ Do nothing for Allocate nodes since its fields values are\n+  \/\/ \"known\" unless they are initialized by arraycopy\/clone.\n+  if (alloc->is_Allocate() && !pta->arraycopy_dst()) {\n+    return 0;\n+  }\n+  assert(pta->arraycopy_dst() || alloc->as_CallStaticJava(), \"sanity\");\n@@ -1620,4 +1641,4 @@\n-    if (!pta->arraycopy_dst() && alloc->as_CallStaticJava()->method() == NULL) {\n-      const char* name = alloc->as_CallStaticJava()->_name;\n-      assert(strncmp(name, \"_multianewarray\", 15) == 0, \"sanity\");\n-    }\n+  if (!pta->arraycopy_dst() && alloc->as_CallStaticJava()->method() == NULL) {\n+    const char* name = alloc->as_CallStaticJava()->_name;\n+    assert(strncmp(name, \"_multianewarray\", 15) == 0, \"sanity\");\n+  }\n@@ -1625,10 +1646,9 @@\n-    \/\/ Non-escaped allocation returned from Java or runtime call have\n-    \/\/ unknown values in fields.\n-    for (EdgeIterator i(pta); i.has_next(); i.next()) {\n-      PointsToNode* field = i.get();\n-      if (field->is_Field() && field->as_Field()->is_oop()) {\n-        if (add_edge(field, phantom_obj)) {\n-          \/\/ New edge was added\n-          new_edges++;\n-          add_field_uses_to_worklist(field->as_Field());\n-        }\n+  \/\/ Non-escaped allocation returned from Java or runtime call have unknown values in fields.\n+  int new_edges = 0;\n+  for (EdgeIterator i(pta); i.has_next(); i.next()) {\n+    PointsToNode* field = i.get();\n+    if (field->is_Field() && field->as_Field()->is_oop()) {\n+      if (add_edge(field, phantom_obj)) {\n+        \/\/ New edge was added\n+        new_edges++;\n+        add_field_uses_to_worklist(field->as_Field());\n@@ -1637,2 +1657,7 @@\n-    return new_edges;\n-  assert(init_val == null_obj, \"sanity\");\n+  return new_edges;\n+}\n+\n+\/\/ Find fields initializing values for allocations.\n+int ConnectionGraph::find_init_values_null(JavaObjectNode* pta, PhaseTransform* phase) {\n+  assert(pta->escape_state() == PointsToNode::NoEscape, \"Not escaped Allocate nodes only\");\n+  Node* alloc = pta->ideal_node();\n@@ -1641,1 +1666,1 @@\n-  if (!alloc->is_Allocate())\n+  if (!alloc->is_Allocate()) {\n@@ -1643,1 +1668,1 @@\n-\n+  }\n@@ -1647,0 +1672,1 @@\n+  int new_edges = 0;\n@@ -1655,1 +1681,1 @@\n-    if (!field->is_Field() || !field->as_Field()->is_oop())\n+    if (!field->is_Field() || !field->as_Field()->is_oop()) {\n@@ -1657,0 +1683,1 @@\n+    }\n@@ -1763,3 +1790,0 @@\n-  \/\/ 1. An object is not scalar replaceable if the field into which it is\n-  \/\/ stored has unknown offset (stored into unknown element of an array).\n-  \/\/\n@@ -1774,0 +1798,2 @@\n+      \/\/ 1. An object is not scalar replaceable if the field into which it is\n+      \/\/ stored has unknown offset (stored into unknown element of an array).\n@@ -1879,1 +1905,1 @@\n-                         GrowableArray<JavaObjectNode*>& non_escaped_worklist,\n+                         GrowableArray<JavaObjectNode*>& non_escaped_allocs_worklist,\n@@ -1884,1 +1910,1 @@\n-  int non_escaped_length  = non_escaped_worklist.length();\n+  int non_escaped_length  = non_escaped_allocs_worklist.length();\n@@ -1892,3 +1918,3 @@\n-  int length = non_escaped_worklist.length();\n-  find_non_escaped_objects(ptnodes_worklist, non_escaped_worklist);\n-  assert((non_escaped_length == non_escaped_worklist.length()) &&\n+  int length = non_escaped_allocs_worklist.length();\n+  find_non_escaped_objects(ptnodes_worklist, non_escaped_allocs_worklist);\n+  assert((non_escaped_length == non_escaped_allocs_worklist.length()) &&\n@@ -1955,1 +1981,1 @@\n-    for( int i=0; i < cnt; i++ ) {\n+    for (int i = 0; i < cnt; i++) {\n@@ -1976,8 +2002,5 @@\n-    \/\/ Add ConI(#CC_GT) and ConI(#CC_EQ).\n-    _pcmp_neq = igvn->makecon(TypeInt::CC_GT);\n-    _pcmp_eq = igvn->makecon(TypeInt::CC_EQ);\n-    \/\/ Optimize objects compare.\n-    while (ptr_cmp_worklist.length() != 0) {\n-      Node *n = ptr_cmp_worklist.pop();\n-      Node *res = optimize_ptr_compare(n);\n-      if (res != NULL) {\n+    for (int i = 0; i < ptr_cmp_worklist.length(); i++) {\n+      Node *n = ptr_cmp_worklist.at(i);\n+      const TypeInt* tcmp = optimize_ptr_compare(n);\n+      if (tcmp->singleton()) {\n+        Node* cmp = igvn->makecon(tcmp);\n@@ -1986,1 +2009,1 @@\n-          tty->print_cr(\"++++ Replaced: %d %s(%d,%d) --> %s\", n->_idx, (n->Opcode() == Op_CmpP ? \"CmpP\" : \"CmpN\"), n->in(1)->_idx, n->in(2)->_idx, (res == _pcmp_eq ? \"EQ\" : \"NotEQ\"));\n+          tty->print_cr(\"++++ Replaced: %d %s(%d,%d) --> %s\", n->_idx, (n->Opcode() == Op_CmpP ? \"CmpP\" : \"CmpN\"), n->in(1)->_idx, n->in(2)->_idx, (tcmp == TypeInt::CC_EQ ? \"EQ\" : \"NotEQ\"));\n@@ -1992,1 +2015,1 @@\n-        igvn->replace_node(n, res);\n+        igvn->replace_node(n, cmp);\n@@ -1995,5 +2018,0 @@\n-    \/\/ cleanup\n-    if (_pcmp_neq->outcnt() == 0)\n-      igvn->hash_delete(_pcmp_neq);\n-    if (_pcmp_eq->outcnt()  == 0)\n-      igvn->hash_delete(_pcmp_eq);\n@@ -2005,4 +2023,4 @@\n-  while (storestore_worklist.length() != 0) {\n-    Node *n = storestore_worklist.pop();\n-    MemBarStoreStoreNode *storestore = n ->as_MemBarStoreStore();\n-    Node *alloc = storestore->in(MemBarNode::Precedent)->in(0);\n+  for (int i = 0; i < storestore_worklist.length(); i++) {\n+    Node* storestore = storestore_worklist.at(i);\n+    assert(storestore->is_MemBarStoreStore(), \"\");\n+    Node* alloc = storestore->in(MemBarNode::Precedent)->in(0);\n@@ -2011,1 +2029,1 @@\n-      mb->init_req(TypeFunc::Memory, storestore->in(TypeFunc::Memory));\n+      mb->init_req(TypeFunc::Memory,  storestore->in(TypeFunc::Memory));\n@@ -2020,1 +2038,1 @@\n-Node* ConnectionGraph::optimize_ptr_compare(Node* n) {\n+const TypeInt* ConnectionGraph::optimize_ptr_compare(Node* n) {\n@@ -2022,0 +2040,4 @@\n+  const TypeInt* EQ = TypeInt::CC_EQ; \/\/ [0] == ZERO\n+  const TypeInt* NE = TypeInt::CC_GT; \/\/ [1] == ONE\n+  const TypeInt* UNKNOWN = TypeInt::CC;    \/\/ [-1, 0,1]\n+\n@@ -2034,1 +2056,1 @@\n-        return _pcmp_eq;\n+        return EQ;\n@@ -2040,1 +2062,1 @@\n-        return _pcmp_neq; \/\/ This includes nullness check.\n+        return NE; \/\/ This includes nullness check.\n@@ -2050,1 +2072,1 @@\n-        return _pcmp_neq; \/\/ This includes nullness check.\n+        return NE; \/\/ This includes nullness check.\n@@ -2063,1 +2085,1 @@\n-      return _pcmp_eq;\n+      return EQ;\n@@ -2065,1 +2087,1 @@\n-      return _pcmp_neq;\n+      return NE;\n@@ -2069,1 +2091,1 @@\n-    return NULL; \/\/ Sets are not disjoint\n+    return UNKNOWN; \/\/ Sets are not disjoint\n@@ -2080,1 +2102,1 @@\n-    return NULL;\n+    return UNKNOWN;\n@@ -2089,1 +2111,1 @@\n-      return _pcmp_neq;\n+      return NE;\n@@ -2094,1 +2116,1 @@\n-      return _pcmp_neq;\n+      return NE;\n@@ -2097,1 +2119,1 @@\n-  return NULL;\n+  return UNKNOWN;\n@@ -2100,1 +2122,1 @@\n-\/\/ Connection Graph constuction functions.\n+\/\/ Connection Graph construction functions.\n@@ -2110,1 +2132,1 @@\n-  _nodes.at_put(n->_idx, ptadr);\n+  map_ideal_node(n, ptadr);\n@@ -2121,1 +2143,1 @@\n-  _nodes.at_put(n->_idx, ptadr);\n+  map_ideal_node(n, ptadr);\n@@ -2137,1 +2159,1 @@\n-  _nodes.at_put(n->_idx, field);\n+  map_ideal_node(n, field);\n@@ -2151,1 +2173,1 @@\n-  _nodes.at_put(n->_idx, ptadr);\n+  map_ideal_node(n, ptadr);\n@@ -2213,1 +2235,1 @@\n-  assert(!_collecting, \"should not call when contructed graph\");\n+  assert(!_collecting, \"should not call when constructed graph\");\n@@ -2281,1 +2303,1 @@\n-  if (es >= PointsToNode::GlobalEscape)\n+  if (es >= PointsToNode::GlobalEscape) {\n@@ -2283,0 +2305,1 @@\n+  }\n@@ -2289,1 +2312,1 @@\n-    if (i.get()->escape_state() >= PointsToNode::GlobalEscape)\n+    if (i.get()->escape_state() >= PointsToNode::GlobalEscape) {\n@@ -2291,0 +2314,1 @@\n+    }\n@@ -2305,1 +2329,1 @@\n-    if (i.get() == ptn)\n+    if (i.get() == ptn) {\n@@ -2307,0 +2331,1 @@\n+    }\n@@ -2325,1 +2350,1 @@\n-      if (this_e == ptn->edge(j))\n+      if (this_e == ptn->edge(j)) {\n@@ -2327,0 +2352,1 @@\n+      }\n@@ -2336,1 +2362,1 @@\n-    if (i.get() == jobj)\n+    if (i.get() == jobj) {\n@@ -2338,0 +2364,1 @@\n+    }\n@@ -2773,1 +2800,1 @@\n-      imax -= use->replace_edge(n, m);\n+      imax -= use->replace_edge(n, m, igvn);\n@@ -2808,1 +2835,1 @@\n-  if (orig_mem == NULL)\n+  if (orig_mem == NULL) {\n@@ -2810,0 +2837,1 @@\n+  }\n@@ -2819,1 +2847,1 @@\n-    if (result == start_mem)\n+    if (result == start_mem) {\n@@ -2821,0 +2849,1 @@\n+    }\n@@ -2823,1 +2852,1 @@\n-      if (at == Type::TOP)\n+      if (at == Type::TOP) {\n@@ -2825,0 +2854,1 @@\n+      }\n@@ -2827,1 +2857,1 @@\n-      if (idx == alias_idx)\n+      if (idx == alias_idx) {\n@@ -2829,0 +2859,1 @@\n+      }\n@@ -2835,1 +2866,1 @@\n-    if (!is_instance)\n+    if (!is_instance) {\n@@ -2837,0 +2868,1 @@\n+    }\n@@ -2952,1 +2984,1 @@\n-\/\/  Convert the types of unescaped object to instance types where possible,\n+\/\/  Convert the types of non-escaped object to instance types where possible,\n@@ -2980,1 +3012,1 @@\n-\/\/ results and the allocation of node 29 is unescaped and eligible to be an\n+\/\/ results and the allocation of node 29 is non-escaped and eligible to be an\n@@ -3065,2 +3097,2 @@\n-      \/\/ see if it is unescaped.\n-      if (es != PointsToNode::NoEscape || !ptn->scalar_replaceable())\n+      \/\/ see if it is non-escaped.\n+      if (es != PointsToNode::NoEscape || !ptn->scalar_replaceable()) {\n@@ -3068,0 +3100,1 @@\n+      }\n@@ -3114,1 +3147,1 @@\n-      if (t == NULL)\n+      if (t == NULL) {\n@@ -3116,1 +3149,2 @@\n-      if (!t->klass_is_exact())\n+      }\n+      if (!t->klass_is_exact()) {\n@@ -3118,1 +3152,1 @@\n-\n+      }\n@@ -3355,1 +3389,1 @@\n-    if (visited.test_set(n->_idx))\n+    if (visited.test_set(n->_idx)) {\n@@ -3357,0 +3391,1 @@\n+    }\n@@ -3362,1 +3397,1 @@\n-      if (n == NULL)\n+      if (n == NULL) {\n@@ -3364,0 +3399,1 @@\n+      }\n@@ -3373,1 +3409,1 @@\n-      if (addr_t == Type::TOP)\n+      if (addr_t == Type::TOP) {\n@@ -3375,0 +3411,1 @@\n+      }\n@@ -3401,1 +3438,1 @@\n-        if (use->Opcode() == Op_StoreCM) \/\/ Ignore cardmark stores\n+        if (use->Opcode() == Op_StoreCM) { \/\/ Ignore cardmark stores\n@@ -3403,0 +3440,1 @@\n+        }\n@@ -3453,1 +3491,1 @@\n-      if (mem == NULL || mem->is_top())\n+      if (mem == NULL || mem->is_top()) {\n@@ -3455,0 +3493,1 @@\n+      }\n@@ -3463,1 +3502,1 @@\n-            if (cur == NULL)\n+            if (cur == NULL) {\n@@ -3465,0 +3504,1 @@\n+            }\n@@ -3511,1 +3551,1 @@\n-  \/\/ to recursively process Phi's encounted on the input memory\n+  \/\/ to recursively process Phi's encountered on the input memory\n@@ -3600,1 +3640,1 @@\n-    if (nt == PointsToNode::JavaObject && !this->scalar_replaceable())\n+    if (nt == PointsToNode::JavaObject && !this->scalar_replaceable()) {\n@@ -3602,0 +3642,1 @@\n+    }\n@@ -3605,1 +3646,1 @@\n-    if (f->is_oop())\n+    if (f->is_oop()) {\n@@ -3607,1 +3648,2 @@\n-    if (f->offset() > 0)\n+    }\n+    if (f->offset() > 0) {\n@@ -3609,0 +3651,1 @@\n+    }\n@@ -3632,1 +3675,1 @@\n-  if (_node == NULL)\n+  if (_node == NULL) {\n@@ -3634,1 +3677,1 @@\n-  else\n+  } else {\n@@ -3636,0 +3679,1 @@\n+  }\n@@ -3643,1 +3687,1 @@\n-    if (ptn == NULL || !ptn->is_JavaObject())\n+    if (ptn == NULL || !ptn->is_JavaObject()) {\n@@ -3645,0 +3689,1 @@\n+    }\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":207,"deletions":162,"binary":false,"changes":369,"status":"modified"},{"patch":"@@ -4212,1 +4212,1 @@\n-  Node* res_mem = _gvn.transform(new SCMemProjNode(str));\n+  Node* res_mem = _gvn.transform(new SCMemProjNode(_gvn.transform(str)));\n@@ -4234,0 +4234,2 @@\n+  C->set_has_loops(true);\n+\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -254,2 +254,1 @@\n-  AllocateArrayNode* tightly_coupled_allocation(Node* ptr,\n-                                                RegionNode* slow_region);\n+  AllocateArrayNode* tightly_coupled_allocation(Node* ptr);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -98,0 +98,1 @@\n+  idealreg2spillmask  [Op_RegVectMask] = NULL;\n@@ -112,0 +113,1 @@\n+  idealreg2debugmask  [Op_RegVectMask] = NULL;\n@@ -126,0 +128,1 @@\n+  idealreg2mhdebugmask[Op_RegVectMask] = NULL;\n@@ -433,1 +436,1 @@\n-#define NOF_STACK_MASKS (3*12)\n+#define NOF_STACK_MASKS (3*13)\n@@ -490,0 +493,4 @@\n+  idealreg2spillmask  [Op_RegVectMask] = &rms[36];\n+  idealreg2debugmask  [Op_RegVectMask] = &rms[37];\n+  idealreg2mhdebugmask[Op_RegVectMask] = &rms[38];\n+\n@@ -534,0 +541,5 @@\n+  if (Matcher::has_predicated_vectors()) {\n+    *idealreg2spillmask[Op_RegVectMask] = *idealreg2regmask[Op_RegVectMask];\n+     idealreg2spillmask[Op_RegVectMask]->OR(aligned_stack_mask);\n+  }\n+\n@@ -652,0 +664,1 @@\n+  *idealreg2debugmask  [Op_RegVectMask] = *idealreg2spillmask[Op_RegVectMask];\n@@ -666,0 +679,1 @@\n+  *idealreg2mhdebugmask[Op_RegVectMask] = *idealreg2spillmask[Op_RegVectMask];\n@@ -686,0 +700,1 @@\n+  idealreg2debugmask[Op_RegVectMask]->SUBTRACT(*caller_save_mask);\n@@ -700,0 +715,1 @@\n+  idealreg2mhdebugmask[Op_RegVectMask]->SUBTRACT(*mh_caller_save_mask);\n@@ -968,0 +984,1 @@\n+  idealreg2regmask[Op_RegVectMask] = regmask_for_ideal_register(Op_RegVectMask, ret);\n@@ -2573,0 +2590,1 @@\n+    case Op_RegVectMask: return Matcher::predicate_reg_mask();\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":20,"deletions":2,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -322,0 +322,2 @@\n+  static const RegMask* predicate_reg_mask(void);\n+  static const TypeVect* predicate_reg_type(const Type* elemTy, int length);\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -75,0 +75,1 @@\n+#include \"runtime\/threadWXSetters.inline.hpp\"\n@@ -1433,0 +1434,4 @@\n+\n+  \/\/ Enable WXWrite: the function called directly by compiled code.\n+  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, thread));\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2007, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2007, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -164,0 +164,2 @@\n+ private:\n+  const Type* _bottom_type;\n@@ -165,1 +167,2 @@\n-  ReductionNode(Node *ctrl, Node* in1, Node* in2) : Node(ctrl, in1, in2) {}\n+  ReductionNode(Node *ctrl, Node* in1, Node* in2) : Node(ctrl, in1, in2),\n+               _bottom_type(Type::get_const_basic_type(in1->bottom_type()->basic_type())) {}\n@@ -173,2 +176,1 @@\n-    BasicType vbt = in(1)->bottom_type()->basic_type();\n-    return Type::get_const_basic_type(vbt);\n+    return _bottom_type;\n@@ -180,0 +182,3 @@\n+\n+  \/\/ Needed for proper cloning.\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -517,0 +522,10 @@\n+\/\/------------------------------ShiftVNode-----------------------------------\n+\/\/ Class ShiftV functionality.  This covers the common behaviors for all kinds\n+\/\/ of vector shifts.\n+class ShiftVNode : public VectorNode {\n+ public:\n+  ShiftVNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  virtual Node* Identity(PhaseGVN* phase);\n+  virtual int Opcode() const = 0;\n+};\n+\n@@ -519,1 +534,1 @@\n-class LShiftVBNode : public VectorNode {\n+class LShiftVBNode : public ShiftVNode {\n@@ -521,1 +536,1 @@\n-  LShiftVBNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  LShiftVBNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -527,1 +542,1 @@\n-class LShiftVSNode : public VectorNode {\n+class LShiftVSNode : public ShiftVNode {\n@@ -529,1 +544,1 @@\n-  LShiftVSNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  LShiftVSNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -535,1 +550,1 @@\n-class LShiftVINode : public VectorNode {\n+class LShiftVINode : public ShiftVNode {\n@@ -537,1 +552,1 @@\n-  LShiftVINode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  LShiftVINode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -543,1 +558,1 @@\n-class LShiftVLNode : public VectorNode {\n+class LShiftVLNode : public ShiftVNode {\n@@ -545,1 +560,1 @@\n-  LShiftVLNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  LShiftVLNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -551,1 +566,1 @@\n-class RShiftVBNode : public VectorNode {\n+class RShiftVBNode : public ShiftVNode {\n@@ -553,1 +568,1 @@\n-  RShiftVBNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  RShiftVBNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -559,1 +574,1 @@\n-class RShiftVSNode : public VectorNode {\n+class RShiftVSNode : public ShiftVNode {\n@@ -561,1 +576,1 @@\n-  RShiftVSNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  RShiftVSNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -567,1 +582,1 @@\n-class RShiftVINode : public VectorNode {\n+class RShiftVINode : public ShiftVNode {\n@@ -569,1 +584,1 @@\n-  RShiftVINode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  RShiftVINode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -575,1 +590,1 @@\n-class RShiftVLNode : public VectorNode {\n+class RShiftVLNode : public ShiftVNode {\n@@ -577,1 +592,1 @@\n-  RShiftVLNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  RShiftVLNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -583,1 +598,1 @@\n-class URShiftVBNode : public VectorNode {\n+class URShiftVBNode : public ShiftVNode {\n@@ -585,1 +600,1 @@\n-  URShiftVBNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  URShiftVBNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -591,1 +606,1 @@\n-class URShiftVSNode : public VectorNode {\n+class URShiftVSNode : public ShiftVNode {\n@@ -593,1 +608,1 @@\n-  URShiftVSNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  URShiftVSNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -599,1 +614,1 @@\n-class URShiftVINode : public VectorNode {\n+class URShiftVINode : public ShiftVNode {\n@@ -601,1 +616,1 @@\n-  URShiftVINode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  URShiftVINode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -607,1 +622,1 @@\n-class URShiftVLNode : public VectorNode {\n+class URShiftVLNode : public ShiftVNode {\n@@ -609,1 +624,1 @@\n-  URShiftVLNode(Node* in1, Node* in2, const TypeVect* vt) : VectorNode(in1,in2,vt) {}\n+  URShiftVLNode(Node* in1, Node* in2, const TypeVect* vt) : ShiftVNode(in1,in2,vt) {}\n@@ -742,0 +757,2 @@\n+ private:\n+  const TypeVect* _vect_type;\n@@ -744,1 +761,1 @@\n-    : StoreNode(c, mem, adr, at, val, MemNode::unordered) {\n+    : StoreNode(c, mem, adr, at, val, MemNode::unordered), _vect_type(val->bottom_type()->is_vect()) {\n@@ -749,1 +766,1 @@\n-  const TypeVect* vect_type() const { return in(MemNode::ValueIn)->bottom_type()->is_vect(); }\n+  const TypeVect* vect_type() const { return _vect_type; }\n@@ -763,0 +780,3 @@\n+\n+  \/\/ Needed for proper cloning.\n+  virtual uint size_of() const { return sizeof(*this); }\n@@ -787,1 +807,1 @@\n-    assert(mask->bottom_type()->is_long(), \"sanity\");\n+    assert(mask->bottom_type()->is_vectmask(), \"sanity\");\n@@ -805,1 +825,1 @@\n-    assert(mask->bottom_type()->is_long(), \"sanity\");\n+    assert(mask->bottom_type()->is_vectmask(), \"sanity\");\n@@ -828,0 +848,3 @@\n+  virtual uint  ideal_reg() const {\n+    return Op_RegVectMask;\n+  }\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":55,"deletions":32,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -156,3 +156,1 @@\n-  if (payload->is_location() &&\n-      payload->as_LocationValue()->location().type() == Location::vector) {\n-    \/\/ Vector value in an aligned adjacent tuple (1, 2, 4, 8, or 16 slots).\n+  if (payload->is_location()) {\n@@ -160,5 +158,17 @@\n-    return allocate_vector_payload_helper(ik, fr, reg_map, location, THREAD); \/\/ safepoint\n-  } else {\n-    \/\/ Scalar-replaced boxed vector representation.\n-    StackValue* value = StackValue::create_stack_value(fr, reg_map, payload);\n-    return value->get_obj();\n+    if (location.type() == Location::vector) {\n+      \/\/ Vector value in an aligned adjacent tuple (1, 2, 4, 8, or 16 slots).\n+      return allocate_vector_payload_helper(ik, fr, reg_map, location, THREAD); \/\/ safepoint\n+    }\n+#ifdef ASSERT\n+    \/\/ Other payload values are: 'oop' type location and Scalar-replaced boxed vector representation.\n+    \/\/ They will be processed in Deoptimization::reassign_fields() after all objects are reallocated.\n+    else {\n+      Location::Type loc_type = location.type();\n+      assert(loc_type == Location::oop || loc_type == Location::narrowoop,\n+             \"expected 'oop'(%d) or 'narrowoop'(%d) types location but got: %d\", Location::oop, Location::narrowoop, loc_type);\n+    }\n+  } else if (!payload->is_object()) {\n+    stringStream ss;\n+    payload->print_on(&ss);\n+    assert(payload->is_object(), \"expected 'object' value for scalar-replaced boxed vector but got: %s\", ss.as_string());\n+#endif\n@@ -166,0 +176,1 @@\n+  return Handle(THREAD, nullptr);\n","filename":"src\/hotspot\/share\/prims\/vectorSupport.cpp","additions":19,"deletions":8,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -88,2 +88,0 @@\n-intx   Arguments::_Tier3InvokeNotifyFreqLog     = Tier3InvokeNotifyFreqLog;\n-intx   Arguments::_Tier4InvocationThreshold     = Tier4InvocationThreshold;\n@@ -1461,6 +1459,0 @@\n-  if (FLAG_IS_DEFAULT(Tier3InvokeNotifyFreqLog)) {\n-    Tier3InvokeNotifyFreqLog = Arguments::_Tier3InvokeNotifyFreqLog;\n-  }\n-  if (FLAG_IS_DEFAULT(Tier4InvocationThreshold)) {\n-    Tier4InvocationThreshold = Arguments::_Tier4InvocationThreshold;\n-  }\n@@ -1486,7 +1478,0 @@\n-    \/\/ Be much more aggressive in tiered mode with -Xcomp and exercise C2 more.\n-    \/\/ We will first compile a level 3 version (C1 with full profiling), then do one invocation of it and\n-    \/\/ compile a level 4 (C2) and then continue executing it.\n-    if (CompilerConfig::is_c2_or_jvmci_compiler_enabled()) {\n-      Tier3InvokeNotifyFreqLog = 0;\n-      Tier4InvocationThreshold = 0;\n-    }\n@@ -2139,2 +2124,0 @@\n-  Arguments::_Tier3InvokeNotifyFreqLog = Tier3InvokeNotifyFreqLog;\n-  Arguments::_Tier4InvocationThreshold = Tier4InvocationThreshold;\n@@ -3458,1 +3441,1 @@\n-               UseCompressedOops ? \"%s%sclasses.jsa\": \"%s%sclasses_nocoops.jsa\",\n+               LP64_ONLY(!UseCompressedOops ? \"%s%sclasses_nocoops.jsa\":) \"%s%sclasses.jsa\",\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":18,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -346,1 +346,1 @@\n-  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* thread);\n+  static void monitor_exit_helper(oopDesc* obj, BasicLock* lock, JavaThread* current);\n@@ -397,2 +397,0 @@\n-  static void generate_trampoline(MacroAssembler *masm, address destination);\n-\n@@ -702,1 +700,0 @@\n-  static AdapterHandlerEntry* get_adapter0(const methodHandle& method);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"runtime\/safefetch.hpp\"\n+#include \"runtime\/safefetch.inline.hpp\"\n@@ -436,0 +436,2 @@\n+  MACOS_AARCH64_ONLY(os::current_thread_enable_wx(WXExec));\n+\n@@ -509,0 +511,2 @@\n+  MACOS_AARCH64_ONLY(os::current_thread_enable_wx(WXWrite));\n+\n@@ -665,2 +669,2 @@\n-#define RETURN_STUB_PARM(xxx_arraycopy, parm) {           \\\n-  name = #xxx_arraycopy; \\\n+#define RETURN_STUB_PARM(xxx_arraycopy, parm) { \\\n+  name = parm ? #xxx_arraycopy \"_uninit\": #xxx_arraycopy; \\\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -494,4 +494,0 @@\n-  volatile_nonstatic_field(BasicHashtable<mtInternal>,  _free_list,                           BasicHashtableEntry<mtInternal>*)      \\\n-  nonstatic_field(BasicHashtable<mtInternal>,  _first_free_entry,                             char*)                                 \\\n-  nonstatic_field(BasicHashtable<mtInternal>,  _end_block,                                    char*)                                 \\\n-  nonstatic_field(BasicHashtable<mtInternal>,  _entry_size,                                   int)                                   \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,4 @@\n+#include <cstddef>\n+\n+class oopDesc;\n+\n@@ -77,12 +81,6 @@\n-\/\/ Declare the named class to be noncopyable.  This macro must be used in\n-\/\/ a private part of the class's definition, followed by a semi-colon.\n-\/\/ Doing so provides private declarations for the class's copy constructor\n-\/\/ and assignment operator.  Because these operations are private, most\n-\/\/ potential callers will fail to compile because they are inaccessible.\n-\/\/ The operations intentionally lack a definition, to provoke link-time\n-\/\/ failures for calls from contexts where they are accessible, e.g. from\n-\/\/ within the class or from a friend of the class.\n-\/\/ Note: The lack of definitions is still not completely bullet-proof, as\n-\/\/ an apparent call might be optimized away by copy elision.\n-\/\/ For C++11 the declarations should be changed to deleted definitions.\n-#define NONCOPYABLE(C) C(C const&); C& operator=(C const&) \/* next token must be ; *\/\n+\/\/ Declare the named class to be noncopyable.  This macro must be followed by\n+\/\/ a semi-colon.  The macro provides deleted declarations for the class's copy\n+\/\/ constructor and assignment operator.  Because these operations are deleted,\n+\/\/ they cannot be defined and potential callers will fail to compile.\n+#define NONCOPYABLE(C) C(C const&) = delete; C& operator=(C const&) = delete \/* next token must be ; *\/\n+\n@@ -815,0 +813,1 @@\n+    oopDesc* o;\n@@ -839,0 +838,1 @@\n+ oopDesc* get_oop() const { return _value.o; }\n@@ -847,0 +847,1 @@\n+ void set_oop(oopDesc* o) { _value.o = o;}\n@@ -992,1 +993,0 @@\n-#define left_n_bits(n)    (right_n_bits(n) << (((n) >= BitsPerWord) ? 0 : (BitsPerWord - (n))))\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -1404,3 +1404,6 @@\n-          [\"sminv\", \"sminv\", \"8B\"], [\"sminv\", \"sminv\", \"16B\"],\n-          [\"sminv\", \"sminv\", \"4H\"], [\"sminv\", \"sminv\", \"8H\"],\n-          [\"sminv\", \"sminv\", \"4S\"], [\"fminv\", \"fminv\", \"4S\"],\n+          [\"sminv\", \"sminv\", \"8B\"], [\"uminv\", \"uminv\", \"8B\"],\n+          [\"sminv\", \"sminv\", \"16B\"],[\"uminv\", \"uminv\", \"16B\"],\n+          [\"sminv\", \"sminv\", \"4H\"], [\"uminv\", \"uminv\", \"4H\"],\n+          [\"sminv\", \"sminv\", \"8H\"], [\"uminv\", \"uminv\", \"8H\"],\n+          [\"sminv\", \"sminv\", \"4S\"], [\"uminv\", \"uminv\", \"4S\"],\n+          [\"fminv\", \"fminv\", \"4S\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -538,9 +538,14 @@\n-    __ sminv(v23, __ T16B, v24);                       \/\/       sminv   b23, v24.16B\n-    __ sminv(v4, __ T4H, v5);                          \/\/       sminv   h4, v5.4H\n-    __ sminv(v19, __ T8H, v20);                        \/\/       sminv   h19, v20.8H\n-    __ sminv(v15, __ T4S, v16);                        \/\/       sminv   s15, v16.4S\n-    __ fminv(v0, __ T4S, v1);                          \/\/       fminv   s0, v1.4S\n-    __ fmaxp(v4, v5, __ S);                            \/\/       fmaxp   s4, v5.2S\n-    __ fmaxp(v20, v21, __ D);                          \/\/       fmaxp   d20, v21.2D\n-    __ fminp(v11, v12, __ S);                          \/\/       fminp   s11, v12.2S\n-    __ fminp(v29, v30, __ D);                          \/\/       fminp   d29, v30.2D\n+    __ uminv(v23, __ T8B, v24);                        \/\/       uminv   b23, v24.8B\n+    __ sminv(v4, __ T16B, v5);                         \/\/       sminv   b4, v5.16B\n+    __ uminv(v19, __ T16B, v20);                       \/\/       uminv   b19, v20.16B\n+    __ sminv(v15, __ T4H, v16);                        \/\/       sminv   h15, v16.4H\n+    __ uminv(v0, __ T4H, v1);                          \/\/       uminv   h0, v1.4H\n+    __ sminv(v4, __ T8H, v5);                          \/\/       sminv   h4, v5.8H\n+    __ uminv(v20, __ T8H, v21);                        \/\/       uminv   h20, v21.8H\n+    __ sminv(v11, __ T4S, v12);                        \/\/       sminv   s11, v12.4S\n+    __ uminv(v29, __ T4S, v30);                        \/\/       uminv   s29, v30.4S\n+    __ fminv(v15, __ T4S, v16);                        \/\/       fminv   s15, v16.4S\n+    __ fmaxp(v21, v22, __ S);                          \/\/       fmaxp   s21, v22.2S\n+    __ fmaxp(v4, v5, __ D);                            \/\/       fmaxp   d4, v5.2D\n+    __ fminp(v14, v15, __ S);                          \/\/       fminp   s14, v15.2S\n+    __ fminp(v22, v23, __ D);                          \/\/       fminp   d22, v23.2D\n@@ -549,3 +554,3 @@\n-    __ absr(v15, __ T8B, v16);                         \/\/       abs     v15.8B, v16.8B\n-    __ absr(v21, __ T16B, v22);                        \/\/       abs     v21.16B, v22.16B\n-    __ absr(v4, __ T4H, v5);                           \/\/       abs     v4.4H, v5.4H\n+    __ absr(v25, __ T8B, v26);                         \/\/       abs     v25.8B, v26.8B\n+    __ absr(v6, __ T16B, v7);                          \/\/       abs     v6.16B, v7.16B\n+    __ absr(v12, __ T4H, v13);                         \/\/       abs     v12.4H, v13.4H\n@@ -553,14 +558,14 @@\n-    __ absr(v22, __ T2S, v23);                         \/\/       abs     v22.2S, v23.2S\n-    __ absr(v25, __ T4S, v26);                         \/\/       abs     v25.4S, v26.4S\n-    __ absr(v6, __ T2D, v7);                           \/\/       abs     v6.2D, v7.2D\n-    __ fabs(v12, __ T2S, v13);                         \/\/       fabs    v12.2S, v13.2S\n-    __ fabs(v14, __ T4S, v15);                         \/\/       fabs    v14.4S, v15.4S\n-    __ fabs(v13, __ T2D, v14);                         \/\/       fabs    v13.2D, v14.2D\n-    __ fneg(v14, __ T2S, v15);                         \/\/       fneg    v14.2S, v15.2S\n-    __ fneg(v9, __ T4S, v10);                          \/\/       fneg    v9.4S, v10.4S\n-    __ fneg(v25, __ T2D, v26);                         \/\/       fneg    v25.2D, v26.2D\n-    __ fsqrt(v28, __ T2S, v29);                        \/\/       fsqrt   v28.2S, v29.2S\n-    __ fsqrt(v10, __ T4S, v11);                        \/\/       fsqrt   v10.4S, v11.4S\n-    __ fsqrt(v19, __ T2D, v20);                        \/\/       fsqrt   v19.2D, v20.2D\n-    __ notr(v11, __ T8B, v12);                         \/\/       not     v11.8B, v12.8B\n-    __ notr(v17, __ T16B, v18);                        \/\/       not     v17.16B, v18.16B\n+    __ absr(v13, __ T2S, v14);                         \/\/       abs     v13.2S, v14.2S\n+    __ absr(v14, __ T4S, v15);                         \/\/       abs     v14.4S, v15.4S\n+    __ absr(v9, __ T2D, v10);                          \/\/       abs     v9.2D, v10.2D\n+    __ fabs(v25, __ T2S, v26);                         \/\/       fabs    v25.2S, v26.2S\n+    __ fabs(v28, __ T4S, v29);                         \/\/       fabs    v28.4S, v29.4S\n+    __ fabs(v10, __ T2D, v11);                         \/\/       fabs    v10.2D, v11.2D\n+    __ fneg(v19, __ T2S, v20);                         \/\/       fneg    v19.2S, v20.2S\n+    __ fneg(v11, __ T4S, v12);                         \/\/       fneg    v11.4S, v12.4S\n+    __ fneg(v17, __ T2D, v18);                         \/\/       fneg    v17.2D, v18.2D\n+    __ fsqrt(v21, __ T2S, v22);                        \/\/       fsqrt   v21.2S, v22.2S\n+    __ fsqrt(v15, __ T4S, v16);                        \/\/       fsqrt   v15.4S, v16.4S\n+    __ fsqrt(v20, __ T2D, v21);                        \/\/       fsqrt   v20.2D, v21.2D\n+    __ notr(v23, __ T8B, v24);                         \/\/       not     v23.8B, v24.8B\n+    __ notr(v26, __ T16B, v27);                        \/\/       not     v26.16B, v27.16B\n@@ -569,8 +574,8 @@\n-    __ andr(v21, __ T8B, v22, v23);                    \/\/       and     v21.8B, v22.8B, v23.8B\n-    __ andr(v15, __ T16B, v16, v17);                   \/\/       and     v15.16B, v16.16B, v17.16B\n-    __ orr(v20, __ T8B, v21, v22);                     \/\/       orr     v20.8B, v21.8B, v22.8B\n-    __ orr(v23, __ T16B, v24, v25);                    \/\/       orr     v23.16B, v24.16B, v25.16B\n-    __ eor(v26, __ T8B, v27, v28);                     \/\/       eor     v26.8B, v27.8B, v28.8B\n-    __ eor(v5, __ T16B, v6, v7);                       \/\/       eor     v5.16B, v6.16B, v7.16B\n-    __ addv(v6, __ T8B, v7, v8);                       \/\/       add     v6.8B, v7.8B, v8.8B\n-    __ addv(v15, __ T16B, v16, v17);                   \/\/       add     v15.16B, v16.16B, v17.16B\n+    __ andr(v5, __ T8B, v6, v7);                       \/\/       and     v5.8B, v6.8B, v7.8B\n+    __ andr(v6, __ T16B, v7, v8);                      \/\/       and     v6.16B, v7.16B, v8.16B\n+    __ orr(v15, __ T8B, v16, v17);                     \/\/       orr     v15.8B, v16.8B, v17.8B\n+    __ orr(v15, __ T16B, v16, v17);                    \/\/       orr     v15.16B, v16.16B, v17.16B\n+    __ eor(v25, __ T8B, v26, v27);                     \/\/       eor     v25.8B, v26.8B, v27.8B\n+    __ eor(v16, __ T16B, v17, v18);                    \/\/       eor     v16.16B, v17.16B, v18.16B\n+    __ addv(v27, __ T8B, v28, v29);                    \/\/       add     v27.8B, v28.8B, v29.8B\n+    __ addv(v24, __ T16B, v25, v26);                   \/\/       add     v24.16B, v25.16B, v26.16B\n@@ -579,8 +584,8 @@\n-    __ addv(v16, __ T2S, v17, v18);                    \/\/       add     v16.2S, v17.2S, v18.2S\n-    __ addv(v27, __ T4S, v28, v29);                    \/\/       add     v27.4S, v28.4S, v29.4S\n-    __ addv(v24, __ T2D, v25, v26);                    \/\/       add     v24.2D, v25.2D, v26.2D\n-    __ fadd(v15, __ T2S, v16, v17);                    \/\/       fadd    v15.2S, v16.2S, v17.2S\n-    __ fadd(v25, __ T4S, v26, v27);                    \/\/       fadd    v25.4S, v26.4S, v27.4S\n-    __ fadd(v14, __ T2D, v15, v16);                    \/\/       fadd    v14.2D, v15.2D, v16.2D\n-    __ subv(v10, __ T8B, v11, v12);                    \/\/       sub     v10.8B, v11.8B, v12.8B\n-    __ subv(v13, __ T16B, v14, v15);                   \/\/       sub     v13.16B, v14.16B, v15.16B\n+    __ addv(v14, __ T2S, v15, v16);                    \/\/       add     v14.2S, v15.2S, v16.2S\n+    __ addv(v10, __ T4S, v11, v12);                    \/\/       add     v10.4S, v11.4S, v12.4S\n+    __ addv(v13, __ T2D, v14, v15);                    \/\/       add     v13.2D, v14.2D, v15.2D\n+    __ fadd(v14, __ T2S, v15, v16);                    \/\/       fadd    v14.2S, v15.2S, v16.2S\n+    __ fadd(v20, __ T4S, v21, v22);                    \/\/       fadd    v20.4S, v21.4S, v22.4S\n+    __ fadd(v1, __ T2D, v2, v3);                       \/\/       fadd    v1.2D, v2.2D, v3.2D\n+    __ subv(v22, __ T8B, v23, v24);                    \/\/       sub     v22.8B, v23.8B, v24.8B\n+    __ subv(v30, __ T16B, v31, v0);                    \/\/       sub     v30.16B, v31.16B, v0.16B\n@@ -588,48 +593,48 @@\n-    __ subv(v20, __ T8H, v21, v22);                    \/\/       sub     v20.8H, v21.8H, v22.8H\n-    __ subv(v1, __ T2S, v2, v3);                       \/\/       sub     v1.2S, v2.2S, v3.2S\n-    __ subv(v22, __ T4S, v23, v24);                    \/\/       sub     v22.4S, v23.4S, v24.4S\n-    __ subv(v30, __ T2D, v31, v0);                     \/\/       sub     v30.2D, v31.2D, v0.2D\n-    __ fsub(v14, __ T2S, v15, v16);                    \/\/       fsub    v14.2S, v15.2S, v16.2S\n-    __ fsub(v2, __ T4S, v3, v4);                       \/\/       fsub    v2.4S, v3.4S, v4.4S\n-    __ fsub(v6, __ T2D, v7, v8);                       \/\/       fsub    v6.2D, v7.2D, v8.2D\n-    __ mulv(v3, __ T8B, v4, v5);                       \/\/       mul     v3.8B, v4.8B, v5.8B\n-    __ mulv(v7, __ T16B, v8, v9);                      \/\/       mul     v7.16B, v8.16B, v9.16B\n-    __ mulv(v24, __ T4H, v25, v26);                    \/\/       mul     v24.4H, v25.4H, v26.4H\n-    __ mulv(v0, __ T8H, v1, v2);                       \/\/       mul     v0.8H, v1.8H, v2.8H\n-    __ mulv(v27, __ T2S, v28, v29);                    \/\/       mul     v27.2S, v28.2S, v29.2S\n-    __ mulv(v29, __ T4S, v30, v31);                    \/\/       mul     v29.4S, v30.4S, v31.4S\n-    __ fabd(v5, __ T2S, v6, v7);                       \/\/       fabd    v5.2S, v6.2S, v7.2S\n-    __ fabd(v5, __ T4S, v6, v7);                       \/\/       fabd    v5.4S, v6.4S, v7.4S\n-    __ fabd(v29, __ T2D, v30, v31);                    \/\/       fabd    v29.2D, v30.2D, v31.2D\n-    __ fmul(v11, __ T2S, v12, v13);                    \/\/       fmul    v11.2S, v12.2S, v13.2S\n-    __ fmul(v25, __ T4S, v26, v27);                    \/\/       fmul    v25.4S, v26.4S, v27.4S\n-    __ fmul(v0, __ T2D, v1, v2);                       \/\/       fmul    v0.2D, v1.2D, v2.2D\n-    __ mlav(v30, __ T4H, v31, v0);                     \/\/       mla     v30.4H, v31.4H, v0.4H\n-    __ mlav(v0, __ T8H, v1, v2);                       \/\/       mla     v0.8H, v1.8H, v2.8H\n-    __ mlav(v17, __ T2S, v18, v19);                    \/\/       mla     v17.2S, v18.2S, v19.2S\n-    __ mlav(v28, __ T4S, v29, v30);                    \/\/       mla     v28.4S, v29.4S, v30.4S\n-    __ fmla(v25, __ T2S, v26, v27);                    \/\/       fmla    v25.2S, v26.2S, v27.2S\n-    __ fmla(v9, __ T4S, v10, v11);                     \/\/       fmla    v9.4S, v10.4S, v11.4S\n-    __ fmla(v25, __ T2D, v26, v27);                    \/\/       fmla    v25.2D, v26.2D, v27.2D\n-    __ mlsv(v12, __ T4H, v13, v14);                    \/\/       mls     v12.4H, v13.4H, v14.4H\n-    __ mlsv(v15, __ T8H, v16, v17);                    \/\/       mls     v15.8H, v16.8H, v17.8H\n-    __ mlsv(v11, __ T2S, v12, v13);                    \/\/       mls     v11.2S, v12.2S, v13.2S\n-    __ mlsv(v10, __ T4S, v11, v12);                    \/\/       mls     v10.4S, v11.4S, v12.4S\n-    __ fmls(v17, __ T2S, v18, v19);                    \/\/       fmls    v17.2S, v18.2S, v19.2S\n-    __ fmls(v24, __ T4S, v25, v26);                    \/\/       fmls    v24.4S, v25.4S, v26.4S\n-    __ fmls(v21, __ T2D, v22, v23);                    \/\/       fmls    v21.2D, v22.2D, v23.2D\n-    __ fdiv(v23, __ T2S, v24, v25);                    \/\/       fdiv    v23.2S, v24.2S, v25.2S\n-    __ fdiv(v0, __ T4S, v1, v2);                       \/\/       fdiv    v0.4S, v1.4S, v2.4S\n-    __ fdiv(v16, __ T2D, v17, v18);                    \/\/       fdiv    v16.2D, v17.2D, v18.2D\n-    __ maxv(v10, __ T8B, v11, v12);                    \/\/       smax    v10.8B, v11.8B, v12.8B\n-    __ maxv(v6, __ T16B, v7, v8);                      \/\/       smax    v6.16B, v7.16B, v8.16B\n-    __ maxv(v28, __ T4H, v29, v30);                    \/\/       smax    v28.4H, v29.4H, v30.4H\n-    __ maxv(v6, __ T8H, v7, v8);                       \/\/       smax    v6.8H, v7.8H, v8.8H\n-    __ maxv(v5, __ T2S, v6, v7);                       \/\/       smax    v5.2S, v6.2S, v7.2S\n-    __ maxv(v5, __ T4S, v6, v7);                       \/\/       smax    v5.4S, v6.4S, v7.4S\n-    __ fmax(v20, __ T2S, v21, v22);                    \/\/       fmax    v20.2S, v21.2S, v22.2S\n-    __ fmax(v17, __ T4S, v18, v19);                    \/\/       fmax    v17.4S, v18.4S, v19.4S\n-    __ fmax(v15, __ T2D, v16, v17);                    \/\/       fmax    v15.2D, v16.2D, v17.2D\n-    __ minv(v17, __ T8B, v18, v19);                    \/\/       smin    v17.8B, v18.8B, v19.8B\n-    __ minv(v29, __ T16B, v30, v31);                   \/\/       smin    v29.16B, v30.16B, v31.16B\n-    __ minv(v26, __ T4H, v27, v28);                    \/\/       smin    v26.4H, v27.4H, v28.4H\n+    __ subv(v2, __ T8H, v3, v4);                       \/\/       sub     v2.8H, v3.8H, v4.8H\n+    __ subv(v6, __ T2S, v7, v8);                       \/\/       sub     v6.2S, v7.2S, v8.2S\n+    __ subv(v3, __ T4S, v4, v5);                       \/\/       sub     v3.4S, v4.4S, v5.4S\n+    __ subv(v7, __ T2D, v8, v9);                       \/\/       sub     v7.2D, v8.2D, v9.2D\n+    __ fsub(v24, __ T2S, v25, v26);                    \/\/       fsub    v24.2S, v25.2S, v26.2S\n+    __ fsub(v0, __ T4S, v1, v2);                       \/\/       fsub    v0.4S, v1.4S, v2.4S\n+    __ fsub(v27, __ T2D, v28, v29);                    \/\/       fsub    v27.2D, v28.2D, v29.2D\n+    __ mulv(v29, __ T8B, v30, v31);                    \/\/       mul     v29.8B, v30.8B, v31.8B\n+    __ mulv(v5, __ T16B, v6, v7);                      \/\/       mul     v5.16B, v6.16B, v7.16B\n+    __ mulv(v5, __ T4H, v6, v7);                       \/\/       mul     v5.4H, v6.4H, v7.4H\n+    __ mulv(v29, __ T8H, v30, v31);                    \/\/       mul     v29.8H, v30.8H, v31.8H\n+    __ mulv(v11, __ T2S, v12, v13);                    \/\/       mul     v11.2S, v12.2S, v13.2S\n+    __ mulv(v25, __ T4S, v26, v27);                    \/\/       mul     v25.4S, v26.4S, v27.4S\n+    __ fabd(v0, __ T2S, v1, v2);                       \/\/       fabd    v0.2S, v1.2S, v2.2S\n+    __ fabd(v30, __ T4S, v31, v0);                     \/\/       fabd    v30.4S, v31.4S, v0.4S\n+    __ fabd(v0, __ T2D, v1, v2);                       \/\/       fabd    v0.2D, v1.2D, v2.2D\n+    __ fmul(v17, __ T2S, v18, v19);                    \/\/       fmul    v17.2S, v18.2S, v19.2S\n+    __ fmul(v28, __ T4S, v29, v30);                    \/\/       fmul    v28.4S, v29.4S, v30.4S\n+    __ fmul(v25, __ T2D, v26, v27);                    \/\/       fmul    v25.2D, v26.2D, v27.2D\n+    __ mlav(v9, __ T4H, v10, v11);                     \/\/       mla     v9.4H, v10.4H, v11.4H\n+    __ mlav(v25, __ T8H, v26, v27);                    \/\/       mla     v25.8H, v26.8H, v27.8H\n+    __ mlav(v12, __ T2S, v13, v14);                    \/\/       mla     v12.2S, v13.2S, v14.2S\n+    __ mlav(v15, __ T4S, v16, v17);                    \/\/       mla     v15.4S, v16.4S, v17.4S\n+    __ fmla(v11, __ T2S, v12, v13);                    \/\/       fmla    v11.2S, v12.2S, v13.2S\n+    __ fmla(v10, __ T4S, v11, v12);                    \/\/       fmla    v10.4S, v11.4S, v12.4S\n+    __ fmla(v17, __ T2D, v18, v19);                    \/\/       fmla    v17.2D, v18.2D, v19.2D\n+    __ mlsv(v24, __ T4H, v25, v26);                    \/\/       mls     v24.4H, v25.4H, v26.4H\n+    __ mlsv(v21, __ T8H, v22, v23);                    \/\/       mls     v21.8H, v22.8H, v23.8H\n+    __ mlsv(v23, __ T2S, v24, v25);                    \/\/       mls     v23.2S, v24.2S, v25.2S\n+    __ mlsv(v0, __ T4S, v1, v2);                       \/\/       mls     v0.4S, v1.4S, v2.4S\n+    __ fmls(v16, __ T2S, v17, v18);                    \/\/       fmls    v16.2S, v17.2S, v18.2S\n+    __ fmls(v10, __ T4S, v11, v12);                    \/\/       fmls    v10.4S, v11.4S, v12.4S\n+    __ fmls(v6, __ T2D, v7, v8);                       \/\/       fmls    v6.2D, v7.2D, v8.2D\n+    __ fdiv(v28, __ T2S, v29, v30);                    \/\/       fdiv    v28.2S, v29.2S, v30.2S\n+    __ fdiv(v6, __ T4S, v7, v8);                       \/\/       fdiv    v6.4S, v7.4S, v8.4S\n+    __ fdiv(v5, __ T2D, v6, v7);                       \/\/       fdiv    v5.2D, v6.2D, v7.2D\n+    __ maxv(v5, __ T8B, v6, v7);                       \/\/       smax    v5.8B, v6.8B, v7.8B\n+    __ maxv(v20, __ T16B, v21, v22);                   \/\/       smax    v20.16B, v21.16B, v22.16B\n+    __ maxv(v17, __ T4H, v18, v19);                    \/\/       smax    v17.4H, v18.4H, v19.4H\n+    __ maxv(v15, __ T8H, v16, v17);                    \/\/       smax    v15.8H, v16.8H, v17.8H\n+    __ maxv(v17, __ T2S, v18, v19);                    \/\/       smax    v17.2S, v18.2S, v19.2S\n+    __ maxv(v29, __ T4S, v30, v31);                    \/\/       smax    v29.4S, v30.4S, v31.4S\n+    __ fmax(v26, __ T2S, v27, v28);                    \/\/       fmax    v26.2S, v27.2S, v28.2S\n+    __ fmax(v28, __ T4S, v29, v30);                    \/\/       fmax    v28.4S, v29.4S, v30.4S\n+    __ fmax(v1, __ T2D, v2, v3);                       \/\/       fmax    v1.2D, v2.2D, v3.2D\n+    __ minv(v27, __ T8B, v28, v29);                    \/\/       smin    v27.8B, v28.8B, v29.8B\n+    __ minv(v0, __ T16B, v1, v2);                      \/\/       smin    v0.16B, v1.16B, v2.16B\n+    __ minv(v20, __ T4H, v21, v22);                    \/\/       smin    v20.4H, v21.4H, v22.4H\n@@ -637,4 +642,4 @@\n-    __ minv(v1, __ T2S, v2, v3);                       \/\/       smin    v1.2S, v2.2S, v3.2S\n-    __ minv(v27, __ T4S, v28, v29);                    \/\/       smin    v27.4S, v28.4S, v29.4S\n-    __ fmin(v0, __ T2S, v1, v2);                       \/\/       fmin    v0.2S, v1.2S, v2.2S\n-    __ fmin(v20, __ T4S, v21, v22);                    \/\/       fmin    v20.4S, v21.4S, v22.4S\n+    __ minv(v15, __ T2S, v16, v17);                    \/\/       smin    v15.2S, v16.2S, v17.2S\n+    __ minv(v12, __ T4S, v13, v14);                    \/\/       smin    v12.4S, v13.4S, v14.4S\n+    __ fmin(v10, __ T2S, v11, v12);                    \/\/       fmin    v10.2S, v11.2S, v12.2S\n+    __ fmin(v28, __ T4S, v29, v30);                    \/\/       fmin    v28.4S, v29.4S, v30.4S\n@@ -642,2 +647,2 @@\n-    __ cmeq(v15, __ T8B, v16, v17);                    \/\/       cmeq    v15.8B, v16.8B, v17.8B\n-    __ cmeq(v12, __ T16B, v13, v14);                   \/\/       cmeq    v12.16B, v13.16B, v14.16B\n+    __ cmeq(v19, __ T8B, v20, v21);                    \/\/       cmeq    v19.8B, v20.8B, v21.8B\n+    __ cmeq(v22, __ T16B, v23, v24);                   \/\/       cmeq    v22.16B, v23.16B, v24.16B\n@@ -645,23 +650,23 @@\n-    __ cmeq(v28, __ T8H, v29, v30);                    \/\/       cmeq    v28.8H, v29.8H, v30.8H\n-    __ cmeq(v28, __ T2S, v29, v30);                    \/\/       cmeq    v28.2S, v29.2S, v30.2S\n-    __ cmeq(v19, __ T4S, v20, v21);                    \/\/       cmeq    v19.4S, v20.4S, v21.4S\n-    __ cmeq(v22, __ T2D, v23, v24);                    \/\/       cmeq    v22.2D, v23.2D, v24.2D\n-    __ fcmeq(v10, __ T2S, v11, v12);                   \/\/       fcmeq   v10.2S, v11.2S, v12.2S\n-    __ fcmeq(v4, __ T4S, v5, v6);                      \/\/       fcmeq   v4.4S, v5.4S, v6.4S\n-    __ fcmeq(v30, __ T2D, v31, v0);                    \/\/       fcmeq   v30.2D, v31.2D, v0.2D\n-    __ cmgt(v20, __ T8B, v21, v22);                    \/\/       cmgt    v20.8B, v21.8B, v22.8B\n-    __ cmgt(v8, __ T16B, v9, v10);                     \/\/       cmgt    v8.16B, v9.16B, v10.16B\n-    __ cmgt(v30, __ T4H, v31, v0);                     \/\/       cmgt    v30.4H, v31.4H, v0.4H\n-    __ cmgt(v17, __ T8H, v18, v19);                    \/\/       cmgt    v17.8H, v18.8H, v19.8H\n-    __ cmgt(v10, __ T2S, v11, v12);                    \/\/       cmgt    v10.2S, v11.2S, v12.2S\n-    __ cmgt(v27, __ T4S, v28, v29);                    \/\/       cmgt    v27.4S, v28.4S, v29.4S\n-    __ cmgt(v2, __ T2D, v3, v4);                       \/\/       cmgt    v2.2D, v3.2D, v4.2D\n-    __ fcmgt(v24, __ T2S, v25, v26);                   \/\/       fcmgt   v24.2S, v25.2S, v26.2S\n-    __ fcmgt(v4, __ T4S, v5, v6);                      \/\/       fcmgt   v4.4S, v5.4S, v6.4S\n-    __ fcmgt(v3, __ T2D, v4, v5);                      \/\/       fcmgt   v3.2D, v4.2D, v5.2D\n-    __ cmge(v8, __ T8B, v9, v10);                      \/\/       cmge    v8.8B, v9.8B, v10.8B\n-    __ cmge(v22, __ T16B, v23, v24);                   \/\/       cmge    v22.16B, v23.16B, v24.16B\n-    __ cmge(v17, __ T4H, v18, v19);                    \/\/       cmge    v17.4H, v18.4H, v19.4H\n-    __ cmge(v13, __ T8H, v14, v15);                    \/\/       cmge    v13.8H, v14.8H, v15.8H\n-    __ cmge(v4, __ T2S, v5, v6);                       \/\/       cmge    v4.2S, v5.2S, v6.2S\n-    __ cmge(v28, __ T4S, v29, v30);                    \/\/       cmge    v28.4S, v29.4S, v30.4S\n+    __ cmeq(v4, __ T8H, v5, v6);                       \/\/       cmeq    v4.8H, v5.8H, v6.8H\n+    __ cmeq(v30, __ T2S, v31, v0);                     \/\/       cmeq    v30.2S, v31.2S, v0.2S\n+    __ cmeq(v20, __ T4S, v21, v22);                    \/\/       cmeq    v20.4S, v21.4S, v22.4S\n+    __ cmeq(v8, __ T2D, v9, v10);                      \/\/       cmeq    v8.2D, v9.2D, v10.2D\n+    __ fcmeq(v30, __ T2S, v31, v0);                    \/\/       fcmeq   v30.2S, v31.2S, v0.2S\n+    __ fcmeq(v17, __ T4S, v18, v19);                   \/\/       fcmeq   v17.4S, v18.4S, v19.4S\n+    __ fcmeq(v10, __ T2D, v11, v12);                   \/\/       fcmeq   v10.2D, v11.2D, v12.2D\n+    __ cmgt(v27, __ T8B, v28, v29);                    \/\/       cmgt    v27.8B, v28.8B, v29.8B\n+    __ cmgt(v2, __ T16B, v3, v4);                      \/\/       cmgt    v2.16B, v3.16B, v4.16B\n+    __ cmgt(v24, __ T4H, v25, v26);                    \/\/       cmgt    v24.4H, v25.4H, v26.4H\n+    __ cmgt(v4, __ T8H, v5, v6);                       \/\/       cmgt    v4.8H, v5.8H, v6.8H\n+    __ cmgt(v3, __ T2S, v4, v5);                       \/\/       cmgt    v3.2S, v4.2S, v5.2S\n+    __ cmgt(v8, __ T4S, v9, v10);                      \/\/       cmgt    v8.4S, v9.4S, v10.4S\n+    __ cmgt(v22, __ T2D, v23, v24);                    \/\/       cmgt    v22.2D, v23.2D, v24.2D\n+    __ fcmgt(v17, __ T2S, v18, v19);                   \/\/       fcmgt   v17.2S, v18.2S, v19.2S\n+    __ fcmgt(v13, __ T4S, v14, v15);                   \/\/       fcmgt   v13.4S, v14.4S, v15.4S\n+    __ fcmgt(v4, __ T2D, v5, v6);                      \/\/       fcmgt   v4.2D, v5.2D, v6.2D\n+    __ cmge(v28, __ T8B, v29, v30);                    \/\/       cmge    v28.8B, v29.8B, v30.8B\n+    __ cmge(v23, __ T16B, v24, v25);                   \/\/       cmge    v23.16B, v24.16B, v25.16B\n+    __ cmge(v21, __ T4H, v22, v23);                    \/\/       cmge    v21.4H, v22.4H, v23.4H\n+    __ cmge(v25, __ T8H, v26, v27);                    \/\/       cmge    v25.8H, v26.8H, v27.8H\n+    __ cmge(v24, __ T2S, v25, v26);                    \/\/       cmge    v24.2S, v25.2S, v26.2S\n+    __ cmge(v3, __ T4S, v4, v5);                       \/\/       cmge    v3.4S, v4.4S, v5.4S\n@@ -669,3 +674,3 @@\n-    __ fcmge(v21, __ T2S, v22, v23);                   \/\/       fcmge   v21.2S, v22.2S, v23.2S\n-    __ fcmge(v25, __ T4S, v26, v27);                   \/\/       fcmge   v25.4S, v26.4S, v27.4S\n-    __ fcmge(v24, __ T2D, v25, v26);                   \/\/       fcmge   v24.2D, v25.2D, v26.2D\n+    __ fcmge(v26, __ T2S, v27, v28);                   \/\/       fcmge   v26.2S, v27.2S, v28.2S\n+    __ fcmge(v23, __ T4S, v24, v25);                   \/\/       fcmge   v23.4S, v24.4S, v25.4S\n+    __ fcmge(v14, __ T2D, v15, v16);                   \/\/       fcmge   v14.2D, v15.2D, v16.2D\n@@ -822,9 +827,9 @@\n-    __ swp(Assembler::xword, r3, r24, r26);            \/\/       swp     x3, x24, [x26]\n-    __ ldadd(Assembler::xword, r23, r15, r21);         \/\/       ldadd   x23, x15, [x21]\n-    __ ldbic(Assembler::xword, r3, r24, r8);           \/\/       ldclr   x3, x24, [x8]\n-    __ ldeor(Assembler::xword, r25, r20, r16);         \/\/       ldeor   x25, x20, [x16]\n-    __ ldorr(Assembler::xword, r17, r2, r1);           \/\/       ldset   x17, x2, [x1]\n-    __ ldsmin(Assembler::xword, r0, r24, r4);          \/\/       ldsmin  x0, x24, [x4]\n-    __ ldsmax(Assembler::xword, r3, r12, sp);          \/\/       ldsmax  x3, x12, [sp]\n-    __ ldumin(Assembler::xword, r28, r10, r26);        \/\/       ldumin  x28, x10, [x26]\n-    __ ldumax(Assembler::xword, r2, r12, r15);         \/\/       ldumax  x2, x12, [x15]\n+    __ swp(Assembler::xword, r21, r3, r24);            \/\/       swp     x21, x3, [x24]\n+    __ ldadd(Assembler::xword, r8, r25, r20);          \/\/       ldadd   x8, x25, [x20]\n+    __ ldbic(Assembler::xword, r16, r17, r2);          \/\/       ldclr   x16, x17, [x2]\n+    __ ldeor(Assembler::xword, r1, r0, r24);           \/\/       ldeor   x1, x0, [x24]\n+    __ ldorr(Assembler::xword, r4, r3, r12);           \/\/       ldset   x4, x3, [x12]\n+    __ ldsmin(Assembler::xword, zr, r28, r10);         \/\/       ldsmin  xzr, x28, [x10]\n+    __ ldsmax(Assembler::xword, r26, r2, r12);         \/\/       ldsmax  x26, x2, [x12]\n+    __ ldumin(Assembler::xword, r16, zr, r1);          \/\/       ldumin  x16, xzr, [x1]\n+    __ ldumax(Assembler::xword, r13, r29, r0);         \/\/       ldumax  x13, x29, [x0]\n@@ -833,9 +838,9 @@\n-    __ swpa(Assembler::xword, zr, r1, r13);            \/\/       swpa    xzr, x1, [x13]\n-    __ ldadda(Assembler::xword, r29, r0, r19);         \/\/       ldadda  x29, x0, [x19]\n-    __ ldbica(Assembler::xword, r12, r17, r22);        \/\/       ldclra  x12, x17, [x22]\n-    __ ldeora(Assembler::xword, r13, r28, r30);        \/\/       ldeora  x13, x28, [x30]\n-    __ ldorra(Assembler::xword, zr, r1, r26);          \/\/       ldseta  xzr, x1, [x26]\n-    __ ldsmina(Assembler::xword, r28, r4, r30);        \/\/       ldsmina x28, x4, [x30]\n-    __ ldsmaxa(Assembler::xword, r4, r6, r30);         \/\/       ldsmaxa x4, x6, [x30]\n-    __ ldumina(Assembler::xword, r26, r16, r9);        \/\/       ldumina x26, x16, [x9]\n-    __ ldumaxa(Assembler::xword, r8, r12, r0);         \/\/       ldumaxa x8, x12, [x0]\n+    __ swpa(Assembler::xword, r19, r12, r17);          \/\/       swpa    x19, x12, [x17]\n+    __ ldadda(Assembler::xword, r22, r13, r28);        \/\/       ldadda  x22, x13, [x28]\n+    __ ldbica(Assembler::xword, r30, zr, r1);          \/\/       ldclra  x30, xzr, [x1]\n+    __ ldeora(Assembler::xword, r26, r28, r4);         \/\/       ldeora  x26, x28, [x4]\n+    __ ldorra(Assembler::xword, r30, r4, r6);          \/\/       ldseta  x30, x4, [x6]\n+    __ ldsmina(Assembler::xword, r30, r26, r15);       \/\/       ldsmina x30, x26, [x15]\n+    __ ldsmaxa(Assembler::xword, r9, r8, r12);         \/\/       ldsmaxa x9, x8, [x12]\n+    __ ldumina(Assembler::xword, r0, r20, r1);         \/\/       ldumina x0, x20, [x1]\n+    __ ldumaxa(Assembler::xword, r24, r2, r0);         \/\/       ldumaxa x24, x2, [x0]\n@@ -844,9 +849,9 @@\n-    __ swpal(Assembler::xword, r20, r1, r24);          \/\/       swpal   x20, x1, [x24]\n-    __ ldaddal(Assembler::xword, r2, r0, r9);          \/\/       ldaddal x2, x0, [x9]\n-    __ ldbical(Assembler::xword, r24, r26, r16);       \/\/       ldclral x24, x26, [x16]\n-    __ ldeoral(Assembler::xword, r30, r3, r10);        \/\/       ldeoral x30, x3, [x10]\n-    __ ldorral(Assembler::xword, r23, r10, r4);        \/\/       ldsetal x23, x10, [x4]\n-    __ ldsminal(Assembler::xword, r16, r2, r11);       \/\/       ldsminal        x16, x2, [x11]\n-    __ ldsmaxal(Assembler::xword, r8, r10, r15);       \/\/       ldsmaxal        x8, x10, [x15]\n-    __ lduminal(Assembler::xword, r17, r2, r10);       \/\/       lduminal        x17, x2, [x10]\n-    __ ldumaxal(Assembler::xword, r12, r12, r15);      \/\/       ldumaxal        x12, x12, [x15]\n+    __ swpal(Assembler::xword, r9, r24, r26);          \/\/       swpal   x9, x24, [x26]\n+    __ ldaddal(Assembler::xword, r16, r30, r3);        \/\/       ldaddal x16, x30, [x3]\n+    __ ldbical(Assembler::xword, r10, r23, r10);       \/\/       ldclral x10, x23, [x10]\n+    __ ldeoral(Assembler::xword, r4, r16, r2);         \/\/       ldeoral x4, x16, [x2]\n+    __ ldorral(Assembler::xword, r11, r8, r10);        \/\/       ldsetal x11, x8, [x10]\n+    __ ldsminal(Assembler::xword, r15, r17, r2);       \/\/       ldsminal        x15, x17, [x2]\n+    __ ldsmaxal(Assembler::xword, r10, r12, r12);      \/\/       ldsmaxal        x10, x12, [x12]\n+    __ lduminal(Assembler::xword, r15, r13, r2);       \/\/       lduminal        x15, x13, [x2]\n+    __ ldumaxal(Assembler::xword, r7, r20, r26);       \/\/       ldumaxal        x7, x20, [x26]\n@@ -855,9 +860,9 @@\n-    __ swpl(Assembler::xword, r13, r2, r7);            \/\/       swpl    x13, x2, [x7]\n-    __ ldaddl(Assembler::xword, r20, r26, r16);        \/\/       ldaddl  x20, x26, [x16]\n-    __ ldbicl(Assembler::xword, r4, r2, r4);           \/\/       ldclrl  x4, x2, [x4]\n-    __ ldeorl(Assembler::xword, r12, r16, r21);        \/\/       ldeorl  x12, x16, [x21]\n-    __ ldorrl(Assembler::xword, r16, r16, r11);        \/\/       ldsetl  x16, x16, [x11]\n-    __ ldsminl(Assembler::xword, r21, r23, r12);       \/\/       ldsminl x21, x23, [x12]\n-    __ ldsmaxl(Assembler::xword, r26, r23, r28);       \/\/       ldsmaxl x26, x23, [x28]\n-    __ lduminl(Assembler::xword, r14, r11, r24);       \/\/       lduminl x14, x11, [x24]\n-    __ ldumaxl(Assembler::xword, r1, r12, sp);         \/\/       ldumaxl x1, x12, [sp]\n+    __ swpl(Assembler::xword, r16, r4, r2);            \/\/       swpl    x16, x4, [x2]\n+    __ ldaddl(Assembler::xword, r4, r12, r15);         \/\/       ldaddl  x4, x12, [x15]\n+    __ ldbicl(Assembler::xword, r21, r16, r15);        \/\/       ldclrl  x21, x16, [x15]\n+    __ ldeorl(Assembler::xword, r11, r21, r23);        \/\/       ldeorl  x11, x21, [x23]\n+    __ ldorrl(Assembler::xword, r12, r26, r23);        \/\/       ldsetl  x12, x26, [x23]\n+    __ ldsminl(Assembler::xword, r28, r14, r11);       \/\/       ldsminl x28, x14, [x11]\n+    __ ldsmaxl(Assembler::xword, r24, r1, r12);        \/\/       ldsmaxl x24, x1, [x12]\n+    __ lduminl(Assembler::xword, zr, r10, r16);        \/\/       lduminl xzr, x10, [x16]\n+    __ ldumaxl(Assembler::xword, r7, r2, r3);          \/\/       ldumaxl x7, x2, [x3]\n@@ -866,9 +871,9 @@\n-    __ swp(Assembler::word, r10, r16, r7);             \/\/       swp     w10, w16, [x7]\n-    __ ldadd(Assembler::word, r2, r3, r13);            \/\/       ldadd   w2, w3, [x13]\n-    __ ldbic(Assembler::word, r19, r17, r16);          \/\/       ldclr   w19, w17, [x16]\n-    __ ldeor(Assembler::word, r3, r1, r11);            \/\/       ldeor   w3, w1, [x11]\n-    __ ldorr(Assembler::word, r30, r5, r8);            \/\/       ldset   w30, w5, [x8]\n-    __ ldsmin(Assembler::word, r15, r29, r30);         \/\/       ldsmin  w15, w29, [x30]\n-    __ ldsmax(Assembler::word, r0, r20, r7);           \/\/       ldsmax  w0, w20, [x7]\n-    __ ldumin(Assembler::word, r20, r23, r28);         \/\/       ldumin  w20, w23, [x28]\n-    __ ldumax(Assembler::word, r21, r27, r25);         \/\/       ldumax  w21, w27, [x25]\n+    __ swp(Assembler::word, r13, r19, r17);            \/\/       swp     w13, w19, [x17]\n+    __ ldadd(Assembler::word, r16, r3, r1);            \/\/       ldadd   w16, w3, [x1]\n+    __ ldbic(Assembler::word, r11, r30, r5);           \/\/       ldclr   w11, w30, [x5]\n+    __ ldeor(Assembler::word, r8, r15, r29);           \/\/       ldeor   w8, w15, [x29]\n+    __ ldorr(Assembler::word, r30, r0, r20);           \/\/       ldset   w30, w0, [x20]\n+    __ ldsmin(Assembler::word, r7, r20, r23);          \/\/       ldsmin  w7, w20, [x23]\n+    __ ldsmax(Assembler::word, r28, r21, r27);         \/\/       ldsmax  w28, w21, [x27]\n+    __ ldumin(Assembler::word, r25, r5, r1);           \/\/       ldumin  w25, w5, [x1]\n+    __ ldumax(Assembler::word, r23, r16, sp);          \/\/       ldumax  w23, w16, [sp]\n@@ -877,9 +882,9 @@\n-    __ swpa(Assembler::word, r5, r1, r23);             \/\/       swpa    w5, w1, [x23]\n-    __ ldadda(Assembler::word, r16, zr, r5);           \/\/       ldadda  w16, wzr, [x5]\n-    __ ldbica(Assembler::word, r12, r9, r28);          \/\/       ldclra  w12, w9, [x28]\n-    __ ldeora(Assembler::word, r15, r29, r22);         \/\/       ldeora  w15, w29, [x22]\n-    __ ldorra(Assembler::word, zr, r19, sp);           \/\/       ldseta  wzr, w19, [sp]\n-    __ ldsmina(Assembler::word, r5, r14, r15);         \/\/       ldsmina w5, w14, [x15]\n-    __ ldsmaxa(Assembler::word, zr, r16, r27);         \/\/       ldsmaxa wzr, w16, [x27]\n-    __ ldumina(Assembler::word, r20, r16, r12);        \/\/       ldumina w20, w16, [x12]\n-    __ ldumaxa(Assembler::word, r11, r9, r6);          \/\/       ldumaxa w11, w9, [x6]\n+    __ swpa(Assembler::word, r5, r12, r9);             \/\/       swpa    w5, w12, [x9]\n+    __ ldadda(Assembler::word, r28, r15, r29);         \/\/       ldadda  w28, w15, [x29]\n+    __ ldbica(Assembler::word, r22, zr, r19);          \/\/       ldclra  w22, wzr, [x19]\n+    __ ldeora(Assembler::word, zr, r5, r14);           \/\/       ldeora  wzr, w5, [x14]\n+    __ ldorra(Assembler::word, r16, zr, r15);          \/\/       ldseta  w16, wzr, [x15]\n+    __ ldsmina(Assembler::word, r27, r20, r16);        \/\/       ldsmina w27, w20, [x16]\n+    __ ldsmaxa(Assembler::word, r12, r11, r9);         \/\/       ldsmaxa w12, w11, [x9]\n+    __ ldumina(Assembler::word, r6, r30, r17);         \/\/       ldumina w6, w30, [x17]\n+    __ ldumaxa(Assembler::word, r27, r28, r30);        \/\/       ldumaxa w27, w28, [x30]\n@@ -888,9 +893,9 @@\n-    __ swpal(Assembler::word, r30, r17, r27);          \/\/       swpal   w30, w17, [x27]\n-    __ ldaddal(Assembler::word, r28, r30, r7);         \/\/       ldaddal w28, w30, [x7]\n-    __ ldbical(Assembler::word, r10, r20, r10);        \/\/       ldclral w10, w20, [x10]\n-    __ ldeoral(Assembler::word, r4, r24, r17);         \/\/       ldeoral w4, w24, [x17]\n-    __ ldorral(Assembler::word, r17, r22, r3);         \/\/       ldsetal w17, w22, [x3]\n-    __ ldsminal(Assembler::word, r29, r15, r22);       \/\/       ldsminal        w29, w15, [x22]\n-    __ ldsmaxal(Assembler::word, r19, r19, r22);       \/\/       ldsmaxal        w19, w19, [x22]\n-    __ lduminal(Assembler::word, r2, r15, r6);         \/\/       lduminal        w2, w15, [x6]\n-    __ ldumaxal(Assembler::word, r12, r16, r11);       \/\/       ldumaxal        w12, w16, [x11]\n+    __ swpal(Assembler::word, r7, r10, r20);           \/\/       swpal   w7, w10, [x20]\n+    __ ldaddal(Assembler::word, r10, r4, r24);         \/\/       ldaddal w10, w4, [x24]\n+    __ ldbical(Assembler::word, r17, r17, r22);        \/\/       ldclral w17, w17, [x22]\n+    __ ldeoral(Assembler::word, r3, r29, r15);         \/\/       ldeoral w3, w29, [x15]\n+    __ ldorral(Assembler::word, r22, r19, r19);        \/\/       ldsetal w22, w19, [x19]\n+    __ ldsminal(Assembler::word, r22, r2, r15);        \/\/       ldsminal        w22, w2, [x15]\n+    __ ldsmaxal(Assembler::word, r6, r12, r16);        \/\/       ldsmaxal        w6, w12, [x16]\n+    __ lduminal(Assembler::word, r11, r13, r23);       \/\/       lduminal        w11, w13, [x23]\n+    __ ldumaxal(Assembler::word, r1, r30, r19);        \/\/       ldumaxal        w1, w30, [x19]\n@@ -899,9 +904,9 @@\n-    __ swpl(Assembler::word, r13, r23, r1);            \/\/       swpl    w13, w23, [x1]\n-    __ ldaddl(Assembler::word, r30, r19, r5);          \/\/       ldaddl  w30, w19, [x5]\n-    __ ldbicl(Assembler::word, r17, r2, r16);          \/\/       ldclrl  w17, w2, [x16]\n-    __ ldeorl(Assembler::word, r22, r13, r10);         \/\/       ldeorl  w22, w13, [x10]\n-    __ ldorrl(Assembler::word, r21, r29, r27);         \/\/       ldsetl  w21, w29, [x27]\n-    __ ldsminl(Assembler::word, r12, r27, r3);         \/\/       ldsminl w12, w27, [x3]\n-    __ ldsmaxl(Assembler::word, r1, zr, r24);          \/\/       ldsmaxl w1, wzr, [x24]\n-    __ lduminl(Assembler::word, r19, r17, r9);         \/\/       lduminl w19, w17, [x9]\n-    __ ldumaxl(Assembler::word, r28, r27, r15);        \/\/       ldumaxl w28, w27, [x15]\n+    __ swpl(Assembler::word, r5, r17, r2);             \/\/       swpl    w5, w17, [x2]\n+    __ ldaddl(Assembler::word, r16, r22, r13);         \/\/       ldaddl  w16, w22, [x13]\n+    __ ldbicl(Assembler::word, r10, r21, r29);         \/\/       ldclrl  w10, w21, [x29]\n+    __ ldeorl(Assembler::word, r27, r12, r27);         \/\/       ldeorl  w27, w12, [x27]\n+    __ ldorrl(Assembler::word, r3, r1, sp);            \/\/       ldsetl  w3, w1, [sp]\n+    __ ldsminl(Assembler::word, r24, r19, r17);        \/\/       ldsminl w24, w19, [x17]\n+    __ ldsmaxl(Assembler::word, r9, r28, r27);         \/\/       ldsmaxl w9, w28, [x27]\n+    __ lduminl(Assembler::word, r15, r7, r21);         \/\/       lduminl w15, w7, [x21]\n+    __ ldumaxl(Assembler::word, r23, zr, r25);         \/\/       ldumaxl w23, wzr, [x25]\n@@ -910,4 +915,4 @@\n-    __ bcax(v6, __ T16B, v20, v22, v30);               \/\/       bcax            v6.16B, v20.16B, v22.16B, v30.16B\n-    __ eor3(v24, __ T16B, v2, v30, v26);               \/\/       eor3            v24.16B, v2.16B, v30.16B, v26.16B\n-    __ rax1(v17, __ T2D, v10, v22);                    \/\/       rax1            v17.2D, v10.2D, v22.2D\n-    __ xar(v17, __ T2D, v2, v17, 1);                   \/\/       xar             v17.2D, v2.2D, v17.2D, #1\n+    __ bcax(v2, __ T16B, v30, v26, v17);               \/\/       bcax            v2.16B, v30.16B, v26.16B, v17.16B\n+    __ eor3(v10, __ T16B, v22, v17, v2);               \/\/       eor3            v10.16B, v22.16B, v17.16B, v2.16B\n+    __ rax1(v17, __ T2D, v0, v24);                     \/\/       rax1            v17.2D, v0.2D, v24.2D\n+    __ xar(v25, __ T2D, v22, v2, 37);                  \/\/       xar             v25.2D, v22.2D, v2.2D, #37\n@@ -916,4 +921,4 @@\n-    __ sha512h(v24, __ T2D, v25, v22);                 \/\/       sha512h         q24, q25, v22.2D\n-    __ sha512h2(v2, __ T2D, v17, v12);                 \/\/       sha512h2                q2, q17, v12.2D\n-    __ sha512su0(v3, __ T2D, v27);                     \/\/       sha512su0               v3.2D, v27.2D\n-    __ sha512su1(v29, __ T2D, v28, v16);               \/\/       sha512su1               v29.2D, v28.2D, v16.2D\n+    __ sha512h(v12, __ T2D, v3, v27);                  \/\/       sha512h         q12, q3, v27.2D\n+    __ sha512h2(v29, __ T2D, v28, v16);                \/\/       sha512h2                q29, q28, v16.2D\n+    __ sha512su0(v26, __ T2D, v6);                     \/\/       sha512su0               v26.2D, v6.2D\n+    __ sha512su1(v9, __ T2D, v28, v17);                \/\/       sha512su1               v9.2D, v28.2D, v17.2D\n@@ -922,0 +927,1 @@\n+<<<<<<< HEAD\n@@ -973,0 +979,51 @@\n+=======\n+    __ sve_add(z7, __ H, z4, z7);                      \/\/       add     z7.h, z4.h, z7.h\n+    __ sve_sub(z9, __ B, z22, z8);                     \/\/       sub     z9.b, z22.b, z8.b\n+    __ sve_fadd(z27, __ S, z20, z30);                  \/\/       fadd    z27.s, z20.s, z30.s\n+    __ sve_fmul(z26, __ S, z0, z16);                   \/\/       fmul    z26.s, z0.s, z16.s\n+    __ sve_fsub(z3, __ D, z25, z8);                    \/\/       fsub    z3.d, z25.d, z8.d\n+    __ sve_abs(z21, __ D, p6, z26);                    \/\/       abs     z21.d, p6\/m, z26.d\n+    __ sve_add(z22, __ B, p0, z4);                     \/\/       add     z22.b, p0\/m, z22.b, z4.b\n+    __ sve_asr(z17, __ H, p0, z3);                     \/\/       asr     z17.h, p0\/m, z17.h, z3.h\n+    __ sve_cnt(z1, __ B, p2, z6);                      \/\/       cnt     z1.b, p2\/m, z6.b\n+    __ sve_lsl(z9, __ S, p7, z7);                      \/\/       lsl     z9.s, p7\/m, z9.s, z7.s\n+    __ sve_lsr(z22, __ H, p5, z5);                     \/\/       lsr     z22.h, p5\/m, z22.h, z5.h\n+    __ sve_mul(z8, __ B, p4, z30);                     \/\/       mul     z8.b, p4\/m, z8.b, z30.b\n+    __ sve_neg(z17, __ D, p0, z11);                    \/\/       neg     z17.d, p0\/m, z11.d\n+    __ sve_not(z28, __ S, p0, z26);                    \/\/       not     z28.s, p0\/m, z26.s\n+    __ sve_smax(z28, __ D, p3, z13);                   \/\/       smax    z28.d, p3\/m, z28.d, z13.d\n+    __ sve_smin(z16, __ B, p6, z5);                    \/\/       smin    z16.b, p6\/m, z16.b, z5.b\n+    __ sve_sub(z13, __ H, p2, z15);                    \/\/       sub     z13.h, p2\/m, z13.h, z15.h\n+    __ sve_fabs(z26, __ S, p5, z11);                   \/\/       fabs    z26.s, p5\/m, z11.s\n+    __ sve_fadd(z22, __ S, p4, z4);                    \/\/       fadd    z22.s, p4\/m, z22.s, z4.s\n+    __ sve_fdiv(z19, __ S, p4, z17);                   \/\/       fdiv    z19.s, p4\/m, z19.s, z17.s\n+    __ sve_fmax(z14, __ D, p3, z2);                    \/\/       fmax    z14.d, p3\/m, z14.d, z2.d\n+    __ sve_fmin(z3, __ S, p5, z23);                    \/\/       fmin    z3.s, p5\/m, z3.s, z23.s\n+    __ sve_fmul(z6, __ S, p1, z17);                    \/\/       fmul    z6.s, p1\/m, z6.s, z17.s\n+    __ sve_fneg(z27, __ S, p4, z16);                   \/\/       fneg    z27.s, p4\/m, z16.s\n+    __ sve_frintm(z2, __ S, p7, z3);                   \/\/       frintm  z2.s, p7\/m, z3.s\n+    __ sve_frintn(z6, __ S, p4, z19);                  \/\/       frintn  z6.s, p4\/m, z19.s\n+    __ sve_frintp(z12, __ D, p5, z8);                  \/\/       frintp  z12.d, p5\/m, z8.d\n+    __ sve_fsqrt(z19, __ S, p4, z0);                   \/\/       fsqrt   z19.s, p4\/m, z0.s\n+    __ sve_fsub(z23, __ D, p1, z19);                   \/\/       fsub    z23.d, p1\/m, z23.d, z19.d\n+    __ sve_fmla(z13, __ S, p4, z6, z0);                \/\/       fmla    z13.s, p4\/m, z6.s, z0.s\n+    __ sve_fmls(z14, __ S, p4, z25, z8);               \/\/       fmls    z14.s, p4\/m, z25.s, z8.s\n+    __ sve_fnmla(z22, __ S, p5, z22, z27);             \/\/       fnmla   z22.s, p5\/m, z22.s, z27.s\n+    __ sve_fnmls(z3, __ S, p3, z17, z20);              \/\/       fnmls   z3.s, p3\/m, z17.s, z20.s\n+    __ sve_mla(z4, __ H, p7, z7, z0);                  \/\/       mla     z4.h, p7\/m, z7.h, z0.h\n+    __ sve_mls(z16, __ S, p5, z22, z4);                \/\/       mls     z16.s, p5\/m, z22.s, z4.s\n+    __ sve_and(z9, z22, z11);                          \/\/       and     z9.d, z22.d, z11.d\n+    __ sve_eor(z5, z30, z16);                          \/\/       eor     z5.d, z30.d, z16.d\n+    __ sve_orr(z22, z11, z1);                          \/\/       orr     z22.d, z11.d, z1.d\n+\n+\/\/ SVEReductionOp\n+    __ sve_andv(v8, __ D, p5, z16);                    \/\/       andv d8, p5, z16.d\n+    __ sve_orv(v15, __ S, p1, z4);                     \/\/       orv s15, p1, z4.s\n+    __ sve_eorv(v8, __ B, p1, z29);                    \/\/       eorv b8, p1, z29.b\n+    __ sve_smaxv(v28, __ D, p4, z29);                  \/\/       smaxv d28, p4, z29.d\n+    __ sve_sminv(v9, __ H, p3, z2);                    \/\/       sminv h9, p3, z2.h\n+    __ sve_fminv(v28, __ S, p0, z7);                   \/\/       fminv s28, p0, z7.s\n+    __ sve_fmaxv(v26, __ S, p5, z17);                  \/\/       fmaxv s26, p5, z17.s\n+    __ sve_fadda(v8, __ D, p4, z21);                   \/\/       fadda d8, p4, d8, z21.d\n+    __ sve_uaddv(v5, __ S, p5, z21);                   \/\/       uaddv d5, p5, z21.s\n+>>>>>>> master\n@@ -991,0 +1048,1 @@\n+<<<<<<< HEAD\n@@ -998,0 +1056,9 @@\n+=======\n+    0x14000000,     0x17ffffd7,     0x140002e0,     0x94000000,\n+    0x97ffffd4,     0x940002dd,     0x3400000a,     0x34fffa2a,\n+    0x34005b4a,     0x35000008,     0x35fff9c8,     0x35005ae8,\n+    0xb400000b,     0xb4fff96b,     0xb4005a8b,     0xb500001d,\n+    0xb5fff91d,     0xb5005a3d,     0x10000013,     0x10fff8b3,\n+    0x100059d3,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36305956,     0x3758000c,     0x375ff7cc,     0x375858ec,\n+>>>>>>> master\n@@ -1002,0 +1069,1 @@\n+<<<<<<< HEAD\n@@ -1015,0 +1083,15 @@\n+=======\n+    0x540056c0,     0x54000001,     0x54fff541,     0x54005661,\n+    0x54000002,     0x54fff4e2,     0x54005602,     0x54000002,\n+    0x54fff482,     0x540055a2,     0x54000003,     0x54fff423,\n+    0x54005543,     0x54000003,     0x54fff3c3,     0x540054e3,\n+    0x54000004,     0x54fff364,     0x54005484,     0x54000005,\n+    0x54fff305,     0x54005425,     0x54000006,     0x54fff2a6,\n+    0x540053c6,     0x54000007,     0x54fff247,     0x54005367,\n+    0x54000008,     0x54fff1e8,     0x54005308,     0x54000009,\n+    0x54fff189,     0x540052a9,     0x5400000a,     0x54fff12a,\n+    0x5400524a,     0x5400000b,     0x54fff0cb,     0x540051eb,\n+    0x5400000c,     0x54fff06c,     0x5400518c,     0x5400000d,\n+    0x54fff00d,     0x5400512d,     0x5400000e,     0x54ffefae,\n+    0x540050ce,     0x5400000f,     0x54ffef4f,     0x5400506f,\n+>>>>>>> master\n@@ -1046,0 +1129,1 @@\n+<<<<<<< HEAD\n@@ -1047,0 +1131,3 @@\n+=======\n+    0xbd1b1869,     0x580040bb,     0x1800000b,     0xf8945060,\n+>>>>>>> master\n@@ -1088,0 +1175,1 @@\n+<<<<<<< HEAD\n@@ -1149,0 +1237,50 @@\n+=======\n+    0x0e31ab38,     0x2e31ab17,     0x4e31a8a4,     0x6e31aa93,\n+    0x0e71aa0f,     0x2e71a820,     0x4e71a8a4,     0x6e71aab4,\n+    0x4eb1a98b,     0x6eb1abdd,     0x6eb0fa0f,     0x7e30fad5,\n+    0x7e70f8a4,     0x7eb0f9ee,     0x7ef0faf6,     0x0e20bb59,\n+    0x4e20b8e6,     0x0e60b9ac,     0x4e60b9ee,     0x0ea0b9cd,\n+    0x4ea0b9ee,     0x4ee0b949,     0x0ea0fb59,     0x4ea0fbbc,\n+    0x4ee0f96a,     0x2ea0fa93,     0x6ea0f98b,     0x6ee0fa51,\n+    0x2ea1fad5,     0x6ea1fa0f,     0x6ee1fab4,     0x2e205b17,\n+    0x6e205b7a,     0x0e271cc5,     0x4e281ce6,     0x0eb11e0f,\n+    0x4eb11e0f,     0x2e3b1f59,     0x6e321e30,     0x0e3d879b,\n+    0x4e3a8738,     0x0e71860f,     0x4e7b8759,     0x0eb085ee,\n+    0x4eac856a,     0x4eef85cd,     0x0e30d5ee,     0x4e36d6b4,\n+    0x4e63d441,     0x2e3886f6,     0x6e2087fe,     0x2e7085ee,\n+    0x6e648462,     0x2ea884e6,     0x6ea58483,     0x6ee98507,\n+    0x0ebad738,     0x4ea2d420,     0x4efdd79b,     0x0e3f9fdd,\n+    0x4e279cc5,     0x0e679cc5,     0x4e7f9fdd,     0x0ead9d8b,\n+    0x4ebb9f59,     0x2ea2d420,     0x6ea0d7fe,     0x6ee2d420,\n+    0x2e33de51,     0x6e3edfbc,     0x6e7bdf59,     0x0e6b9549,\n+    0x4e7b9759,     0x0eae95ac,     0x4eb1960f,     0x0e2dcd8b,\n+    0x4e2ccd6a,     0x4e73ce51,     0x2e7a9738,     0x6e7796d5,\n+    0x2eb99717,     0x6ea29420,     0x0eb2ce30,     0x4eaccd6a,\n+    0x4ee8cce6,     0x2e3effbc,     0x6e28fce6,     0x6e67fcc5,\n+    0x0e2764c5,     0x4e3666b4,     0x0e736651,     0x4e71660f,\n+    0x0eb36651,     0x4ebf67dd,     0x0e3cf77a,     0x4e3ef7bc,\n+    0x4e63f441,     0x0e3d6f9b,     0x4e226c20,     0x0e766eb4,\n+    0x4e7e6fbc,     0x0eb16e0f,     0x4eae6dac,     0x0eacf56a,\n+    0x4ebef7bc,     0x4efef7bc,     0x2e358e93,     0x6e388ef6,\n+    0x2e6c8d6a,     0x6e668ca4,     0x2ea08ffe,     0x6eb68eb4,\n+    0x6eea8d28,     0x0e20e7fe,     0x4e33e651,     0x4e6ce56a,\n+    0x0e3d379b,     0x4e243462,     0x0e7a3738,     0x4e6634a4,\n+    0x0ea53483,     0x4eaa3528,     0x4ef836f6,     0x2eb3e651,\n+    0x6eafe5cd,     0x6ee6e4a4,     0x0e3e3fbc,     0x4e393f17,\n+    0x0e773ed5,     0x4e7b3f59,     0x0eba3f38,     0x4ea53c83,\n+    0x4ef93f17,     0x2e3ce77a,     0x6e39e717,     0x6e70e5ee,\n+    0xba5fd3e3,     0x3a5f03e5,     0xfa411be4,     0x7a42cbe2,\n+    0x93df03ff,     0xc820ffff,     0x8822fc7f,     0xc8247cbf,\n+    0x88267fff,     0x4e010fe0,     0x4e081fe1,     0x4e0c1fe1,\n+    0x4e0a1fe1,     0x4e071fe1,     0x4e042c20,     0x4e062c20,\n+    0x4e052c20,     0x4e083c20,     0x0e0c3c20,     0x0e0a3c20,\n+    0x0e073c20,     0x4cc0ac3f,     0x05a08020,     0x04b0e3e0,\n+    0x0470e7e1,     0x042f9c20,     0x043f9c35,     0x047f9c20,\n+    0x04ff9c20,     0x04299420,     0x04319160,     0x0461943e,\n+    0x04a19020,     0x042053ff,     0x047f5401,     0x25208028,\n+    0x2538cfe0,     0x2578d001,     0x25b8efe2,     0x25f8f007,\n+    0xa400a3e0,     0xa4a8a7ea,     0xa547a814,     0xa4084ffe,\n+    0xa55c53e0,     0xa5e1540b,     0xe400fbf6,     0xe408ffff,\n+    0xe547e400,     0xe4014be0,     0xe4a84fe0,     0xe5f15000,\n+    0x858043e0,     0x85a043ff,     0xe59f5d08,     0x1e601000,\n+>>>>>>> master\n@@ -1156,0 +1294,1 @@\n+<<<<<<< HEAD\n@@ -1190,0 +1329,35 @@\n+=======\n+    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8358303,\n+    0xf8280299,     0xf8301051,     0xf8212300,     0xf8243183,\n+    0xf83f515c,     0xf83a4182,     0xf830703f,     0xf82d601d,\n+    0xf8b3822c,     0xf8b6038d,     0xf8be103f,     0xf8ba209c,\n+    0xf8be30c4,     0xf8be51fa,     0xf8a94188,     0xf8a07034,\n+    0xf8b86002,     0xf8e98358,     0xf8f0007e,     0xf8ea1157,\n+    0xf8e42050,     0xf8eb3148,     0xf8ef5051,     0xf8ea418c,\n+    0xf8ef704d,     0xf8e76354,     0xf8708044,     0xf86401ec,\n+    0xf87511f0,     0xf86b22f5,     0xf86c32fa,     0xf87c516e,\n+    0xf8784181,     0xf87f720a,     0xf8676062,     0xb82d8233,\n+    0xb8300023,     0xb82b10be,     0xb82823af,     0xb83e3280,\n+    0xb82752f4,     0xb83c4375,     0xb8397025,     0xb83763f0,\n+    0xb8a5812c,     0xb8bc03af,     0xb8b6127f,     0xb8bf21c5,\n+    0xb8b031ff,     0xb8bb5214,     0xb8ac412b,     0xb8a6723e,\n+    0xb8bb63dc,     0xb8e7828a,     0xb8ea0304,     0xb8f112d1,\n+    0xb8e321fd,     0xb8f63273,     0xb8f651e2,     0xb8e6420c,\n+    0xb8eb72ed,     0xb8e1627e,     0xb8658051,     0xb87001b6,\n+    0xb86a13b5,     0xb87b236c,     0xb86333e1,     0xb8785233,\n+    0xb869437c,     0xb86f72a7,     0xb877633f,     0xce3a47c2,\n+    0xce110aca,     0xce788c11,     0xce8296d9,     0xce7b806c,\n+    0xce70879d,     0xcec080da,     0xce718b89,     0x04670087,\n+    0x042806c9,     0x659e029b,     0x6590081a,     0x65c80723,\n+    0x04d6bb55,     0x04000096,     0x04508071,     0x041aa8c1,\n+    0x04939ce9,     0x045194b6,     0x041013c8,     0x04d7a171,\n+    0x049ea35c,     0x04c80dbc,     0x040a18b0,     0x044109ed,\n+    0x049cb57a,     0x65809096,     0x658d9233,     0x65c68c4e,\n+    0x658796e3,     0x65828626,     0x049db21b,     0x6582bc62,\n+    0x6580b266,     0x65c1b50c,     0x658db013,     0x65c18677,\n+    0x65a010cd,     0x65a8332e,     0x65bb56d6,     0x65b46e23,\n+    0x04405ce4,     0x048476d0,     0x042b32c9,     0x04b033c5,\n+    0x04613176,     0x04da3608,     0x0498248f,     0x041927a8,\n+    0x04c833bc,     0x044a2c49,     0x658720fc,     0x6586363a,\n+    0x65d832a8,     0x048136a5,\n+>>>>>>> master\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":376,"deletions":202,"binary":false,"changes":578,"status":"modified"}]}