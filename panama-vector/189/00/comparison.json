{"files":[{"patch":"@@ -7918,0 +7918,26 @@\n+void Assembler::evplzcntd(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512cd() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16(0x44, (0xC0 | encode));\n+}\n+\n+void Assembler::evplzcntq(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512cd() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV,\/* input_size_in_bits *\/ EVEX_32bit);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16(0x44, (0xC0 | encode));\n+}\n+\n@@ -8448,0 +8474,14 @@\n+void Assembler::vpunpckhwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x69, (0xC0 | encode));\n+}\n+\n+void Assembler::vpunpcklwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x61, (0xC0 | encode));\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":40,"deletions":0,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -1935,0 +1935,6 @@\n+  \/\/ Interleave High Word\n+  void vpunpckhwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+\n+  \/\/ Interleave Low Word\n+  void vpunpcklwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+\n@@ -2426,0 +2432,2 @@\n+  void evplzcntd(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len);\n+  void evplzcntq(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -4532,0 +4532,105 @@\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_evex(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                        XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                                        KRegister ktmp, Register rtmp, bool merge, int vec_enc) {\n+  assert(is_integral_type(bt), \"\");\n+  assert(VM_Version::supports_avx512vl() || vec_enc == Assembler::AVX_512bit, \"\");\n+  assert(VM_Version::supports_avx512cd(), \"\");\n+  switch(bt) {\n+    case T_LONG:\n+      evplzcntq(dst, ktmp, src, merge, vec_enc);\n+      break;\n+    case T_INT:\n+      evplzcntd(dst, ktmp, src, merge, vec_enc);\n+      break;\n+    case T_SHORT:\n+      vpternlogd(xtmp1, 0xff, xtmp1, xtmp1, vec_enc);\n+      vpunpcklwd(xtmp2, xtmp1, src, vec_enc);\n+      evplzcntd(xtmp2, k0, xtmp2, merge, vec_enc);\n+      vpunpckhwd(dst, xtmp1, src, vec_enc);\n+      evplzcntd(dst, k0, dst, merge, vec_enc);\n+      vpackusdw(dst, xtmp2, dst, vec_enc);\n+      break;\n+    case T_BYTE:\n+      \/\/ T1 = Compute leading zero counts of 4 LSB bits of each byte by\n+      \/\/ accessing the lookup table.\n+      \/\/ T2 = Compute leading zero counts of 4 MSB bits of each byte by\n+      \/\/ accessing the lookup table.\n+      \/\/ Add T1 to T2 if 4 MSB bits of byte are all zeros.\n+      assert(VM_Version::supports_avx512bw(), \"\");\n+      evmovdquq(xtmp1, ExternalAddress(StubRoutines::x86::vector_count_leading_zeros_lut()), vec_enc, rtmp);\n+      movl(rtmp, 0x0F0F0F0F);\n+      evpbroadcastd(xtmp2, rtmp, vec_enc);\n+      vpand(dst, xtmp2, src, vec_enc);\n+      vpshufb(dst, xtmp1, dst, vec_enc);\n+      vpsrlw(xtmp3, src, 4, vec_enc);\n+      vpand(xtmp3, xtmp2, xtmp3, vec_enc);\n+      vpshufb(xtmp2, xtmp1, xtmp3, vec_enc);\n+      vpxor(xtmp1, xtmp1, xtmp1, vec_enc);\n+      evpcmpeqb(ktmp, xtmp1, xtmp3, vec_enc);\n+      vpaddb(dst, dst, xtmp2, vec_enc);\n+      evpblendmb(dst, ktmp, xtmp2, dst, true, vec_enc);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_avx(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                       XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                                       Register rtmp, int vec_enc) {\n+  assert(is_integral_type(bt), \"unexpected type\");\n+  assert(vec_enc < Assembler::AVX_512bit, \"\");\n+  vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_count_leading_zeros_lut()));\n+  movl(rtmp, 0x0F0F0F0F);\n+  movdl(xtmp2, rtmp);\n+  vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+\n+  \/\/ T1 = Compute leading zero counts of 4 LSB bits of each byte by\n+  \/\/ accessing the lookup table.\n+  vpand(dst, xtmp2, src, vec_enc);\n+  vpshufb(dst, xtmp1, dst, vec_enc);\n+\n+  \/\/ T2 = Compute leading zero counts of 4 MSB bits of each byte by\n+  \/\/ accessing the lookup table.\n+  vpsrlw(xtmp3, src, 4, vec_enc);\n+  vpand(xtmp3, xtmp2, xtmp3, vec_enc);\n+  vpshufb(xtmp2, xtmp1, xtmp3, vec_enc);\n+\n+  \/\/ Add T1 to T2 if 4 MSB bits of byte are all zeros.\n+  vpxor(xtmp1, xtmp1, xtmp1, vec_enc);\n+  vpcmpeqb(xtmp3, xtmp1, xtmp3, vec_enc);\n+  vpaddb(dst, dst, xtmp2, vec_enc);\n+  vpblendvb(dst, xtmp2, dst, xtmp3, vec_enc);\n+\n+  if (bt != T_BYTE) {\n+    \/\/ Add zero counts of lower byte and upper byte of a word if\n+    \/\/ upper byte holds a zero value.\n+    vpsrlw(xtmp3, src, 8, vec_enc);\n+    vpcmpeqw(xtmp3, xtmp1, xtmp3, vec_enc);\n+    vpsllw(xtmp2, dst, 8, vec_enc);\n+    vpaddw(xtmp2, xtmp2, dst, vec_enc);\n+    vpblendvb(dst, dst, xtmp2, xtmp3, vec_enc);\n+    vpsrlw(dst, dst, 8, vec_enc);\n+    if (!is_subword_type(bt)) {\n+      \/\/ Add zero counts of lower word and upper word of a double word if\n+      \/\/ upper word holds a zero value.\n+      vpsrld(xtmp3, src, 16, vec_enc);\n+      vpcmpeqd(xtmp3, xtmp1, xtmp3, vec_enc);\n+      vpslld(xtmp2, dst, 16, vec_enc);\n+      vpaddd(xtmp2, xtmp2, dst, vec_enc);\n+      vpblendvb(dst, dst, xtmp2, xtmp3, vec_enc);\n+      vpsrld(dst, dst, 16, vec_enc);\n+      if (bt == T_LONG) {\n+        \/\/ Add zero counts of lower doubleword and upper doubleword of a\n+        \/\/ quadword if upper doubleword holds a zero value.\n+        vpsrlq(xtmp3, src, 32, vec_enc);\n+        vpcmpeqq(xtmp3, xtmp1, xtmp3, vec_enc);\n+        vpsllq(xtmp2, dst, 32, vec_enc);\n+        vpaddq(xtmp2, xtmp2, dst, vec_enc);\n+        vpblendvb(dst, dst, xtmp2, xtmp3, vec_enc);\n+        vpsrlq(dst, dst, 32, vec_enc);\n+      }\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":105,"deletions":0,"binary":false,"changes":105,"status":"modified"},{"patch":"@@ -331,0 +331,8 @@\n+  void vector_count_leading_zeros_evex(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                       XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                       KRegister ktmp, Register rtmp, bool merge, int vec_enc);\n+\n+  void vector_count_leading_zeros_avx(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                      XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                      Register rtmp, int vec_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -192,0 +192,2 @@\n+      case Op_CountLeadingZerosV:\n+         return VM_Version::supports_avx512cd() && (ety == T_INT || ety == T_LONG) ? 0 : 40;\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -591,0 +591,24 @@\n+  address generate_count_leading_zeros_lut(const char *stub_name) {\n+    __ align64();\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    return start;\n+  }\n+\n+\n@@ -4030,0 +4054,1 @@\n+    StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut(\"count_leading_zeros_lut\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -798,0 +798,15 @@\n+  address generate_count_leading_zeros_lut(const char *stub_name) {\n+    __ align64();\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    return start;\n+  }\n+\n@@ -7730,0 +7745,1 @@\n+    StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut(\"count_leading_zeros_lut\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+address StubRoutines::x86::_vector_count_leading_zeros_lut = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -181,0 +181,1 @@\n+  static address _vector_count_leading_zeros_lut;\n@@ -344,0 +345,4 @@\n+  static address vector_count_leading_zeros_lut() {\n+    return _vector_count_leading_zeros_lut;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1908,0 +1908,5 @@\n+    case Op_CountLeadingZerosV:\n+      if (UseAVX < 2) {\n+        return false;\n+      }\n+      break;\n@@ -2055,0 +2060,4 @@\n+    case Op_CountLeadingZerosV:\n+      if ((bt == T_INT || bt == T_LONG) && VM_Version::supports_avx512cd()) {\n+        return true;\n+      }\n@@ -8976,0 +8985,95 @@\n+\/\/ ---------------------------------- Vector Count Leading Zeros -----------------------------------\n+\n+instruct vcount_leading_zeros_IL_reg_evex(vec dst, vec src) %{\n+  predicate((Matcher::vector_element_basic_type(n->in(1)) == T_INT ||\n+             Matcher::vector_element_basic_type(n->in(1)) == T_LONG) &&\n+             VM_Version::supports_avx512cd() &&\n+             (VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64));\n+  match(Set dst (CountLeadingZerosV src));\n+  format %{ \"vector_count_leading_zeros $dst, $src\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    BasicType rbt = Matcher::vector_element_basic_type(this);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, xnoreg,\n+                                       xnoreg, xnoreg, k0, noreg, true, vlen_enc);\n+    \/\/ TODO: Once auto-vectorizer supports ConvL2I operation, CountLeadingZerosV\n+    \/\/ should be succeeded by its corresponding vector IR and following\n+    \/\/ special handling should be removed.\n+    if (rbt == T_INT && bt == T_LONG) {\n+      __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_IL_reg_evex_masked(vec dst, vec src, kReg mask) %{\n+  predicate((Matcher::vector_element_basic_type(n->in(1)) == T_INT ||\n+             Matcher::vector_element_basic_type(n->in(1)) == T_LONG) &&\n+             VM_Version::supports_avx512cd() &&\n+             (VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64));\n+  match(Set dst (CountLeadingZerosV src mask));\n+  format %{ \"vector_count_leading_zeros $dst, $src, $mask\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, xnoreg, xnoreg,\n+                                       xnoreg, $mask$$KRegister, noreg, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_short_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_SHORT &&\n+             VM_Version::supports_avx512cd() &&\n+             (VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64));\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2);\n+  format %{ \"vector_count_leading_zeros $dst, $src!\\t using $xtmp1 and $xtmp2 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                       $xtmp2$$XMMRegister, xnoreg, knoreg, noreg, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_byte_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, kReg ktmp, rRegP rtmp) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_BYTE &&\n+             (VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64));\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP ktmp, TEMP rtmp);\n+  format %{ \"vector_count_leading_zeros $dst, $src!\\t using $xtmp1, $xtmp2, $xtmp3, $ktmp and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $ktmp$$KRegister,\n+                                       $rtmp$$Register, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp) %{\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n->in(1)) < 64);\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp);\n+  format %{ \"vector_count_leading_zeros $dst, $src\\t! using $xtmp1, $xtmp2, $xtmp3, and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    BasicType rbt = Matcher::vector_element_basic_type(this);\n+    __ vector_count_leading_zeros_avx(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                      $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    \/\/ TODO: Once auto-vectorizer supports ConvL2I operation, CountLeadingZerosV\n+    \/\/ should be succeeded by its corresponding vector IR and following\n+    \/\/ special handling should be removed.\n+    if (rbt == T_INT && bt == T_LONG) {\n+      __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":104,"deletions":0,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -978,0 +978,4 @@\n+      case Op_CountLeadingZerosV: {\n+        const TypeVect* vt = n->bottom_type()->is_vect();\n+        body_size += Matcher::vector_op_pre_select_sz_estimate(n->Opcode(), vt->element_basic_type(), vt->length());\n+      } break;\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2566,1 +2566,2 @@\n-                 opc == Op_PopCountI || opc == Op_PopCountL) {\n+                 opc == Op_PopCountI || opc == Op_PopCountL ||\n+                 opc == Op_CountLeadingZerosI || opc == Op_CountLeadingZerosL) {\n@@ -2958,3 +2959,3 @@\n-  if (VectorNode::is_vpopcnt_long(use)) {\n-    \/\/ VPOPCNT_LONG takes long and produces int - hence the special checks\n-    \/\/ on alignment and size.\n+  if (VectorNode::is_downcasting_l2i_candidate(use)) {\n+    \/\/ PopCountL\/CountLeadingZerosL takes long and produces\n+    \/\/ int - hence the special checks on alignment and size.\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -314,3 +314,7 @@\n-bool VectorNode::is_vpopcnt_long(Node* n) {\n-  if (n->Opcode() == Op_PopCountL) {\n-    return true;\n+bool VectorNode::is_downcasting_l2i_candidate(Node* n) {\n+  switch(n->Opcode()) {\n+    case Op_PopCountL:\n+    case Op_CountLeadingZerosL:\n+       return true;\n+    default:\n+       return false;\n@@ -318,1 +322,0 @@\n-  return false;\n@@ -321,3 +324,0 @@\n-\n-\n-\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -96,1 +96,1 @@\n-  static bool is_vpopcnt_long(Node* n);\n+  static bool is_downcasting_l2i_candidate(Node* n);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}