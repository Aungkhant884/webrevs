{"files":[{"patch":"@@ -7954,0 +7954,24 @@\n+void Assembler::evplzcntd(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512cd() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16(0x44, (0xC0 | encode));\n+}\n+\n+void Assembler::evplzcntq(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512cd() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ true,\/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16(0x44, (0xC0 | encode));\n+}\n+\n@@ -8484,0 +8508,14 @@\n+void Assembler::vpunpckhwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x69, (0xC0 | encode));\n+}\n+\n+void Assembler::vpunpcklwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x61, (0xC0 | encode));\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":38,"deletions":0,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -1937,0 +1937,6 @@\n+  \/\/ Interleave High Word\n+  void vpunpckhwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+\n+  \/\/ Interleave Low Word\n+  void vpunpcklwd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+\n@@ -2428,0 +2434,2 @@\n+  void evplzcntd(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len);\n+  void evplzcntq(XMMRegister dst, KRegister mask, XMMRegister src, bool merge, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -4436,4 +4436,14 @@\n-void C2_MacroAssembler::vbroadcastd(XMMRegister dst, int imm32, Register rtmp, int vec_enc) {\n-  if (VM_Version::supports_avx512vl()) {\n-    movl(rtmp, imm32);\n-    evpbroadcastd(dst, rtmp, vec_enc);\n+void C2_MacroAssembler::vbroadcast(BasicType bt, XMMRegister dst, int imm32, Register rtmp, int vec_enc) {\n+  int lane_size = type2aelembytes(bt);\n+  bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);\n+  if ((is_LP64 || lane_size < 8) &&\n+      ((is_non_subword_integral_type(bt) && VM_Version::supports_avx512vl()) ||\n+       (is_subword_type(bt) && VM_Version::supports_avx512bw()))) {\n+    movptr(rtmp, imm32);\n+    switch(lane_size) {\n+      case 1 : evpbroadcastb(dst, rtmp, vec_enc); break;\n+      case 2 : evpbroadcastw(dst, rtmp, vec_enc); break;\n+      case 4 : evpbroadcastd(dst, rtmp, vec_enc); break;\n+      case 8 : evpbroadcastq(dst, rtmp, vec_enc); break;\n+      default : ShouldNotReachHere(); break;\n+    }\n@@ -4441,3 +4451,9 @@\n-    movl(rtmp, imm32);\n-    movdl(dst, rtmp);\n-    vpbroadcastd(dst, dst, vec_enc);\n+    movptr(rtmp, imm32);\n+    LP64_ONLY(movq(dst, rtmp)) NOT_LP64(movdl(dst, rtmp));\n+    switch(lane_size) {\n+      case 1 : vpbroadcastb(dst, dst, vec_enc); break;\n+      case 2 : vpbroadcastw(dst, dst, vec_enc); break;\n+      case 4 : vpbroadcastd(dst, dst, vec_enc); break;\n+      case 8 : vpbroadcastq(dst, dst, vec_enc); break;\n+      default : ShouldNotReachHere(); break;\n+    }\n@@ -4480,1 +4496,1 @@\n-  vbroadcastd(xtmp1, 0x0F0F0F0F, rtmp, vec_enc);\n+  vbroadcast(T_INT, xtmp1, 0x0F0F0F0F, rtmp, vec_enc);\n@@ -4506,1 +4522,1 @@\n-  vbroadcastd(xtmp2, 0x00FF00FF, rtmp, vec_enc);\n+  vbroadcast(T_INT, xtmp2, 0x00FF00FF, rtmp, vec_enc);\n@@ -4522,0 +4538,3 @@\n+    case T_LONG:\n+      vector_popcount_long(dst, src, xtmp1, xtmp2, rtmp, vec_enc);\n+      break;\n@@ -4585,2 +4604,1 @@\n-    movl(rtmp, 0x0F0F0F0F);\n-    evpbroadcastd(xtmp2, rtmp, vec_enc);\n+    vbroadcast(T_INT, xtmp2, 0x0F0F0F0F, rtmp, vec_enc);\n@@ -4605,2 +4623,1 @@\n-    movl(rtmp, 0x0f0f0f0f);\n-    evpbroadcastd(xtmp1, rtmp, vec_enc);\n+    vbroadcast(T_INT, xtmp1, 0x0F0F0F0F, rtmp, vec_enc);\n@@ -4616,2 +4633,1 @@\n-    movl(rtmp, 0x33333333);\n-    evpbroadcastd(xtmp2, rtmp, vec_enc);\n+    vbroadcast(T_INT, xtmp2, 0x33333333, rtmp, vec_enc);\n@@ -4625,2 +4641,1 @@\n-    movl(rtmp, 0x55555555);\n-    evpbroadcastd(xtmp2, rtmp, vec_enc);\n+    vbroadcast(T_INT, xtmp2, 0x55555555, rtmp, vec_enc);\n@@ -4637,3 +4652,1 @@\n-    movl(rtmp, 0x0F0F0F0F);\n-    movdl(xtmp2, rtmp);\n-    vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+    vbroadcast(T_INT, xtmp2, 0x0F0F0F0F, rtmp, vec_enc);\n@@ -4682,2 +4695,1 @@\n-      movl(rtmp, 0x00FF00FF);\n-      evpbroadcastd(dst, rtmp, vec_enc);\n+      vbroadcast(T_INT, dst, 0x00FF00FF, rtmp, vec_enc);\n@@ -4726,0 +4738,246 @@\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_evex(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                        XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                                        KRegister ktmp, Register rtmp, bool merge, int vec_enc) {\n+  assert(is_integral_type(bt), \"\");\n+  assert(VM_Version::supports_avx512vl() || vec_enc == Assembler::AVX_512bit, \"\");\n+  assert(VM_Version::supports_avx512cd(), \"\");\n+  switch(bt) {\n+    case T_LONG:\n+      evplzcntq(dst, ktmp, src, merge, vec_enc);\n+      break;\n+    case T_INT:\n+      evplzcntd(dst, ktmp, src, merge, vec_enc);\n+      break;\n+    case T_SHORT:\n+      vpternlogd(xtmp1, 0xff, xtmp1, xtmp1, vec_enc);\n+      vpunpcklwd(xtmp2, xtmp1, src, vec_enc);\n+      evplzcntd(xtmp2, k0, xtmp2, merge, vec_enc);\n+      vpunpckhwd(dst, xtmp1, src, vec_enc);\n+      evplzcntd(dst, k0, dst, merge, vec_enc);\n+      vpackusdw(dst, xtmp2, dst, vec_enc);\n+      break;\n+    case T_BYTE:\n+      \/\/ T1 = Compute leading zero counts of 4 LSB bits of each byte by\n+      \/\/ accessing the lookup table.\n+      \/\/ T2 = Compute leading zero counts of 4 MSB bits of each byte by\n+      \/\/ accessing the lookup table.\n+      \/\/ Add T1 to T2 if 4 MSB bits of byte are all zeros.\n+      assert(VM_Version::supports_avx512bw(), \"\");\n+      evmovdquq(xtmp1, ExternalAddress(StubRoutines::x86::vector_count_leading_zeros_lut()), vec_enc, rtmp);\n+      movl(rtmp, 0x0F0F0F0F);\n+      evpbroadcastd(dst, rtmp, vec_enc);\n+      vpand(xtmp2, dst, src, vec_enc);\n+      vpshufb(xtmp2, xtmp1, xtmp2, vec_enc);\n+      vpsrlw(xtmp3, src, 4, vec_enc);\n+      vpand(xtmp3, dst, xtmp3, vec_enc);\n+      vpshufb(dst, xtmp1, xtmp3, vec_enc);\n+      vpxor(xtmp1, xtmp1, xtmp1, vec_enc);\n+      evpcmpeqb(ktmp, xtmp1, xtmp3, vec_enc);\n+      evpaddb(dst, ktmp, dst, xtmp2, true, vec_enc);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_byte_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                            XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc) {\n+  vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_count_leading_zeros_lut()));\n+  movl(rtmp, 0x0F0F0F0F);\n+  movdl(xtmp2, rtmp);\n+  vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+  \/\/ T1 = Compute leading zero counts of 4 LSB bits of each byte by\n+  \/\/ accessing the lookup table.\n+  vpand(dst, xtmp2, src, vec_enc);\n+  vpshufb(dst, xtmp1, dst, vec_enc);\n+  \/\/ T2 = Compute leading zero counts of 4 MSB bits of each byte by\n+  \/\/ accessing the lookup table.\n+  vpsrlw(xtmp3, src, 4, vec_enc);\n+  vpand(xtmp3, xtmp2, xtmp3, vec_enc);\n+  vpshufb(xtmp2, xtmp1, xtmp3, vec_enc);\n+  \/\/ Add T1 to T2 if 4 MSB bits of byte are all zeros.\n+  vpxor(xtmp1, xtmp1, xtmp1, vec_enc);\n+  vpcmpeqb(xtmp3, xtmp1, xtmp3, vec_enc);\n+  vpaddb(dst, dst, xtmp2, vec_enc);\n+  vpblendvb(dst, xtmp2, dst, xtmp3, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_short_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                             XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc) {\n+   vector_count_leading_zeros_byte_avx(dst, src, xtmp1, xtmp2, xtmp3, rtmp, vec_enc);\n+   \/\/ Add zero counts of lower byte and upper byte of a word if\n+   \/\/ upper byte holds a zero value.\n+   vpsrlw(xtmp3, src, 8, vec_enc);\n+   vpcmpeqw(xtmp3, xtmp1, xtmp3, vec_enc);\n+   vpsllw(xtmp2, dst, 8, vec_enc);\n+   vpaddw(xtmp2, xtmp2, dst, vec_enc);\n+   vpblendvb(dst, dst, xtmp2, xtmp3, vec_enc);\n+   vpsrlw(dst, dst, 8, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_int_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                           XMMRegister xtmp2, XMMRegister xtmp3, int vec_enc) {\n+   \/\/ Since IEEE 754 floating point format represents mantissa in 1.0 format\n+   \/\/ hence biased exponent can be used to compute leading zero count as per\n+   \/\/ following formula:-\n+   \/\/ LZCNT = 32 - (biased_exp - 127)\n+   \/\/ Special handling has been introduced for Zero, Max_Int and -ve source values.\n+\n+   \/\/ Broadcast 0xFF\n+   vpcmpeqd(xtmp1, xtmp1, xtmp1, vec_enc);\n+   vpsrld(xtmp1, xtmp1, 24, vec_enc);\n+\n+   \/\/ Extract biased exponent.\n+   vcvtdq2ps(dst, src, vec_enc);\n+   vpsrld(dst, dst, 23, vec_enc);\n+   vpand(dst, dst, xtmp1, vec_enc);\n+\n+   \/\/ Broadcast 127.\n+   vpsrld(xtmp1, xtmp1, 1, vec_enc);\n+   \/\/ Exponent = biased_exp - 127\n+   vpsubd(dst, dst, xtmp1, vec_enc);\n+\n+   \/\/ Exponent = Exponent  + 1\n+   vpsrld(xtmp3, xtmp1, 6, vec_enc);\n+   vpaddd(dst, dst, xtmp3, vec_enc);\n+\n+   \/\/ Replace -ve exponent with zero, exponent is -ve when src\n+   \/\/ lane contains a zero value.\n+   vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+   vblendvps(dst, dst, xtmp2, dst, vec_enc);\n+\n+   \/\/ Rematerialize broadcast 32.\n+   vpslld(xtmp1, xtmp3, 5, vec_enc);\n+   \/\/ Exponent is 32 if corresponding source lane contains max_int value.\n+   vpcmpeqd(xtmp2, dst, xtmp1, vec_enc);\n+   \/\/ LZCNT = 32 - exponent\n+   vpsubd(dst, xtmp1, dst, vec_enc);\n+\n+   \/\/ Replace LZCNT with a value 1 if corresponding source lane\n+   \/\/ contains max_int value.\n+   vpblendvb(dst, dst, xtmp3, xtmp2, vec_enc);\n+\n+   \/\/ Replace biased_exp with 0 if source lane value is less than zero.\n+   vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+   vblendvps(dst, dst, xtmp2, src, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_long_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                            XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc) {\n+  vector_count_leading_zeros_short_avx(dst, src, xtmp1, xtmp2, xtmp3, rtmp, vec_enc);\n+  \/\/ Add zero counts of lower word and upper word of a double word if\n+  \/\/ upper word holds a zero value.\n+  vpsrld(xtmp3, src, 16, vec_enc);\n+  vpcmpeqd(xtmp3, xtmp1, xtmp3, vec_enc);\n+  vpslld(xtmp2, dst, 16, vec_enc);\n+  vpaddd(xtmp2, xtmp2, dst, vec_enc);\n+  vpblendvb(dst, dst, xtmp2, xtmp3, vec_enc);\n+  vpsrld(dst, dst, 16, vec_enc);\n+  \/\/ Add zero counts of lower doubleword and upper doubleword of a\n+  \/\/ quadword if upper doubleword holds a zero value.\n+  vpsrlq(xtmp3, src, 32, vec_enc);\n+  vpcmpeqq(xtmp3, xtmp1, xtmp3, vec_enc);\n+  vpsllq(xtmp2, dst, 32, vec_enc);\n+  vpaddq(xtmp2, xtmp2, dst, vec_enc);\n+  vpblendvb(dst, dst, xtmp2, xtmp3, vec_enc);\n+  vpsrlq(dst, dst, 32, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_count_leading_zeros_avx(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                       XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                                       Register rtmp, int vec_enc) {\n+  assert(is_integral_type(bt), \"unexpected type\");\n+  assert(vec_enc < Assembler::AVX_512bit, \"\");\n+  switch(bt) {\n+    case T_LONG:\n+      vector_count_leading_zeros_long_avx(dst, src, xtmp1, xtmp2, xtmp3, rtmp, vec_enc);\n+      break;\n+    case T_INT:\n+      vector_count_leading_zeros_int_avx(dst, src, xtmp1, xtmp2, xtmp3, vec_enc);\n+      break;\n+    case T_SHORT:\n+      vector_count_leading_zeros_short_avx(dst, src, xtmp1, xtmp2, xtmp3, rtmp, vec_enc);\n+      break;\n+    case T_BYTE:\n+      vector_count_leading_zeros_byte_avx(dst, src, xtmp1, xtmp2, xtmp3, rtmp, vec_enc);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::vpsub(BasicType bt, XMMRegister dst, XMMRegister src1, XMMRegister src2, int vec_enc) {\n+  switch(bt) {\n+    case T_BYTE:\n+      vpsubb(dst, src1, src2, vec_enc);\n+      break;\n+    case T_SHORT:\n+      vpsubw(dst, src1, src2, vec_enc);\n+      break;\n+    case T_INT:\n+      vpsubd(dst, src1, src2, vec_enc);\n+      break;\n+    case T_LONG:\n+      vpsubq(dst, src1, src2, vec_enc);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::vpadd(BasicType bt, XMMRegister dst, XMMRegister src1, XMMRegister src2, int vec_enc) {\n+  switch(bt) {\n+    case T_BYTE:\n+      vpaddb(dst, src1, src2, vec_enc);\n+      break;\n+    case T_SHORT:\n+      vpaddw(dst, src1, src2, vec_enc);\n+      break;\n+    case T_INT:\n+      vpaddd(dst, src1, src2, vec_enc);\n+      break;\n+    case T_LONG:\n+      vpaddq(dst, src1, src2, vec_enc);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+\/\/ Trailing zero count computation is based on leading zero count operation as per\n+\/\/ following equation. All AVX3 targets support AVX512CD feature which offers\n+\/\/ direct vector instruction to compute leading zero count.\n+\/\/      CTZ = PRIM_TYPE_WIDHT - CLZ((x - 1) & ~x)\n+void C2_MacroAssembler::vector_count_trailing_zeros_evex(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                         XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                                         XMMRegister xtmp4, KRegister ktmp, Register rtmp, int vec_enc) {\n+  assert(is_integral_type(bt), \"\");\n+  int bcast_value [] = { 0x8, 0x10, 0, 0x20, 0, 0, 0, 0x40 };\n+  \/\/ xtmp = -1\n+  vpternlogd(xtmp4, 0xff, xtmp4, xtmp4, vec_enc);\n+  \/\/ xtmp = xtmp + src\n+  vpadd(bt, xtmp4, xtmp4, src, vec_enc);\n+  \/\/ xtmp = xtmp & ~src\n+  vpternlogd(xtmp4, 0x40, xtmp4, src, vec_enc);\n+  vector_count_leading_zeros_evex(bt, dst, xtmp4, xtmp1, xtmp2, xtmp3, ktmp, rtmp, true, vec_enc);\n+  vbroadcast(bt, xtmp4, bcast_value[type2aelembytes(bt) - 1], rtmp, vec_enc);\n+  vpsub(bt, dst, xtmp4, dst, vec_enc);\n+}\n+\n+\/\/ Trailing zero count computation for AVX2 targets is based on popcount operation as per following equation\n+\/\/      CTZ = PRIM_TYPE_WIDHT - POPC(x | -x)\n+void C2_MacroAssembler::vector_count_trailing_zeros_avx(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                        XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc) {\n+  assert(is_integral_type(bt), \"\");\n+  int bcast_value [] = { 0x8, 0x10, 0, 0x20, 0, 0, 0, 0x40 };\n+  \/\/ xtmp = 0\n+  vpxor(xtmp3 , xtmp3, xtmp3, vec_enc);\n+  \/\/ xtmp = 0 - src\n+  vpsub(bt, xtmp3, xtmp3, src, vec_enc);\n+  \/\/ xtmp = xtmp | src\n+  vpor(xtmp3, xtmp3, src, vec_enc);\n+  vector_popcount_integral(bt, dst, xtmp3, xtmp1, xtmp2, rtmp, vec_enc);\n+  vbroadcast(bt, xtmp1, bcast_value[type2aelembytes(bt) - 1], rtmp, vec_enc);\n+  vpsub(bt, dst, xtmp1, dst, vec_enc);\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":280,"deletions":22,"binary":false,"changes":302,"status":"modified"},{"patch":"@@ -350,1 +350,1 @@\n-  void vbroadcastd(XMMRegister dst, int imm32, Register rtmp, int vec_enc);\n+  void vbroadcast(BasicType bt, XMMRegister dst, int imm32, Register rtmp, int vec_enc);\n@@ -356,0 +356,30 @@\n+  void vector_count_leading_zeros_evex(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                       XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3,\n+                                       KRegister ktmp, Register rtmp, bool merge, int vec_enc);\n+\n+  void vector_count_leading_zeros_byte_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc);\n+\n+  void vector_count_leading_zeros_short_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                            XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc);\n+\n+  void vector_count_leading_zeros_int_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                          XMMRegister xtmp2, XMMRegister xtmp3, int vec_enc);\n+\n+  void vector_count_leading_zeros_long_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc);\n+\n+  void vector_count_leading_zeros_avx(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                      XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc);\n+\n+  void vpadd(BasicType bt, XMMRegister dst, XMMRegister src1, XMMRegister src2, int vec_enc);\n+\n+  void vpsub(BasicType bt, XMMRegister dst, XMMRegister src1, XMMRegister src2, int vec_enc);\n+\n+  void vector_count_trailing_zeros_evex(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                        XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4, KRegister ktmp,\n+                                        Register rtmp, int vec_enc);\n+\n+  void vector_count_trailing_zeros_avx(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                       XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp, int vec_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":31,"deletions":1,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -190,0 +190,3 @@\n+      case Op_CountTrailingZerosV:\n+      case Op_CountLeadingZerosV:\n+         return VM_Version::supports_avx512cd() && (ety == T_INT || ety == T_LONG) ? 0 : 40;\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -591,0 +591,24 @@\n+  address generate_count_leading_zeros_lut(const char *stub_name) {\n+    __ align64();\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x02020304, relocInfo::none, 0);\n+    __ emit_data(0x01010101, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    __ emit_data(0x00000000, relocInfo::none, 0);\n+    return start;\n+  }\n+\n+\n@@ -4122,0 +4146,1 @@\n+    StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut(\"count_leading_zeros_lut\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -798,0 +798,15 @@\n+  address generate_count_leading_zeros_lut(const char *stub_name) {\n+    __ align64();\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    __ emit_data64(0x0101010102020304, relocInfo::none);\n+    __ emit_data64(0x0000000000000000, relocInfo::none);\n+    return start;\n+  }\n+\n@@ -7790,0 +7805,1 @@\n+    StubRoutines::x86::_vector_count_leading_zeros_lut = generate_count_leading_zeros_lut(\"count_leading_zeros_lut\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -67,0 +67,1 @@\n+address StubRoutines::x86::_vector_count_leading_zeros_lut = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -181,0 +181,1 @@\n+  static address _vector_count_leading_zeros_lut;\n@@ -348,0 +349,4 @@\n+  static address vector_count_leading_zeros_lut() {\n+    return _vector_count_leading_zeros_lut;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1244,0 +1244,5 @@\n+static inline bool is_vector_popcount_predicate(BasicType bt) {\n+  return (is_subword_type(bt) && VM_Version::supports_avx512_bitalg()) ||\n+         (is_non_subword_integral_type(bt) && VM_Version::supports_avx512_vpopcntdq());\n+}\n+\n@@ -1248,0 +1253,5 @@\n+static inline bool is_clz_non_subword_predicate_evex(BasicType bt, int vlen_bytes) {\n+  return is_non_subword_integral_type(bt) && VM_Version::supports_avx512cd() &&\n+           (VM_Version::supports_avx512vl() || vlen_bytes == 64);\n+}\n+\n@@ -1914,0 +1924,7 @@\n+      break;\n+    case Op_CountTrailingZerosV:\n+    case Op_CountLeadingZerosV:\n+      if (UseAVX < 2) {\n+        return false;\n+      }\n+      break;\n@@ -2068,0 +2085,4 @@\n+    case Op_CountLeadingZerosV:\n+      if ((bt == T_INT || bt == T_LONG) && VM_Version::supports_avx512cd()) {\n+        return true;\n+      }\n@@ -8630,0 +8651,1 @@\n+\n@@ -8631,4 +8653,1 @@\n-  predicate((is_subword_type(Matcher::vector_element_basic_type(n->in(1))) &&\n-              VM_Version::supports_avx512_bitalg()) ||\n-             (is_non_subword_integral_type(Matcher::vector_element_basic_type(n->in(1))) &&\n-              VM_Version::supports_avx512_vpopcntdq()));\n+  predicate(is_vector_popcount_predicate(Matcher::vector_element_basic_type(n->in(1))));\n@@ -8638,1 +8657,1 @@\n-  format %{ \"vector_popcount_integral_evex $dst, $src\" %}\n+  format %{ \"vector_popcount_integral $dst, $src\" %}\n@@ -8655,4 +8674,1 @@\n-  predicate((is_subword_type(Matcher::vector_element_basic_type(n->in(1))) &&\n-              VM_Version::supports_avx512_bitalg()) ||\n-             (is_non_subword_integral_type(Matcher::vector_element_basic_type(n->in(1))) &&\n-              VM_Version::supports_avx512_vpopcntdq()));\n+  predicate(is_vector_popcount_predicate(Matcher::vector_element_basic_type(n->in(1))));\n@@ -8661,1 +8677,1 @@\n-  format %{ \"vector_popcount_integral_evex_masked $dst, $src, $mask\" %}\n+  format %{ \"vector_popcount_integral_masked $dst, $src, $mask\" %}\n@@ -8663,1 +8679,0 @@\n-    int opcode = this->ideal_Opcode();\n@@ -8672,3 +8687,2 @@\n-instruct vpopcountI_avx_reg(vec dst, vec src, vec xtmp1, vec xtmp2, rRegP rtmp) %{\n-  predicate((!VM_Version::supports_avx512_vpopcntdq() && Matcher::vector_element_basic_type(n->in(1)) == T_INT) ||\n-            (!VM_Version::supports_avx512_bitalg() && is_subword_type(Matcher::vector_element_basic_type(n->in(1)))));\n+instruct vpopcount_evx_reg(vec dst, vec src, vec xtmp1, vec xtmp2, rRegP rtmp) %{\n+  predicate(!is_vector_popcount_predicate(Matcher::vector_element_basic_type(n->in(1))));\n@@ -8676,0 +8690,1 @@\n+  match(Set dst (PopCountVL src));\n@@ -8677,1 +8692,1 @@\n-  format %{ \"vector_popcount_int  $dst, $src\\t! using $xtmp1, $xtmp2 and $rtmp as TEMP\" %}\n+  format %{ \"vector_popcount_integral $dst, $src\\t! using $xtmp1, $xtmp2, and $rtmp as TEMP\" %}\n@@ -8679,0 +8694,2 @@\n+    int opcode = this->ideal_Opcode();\n+    int vlen_enc = vector_length_encoding(this, $src);\n@@ -8680,1 +8697,0 @@\n-    int vlen_enc = vector_length_encoding(this);\n@@ -8683,0 +8699,12 @@\n+    \/\/ TODO: Once auto-vectorizer supports ConvL2I operation, PopCountVL\n+    \/\/ should be succeeded by its corresponding vector IR and following\n+    \/\/ special handling should be removed.\n+    if (opcode == Op_PopCountVL && Matcher::vector_element_basic_type(this) == T_INT) {\n+      if (VM_Version::supports_avx512vl()) {\n+        __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+      } else {\n+        assert(VM_Version::supports_avx2(), \"\");\n+        __ vpshufd($dst$$XMMRegister, $dst$$XMMRegister, 8, vlen_enc);\n+        __ vpermq($dst$$XMMRegister, $dst$$XMMRegister, 8, vlen_enc);\n+      }\n+    }\n@@ -8687,3 +8715,30 @@\n-instruct vpopcountL_avx_reg(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp) %{\n-  predicate(!VM_Version::supports_avx512_vpopcntdq());\n-  match(Set dst (PopCountVL src));\n+\/\/ --------------------------------- Vector Trailing Zeros Count --------------------------------------\n+\n+instruct vcount_trailing_zeros_reg_evex(vec dst, vec src, vec xtmp, rRegP rtmp) %{\n+  predicate(is_clz_non_subword_predicate_evex(Matcher::vector_element_basic_type(n->in(1)),\n+                                              Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (CountTrailingZerosV src));\n+  effect(TEMP dst, TEMP xtmp, TEMP rtmp);\n+  ins_cost(400);\n+  format %{ \"vector_count_trailing_zeros $dst, $src!\\t using $xtmp and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    BasicType rbt = Matcher::vector_element_basic_type(this);\n+    __ vector_count_trailing_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, xnoreg,\n+                                        xnoreg, xnoreg, $xtmp$$XMMRegister, k0, $rtmp$$Register, vlen_enc);\n+    \/\/ TODO: Once auto-vectorizer supports ConvL2I operation, CountTrailingZerosV\n+    \/\/ should be succeeded by its corresponding vector IR and following\n+    \/\/ special handling should be removed.\n+    if (bt == T_LONG && rbt == T_INT) {\n+      __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_trailing_zeros_short_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_SHORT &&\n+            VM_Version::supports_avx512cd() &&\n+            (VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64));\n+  match(Set dst (CountTrailingZerosV src));\n@@ -8691,1 +8746,2 @@\n-  format %{ \"vector_popcount_long  $dst, $src\\t! using $xtmp1, $xtmp2, $xtmp3, and $rtmp as TEMP\" %}\n+  ins_cost(400);\n+  format %{ \"vector_count_trailing_zeros $dst, $src!\\t using $xtmp1, $xtmp2, $xtmp3 and $rtmp as TEMP\" %}\n@@ -8694,3 +8750,34 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    __ vector_popcount_long($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n-                            $xtmp2$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_trailing_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                        $xtmp2$$XMMRegister, xnoreg, $xtmp3$$XMMRegister, k0, $rtmp$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_trailing_zeros_byte_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, kReg ktmp, rRegP rtmp) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_BYTE && VM_Version::supports_avx512vlbw());\n+  match(Set dst (CountTrailingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, TEMP ktmp, TEMP rtmp);\n+  ins_cost(400);\n+  format %{ \"vector_count_trailing_zeros $dst, $src!\\t using $xtmp1, $xtmp2, $xtmp3, $xtmp4, $ktmp and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_trailing_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                        $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister,\n+                                        $ktmp$$KRegister, $rtmp$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_trailing_zeros_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp) %{\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n->in(1)) < 64);\n+  match(Set dst (CountTrailingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp);\n+  format %{ \"vector_count_trailing_zeros $dst, $src\\t! using $xtmp1, $xtmp2, $xtmp3, and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    BasicType rbt = Matcher::vector_element_basic_type(this);\n+    __ vector_count_trailing_zeros_avx(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, vlen_enc);\n@@ -8700,1 +8787,1 @@\n-    if (bt == T_INT) {\n+    if (bt == T_LONG && rbt == T_INT) {\n@@ -8713,0 +8800,1 @@\n+\n@@ -9075,0 +9163,106 @@\n+\/\/ ---------------------------------- Vector Count Leading Zeros -----------------------------------\n+\n+instruct vcount_leading_zeros_IL_reg_evex(vec dst, vec src) %{\n+  predicate(is_clz_non_subword_predicate_evex(Matcher::vector_element_basic_type(n->in(1)),\n+                                              Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (CountLeadingZerosV src));\n+  format %{ \"vector_count_leading_zeros $dst, $src\" %}\n+  ins_encode %{\n+     int vlen_enc = vector_length_encoding(this, $src);\n+     BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+     BasicType rbt = Matcher::vector_element_basic_type(this);\n+     __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, xnoreg,\n+                                        xnoreg, xnoreg, k0, noreg, true, vlen_enc);\n+     \/\/ TODO: Once auto-vectorizer supports ConvL2I operation, CountLeadingZerosV\n+     \/\/ should be succeeded by its corresponding vector IR and following\n+     \/\/ special handling should be removed.\n+     if (rbt == T_INT && bt == T_LONG) {\n+       __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+     }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_IL_reg_evex_masked(vec dst, vec src, kReg mask) %{\n+  predicate(is_clz_non_subword_predicate_evex(Matcher::vector_element_basic_type(n->in(1)),\n+                                              Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (CountLeadingZerosV src mask));\n+  format %{ \"vector_count_leading_zeros $dst, $src, $mask\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ evmovdquq($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, xnoreg, xnoreg,\n+                                       xnoreg, $mask$$KRegister, noreg, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_short_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_SHORT &&\n+            VM_Version::supports_avx512cd() &&\n+            (VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n) == 64));\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2);\n+  format %{ \"vector_count_leading_zeros $dst, $src!\\t using $xtmp1 and $xtmp2 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                       $xtmp2$$XMMRegister, xnoreg, knoreg, noreg, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_byte_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, kReg ktmp, rRegP rtmp) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_BYTE && VM_Version::supports_avx512vlbw());\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP ktmp, TEMP rtmp);\n+  format %{ \"vector_count_leading_zeros $dst, $src!\\t using $xtmp1, $xtmp2, $xtmp3, $ktmp and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_leading_zeros_evex(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                       $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $ktmp$$KRegister,\n+                                       $rtmp$$Register, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_int_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) == T_INT &&\n+            !VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n->in(1)) < 64);\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3);\n+  format %{ \"vector_count_leading_zeros $dst, $src\\t! using $xtmp1, $xtmp2 and $xtmp3 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ vector_count_leading_zeros_avx(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                      $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, noreg, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcount_leading_zeros_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(1)) != T_INT &&\n+            !VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n->in(1)) < 64);\n+  match(Set dst (CountLeadingZerosV src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp);\n+  format %{ \"vector_count_leading_zeros $dst, $src\\t! using $xtmp1, $xtmp2, $xtmp3, and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    BasicType rbt = Matcher::vector_element_basic_type(this);\n+    __ vector_count_leading_zeros_avx(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                      $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $rtmp$$Register, vlen_enc);\n+    \/\/ TODO: Once auto-vectorizer supports ConvL2I operation, CountLeadingZerosV\n+    \/\/ should be succeeded by its corresponding vector IR and following\n+    \/\/ special handling should be removed.\n+    if (rbt == T_INT && bt == T_LONG) {\n+      __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":218,"deletions":24,"binary":false,"changes":242,"status":"modified"},{"patch":"@@ -973,0 +973,3 @@\n+      case Op_CountTrailingZerosV:\n+      case Op_CountLeadingZerosV:\n+      case Op_ReverseV:\n@@ -978,4 +981,0 @@\n-      case Op_ReverseV: {\n-        const TypeVect* vt = n->bottom_type()->is_vect();\n-        body_size += Matcher::vector_op_pre_select_sz_estimate(n->Opcode(), vt->element_basic_type(), vt->length());\n-      } break;\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2566,1 +2566,3 @@\n-                 opc == Op_PopCountI || opc == Op_PopCountL) {\n+                 opc == Op_PopCountI || opc == Op_PopCountL ||\n+                 opc == Op_CountLeadingZerosI || opc == Op_CountLeadingZerosL ||\n+                 opc == Op_CountTrailingZerosI || opc == Op_CountTrailingZerosL) {\n@@ -2958,3 +2960,3 @@\n-  if (VectorNode::is_vpopcnt_long(use)) {\n-    \/\/ VPOPCNT_LONG takes long and produces int - hence the special checks\n-    \/\/ on alignment and size.\n+  if (VectorNode::is_type_transition_long_to_int(use)) {\n+    \/\/ PopCountL\/CountLeadingZerosL\/CountTrailingZerosL takes long and produces\n+    \/\/ int - hence the special checks on alignment and size.\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -313,3 +313,8 @@\n-bool VectorNode::is_vpopcnt_long(Node* n) {\n-  if (n->Opcode() == Op_PopCountL) {\n-    return true;\n+bool VectorNode::is_type_transition_long_to_int(Node* n) {\n+  switch(n->Opcode()) {\n+    case Op_PopCountL:\n+    case Op_CountLeadingZerosL:\n+    case Op_CountTrailingZerosL:\n+       return true;\n+    default:\n+       return false;\n@@ -317,1 +322,0 @@\n-  return false;\n@@ -320,3 +324,0 @@\n-\n-\n-\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -96,1 +96,1 @@\n-  static bool is_vpopcnt_long(Node* n);\n+  static bool is_type_transition_long_to_int(Node* n);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}