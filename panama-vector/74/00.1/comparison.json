{"files":[{"patch":"@@ -1906,1 +1906,1 @@\n-  if (C->max_vector_size() >= 16) {\n+  if (C->max_vector_size() > 0) {\n@@ -2392,1 +2392,1 @@\n-  if (!match_rule_supported(opcode) || !vector_size_supported(bt, vlen)) {\n+  if (!match_rule_supported(opcode)) {\n@@ -2400,1 +2400,1 @@\n-    return op_sve_supported(opcode);\n+    return op_sve_supported(opcode, vlen, bt);\n@@ -2421,1 +2421,1 @@\n-  return true; \/\/ Per default match rules are supported.\n+  return vector_size_supported(bt, vlen);\n@@ -2440,0 +2440,18 @@\n+bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+  return false;\n+}\n+\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n@@ -2484,0 +2502,1 @@\n+\n@@ -2486,15 +2505,8 @@\n-  if ((UseSVE > 0) && (MaxVectorSize >= 16)) {\n-    \/\/ Currently vector length less than SVE vector register size is not supported.\n-    return max_size;\n-  } else { \/\/ NEON\n-    \/\/ Limit the vector size to 8 bytes\n-    int size = 8 \/ type2aelembytes(bt);\n-    if (bt == T_BYTE) {\n-      \/\/ To support vector api shuffle\/rearrange.\n-      size = 4;\n-    } else if (bt == T_BOOLEAN) {\n-      \/\/ To support vector api load\/store mask.\n-      size = 2;\n-    }\n-    if (size < 2) size = 2;\n-    return MIN2(size,max_size);\n+  \/\/ Limit the min vector size to 8 bytes for NEON, 16 bytes for SVE\n+  int size = (UseSVE > 0 ? 16 : 8) \/ type2aelembytes(bt);\n+  if (bt == T_BYTE) {\n+    \/\/ To support vector api shuffle\/rearrange.\n+    size = 4;\n+  } else if (bt == T_BOOLEAN) {\n+    \/\/ To support vector api load\/store mask.\n+    size = 2;\n@@ -2502,0 +2514,2 @@\n+  if (size < 2) size = 2;\n+  return MIN2(size, max_size);\n@@ -2515,1 +2529,1 @@\n-  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+  if (UseSVE > 0 && 2 <= len && len <= 256) {\n@@ -3797,1 +3811,1 @@\n-    if (Compile::current()->max_vector_size() >= 16 && uncommon_trap_request() == 0) {\n+    if (Compile::current()->max_vector_size() > 0 && uncommon_trap_request() == 0) {\n@@ -3809,1 +3823,1 @@\n-    } else if (Compile::current()->max_vector_size() >= 16) {\n+    } else if (Compile::current()->max_vector_size() > 0) {\n@@ -3847,1 +3861,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -3860,1 +3874,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -4241,0 +4255,10 @@\n+operand immI_gt_1()\n+%{\n+  predicate(n->get_int() > 1);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":48,"deletions":24,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 2);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 2);\n@@ -47,1 +47,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 4);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 4);\n@@ -58,1 +58,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 8);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 8);\n@@ -3843,2 +3843,2 @@\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 8 ||\n+                            n->as_Vector()->length() == 4));\n@@ -3868,2 +3868,2 @@\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 8 ||\n+                            n->as_Vector()->length() == 4));\n@@ -3893,2 +3893,2 @@\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 4 ||\n+                            n->as_Vector()->length() == 2));\n@@ -3918,2 +3918,2 @@\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 4 ||\n+                            n->as_Vector()->length() == 2));\n@@ -3943,1 +3943,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -3967,1 +3967,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -4017,1 +4017,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -5148,2 +5148,2 @@\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length_in_bytes() == 4 ||\n+            n->as_Vector()->length_in_bytes() == 8));\n@@ -5160,1 +5160,1 @@\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length_in_bytes() == 16));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":17,"deletions":17,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -72,3 +72,3 @@\n-VLoadStore(ldrh, H, load,  2,  D, 16,  dst, )\n-VLoadStore(ldrs, S, load,  4,  D, 32,  dst, )\n-VLoadStore(ldrd, D, load,  8,  D, 64,  dst, )\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst, UseSVE == 0 && )\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst, UseSVE == 0 && )\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst, UseSVE == 0 && )\n@@ -1555,3 +1555,4 @@\n-  predicate(ifelse($8, UseSVE == 0 && , $8,\n-                   $8, , , $8`\n-            ')n->as_Vector()->length() == $3);\n+  predicate(UseSVE == 0 && ifelse($8, `',\n+                                  n->as_Vector()->length() == $3,\n+                                  (n->as_Vector()->length() == $3 ||`\n+                            'n->as_Vector()->length() == $8)));\n@@ -1583,18 +1584,18 @@\n-dnl        $1    $2    $3  $4 $5     $6 $7          $8                                $9\n-VREPLICATE(dup,  dup,  8,  B, ,      D, iRegIorL2I, n->as_Vector()->length() == 4 ||, B)\n-VREPLICATE(dup,  dup,  16, B, ,      X, iRegIorL2I, UseSVE == 0 && ,                  B)\n-VREPLICATE(movi, mov,  8,  B, _imm,  D, immI,       n->as_Vector()->length() == 4 ||, B)\n-VREPLICATE(movi, mov,  16, B, _imm,  X, immI,       UseSVE == 0 && ,                  B)\n-VREPLICATE(dup,  dup,  4,  S, ,      D, iRegIorL2I, n->as_Vector()->length() == 2 ||, H)\n-VREPLICATE(dup,  dup,  8,  S, ,      X, iRegIorL2I, UseSVE == 0 && ,                  H)\n-VREPLICATE(movi, mov,  4,  S, _imm,  D, immI,       n->as_Vector()->length() == 2 ||, H)\n-VREPLICATE(movi, mov,  8,  S,  _imm, X, immI,       UseSVE == 0 && ,                  H)\n-VREPLICATE(dup,  dup,  2,  I, ,      D, iRegIorL2I, ,                                 S)\n-VREPLICATE(dup,  dup,  4,  I, ,      X, iRegIorL2I, UseSVE == 0 && ,                  S)\n-VREPLICATE(movi, mov,  2,  I, _imm,  D, immI,       ,                                 S)\n-VREPLICATE(movi, mov,  4,  I,  _imm, X, immI,       UseSVE == 0 && ,                  S)\n-VREPLICATE(dup,  dup,  2,  L, ,      X, iRegL,      UseSVE == 0 && ,                  D)\n-VREPLICATE(movi, eor,  2,  L, _zero, X, immI0,      UseSVE == 0 && ,                  D)\n-VREPLICATE(dup,  dup,  2,  F, ,      D, vRegF,      ,                                 S)\n-VREPLICATE(dup,  dup,  4,  F, ,      X, vRegF,      UseSVE == 0 && ,                  S)\n-VREPLICATE(dup,  dup,  2,  D, ,      X, vRegD,      UseSVE == 0 && ,                  D)\n+dnl        $1    $2    $3  $4 $5     $6 $7          $8 $9\n+VREPLICATE(dup,  dup,  8,  B, ,      D, iRegIorL2I, 4, B)\n+VREPLICATE(dup,  dup,  16, B, ,      X, iRegIorL2I,  , B)\n+VREPLICATE(movi, mov,  8,  B, _imm,  D, immI,       4, B)\n+VREPLICATE(movi, mov,  16, B, _imm,  X, immI,        , B)\n+VREPLICATE(dup,  dup,  4,  S, ,      D, iRegIorL2I, 2, H)\n+VREPLICATE(dup,  dup,  8,  S, ,      X, iRegIorL2I,  , H)\n+VREPLICATE(movi, mov,  4,  S, _imm,  D, immI,       2, H)\n+VREPLICATE(movi, mov,  8,  S,  _imm, X, immI,        , H)\n+VREPLICATE(dup,  dup,  2,  I, ,      D, iRegIorL2I, ,  S)\n+VREPLICATE(dup,  dup,  4,  I, ,      X, iRegIorL2I, ,  S)\n+VREPLICATE(movi, mov,  2,  I, _imm,  D, immI,       ,  S)\n+VREPLICATE(movi, mov,  4,  I,  _imm, X, immI,       ,  S)\n+VREPLICATE(dup,  dup,  2,  L, ,      X, iRegL,      ,  D)\n+VREPLICATE(movi, eor,  2,  L, _zero, X, immI0,      ,  D)\n+VREPLICATE(dup,  dup,  2,  F, ,      D, vRegF,      ,  S)\n+VREPLICATE(dup,  dup,  4,  F, ,      X, vRegF,      ,  S)\n+VREPLICATE(dup,  dup,  2,  D, ,      X, vRegD,      ,  D)\n@@ -1978,2 +1979,2 @@\n-  predicate(ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n-            ')n->as_Vector()->length_in_bytes() == $3);\n+  predicate(UseSVE == 0 && (ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n+            ')n->as_Vector()->length_in_bytes() == $3));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":27,"deletions":26,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -46,0 +47,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -60,1 +62,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -74,1 +76,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -83,0 +85,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -86,1 +90,1 @@\n-  bool op_sve_supported(int opcode);\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -102,0 +106,24 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n@@ -127,2 +155,2 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n+  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                   PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n@@ -131,2 +159,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int mesize = type2aelembytes(mem_elem_bt);\n@@ -135,1 +162,1 @@\n-      switch(esize) {\n+      switch(mesize) {\n@@ -138,1 +165,0 @@\n-        type = Assembler::B;\n@@ -142,1 +168,0 @@\n-        type = Assembler::H;\n@@ -146,1 +171,0 @@\n-        type = Assembler::S;\n@@ -150,1 +174,0 @@\n-        type = Assembler::D;\n@@ -156,1 +179,2 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n@@ -163,1 +187,31 @@\n-  bool op_sve_supported(int opcode) {\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt) {\n@@ -172,7 +226,0 @@\n-      case Op_Extract:\n-      case Op_ExtractB:\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -182,16 +229,1 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n-      case Op_LoadVectorGather:\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadMask:\n+        return false;\n@@ -201,5 +233,4 @@\n-      case Op_VectorMaskCmp:\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n-        return false;\n+        if (vlen < 4) {\n+          return false;\n+        }\n+        break;\n@@ -208,1 +239,1 @@\n-        return true;\n+        break;\n@@ -210,0 +241,3 @@\n+    \/\/ By default, we only support vector operations with larger than 16 bytes.\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n+    return 16 <= length_in_bytes && length_in_bytes <= MaxVectorSize;\n@@ -222,1 +256,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -224,1 +258,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -226,1 +261,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -230,0 +265,1 @@\n+    BasicType bt = vector_element_basic_type(this);\n@@ -231,1 +267,1 @@\n-                         vector_element_basic_type(this), $mem->opcode(),\n+                         bt, bt, $mem->opcode(),\n@@ -238,1 +274,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -240,1 +277,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -244,0 +281,1 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n@@ -245,1 +283,145 @@\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n+                         bt, bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (16 bits)\n+instruct loadV2_vreg(vReg dst, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 2 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrh   $dst,$mem\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvH(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (16 bits)\n+instruct storeV2_vreg(vReg src, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 2 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strh   $mem,$src\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_strvH(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (32 bits)\n+instruct loadV4_vreg(vReg dst, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 4 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (32 bits)\n+instruct storeV4_vreg(vReg src, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 4 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8_vreg(vReg dst, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 8 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8_vreg(vReg src, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 8 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16_vreg(vReg dst, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(vload_reg_mem128);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16_vreg(vReg src, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(vstore_reg_mem128);\n+%}\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ mov(rscratch1, vector_length(this));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    __ mov(rscratch1, vector_length(this, $src));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n+                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n@@ -251,0 +433,36 @@\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \"# reinterpret $dst\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"reinterpretResize $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ mov(rscratch1, length_in_bytes_resize);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -254,1 +472,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n+  predicate(UseSVE > 0 &&\n@@ -267,1 +485,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n+  predicate(UseSVE > 0 &&\n@@ -280,1 +498,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+  predicate(UseSVE > 0 &&\n@@ -293,1 +511,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+  predicate(UseSVE > 0 &&\n@@ -306,1 +524,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+  predicate(UseSVE > 0 &&\n@@ -319,1 +537,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+  predicate(UseSVE > 0 &&\n@@ -334,1 +552,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -347,1 +565,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -360,1 +578,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -373,1 +591,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -386,1 +604,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -399,1 +617,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -414,1 +632,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -429,1 +647,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -444,1 +662,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -519,1 +737,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -531,1 +749,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -545,1 +763,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -565,1 +783,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -588,1 +806,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -601,1 +819,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -617,1 +835,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -632,1 +850,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -649,1 +867,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -664,1 +882,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -680,1 +898,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -693,1 +911,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -709,1 +927,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -723,1 +941,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -737,1 +955,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -751,1 +969,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -767,1 +985,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -781,1 +999,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -795,1 +1013,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -809,1 +1027,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -824,1 +1042,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -836,1 +1054,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -848,1 +1066,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -860,1 +1078,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -872,1 +1090,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -885,1 +1103,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -900,1 +1118,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -912,1 +1130,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -926,1 +1144,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -928,1 +1146,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -935,0 +1153,297 @@\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ load\/store mask vector\n+\n+instruct vloadmask_loadV_byte(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_loadV_non_byte(vReg dst, indirect mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask_byte(vmemA mem, vReg src, vReg tmp, immI_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask_non_byte(indirect mem, vReg src, vReg tmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n@@ -938,2 +1453,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -958,2 +1473,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -978,2 +1493,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -996,2 +1511,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1014,1 +1528,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1026,1 +1540,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1037,10 +1551,7 @@\n-\/\/ vector max reduction\n-\n-instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n@@ -1048,3 +1559,13 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1055,8 +1576,7 @@\n-instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n+instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n@@ -1064,3 +1584,6 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1071,10 +1594,6 @@\n-\/\/ vector min reduction\n-\n-instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n+instruct reduce_addF_partial(vRegF src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF src1_dst src2));\n+  ins_cost(SVE_COST);\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (S)\" %}\n@@ -1082,3 +1601,4 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ S, zr, rscratch1);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1089,8 +1609,6 @@\n-instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n+instruct reduce_addD_partial(vRegD src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD src1_dst src2));\n+  ins_cost(SVE_COST);\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (D)\" %}\n@@ -1098,3 +1616,4 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1105,1 +1624,1 @@\n-\/\/ vector Math.rint, floor, ceil\n+\/\/ vector and reduction\n@@ -1107,5 +1626,10 @@\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct reduce_andB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # and reduction B\" %}\n@@ -1113,14 +1637,5 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-    }\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1131,5 +1646,5 @@\n-\/\/ vector replicate\n-\n-instruct replicateB(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB src));\n+instruct reduce_andS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1137,1 +1652,4 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # and reduction H\" %}\n@@ -1139,1 +1657,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1144,3 +1666,5 @@\n-instruct replicateS(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS src));\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1148,1 +1672,3 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\t # and reduction S\" %}\n@@ -1150,1 +1676,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1155,3 +1684,5 @@\n-instruct replicateI(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI src));\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1159,1 +1690,3 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"andr  $dst, $dst, $src1\\t # and reduction D\" %}\n@@ -1161,1 +1694,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1166,3 +1702,6 @@\n-instruct replicateL(vReg dst, iRegL src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL src));\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1170,1 +1709,1 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n@@ -1172,1 +1711,13 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1177,3 +1728,6 @@\n-instruct replicateB_imm8(vReg dst, immI8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB con));\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1181,1 +1735,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n@@ -1183,1 +1737,6 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1188,3 +1747,8 @@\n-instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS con));\n+\n+\/\/ vector or reduction\n+\n+instruct reduce_orB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1192,1 +1756,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # or reduction B\" %}\n@@ -1194,1 +1761,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1199,3 +1770,5 @@\n-instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI con));\n+instruct reduce_orS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1203,1 +1776,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # or reduction H\" %}\n@@ -1205,1 +1781,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1210,3 +1790,5 @@\n-instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL con));\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1214,1 +1796,3 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\t # or reduction S\" %}\n@@ -1216,1 +1800,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1221,3 +1808,5 @@\n-instruct replicateF(vReg dst, vRegF src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateF src));\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1225,1 +1814,3 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"orr  $dst, $dst, $src1\\t # or reduction D\" %}\n@@ -1227,2 +1818,4 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1233,3 +1826,6 @@\n-instruct replicateD(vReg dst, vRegD src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateD src));\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1237,1 +1833,1 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n@@ -1239,2 +1835,13 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1245,5 +1852,6 @@\n-\/\/ vector shift\n-\n-instruct vasrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB dst shift));\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1251,1 +1859,1 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n@@ -1253,2 +1861,6 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1259,3 +1871,9 @@\n-instruct vasrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS dst shift));\n+\n+\/\/ vector xor reduction\n+\n+instruct reduce_eorB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1263,1 +1881,4 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # eor reduction B\" %}\n@@ -1265,2 +1886,5 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1271,3 +1895,6 @@\n-instruct vasrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI dst shift));\n+instruct reduce_eorS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1275,1 +1902,4 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # eor reduction H\" %}\n@@ -1277,2 +1907,5 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1283,3 +1916,6 @@\n-instruct vasrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL dst shift));\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1287,1 +1923,3 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\t # eor reduction S\" %}\n@@ -1289,2 +1927,4 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1295,3 +1935,6 @@\n-instruct vlslB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB dst shift));\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1299,1 +1942,3 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"eor  $dst, $dst, $src1\\t # eor reduction D\" %}\n@@ -1301,2 +1946,4 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1307,3 +1954,6 @@\n-instruct vlslS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS dst shift));\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1311,1 +1961,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n@@ -1313,2 +1963,13 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1319,3 +1980,6 @@\n-instruct vlslI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI dst shift));\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1323,1 +1987,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n@@ -1325,2 +1989,6 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1331,3 +1999,8 @@\n-instruct vlslL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL dst shift));\n+\n+\/\/ vector max reduction\n+\n+instruct reduce_maxB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1335,1 +2008,4 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction B\" %}\n@@ -1337,2 +2013,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1343,3 +2022,5 @@\n-instruct vlsrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB dst shift));\n+instruct reduce_maxS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1347,1 +2028,4 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction H\" %}\n@@ -1349,2 +2033,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1355,3 +2042,5 @@\n-instruct vlsrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS dst shift));\n+instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1359,1 +2048,4 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"smov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction S\" %}\n@@ -1361,2 +2053,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1367,3 +2062,5 @@\n-instruct vlsrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI dst shift));\n+instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1371,1 +2068,4 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"smov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 GT\\t# max reduction D\" %}\n@@ -1373,2 +2073,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1379,3 +2082,8 @@\n-instruct vlsrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL dst shift));\n+instruct reduce_maxI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1383,1 +2091,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# reduce maxI partial (sve)\" %}\n@@ -1385,2 +2093,9 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1391,3 +2106,6 @@\n-instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+instruct reduce_maxL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1395,1 +2113,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# reduce maxL partial (sve)\" %}\n@@ -1397,9 +2115,7 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) con = 7;\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1410,5 +2126,8 @@\n-instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n@@ -1416,9 +2135,3 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) con = 15;\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1429,5 +2142,8 @@\n-instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n@@ -1435,5 +2151,258 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxF_partial(vRegF dst, vRegF src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_S $dst, $src1, $src2\\t# reduce max S partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ S, zr, rscratch1);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxD_partial(vRegD dst, vRegD src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_D $dst, $src1, $src2\\t# reduce max D partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector min reduction\n+\n+instruct reduce_minB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction B\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction H\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"smov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction S\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"smov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 LT\\t# min reduction D\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# reduce minI partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# reduce minL partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n+  ins_encode %{\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n+  ins_encode %{\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF_partial(vRegF dst, vRegF src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_S $dst, $src1, $src2\\t# reduce min S partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ S, zr, rscratch1);\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD_partial(vRegD dst, vRegD src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_D $dst, $src1, $src2\\t# reduce min D partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n@@ -1441,2 +2410,0 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n@@ -1447,3 +2414,1318 @@\n-instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+\/\/ vector replicate\n+\n+instruct replicateB(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateB src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateS src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateI src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL(vReg dst, iRegL src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateL src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateB_imm8(vReg dst, immI8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateB con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateS con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateI con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateL con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateF(vReg dst, vRegF src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateD(vReg dst, vRegD src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift\n+\n+instruct vasrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) con = 7;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) con = 15;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sqrt\n+\n+instruct vsqrtF(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SqrtVF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SqrtVD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sub\n+\n+instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVB src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVS src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVI src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVL src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVF src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVD src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector cast -------------------------------\n+\n+instruct vcvtBtoS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\t# convert B to S vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\t# convert S to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\t# convert I to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\t# convert B to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert S to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert B to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtStoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, B, 0\\n\\t\"\n+            \"sve_uzp1  $dst, B, $src, tmp\\t# convert S to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\t# convert I to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\t# convert L to I vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtItoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert I to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert L to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtLtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert L to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert B to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert S to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtBtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert B to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtLtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert L to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvt  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert D to F vector\" %}\n+  ins_encode %{\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtItoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, S\\t# convert I to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastL2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, D, $src, D\\t# convert L to D vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\t# convert F to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\t# convert D to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtItoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert I to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert S to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_fcvt  $dst, D, $dst, S\\t# convert F to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtFtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\t# convert F to S vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\t# convert D to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+\n+instruct vcvtFtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert F to B vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert D to S vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+\n+instruct vcvtFtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert F to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct vcvtDtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert D to B vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+\n+instruct extractB(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractB src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, B, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, B, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 7U\\t# extract from vector(B)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ B, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 7U);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractS(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractS src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, H, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, H, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 15U\\t# extract from vector(S)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ H, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ H, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct extractI(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractI src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, S, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, S, $pTmp, $src\\t# extract from vector(I)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ S, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractL(iRegLNoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractL src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, D, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, D, $pTmp, $src\\t# extract from vector(L)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ D, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractF(vRegF dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractF src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, S, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, S, $pTmp, $src\\t# extract from vector(F)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ S, zr, rscratch1);\n+    __ sve_lastb(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractD(vRegD dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractD src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, D, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, D, $pTmp, $src\\t# extract from vector(D)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ D, zr, rscratch1);\n+    __ sve_lastb(as_FloatRegister($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+\n+instruct vtest_alltrue(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, 0\\n\\t\"\n+            \"csetw $dst, EQ\\t# VectorTest (sve) - alltrue\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_anytrue(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, -1\\n\\t\"\n+            \"csetw $dst, NE\\t# VectorTest (sve) - anytrue\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_alltrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vtest_alltrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - alltrue\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_anytrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1451,1 +3733,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"vtest_anytrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - anytrue\" %}\n@@ -1453,8 +3735,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -1465,5 +3747,13 @@\n-instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+\n+instruct insertB_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, B, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B)\" %}\n@@ -1471,13 +3761,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ B, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ B, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1488,5 +3773,11 @@\n-instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+instruct insertS_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, H, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (S)\" %}\n@@ -1494,13 +3785,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ H, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ H, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1511,5 +3797,11 @@\n-instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+instruct insertI_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, S, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (I)\" %}\n@@ -1517,8 +3809,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1529,5 +3821,11 @@\n-instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct insertF_small(vReg dst, vReg src, vRegF val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, S, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n@@ -1535,8 +3833,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1547,5 +3845,12 @@\n-instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+\n+instruct insertL(vReg dst, vReg src, iRegL val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, D, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (L)\" %}\n@@ -1553,8 +3858,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ D, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ D, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1565,5 +3870,11 @@\n-instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+instruct insertD(vReg dst, vReg src, vRegD val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, D, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (D)\" %}\n@@ -1571,8 +3882,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ D, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ D, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1583,5 +3894,13 @@\n-instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+\n+instruct insertB(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, B, 0, 1\\n\\t\"\n+            \"sve_dup $dst, B, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B)\" %}\n@@ -1589,3 +3908,9 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ B, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ B, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1596,5 +3921,12 @@\n-instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct insertS(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, H, 0, 1\\n\\t\"\n+            \"sve_dup $dst, H, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (S)\" %}\n@@ -1602,3 +3934,9 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ H, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ H, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1609,6 +3947,12 @@\n-instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+instruct insertI(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, S, 0, 1\\n\\t\"\n+            \"sve_dup $dst, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (I)\" %}\n@@ -1616,1 +3960,9 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1621,7 +3973,12 @@\n-instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+instruct insertF(vReg dst, vReg src, vRegF val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, S, 0, 1\\n\\t\"\n+            \"sve_dup $dst, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n@@ -1629,1 +3986,9 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1634,6 +3999,7 @@\n-instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+instruct loadshuffleB(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orr $dst, $src, $src\\t# vector load shuffle (B)\" %}\n@@ -1641,1 +4007,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+                 as_FloatRegister($src$$reg),\n+                 as_FloatRegister($src$$reg));\n+    }\n@@ -1646,6 +4016,6 @@\n-instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+instruct loadshuffleS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\t# vector load shuffle (B to H)\" %}\n@@ -1653,1 +4023,1 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n@@ -1658,1 +4028,15 @@\n-\/\/ vector sqrt\n+instruct loadshuffleI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -1660,5 +4044,10 @@\n-instruct vsqrtF(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVF src));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+instruct loadshuffleL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to D)\" %}\n@@ -1666,2 +4055,3 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n@@ -1672,3 +4062,7 @@\n-instruct vsqrtD(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVD src));\n+\/\/ ------------------------------ Vector rearrange -------------------------------\n+\n+instruct rearrangeB(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1676,1 +4070,1 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_tbl $dst, B, $src, $shuffle\\t# vector rearrange (B)\" %}\n@@ -1678,2 +4072,2 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ B,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1684,5 +4078,5 @@\n-\/\/ vector sub\n-\n-instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (SubVB src1 src2));\n+instruct rearrangeS(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1690,1 +4084,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+  format %{ \"sve_tbl $dst, H, $src, $shuffle\\t# vector rearrange (S)\" %}\n@@ -1692,3 +4086,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ H,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1699,3 +4092,5 @@\n-instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (SubVS src1 src2));\n+instruct rearrangeI(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1703,1 +4098,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  format %{ \"sve_tbl $dst, S, $src, $shuffle\\t# vector rearrange (I)\" %}\n@@ -1705,3 +4100,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ S,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1712,3 +4106,5 @@\n-instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVI src1 src2));\n+instruct rearrangeF(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1716,1 +4112,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  format %{ \"sve_tbl $dst, S, $src, $shuffle\\t# vector rearrange (F)\" %}\n@@ -1718,3 +4114,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ S,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1725,3 +4120,5 @@\n-instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVL src1 src2));\n+instruct rearrangeL(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1729,1 +4126,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  format %{ \"sve_tbl $dst, D, $src, $shuffle\\t# vector rearrange (L)\" %}\n@@ -1731,3 +4128,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ D,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1738,3 +4134,5 @@\n-instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVF src1 src2));\n+instruct rearrangeD(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1742,1 +4140,1 @@\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  format %{ \"sve_tbl $dst, D, $src, $shuffle\\t# vector rearrange (D)\" %}\n@@ -1744,3 +4142,2 @@\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ D,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1751,3 +4148,6 @@\n-instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVD src1 src2));\n+\/\/ ------------------------------ Vector Load Gather ---------------------------------\n+instruct gatherI(vReg dst, vmemA mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n@@ -1755,1 +4155,1 @@\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n@@ -1757,3 +4157,16 @@\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL(vReg dst, vmemA mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":2956,"deletions":543,"binary":false,"changes":3499,"status":"modified"},{"patch":"@@ -32,4 +32,11 @@\n-\n-\/\/ 4 bit signed offset -- for predicated load\/store\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3     )\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len)\n+define(`TYPE2DATATYPE',\n+`ifelse($1, `B', `BYTE',\n+        $1, `S', `SHORT',\n+        $1, `I', `INT',\n+        $1, `L', `LONG',\n+        $1, `F', `FLOAT',\n+        $1, `D', `DOUBLE',\n+        `error($1)')')dnl\n+dnl\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3       $4   )\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len, scale)\n@@ -40,0 +47,1 @@\n+  \/\/ (esize \/ msize) = $4\n@@ -41,1 +49,1 @@\n-            Matcher::scalable_vector_reg_size(T_BYTE)));\n+            Matcher::scalable_vector_reg_size(T_BYTE)ifelse($4, `1', `', ` \/ $4')));\n@@ -48,2 +56,4 @@\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4)\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4)\n+\n+\/\/ 4 bit signed offset -- for predicated load\/store\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4, 1)\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4, 1)\n@@ -54,1 +64,1 @@\n-operand vmemA_indOff$1$2(iRegP reg, vmemA_imm$1Offset$2 off)\n+operand vmemA_indOff$1$2$3(iRegP reg, vmemA_imm$1Offset$2 off)\n@@ -59,1 +69,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -70,0 +80,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -73,1 +85,1 @@\n-  bool op_sve_supported(int opcode);\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -89,0 +101,24 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n@@ -114,2 +150,2 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n+  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                   PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n@@ -118,2 +154,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int mesize = type2aelembytes(mem_elem_bt);\n@@ -122,1 +157,1 @@\n-      switch(esize) {\n+      switch(mesize) {\n@@ -125,1 +160,0 @@\n-        type = Assembler::B;\n@@ -129,1 +163,0 @@\n-        type = Assembler::H;\n@@ -133,1 +166,0 @@\n-        type = Assembler::S;\n@@ -137,1 +169,0 @@\n-        type = Assembler::D;\n@@ -143,1 +174,2 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n@@ -150,1 +182,31 @@\n-  bool op_sve_supported(int opcode) {\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt) {\n@@ -159,7 +221,0 @@\n-      case Op_Extract:\n-      case Op_ExtractB:\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -169,16 +224,1 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n-      case Op_LoadVectorGather:\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadMask:\n+        return false;\n@@ -188,5 +228,4 @@\n-      case Op_VectorMaskCmp:\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n-        return false;\n+        if (vlen < 4) {\n+          return false;\n+        }\n+        break;\n@@ -195,1 +234,1 @@\n-        return true;\n+        break;\n@@ -197,0 +236,3 @@\n+    \/\/ By default, we only support vector operations with larger than 16 bytes.\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n+    return 16 <= length_in_bytes && length_in_bytes <= MaxVectorSize;\n@@ -217,1 +259,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -219,1 +261,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -221,1 +264,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -225,0 +268,1 @@\n+    BasicType bt = vector_element_basic_type(this);\n@@ -226,1 +270,1 @@\n-                         vector_element_basic_type(this), $mem->opcode(),\n+                         bt, bt, $mem->opcode(),\n@@ -233,1 +277,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -235,1 +280,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -239,0 +284,1 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n@@ -240,1 +286,50 @@\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n+                         bt, bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n+\n+dnl\n+define(`VLoadStore', `\n+\/\/ ifelse(load, $3, Load, Store) Vector ($6 bits)\n+instruct $3V$4_vreg`'(vReg $7, vmem$4 mem)\n+%{\n+  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4 &&\n+            `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() < MaxVectorSize);\n+  match(Set ifelse(load, $3, dst (LoadVector mem), mem (StoreVector mem src)));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"$1   ifelse(load, $3, `$dst,$mem', `$mem,$src')\\t# vector ($6 bits)\" %}\n+  ins_encode( `aarch64_enc_'ifelse(load, $3, ldr, str)v$2($7, mem) );\n+  ins_pipe(v$3`_reg_mem'ifelse(eval($4 * 8), 128, 128, 64));\n+%}')dnl\n+dnl        $1    $2 $3     $4  $5 $6   $7\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst)\n+VLoadStore(strh, H, store, 2,  D, 16,  src)\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst)\n+VLoadStore(strs, S, store, 4,  D, 32,  src)\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst)\n+VLoadStore(strd, D, store, 8,  D, 64,  src)\n+VLoadStore(ldrq, Q, load, 16,  X, 128, dst)\n+VLoadStore(strq, Q, store, 16, X, 128, src)\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ mov(rscratch1, vector_length(this));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n@@ -246,0 +341,59 @@\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    __ mov(rscratch1, vector_length(this, $src));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n+                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n+\n+\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \"# reinterpret $dst\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"reinterpretResize $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ mov(rscratch1, length_in_bytes_resize);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -251,1 +405,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5 &&\n+  predicate(UseSVE > 0 &&\n@@ -275,1 +429,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -299,1 +453,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= $3);\n+  predicate(UseSVE > 0);\n@@ -375,1 +529,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -393,1 +547,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -413,1 +567,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -438,1 +592,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -460,1 +614,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -483,1 +637,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -505,1 +659,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -527,1 +681,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -551,1 +705,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -573,1 +727,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -597,1 +751,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= $4);\n+  predicate(UseSVE > 0);\n@@ -615,1 +769,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -617,1 +771,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -622,1 +776,272 @@\n-%}dnl\n+%}\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n+                   as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n+                   as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, 0\\n\\t\"\n+            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl\n+dnl VLOADMASK_LOADV($1,    $2  )\n+dnl VLOADMASK_LOADV(esize, cond)\n+define(`VLOADMASK_LOADV', `\n+instruct vloadmask_loadV_$1(vReg dst, ifelse($1, `byte', vmemA, indirect) mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) $2);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+define(`ARGLIST',\n+`ifelse($1, `byte', vmemA, indirect) mem, vReg src, vReg tmp, ifelse($1, `byte', immI_1, immI_gt_1) esize')\n+dnl\n+dnl STOREV_VSTOREMASK($1,  )\n+dnl STOREV_VSTOREMASK(esize)\n+define(`STOREV_VSTOREMASK', `\n+instruct storeV_vstoremask_$1(ARGLIST($1)) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+undefine(ARGLIST)dnl\n+dnl\n+\/\/ load\/store mask vector\n+VLOADMASK_LOADV(byte, == 1)\n+VLOADMASK_LOADV(non_byte, > 1)\n+STOREV_VSTOREMASK(byte)\n+STOREV_VSTOREMASK(non_byte)\n@@ -629,2 +1054,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -648,0 +1073,5 @@\n+define(`PREDICATE', `ifelse($1, AddReductionVL,\n+       `predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n+       `predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')')dnl\n+dnl\n@@ -652,2 +1082,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  PREDICATE($2)\n@@ -668,0 +1097,1 @@\n+undefine(PREDICATE)dnl\n@@ -673,1 +1103,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -685,1 +1115,1 @@\n-REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE,  sxtb)\n+REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n@@ -692,12 +1122,7 @@\n-dnl\n-dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )\n-dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)\n-define(`REDUCE_FMINMAX', `\n-instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_f$1v $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"f$1s $dst, $dst, $src1\\t # $1 reduction $2\" %}\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n@@ -705,3 +1130,13 @@\n-    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -710,10 +1145,1 @@\n-%}')dnl\n-\/\/ vector max reduction\n-REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)\n-REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)\n-\n-\/\/ vector min reduction\n-REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)\n-REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)\n-\n-\/\/ vector Math.rint, floor, ceil\n+%}\n@@ -721,5 +1147,7 @@\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n@@ -727,14 +1155,6 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-    }\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -745,6 +1165,7 @@\n-dnl REPLICATE($1,        $2,      $3,      $4,   $5         )\n-dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n-define(`REPLICATE', `\n-instruct $1(vReg dst, $3 src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src));\n+dnl\n+dnl REDUCE_ADDF_PARTIAL($1,        $2,      $3,      $4  )\n+dnl REDUCE_ADDF_PARTIAL(insn_name, op_name, reg_dst, size)\n+define(`REDUCE_ADDF_PARTIAL', `\n+instruct $1($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst ($2 src1_dst src2));\n@@ -752,1 +1173,2 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) ($4)\" %}\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) ($4)\" %}\n@@ -754,1 +1176,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ $4, zr, rscratch1);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -759,6 +1184,11 @@\n-dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )\n-dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)\n-define(`REPLICATE_IMM8', `\n-instruct $1(vReg dst, $3 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 con));\n+REDUCE_ADDF_PARTIAL(reduce_addF_partial, AddReductionVF, vRegF, S)\n+REDUCE_ADDF_PARTIAL(reduce_addD_partial, AddReductionVD, vRegD, D)\n+dnl\n+dnl REDUCE_AND_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -766,1 +1196,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # and reduction $5\" %}\n@@ -768,1 +1201,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n@@ -773,6 +1210,8 @@\n-dnl FREPLICATE($1,        $2,      $3,      $4,   $5         )\n-dnl FREPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n-define(`FREPLICATE', `\n-instruct $1(vReg dst, $3 src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src));\n+dnl REDUCE_AND($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -780,1 +1219,3 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # and reduction $5\" %}\n@@ -782,2 +1223,4 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -788,11 +1231,464 @@\n-\/\/ vector replicate\n-REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)\n-REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)\n-REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)\n-REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)\n-REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)\n-REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)\n-REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)\n-REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)\n-FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)\n-FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)\n+\/\/ vector and reduction\n+REDUCE_AND_EXT(reduce_andB, AndReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_AND_EXT(reduce_andS, AndReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_AND(reduce_andI, AndReductionV, iRegINoSp, iRegIorL2I, S, T_INT, andw)\n+REDUCE_AND(reduce_andL, AndReductionV, iRegLNoSp, iRegL, D, T_LONG, andr)\n+\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_OR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_OR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector or reduction\n+REDUCE_OR_EXT(reduce_orB, OrReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_OR_EXT(reduce_orS, OrReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_OR(reduce_orI, OrReductionV, iRegINoSp, iRegIorL2I, S, T_INT, orrw)\n+REDUCE_OR(reduce_orL, OrReductionV, iRegLNoSp, iRegL, D, T_LONG, orr)\n+\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_XOR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_XOR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector xor reduction\n+REDUCE_XOR_EXT(reduce_eorB, XorReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_XOR_EXT(reduce_eorS, XorReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_XOR(reduce_eorI, XorReductionV, iRegINoSp, iRegIorL2I, S, T_INT, eorw)\n+REDUCE_XOR(reduce_eorL, XorReductionV, iRegLNoSp, iRegL, D, T_LONG, eor)\n+\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_MAXMIN($1,        $2,      $3,      $4,      $5,   $6,        $7,    $8,    $9 , $10    )\n+dnl REDUCE_MAXMIN(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1, insn2, cmp, min_max)\n+define(`REDUCE_MAXMIN', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_s$10v $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $src1\\n\\t\"\n+            \"$8 $dst, $dst, $src1 $9\\t# $10 reduction $5\" %}\n+  ins_encode %{\n+    __ sve_s$10v(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ ifelse($5,D,u,s)mov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $src1$$Register);\n+    __ $8(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$9);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_I_PARTIAL($1\n+dnl REDUCE_MAXMIN_I_PARTIAL(min_max, reg_src,\n+define(`REDUCE_MAXMIN_I_PARTIAL', `\n+instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# reduce $1I partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_PARTIAL($1\n+dnl REDUCE_MAXMIN_L_PARTIAL(min_max, reg_src,\n+define(`REDUCE_MAXMIN_L_PARTIAL', `\n+instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# reduce $1L partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX', `\n+instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_f$1v $dst, $src2 # vector (sve) ($4)\\n\\t\"\n+            \"f$1s $dst, $dst, $src1\\t # $1 reduction $2\" %}\n+  ins_encode %{\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+dnl REDUCE_FMINMAX_PARTIAL($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX_PARTIAL(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX_PARTIAL', `\n+instruct reduce_$1$2_partial($5 dst, $5 src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_$4 $dst, $src1, $src2\\t# reduce $1 $4 partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ $4, zr, rscratch1);\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector max reduction\n+REDUCE_MAXMIN(reduce_maxB, MaxReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE,  cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxS, MaxReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxI, MaxReductionV, iRegINoSp, iRegIorL2I, S, T_INT,   cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxL, MaxReductionV, iRegLNoSp, iRegL,      D, T_LONG,  cmp,  csel,  GT, max)\n+REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PARTIAL(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PARTIAL(max, D, T_DOUBLE, D, vRegD)\n+\n+\/\/ vector min reduction\n+REDUCE_MAXMIN(reduce_minB, MinReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE,  cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minS, MinReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minI, MinReductionV, iRegINoSp, iRegIorL2I, S, T_INT,   cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minL, MinReductionV, iRegLNoSp, iRegL,      D, T_LONG,  cmp,  csel,  LT, min)\n+REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV, LT)\n+REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV, LT)\n+REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PARTIAL(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PARTIAL(min, D, T_DOUBLE, D, vRegD)\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl REPLICATE($1,        $2,      $3,      $4,   $5         )\n+dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n+define(`REPLICATE', `\n+instruct $1(vReg dst, $3 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )\n+dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)\n+define(`REPLICATE_IMM8', `\n+instruct $1(vReg dst, $3 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl FREPLICATE($1,        $2,      $3,        $4)\n+dnl FREPLICATE(insn_name, op_name, reg_src, size)\n+define(`FREPLICATE', `\n+instruct $1(vReg dst, $3 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector replicate\n+REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)\n+REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)\n+REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)\n+REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)\n+REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)\n+REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)\n+REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)\n+REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)\n+FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)\n+FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)\n@@ -804,1 +1700,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -819,1 +1715,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n+  predicate(UseSVE > 0);\n@@ -855,1 +1751,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3 &&\n+  predicate(UseSVE > 0 &&\n@@ -908,0 +1804,645 @@\n+\/\/ ------------------------------ Vector cast -------------------------------\n+dnl\n+define(`VECTOR_CAST_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4\n+VECTOR_CAST_EXTEND1(B, S, sunpklo, H)\n+VECTOR_CAST_EXTEND1(S, I, sunpklo, S)\n+VECTOR_CAST_EXTEND1(I, L, sunpklo, D)\n+\n+dnl\n+define(`VECTOR_CAST_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4 $5\n+VECTOR_CAST_EXTEND2(B, I, sunpklo, H, S)\n+VECTOR_CAST_EXTEND2(S, L, sunpklo, S, D)\n+\n+dnl\n+define(`VECTOR_CAST_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4 $5 $6\n+VECTOR_CAST_EXTEND3(B, L, sunpklo, H, S, D)\n+\n+dnl\n+define(`VECTOR_CAST_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5\n+VECTOR_CAST_NARROW1(S, B, dup, B, uzp1)\n+VECTOR_CAST_NARROW1(I, S, dup, H, uzp1)\n+VECTOR_CAST_NARROW1(L, I, dup, S, uzp1)\n+\n+dnl\n+define(`VECTOR_CAST_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5    $6\n+VECTOR_CAST_NARROW2(I, B, dup, H, uzp1, B)\n+VECTOR_CAST_NARROW2(L, S, dup, S, uzp1, H)\n+\n+dnl\n+define(`VECTOR_CAST_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$5  $dst, $7, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5    $6 $7\n+VECTOR_CAST_NARROW3(L, B, dup, S, uzp1, H, B)\n+\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$6  $dst, $5, $dst, $5\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$6(as_FloatRegister($dst$$reg), __ $5, ptrue, as_FloatRegister($dst$$reg), __ $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5 $6\n+VECTOR_CAST_I2F_EXTEND2(B, F, sunpklo, H, S, scvtf)\n+VECTOR_CAST_I2F_EXTEND2(S, D, sunpklo, S, D, scvtf)\n+\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5 $6 $7\n+VECTOR_CAST_I2F_EXTEND3(B, D, sunpklo, H, S, D, scvtf)\n+\n+dnl\n+define(`VECTOR_CAST_X2F_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $5\\n\\t\"\n+            \"sve_$6  $tmp, $7, 0\\n\\t\"\n+            \"sve_$8  $dst, $7, $dst, $tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $5);\n+    __ sve_$6(as_FloatRegister($tmp$$reg), __ $7, 0);\n+    __ sve_$8(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3     $4 $5 $6   $7 $8\n+VECTOR_CAST_X2F_NARROW1(L, F, scvtf, S, D, dup, S, uzp1)\n+VECTOR_CAST_X2F_NARROW1(D, F, fcvt,  S, D, dup, S, uzp1)\n+\n+dnl\n+define(`VECTOR_CAST_X2X', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl             $1 $2 $3      $4\n+VECTOR_CAST_X2X(I, F, scvtf,  S)\n+VECTOR_CAST_X2X(L, D, scvtf,  D)\n+VECTOR_CAST_X2X(F, I, fcvtzs, S)\n+VECTOR_CAST_X2X(D, L, fcvtzs, D)\n+\n+dnl\n+define(`VECTOR_CAST_X2F_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$5  $dst, $4, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5     $6\n+VECTOR_CAST_X2F_EXTEND1(I, D, sunpklo, D, scvtf, D)\n+VECTOR_CAST_X2F_EXTEND1(S, F, sunpklo, S, scvtf, S)\n+VECTOR_CAST_X2F_EXTEND1(F, D, sunpklo, D, fcvt,  S)\n+\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7\n+VECTOR_CAST_F2X_NARROW1(F, S, fcvtzs, S, dup, H, uzp1)\n+VECTOR_CAST_F2X_NARROW1(D, I, fcvtzs, D, dup, S, uzp1)\n+\n+\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7    $8\n+VECTOR_CAST_F2X_NARROW2(F, B, fcvtzs, S, dup, H, uzp1, B)\n+VECTOR_CAST_F2X_NARROW2(D, S, fcvtzs, D, dup, S, uzp1, H)\n+\n+\n+dnl\n+define(`VECTOR_CAST_F2X_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5       $6\n+VECTOR_CAST_F2X_EXTEND1(F, L, fcvtzs, S, sunpklo, D)\n+\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $9, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $9, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7    $8 $9\n+VECTOR_CAST_F2X_NARROW3(D, B, fcvtzs, D, dup, S, uzp1, H, B)\n+\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+define(`VECTOR_EXTRACT_SXT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, $3, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, $3, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, $5\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ $3, zr, rscratch1);\n+    __ sve_lastb(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_$4($dst$$reg), as_$4($dst$$reg), 0U, $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                $1 $2         $3 $4        $5\n+VECTOR_EXTRACT_SXT(B, iRegINoSp, B, Register, 7U)\n+VECTOR_EXTRACT_SXT(S, iRegINoSp, H, Register, 15U)\n+\n+dnl\n+define(`VECTOR_EXTRACT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, $3, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, $3, $pTmp, $src\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ $3, zr, rscratch1);\n+    __ sve_lastb(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl            $1 $2         $3 $4\n+VECTOR_EXTRACT(I, iRegINoSp, S, Register)\n+VECTOR_EXTRACT(L, iRegLNoSp, D, Register)\n+VECTOR_EXTRACT(F, vRegF,     S, FloatRegister)\n+VECTOR_EXTRACT(D, vRegD,     D, FloatRegister)\n+\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+dnl\n+dnl VTEST($1,      $2,   $3,  $4  )\n+dnl VTEST(op_name, pred, imm, cond)\n+define(`VTEST', `\n+instruct vtest_$1`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, $3\\n\\t\"\n+            \"csetw $dst, $4\\t# VectorTest (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST(alltrue, overflow, 0, EQ)\n+VTEST(anytrue, ne,      -1, NE)\n+dnl\n+dnl\n+dnl VTEST_PARTIAL($1,      $2,   $3,  $4  )\n+dnl VTEST_PARTIAL(op_name, pred, imm, cond)\n+define(`VTEST_PARTIAL', `\n+instruct vtest_$1_partial`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vtest_$1_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST_PARTIAL(alltrue, overflow, 0, EQ)\n+VTEST_PARTIAL(anytrue, ne,      -1, NE)\n+\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+define(`VECTOR_INSERT_SMALL', `\n+instruct insert$1_small`'(vReg dst, vReg src, $2 val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, $3, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ $3, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2          $3 $4\n+VECTOR_INSERT_SMALL(B, iRegIorL2I, B, Register)\n+VECTOR_INSERT_SMALL(S, iRegIorL2I, H, Register)\n+VECTOR_INSERT_SMALL(I, iRegIorL2I, S, Register)\n+VECTOR_INSERT_SMALL(F, vRegF,      S, FloatRegister)\n+\n+define(`VECTOR_INSERT_D', `\n+instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, $3, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ $3, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl             $1 $2     $3 $4\n+VECTOR_INSERT_D(L, iRegL, D, Register)\n+VECTOR_INSERT_D(D, vRegD, D, FloatRegister)\n+\n+define(`VECTOR_INSERT', `\n+instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, $3, 0, 1\\n\\t\"\n+            \"sve_dup $dst, $3, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ $3, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $3, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl           $1 $2          $3 $4\n+VECTOR_INSERT(B, iRegIorL2I, B, Register)\n+VECTOR_INSERT(S, iRegIorL2I, H, Register)\n+VECTOR_INSERT(I, iRegIorL2I, S, Register)\n+VECTOR_INSERT(F, vRegF,      S, FloatRegister)\n+\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+instruct loadshuffleB(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orr $dst, $src, $src\\t# vector load shuffle (B)\" %}\n+  ins_encode %{\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+                 as_FloatRegister($src$$reg),\n+                 as_FloatRegister($src$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\t# vector load shuffle (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector rearrange -------------------------------\n+dnl\n+define(`VECTOR_REARRANGE', `\n+instruct rearrange$1`'(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorRearrange src shuffle));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_tbl $dst, $2, $src, $shuffle\\t# vector rearrange ($1)\" %}\n+  ins_encode %{\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ $2,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl              $1 $2\n+VECTOR_REARRANGE(B, B)\n+VECTOR_REARRANGE(S, H)\n+VECTOR_REARRANGE(I, S)\n+VECTOR_REARRANGE(F, S)\n+VECTOR_REARRANGE(L, D)\n+VECTOR_REARRANGE(D, D)\n+\n+\/\/ ------------------------------ Vector Load Gather ---------------------------------\n+instruct gatherI(vReg dst, vmemA mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(SVE_COST);\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL(vReg dst, vmemA mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":1704,"deletions":163,"binary":false,"changes":1867,"status":"modified"},{"patch":"@@ -3161,0 +3161,12 @@\n+\/\/ SVE load gather (scalar plus vector) - 32-bit scaled offset\n+#define INSN(NAME, op1, type, op2, op3)                                         \\\n+  void NAME(FloatRegister Zt, PRegister Pg, Register Xn, FloatRegister Zm) {    \\\n+    starti;                                                                     \\\n+    f(op1, 31, 25), f(type, 24, 23), f(op2, 22, 21), rf(Zm, 16);                \\\n+    f(op3, 15, 13), pgrf(Pg, 10), srf(Xn, 5), rf(Zt, 0);                        \\\n+  }\n+\n+  INSN(sve_ld1w_gather,  0b1000010, 0b10, 0b01, 0b010);\n+  INSN(sve_ld1d_gather,  0b1100010, 0b11, 0b01, 0b010);\n+#undef INSN\n+\n@@ -3215,1 +3227,1 @@\n-  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm8) {\n+  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm16) {\n@@ -3219,1 +3231,2 @@\n-    if (imm8 <= 127 && imm8 >= -128) {\n+    unsigned imm = imm16;\n+    if (imm16 <= 127 && imm16 >= -128) {\n@@ -3221,1 +3234,1 @@\n-    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n+    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n@@ -3223,1 +3236,1 @@\n-      imm8 = (imm8 >> 8);\n+      imm = (imm >> 8);\n@@ -3227,0 +3240,2 @@\n+    unsigned mask = (1U << 8) - 1;\n+    imm &= mask;\n@@ -3228,1 +3243,1 @@\n-    f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n+    f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n@@ -3237,0 +3252,320 @@\n+   \/\/ SVE cpy immediate\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm16, bool isMerge) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    int sh = 0;\n+    unsigned imm = imm16;\n+    if (imm16 <= 127 && imm16 >= -128) {\n+      sh = 0;\n+    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n+      sh = 1;\n+      imm = (imm >> 8);\n+    } else {\n+      guarantee(false, \"invalid immediate\");\n+    }\n+    unsigned mask = (1U << 8) - 1;\n+    imm &= mask;\n+    int m = isMerge ? 1 : 0;\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b01, 21, 20);\n+    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE vector sel\n+  void sve_sel(FloatRegister Zd,\n+               SIMD_RegVariant T,\n+               PRegister Pg,\n+               FloatRegister Zn,\n+               FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b11, 15, 14), prf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE compare vector\n+#define INSN(NAME, op, cond, fp)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, FloatRegister Zm)  { \\\n+    starti;                                                                                       \\\n+    if (fp == 0) {                                                                                \\\n+      assert(T != Q, \"invalid size\");                                                             \\\n+    } else {                                                                                      \\\n+      assert(T != B && T != Q, \"invalid size\");                                                   \\\n+    }                                                                                             \\\n+    f(op, 31, 24), f(T, 23, 22), f(0b0, 21), rf(Zm, 16), f((cond >> 1) & 0x7, 15, 13);            \\\n+    pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0);                                        \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b00100100, 0b1010, 0);\n+  INSN(sve_cmpne, 0b00100100, 0b1011, 0);\n+  INSN(sve_cmpge, 0b00100100, 0b1000, 0);\n+  INSN(sve_cmpgt, 0b00100100, 0b1001, 0);\n+  INSN(sve_fcmeq, 0b01100101, 0b0110, 1);\n+  INSN(sve_fcmne, 0b01100101, 0b0111, 1);\n+  INSN(sve_fcmgt, 0b01100101, 0b0101, 1);\n+  INSN(sve_fcmge, 0b01100101, 0b0100, 1);\n+#undef INSN\n+\n+\/\/ SVE compare vector with immediate\n+#define INSN(NAME, cond)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, int imm5) { \\\n+    starti;                                                                              \\\n+    assert(T != Q, \"invalid size\");                                                      \\\n+    if (imm5 > 15 || imm5 < -16) {                                                       \\\n+      guarantee(false, \"invalid immediate\");                                             \\\n+    }                                                                                    \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(0b0, 21), sf(imm5, 20, 16),                   \\\n+    f((cond >> 1) & 0x7, 15, 13), pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0); \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b1000);\n+  INSN(sve_cmpne, 0b1001);\n+  INSN(sve_cmpgt, 0b0001);\n+  INSN(sve_cmpge, 0b0000);\n+  INSN(sve_cmplt, 0b0010);\n+  INSN(sve_cmple, 0b0011);\n+#undef INSN\n+\n+\/\/ SVE unpack and extend\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn) { \\\n+    starti;                                                          \\\n+    assert(T != B && T != Q, \"invalid size\");                        \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1100, 21, 18);          \\\n+    f(op, 17, 16), f(0b001110, 15, 10), rf(Zn, 5), rf(Zd, 0);        \\\n+  }\n+\n+  INSN(sve_uunpkhi, 0b11);\n+  INSN(sve_uunpklo, 0b10);\n+  INSN(sve_sunpkhi, 0b01);\n+  INSN(sve_sunpklo, 0b00);\n+#undef INSN\n+\n+\/\/ SVE vector uzp1,uzp2\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) { \\\n+    starti;                                                                            \\\n+    assert(T != Q, \"invalid size\");                                                    \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);                       \\\n+    f(0b01101, 15, 11), f(op, 10), rf(Zn, 5), rf(Zd, 0);                               \\\n+  }\n+\n+  INSN(sve_uzp1, 0b0);\n+  INSN(sve_uzp2, 0b1);\n+#undef INSN\n+\n+\/\/ SVE while[cond]\n+#define INSN(NAME, decode, sf)                                            \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, Register Rn, Register Rm) {  \\\n+    starti;                                                               \\\n+    assert(T != Q, \"invalid register variant\");                           \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(1, 21),                        \\\n+    zrf(Rm, 16), f(0, 15, 13), f(sf, 12), f(decode >> 1, 11, 10),         \\\n+    zrf(Rn, 5), f(decode & 0b1, 4), prf(Pd, 0);                           \\\n+  }\n+\n+  INSN(sve_whilelt,  0b010, 1);\n+  INSN(sve_whileltw, 0b010, 0);\n+  INSN(sve_whilele,  0b011, 1);\n+  INSN(sve_whilelew, 0b011, 0);\n+  INSN(sve_whilelo,  0b110, 1);\n+  INSN(sve_whilelow, 0b110, 0);\n+  INSN(sve_whilels,  0b111, 1);\n+  INSN(sve_whilelsw, 0b111, 0);\n+#undef INSN\n+\n+private:\n+\n+  void encode_cvtf_T(SIMD_RegVariant T_dst, SIMD_RegVariant T_src,\n+                     unsigned& opc, unsigned& opc2) {\n+    assert(T_src != B && T_dst != B &&\n+           T_src != Q && T_dst != Q, \"invalid register variant\");\n+    if (T_dst != D) {\n+      assert(T_dst <= T_src, \"invalid register variant\");\n+    } else {\n+      assert(T_src != H, \"invalid register variant\");\n+    }\n+    \/\/ In most cases we can treat T_dst,T_src as opc,opc2\n+    \/\/ except following four cases. These cases should be converted\n+    \/\/ according to Arm's architecture reference manual:\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ | opc | opc2 | U |        Instruction Details         |\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ |  11 |   00 | 0 | SCVTF — 32-bit to double-precision |\n+    \/\/ |  11 |   00 | 1 | UCVTF — 32-bit to double-precision |\n+    \/\/ |  11 |   10 | 0 | SCVTF — 64-bit to single-precision |\n+    \/\/ |  11 |   10 | 1 | UCVTF — 64-bit to single-precision |\n+    \/\/ +-----+------+---+------------------------------------+\n+    if (T_dst == S && T_src == D) { \/\/ 64-bit to single-precision\n+      T_dst = D;\n+      T_src = S;\n+    } else if (T_dst == D && T_src == S) { \/\/ 32-bit to double-precision\n+      T_dst = D;\n+      T_src = B;\n+    }\n+    opc = T_dst;\n+    opc2 = T_src;\n+  }\n+public:\n+\n+\/\/ SVE convert integer to floating-point (predicated)\n+#define INSN(NAME, sign)                                                \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,      \\\n+            FloatRegister Zn, SIMD_RegVariant T_src) {                  \\\n+    starti;                                                             \\\n+    unsigned opc, opc2;                                                 \\\n+    encode_cvtf_T(T_dst, T_src, opc, opc2);                             \\\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b010, 21, 19);            \\\n+    f(opc2, 18, 17), f(sign, 16), f(0b101, 15, 13);                     \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);                                 \\\n+  }\n+\n+  INSN(sve_scvtf, 0b0);\n+  INSN(sve_ucvtf, 0b1);\n+#undef INSN\n+\n+private:\n+\n+  void encode_fcvt_T(SIMD_RegVariant T_src,SIMD_RegVariant T_dst,\n+                     unsigned& opc, unsigned& opc2) {\n+    assert(T_src != B && T_dst != B &&\n+           T_src != Q && T_dst != Q, \"invalid register variant\");\n+    assert(T_src != T_dst, \"invalid register variant\");\n+    if (T_src == S) {\n+      if (T_dst == H) {\n+        opc = 0b10;\n+        opc2 = 0b00;\n+      } else if (T_dst == D) {\n+        opc = 0b11;\n+        opc2 = 0b11;\n+      }\n+    } else if (T_src == H) {\n+      if (T_dst == S) {\n+        opc = 0b10;\n+        opc2 = 0b01;\n+      } else if (T_dst == D) {\n+        opc = 0b11;\n+        opc2 = 0b01;\n+      }\n+    } else if (T_src == D) {\n+      if (T_dst == H) {\n+        opc = 0b11;\n+        opc2 = 0b00;\n+      } else if (T_dst == S) {\n+        opc = 0b11;\n+        opc2 = 0b10;\n+      }\n+    }\n+  }\n+public:\n+\n+\/\/ SVE floating-point convert precision (predicated)\n+  void sve_fcvt(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+            FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    unsigned opc, opc2;\n+    encode_fcvt_T(T_src, T_dst, opc, opc2);\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b0010, 21, 18);\n+    f(opc2, 17, 16), f(0b101, 15, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+private:\n+\n+  void encode_fcvtz_T (SIMD_RegVariant T_dst, SIMD_RegVariant T_src,\n+                       unsigned& opc, unsigned& opc2) {\n+    assert(T_src != B && T_dst != B &&\n+           T_src != Q && T_dst != Q, \"invalid register variant\");\n+    if (T_src != D) {\n+      assert(T_src <= T_dst, \"invalid register variant\");\n+    } else {\n+      assert(T_dst != H, \"invalid register variant\");\n+    }\n+    \/\/ In most cases we can treat T_dst,T_src as opc2,opc\n+    \/\/ except following four cases. These cases should be converted\n+    \/\/ according to Arm's architecture reference manual:\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ | opc | opc2 | U |        Instruction Details          |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ |  11 |   10 | 0 | FCVTZS — Single-precision to 64-bit |\n+    \/\/ |  11 |   10 | 1 | FCVTZU — Single-precision to 64-bit |\n+    \/\/ |  11 |   00 | 0 | FCVTZS — Double-precision to 32-bit |\n+    \/\/ |  11 |   00 | 1 | FCVTZU — Double-precision to 32-bit |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    if (T_dst == D && T_src == S) { \/\/ Single-precision to 64-bit\n+      T_dst = S;\n+      T_src = D;\n+    } else if (T_dst == S && T_src == D) { \/\/ Double-precision to 32-bit\n+      T_dst = B;\n+      T_src = D;\n+    }\n+    opc = T_src;\n+    opc2 = T_dst;\n+  }\n+public:\n+\n+\/\/ SVE floating-point convert to integer (predicated)\n+#define INSN(NAME, sign)                                                \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,      \\\n+            FloatRegister Zn, SIMD_RegVariant T_src) {                  \\\n+    starti;                                                             \\\n+    unsigned opc, opc2;                                                 \\\n+    encode_fcvtz_T(T_dst, T_src, opc, opc2);                            \\\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b011, 21, 19);            \\\n+    f(opc2, 18, 17), f(sign, 16), f(0b101, 15, 13);                     \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);                                 \\\n+  }\n+\n+  INSN(sve_fcvtzs, 0b0);\n+  INSN(sve_fcvtzu, 0b1);\n+#undef INSN\n+\n+\/\/ SVE conditionally extract element to general-purpose register\n+#define INSN(NAME, before)                                                      \\\n+  void NAME(Register Rd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                     \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10000, 21, 17);                    \\\n+    f(before, 16), f(0b101, 15, 13);                                            \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Rd, 0);                                         \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+#define INSN(NAME, before)                                                           \\\n+  void NAME(FloatRegister Vd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                          \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10001, 21, 17);                         \\\n+    f(before, 16), f(0b100, 15, 13);                                                 \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Vd, 0);                                              \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+\/\/ SVE cpy general-purpose register\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, Register Rn) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b101000101, 21, 13);\n+    pgrf(Pg, 10), srf(Rn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE INDEX (immediates)\n+  void sve_index(FloatRegister Zd, SIMD_RegVariant T,\n+                 int imm1, int imm2) {\n+    starti;\n+    f(0b00000100, 31, 24), f(T, 23, 22), f(0b1, 21);\n+    sf(imm2, 20, 16), f(0b010000, 15, 10);\n+    sf(imm1, 9, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE programmable table lookup in single vector table\n+  void sve_tbl(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b001100, 15, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":340,"deletions":5,"binary":false,"changes":345,"status":"modified"},{"patch":"@@ -867,0 +867,7 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1002,0 +1002,18 @@\n+bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+  return false;\n+}\n+\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -358,0 +358,7 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2197,0 +2197,18 @@\n+bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+  return false;\n+}\n+\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -920,0 +920,7 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1555,0 +1555,18 @@\n+bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+  return false;\n+}\n+\n+\/\/ Vector calling convention not yet implemented.\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return false;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  Unimplemented();\n+  return OptoRegPair(0, 0);\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -855,0 +855,7 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -3146,1 +3146,1 @@\n-                             int comparison, int vector_len, Register scratch_reg) {\n+                             int comparison, bool is_signed, int vector_len, Register scratch_reg) {\n@@ -3148,1 +3148,1 @@\n-    Assembler::evpcmpd(kdst, mask, nds, as_Address(src), comparison, vector_len);\n+    Assembler::evpcmpd(kdst, mask, nds, as_Address(src), comparison, is_signed, vector_len);\n@@ -3151,1 +3151,1 @@\n-    Assembler::evpcmpd(kdst, mask, nds, Address(scratch_reg, 0), comparison, vector_len);\n+    Assembler::evpcmpd(kdst, mask, nds, Address(scratch_reg, 0), comparison, is_signed, vector_len);\n@@ -3156,1 +3156,1 @@\n-                             int comparison, int vector_len, Register scratch_reg) {\n+                             int comparison, bool is_signed, int vector_len, Register scratch_reg) {\n@@ -3158,1 +3158,1 @@\n-    Assembler::evpcmpq(kdst, mask, nds, as_Address(src), comparison, vector_len);\n+    Assembler::evpcmpq(kdst, mask, nds, as_Address(src), comparison, is_signed, vector_len);\n@@ -3161,1 +3161,1 @@\n-    Assembler::evpcmpq(kdst, mask, nds, Address(scratch_reg, 0), comparison, vector_len);\n+    Assembler::evpcmpq(kdst, mask, nds, Address(scratch_reg, 0), comparison, is_signed, vector_len);\n@@ -3166,1 +3166,1 @@\n-                             int comparison, int vector_len, Register scratch_reg) {\n+                             int comparison, bool is_signed, int vector_len, Register scratch_reg) {\n@@ -3168,1 +3168,1 @@\n-    Assembler::evpcmpb(kdst, mask, nds, as_Address(src), comparison, vector_len);\n+    Assembler::evpcmpb(kdst, mask, nds, as_Address(src), comparison, is_signed, vector_len);\n@@ -3171,1 +3171,1 @@\n-    Assembler::evpcmpb(kdst, mask, nds, Address(scratch_reg, 0), comparison, vector_len);\n+    Assembler::evpcmpb(kdst, mask, nds, Address(scratch_reg, 0), comparison, is_signed, vector_len);\n@@ -3176,1 +3176,1 @@\n-                             int comparison, int vector_len, Register scratch_reg) {\n+                             int comparison, bool is_signed, int vector_len, Register scratch_reg) {\n@@ -3178,1 +3178,1 @@\n-    Assembler::evpcmpw(kdst, mask, nds, as_Address(src), comparison, vector_len);\n+    Assembler::evpcmpw(kdst, mask, nds, as_Address(src), comparison, is_signed, vector_len);\n@@ -3181,1 +3181,1 @@\n-    Assembler::evpcmpw(kdst, mask, nds, Address(scratch_reg, 0), comparison, vector_len);\n+    Assembler::evpcmpw(kdst, mask, nds, Address(scratch_reg, 0), comparison, is_signed, vector_len);\n@@ -7861,1 +7861,1 @@\n-    evpcmpuw(mask1, mask2, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n+    evpcmpw(mask1, mask2, tmp1Reg, tmp2Reg, Assembler::le, \/*signed*\/ false, Assembler::AVX_512bit);\n@@ -7911,1 +7911,1 @@\n-    evpcmpuw(mask1, mask2, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n+    evpcmpw(mask1, mask2, tmp1Reg, tmp2Reg, Assembler::le, \/*signed*\/ false, Assembler::AVX_512bit);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -1288,1 +1288,1 @@\n-               int comparison, int vector_len) { Assembler::evpcmpd(kdst, mask, nds, src, comparison, vector_len); }\n+               int comparison, bool is_signed, int vector_len) { Assembler::evpcmpd(kdst, mask, nds, src, comparison, is_signed, vector_len); }\n@@ -1290,1 +1290,1 @@\n-               int comparison, int vector_len, Register scratch_reg);\n+               int comparison, bool is_signed, int vector_len, Register scratch_reg);\n@@ -1292,1 +1292,1 @@\n-               int comparison, int vector_len) { Assembler::evpcmpq(kdst, mask, nds, src, comparison, vector_len); }\n+               int comparison, bool is_signed, int vector_len) { Assembler::evpcmpq(kdst, mask, nds, src, comparison, is_signed, vector_len); }\n@@ -1294,1 +1294,1 @@\n-               int comparison, int vector_len, Register scratch_reg);\n+               int comparison, bool is_signed, int vector_len, Register scratch_reg);\n@@ -1296,1 +1296,1 @@\n-               int comparison, int vector_len) { Assembler::evpcmpb(kdst, mask, nds, src, comparison, vector_len); }\n+               int comparison, bool is_signed, int vector_len) { Assembler::evpcmpb(kdst, mask, nds, src, comparison, is_signed, vector_len); }\n@@ -1298,1 +1298,1 @@\n-               int comparison, int vector_len, Register scratch_reg);\n+               int comparison, bool is_signed, int vector_len, Register scratch_reg);\n@@ -1300,1 +1300,1 @@\n-               int comparison, int vector_len) { Assembler::evpcmpw(kdst, mask, nds, src, comparison, vector_len); }\n+               int comparison, bool is_signed, int vector_len) { Assembler::evpcmpw(kdst, mask, nds, src, comparison, is_signed, vector_len); }\n@@ -1302,1 +1302,1 @@\n-               int comparison, int vector_len, Register scratch_reg);\n+               int comparison, bool is_signed, int vector_len, Register scratch_reg);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1047,0 +1047,7 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  Unimplemented();\n+  return 0;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1166,0 +1166,25 @@\n+int SharedRuntime::vector_calling_convention(VMRegPair *regs,\n+                                             uint num_bits,\n+                                             uint total_args_passed) {\n+  assert(num_bits == 64 || num_bits == 128 || num_bits == 256 || num_bits == 512,\n+         \"only certain vector sizes are supported for now\");\n+\n+  static const XMMRegister VEC_ArgReg[32] = {\n+     xmm0,  xmm1,  xmm2,  xmm3,  xmm4,  xmm5,  xmm6,  xmm7,\n+     xmm8,  xmm9, xmm10, xmm11, xmm12, xmm13, xmm14, xmm15,\n+    xmm16, xmm17, xmm18, xmm19, xmm20, xmm21, xmm22, xmm23,\n+    xmm24, xmm25, xmm26, xmm27, xmm28, xmm29, xmm30, xmm31\n+  };\n+\n+  uint stk_args = 0;\n+  uint fp_args = 0;\n+\n+  for (uint i = 0; i < total_args_passed; i++) {\n+    VMReg vmreg = VEC_ArgReg[fp_args++]->as_VMReg();\n+    int next_val = num_bits == 64 ? 1 : (num_bits == 128 ? 3 : (num_bits  == 256 ? 7 : 15));\n+    regs[i].set_pair(vmreg->next(next_val), vmreg);\n+  }\n+\n+  return stk_args;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -6969,0 +6969,322 @@\n+#ifdef __VECTOR_API_MATH_INTRINSICS_COMMON\n+    void *libsvml = NULL;\n+    char ebuf[1024];\n+    libsvml = os::dll_load(JNI_LIB_PREFIX \"svml\" JNI_LIB_SUFFIX, ebuf, sizeof ebuf);\n+    if (libsvml != NULL) {\n+      log_info(library)(\"Loaded library %s, handle \" INTPTR_FORMAT, JNI_LIB_PREFIX \"svml\" JNI_LIB_SUFFIX, p2i(libsvml));\n+      if (UseAVX > 2) {\n+        StubRoutines::_vector_exp_float512    = (address)os::dll_lookup(libsvml, \"__svml_expf16_ha_z0\");\n+        StubRoutines::_vector_exp_double512   = (address)os::dll_lookup(libsvml, \"__svml_exp8_ha_z0\");\n+        StubRoutines::_vector_expm1_float512  = (address)os::dll_lookup(libsvml, \"__svml_expm1f16_ha_z0\");\n+        StubRoutines::_vector_expm1_double512 = (address)os::dll_lookup(libsvml, \"__svml_expm18_ha_z0\");\n+        StubRoutines::_vector_log1p_float512  = (address)os::dll_lookup(libsvml, \"__svml_log1pf16_ha_z0\");\n+        StubRoutines::_vector_log1p_double512 = (address)os::dll_lookup(libsvml, \"__svml_log1p8_ha_z0\");\n+        StubRoutines::_vector_log_float512    = (address)os::dll_lookup(libsvml, \"__svml_logf16_ha_z0\");\n+        StubRoutines::_vector_log_double512   = (address)os::dll_lookup(libsvml, \"__svml_log8_ha_z0\");\n+        StubRoutines::_vector_log10_float512  = (address)os::dll_lookup(libsvml, \"__svml_log10f16_ha_z0\");\n+        StubRoutines::_vector_log10_double512 = (address)os::dll_lookup(libsvml, \"__svml_log108_ha_z0\");\n+        StubRoutines::_vector_sin_float512    = (address)os::dll_lookup(libsvml, \"__svml_sinf16_ha_z0\");\n+        StubRoutines::_vector_sin_double512   = (address)os::dll_lookup(libsvml, \"__svml_sin8_ha_z0\");\n+        StubRoutines::_vector_cos_float512    = (address)os::dll_lookup(libsvml, \"__svml_cosf16_ha_z0\");\n+        StubRoutines::_vector_cos_double512   = (address)os::dll_lookup(libsvml, \"__svml_cos8_ha_z0\");\n+        StubRoutines::_vector_tan_float512    = (address)os::dll_lookup(libsvml, \"__svml_tanf16_ha_z0\");\n+        StubRoutines::_vector_tan_double512   = (address)os::dll_lookup(libsvml, \"__svml_tan8_ha_z0\");\n+        StubRoutines::_vector_sinh_float512   = (address)os::dll_lookup(libsvml, \"__svml_sinhf16_ha_z0\");\n+        StubRoutines::_vector_sinh_double512  = (address)os::dll_lookup(libsvml, \"__svml_sinh8_ha_z0\");\n+        StubRoutines::_vector_cosh_float512   = (address)os::dll_lookup(libsvml, \"__svml_coshf16_ha_z0\");\n+        StubRoutines::_vector_cosh_double512  = (address)os::dll_lookup(libsvml, \"__svml_cosh8_ha_z0\");\n+        StubRoutines::_vector_tanh_float512   = (address)os::dll_lookup(libsvml, \"__svml_tanhf16_ha_z0\");\n+        StubRoutines::_vector_tanh_double512  = (address)os::dll_lookup(libsvml, \"__svml_tanh8_ha_z0\");\n+        StubRoutines::_vector_acos_float512   = (address)os::dll_lookup(libsvml, \"__svml_acosf16_ha_z0\");\n+        StubRoutines::_vector_acos_double512  = (address)os::dll_lookup(libsvml, \"__svml_acos8_ha_z0\");\n+        StubRoutines::_vector_asin_float512   = (address)os::dll_lookup(libsvml, \"__svml_asinf16_ha_z0\");\n+        StubRoutines::_vector_asin_double512  = (address)os::dll_lookup(libsvml, \"__svml_asin8_ha_z0\");\n+        StubRoutines::_vector_atan_float512   = (address)os::dll_lookup(libsvml, \"__svml_atanf16_ha_z0\");\n+        StubRoutines::_vector_atan_double512  = (address)os::dll_lookup(libsvml, \"__svml_atan8_ha_z0\");\n+        StubRoutines::_vector_pow_float512    = (address)os::dll_lookup(libsvml, \"__svml_powf16_ha_z0\");\n+        StubRoutines::_vector_pow_double512   = (address)os::dll_lookup(libsvml, \"__svml_pow8_ha_z0\");\n+        StubRoutines::_vector_hypot_float512  = (address)os::dll_lookup(libsvml, \"__svml_hypotf16_ha_z0\");\n+        StubRoutines::_vector_hypot_double512 = (address)os::dll_lookup(libsvml, \"__svml_hypot8_ha_z0\");\n+        StubRoutines::_vector_cbrt_float512   = (address)os::dll_lookup(libsvml, \"__svml_cbrtf16_ha_z0\");\n+        StubRoutines::_vector_cbrt_double512  = (address)os::dll_lookup(libsvml, \"__svml_cbrt8_ha_z0\");\n+        StubRoutines::_vector_atan2_float512  = (address)os::dll_lookup(libsvml, \"__svml_atan2f16_ha_z0\");\n+        StubRoutines::_vector_atan2_double512 = (address)os::dll_lookup(libsvml, \"__svml_atan28_ha_z0\");\n+      } else if (UseAVX > 1) {\n+        StubRoutines::_vector_exp_float64     = (address)os::dll_lookup(libsvml, \"__svml_expf4_ha_l9\");\n+        StubRoutines::_vector_exp_float128    = (address)os::dll_lookup(libsvml, \"__svml_expf4_ha_l9\");\n+        StubRoutines::_vector_exp_float256    = (address)os::dll_lookup(libsvml, \"__svml_expf8_ha_l9\");\n+        StubRoutines::_vector_exp_double64    = (address)os::dll_lookup(libsvml, \"__svml_exp1_ha_l9\");\n+        StubRoutines::_vector_exp_double128   = (address)os::dll_lookup(libsvml, \"__svml_exp2_ha_l9\");\n+        StubRoutines::_vector_exp_double256   = (address)os::dll_lookup(libsvml, \"__svml_exp4_ha_l9\");\n+        StubRoutines::_vector_expm1_float64   = (address)os::dll_lookup(libsvml, \"__svml_expm1f4_ha_l9\");\n+        StubRoutines::_vector_expm1_float128  = (address)os::dll_lookup(libsvml, \"__svml_expm1f4_ha_l9\");\n+        StubRoutines::_vector_expm1_float256  = (address)os::dll_lookup(libsvml, \"__svml_expm1f8_ha_l9\");\n+        StubRoutines::_vector_expm1_double64  = (address)os::dll_lookup(libsvml, \"__svml_expm11_ha_l9\");\n+        StubRoutines::_vector_expm1_double128 = (address)os::dll_lookup(libsvml, \"__svml_expm12_ha_l9\");\n+        StubRoutines::_vector_expm1_double256 = (address)os::dll_lookup(libsvml, \"__svml_expm14_ha_l9\");\n+        StubRoutines::_vector_log1p_float64   = (address)os::dll_lookup(libsvml, \"__svml_log1pf4_ha_l9\");\n+        StubRoutines::_vector_log1p_float128  = (address)os::dll_lookup(libsvml, \"__svml_log1pf4_ha_l9\");\n+        StubRoutines::_vector_log1p_float256  = (address)os::dll_lookup(libsvml, \"__svml_log1pf8_ha_l9\");\n+        StubRoutines::_vector_log1p_double64  = (address)os::dll_lookup(libsvml, \"__svml_log1p1_ha_l9\");\n+        StubRoutines::_vector_log1p_double128 = (address)os::dll_lookup(libsvml, \"__svml_log1p2_ha_l9\");\n+        StubRoutines::_vector_log1p_double256 = (address)os::dll_lookup(libsvml, \"__svml_log1p4_ha_l9\");\n+        StubRoutines::_vector_log_float64     = (address)os::dll_lookup(libsvml, \"__svml_logf4_ha_l9\");\n+        StubRoutines::_vector_log_float128    = (address)os::dll_lookup(libsvml, \"__svml_logf4_ha_l9\");\n+        StubRoutines::_vector_log_float256    = (address)os::dll_lookup(libsvml, \"__svml_logf8_ha_l9\");\n+        StubRoutines::_vector_log_double64    = (address)os::dll_lookup(libsvml, \"__svml_log1_ha_l9\");\n+        StubRoutines::_vector_log_double128   = (address)os::dll_lookup(libsvml, \"__svml_log2_ha_l9\");\n+        StubRoutines::_vector_log_double256   = (address)os::dll_lookup(libsvml, \"__svml_log4_ha_l9\");\n+        StubRoutines::_vector_log10_float64   = (address)os::dll_lookup(libsvml, \"__svml_log10f4_ha_l9\");\n+        StubRoutines::_vector_log10_float128  = (address)os::dll_lookup(libsvml, \"__svml_log10f4_ha_l9\");\n+        StubRoutines::_vector_log10_float256  = (address)os::dll_lookup(libsvml, \"__svml_log10f8_ha_l9\");\n+        StubRoutines::_vector_log10_double64  = (address)os::dll_lookup(libsvml, \"__svml_log101_ha_l9\");\n+        StubRoutines::_vector_log10_double128 = (address)os::dll_lookup(libsvml, \"__svml_log102_ha_l9\");\n+        StubRoutines::_vector_log10_double256 = (address)os::dll_lookup(libsvml, \"__svml_log104_ha_l9\");\n+        StubRoutines::_vector_sin_float64     = (address)os::dll_lookup(libsvml, \"__svml_sinf4_ha_l9\");\n+        StubRoutines::_vector_sin_float128    = (address)os::dll_lookup(libsvml, \"__svml_sinf4_ha_l9\");\n+        StubRoutines::_vector_sin_float256    = (address)os::dll_lookup(libsvml, \"__svml_sinf8_ha_l9\");\n+        StubRoutines::_vector_sin_double64    = (address)os::dll_lookup(libsvml, \"__svml_sin1_ha_l9\");\n+        StubRoutines::_vector_sin_double128   = (address)os::dll_lookup(libsvml, \"__svml_sin2_ha_l9\");\n+        StubRoutines::_vector_sin_double256   = (address)os::dll_lookup(libsvml, \"__svml_sin4_ha_l9\");\n+        StubRoutines::_vector_cos_float64     = (address)os::dll_lookup(libsvml, \"__svml_cosf4_ha_l9\");\n+        StubRoutines::_vector_cos_float128    = (address)os::dll_lookup(libsvml, \"__svml_cosf4_ha_l9\");\n+        StubRoutines::_vector_cos_float256    = (address)os::dll_lookup(libsvml, \"__svml_cosf8_ha_l9\");\n+        StubRoutines::_vector_cos_double64    = (address)os::dll_lookup(libsvml, \"__svml_cos1_ha_l9\");\n+        StubRoutines::_vector_cos_double128   = (address)os::dll_lookup(libsvml, \"__svml_cos2_ha_l9\");\n+        StubRoutines::_vector_cos_double256   = (address)os::dll_lookup(libsvml, \"__svml_cos4_ha_l9\");\n+        StubRoutines::_vector_tan_float64     = (address)os::dll_lookup(libsvml, \"__svml_tanf4_ha_l9\");\n+        StubRoutines::_vector_tan_float128    = (address)os::dll_lookup(libsvml, \"__svml_tanf4_ha_l9\");\n+        StubRoutines::_vector_tan_float256    = (address)os::dll_lookup(libsvml, \"__svml_tanf8_ha_l9\");\n+        StubRoutines::_vector_tan_double64    = (address)os::dll_lookup(libsvml, \"__svml_tan1_ha_l9\");\n+        StubRoutines::_vector_tan_double128   = (address)os::dll_lookup(libsvml, \"__svml_tan2_ha_l9\");\n+        StubRoutines::_vector_tan_double256   = (address)os::dll_lookup(libsvml, \"__svml_tan4_ha_l9\");\n+        StubRoutines::_vector_sinh_float64    = (address)os::dll_lookup(libsvml, \"__svml_sinhf4_ha_l9\");\n+        StubRoutines::_vector_sinh_float128   = (address)os::dll_lookup(libsvml, \"__svml_sinhf4_ha_l9\");\n+        StubRoutines::_vector_sinh_float256   = (address)os::dll_lookup(libsvml, \"__svml_sinhf8_ha_l9\");\n+        StubRoutines::_vector_sinh_double64   = (address)os::dll_lookup(libsvml, \"__svml_sinh1_ha_l9\");\n+        StubRoutines::_vector_sinh_double128  = (address)os::dll_lookup(libsvml, \"__svml_sinh2_ha_l9\");\n+        StubRoutines::_vector_sinh_double256  = (address)os::dll_lookup(libsvml, \"__svml_sinh4_ha_l9\");\n+        StubRoutines::_vector_cosh_float64    = (address)os::dll_lookup(libsvml, \"__svml_coshf4_ha_l9\");\n+        StubRoutines::_vector_cosh_float128   = (address)os::dll_lookup(libsvml, \"__svml_coshf4_ha_l9\");\n+        StubRoutines::_vector_cosh_float256   = (address)os::dll_lookup(libsvml, \"__svml_coshf8_ha_l9\");\n+        StubRoutines::_vector_cosh_double64   = (address)os::dll_lookup(libsvml, \"__svml_cosh1_ha_l9\");\n+        StubRoutines::_vector_cosh_double128  = (address)os::dll_lookup(libsvml, \"__svml_cosh2_ha_l9\");\n+        StubRoutines::_vector_cosh_double256  = (address)os::dll_lookup(libsvml, \"__svml_cosh4_ha_l9\");\n+        StubRoutines::_vector_tanh_float64    = (address)os::dll_lookup(libsvml, \"__svml_tanhf4_ha_l9\");\n+        StubRoutines::_vector_tanh_float128   = (address)os::dll_lookup(libsvml, \"__svml_tanhf4_ha_l9\");\n+        StubRoutines::_vector_tanh_float256   = (address)os::dll_lookup(libsvml, \"__svml_tanhf8_ha_l9\");\n+        StubRoutines::_vector_tanh_double64   = (address)os::dll_lookup(libsvml, \"__svml_tanh1_ha_l9\");\n+        StubRoutines::_vector_tanh_double128  = (address)os::dll_lookup(libsvml, \"__svml_tanh2_ha_l9\");\n+        StubRoutines::_vector_tanh_double256  = (address)os::dll_lookup(libsvml, \"__svml_tanh4_ha_l9\");\n+        StubRoutines::_vector_acos_float64    = (address)os::dll_lookup(libsvml, \"__svml_acosf4_ha_l9\");\n+        StubRoutines::_vector_acos_float128   = (address)os::dll_lookup(libsvml, \"__svml_acosf4_ha_l9\");\n+        StubRoutines::_vector_acos_float256   = (address)os::dll_lookup(libsvml, \"__svml_acosf8_ha_l9\");\n+        StubRoutines::_vector_acos_double64   = (address)os::dll_lookup(libsvml, \"__svml_acos1_ha_l9\");\n+        StubRoutines::_vector_acos_double128  = (address)os::dll_lookup(libsvml, \"__svml_acos2_ha_l9\");\n+        StubRoutines::_vector_acos_double256  = (address)os::dll_lookup(libsvml, \"__svml_acos4_ha_l9\");\n+        StubRoutines::_vector_asin_float64    = (address)os::dll_lookup(libsvml, \"__svml_asinf4_ha_l9\");\n+        StubRoutines::_vector_asin_float128   = (address)os::dll_lookup(libsvml, \"__svml_asinf4_ha_l9\");\n+        StubRoutines::_vector_asin_float256   = (address)os::dll_lookup(libsvml, \"__svml_asinf8_ha_l9\");\n+        StubRoutines::_vector_asin_double64   = (address)os::dll_lookup(libsvml, \"__svml_asin1_ha_l9\");\n+        StubRoutines::_vector_asin_double128  = (address)os::dll_lookup(libsvml, \"__svml_asin2_ha_l9\");\n+        StubRoutines::_vector_asin_double256  = (address)os::dll_lookup(libsvml, \"__svml_asin4_ha_l9\");\n+        StubRoutines::_vector_atan_float64    = (address)os::dll_lookup(libsvml, \"__svml_atanf4_ha_l9\");\n+        StubRoutines::_vector_atan_float128   = (address)os::dll_lookup(libsvml, \"__svml_atanf4_ha_l9\");\n+        StubRoutines::_vector_atan_float256   = (address)os::dll_lookup(libsvml, \"__svml_atanf8_ha_l9\");\n+        StubRoutines::_vector_atan_double64   = (address)os::dll_lookup(libsvml, \"__svml_atan1_ha_l9\");\n+        StubRoutines::_vector_atan_double128  = (address)os::dll_lookup(libsvml, \"__svml_atan2_ha_l9\");\n+        StubRoutines::_vector_atan_double256  = (address)os::dll_lookup(libsvml, \"__svml_atan4_ha_l9\");\n+        StubRoutines::_vector_hypot_float64   = (address)os::dll_lookup(libsvml, \"__svml_hypotf4_ha_l9\");\n+        StubRoutines::_vector_hypot_float128  = (address)os::dll_lookup(libsvml, \"__svml_hypotf4_ha_l9\");\n+        StubRoutines::_vector_hypot_float256  = (address)os::dll_lookup(libsvml, \"__svml_hypotf8_ha_l9\");\n+        StubRoutines::_vector_hypot_double64  = (address)os::dll_lookup(libsvml, \"__svml_hypot1_ha_l9\");\n+        StubRoutines::_vector_hypot_double128 = (address)os::dll_lookup(libsvml, \"__svml_hypot2_ha_l9\");\n+        StubRoutines::_vector_hypot_double256 = (address)os::dll_lookup(libsvml, \"__svml_hypot4_ha_l9\");\n+        StubRoutines::_vector_cbrt_float64    = (address)os::dll_lookup(libsvml, \"__svml_cbrtf4_ha_l9\");\n+        StubRoutines::_vector_cbrt_float128   = (address)os::dll_lookup(libsvml, \"__svml_cbrtf4_ha_l9\");\n+        StubRoutines::_vector_cbrt_float256   = (address)os::dll_lookup(libsvml, \"__svml_cbrtf8_ha_l9\");\n+        StubRoutines::_vector_cbrt_double64   = (address)os::dll_lookup(libsvml, \"__svml_cbrt1_ha_l9\");\n+        StubRoutines::_vector_cbrt_double128  = (address)os::dll_lookup(libsvml, \"__svml_cbrt2_ha_l9\");\n+        StubRoutines::_vector_cbrt_double256  = (address)os::dll_lookup(libsvml, \"__svml_cbrt4_ha_l9\");\n+        StubRoutines::_vector_atan2_float64   = (address)os::dll_lookup(libsvml, \"__svml_atan2f4_ha_l9\");\n+        StubRoutines::_vector_atan2_float128  = (address)os::dll_lookup(libsvml, \"__svml_atan2f4_ha_l9\");\n+        StubRoutines::_vector_atan2_float256  = (address)os::dll_lookup(libsvml, \"__svml_atan2f8_ha_l9\");\n+        StubRoutines::_vector_atan2_double64  = (address)os::dll_lookup(libsvml, \"__svml_atan21_ha_l9\");\n+        StubRoutines::_vector_atan2_double128 = (address)os::dll_lookup(libsvml, \"__svml_atan22_ha_l9\");\n+        StubRoutines::_vector_atan2_double256 = (address)os::dll_lookup(libsvml, \"__svml_atan24_ha_l9\");\n+      } else if (UseAVX > 0) {\n+        StubRoutines::_vector_exp_float64     = (address)os::dll_lookup(libsvml, \"__svml_expf4_ha_e9\");\n+        StubRoutines::_vector_exp_float128    = (address)os::dll_lookup(libsvml, \"__svml_expf4_ha_e9\");\n+        StubRoutines::_vector_exp_float256    = (address)os::dll_lookup(libsvml, \"__svml_expf8_ha_e9\");\n+        StubRoutines::_vector_exp_double64    = (address)os::dll_lookup(libsvml, \"__svml_exp1_ha_e9\");\n+        StubRoutines::_vector_exp_double128   = (address)os::dll_lookup(libsvml, \"__svml_exp2_ha_e9\");\n+        StubRoutines::_vector_exp_double256   = (address)os::dll_lookup(libsvml, \"__svml_exp4_ha_e9\");\n+        StubRoutines::_vector_expm1_float64   = (address)os::dll_lookup(libsvml, \"__svml_expm1f4_ha_e9\");\n+        StubRoutines::_vector_expm1_float128  = (address)os::dll_lookup(libsvml, \"__svml_expm1f4_ha_e9\");\n+        StubRoutines::_vector_expm1_float256  = (address)os::dll_lookup(libsvml, \"__svml_expm1f8_ha_e9\");\n+        StubRoutines::_vector_expm1_double64  = (address)os::dll_lookup(libsvml, \"__svml_expm11_ha_e9\");\n+        StubRoutines::_vector_expm1_double128 = (address)os::dll_lookup(libsvml, \"__svml_expm12_ha_e9\");\n+        StubRoutines::_vector_expm1_double256 = (address)os::dll_lookup(libsvml, \"__svml_expm14_ha_e9\");\n+        StubRoutines::_vector_log1p_float64   = (address)os::dll_lookup(libsvml, \"__svml_log1pf4_ha_e9\");\n+        StubRoutines::_vector_log1p_float128  = (address)os::dll_lookup(libsvml, \"__svml_log1pf4_ha_e9\");\n+        StubRoutines::_vector_log1p_float256  = (address)os::dll_lookup(libsvml, \"__svml_log1pf8_ha_e9\");\n+        StubRoutines::_vector_log1p_double64  = (address)os::dll_lookup(libsvml, \"__svml_log1p1_ha_e9\");\n+        StubRoutines::_vector_log1p_double128 = (address)os::dll_lookup(libsvml, \"__svml_log1p2_ha_e9\");\n+        StubRoutines::_vector_log1p_double256 = (address)os::dll_lookup(libsvml, \"__svml_log1p4_ha_e9\");\n+        StubRoutines::_vector_log_float64     = (address)os::dll_lookup(libsvml, \"__svml_logf4_ha_e9\");\n+        StubRoutines::_vector_log_float128    = (address)os::dll_lookup(libsvml, \"__svml_logf4_ha_e9\");\n+        StubRoutines::_vector_log_float256    = (address)os::dll_lookup(libsvml, \"__svml_logf8_ha_e9\");\n+        StubRoutines::_vector_log_double64    = (address)os::dll_lookup(libsvml, \"__svml_log1_ha_e9\");\n+        StubRoutines::_vector_log_double128   = (address)os::dll_lookup(libsvml, \"__svml_log2_ha_e9\");\n+        StubRoutines::_vector_log_double256   = (address)os::dll_lookup(libsvml, \"__svml_log4_ha_e9\");\n+        StubRoutines::_vector_log10_float64   = (address)os::dll_lookup(libsvml, \"__svml_log10f4_ha_e9\");\n+        StubRoutines::_vector_log10_float128  = (address)os::dll_lookup(libsvml, \"__svml_log10f4_ha_e9\");\n+        StubRoutines::_vector_log10_float256  = (address)os::dll_lookup(libsvml, \"__svml_log10f8_ha_e9\");\n+        StubRoutines::_vector_log10_double64  = (address)os::dll_lookup(libsvml, \"__svml_log101_ha_e9\");\n+        StubRoutines::_vector_log10_double128 = (address)os::dll_lookup(libsvml, \"__svml_log102_ha_e9\");\n+        StubRoutines::_vector_log10_double256 = (address)os::dll_lookup(libsvml, \"__svml_log104_ha_e9\");\n+        StubRoutines::_vector_sin_float64     = (address)os::dll_lookup(libsvml, \"__svml_sinf4_ha_e9\");\n+        StubRoutines::_vector_sin_float128    = (address)os::dll_lookup(libsvml, \"__svml_sinf4_ha_e9\");\n+        StubRoutines::_vector_sin_float256    = (address)os::dll_lookup(libsvml, \"__svml_sinf8_ha_e9\");\n+        StubRoutines::_vector_sin_double64    = (address)os::dll_lookup(libsvml, \"__svml_sin1_ha_e9\");\n+        StubRoutines::_vector_sin_double128   = (address)os::dll_lookup(libsvml, \"__svml_sin2_ha_e9\");\n+        StubRoutines::_vector_sin_double256   = (address)os::dll_lookup(libsvml, \"__svml_sin4_ha_e9\");\n+        StubRoutines::_vector_cos_float64     = (address)os::dll_lookup(libsvml, \"__svml_cosf4_ha_e9\");\n+        StubRoutines::_vector_cos_float128    = (address)os::dll_lookup(libsvml, \"__svml_cosf4_ha_e9\");\n+        StubRoutines::_vector_cos_float256    = (address)os::dll_lookup(libsvml, \"__svml_cosf8_ha_e9\");\n+        StubRoutines::_vector_cos_double64    = (address)os::dll_lookup(libsvml, \"__svml_cos1_ha_e9\");\n+        StubRoutines::_vector_cos_double128   = (address)os::dll_lookup(libsvml, \"__svml_cos2_ha_e9\");\n+        StubRoutines::_vector_cos_double256   = (address)os::dll_lookup(libsvml, \"__svml_cos4_ha_e9\");\n+        StubRoutines::_vector_tan_float64     = (address)os::dll_lookup(libsvml, \"__svml_tanf4_ha_e9\");\n+        StubRoutines::_vector_tan_float128    = (address)os::dll_lookup(libsvml, \"__svml_tanf4_ha_e9\");\n+        StubRoutines::_vector_tan_float256    = (address)os::dll_lookup(libsvml, \"__svml_tanf8_ha_e9\");\n+        StubRoutines::_vector_tan_double64    = (address)os::dll_lookup(libsvml, \"__svml_tan1_ha_e9\");\n+        StubRoutines::_vector_tan_double128   = (address)os::dll_lookup(libsvml, \"__svml_tan2_ha_e9\");\n+        StubRoutines::_vector_tan_double256   = (address)os::dll_lookup(libsvml, \"__svml_tan4_ha_e9\");\n+        StubRoutines::_vector_sinh_float64    = (address)os::dll_lookup(libsvml, \"__svml_sinhf4_ha_e9\");\n+        StubRoutines::_vector_sinh_float128   = (address)os::dll_lookup(libsvml, \"__svml_sinhf4_ha_e9\");\n+        StubRoutines::_vector_sinh_float256   = (address)os::dll_lookup(libsvml, \"__svml_sinhf8_ha_e9\");\n+        StubRoutines::_vector_sinh_double64   = (address)os::dll_lookup(libsvml, \"__svml_sinh1_ha_e9\");\n+        StubRoutines::_vector_sinh_double128  = (address)os::dll_lookup(libsvml, \"__svml_sinh2_ha_e9\");\n+        StubRoutines::_vector_sinh_double256  = (address)os::dll_lookup(libsvml, \"__svml_sinh4_ha_e9\");\n+        StubRoutines::_vector_cosh_float64    = (address)os::dll_lookup(libsvml, \"__svml_coshf4_ha_e9\");\n+        StubRoutines::_vector_cosh_float128   = (address)os::dll_lookup(libsvml, \"__svml_coshf4_ha_e9\");\n+        StubRoutines::_vector_cosh_float256   = (address)os::dll_lookup(libsvml, \"__svml_coshf8_ha_e9\");\n+        StubRoutines::_vector_cosh_double64   = (address)os::dll_lookup(libsvml, \"__svml_cosh1_ha_e9\");\n+        StubRoutines::_vector_cosh_double128  = (address)os::dll_lookup(libsvml, \"__svml_cosh2_ha_e9\");\n+        StubRoutines::_vector_cosh_double256  = (address)os::dll_lookup(libsvml, \"__svml_cosh4_ha_e9\");\n+        StubRoutines::_vector_tanh_float64    = (address)os::dll_lookup(libsvml, \"__svml_tanhf4_ha_e9\");\n+        StubRoutines::_vector_tanh_float128   = (address)os::dll_lookup(libsvml, \"__svml_tanhf4_ha_e9\");\n+        StubRoutines::_vector_tanh_float256   = (address)os::dll_lookup(libsvml, \"__svml_tanhf8_ha_e9\");\n+        StubRoutines::_vector_tanh_double64   = (address)os::dll_lookup(libsvml, \"__svml_tanh1_ha_e9\");\n+        StubRoutines::_vector_tanh_double128  = (address)os::dll_lookup(libsvml, \"__svml_tanh2_ha_e9\");\n+        StubRoutines::_vector_tanh_double256  = (address)os::dll_lookup(libsvml, \"__svml_tanh4_ha_e9\");\n+        StubRoutines::_vector_acos_float64    = (address)os::dll_lookup(libsvml, \"__svml_acosf4_ha_e9\");\n+        StubRoutines::_vector_acos_float128   = (address)os::dll_lookup(libsvml, \"__svml_acosf4_ha_e9\");\n+        StubRoutines::_vector_acos_float256   = (address)os::dll_lookup(libsvml, \"__svml_acosf8_ha_e9\");\n+        StubRoutines::_vector_acos_double64   = (address)os::dll_lookup(libsvml, \"__svml_acos1_ha_e9\");\n+        StubRoutines::_vector_acos_double128  = (address)os::dll_lookup(libsvml, \"__svml_acos2_ha_e9\");\n+        StubRoutines::_vector_acos_double256  = (address)os::dll_lookup(libsvml, \"__svml_acos4_ha_e9\");\n+        StubRoutines::_vector_asin_float64    = (address)os::dll_lookup(libsvml, \"__svml_asinf4_ha_e9\");\n+        StubRoutines::_vector_asin_float128   = (address)os::dll_lookup(libsvml, \"__svml_asinf4_ha_e9\");\n+        StubRoutines::_vector_asin_float256   = (address)os::dll_lookup(libsvml, \"__svml_asinf8_ha_e9\");\n+        StubRoutines::_vector_asin_double64   = (address)os::dll_lookup(libsvml, \"__svml_asin1_ha_e9\");\n+        StubRoutines::_vector_asin_double128  = (address)os::dll_lookup(libsvml, \"__svml_asin2_ha_e9\");\n+        StubRoutines::_vector_asin_double256  = (address)os::dll_lookup(libsvml, \"__svml_asin4_ha_e9\");\n+        StubRoutines::_vector_atan_float64    = (address)os::dll_lookup(libsvml, \"__svml_atanf4_ha_e9\");\n+        StubRoutines::_vector_atan_float128   = (address)os::dll_lookup(libsvml, \"__svml_atanf4_ha_e9\");\n+        StubRoutines::_vector_atan_float256   = (address)os::dll_lookup(libsvml, \"__svml_atanf8_ha_e9\");\n+        StubRoutines::_vector_atan_double64   = (address)os::dll_lookup(libsvml, \"__svml_atan1_ha_e9\");\n+        StubRoutines::_vector_atan_double128  = (address)os::dll_lookup(libsvml, \"__svml_atan2_ha_e9\");\n+        StubRoutines::_vector_atan_double256  = (address)os::dll_lookup(libsvml, \"__svml_atan4_ha_e9\");\n+        StubRoutines::_vector_hypot_float64   = (address)os::dll_lookup(libsvml, \"__svml_hypotf4_ha_e9\");\n+        StubRoutines::_vector_hypot_float128  = (address)os::dll_lookup(libsvml, \"__svml_hypotf4_ha_e9\");\n+        StubRoutines::_vector_hypot_float256  = (address)os::dll_lookup(libsvml, \"__svml_hypotf8_ha_e9\");\n+        StubRoutines::_vector_hypot_double64  = (address)os::dll_lookup(libsvml, \"__svml_hypot1_ha_e9\");\n+        StubRoutines::_vector_hypot_double128 = (address)os::dll_lookup(libsvml, \"__svml_hypot2_ha_e9\");\n+        StubRoutines::_vector_hypot_double256 = (address)os::dll_lookup(libsvml, \"__svml_hypot4_ha_e9\");\n+        StubRoutines::_vector_cbrt_float64    = (address)os::dll_lookup(libsvml, \"__svml_cbrtf4_ha_e9\");\n+        StubRoutines::_vector_cbrt_float128   = (address)os::dll_lookup(libsvml, \"__svml_cbrtf4_ha_e9\");\n+        StubRoutines::_vector_cbrt_float256   = (address)os::dll_lookup(libsvml, \"__svml_cbrtf8_ha_e9\");\n+        StubRoutines::_vector_cbrt_double64   = (address)os::dll_lookup(libsvml, \"__svml_cbrt1_ha_e9\");\n+        StubRoutines::_vector_cbrt_double128  = (address)os::dll_lookup(libsvml, \"__svml_cbrt2_ha_e9\");\n+        StubRoutines::_vector_cbrt_double256  = (address)os::dll_lookup(libsvml, \"__svml_cbrt4_ha_e9\");\n+        StubRoutines::_vector_atan2_float64   = (address)os::dll_lookup(libsvml, \"__svml_atan2f4_ha_e9\");\n+        StubRoutines::_vector_atan2_float128  = (address)os::dll_lookup(libsvml, \"__svml_atan2f4_ha_e9\");\n+        StubRoutines::_vector_atan2_float256  = (address)os::dll_lookup(libsvml, \"__svml_atan2f8_ha_e9\");\n+        StubRoutines::_vector_atan2_double64  = (address)os::dll_lookup(libsvml, \"__svml_atan21_ha_e9\");\n+        StubRoutines::_vector_atan2_double128 = (address)os::dll_lookup(libsvml, \"__svml_atan22_ha_e9\");\n+        StubRoutines::_vector_atan2_double256 = (address)os::dll_lookup(libsvml, \"__svml_atan24_ha_e9\");\n+      } else {\n+        assert(UseAVX == 0 && UseSSE >= 2, \"\");\n+        StubRoutines::_vector_exp_float64     = (address)os::dll_lookup(libsvml, \"__svml_expf4_ha_ex\");\n+        StubRoutines::_vector_exp_float128    = (address)os::dll_lookup(libsvml, \"__svml_expf4_ha_ex\");\n+        StubRoutines::_vector_exp_double64    = (address)os::dll_lookup(libsvml, \"__svml_exp1_ha_ex\");\n+        StubRoutines::_vector_exp_double128   = (address)os::dll_lookup(libsvml, \"__svml_exp2_ha_ex\");\n+        StubRoutines::_vector_expm1_float64   = (address)os::dll_lookup(libsvml, \"__svml_expm1f4_ha_ex\");\n+        StubRoutines::_vector_expm1_float128  = (address)os::dll_lookup(libsvml, \"__svml_expm1f4_ha_ex\");\n+        StubRoutines::_vector_expm1_double64  = (address)os::dll_lookup(libsvml, \"__svml_expm11_ha_ex\");\n+        StubRoutines::_vector_expm1_double128 = (address)os::dll_lookup(libsvml, \"__svml_expm12_ha_ex\");\n+        StubRoutines::_vector_acos_float64    = (address)os::dll_lookup(libsvml, \"__svml_acosf4_ha_ex\");\n+        StubRoutines::_vector_acos_float128   = (address)os::dll_lookup(libsvml, \"__svml_acosf4_ha_ex\");\n+        StubRoutines::_vector_acos_double64   = (address)os::dll_lookup(libsvml, \"__svml_acos1_ha_ex\");\n+        StubRoutines::_vector_acos_double128  = (address)os::dll_lookup(libsvml, \"__svml_acos2_ha_ex\");\n+        StubRoutines::_vector_asin_float64    = (address)os::dll_lookup(libsvml, \"__svml_asinf4_ha_ex\");\n+        StubRoutines::_vector_asin_float128   = (address)os::dll_lookup(libsvml, \"__svml_asinf4_ha_ex\");\n+        StubRoutines::_vector_asin_double64   = (address)os::dll_lookup(libsvml, \"__svml_asin1_ha_ex\");\n+        StubRoutines::_vector_asin_double128  = (address)os::dll_lookup(libsvml, \"__svml_asin2_ha_ex\");\n+        StubRoutines::_vector_atan_float64    = (address)os::dll_lookup(libsvml, \"__svml_atanf4_ha_ex\");\n+        StubRoutines::_vector_atan_float128   = (address)os::dll_lookup(libsvml, \"__svml_atanf4_ha_ex\");\n+        StubRoutines::_vector_atan_double64   = (address)os::dll_lookup(libsvml, \"__svml_atan1_ha_ex\");\n+        StubRoutines::_vector_atan_double128  = (address)os::dll_lookup(libsvml, \"__svml_atan2_ha_ex\");\n+        StubRoutines::_vector_sin_float64     = (address)os::dll_lookup(libsvml, \"__svml_sinf4_ha_ex\");\n+        StubRoutines::_vector_sin_float128    = (address)os::dll_lookup(libsvml, \"__svml_sinf4_ha_ex\");\n+        StubRoutines::_vector_sin_double64    = (address)os::dll_lookup(libsvml, \"__svml_sin1_ha_ex\");\n+        StubRoutines::_vector_sin_double128   = (address)os::dll_lookup(libsvml, \"__svml_sin2_ha_ex\");\n+        StubRoutines::_vector_cos_float64     = (address)os::dll_lookup(libsvml, \"__svml_cosf4_ha_ex\");\n+        StubRoutines::_vector_cos_float128    = (address)os::dll_lookup(libsvml, \"__svml_cosf4_ha_ex\");\n+        StubRoutines::_vector_cos_double64    = (address)os::dll_lookup(libsvml, \"__svml_cos1_ha_ex\");\n+        StubRoutines::_vector_cos_double128   = (address)os::dll_lookup(libsvml, \"__svml_cos2_ha_ex\");\n+        StubRoutines::_vector_tan_float64     = (address)os::dll_lookup(libsvml, \"__svml_tanf4_ha_ex\");\n+        StubRoutines::_vector_tan_float128    = (address)os::dll_lookup(libsvml, \"__svml_tanf4_ha_ex\");\n+        StubRoutines::_vector_tan_double64    = (address)os::dll_lookup(libsvml, \"__svml_tan1_ha_ex\");\n+        StubRoutines::_vector_tan_double128   = (address)os::dll_lookup(libsvml, \"__svml_tan2_ha_ex\");\n+        StubRoutines::_vector_sinh_float64    = (address)os::dll_lookup(libsvml, \"__svml_sinhf4_ha_ex\");\n+        StubRoutines::_vector_sinh_float128   = (address)os::dll_lookup(libsvml, \"__svml_sinhf4_ha_ex\");\n+        StubRoutines::_vector_sinh_double64   = (address)os::dll_lookup(libsvml, \"__svml_sinh1_ha_ex\");\n+        StubRoutines::_vector_sinh_double128  = (address)os::dll_lookup(libsvml, \"__svml_sinh2_ha_ex\");\n+        StubRoutines::_vector_cosh_float64    = (address)os::dll_lookup(libsvml, \"__svml_coshf4_ha_ex\");\n+        StubRoutines::_vector_cosh_float128   = (address)os::dll_lookup(libsvml, \"__svml_coshf4_ha_ex\");\n+        StubRoutines::_vector_cosh_double64   = (address)os::dll_lookup(libsvml, \"__svml_cosh1_ha_ex\");\n+        StubRoutines::_vector_cosh_double128  = (address)os::dll_lookup(libsvml, \"__svml_cosh2_ha_ex\");\n+        StubRoutines::_vector_tanh_float64    = (address)os::dll_lookup(libsvml, \"__svml_tanhf4_ha_ex\");\n+        StubRoutines::_vector_tanh_float128   = (address)os::dll_lookup(libsvml, \"__svml_tanhf4_ha_ex\");\n+        StubRoutines::_vector_tanh_double64   = (address)os::dll_lookup(libsvml, \"__svml_tanh1_ha_ex\");\n+        StubRoutines::_vector_tanh_double128  = (address)os::dll_lookup(libsvml, \"__svml_tanh2_ha_ex\");\n+        StubRoutines::_vector_log_float64     = (address)os::dll_lookup(libsvml, \"__svml_logf4_ha_ex\");\n+        StubRoutines::_vector_log_float128    = (address)os::dll_lookup(libsvml, \"__svml_logf4_ha_ex\");\n+        StubRoutines::_vector_log_double64    = (address)os::dll_lookup(libsvml, \"__svml_log1_ha_ex\");\n+        StubRoutines::_vector_log_double128   = (address)os::dll_lookup(libsvml, \"__svml_log2_ha_ex\");\n+        StubRoutines::_vector_log10_float64   = (address)os::dll_lookup(libsvml, \"__svml_log10f4_ha_ex\");\n+        StubRoutines::_vector_log10_float128  = (address)os::dll_lookup(libsvml, \"__svml_log10f4_ha_ex\");\n+        StubRoutines::_vector_log10_double64  = (address)os::dll_lookup(libsvml, \"__svml_log101_ha_ex\");\n+        StubRoutines::_vector_log10_double128 = (address)os::dll_lookup(libsvml, \"__svml_log102_ha_ex\");\n+        StubRoutines::_vector_log1p_float64   = (address)os::dll_lookup(libsvml, \"__svml_log1pf4_ha_ex\");\n+        StubRoutines::_vector_log1p_float128  = (address)os::dll_lookup(libsvml, \"__svml_log1pf4_ha_ex\");\n+        StubRoutines::_vector_log1p_double64  = (address)os::dll_lookup(libsvml, \"__svml_log1p1_ha_ex\");\n+        StubRoutines::_vector_log1p_double128 = (address)os::dll_lookup(libsvml, \"__svml_log1p2_ha_ex\");\n+        StubRoutines::_vector_atan2_float64   = (address)os::dll_lookup(libsvml, \"__svml_atan2f4_ha_ex\");\n+        StubRoutines::_vector_atan2_float128  = (address)os::dll_lookup(libsvml, \"__svml_atan2f4_ha_ex\");\n+        StubRoutines::_vector_atan2_double64  = (address)os::dll_lookup(libsvml, \"__svml_atan21_ha_ex\");\n+        StubRoutines::_vector_atan2_double128 = (address)os::dll_lookup(libsvml, \"__svml_atan22_ha_ex\");\n+        StubRoutines::_vector_hypot_float64   = (address)os::dll_lookup(libsvml, \"__svml_hypotf4_ha_ex\");\n+        StubRoutines::_vector_hypot_float128  = (address)os::dll_lookup(libsvml, \"__svml_hypotf4_ha_ex\");\n+        StubRoutines::_vector_hypot_double64  = (address)os::dll_lookup(libsvml, \"__svml_hypot1_ha_ex\");\n+        StubRoutines::_vector_hypot_double128 = (address)os::dll_lookup(libsvml, \"__svml_hypot2_ha_ex\");\n+        StubRoutines::_vector_cbrt_float64    = (address)os::dll_lookup(libsvml, \"__svml_cbrtf4_ha_ex\");\n+        StubRoutines::_vector_cbrt_float128   = (address)os::dll_lookup(libsvml, \"__svml_cbrtf4_ha_ex\");\n+        StubRoutines::_vector_cbrt_double64   = (address)os::dll_lookup(libsvml, \"__svml_cbrt1_ha_ex\");\n+        StubRoutines::_vector_cbrt_double128  = (address)os::dll_lookup(libsvml, \"__svml_cbrt2_ha_ex\");\n+      }\n+    }\n+#endif \/\/ __VECTOR_API_MATH_INTRINSICS_COMMON\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":322,"deletions":0,"binary":false,"changes":322,"status":"modified"},{"patch":"@@ -1277,0 +1277,4 @@\n+static inline bool is_unsigned_booltest_pred(int bt) {\n+  return  ((bt & BoolTest::unsigned_compare) == BoolTest::unsigned_compare);\n+}\n+\n@@ -1689,0 +1693,5 @@\n+    case Op_CallLeafVector:\n+      if (size_in_bits == 512 && !VM_Version::supports_avx512vlbwdq()) {\n+        return false;\n+      }\n+      break;\n@@ -1876,0 +1885,16 @@\n+bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+  if ((UseAVX > 2) && (VM_Version::supports_avx512vl() || vlen == 64))\n+    return true;\n+  else {\n+    \/\/ instruction set supports only signed comparison\n+    \/\/ so need to zero extend to higher integral type and perform comparison\n+    \/\/ cannot cast long to higher integral type\n+    \/\/ and on avx1 cannot cast 128 bit integral vectors to higher size\n+\n+    if ((bt != T_LONG)  &&\n+        ((UseAVX >= 2) || (vlen <= 8)))\n+      return true;\n+  }\n+  return false;\n+}\n+\n@@ -1956,0 +1981,4 @@\n+  \/\/ Support for calling svml double64 vectors\n+  if (bt == T_DOUBLE) {\n+    size = 1;\n+  }\n@@ -2171,6 +2200,16 @@\n-    case BoolTest::eq: return Assembler::eq;\n-    case BoolTest::ne: return Assembler::neq;\n-    case BoolTest::le: return Assembler::le;\n-    case BoolTest::ge: return Assembler::nlt;\n-    case BoolTest::lt: return Assembler::lt;\n-    case BoolTest::gt: return Assembler::nle;\n+    case BoolTest::eq:\n+      return Assembler::eq;\n+    case BoolTest::ne:\n+      return Assembler::neq;\n+    case BoolTest::le:\n+    case BoolTest::ule:\n+      return Assembler::le;\n+    case BoolTest::ge:\n+    case BoolTest::uge:\n+      return Assembler::nlt;\n+    case BoolTest::lt:\n+    case BoolTest::ult:\n+      return Assembler::lt;\n+    case BoolTest::gt:\n+    case BoolTest::ugt:\n+      return Assembler::nle;\n@@ -6860,1 +6899,3 @@\n-  predicate(vector_length_in_bytes(n->in(1)->in(1)) >=  8 && \/\/ src1\n+  predicate((UseAVX <= 2 || !VM_Version::supports_avx512vl()) && \n+            !is_unsigned_booltest_pred(n->in(2)->get_int()) &&\n+            vector_length_in_bytes(n->in(1)->in(1)) >=  8 && \/\/ src1\n@@ -6875,2 +6916,5 @@\n-instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n-  predicate(vector_length_in_bytes(n->in(1)->in(1)) == 64 && \/\/ src1\n+instruct vcmpu(legVec dst, legVec src1, legVec src2, immI8 cond, legVec vtmp1, legVec vtmp2, rRegP scratch) %{\n+  predicate((UseAVX == 2 || !VM_Version::supports_avx512vl()) && \n+            is_unsigned_booltest_pred(n->in(2)->get_int()) &&\n+            vector_length_in_bytes(n->in(1)->in(1)) >=  8 && \/\/ src1\n+            vector_length_in_bytes(n->in(1)->in(1)) <= 16 && \/\/ src1\n@@ -6879,0 +6923,36 @@\n+  effect(TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n+  format %{ \"vector_compareu $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  ins_encode %{\n+    int vlen = vector_length_in_bytes(this, $src1);\n+    Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    __ vpcmpu(bt, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen, $vtmp1$$XMMRegister,\n+              $vtmp2$$XMMRegister, $scratch$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcmpu32(legVec dst, legVec src1, legVec src2, immI8 cond, legVec vtmp1, legVec vtmp2, legVec vtmp3, rRegP scratch) %{\n+  predicate((UseAVX == 2 || !VM_Version::supports_avx512vl()) && \n+            is_unsigned_booltest_pred(n->in(2)->get_int()) &&\n+            vector_length_in_bytes(n->in(1)->in(1)) == 32 && \/\/ src1\n+            is_integral_type(vector_element_basic_type(n->in(1)->in(1)))); \/\/ src1\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP vtmp3, TEMP scratch);\n+  format %{ \"vector_compareu $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  ins_encode %{\n+    int vlen = vector_length_in_bytes(this, $src1);\n+    Assembler::ComparisonPredicate cmp = booltest_pred_to_comparison_pred($cond$$constant);\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    __ vpcmpu32(bt, $dst$$XMMRegister, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen, $vtmp1$$XMMRegister,\n+                $vtmp2$$XMMRegister, $vtmp3$$XMMRegister, $scratch$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n+  predicate(UseAVX > 2 && \n+            (VM_Version::supports_avx512vl() ||  \n+             vector_length_in_bytes(n->in(1)->in(1)) == 64) && \/\/ src1\n+             is_integral_type(vector_element_basic_type(n->in(1)->in(1)))); \/\/ src1\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n@@ -6884,1 +6964,1 @@\n-    int vlen_enc = Assembler::AVX_512bit;\n+    int vlen_enc = vector_length_encoding(this, $src1);\n@@ -6886,0 +6966,1 @@\n+    bool is_unsigned = is_unsigned_booltest_pred($cond$$constant);\n@@ -6892,1 +6973,1 @@\n-        __ evpcmpb($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evpcmpb($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -6897,1 +6978,1 @@\n-        __ evpcmpw($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evpcmpw($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -6902,1 +6983,1 @@\n-        __ evpcmpd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evpcmpd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -6904,0 +6985,1 @@\n+\n@@ -6907,1 +6989,1 @@\n-        __ evpcmpq($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evpcmpq($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, !is_unsigned, vlen_enc);\n@@ -6911,1 +6993,0 @@\n-\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":96,"deletions":15,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -466,1 +466,3 @@\n-  offset += clear_avx_size();\n+  if (this->ideal_Opcode() != Op_CallLeafVector) {\n+    offset += clear_avx_size();\n+  }\n@@ -1695,0 +1697,17 @@\n+const bool Matcher::supports_vector_calling_convention(void) {\n+  return true;\n+}\n+\n+void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+}\n+\n+OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n+  int lo = XMM0_num;\n+  int hi = XMM0b_num;\n+  if (ideal_reg == Op_VecX) hi = XMM0d_num;\n+  else if (ideal_reg == Op_VecY) hi = XMM0h_num;\n+  else if (ideal_reg == Op_VecZ) hi = XMM0p_num;\n+  return OptoRegPair(hi, lo);\n+}\n+\n@@ -12903,0 +12922,12 @@\n+\/\/ Call runtime without safepoint and with vector arguments\n+instruct CallLeafDirectVector(method meth)\n+%{\n+  match(CallLeafVector);\n+  effect(USE meth);\n+\n+  ins_cost(300);\n+  format %{ \"call_leaf,vector \" %}\n+  ins_encode(Java_To_Runtime(meth));\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":32,"deletions":1,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -422,0 +422,2 @@\n+  if(_matrule->find_type(\"CallLeafVector\",idx))   return Form::JAVA_LEAF;\n+  idx = 0;\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -467,0 +467,3 @@\n+    if (EnableVectorSupport && FLAG_IS_DEFAULT(UseVectorStubs)) {\n+      FLAG_SET_DEFAULT(UseVectorStubs, true);\n+    }\n@@ -470,0 +473,1 @@\n+    log_info(compilation)(\"UseVectorStubs=%s\",                 (UseVectorStubs                 ? \"true\" : \"false\"));\n","filename":"src\/hotspot\/share\/classfile\/modules.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+class         CallLeafVectorNode;\n@@ -782,0 +783,1 @@\n+protected:\n@@ -869,0 +871,18 @@\n+\/\/------------------------------CallLeafVectorNode-------------------------------\n+\/\/ CallLeafNode but calling with vector calling convention instead.\n+class CallLeafVectorNode : public CallLeafNode {\n+private:\n+  uint _num_bits;\n+protected:\n+  virtual bool cmp( const Node &n ) const;\n+  virtual uint size_of() const; \/\/ Size is bigger\n+public:\n+  CallLeafVectorNode(const TypeFunc* tf, address addr, const char* name,\n+                   const TypePtr* adr_type, uint num_bits)\n+    : CallLeafNode(tf, addr, name, adr_type), _num_bits(num_bits)\n+  {\n+  }\n+  virtual int   Opcode() const;\n+  virtual void  calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -61,0 +61,1 @@\n+macro(CallLeafVector)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2189,1 +2189,2 @@\n-    for_igvn()->clear();\n+    Unique_Node_List* old_worklist = for_igvn();\n+    old_worklist->clear();\n@@ -2199,1 +2200,1 @@\n-    set_for_igvn(save_for_igvn);\n+    set_for_igvn(old_worklist); \/\/ new_worklist is dead beyond this point\n@@ -3032,0 +3033,1 @@\n+  case Op_CallLeafVector:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -858,0 +858,1 @@\n+    case Op_CallLeafVector:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -328,0 +328,1 @@\n+  Node* gen_call_to_svml(int vector_api_op_id, BasicType bt, int num_elem, Node* opd1, Node* opd2);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1376,2 +1376,4 @@\n-      if( !parm_regs[i].first()->is_valid() &&\n-          !parm_regs[i].second()->is_valid() ) {\n+      VMReg first = parm_regs[i].first();\n+      VMReg second = parm_regs[i].second();\n+      if( !first->is_valid() &&\n+          !second->is_valid() ) {\n@@ -1380,0 +1382,9 @@\n+      \/\/ Handle case where arguments are in vector registers.\n+      if(call->in(TypeFunc::Parms + i)->bottom_type()->isa_vect()) {\n+        OptoReg::Name reg_fst = OptoReg::as_OptoReg(first);\n+        OptoReg::Name reg_snd = OptoReg::as_OptoReg(second);\n+        assert (reg_fst <= reg_snd, \"fst=%d snd=%d\", reg_fst, reg_snd);\n+        for (OptoReg::Name r = reg_fst; r <= reg_snd; r++) {\n+          rm->Insert(r);\n+        }\n+      }\n@@ -1381,1 +1392,1 @@\n-      OptoReg::Name reg1 = warp_outgoing_stk_arg(parm_regs[i].first(), begin_out_arg_area, out_arg_limit_per_call );\n+      OptoReg::Name reg1 = warp_outgoing_stk_arg(first, begin_out_arg_area, out_arg_limit_per_call );\n@@ -1385,1 +1396,1 @@\n-      OptoReg::Name reg2 = warp_outgoing_stk_arg(parm_regs[i].second(), begin_out_arg_area, out_arg_limit_per_call );\n+      OptoReg::Name reg2 = warp_outgoing_stk_arg(second, begin_out_arg_area, out_arg_limit_per_call );\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -359,0 +359,3 @@\n+  \/\/ Does the CPU supports vector unsigned comparison instructions for given vector length and type?\n+  static bool supports_unsigned_vector_comparison(int vlen, BasicType bt);\n+\n@@ -434,0 +437,7 @@\n+  \/\/ Java-Native vector calling convention\n+  static const bool supports_vector_calling_convention();\n+  static void vector_calling_convention(VMRegPair *regs,\n+                                        uint num_bits,\n+                                        uint total_args_passed);\n+  static OptoRegPair vector_return_value(uint ideal_reg);\n+\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -664,0 +664,19 @@\n+  return TypeFunc::make(domain, range);\n+}\n+\n+const TypeFunc *OptoRuntime::Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type) {\n+  \/\/ create input type (domain)\n+  const Type **fields = TypeTuple::fields(num_arg);\n+  \/\/ Symbol* name of class to be loaded\n+  assert(num_arg > 0, \"must have at least 1 input\");\n+  for (uint i = 0; i < num_arg; i++) {\n+    fields[TypeFunc::Parms+i] = in_type;\n+  }\n+  const TypeTuple *domain = TypeTuple::make(TypeFunc::Parms+num_arg, fields);\n+\n+  \/\/ create result type (range)\n+  const uint num_ret = 1;\n+  fields = TypeTuple::fields(num_ret);\n+  fields[TypeFunc::Parms+0] = out_type;\n+  const TypeTuple *range = TypeTuple::make(TypeFunc::Parms+num_ret, fields);\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -259,0 +259,1 @@\n+  static const TypeFunc* Math_Vector_Vector_Type(uint num_arg, const TypeVect* in_type, const TypeVect* out_type);\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1137,0 +1137,1 @@\n+    assert((BoolTest::mask)predicate_node->get_int() == predicate, \"Unmatched predicates\");\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -4094,0 +4094,5 @@\n+\n+    if (!FLAG_IS_DEFAULT(UseVectorStubs) && UseVectorStubs) {\n+      warning(\"Disabling UseVectorStubs since EnableVectorSupport is turned off.\");\n+    }\n+    FLAG_SET_DEFAULT(UseVectorStubs, false);\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -382,0 +382,4 @@\n+  static int vector_calling_convention(VMRegPair *regs,\n+                                       uint num_bits,\n+                                       uint total_args_passed);\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1529,0 +1529,1 @@\n+  declare_c2_type(CallLeafVectorNode, CallLeafNode)                       \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1514,33 +1514,93 @@\n-                        [\"cpy\",    \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n-                        [\"inc\",    \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n-                        [\"dec\",    \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n-                        [\"lsl\",    \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n-                        [\"lsr\",    \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n-                        [\"lsr\",    \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n-                        [\"addvl\",  \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n-                        [\"addpl\",  \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n-                        [\"cntp\",   \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n-                        [\"dup\",    \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n-                        [\"dup\",    \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n-                        [\"dup\",    \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n-                        [\"dup\",    \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n-                        [\"ld1h\",   \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n-                        [\"ld1d\",   \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n-                        [\"st1w\",   \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n-                        [\"st1h\",   \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n-                        [\"st1d\",   \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n-                        [\"str\",    \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n+                        [\"cpy\",     \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n+                        [\"cpy\",     \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n+                        [\"cpy\",     \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n+                        [\"cpy\",     \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n+                        [\"inc\",     \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n+                        [\"dec\",     \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n+                        [\"lsl\",     \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n+                        [\"lsr\",     \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n+                        [\"addvl\",   \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n+                        [\"addpl\",   \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n+                        [\"cntp\",    \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n+                        [\"dup\",     \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n+                        [\"dup\",     \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n+                        [\"dup\",     \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n+                        [\"dup\",     \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n+                        [\"dup\",     \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n+                        [\"dup\",     \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n+                        [\"ld1h\",    \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n+                        [\"st1w\",    \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n+                        [\"st1h\",    \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n+                        [\"st1d\",    \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n+                        [\"str\",     \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"sel\",     \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n+                        [\"sel\",     \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p0, z0, z1);\",                \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, z3);\",                \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p2, z4, z5);\",                \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ D, p3, z6, z7);\",                \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmple\",   \"__ sve_cmpge(p2, __ B, p0, z10, z11);\",              \"cmple\\tp2.b, p0\/z, z11.b, z10.b\"],\n+                        [\"cmplt\",   \"__ sve_cmpgt(p3, __ S, p0, z16, z17);\",              \"cmplt\\tp3.s, p0\/z, z17.s, z16.s\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p4, z0, 15);\",                \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, -16);\",               \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n+                        [\"cmple\",   \"__ sve_cmple(p1, __ S, p1, z4, 0);\",                 \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n+                        [\"cmplt\",   \"__ sve_cmplt(p1, __ D, p2, z6, -1);\",                \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p3, z4, 5);\",                 \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ B, p4, z6, -2);\",                \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n+                        [\"fcmeq\",   \"__ sve_fcmeq(p1, __ S, p0, z0, z1);\",                \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n+                        [\"fcmne\",   \"__ sve_fcmne(p1, __ D, p0, z2, z3);\",                \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n+                        [\"fcmgt\",   \"__ sve_fcmgt(p1, __ S, p2, z4, z5);\",                \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"fcmge\",   \"__ sve_fcmge(p1, __ D, p3, z6, z7);\",                \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"fcmlt\",   \"__ sve_fcmgt(p2, __ S, p0, z10, z11);\",              \"fcmlt\\tp2.s, p0\/z, z11.s, z10.s\"],\n+                        [\"fcmle\",   \"__ sve_fcmge(p3, __ D, p0, z16, z17);\",              \"fcmle\\tp3.d, p0\/z, z17.d, z16.d\"],\n+                        [\"uunpkhi\", \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n+                        [\"uunpklo\", \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n+                        [\"sunpkhi\", \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n+                        [\"sunpklo\", \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n+                        [\"whilelt\", \"__ sve_whilelt(p0, __ B, r1, r2);\",                  \"whilelt\\tp0.b, x1, x2\"],\n+                        [\"whilelt\", \"__ sve_whileltw(p1, __ H, r3, r4);\",                 \"whilelt\\tp1.h, w3, w4\"],\n+                        [\"whilele\", \"__ sve_whilele(p2, __ S, r5, r6);\",                  \"whilele\\tp2.s, x5, x6\"],\n+                        [\"whilele\", \"__ sve_whilelew(p3, __ D, r10, r11);\",               \"whilele\\tp3.d, w10, w11\"],\n+                        [\"whilelo\", \"__ sve_whilelo(p4, __ B, r1, r2);\",                  \"whilelo\\tp4.b, x1, x2\"],\n+                        [\"whilelo\", \"__ sve_whilelow(p0, __ H, r3, r4);\",                 \"whilelo\\tp0.h, w3, w4\"],\n+                        [\"whilels\", \"__ sve_whilels(p1, __ S, r5, r6);\",                  \"whilels\\tp1.s, x5, x6\"],\n+                        [\"whilels\", \"__ sve_whilelsw(p2, __ D, r10, r11);\",               \"whilels\\tp2.d, w10, w11\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z1, __ D, p0, z0, __ S);\",              \"scvtf\\tz1.d, p0\/m, z0.s\"],\n+                        [\"ucvtf\",   \"__ sve_ucvtf(z3, __ D, p1, z2, __ S);\",              \"ucvtf\\tz3.d, p1\/m, z2.s\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z5, __ D, p3, z4, __ S);\",               \"fcvt\\tz5.d, p3\/m, z4.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z18, __ D);\",           \"fcvtzs\\tz19.d, p2\/m, z18.d\"],\n+                        [\"fcvtzu\",  \"__ sve_fcvtzu(z19, __ D, p2, z18, __ D);\",           \"fcvtzu\\tz19.d, p2\/m, z18.d\"],\n+                        [\"lasta\",   \"__ sve_lasta(r0, __ B, p0, z15);\",                   \"lasta\\tw0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(r1, __ B, p1, z16);\",                   \"lastb\\tw1, p1, z16.b\"],\n+                        [\"lasta\",   \"__ sve_lasta(v0, __ B, p0, z15);\",                   \"lasta\\tb0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(v1, __ B, p1, z16);\",                   \"lastb\\tb1, p1, z16.b\"],\n+                        [\"index\",   \"__ sve_index(z6, __ S, 1, 1);\",                      \"index\\tz6.s, #1, #1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z7, __ H, p3, r5);\",                      \"cpy\\tz7.h, p3\/m, w5\"],\n+                        [\"tbl\",     \"__ sve_tbl(z16, __ S, z17, z18);\",                   \"tbl\\tz16.s, {z17.s}, z18.s\"],\n+                        [\"ld1w\",    \"__ sve_ld1w_gather(z15, p0, r5, z16);\",              \"ld1w\\t{z15.s}, p0\/z, [x5, z16.s, uxtw #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d_gather(z15, p0, r5, z16);\",              \"ld1d\\t{z15.d}, p0\/z, [x5, z16.d, uxtw #3]\"],\n@@ -1615,0 +1675,2 @@\n+                       [\"uzp1\", \"ZZZ\"],\n+                       [\"uzp2\", \"ZZZ\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":95,"deletions":33,"binary":false,"changes":128,"status":"modified"},{"patch":"@@ -702,0 +702,6 @@\n+    __ sve_cpy(z0, __ B, p0, 127, true);               \/\/       mov     z0.b, p0\/m, 127\n+    __ sve_cpy(z1, __ H, p0, -128, true);              \/\/       mov     z1.h, p0\/m, -128\n+    __ sve_cpy(z2, __ S, p0, 32512, true);             \/\/       mov     z2.s, p0\/m, 32512\n+    __ sve_cpy(z5, __ D, p0, -32768, false);           \/\/       mov     z5.d, p0\/z, -32768\n+    __ sve_cpy(z10, __ B, p0, -1, false);              \/\/       mov     z10.b, p0\/z, -1\n+    __ sve_cpy(z11, __ S, p0, -1, false);              \/\/       mov     z11.s, p0\/z, -1\n@@ -719,0 +725,2 @@\n+    __ sve_dup(z10, __ B, -1);                         \/\/       dup     z10.b, -1\n+    __ sve_dup(z11, __ S, -1);                         \/\/       dup     z11.s, -1\n@@ -720,0 +728,3 @@\n+    __ sve_ld1b(z0, __ H, p1, Address(sp));            \/\/       ld1b    {z0.h}, p1\/z, [sp]\n+    __ sve_ld1b(z0, __ S, p2, Address(sp, r8));        \/\/       ld1b    {z0.s}, p2\/z, [sp, x8]\n+    __ sve_ld1b(z0, __ D, p3, Address(sp, 7));         \/\/       ld1b    {z0.d}, p3\/z, [sp, #7, MUL VL]\n@@ -727,0 +738,3 @@\n+    __ sve_st1b(z0, __ H, p1, Address(sp));            \/\/       st1b    {z0.h}, p1, [sp]\n+    __ sve_st1b(z0, __ S, p2, Address(sp, r8));        \/\/       st1b    {z0.s}, p2, [sp, x8]\n+    __ sve_st1b(z0, __ D, p3, Address(sp));            \/\/       st1b    {z0.d}, p3, [sp]\n@@ -734,0 +748,46 @@\n+    __ sve_sel(z0, __ B, p0, z1, z2);                  \/\/       sel     z0.b, p0, z1.b, z2.b\n+    __ sve_sel(z4, __ D, p0, z5, z6);                  \/\/       sel     z4.d, p0, z5.d, z6.d\n+    __ sve_cmpeq(p1, __ B, p0, z0, z1);                \/\/       cmpeq   p1.b, p0\/z, z0.b, z1.b\n+    __ sve_cmpne(p1, __ H, p0, z2, z3);                \/\/       cmpne   p1.h, p0\/z, z2.h, z3.h\n+    __ sve_cmpge(p1, __ S, p2, z4, z5);                \/\/       cmpge   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_cmpgt(p1, __ D, p3, z6, z7);                \/\/       cmpgt   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_cmpge(p2, __ B, p0, z10, z11);              \/\/       cmple   p2.b, p0\/z, z11.b, z10.b\n+    __ sve_cmpgt(p3, __ S, p0, z16, z17);              \/\/       cmplt   p3.s, p0\/z, z17.s, z16.s\n+    __ sve_cmpeq(p1, __ B, p4, z0, 15);                \/\/       cmpeq   p1.b, p4\/z, z0.b, #15\n+    __ sve_cmpne(p1, __ H, p0, z2, -16);               \/\/       cmpne   p1.h, p0\/z, z2.h, #-16\n+    __ sve_cmple(p1, __ S, p1, z4, 0);                 \/\/       cmple   p1.s, p1\/z, z4.s, #0\n+    __ sve_cmplt(p1, __ D, p2, z6, -1);                \/\/       cmplt   p1.d, p2\/z, z6.d, #-1\n+    __ sve_cmpge(p1, __ S, p3, z4, 5);                 \/\/       cmpge   p1.s, p3\/z, z4.s, #5\n+    __ sve_cmpgt(p1, __ B, p4, z6, -2);                \/\/       cmpgt   p1.b, p4\/z, z6.b, #-2\n+    __ sve_fcmeq(p1, __ S, p0, z0, z1);                \/\/       fcmeq   p1.s, p0\/z, z0.s, z1.s\n+    __ sve_fcmne(p1, __ D, p0, z2, z3);                \/\/       fcmne   p1.d, p0\/z, z2.d, z3.d\n+    __ sve_fcmgt(p1, __ S, p2, z4, z5);                \/\/       fcmgt   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_fcmge(p1, __ D, p3, z6, z7);                \/\/       fcmge   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_fcmgt(p2, __ S, p0, z10, z11);              \/\/       fcmlt   p2.s, p0\/z, z11.s, z10.s\n+    __ sve_fcmge(p3, __ D, p0, z16, z17);              \/\/       fcmle   p3.d, p0\/z, z17.d, z16.d\n+    __ sve_uunpkhi(z0, __ H, z1);                      \/\/       uunpkhi z0.h, z1.b\n+    __ sve_uunpklo(z4, __ S, z5);                      \/\/       uunpklo z4.s, z5.h\n+    __ sve_sunpkhi(z6, __ D, z7);                      \/\/       sunpkhi z6.d, z7.s\n+    __ sve_sunpklo(z10, __ H, z11);                    \/\/       sunpklo z10.h, z11.b\n+    __ sve_whilelt(p0, __ B, r1, r2);                  \/\/       whilelt p0.b, x1, x2\n+    __ sve_whileltw(p1, __ H, r3, r4);                 \/\/       whilelt p1.h, w3, w4\n+    __ sve_whilele(p2, __ S, r5, r6);                  \/\/       whilele p2.s, x5, x6\n+    __ sve_whilelew(p3, __ D, r10, r11);               \/\/       whilele p3.d, w10, w11\n+    __ sve_whilelo(p4, __ B, r1, r2);                  \/\/       whilelo p4.b, x1, x2\n+    __ sve_whilelow(p0, __ H, r3, r4);                 \/\/       whilelo p0.h, w3, w4\n+    __ sve_whilels(p1, __ S, r5, r6);                  \/\/       whilels p1.s, x5, x6\n+    __ sve_whilelsw(p2, __ D, r10, r11);               \/\/       whilels p2.d, w10, w11\n+    __ sve_scvtf(z1, __ D, p0, z0, __ S);              \/\/       scvtf   z1.d, p0\/m, z0.s\n+    __ sve_ucvtf(z3, __ D, p1, z2, __ S);              \/\/       ucvtf   z3.d, p1\/m, z2.s\n+    __ sve_fcvt(z5, __ D, p3, z4, __ S);               \/\/       fcvt    z5.d, p3\/m, z4.s\n+    __ sve_fcvtzs(z19, __ D, p2, z18, __ D);           \/\/       fcvtzs  z19.d, p2\/m, z18.d\n+    __ sve_fcvtzu(z19, __ D, p2, z18, __ D);           \/\/       fcvtzu  z19.d, p2\/m, z18.d\n+    __ sve_lasta(r0, __ B, p0, z15);                   \/\/       lasta   w0, p0, z15.b\n+    __ sve_lastb(r1, __ B, p1, z16);                   \/\/       lastb   w1, p1, z16.b\n+    __ sve_lasta(v0, __ B, p0, z15);                   \/\/       lasta   b0, p0, z15.b\n+    __ sve_lastb(v1, __ B, p1, z16);                   \/\/       lastb   b1, p1, z16.b\n+    __ sve_index(z6, __ S, 1, 1);                      \/\/       index   z6.s, #1, #1\n+    __ sve_cpy(z7, __ H, p3, r5);                      \/\/       cpy     z7.h, p3\/m, w5\n+    __ sve_tbl(z16, __ S, z17, z18);                   \/\/       tbl     z16.s, {z17.s}, z18.s\n+    __ sve_ld1w_gather(z15, p0, r5, z16);              \/\/       ld1w    {z15.s}, p0\/z, [x5, z16.s, uxtw #2]\n+    __ sve_ld1d_gather(z15, p0, r5, z16);              \/\/       ld1d    {z15.d}, p0\/z, [x5, z16.d, uxtw #3]\n@@ -908,0 +968,15 @@\n+<<<<<<< HEAD\n+    __ sve_uzp1(z8, __ D, z20, z16);                   \/\/       uzp1    z8.d, z20.d, z16.d\n+    __ sve_uzp2(z15, __ S, z4, z4);                    \/\/       uzp2    z15.s, z4.s, z4.s\n+\n+\/\/ SVEReductionOp\n+    __ sve_andv(v8, __ B, p1, z29);                    \/\/       andv b8, p1, z29.b\n+    __ sve_orv(v28, __ D, p4, z29);                    \/\/       orv d28, p4, z29.d\n+    __ sve_eorv(v9, __ H, p3, z2);                     \/\/       eorv h9, p3, z2.h\n+    __ sve_smaxv(v28, __ B, p0, z7);                   \/\/       smaxv b28, p0, z7.b\n+    __ sve_sminv(v26, __ H, p5, z17);                  \/\/       sminv h26, p5, z17.h\n+    __ sve_fminv(v8, __ D, p4, z21);                   \/\/       fminv d8, p4, z21.d\n+    __ sve_fmaxv(v5, __ D, p5, z21);                   \/\/       fmaxv d5, p5, z21.d\n+    __ sve_fadda(v22, __ D, p4, z29);                  \/\/       fadda d22, p4, d22, z29.d\n+    __ sve_uaddv(v19, __ S, p0, z4);                   \/\/       uaddv d19, p0, z4.s\n+=======\n@@ -920,0 +995,1 @@\n+>>>>>>> master\n@@ -938,0 +1014,9 @@\n+<<<<<<< HEAD\n+    0x14000000,     0x17ffffd7,     0x1400031e,     0x94000000,\n+    0x97ffffd4,     0x9400031b,     0x3400000a,     0x34fffa2a,\n+    0x3400630a,     0x35000008,     0x35fff9c8,     0x350062a8,\n+    0xb400000b,     0xb4fff96b,     0xb400624b,     0xb500001d,\n+    0xb5fff91d,     0xb50061fd,     0x10000013,     0x10fff8b3,\n+    0x10006193,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36306116,     0x3758000c,     0x375ff7cc,     0x375860ac,\n+=======\n@@ -945,0 +1030,1 @@\n+>>>>>>> master\n@@ -949,0 +1035,15 @@\n+<<<<<<< HEAD\n+    0x54005e80,     0x54000001,     0x54fff541,     0x54005e21,\n+    0x54000002,     0x54fff4e2,     0x54005dc2,     0x54000002,\n+    0x54fff482,     0x54005d62,     0x54000003,     0x54fff423,\n+    0x54005d03,     0x54000003,     0x54fff3c3,     0x54005ca3,\n+    0x54000004,     0x54fff364,     0x54005c44,     0x54000005,\n+    0x54fff305,     0x54005be5,     0x54000006,     0x54fff2a6,\n+    0x54005b86,     0x54000007,     0x54fff247,     0x54005b27,\n+    0x54000008,     0x54fff1e8,     0x54005ac8,     0x54000009,\n+    0x54fff189,     0x54005a69,     0x5400000a,     0x54fff12a,\n+    0x54005a0a,     0x5400000b,     0x54fff0cb,     0x540059ab,\n+    0x5400000c,     0x54fff06c,     0x5400594c,     0x5400000d,\n+    0x54fff00d,     0x540058ed,     0x5400000e,     0x54ffefae,\n+    0x5400588e,     0x5400000f,     0x54ffef4f,     0x5400582f,\n+=======\n@@ -962,0 +1063,1 @@\n+>>>>>>> master\n@@ -993,0 +1095,3 @@\n+<<<<<<< HEAD\n+    0xbd1b1869,     0x5800487b,     0x1800000b,     0xf8945060,\n+=======\n@@ -994,0 +1099,1 @@\n+>>>>>>> master\n@@ -1074,9 +1180,24 @@\n-    0x0e073c20,     0x4cc0ac3f,     0x05a08020,     0x04b0e3e0,\n-    0x0470e7e1,     0x042f9c20,     0x043f9c35,     0x047f9c20,\n-    0x04ff9c20,     0x04299420,     0x04319160,     0x0461943e,\n-    0x04a19020,     0x042053ff,     0x047f5401,     0x25208028,\n-    0x2538cfe0,     0x2578d001,     0x25b8efe2,     0x25f8f007,\n-    0xa400a3e0,     0xa4a8a7ea,     0xa547a814,     0xa4084ffe,\n-    0xa55c53e0,     0xa5e1540b,     0xe400fbf6,     0xe408ffff,\n-    0xe547e400,     0xe4014be0,     0xe4a84fe0,     0xe5f15000,\n-    0x858043e0,     0x85a043ff,     0xe59f5d08,     0x1e601000,\n+    0x0e073c20,     0x4cc0ac3f,     0x05a08020,     0x05104fe0,\n+    0x05505001,     0x05906fe2,     0x05d03005,     0x05101fea,\n+    0x05901feb,     0x04b0e3e0,     0x0470e7e1,     0x042f9c20,\n+    0x043f9c35,     0x047f9c20,     0x04ff9c20,     0x04299420,\n+    0x04319160,     0x0461943e,     0x04a19020,     0x042053ff,\n+    0x047f5401,     0x25208028,     0x2538cfe0,     0x2578d001,\n+    0x25b8efe2,     0x25f8f007,     0x2538dfea,     0x25b8dfeb,\n+    0xa400a3e0,     0xa420a7e0,     0xa4484be0,     0xa467afe0,\n+    0xa4a8a7ea,     0xa547a814,     0xa4084ffe,     0xa55c53e0,\n+    0xa5e1540b,     0xe400fbf6,     0xe408ffff,     0xe420e7e0,\n+    0xe4484be0,     0xe460efe0,     0xe547e400,     0xe4014be0,\n+    0xe4a84fe0,     0xe5f15000,     0x858043e0,     0x85a043ff,\n+    0xe59f5d08,     0x0522c020,     0x05e6c0a4,     0x2401a001,\n+    0x2443a051,     0x24858881,     0x24c78cd1,     0x240b8142,\n+    0x24918213,     0x250f9001,     0x25508051,     0x25802491,\n+    0x25df28c1,     0x25850c81,     0x251e10d1,     0x65816001,\n+    0x65c36051,     0x65854891,     0x65c74cc1,     0x658b4152,\n+    0x65d14203,     0x05733820,     0x05b238a4,     0x05f138e6,\n+    0x0570396a,     0x25221420,     0x25640461,     0x25a614b2,\n+    0x25eb0553,     0x25221c24,     0x25640c60,     0x25a61cb1,\n+    0x25eb0d52,     0x65d0a001,     0x65d1a443,     0x65cbac85,\n+    0x65deaa53,     0x65dfaa53,     0x0520a1e0,     0x0521a601,\n+    0x052281e0,     0x05238601,     0x04a14026,     0x0568aca7,\n+    0x05b23230,     0x853040af,     0xc5b040af,     0x1e601000,\n@@ -1120,0 +1241,6 @@\n+<<<<<<< HEAD\n+    0x04613176,     0x05f06a88,     0x05a46c8f,     0x041a27a8,\n+    0x04d833bc,     0x04592c49,     0x040820fc,     0x044a363a,\n+    0x65c732a8,     0x65c636a5,     0x65d833b6,     0x04812093,\n+\n+=======\n@@ -1123,0 +1250,1 @@\n+>>>>>>> master\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":137,"deletions":9,"binary":false,"changes":146,"status":"modified"}]}