{"files":[{"patch":"@@ -855,2 +855,2 @@\n-  do_intrinsic(_VectorStoreMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_store_masked_op_name, vector_store_masked_op_sig, F_S)             \\\n-   do_signature(vector_store_masked_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjdk\/internal\/vm\/vector\/VectorSupport$Vector;\"    \\\n+  do_intrinsic(_VectorStoreMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_store_masked_op_name, vector_store_masked_op_sig, F_S)       \\\n+   do_signature(vector_store_masked_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjdk\/internal\/vm\/vector\/VectorSupport$Vector;\"  \\\n@@ -861,2 +861,3 @@\n-  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S) \\\n-   do_signature(vector_reduction_coerced_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljava\/util\/function\/Function;)J\") \\\n+  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S)\\\n+   do_signature(vector_reduction_coerced_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"     \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$ReductionOperation;)J\")                                  \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1167,5 +1167,5 @@\n-\/\/ <V extends Vector<?,?>>\n-\/\/ long reductionCoerced(int oprId, Class<?> vectorClass, Class<?> elementType, int vlen,\n-\/\/                       V v,\n-\/\/                       Function<V,Long> defaultImpl)\n-\n+\/\/ <V, M>\n+\/\/ long reductionCoerced(int oprId, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+\/\/                       Class<?> elementType, int length, V v, M m,\n+\/\/                       ReductionOperation<V, M> defaultImpl) {\n+\/\/\n@@ -1175,2 +1175,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -1184,2 +1185,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -1202,0 +1203,26 @@\n+\n+  const Type* vmask_type = gvn().type(argument(6));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1204,1 +1231,0 @@\n-\n@@ -1208,2 +1234,2 @@\n-  \/\/ TODO When mask usage is supported, VecMaskNotUsed needs to be VecMaskUseLoad.\n-  if (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed)) {\n+  \/\/ When using mask, mask use type needs to be VecMaskUseLoad.\n+  if (!arch_supports_vector(sopc, num_elem, elem_bt, is_masked_op ? VecMaskUseLoad : VecMaskNotUsed)) {\n@@ -1220,1 +1246,1 @@\n-  Node* opd = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n+  Node* opd = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n@@ -1225,0 +1251,23 @@\n+  Node* mask = NULL;\n+  bool use_predicate = false;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    assert(is_vector_mask(mbox_klass), \"argument(2) should be a mask class\");\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(6), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                      NodeClassNames[argument(6)->Opcode()]);\n+      }\n+      return false;\n+    }\n+\n+    \/\/ Return true if current platform has implemented the masked operation with predicate feature.\n+    use_predicate = Matcher::has_predicated_vectors() &&\n+                    Matcher::match_rule_supported_vector_masked(sopc, num_elem, elem_bt);\n+    if (!use_predicate && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+      return false;\n+    }\n+  }\n+\n@@ -1226,1 +1275,17 @@\n-  Node* rn = gvn().transform(ReductionNode::make(opc, NULL, init, opd, elem_bt));\n+  Node* value = NULL;\n+  if (mask == NULL) {\n+    assert(!is_masked_op, \"Masked op needs the mask value never null\");\n+    value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+  } else {\n+    if (use_predicate) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** predicate feature is not supported on current platform!\");\n+      }\n+      return false;\n+    } else {\n+      Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n+      value = gvn().transform(new VectorBlendNode(reduce_identity, opd, mask));\n+      value = ReductionNode::make(opc, NULL, init, value, elem_bt);\n+    }\n+  }\n+  value = gvn().transform(value);\n@@ -1233,1 +1298,1 @@\n-      bits = gvn().transform(new ConvI2LNode(rn));\n+      bits = gvn().transform(new ConvI2LNode(value));\n@@ -1237,2 +1302,2 @@\n-      rn   = gvn().transform(new MoveF2INode(rn));\n-      bits = gvn().transform(new ConvI2LNode(rn));\n+      value = gvn().transform(new MoveF2INode(value));\n+      bits  = gvn().transform(new ConvI2LNode(value));\n@@ -1242,1 +1307,1 @@\n-      bits = gvn().transform(new MoveD2LNode(rn));\n+      bits = gvn().transform(new MoveD2LNode(value));\n@@ -1246,1 +1311,1 @@\n-      bits = rn; \/\/ no conversion needed\n+      bits = value; \/\/ no conversion needed\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":84,"deletions":19,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -1075,0 +1075,1 @@\n+          return gvn.makecon(TypeInt::make(max_jbyte));\n@@ -1076,0 +1077,1 @@\n+          return gvn.makecon(TypeInt::make(max_jshort));\n@@ -1090,0 +1092,1 @@\n+          return gvn.makecon(TypeInt::make(min_jbyte));\n@@ -1091,0 +1094,1 @@\n+          return gvn.makecon(TypeInt::make(min_jshort));\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -211,4 +211,4 @@\n-    <V extends Vector<?>>\n-    long reductionCoerced(int oprId, Class<?> vectorClass, Class<?> elementType, int length,\n-                          V v,\n-                          Function<V,Long> defaultImpl) {\n+    <V, M>\n+    long reductionCoerced(int oprId, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+                          Class<?> elementType, int length, V v, M m,\n+                          ReductionOperation<V, M> defaultImpl) {\n@@ -216,1 +216,1 @@\n-        return defaultImpl.apply(v);\n+        return defaultImpl.apply(v, m);\n@@ -219,0 +219,5 @@\n+    public interface ReductionOperation<V, M> {\n+        long apply(V v, M mask);\n+    }\n+\n+\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":10,"deletions":5,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte128Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte128Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte128Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte256Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte256Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte256Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte512Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte512Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte512Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Byte64Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Byte64Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte64Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    byte rOp(byte v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, ByteMaxMask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, ByteMaxMask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteMaxVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -290,1 +290,16 @@\n-    byte rOp(byte v, FBinOp f);\n+    byte rOp(byte v, VectorMask<Byte> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    byte rOpTemplate(byte v, VectorMask<Byte> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        byte[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Byte>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2512,0 +2527,1 @@\n+                               Class<? extends VectorMask<Byte>> maskClass,\n@@ -2513,2 +2529,10 @@\n-        ByteVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            ByteVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, byte.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, ByteVector::reductionOperations)));\n@@ -2529,20 +2553,3 @@\n-            opc, getClass(), byte.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((byte)0, (i, a, b) -> (byte)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((byte)1, (i, a, b) -> (byte)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (byte) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (byte) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((byte)-1, (i, a, b) -> (byte)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((byte)0, (i, a, b) -> (byte)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((byte)0, (i, a, b) -> (byte)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, byte.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, ByteVector::reductionOperations)));\n@@ -2550,0 +2557,1 @@\n+\n@@ -2551,2 +2559,22 @@\n-    ImplCache<Associative,Function<ByteVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, ByteVector.class);\n+    ImplCache<Associative, ReductionOperation<ByteVector, VectorMask<Byte>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, ByteVector.class);\n+\n+    private static ReductionOperation<ByteVector, VectorMask<Byte>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((byte)0, m, (i, a, b) -> (byte)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((byte)1, m, (i, a, b) -> (byte)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (byte) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (byte) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((byte)-1, m, (i, a, b) -> (byte)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((byte)0, m, (i, a, b) -> (byte)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((byte)0, m, (i, a, b) -> (byte)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":53,"deletions":25,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double128Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double128Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double128Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double256Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double256Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double256Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double512Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double512Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double512Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Double64Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Double64Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double64Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    double rOp(double v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    double rOp(double v, VectorMask<Double> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, DoubleMaxMask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, DoubleMaxMask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleMaxVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -290,1 +290,16 @@\n-    double rOp(double v, FBinOp f);\n+    double rOp(double v, VectorMask<Double> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    double rOpTemplate(double v, VectorMask<Double> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        double[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Double>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2369,0 +2384,1 @@\n+                               Class<? extends VectorMask<Double>> maskClass,\n@@ -2370,2 +2386,10 @@\n-        DoubleVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            DoubleVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, double.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, DoubleVector::reductionOperations)));\n@@ -2386,14 +2410,3 @@\n-            opc, getClass(), double.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((double)0, (i, a, b) -> (double)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((double)1, (i, a, b) -> (double)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (double) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (double) Math.max(a, b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, double.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, DoubleVector::reductionOperations)));\n@@ -2401,0 +2414,1 @@\n+\n@@ -2402,2 +2416,16 @@\n-    ImplCache<Associative,Function<DoubleVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, DoubleVector.class);\n+    ImplCache<Associative, ReductionOperation<DoubleVector, VectorMask<Double>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, DoubleVector.class);\n+\n+    private static ReductionOperation<DoubleVector, VectorMask<Double>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((double)0, m, (i, a, b) -> (double)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((double)1, m, (i, a, b) -> (double)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (double) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (double) Math.max(a, b)));\n+            default: return null;\n+        }\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":47,"deletions":19,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float128Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float128Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float128Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float256Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float256Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float256Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float512Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float512Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float512Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Float64Mask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Float64Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float64Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    float rOp(float v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    float rOp(float v, VectorMask<Float> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -331,1 +331,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, FloatMaxMask.class, m);  \/\/ specialized\n@@ -344,1 +344,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, FloatMaxMask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatMaxVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -290,1 +290,16 @@\n-    float rOp(float v, FBinOp f);\n+    float rOp(float v, VectorMask<Float> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    float rOpTemplate(float v, VectorMask<Float> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        float[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Float>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2389,0 +2404,1 @@\n+                               Class<? extends VectorMask<Float>> maskClass,\n@@ -2390,2 +2406,10 @@\n-        FloatVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            FloatVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, float.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, FloatVector::reductionOperations)));\n@@ -2406,14 +2430,3 @@\n-            opc, getClass(), float.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((float)0, (i, a, b) -> (float)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((float)1, (i, a, b) -> (float)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (float) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (float) Math.max(a, b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, float.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, FloatVector::reductionOperations)));\n@@ -2421,0 +2434,1 @@\n+\n@@ -2422,2 +2436,16 @@\n-    ImplCache<Associative,Function<FloatVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, FloatVector.class);\n+    ImplCache<Associative, ReductionOperation<FloatVector, VectorMask<Float>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, FloatVector.class);\n+\n+    private static ReductionOperation<FloatVector, VectorMask<Float>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((float)0, m, (i, a, b) -> (float)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((float)1, m, (i, a, b) -> (float)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (float) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (float) Math.max(a, b)));\n+            default: return null;\n+        }\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":47,"deletions":19,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int128Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int128Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int128Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int256Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int256Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int256Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int512Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int512Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int512Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Int64Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Int64Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int64Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    int rOp(int v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, IntMaxMask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, IntMaxMask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntMaxVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -290,1 +290,16 @@\n-    int rOp(int v, FBinOp f);\n+    int rOp(int v, VectorMask<Integer> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    int rOpTemplate(int v, VectorMask<Integer> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        int[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Integer>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2511,0 +2526,1 @@\n+                               Class<? extends VectorMask<Integer>> maskClass,\n@@ -2512,2 +2528,10 @@\n-        IntVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            IntVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, int.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, IntVector::reductionOperations)));\n@@ -2528,20 +2552,3 @@\n-            opc, getClass(), int.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((int)0, (i, a, b) -> (int)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((int)1, (i, a, b) -> (int)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (int) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (int) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((int)-1, (i, a, b) -> (int)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((int)0, (i, a, b) -> (int)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((int)0, (i, a, b) -> (int)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, int.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, IntVector::reductionOperations)));\n@@ -2549,0 +2556,1 @@\n+\n@@ -2550,2 +2558,22 @@\n-    ImplCache<Associative,Function<IntVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, IntVector.class);\n+    ImplCache<Associative, ReductionOperation<IntVector, VectorMask<Integer>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, IntVector.class);\n+\n+    private static ReductionOperation<IntVector, VectorMask<Integer>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((int)0, m, (i, a, b) -> (int)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((int)1, m, (i, a, b) -> (int)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (int) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (int) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((int)-1, m, (i, a, b) -> (int)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((int)0, m, (i, a, b) -> (int)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((int)0, m, (i, a, b) -> (int)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":53,"deletions":25,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -332,1 +332,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long128Mask.class, m);  \/\/ specialized\n@@ -345,1 +345,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long128Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long128Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -332,1 +332,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long256Mask.class, m);  \/\/ specialized\n@@ -345,1 +345,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long256Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long256Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -332,1 +332,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long512Mask.class, m);  \/\/ specialized\n@@ -345,1 +345,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long512Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long512Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -332,1 +332,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Long64Mask.class, m);  \/\/ specialized\n@@ -345,1 +345,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Long64Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long64Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-    long rOp(long v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    long rOp(long v, VectorMask<Long> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -332,1 +332,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, LongMaxMask.class, m);  \/\/ specialized\n@@ -345,1 +345,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, LongMaxMask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongMaxVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -290,1 +290,16 @@\n-    long rOp(long v, FBinOp f);\n+    long rOp(long v, VectorMask<Long> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    long rOpTemplate(long v, VectorMask<Long> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        long[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Long>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2377,0 +2392,1 @@\n+                               Class<? extends VectorMask<Long>> maskClass,\n@@ -2378,2 +2394,10 @@\n-        LongVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            LongVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, long.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, LongVector::reductionOperations)));\n@@ -2394,20 +2418,3 @@\n-            opc, getClass(), long.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((long)0, (i, a, b) -> (long)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((long)1, (i, a, b) -> (long)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (long) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (long) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((long)-1, (i, a, b) -> (long)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((long)0, (i, a, b) -> (long)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((long)0, (i, a, b) -> (long)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, long.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, LongVector::reductionOperations)));\n@@ -2415,0 +2422,1 @@\n+\n@@ -2416,2 +2424,22 @@\n-    ImplCache<Associative,Function<LongVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, LongVector.class);\n+    ImplCache<Associative, ReductionOperation<LongVector, VectorMask<Long>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, LongVector.class);\n+\n+    private static ReductionOperation<LongVector, VectorMask<Long>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((long)0, m, (i, a, b) -> (long)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((long)1, m, (i, a, b) -> (long)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (long) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (long) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((long)-1, m, (i, a, b) -> (long)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((long)0, m, (i, a, b) -> (long)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((long)0, m, (i, a, b) -> (long)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":53,"deletions":25,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short128Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short128Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short128Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short256Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short256Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short256Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short512Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short512Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short512Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, Short64Mask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, Short64Mask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short64Vector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -239,2 +239,2 @@\n-    short rOp(short v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    short rOp(short v, VectorMask<Short> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -337,1 +337,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, ShortMaxMask.class, m);  \/\/ specialized\n@@ -350,1 +350,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, ShortMaxMask.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortMaxVector.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -290,1 +290,16 @@\n-    short rOp(short v, FBinOp f);\n+    short rOp(short v, VectorMask<Short> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    short rOpTemplate(short v, VectorMask<Short> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        short[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Short>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2512,0 +2527,1 @@\n+                               Class<? extends VectorMask<Short>> maskClass,\n@@ -2513,2 +2529,10 @@\n-        ShortVector v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            ShortVector v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, short.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, ShortVector::reductionOperations)));\n@@ -2529,20 +2553,3 @@\n-            opc, getClass(), short.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp((short)0, (i, a, b) -> (short)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp((short)1, (i, a, b) -> (short)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> (short) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> (short) Math.max(a, b)));\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp((short)-1, (i, a, b) -> (short)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp((short)0, (i, a, b) -> (short)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp((short)0, (i, a, b) -> (short)(a ^ b)));\n-              default: return null;\n-              }})));\n+            opc, getClass(), null, short.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, ShortVector::reductionOperations)));\n@@ -2550,0 +2557,1 @@\n+\n@@ -2551,2 +2559,22 @@\n-    ImplCache<Associative,Function<ShortVector,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, ShortVector.class);\n+    ImplCache<Associative, ReductionOperation<ShortVector, VectorMask<Short>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, ShortVector.class);\n+\n+    private static ReductionOperation<ShortVector, VectorMask<Short>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp((short)0, m, (i, a, b) -> (short)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp((short)1, m, (i, a, b) -> (short)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> (short) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> (short) Math.max(a, b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp((short)-1, m, (i, a, b) -> (short)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp((short)0, m, (i, a, b) -> (short)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp((short)0, m, (i, a, b) -> (short)(a ^ b)));\n+            default: return null;\n+        }\n+    }\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":53,"deletions":25,"binary":false,"changes":78,"status":"modified"},{"patch":"@@ -294,1 +294,16 @@\n-    $type$ rOp($type$ v, FBinOp f);\n+    $type$ rOp($type$ v, VectorMask<$Boxtype$> m, FBinOp f);\n+\n+    @ForceInline\n+    final\n+    $type$ rOpTemplate($type$ v, VectorMask<$Boxtype$> m, FBinOp f) {\n+        if (m == null) {\n+            return rOpTemplate(v, f);\n+        }\n+        $type$[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<$Boxtype$>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            v = mbits[i] ? f.apply(i, v, vec[i]) : v;\n+        }\n+        return v;\n+    }\n+\n@@ -2928,0 +2943,1 @@\n+                               Class<? extends VectorMask<$Boxtype$>> maskClass,\n@@ -2929,2 +2945,10 @@\n-        $abstractvectortype$ v = reduceIdentityVector(op).blend(this, m);\n-        return v.reduceLanesTemplate(op);\n+        m.check(maskClass, this);\n+        if (op == FIRST_NONZERO) {\n+            $abstractvectortype$ v = reduceIdentityVector(op).blend(this, m);\n+            return v.reduceLanesTemplate(op);\n+        }\n+        int opc = opCode(op);\n+        return fromBits(VectorSupport.reductionCoerced(\n+            opc, getClass(), maskClass, $type$.class, length(),\n+            this, m,\n+            REDUCE_IMPL.find(op, opc, $abstractvectortype$::reductionOperations)));\n@@ -2945,12 +2969,19 @@\n-            opc, getClass(), $type$.class, length(),\n-            this,\n-            REDUCE_IMPL.find(op, opc, (opc_) -> {\n-              switch (opc_) {\n-              case VECTOR_OP_ADD: return v ->\n-                      toBits(v.rOp(($type$)0, (i, a, b) -> ($type$)(a + b)));\n-              case VECTOR_OP_MUL: return v ->\n-                      toBits(v.rOp(($type$)1, (i, a, b) -> ($type$)(a * b)));\n-              case VECTOR_OP_MIN: return v ->\n-                      toBits(v.rOp(MAX_OR_INF, (i, a, b) -> ($type$) Math.min(a, b)));\n-              case VECTOR_OP_MAX: return v ->\n-                      toBits(v.rOp(MIN_OR_INF, (i, a, b) -> ($type$) Math.max(a, b)));\n+            opc, getClass(), null, $type$.class, length(),\n+            this, null,\n+            REDUCE_IMPL.find(op, opc, $abstractvectortype$::reductionOperations)));\n+    }\n+\n+    private static final\n+    ImplCache<Associative, ReductionOperation<$abstractvectortype$, VectorMask<$Boxtype$>>>\n+        REDUCE_IMPL = new ImplCache<>(Associative.class, $Type$Vector.class);\n+\n+    private static ReductionOperation<$abstractvectortype$, VectorMask<$Boxtype$>> reductionOperations(int opc_) {\n+        switch (opc_) {\n+            case VECTOR_OP_ADD: return (v, m) ->\n+                    toBits(v.rOp(($type$)0, m, (i, a, b) -> ($type$)(a + b)));\n+            case VECTOR_OP_MUL: return (v, m) ->\n+                    toBits(v.rOp(($type$)1, m, (i, a, b) -> ($type$)(a * b)));\n+            case VECTOR_OP_MIN: return (v, m) ->\n+                    toBits(v.rOp(MAX_OR_INF, m, (i, a, b) -> ($type$) Math.min(a, b)));\n+            case VECTOR_OP_MAX: return (v, m) ->\n+                    toBits(v.rOp(MIN_OR_INF, m, (i, a, b) -> ($type$) Math.max(a, b)));\n@@ -2958,6 +2989,6 @@\n-              case VECTOR_OP_AND: return v ->\n-                      toBits(v.rOp(($type$)-1, (i, a, b) -> ($type$)(a & b)));\n-              case VECTOR_OP_OR: return v ->\n-                      toBits(v.rOp(($type$)0, (i, a, b) -> ($type$)(a | b)));\n-              case VECTOR_OP_XOR: return v ->\n-                      toBits(v.rOp(($type$)0, (i, a, b) -> ($type$)(a ^ b)));\n+            case VECTOR_OP_AND: return (v, m) ->\n+                    toBits(v.rOp(($type$)-1, m, (i, a, b) -> ($type$)(a & b)));\n+            case VECTOR_OP_OR: return (v, m) ->\n+                    toBits(v.rOp(($type$)0, m, (i, a, b) -> ($type$)(a | b)));\n+            case VECTOR_OP_XOR: return (v, m) ->\n+                    toBits(v.rOp(($type$)0, m, (i, a, b) -> ($type$)(a ^ b)));\n@@ -2965,2 +2996,2 @@\n-              default: return null;\n-              }})));\n+            default: return null;\n+        }\n@@ -2968,3 +2999,0 @@\n-    private static final\n-    ImplCache<Associative,Function<$abstractvectortype$,Long>> REDUCE_IMPL\n-        = new ImplCache<>(Associative.class, $Type$Vector.class);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":54,"deletions":26,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -241,2 +241,2 @@\n-    $type$ rOp($type$ v, FBinOp f) {\n-        return super.rOpTemplate(v, f);  \/\/ specialize\n+    $type$ rOp($type$ v, VectorMask<$Boxtype$> m, FBinOp f) {\n+        return super.rOpTemplate(v, m, f);  \/\/ specialize\n@@ -341,1 +341,1 @@\n-        return super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return super.reduceLanesTemplate(op, $masktype$.class, m);  \/\/ specialized\n@@ -354,1 +354,1 @@\n-        return (long) super.reduceLanesTemplate(op, m);  \/\/ specialized\n+        return (long) super.reduceLanesTemplate(op, $masktype$.class, m);  \/\/ specialized\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-VectorBits.java.template","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}