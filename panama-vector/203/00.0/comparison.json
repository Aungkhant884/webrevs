{"files":[{"patch":"@@ -44,0 +44,1 @@\n+    public static final int VECTOR_OP_BIT_COUNT = 3;\n@@ -66,1 +67,2 @@\n-    public static final int VECTOR_OP_REINTERPRET = 18;\n+    public static final int VECTOR_OP_UCAST       = 18;\n+    public static final int VECTOR_OP_REINTERPRET = 19;\n@@ -69,4 +71,4 @@\n-    public static final int VECTOR_OP_MASK_TRUECOUNT = 19;\n-    public static final int VECTOR_OP_MASK_FIRSTTRUE = 20;\n-    public static final int VECTOR_OP_MASK_LASTTRUE  = 21;\n-    public static final int VECTOR_OP_MASK_TOLONG    = 22;\n+    public static final int VECTOR_OP_MASK_TRUECOUNT = 20;\n+    public static final int VECTOR_OP_MASK_FIRSTTRUE = 21;\n+    public static final int VECTOR_OP_MASK_LASTTRUE  = 22;\n+    public static final int VECTOR_OP_MASK_TOLONG    = 23;\n@@ -75,2 +77,19 @@\n-    public static final int VECTOR_OP_LROTATE = 23;\n-    public static final int VECTOR_OP_RROTATE = 24;\n+    public static final int VECTOR_OP_LROTATE = 24;\n+    public static final int VECTOR_OP_RROTATE = 25;\n+\n+    \/\/ Compression expansion operations\n+    public static final int VECTOR_OP_COMPRESS = 26;\n+    public static final int VECTOR_OP_EXPAND = 27;\n+    public static final int VECTOR_OP_MASK_COMPRESS = 28;\n+\n+    \/\/ Leading\/Trailing zeros count operations\n+    public static final int VECTOR_OP_TZ_COUNT  = 29;\n+    public static final int VECTOR_OP_LZ_COUNT  = 30;\n+\n+    \/\/ Reverse operation\n+    public static final int VECTOR_OP_REVERSE   = 31;\n+    public static final int VECTOR_OP_REVERSE_BYTES = 32;\n+\n+    \/\/ Compress and Expand Bits operation\n+    public static final int VECTOR_OP_COMPRESS_BITS = 33;\n+    public static final int VECTOR_OP_EXPAND_BITS = 34;\n@@ -117,0 +136,4 @@\n+    \/\/ Various broadcasting modes.\n+    public static final int MODE_BROADCAST = 0;\n+    public static final int MODE_BITS_COERCED_LONG_TO_MASK = 1;\n+\n@@ -161,3 +184,3 @@\n-    public interface BroadcastOperation<VM extends VectorPayload,\n-                                        S extends VectorSpecies<?>> {\n-        VM broadcast(long l, S s);\n+    public interface FromBitsCoercedOperation<VM extends VectorPayload,\n+                                              S extends VectorSpecies<?>> {\n+        VM fromBits(long l, S s);\n@@ -171,4 +194,4 @@\n-    VM broadcastCoerced(Class<? extends VM> vmClass, Class<E> eClass,\n-                        int length,\n-                        long bits, S s,\n-                        BroadcastOperation<VM, S> defaultImpl) {\n+    VM fromBitsCoerced(Class<? extends VM> vmClass, Class<E> eClass,\n+                       int length,\n+                       long bits, int mode, S s,\n+                       FromBitsCoercedOperation<VM, S> defaultImpl) {\n@@ -176,1 +199,1 @@\n-        return defaultImpl.broadcast(bits, s);\n+        return defaultImpl.fromBits(bits, s);\n@@ -362,1 +385,1 @@\n-        VM load(C container, int index, S s);\n+        VM load(C container, long index, S s);\n@@ -374,1 +397,1 @@\n-            C container, int index, S s,\n+            C container, long index, S s,\n@@ -386,1 +409,1 @@\n-        V load(C container, int index, S s, M m);\n+        V load(C container, long index, S s, M m);\n@@ -399,1 +422,1 @@\n-                 M m, C container, int index, S s,\n+                 M m, C container, long index, S s,\n@@ -436,2 +459,2 @@\n-                                          V extends Vector<?>> {\n-        void store(C container, int index, V v);\n+                                          V extends VectorPayload> {\n+        void store(C container, long index, V v);\n@@ -443,1 +466,1 @@\n-     V extends Vector<?>>\n+     V extends VectorPayload>\n@@ -447,1 +470,1 @@\n-               V v, C container, int index,\n+               V v, C container, long index,\n@@ -456,1 +479,1 @@\n-        void store(C container, int index, V v, M m);\n+        void store(C container, long index, V v, M m);\n@@ -468,1 +491,1 @@\n-                     V v, M m, C container, int index,\n+                     V v, M m, C container, long index,\n@@ -625,0 +648,20 @@\n+    public interface ComExpOperation<V extends Vector<?>,\n+                                     M extends VectorMask<?>> {\n+        VectorPayload apply(V v, M m);\n+    }\n+\n+    @IntrinsicCandidate\n+    public static\n+    <V extends Vector<E>,\n+     M extends VectorMask<E>,\n+     E>\n+    VectorPayload comExpOp(int opr,\n+                           Class<? extends V> vClass, Class<? extends M> mClass, Class<E> eClass,\n+                           int length, V v, M m,\n+                           ComExpOperation<V, M> defaultImpl) {\n+        assert isNonCapturingLambda(defaultImpl) : defaultImpl;\n+        return defaultImpl.apply(v, m);\n+    }\n+\n+    \/* ============================================================================ *\/\n+\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":68,"deletions":25,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -29,1 +30,1 @@\n-import java.nio.ByteOrder;\n+import java.nio.ByteOrder;\n@@ -206,0 +207,6 @@\n+    @Override\n+    @ForceInline\n+    public final long loopBound(long length) {\n+        return VectorIntrinsics.roundDown(length, laneCount);\n+    }\n+\n@@ -212,0 +219,6 @@\n+    @Override\n+    @ForceInline\n+    public final VectorMask<E> indexInRange(long offset, long limit) {\n+        return maskAll(true).indexInRange(offset, limit);\n+    }\n+\n@@ -360,1 +373,1 @@\n-    public final Vector<E> fromByteArray(byte[] a, int offset, ByteOrder bo) {\n+    public final Vector<E> fromMemorySegment(MemorySegment ms, long offset, ByteOrder bo) {\n@@ -362,1 +375,1 @@\n-            .fromByteArray0(a, offset)\n+            .fromMemorySegment0(ms, offset)\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractSpecies.java","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2019, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2019, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -30,1 +31,0 @@\n-import java.nio.ByteBuffer;\n@@ -197,1 +197,1 @@\n-    abstract AbstractVector<E> fromByteArray0(byte[] a, int offset);\n+    abstract AbstractVector<E> fromMemorySegment0(MemorySegment ms, long offset);\n@@ -516,2 +516,2 @@\n-        ByteBuffer bb = ByteBuffer.allocate(blen);\n-        this.intoByteBuffer(bb, 0, bo);\n+        MemorySegment ms = MemorySegment.ofArray(new byte[blen]);\n+        this.intoMemorySegment(ms, 0, bo);\n@@ -522,1 +522,1 @@\n-            return ByteVector.fromByteBuffer(rsp.check(byte.class), bb, 0, bo, m.check(byte.class)).check0(rsp);\n+            return ByteVector.fromMemorySegment(rsp.check(byte.class), ms, 0, bo, m.check(byte.class)).check0(rsp);\n@@ -524,1 +524,1 @@\n-            return ShortVector.fromByteBuffer(rsp.check(short.class), bb, 0, bo, m.check(short.class)).check0(rsp);\n+            return ShortVector.fromMemorySegment(rsp.check(short.class), ms, 0, bo, m.check(short.class)).check0(rsp);\n@@ -526,1 +526,1 @@\n-            return IntVector.fromByteBuffer(rsp.check(int.class), bb, 0, bo, m.check(int.class)).check0(rsp);\n+            return IntVector.fromMemorySegment(rsp.check(int.class), ms, 0, bo, m.check(int.class)).check0(rsp);\n@@ -528,1 +528,1 @@\n-            return LongVector.fromByteBuffer(rsp.check(long.class), bb, 0, bo, m.check(long.class)).check0(rsp);\n+            return LongVector.fromMemorySegment(rsp.check(long.class), ms, 0, bo, m.check(long.class)).check0(rsp);\n@@ -530,1 +530,1 @@\n-            return FloatVector.fromByteBuffer(rsp.check(float.class), bb, 0, bo, m.check(float.class)).check0(rsp);\n+            return FloatVector.fromMemorySegment(rsp.check(float.class), ms, 0, bo, m.check(float.class)).check0(rsp);\n@@ -532,2 +532,1 @@\n-            return DoubleVector.fromByteBuffer(rsp.check(double.class), bb, 0, bo, m.check(double.class)).check0(rsp);\n-        \/\/ FIXME: Add lanetype for Halffloat\n+            return DoubleVector.fromMemorySegment(rsp.check(double.class), ms, 0, bo, m.check(double.class)).check0(rsp);\n@@ -652,0 +651,19 @@\n+    \/**\n+     * Helper function for all sorts of lane-wise unsigned conversions.\n+     * This function kicks in after intrinsic failure.\n+     *\/\n+    \/*package-private*\/\n+    @ForceInline\n+    final <F>\n+    AbstractVector<F> defaultUCast(AbstractSpecies<F> dsp) {\n+        AbstractSpecies<?> vsp = this.vspecies();\n+        if (vsp.elementSize() >= dsp.elementSize()) {\n+            \/\/ clip in place\n+            return this.convert0('C', dsp);\n+        } else {\n+            \/\/ extend in place, but remove unwanted sign extension\n+            long mask = -1L >>> -vsp.elementSize();\n+            return (AbstractVector<F>) this.convert0('C', dsp).lanewise(AND, dsp.broadcast(mask));\n+        }\n+    }\n+\n@@ -671,0 +689,1 @@\n+        Class<?> vtype;\n@@ -678,2 +697,15 @@\n-            \/\/ Maybe this should be an intrinsic also.\n-            AbstractVector<?> bitv = resizeLanes0(this, rspi);\n+            AbstractSpecies<?> vsp = this.vspecies();\n+            AbstractSpecies<?> vspi = vsp.asIntegral();\n+            AbstractVector<?> biti = vspi == vsp ? this : this.convert0('X', vspi);\n+            rtype = rspi.elementType();\n+            rlength = rspi.laneCount();\n+            etype = vspi.elementType();\n+            vlength = vspi.laneCount();\n+            rvtype = rspi.dummyVector().getClass();\n+            vtype = vspi.dummyVector().getClass();\n+            int opc = vspi.elementSize() < rspi.elementSize() ? VectorSupport.VECTOR_OP_UCAST : VectorSupport.VECTOR_OP_CAST;\n+            AbstractVector<?> bitv = VectorSupport.convert(opc,\n+                    vtype, etype, vlength,\n+                    rvtype, rtype, rlength,\n+                    biti, rspi,\n+                    AbstractVector::defaultUCast);\n@@ -688,0 +720,1 @@\n+            vtype = this.getClass();\n@@ -689,1 +722,1 @@\n-                    this.getClass(), etype, vlength,\n+                    vtype, etype, vlength,\n@@ -699,0 +732,1 @@\n+            vtype = this.getClass();\n@@ -700,1 +734,1 @@\n-                    this.getClass(), etype, vlength,\n+                    vtype, etype, vlength,\n@@ -708,27 +742,0 @@\n-    @ForceInline\n-    private static <F>\n-    AbstractVector<F>\n-    resizeLanes0(AbstractVector<?> v, AbstractSpecies<F> rspi) {\n-        AbstractSpecies<?> dsp = v.vspecies();\n-        int sizeChange = rspi.elementSize() - dsp.elementSize();\n-        AbstractSpecies<?> dspi = dsp.asIntegral();\n-        if (dspi != dsp)  v = v.convert0('R', dspi);\n-        if (sizeChange <= 0) {  \/\/ clip in place\n-            return v.convert0('C', rspi);\n-        }\n-        \/\/ extend in place, but remove unwanted sign extension\n-        long mask = -1L >>> sizeChange;\n-        return (AbstractVector<F>)\n-            v.convert0('C', rspi)\n-            .lanewise(AND, rspi.broadcast(mask));\n-    }\n-\n-    \/\/ Byte buffer wrappers.\n-    static ByteBuffer wrapper(ByteBuffer bb, ByteOrder bo) {\n-        return bb.duplicate().order(bo);\n-    }\n-\n-    static ByteBuffer wrapper(byte[] a, ByteOrder bo) {\n-        return ByteBuffer.wrap(a).order(bo);\n-    }\n-\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/AbstractVector.java","additions":50,"deletions":43,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -32,0 +31,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -360,0 +360,6 @@\n+    @Override\n+    @ForceInline\n+    public final Halffloat128Mask test(Test op, VectorMask<Halffloat> m) {\n+        return super.testTemplate(Halffloat128Mask.class, op, (Halffloat128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -458,0 +464,16 @@\n+    @Override\n+    @ForceInline\n+    public Halffloat128Vector compress(VectorMask<Halffloat> m) {\n+        return (Halffloat128Vector)\n+            super.compressTemplate(Halffloat128Mask.class,\n+                                   (Halffloat128Mask) m);  \/\/ specialize\n+    }\n+\n+    @Override\n+    @ForceInline\n+    public Halffloat128Vector expand(VectorMask<Halffloat> m) {\n+        return (Halffloat128Vector)\n+            super.expandTemplate(Halffloat128Mask.class,\n+                                   (Halffloat128Mask) m);  \/\/ specialize\n+    }\n+\n@@ -647,0 +669,9 @@\n+        @Override\n+        @ForceInline\n+        public Halffloat128Mask compress() {\n+            return (Halffloat128Mask)VectorSupport.comExpOp(VectorSupport.VECTOR_OP_MASK_COMPRESS,\n+                Halffloat128Vector.class, Halffloat128Mask.class, ETYPE, VLENGTH, null, this,\n+                (v1, m1) -> VSPECIES.iota().compare(VectorOperators.LT, m1.trueCount()));\n+        }\n+\n+\n@@ -733,3 +764,3 @@\n-            return VectorSupport.broadcastCoerced(Halffloat128Mask.class, short.class, VLENGTH,\n-                                                  (bit ? -1 : 0), null,\n-                                                  (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n+            return VectorSupport.fromBitsCoerced(Halffloat128Mask.class, short.class, VLENGTH,\n+                                                 (bit ? -1 : 0), MODE_BROADCAST, null,\n+                                                 (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n@@ -846,2 +877,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset) {\n-        return super.fromByteArray0Template(a, offset);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset) {\n+        return super.fromMemorySegment0Template(ms, offset);  \/\/ specialize\n@@ -853,16 +884,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteArray0Template(Halffloat128Mask.class, a, offset, (Halffloat128Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset) {\n-        return super.fromByteBuffer0Template(bb, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteBuffer0Template(Halffloat128Mask.class, bb, offset, (Halffloat128Mask) m);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        return super.fromMemorySegment0Template(Halffloat128Mask.class, ms, offset, (Halffloat128Mask) m);  \/\/ specialize\n@@ -890,16 +907,2 @@\n-    void intoByteArray0(byte[] a, int offset) {\n-        super.intoByteArray0Template(a, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteArray0Template(Halffloat128Mask.class, a, offset, (Halffloat128Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteBuffer0Template(Halffloat128Mask.class, bb, offset, (Halffloat128Mask) m);\n+    void intoMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        super.intoMemorySegment0Template(Halffloat128Mask.class, ms, offset, (Halffloat128Mask) m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Halffloat128Vector.java","additions":42,"deletions":39,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -32,0 +31,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -360,0 +360,6 @@\n+    @Override\n+    @ForceInline\n+    public final Halffloat256Mask test(Test op, VectorMask<Halffloat> m) {\n+        return super.testTemplate(Halffloat256Mask.class, op, (Halffloat256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -458,0 +464,16 @@\n+    @Override\n+    @ForceInline\n+    public Halffloat256Vector compress(VectorMask<Halffloat> m) {\n+        return (Halffloat256Vector)\n+            super.compressTemplate(Halffloat256Mask.class,\n+                                   (Halffloat256Mask) m);  \/\/ specialize\n+    }\n+\n+    @Override\n+    @ForceInline\n+    public Halffloat256Vector expand(VectorMask<Halffloat> m) {\n+        return (Halffloat256Vector)\n+            super.expandTemplate(Halffloat256Mask.class,\n+                                   (Halffloat256Mask) m);  \/\/ specialize\n+    }\n+\n@@ -663,0 +685,9 @@\n+        @Override\n+        @ForceInline\n+        public Halffloat256Mask compress() {\n+            return (Halffloat256Mask)VectorSupport.comExpOp(VectorSupport.VECTOR_OP_MASK_COMPRESS,\n+                Halffloat256Vector.class, Halffloat256Mask.class, ETYPE, VLENGTH, null, this,\n+                (v1, m1) -> VSPECIES.iota().compare(VectorOperators.LT, m1.trueCount()));\n+        }\n+\n+\n@@ -749,3 +780,3 @@\n-            return VectorSupport.broadcastCoerced(Halffloat256Mask.class, short.class, VLENGTH,\n-                                                  (bit ? -1 : 0), null,\n-                                                  (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n+            return VectorSupport.fromBitsCoerced(Halffloat256Mask.class, short.class, VLENGTH,\n+                                                 (bit ? -1 : 0), MODE_BROADCAST, null,\n+                                                 (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n@@ -862,2 +893,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset) {\n-        return super.fromByteArray0Template(a, offset);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset) {\n+        return super.fromMemorySegment0Template(ms, offset);  \/\/ specialize\n@@ -869,16 +900,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteArray0Template(Halffloat256Mask.class, a, offset, (Halffloat256Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset) {\n-        return super.fromByteBuffer0Template(bb, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteBuffer0Template(Halffloat256Mask.class, bb, offset, (Halffloat256Mask) m);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        return super.fromMemorySegment0Template(Halffloat256Mask.class, ms, offset, (Halffloat256Mask) m);  \/\/ specialize\n@@ -906,16 +923,2 @@\n-    void intoByteArray0(byte[] a, int offset) {\n-        super.intoByteArray0Template(a, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteArray0Template(Halffloat256Mask.class, a, offset, (Halffloat256Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteBuffer0Template(Halffloat256Mask.class, bb, offset, (Halffloat256Mask) m);\n+    void intoMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        super.intoMemorySegment0Template(Halffloat256Mask.class, ms, offset, (Halffloat256Mask) m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Halffloat256Vector.java","additions":42,"deletions":39,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -32,0 +31,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -360,0 +360,6 @@\n+    @Override\n+    @ForceInline\n+    public final Halffloat512Mask test(Test op, VectorMask<Halffloat> m) {\n+        return super.testTemplate(Halffloat512Mask.class, op, (Halffloat512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -458,0 +464,16 @@\n+    @Override\n+    @ForceInline\n+    public Halffloat512Vector compress(VectorMask<Halffloat> m) {\n+        return (Halffloat512Vector)\n+            super.compressTemplate(Halffloat512Mask.class,\n+                                   (Halffloat512Mask) m);  \/\/ specialize\n+    }\n+\n+    @Override\n+    @ForceInline\n+    public Halffloat512Vector expand(VectorMask<Halffloat> m) {\n+        return (Halffloat512Vector)\n+            super.expandTemplate(Halffloat512Mask.class,\n+                                   (Halffloat512Mask) m);  \/\/ specialize\n+    }\n+\n@@ -663,0 +685,9 @@\n+        @Override\n+        @ForceInline\n+        public Halffloat512Mask compress() {\n+            return (Halffloat512Mask)VectorSupport.comExpOp(VectorSupport.VECTOR_OP_MASK_COMPRESS,\n+                Halffloat512Vector.class, Halffloat512Mask.class, ETYPE, VLENGTH, null, this,\n+                (v1, m1) -> VSPECIES.iota().compare(VectorOperators.LT, m1.trueCount()));\n+        }\n+\n+\n@@ -749,3 +780,3 @@\n-            return VectorSupport.broadcastCoerced(Halffloat512Mask.class, short.class, VLENGTH,\n-                                                  (bit ? -1 : 0), null,\n-                                                  (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n+            return VectorSupport.fromBitsCoerced(Halffloat512Mask.class, short.class, VLENGTH,\n+                                                 (bit ? -1 : 0), MODE_BROADCAST, null,\n+                                                 (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n@@ -862,2 +893,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset) {\n-        return super.fromByteArray0Template(a, offset);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset) {\n+        return super.fromMemorySegment0Template(ms, offset);  \/\/ specialize\n@@ -869,16 +900,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteArray0Template(Halffloat512Mask.class, a, offset, (Halffloat512Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset) {\n-        return super.fromByteBuffer0Template(bb, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteBuffer0Template(Halffloat512Mask.class, bb, offset, (Halffloat512Mask) m);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        return super.fromMemorySegment0Template(Halffloat512Mask.class, ms, offset, (Halffloat512Mask) m);  \/\/ specialize\n@@ -906,16 +923,2 @@\n-    void intoByteArray0(byte[] a, int offset) {\n-        super.intoByteArray0Template(a, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteArray0Template(Halffloat512Mask.class, a, offset, (Halffloat512Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteBuffer0Template(Halffloat512Mask.class, bb, offset, (Halffloat512Mask) m);\n+    void intoMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        super.intoMemorySegment0Template(Halffloat512Mask.class, ms, offset, (Halffloat512Mask) m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Halffloat512Vector.java","additions":42,"deletions":39,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -32,0 +31,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -360,0 +360,6 @@\n+    @Override\n+    @ForceInline\n+    public final Halffloat64Mask test(Test op, VectorMask<Halffloat> m) {\n+        return super.testTemplate(Halffloat64Mask.class, op, (Halffloat64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -458,0 +464,16 @@\n+    @Override\n+    @ForceInline\n+    public Halffloat64Vector compress(VectorMask<Halffloat> m) {\n+        return (Halffloat64Vector)\n+            super.compressTemplate(Halffloat64Mask.class,\n+                                   (Halffloat64Mask) m);  \/\/ specialize\n+    }\n+\n+    @Override\n+    @ForceInline\n+    public Halffloat64Vector expand(VectorMask<Halffloat> m) {\n+        return (Halffloat64Vector)\n+            super.expandTemplate(Halffloat64Mask.class,\n+                                   (Halffloat64Mask) m);  \/\/ specialize\n+    }\n+\n@@ -639,0 +661,9 @@\n+        @Override\n+        @ForceInline\n+        public Halffloat64Mask compress() {\n+            return (Halffloat64Mask)VectorSupport.comExpOp(VectorSupport.VECTOR_OP_MASK_COMPRESS,\n+                Halffloat64Vector.class, Halffloat64Mask.class, ETYPE, VLENGTH, null, this,\n+                (v1, m1) -> VSPECIES.iota().compare(VectorOperators.LT, m1.trueCount()));\n+        }\n+\n+\n@@ -725,3 +756,3 @@\n-            return VectorSupport.broadcastCoerced(Halffloat64Mask.class, short.class, VLENGTH,\n-                                                  (bit ? -1 : 0), null,\n-                                                  (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n+            return VectorSupport.fromBitsCoerced(Halffloat64Mask.class, short.class, VLENGTH,\n+                                                 (bit ? -1 : 0), MODE_BROADCAST, null,\n+                                                 (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n@@ -838,2 +869,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset) {\n-        return super.fromByteArray0Template(a, offset);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset) {\n+        return super.fromMemorySegment0Template(ms, offset);  \/\/ specialize\n@@ -845,16 +876,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteArray0Template(Halffloat64Mask.class, a, offset, (Halffloat64Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset) {\n-        return super.fromByteBuffer0Template(bb, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteBuffer0Template(Halffloat64Mask.class, bb, offset, (Halffloat64Mask) m);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        return super.fromMemorySegment0Template(Halffloat64Mask.class, ms, offset, (Halffloat64Mask) m);  \/\/ specialize\n@@ -882,16 +899,2 @@\n-    void intoByteArray0(byte[] a, int offset) {\n-        super.intoByteArray0Template(a, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteArray0Template(Halffloat64Mask.class, a, offset, (Halffloat64Mask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteBuffer0Template(Halffloat64Mask.class, bb, offset, (Halffloat64Mask) m);\n+    void intoMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        super.intoMemorySegment0Template(Halffloat64Mask.class, ms, offset, (Halffloat64Mask) m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Halffloat64Vector.java","additions":42,"deletions":39,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -32,0 +31,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -360,0 +360,6 @@\n+    @Override\n+    @ForceInline\n+    public final HalffloatMaxMask test(Test op, VectorMask<Halffloat> m) {\n+        return super.testTemplate(HalffloatMaxMask.class, op, (HalffloatMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -458,0 +464,16 @@\n+    @Override\n+    @ForceInline\n+    public HalffloatMaxVector compress(VectorMask<Halffloat> m) {\n+        return (HalffloatMaxVector)\n+            super.compressTemplate(HalffloatMaxMask.class,\n+                                   (HalffloatMaxMask) m);  \/\/ specialize\n+    }\n+\n+    @Override\n+    @ForceInline\n+    public HalffloatMaxVector expand(VectorMask<Halffloat> m) {\n+        return (HalffloatMaxVector)\n+            super.expandTemplate(HalffloatMaxMask.class,\n+                                   (HalffloatMaxMask) m);  \/\/ specialize\n+    }\n+\n@@ -632,0 +654,9 @@\n+        @Override\n+        @ForceInline\n+        public HalffloatMaxMask compress() {\n+            return (HalffloatMaxMask)VectorSupport.comExpOp(VectorSupport.VECTOR_OP_MASK_COMPRESS,\n+                HalffloatMaxVector.class, HalffloatMaxMask.class, ETYPE, VLENGTH, null, this,\n+                (v1, m1) -> VSPECIES.iota().compare(VectorOperators.LT, m1.trueCount()));\n+        }\n+\n+\n@@ -718,3 +749,3 @@\n-            return VectorSupport.broadcastCoerced(HalffloatMaxMask.class, short.class, VLENGTH,\n-                                                  (bit ? -1 : 0), null,\n-                                                  (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n+            return VectorSupport.fromBitsCoerced(HalffloatMaxMask.class, short.class, VLENGTH,\n+                                                 (bit ? -1 : 0), MODE_BROADCAST, null,\n+                                                 (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n@@ -831,2 +862,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset) {\n-        return super.fromByteArray0Template(a, offset);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset) {\n+        return super.fromMemorySegment0Template(ms, offset);  \/\/ specialize\n@@ -838,16 +869,2 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteArray0Template(HalffloatMaxMask.class, a, offset, (HalffloatMaxMask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset) {\n-        return super.fromByteBuffer0Template(bb, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        return super.fromByteBuffer0Template(HalffloatMaxMask.class, bb, offset, (HalffloatMaxMask) m);  \/\/ specialize\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        return super.fromMemorySegment0Template(HalffloatMaxMask.class, ms, offset, (HalffloatMaxMask) m);  \/\/ specialize\n@@ -875,16 +892,2 @@\n-    void intoByteArray0(byte[] a, int offset) {\n-        super.intoByteArray0Template(a, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteArray0Template(HalffloatMaxMask.class, a, offset, (HalffloatMaxMask) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m) {\n-        super.intoByteBuffer0Template(HalffloatMaxMask.class, bb, offset, (HalffloatMaxMask) m);\n+    void intoMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m) {\n+        super.intoMemorySegment0Template(HalffloatMaxMask.class, ms, offset, (HalffloatMaxMask) m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/HalffloatMaxVector.java","additions":42,"deletions":39,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -29,1 +28,0 @@\n-import java.nio.ReadOnlyBufferException;\n@@ -33,1 +31,0 @@\n-import java.util.function.UnaryOperator;\n@@ -35,0 +32,3 @@\n+import jdk.incubator.foreign.MemorySegment;\n+import jdk.incubator.foreign.ValueLayout;\n+import jdk.internal.access.foreign.MemorySegmentProxy;\n@@ -60,0 +60,2 @@\n+    static final ValueLayout.OfShort ELEMENT_LAYOUT = ValueLayout.JAVA_SHORT.withBitAlignment(8);\n+\n@@ -354,0 +356,39 @@\n+    \/*package-private*\/\n+    interface FLdLongOp {\n+        short apply(MemorySegment memory, long offset, int i);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    HalffloatVector ldLongOp(MemorySegment memory, long offset,\n+                                  FLdLongOp f) {\n+        \/\/dummy; no vec = vec();\n+        short[] res = new short[length()];\n+        for (int i = 0; i < res.length; i++) {\n+            res[i] = f.apply(memory, offset, i);\n+        }\n+        return vectorFactory(res);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    HalffloatVector ldLongOp(MemorySegment memory, long offset,\n+                                  VectorMask<Halffloat> m,\n+                                  FLdLongOp f) {\n+        \/\/short[] vec = vec();\n+        short[] res = new short[length()];\n+        boolean[] mbits = ((AbstractMask<Halffloat>)m).getBits();\n+        for (int i = 0; i < res.length; i++) {\n+            if (mbits[i]) {\n+                res[i] = f.apply(memory, offset, i);\n+            }\n+        }\n+        return vectorFactory(res);\n+    }\n+\n+    static short memorySegmentGet(MemorySegment ms, long o, int i) {\n+        return ms.get(ELEMENT_LAYOUT, o + i * 2L);\n+    }\n+\n@@ -384,0 +425,34 @@\n+    interface FStLongOp {\n+        void apply(MemorySegment memory, long offset, int i, short a);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    void stLongOp(MemorySegment memory, long offset,\n+                  FStLongOp f) {\n+        short[] vec = vec();\n+        for (int i = 0; i < vec.length; i++) {\n+            f.apply(memory, offset, i, vec[i]);\n+        }\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    void stLongOp(MemorySegment memory, long offset,\n+                  VectorMask<Halffloat> m,\n+                  FStLongOp f) {\n+        short[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Halffloat>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            if (mbits[i]) {\n+                f.apply(memory, offset, i, vec[i]);\n+            }\n+        }\n+    }\n+\n+    static void memorySegmentSet(MemorySegment ms, long o, int i, short e) {\n+        ms.set(ELEMENT_LAYOUT, o + i * 2L, e);\n+    }\n+\n@@ -423,0 +498,30 @@\n+    static HalffloatVector expandHelper(Vector<Halffloat> v, VectorMask<Halffloat> m) {\n+        VectorSpecies<Halffloat> vsp = m.vectorSpecies();\n+        HalffloatVector r  = (HalffloatVector) vsp.zero();\n+        HalffloatVector vi = (HalffloatVector) v;\n+        if (m.allTrue()) {\n+            return vi;\n+        }\n+        for (int i = 0, j = 0; i < vsp.length(); i++) {\n+            if (m.laneIsSet(i)) {\n+                r = r.withLane(i, vi.lane(j++));\n+            }\n+        }\n+        return r;\n+    }\n+\n+    static HalffloatVector compressHelper(Vector<Halffloat> v, VectorMask<Halffloat> m) {\n+        VectorSpecies<Halffloat> vsp = m.vectorSpecies();\n+        HalffloatVector r  = (HalffloatVector) vsp.zero();\n+        HalffloatVector vi = (HalffloatVector) v;\n+        if (m.allTrue()) {\n+            return vi;\n+        }\n+        for (int i = 0, j = 0; i < vsp.length(); i++) {\n+            if (m.laneIsSet(i)) {\n+                r = r.withLane(j++, vi.lane(i));\n+            }\n+        }\n+        return r;\n+    }\n+\n@@ -447,2 +552,2 @@\n-        return VectorSupport.broadcastCoerced(vsp.vectorType(), Halffloat.class, species.length(),\n-                        toBits((short)0), vsp,\n+        return VectorSupport.fromBitsCoerced(vsp.vectorType(), Halffloat.class, species.length(),\n+                        toBits((short)0), MODE_BROADCAST, vsp,\n@@ -1556,0 +1661,1 @@\n+\n@@ -1677,1 +1783,1 @@\n-            return maskType.cast(m.cast(this.vspecies()));\n+            return maskType.cast(m.cast(vsp));\n@@ -1687,2 +1793,1 @@\n-    @ForceInline\n-    public final\n+    public abstract\n@@ -1690,2 +1795,40 @@\n-                                  VectorMask<Halffloat> m) {\n-        return test(op).and(m);\n+                                  VectorMask<Halffloat> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Halffloat>>\n+    M testTemplate(Class<M> maskType, Test op, M mask) {\n+        HalffloatSpecies vsp = vspecies();\n+        mask.check(maskType, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            ShortVector bits = this.viewAsIntegralLanes();\n+            VectorMask<Short> m = mask.cast(ShortVector.species(shape()));\n+            if (op == IS_DEFAULT) {\n+                m = bits.compare(EQ, (short) 0, m);\n+            } else if (op == IS_NEGATIVE) {\n+                m = bits.compare(LT, (short) 0, m);\n+            }\n+            else if (op == IS_FINITE ||\n+                     op == IS_NAN ||\n+                     op == IS_INFINITE) {\n+                \/\/ first kill the sign:\n+                bits = bits.and(Short.MAX_VALUE);\n+                \/\/ next find the bit pattern for infinity:\n+                short infbits = (short) toBits(Halffloat.POSITIVE_INFINITY);\n+                \/\/ now compare:\n+                if (op == IS_FINITE) {\n+                    m = bits.compare(LT, infbits, m);\n+                } else if (op == IS_NAN) {\n+                    m = bits.compare(GT, infbits, m);\n+                } else {\n+                    m = bits.compare(EQ, infbits, m);\n+                }\n+            }\n+            else {\n+                throw new AssertionError(op);\n+            }\n+            return maskType.cast(m.cast(vsp));\n+        }\n+        int opc = opCode(op);\n+        throw new AssertionError(op);\n@@ -2166,0 +2309,39 @@\n+    \/**\n+     * {@inheritDoc} <!--workaround-->\n+     * @since 19\n+     *\/\n+    @Override\n+    public abstract\n+    HalffloatVector compress(VectorMask<Halffloat> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends AbstractMask<Halffloat>>\n+    HalffloatVector compressTemplate(Class<M> masktype, M m) {\n+      m.check(masktype, this);\n+      return (HalffloatVector) VectorSupport.comExpOp(VectorSupport.VECTOR_OP_COMPRESS, getClass(), masktype,\n+                                                   Halffloat.class, length(), this, m,\n+                                                   (v1, m1) -> compressHelper(v1, m1));\n+    }\n+\n+    \/**\n+     * {@inheritDoc} <!--workaround-->\n+     * @since 19\n+     *\/\n+    @Override\n+    public abstract\n+    HalffloatVector expand(VectorMask<Halffloat> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends AbstractMask<Halffloat>>\n+    HalffloatVector expandTemplate(Class<M> masktype, M m) {\n+      m.check(masktype, this);\n+      return (HalffloatVector) VectorSupport.comExpOp(VectorSupport.VECTOR_OP_EXPAND, getClass(), masktype,\n+                                                   Halffloat.class, length(), this, m,\n+                                                   (v1, m1) -> expandHelper(v1, m1));\n+    }\n+\n+\n@@ -2381,1 +2563,2 @@\n-            HalffloatVector v = reduceIdentityVector(op).blend(this, m);\n+            \/\/ FIXME:  The JIT should handle this.\n+            HalffloatVector v = broadcast((short) 0).blend(this, m);\n@@ -2396,1 +2579,1 @@\n-            \/\/ FIXME:  The JIT should handle this, and other scan ops alos.\n+            \/\/ FIXME:  The JIT should handle this.\n@@ -2399,1 +2582,2 @@\n-            return this.lane(thisNZ.firstTrue());\n+            int ft = thisNZ.firstTrue();\n+            return ft < length() ? this.lane(ft) : (short) 0;\n@@ -2426,24 +2610,0 @@\n-    private\n-    @ForceInline\n-    HalffloatVector reduceIdentityVector(VectorOperators.Associative op) {\n-        int opc = opCode(op);\n-        UnaryOperator<HalffloatVector> fn\n-            = REDUCE_ID_IMPL.find(op, opc, (opc_) -> {\n-                switch (opc_) {\n-                case VECTOR_OP_ADD:\n-                    return v -> v.broadcast(0);\n-                case VECTOR_OP_MUL:\n-                    return v -> v.broadcast(1);\n-                case VECTOR_OP_MIN:\n-                    return v -> v.broadcast(MAX_OR_INF);\n-                case VECTOR_OP_MAX:\n-                    return v -> v.broadcast(MIN_OR_INF);\n-                default: return null;\n-                }\n-            });\n-        return fn.apply(this);\n-    }\n-    private static final\n-    ImplCache<Associative,UnaryOperator<HalffloatVector>> REDUCE_ID_IMPL\n-        = new ImplCache<>(Associative.class, HalffloatVector.class);\n-\n@@ -2560,84 +2720,0 @@\n-    \/**\n-     * Loads a vector from a byte array starting at an offset.\n-     * Bytes are composed into primitive lane elements according\n-     * to the specified byte order.\n-     * The vector is arranged into lanes according to\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it returns the result of calling\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * var m = species.maskAll(true);\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param species species of desired vector\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @return a vector loaded from a byte array\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *\/\n-    @ForceInline\n-    public static\n-    HalffloatVector fromByteArray(VectorSpecies<Halffloat> species,\n-                                       byte[] a, int offset,\n-                                       ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, species.vectorByteSize(), a.length);\n-        HalffloatSpecies vsp = (HalffloatSpecies) species;\n-        return vsp.dummyVector().fromByteArray0(a, offset).maybeSwap(bo);\n-    }\n-\n-    \/**\n-     * Loads a vector from a byte array starting at an offset\n-     * and using a mask.\n-     * Lanes where the mask is unset are filled with the default\n-     * value of {@code short} (positive zero).\n-     * Bytes are composed into primitive lane elements according\n-     * to the specified byte order.\n-     * The vector is arranged into lanes according to\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it returns the result of calling\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param species species of desired vector\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @param m the mask controlling lane selection\n-     * @return a vector loaded from a byte array\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *         where the mask is set\n-     *\/\n-    @ForceInline\n-    public static\n-    HalffloatVector fromByteArray(VectorSpecies<Halffloat> species,\n-                                       byte[] a, int offset,\n-                                       ByteOrder bo,\n-                                       VectorMask<Halffloat> m) {\n-        HalffloatSpecies vsp = (HalffloatSpecies) species;\n-        if (offset >= 0 && offset <= (a.length - species.vectorByteSize())) {\n-            return vsp.dummyVector().fromByteArray0(a, offset, m).maybeSwap(bo);\n-        }\n-\n-        \/\/ FIXME: optimize\n-        checkMaskFromIndexSize(offset, vsp, m, 2, a.length);\n-        ByteBuffer wb = wrapper(a, bo);\n-        return vsp.ldOp(wb, offset, (AbstractMask<Halffloat>)m,\n-                   (wb_, o, i)  -> wb_.getShort(o + i * 2));\n-    }\n-\n@@ -2943,2 +3019,2 @@\n-     * Loads a vector from a {@linkplain ByteBuffer byte buffer}\n-     * starting at an offset into the byte buffer.\n+     * Loads a vector from a {@linkplain MemorySegment memory segment}\n+     * starting at an offset into the memory segment.\n@@ -2951,2 +3027,2 @@\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n+     * {@link #fromMemorySegment(VectorSpecies,MemorySegment,long,ByteOrder,VectorMask)\n+     * fromMemorySegment()} as follows:\n@@ -2955,1 +3031,1 @@\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n+     * return fromMemorySegment(species, ms, offset, bo, m);\n@@ -2959,2 +3035,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the byte buffer\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -2962,1 +3038,1 @@\n-     * @return a vector loaded from a byte buffer\n+     * @return a vector loaded from the memory segment\n@@ -2965,1 +3041,1 @@\n-     *         or {@code offset+N*2 >= bb.limit()}\n+     *         or {@code offset+N*2 >= ms.byteSize()}\n@@ -2967,0 +3043,5 @@\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -2970,4 +3051,4 @@\n-    HalffloatVector fromByteBuffer(VectorSpecies<Halffloat> species,\n-                                        ByteBuffer bb, int offset,\n-                                        ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, species.vectorByteSize(), bb.limit());\n+    HalffloatVector fromMemorySegment(VectorSpecies<Halffloat> species,\n+                                           MemorySegment ms, long offset,\n+                                           ByteOrder bo) {\n+        offset = checkFromIndexSize(offset, species.vectorByteSize(), ms.byteSize());\n@@ -2975,1 +3056,1 @@\n-        return vsp.dummyVector().fromByteBuffer0(bb, offset).maybeSwap(bo);\n+        return vsp.dummyVector().fromMemorySegment0(ms, offset).maybeSwap(bo);\n@@ -2979,2 +3060,2 @@\n-     * Loads a vector from a {@linkplain ByteBuffer byte buffer}\n-     * starting at an offset into the byte buffer\n+     * Loads a vector from a {@linkplain MemorySegment memory segment}\n+     * starting at an offset into the memory segment\n@@ -2991,3 +3072,1 @@\n-     * HalffloatBuffer eb = bb.duplicate()\n-     *     .position(offset)\n-     *     .order(bo).asHalffloatBuffer();\n+     * var slice = ms.asSlice(offset);\n@@ -2997,1 +3076,1 @@\n-     *         ar[n] = eb.get(n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_SHORT.withBitAlignment(8), n);\n@@ -3011,2 +3090,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the byte buffer\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -3015,1 +3094,1 @@\n-     * @return a vector loaded from a byte buffer\n+     * @return a vector loaded from the memory segment\n@@ -3018,1 +3097,1 @@\n-     *         or {@code offset+N*2 >= bb.limit()}\n+     *         or {@code offset+N*2 >= ms.byteSize()}\n@@ -3021,0 +3100,5 @@\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -3024,4 +3108,4 @@\n-    HalffloatVector fromByteBuffer(VectorSpecies<Halffloat> species,\n-                                        ByteBuffer bb, int offset,\n-                                        ByteOrder bo,\n-                                        VectorMask<Halffloat> m) {\n+    HalffloatVector fromMemorySegment(VectorSpecies<Halffloat> species,\n+                                           MemorySegment ms, long offset,\n+                                           ByteOrder bo,\n+                                           VectorMask<Halffloat> m) {\n@@ -3029,2 +3113,2 @@\n-        if (offset >= 0 && offset <= (bb.limit() - species.vectorByteSize())) {\n-            return vsp.dummyVector().fromByteBuffer0(bb, offset, m).maybeSwap(bo);\n+        if (offset >= 0 && offset <= (ms.byteSize() - species.vectorByteSize())) {\n+            return vsp.dummyVector().fromMemorySegment0(ms, offset, m).maybeSwap(bo);\n@@ -3034,4 +3118,2 @@\n-        checkMaskFromIndexSize(offset, vsp, m, 2, bb.limit());\n-        ByteBuffer wb = wrapper(bb, bo);\n-        return vsp.ldOp(wb, offset, (AbstractMask<Halffloat>)m,\n-                   (wb_, o, i)  -> wb_.getShort(o + i * 2));\n+        checkMaskFromIndexSize(offset, vsp, m, 2, ms.byteSize());\n+        return vsp.ldLongOp(ms, offset, m, HalffloatVector::memorySegmentGet);\n@@ -3067,1 +3149,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -3213,1 +3295,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -3343,0 +3425,1 @@\n+     * @since 19\n@@ -3347,21 +3430,4 @@\n-    void intoByteArray(byte[] a, int offset,\n-                       ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, byteSize(), a.length);\n-        maybeSwap(bo).intoByteArray0(a, offset);\n-    }\n-\n-    \/**\n-     * {@inheritDoc} <!--workaround-->\n-     *\/\n-    @Override\n-    @ForceInline\n-    public final\n-    void intoByteArray(byte[] a, int offset,\n-                       ByteOrder bo,\n-                       VectorMask<Halffloat> m) {\n-        if (m.allTrue()) {\n-            intoByteArray(a, offset, bo);\n-        } else {\n-            HalffloatSpecies vsp = vspecies();\n-            checkMaskFromIndexSize(offset, vsp, m, 2, a.length);\n-            maybeSwap(bo).intoByteArray0(a, offset, m);\n+    void intoMemorySegment(MemorySegment ms, long offset,\n+                           ByteOrder bo) {\n+        if (ms.isReadOnly()) {\n+            throw new UnsupportedOperationException(\"Attempt to write a read-only segment\");\n@@ -3369,1 +3435,0 @@\n-    }\n@@ -3371,13 +3436,2 @@\n-    \/**\n-     * {@inheritDoc} <!--workaround-->\n-     *\/\n-    @Override\n-    @ForceInline\n-    public final\n-    void intoByteBuffer(ByteBuffer bb, int offset,\n-                        ByteOrder bo) {\n-        if (ScopedMemoryAccess.isReadOnly(bb)) {\n-            throw new ReadOnlyBufferException();\n-        }\n-        offset = checkFromIndexSize(offset, byteSize(), bb.limit());\n-        maybeSwap(bo).intoByteBuffer0(bb, offset);\n+        offset = checkFromIndexSize(offset, byteSize(), ms.byteSize());\n+        maybeSwap(bo).intoMemorySegment0(ms, offset);\n@@ -3388,0 +3442,1 @@\n+     * @since 19\n@@ -3392,3 +3447,3 @@\n-    void intoByteBuffer(ByteBuffer bb, int offset,\n-                        ByteOrder bo,\n-                        VectorMask<Halffloat> m) {\n+    void intoMemorySegment(MemorySegment ms, long offset,\n+                           ByteOrder bo,\n+                           VectorMask<Halffloat> m) {\n@@ -3396,1 +3451,1 @@\n-            intoByteBuffer(bb, offset, bo);\n+            intoMemorySegment(ms, offset, bo);\n@@ -3398,2 +3453,2 @@\n-            if (bb.isReadOnly()) {\n-                throw new ReadOnlyBufferException();\n+            if (ms.isReadOnly()) {\n+                throw new UnsupportedOperationException(\"Attempt to write a read-only segment\");\n@@ -3402,2 +3457,2 @@\n-            checkMaskFromIndexSize(offset, vsp, m, 2, bb.limit());\n-            maybeSwap(bo).intoByteBuffer0(bb, offset, m);\n+            checkMaskFromIndexSize(offset, vsp, m, 2, ms.byteSize());\n+            maybeSwap(bo).intoMemorySegment0(ms, offset, m);\n@@ -3437,1 +3492,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -3454,1 +3509,1 @@\n-            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+            (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -3470,1 +3525,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -3487,1 +3542,1 @@\n-                (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -3492,1 +3547,0 @@\n-    @Override\n@@ -3494,1 +3548,1 @@\n-    HalffloatVector fromByteArray0(byte[] a, int offset);\n+    HalffloatVector fromMemorySegment0(MemorySegment bb, long offset);\n@@ -3497,1 +3551,1 @@\n-    HalffloatVector fromByteArray0Template(byte[] a, int offset) {\n+    HalffloatVector fromMemorySegment0Template(MemorySegment ms, long offset) {\n@@ -3499,37 +3553,1 @@\n-        return VectorSupport.load(\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            a, offset, vsp,\n-            (arr, off, s) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                return s.ldOp(wb, off,\n-                        (wb_, o, i) -> wb_.getShort(o + i * 2));\n-            });\n-    }\n-\n-    abstract\n-    HalffloatVector fromByteArray0(byte[] a, int offset, VectorMask<Halffloat> m);\n-    @ForceInline\n-    final\n-    <M extends VectorMask<Halffloat>>\n-    HalffloatVector fromByteArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n-        HalffloatSpecies vsp = vspecies();\n-        m.check(vsp);\n-        return VectorSupport.loadMasked(\n-            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset), m,\n-            a, offset, vsp,\n-            (arr, off, s, vm) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                return s.ldOp(wb, off, vm,\n-                        (wb_, o, i) -> wb_.getShort(o + i * 2));\n-            });\n-    }\n-\n-    abstract\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset);\n-    @ForceInline\n-    final\n-    HalffloatVector fromByteBuffer0Template(ByteBuffer bb, int offset) {\n-        HalffloatSpecies vsp = vspecies();\n-        return ScopedMemoryAccess.loadFromByteBuffer(\n+        return ScopedMemoryAccess.loadFromMemorySegment(\n@@ -3537,5 +3555,3 @@\n-                bb, offset, vsp,\n-                (buf, off, s) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    return s.ldOp(wb, off,\n-                            (wb_, o, i) -> wb_.getShort(o + i * 2));\n+                (MemorySegmentProxy) ms, offset, vsp,\n+                (msp, off, s) -> {\n+                    return s.ldLongOp((MemorySegment) msp, off, HalffloatVector::memorySegmentGet);\n@@ -3546,1 +3562,1 @@\n-    HalffloatVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m);\n+    HalffloatVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Halffloat> m);\n@@ -3550,1 +3566,1 @@\n-    HalffloatVector fromByteBuffer0Template(Class<M> maskClass, ByteBuffer bb, int offset, M m) {\n+    HalffloatVector fromMemorySegment0Template(Class<M> maskClass, MemorySegment ms, long offset, M m) {\n@@ -3553,1 +3569,1 @@\n-        return ScopedMemoryAccess.loadFromByteBufferMasked(\n+        return ScopedMemoryAccess.loadFromMemorySegmentMasked(\n@@ -3555,5 +3571,3 @@\n-                bb, offset, m, vsp,\n-                (buf, off, s, vm) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    return s.ldOp(wb, off, vm,\n-                            (wb_, o, i) -> wb_.getShort(o + i * 2));\n+                (MemorySegmentProxy) ms, offset, m, vsp,\n+                (msp, off, s, vm) -> {\n+                    return s.ldLongOp((MemorySegment) msp, off, vm, HalffloatVector::memorySegmentGet);\n@@ -3578,1 +3592,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -3595,1 +3609,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -3601,2 +3615,0 @@\n-    abstract\n-    void intoByteArray0(byte[] a, int offset);\n@@ -3605,1 +3617,1 @@\n-    void intoByteArray0Template(byte[] a, int offset) {\n+    void intoMemorySegment0(MemorySegment ms, long offset) {\n@@ -3607,35 +3619,1 @@\n-        VectorSupport.store(\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            this, a, offset,\n-            (arr, off, v) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                v.stOp(wb, off,\n-                        (tb_, o, i, e) -> tb_.putShort(o + i * 2, e));\n-            });\n-    }\n-\n-    abstract\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Halffloat> m);\n-    @ForceInline\n-    final\n-    <M extends VectorMask<Halffloat>>\n-    void intoByteArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n-        HalffloatSpecies vsp = vspecies();\n-        m.check(vsp);\n-        VectorSupport.storeMasked(\n-            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            this, m, a, offset,\n-            (arr, off, v, vm) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                v.stOp(wb, off, vm,\n-                        (tb_, o, i, e) -> tb_.putShort(o + i * 2, e));\n-            });\n-    }\n-\n-    @ForceInline\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset) {\n-        HalffloatSpecies vsp = vspecies();\n-        ScopedMemoryAccess.storeIntoByteBuffer(\n+        ScopedMemoryAccess.storeIntoMemorySegment(\n@@ -3643,5 +3621,4 @@\n-                this, bb, offset,\n-                (buf, off, v) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    v.stOp(wb, off,\n-                            (wb_, o, i, e) -> wb_.putShort(o + i * 2, e));\n+                this,\n+                (MemorySegmentProxy) ms, offset,\n+                (msp, off, v) -> {\n+                    v.stLongOp((MemorySegment) msp, off, HalffloatVector::memorySegmentSet);\n@@ -3652,1 +3629,1 @@\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Halffloat> m);\n+    void intoMemorySegment0(MemorySegment bb, long offset, VectorMask<Halffloat> m);\n@@ -3656,1 +3633,1 @@\n-    void intoByteBuffer0Template(Class<M> maskClass, ByteBuffer bb, int offset, M m) {\n+    void intoMemorySegment0Template(Class<M> maskClass, MemorySegment ms, long offset, M m) {\n@@ -3659,1 +3636,1 @@\n-        ScopedMemoryAccess.storeIntoByteBufferMasked(\n+        ScopedMemoryAccess.storeIntoMemorySegmentMasked(\n@@ -3661,5 +3638,4 @@\n-                this, m, bb, offset,\n-                (buf, off, v, vm) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    v.stOp(wb, off, vm,\n-                            (wb_, o, i, e) -> wb_.putShort(o + i * 2, e));\n+                this, m,\n+                (MemorySegmentProxy) ms, offset,\n+                (msp, off, v, vm) -> {\n+                    v.stLongOp((MemorySegment) msp, off, vm, HalffloatVector::memorySegmentSet);\n@@ -3683,1 +3659,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -3699,0 +3675,10 @@\n+    private static\n+    void checkMaskFromIndexSize(long offset,\n+                                HalffloatSpecies vsp,\n+                                VectorMask<Halffloat> m,\n+                                int scale,\n+                                long limit) {\n+        ((AbstractMask<Halffloat>)m)\n+            .checkIndexByLane(offset, limit, vsp.iota(), scale);\n+    }\n+\n@@ -3906,1 +3892,1 @@\n-                VectorSupport.broadcastCoerced(\n+                VectorSupport.fromBitsCoerced(\n@@ -3908,1 +3894,1 @@\n-                    bits, this,\n+                    bits, MODE_BROADCAST, this,\n@@ -4025,0 +4011,15 @@\n+        \/*package-private*\/\n+        @ForceInline\n+        HalffloatVector ldLongOp(MemorySegment memory, long offset,\n+                                      FLdLongOp f) {\n+            return dummyVector().ldLongOp(memory, offset, f);\n+        }\n+\n+        \/*package-private*\/\n+        @ForceInline\n+        HalffloatVector ldLongOp(MemorySegment memory, long offset,\n+                                      VectorMask<Halffloat> m,\n+                                      FLdLongOp f) {\n+            return dummyVector().ldLongOp(memory, offset, m, f);\n+        }\n+\n@@ -4039,0 +4040,14 @@\n+        \/*package-private*\/\n+        @ForceInline\n+        void stLongOp(MemorySegment memory, long offset, FStLongOp f) {\n+            dummyVector().stLongOp(memory, offset, f);\n+        }\n+\n+        \/*package-private*\/\n+        @ForceInline\n+        void stLongOp(MemorySegment memory, long offset,\n+                      AbstractMask<Halffloat> m,\n+                      FStLongOp f) {\n+            dummyVector().stLongOp(memory, offset, m, f);\n+        }\n+\n@@ -4100,6 +4115,6 @@\n-        switch (s) {\n-            case S_64_BIT: return (HalffloatSpecies) SPECIES_64;\n-            case S_128_BIT: return (HalffloatSpecies) SPECIES_128;\n-            case S_256_BIT: return (HalffloatSpecies) SPECIES_256;\n-            case S_512_BIT: return (HalffloatSpecies) SPECIES_512;\n-            case S_Max_BIT: return (HalffloatSpecies) SPECIES_MAX;\n+        switch (s.switchKey) {\n+            case VectorShape.SK_64_BIT: return (HalffloatSpecies) SPECIES_64;\n+            case VectorShape.SK_128_BIT: return (HalffloatSpecies) SPECIES_128;\n+            case VectorShape.SK_256_BIT: return (HalffloatSpecies) SPECIES_256;\n+            case VectorShape.SK_512_BIT: return (HalffloatSpecies) SPECIES_512;\n+            case VectorShape.SK_Max_BIT: return (HalffloatSpecies) SPECIES_MAX;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/HalffloatVector.java","additions":335,"deletions":320,"binary":false,"changes":655,"status":"modified"},{"patch":"@@ -99,0 +99,1 @@\n+    @ForceInline\n@@ -103,0 +104,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LaneType.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,2 +27,0 @@\n-import java.nio.ByteBuffer;\n-import java.nio.ReadOnlyBufferException;\n@@ -33,1 +31,3 @@\n-import java.util.function.UnaryOperator;\n+import jdk.incubator.foreign.MemorySegment;\n+import jdk.incubator.foreign.ValueLayout;\n+import jdk.internal.access.foreign.MemorySegmentProxy;\n@@ -60,0 +60,2 @@\n+    static final ValueLayout.OfShort ELEMENT_LAYOUT = ValueLayout.JAVA_SHORT.withBitAlignment(8);\n+\n@@ -354,0 +356,39 @@\n+    \/*package-private*\/\n+    interface FLdLongOp {\n+        short apply(MemorySegment memory, long offset, int i);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    ShortVector ldLongOp(MemorySegment memory, long offset,\n+                                  FLdLongOp f) {\n+        \/\/dummy; no vec = vec();\n+        short[] res = new short[length()];\n+        for (int i = 0; i < res.length; i++) {\n+            res[i] = f.apply(memory, offset, i);\n+        }\n+        return vectorFactory(res);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    ShortVector ldLongOp(MemorySegment memory, long offset,\n+                                  VectorMask<Short> m,\n+                                  FLdLongOp f) {\n+        \/\/short[] vec = vec();\n+        short[] res = new short[length()];\n+        boolean[] mbits = ((AbstractMask<Short>)m).getBits();\n+        for (int i = 0; i < res.length; i++) {\n+            if (mbits[i]) {\n+                res[i] = f.apply(memory, offset, i);\n+            }\n+        }\n+        return vectorFactory(res);\n+    }\n+\n+    static short memorySegmentGet(MemorySegment ms, long o, int i) {\n+        return ms.get(ELEMENT_LAYOUT, o + i * 2L);\n+    }\n+\n@@ -384,0 +425,34 @@\n+    interface FStLongOp {\n+        void apply(MemorySegment memory, long offset, int i, short a);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    void stLongOp(MemorySegment memory, long offset,\n+                  FStLongOp f) {\n+        short[] vec = vec();\n+        for (int i = 0; i < vec.length; i++) {\n+            f.apply(memory, offset, i, vec[i]);\n+        }\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    void stLongOp(MemorySegment memory, long offset,\n+                  VectorMask<Short> m,\n+                  FStLongOp f) {\n+        short[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<Short>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            if (mbits[i]) {\n+                f.apply(memory, offset, i, vec[i]);\n+            }\n+        }\n+    }\n+\n+    static void memorySegmentSet(MemorySegment ms, long o, int i, short e) {\n+        ms.set(ELEMENT_LAYOUT, o + i * 2L, e);\n+    }\n+\n@@ -434,0 +509,30 @@\n+    static ShortVector expandHelper(Vector<Short> v, VectorMask<Short> m) {\n+        VectorSpecies<Short> vsp = m.vectorSpecies();\n+        ShortVector r  = (ShortVector) vsp.zero();\n+        ShortVector vi = (ShortVector) v;\n+        if (m.allTrue()) {\n+            return vi;\n+        }\n+        for (int i = 0, j = 0; i < vsp.length(); i++) {\n+            if (m.laneIsSet(i)) {\n+                r = r.withLane(i, vi.lane(j++));\n+            }\n+        }\n+        return r;\n+    }\n+\n+    static ShortVector compressHelper(Vector<Short> v, VectorMask<Short> m) {\n+        VectorSpecies<Short> vsp = m.vectorSpecies();\n+        ShortVector r  = (ShortVector) vsp.zero();\n+        ShortVector vi = (ShortVector) v;\n+        if (m.allTrue()) {\n+            return vi;\n+        }\n+        for (int i = 0, j = 0; i < vsp.length(); i++) {\n+            if (m.laneIsSet(i)) {\n+                r = r.withLane(j++, vi.lane(i));\n+            }\n+        }\n+        return r;\n+    }\n+\n@@ -458,2 +563,2 @@\n-        return VectorSupport.broadcastCoerced(vsp.vectorType(), short.class, species.length(),\n-                                0, vsp,\n+        return VectorSupport.fromBitsCoerced(vsp.vectorType(), short.class, species.length(),\n+                                0, MODE_BROADCAST, vsp,\n@@ -576,3 +681,0 @@\n-            } else if (op == NEG) {\n-                \/\/ FIXME: Support this in the JIT.\n-                return broadcast(0).lanewise(SUB, this);\n@@ -607,2 +709,0 @@\n-            } else if (op == NEG) {\n-                return lanewise(NOT, m).lanewise(ADD, broadcast(1), m);\n@@ -628,0 +728,10 @@\n+            case VECTOR_OP_BIT_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) bitCount(a));\n+            case VECTOR_OP_TZ_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) numberOfTrailingZeros(a));\n+            case VECTOR_OP_LZ_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) numberOfLeadingZeros(a));\n+            case VECTOR_OP_REVERSE: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> reverse(a));\n+            case VECTOR_OP_REVERSE_BYTES: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> (short) Short.reverseBytes(a));\n@@ -1754,0 +1864,20 @@\n+    static int bitCount(short a) {\n+        return Integer.bitCount((int)a & 0xFFFF);\n+    }\n+    static int numberOfTrailingZeros(short a) {\n+        return a != 0 ? Integer.numberOfTrailingZeros(a) : 16;\n+    }\n+    static int numberOfLeadingZeros(short a) {\n+        return a >= 0 ? Integer.numberOfLeadingZeros(a) - 16 : 0;\n+    }\n+\n+    static short reverse(short a) {\n+        if (a == 0 || a == -1) return a;\n+\n+        short b = rotateLeft(a, 8);\n+        b = (short) (((b & 0x5555) << 1) | ((b & 0xAAAA) >>> 1));\n+        b = (short) (((b & 0x3333) << 2) | ((b & 0xCCCC) >>> 2));\n+        b = (short) (((b & 0x0F0F) << 4) | ((b & 0xF0F0) >>> 4));\n+        return b;\n+    }\n+\n@@ -1858,1 +1988,0 @@\n-            ShortVector bits = this.viewAsIntegralLanes();\n@@ -1861,1 +1990,1 @@\n-                m = bits.compare(EQ, (short) 0);\n+                m = compare(EQ, (short) 0);\n@@ -1863,1 +1992,1 @@\n-                m = bits.compare(LT, (short) 0);\n+                m = compare(LT, (short) 0);\n@@ -1878,2 +2007,1 @@\n-    @ForceInline\n-    public final\n+    public abstract\n@@ -1881,2 +2009,23 @@\n-                                  VectorMask<Short> m) {\n-        return test(op).and(m);\n+                                  VectorMask<Short> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends VectorMask<Short>>\n+    M testTemplate(Class<M> maskType, Test op, M mask) {\n+        ShortSpecies vsp = vspecies();\n+        mask.check(maskType, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+            VectorMask<Short> m = mask;\n+            if (op == IS_DEFAULT) {\n+                m = compare(EQ, (short) 0, m);\n+            } else if (op == IS_NEGATIVE) {\n+                m = compare(LT, (short) 0, m);\n+            }\n+            else {\n+                throw new AssertionError(op);\n+            }\n+            return maskType.cast(m);\n+        }\n+        int opc = opCode(op);\n+        throw new AssertionError(op);\n@@ -2361,0 +2510,39 @@\n+    \/**\n+     * {@inheritDoc} <!--workaround-->\n+     * @since 19\n+     *\/\n+    @Override\n+    public abstract\n+    ShortVector compress(VectorMask<Short> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends AbstractMask<Short>>\n+    ShortVector compressTemplate(Class<M> masktype, M m) {\n+      m.check(masktype, this);\n+      return (ShortVector) VectorSupport.comExpOp(VectorSupport.VECTOR_OP_COMPRESS, getClass(), masktype,\n+                                                   short.class, length(), this, m,\n+                                                   (v1, m1) -> compressHelper(v1, m1));\n+    }\n+\n+    \/**\n+     * {@inheritDoc} <!--workaround-->\n+     * @since 19\n+     *\/\n+    @Override\n+    public abstract\n+    ShortVector expand(VectorMask<Short> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends AbstractMask<Short>>\n+    ShortVector expandTemplate(Class<M> masktype, M m) {\n+      m.check(masktype, this);\n+      return (ShortVector) VectorSupport.comExpOp(VectorSupport.VECTOR_OP_EXPAND, getClass(), masktype,\n+                                                   short.class, length(), this, m,\n+                                                   (v1, m1) -> expandHelper(v1, m1));\n+    }\n+\n+\n@@ -2598,1 +2786,2 @@\n-            ShortVector v = reduceIdentityVector(op).blend(this, m);\n+            \/\/ FIXME:  The JIT should handle this.\n+            ShortVector v = broadcast((short) 0).blend(this, m);\n@@ -2613,1 +2802,1 @@\n-            \/\/ FIXME:  The JIT should handle this, and other scan ops alos.\n+            \/\/ FIXME:  The JIT should handle this.\n@@ -2616,1 +2805,2 @@\n-            return this.lane(thisNZ.firstTrue());\n+            int ft = thisNZ.firstTrue();\n+            return ft < length() ? this.lane(ft) : (short) 0;\n@@ -2649,28 +2839,0 @@\n-    private\n-    @ForceInline\n-    ShortVector reduceIdentityVector(VectorOperators.Associative op) {\n-        int opc = opCode(op);\n-        UnaryOperator<ShortVector> fn\n-            = REDUCE_ID_IMPL.find(op, opc, (opc_) -> {\n-                switch (opc_) {\n-                case VECTOR_OP_ADD:\n-                case VECTOR_OP_OR:\n-                case VECTOR_OP_XOR:\n-                    return v -> v.broadcast(0);\n-                case VECTOR_OP_MUL:\n-                    return v -> v.broadcast(1);\n-                case VECTOR_OP_AND:\n-                    return v -> v.broadcast(-1);\n-                case VECTOR_OP_MIN:\n-                    return v -> v.broadcast(MAX_OR_INF);\n-                case VECTOR_OP_MAX:\n-                    return v -> v.broadcast(MIN_OR_INF);\n-                default: return null;\n-                }\n-            });\n-        return fn.apply(this);\n-    }\n-    private static final\n-    ImplCache<Associative,UnaryOperator<ShortVector>> REDUCE_ID_IMPL\n-        = new ImplCache<>(Associative.class, ShortVector.class);\n-\n@@ -2799,84 +2961,0 @@\n-    \/**\n-     * Loads a vector from a byte array starting at an offset.\n-     * Bytes are composed into primitive lane elements according\n-     * to the specified byte order.\n-     * The vector is arranged into lanes according to\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it returns the result of calling\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * var m = species.maskAll(true);\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param species species of desired vector\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @return a vector loaded from a byte array\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *\/\n-    @ForceInline\n-    public static\n-    ShortVector fromByteArray(VectorSpecies<Short> species,\n-                                       byte[] a, int offset,\n-                                       ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, species.vectorByteSize(), a.length);\n-        ShortSpecies vsp = (ShortSpecies) species;\n-        return vsp.dummyVector().fromByteArray0(a, offset).maybeSwap(bo);\n-    }\n-\n-    \/**\n-     * Loads a vector from a byte array starting at an offset\n-     * and using a mask.\n-     * Lanes where the mask is unset are filled with the default\n-     * value of {@code short} (zero).\n-     * Bytes are composed into primitive lane elements according\n-     * to the specified byte order.\n-     * The vector is arranged into lanes according to\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it returns the result of calling\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param species species of desired vector\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @param m the mask controlling lane selection\n-     * @return a vector loaded from a byte array\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *         where the mask is set\n-     *\/\n-    @ForceInline\n-    public static\n-    ShortVector fromByteArray(VectorSpecies<Short> species,\n-                                       byte[] a, int offset,\n-                                       ByteOrder bo,\n-                                       VectorMask<Short> m) {\n-        ShortSpecies vsp = (ShortSpecies) species;\n-        if (offset >= 0 && offset <= (a.length - species.vectorByteSize())) {\n-            return vsp.dummyVector().fromByteArray0(a, offset, m).maybeSwap(bo);\n-        }\n-\n-        \/\/ FIXME: optimize\n-        checkMaskFromIndexSize(offset, vsp, m, 2, a.length);\n-        ByteBuffer wb = wrapper(a, bo);\n-        return vsp.ldOp(wb, offset, (AbstractMask<Short>)m,\n-                   (wb_, o, i)  -> wb_.getShort(o + i * 2));\n-    }\n-\n@@ -3182,2 +3260,2 @@\n-     * Loads a vector from a {@linkplain ByteBuffer byte buffer}\n-     * starting at an offset into the byte buffer.\n+     * Loads a vector from a {@linkplain MemorySegment memory segment}\n+     * starting at an offset into the memory segment.\n@@ -3190,2 +3268,2 @@\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n+     * {@link #fromMemorySegment(VectorSpecies,MemorySegment,long,ByteOrder,VectorMask)\n+     * fromMemorySegment()} as follows:\n@@ -3194,1 +3272,1 @@\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n+     * return fromMemorySegment(species, ms, offset, bo, m);\n@@ -3198,2 +3276,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the byte buffer\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -3201,1 +3279,1 @@\n-     * @return a vector loaded from a byte buffer\n+     * @return a vector loaded from the memory segment\n@@ -3204,1 +3282,1 @@\n-     *         or {@code offset+N*2 >= bb.limit()}\n+     *         or {@code offset+N*2 >= ms.byteSize()}\n@@ -3206,0 +3284,5 @@\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -3209,4 +3292,4 @@\n-    ShortVector fromByteBuffer(VectorSpecies<Short> species,\n-                                        ByteBuffer bb, int offset,\n-                                        ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, species.vectorByteSize(), bb.limit());\n+    ShortVector fromMemorySegment(VectorSpecies<Short> species,\n+                                           MemorySegment ms, long offset,\n+                                           ByteOrder bo) {\n+        offset = checkFromIndexSize(offset, species.vectorByteSize(), ms.byteSize());\n@@ -3214,1 +3297,1 @@\n-        return vsp.dummyVector().fromByteBuffer0(bb, offset).maybeSwap(bo);\n+        return vsp.dummyVector().fromMemorySegment0(ms, offset).maybeSwap(bo);\n@@ -3218,2 +3301,2 @@\n-     * Loads a vector from a {@linkplain ByteBuffer byte buffer}\n-     * starting at an offset into the byte buffer\n+     * Loads a vector from a {@linkplain MemorySegment memory segment}\n+     * starting at an offset into the memory segment\n@@ -3230,3 +3313,1 @@\n-     * ShortBuffer eb = bb.duplicate()\n-     *     .position(offset)\n-     *     .order(bo).asShortBuffer();\n+     * var slice = ms.asSlice(offset);\n@@ -3236,1 +3317,1 @@\n-     *         ar[n] = eb.get(n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_SHORT.withBitAlignment(8), n);\n@@ -3250,2 +3331,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the byte buffer\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -3254,1 +3335,1 @@\n-     * @return a vector loaded from a byte buffer\n+     * @return a vector loaded from the memory segment\n@@ -3257,1 +3338,1 @@\n-     *         or {@code offset+N*2 >= bb.limit()}\n+     *         or {@code offset+N*2 >= ms.byteSize()}\n@@ -3260,0 +3341,5 @@\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -3263,4 +3349,4 @@\n-    ShortVector fromByteBuffer(VectorSpecies<Short> species,\n-                                        ByteBuffer bb, int offset,\n-                                        ByteOrder bo,\n-                                        VectorMask<Short> m) {\n+    ShortVector fromMemorySegment(VectorSpecies<Short> species,\n+                                           MemorySegment ms, long offset,\n+                                           ByteOrder bo,\n+                                           VectorMask<Short> m) {\n@@ -3268,2 +3354,2 @@\n-        if (offset >= 0 && offset <= (bb.limit() - species.vectorByteSize())) {\n-            return vsp.dummyVector().fromByteBuffer0(bb, offset, m).maybeSwap(bo);\n+        if (offset >= 0 && offset <= (ms.byteSize() - species.vectorByteSize())) {\n+            return vsp.dummyVector().fromMemorySegment0(ms, offset, m).maybeSwap(bo);\n@@ -3273,4 +3359,2 @@\n-        checkMaskFromIndexSize(offset, vsp, m, 2, bb.limit());\n-        ByteBuffer wb = wrapper(bb, bo);\n-        return vsp.ldOp(wb, offset, (AbstractMask<Short>)m,\n-                   (wb_, o, i)  -> wb_.getShort(o + i * 2));\n+        checkMaskFromIndexSize(offset, vsp, m, 2, ms.byteSize());\n+        return vsp.ldLongOp(ms, offset, m, ShortVector::memorySegmentGet);\n@@ -3306,1 +3390,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -3452,1 +3536,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -3582,0 +3666,1 @@\n+     * @since 19\n@@ -3586,21 +3671,4 @@\n-    void intoByteArray(byte[] a, int offset,\n-                       ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, byteSize(), a.length);\n-        maybeSwap(bo).intoByteArray0(a, offset);\n-    }\n-\n-    \/**\n-     * {@inheritDoc} <!--workaround-->\n-     *\/\n-    @Override\n-    @ForceInline\n-    public final\n-    void intoByteArray(byte[] a, int offset,\n-                       ByteOrder bo,\n-                       VectorMask<Short> m) {\n-        if (m.allTrue()) {\n-            intoByteArray(a, offset, bo);\n-        } else {\n-            ShortSpecies vsp = vspecies();\n-            checkMaskFromIndexSize(offset, vsp, m, 2, a.length);\n-            maybeSwap(bo).intoByteArray0(a, offset, m);\n+    void intoMemorySegment(MemorySegment ms, long offset,\n+                           ByteOrder bo) {\n+        if (ms.isReadOnly()) {\n+            throw new UnsupportedOperationException(\"Attempt to write a read-only segment\");\n@@ -3608,14 +3676,2 @@\n-    }\n-    \/**\n-     * {@inheritDoc} <!--workaround-->\n-     *\/\n-    @Override\n-    @ForceInline\n-    public final\n-    void intoByteBuffer(ByteBuffer bb, int offset,\n-                        ByteOrder bo) {\n-        if (ScopedMemoryAccess.isReadOnly(bb)) {\n-            throw new ReadOnlyBufferException();\n-        }\n-        offset = checkFromIndexSize(offset, byteSize(), bb.limit());\n-        maybeSwap(bo).intoByteBuffer0(bb, offset);\n+        offset = checkFromIndexSize(offset, byteSize(), ms.byteSize());\n+        maybeSwap(bo).intoMemorySegment0(ms, offset);\n@@ -3627,0 +3683,1 @@\n+     * @since 19\n@@ -3631,3 +3688,3 @@\n-    void intoByteBuffer(ByteBuffer bb, int offset,\n-                        ByteOrder bo,\n-                        VectorMask<Short> m) {\n+    void intoMemorySegment(MemorySegment ms, long offset,\n+                           ByteOrder bo,\n+                           VectorMask<Short> m) {\n@@ -3635,1 +3692,1 @@\n-            intoByteBuffer(bb, offset, bo);\n+            intoMemorySegment(ms, offset, bo);\n@@ -3637,2 +3694,2 @@\n-            if (bb.isReadOnly()) {\n-                throw new ReadOnlyBufferException();\n+            if (ms.isReadOnly()) {\n+                throw new UnsupportedOperationException(\"Attempt to write a read-only segment\");\n@@ -3641,2 +3698,2 @@\n-            checkMaskFromIndexSize(offset, vsp, m, 2, bb.limit());\n-            maybeSwap(bo).intoByteBuffer0(bb, offset, m);\n+            checkMaskFromIndexSize(offset, vsp, m, 2, ms.byteSize());\n+            maybeSwap(bo).intoMemorySegment0(ms, offset, m);\n@@ -3676,1 +3733,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -3693,1 +3750,1 @@\n-            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+            (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -3709,1 +3766,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -3726,1 +3783,1 @@\n-                (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -3731,38 +3788,1 @@\n-    @Override\n-    abstract\n-    ShortVector fromByteArray0(byte[] a, int offset);\n-    @ForceInline\n-    final\n-    ShortVector fromByteArray0Template(byte[] a, int offset) {\n-        ShortSpecies vsp = vspecies();\n-        return VectorSupport.load(\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            a, offset, vsp,\n-            (arr, off, s) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                return s.ldOp(wb, off,\n-                        (wb_, o, i) -> wb_.getShort(o + i * 2));\n-            });\n-    }\n-\n-    abstract\n-    ShortVector fromByteArray0(byte[] a, int offset, VectorMask<Short> m);\n-    @ForceInline\n-    final\n-    <M extends VectorMask<Short>>\n-    ShortVector fromByteArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n-        ShortSpecies vsp = vspecies();\n-        m.check(vsp);\n-        return VectorSupport.loadMasked(\n-            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset), m,\n-            a, offset, vsp,\n-            (arr, off, s, vm) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                return s.ldOp(wb, off, vm,\n-                        (wb_, o, i) -> wb_.getShort(o + i * 2));\n-            });\n-    }\n-\n-    ShortVector fromByteBuffer0(ByteBuffer bb, int offset);\n+    ShortVector fromMemorySegment0(MemorySegment bb, long offset);\n@@ -3772,1 +3792,1 @@\n-    ShortVector fromByteBuffer0Template(ByteBuffer bb, int offset) {\n+    ShortVector fromMemorySegment0Template(MemorySegment ms, long offset) {\n@@ -3774,1 +3794,1 @@\n-        return ScopedMemoryAccess.loadFromByteBuffer(\n+        return ScopedMemoryAccess.loadFromMemorySegment(\n@@ -3776,5 +3796,3 @@\n-                bb, offset, vsp,\n-                (buf, off, s) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    return s.ldOp(wb, off,\n-                            (wb_, o, i) -> wb_.getShort(o + i * 2));\n+                (MemorySegmentProxy) ms, offset, vsp,\n+                (msp, off, s) -> {\n+                    return s.ldLongOp((MemorySegment) msp, off, ShortVector::memorySegmentGet);\n@@ -3785,1 +3803,1 @@\n-    ShortVector fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<Short> m);\n+    ShortVector fromMemorySegment0(MemorySegment ms, long offset, VectorMask<Short> m);\n@@ -3789,1 +3807,1 @@\n-    ShortVector fromByteBuffer0Template(Class<M> maskClass, ByteBuffer bb, int offset, M m) {\n+    ShortVector fromMemorySegment0Template(Class<M> maskClass, MemorySegment ms, long offset, M m) {\n@@ -3792,1 +3810,1 @@\n-        return ScopedMemoryAccess.loadFromByteBufferMasked(\n+        return ScopedMemoryAccess.loadFromMemorySegmentMasked(\n@@ -3794,5 +3812,3 @@\n-                bb, offset, m, vsp,\n-                (buf, off, s, vm) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    return s.ldOp(wb, off, vm,\n-                            (wb_, o, i) -> wb_.getShort(o + i * 2));\n+                (MemorySegmentProxy) ms, offset, m, vsp,\n+                (msp, off, s, vm) -> {\n+                    return s.ldLongOp((MemorySegment) msp, off, vm, ShortVector::memorySegmentGet);\n@@ -3817,1 +3833,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -3834,1 +3850,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -3840,36 +3856,0 @@\n-    abstract\n-    void intoByteArray0(byte[] a, int offset);\n-    @ForceInline\n-    final\n-    void intoByteArray0Template(byte[] a, int offset) {\n-        ShortSpecies vsp = vspecies();\n-        VectorSupport.store(\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            this, a, offset,\n-            (arr, off, v) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                v.stOp(wb, off,\n-                        (tb_, o, i, e) -> tb_.putShort(o + i * 2, e));\n-            });\n-    }\n-\n-    abstract\n-    void intoByteArray0(byte[] a, int offset, VectorMask<Short> m);\n-    @ForceInline\n-    final\n-    <M extends VectorMask<Short>>\n-    void intoByteArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n-        ShortSpecies vsp = vspecies();\n-        m.check(vsp);\n-        VectorSupport.storeMasked(\n-            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            this, m, a, offset,\n-            (arr, off, v, vm) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                v.stOp(wb, off, vm,\n-                        (tb_, o, i, e) -> tb_.putShort(o + i * 2, e));\n-            });\n-    }\n-\n@@ -3878,1 +3858,1 @@\n-    void intoByteBuffer0(ByteBuffer bb, int offset) {\n+    void intoMemorySegment0(MemorySegment ms, long offset) {\n@@ -3880,1 +3860,1 @@\n-        ScopedMemoryAccess.storeIntoByteBuffer(\n+        ScopedMemoryAccess.storeIntoMemorySegment(\n@@ -3882,5 +3862,4 @@\n-                this, bb, offset,\n-                (buf, off, v) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    v.stOp(wb, off,\n-                            (wb_, o, i, e) -> wb_.putShort(o + i * 2, e));\n+                this,\n+                (MemorySegmentProxy) ms, offset,\n+                (msp, off, v) -> {\n+                    v.stLongOp((MemorySegment) msp, off, ShortVector::memorySegmentSet);\n@@ -3891,1 +3870,1 @@\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<Short> m);\n+    void intoMemorySegment0(MemorySegment bb, long offset, VectorMask<Short> m);\n@@ -3895,1 +3874,1 @@\n-    void intoByteBuffer0Template(Class<M> maskClass, ByteBuffer bb, int offset, M m) {\n+    void intoMemorySegment0Template(Class<M> maskClass, MemorySegment ms, long offset, M m) {\n@@ -3898,1 +3877,1 @@\n-        ScopedMemoryAccess.storeIntoByteBufferMasked(\n+        ScopedMemoryAccess.storeIntoMemorySegmentMasked(\n@@ -3900,5 +3879,4 @@\n-                this, m, bb, offset,\n-                (buf, off, v, vm) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    v.stOp(wb, off, vm,\n-                            (wb_, o, i, e) -> wb_.putShort(o + i * 2, e));\n+                this, m,\n+                (MemorySegmentProxy) ms, offset,\n+                (msp, off, v, vm) -> {\n+                    v.stLongOp((MemorySegment) msp, off, vm, ShortVector::memorySegmentSet);\n@@ -3922,1 +3900,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -3938,0 +3916,10 @@\n+    private static\n+    void checkMaskFromIndexSize(long offset,\n+                                ShortSpecies vsp,\n+                                VectorMask<Short> m,\n+                                int scale,\n+                                long limit) {\n+        ((AbstractMask<Short>)m)\n+            .checkIndexByLane(offset, limit, vsp.iota(), scale);\n+    }\n+\n@@ -4145,1 +4133,1 @@\n-                VectorSupport.broadcastCoerced(\n+                VectorSupport.fromBitsCoerced(\n@@ -4147,1 +4135,1 @@\n-                    bits, this,\n+                    bits, MODE_BROADCAST, this,\n@@ -4264,0 +4252,15 @@\n+        \/*package-private*\/\n+        @ForceInline\n+        ShortVector ldLongOp(MemorySegment memory, long offset,\n+                                      FLdLongOp f) {\n+            return dummyVector().ldLongOp(memory, offset, f);\n+        }\n+\n+        \/*package-private*\/\n+        @ForceInline\n+        ShortVector ldLongOp(MemorySegment memory, long offset,\n+                                      VectorMask<Short> m,\n+                                      FLdLongOp f) {\n+            return dummyVector().ldLongOp(memory, offset, m, f);\n+        }\n+\n@@ -4278,0 +4281,14 @@\n+        \/*package-private*\/\n+        @ForceInline\n+        void stLongOp(MemorySegment memory, long offset, FStLongOp f) {\n+            dummyVector().stLongOp(memory, offset, f);\n+        }\n+\n+        \/*package-private*\/\n+        @ForceInline\n+        void stLongOp(MemorySegment memory, long offset,\n+                      AbstractMask<Short> m,\n+                      FStLongOp f) {\n+            dummyVector().stLongOp(memory, offset, m, f);\n+        }\n+\n@@ -4339,6 +4356,6 @@\n-        switch (s) {\n-            case S_64_BIT: return (ShortSpecies) SPECIES_64;\n-            case S_128_BIT: return (ShortSpecies) SPECIES_128;\n-            case S_256_BIT: return (ShortSpecies) SPECIES_256;\n-            case S_512_BIT: return (ShortSpecies) SPECIES_512;\n-            case S_Max_BIT: return (ShortSpecies) SPECIES_MAX;\n+        switch (s.switchKey) {\n+            case VectorShape.SK_64_BIT: return (ShortSpecies) SPECIES_64;\n+            case VectorShape.SK_128_BIT: return (ShortSpecies) SPECIES_128;\n+            case VectorShape.SK_256_BIT: return (ShortSpecies) SPECIES_256;\n+            case VectorShape.SK_512_BIT: return (ShortSpecies) SPECIES_512;\n+            case VectorShape.SK_Max_BIT: return (ShortSpecies) SPECIES_MAX;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":348,"deletions":331,"binary":false,"changes":679,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,2 @@\n-import java.nio.ByteBuffer;\n+import jdk.incubator.foreign.MemorySegment;\n+\n@@ -766,1 +767,1 @@\n- * in a {@link java.nio.ByteBuffer}.\n+ * in a {@link jdk.incubator.foreign.MemorySegment}.\n@@ -770,1 +771,1 @@\n- * within the array or buffer that holds the vector, producing the\n+ * within the array or segment that holds the vector, producing the\n@@ -1042,0 +1043,6 @@\n+ * <li>The {@link #compress(VectorMask)} and {@link #expand(VectorMask)}\n+ * methods, which select up to {@code VLENGTH} lanes from an\n+ * input vector, and assemble them in lane order.  The selection of lanes\n+ * is controlled by a {@code VectorMask}, with set lane elements mapping, by\n+ * compression or expansion in lane order, source lanes to destination lanes.\n+ *\n@@ -2692,0 +2699,40 @@\n+    \/**\n+     * Compresses the lane elements of this vector selecting lanes\n+     * under the control of a specific mask.\n+     *\n+     * This is a cross-lane operation that compresses the lane\n+     * elements of this vector as selected by the specified mask.\n+     *\n+     * For each lane {@code N} of the mask, if the mask at\n+     * lane {@code N} is set, the element at lane {@code N}\n+     * of input vector is selected and stored into the output\n+     * vector contiguously starting from the lane {@code 0}.\n+     * All the upper remaining lanes, if any, of the output\n+     * vector are set to zero.\n+     *\n+     * @param m the mask controlling the compression\n+     * @return the compressed lane elements of this vector\n+     * @since 19\n+     *\/\n+    public abstract Vector<E> compress(VectorMask<E> m);\n+\n+    \/**\n+     * Expands the lane elements of this vector\n+     * under the control of a specific mask.\n+     *\n+     * This is a cross-lane operation that expands the contiguous lane\n+     * elements of this vector into lanes of an output vector\n+     * as selected by the specified mask.\n+     *\n+     * For each lane {@code N} of the mask, if the mask at\n+     * lane {@code N} is set, the next contiguous element of input vector\n+     * starting from lane {@code 0} is selected and stored into the output\n+     * vector at lane {@code N}.\n+     * All the remaining lanes, if any, of the output vector are set to zero.\n+     *\n+     * @param m the mask controlling the compression\n+     * @return the expanded lane elements of this vector\n+     * @since 19\n+     *\/\n+    public abstract Vector<E> expand(VectorMask<E> m);\n+\n@@ -2857,3 +2904,2 @@\n-     * buffer or array using little-endian byte ordering and then the\n-     * desired vector is loaded from the same byte buffer or array\n-     * using the same ordering.\n+     * array using little-endian byte ordering and then the desired vector is loaded from the same byte\n+     * array using the same ordering.\n@@ -2868,1 +2914,1 @@\n-     * byte[] ra = new byte[Math.max(domSize, ranSize)];\n+     * MemorySegment ms = MemorySegment.ofArray(new byte[Math.max(domSize, ranSize)]);\n@@ -2870,1 +2916,1 @@\n-     *     this.intoByteArray(ra, 0, ByteOrder.native());\n+     *     this.intoMemorySegment(ms, 0, ByteOrder.native());\n@@ -2872,1 +2918,1 @@\n-     *     return species.fromByteArray(ra, origin, ByteOrder.native());\n+     *     return species.fromMemorySegment(ms, origin, ByteOrder.native());\n@@ -2875,2 +2921,2 @@\n-     *     this.intoByteArray(ra, origin, ByteOrder.native());\n-     *     return species.fromByteArray(ra, 0, ByteOrder.native());\n+     *     this.intoMemorySegment(ms, origin, ByteOrder.native());\n+     *     return species.fromMemorySegment(ms, 0, ByteOrder.native());\n@@ -2913,2 +2959,2 @@\n-     * @see IntVector#intoByteArray(byte[], int, ByteOrder)\n-     * @see FloatVector#intoByteArray(byte[], int, ByteOrder)\n+     * @see IntVector#intoMemorySegment(jdk.incubator.foreign.MemorySegment, long, java.nio.ByteOrder)\n+     * @see FloatVector#intoMemorySegment(jdk.incubator.foreign.MemorySegment, long, java.nio.ByteOrder)\n@@ -3335,2 +3381,2 @@\n-     * Stores this vector into a byte array starting at an offset\n-     * using explicit byte order.\n+     * Stores this vector into a {@linkplain MemorySegment memory segment}\n+     * starting at an offset using explicit byte order.\n@@ -3344,2 +3390,2 @@\n-     * {@link #intoByteBuffer(ByteBuffer,int,ByteOrder,VectorMask)\n-     * intoByteBuffer()} as follows:\n+     * {@link #intoMemorySegment(MemorySegment,long,ByteOrder,VectorMask)\n+     * intoMemorySegment()} as follows:\n@@ -3347,2 +3393,1 @@\n-     * var bb = ByteBuffer.wrap(a);\n-     * intoByteBuffer(bb, offset, bo, m);\n+     * intoMemorySegment(ms, offset, bo, m);\n@@ -3352,2 +3397,2 @@\n-     * @param a the byte array\n-     * @param offset the offset into the array\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -3357,1 +3402,1 @@\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n+     *         or {@code offset+(N+1)*ESIZE > ms.byteSize()}\n@@ -3359,0 +3404,7 @@\n+     * @throws UnsupportedOperationException\n+     *         if the memory segment is read-only\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -3360,2 +3412,1 @@\n-    public abstract void intoByteArray(byte[] a, int offset,\n-                                       ByteOrder bo);\n+    public abstract void intoMemorySegment(MemorySegment ms, long offset, ByteOrder bo);\n@@ -3364,62 +3415,2 @@\n-     * Stores this vector into a byte array starting at an offset\n-     * using explicit byte order and a mask.\n-     * <p>\n-     * Bytes are extracted from primitive lane elements according\n-     * to the specified byte ordering.\n-     * The lanes are stored according to their\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it calls\n-     * {@link #intoByteBuffer(ByteBuffer,int,ByteOrder,VectorMask)\n-     * intoByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * intoByteBuffer(bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @param m the mask controlling lane selection\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *         where the mask is set\n-     *\/\n-    public abstract void intoByteArray(byte[] a, int offset,\n-                                       ByteOrder bo,\n-                                       VectorMask<E> m);\n-\n-    \/**\n-     * Stores this vector into a byte buffer starting at an offset\n-     * using explicit byte order.\n-     * <p>\n-     * Bytes are extracted from primitive lane elements according\n-     * to the specified byte ordering.\n-     * The lanes are stored according to their\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it calls\n-     * {@link #intoByteBuffer(ByteBuffer,int,ByteOrder,VectorMask)\n-     * intoByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var m = maskAll(true);\n-     * intoByteBuffer(bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param bb the byte buffer\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > bb.limit()}\n-     *         for any lane {@code N} in the vector\n-     * @throws java.nio.ReadOnlyBufferException\n-     *         if the byte buffer is read-only\n-     *\/\n-    public abstract void intoByteBuffer(ByteBuffer bb, int offset, ByteOrder bo);\n-\n-    \/**\n-     * Stores this vector into a byte buffer starting at an offset\n-     * using explicit byte order and a mask.\n+     * Stores this vector into a {@linkplain MemorySegment memory segment}\n+     * starting at an offset using explicit byte order and a mask.\n@@ -3433,2 +3424,1 @@\n-     * the primitive element type is not of {@code byte},\n-     * {@code EBuffer} is the primitive buffer type, {@code ETYPE} is the\n+     * {@code JAVA_E} is the layout of the primitive element type, {@code ETYPE} is the\n@@ -3438,3 +3428,1 @@\n-     * EBuffer eb = bb.duplicate()\n-     *     .position(offset)\n-     *     .order(bo).asEBuffer();\n+     * var slice = ms.asSlice(offset)\n@@ -3444,1 +3432,1 @@\n-     *         eb.put(n, a[n]);\n+     *         slice.setAtIndex(ValueLayout.JAVA_E.withBitAlignment(8), n);\n@@ -3448,7 +3436,0 @@\n-     * When the primitive element type is of {@code byte} the primitive\n-     * byte buffer is obtained as follows, where operation on the buffer\n-     * remains the same as in the prior pseudocode:\n-     * <pre>{@code\n-     * ByteBuffer eb = bb.duplicate()\n-     *     .position(offset);\n-     * }<\/pre>\n@@ -3467,2 +3448,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the array\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -3473,1 +3454,1 @@\n-     *         or {@code offset+(N+1)*ESIZE > bb.limit()}\n+     *         or {@code offset+(N+1)*ESIZE > ms.byteSize()}\n@@ -3476,5 +3457,10 @@\n-     * @throws java.nio.ReadOnlyBufferException\n-     *         if the byte buffer is read-only\n-     *\/\n-    public abstract void intoByteBuffer(ByteBuffer bb, int offset,\n-                                        ByteOrder bo, VectorMask<E> m);\n+     * @throws UnsupportedOperationException\n+     *         if the memory segment is read-only\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n+     *\/\n+    public abstract void intoMemorySegment(MemorySegment ms, long offset,\n+                                           ByteOrder bo, VectorMask<E> m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Vector.java","additions":94,"deletions":108,"binary":false,"changes":202,"status":"modified"},{"patch":"@@ -60,0 +60,10 @@\n+    @ForceInline\n+    static long checkFromIndexSize(long ix, long vlen, long length) {\n+        switch (VectorIntrinsics.VECTOR_ACCESS_OOB_CHECK) {\n+            case 0: return ix; \/\/ no range check\n+            case 1: return Objects.checkFromIndexSize(ix, vlen, length);\n+            case 2: return Objects.checkIndex(ix, length - (vlen - 1));\n+            default: throw new InternalError();\n+        }\n+    }\n+\n@@ -98,1 +108,1 @@\n-            return index - Math.floorMod(index, Math.abs(size));\n+            return index - Math.floorMod(index, size);\n@@ -101,0 +111,21 @@\n+\n+    \/\/ If the index is not already a multiple of size,\n+    \/\/ round it down to the next smaller multiple of size.\n+    \/\/ It is an error if size is less than zero.\n+    @ForceInline\n+    static long roundDown(long index, int size) {\n+        if ((size & (size - 1)) == 0) {\n+            \/\/ Size is zero or a power of two, so we got this.\n+            return index & ~(size - 1);\n+        } else {\n+            return roundDownNPOT(index, size);\n+        }\n+    }\n+    private static long roundDownNPOT(long index, int size) {\n+        if (index >= 0) {\n+            return index - (index % size);\n+        } else {\n+            return index - Math.floorMod(index, size);\n+        }\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/VectorIntrinsics.java","additions":32,"deletions":1,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,2 +27,0 @@\n-import java.nio.ByteBuffer;\n-import java.nio.ReadOnlyBufferException;\n@@ -33,1 +31,3 @@\n-import java.util.function.UnaryOperator;\n+import jdk.incubator.foreign.MemorySegment;\n+import jdk.incubator.foreign.ValueLayout;\n+import jdk.internal.access.foreign.MemorySegmentProxy;\n@@ -64,0 +64,2 @@\n+    static final ValueLayout.Of$Elemtype$ ELEMENT_LAYOUT = ValueLayout.JAVA_$TYPE$.withBitAlignment(8);\n+\n@@ -358,0 +360,39 @@\n+    \/*package-private*\/\n+    interface FLdLongOp {\n+        $type$ apply(MemorySegment memory, long offset, int i);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    $abstractvectortype$ ldLongOp(MemorySegment memory, long offset,\n+                                  FLdLongOp f) {\n+        \/\/dummy; no vec = vec();\n+        $type$[] res = new $type$[length()];\n+        for (int i = 0; i < res.length; i++) {\n+            res[i] = f.apply(memory, offset, i);\n+        }\n+        return vectorFactory(res);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    $abstractvectortype$ ldLongOp(MemorySegment memory, long offset,\n+                                  VectorMask<$Boxtype$> m,\n+                                  FLdLongOp f) {\n+        \/\/$type$[] vec = vec();\n+        $type$[] res = new $type$[length()];\n+        boolean[] mbits = ((AbstractMask<$Boxtype$>)m).getBits();\n+        for (int i = 0; i < res.length; i++) {\n+            if (mbits[i]) {\n+                res[i] = f.apply(memory, offset, i);\n+            }\n+        }\n+        return vectorFactory(res);\n+    }\n+\n+    static $type$ memorySegmentGet(MemorySegment ms, long o, int i) {\n+        return ms.get(ELEMENT_LAYOUT, o + i * $sizeInBytes$L);\n+    }\n+\n@@ -388,0 +429,34 @@\n+    interface FStLongOp {\n+        void apply(MemorySegment memory, long offset, int i, $type$ a);\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    void stLongOp(MemorySegment memory, long offset,\n+                  FStLongOp f) {\n+        $type$[] vec = vec();\n+        for (int i = 0; i < vec.length; i++) {\n+            f.apply(memory, offset, i, vec[i]);\n+        }\n+    }\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    void stLongOp(MemorySegment memory, long offset,\n+                  VectorMask<$Boxtype$> m,\n+                  FStLongOp f) {\n+        $type$[] vec = vec();\n+        boolean[] mbits = ((AbstractMask<$Boxtype$>)m).getBits();\n+        for (int i = 0; i < vec.length; i++) {\n+            if (mbits[i]) {\n+                f.apply(memory, offset, i, vec[i]);\n+            }\n+        }\n+    }\n+\n+    static void memorySegmentSet(MemorySegment ms, long o, int i, $type$ e) {\n+        ms.set(ELEMENT_LAYOUT, o + i * $sizeInBytes$L, e);\n+    }\n+\n@@ -448,0 +523,30 @@\n+    static $abstractvectortype$ expandHelper(Vector<$Boxtype$> v, VectorMask<$Boxtype$> m) {\n+        VectorSpecies<$Boxtype$> vsp = m.vectorSpecies();\n+        $abstractvectortype$ r  = ($abstractvectortype$) vsp.zero();\n+        $abstractvectortype$ vi = ($abstractvectortype$) v;\n+        if (m.allTrue()) {\n+            return vi;\n+        }\n+        for (int i = 0, j = 0; i < vsp.length(); i++) {\n+            if (m.laneIsSet(i)) {\n+                r = r.withLane(i, vi.lane(j++));\n+            }\n+        }\n+        return r;\n+    }\n+\n+    static $abstractvectortype$ compressHelper(Vector<$Boxtype$> v, VectorMask<$Boxtype$> m) {\n+        VectorSpecies<$Boxtype$> vsp = m.vectorSpecies();\n+        $abstractvectortype$ r  = ($abstractvectortype$) vsp.zero();\n+        $abstractvectortype$ vi = ($abstractvectortype$) v;\n+        if (m.allTrue()) {\n+            return vi;\n+        }\n+        for (int i = 0, j = 0; i < vsp.length(); i++) {\n+            if (m.laneIsSet(i)) {\n+                r = r.withLane(j++, vi.lane(i));\n+            }\n+        }\n+        return r;\n+    }\n+\n@@ -474,2 +579,2 @@\n-        return VectorSupport.broadcastCoerced(vsp.vectorType(), Halffloat.class, species.length(),\n-                        toBits((short)0), vsp,\n+        return VectorSupport.fromBitsCoerced(vsp.vectorType(), Halffloat.class, species.length(),\n+                        toBits((short)0), MODE_BROADCAST, vsp,\n@@ -478,2 +583,2 @@\n-        return VectorSupport.broadcastCoerced(vsp.vectorType(), $type$.class, species.length(),\n-                        toBits(0.0f), vsp,\n+        return VectorSupport.fromBitsCoerced(vsp.vectorType(), $type$.class, species.length(),\n+                        toBits(0.0f), MODE_BROADCAST, vsp,\n@@ -483,2 +588,2 @@\n-        return VectorSupport.broadcastCoerced(vsp.vectorType(), $type$.class, species.length(),\n-                                0, vsp,\n+        return VectorSupport.fromBitsCoerced(vsp.vectorType(), $type$.class, species.length(),\n+                                0, MODE_BROADCAST, vsp,\n@@ -605,3 +710,0 @@\n-            } else if (op == NEG) {\n-                \/\/ FIXME: Support this in the JIT.\n-                return broadcast(0).lanewise(SUB, this);\n@@ -638,2 +740,0 @@\n-            } else if (op == NEG) {\n-                return lanewise(NOT, m).lanewise(ADD, broadcast(1), m);\n@@ -660,0 +760,30 @@\n+#if[!FP]\n+#if[intOrLong]\n+            case VECTOR_OP_BIT_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) $Boxtype$.bitCount(a));\n+            case VECTOR_OP_TZ_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) $Boxtype$.numberOfTrailingZeros(a));\n+            case VECTOR_OP_LZ_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) $Boxtype$.numberOfLeadingZeros(a));\n+            case VECTOR_OP_REVERSE: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) $Boxtype$.reverse(a));\n+#else[intOrLong]\n+            case VECTOR_OP_BIT_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) bitCount(a));\n+            case VECTOR_OP_TZ_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) numberOfTrailingZeros(a));\n+            case VECTOR_OP_LZ_COUNT: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) numberOfLeadingZeros(a));\n+            case VECTOR_OP_REVERSE: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> reverse(a));\n+#end[intOrLong]\n+#if[BITWISE]\n+#if[byte]\n+            case VECTOR_OP_REVERSE_BYTES: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> a);\n+#else[byte]\n+            case VECTOR_OP_REVERSE_BYTES: return (v0, m) ->\n+                    v0.uOp(m, (i, a) -> ($type$) $Boxtype$.reverseBytes(a));\n+#end[byte]\n+#end[BITWISE]\n+#end[!FP]\n@@ -883,0 +1013,6 @@\n+#if[intOrLong]\n+            case VECTOR_OP_COMPRESS_BITS: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> $Boxtype$.compress(a, n));\n+            case VECTOR_OP_EXPAND_BITS: return (v0, v1, vm) ->\n+                    v0.bOp(v1, vm, (i, a, n) -> $Boxtype$.expand(a, n));\n+#end[intOrLong]\n@@ -2039,0 +2175,50 @@\n+#if[!FP]\n+#if[!intOrLong]\n+    static int bitCount($type$ a) {\n+#if[short]\n+        return Integer.bitCount((int)a & 0xFFFF);\n+#else[short]\n+        return Integer.bitCount((int)a & 0xFF);\n+#end[short]\n+    }\n+#end[!intOrLong]\n+#end[!FP]\n+#if[!FP]\n+#if[!intOrLong]\n+    static int numberOfTrailingZeros($type$ a) {\n+#if[short]\n+        return a != 0 ? Integer.numberOfTrailingZeros(a) : 16;\n+#else[short]\n+        return a != 0 ? Integer.numberOfTrailingZeros(a) : 8;\n+#end[short]\n+    }\n+#end[!intOrLong]\n+#end[!FP]\n+#if[!FP]\n+#if[!intOrLong]\n+    static int numberOfLeadingZeros($type$ a) {\n+#if[short]\n+        return a >= 0 ? Integer.numberOfLeadingZeros(a) - 16 : 0;\n+#else[short]\n+        return a >= 0 ? Integer.numberOfLeadingZeros(a) - 24 : 0;\n+#end[short]\n+    }\n+\n+    static $type$ reverse($type$ a) {\n+        if (a == 0 || a == -1) return a;\n+\n+#if[short]\n+        $type$ b = rotateLeft(a, 8);\n+        b = ($type$) (((b & 0x5555) << 1) | ((b & 0xAAAA) >>> 1));\n+        b = ($type$) (((b & 0x3333) << 2) | ((b & 0xCCCC) >>> 2));\n+        b = ($type$) (((b & 0x0F0F) << 4) | ((b & 0xF0F0) >>> 4));\n+#else[short]\n+        $type$ b = rotateLeft(a, 4);\n+        b = ($type$) (((b & 0x55) << 1) | ((b & 0xAA) >>> 1));\n+        b = ($type$) (((b & 0x33) << 2) | ((b & 0xCC) >>> 2));\n+#end[short]\n+        return b;\n+    }\n+#end[!intOrLong]\n+#end[!FP]\n+\n@@ -2175,0 +2361,1 @@\n+#if[FP]\n@@ -2176,0 +2363,1 @@\n+#end[FP]\n@@ -2178,1 +2366,1 @@\n-                m = bits.compare(EQ, ($bitstype$) 0);\n+                m = {#if[FP]?bits.}compare(EQ, ($bitstype$) 0);\n@@ -2180,1 +2368,1 @@\n-                m = bits.compare(LT, ($bitstype$) 0);\n+                m = {#if[FP]?bits.}compare(LT, ($bitstype$) 0);\n@@ -2203,1 +2391,1 @@\n-            return maskType.cast(m{#if[FP]?.cast(this.vspecies())});\n+            return maskType.cast(m{#if[FP]?.cast(vsp)});\n@@ -2213,2 +2401,1 @@\n-    @ForceInline\n-    public final\n+    public abstract\n@@ -2216,2 +2403,46 @@\n-                                  VectorMask<$Boxtype$> m) {\n-        return test(op).and(m);\n+                                  VectorMask<$Boxtype$> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends VectorMask<$Boxtype$>>\n+    M testTemplate(Class<M> maskType, Test op, M mask) {\n+        $Type$Species vsp = vspecies();\n+        mask.check(maskType, this);\n+        if (opKind(op, VO_SPECIAL)) {\n+#if[FP]\n+            $Bitstype$Vector bits = this.viewAsIntegralLanes();\n+            VectorMask<$Boxbitstype$> m = mask.cast($Bitstype$Vector.species(shape()));\n+#else[FP]\n+            VectorMask<$Boxbitstype$> m = mask;\n+#end[FP]\n+            if (op == IS_DEFAULT) {\n+                m = {#if[FP]?bits.}compare(EQ, ($bitstype$) 0, m);\n+            } else if (op == IS_NEGATIVE) {\n+                m = {#if[FP]?bits.}compare(LT, ($bitstype$) 0, m);\n+            }\n+#if[FP]\n+            else if (op == IS_FINITE ||\n+                     op == IS_NAN ||\n+                     op == IS_INFINITE) {\n+                \/\/ first kill the sign:\n+                bits = bits.and($Boxbitstype$.MAX_VALUE);\n+                \/\/ next find the bit pattern for infinity:\n+                $bitstype$ infbits = ($bitstype$) toBits($Boxtype$.POSITIVE_INFINITY);\n+                \/\/ now compare:\n+                if (op == IS_FINITE) {\n+                    m = bits.compare(LT, infbits, m);\n+                } else if (op == IS_NAN) {\n+                    m = bits.compare(GT, infbits, m);\n+                } else {\n+                    m = bits.compare(EQ, infbits, m);\n+                }\n+            }\n+#end[FP]\n+            else {\n+                throw new AssertionError(op);\n+            }\n+            return maskType.cast(m{#if[FP]?.cast(vsp)});\n+        }\n+        int opc = opCode(op);\n+        throw new AssertionError(op);\n@@ -2721,0 +2952,39 @@\n+    \/**\n+     * {@inheritDoc} <!--workaround-->\n+     * @since 19\n+     *\/\n+    @Override\n+    public abstract\n+    $Type$Vector compress(VectorMask<$Boxtype$> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends AbstractMask<$Boxtype$>>\n+    $Type$Vector compressTemplate(Class<M> masktype, M m) {\n+      m.check(masktype, this);\n+      return ($Type$Vector) VectorSupport.comExpOp(VectorSupport.VECTOR_OP_COMPRESS, getClass(), masktype,\n+                                                   $elemtype$.class, length(), this, m,\n+                                                   (v1, m1) -> compressHelper(v1, m1));\n+    }\n+\n+    \/**\n+     * {@inheritDoc} <!--workaround-->\n+     * @since 19\n+     *\/\n+    @Override\n+    public abstract\n+    $Type$Vector expand(VectorMask<$Boxtype$> m);\n+\n+    \/*package-private*\/\n+    @ForceInline\n+    final\n+    <M extends AbstractMask<$Boxtype$>>\n+    $Type$Vector expandTemplate(Class<M> masktype, M m) {\n+      m.check(masktype, this);\n+      return ($Type$Vector) VectorSupport.comExpOp(VectorSupport.VECTOR_OP_EXPAND, getClass(), masktype,\n+                                                   $elemtype$.class, length(), this, m,\n+                                                   (v1, m1) -> expandHelper(v1, m1));\n+    }\n+\n+\n@@ -3087,1 +3357,2 @@\n-            $abstractvectortype$ v = reduceIdentityVector(op).blend(this, m);\n+            \/\/ FIXME:  The JIT should handle this.\n+            $abstractvectortype$ v = broadcast(($type$) 0).blend(this, m);\n@@ -3102,1 +3373,1 @@\n-            \/\/ FIXME:  The JIT should handle this, and other scan ops alos.\n+            \/\/ FIXME:  The JIT should handle this.\n@@ -3105,1 +3376,2 @@\n-            return this.lane(thisNZ.firstTrue());\n+            int ft = thisNZ.firstTrue();\n+            return ft < length() ? this.lane(ft) : ($type$) 0;\n@@ -3162,32 +3434,0 @@\n-    private\n-    @ForceInline\n-    $abstractvectortype$ reduceIdentityVector(VectorOperators.Associative op) {\n-        int opc = opCode(op);\n-        UnaryOperator<$abstractvectortype$> fn\n-            = REDUCE_ID_IMPL.find(op, opc, (opc_) -> {\n-                switch (opc_) {\n-                case VECTOR_OP_ADD:\n-#if[BITWISE]\n-                case VECTOR_OP_OR:\n-                case VECTOR_OP_XOR:\n-#end[BITWISE]\n-                    return v -> v.broadcast(0);\n-                case VECTOR_OP_MUL:\n-                    return v -> v.broadcast(1);\n-#if[BITWISE]\n-                case VECTOR_OP_AND:\n-                    return v -> v.broadcast(-1);\n-#end[BITWISE]\n-                case VECTOR_OP_MIN:\n-                    return v -> v.broadcast(MAX_OR_INF);\n-                case VECTOR_OP_MAX:\n-                    return v -> v.broadcast(MIN_OR_INF);\n-                default: return null;\n-                }\n-            });\n-        return fn.apply(this);\n-    }\n-    private static final\n-    ImplCache<Associative,UnaryOperator<$abstractvectortype$>> REDUCE_ID_IMPL\n-        = new ImplCache<>(Associative.class, $Type$Vector.class);\n-\n@@ -3380,84 +3620,0 @@\n-    \/**\n-     * Loads a vector from a byte array starting at an offset.\n-     * Bytes are composed into primitive lane elements according\n-     * to the specified byte order.\n-     * The vector is arranged into lanes according to\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it returns the result of calling\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * var m = species.maskAll(true);\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param species species of desired vector\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @return a vector loaded from a byte array\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *\/\n-    @ForceInline\n-    public static\n-    $abstractvectortype$ fromByteArray(VectorSpecies<$Boxtype$> species,\n-                                       byte[] a, int offset,\n-                                       ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, species.vectorByteSize(), a.length);\n-        $Type$Species vsp = ($Type$Species) species;\n-        return vsp.dummyVector().fromByteArray0(a, offset).maybeSwap(bo);\n-    }\n-\n-    \/**\n-     * Loads a vector from a byte array starting at an offset\n-     * and using a mask.\n-     * Lanes where the mask is unset are filled with the default\n-     * value of {@code $type$} ({#if[FP]?positive }zero).\n-     * Bytes are composed into primitive lane elements according\n-     * to the specified byte order.\n-     * The vector is arranged into lanes according to\n-     * <a href=\"Vector.html#lane-order\">memory ordering<\/a>.\n-     * <p>\n-     * This method behaves as if it returns the result of calling\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n-     * <pre>{@code\n-     * var bb = ByteBuffer.wrap(a);\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n-     * }<\/pre>\n-     *\n-     * @param species species of desired vector\n-     * @param a the byte array\n-     * @param offset the offset into the array\n-     * @param bo the intended byte order\n-     * @param m the mask controlling lane selection\n-     * @return a vector loaded from a byte array\n-     * @throws IndexOutOfBoundsException\n-     *         if {@code offset+N*ESIZE < 0}\n-     *         or {@code offset+(N+1)*ESIZE > a.length}\n-     *         for any lane {@code N} in the vector\n-     *         where the mask is set\n-     *\/\n-    @ForceInline\n-    public static\n-    $abstractvectortype$ fromByteArray(VectorSpecies<$Boxtype$> species,\n-                                       byte[] a, int offset,\n-                                       ByteOrder bo,\n-                                       VectorMask<$Boxtype$> m) {\n-        $Type$Species vsp = ($Type$Species) species;\n-        if (offset >= 0 && offset <= (a.length - species.vectorByteSize())) {\n-            return vsp.dummyVector().fromByteArray0(a, offset, m).maybeSwap(bo);\n-        }\n-\n-        \/\/ FIXME: optimize\n-        checkMaskFromIndexSize(offset, vsp, m, $sizeInBytes$, a.length);\n-        ByteBuffer wb = wrapper(a, bo);\n-        return vsp.ldOp(wb, offset, (AbstractMask<$Boxtype$>)m,\n-                   (wb_, o, i)  -> wb_.get{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$));\n-    }\n-\n@@ -3995,2 +4151,2 @@\n-     * Loads a vector from a {@linkplain ByteBuffer byte buffer}\n-     * starting at an offset into the byte buffer.\n+     * Loads a vector from a {@linkplain MemorySegment memory segment}\n+     * starting at an offset into the memory segment.\n@@ -4003,2 +4159,2 @@\n-     * {@link #fromByteBuffer(VectorSpecies,ByteBuffer,int,ByteOrder,VectorMask)\n-     * fromByteBuffer()} as follows:\n+     * {@link #fromMemorySegment(VectorSpecies,MemorySegment,long,ByteOrder,VectorMask)\n+     * fromMemorySegment()} as follows:\n@@ -4007,1 +4163,1 @@\n-     * return fromByteBuffer(species, bb, offset, bo, m);\n+     * return fromMemorySegment(species, ms, offset, bo, m);\n@@ -4011,2 +4167,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the byte buffer\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -4014,1 +4170,1 @@\n-     * @return a vector loaded from a byte buffer\n+     * @return a vector loaded from the memory segment\n@@ -4017,1 +4173,1 @@\n-     *         or {@code offset+N*$sizeInBytes$ >= bb.limit()}\n+     *         or {@code offset+N*$sizeInBytes$ >= ms.byteSize()}\n@@ -4019,0 +4175,5 @@\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -4022,4 +4183,4 @@\n-    $abstractvectortype$ fromByteBuffer(VectorSpecies<$Boxtype$> species,\n-                                        ByteBuffer bb, int offset,\n-                                        ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, species.vectorByteSize(), bb.limit());\n+    $abstractvectortype$ fromMemorySegment(VectorSpecies<$Boxtype$> species,\n+                                           MemorySegment ms, long offset,\n+                                           ByteOrder bo) {\n+        offset = checkFromIndexSize(offset, species.vectorByteSize(), ms.byteSize());\n@@ -4027,1 +4188,1 @@\n-        return vsp.dummyVector().fromByteBuffer0(bb, offset).maybeSwap(bo);\n+        return vsp.dummyVector().fromMemorySegment0(ms, offset).maybeSwap(bo);\n@@ -4031,2 +4192,2 @@\n-     * Loads a vector from a {@linkplain ByteBuffer byte buffer}\n-     * starting at an offset into the byte buffer\n+     * Loads a vector from a {@linkplain MemorySegment memory segment}\n+     * starting at an offset into the memory segment\n@@ -4043,5 +4204,1 @@\n-     * $Type$Buffer eb = bb.duplicate()\n-     *     .position(offset){#if[byte]?;}\n-#if[!byte]\n-     *     .order(bo).as$Type$Buffer();\n-#end[!byte]\n+     * var slice = ms.asSlice(offset);\n@@ -4051,1 +4208,1 @@\n-     *         ar[n] = eb.get(n);\n+     *         ar[n] = slice.getAtIndex(ValuaLayout.JAVA_$TYPE$.withBitAlignment(8), n);\n@@ -4069,2 +4226,2 @@\n-     * @param bb the byte buffer\n-     * @param offset the offset into the byte buffer\n+     * @param ms the memory segment\n+     * @param offset the offset into the memory segment\n@@ -4073,1 +4230,1 @@\n-     * @return a vector loaded from a byte buffer\n+     * @return a vector loaded from the memory segment\n@@ -4076,1 +4233,1 @@\n-     *         or {@code offset+N*$sizeInBytes$ >= bb.limit()}\n+     *         or {@code offset+N*$sizeInBytes$ >= ms.byteSize()}\n@@ -4079,0 +4236,5 @@\n+     * @throws IllegalArgumentException if the memory segment is a heap segment that is\n+     *         not backed by a {@code byte[]} array.\n+     * @throws IllegalStateException if the memory segment's session is not alive,\n+     *         or if access occurs from a thread other than the thread owning the session.\n+     * @since 19\n@@ -4082,4 +4244,4 @@\n-    $abstractvectortype$ fromByteBuffer(VectorSpecies<$Boxtype$> species,\n-                                        ByteBuffer bb, int offset,\n-                                        ByteOrder bo,\n-                                        VectorMask<$Boxtype$> m) {\n+    $abstractvectortype$ fromMemorySegment(VectorSpecies<$Boxtype$> species,\n+                                           MemorySegment ms, long offset,\n+                                           ByteOrder bo,\n+                                           VectorMask<$Boxtype$> m) {\n@@ -4087,2 +4249,2 @@\n-        if (offset >= 0 && offset <= (bb.limit() - species.vectorByteSize())) {\n-            return vsp.dummyVector().fromByteBuffer0(bb, offset, m).maybeSwap(bo);\n+        if (offset >= 0 && offset <= (ms.byteSize() - species.vectorByteSize())) {\n+            return vsp.dummyVector().fromMemorySegment0(ms, offset, m).maybeSwap(bo);\n@@ -4092,4 +4254,2 @@\n-        checkMaskFromIndexSize(offset, vsp, m, $sizeInBytes$, bb.limit());\n-        ByteBuffer wb = wrapper(bb, bo);\n-        return vsp.ldOp(wb, offset, (AbstractMask<$Boxtype$>)m,\n-                   (wb_, o, i)  -> wb_.get{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$));\n+        checkMaskFromIndexSize(offset, vsp, m, $sizeInBytes$, ms.byteSize());\n+        return vsp.ldLongOp(ms, offset, m, $abstractvectortype$::memorySegmentGet);\n@@ -4125,1 +4285,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -4342,1 +4502,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -4501,1 +4661,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -4640,0 +4800,1 @@\n+     * @since 19\n@@ -4644,21 +4805,4 @@\n-    void intoByteArray(byte[] a, int offset,\n-                       ByteOrder bo) {\n-        offset = checkFromIndexSize(offset, byteSize(), a.length);\n-        maybeSwap(bo).intoByteArray0(a, offset);\n-    }\n-\n-    \/**\n-     * {@inheritDoc} <!--workaround-->\n-     *\/\n-    @Override\n-    @ForceInline\n-    public final\n-    void intoByteArray(byte[] a, int offset,\n-                       ByteOrder bo,\n-                       VectorMask<$Boxtype$> m) {\n-        if (m.allTrue()) {\n-            intoByteArray(a, offset, bo);\n-        } else {\n-            $Type$Species vsp = vspecies();\n-            checkMaskFromIndexSize(offset, vsp, m, $sizeInBytes$, a.length);\n-            maybeSwap(bo).intoByteArray0(a, offset, m);\n+    void intoMemorySegment(MemorySegment ms, long offset,\n+                           ByteOrder bo) {\n+        if (ms.isReadOnly()) {\n+            throw new UnsupportedOperationException(\"Attempt to write a read-only segment\");\n@@ -4666,14 +4810,2 @@\n-    }\n-    \/**\n-     * {@inheritDoc} <!--workaround-->\n-     *\/\n-    @Override\n-    @ForceInline\n-    public final\n-    void intoByteBuffer(ByteBuffer bb, int offset,\n-                        ByteOrder bo) {\n-        if (ScopedMemoryAccess.isReadOnly(bb)) {\n-            throw new ReadOnlyBufferException();\n-        }\n-        offset = checkFromIndexSize(offset, byteSize(), bb.limit());\n-        maybeSwap(bo).intoByteBuffer0(bb, offset);\n+        offset = checkFromIndexSize(offset, byteSize(), ms.byteSize());\n+        maybeSwap(bo).intoMemorySegment0(ms, offset);\n@@ -4685,0 +4817,1 @@\n+     * @since 19\n@@ -4689,3 +4822,3 @@\n-    void intoByteBuffer(ByteBuffer bb, int offset,\n-                        ByteOrder bo,\n-                        VectorMask<$Boxtype$> m) {\n+    void intoMemorySegment(MemorySegment ms, long offset,\n+                           ByteOrder bo,\n+                           VectorMask<$Boxtype$> m) {\n@@ -4693,1 +4826,1 @@\n-            intoByteBuffer(bb, offset, bo);\n+            intoMemorySegment(ms, offset, bo);\n@@ -4695,2 +4828,2 @@\n-            if (bb.isReadOnly()) {\n-                throw new ReadOnlyBufferException();\n+            if (ms.isReadOnly()) {\n+                throw new UnsupportedOperationException(\"Attempt to write a read-only segment\");\n@@ -4699,2 +4832,2 @@\n-            checkMaskFromIndexSize(offset, vsp, m, $sizeInBytes$, bb.limit());\n-            maybeSwap(bo).intoByteBuffer0(bb, offset, m);\n+            checkMaskFromIndexSize(offset, vsp, m, $sizeInBytes$, ms.byteSize());\n+            maybeSwap(bo).intoMemorySegment0(ms, offset, m);\n@@ -4734,1 +4867,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -4751,1 +4884,1 @@\n-            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+            (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -4828,1 +4961,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -4845,1 +4978,1 @@\n-                (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+                (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -4862,1 +4995,1 @@\n-            (arr, off, s) -> s.ldOp(arr, off,\n+            (arr, off, s) -> s.ldOp(arr, (int) off,\n@@ -4879,1 +5012,1 @@\n-            (arr, off, s, vm) -> s.ldOp(arr, off, vm,\n+            (arr, off, s, vm) -> s.ldOp(arr, (int) off, vm,\n@@ -4884,38 +5017,1 @@\n-    @Override\n-    abstract\n-    $abstractvectortype$ fromByteArray0(byte[] a, int offset);\n-    @ForceInline\n-    final\n-    $abstractvectortype$ fromByteArray0Template(byte[] a, int offset) {\n-        $Type$Species vsp = vspecies();\n-        return VectorSupport.load(\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            a, offset, vsp,\n-            (arr, off, s) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                return s.ldOp(wb, off,\n-                        (wb_, o, i) -> wb_.get{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$));\n-            });\n-    }\n-\n-    abstract\n-    $abstractvectortype$ fromByteArray0(byte[] a, int offset, VectorMask<$Boxtype$> m);\n-    @ForceInline\n-    final\n-    <M extends VectorMask<$Boxtype$>>\n-    $abstractvectortype$ fromByteArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n-        $Type$Species vsp = vspecies();\n-        m.check(vsp);\n-        return VectorSupport.loadMasked(\n-            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset), m,\n-            a, offset, vsp,\n-            (arr, off, s, vm) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                return s.ldOp(wb, off, vm,\n-                        (wb_, o, i) -> wb_.get{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$));\n-            });\n-    }\n-\n-    $abstractvectortype$ fromByteBuffer0(ByteBuffer bb, int offset);\n+    $abstractvectortype$ fromMemorySegment0(MemorySegment bb, long offset);\n@@ -4925,1 +5021,1 @@\n-    $abstractvectortype$ fromByteBuffer0Template(ByteBuffer bb, int offset) {\n+    $abstractvectortype$ fromMemorySegment0Template(MemorySegment ms, long offset) {\n@@ -4927,1 +5023,1 @@\n-        return ScopedMemoryAccess.loadFromByteBuffer(\n+        return ScopedMemoryAccess.loadFromMemorySegment(\n@@ -4929,5 +5025,3 @@\n-                bb, offset, vsp,\n-                (buf, off, s) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    return s.ldOp(wb, off,\n-                            (wb_, o, i) -> wb_.get{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$));\n+                (MemorySegmentProxy) ms, offset, vsp,\n+                (msp, off, s) -> {\n+                    return s.ldLongOp((MemorySegment) msp, off, $abstractvectortype$::memorySegmentGet);\n@@ -4938,1 +5032,1 @@\n-    $abstractvectortype$ fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<$Boxtype$> m);\n+    $abstractvectortype$ fromMemorySegment0(MemorySegment ms, long offset, VectorMask<$Boxtype$> m);\n@@ -4942,1 +5036,1 @@\n-    $abstractvectortype$ fromByteBuffer0Template(Class<M> maskClass, ByteBuffer bb, int offset, M m) {\n+    $abstractvectortype$ fromMemorySegment0Template(Class<M> maskClass, MemorySegment ms, long offset, M m) {\n@@ -4945,1 +5039,1 @@\n-        return ScopedMemoryAccess.loadFromByteBufferMasked(\n+        return ScopedMemoryAccess.loadFromMemorySegmentMasked(\n@@ -4947,5 +5041,3 @@\n-                bb, offset, m, vsp,\n-                (buf, off, s, vm) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    return s.ldOp(wb, off, vm,\n-                            (wb_, o, i) -> wb_.get{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$));\n+                (MemorySegmentProxy) ms, offset, m, vsp,\n+                (msp, off, s, vm) -> {\n+                    return s.ldLongOp((MemorySegment) msp, off, vm, $abstractvectortype$::memorySegmentGet);\n@@ -4970,1 +5062,1 @@\n-            -> v.stOp(arr, off,\n+            -> v.stOp(arr, (int) off,\n@@ -4987,1 +5079,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -5068,1 +5160,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -5073,19 +5165,0 @@\n-    abstract\n-    void intoByteArray0(byte[] a, int offset);\n-    @ForceInline\n-    final\n-    void intoByteArray0Template(byte[] a, int offset) {\n-        $Type$Species vsp = vspecies();\n-        VectorSupport.store(\n-            vsp.vectorType(), vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            this, a, offset,\n-            (arr, off, v) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                v.stOp(wb, off,\n-                        (tb_, o, i, e) -> tb_.put{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$, e));\n-            });\n-    }\n-\n-    abstract\n-    void intoByteArray0(byte[] a, int offset, VectorMask<$Boxtype$> m);\n@@ -5094,2 +5167,1 @@\n-    <M extends VectorMask<$Boxtype$>>\n-    void intoByteArray0Template(Class<M> maskClass, byte[] a, int offset, M m) {\n+    void intoMemorySegment0(MemorySegment ms, long offset) {\n@@ -5097,17 +5169,1 @@\n-        m.check(vsp);\n-        VectorSupport.storeMasked(\n-            vsp.vectorType(), maskClass, vsp.elementType(), vsp.laneCount(),\n-            a, byteArrayAddress(a, offset),\n-            this, m, a, offset,\n-            (arr, off, v, vm) -> {\n-                ByteBuffer wb = wrapper(arr, NATIVE_ENDIAN);\n-                v.stOp(wb, off, vm,\n-                        (tb_, o, i, e) -> tb_.put{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$, e));\n-            });\n-    }\n-\n-    @ForceInline\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset) {\n-        $Type$Species vsp = vspecies();\n-        ScopedMemoryAccess.storeIntoByteBuffer(\n+        ScopedMemoryAccess.storeIntoMemorySegment(\n@@ -5115,5 +5171,4 @@\n-                this, bb, offset,\n-                (buf, off, v) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    v.stOp(wb, off,\n-                            (wb_, o, i, e) -> wb_.put{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$, e));\n+                this,\n+                (MemorySegmentProxy) ms, offset,\n+                (msp, off, v) -> {\n+                    v.stLongOp((MemorySegment) msp, off, $abstractvectortype$::memorySegmentSet);\n@@ -5124,1 +5179,1 @@\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<$Boxtype$> m);\n+    void intoMemorySegment0(MemorySegment bb, long offset, VectorMask<$Boxtype$> m);\n@@ -5128,1 +5183,1 @@\n-    void intoByteBuffer0Template(Class<M> maskClass, ByteBuffer bb, int offset, M m) {\n+    void intoMemorySegment0Template(Class<M> maskClass, MemorySegment ms, long offset, M m) {\n@@ -5131,1 +5186,1 @@\n-        ScopedMemoryAccess.storeIntoByteBufferMasked(\n+        ScopedMemoryAccess.storeIntoMemorySegmentMasked(\n@@ -5133,5 +5188,4 @@\n-                this, m, bb, offset,\n-                (buf, off, v, vm) -> {\n-                    ByteBuffer wb = wrapper(buf, NATIVE_ENDIAN);\n-                    v.stOp(wb, off, vm,\n-                            (wb_, o, i, e) -> wb_.put{#if[byte]?(:$Elemtype$(}o + i * $sizeInBytes$, e));\n+                this, m,\n+                (MemorySegmentProxy) ms, offset,\n+                (msp, off, v, vm) -> {\n+                    v.stLongOp((MemorySegment) msp, off, vm, $abstractvectortype$::memorySegmentSet);\n@@ -5156,1 +5210,1 @@\n-            -> v.stOp(arr, off, vm,\n+            -> v.stOp(arr, (int) off, vm,\n@@ -5173,0 +5227,10 @@\n+    private static\n+    void checkMaskFromIndexSize(long offset,\n+                                $Type$Species vsp,\n+                                VectorMask<$Boxtype$> m,\n+                                int scale,\n+                                long limit) {\n+        ((AbstractMask<$Boxtype$>)m)\n+            .checkIndexByLane(offset, limit, vsp.iota(), scale);\n+    }\n+\n@@ -5423,1 +5487,1 @@\n-                VectorSupport.broadcastCoerced(\n+                VectorSupport.fromBitsCoerced(\n@@ -5425,1 +5489,1 @@\n-                    bits, this,\n+                    bits, MODE_BROADCAST, this,\n@@ -5549,0 +5613,15 @@\n+        \/*package-private*\/\n+        @ForceInline\n+        $abstractvectortype$ ldLongOp(MemorySegment memory, long offset,\n+                                      FLdLongOp f) {\n+            return dummyVector().ldLongOp(memory, offset, f);\n+        }\n+\n+        \/*package-private*\/\n+        @ForceInline\n+        $abstractvectortype$ ldLongOp(MemorySegment memory, long offset,\n+                                      VectorMask<$Boxtype$> m,\n+                                      FLdLongOp f) {\n+            return dummyVector().ldLongOp(memory, offset, m, f);\n+        }\n+\n@@ -5563,0 +5642,14 @@\n+        \/*package-private*\/\n+        @ForceInline\n+        void stLongOp(MemorySegment memory, long offset, FStLongOp f) {\n+            dummyVector().stLongOp(memory, offset, f);\n+        }\n+\n+        \/*package-private*\/\n+        @ForceInline\n+        void stLongOp(MemorySegment memory, long offset,\n+                      AbstractMask<$Boxtype$> m,\n+                      FStLongOp f) {\n+            dummyVector().stLongOp(memory, offset, m, f);\n+        }\n+\n@@ -5624,6 +5717,6 @@\n-        switch (s) {\n-            case S_64_BIT: return ($Type$Species) SPECIES_64;\n-            case S_128_BIT: return ($Type$Species) SPECIES_128;\n-            case S_256_BIT: return ($Type$Species) SPECIES_256;\n-            case S_512_BIT: return ($Type$Species) SPECIES_512;\n-            case S_Max_BIT: return ($Type$Species) SPECIES_MAX;\n+        switch (s.switchKey) {\n+            case VectorShape.SK_64_BIT: return ($Type$Species) SPECIES_64;\n+            case VectorShape.SK_128_BIT: return ($Type$Species) SPECIES_128;\n+            case VectorShape.SK_256_BIT: return ($Type$Species) SPECIES_256;\n+            case VectorShape.SK_512_BIT: return ($Type$Species) SPECIES_512;\n+            case VectorShape.SK_Max_BIT: return ($Type$Species) SPECIES_MAX;\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":438,"deletions":345,"binary":false,"changes":783,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,1 +27,0 @@\n-import java.nio.ByteBuffer;\n@@ -32,0 +31,1 @@\n+import jdk.incubator.foreign.MemorySegment;\n@@ -377,0 +377,6 @@\n+    @Override\n+    @ForceInline\n+    public final $masktype$ test(Test op, VectorMask<$Boxtype$> m) {\n+        return super.testTemplate($masktype$.class, op, ($masktype$) m);  \/\/ specialize\n+    }\n+\n@@ -477,0 +483,16 @@\n+    @Override\n+    @ForceInline\n+    public $vectortype$ compress(VectorMask<$Boxtype$> m) {\n+        return ($vectortype$)\n+            super.compressTemplate($masktype$.class,\n+                                   ($masktype$) m);  \/\/ specialize\n+    }\n+\n+    @Override\n+    @ForceInline\n+    public $vectortype$ expand(VectorMask<$Boxtype$> m) {\n+        return ($vectortype$)\n+            super.expandTemplate($masktype$.class,\n+                                   ($masktype$) m);  \/\/ specialize\n+    }\n+\n@@ -917,0 +939,9 @@\n+        @Override\n+        @ForceInline\n+        public $masktype$ compress() {\n+            return ($masktype$)VectorSupport.comExpOp(VectorSupport.VECTOR_OP_MASK_COMPRESS,\n+                $vectortype$.class, $masktype$.class, ETYPE, VLENGTH, null, this,\n+                (v1, m1) -> VSPECIES.iota().compare(VectorOperators.LT, m1.trueCount()));\n+        }\n+\n+\n@@ -1003,3 +1034,3 @@\n-            return VectorSupport.broadcastCoerced($masktype$.class, $bitstype$.class, VLENGTH,\n-                                                  (bit ? -1 : 0), null,\n-                                                  (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n+            return VectorSupport.fromBitsCoerced($masktype$.class, $bitstype$.class, VLENGTH,\n+                                                 (bit ? -1 : 0), MODE_BROADCAST, null,\n+                                                 (v, __) -> (v != 0 ? TRUE_MASK : FALSE_MASK));\n@@ -1156,2 +1187,2 @@\n-    $abstractvectortype$ fromByteArray0(byte[] a, int offset) {\n-        return super.fromByteArray0Template(a, offset);  \/\/ specialize\n+    $abstractvectortype$ fromMemorySegment0(MemorySegment ms, long offset) {\n+        return super.fromMemorySegment0Template(ms, offset);  \/\/ specialize\n@@ -1163,16 +1194,2 @@\n-    $abstractvectortype$ fromByteArray0(byte[] a, int offset, VectorMask<$Boxtype$> m) {\n-        return super.fromByteArray0Template($masktype$.class, a, offset, ($masktype$) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    $abstractvectortype$ fromByteBuffer0(ByteBuffer bb, int offset) {\n-        return super.fromByteBuffer0Template(bb, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    $abstractvectortype$ fromByteBuffer0(ByteBuffer bb, int offset, VectorMask<$Boxtype$> m) {\n-        return super.fromByteBuffer0Template($masktype$.class, bb, offset, ($masktype$) m);  \/\/ specialize\n+    $abstractvectortype$ fromMemorySegment0(MemorySegment ms, long offset, VectorMask<$Boxtype$> m) {\n+        return super.fromMemorySegment0Template($masktype$.class, ms, offset, ($masktype$) m);  \/\/ specialize\n@@ -1216,16 +1233,2 @@\n-    void intoByteArray0(byte[] a, int offset) {\n-        super.intoByteArray0Template(a, offset);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteArray0(byte[] a, int offset, VectorMask<$Boxtype$> m) {\n-        super.intoByteArray0Template($masktype$.class, a, offset, ($masktype$) m);  \/\/ specialize\n-    }\n-\n-    @ForceInline\n-    @Override\n-    final\n-    void intoByteBuffer0(ByteBuffer bb, int offset, VectorMask<$Boxtype$> m) {\n-        super.intoByteBuffer0Template($masktype$.class, bb, offset, ($masktype$) m);\n+    void intoMemorySegment0(MemorySegment ms, long offset, VectorMask<$Boxtype$> m) {\n+        super.intoMemorySegment0Template($masktype$.class, ms, offset, ($masktype$) m);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-VectorBits.java.template","additions":42,"deletions":39,"binary":false,"changes":81,"status":"modified"}]}