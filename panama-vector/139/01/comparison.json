{"files":[{"patch":"@@ -4057,1 +4057,2 @@\n-                                              Register tmp, int masklen, int vec_enc) {\n+                                              Register tmp, int masklen, int masksize,\n+                                              int vec_enc) {\n@@ -4064,0 +4065,3 @@\n+  if (masksize < 16) {\n+    andq(tmp, (((jlong)1 << masklen) - 1));\n+  }\n@@ -4083,1 +4087,2 @@\n-                                              XMMRegister xtmp1, Register tmp, int masklen, int vec_enc) {\n+                                              XMMRegister xtmp1, Register tmp, int masklen, int masksize,\n+                                              int vec_enc) {\n@@ -4088,1 +4093,1 @@\n-  if (masklen < 64) {\n+  if (masksize < 16) {\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -227,1 +227,1 @@\n-  void vector_mask_operation(int opc, Register dst, KRegister mask, Register tmp, int masklen, int vec_enc);\n+  void vector_mask_operation(int opc, Register dst, KRegister mask, Register tmp, int masklen, int masksize, int vec_enc);\n@@ -230,1 +230,1 @@\n-                             Register tmp, int masklen, int vec_enc);\n+                             Register tmp, int masklen, int masksize, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4168,1 +4168,1 @@\n-  predicate(UseAVX > 0);\n+  predicate(UseAVX > 0 && Matcher::vector_length_in_bytes(n) >= 16);\n@@ -7922,1 +7922,1 @@\n-instruct vstoreMask2B(vec dst, vec src, immI_2 size) %{\n+instruct vstoreMask2B(vec dst, vec src, vec xtmp, immI_2 size) %{\n@@ -7925,1 +7925,1 @@\n-  effect(TEMP_DEF dst);\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7930,1 +7930,1 @@\n-    if (vlen <= 8 && UseAVX <= 2) {\n+    if (vlen <= 8) {\n@@ -7932,0 +7932,1 @@\n+      __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7933,1 +7934,1 @@\n-      __ packuswb($dst$$XMMRegister, $dst$$XMMRegister);\n+      __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7944,1 +7945,1 @@\n-instruct vstoreMask4B(vec dst, vec src, immI_4 size) %{\n+instruct vstoreMask4B(vec dst, vec src, vec xtmp, immI_4 size) %{\n@@ -7948,1 +7949,1 @@\n-  effect(TEMP_DEF dst);\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7952,1 +7953,1 @@\n-    if (vlen <= 4 && UseAVX <= 2) {\n+    if (vlen <= 4) {\n@@ -7954,0 +7955,1 @@\n+      __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7955,2 +7957,2 @@\n-      __ packusdw($dst$$XMMRegister, $dst$$XMMRegister);\n-      __ packuswb($dst$$XMMRegister, $dst$$XMMRegister);\n+      __ packusdw($dst$$XMMRegister, $xtmp$$XMMRegister);\n+      __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7959,0 +7961,1 @@\n+      __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n@@ -7961,1 +7964,1 @@\n-      __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+      __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n@@ -7968,1 +7971,1 @@\n-instruct storeMask8B(vec dst, vec src, immI_8 size) %{\n+instruct storeMask8B(vec dst, vec src, vec xtmp, immI_8 size) %{\n@@ -7971,0 +7974,1 @@\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7974,0 +7978,1 @@\n+    __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7975,3 +7980,3 @@\n-    __ packssdw($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ packsswb($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ pabsb($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ pabsd($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ packusdw($dst$$XMMRegister, $xtmp$$XMMRegister);\n+    __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7986,1 +7991,1 @@\n-  effect(TEMP dst, TEMP vtmp);\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -7992,2 +7997,3 @@\n-    __ vpackssdw($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vpxor($vtmp$$XMMRegister, $vtmp$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n+    __ vpackssdw($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n+    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n@@ -8638,1 +8644,1 @@\n-instruct vmask_tolong_evex(rRegL dst, kReg mask) %{\n+instruct vmask_tolong_evex(rRegL dst, kReg mask, rFlagsReg cr) %{\n@@ -8641,0 +8647,1 @@\n+  effect(TEMP dst, KILL cr);\n@@ -8643,0 +8650,2 @@\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8646,1 +8655,0 @@\n-      int mask_len = Matcher::vector_length(this, $mask);\n@@ -8650,0 +8658,6 @@\n+    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+    \/\/ operations needs to be clipped.\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    if (mask_size < 16) {\n+      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n+    }\n@@ -8654,1 +8668,1 @@\n-instruct vmask_tolong_avx(rRegL dst, vec mask, vec xtmp) %{\n+instruct vmask_tolong_avx(rRegL dst, vec mask, vec xtmp, rFlagsReg cr) %{\n@@ -8659,1 +8673,1 @@\n-  effect(TEMP xtmp);\n+  effect(TEMP_DEF dst, TEMP xtmp, KILL cr);\n@@ -8661,0 +8675,2 @@\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8662,3 +8678,9 @@\n-     __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n-     __ vpsubb($xtmp$$XMMRegister, $xtmp$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n-     __ vpmovmskb($dst$$Register, $xtmp$$XMMRegister, vlen_enc);\n+    __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+    __ vpsubb($xtmp$$XMMRegister, $xtmp$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n+    __ vpmovmskb($dst$$Register, $xtmp$$XMMRegister, vlen_enc);\n+    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+    \/\/ operations needs to be clipped.\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    if (mask_size < 16) {\n+      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n+    }\n@@ -8676,1 +8698,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8678,1 +8700,4 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len, vlen_enc);\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register,\n+                             mask_len, mask_size, vlen_enc);\n@@ -8690,1 +8715,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8692,0 +8717,2 @@\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n@@ -8693,1 +8720,1 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, vlen_enc);\n+                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n@@ -8706,1 +8733,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8708,1 +8735,4 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len, vlen_enc);\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len,\n+                             mask_size, vlen_enc);\n@@ -8721,1 +8751,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8723,0 +8753,2 @@\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n@@ -8724,1 +8756,1 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, vlen_enc);\n+                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":65,"deletions":33,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -0,0 +1,235 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.vectorapi;\n+\n+import java.util.Random;\n+\n+import jdk.incubator.vector.VectorSpecies;\n+import jdk.incubator.vector.ByteVector;\n+import jdk.incubator.vector.DoubleVector;\n+import jdk.incubator.vector.FloatVector;\n+import jdk.incubator.vector.IntVector;\n+import jdk.incubator.vector.LongVector;\n+import jdk.incubator.vector.ShortVector;\n+import jdk.incubator.vector.VectorMask;\n+import jdk.test.lib.Utils;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+\/**\n+ * @test\n+ * @bug 8274569\n+ * @key randomness\n+ * @library \/test\/lib\n+ * @summary Tests X86 backend related incorrectness issues in legacy storemask patterns\n+ * @modules jdk.incubator.vector\n+ *\n+ * @run testng\/othervm -XX:-TieredCompilation -XX:CompileThreshold=100 compiler.vectorapi.VectorMaskLoadStoreTest\n+ *\/\n+\n+\n+public class VectorMaskLoadStoreTest{\n+\n+    private static final int NUM_ITER = 5000;\n+    private static final Random rd = Utils.getRandomInstance();\n+\n+    public static void testByte64(long val) {\n+        VectorSpecies<Byte> SPECIES = ByteVector.SPECIES_64;\n+        VectorMask<Byte> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFL);\n+    }\n+\n+    public static void testByte128(long val) {\n+        VectorSpecies<Byte> SPECIES = ByteVector.SPECIES_128;\n+        VectorMask<Byte> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFFFL);\n+    }\n+\n+    public static void testByte256(long val) {\n+        VectorSpecies<Byte> SPECIES = ByteVector.SPECIES_256;\n+        VectorMask<Byte> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFFFFFFFL);\n+    }\n+\n+    public static void testByte512(long val) {\n+        VectorSpecies<Byte> SPECIES = ByteVector.SPECIES_512;\n+        VectorMask<Byte> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & -1L);\n+    }\n+\n+    public static void testShort64(long val) {\n+        VectorSpecies<Short> SPECIES = ShortVector.SPECIES_64;\n+        VectorMask<Short> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFL);\n+    }\n+\n+    public static void testShort128(long val) {\n+        VectorSpecies<Short> SPECIES = ShortVector.SPECIES_128;\n+        VectorMask<Short> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFL);\n+    }\n+\n+    public static void testShort256(long val) {\n+        VectorSpecies<Short> SPECIES = ShortVector.SPECIES_256;\n+        VectorMask<Short> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFFFL);\n+    }\n+\n+    public static void testShort512(long val) {\n+        VectorSpecies<Short> SPECIES = ShortVector.SPECIES_512;\n+        VectorMask<Short> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFFFFFFFL);\n+    }\n+\n+    public static void testInteger64(long val) {\n+        VectorSpecies<Integer> SPECIES = IntVector.SPECIES_64;\n+        VectorMask<Integer> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0x3L);\n+    }\n+\n+    public static void testInteger128(long val) {\n+        VectorSpecies<Integer> SPECIES = IntVector.SPECIES_128;\n+        VectorMask<Integer> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFL);\n+    }\n+\n+    public static void testInteger256(long val) {\n+        VectorSpecies<Integer> SPECIES = IntVector.SPECIES_256;\n+        VectorMask<Integer> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFL);\n+    }\n+\n+    public static void testInteger512(long val) {\n+        VectorSpecies<Integer> SPECIES = IntVector.SPECIES_512;\n+        VectorMask<Integer> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFFFL);\n+    }\n+\n+    public static void testLong64(long val) {\n+        VectorSpecies<Long> SPECIES = LongVector.SPECIES_64;\n+        VectorMask<Long> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0x1L);\n+    }\n+\n+    public static void testLong128(long val) {\n+        VectorSpecies<Long> SPECIES = LongVector.SPECIES_128;\n+        VectorMask<Long> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0x3L);\n+    }\n+\n+    public static void testLong256(long val) {\n+        VectorSpecies<Long> SPECIES = LongVector.SPECIES_256;\n+        VectorMask<Long> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFL);\n+    }\n+\n+    public static void testLong512(long val) {\n+        VectorSpecies<Long> SPECIES = LongVector.SPECIES_512;\n+        VectorMask<Long> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFL);\n+    }\n+\n+    public static void testFloat64(long val) {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_64;\n+        VectorMask<Float> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0x3L);\n+    }\n+\n+    public static void testFloat128(long val) {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        VectorMask<Float> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFL);\n+    }\n+\n+    public static void testFloat256(long val) {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        VectorMask<Float> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFL);\n+    }\n+\n+    public static void testFloat512(long val) {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_512;\n+        VectorMask<Float> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFFFL);\n+    }\n+\n+    public static void testDouble64(long val) {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_64;\n+        VectorMask<Double> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0x1L);\n+    }\n+\n+    public static void testDouble128(long val) {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        VectorMask<Double> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0x3L);\n+    }\n+\n+    public static void testDouble256(long val) {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        VectorMask<Double> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFL);\n+    }\n+\n+    public static void testDouble512(long val) {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_512;\n+        VectorMask<Double> mask = VectorMask.fromLong(SPECIES, val);\n+        Assert.assertEquals(mask.toLong(), val & 0xFFL);\n+    }\n+\n+    @Test\n+    public static void testMaskCast() {\n+        long [] vals = {-1L, 0, rd.nextLong(), rd.nextLong()};\n+        for(int i = 0; i < vals.length; i++) {\n+            long val = vals[i];\n+            for (int ctr = 0; ctr < NUM_ITER; ctr++) {\n+                testByte64(val);\n+                testByte128(val);\n+                testByte256(val);\n+                testByte512(val);\n+                testShort64(val);\n+                testShort128(val);\n+                testShort256(val);\n+                testShort512(val);\n+                testInteger64(val);\n+                testInteger128(val);\n+                testInteger256(val);\n+                testInteger512(val);\n+                testLong64(val);\n+                testLong128(val);\n+                testLong256(val);\n+                testLong512(val);\n+                testFloat64(val);\n+                testFloat128(val);\n+                testFloat256(val);\n+                testFloat512(val);\n+                testDouble64(val);\n+                testDouble128(val);\n+                testDouble256(val);\n+                testDouble512(val);\n+            }\n+        }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/VectorMaskLoadStoreTest.java","additions":235,"deletions":0,"binary":false,"changes":235,"status":"added"}]}