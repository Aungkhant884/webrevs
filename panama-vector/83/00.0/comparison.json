{"files":[{"patch":"@@ -1889,1 +1889,0 @@\n-  assert(framesize%(2*wordSize) == 0, \"must preserve 2*wordSize alignment\");\n@@ -2427,4 +2426,0 @@\n-const bool Matcher::has_predicated_vectors(void) {\n-  return UseSVE > 0;\n-}\n-\n@@ -2439,26 +2434,0 @@\n-bool Matcher::supports_vector_variable_shifts(void) {\n-  return true;\n-}\n-\n-bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n-  return false;\n-}\n-\n-\/\/ Vector calling convention not yet implemented.\n-const bool Matcher::supports_vector_calling_convention(void) {\n-  return false;\n-}\n-\n-void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n-  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n-}\n-\n-OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n-  Unimplemented();\n-  return OptoRegPair(0, 0);\n-}\n-\n-bool Matcher::supports_vector_variable_rotates(void) {\n-  return false; \/\/ not supported\n-}\n-\n@@ -2479,11 +2448,0 @@\n-const bool Matcher::isSimpleConstant64(jlong value) {\n-  \/\/ Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.\n-  \/\/ Probably always true, even if a temp register is required.\n-  return true;\n-}\n-\n-\/\/ true just means we have fast l2f conversion\n-const bool Matcher::convL2FSupported(void) {\n-  return true;\n-}\n-\n@@ -2521,4 +2479,0 @@\n-const bool Matcher::supports_scalable_vector() {\n-  return UseSVE > 0;\n-}\n-\n@@ -2546,29 +2500,0 @@\n-\/\/ aarch64 supports misaligned vectors store\/load.\n-const bool Matcher::misaligned_vectors_ok() {\n-  return true;\n-}\n-\n-\/\/ false => size gets scaled to BytesPerLong, ok.\n-const bool Matcher::init_array_count_is_in_bytes = false;\n-\n-\/\/ Use conditional move (CMOVL)\n-const int Matcher::long_cmove_cost() {\n-  \/\/ long cmoves are no more expensive than int cmoves\n-  return 0;\n-}\n-\n-const int Matcher::float_cmove_cost() {\n-  \/\/ float cmoves are no more expensive than int cmoves\n-  return 0;\n-}\n-\n-\/\/ Does the CPU require late expand (see block.cpp for description of late expand)?\n-const bool Matcher::require_postalloc_expand = false;\n-\n-\/\/ Do we need to mask the count passed to shift instructions or does\n-\/\/ the cpu only look at the lower 5\/6 bits anyway?\n-const bool Matcher::need_masked_shift_count = false;\n-\n-\/\/ No support for generic vector operands.\n-const bool Matcher::supports_generic_vector_operands  = false;\n-\n@@ -2590,56 +2515,0 @@\n-\/\/ This affects two different things:\n-\/\/  - how Decode nodes are matched\n-\/\/  - how ImplicitNullCheck opportunities are recognized\n-\/\/ If true, the matcher will try to remove all Decodes and match them\n-\/\/ (as operands) into nodes. NullChecks are not prepared to deal with\n-\/\/ Decodes by final_graph_reshaping().\n-\/\/ If false, final_graph_reshaping() forces the decode behind the Cmp\n-\/\/ for a NullCheck. The matcher matches the Decode node into a register.\n-\/\/ Implicit_null_check optimization moves the Decode along with the\n-\/\/ memory operation back up before the NullCheck.\n-bool Matcher::narrow_oop_use_complex_address() {\n-  return CompressedOops::shift() == 0;\n-}\n-\n-bool Matcher::narrow_klass_use_complex_address() {\n-\/\/ TODO\n-\/\/ decide whether we need to set this to true\n-  return false;\n-}\n-\n-bool Matcher::const_oop_prefer_decode() {\n-  \/\/ Prefer ConN+DecodeN over ConP in simple compressed oops mode.\n-  return CompressedOops::base() == NULL;\n-}\n-\n-bool Matcher::const_klass_prefer_decode() {\n-  \/\/ Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.\n-  return CompressedKlassPointers::base() == NULL;\n-}\n-\n-\/\/ Is it better to copy float constants, or load them directly from\n-\/\/ memory?  Intel can load a float constant from a direct address,\n-\/\/ requiring no extra registers.  Most RISCs will have to materialize\n-\/\/ an address into a register first, so they would do better to copy\n-\/\/ the constant from stack.\n-const bool Matcher::rematerialize_float_constants = false;\n-\n-\/\/ If CPU can load and store mis-aligned doubles directly then no\n-\/\/ fixup is needed.  Else we split the double into 2 integer pieces\n-\/\/ and move it piece-by-piece.  Only happens when passing doubles into\n-\/\/ C code as the Java calling convention forces doubles to be aligned.\n-const bool Matcher::misaligned_doubles_ok = true;\n-\n-\/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n-const bool Matcher::strict_fp_requires_explicit_rounding = false;\n-\n-\/\/ Are floats converted to double when stored to stack during\n-\/\/ deoptimization?\n-bool Matcher::float_in_double() { return false; }\n-\n-\/\/ Do ints take an entire long register or just half?\n-\/\/ The relevant question is how the int is callee-saved:\n-\/\/ the whole long is written but de-opt'ing will have to extract\n-\/\/ the relevant 32 bits.\n-const bool Matcher::int_in_long = true;\n-\n@@ -2722,2 +2591,0 @@\n-const bool Matcher::convi2l_type_required = false;\n-\n@@ -2774,4 +2641,0 @@\n-void Compile::reshape_address(AddPNode* addp) {\n-}\n-\n-\n@@ -3133,26 +2996,0 @@\n-  \/\/ This encoding class is generated automatically from ad_encode.m4.\n-  \/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n-  enc_class aarch64_enc_strw_immn(immN src, memory1 mem) %{\n-    C2_MacroAssembler _masm(&cbuf);\n-    address con = (address)$src$$constant;\n-    \/\/ need to do this the hard way until we can manage relocs\n-    \/\/ for 32 bit constants\n-    __ movoop(rscratch2, (jobject)con);\n-    if (con) __ encode_heap_oop_not_null(rscratch2);\n-    loadStore(_masm, &MacroAssembler::strw, rscratch2, $mem->opcode(),\n-               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);\n-  %}\n-\n-  \/\/ This encoding class is generated automatically from ad_encode.m4.\n-  \/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n-  enc_class aarch64_enc_strw_immnk(immN src, memory4 mem) %{\n-    C2_MacroAssembler _masm(&cbuf);\n-    address con = (address)$src$$constant;\n-    \/\/ need to do this the hard way until we can manage relocs\n-    \/\/ for 32 bit constants\n-    __ movoop(rscratch2, (jobject)con);\n-    __ encode_klass_not_null(rscratch2);\n-    loadStore(_masm, &MacroAssembler::strw, rscratch2, $mem->opcode(),\n-               as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp, 4);\n-  %}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":163,"binary":false,"changes":163,"status":"modified"},{"patch":"@@ -3762,2 +3762,1 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->obj_equals(this, obj1, obj2);\n+  cmp(obj1, obj2);\n@@ -4165,9 +4164,0 @@\n-void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {\n-  \/\/ Use stronger ACCESS_WRITE|ACCESS_READ by default.\n-  if ((decorators & (ACCESS_READ | ACCESS_WRITE)) == 0) {\n-    decorators |= ACCESS_READ | ACCESS_WRITE;\n-  }\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  return bs->resolve(this, decorators, obj);\n-}\n-\n@@ -4453,1 +4443,2 @@\n-  assert(framesize > 0, \"framesize must be > 0\");\n+  assert(framesize >= 2 * wordSize, \"framesize must include space for FP\/LR\");\n+  assert(framesize % (2*wordSize) == 0, \"must preserve 2*wordSize alignment\");\n@@ -4472,1 +4463,2 @@\n-  assert(framesize > 0, \"framesize must be > 0\");\n+  assert(framesize >= 2 * wordSize, \"framesize must include space for FP\/LR\");\n+  assert(framesize % (2*wordSize) == 0, \"must preserve 2*wordSize alignment\");\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":5,"deletions":13,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -0,0 +1,170 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef CPU_AARCH64_MATCHER_AARCH64_HPP\n+#define CPU_AARCH64_MATCHER_AARCH64_HPP\n+\n+  \/\/ Defined within class Matcher\n+\n+  \/\/ false => size gets scaled to BytesPerLong, ok.\n+  static const bool init_array_count_is_in_bytes = false;\n+\n+  \/\/ Whether this platform implements the scalable vector feature\n+  static const bool implements_scalable_vector = true;\n+\n+  static const bool supports_scalable_vector() {\n+    return UseSVE > 0;\n+  }\n+\n+  \/\/ aarch64 supports misaligned vectors store\/load.\n+  static constexpr bool misaligned_vectors_ok() {\n+    return true;\n+  }\n+\n+  \/\/ Whether code generation need accurate ConvI2L types.\n+  static const bool convi2l_type_required = false;\n+\n+  \/\/ Does the CPU require late expand (see block.cpp for description of late expand)?\n+  static const bool require_postalloc_expand = false;\n+\n+  \/\/ Do we need to mask the count passed to shift instructions or does\n+  \/\/ the cpu only look at the lower 5\/6 bits anyway?\n+  static const bool need_masked_shift_count = false;\n+\n+  \/\/ No support for generic vector operands.\n+  static const bool supports_generic_vector_operands = false;\n+\n+  static constexpr bool isSimpleConstant64(jlong value) {\n+    \/\/ Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.\n+    \/\/ Probably always true, even if a temp register is required.\n+    return true;\n+  }\n+\n+  \/\/ Use conditional move (CMOVL)\n+  static constexpr int long_cmove_cost() {\n+    \/\/ long cmoves are no more expensive than int cmoves\n+    return 0;\n+  }\n+\n+  static constexpr int float_cmove_cost() {\n+    \/\/ float cmoves are no more expensive than int cmoves\n+    return 0;\n+  }\n+\n+  \/\/ This affects two different things:\n+  \/\/  - how Decode nodes are matched\n+  \/\/  - how ImplicitNullCheck opportunities are recognized\n+  \/\/ If true, the matcher will try to remove all Decodes and match them\n+  \/\/ (as operands) into nodes. NullChecks are not prepared to deal with\n+  \/\/ Decodes by final_graph_reshaping().\n+  \/\/ If false, final_graph_reshaping() forces the decode behind the Cmp\n+  \/\/ for a NullCheck. The matcher matches the Decode node into a register.\n+  \/\/ Implicit_null_check optimization moves the Decode along with the\n+  \/\/ memory operation back up before the NullCheck.\n+  static bool narrow_oop_use_complex_address() {\n+    return CompressedOops::shift() == 0;\n+  }\n+\n+  static bool narrow_klass_use_complex_address() {\n+    \/\/ TODO\n+    \/\/ decide whether we need to set this to true\n+    return false;\n+  }\n+\n+  static bool const_oop_prefer_decode() {\n+    \/\/ Prefer ConN+DecodeN over ConP in simple compressed oops mode.\n+    return CompressedOops::base() == NULL;\n+  }\n+\n+  static bool const_klass_prefer_decode() {\n+    \/\/ Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.\n+    return CompressedKlassPointers::base() == NULL;\n+  }\n+\n+  \/\/ Is it better to copy float constants, or load them directly from\n+  \/\/ memory?  Intel can load a float constant from a direct address,\n+  \/\/ requiring no extra registers.  Most RISCs will have to materialize\n+  \/\/ an address into a register first, so they would do better to copy\n+  \/\/ the constant from stack.\n+  static const bool rematerialize_float_constants = false;\n+\n+  \/\/ If CPU can load and store mis-aligned doubles directly then no\n+  \/\/ fixup is needed.  Else we split the double into 2 integer pieces\n+  \/\/ and move it piece-by-piece.  Only happens when passing doubles into\n+  \/\/ C code as the Java calling convention forces doubles to be aligned.\n+  static const bool misaligned_doubles_ok = true;\n+\n+  \/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n+  static const bool strict_fp_requires_explicit_rounding = false;\n+\n+  \/\/ Are floats converted to double when stored to stack during\n+  \/\/ deoptimization?\n+  static constexpr bool float_in_double() { return false; }\n+\n+  \/\/ Do ints take an entire long register or just half?\n+  \/\/ The relevant question is how the int is callee-saved:\n+  \/\/ the whole long is written but de-opt'ing will have to extract\n+  \/\/ the relevant 32 bits.\n+  static const bool int_in_long = true;\n+\n+  \/\/ Does the CPU supports vector variable shift instructions?\n+  static constexpr bool supports_vector_variable_shifts(void) {\n+    return true;\n+  }\n+\n+  \/\/ Does the CPU supports vector variable rotate instructions?\n+  static constexpr bool supports_vector_variable_rotates(void) {\n+    return false;\n+  }\n+\n+  static bool supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+    return false;\n+  }\n+\n+  \/\/ Vector calling convention not yet implemented.\n+  static const bool supports_vector_calling_convention(void) {\n+    return false;\n+  }\n+\n+  static void vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+    (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+  }\n+\n+  static OptoRegPair vector_return_value(uint ideal_reg) {\n+    Unimplemented();\n+    return OptoRegPair(0, 0);\n+  }\n+\n+  \/\/ Some microarchitectures have mask registers used on vectors\n+  static const bool has_predicated_vectors(void) {\n+    return UseSVE > 0;\n+  }\n+\n+  \/\/ true means we have fast l2f convers\n+  \/\/ false means that conversion is done by runtime call\n+  static constexpr bool convL2FSupported(void) {\n+      return true;\n+  }\n+\n+#endif \/\/ CPU_AARCH64_MATCHER_AARCH64_HPP\n","filename":"src\/hotspot\/cpu\/aarch64\/matcher_aarch64.hpp","additions":170,"deletions":0,"binary":false,"changes":170,"status":"added"},{"patch":"@@ -1776,2 +1776,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n-\n@@ -1928,2 +1926,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,163 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef CPU_ARM_MATCHER_ARM_HPP\n+#define CPU_ARM_MATCHER_ARM_HPP\n+\n+  \/\/ Defined within class Matcher\n+\n+  \/\/ No scaling for the parameter the ClearArray node.\n+  static const bool init_array_count_is_in_bytes = true;\n+\n+  \/\/ Whether this platform implements the scalable vector feature\n+  static const bool implements_scalable_vector = false;\n+\n+  static constexpr bool supports_scalable_vector() {\n+    return false;\n+  }\n+\n+  \/\/ ARM doesn't support misaligned vectors store\/load.\n+  static constexpr bool misaligned_vectors_ok() {\n+    return false;\n+  }\n+\n+  \/\/ Whether code generation need accurate ConvI2L types.\n+  static const bool convi2l_type_required = true;\n+\n+  \/\/ Do we need to mask the count passed to shift instructions or does\n+  \/\/ the cpu only look at the lower 5\/6 bits anyway?\n+  \/\/ FIXME: does this handle vector shifts as well?\n+  static const bool need_masked_shift_count = true;\n+\n+  \/\/ Does the CPU require late expand (see block.cpp for description of late expand)?\n+  static const bool require_postalloc_expand = false;\n+\n+  \/\/ No support for generic vector operands.\n+  static const bool supports_generic_vector_operands = false;\n+\n+  static constexpr bool isSimpleConstant64(jlong value) {\n+    \/\/ Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.\n+    return false;\n+  }\n+\n+  \/\/ Needs 2 CMOV's for longs.\n+  static constexpr int long_cmove_cost() { return 2; }\n+\n+  \/\/ CMOVF\/CMOVD are expensive on ARM.\n+  static int float_cmove_cost() { return ConditionalMoveLimit; }\n+\n+  static bool narrow_oop_use_complex_address() {\n+    NOT_LP64(ShouldNotCallThis());\n+    assert(UseCompressedOops, \"only for compressed oops code\");\n+    return false;\n+  }\n+\n+  static bool narrow_klass_use_complex_address() {\n+    NOT_LP64(ShouldNotCallThis());\n+    assert(UseCompressedClassPointers, \"only for compressed klass code\");\n+    return false;\n+  }\n+\n+  static bool const_oop_prefer_decode() {\n+    NOT_LP64(ShouldNotCallThis());\n+    return true;\n+  }\n+\n+  static bool const_klass_prefer_decode() {\n+    NOT_LP64(ShouldNotCallThis());\n+    return true;\n+  }\n+\n+  \/\/ Is it better to copy float constants, or load them directly from memory?\n+  \/\/ Intel can load a float constant from a direct address, requiring no\n+  \/\/ extra registers.  Most RISCs will have to materialize an address into a\n+  \/\/ register first, so they would do better to copy the constant from stack.\n+  static const bool rematerialize_float_constants = false;\n+\n+  \/\/ If CPU can load and store mis-aligned doubles directly then no fixup is\n+  \/\/ needed.  Else we split the double into 2 integer pieces and move it\n+  \/\/ piece-by-piece.  Only happens when passing doubles into C code as the\n+  \/\/ Java calling convention forces doubles to be aligned.\n+  static const bool misaligned_doubles_ok = false;\n+\n+  \/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n+  static const bool strict_fp_requires_explicit_rounding = false;\n+\n+  \/\/ Are floats converted to double when stored to stack during deoptimization?\n+  \/\/ ARM does not handle callee-save floats.\n+  static constexpr bool float_in_double() {\n+    return false;\n+  }\n+\n+  \/\/ Do ints take an entire long register or just half?\n+  \/\/ Note that we if-def off of _LP64.\n+  \/\/ The relevant question is how the int is callee-saved.  In _LP64\n+  \/\/ the whole long is written but de-opt'ing will have to extract\n+  \/\/ the relevant 32 bits, in not-_LP64 only the low 32 bits is written.\n+#ifdef _LP64\n+  static const bool int_in_long = true;\n+#else\n+  static const bool int_in_long = false;\n+#endif\n+\n+  \/\/ Does the CPU supports vector variable shift instructions?\n+  static bool supports_vector_variable_shifts(void) {\n+    return VM_Version::has_simd();\n+  }\n+\n+  \/\/ Does the CPU supports vector variable rotate instructions?\n+  static constexpr bool supports_vector_variable_rotates(void) {\n+    return false; \/\/ not supported\n+  }\n+\n+  static bool supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+    return false;\n+  }\n+\n+  \/\/ Vector calling convention not yet implemented.\n+  static const bool supports_vector_calling_convention(void) {\n+    return false;\n+  }\n+\n+  static void vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+    (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+  }\n+\n+  static OptoRegPair vector_return_value(uint ideal_reg) {\n+    Unimplemented();\n+    return OptoRegPair(0, 0);\n+  }\n+\n+  \/\/ Some microarchitectures have mask registers used on vectors\n+  static constexpr bool has_predicated_vectors(void) {\n+    return false;\n+  }\n+\n+  \/\/ true means we have fast l2f convers\n+  \/\/ false means that conversion is done by runtime call\n+  static constexpr bool convL2FSupported(void) {\n+      return true;\n+  }\n+\n+#endif \/\/ CPU_ARM_MATCHER_ARM_HPP\n","filename":"src\/hotspot\/cpu\/arm\/matcher_arm.hpp","additions":163,"deletions":0,"binary":false,"changes":163,"status":"added"},{"patch":"@@ -1162,2 +1162,0 @@\n-    __ resolve(IS_NOT_NULL, sync_obj);\n-\n@@ -1248,2 +1246,0 @@\n-    __ resolve(IS_NOT_NULL, sync_obj);\n-\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,173 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef CPU_PPC_MATCHER_PPC_HPP\n+#define CPU_PPC_MATCHER_PPC_HPP\n+\n+  \/\/ Defined within class Matcher\n+\n+  \/\/ false => size gets scaled to BytesPerLong, ok.\n+  static const bool init_array_count_is_in_bytes = false;\n+\n+  \/\/ Whether this platform implements the scalable vector feature\n+  static const bool implements_scalable_vector = false;\n+\n+  static constexpr bool supports_scalable_vector() {\n+    return false;\n+  }\n+\n+  \/\/ PPC implementation uses VSX load\/store instructions (if\n+  \/\/ SuperwordUseVSX) which support 4 byte but not arbitrary alignment\n+  static const bool misaligned_vectors_ok() {\n+    return false;\n+  }\n+\n+  \/\/ Whether code generation need accurate ConvI2L types.\n+  static const bool convi2l_type_required = true;\n+\n+  \/\/ Do we need to mask the count passed to shift instructions or does\n+  \/\/ the cpu only look at the lower 5\/6 bits anyway?\n+  \/\/ PowerPC requires masked shift counts.\n+  static const bool need_masked_shift_count = true;\n+\n+  \/\/ Power6 requires postalloc expand (see block.cpp for description of postalloc expand).\n+  static const bool require_postalloc_expand = true;\n+\n+  \/\/ No support for generic vector operands.\n+  static const bool supports_generic_vector_operands = false;\n+\n+  static constexpr bool isSimpleConstant64(jlong value) {\n+    \/\/ Probably always true, even if a temp register is required.\n+    return true;\n+  }\n+\n+  \/\/ Use conditional move (CMOVL) on Power7.\n+  static constexpr int long_cmove_cost() { return 0; } \/\/ this only makes long cmoves more expensive than int cmoves\n+\n+  \/\/ Suppress CMOVF. Conditional move available (sort of) on PPC64 only from P7 onwards. Not exploited yet.\n+  \/\/ fsel doesn't accept a condition register as input, so this would be slightly different.\n+  static int float_cmove_cost() { return ConditionalMoveLimit; }\n+\n+  \/\/ This affects two different things:\n+  \/\/  - how Decode nodes are matched\n+  \/\/  - how ImplicitNullCheck opportunities are recognized\n+  \/\/ If true, the matcher will try to remove all Decodes and match them\n+  \/\/ (as operands) into nodes. NullChecks are not prepared to deal with\n+  \/\/ Decodes by final_graph_reshaping().\n+  \/\/ If false, final_graph_reshaping() forces the decode behind the Cmp\n+  \/\/ for a NullCheck. The matcher matches the Decode node into a register.\n+  \/\/ Implicit_null_check optimization moves the Decode along with the\n+  \/\/ memory operation back up before the NullCheck.\n+  static constexpr bool narrow_oop_use_complex_address() {\n+    \/\/ TODO: PPC port if (MatchDecodeNodes) return true;\n+    return false;\n+  }\n+\n+  static bool narrow_klass_use_complex_address() {\n+    NOT_LP64(ShouldNotCallThis());\n+    assert(UseCompressedClassPointers, \"only for compressed klass code\");\n+    \/\/ TODO: PPC port if (MatchDecodeNodes) return true;\n+    return false;\n+  }\n+\n+  static bool const_oop_prefer_decode() {\n+    \/\/ Prefer ConN+DecodeN over ConP in simple compressed oops mode.\n+    return CompressedOops::base() == NULL;\n+  }\n+\n+  static bool const_klass_prefer_decode() {\n+    \/\/ Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.\n+    return CompressedKlassPointers::base() == NULL;\n+  }\n+\n+  \/\/ Is it better to copy float constants, or load them directly from memory?\n+  \/\/ Intel can load a float constant from a direct address, requiring no\n+  \/\/ extra registers. Most RISCs will have to materialize an address into a\n+  \/\/ register first, so they would do better to copy the constant from stack.\n+  static const bool rematerialize_float_constants = false;\n+\n+  \/\/ If CPU can load and store mis-aligned doubles directly then no fixup is\n+  \/\/ needed. Else we split the double into 2 integer pieces and move it\n+  \/\/ piece-by-piece. Only happens when passing doubles into C code as the\n+  \/\/ Java calling convention forces doubles to be aligned.\n+  static const bool misaligned_doubles_ok = true;\n+\n+  \/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n+  static const bool strict_fp_requires_explicit_rounding = false;\n+\n+  \/\/ Do floats take an entire double register or just half?\n+  \/\/\n+  \/\/ A float occupies a ppc64 double register. For the allocator, a\n+  \/\/ ppc64 double register appears as a pair of float registers.\n+  static constexpr bool float_in_double() { return true; }\n+\n+  \/\/ Do ints take an entire long register or just half?\n+  \/\/ The relevant question is how the int is callee-saved:\n+  \/\/ the whole long is written but de-opt'ing will have to extract\n+  \/\/ the relevant 32 bits.\n+  static const bool int_in_long = true;\n+\n+  \/\/ Does the CPU supports vector variable shift instructions?\n+  static constexpr bool supports_vector_variable_shifts(void) {\n+    return false;\n+  }\n+\n+  \/\/ Does the CPU supports vector variable rotate instructions?\n+  static constexpr bool supports_vector_variable_rotates(void) {\n+    return false;\n+  }\n+\n+  static bool supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+    return false;\n+  }\n+\n+  \/\/ Vector calling convention not yet implemented.\n+  static const bool supports_vector_calling_convention(void) {\n+    return false;\n+  }\n+\n+  static void vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+    (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+  }\n+\n+  static OptoRegPair vector_return_value(uint ideal_reg) {\n+    Unimplemented();\n+    return OptoRegPair(0, 0);\n+  }\n+\n+  \/\/ Some microarchitectures have mask registers used on vectors\n+  static constexpr bool has_predicated_vectors(void) {\n+    return false;\n+  }\n+\n+  \/\/ true means we have fast l2f convers\n+  \/\/ false means that conversion is done by runtime call\n+  static const bool convL2FSupported(void) {\n+    \/\/ fcfids can do the conversion (>= Power7).\n+    \/\/ fcfid + frsp showed rounding problem when result should be 0x3f800001.\n+    return VM_Version::has_fcfids();\n+  }\n+\n+\n+#endif \/\/ CPU_PPC_MATCHER_PPC_HPP\n","filename":"src\/hotspot\/cpu\/ppc\/matcher_ppc.hpp","additions":173,"deletions":0,"binary":false,"changes":173,"status":"added"},{"patch":"@@ -0,0 +1,160 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef CPU_S390_MATCHER_S390_HPP\n+#define CPU_S390_MATCHER_S390_HPP\n+\n+  \/\/ Defined within class Matcher\n+\n+\n+  \/\/ Should correspond to setting above\n+  static const bool init_array_count_is_in_bytes = false;\n+\n+  \/\/ Whether this platform implements the scalable vector feature\n+  static const bool implements_scalable_vector = false;\n+\n+  static constexpr const bool supports_scalable_vector() {\n+    return false;\n+  }\n+\n+  \/\/ z\/Architecture does support misaligned store\/load at minimal extra cost.\n+  static constexpr bool misaligned_vectors_ok() {\n+    return true;\n+  }\n+\n+  \/\/ Whether code generation need accurate ConvI2L types.\n+  static const bool convi2l_type_required = true;\n+\n+  \/\/ Do the processor's shift instructions only use the low 5\/6 bits\n+  \/\/ of the count for 32\/64 bit ints? If not we need to do the masking\n+  \/\/ ourselves.\n+  static const bool need_masked_shift_count = false;\n+\n+  \/\/ Does the CPU require late expand (see block.cpp for description of late expand)?\n+  static const bool require_postalloc_expand = false;\n+\n+  \/\/ No support for generic vector operands.\n+  static const bool supports_generic_vector_operands = false;\n+\n+  static constexpr bool isSimpleConstant64(jlong value) {\n+    \/\/ Probably always true, even if a temp register is required.\n+    return true;\n+  }\n+\n+  \/\/ Suppress CMOVL. Conditional move available on z\/Architecture only from z196 onwards. Not exploited yet.\n+  static const int long_cmove_cost() { return ConditionalMoveLimit; }\n+\n+  \/\/ Suppress CMOVF. Conditional move available on z\/Architecture only from z196 onwards. Not exploited yet.\n+  static const int float_cmove_cost() { return ConditionalMoveLimit; }\n+\n+  \/\/ Set this as clone_shift_expressions.\n+  static bool narrow_oop_use_complex_address() {\n+    if (CompressedOops::base() == NULL && CompressedOops::shift() == 0) return true;\n+    return false;\n+  }\n+\n+  static bool narrow_klass_use_complex_address() {\n+    NOT_LP64(ShouldNotCallThis());\n+    assert(UseCompressedClassPointers, \"only for compressed klass code\");\n+    \/\/ TODO HS25: z port if (MatchDecodeNodes) return true;\n+    return false;\n+  }\n+\n+  static bool const_oop_prefer_decode() {\n+    \/\/ Prefer ConN+DecodeN over ConP in simple compressed oops mode.\n+    return CompressedOops::base() == NULL;\n+  }\n+\n+  static bool const_klass_prefer_decode() {\n+    \/\/ Prefer ConNKlass+DecodeNKlass over ConP in simple compressed klass mode.\n+    return CompressedKlassPointers::base() == NULL;\n+  }\n+\n+  \/\/ Is it better to copy float constants, or load them directly from memory?\n+  \/\/ Most RISCs will have to materialize an address into a\n+  \/\/ register first, so they would do better to copy the constant from stack.\n+  static const bool rematerialize_float_constants = false;\n+\n+  \/\/ If CPU can load and store mis-aligned doubles directly then no fixup is\n+  \/\/ needed. Else we split the double into 2 integer pieces and move it\n+  \/\/ piece-by-piece. Only happens when passing doubles into C code as the\n+  \/\/ Java calling convention forces doubles to be aligned.\n+  static const bool misaligned_doubles_ok = true;\n+\n+  \/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n+  static const bool strict_fp_requires_explicit_rounding = false;\n+\n+  \/\/ Do floats take an entire double register or just half?\n+  \/\/\n+  \/\/ A float in resides in a zarch double register. When storing it by\n+  \/\/ z_std, it cannot be restored in C-code by reloading it as a double\n+  \/\/ and casting it into a float afterwards.\n+  static constexpr bool float_in_double() { return false; }\n+\n+  \/\/ Do ints take an entire long register or just half?\n+  \/\/ The relevant question is how the int is callee-saved:\n+  \/\/ the whole long is written but de-opt'ing will have to extract\n+  \/\/ the relevant 32 bits.\n+  static const bool int_in_long = true;\n+\n+  \/\/ Does the CPU supports vector variable shift instructions?\n+  static constexpr bool supports_vector_variable_shifts(void) {\n+    return false;\n+  }\n+\n+  \/\/ Does the CPU supports vector variable rotate instructions?\n+  static constexpr bool supports_vector_variable_rotates(void) {\n+    return false;\n+  }\n+\n+  static bool supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+    return false;\n+  }\n+\n+  \/\/ Vector calling convention not yet implemented.\n+  static const bool supports_vector_calling_convention(void) {\n+    return false;\n+  }\n+\n+  static void vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+    (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+  }\n+\n+  static OptoRegPair vector_return_value(uint ideal_reg) {\n+    Unimplemented();\n+    return OptoRegPair(0, 0);\n+  }\n+\n+  \/\/ Some microarchitectures have mask registers used on vectors\n+  static constexpr bool has_predicated_vectors(void) {\n+    return false;\n+  }\n+\n+  \/\/ true means we have fast l2f convers\n+  \/\/ false means that conversion is done by runtime call\n+  static constexpr bool convL2FSupported(void) {\n+      return true;\n+  }\n+\n+#endif \/\/ CPU_S390_MATCHER_S390_HPP\n","filename":"src\/hotspot\/cpu\/s390\/matcher_s390.hpp","additions":160,"deletions":0,"binary":false,"changes":160,"status":"added"},{"patch":"@@ -1472,0 +1472,7 @@\n+void Assembler::andb(Address dst, Register src) {\n+  InstructionMark im(this);\n+  prefix(dst, src);\n+  emit_int8(0x20);\n+  emit_operand(src, dst);\n+}\n+\n@@ -1480,3 +1487,1 @@\n-  emit_int8((unsigned char)0x81);\n-  emit_operand(rsp, dst, 4);\n-  emit_int32(imm32);\n+  emit_arith_operand(0x81, as_Register(4), dst, imm32);\n@@ -1490,0 +1495,7 @@\n+void Assembler::andl(Address dst, Register src) {\n+  InstructionMark im(this);\n+  prefix(dst, src);\n+  emit_int8(0x21);\n+  emit_operand(src, dst);\n+}\n+\n@@ -1652,0 +1664,1 @@\n+  InstructionMark im(this);\n@@ -1674,0 +1687,6 @@\n+void Assembler::cmp(Register dst, int32_t imm32) {\n+  prefix(dst);\n+  emit_int8((unsigned char)0x3D);\n+  emit_int32(imm32);\n+}\n+\n@@ -1709,0 +1728,8 @@\n+void Assembler::cmpxchgw(Register reg, Address adr) { \/\/ cmpxchg\n+  InstructionMark im(this);\n+  size_prefix();\n+  prefix(adr, reg);\n+  emit_int16(0x0F, (unsigned char)0xB1);\n+  emit_operand(reg, adr);\n+}\n+\n@@ -2171,0 +2198,13 @@\n+void Assembler::imull(Register dst, Address src, int32_t value) {\n+  InstructionMark im(this);\n+  prefix(src, dst);\n+  if (is8bit(value)) {\n+    emit_int8((unsigned char)0x6B);\n+    emit_operand(dst, src);\n+    emit_int8(value);\n+  } else {\n+    emit_int8((unsigned char)0x69);\n+    emit_operand(dst, src);\n+    emit_int32(value);\n+  }\n+}\n@@ -2354,0 +2394,4 @@\n+void Assembler::size_prefix() {\n+  emit_int8(0x66);\n+}\n+\n@@ -3249,0 +3293,7 @@\n+void Assembler::negl(Address dst) {\n+  InstructionMark im(this);\n+  prefix(dst);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(as_Register(3), dst);\n+}\n+\n@@ -3603,0 +3654,7 @@\n+void Assembler::orb(Address dst, Register src) {\n+  InstructionMark im(this);\n+  prefix(dst, src, true);\n+  emit_int8(0x08);\n+  emit_operand(src, dst);\n+}\n+\n@@ -5014,0 +5072,59 @@\n+void Assembler::sall(Address dst, int imm8) {\n+  InstructionMark im(this);\n+  assert(isShiftCount(imm8), \"illegal shift count\");\n+  prefix(dst);\n+  if (imm8 == 1) {\n+    emit_int8((unsigned char)0xD1);\n+    emit_operand(as_Register(4), dst);\n+  }\n+  else {\n+    emit_int8((unsigned char)0xC1);\n+    emit_operand(as_Register(4), dst);\n+    emit_int8(imm8);\n+  }\n+}\n+\n+void Assembler::sall(Address dst) {\n+  InstructionMark im(this);\n+  prefix(dst);\n+  emit_int8((unsigned char)0xD3);\n+  emit_operand(as_Register(4), dst);\n+}\n+\n+void Assembler::sall(Register dst, int imm8) {\n+  assert(isShiftCount(imm8), \"illegal shift count\");\n+  int encode = prefix_and_encode(dst->encoding());\n+  if (imm8 == 1) {\n+    emit_int16((unsigned char)0xD1, (0xE0 | encode));\n+  } else {\n+    emit_int24((unsigned char)0xC1, (0xE0 | encode), imm8);\n+  }\n+}\n+\n+void Assembler::sall(Register dst) {\n+  int encode = prefix_and_encode(dst->encoding());\n+  emit_int16((unsigned char)0xD3, (0xE0 | encode));\n+}\n+\n+void Assembler::sarl(Address dst, int imm8) {\n+  assert(isShiftCount(imm8), \"illegal shift count\");\n+  InstructionMark im(this);\n+  prefix(dst);\n+  if (imm8 == 1) {\n+    emit_int8((unsigned char)0xD1);\n+    emit_operand(as_Register(7), dst);\n+  }\n+  else {\n+    emit_int8((unsigned char)0xC1);\n+    emit_operand(as_Register(7), dst);\n+    emit_int8(imm8);\n+  }\n+}\n+\n+void Assembler::sarl(Address dst) {\n+  InstructionMark im(this);\n+  prefix(dst);\n+  emit_int8((unsigned char)0xD3);\n+  emit_operand(as_Register(7), dst);\n+}\n+\n@@ -5059,0 +5176,15 @@\n+void Assembler::sete(Register dst) {\n+  int encode = prefix_and_encode(dst->encoding(), true);\n+  emit_int24(0x0F, (unsigned char)0x94, (0xC0 | encode));\n+}\n+\n+void Assembler::setl(Register dst) {\n+  int encode = prefix_and_encode(dst->encoding(), true);\n+  emit_int24(0x0F, (unsigned char)0x9C, (0xC0 | encode));\n+}\n+\n+void Assembler::setne(Register dst) {\n+  int encode = prefix_and_encode(dst->encoding(), true);\n+  emit_int24(0x0F, (unsigned char)0x95, (0xC0 | encode));\n+}\n+\n@@ -5152,1 +5284,6 @@\n-  emit_int24((unsigned char)0xC1, (0xE8 | encode), imm8);\n+  if (imm8 == 1) {\n+    emit_int16((unsigned char)0xD1, (0xE8 | encode));\n+  }\n+  else {\n+    emit_int24((unsigned char)0xC1, (0xE8 | encode), imm8);\n+  }\n@@ -5160,0 +5297,23 @@\n+void Assembler::shrl(Address dst) {\n+  InstructionMark im(this);\n+  prefix(dst);\n+  emit_int8((unsigned char)0xD3);\n+  emit_operand(as_Register(5), dst);\n+}\n+\n+void Assembler::shrl(Address dst, int imm8) {\n+  InstructionMark im(this);\n+  assert(isShiftCount(imm8), \"illegal shift count\");\n+  prefix(dst);\n+  if (imm8 == 1) {\n+    emit_int8((unsigned char)0xD1);\n+    emit_operand(as_Register(5), dst);\n+  }\n+  else {\n+    emit_int8((unsigned char)0xC1);\n+    emit_operand(as_Register(5), dst);\n+    emit_int8(imm8);\n+  }\n+}\n+\n+\n@@ -5350,6 +5510,2 @@\n-  if (encode == 0) {\n-    emit_int8((unsigned char)0xA9);\n-  } else {\n-    encode = prefix_and_encode(encode);\n-    emit_int16((unsigned char)0xF7, (0xC0 | encode));\n-  }\n+  encode = prefix_and_encode(encode);\n+  emit_int16((unsigned char)0xF7, (0xC0 | encode));\n@@ -5500,0 +5656,6 @@\n+void Assembler::xorl(Address dst, int32_t imm32) {\n+  InstructionMark im(this);\n+  prefix(dst);\n+  emit_arith_operand(0x81, as_Register(6), dst, imm32);\n+}\n+\n@@ -5517,0 +5679,7 @@\n+void Assembler::xorl(Address dst, Register src) {\n+  InstructionMark im(this);\n+  prefix(dst, src);\n+  emit_int8(0x31);\n+  emit_operand(src, dst);\n+}\n+\n@@ -5524,0 +5693,7 @@\n+void Assembler::xorb(Address dst, Register src) {\n+  InstructionMark im(this);\n+  prefix(dst, src, true);\n+  emit_int8(0x30);\n+  emit_operand(src, dst);\n+}\n+\n@@ -9258,1 +9434,1 @@\n-  emit_int24(0x0F, (unsigned char)0x95, (0xE0 | dst->encoding()));\n+  emit_int24(0x0F, (unsigned char)0x95, (0xC0 | dst->encoding()));\n@@ -9265,1 +9441,1 @@\n-  emit_int24(0x0F, (unsigned char)0x95, (0xE0 | enc));\n+  emit_int24(0x0F, (unsigned char)0x95, (0xC0 | enc));\n@@ -9692,3 +9868,2 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0x81);\n-  emit_operand(rsp, dst, 4);\n-  emit_int32(imm32);\n+  prefixq(dst);\n+  emit_arith_operand(0x81, as_Register(4), dst, imm32);\n@@ -9713,0 +9888,6 @@\n+void Assembler::andq(Address dst, Register src) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst, src), 0x21);\n+  emit_operand(src, dst);\n+}\n+\n@@ -9980,0 +10161,19 @@\n+void Assembler::imulq(Register src) {\n+  int encode = prefixq_and_encode(src->encoding());\n+  emit_int16((unsigned char)0xF7, (0xE8 | encode));\n+}\n+\n+void Assembler::imulq(Register dst, Address src, int32_t value) {\n+  InstructionMark im(this);\n+  prefixq(src, dst);\n+  if (is8bit(value)) {\n+    emit_int8((unsigned char)0x6B);\n+    emit_operand(dst, src);\n+    emit_int8(value);\n+  } else {\n+    emit_int8((unsigned char)0x69);\n+    emit_operand(dst, src);\n+    emit_int32(value);\n+  }\n+}\n+\n@@ -10034,0 +10234,7 @@\n+void Assembler::mov64(Register dst, int64_t imm64, relocInfo::relocType rtype, int format) {\n+  InstructionMark im(this);\n+  int encode = prefixq_and_encode(dst->encoding());\n+  emit_int8(0xB8 | encode);\n+  emit_data64(imm64, rtype, format);\n+}\n+\n@@ -10114,0 +10321,13 @@\n+void Assembler::movq(Address dst, int32_t imm32) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst), (unsigned char)0xC7);\n+  emit_operand(as_Register(0), dst);\n+  emit_int32(imm32);\n+}\n+\n+void Assembler::movq(Register dst, int32_t imm32) {\n+  int encode = prefixq_and_encode(dst->encoding());\n+  emit_int16((unsigned char)0xC7, (0xC0 | encode));\n+  emit_int32(imm32);\n+}\n+\n@@ -10219,0 +10439,6 @@\n+void Assembler::negq(Address dst) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst), (unsigned char)0xF7);\n+  emit_operand(as_Register(3), dst);\n+}\n+\n@@ -10246,3 +10472,8 @@\n-  emit_int16(get_prefixq(dst), (unsigned char)0x81);\n-  emit_operand(rcx, dst, 4);\n-  emit_int32(imm32);\n+  prefixq(dst);\n+  emit_arith_operand(0x81, as_Register(1), dst, imm32);\n+}\n+\n+void Assembler::orq(Address dst, Register src) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst, src), (unsigned char)0x09);\n+  emit_operand(src, dst);\n@@ -10290,0 +10521,4 @@\n+void Assembler::popq(Register dst) {\n+  emit_int8((unsigned char)0x58 | dst->encoding());\n+}\n+\n@@ -10459,0 +10694,56 @@\n+#ifdef _LP64\n+void Assembler::salq(Address dst, int imm8) {\n+  InstructionMark im(this);\n+  assert(isShiftCount(imm8 >> 1), \"illegal shift count\");\n+  if (imm8 == 1) {\n+    emit_int16(get_prefixq(dst), (unsigned char)0xD1);\n+    emit_operand(as_Register(4), dst);\n+  }\n+  else {\n+    emit_int16(get_prefixq(dst), (unsigned char)0xC1);\n+    emit_operand(as_Register(4), dst);\n+    emit_int8(imm8);\n+  }\n+}\n+\n+void Assembler::salq(Address dst) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst), (unsigned char)0xD3);\n+  emit_operand(as_Register(4), dst);\n+}\n+\n+void Assembler::salq(Register dst, int imm8) {\n+  assert(isShiftCount(imm8 >> 1), \"illegal shift count\");\n+  int encode = prefixq_and_encode(dst->encoding());\n+  if (imm8 == 1) {\n+    emit_int16((unsigned char)0xD1, (0xE0 | encode));\n+  } else {\n+    emit_int24((unsigned char)0xC1, (0xE0 | encode), imm8);\n+  }\n+}\n+\n+void Assembler::salq(Register dst) {\n+  int encode = prefixq_and_encode(dst->encoding());\n+  emit_int16((unsigned char)0xD3, (0xE0 | encode));\n+}\n+\n+void Assembler::sarq(Address dst, int imm8) {\n+  InstructionMark im(this);\n+  assert(isShiftCount(imm8 >> 1), \"illegal shift count\");\n+  if (imm8 == 1) {\n+    emit_int16(get_prefixq(dst), (unsigned char)0xD1);\n+    emit_operand(as_Register(7), dst);\n+  }\n+  else {\n+    emit_int16(get_prefixq(dst), (unsigned char)0xC1);\n+    emit_operand(as_Register(7), dst);\n+    emit_int8(imm8);\n+  }\n+}\n+\n+void Assembler::sarq(Address dst) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst), (unsigned char)0xD3);\n+  emit_operand(as_Register(7), dst);\n+}\n+\n@@ -10473,0 +10764,1 @@\n+#endif\n@@ -10514,1 +10806,6 @@\n-  emit_int24((unsigned char)0xC1, (0xE8 | encode), imm8);\n+  if (imm8 == 1) {\n+    emit_int16((unsigned char)0xD1, (0xE8 | encode));\n+  }\n+  else {\n+    emit_int24((unsigned char)0xC1, (0xE8 | encode), imm8);\n+  }\n@@ -10522,0 +10819,20 @@\n+void Assembler::shrq(Address dst) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst), (unsigned char)0xD3);\n+  emit_operand(as_Register(5), dst);\n+}\n+\n+void Assembler::shrq(Address dst, int imm8) {\n+  InstructionMark im(this);\n+  assert(isShiftCount(imm8 >> 1), \"illegal shift count\");\n+  if (imm8 == 1) {\n+    emit_int16(get_prefixq(dst), (unsigned char)0xD1);\n+    emit_operand(as_Register(5), dst);\n+  }\n+  else {\n+    emit_int16(get_prefixq(dst), (unsigned char)0xC1);\n+    emit_operand(as_Register(5), dst);\n+    emit_int8(imm8);\n+  }\n+}\n+\n@@ -10556,0 +10873,7 @@\n+void Assembler::testq(Address dst, int32_t imm32) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst), (unsigned char)0xF7);\n+  emit_operand(as_Register(0), dst);\n+  emit_int32(imm32);\n+}\n+\n@@ -10561,6 +10885,2 @@\n-  if (encode == 0) {\n-    emit_int16(REX_W, (unsigned char)0xA9);\n-  } else {\n-    encode = prefixq_and_encode(encode);\n-    emit_int16((unsigned char)0xF7, (0xC0 | encode));\n-  }\n+  encode = prefixq_and_encode(encode);\n+  emit_int16((unsigned char)0xF7, (0xC0 | encode));\n@@ -10609,0 +10929,17 @@\n+void Assembler::xorq(Register dst, int32_t imm32) {\n+  (void) prefixq_and_encode(dst->encoding());\n+  emit_arith(0x81, 0xF0, dst, imm32);\n+}\n+\n+void Assembler::xorq(Address dst, int32_t imm32) {\n+  InstructionMark im(this);\n+  prefixq(dst);\n+  emit_arith_operand(0x81, as_Register(6), dst, imm32);\n+}\n+\n+void Assembler::xorq(Address dst, Register src) {\n+  InstructionMark im(this);\n+  emit_int16(get_prefixq(dst, src), 0x31);\n+  emit_operand(src, dst);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":362,"deletions":25,"binary":false,"changes":387,"status":"modified"},{"patch":"@@ -1015,0 +1015,1 @@\n+  void andb(Address dst, Register src);\n@@ -1020,0 +1021,1 @@\n+  void andl(Address dst, Register src);\n@@ -1025,0 +1027,1 @@\n+  void andq(Address dst, Register src);\n@@ -1084,0 +1087,1 @@\n+  void cmp(Register dst, int32_t imm32);\n@@ -1107,0 +1111,1 @@\n+  void cmpxchgw(Register reg, Address adr);\n@@ -1366,0 +1371,1 @@\n+  void imull(Register dst, Address src, int value);\n@@ -1371,0 +1377,1 @@\n+  void imulq(Register dst, Address src, int value);\n@@ -1372,0 +1379,1 @@\n+  void imulq(Register dst);\n@@ -1427,0 +1435,1 @@\n+  void size_prefix();\n@@ -1450,0 +1459,1 @@\n+  void mov64(Register dst, int64_t imm64, relocInfo::relocType rtype, int format);\n@@ -1549,0 +1559,2 @@\n+  void movq(Address  dst, int32_t imm32);\n+  void movq(Register  dst, int32_t imm32);\n@@ -1627,0 +1639,1 @@\n+  void negl(Address dst);\n@@ -1630,0 +1643,1 @@\n+  void negq(Address dst);\n@@ -1652,0 +1666,1 @@\n+  void orb(Address dst, Register src);\n@@ -1654,0 +1669,1 @@\n+  void orq(Address dst, Register src);\n@@ -1807,0 +1823,1 @@\n+  void popq(Register dst);\n@@ -1917,0 +1934,7 @@\n+  void sall(Register dst, int imm8);\n+  void sall(Register dst);\n+  void sall(Address dst, int imm8);\n+  void sall(Address dst);\n+\n+  void sarl(Address dst, int imm8);\n+  void sarl(Address dst);\n@@ -1920,0 +1944,8 @@\n+#ifdef _LP64\n+  void salq(Register dst, int imm8);\n+  void salq(Register dst);\n+  void salq(Address dst, int imm8);\n+  void salq(Address dst);\n+\n+  void sarq(Address dst, int imm8);\n+  void sarq(Address dst);\n@@ -1922,0 +1954,1 @@\n+#endif\n@@ -1935,0 +1968,4 @@\n+  void sete(Register dst);\n+  void setl(Register dst);\n+  void setne(Register dst);\n+\n@@ -1964,0 +2001,2 @@\n+  void shrl(Address dst);\n+  void shrl(Address dst, int imm8);\n@@ -1967,0 +2006,2 @@\n+  void shrq(Address dst);\n+  void shrq(Address dst, int imm8);\n@@ -2016,0 +2057,1 @@\n+  void testq(Address dst, int32_t imm32);\n@@ -2055,0 +2097,1 @@\n+  void xorl(Address dst, int32_t imm32);\n@@ -2057,0 +2100,1 @@\n+  void xorl(Address dst, Register src);\n@@ -2058,0 +2102,1 @@\n+  void xorb(Address dst, Register src);\n@@ -2062,0 +2107,1 @@\n+  void xorq(Address dst, int32_t imm32);\n@@ -2063,0 +2109,2 @@\n+  void xorq(Register dst, int32_t imm32);\n+  void xorq(Address dst, Register src);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -1048,0 +1048,29 @@\n+\/\/ Float\/Double signum\n+void C2_MacroAssembler::signum_fp(int opcode, XMMRegister dst,\n+                                  XMMRegister zero, XMMRegister one,\n+                                  Register scratch) {\n+  assert(opcode == Op_SignumF || opcode == Op_SignumD, \"sanity\");\n+\n+  Label DONE_LABEL;\n+\n+  if (opcode == Op_SignumF) {\n+    assert(UseSSE > 0, \"required\");\n+    ucomiss(dst, zero);\n+    jcc(Assembler::equal, DONE_LABEL);    \/\/ handle special case +0.0\/-0.0, if argument is +0.0\/-0.0, return argument\n+    jcc(Assembler::parity, DONE_LABEL);   \/\/ handle special case NaN, if argument NaN, return NaN\n+    movflt(dst, one);\n+    jcc(Assembler::above, DONE_LABEL);\n+    xorps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), scratch);\n+  } else if (opcode == Op_SignumD) {\n+    assert(UseSSE > 1, \"required\");\n+    ucomisd(dst, zero);\n+    jcc(Assembler::equal, DONE_LABEL);    \/\/ handle special case +0.0\/-0.0, if argument is +0.0\/-0.0, return argument\n+    jcc(Assembler::parity, DONE_LABEL);   \/\/ handle special case NaN, if argument NaN, return NaN\n+    movdbl(dst, one);\n+    jcc(Assembler::above, DONE_LABEL);\n+    xorpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), scratch);\n+  }\n+\n+  bind(DONE_LABEL);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -92,0 +92,4 @@\n+  void signum_fp(int opcode, XMMRegister dst,\n+                 XMMRegister zero, XMMRegister one,\n+                 Register scratch);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -124,10 +124,1 @@\n-void MacroAssembler::cmpoop_raw(Address src1, jobject obj) {\n-  cmp_literal32(src1, (int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-void MacroAssembler::cmpoop_raw(Register src1, jobject obj) {\n-  cmp_literal32(src1, (int32_t)obj, oop_Relocation::spec_for_immediate());\n-}\n-\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->obj_equals(this, src1, obj);\n+  cmp_literal32(src1, (int32_t)obj, oop_Relocation::spec_for_immediate());\n@@ -138,2 +129,1 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->obj_equals(this, src1, obj);\n+  cmp_literal32(src1, (int32_t)obj, oop_Relocation::spec_for_immediate());\n@@ -1797,2 +1787,1 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->obj_equals(this, src1, src2);\n+  cmpptr(src1, src2);\n@@ -1802,2 +1791,1 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->obj_equals(this, src1, src2);\n+  cmpptr(src1, src2);\n@@ -1809,2 +1797,1 @@\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  bs->obj_equals(this, src1, rscratch1);\n+  cmpptr(src1, rscratch1);\n@@ -4564,9 +4551,0 @@\n-void MacroAssembler::resolve(DecoratorSet decorators, Register obj) {\n-  \/\/ Use stronger ACCESS_WRITE|ACCESS_READ by default.\n-  if ((decorators & (ACCESS_READ | ACCESS_WRITE)) == 0) {\n-    decorators |= ACCESS_READ | ACCESS_WRITE;\n-  }\n-  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n-  return bs->resolve(this, decorators, obj);\n-}\n-\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":5,"deletions":27,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -330,4 +330,0 @@\n-  \/\/ Resolves obj access. Result is placed in the same register.\n-  \/\/ All other registers are preserved.\n-  void resolve(DecoratorSet decorators, Register obj);\n-\n@@ -716,1 +712,0 @@\n-  void cmpoop_raw(Address dst, jobject obj);\n@@ -722,1 +717,0 @@\n-  void cmpoop_raw(Register dst, jobject obj);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,218 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef CPU_X86_MATCHER_X86_HPP\n+#define CPU_X86_MATCHER_X86_HPP\n+\n+  \/\/ Defined within class Matcher\n+\n+  \/\/ The ecx parameter to rep stosq for the ClearArray node is in words.\n+  static const bool init_array_count_is_in_bytes = false;\n+\n+  \/\/ Whether this platform implements the scalable vector feature\n+  static const bool implements_scalable_vector = false;\n+\n+  static constexpr bool supports_scalable_vector() {\n+    return false;\n+  }\n+\n+  \/\/ x86 supports misaligned vectors store\/load.\n+  static constexpr bool misaligned_vectors_ok() {\n+    return true;\n+  }\n+\n+  \/\/ Whether code generation need accurate ConvI2L types.\n+  static const bool convi2l_type_required = true;\n+\n+  \/\/ Do the processor's shift instructions only use the low 5\/6 bits\n+  \/\/ of the count for 32\/64 bit ints? If not we need to do the masking\n+  \/\/ ourselves.\n+  static const bool need_masked_shift_count = false;\n+\n+  \/\/ Does the CPU require late expand (see block.cpp for description of late expand)?\n+  static const bool require_postalloc_expand = false;\n+\n+  \/\/ x86 supports generic vector operands: vec and legVec.\n+  static const bool supports_generic_vector_operands = true;\n+\n+  static constexpr bool isSimpleConstant64(jlong value) {\n+    \/\/ Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.\n+    \/\/return value == (int) value;  \/\/ Cf. storeImmL and immL32.\n+\n+    \/\/ Probably always true, even if a temp register is required.\n+#ifdef _LP64\n+    return true;\n+#else\n+    return false;\n+#endif\n+  }\n+\n+#ifdef _LP64\n+  \/\/ No additional cost for CMOVL.\n+  static constexpr int long_cmove_cost() { return 0; }\n+#else\n+  \/\/ Needs 2 CMOV's for longs.\n+  static constexpr int long_cmove_cost() { return 1; }\n+#endif\n+\n+#ifdef _LP64\n+  \/\/ No CMOVF\/CMOVD with SSE2\n+  static int float_cmove_cost() { return ConditionalMoveLimit; }\n+#else\n+  \/\/ No CMOVF\/CMOVD with SSE\/SSE2\n+  static int float_cmove_cost() { return (UseSSE>=1) ? ConditionalMoveLimit : 0; }\n+#endif\n+\n+  static bool narrow_oop_use_complex_address() {\n+    NOT_LP64(ShouldNotCallThis();)\n+    assert(UseCompressedOops, \"only for compressed oops code\");\n+    return (LogMinObjAlignmentInBytes <= 3);\n+  }\n+\n+  static bool narrow_klass_use_complex_address() {\n+    NOT_LP64(ShouldNotCallThis();)\n+    assert(UseCompressedClassPointers, \"only for compressed klass code\");\n+    return (LogKlassAlignmentInBytes <= 3);\n+  }\n+\n+  \/\/ Prefer ConN+DecodeN over ConP.\n+  static const bool const_oop_prefer_decode() {\n+    NOT_LP64(ShouldNotCallThis();)\n+    \/\/ Prefer ConN+DecodeN over ConP.\n+    return true;\n+  }\n+\n+  \/\/ Prefer ConP over ConNKlass+DecodeNKlass.\n+  static const bool const_klass_prefer_decode() {\n+    NOT_LP64(ShouldNotCallThis();)\n+    return false;\n+  }\n+\n+  \/\/ Is it better to copy float constants, or load them directly from memory?\n+  \/\/ Intel can load a float constant from a direct address, requiring no\n+  \/\/ extra registers.  Most RISCs will have to materialize an address into a\n+  \/\/ register first, so they would do better to copy the constant from stack.\n+  static const bool rematerialize_float_constants = true;\n+\n+  \/\/ If CPU can load and store mis-aligned doubles directly then no fixup is\n+  \/\/ needed.  Else we split the double into 2 integer pieces and move it\n+  \/\/ piece-by-piece.  Only happens when passing doubles into C code as the\n+  \/\/ Java calling convention forces doubles to be aligned.\n+  static const bool misaligned_doubles_ok = true;\n+\n+  \/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n+#ifdef _LP64\n+  static const bool strict_fp_requires_explicit_rounding = false;\n+#else\n+  static const bool strict_fp_requires_explicit_rounding = true;\n+#endif\n+\n+  \/\/ Are floats converted to double when stored to stack during deoptimization?\n+  \/\/ On x64 it is stored without convertion so we can use normal access.\n+  \/\/ On x32 it is stored with convertion only when FPU is used for floats.\n+#ifdef _LP64\n+  static constexpr bool float_in_double() {\n+    return false;\n+  }\n+#else\n+  static bool float_in_double() {\n+    return (UseSSE == 0);\n+  }\n+#endif\n+\n+  \/\/ Do ints take an entire long register or just half?\n+#ifdef _LP64\n+  static const bool int_in_long = true;\n+#else\n+  static const bool int_in_long = false;\n+#endif\n+\n+  \/\/ Does the CPU supports vector variable shift instructions?\n+  static bool supports_vector_variable_shifts(void) {\n+    return (UseAVX >= 2);\n+  }\n+\n+  \/\/ Does the CPU supports vector variable rotate instructions?\n+  static constexpr bool supports_vector_variable_rotates(void) {\n+    return true;\n+  }\n+\n+  static bool supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n+    if ((UseAVX > 2) && (VM_Version::supports_avx512vl() || vlen == 64))\n+      return true;\n+    else {\n+      \/\/ instruction set supports only signed comparison\n+      \/\/ so need to zero extend to higher integral type and perform comparison\n+      \/\/ cannot cast long to higher integral type\n+      \/\/ and on avx1 cannot cast 128 bit integral vectors to higher size\n+\n+      if ((bt != T_LONG)  &&\n+          ((UseAVX >= 2) || (vlen <= 8)))\n+        return true;\n+    }\n+    return false;\n+  }\n+\n+  static const bool supports_vector_calling_convention() {\n+#ifdef _LP64\n+    return true;\n+#else\n+    return false;\n+#endif\n+  }\n+\n+  static void vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n+    (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n+  }\n+\n+  static OptoRegPair vector_return_value(uint ideal_reg) {\n+#ifdef _LP64\n+    int lo = XMM0_num;\n+    int hi = XMM0b_num;\n+    if (ideal_reg == Op_VecX) hi = XMM0d_num;\n+    else if (ideal_reg == Op_VecY) hi = XMM0h_num;\n+    else if (ideal_reg == Op_VecZ) hi = XMM0p_num;\n+    return OptoRegPair(hi, lo);\n+#else\n+    Unimplemented();\n+    return OptoRegPair(0, 0);\n+#endif\n+  }\n+\n+  \/\/ Some microarchitectures have mask registers used on vectors\n+  static const bool has_predicated_vectors(void) {\n+    bool ret_value = false;\n+    if (UseAVX > 2) {\n+      ret_value = VM_Version::supports_avx512vl();\n+    }\n+    return ret_value;\n+  }\n+\n+  \/\/ true means we have fast l2f convers\n+  \/\/ false means that conversion is done by runtime call\n+  static constexpr bool convL2FSupported(void) {\n+      return true;\n+  }\n+\n+#endif \/\/ CPU_X86_MATCHER_X86_HPP\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":218,"deletions":0,"binary":false,"changes":218,"status":"added"},{"patch":"@@ -2289,1 +2289,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n@@ -2442,1 +2441,0 @@\n-    __ resolve(IS_NOT_NULL, obj_reg);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1606,0 +1606,10 @@\n+    case Op_SignumF:\n+      if (UseSSE < 1) {\n+        return false;\n+      }\n+      break;\n+    case Op_SignumD:\n+      if (UseSSE < 2) {\n+        return false;\n+      }\n+      break;\n@@ -1823,3 +1833,0 @@\n-\/\/ x86 supports generic vector operands: vec and legVec.\n-const bool Matcher::supports_generic_vector_operands = true;\n-\n@@ -1877,33 +1884,0 @@\n-bool Matcher::supports_vector_variable_shifts(void) {\n-  return (UseAVX >= 2);\n-}\n-\n-bool Matcher::supports_vector_variable_rotates(void) {\n-  return true;\n-}\n-\n-bool Matcher::supports_unsigned_vector_comparison(int vlen, BasicType bt) {\n-  if ((UseAVX > 2) && (VM_Version::supports_avx512vl() || vlen == 64))\n-    return true;\n-  else {\n-    \/\/ instruction set supports only signed comparison\n-    \/\/ so need to zero extend to higher integral type and perform comparison\n-    \/\/ cannot cast long to higher integral type\n-    \/\/ and on avx1 cannot cast 128 bit integral vectors to higher size\n-\n-    if ((bt != T_LONG)  &&\n-        ((UseAVX >= 2) || (vlen <= 8)))\n-      return true;\n-  }\n-  return false;\n-}\n-\n-const bool Matcher::has_predicated_vectors(void) {\n-  bool ret_value = false;\n-  if (UseAVX > 2) {\n-    ret_value = VM_Version::supports_avx512vl();\n-  }\n-\n-  return ret_value;\n-}\n-\n@@ -1988,4 +1962,0 @@\n-const bool Matcher::supports_scalable_vector() {\n-  return false;\n-}\n-\n@@ -2010,8 +1980,0 @@\n-\/\/ x86 supports misaligned vectors store\/load.\n-const bool Matcher::misaligned_vectors_ok() {\n-  return true;\n-}\n-\n-\n-const bool Matcher::convi2l_type_required = true;\n-\n@@ -2151,0 +2113,4 @@\n+  if (is_vshift_con_pattern(n, m)) { \/\/ ShiftV src (ShiftCntV con)\n+    mstack.push(m, Visit);           \/\/ m = ShiftCntV\n+    return true;\n+  }\n@@ -2195,3 +2161,0 @@\n-void Compile::reshape_address(AddPNode* addp) {\n-}\n-\n@@ -5817,0 +5780,24 @@\n+\/\/ --------------------------------- Signum ---------------------------\n+\n+instruct signumF_reg(regF dst, regF zero, regF one, rRegP scratch, rFlagsReg cr) %{\n+  match(Set dst (SignumF dst (Binary zero one)));\n+  effect(TEMP scratch, KILL cr);\n+  format %{ \"signumF $dst, $dst\\t! using $scratch as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    __ signum_fp(opcode, $dst$$XMMRegister, $zero$$XMMRegister, $one$$XMMRegister, $scratch$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct signumD_reg(regD dst, regD zero, regD one, rRegP scratch, rFlagsReg cr) %{\n+  match(Set dst (SignumD dst (Binary zero one)));\n+  effect(TEMP scratch, KILL cr);\n+  format %{ \"signumD $dst, $dst\\t! using $scratch as TEMP\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    __ signum_fp(opcode, $dst$$XMMRegister, $zero$$XMMRegister, $one$$XMMRegister, $scratch$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":38,"deletions":51,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -1697,22 +1697,0 @@\n-const bool Matcher::supports_vector_calling_convention(void) {\n-  return true;\n-}\n-\n-void Matcher::vector_calling_convention(VMRegPair *regs, uint num_bits, uint total_args_passed) {\n-  (void) SharedRuntime::vector_calling_convention(regs, num_bits, total_args_passed);\n-}\n-\n-OptoRegPair Matcher::vector_return_value(uint ideal_reg) {\n-  int lo = XMM0_num;\n-  int hi = XMM0b_num;\n-  if (ideal_reg == Op_VecX) hi = XMM0d_num;\n-  else if (ideal_reg == Op_VecY) hi = XMM0h_num;\n-  else if (ideal_reg == Op_VecZ) hi = XMM0p_num;\n-  return OptoRegPair(hi, lo);\n-}\n-\n-\/\/ This is UltraSparc specific, true just means we have fast l2f conversion\n-const bool Matcher::convL2FSupported(void) {\n-  return true;\n-}\n-\n@@ -1736,67 +1714,0 @@\n-const bool Matcher::isSimpleConstant64(jlong value) {\n-  \/\/ Will one (StoreL ConL) be cheaper than two (StoreI ConI)?.\n-  \/\/return value == (int) value;  \/\/ Cf. storeImmL and immL32.\n-\n-  \/\/ Probably always true, even if a temp register is required.\n-  return true;\n-}\n-\n-\/\/ The ecx parameter to rep stosq for the ClearArray node is in words.\n-const bool Matcher::init_array_count_is_in_bytes = false;\n-\n-\/\/ No additional cost for CMOVL.\n-const int Matcher::long_cmove_cost() { return 0; }\n-\n-\/\/ No CMOVF\/CMOVD with SSE2\n-const int Matcher::float_cmove_cost() { return ConditionalMoveLimit; }\n-\n-\/\/ Does the CPU require late expand (see block.cpp for description of late expand)?\n-const bool Matcher::require_postalloc_expand = false;\n-\n-\/\/ Do we need to mask the count passed to shift instructions or does\n-\/\/ the cpu only look at the lower 5\/6 bits anyway?\n-const bool Matcher::need_masked_shift_count = false;\n-\n-bool Matcher::narrow_oop_use_complex_address() {\n-  assert(UseCompressedOops, \"only for compressed oops code\");\n-  return (LogMinObjAlignmentInBytes <= 3);\n-}\n-\n-bool Matcher::narrow_klass_use_complex_address() {\n-  assert(UseCompressedClassPointers, \"only for compressed klass code\");\n-  return (LogKlassAlignmentInBytes <= 3);\n-}\n-\n-bool Matcher::const_oop_prefer_decode() {\n-  \/\/ Prefer ConN+DecodeN over ConP.\n-  return true;\n-}\n-\n-bool Matcher::const_klass_prefer_decode() {\n-  \/\/ Prefer ConP over ConNKlass+DecodeNKlass.\n-  return false;\n-}\n-\n-\/\/ Is it better to copy float constants, or load them directly from\n-\/\/ memory?  Intel can load a float constant from a direct address,\n-\/\/ requiring no extra registers.  Most RISCs will have to materialize\n-\/\/ an address into a register first, so they would do better to copy\n-\/\/ the constant from stack.\n-const bool Matcher::rematerialize_float_constants = true; \/\/ XXX\n-\n-\/\/ If CPU can load and store mis-aligned doubles directly then no\n-\/\/ fixup is needed.  Else we split the double into 2 integer pieces\n-\/\/ and move it piece-by-piece.  Only happens when passing doubles into\n-\/\/ C code as the Java calling convention forces doubles to be aligned.\n-const bool Matcher::misaligned_doubles_ok = true;\n-\n-\/\/ Advertise here if the CPU requires explicit rounding operations to implement strictfp mode.\n-const bool Matcher::strict_fp_requires_explicit_rounding = false;\n-\n-\/\/ Are floats conerted to double when stored to stack during deoptimization?\n-\/\/ On x64 it is stored without convertion so we can use normal access.\n-bool Matcher::float_in_double() { return false; }\n-\n-\/\/ Do ints take an entire long register or just half?\n-const bool Matcher::int_in_long = true;\n-\n@@ -1976,0 +1887,3 @@\n+    MacroAssembler _masm(&cbuf);\n+    Label normal;\n+    Label done;\n@@ -1978,5 +1892,1 @@\n-    emit_opcode(cbuf, 0x3d);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x80);\n+    __ cmp(as_Register(RAX_enc), 0x80000000);\n@@ -1985,2 +1895,1 @@\n-    emit_opcode(cbuf, 0x75);\n-    emit_d8(cbuf, $div$$reg < 8 ? 0x07 : 0x08);\n+    __ jccb(Assembler::notEqual, normal);\n@@ -1989,2 +1898,1 @@\n-    emit_opcode(cbuf, 0x33);\n-    emit_d8(cbuf, 0xD2);\n+    __ xorl(as_Register(RDX_enc), as_Register(RDX_enc));\n@@ -1993,6 +1901,1 @@\n-    if ($div$$reg >= 8) {\n-      emit_opcode(cbuf, Assembler::REX_B);\n-    }\n-    emit_opcode(cbuf, 0x83);\n-    emit_rm(cbuf, 0x3, 0x7, $div$$reg & 7);\n-    emit_d8(cbuf, 0xFF);\n+    __ cmpl($div$$Register, -1);\n@@ -2001,2 +1904,1 @@\n-    emit_opcode(cbuf, 0x74);\n-    emit_d8(cbuf, $div$$reg < 8 ? 0x03 : 0x04);\n+    __ jccb(Assembler::equal, done);\n@@ -2006,1 +1908,2 @@\n-    emit_opcode(cbuf, 0x99);\n+    __ bind(normal);\n+    __ cdql();\n@@ -2008,1 +1911,1 @@\n-    \/\/ idivl (note: must be emitted by the user of this rule)\n+    \/\/ idivl\n@@ -2010,0 +1913,2 @@\n+    __ idivl($div$$Register);\n+    __ bind(done);\n@@ -2038,0 +1943,3 @@\n+    MacroAssembler _masm(&cbuf);\n+    Label normal;\n+    Label done;\n@@ -2040,10 +1948,1 @@\n-    emit_opcode(cbuf, Assembler::REX_W);\n-    emit_opcode(cbuf, 0xBA);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x00);\n-    emit_d8(cbuf, 0x80);\n+    __ mov64(as_Register(RDX_enc), 0x8000000000000000);\n@@ -2052,3 +1951,1 @@\n-    emit_opcode(cbuf, Assembler::REX_W);\n-    emit_opcode(cbuf, 0x39);\n-    emit_d8(cbuf, 0xD0);\n+    __ cmpq(as_Register(RAX_enc), as_Register(RDX_enc));\n@@ -2057,2 +1954,1 @@\n-    emit_opcode(cbuf, 0x75);\n-    emit_d8(cbuf, 0x08);\n+    __ jccb(Assembler::notEqual, normal);\n@@ -2061,2 +1957,1 @@\n-    emit_opcode(cbuf, 0x33);\n-    emit_d8(cbuf, 0xD2);\n+    __ xorl(as_Register(RDX_enc), as_Register(RDX_enc));\n@@ -2065,4 +1960,1 @@\n-    emit_opcode(cbuf, $div$$reg < 8 ? Assembler::REX_W : Assembler::REX_WB);\n-    emit_opcode(cbuf, 0x83);\n-    emit_rm(cbuf, 0x3, 0x7, $div$$reg & 7);\n-    emit_d8(cbuf, 0xFF);\n+    __ cmpq($div$$Register, -1);\n@@ -2071,2 +1963,1 @@\n-    emit_opcode(cbuf, 0x74);\n-    emit_d8(cbuf, 0x05);\n+    __ jccb(Assembler::equal, done);\n@@ -2076,2 +1967,2 @@\n-    emit_opcode(cbuf, Assembler::REX_W);\n-    emit_opcode(cbuf, 0x99);\n+    __ bind(normal);\n+    __ cdqq();\n@@ -2081,0 +1972,2 @@\n+    __ idivq($div$$Register);\n+    __ bind(done);\n@@ -5233,2 +5126,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ movl($dst$$Register, $mem$$Address);\n+  %}\n@@ -5246,2 +5140,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ movq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5272,2 +5167,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ movq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5568,2 +5464,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5579,2 +5476,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5584,11 +5482,0 @@\n-\/\/ instruct leaPIdx(rRegP dst, indIndex mem)\n-\/\/ %{\n-\/\/   match(Set dst mem);\n-\n-\/\/   ins_cost(110);\n-\/\/   format %{ \"leaq    $dst, $mem\\t# ptr idx\" %}\n-\/\/   opcode(0x8D);\n-\/\/   ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n-\/\/   ins_pipe(ialu_reg_reg_fat);\n-\/\/ %}\n-\n@@ -5601,2 +5488,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5612,2 +5500,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5623,2 +5512,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5634,2 +5524,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5645,2 +5536,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5656,2 +5548,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5669,2 +5562,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5681,2 +5575,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5693,2 +5588,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5705,2 +5601,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5717,2 +5614,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5729,2 +5627,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5741,2 +5640,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5753,2 +5653,3 @@\n-  opcode(0x8D);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ leaq($dst$$Register, $mem$$Address);\n+  %}\n@@ -5763,1 +5664,3 @@\n-  ins_encode(load_immI(dst, src));\n+  ins_encode %{\n+    __ movl($dst$$Register, $src$$constant);\n+  %}\n@@ -5774,2 +5677,3 @@\n-  opcode(0x33); \/* + rd *\/\n-  ins_encode(REX_reg_reg(dst, dst), OpcP, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ xorl($dst$$Register, $dst$$Register);\n+  %}\n@@ -5785,1 +5689,3 @@\n-  ins_encode(load_immL(dst, src));\n+  ins_encode %{\n+    __ mov64($dst$$Register, $src$$constant);\n+  %}\n@@ -5796,2 +5702,3 @@\n-  opcode(0x33); \/* + rd *\/\n-  ins_encode(REX_reg_reg(dst, dst), OpcP, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ xorl($dst$$Register, $dst$$Register);\n+  %}\n@@ -5807,1 +5714,3 @@\n-  ins_encode(load_immUL32(dst, src));\n+  ins_encode %{\n+    __ movl($dst$$Register, $src$$constant);\n+  %}\n@@ -5817,1 +5726,3 @@\n-  ins_encode(load_immL32(dst, src));\n+  ins_encode %{\n+    __ movq($dst$$Register, $src$$constant);\n+  %}\n@@ -5825,1 +5736,3 @@\n-  ins_encode(load_immP(dst, con));\n+  ins_encode %{\n+    __ mov64($dst$$Register, $con$$constant, $con->constant_reloc(), RELOC_IMM64);\n+  %}\n@@ -5836,2 +5749,3 @@\n-  opcode(0x33); \/* + rd *\/\n-  ins_encode(REX_reg_reg(dst, dst), OpcP, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ xorl($dst$$Register, $dst$$Register);\n+  %}\n@@ -5848,1 +5762,3 @@\n-  ins_encode(load_immP31(dst, src));\n+  ins_encode %{\n+    __ movl($dst$$Register, $src$$constant);\n+  %}\n@@ -6057,2 +5973,3 @@\n-  opcode(0x88);\n-  ins_encode(REX_breg_mem(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ movb($mem$$Address, $src$$Register);\n+  %}\n@@ -6069,2 +5986,3 @@\n-  opcode(0x89);\n-  ins_encode(SizePrefix, REX_reg_mem(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ movw($mem$$Address, $src$$Register);\n+  %}\n@@ -6081,2 +5999,3 @@\n-  opcode(0x89);\n-  ins_encode(REX_reg_mem(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ movl($mem$$Address, $src$$Register);\n+  %}\n@@ -6093,2 +6012,3 @@\n-  opcode(0x89);\n-  ins_encode(REX_reg_mem_wide(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ movq($mem$$Address, $src$$Register);\n+  %}\n@@ -6105,2 +6025,3 @@\n-  opcode(0x89);\n-  ins_encode(REX_reg_mem_wide(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ movq($mem$$Address, $src$$Register);\n+  %}\n@@ -6130,2 +6051,3 @@\n-  opcode(0xC7); \/* C7 \/0 *\/\n-  ins_encode(REX_mem_wide(mem), OpcP, RM_opc_mem(0x00, mem), Con32(src));\n+  ins_encode %{\n+    __ movq($mem$$Address, $src$$constant);\n+  %}\n@@ -6222,2 +6144,3 @@\n-  opcode(0xC7); \/* C7 \/0 *\/\n-  ins_encode(REX_mem(mem), OpcP, RM_opc_mem(0x00, mem), Con32(src));\n+  ins_encode %{\n+    __ movl($mem$$Address, $src$$constant);\n+  %}\n@@ -6247,2 +6170,3 @@\n-  opcode(0xC7); \/* C7 \/0 *\/\n-  ins_encode(REX_mem_wide(mem), OpcP, RM_opc_mem(0x00, mem), Con32(src));\n+  ins_encode %{\n+    __ movq($mem$$Address, $src$$constant);\n+  %}\n@@ -6273,2 +6197,3 @@\n-  opcode(0xC7); \/* C7 \/0 Same as 32 store immediate with prefix *\/\n-  ins_encode(SizePrefix, REX_mem(mem), OpcP, RM_opc_mem(0x00, mem),Con16(src));\n+  ins_encode %{\n+    __ movw($mem$$Address, $src$$constant);\n+  %}\n@@ -6298,2 +6223,3 @@\n-  opcode(0xC6); \/* C6 \/0 *\/\n-  ins_encode(REX_mem(mem), OpcP, RM_opc_mem(0x00, mem), Con8or32(src));\n+  ins_encode %{\n+    __ movb($mem$$Address, $src$$constant);\n+  %}\n@@ -6323,2 +6249,3 @@\n-  opcode(0xC6); \/* C6 \/0 *\/\n-  ins_encode(REX_mem(mem), OpcP, RM_opc_mem(0x00, mem), Con8or32(src));\n+  ins_encode %{\n+    __ movb($mem$$Address, $src$$constant);\n+  %}\n@@ -6361,2 +6288,3 @@\n-  opcode(0xC7); \/* C7 \/0 *\/\n-  ins_encode(REX_mem(mem), OpcP, RM_opc_mem(0x00, mem), Con32F_as_bits(src));\n+  ins_encode %{\n+    __ movl($mem$$Address, jint_cast($src$$constant));\n+  %}\n@@ -6387,2 +6315,3 @@\n-  opcode(0xC7); \/* C7 \/0 *\/\n-  ins_encode(REX_mem_wide(mem), OpcP, RM_opc_mem(0x00, mem), Con32F_as_bits(src));\n+  ins_encode %{\n+    __ movq($mem$$Address, $src$$constant);\n+  %}\n@@ -6508,2 +6437,3 @@\n-  opcode(0x0F, 0xC8);  \/*Opcode 0F \/C8 *\/\n-  ins_encode( REX_reg(dst), OpcP, opc2_reg(dst) );\n+  ins_encode %{\n+    __ bswapl($dst$$Register);\n+  %}\n@@ -6517,2 +6447,3 @@\n-  opcode(0x0F, 0xC8); \/* Opcode 0F \/C8 *\/\n-  ins_encode( REX_reg_wide(dst), OpcP, opc2_reg(dst) );\n+  ins_encode %{\n+    __ bswapq($dst$$Register);\n+  %}\n@@ -7036,2 +6967,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovl((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7046,2 +6978,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovl((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7065,2 +6998,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_mem(dst, src), enc_cmov(cop), reg_mem(dst, src));\n+  ins_encode %{\n+    __ cmovl((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Address);\n+  %}\n@@ -7077,2 +7011,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_mem(dst, src), enc_cmov(cop), reg_mem(dst, src));\n+  ins_encode %{\n+    __ cmovl((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Address);\n+  %}\n@@ -7097,2 +7032,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovl((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7109,2 +7045,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovl((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7129,2 +7066,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg_wide(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovq((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7141,2 +7079,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg_wide(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovq((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7187,2 +7126,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg_wide(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovq((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7198,2 +7138,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_mem_wide(dst, src), enc_cmov(cop), reg_mem(dst, src));\n+  ins_encode %{\n+    __ cmovq((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Address);\n+  %}\n@@ -7209,2 +7150,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_reg_wide(dst, src), enc_cmov(cop), reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovq((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Register);\n+  %}\n@@ -7228,2 +7170,3 @@\n-  opcode(0x0F, 0x40);\n-  ins_encode(REX_reg_mem_wide(dst, src), enc_cmov(cop), reg_mem(dst, src));\n+  ins_encode %{\n+    __ cmovq((Assembler::Condition)($cop$$cmpcode), $dst$$Register, $src$$Address);\n+  %}\n@@ -7350,2 +7293,3 @@\n-  opcode(0x03);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ addl($dst$$Register, $src$$Register);\n+  %}\n@@ -7361,2 +7305,3 @@\n-  opcode(0x81, 0x00); \/* \/0 id *\/\n-  ins_encode(OpcSErm(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ addl($dst$$Register, $src$$constant);\n+  %}\n@@ -7373,2 +7318,3 @@\n-  opcode(0x03);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ addl($dst$$Register, $src$$Address);\n+  %}\n@@ -7385,2 +7331,3 @@\n-  opcode(0x01); \/* Opcode 01 \/r *\/\n-  ins_encode(REX_reg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ addl($dst$$Address, $src$$Register);\n+  %}\n@@ -7397,2 +7344,3 @@\n-  opcode(0x81); \/* Opcode 81 \/0 id *\/\n-  ins_encode(REX_mem(dst), OpcSE(src), RM_opc_mem(0x00, dst), Con8or32(src));\n+  ins_encode %{\n+    __ addl($dst$$Address, $src$$constant);\n+  %}\n@@ -7409,2 +7357,3 @@\n-  opcode(0xFF, 0x00); \/\/ FF \/0\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ incrementl($dst$$Register);\n+  %}\n@@ -7422,2 +7371,3 @@\n-  opcode(0xFF); \/* Opcode FF \/0 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(0x00, dst));\n+  ins_encode %{\n+    __ incrementl($dst$$Address);\n+  %}\n@@ -7435,2 +7385,3 @@\n-  opcode(0xFF, 0x01); \/\/ FF \/1\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ decrementl($dst$$Register);\n+  %}\n@@ -7449,2 +7400,3 @@\n-  opcode(0xFF); \/* Opcode FF \/1 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(0x01, dst));\n+  ins_encode %{\n+    __ decrementl($dst$$Address);\n+  %}\n@@ -7460,2 +7412,3 @@\n-  opcode(0x8D); \/* 0x8D \/r *\/\n-  ins_encode(Opcode(0x67), REX_reg_reg(dst, src0), OpcP, reg_lea(dst, src0, src1)); \/\/ XXX\n+  ins_encode %{\n+    __ leal($dst$$Register, Address($src0$$Register, $src1$$constant));\n+  %}\n@@ -7471,2 +7424,3 @@\n-  opcode(0x03);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ addq($dst$$Register, $src$$Register);\n+  %}\n@@ -7482,2 +7436,3 @@\n-  opcode(0x81, 0x00); \/* \/0 id *\/\n-  ins_encode(OpcSErm_wide(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ addq($dst$$Register, $src$$constant);\n+  %}\n@@ -7494,2 +7449,3 @@\n-  opcode(0x03);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ addq($dst$$Register, $src$$Address);\n+  %}\n@@ -7506,2 +7462,3 @@\n-  opcode(0x01); \/* Opcode 01 \/r *\/\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ addq($dst$$Address, $src$$Register);\n+  %}\n@@ -7518,3 +7475,3 @@\n-  opcode(0x81); \/* Opcode 81 \/0 id *\/\n-  ins_encode(REX_mem_wide(dst),\n-             OpcSE(src), RM_opc_mem(0x00, dst), Con8or32(src));\n+  ins_encode %{\n+    __ addq($dst$$Address, $src$$constant);\n+  %}\n@@ -7531,2 +7488,3 @@\n-  opcode(0xFF, 0x00); \/\/ FF \/0\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ incrementq($dst$$Register);\n+  %}\n@@ -7544,2 +7502,3 @@\n-  opcode(0xFF); \/* Opcode FF \/0 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(0x00, dst));\n+  ins_encode %{\n+    __ incrementq($dst$$Address);\n+  %}\n@@ -7557,2 +7516,3 @@\n-  opcode(0xFF, 0x01); \/\/ FF \/1\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ decrementq($dst$$Register);\n+  %}\n@@ -7571,2 +7531,3 @@\n-  opcode(0xFF); \/* Opcode FF \/1 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(0x01, dst));\n+  ins_encode %{\n+    __ decrementq($dst$$Address);\n+  %}\n@@ -7582,2 +7543,3 @@\n-  opcode(0x8D); \/* 0x8D \/r *\/\n-  ins_encode(REX_reg_reg_wide(dst, src0), OpcP, reg_lea(dst, src0, src1)); \/\/ XXX\n+  ins_encode %{\n+    __ leaq($dst$$Register, Address($src0$$Register, $src1$$constant));\n+  %}\n@@ -7593,2 +7555,3 @@\n-  opcode(0x03);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ addq($dst$$Register, $src$$Register);\n+  %}\n@@ -7604,2 +7567,3 @@\n-  opcode(0x81, 0x00); \/* \/0 id *\/\n-  ins_encode(OpcSErm_wide(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ addq($dst$$Register, $src$$constant);\n+  %}\n@@ -7617,2 +7581,3 @@\n-  opcode(0x8D); \/* 0x8D \/r *\/\n-  ins_encode(REX_reg_reg_wide(dst, src0), OpcP, reg_lea(dst, src0, src1));\/\/ XXX\n+  ins_encode %{\n+    __ leaq($dst$$Register, Address($src0$$Register, $src1$$constant));\n+  %}\n@@ -7671,2 +7636,3 @@\n-  opcode(0x8B);\n-  ins_encode(REX_reg_mem_wide(dst, mem), OpcP, reg_mem(dst, mem));\n+  ins_encode %{\n+    __ movq($dst$$Register, $mem$$Address);\n+  %}\n@@ -7689,5 +7655,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem_wide(newval, heap_top_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, heap_top_ptr));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgq($newval$$Register, $heap_top_ptr$$Address);\n+  %}\n@@ -7721,5 +7686,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem_wide(newval, mem),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgq($newval$$Register, $mem$$Address);\n+  %}\n@@ -7745,8 +7709,6 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem_wide(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr),\n-             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), \/\/ sete\n-             REX_reg_breg(res, res), \/\/ movzbl\n-             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgq($newval$$Register, $mem_ptr$$Address);\n+    __ sete($res$$Register);\n+    __ movzbl($res$$Register, $res$$Register);\n+  %}\n@@ -7770,8 +7732,6 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem_wide(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr),\n-             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), \/\/ sete\n-             REX_reg_breg(res, res), \/\/ movzbl\n-             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgq($newval$$Register, $mem_ptr$$Address);\n+    __ sete($res$$Register);\n+    __ movzbl($res$$Register, $res$$Register);\n+  %}\n@@ -7794,8 +7754,6 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr),\n-             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), \/\/ sete\n-             REX_reg_breg(res, res), \/\/ movzbl\n-             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgl($newval$$Register, $mem_ptr$$Address);\n+    __ sete($res$$Register);\n+    __ movzbl($res$$Register, $res$$Register);\n+  %}\n@@ -7818,8 +7776,6 @@\n-  opcode(0x0F, 0xB0);\n-  ins_encode(lock_prefix,\n-             REX_breg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr),\n-             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), \/\/ sete\n-             REX_reg_breg(res, res), \/\/ movzbl\n-             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgb($newval$$Register, $mem_ptr$$Address);\n+    __ sete($res$$Register);\n+    __ movzbl($res$$Register, $res$$Register);\n+  %}\n@@ -7842,9 +7798,6 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             SizePrefix,\n-             REX_reg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr),\n-             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), \/\/ sete\n-             REX_reg_breg(res, res), \/\/ movzbl\n-             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgw($newval$$Register, $mem_ptr$$Address);\n+    __ sete($res$$Register);\n+    __ movzbl($res$$Register, $res$$Register);\n+  %}\n@@ -7866,8 +7819,6 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr),\n-             REX_breg(res), Opcode(0x0F), Opcode(0x94), reg(res), \/\/ sete\n-             REX_reg_breg(res, res), \/\/ movzbl\n-             Opcode(0xF), Opcode(0xB6), reg_reg(res, res));\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgl($newval$$Register, $mem_ptr$$Address);\n+    __ sete($res$$Register);\n+    __ movzbl($res$$Register, $res$$Register);\n+  %}\n@@ -7887,6 +7838,4 @@\n-  opcode(0x0F, 0xB0);\n-  ins_encode(lock_prefix,\n-             REX_breg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr) \/\/ lock cmpxchg\n-             );\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgb($newval$$Register, $mem_ptr$$Address);\n+  %}\n@@ -7906,7 +7855,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             SizePrefix,\n-             REX_reg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr) \/\/ lock cmpxchg\n-             );\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgw($newval$$Register, $mem_ptr$$Address);\n+  %}\n@@ -7926,6 +7872,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr) \/\/ lock cmpxchg\n-             );\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgl($newval$$Register, $mem_ptr$$Address);\n+  %}\n@@ -7946,6 +7890,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem_wide(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr)  \/\/ lock cmpxchg\n-            );\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgq($newval$$Register, $mem_ptr$$Address);\n+  %}\n@@ -7964,6 +7906,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr)  \/\/ lock cmpxchg\n-          );\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgl($newval$$Register, $mem_ptr$$Address);\n+  %}\n@@ -7984,6 +7924,4 @@\n-  opcode(0x0F, 0xB1);\n-  ins_encode(lock_prefix,\n-             REX_reg_mem_wide(newval, mem_ptr),\n-             OpcP, OpcS,\n-             reg_mem(newval, mem_ptr)  \/\/ lock cmpxchg\n-          );\n+  ins_encode %{\n+    __ lock();\n+    __ cmpxchgq($newval$$Register, $mem_ptr$$Address);\n+  %}\n@@ -8195,2 +8133,3 @@\n-  opcode(0x2B);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ subl($dst$$Register, $src$$Register);\n+  %}\n@@ -8206,2 +8145,3 @@\n-  opcode(0x81, 0x05);  \/* Opcode 81 \/5 *\/\n-  ins_encode(OpcSErm(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ subl($dst$$Register, $src$$constant);\n+  %}\n@@ -8218,2 +8158,3 @@\n-  opcode(0x2B);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ subl($dst$$Register, $src$$Address);\n+  %}\n@@ -8230,2 +8171,3 @@\n-  opcode(0x29); \/* Opcode 29 \/r *\/\n-  ins_encode(REX_reg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ subl($dst$$Address, $src$$Register);\n+  %}\n@@ -8242,2 +8184,3 @@\n-  opcode(0x81); \/* Opcode 81 \/5 id *\/\n-  ins_encode(REX_mem(dst), OpcSE(src), RM_opc_mem(0x05, dst), Con8or32(src));\n+  ins_encode %{\n+    __ subl($dst$$Address, $src$$constant);\n+  %}\n@@ -8253,2 +8196,3 @@\n-  opcode(0x2B);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ subq($dst$$Register, $src$$Register);\n+  %}\n@@ -8264,2 +8208,3 @@\n-  opcode(0x81, 0x05);  \/* Opcode 81 \/5 *\/\n-  ins_encode(OpcSErm_wide(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ subq($dst$$Register, $src$$constant);\n+  %}\n@@ -8276,2 +8221,3 @@\n-  opcode(0x2B);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ subq($dst$$Register, $src$$Address);\n+  %}\n@@ -8288,2 +8234,3 @@\n-  opcode(0x29); \/* Opcode 29 \/r *\/\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ subq($dst$$Address, $src$$Register);\n+  %}\n@@ -8300,3 +8247,3 @@\n-  opcode(0x81); \/* Opcode 81 \/5 id *\/\n-  ins_encode(REX_mem_wide(dst),\n-             OpcSE(src), RM_opc_mem(0x05, dst), Con8or32(src));\n+  ins_encode %{\n+    __ subq($dst$$Address, $src$$constant);\n+  %}\n@@ -8325,2 +8272,3 @@\n-  opcode(0xF7, 0x03);  \/\/ Opcode F7 \/3\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ negl($dst$$Register);\n+  %}\n@@ -8348,2 +8296,3 @@\n-  opcode(0xF7, 0x03);  \/\/ Opcode F7 \/3\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ negl($dst$$Address);\n+  %}\n@@ -8359,2 +8308,3 @@\n-  opcode(0xF7, 0x03);  \/\/ Opcode F7 \/3\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ negq($dst$$Register);\n+  %}\n@@ -8382,2 +8332,3 @@\n-  opcode(0xF7, 0x03);  \/\/ Opcode F7 \/3\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ negq($dst$$Address);\n+  %}\n@@ -8398,2 +8349,3 @@\n-  opcode(0x0F, 0xAF);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ imull($dst$$Register, $src$$Register);\n+  %}\n@@ -8410,3 +8362,3 @@\n-  opcode(0x69); \/* 69 \/r id *\/\n-  ins_encode(REX_reg_reg(dst, src),\n-             OpcSE(imm), reg_reg(dst, src), Con8or32(imm));\n+  ins_encode %{\n+    __ imull($dst$$Register, $src$$Register, $imm$$constant);\n+  %}\n@@ -8423,2 +8375,3 @@\n-  opcode(0x0F, 0xAF);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, OpcS, reg_mem(dst, src));\n+  ins_encode %{\n+    __ imull($dst$$Register, $src$$Address);\n+  %}\n@@ -8435,3 +8388,3 @@\n-  opcode(0x69); \/* 69 \/r id *\/\n-  ins_encode(REX_reg_mem(dst, src),\n-             OpcSE(imm), reg_mem(dst, src), Con8or32(imm));\n+  ins_encode %{\n+    __ imull($dst$$Register, $src$$Address, $imm$$constant);\n+  %}\n@@ -8458,2 +8411,3 @@\n-  opcode(0x0F, 0xAF);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ imulq($dst$$Register, $src$$Register);\n+  %}\n@@ -8470,3 +8424,3 @@\n-  opcode(0x69); \/* 69 \/r id *\/\n-  ins_encode(REX_reg_reg_wide(dst, src),\n-             OpcSE(imm), reg_reg(dst, src), Con8or32(imm));\n+  ins_encode %{\n+    __ imulq($dst$$Register, $src$$Register, $imm$$constant);\n+  %}\n@@ -8483,2 +8437,3 @@\n-  opcode(0x0F, 0xAF);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, OpcS, reg_mem(dst, src));\n+  ins_encode %{\n+    __ imulq($dst$$Register, $src$$Address);\n+  %}\n@@ -8495,3 +8450,3 @@\n-  opcode(0x69); \/* 69 \/r id *\/\n-  ins_encode(REX_reg_mem_wide(dst, src),\n-             OpcSE(imm), reg_mem(dst, src), Con8or32(imm));\n+  ins_encode %{\n+    __ imulq($dst$$Register, $src$$Address, $imm$$constant);\n+  %}\n@@ -8508,2 +8463,3 @@\n-  opcode(0xF7, 0x5); \/* Opcode F7 \/5 *\/\n-  ins_encode(REX_reg_wide(src), OpcP, reg_opc(src));\n+  ins_encode %{\n+    __ imulq($src$$Register);\n+  %}\n@@ -8528,2 +8484,1 @@\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode(cdql_enc(div), REX_reg(div), OpcP, reg_opc(div));\n+  ins_encode(cdql_enc(div));\n@@ -8549,2 +8504,1 @@\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode(cdqq_enc(div), REX_reg_wide(div), OpcP, reg_opc(div));\n+  ins_encode(cdqq_enc(div));\n@@ -8570,2 +8524,1 @@\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode(cdql_enc(div), REX_reg(div), OpcP, reg_opc(div));\n+  ins_encode(cdql_enc(div));\n@@ -8592,2 +8545,1 @@\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode(cdqq_enc(div), REX_reg_wide(div), OpcP, reg_opc(div));\n+  ins_encode(cdqq_enc(div));\n@@ -8615,2 +8567,3 @@\n-  opcode(0xF7, 0x5); \/* Opcode F7 \/5 *\/\n-  ins_encode(REX_reg_wide(src), OpcP, reg_opc(src));\n+  ins_encode %{\n+    __ imulq($src$$Register);\n+  %}\n@@ -8625,2 +8578,3 @@\n-  opcode(0xC1, 0x7); \/* C1 \/7 ib *\/\n-  ins_encode(reg_opc_imm_wide(dst, 0x3F));\n+  ins_encode %{\n+    __ sarq($dst$$Register, 63);\n+  %}\n@@ -8635,2 +8589,3 @@\n-  opcode(0xC1, 0x7); \/* C1 \/7 ib *\/\n-  ins_encode(reg_opc_imm_wide(dst, 0x2));\n+  ins_encode %{\n+    __ sarq($dst$$Register, 2);\n+  %}\n@@ -8673,2 +8628,1 @@\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode(cdql_enc(div), REX_reg(div), OpcP, reg_opc(div));\n+  ins_encode(cdql_enc(div));\n@@ -8694,2 +8648,1 @@\n-  opcode(0xF7, 0x7);  \/* Opcode F7 \/7 *\/\n-  ins_encode(cdqq_enc(div), REX_reg_wide(div), OpcP, reg_opc(div));\n+  ins_encode(cdqq_enc(div));\n@@ -8707,2 +8660,3 @@\n-  opcode(0xD1, 0x4); \/* D1 \/4 *\/\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ sall($dst$$Register, $shift$$constant);\n+  %}\n@@ -8719,2 +8673,3 @@\n-  opcode(0xD1, 0x4); \/* D1 \/4 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ sall($dst$$Address, $shift$$constant);\n+  %}\n@@ -8731,2 +8686,3 @@\n-  opcode(0xC1, 0x4); \/* C1 \/4 ib *\/\n-  ins_encode(reg_opc_imm(dst, shift));\n+  ins_encode %{\n+    __ sall($dst$$Register, $shift$$constant);\n+  %}\n@@ -8743,2 +8699,3 @@\n-  opcode(0xC1, 0x4); \/* C1 \/4 ib *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst), Con8or32(shift));\n+  ins_encode %{\n+    __ sall($dst$$Address, $shift$$constant);\n+  %}\n@@ -8755,2 +8712,3 @@\n-  opcode(0xD3, 0x4); \/* D3 \/4 *\/\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ sall($dst$$Register);\n+  %}\n@@ -8767,2 +8725,3 @@\n-  opcode(0xD3, 0x4); \/* D3 \/4 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ sall($dst$$Address);\n+  %}\n@@ -8779,2 +8738,3 @@\n-  opcode(0xD1, 0x7); \/* D1 \/7 *\/\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ sarl($dst$$Register, $shift$$constant);\n+  %}\n@@ -8791,2 +8751,3 @@\n-  opcode(0xD1, 0x7); \/* D1 \/7 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ sarl($dst$$Address, $shift$$constant);\n+  %}\n@@ -8803,2 +8764,3 @@\n-  opcode(0xC1, 0x7); \/* C1 \/7 ib *\/\n-  ins_encode(reg_opc_imm(dst, shift));\n+  ins_encode %{\n+    __ sarl($dst$$Register, $shift$$constant);\n+  %}\n@@ -8815,2 +8777,3 @@\n-  opcode(0xC1, 0x7); \/* C1 \/7 ib *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst), Con8or32(shift));\n+  ins_encode %{\n+    __ sarl($dst$$Address, $shift$$constant);\n+  %}\n@@ -8825,3 +8788,3 @@\n-\n-  opcode(0xD3, 0x7); \/* D3 \/7 *\/\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ sarl($dst$$Register);\n+  %}\n@@ -8839,2 +8802,3 @@\n-  opcode(0xD3, 0x7); \/* D3 \/7 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ sarl($dst$$Address);\n+  %}\n@@ -8851,2 +8815,3 @@\n-  opcode(0xD1, 0x5); \/* D1 \/5 *\/\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ shrl($dst$$Register, $shift$$constant);\n+  %}\n@@ -8863,2 +8828,3 @@\n-  opcode(0xD1, 0x5); \/* D1 \/5 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ shrl($dst$$Address, $shift$$constant);\n+  %}\n@@ -8875,2 +8841,3 @@\n-  opcode(0xC1, 0x5); \/* C1 \/5 ib *\/\n-  ins_encode(reg_opc_imm(dst, shift));\n+  ins_encode %{\n+    __ shrl($dst$$Register, $shift$$constant);\n+  %}\n@@ -8887,2 +8854,3 @@\n-  opcode(0xC1, 0x5); \/* C1 \/5 ib *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst), Con8or32(shift));\n+  ins_encode %{\n+    __ shrl($dst$$Address, $shift$$constant);\n+  %}\n@@ -8899,2 +8867,3 @@\n-  opcode(0xD3, 0x5); \/* D3 \/5 *\/\n-  ins_encode(REX_reg(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ shrl($dst$$Register);\n+  %}\n@@ -8911,2 +8880,3 @@\n-  opcode(0xD3, 0x5); \/* D3 \/5 *\/\n-  ins_encode(REX_mem(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ shrl($dst$$Address);\n+  %}\n@@ -8924,2 +8894,3 @@\n-  opcode(0xD1, 0x4); \/* D1 \/4 *\/\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ salq($dst$$Register, $shift$$constant);\n+  %}\n@@ -8936,2 +8907,3 @@\n-  opcode(0xD1, 0x4); \/* D1 \/4 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ salq($dst$$Address, $shift$$constant);\n+  %}\n@@ -8948,2 +8920,3 @@\n-  opcode(0xC1, 0x4); \/* C1 \/4 ib *\/\n-  ins_encode(reg_opc_imm_wide(dst, shift));\n+  ins_encode %{\n+    __ salq($dst$$Register, $shift$$constant);\n+  %}\n@@ -8960,3 +8933,3 @@\n-  opcode(0xC1, 0x4); \/* C1 \/4 ib *\/\n-  ins_encode(REX_mem_wide(dst), OpcP,\n-             RM_opc_mem(secondary, dst), Con8or32(shift));\n+  ins_encode %{\n+    __ salq($dst$$Address, $shift$$constant);\n+  %}\n@@ -8973,2 +8946,3 @@\n-  opcode(0xD3, 0x4); \/* D3 \/4 *\/\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ salq($dst$$Register);\n+  %}\n@@ -8985,2 +8959,3 @@\n-  opcode(0xD3, 0x4); \/* D3 \/4 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ salq($dst$$Address);\n+  %}\n@@ -8997,2 +8972,3 @@\n-  opcode(0xD1, 0x7); \/* D1 \/7 *\/\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ sarq($dst$$Register, $shift$$constant);\n+  %}\n@@ -9009,2 +8985,3 @@\n-  opcode(0xD1, 0x7); \/* D1 \/7 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ sarq($dst$$Address, $shift$$constant);\n+  %}\n@@ -9021,2 +8998,3 @@\n-  opcode(0xC1, 0x7); \/* C1 \/7 ib *\/\n-  ins_encode(reg_opc_imm_wide(dst, shift));\n+  ins_encode %{\n+    __ sarq($dst$$Register, (unsigned char)($shift$$constant & 0x3F));\n+  %}\n@@ -9033,3 +9011,3 @@\n-  opcode(0xC1, 0x7); \/* C1 \/7 ib *\/\n-  ins_encode(REX_mem_wide(dst), OpcP,\n-             RM_opc_mem(secondary, dst), Con8or32(shift));\n+  ins_encode %{\n+    __ sarq($dst$$Address, (unsigned char)($shift$$constant & 0x3F));\n+  %}\n@@ -9046,2 +9024,3 @@\n-  opcode(0xD3, 0x7); \/* D3 \/7 *\/\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ sarq($dst$$Register);\n+  %}\n@@ -9058,2 +9037,3 @@\n-  opcode(0xD3, 0x7); \/* D3 \/7 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ sarq($dst$$Address);\n+  %}\n@@ -9070,2 +9050,3 @@\n-  opcode(0xD1, 0x5); \/* D1 \/5 *\/\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst ));\n+  ins_encode %{\n+    __ shrq($dst$$Register, $shift$$constant);\n+  %}\n@@ -9082,2 +9063,3 @@\n-  opcode(0xD1, 0x5); \/* D1 \/5 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ shrq($dst$$Address, $shift$$constant);\n+  %}\n@@ -9094,2 +9076,3 @@\n-  opcode(0xC1, 0x5); \/* C1 \/5 ib *\/\n-  ins_encode(reg_opc_imm_wide(dst, shift));\n+  ins_encode %{\n+    __ shrq($dst$$Register, $shift$$constant);\n+  %}\n@@ -9099,1 +9082,0 @@\n-\n@@ -9107,3 +9089,3 @@\n-  opcode(0xC1, 0x5); \/* C1 \/5 ib *\/\n-  ins_encode(REX_mem_wide(dst), OpcP,\n-             RM_opc_mem(secondary, dst), Con8or32(shift));\n+  ins_encode %{\n+    __ shrq($dst$$Address, $shift$$constant);\n+  %}\n@@ -9120,2 +9102,3 @@\n-  opcode(0xD3, 0x5); \/* D3 \/5 *\/\n-  ins_encode(REX_reg_wide(dst), OpcP, reg_opc(dst));\n+  ins_encode %{\n+    __ shrq($dst$$Register);\n+  %}\n@@ -9132,2 +9115,3 @@\n-  opcode(0xD3, 0x5); \/* D3 \/5 *\/\n-  ins_encode(REX_mem_wide(dst), OpcP, RM_opc_mem(secondary, dst));\n+  ins_encode %{\n+    __ shrq($dst$$Address);\n+  %}\n@@ -9144,2 +9128,3 @@\n-  opcode(0x0F, 0xBE);\n-  ins_encode(REX_reg_breg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ movsbl($dst$$Register, $src$$Register);\n+  %}\n@@ -9156,2 +9141,3 @@\n-  opcode(0x0F, 0xBF);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ movswl($dst$$Register, $src$$Register);\n+  %}\n@@ -9307,2 +9293,3 @@\n-  opcode(0x23);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ andl($dst$$Register, $src$$Register);\n+  %}\n@@ -9318,2 +9305,3 @@\n-  opcode(0x0F, 0xB6);\n-  ins_encode(REX_reg_breg(dst, dst), OpcP, OpcS, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n@@ -9329,2 +9317,3 @@\n-  opcode(0x0F, 0xB6);\n-  ins_encode(REX_reg_breg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ movzbl($dst$$Register, $src$$Register);\n+  %}\n@@ -9340,2 +9329,3 @@\n-  opcode(0x0F, 0xB7);\n-  ins_encode(REX_reg_reg(dst, dst), OpcP, OpcS, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ movzwl($dst$$Register, $dst$$Register);\n+  %}\n@@ -9351,2 +9341,3 @@\n-  opcode(0x0F, 0xB7);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ movzwl($dst$$Register, $src$$Register);\n+  %}\n@@ -9378,2 +9369,3 @@\n-  opcode(0x81, 0x04); \/* Opcode 81 \/4 *\/\n-  ins_encode(OpcSErm(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ andl($dst$$Register, $src$$constant);\n+  %}\n@@ -9391,2 +9383,3 @@\n-  opcode(0x23);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ andl($dst$$Register, $src$$Address);\n+  %}\n@@ -9404,2 +9397,3 @@\n-  opcode(0x20);\n-  ins_encode(REX_breg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ andb($dst$$Address, $src$$Register);\n+  %}\n@@ -9416,2 +9410,3 @@\n-  opcode(0x21); \/* Opcode 21 \/r *\/\n-  ins_encode(REX_reg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ andl($dst$$Address, $src$$Register);\n+  %}\n@@ -9429,3 +9424,3 @@\n-  opcode(0x81, 0x4); \/* Opcode 81 \/4 id *\/\n-  ins_encode(REX_mem(dst), OpcSE(src),\n-             RM_opc_mem(secondary, dst), Con8or32(src));\n+  ins_encode %{\n+    __ andl($dst$$Address, $src$$constant);\n+  %}\n@@ -9559,2 +9554,3 @@\n-  opcode(0x0B);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ orl($dst$$Register, $src$$Register);\n+  %}\n@@ -9571,2 +9567,3 @@\n-  opcode(0x81, 0x01); \/* Opcode 81 \/1 id *\/\n-  ins_encode(OpcSErm(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ orl($dst$$Register, $src$$constant);\n+  %}\n@@ -9584,2 +9581,3 @@\n-  opcode(0x0B);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ orl($dst$$Register, $src$$Address);\n+  %}\n@@ -9597,2 +9595,3 @@\n-  opcode(0x08);\n-  ins_encode(REX_breg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ orb($dst$$Address, $src$$Register);\n+  %}\n@@ -9609,2 +9608,3 @@\n-  opcode(0x09); \/* Opcode 09 \/r *\/\n-  ins_encode(REX_reg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ orl($dst$$Address, $src$$Register);\n+  %}\n@@ -9622,3 +9622,3 @@\n-  opcode(0x81, 0x1); \/* Opcode 81 \/1 id *\/\n-  ins_encode(REX_mem(dst), OpcSE(src),\n-             RM_opc_mem(secondary, dst), Con8or32(src));\n+  ins_encode %{\n+    __ orl($dst$$Address, $src$$constant);\n+  %}\n@@ -9636,2 +9636,3 @@\n-  opcode(0x33);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ xorl($dst$$Register, $src$$Register);\n+  %}\n@@ -9659,2 +9660,3 @@\n-  opcode(0x81, 0x06); \/* Opcode 81 \/6 id *\/\n-  ins_encode(OpcSErm(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ xorl($dst$$Register, $src$$constant);\n+  %}\n@@ -9672,2 +9674,3 @@\n-  opcode(0x33);\n-  ins_encode(REX_reg_mem(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ xorl($dst$$Register, $src$$Address);\n+  %}\n@@ -9685,2 +9688,3 @@\n-  opcode(0x30);\n-  ins_encode(REX_breg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ xorb($dst$$Address, $src$$Register);\n+  %}\n@@ -9697,2 +9701,3 @@\n-  opcode(0x31); \/* Opcode 31 \/r *\/\n-  ins_encode(REX_reg_mem(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ xorl($dst$$Address, $src$$Register);\n+  %}\n@@ -9710,3 +9715,3 @@\n-  opcode(0x81, 0x6); \/* Opcode 81 \/6 id *\/\n-  ins_encode(REX_mem(dst), OpcSE(src),\n-             RM_opc_mem(secondary, dst), Con8or32(src));\n+  ins_encode %{\n+    __ xorl($dst$$Address, $src$$constant);\n+  %}\n@@ -9727,2 +9732,3 @@\n-  opcode(0x23);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ andq($dst$$Register, $src$$Register);\n+  %}\n@@ -9738,2 +9744,3 @@\n-  opcode(0x0F, 0xB6);\n-  ins_encode(REX_reg_reg_wide(dst, dst), OpcP, OpcS, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ movzbq($dst$$Register, $dst$$Register);\n+  %}\n@@ -9749,2 +9756,3 @@\n-  opcode(0x0F, 0xB7);\n-  ins_encode(REX_reg_reg_wide(dst, dst), OpcP, OpcS, reg_reg(dst, dst));\n+  ins_encode %{\n+    __ movzwq($dst$$Register, $dst$$Register);\n+  %}\n@@ -9761,2 +9769,3 @@\n-  opcode(0x81, 0x04); \/* Opcode 81 \/4 *\/\n-  ins_encode(OpcSErm_wide(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ andq($dst$$Register, $src$$constant);\n+  %}\n@@ -9774,2 +9783,3 @@\n-  opcode(0x23);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ andq($dst$$Register, $src$$Address);\n+  %}\n@@ -9787,2 +9797,3 @@\n-  opcode(0x21); \/* Opcode 21 \/r *\/\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ andq($dst$$Address, $src$$Register);\n+  %}\n@@ -9800,3 +9811,3 @@\n-  opcode(0x81, 0x4); \/* Opcode 81 \/4 id *\/\n-  ins_encode(REX_mem_wide(dst), OpcSE(src),\n-             RM_opc_mem(secondary, dst), Con8or32(src));\n+  ins_encode %{\n+    __ andq($dst$$Address, $src$$constant);\n+  %}\n@@ -9947,2 +9958,3 @@\n-  opcode(0x0B);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ orq($dst$$Register, $src$$Register);\n+  %}\n@@ -9958,2 +9970,3 @@\n-  opcode(0x0B);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ orq($dst$$Register, $src$$Register);\n+  %}\n@@ -9971,2 +9984,3 @@\n-  opcode(0x81, 0x01); \/* Opcode 81 \/1 id *\/\n-  ins_encode(OpcSErm_wide(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ orq($dst$$Register, $src$$constant);\n+  %}\n@@ -9984,2 +9998,3 @@\n-  opcode(0x0B);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ orq($dst$$Register, $src$$Address);\n+  %}\n@@ -9997,2 +10012,3 @@\n-  opcode(0x09); \/* Opcode 09 \/r *\/\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ orq($dst$$Address, $src$$Register);\n+  %}\n@@ -10010,3 +10026,3 @@\n-  opcode(0x81, 0x1); \/* Opcode 81 \/1 id *\/\n-  ins_encode(REX_mem_wide(dst), OpcSE(src),\n-             RM_opc_mem(secondary, dst), Con8or32(src));\n+  ins_encode %{\n+    __ orq($dst$$Address, $src$$constant);\n+  %}\n@@ -10041,2 +10057,3 @@\n-  opcode(0x33);\n-  ins_encode(REX_reg_reg_wide(dst, src), OpcP, reg_reg(dst, src));\n+  ins_encode %{\n+    __ xorq($dst$$Register, $src$$Register);\n+  %}\n@@ -10064,2 +10081,3 @@\n-  opcode(0x81, 0x06); \/* Opcode 81 \/6 id *\/\n-  ins_encode(OpcSErm_wide(dst, src), Con8or32(src));\n+  ins_encode %{\n+    __ xorq($dst$$Register, $src$$constant);\n+  %}\n@@ -10077,2 +10095,3 @@\n-  opcode(0x33);\n-  ins_encode(REX_reg_mem_wide(dst, src), OpcP, reg_mem(dst, src));\n+  ins_encode %{\n+    __ xorq($dst$$Register, $src$$Address);\n+  %}\n@@ -10090,2 +10109,3 @@\n-  opcode(0x31); \/* Opcode 31 \/r *\/\n-  ins_encode(REX_reg_mem_wide(src, dst), OpcP, reg_mem(src, dst));\n+  ins_encode %{\n+    __ xorq($dst$$Address, $src$$Register);\n+  %}\n@@ -10103,3 +10123,3 @@\n-  opcode(0x81, 0x6); \/* Opcode 81 \/6 id *\/\n-  ins_encode(REX_mem_wide(dst), OpcSE(src),\n-             RM_opc_mem(secondary, dst), Con8or32(src));\n+  ins_encode %{\n+    __ xorq($dst$$Address, $src$$constant);\n+  %}\n@@ -10118,4 +10138,5 @@\n-  ins_encode(REX_reg_reg(src, src), opc_reg_reg(0x85, src, src), \/\/ testl\n-             setNZ_reg(dst),\n-             REX_reg_breg(dst, dst), \/\/ movzbl\n-             Opcode(0x0F), Opcode(0xB6), reg_reg(dst, dst));\n+  ins_encode %{\n+    __ testl($src$$Register, $src$$Register);\n+    __ set_byte_if_not_zero($dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n@@ -10134,4 +10155,5 @@\n-  ins_encode(REX_reg_reg_wide(src, src), opc_reg_reg(0x85, src, src), \/\/ testq\n-             setNZ_reg(dst),\n-             REX_reg_breg(dst, dst), \/\/ movzbl\n-             Opcode(0x0F), Opcode(0xB6), reg_reg(dst, dst));\n+  ins_encode %{\n+    __ testq($src$$Register, $src$$Register);\n+    __ set_byte_if_not_zero($dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n@@ -10151,5 +10173,6 @@\n-  ins_encode(REX_reg_reg(p, q), opc_reg_reg(0x3B, p, q), \/\/ cmpl\n-             setLT_reg(dst),\n-             REX_reg_breg(dst, dst), \/\/ movzbl\n-             Opcode(0x0F), Opcode(0xB6), reg_reg(dst, dst),\n-             neg_reg(dst));\n+  ins_encode %{\n+    __ cmpl($p$$Register, $q$$Register);\n+    __ setl($dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+    __ negl($dst$$Register);\n+  %}\n@@ -10167,1 +10190,1 @@\n-  __ sarl($dst$$Register, 31);\n+    __ sarl($dst$$Register, 31);\n@@ -11882,2 +11905,3 @@\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_reg(op1, op2), OpcP, reg_reg(op1, op2));\n+  ins_encode %{\n+    __ cmpl($op1$$Register, $op2$$Register);\n+  %}\n@@ -11892,2 +11916,3 @@\n-  opcode(0x81, 0x07); \/* Opcode 81 \/7 *\/\n-  ins_encode(OpcSErm(op1, op2), Con8or32(op2));\n+  ins_encode %{\n+    __ cmpl($op1$$Register, $op2$$constant);\n+  %}\n@@ -11903,2 +11928,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_mem(op1, op2), OpcP, reg_mem(op1, op2));\n+  ins_encode %{\n+    __ cmpl($op1$$Register, $op2$$Address);\n+  %}\n@@ -11913,2 +11939,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_reg(src, src), OpcP, reg_reg(src, src));\n+  ins_encode %{\n+    __ testl($src$$Register, $src$$Register);\n+  %}\n@@ -11923,2 +11950,3 @@\n-  opcode(0xF7, 0x00);\n-  ins_encode(REX_reg(src), OpcP, reg_opc(src), Con32(con));\n+  ins_encode %{\n+    __ testl($src$$Register, $con$$constant);\n+  %}\n@@ -11933,2 +11961,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_mem(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ testl($src$$Register, $mem$$Address);\n+  %}\n@@ -11945,2 +11974,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_reg(op1, op2), OpcP, reg_reg(op1, op2));\n+  ins_encode %{\n+    __ cmpl($op1$$Register, $op2$$Register);\n+  %}\n@@ -11955,2 +11985,3 @@\n-  opcode(0x81,0x07); \/* Opcode 81 \/7 *\/\n-  ins_encode(OpcSErm(op1, op2), Con8or32(op2));\n+  ins_encode %{\n+    __ cmpl($op1$$Register, $op2$$constant);\n+  %}\n@@ -11966,2 +11997,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_mem(op1, op2), OpcP, reg_mem(op1, op2));\n+  ins_encode %{\n+    __ cmpl($op1$$Register, $op2$$Address);\n+  %}\n@@ -11987,2 +12019,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_reg(src, src), OpcP, reg_reg(src, src));\n+  ins_encode %{\n+    __ testl($src$$Register, $src$$Register);\n+  %}\n@@ -11997,2 +12030,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_reg_wide(op1, op2), OpcP, reg_reg(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Register);\n+  %}\n@@ -12009,2 +12043,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_mem_wide(op1, op2), OpcP, reg_mem(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Address);\n+  %}\n@@ -12036,2 +12071,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_mem_wide(op1, op2), OpcP, reg_mem(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Address);\n+  %}\n@@ -12048,2 +12084,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_reg_wide(src, src), OpcP, reg_reg(src, src));\n+  ins_encode %{\n+    __ testq($src$$Register, $src$$Register);\n+  %}\n@@ -12063,3 +12100,3 @@\n-  opcode(0xF7); \/* Opcode F7 \/0 *\/\n-  ins_encode(REX_mem_wide(op),\n-             OpcP, RM_opc_mem(0x00, op), Con_d32(0xFFFFFFFF));\n+  ins_encode %{\n+    __ testq($op$$Address, 0xFFFFFFFF);\n+  %}\n@@ -12185,2 +12222,3 @@\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_reg_wide(op1, op2), OpcP, reg_reg(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Register);\n+  %}\n@@ -12195,2 +12233,3 @@\n-  opcode(0x81, 0x07); \/* Opcode 81 \/7 *\/\n-  ins_encode(OpcSErm_wide(op1, op2), Con8or32(op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$constant);\n+  %}\n@@ -12205,2 +12244,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_mem_wide(op1, op2), OpcP, reg_mem(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Address);\n+  %}\n@@ -12215,2 +12255,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_reg_wide(src, src), OpcP, reg_reg(src, src));\n+  ins_encode %{\n+    __ testq($src$$Register, $src$$Register);\n+  %}\n@@ -12225,2 +12266,3 @@\n-  opcode(0xF7, 0x00);\n-  ins_encode(REX_reg_wide(src), OpcP, reg_opc(src), Con32(con));\n+  ins_encode %{\n+    __ testq($src$$Register, $con$$constant);\n+  %}\n@@ -12235,2 +12277,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_mem_wide(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ testq($src$$Register, $mem$$Address);\n+  %}\n@@ -12245,2 +12288,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_mem_wide(src, mem), OpcP, reg_mem(src, mem));\n+  ins_encode %{\n+    __ testq($src$$Register, $mem$$Address);\n+  %}\n@@ -12264,1 +12308,9 @@\n-  ins_encode(cmpl3_flag(src1, src2, dst));\n+  ins_encode %{\n+    Label done;\n+    __ cmpq($src1$$Register, $src2$$Register);\n+    __ movl($dst$$Register, -1);\n+    __ jccb(Assembler::less, done);\n+    __ setne($dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+    __ bind(done);\n+  %}\n@@ -12275,2 +12327,3 @@\n-  opcode(0x3B);  \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_reg_wide(op1, op2), OpcP, reg_reg(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Register);\n+  %}\n@@ -12285,2 +12338,3 @@\n-  opcode(0x81, 0x07); \/* Opcode 81 \/7 *\/\n-  ins_encode(OpcSErm_wide(op1, op2), Con8or32(op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$constant);\n+  %}\n@@ -12295,2 +12349,3 @@\n-  opcode(0x3B); \/* Opcode 3B \/r *\/\n-  ins_encode(REX_reg_mem_wide(op1, op2), OpcP, reg_mem(op1, op2));\n+  ins_encode %{\n+    __ cmpq($op1$$Register, $op2$$Address);\n+  %}\n@@ -12305,2 +12360,3 @@\n-  opcode(0x85);\n-  ins_encode(REX_reg_reg_wide(src, src), OpcP, reg_reg(src, src));\n+  ins_encode %{\n+    __ testq($src$$Register, $src$$Register);\n+  %}\n@@ -12348,2 +12404,3 @@\n-  opcode(0x0F, 0x4F);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovl(Assembler::greater, $dst$$Register, $src$$Register);\n+  %}\n@@ -12371,2 +12428,3 @@\n-  opcode(0x0F, 0x4C);\n-  ins_encode(REX_reg_reg(dst, src), OpcP, OpcS, reg_reg(dst, src));\n+  ins_encode %{\n+    __ cmovl(Assembler::less, $dst$$Register, $src$$Register);\n+  %}\n@@ -12967,2 +13025,3 @@\n-  opcode(0xC3);\n-  ins_encode(OpcP);\n+  ins_encode %{\n+    __ ret(0);\n+  %}\n@@ -12982,2 +13041,3 @@\n-  opcode(0xFF, 0x4); \/* Opcode FF \/4 *\/\n-  ins_encode(REX_reg(jump_target), OpcP, reg_opc(jump_target));\n+  ins_encode %{\n+    __ jmp($jump_target$$Register);\n+  %}\n@@ -12996,3 +13056,4 @@\n-  opcode(0xFF, 0x4); \/* Opcode FF \/4 *\/\n-  ins_encode(Opcode(0x5a), \/\/ popq rdx\n-             REX_reg(jump_target), OpcP, reg_opc(jump_target));\n+  ins_encode %{\n+    __ popq(as_Register(RDX_enc));\n+    __ jmp($jump_target$$Register);\n+  %}\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":769,"deletions":708,"binary":false,"changes":1477,"status":"modified"},{"patch":"@@ -161,3 +161,0 @@\n-  develop(bool, OptoRemoveUseless, true,                                    \\\n-          \"Remove useless nodes after parsing\")                             \\\n-                                                                            \\\n@@ -422,40 +419,0 @@\n-  develop(intx, NodeCountInliningStep, 1000,                                \\\n-          \"Target size of warm calls inlined between optimization passes\")  \\\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  develop(bool, InlineWarmCalls, false,                                     \\\n-          \"Use a heat-based priority queue to govern inlining\")             \\\n-                                                                            \\\n-  \/* Max values must not exceed WarmCallInfo::MAX_VALUE(). *\/               \\\n-  develop(intx, HotCallCountThreshold, 999999,                              \\\n-          \"large numbers of calls (per method invocation) force hotness\")   \\\n-          range(0, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))      \\\n-                                                                            \\\n-  develop(intx, HotCallProfitThreshold, 999999,                             \\\n-          \"highly profitable inlining opportunities force hotness\")         \\\n-          range(0, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))      \\\n-                                                                            \\\n-  develop(intx, HotCallTrivialWork, -1,                                     \\\n-          \"trivial execution time (no larger than this) forces hotness\")    \\\n-          range(-1, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))     \\\n-                                                                            \\\n-  develop(intx, HotCallTrivialSize, -1,                                     \\\n-          \"trivial methods (no larger than this) force calls to be hot\")    \\\n-          range(-1, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))     \\\n-                                                                            \\\n-  develop(intx, WarmCallMinCount, -1,                                       \\\n-          \"number of calls (per method invocation) to enable inlining\")     \\\n-          range(-1, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))     \\\n-                                                                            \\\n-  develop(intx, WarmCallMinProfit, -1,                                      \\\n-          \"number of calls (per method invocation) to enable inlining\")     \\\n-          range(-1, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))     \\\n-                                                                            \\\n-  develop(intx, WarmCallMaxWork, 999999,                                    \\\n-          \"execution time of the largest inlinable method\")                 \\\n-          range(0, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))      \\\n-                                                                            \\\n-  develop(intx, WarmCallMaxSize, 999999,                                    \\\n-          \"size of the largest inlinable method\")                           \\\n-          range(0, ((intx)MIN2((int64_t)max_intx,(int64_t)(+1.0e10))))      \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":0,"deletions":43,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -1397,0 +1397,1 @@\n+  assert(_jvms == NULL || ((uintptr_t)_jvms->map() & 1) || _jvms->map() == this, \"inconsistent JVMState\");\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -356,0 +356,12 @@\n+  virtual bool needs_deep_clone_jvms(Compile* C) { return false; }\n+  void clone_jvms(Compile* C) {\n+    if (jvms() != NULL) {\n+      if (needs_deep_clone_jvms(C)) {\n+        set_jvms(jvms()->clone_deep(C));\n+        jvms()->set_map_deep(this);\n+      } else {\n+        jvms()->clone_shallow(C)->bind_map(this);\n+      }\n+    }\n+  }\n+\n@@ -619,8 +631,2 @@\n-  \/\/ the node the JVMState must be cloned. Default is not to clone.\n-  virtual bool needs_clone_jvms(Compile* C) { return C->needs_clone_jvms(); }\n-  void clone_jvms(Compile* C) {\n-    if ((jvms() != NULL) && needs_clone_jvms(C)) {\n-      set_jvms(jvms()->clone_deep(C));\n-      jvms()->set_map_deep(this);\n-    }\n-  }\n+  \/\/ the node the JVMState must be deep cloned. Default is to shallow clone.\n+  virtual bool needs_deep_clone_jvms(Compile* C) { return C->needs_deep_clone_jvms(); }\n@@ -740,1 +746,1 @@\n-  \/\/ Late inlining modifies the JVMState, so we need to clone it\n+  \/\/ Late inlining modifies the JVMState, so we need to deep clone it\n@@ -742,2 +748,2 @@\n-  virtual bool needs_clone_jvms(Compile* C) {\n-    return is_boxing_method() || CallNode::needs_clone_jvms(C);\n+  virtual bool needs_deep_clone_jvms(Compile* C) {\n+    return is_boxing_method() || CallNode::needs_deep_clone_jvms(C);\n@@ -766,1 +772,1 @@\n-  \/\/ Late inlining modifies the JVMState, so we need to clone it\n+  \/\/ Late inlining modifies the JVMState, so we need to deep clone it\n@@ -768,2 +774,2 @@\n-  virtual bool needs_clone_jvms(Compile* C) {\n-    return IncrementalInlineVirtual || CallNode::needs_clone_jvms(C);\n+  virtual bool needs_deep_clone_jvms(Compile* C) {\n+    return IncrementalInlineVirtual || CallNode::needs_deep_clone_jvms(C);\n@@ -940,2 +946,2 @@\n-  \/\/ Expansion modifies the JVMState, so we need to clone it\n-  virtual bool needs_clone_jvms(Compile* C) { return true; }\n+  \/\/ Expansion modifies the JVMState, so we need to deep clone it\n+  virtual bool needs_deep_clone_jvms(Compile* C) { return true; }\n@@ -1154,2 +1160,2 @@\n-  \/\/ Expansion modifies the JVMState, so we need to clone it\n-  virtual bool needs_clone_jvms(Compile* C) { return true; }\n+  \/\/ Expansion modifies the JVMState, so we need to deep clone it\n+  virtual bool needs_deep_clone_jvms(Compile* C) { return true; }\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":24,"deletions":18,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+macro(Blackhole)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -430,1 +430,3 @@\n-  remove_useless_nodes(_macro_nodes,        useful); \/\/ remove useless macro and predicate opaq nodes\n+  remove_useless_nodes(_macro_nodes,        useful); \/\/ remove useless macro nodes\n+  remove_useless_nodes(_predicate_opaqs,    useful); \/\/ remove useless predicate opaque nodes\n+  remove_useless_nodes(_skeleton_predicate_opaqs, useful);\n@@ -532,1 +534,0 @@\n-                  _save_argument_registers(false),\n@@ -578,1 +579,0 @@\n-                  _warm_calls(NULL),\n@@ -751,8 +751,0 @@\n-  for (;;) {\n-    int successes = Inline_Warm();\n-    if (failing())  return;\n-    if (successes == 0)  break;\n-  }\n-\n-  \/\/ Drain the list.\n-  Finish_Warm();\n@@ -835,1 +827,0 @@\n-                  bool save_arg_registers,\n@@ -840,1 +831,0 @@\n-    _save_argument_registers(save_arg_registers),\n@@ -879,1 +869,0 @@\n-    _warm_calls(NULL),\n@@ -1755,51 +1744,0 @@\n-\n-\n-\/\/---------------------------pop_warm_call-------------------------------------\n-WarmCallInfo* Compile::pop_warm_call() {\n-  WarmCallInfo* wci = _warm_calls;\n-  if (wci != NULL)  _warm_calls = wci->remove_from(wci);\n-  return wci;\n-}\n-\n-\/\/----------------------------Inline_Warm--------------------------------------\n-int Compile::Inline_Warm() {\n-  \/\/ If there is room, try to inline some more warm call sites.\n-  \/\/ %%% Do a graph index compaction pass when we think we're out of space?\n-  if (!InlineWarmCalls)  return 0;\n-\n-  int calls_made_hot = 0;\n-  int room_to_grow   = NodeCountInliningCutoff - unique();\n-  int amount_to_grow = MIN2(room_to_grow, (int)NodeCountInliningStep);\n-  int amount_grown   = 0;\n-  WarmCallInfo* call;\n-  while (amount_to_grow > 0 && (call = pop_warm_call()) != NULL) {\n-    int est_size = (int)call->size();\n-    if (est_size > (room_to_grow - amount_grown)) {\n-      \/\/ This one won't fit anyway.  Get rid of it.\n-      call->make_cold();\n-      continue;\n-    }\n-    call->make_hot();\n-    calls_made_hot++;\n-    amount_grown   += est_size;\n-    amount_to_grow -= est_size;\n-  }\n-\n-  if (calls_made_hot > 0)  set_major_progress();\n-  return calls_made_hot;\n-}\n-\n-\n-\/\/----------------------------Finish_Warm--------------------------------------\n-void Compile::Finish_Warm() {\n-  if (!InlineWarmCalls)  return;\n-  if (failing())  return;\n-  if (warm_calls() == NULL)  return;\n-\n-  \/\/ Clean up loose ends, if we are out of space for inlining.\n-  WarmCallInfo* call;\n-  while ((call = pop_warm_call()) != NULL) {\n-    call->make_cold();\n-  }\n-}\n-\n@@ -3196,2 +3134,0 @@\n-    \/\/ platform dependent reshaping of the address expression\n-    reshape_address(n->as_AddP());\n@@ -3583,0 +3519,2 @@\n+  case Op_Blackhole:\n+    break;\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":5,"deletions":67,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -377,1 +377,15 @@\n-      \/\/ Hoist it up to the end of the test block.\n+      \/\/ Hoist it up to the end of the test block together with its inputs if they exist.\n+      for (uint i = 2; i < val->req(); i++) {\n+        \/\/ DecodeN has 2 regular inputs + optional MachTemp or load Base inputs.\n+        Node *temp = val->in(i);\n+        Block *tempb = get_block_for_node(temp);\n+        if (!tempb->dominates(block)) {\n+          assert(block->dominates(tempb), \"sanity check: temp node placement\");\n+          \/\/ We only expect nodes without further inputs, like MachTemp or load Base.\n+          assert(temp->req() == 0 || (temp->req() == 1 && temp->in(0) == (Node*)C->root()),\n+                 \"need for recursive hoisting not expected\");\n+          tempb->find_remove(temp);\n+          block->add_inst(temp);\n+          map_node_to_block(temp, block);\n+        }\n+      }\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -222,1 +222,1 @@\n-  Node* make_unsafe_address(Node*& base, Node* offset, DecoratorSet decorators, BasicType type = T_ILLEGAL, bool can_cast = false);\n+  Node* make_unsafe_address(Node*& base, Node* offset, BasicType type = T_ILLEGAL, bool can_cast = false);\n@@ -348,0 +348,2 @@\n+\n+  bool inline_blackhole();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -727,1 +727,1 @@\n-bool Matcher::is_save_on_entry( int reg ) {\n+bool Matcher::is_save_on_entry(int reg) {\n@@ -730,3 +730,1 @@\n-    _register_save_policy[reg] == 'A' || \/\/ Save-on-entry register?\n-    \/\/ Also save argument registers in the trampolining stubs\n-    (C->save_argument_registers() && is_spillable_arg(reg));\n+    _register_save_policy[reg] == 'A'; \/\/ Save-on-entry register?\n@@ -748,6 +746,0 @@\n-  \/\/ Save argument registers in the trampolining stubs\n-  if( C->save_argument_registers() )\n-    for( i = 0; i < _last_Mach_Reg; i++ )\n-      if( is_spillable_arg(i) )\n-        soe_cnt++;\n-\n@@ -2039,1 +2031,1 @@\n-bool Matcher::is_vshift_con_pattern(Node *n, Node *m) {\n+bool Matcher::is_vshift_con_pattern(Node* n, Node* m) {\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":3,"deletions":11,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -127,2 +127,2 @@\n-#define gen(env, var, type_func_gen, c_func, fancy_jump, pass_tls, save_arg_regs, return_pc) \\\n-  var = generate_stub(env, type_func_gen, CAST_FROM_FN_PTR(address, c_func), #var, fancy_jump, pass_tls, save_arg_regs, return_pc); \\\n+#define gen(env, var, type_func_gen, c_func, fancy_jump, pass_tls, return_pc) \\\n+  var = generate_stub(env, type_func_gen, CAST_FROM_FN_PTR(address, c_func), #var, fancy_jump, pass_tls, return_pc); \\\n@@ -137,1 +137,1 @@\n-  \/\/   variable\/name                       type-function-gen              , runtime method                  ,fncy_jp, tls,save_args,retpc\n+  \/\/   variable\/name                       type-function-gen              , runtime method                  ,fncy_jp, tls,retpc\n@@ -139,15 +139,15 @@\n-  gen(env, _new_instance_Java              , new_instance_Type            , new_instance_C                  ,    0 , true , false, false);\n-  gen(env, _new_array_Java                 , new_array_Type               , new_array_C                     ,    0 , true , false, false);\n-  gen(env, _new_array_nozero_Java          , new_array_Type               , new_array_nozero_C              ,    0 , true , false, false);\n-  gen(env, _multianewarray2_Java           , multianewarray2_Type         , multianewarray2_C               ,    0 , true , false, false);\n-  gen(env, _multianewarray3_Java           , multianewarray3_Type         , multianewarray3_C               ,    0 , true , false, false);\n-  gen(env, _multianewarray4_Java           , multianewarray4_Type         , multianewarray4_C               ,    0 , true , false, false);\n-  gen(env, _multianewarray5_Java           , multianewarray5_Type         , multianewarray5_C               ,    0 , true , false, false);\n-  gen(env, _multianewarrayN_Java           , multianewarrayN_Type         , multianewarrayN_C               ,    0 , true , false, false);\n-  gen(env, _complete_monitor_locking_Java  , complete_monitor_enter_Type  , SharedRuntime::complete_monitor_locking_C, 0, false, false, false);\n-  gen(env, _monitor_notify_Java            , monitor_notify_Type          , monitor_notify_C                ,    0 , false, false, false);\n-  gen(env, _monitor_notifyAll_Java         , monitor_notify_Type          , monitor_notifyAll_C             ,    0 , false, false, false);\n-  gen(env, _rethrow_Java                   , rethrow_Type                 , rethrow_C                       ,    2 , true , false, true );\n-\n-  gen(env, _slow_arraycopy_Java            , slow_arraycopy_Type          , SharedRuntime::slow_arraycopy_C ,    0 , false, false, false);\n-  gen(env, _register_finalizer_Java        , register_finalizer_Type      , register_finalizer              ,    0 , false, false, false);\n+  gen(env, _new_instance_Java              , new_instance_Type            , new_instance_C                  ,    0 , true, false);\n+  gen(env, _new_array_Java                 , new_array_Type               , new_array_C                     ,    0 , true, false);\n+  gen(env, _new_array_nozero_Java          , new_array_Type               , new_array_nozero_C              ,    0 , true, false);\n+  gen(env, _multianewarray2_Java           , multianewarray2_Type         , multianewarray2_C               ,    0 , true, false);\n+  gen(env, _multianewarray3_Java           , multianewarray3_Type         , multianewarray3_C               ,    0 , true, false);\n+  gen(env, _multianewarray4_Java           , multianewarray4_Type         , multianewarray4_C               ,    0 , true, false);\n+  gen(env, _multianewarray5_Java           , multianewarray5_Type         , multianewarray5_C               ,    0 , true, false);\n+  gen(env, _multianewarrayN_Java           , multianewarrayN_Type         , multianewarrayN_C               ,    0 , true, false);\n+  gen(env, _complete_monitor_locking_Java  , complete_monitor_enter_Type  , SharedRuntime::complete_monitor_locking_C, 0, false, false);\n+  gen(env, _monitor_notify_Java            , monitor_notify_Type          , monitor_notify_C                ,    0 , false, false);\n+  gen(env, _monitor_notifyAll_Java         , monitor_notify_Type          , monitor_notifyAll_C             ,    0 , false, false);\n+  gen(env, _rethrow_Java                   , rethrow_Type                 , rethrow_C                       ,    2 , true , true );\n+\n+  gen(env, _slow_arraycopy_Java            , slow_arraycopy_Type          , SharedRuntime::slow_arraycopy_C ,    0 , false, false);\n+  gen(env, _register_finalizer_Java        , register_finalizer_Type      , register_finalizer              ,    0 , false, false);\n@@ -162,6 +162,5 @@\n-address OptoRuntime::generate_stub( ciEnv* env,\n-                                    TypeFunc_generator gen, address C_function,\n-                                    const char *name, int is_fancy_jump,\n-                                    bool pass_tls,\n-                                    bool save_argument_registers,\n-                                    bool return_pc) {\n+address OptoRuntime::generate_stub(ciEnv* env,\n+                                   TypeFunc_generator gen, address C_function,\n+                                   const char *name, int is_fancy_jump,\n+                                   bool pass_tls,\n+                                   bool return_pc) {\n@@ -172,1 +171,1 @@\n-  Compile C( env, gen, C_function, name, is_fancy_jump, pass_tls, save_argument_registers, return_pc, directive);\n+  Compile C(env, gen, C_function, name, is_fancy_jump, pass_tls, return_pc, directive);\n@@ -1399,1 +1398,1 @@\n-    RegisterMap map(current, false \/* update_map *\/, false \/* process_frames *\/);\n+    RegisterMap map(current, false);\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":25,"deletions":26,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -133,1 +133,1 @@\n-  static address generate_stub(ciEnv* ci_env, TypeFunc_generator gen, address C_function, const char *name, int is_fancy_jump, bool pass_tls, bool save_arguments, bool return_pc);\n+  static address generate_stub(ciEnv* ci_env, TypeFunc_generator gen, address C_function, const char* name, int is_fancy_jump, bool pass_tls, bool return_pc);\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -442,1 +442,2 @@\n-    res = gvn().transform(VectorNode::make(Op_LShiftVB, res, cnt, vt));\n+    Node* shift_cnt = vector_shift_count(cnt, Op_LShiftI, elem_bt, num_elem);\n+    res = gvn().transform(VectorNode::make(Op_LShiftVB, res, shift_cnt, vt));\n@@ -697,1 +698,0 @@\n-  DecoratorSet decorators = C2_UNSAFE_ACCESS;\n@@ -703,1 +703,1 @@\n-  Node* addr = make_unsafe_address(base, offset, decorators, (is_mask ? T_BOOLEAN : elem_bt), true);\n+  Node* addr = make_unsafe_address(base, offset, (is_mask ? T_BOOLEAN : elem_bt), true);\n@@ -896,1 +896,1 @@\n-  Node* addr = make_unsafe_address(base, offset, C2_UNSAFE_ACCESS, elem_bt, true);\n+  Node* addr = make_unsafe_address(base, offset, elem_bt, true);\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/shared\/stringdedup\/stringDedup.hpp\"\n@@ -4001,0 +4002,4 @@\n+  if (!StringDedup::ergo_initialize()) {\n+    return JNI_EINVAL;\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -627,0 +627,1 @@\n+  friend class AdapterHandlerLibrary;\n@@ -649,1 +650,0 @@\n-    _saved_code = NULL;\n@@ -677,1 +677,1 @@\n-  bool compare_code(unsigned char* code, int length);\n+  bool compare_code(AdapterHandlerEntry* other);\n@@ -685,0 +685,1 @@\n+  friend class SharedRuntime;\n@@ -689,0 +690,6 @@\n+  static AdapterHandlerEntry* _no_arg_handler;\n+  static AdapterHandlerEntry* _int_arg_handler;\n+  static AdapterHandlerEntry* _obj_arg_handler;\n+  static AdapterHandlerEntry* _obj_int_arg_handler;\n+  static AdapterHandlerEntry* _obj_obj_arg_handler;\n+\n@@ -691,1 +698,5 @@\n-\n+  static AdapterHandlerEntry* create_adapter(AdapterBlob*& new_adapter,\n+                                             int total_args_passed,\n+                                             BasicType* sig_bt,\n+                                             bool allocate_code_blob);\n+  static AdapterHandlerEntry* get_simple_adapter(const methodHandle& method);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":14,"deletions":3,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -733,1 +733,0 @@\n-  volatile_nonstatic_field(Thread,             _suspend_flags,                                uint32_t)                              \\\n@@ -737,3 +736,0 @@\n-  nonstatic_field(Thread,                      _current_pending_monitor,                      ObjectMonitor*)                        \\\n-  nonstatic_field(Thread,                      _current_pending_monitor_is_from_java,         bool)                                  \\\n-  nonstatic_field(Thread,                      _current_waiting_monitor,                      ObjectMonitor*)                        \\\n@@ -746,0 +742,5 @@\n+  nonstatic_field(JavaThread,                  _current_pending_monitor,                      ObjectMonitor*)                        \\\n+  nonstatic_field(JavaThread,                  _current_pending_monitor_is_from_java,         bool)                                  \\\n+  nonstatic_field(JavaThread,                  _current_waiting_monitor,                      ObjectMonitor*)                        \\\n+  volatile_nonstatic_field(JavaThread,         _suspend_flags,                                uint32_t)                              \\\n+  nonstatic_field(JavaThread,                  _async_exception_condition,                    JavaThread::AsyncExceptionCondition)   \\\n@@ -750,1 +751,0 @@\n-  nonstatic_field(JavaThread,                  _special_runtime_exit_condition,               JavaThread::AsyncRequests)             \\\n@@ -915,1 +915,0 @@\n-  c2_nonstatic_field(Compile,                  _save_argument_registers,                      const bool)                            \\\n@@ -1600,0 +1599,1 @@\n+  declare_c2_type(BlackholeNode, MemBarNode)                              \\\n@@ -1987,1 +1987,1 @@\n-  declare_integer_type(JavaThread::AsyncRequests)                         \\\n+  declare_integer_type(JavaThread::AsyncExceptionCondition)               \\\n@@ -2147,1 +2147,1 @@\n-  declare_constant(Thread::_has_async_exception)                          \\\n+  declare_constant(JavaThread::_has_async_exception)                      \\\n@@ -2300,1 +2300,0 @@\n-  declare_constant(InstanceKlass::_misc_is_unsafe_anonymous)              \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":8,"deletions":9,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -420,0 +420,1 @@\n+  assert(left >= right, \"avoid underflow\");\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte128Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte128Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte128Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((byte)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte128Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte128Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte256Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte256Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte256Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((byte)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte256Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte256Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte512Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte512Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte512Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((byte)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte512Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte512Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte64Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte64Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Byte64Shuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((byte)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Byte64Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Byte64Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         ByteMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (ByteMaxVector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         ByteMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Byte> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((byte)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (ByteMaxVector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteMaxVector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1973,8 +1973,5 @@\n-        byte[] a0 = this.vec();\n-        byte[] a1 = that.vec();\n-        byte[] res = new byte[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Byte> iota = iotaShuffle();\n+        VectorMask<Byte> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -2002,0 +1999,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    ByteVector sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Byte> iota = iotaShuffle();\n+        VectorMask<Byte> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((byte)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -2016,15 +2024,6 @@\n-        byte[] slice = this.vec();\n-        byte[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Byte> iota = iotaShuffle();\n+        VectorMask<Byte> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast((byte)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -2060,0 +2059,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    ByteVector\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Byte> iota = iotaShuffle();\n+        VectorMask<Byte> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast((byte)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double128Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((double)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double128Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double128Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((double)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double128Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double128Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double256Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((double)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double256Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double256Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((double)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double256Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double256Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double512Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((double)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double512Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double512Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((double)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double512Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double512Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double64Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((double)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double64Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Double64Shuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((double)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Double64Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Double64Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         DoubleMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((double)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (DoubleMaxVector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         DoubleMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Double> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((double)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (DoubleMaxVector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleMaxVector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1882,8 +1882,5 @@\n-        double[] a0 = this.vec();\n-        double[] a1 = that.vec();\n-        double[] res = new double[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Double> iota = iotaShuffle();\n+        VectorMask<Double> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((double)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -1911,0 +1908,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    DoubleVector sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Double> iota = iotaShuffle();\n+        VectorMask<Double> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((double)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -1925,15 +1933,6 @@\n-        double[] slice = this.vec();\n-        double[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Double> iota = iotaShuffle();\n+        VectorMask<Double> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast((double)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -1969,0 +1968,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    DoubleVector\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Double> iota = iotaShuffle();\n+        VectorMask<Double> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast((double)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float128Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((float)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float128Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float128Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((float)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float128Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float128Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float256Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((float)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float256Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float256Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((float)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float256Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float256Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float512Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((float)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float512Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float512Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((float)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float512Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float512Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float64Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((float)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float64Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Float64Shuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((float)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Float64Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Float64Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -384,8 +384,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         FloatMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((float)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (FloatMaxVector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -412,8 +405,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         FloatMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Float> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((float)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (FloatMaxVector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatMaxVector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1894,8 +1894,5 @@\n-        float[] a0 = this.vec();\n-        float[] a1 = that.vec();\n-        float[] res = new float[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Float> iota = iotaShuffle();\n+        VectorMask<Float> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((float)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -1923,0 +1920,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    FloatVector sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Float> iota = iotaShuffle();\n+        VectorMask<Float> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((float)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -1937,15 +1945,6 @@\n-        float[] slice = this.vec();\n-        float[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Float> iota = iotaShuffle();\n+        VectorMask<Float> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast((float)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -1981,0 +1980,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    FloatVector\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Float> iota = iotaShuffle();\n+        VectorMask<Float> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast((float)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int128Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((int)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int128Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int128Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((int)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int128Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int128Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int256Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((int)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int256Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int256Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((int)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int256Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int256Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int512Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((int)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int512Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int512Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((int)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int512Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int512Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int64Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((int)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int64Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Int64Shuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((int)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Int64Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Int64Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         IntMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((int)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (IntMaxVector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         IntMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Integer> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((int)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (IntMaxVector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntMaxVector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1972,8 +1972,5 @@\n-        int[] a0 = this.vec();\n-        int[] a1 = that.vec();\n-        int[] res = new int[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Integer> iota = iotaShuffle();\n+        VectorMask<Integer> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((int)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -2001,0 +1998,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    IntVector sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Integer> iota = iotaShuffle();\n+        VectorMask<Integer> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((int)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -2015,15 +2023,6 @@\n-        int[] slice = this.vec();\n-        int[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Integer> iota = iotaShuffle();\n+        VectorMask<Integer> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast((int)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -2059,0 +2058,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    IntVector\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Integer> iota = iotaShuffle();\n+        VectorMask<Integer> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast((int)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -380,8 +380,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long128Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((long)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long128Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -408,8 +401,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long128Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((long)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long128Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long128Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -380,8 +380,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long256Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((long)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long256Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -408,8 +401,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long256Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((long)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long256Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long256Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -380,8 +380,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long512Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((long)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long512Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -408,8 +401,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long512Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((long)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long512Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long512Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -380,8 +380,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long64Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((long)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long64Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -408,8 +401,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Long64Shuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((long)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Long64Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Long64Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -380,8 +380,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         LongMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((long)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (LongMaxVector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -408,8 +401,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         LongMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Long> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((long)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (LongMaxVector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongMaxVector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1843,8 +1843,5 @@\n-        long[] a0 = this.vec();\n-        long[] a1 = that.vec();\n-        long[] res = new long[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Long> iota = iotaShuffle();\n+        VectorMask<Long> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((long)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -1872,0 +1869,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    LongVector sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Long> iota = iotaShuffle();\n+        VectorMask<Long> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((long)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -1886,15 +1894,6 @@\n-        long[] slice = this.vec();\n-        long[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Long> iota = iotaShuffle();\n+        VectorMask<Long> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast((long)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -1930,0 +1929,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    LongVector\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Long> iota = iotaShuffle();\n+        VectorMask<Long> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast((long)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short128Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((short)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short128Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short128Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((short)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short128Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short128Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short256Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((short)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short256Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short256Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((short)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short256Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short256Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short512Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((short)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short512Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short512Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((short)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short512Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short512Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short64Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((short)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short64Vector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         Short64Shuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((short)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (Short64Vector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/Short64Vector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -390,8 +390,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         ShortMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast((short)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (ShortMaxVector) super.sliceTemplate(origin);  \/\/ specialize\n@@ -418,8 +411,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         ShortMaxShuffle Iota = iotaShuffle();\n-         VectorMask<Short> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast((short)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return (ShortMaxVector) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortMaxVector.java","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1973,8 +1973,5 @@\n-        short[] a0 = this.vec();\n-        short[] a1 = that.vec();\n-        short[] res = new short[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Short> iota = iotaShuffle();\n+        VectorMask<Short> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((short)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -2002,0 +1999,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    ShortVector sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Short> iota = iotaShuffle();\n+        VectorMask<Short> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast((short)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -2016,15 +2024,6 @@\n-        short[] slice = this.vec();\n-        short[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Short> iota = iotaShuffle();\n+        VectorMask<Short> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast((short)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -2060,0 +2059,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    ShortVector\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<Short> iota = iotaShuffle();\n+        VectorMask<Short> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast((short)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2242,8 +2242,5 @@\n-        $type$[] a0 = this.vec();\n-        $type$[] a1 = that.vec();\n-        $type$[] res = new $type$[a0.length];\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        System.arraycopy(a0, origin, res, 0, firstPart);\n-        System.arraycopy(a1, 0, res, firstPart, origin);\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<$Boxtype$> iota = iotaShuffle();\n+        VectorMask<$Boxtype$> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast(($type$)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return that.rearrange(iota).blend(this.rearrange(iota), blendMask);\n@@ -2271,0 +2268,11 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    $abstractvectortype$ sliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<$Boxtype$> iota = iotaShuffle();\n+        VectorMask<$Boxtype$> blendMask = iota.toVector().compare(VectorOperators.LT, (broadcast(($type$)(length() - origin))));\n+        iota = iotaShuffle(origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n@@ -2285,15 +2293,6 @@\n-        $type$[] slice = this.vec();\n-        $type$[] res = that.vec().clone();\n-        int vlen = res.length;\n-        int firstPart = vlen - origin;\n-        switch (part) {\n-        case 0:\n-            System.arraycopy(slice, 0, res, origin, firstPart);\n-            break;\n-        case 1:\n-            System.arraycopy(slice, firstPart, res, 0, origin);\n-            break;\n-        default:\n-            throw wrongPartForSlice(part);\n-        }\n-        return vectorFactory(res);\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<$Boxtype$> iota = iotaShuffle();\n+        VectorMask<$Boxtype$> blendMask = iota.toVector().compare((part == 0) ? VectorOperators.GE : VectorOperators.LT,\n+                                                                  (broadcast(($type$)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return that.blend(this.rearrange(iota), blendMask);\n@@ -2329,0 +2328,13 @@\n+    \/*package-private*\/\n+    final\n+    @ForceInline\n+    $abstractvectortype$\n+    unsliceTemplate(int origin) {\n+        Objects.checkIndex(origin, length() + 1);\n+        VectorShuffle<$Boxtype$> iota = iotaShuffle();\n+        VectorMask<$Boxtype$> blendMask = iota.toVector().compare(VectorOperators.GE,\n+                                                                  (broadcast(($type$)(origin))));\n+        iota = iotaShuffle(-origin, 1, true);\n+        return vspecies().zero().blend(this.rearrange(iota), blendMask);\n+    }\n+\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":35,"deletions":23,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -396,8 +396,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         $shuffletype$ Iota = iotaShuffle();\n-         VectorMask<$Boxtype$> BlendMask = Iota.toVector().compare(VectorOperators.LT, (broadcast(($type$)(VLENGTH-origin))));\n-         Iota = iotaShuffle(origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return ($vectortype$) super.sliceTemplate(origin);  \/\/ specialize\n@@ -424,8 +417,1 @@\n-       if ((origin < 0) || (origin >= VLENGTH)) {\n-         throw new ArrayIndexOutOfBoundsException(\"Index \" + origin + \" out of bounds for vector length \" + VLENGTH);\n-       } else {\n-         $shuffletype$ Iota = iotaShuffle();\n-         VectorMask<$Boxtype$> BlendMask = Iota.toVector().compare(VectorOperators.GE, (broadcast(($type$)(origin))));\n-         Iota = iotaShuffle(-origin, 1, true);\n-         return ZERO.blend(this.rearrange(Iota), BlendMask);\n-       }\n+        return ($vectortype$) super.unsliceTemplate(origin);  \/\/ specialize\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-VectorBits.java.template","additions":3,"deletions":17,"binary":false,"changes":20,"status":"modified"}]}