{"files":[{"patch":"@@ -2062,1 +2062,1 @@\n-  if (src_hi != OptoReg::Bad) {\n+  if (src_hi != OptoReg::Bad && !bottom_type()->isa_vectmask()) {\n@@ -2077,1 +2077,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -2183,0 +2183,3 @@\n+      } else if (dst_lo_rc == rc_predicate) {\n+        __ unspill_sve_predicate(as_PRegister(Matcher::_regEncode[dst_lo]), ra_->reg2offset(src_lo),\n+                                 Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n@@ -2185,2 +2188,18 @@\n-        __ unspill(rscratch1, is64, src_offset);\n-        __ spill(rscratch1, is64, dst_offset);\n+        if (ideal_reg() == Op_RegVectMask) {\n+          __ spill_copy_sve_predicate_stack_to_stack(src_offset, dst_offset,\n+                                                     Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n+        } else {\n+          __ unspill(rscratch1, is64, src_offset);\n+          __ spill(rscratch1, is64, dst_offset);\n+        }\n+      }\n+      break;\n+    case rc_predicate:\n+      if (dst_lo_rc == rc_predicate) {\n+        __ sve_mov(as_PRegister(Matcher::_regEncode[dst_lo]), as_PRegister(Matcher::_regEncode[src_lo]));\n+      } else if (dst_lo_rc == rc_stack) {\n+        __ spill_sve_predicate(as_PRegister(Matcher::_regEncode[src_lo]), ra_->reg2offset(dst_lo),\n+                               Matcher::scalable_vector_reg_size(T_BYTE) >> 3);\n+      } else {\n+        assert(false, \"bad src and dst rc_class combination.\");\n+        ShouldNotReachHere();\n@@ -2207,1 +2226,1 @@\n-    if (bottom_type()->isa_vect() != NULL) {\n+    if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -2224,0 +2243,4 @@\n+    } else if (ideal_reg() == Op_RegVectMask) {\n+      assert(Matcher::supports_scalable_vector(), \"bad register type for spill\");\n+      int vsize = Matcher::scalable_predicate_reg_slots() * 32;\n+      st->print(\"\\t# predicate spill size = %d\", vsize);\n@@ -2383,0 +2406,12 @@\n+    case Op_LoadVectorMasked:\n+    case Op_StoreVectorMasked:\n+    case Op_LoadVectorGatherMasked:\n+    case Op_StoreVectorScatterMasked:\n+    case Op_MaskAll:\n+    case Op_AndVMask:\n+    case Op_OrVMask:\n+    case Op_XorVMask:\n+      if (UseSVE == 0) {\n+        ret_value = false;\n+      }\n+      break;\n@@ -2451,0 +2486,9 @@\n+const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+  \/\/ Only SVE supports masked operations.\n+  if (UseSVE == 0) {\n+    return false;\n+  }\n+  return match_rule_supported(opcode) &&\n+         masked_op_sve_supported(opcode, vlen, bt);\n+}\n+\n@@ -2664,2 +2708,9 @@\n-  if (is_vshift_con_pattern(n, m)) { \/\/ ShiftV src (ShiftCntV con)\n-    mstack.push(m, Visit);           \/\/ m = ShiftCntV\n+  \/\/ ShiftV src (ShiftCntV con)\n+  \/\/ * (VectorStoreMask src)\n+  if (is_vshift_con_pattern(n, m) ||\n+      (UseSVE > 0 && m->Opcode() == Op_VectorStoreMask &&\n+       (n->Opcode() == Op_StoreVector ||\n+        n->Opcode() == Op_VectorMaskTrueCount ||\n+        n->Opcode() == Op_VectorMaskFirstTrue ||\n+        n->Opcode() == Op_VectorMaskLastTrue))) {\n+    mstack.push(m, Visit);\n@@ -2668,0 +2719,1 @@\n+\n@@ -8874,0 +8926,11 @@\n+instruct castVVMask(pRegGov dst)\n+%{\n+  match(Set dst (CastVV dst));\n+\n+  size(0);\n+  format %{ \"# castVV of $dst\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_cost(0);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":70,"deletions":7,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -91,0 +91,1 @@\n+  bool masked_op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -147,5 +148,1 @@\n-        if (vlen < 4 || length_in_bytes > MaxVectorSize) {\n-          return false;\n-        } else {\n-          return true;\n-        }\n+        return vlen >= 4 && length_in_bytes <= MaxVectorSize;\n@@ -161,0 +158,8 @@\n+\n+  bool masked_op_sve_supported(int opcode, int vlen, BasicType bt) {\n+    if (opcode == Op_VectorRearrange) {\n+      return false;\n+    }\n+    return op_sve_supported(opcode, vlen, bt);\n+  }\n+\n@@ -304,1 +309,1 @@\n-            \"sve_ldr $dst, $pTmp, $mem\\t# load vector predicated\" %}\n+            \"sve_ldr $dst, $pTmp, $mem\\t# load vector partial\" %}\n@@ -324,1 +329,1 @@\n-            \"sve_str $src, $pTmp, $mem\\t# store vector predicated\" %}\n+            \"sve_str $src, $pTmp, $mem\\t# store vector partial\" %}\n@@ -337,0 +342,206 @@\n+\/\/ vector load\/store - predicated\n+\n+instruct loadV_masked(vReg dst, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n+  match(Set dst (LoadVectorMasked mem pg));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_ldr $dst, $pg, $mem\\t# load vector predicated (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($dst$$reg),\n+                          as_PRegister($pg$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadV_masked_partial(vReg dst, vmemA mem, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVectorMasked mem pg));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_ldr $dst, $pg, $mem\\t# load vector predicated partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ elemType_to_regVariant(bt),\n+                          Matcher::vector_length(this));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($dst$$reg),\n+                          as_PRegister($ptmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked(vReg src, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary src pg)));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_str $mem, $pg, $src\\t# store vector predicated (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($src$$reg),\n+                          as_PRegister($pg$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked_partial(vReg src, vmemA mem, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary src pg)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_str $mem, $pg, $src\\t# store vector predicated partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ elemType_to_regVariant(bt),\n+                          Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($src$$reg),\n+                          as_PRegister($ptmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ maskAll\n+\n+instruct vmaskAll_immI(pRegGov dst, immI src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_ptrue\/sve_pfalse $dst\\t# mask all (sve) (B\/H\/S)\" %}\n+  ins_encode %{\n+    int con = (int)$src$$constant;\n+    if (con == 0) {\n+      __ sve_pfalse(as_PRegister($dst$$reg));\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_ptrue(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllI(pRegGov dst, iRegIorL2I src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup $tmp, $src\\n\\t\"\n+            \"sve_cmpne $dst, $tmp, 0\\t# mask all (sve) (B\/H\/S)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), size, as_Register($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAll_immL(pRegGov dst, immL src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_ptrue\/sve_pfalse $dst\\t# mask all (sve) (D)\" %}\n+  ins_encode %{\n+    long con = (long)$src$$constant;\n+    if (con == 0) {\n+      __ sve_pfalse(as_PRegister($dst$$reg));\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_ptrue(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllL(pRegGov dst, iRegL src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup $tmp, $src\\n\\t\"\n+            \"sve_cmpne $dst, $tmp, 0\\t# mask all (sve) (D)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), size, as_Register($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ mask logical and\/or\/xor\n+\n+instruct vmask_and(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn pm));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_and $pd, $pn, $pm\\t# predicate (sve)\" %}\n+  ins_encode %{\n+    __ sve_and(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_or(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (OrVMask pn pm));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orr $pd, $pn, $pm\\t# predicate (sve)\" %}\n+  ins_encode %{\n+    __ sve_orr(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_xor(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (XorVMask pn pm));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eor $pd, $pn, $pm\\t# predicate (sve)\" %}\n+  ins_encode %{\n+    __ sve_eor(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ mask logical and_not\n+\n+instruct vmask_and_notI(pRegGov pd, pRegGov pn, pRegGov pm, immI_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn (XorVMask pm (MaskAll m1))));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_bic $pd, $pn, $pm\\t# predciate (sve) (B\/H\/S)\" %}\n+  ins_encode %{\n+    __ sve_bic(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_and_notL(pRegGov pd, pRegGov pn, pRegGov pm, immL_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn (XorVMask pm (MaskAll m1))));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_bic $pd, $pn, $pm\\t# predciate (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_bic(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -373,0 +584,34 @@\n+\/\/ vector mask reinterpret\n+\n+instruct vmask_reinterpret_same_esize(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->as_Vector()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst_src (VectorReinterpret dst_src));\n+  ins_cost(0);\n+  format %{ \"# vmask_reinterpret $dst_src\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmask_reinterpret_diff_esize(pRegGov dst, pRegGov src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length() != n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->as_Vector()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"# vmask_reinterpret $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    BasicType from_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant from_size = __ elemType_to_regVariant(from_bt);\n+    BasicType to_bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_size = __ elemType_to_regVariant(to_bt);\n+    __ sve_cpy(as_FloatRegister($tmp$$reg), from_size, as_PRegister($src$$reg), -1, false);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($dst$$reg), to_size, ptrue, as_FloatRegister($tmp$$reg), -1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -377,1 +622,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -390,1 +635,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -403,1 +648,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -416,1 +661,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -429,1 +674,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -442,1 +687,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -453,0 +698,80 @@\n+\/\/ vector abs - predicated\n+\n+instruct vabsB_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVB dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_abs $dst_src, $pg, $dst_src\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_abs(as_FloatRegister($dst_src$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsS_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVS dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_abs $dst_src, $pg, $dst_src\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_abs(as_FloatRegister($dst_src$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsI_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVI dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_abs $dst_src, $pg, $dst_src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_abs(as_FloatRegister($dst_src$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsL_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVL dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_abs $dst_src, $pg, $dst_src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_abs(as_FloatRegister($dst_src$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsF_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVF dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fabs $dst_src, $pg, $dst_src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fabs(as_FloatRegister($dst_src$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsD_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVD dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fabs $dst_src, $pg, $dst_src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fabs(as_FloatRegister($dst_src$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -533,0 +858,80 @@\n+\/\/ vector add - predicated\n+\n+instruct vaddB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVB (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_add $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_add(as_FloatRegister($dst_src1$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVS (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_add $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_add(as_FloatRegister($dst_src1$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVI (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_add $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_add(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVL (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_add $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_add(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVF (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fadd $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fadd(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVD (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fadd $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fadd(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -578,1 +983,1 @@\n-\/\/ vector not\n+\/\/ vector and - predicated\n@@ -580,1 +985,1 @@\n-instruct vnotI(vReg dst, vReg src, immI_M1 m1) %{\n+instruct vand_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n@@ -582,3 +987,1 @@\n-  match(Set dst (XorV src (ReplicateB m1)));\n-  match(Set dst (XorV src (ReplicateS m1)));\n-  match(Set dst (XorV src (ReplicateI m1)));\n+  match(Set dst_src1 (AndV (Binary dst_src1 src2) pg));\n@@ -586,1 +989,1 @@\n-  format %{ \"sve_not $dst, $src\\t# vector (sve) B\/H\/S\" %}\n+  format %{ \"sve_and $dst_src1, $pg, $dst_src1, $src2\\t # vector (sve)\" %}\n@@ -588,2 +991,5 @@\n-    __ sve_not(as_FloatRegister($dst$$reg), __ D,\n-               ptrue, as_FloatRegister($src$$reg));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_and(as_FloatRegister($dst_src1$$reg), size,\n+          as_PRegister($pg$$reg),\n+          as_FloatRegister($src2$$reg));\n@@ -594,1 +1000,3 @@\n-instruct vnotL(vReg dst, vReg src, immL_M1 m1) %{\n+\/\/ vector or - predicated\n+\n+instruct vor_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n@@ -596,1 +1004,1 @@\n-  match(Set dst (XorV src (ReplicateL m1)));\n+  match(Set dst_src1 (OrV (Binary dst_src1 src2) pg));\n@@ -598,1 +1006,1 @@\n-  format %{ \"sve_not $dst, $src\\t# vector (sve) D\" %}\n+  format %{ \"sve_orr $dst_src1, $pg, $dst_src1, $src2\\t # vector (sve)\" %}\n@@ -600,2 +1008,5 @@\n-    __ sve_not(as_FloatRegister($dst$$reg), __ D,\n-               ptrue, as_FloatRegister($src$$reg));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_orr(as_FloatRegister($dst_src1$$reg), size,\n+          as_PRegister($pg$$reg),\n+          as_FloatRegister($src2$$reg));\n@@ -606,0 +1017,1 @@\n+\/\/ vector xor - predicated\n@@ -607,3 +1019,1 @@\n-\/\/ vector and_not\n-\n-instruct vand_notI(vReg dst, vReg src1, vReg src2, immI_M1 m1) %{\n+instruct vxor_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n@@ -611,1 +1021,46 @@\n-  match(Set dst (AndV src1 (XorV src2 (ReplicateB m1))));\n+  match(Set dst_src1 (XorV (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eor $dst_src1, $pg, $dst_src1, $src2\\t # vector (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_eor(as_FloatRegister($dst_src1$$reg), size,\n+          as_PRegister($pg$$reg),\n+          as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector not\n+\n+instruct vnotI(vReg dst, vReg src, immI_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (XorV src (ReplicateB m1)));\n+  match(Set dst (XorV src (ReplicateS m1)));\n+  match(Set dst (XorV src (ReplicateI m1)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_not $dst, $src\\t# vector (sve) B\/H\/S\" %}\n+  ins_encode %{\n+    __ sve_not(as_FloatRegister($dst$$reg), __ D,\n+               ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnotL(vReg dst, vReg src, immL_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (XorV src (ReplicateL m1)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_not $dst, $src\\t# vector (sve) D\" %}\n+  ins_encode %{\n+    __ sve_not(as_FloatRegister($dst$$reg), __ D,\n+               ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector and_not\n+\n+instruct vand_notI(vReg dst, vReg src1, vReg src2, immI_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateB m1))));\n@@ -637,1 +1092,0 @@\n-\n@@ -664,0 +1118,28 @@\n+\/\/ vector float div - predicated\n+\n+instruct vfdivF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (DivVF (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fdiv $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fdiv(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vfdivD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (DivVD (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fdiv $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fdiv(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -678,1 +1160,1 @@\n-      assert(is_integral_type(bt), \"Unsupported type\");\n+      assert(is_integral_type(bt), \"unsupported type\");\n@@ -698,1 +1180,1 @@\n-      assert(is_integral_type(bt), \"Unsupported type\");\n+      assert(is_integral_type(bt), \"unsupported type\");\n@@ -706,0 +1188,42 @@\n+\/\/ vector min\/max - predicated\n+\n+instruct vmin_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MinV (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_min $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    if (is_floating_point_type(bt)) {\n+      __ sve_fmin(as_FloatRegister($dst_src1$$reg), size,\n+                  as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    } else {\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ sve_smin(as_FloatRegister($dst_src1$$reg), size,\n+                  as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmax_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MaxV (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_max $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    if (is_floating_point_type(bt)) {\n+      __ sve_fmax(as_FloatRegister($dst_src1$$reg), size,\n+                  as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    } else {\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ sve_smax(as_FloatRegister($dst_src1$$reg), size,\n+                  as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -734,0 +1258,28 @@\n+\/\/ vector fmla - predicated\n+\n+\/\/ dst_src1 = dst_src1 * src2 + src3\n+instruct vfmlaF_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0);\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 src2) (Binary src3 pg)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fmad $dst_src1, $pg, $src2, $src3\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fmad(as_FloatRegister($dst_src1$$reg), __ S, as_PRegister($pg$$reg),\n+         as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ dst_src1 = dst_src1 * src2 + src3\n+instruct vfmlaD_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0);\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 src2) (Binary src3 pg)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fmad $dst_src1, $pg, $src2, $src3\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fmad(as_FloatRegister($dst_src1$$reg), __ D, as_PRegister($pg$$reg),\n+         as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -942,1 +1494,0 @@\n-\n@@ -1019,0 +1570,80 @@\n+\/\/ vector mul - predicated\n+\n+instruct vmulB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVB (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_mul $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_mul(as_FloatRegister($dst_src1$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVS (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_mul $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_mul(as_FloatRegister($dst_src1$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVI (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_mul $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_mul(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVL (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_mul $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_mul(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVF (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fmul $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fmul(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVD (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fmul $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fmul(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -1022,1 +1653,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 &&\n+            !n->as_Vector()->is_predicated_vector());\n@@ -1034,1 +1666,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 &&\n+            !n->as_Vector()->is_predicated_vector());\n@@ -1045,0 +1678,28 @@\n+\/\/ vector fneg - predicated\n+\n+instruct vnegF_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (NegVF dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fneg $dst_src, $pg, $dst_src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fneg(as_FloatRegister($dst_src$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegD_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (NegVD dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fneg $dst_src, $pg, $dst_src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fneg(as_FloatRegister($dst_src$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -1059,1 +1720,1 @@\n-instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+instruct vmaskcmp(pRegGov dst, vReg src1, vReg src2, immI cond, rFlagsReg cr) %{\n@@ -1062,4 +1723,3 @@\n-  effect(TEMP pTmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n-            \"sve_cpy $dst, $pTmp, -1\\t# vector mask cmp (sve)\" %}\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmp $dst, $src1, $src2\\t# vector mask cmp (sve)\" %}\n@@ -1068,1 +1728,1 @@\n-    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n+    __ sve_compare(as_PRegister($dst$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n@@ -1070,2 +1730,0 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-               as_PRegister($pTmp$$reg), -1, false);\n@@ -1076,3 +1734,1 @@\n-\/\/ vector blend\n-\n-instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+instruct vmaskcmp_masked(pRegGov dst, vReg src1, vReg src2, immI cond, pRegGov pg, rFlagsReg cr) %{\n@@ -1080,5 +1736,4 @@\n-  match(Set dst (VectorBlend (Binary src1 src2) src3));\n-  effect(TEMP pTmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n-            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond pg)));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmp $dst, $pg, $src1, $src2\\t# vector mask cmp (sve)\" %}\n@@ -1086,6 +1741,3 @@\n-    Assembler::SIMD_RegVariant size =\n-      __ elemType_to_regVariant(Matcher::vector_element_basic_type(this));\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               ptrue, as_FloatRegister($src3$$reg), -1);\n-    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n-               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_compare(as_PRegister($dst$$reg), bt, as_PRegister($pg$$reg), as_FloatRegister($src1$$reg),\n+                   as_FloatRegister($src2$$reg), (int)$cond$$constant);\n@@ -1096,1 +1748,1 @@\n-\/\/ vector blend with compare\n+\/\/ vector blend\n@@ -1098,2 +1750,1 @@\n-instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n-                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+instruct vblend(vReg dst, vReg src1, vReg src2, pRegGov pg) %{\n@@ -1101,5 +1752,3 @@\n-  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n-  effect(TEMP pTmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_cmp $pTmp, $src3, $src4\\t# vector cmp (sve)\\n\\t\"\n-            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n+  match(Set dst (VectorBlend (Binary src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sel $dst, $pg, $src2, $src1\\t# vector blend (sve)\" %}\n@@ -1107,6 +1756,4 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src3$$reg),\n-                   as_FloatRegister($src4$$reg), (int)$cond$$constant);\n-    __ sve_sel(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n-               as_FloatRegister($src1$$reg));\n+    Assembler::SIMD_RegVariant size =\n+               __ elemType_to_regVariant(Matcher::vector_element_basic_type(this));\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pg$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n@@ -1119,1 +1766,1 @@\n-instruct vloadmaskB(vReg dst, vReg src) %{\n+instruct vloadmaskB(pRegGov dst, vReg src, rFlagsReg cr) %{\n@@ -1123,0 +1770,1 @@\n+  effect(KILL cr);\n@@ -1124,1 +1772,1 @@\n-  format %{ \"sve_neg $dst, $src\\t# vector load mask (B)\" %}\n+  format %{ \"vloadmaskB $dst, $src\\t# vector load mask (sve) (B)\" %}\n@@ -1126,1 +1774,2 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ B,\n+               ptrue, as_FloatRegister($src$$reg), 0);\n@@ -1131,1 +1780,1 @@\n-instruct vloadmaskS(vReg dst, vReg src) %{\n+instruct vloadmaskS(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n@@ -1135,0 +1784,1 @@\n+  effect(TEMP tmp, KILL cr);\n@@ -1136,2 +1786,1 @@\n-  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# vector load mask (B to H)\" %}\n+  format %{ \"vloadmaskS $dst, $src\\t# vector load mask (sve) (B to H)\" %}\n@@ -1139,2 +1788,3 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ H,\n+               ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -1145,1 +1795,1 @@\n-instruct vloadmaskI(vReg dst, vReg src) %{\n+instruct vloadmaskI(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n@@ -1150,0 +1800,1 @@\n+  effect(TEMP tmp, KILL cr);\n@@ -1151,3 +1802,1 @@\n-  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n-            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# vector load mask (B to S)\" %}\n+  format %{ \"vloadmaskI $dst, $src\\t# vector load mask (sve) (B to S)\" %}\n@@ -1155,3 +1804,3 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($tmp$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ S, ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -1162,1 +1811,1 @@\n-instruct vloadmaskL(vReg dst, vReg src) %{\n+instruct vloadmaskL(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n@@ -1167,0 +1816,1 @@\n+  effect(TEMP tmp, KILL cr);\n@@ -1168,4 +1818,1 @@\n-  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n-            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n-            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# vector load mask (B to D)\" %}\n+  format %{ \"vloadmaskL $dst, $src\\t# vector load mask (sve) (B to D)\" %}\n@@ -1173,4 +1820,4 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($tmp$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($tmp$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ D, ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -1183,1 +1830,1 @@\n-instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+instruct vstoremaskB(vReg dst, pRegGov src, immI_1 size) %{\n@@ -1187,1 +1834,1 @@\n-  format %{ \"sve_neg $dst, $src\\t# vector store mask (B)\" %}\n+  format %{ \"vstoremaskB $dst, $src\\t# vector store mask (sve) (B)\" %}\n@@ -1189,2 +1836,1 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B, as_PRegister($src$$reg), 1, false);\n@@ -1195,1 +1841,1 @@\n-instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+instruct vstoremaskS(vReg dst, pRegGov src, vReg tmp, immI_2 size) %{\n@@ -1200,3 +1846,1 @@\n-  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n-            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n-            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (H to B)\" %}\n+  format %{ \"vstoremaskS $dst, $src\\t# vector store mask (sve) (H to B)\" %}\n@@ -1204,0 +1848,1 @@\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H, as_PRegister($src$$reg), 1, false);\n@@ -1206,4 +1851,1 @@\n-                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($dst$$reg));\n-\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1214,1 +1856,1 @@\n-instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+instruct vstoremaskI(vReg dst, pRegGov src, vReg tmp, immI_4 size) %{\n@@ -1219,4 +1861,1 @@\n-  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n-            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (S to B)\" %}\n+  format %{ \"vstoremaskI $dst, $src\\t# vector store mask (sve) (S to B)\" %}\n@@ -1224,0 +1863,1 @@\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S, as_PRegister($src$$reg), 1, false);\n@@ -1226,1 +1866,1 @@\n-                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1229,2 +1869,0 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($dst$$reg));\n@@ -1235,1 +1873,1 @@\n-instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+instruct vstoremaskL(vReg dst, pRegGov src, vReg tmp, immI_8 size) %{\n@@ -1240,5 +1878,1 @@\n-  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n-            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (D to B)\" %}\n+  format %{ \"vstoremaskL $dst, $src\\t# vector store mask (sve) (D to B)\" %}\n@@ -1246,0 +1880,1 @@\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D, as_PRegister($src$$reg), 1, false);\n@@ -1248,1 +1883,1 @@\n-                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -1253,2 +1888,0 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($dst$$reg));\n@@ -1259,1 +1892,1 @@\n-\/\/ load\/store mask vector\n+\/\/ Combine LoadVector+VectorLoadMask when the vector element type is not T_BYTE\n@@ -1261,3 +1894,4 @@\n-instruct vloadmask_loadV_byte(vReg dst, vmemA mem) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n-            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n+instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n@@ -1265,3 +1899,4 @@\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# load vector mask (sve)\" %}\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $tmp, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $tmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n@@ -1269,1 +1904,2 @@\n-    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ expected vector element type. Convert the vector to predicate.\n@@ -1271,3 +1907,2 @@\n-    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, to_vect_bt, $mem->opcode(),\n@@ -1275,1 +1910,2 @@\n-    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -1280,2 +1916,4 @@\n-instruct vloadmask_loadV_non_byte(vReg dst, indirect mem) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+instruct vloadmask_loadV_partial(pRegGov dst, indirect mem, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length_in_bytes() > 16 &&\n+            n->as_Vector()->length_in_bytes() < MaxVectorSize &&\n@@ -1284,3 +1922,3 @@\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# load vector mask (sve)\" %}\n+  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"vloadmask_loadV $dst, $mem\\t# load vector mask partial (sve) (H\/S\/D)\" %}\n@@ -1288,1 +1926,2 @@\n-    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ expected vector element type. Convert the vector to predicate.\n@@ -1290,3 +1929,4 @@\n-    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(to_vect_bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($ptmp$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n@@ -1294,1 +1934,1 @@\n-    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($vtmp$$reg), 0);\n@@ -1299,3 +1939,5 @@\n-instruct storeV_vstoremask_byte(vmemA mem, vReg src, vReg tmp, immI_1 esize) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n-                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+\/\/ Combine VectorStoreMask+StoreVector when the vector element type is not T_BYTE\n+\n+instruct storeV_vstoremask(indirect mem, pRegGov src, vReg tmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n@@ -1304,3 +1946,3 @@\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_neg $tmp, $src\\n\\t\"\n-            \"sve_st1b $tmp, $mem\\t# store vector mask (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_cpy $tmp, $src, 1\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n@@ -1310,3 +1952,2 @@\n-    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);\n-    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n-               as_FloatRegister($src$$reg));\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy(as_FloatRegister($tmp$$reg), size, as_PRegister($src$$reg), 1, false);\n@@ -1320,3 +1961,6 @@\n-instruct storeV_vstoremask_non_byte(indirect mem, vReg src, vReg tmp, immI_gt_1 esize) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n-                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+instruct storeV_vstoremask_partial(indirect mem, pRegGov src, vReg vtmp,\n+                                   immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() > 16 &&\n+            type2aelembytes(n->as_StoreVector()->vect_type()->element_basic_type()) > 1 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n@@ -1324,4 +1968,3 @@\n-  effect(TEMP tmp);\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_neg $tmp, $src\\n\\t\"\n-            \"sve_st1b $tmp, $mem\\t# store vector mask (sve)\" %}\n+  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n+  format %{ \"storeV_vstoremask $src, $mem\\t# store vector mask partial (sve) (H\/S\/D)\" %}\n+  ins_cost(6 * SVE_COST);\n@@ -1329,0 +1972,2 @@\n+    \/\/ Convert the valid src predicate to vector, and store the vector\n+    \/\/ elements as boolean values.\n@@ -1330,6 +1975,5 @@\n-    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n-    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);\n-    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n-               as_FloatRegister($src$$reg));\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n-                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(from_vect_bt);\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($ptmp$$reg), T_BOOLEAN, from_vect_bt, $mem->opcode(),\n@@ -1343,26 +1987,3 @@\n-instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (AddReductionVI src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addB\/S\/I reduction (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1370,1 +1991,1 @@\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1372,1 +1993,1 @@\n-  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction (sve) (may extend)\" %}\n@@ -1375,14 +1996,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n@@ -1393,2 +2003,3 @@\n-instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1396,1 +2007,1 @@\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1400,3 +2011,49 @@\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addF(vRegF src1_dst, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF src1_dst src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addD(vRegD src1_dst, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD src1_dst src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1409,1 +2066,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n@@ -1412,1 +2070,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -1417,1 +2075,34 @@\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addF_partial(vRegF src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF src1_dst src2));\n+  ins_cost(SVE_COST);\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_addF $src1_dst, $src1_dst, $src2\\t# addF reduction partial (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addD_partial(vRegD src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD src1_dst src2));\n+  ins_cost(SVE_COST);\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_addD $src1_dst, $src1_dst, $src2\\t# addD reduction partial (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n@@ -1419,2 +2110,0 @@\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1425,0 +2114,1 @@\n+\/\/ vector add reduction - predicated\n@@ -1426,3 +2116,5 @@\n-instruct reduce_addF(vRegF src1_dst, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set src1_dst (AddReductionVF src1_dst src2));\n+instruct reduce_addI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AddReductionVI (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1430,1 +2122,31 @@\n-  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_addI $dst, $src1, $pg, $src2\\t# addI reduction predicated (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addL_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AddReductionVL (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addL $dst, $src1, $pg, $src2\\t# addL reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addF_masked(vRegF src1_dst, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF (Binary src1_dst src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addF $src1_dst, $pg, $src2\\t# addF reduction predicated (sve)\" %}\n@@ -1433,1 +2155,1 @@\n-         ptrue, as_FloatRegister($src2$$reg));\n+                 as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n@@ -1438,3 +2160,4 @@\n-instruct reduce_addF_partial(vRegF src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set src1_dst (AddReductionVF src1_dst src2));\n+instruct reduce_addD_masked(vRegD src1_dst, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD (Binary src1_dst src2) pg));\n@@ -1442,0 +2165,54 @@\n+  format %{ \"sve_reduce_addD $src1_dst, $pg, $src2\\t# addD reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+                 as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addI_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $pg, $src2\\t# addI reduction predicated partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addL_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_addL $dst, $src1, $pg, $src2\\t# addL reduction predicated partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addF_masked_partial(vRegF src1_dst, vReg src2, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF (Binary src1_dst src2) pg));\n@@ -1443,1 +2220,2 @@\n-  format %{ \"sve_reduce_addF $src1_dst, $src1_dst, $src2\\t# addF reduction partial (sve) (S)\" %}\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addF $src1_dst, $pg, $src2\\t# addF reduction predicated partial (sve)\" %}\n@@ -1447,0 +2225,2 @@\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n@@ -1453,5 +2233,526 @@\n-instruct reduce_addD(vRegD src1_dst, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set src1_dst (AddReductionVD src1_dst src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (D)\" %}\n+instruct reduce_addD_masked_partial(vRegD src1_dst, vReg src2, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD (Binary src1_dst src2) pg));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addD $src1_dst, $pg, $src2\\t# addD reduction predicated partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector and reduction\n+\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector and reduction - predicated\n+\n+instruct reduce_andI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andI $dst, $src1, $pg, $src2\\t# andI reduction predicated (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $pg, $src2\\t# andL reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andI_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_andI $dst, $src1, $pg, $src2\\t# andI reduction predicated partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $pg, $src2\\t# andL reduction predicated partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector or reduction\n+\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector or reduction - predicated\n+\n+instruct reduce_orI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $pg, $src2\\t# orI reduction predicated (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $pg, $src2\\t# orL reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orI_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $pg, $src2\\t# orI reduction predicated partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $pg, $src2\\t# orL reduction predicated partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector xor reduction\n+\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# eorI reduction (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# eorL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# eorI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# eorL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector xor reduction - predicated\n+\n+instruct reduce_eorI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $pg, $src2\\t# eorI reduction predicated (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $pg, $src2\\t# eorL reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorI_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $pg, $src2\\t# eorI reduction predicated partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $pg, $src2\\t# eorL reduction predicated partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector max reduction\n+\n+instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# maxI reduction (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# maxL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# maxI reduction partial (sve)\" %}\n@@ -1459,2 +2760,7 @@\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1465,6 +2771,9 @@\n-instruct reduce_addD_partial(vRegD src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set src1_dst (AddReductionVD src1_dst src2));\n-  ins_cost(SVE_COST);\n-  effect(TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_addD $src1_dst, $src1_dst, $src2\\t# addD reduction partial (sve) (D)\" %}\n+instruct reduce_maxL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# maxL reduction  partial (sve)\" %}\n@@ -1474,2 +2783,3 @@\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1480,4 +2790,3 @@\n-\/\/ vector and reduction\n-\n-instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n@@ -1485,4 +2794,4 @@\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andB\/S\/I reduction (sve) (may extend)\" %}\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# maxF reduction (sve)\" %}\n@@ -1490,12 +2799,2 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1506,1 +2805,1 @@\n-instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+instruct reduce_maxF_partial(vRegF dst, vRegF src1, vReg src2,\n@@ -1508,1 +2807,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n@@ -1510,4 +2810,4 @@\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# maxF reduction partial (sve)\" %}\n@@ -1515,3 +2815,1 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n@@ -1519,11 +2817,2 @@\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1534,2 +2823,3 @@\n-instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n@@ -1537,4 +2827,4 @@\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction (sve)\" %}\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# maxD reduction (sve)\" %}\n@@ -1542,3 +2832,2 @@\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1549,1 +2838,1 @@\n-instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+instruct reduce_maxD_partial(vRegD dst, vRegD src1, vReg src2,\n@@ -1551,1 +2840,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n@@ -1553,4 +2843,4 @@\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# maxD reduction partial (sve)\" %}\n@@ -1560,4 +2850,2 @@\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1568,1 +2856,1 @@\n-\/\/ vector or reduction\n+\/\/ vector max reduction - predicated\n@@ -1570,5 +2858,8 @@\n-instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+instruct reduce_maxI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp,\n+                           pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1576,1 +2867,1 @@\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orB\/S\/I reduction (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_maxI $dst, $src1, $pg, $src2\\t# maxI reduction predicated (sve)\" %}\n@@ -1579,11 +2870,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n@@ -1594,6 +2877,7 @@\n-instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+instruct reduce_maxL_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp,\n+                          pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1601,1 +2885,1 @@\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_maxL $dst, $src1, $pg, $src2\\t# maxL reduction predicated (sve)\" %}\n@@ -1603,15 +2887,3 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n-               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n@@ -1622,7 +2894,10 @@\n-instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction (sve)\" %}\n+instruct reduce_maxI_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_maxI $dst, $src1, $pg, $src2\\t# maxI reduction predicated partial (sve)\" %}\n@@ -1630,3 +2905,9 @@\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1637,5 +2918,6 @@\n-instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n+instruct reduce_maxL_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n@@ -1643,2 +2925,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_maxL $dst, $src1, $pg, $src2\\t# maxL reduction predicated partial (sve)\" %}\n@@ -1648,4 +2930,5 @@\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n-               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1656,7 +2939,5 @@\n-\/\/ vector xor reduction\n-\n-instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+instruct reduce_maxF_masked(vRegF dst, vRegF src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n@@ -1664,1 +2945,1 @@\n-  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorB\/H\/I reduction (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_maxF $dst, $src1, $pg, $src2\\t# maxF reduction predicated (sve)\" %}\n@@ -1666,12 +2947,2 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S, as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1682,6 +2953,5 @@\n-instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+instruct reduce_maxD_masked(vRegD dst, vRegD src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n@@ -1689,1 +2959,1 @@\n-  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_maxD $dst, $src1, $pg, $src2\\t# maxD reduction predicated (sve)\" %}\n@@ -1691,15 +2961,2 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D, as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1710,7 +2967,9 @@\n-instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction (sve)\" %}\n+instruct reduce_maxF_masked_partial(vRegF dst, vRegF src1, vReg src2, pRegGov pg,\n+                                    pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_maxF $dst, $src1, $pg, $src2\\t# maxF reduction predicated partial (sve)\" %}\n@@ -1718,3 +2977,7 @@\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1725,8 +2988,9 @@\n-instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+instruct reduce_maxD_masked_partial(vRegD dst, vRegD src1, vReg src2, pRegGov pg,\n+                                    pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_maxD $dst, $src1, $pg, $src2\\t# maxD reduction predicated partial (sve)\" %}\n@@ -1736,4 +3000,5 @@\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1744,0 +3009,1 @@\n+\/\/ vector min reduction\n@@ -1745,9 +3011,7 @@\n-\/\/ vector max reduction\n-\n-instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n-            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (MaxReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1755,1 +3019,1 @@\n-  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# reduce maxB\/S\/I (sve)\" %}\n+  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# minI reduction (sve)\" %}\n@@ -1758,5 +3022,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_smaxv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ cmpw($dst$$Register, $src1$$Register);\n-    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n@@ -1767,8 +3029,6 @@\n-instruct reduce_maxI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (MaxReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1776,1 +3036,1 @@\n-  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# reduce maxI partial (sve)\" %}\n+  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# minL reduction (sve)\" %}\n@@ -1778,9 +3038,3 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_smaxv(as_FloatRegister($vtmp$$reg), variant,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ cmpw($dst$$Register, $src1$$Register);\n-    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n@@ -1791,7 +3045,10 @@\n-instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (MaxReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# reduce maxL partial (sve)\" %}\n+instruct reduce_minI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# minI reduction partial (sve)\" %}\n@@ -1799,4 +3056,7 @@\n-    __ sve_smaxv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ cmp($dst$$Register, $src1$$Register);\n-    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1807,1 +3067,1 @@\n-instruct reduce_maxL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+instruct reduce_minL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n@@ -1809,1 +3069,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n@@ -1811,1 +3072,1 @@\n-  match(Set dst (MaxReductionV src1 src2));\n+  match(Set dst (MinReductionV src1 src2));\n@@ -1813,2 +3074,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# reduce maxL partial (sve)\" %}\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# minL reduction  partial (sve)\" %}\n@@ -1818,5 +3079,3 @@\n-    __ sve_smaxv(as_FloatRegister($vtmp$$reg), __ D,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ cmp($dst$$Register, $src1$$Register);\n-    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1827,2 +3086,3 @@\n-instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n@@ -1830,1 +3090,1 @@\n-  match(Set dst (MaxReductionV src1 src2));\n+  match(Set dst (MinReductionV src1 src2));\n@@ -1833,2 +3093,1 @@\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t# max reduction F\" %}\n+  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# minF reduction (sve)\" %}\n@@ -1836,3 +3095,2 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1843,1 +3101,1 @@\n-instruct reduce_maxF_partial(vRegF dst, vRegF src1, vReg src2,\n+instruct reduce_minF_partial(vRegF dst, vRegF src1, vReg src2,\n@@ -1845,1 +3103,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n@@ -1847,1 +3106,1 @@\n-  match(Set dst (MaxReductionV src1 src2));\n+  match(Set dst (MinReductionV src1 src2));\n@@ -1850,1 +3109,1 @@\n-  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# reduce max S partial (sve)\" %}\n+  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# minF reduction partial (sve)\" %}\n@@ -1854,3 +3113,2 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n-         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1861,2 +3119,3 @@\n-instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n@@ -1864,1 +3123,1 @@\n-  match(Set dst (MaxReductionV src1 src2));\n+  match(Set dst (MinReductionV src1 src2));\n@@ -1867,2 +3126,1 @@\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (D)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t# max reduction D\" %}\n+  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# minD reduction (sve)\" %}\n@@ -1870,3 +3128,2 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1877,1 +3134,1 @@\n-instruct reduce_maxD_partial(vRegD dst, vRegD src1, vReg src2,\n+instruct reduce_minD_partial(vRegD dst, vRegD src1, vReg src2,\n@@ -1879,1 +3136,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n@@ -1881,1 +3139,1 @@\n-  match(Set dst (MaxReductionV src1 src2));\n+  match(Set dst (MinReductionV src1 src2));\n@@ -1884,1 +3142,1 @@\n-  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# reduce max D partial (sve)\" %}\n+  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# minD reduction partial (sve)\" %}\n@@ -1888,3 +3146,2 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n-         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1895,1 +3152,1 @@\n-\/\/ vector min reduction\n+\/\/ vector min reduction - predicated\n@@ -1897,7 +3154,8 @@\n-instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n-            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (MinReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+instruct reduce_minI_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp,\n+                           pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1905,1 +3163,1 @@\n-  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# reduce minB\/S\/I (sve)\" %}\n+  format %{ \"sve_reduce_minI $dst, $src1, $pg, $src2\\t# minI reduction predicated (sve)\" %}\n@@ -1908,5 +3166,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_sminv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ cmpw($dst$$Register, $src1$$Register);\n-    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n@@ -1917,7 +3173,24 @@\n-instruct reduce_minI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (MinReductionV src1 src2));\n+instruct reduce_minL_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp,\n+                          pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $pg, $src2\\t# minL reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n@@ -1925,2 +3198,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# reduce minI partial (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_minI $dst, $src1, $pg, $src2\\t# minI reduction predicated partial (sve)\" %}\n@@ -1932,5 +3205,5 @@\n-    __ sve_sminv(as_FloatRegister($vtmp$$reg), variant,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ cmpw($dst$$Register, $src1$$Register);\n-    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1941,7 +3214,9 @@\n-instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (MinReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# reduce minL partial (sve)\" %}\n+instruct reduce_minL_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $pg, $src2\\t# minL reduction predicated partial (sve)\" %}\n@@ -1949,4 +3224,7 @@\n-    __ sve_sminv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ cmp($dst$$Register, $src1$$Register);\n-    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1957,6 +3235,5 @@\n-instruct reduce_minL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (MinReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+instruct reduce_minF_masked(vRegF dst, vRegF src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n@@ -1964,1 +3241,1 @@\n-  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# reduce minL partial (sve)\" %}\n+  format %{ \"sve_reduce_minF $dst, $src1, $pg, $src2\\t# minF reduction predicated (sve)\" %}\n@@ -1966,7 +3243,2 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_sminv(as_FloatRegister($vtmp$$reg), __ D,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ cmp($dst$$Register, $src1$$Register);\n-    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S, as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1977,8 +3249,7 @@\n-instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t# min reduction F\" %}\n+instruct reduce_minD_masked(vRegD dst, vRegD src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minD $dst, $src1, $pg, $src2\\t# minD reduction predicated (sve)\" %}\n@@ -1986,3 +3257,2 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D, as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1993,6 +3263,6 @@\n-instruct reduce_minF_partial(vRegF dst, vRegF src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n+instruct reduce_minF_masked_partial(vRegF dst, vRegF src1, vReg src2, pRegGov pg,\n+                                    pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n@@ -2000,1 +3270,2 @@\n-  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# reduce min S partial (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_minF $dst, $src1, $pg, $src2\\t# minF reduction predicated partial (sve)\" %}\n@@ -2004,0 +3275,2 @@\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n@@ -2005,1 +3278,1 @@\n-         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -2011,22 +3284,6 @@\n-instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (D)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t# min reduction D\" %}\n-  ins_encode %{\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_minD_partial(vRegD dst, vRegD src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n+instruct reduce_minD_masked_partial(vRegD dst, vRegD src1, vReg src2, pRegGov pg,\n+                                    pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV (Binary src1 src2) pg));\n@@ -2034,1 +3291,2 @@\n-  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# reduce min D partial (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_minD $dst, $src1, $pg, $src2\\t# minD reduction predicated partial (sve)\" %}\n@@ -2038,0 +3296,2 @@\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n@@ -2039,1 +3299,1 @@\n-         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -2561,7 +3821,317 @@\n-instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift - predicated\n+\n+instruct vasrB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (RShiftVB (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst_src1$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (RShiftVS (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst_src1$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (RShiftVI (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (RShiftVL (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (LShiftVB (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst_src1$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (LShiftVS (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst_src1$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (LShiftVI (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (LShiftVL (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (URShiftVB (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst_src1$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (URShiftVS (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst_src1$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (URShiftVI (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (URShiftVL (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrB_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (RShiftVB (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 8, \"invalid shift immediate\");\n+    __ sve_asr(as_FloatRegister($dst_src$$reg), __ B, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (RShiftVS (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 16, \"invalid shift immediate\");\n+    __ sve_asr(as_FloatRegister($dst_src$$reg), __ H, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (RShiftVI (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 32, \"invalid shift immediate\");\n+    __ sve_asr(as_FloatRegister($dst_src$$reg), __ S, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (RShiftVL (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 64, \"invalid shift immediate\");\n+    __ sve_asr(as_FloatRegister($dst_src$$reg), __ D, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (URShiftVB (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 8, \"invalid shift immediate\");\n+    __ sve_lsr(as_FloatRegister($dst_src$$reg), __ B, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (URShiftVS (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 16, \"invalid shift immediate\");\n+    __ sve_lsr(as_FloatRegister($dst_src$$reg), __ H, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (URShiftVI (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 32, \"invalid shift immediate\");\n+    __ sve_lsr(as_FloatRegister($dst_src$$reg), __ S, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (URShiftVL (Binary dst_src (RShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < 64, \"invalid shift immediate\");\n+    __ sve_lsr(as_FloatRegister($dst_src$$reg), __ D, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (LShiftVB (Binary dst_src (LShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con >= 0 && con < 8, \"invalid shift immediate\");\n+    __ sve_lsl(as_FloatRegister($dst_src$$reg), __ B, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (LShiftVS (Binary dst_src (LShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (H)\" %}\n@@ -2569,1 +4139,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+    int con = (int)$shift$$constant;\n+    assert(con >= 0 && con < 16, \"invalid shift immediate\");\n+    __ sve_lsl(as_FloatRegister($dst_src$$reg), __ H, as_PRegister($pg$$reg), con);\n@@ -2574,6 +4146,5 @@\n-instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+instruct vlslI_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (LShiftVI (Binary dst_src (LShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (S)\" %}\n@@ -2581,1 +4152,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+    int con = (int)$shift$$constant;\n+    assert(con >= 0 && con < 32, \"invalid shift immediate\");\n+    __ sve_lsl(as_FloatRegister($dst_src$$reg), __ S, as_PRegister($pg$$reg), con);\n@@ -2586,6 +4159,5 @@\n-instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+instruct vlslL_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (LShiftVL (Binary dst_src (LShiftCntV shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst_src, $pg, $dst_src, $shift\\t# vector (sve) (D)\" %}\n@@ -2593,1 +4165,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+    int con = (int)$shift$$constant;\n+    assert(con >= 0 && con < 64, \"invalid shift immediate\");\n+    __ sve_lsl(as_FloatRegister($dst_src$$reg), __ D, as_PRegister($pg$$reg), con);\n@@ -2601,1 +4175,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 &&\n+            !n->as_Vector()->is_predicated_vector());\n@@ -2613,1 +4188,2 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 &&\n+            !n->as_Vector()->is_predicated_vector());\n@@ -2624,0 +4200,28 @@\n+\/\/ vector sqrt - predicated\n+\n+instruct vsqrtF_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (SqrtVF dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst_src, $pg, $dst_src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst_src$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (SqrtVD dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst_src, $pg, $dst_src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst_src$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -2704,1 +4308,81 @@\n-\/\/ vector mask cast\n+\/\/ vector sub - predicated\n+\n+instruct vsubB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVB (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst_src1$$reg), __ B,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVS (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst_src1$$reg), __ H,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVI (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVL (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVF (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst_src1$$reg), __ S,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVD (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst_src1$$reg), __ D,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask cast --------------------------\n@@ -2706,2 +4390,3 @@\n-instruct vmaskcast(vReg dst) %{\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+instruct vmaskcast(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n@@ -2709,1 +4394,1 @@\n-  match(Set dst (VectorMaskCast dst));\n+  match(Set dst_src (VectorMaskCast dst_src));\n@@ -2711,1 +4396,1 @@\n-  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+  format %{ \"vmaskcast $dst_src\\t# empty (sve)\" %}\n@@ -2718,0 +4403,32 @@\n+instruct vmaskcast_extend(pRegGov dst, pReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_length_in_bytes(n) == 2 * Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) == 4 * Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) == 8 * Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorMaskCast src));\n+  ins_cost(SVE_COST * 3);\n+  format %{ \"sve_vmaskcast_extend  $dst, $src\\t# extend predicate $src\" %}\n+  ins_encode %{\n+    __ sve_vmaskcast_extend(as_PRegister($dst$$reg), as_PRegister($src$$reg),\n+                            Matcher::vector_length_in_bytes(this), Matcher::vector_length_in_bytes(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcast_narrow(pRegGov dst, pReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_length_in_bytes(n) * 2 == Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) * 4 == Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) * 8 == Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorMaskCast src));\n+  ins_cost(SVE_COST * 3);\n+  format %{ \"sve_vmaskcast_narrow  $dst, $src\\t# narrow predicate $src\" %}\n+  ins_encode %{\n+    __ sve_vmaskcast_narrow(as_PRegister($dst$$reg), as_PRegister($src$$reg),\n+                            Matcher::vector_length_in_bytes(this), Matcher::vector_length_in_bytes(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -3301,1 +5018,1 @@\n-instruct vtest_alltrue(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)\n+instruct vtest_alltrue(iRegINoSp dst, pRegGov src1, pRegGov src2, pReg ptmp, rFlagsReg cr)\n@@ -3303,1 +5020,2 @@\n-  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -3306,1 +5024,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3308,1 +5026,1 @@\n-  format %{ \"sve_cmpeq $pTmp, $src1, 0\\n\\t\"\n+  format %{ \"sve_eors $ptmp, $src1, $src2\\t# $src2 is all true mask\\n\"\n@@ -3311,5 +5029,2 @@\n-    \/\/ \"src2\" is not used for sve.\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src1);\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               ptrue, as_FloatRegister($src1$$reg), 0);\n+    __ sve_eors(as_PRegister($ptmp$$reg), ptrue,\n+                as_PRegister($src1$$reg), as_PRegister($src2$$reg));\n@@ -3321,1 +5036,1 @@\n-instruct vtest_anytrue(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)\n+instruct vtest_anytrue(iRegINoSp dst, pRegGov src1, pRegGov src2, rFlagsReg cr)\n@@ -3323,1 +5038,2 @@\n-  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -3326,1 +5042,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(KILL cr);\n@@ -3328,1 +5044,1 @@\n-  format %{ \"sve_cmpeq $pTmp, $src1, -1\\n\\t\"\n+  format %{ \"sve_ptest $src1\\n\\t\"\n@@ -3332,4 +5048,1 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src1);\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               ptrue, as_FloatRegister($src1$$reg), -1);\n+    __ sve_ptest(ptrue, as_PRegister($src1$$reg));\n@@ -3341,1 +5054,1 @@\n-instruct vtest_alltrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+instruct vtest_alltrue_partial(iRegINoSp dst, pRegGov src1, pRegGov src2, pRegGov ptmp, rFlagsReg cr)\n@@ -3343,1 +5056,2 @@\n-  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n@@ -3346,1 +5060,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3350,1 +5064,0 @@\n-    \/\/ \"src2\" is not used for sve.\n@@ -3353,1 +5066,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size,\n@@ -3355,2 +5068,2 @@\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               as_PRegister($pTmp$$reg), as_FloatRegister($src1$$reg), 0);\n+    __ sve_eors(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+          as_PRegister($src1$$reg), as_PRegister($src2$$reg));\n@@ -3362,1 +5075,1 @@\n-instruct vtest_anytrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+instruct vtest_anytrue_partial(iRegINoSp dst, pRegGov src1, pRegGov src2, pRegGov ptmp, rFlagsReg cr)\n@@ -3364,1 +5077,2 @@\n-  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n@@ -3367,1 +5081,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3371,1 +5085,0 @@\n-    \/\/ \"src2\" is not used for sve.\n@@ -3374,1 +5087,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size,\n@@ -3376,2 +5089,2 @@\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               as_PRegister($pTmp$$reg), as_FloatRegister($src1$$reg), -1);\n+    __ sve_ands(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+          as_PRegister($src1$$reg), as_PRegister($src2$$reg));\n@@ -3616,1 +5329,1 @@\n-  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (S)\" %}\n@@ -3631,2 +5344,1 @@\n-  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (D)\" %}\n@@ -3643,1 +5355,1 @@\n-instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -3649,1 +5361,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3651,2 +5363,1 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (I\/F)\" %}\n+  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (S)\" %}\n@@ -3654,3 +5365,2 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S,\n-                          Matcher::vector_length(this));\n-    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n@@ -3662,1 +5372,1 @@\n-instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -3668,1 +5378,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3670,3 +5380,55 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (L\/D)\" %}\n+  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather Predicated -------------------------------\n+\n+instruct gatherI_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  ins_cost(SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated (S)\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pg$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated (D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pg$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather Predicated Partial -------------------------------\n+\n+instruct gatherI_masked_partial(vReg dst, indirect mem, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated partial (S)\" %}\n@@ -3674,1 +5436,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n@@ -3676,0 +5438,21 @@\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL_masked_partial(vReg dst, indirect mem, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated partial (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n@@ -3677,1 +5460,1 @@\n-    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n@@ -3692,1 +5475,1 @@\n-  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (I\/F)\" %}\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (S)\" %}\n@@ -3707,2 +5490,1 @@\n-  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (L\/D)\" %}\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (D)\" %}\n@@ -3717,1 +5499,1 @@\n-\/\/ ------------------------------ Vector Store Scatter Partial-------------------------------\n+\/\/ ------------------------------ Vector Store Scatter Partial -------------------------------\n@@ -3719,1 +5501,1 @@\n-instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -3725,1 +5507,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3727,2 +5509,1 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (I\/F)\" %}\n+  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (S)\" %}\n@@ -3730,1 +5511,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n@@ -3732,1 +5513,1 @@\n-    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n@@ -3738,1 +5519,1 @@\n-instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -3744,1 +5525,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -3746,3 +5527,1 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (L\/D)\" %}\n+  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (D)\" %}\n@@ -3750,1 +5529,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n@@ -3753,1 +5532,56 @@\n-    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter Predicated -------------------------------\n+\n+instruct scatterI_masked(indirect mem, vReg src, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  ins_cost(SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicate (S)\" %}\n+  ins_encode %{\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pg$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatterL_masked(indirect mem, vReg src, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicated (D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pg$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter Predicated Partial -------------------------------\n+\n+instruct scatterI_masked_partial(indirect mem, vReg src, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicated partial (S)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n+                          Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n@@ -3759,0 +5593,20 @@\n+instruct scatterL_masked_partial(indirect mem, vReg src, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicated partial (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -3907,1 +5761,1 @@\n-instruct vstoremask_truecount(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+instruct vstoremask_truecount(iRegINoSp dst, pRegGov src, immI esize, rFlagsReg cr) %{\n@@ -3911,2 +5765,2 @@\n-  effect(TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n@@ -3918,2 +5772,1 @@\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           ptrue, as_PRegister($ptmp$$reg), Matcher::vector_length(this, $src));\n+    __ sve_cntp($dst$$Register, variant, ptrue, as_PRegister($src$$reg));\n@@ -3924,1 +5777,1 @@\n-instruct vstoremask_firsttrue(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+instruct vstoremask_firsttrue(iRegINoSp dst, pRegGov src, immI esize, pReg ptmp, rFlagsReg cr) %{\n@@ -3929,1 +5782,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -3935,2 +5788,3 @@\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           ptrue, as_PRegister($ptmp$$reg), Matcher::vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg),\n+                           Matcher::vector_length(this, $src));\n@@ -3941,1 +5795,1 @@\n-instruct vstoremask_lasttrue(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+instruct vstoremask_lasttrue(iRegINoSp dst, pRegGov src, immI esize, pReg ptmp, rFlagsReg cr) %{\n@@ -3946,1 +5800,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(3 * SVE_COST);\n@@ -3952,2 +5806,3 @@\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           ptrue, as_PRegister($ptmp$$reg), Matcher::vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg),\n+                           Matcher::vector_length(this, $src));\n@@ -3958,1 +5813,2 @@\n-instruct vstoremask_truecount_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ptmp, rFlagsReg cr) %{\n+instruct vstoremask_truecount_partial(iRegINoSp dst, pRegGov src, immI esize,\n+                               pRegGov ptmp, rFlagsReg cr) %{\n@@ -3963,1 +5819,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -3969,4 +5825,3 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src));\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg),\n+                          variant, Matcher::vector_length(this, $src));\n+    __ sve_cntp($dst$$Register, variant, as_PRegister($ptmp$$reg), as_PRegister($src$$reg));\n@@ -3977,1 +5832,2 @@\n-instruct vstoremask_firsttrue_partial(iRegINoSp dst, vReg src, immI esize, pRegGov pgtmp, pReg ptmp, rFlagsReg cr) %{\n+instruct vstoremask_firsttrue_partial(iRegINoSp dst, pRegGov src, immI esize,\n+                               pRegGov pgtmp, pReg ptmp, rFlagsReg cr) %{\n@@ -3982,1 +5838,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(3 * SVE_COST);\n@@ -3988,4 +5844,5 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pgtmp$$reg), variant,\n-                          Matcher::vector_length(this, $src));\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           as_PRegister($pgtmp$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+    __ sve_whilelo_zr_imm(as_PRegister($pgtmp$$reg),\n+                          variant, Matcher::vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($src$$reg), as_PRegister($pgtmp$$reg),\n+                           as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n@@ -3996,1 +5853,2 @@\n-instruct vstoremask_lasttrue_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ptmp, rFlagsReg cr) %{\n+instruct vstoremask_lasttrue_partial(iRegINoSp dst, pRegGov src, immI esize,\n+                               pRegGov ptmp, rFlagsReg cr) %{\n@@ -4007,4 +5865,7 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src));\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg),\n+                          variant, Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($src$$reg), as_PRegister($src$$reg));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($ptmp$$reg), ptrue,\n+                           as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":2595,"deletions":734,"binary":false,"changes":3329,"status":"modified"},{"patch":"@@ -86,0 +86,1 @@\n+  bool masked_op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -142,5 +143,1 @@\n-        if (vlen < 4 || length_in_bytes > MaxVectorSize) {\n-          return false;\n-        } else {\n-          return true;\n-        }\n+        return vlen >= 4 && length_in_bytes <= MaxVectorSize;\n@@ -156,0 +153,8 @@\n+\n+  bool masked_op_sve_supported(int opcode, int vlen, BasicType bt) {\n+    if (opcode == Op_VectorRearrange) {\n+      return false;\n+    }\n+    return op_sve_supported(opcode, vlen, bt);\n+  }\n+\n@@ -241,1 +246,1 @@\n-            \"sve_ldr $dst, $pTmp, $mem\\t# load vector predicated\" %}\n+            \"sve_ldr $dst, $pTmp, $mem\\t# load vector partial\" %}\n@@ -261,1 +266,1 @@\n-            \"sve_str $src, $pTmp, $mem\\t# store vector predicated\" %}\n+            \"sve_str $src, $pTmp, $mem\\t# store vector partial\" %}\n@@ -272,1 +277,18 @@\n-%}dnl\n+%}\n+\n+\/\/ vector load\/store - predicated\n+\n+instruct loadV_masked(vReg dst, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n+  match(Set dst (LoadVectorMasked mem pg));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_ldr $dst, $pg, $mem\\t# load vector predicated (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($dst$$reg),\n+                          as_PRegister($pg$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -274,0 +296,142 @@\n+instruct loadV_masked_partial(vReg dst, vmemA mem, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVectorMasked mem pg));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_ldr $dst, $pg, $mem\\t# load vector predicated partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ elemType_to_regVariant(bt),\n+                          Matcher::vector_length(this));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($dst$$reg),\n+                          as_PRegister($ptmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked(vReg src, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary src pg)));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_str $mem, $pg, $src\\t# store vector predicated (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($src$$reg),\n+                          as_PRegister($pg$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked_partial(vReg src, vmemA mem, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary src pg)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_str $mem, $pg, $src\\t# store vector predicated partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ elemType_to_regVariant(bt),\n+                          Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($src$$reg),\n+                          as_PRegister($ptmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl MASKALL_IMM($1,   $2  )\n+dnl MASKALL_IMM(type, size)\n+define(`MASKALL_IMM', `\n+instruct vmaskAll_imm$1(pRegGov dst, imm$1 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_ptrue\/sve_pfalse $dst\\t# mask all (sve) ($2)\" %}\n+  ins_encode %{\n+    ifelse($1, `I', int, long) con = (ifelse($1, `I', int, long))$src$$constant;\n+    if (con == 0) {\n+      __ sve_pfalse(as_PRegister($dst$$reg));\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_ptrue(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl MASKALL($1,   $2  )\n+dnl MASKALL(type, size)\n+define(`MASKALL', `\n+instruct vmaskAll$1(pRegGov dst, ifelse($1, `I', iRegIorL2I, iRegL) src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup $tmp, $src\\n\\t\"\n+            \"sve_cmpne $dst, $tmp, 0\\t# mask all (sve) ($2)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), size, as_Register($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ maskAll\n+MASKALL_IMM(I, B\/H\/S)\n+MASKALL(I, B\/H\/S)\n+MASKALL_IMM(L, D)\n+MASKALL(L, D)\n+\n+dnl\n+dnl MASK_LOGICAL_OP($1,        $2,      $3  )\n+dnl MASK_LOGICAL_OP(insn_name, op_name, insn)\n+define(`MASK_LOGICAL_OP', `\n+instruct vmask_$1(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd ($2 pn pm));\n+  ins_cost(SVE_COST);\n+  format %{ \"$3 $pd, $pn, $pm\\t# predicate (sve)\" %}\n+  ins_encode %{\n+    __ $3(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ mask logical and\/or\/xor\n+MASK_LOGICAL_OP(and, AndVMask, sve_and)\n+MASK_LOGICAL_OP(or, OrVMask, sve_orr)\n+MASK_LOGICAL_OP(xor, XorVMask, sve_eor)\n+\n+dnl\n+dnl MASK_LOGICAL_AND_NOT($1,   $2  )\n+dnl MASK_LOGICAL_AND_NOT(type, size)\n+define(`MASK_LOGICAL_AND_NOT', `\n+instruct vmask_and_not$1(pRegGov pd, pRegGov pn, pRegGov pm, imm$1_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn (XorVMask pm (MaskAll m1))));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_bic $pd, $pn, $pm\\t# predciate (sve) ($2)\" %}\n+  ins_encode %{\n+    __ sve_bic(as_PRegister($pd$$reg), ptrue,\n+               as_PRegister($pn$$reg), as_PRegister($pm$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ mask logical and_not\n+MASK_LOGICAL_AND_NOT(I, B\/H\/S)\n+MASK_LOGICAL_AND_NOT(L, D)\n@@ -310,0 +474,34 @@\n+\n+\/\/ vector mask reinterpret\n+\n+instruct vmask_reinterpret_same_esize(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->as_Vector()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst_src (VectorReinterpret dst_src));\n+  ins_cost(0);\n+  format %{ \"# vmask_reinterpret $dst_src\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmask_reinterpret_diff_esize(pRegGov dst, pRegGov src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length() != n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->as_Vector()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"# vmask_reinterpret $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    BasicType from_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant from_size = __ elemType_to_regVariant(from_bt);\n+    BasicType to_bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_size = __ elemType_to_regVariant(to_bt);\n+    __ sve_cpy(as_FloatRegister($tmp$$reg), from_size, as_PRegister($src$$reg), -1, false);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($dst$$reg), to_size, ptrue, as_FloatRegister($tmp$$reg), -1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -311,3 +509,3 @@\n-dnl UNARY_OP_TRUE_PREDICATE_ETYPE($1,        $2,      $3,           $4,   $5,          %6  )\n-dnl UNARY_OP_TRUE_PREDICATE_ETYPE(insn_name, op_name, element_type, size, min_vec_len, insn)\n-define(`UNARY_OP_TRUE_PREDICATE_ETYPE', `\n+dnl UNARY_OP_TRUE_PREDICATE($1,        $2,      $3,   $4  )\n+dnl UNARY_OP_TRUE_PREDICATE(insn_name, op_name, size, insn)\n+define(`UNARY_OP_TRUE_PREDICATE', `\n@@ -316,1 +514,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == $3);\n+            !n->as_Vector()->is_predicated_vector());\n@@ -319,1 +517,1 @@\n-  format %{ \"$6 $dst, $src\\t# vector (sve) ($4)\" %}\n+  format %{ \"$4 $dst, $src\\t# vector (sve) ($3)\" %}\n@@ -321,1 +519,1 @@\n-    __ $6(as_FloatRegister($dst$$reg), __ $4,\n+    __ $4(as_FloatRegister($dst$$reg), __ $3,\n@@ -329,10 +527,34 @@\n-UNARY_OP_TRUE_PREDICATE_ETYPE(vabsB, AbsVB, T_BYTE,   B, 16, sve_abs)\n-UNARY_OP_TRUE_PREDICATE_ETYPE(vabsS, AbsVS, T_SHORT,  H, 8,  sve_abs)\n-UNARY_OP_TRUE_PREDICATE_ETYPE(vabsI, AbsVI, T_INT,    S, 4,  sve_abs)\n-UNARY_OP_TRUE_PREDICATE_ETYPE(vabsL, AbsVL, T_LONG,   D, 2,  sve_abs)\n-UNARY_OP_TRUE_PREDICATE_ETYPE(vabsF, AbsVF, T_FLOAT,  S, 4,  sve_fabs)\n-UNARY_OP_TRUE_PREDICATE_ETYPE(vabsD, AbsVD, T_DOUBLE, D, 2,  sve_fabs)\n-dnl\n-dnl BINARY_OP_UNPREDICATED($1,        $2       $3,   $4           $5  )\n-dnl BINARY_OP_UNPREDICATED(insn_name, op_name, size, min_vec_len, insn)\n-define(`BINARY_OP_UNPREDICATED', `\n+UNARY_OP_TRUE_PREDICATE(vabsB, AbsVB, B, sve_abs)\n+UNARY_OP_TRUE_PREDICATE(vabsS, AbsVS, H, sve_abs)\n+UNARY_OP_TRUE_PREDICATE(vabsI, AbsVI, S, sve_abs)\n+UNARY_OP_TRUE_PREDICATE(vabsL, AbsVL, D, sve_abs)\n+UNARY_OP_TRUE_PREDICATE(vabsF, AbsVF, S, sve_fabs)\n+UNARY_OP_TRUE_PREDICATE(vabsD, AbsVD, D, sve_fabs)\n+\n+dnl UNARY_OP_PREDICATE($1,        $2,      $3,   $4  )\n+dnl UNARY_OP_PREDICATE(insn_name, op_name, size, insn)\n+define(`UNARY_OP_PREDICATE', `\n+instruct $1_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($2 dst_src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"$4 $dst_src, $pg, $dst_src\\t# vector (sve) ($3)\" %}\n+  ins_encode %{\n+    __ $4(as_FloatRegister($dst_src$$reg), __ $3,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($dst_src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\/\/ vector abs - predicated\n+UNARY_OP_PREDICATE(vabsB, AbsVB, B, sve_abs)\n+UNARY_OP_PREDICATE(vabsS, AbsVS, H, sve_abs)\n+UNARY_OP_PREDICATE(vabsI, AbsVI, S, sve_abs)\n+UNARY_OP_PREDICATE(vabsL, AbsVL, D, sve_abs)\n+UNARY_OP_PREDICATE(vabsF, AbsVF, S, sve_fabs)\n+UNARY_OP_PREDICATE(vabsD, AbsVD, D, sve_fabs)\n+\n+dnl\n+dnl BINARY_OP_UNPREDICATE($1,        $2       $3,   $4           $5  )\n+dnl BINARY_OP_UNPREDICATE(insn_name, op_name, size, min_vec_len, insn)\n+define(`BINARY_OP_UNPREDICATE', `\n@@ -351,1 +573,18 @@\n-\n+dnl\n+dnl\n+dnl BINARY_OP_PREDICATE($1,        $2,      $3,   $4  )\n+dnl BINARY_OP_PREDICATE(insn_name, op_name, size, insn)\n+define(`BINARY_OP_PREDICATE', `\n+instruct $1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 ($2 (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"$4 $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve) ($3)\" %}\n+  ins_encode %{\n+    __ $4(as_FloatRegister($dst_src1$$reg), __ $3,\n+            as_PRegister($pg$$reg),\n+            as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n@@ -353,9 +592,18 @@\n-BINARY_OP_UNPREDICATED(vaddB, AddVB, B, 16, sve_add)\n-BINARY_OP_UNPREDICATED(vaddS, AddVS, H, 8,  sve_add)\n-BINARY_OP_UNPREDICATED(vaddI, AddVI, S, 4,  sve_add)\n-BINARY_OP_UNPREDICATED(vaddL, AddVL, D, 2,  sve_add)\n-BINARY_OP_UNPREDICATED(vaddF, AddVF, S, 4,  sve_fadd)\n-BINARY_OP_UNPREDICATED(vaddD, AddVD, D, 2,  sve_fadd)\n-dnl\n-dnl BINARY_OP_UNSIZED($1,        $2,      $3,          $4  )\n-dnl BINARY_OP_UNSIZED(insn_name, op_name, min_vec_len, insn)\n+BINARY_OP_UNPREDICATE(vaddB, AddVB, B, 16, sve_add)\n+BINARY_OP_UNPREDICATE(vaddS, AddVS, H, 8,  sve_add)\n+BINARY_OP_UNPREDICATE(vaddI, AddVI, S, 4,  sve_add)\n+BINARY_OP_UNPREDICATE(vaddL, AddVL, D, 2,  sve_add)\n+BINARY_OP_UNPREDICATE(vaddF, AddVF, S, 4,  sve_fadd)\n+BINARY_OP_UNPREDICATE(vaddD, AddVD, D, 2,  sve_fadd)\n+\n+\/\/ vector add - predicated\n+BINARY_OP_PREDICATE(vaddB, AddVB, B, sve_add)\n+BINARY_OP_PREDICATE(vaddS, AddVS, H, sve_add)\n+BINARY_OP_PREDICATE(vaddI, AddVI, S, sve_add)\n+BINARY_OP_PREDICATE(vaddL, AddVL, D, sve_add)\n+BINARY_OP_PREDICATE(vaddF, AddVF, S, sve_fadd)\n+BINARY_OP_PREDICATE(vaddD, AddVD, D, sve_fadd)\n+\n+dnl\n+dnl BINARY_OP_UNSIZED($1,        $2,      $3  )\n+dnl BINARY_OP_UNSIZED(insn_name, op_name, insn)\n@@ -367,1 +615,1 @@\n-  format %{ \"$4  $dst, $src1, $src2\\t# vector (sve)\" %}\n+  format %{ \"$3  $dst, $src1, $src2\\t# vector (sve)\" %}\n@@ -369,1 +617,1 @@\n-    __ $4(as_FloatRegister($dst$$reg),\n+    __ $3(as_FloatRegister($dst$$reg),\n@@ -375,1 +623,1 @@\n-\n+dnl\n@@ -377,1 +625,1 @@\n-BINARY_OP_UNSIZED(vand, AndV, 16, sve_and)\n+BINARY_OP_UNSIZED(vand, AndV, sve_and)\n@@ -380,1 +628,1 @@\n-BINARY_OP_UNSIZED(vor, OrV, 16, sve_orr)\n+BINARY_OP_UNSIZED(vor, OrV, sve_orr)\n@@ -383,1 +631,28 @@\n-BINARY_OP_UNSIZED(vxor, XorV, 16, sve_eor)\n+BINARY_OP_UNSIZED(vxor, XorV, sve_eor)\n+\n+dnl BINARY_LOGIC_OP_PREDICATE($1,        $2,      $3  )\n+dnl BINARY_LOGIC_OP_PREDICATE(insn_name, op_name, insn)\n+define(`BINARY_LOGIC_OP_PREDICATE', `\n+instruct $1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 ($2 (Binary dst_src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"$3 $dst_src1, $pg, $dst_src1, $src2\\t # vector (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ $3(as_FloatRegister($dst_src1$$reg), size,\n+          as_PRegister($pg$$reg),\n+          as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector and - predicated\n+BINARY_LOGIC_OP_PREDICATE(vand, AndV, sve_and)\n+\n+\/\/ vector or - predicated\n+BINARY_LOGIC_OP_PREDICATE(vor, OrV, sve_orr)\n+\n+\/\/ vector xor - predicated\n+BINARY_LOGIC_OP_PREDICATE(vxor, XorV, sve_eor)\n@@ -409,1 +684,1 @@\n-\n+dnl\n@@ -450,1 +725,1 @@\n-\n+dnl\n@@ -455,1 +730,3 @@\n-\/\/ vector min\/max\n+\/\/ vector float div - predicated\n+BINARY_OP_PREDICATE(vfdivF, DivVF, S, sve_fdiv)\n+BINARY_OP_PREDICATE(vfdivD, DivVD, D, sve_fdiv)\n@@ -457,1 +734,5 @@\n-instruct vmin(vReg dst_src1, vReg src2) %{\n+dnl\n+dnl VMINMAX($1     , $2, $3   , $4  )\n+dnl VMINMAX(op_name, op, finsn, insn)\n+define(`VMINMAX', `\n+instruct v$1(vReg dst_src1, vReg src2) %{\n@@ -459,1 +740,1 @@\n-  match(Set dst_src1 (MinV dst_src1 src2));\n+  match(Set dst_src1 ($2 dst_src1 src2));\n@@ -461,1 +742,1 @@\n-  format %{ \"sve_min $dst_src1, $dst_src1, $src2\\t # vector (sve)\" %}\n+  format %{ \"sve_$1 $dst_src1, $dst_src1, $src2\\t # vector (sve)\" %}\n@@ -466,1 +747,1 @@\n-      __ sve_fmin(as_FloatRegister($dst_src1$$reg), size,\n+      __ $3(as_FloatRegister($dst_src1$$reg), size,\n@@ -469,2 +750,2 @@\n-      assert(is_integral_type(bt), \"Unsupported type\");\n-      __ sve_smin(as_FloatRegister($dst_src1$$reg), size,\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ $4(as_FloatRegister($dst_src1$$reg), size,\n@@ -475,1 +756,5 @@\n-%}\n+%}')dnl\n+dnl\n+\/\/ vector min\/max\n+VMINMAX(min, MinV, sve_fmin, sve_smin)\n+VMINMAX(max, MaxV, sve_fmax, sve_smax)\n@@ -477,1 +762,5 @@\n-instruct vmax(vReg dst_src1, vReg src2) %{\n+dnl\n+dnl VMINMAX_PREDICATE($1     , $2, $3   , $4  )\n+dnl VMINMAX_PREDICATE(op_name, op, finsn, insn)\n+define(`VMINMAX_PREDICATE', `\n+instruct v$1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n@@ -479,1 +768,1 @@\n-  match(Set dst_src1 (MaxV dst_src1 src2));\n+  match(Set dst_src1 ($2 (Binary dst_src1 src2) pg));\n@@ -481,1 +770,1 @@\n-  format %{ \"sve_max $dst_src1, $dst_src1, $src2\\t # vector (sve)\" %}\n+  format %{ \"sve_$1 $dst_src1, $pg, $dst_src1, $src2\\t# vector (sve)\" %}\n@@ -486,2 +775,2 @@\n-      __ sve_fmax(as_FloatRegister($dst_src1$$reg), size,\n-                  ptrue, as_FloatRegister($src2$$reg));\n+      __ $3(as_FloatRegister($dst_src1$$reg), size,\n+                  as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n@@ -489,3 +778,3 @@\n-      assert(is_integral_type(bt), \"Unsupported type\");\n-      __ sve_smax(as_FloatRegister($dst_src1$$reg), size,\n-                  ptrue, as_FloatRegister($src2$$reg));\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ $4(as_FloatRegister($dst_src1$$reg), size,\n+                  as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n@@ -495,1 +784,5 @@\n-%}\n+%}')dnl\n+dnl\n+\/\/ vector min\/max - predicated\n+VMINMAX_PREDICATE(min, MinV, sve_fmin, sve_smin)\n+VMINMAX_PREDICATE(max, MaxV, sve_fmax, sve_smax)\n@@ -518,0 +811,21 @@\n+dnl\n+dnl VFMLA_PREDICATE($1,   $2  )\n+dnl VFMLA_PREDICATE(type, size)\n+define(`VFMLA_PREDICATE', `\n+\/\/ dst_src1 = dst_src1 * src2 + src3\n+instruct vfmla$1_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0);\n+  match(Set dst_src1 (FmaV$1 (Binary dst_src1 src2) (Binary src3 pg)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fmad $dst_src1, $pg, $src2, $src3\\t# vector (sve) ($2)\" %}\n+  ins_encode %{\n+    __ sve_fmad(as_FloatRegister($dst_src1$$reg), __ $2, as_PRegister($pg$$reg),\n+         as_FloatRegister($src2$$reg), as_FloatRegister($src3$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector fmla - predicated\n+VFMLA_PREDICATE(F, S)\n+VFMLA_PREDICATE(D, D)\n+\n@@ -648,1 +962,1 @@\n-\n+dnl\n@@ -654,2 +968,10 @@\n-BINARY_OP_UNPREDICATED(vmulF, MulVF, S, 4, sve_fmul)\n-BINARY_OP_UNPREDICATED(vmulD, MulVD, D, 2, sve_fmul)\n+BINARY_OP_UNPREDICATE(vmulF, MulVF, S, 4, sve_fmul)\n+BINARY_OP_UNPREDICATE(vmulD, MulVD, D, 2, sve_fmul)\n+\n+\/\/ vector mul - predicated\n+BINARY_OP_PREDICATE(vmulB, MulVB, B, sve_mul)\n+BINARY_OP_PREDICATE(vmulS, MulVS, H, sve_mul)\n+BINARY_OP_PREDICATE(vmulI, MulVI, S, sve_mul)\n+BINARY_OP_PREDICATE(vmulL, MulVL, D, sve_mul)\n+BINARY_OP_PREDICATE(vmulF, MulVF, S, sve_fmul)\n+BINARY_OP_PREDICATE(vmulD, MulVD, D, sve_fmul)\n@@ -657,18 +979,6 @@\n-dnl\n-dnl UNARY_OP_TRUE_PREDICATE($1,        $2,      $3,   $4,            $5  )\n-dnl UNARY_OP_TRUE_PREDICATE(insn_name, op_name, size, min_vec_bytes, insn)\n-define(`UNARY_OP_TRUE_PREDICATE', `\n-instruct $1(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0);\n-  match(Set dst ($2 src));\n-  ins_cost(SVE_COST);\n-  format %{ \"$5 $dst, $src\\t# vector (sve) ($3)\" %}\n-  ins_encode %{\n-    __ $5(as_FloatRegister($dst$$reg), __ $3,\n-         ptrue, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n-dnl\n-UNARY_OP_TRUE_PREDICATE(vnegF, NegVF, S, 16, sve_fneg)\n-UNARY_OP_TRUE_PREDICATE(vnegD, NegVD, D, 16, sve_fneg)\n+UNARY_OP_TRUE_PREDICATE(vnegF, NegVF, S, sve_fneg)\n+UNARY_OP_TRUE_PREDICATE(vnegD, NegVD, D, sve_fneg)\n+\n+\/\/ vector fneg - predicated\n+UNARY_OP_PREDICATE(vnegF, NegVF, S, sve_fneg)\n+UNARY_OP_PREDICATE(vnegD, NegVD, D, sve_fneg)\n@@ -691,1 +1001,1 @@\n-instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+instruct vmaskcmp(pRegGov dst, vReg src1, vReg src2, immI cond, rFlagsReg cr) %{\n@@ -694,4 +1004,3 @@\n-  effect(TEMP pTmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n-            \"sve_cpy $dst, $pTmp, -1\\t# vector mask cmp (sve)\" %}\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmp $dst, $src1, $src2\\t# vector mask cmp (sve)\" %}\n@@ -700,1 +1009,1 @@\n-    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n+    __ sve_compare(as_PRegister($dst$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n@@ -702,2 +1011,0 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-               as_PRegister($pTmp$$reg), -1, false);\n@@ -708,3 +1015,1 @@\n-\/\/ vector blend\n-\n-instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+instruct vmaskcmp_masked(pRegGov dst, vReg src1, vReg src2, immI cond, pRegGov pg, rFlagsReg cr) %{\n@@ -712,5 +1017,4 @@\n-  match(Set dst (VectorBlend (Binary src1 src2) src3));\n-  effect(TEMP pTmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n-            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond pg)));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmp $dst, $pg, $src1, $src2\\t# vector mask cmp (sve)\" %}\n@@ -718,6 +1022,3 @@\n-    Assembler::SIMD_RegVariant size =\n-      __ elemType_to_regVariant(Matcher::vector_element_basic_type(this));\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               ptrue, as_FloatRegister($src3$$reg), -1);\n-    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n-               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_compare(as_PRegister($dst$$reg), bt, as_PRegister($pg$$reg), as_FloatRegister($src1$$reg),\n+                   as_FloatRegister($src2$$reg), (int)$cond$$constant);\n@@ -728,1 +1029,1 @@\n-\/\/ vector blend with compare\n+\/\/ vector blend\n@@ -730,2 +1031,1 @@\n-instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n-                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+instruct vblend(vReg dst, vReg src1, vReg src2, pRegGov pg) %{\n@@ -733,5 +1033,3 @@\n-  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n-  effect(TEMP pTmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_cmp $pTmp, $src3, $src4\\t# vector cmp (sve)\\n\\t\"\n-            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n+  match(Set dst (VectorBlend (Binary src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sel $dst, $pg, $src2, $src1\\t# vector blend (sve)\" %}\n@@ -739,6 +1037,4 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src3$$reg),\n-                   as_FloatRegister($src4$$reg), (int)$cond$$constant);\n-    __ sve_sel(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n-               as_FloatRegister($src1$$reg));\n+    Assembler::SIMD_RegVariant size =\n+               __ elemType_to_regVariant(Matcher::vector_element_basic_type(this));\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pg$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n@@ -751,1 +1047,1 @@\n-instruct vloadmaskB(vReg dst, vReg src) %{\n+instruct vloadmaskB(pRegGov dst, vReg src, rFlagsReg cr) %{\n@@ -755,0 +1051,1 @@\n+  effect(KILL cr);\n@@ -756,1 +1053,1 @@\n-  format %{ \"sve_neg $dst, $src\\t# vector load mask (B)\" %}\n+  format %{ \"vloadmaskB $dst, $src\\t# vector load mask (sve) (B)\" %}\n@@ -758,1 +1055,2 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ B,\n+               ptrue, as_FloatRegister($src$$reg), 0);\n@@ -763,1 +1061,1 @@\n-instruct vloadmaskS(vReg dst, vReg src) %{\n+instruct vloadmaskS(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n@@ -767,0 +1065,1 @@\n+  effect(TEMP tmp, KILL cr);\n@@ -768,2 +1067,1 @@\n-  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# vector load mask (B to H)\" %}\n+  format %{ \"vloadmaskS $dst, $src\\t# vector load mask (sve) (B to H)\" %}\n@@ -771,2 +1069,3 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ H,\n+               ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -777,1 +1076,1 @@\n-instruct vloadmaskI(vReg dst, vReg src) %{\n+instruct vloadmaskI(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n@@ -782,0 +1081,1 @@\n+  effect(TEMP tmp, KILL cr);\n@@ -783,3 +1083,1 @@\n-  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n-            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# vector load mask (B to S)\" %}\n+  format %{ \"vloadmaskI $dst, $src\\t# vector load mask (sve) (B to S)\" %}\n@@ -787,3 +1085,3 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($tmp$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ S, ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -794,1 +1092,1 @@\n-instruct vloadmaskL(vReg dst, vReg src) %{\n+instruct vloadmaskL(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n@@ -799,0 +1097,1 @@\n+  effect(TEMP tmp, KILL cr);\n@@ -800,4 +1099,1 @@\n-  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n-            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n-            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# vector load mask (B to D)\" %}\n+  format %{ \"vloadmaskL $dst, $src\\t# vector load mask (sve) (B to D)\" %}\n@@ -805,4 +1101,4 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($tmp$$reg));\n+    __ sve_uunpklo(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($tmp$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ D, ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -815,1 +1111,1 @@\n-instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+instruct vstoremaskB(vReg dst, pRegGov src, immI_1 size) %{\n@@ -819,1 +1115,1 @@\n-  format %{ \"sve_neg $dst, $src\\t# vector store mask (B)\" %}\n+  format %{ \"vstoremaskB $dst, $src\\t# vector store mask (sve) (B)\" %}\n@@ -821,2 +1117,1 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B, as_PRegister($src$$reg), 1, false);\n@@ -827,1 +1122,1 @@\n-instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+instruct vstoremaskS(vReg dst, pRegGov src, vReg tmp, immI_2 size) %{\n@@ -832,3 +1127,1 @@\n-  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n-            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n-            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (H to B)\" %}\n+  format %{ \"vstoremaskS $dst, $src\\t# vector store mask (sve) (H to B)\" %}\n@@ -836,0 +1129,1 @@\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H, as_PRegister($src$$reg), 1, false);\n@@ -838,4 +1132,1 @@\n-                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($dst$$reg));\n-\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -846,1 +1137,1 @@\n-instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+instruct vstoremaskI(vReg dst, pRegGov src, vReg tmp, immI_4 size) %{\n@@ -851,4 +1142,1 @@\n-  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n-            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (S to B)\" %}\n+  format %{ \"vstoremaskI $dst, $src\\t# vector store mask (sve) (S to B)\" %}\n@@ -856,0 +1144,1 @@\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S, as_PRegister($src$$reg), 1, false);\n@@ -858,1 +1147,1 @@\n-                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -861,2 +1150,0 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($dst$$reg));\n@@ -867,1 +1154,1 @@\n-instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+instruct vstoremaskL(vReg dst, pRegGov src, vReg tmp, immI_8 size) %{\n@@ -872,5 +1159,1 @@\n-  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n-            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (D to B)\" %}\n+  format %{ \"vstoremaskL $dst, $src\\t# vector store mask (sve) (D to B)\" %}\n@@ -878,0 +1161,1 @@\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D, as_PRegister($src$$reg), 1, false);\n@@ -880,1 +1164,1 @@\n-                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n@@ -885,2 +1169,0 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($dst$$reg));\n@@ -890,8 +1172,7 @@\n-dnl\n-dnl\n-dnl VLOADMASK_LOADV($1,    $2  )\n-dnl VLOADMASK_LOADV(esize, cond)\n-define(`VLOADMASK_LOADV', `\n-instruct vloadmask_loadV_$1(vReg dst, ifelse($1, `byte', vmemA, indirect) mem) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n-            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) $2);\n+\n+\/\/ Combine LoadVector+VectorLoadMask when the vector element type is not T_BYTE\n+\n+instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n@@ -899,3 +1180,4 @@\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n-            \"sve_neg $dst, $dst\\t# load vector mask (sve)\" %}\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $tmp, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $tmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n@@ -903,1 +1185,2 @@\n-    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ expected vector element type. Convert the vector to predicate.\n@@ -905,3 +1188,2 @@\n-    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, to_vect_bt, $mem->opcode(),\n@@ -909,1 +1191,2 @@\n-    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -912,11 +1195,30 @@\n-%}')dnl\n-dnl\n-define(`ARGLIST',\n-`ifelse($1, `byte', vmemA, indirect) mem, vReg src, vReg tmp, ifelse($1, `byte', immI_1, immI_gt_1) esize')\n-dnl\n-dnl STOREV_VSTOREMASK($1,  )\n-dnl STOREV_VSTOREMASK(esize)\n-define(`STOREV_VSTOREMASK', `\n-instruct storeV_vstoremask_$1(ARGLIST($1)) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n-                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+%}\n+\n+instruct vloadmask_loadV_partial(pRegGov dst, indirect mem, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_Vector()->length_in_bytes() > 16 &&\n+            n->as_Vector()->length_in_bytes() < MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"vloadmask_loadV $dst, $mem\\t# load vector mask partial (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ expected vector element type. Convert the vector to predicate.\n+    BasicType to_vect_bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(to_vect_bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($ptmp$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($vtmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Combine VectorStoreMask+StoreVector when the vector element type is not T_BYTE\n+\n+instruct storeV_vstoremask(indirect mem, pRegGov src, vReg tmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n@@ -925,3 +1227,3 @@\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_neg $tmp, $src\\n\\t\"\n-            \"sve_st1b $tmp, $mem\\t# store vector mask (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_cpy $tmp, $src, 1\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n@@ -931,3 +1233,2 @@\n-    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);\n-    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n-               as_FloatRegister($src$$reg));\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy(as_FloatRegister($tmp$$reg), size, as_PRegister($src$$reg), 1, false);\n@@ -939,10 +1240,1 @@\n-%}')dnl\n-undefine(ARGLIST)dnl\n-dnl\n-\/\/ load\/store mask vector\n-VLOADMASK_LOADV(byte, == 1)\n-VLOADMASK_LOADV(non_byte, > 1)\n-STOREV_VSTOREMASK(byte)\n-STOREV_VSTOREMASK(non_byte)\n-\n-\/\/ vector add reduction\n+%}\n@@ -950,4 +1242,36 @@\n-instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (AddReductionVI src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+instruct storeV_vstoremask_partial(indirect mem, pRegGov src, vReg vtmp,\n+                                   immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() > 16 &&\n+            type2aelembytes(n->as_StoreVector()->vect_type()->element_basic_type()) > 1 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n+  format %{ \"storeV_vstoremask $src, $mem\\t# store vector mask partial (sve) (H\/S\/D)\" %}\n+  ins_cost(6 * SVE_COST);\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector\n+    \/\/ elements as boolean values.\n+    BasicType from_vect_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(from_vect_bt);\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($ptmp$$reg), T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl REDUCE_I($1,        $2     )\n+dnl REDUCE_I(insn_name, op_name)\n+define(`REDUCE_I', `\n+instruct reduce_$1I(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  ifelse($2, AddReductionVI,\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -955,1 +1279,1 @@\n-  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addB\/S\/I reduction (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# $1I reduction (sve) (may extend)\" %}\n@@ -958,11 +1282,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n@@ -971,3 +1287,29 @@\n-%}\n-\n-instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+%}')dnl\n+dnl\n+dnl\n+dnl REDUCE_L($1,        $2    )\n+dnl REDUCE_L(insn_name, op_name)\n+define(`REDUCE_L', `\n+instruct reduce_$1L(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  ifelse($2, AddReductionVL,\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# $1L reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_I_PARTIAL($1,        $2     )\n+dnl REDUCE_I_PARTIAL(insn_name, op_name)\n+define(`REDUCE_I_PARTIAL', `\n+instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n@@ -975,2 +1317,7 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AddReductionVI src1 src2));\n+  ifelse($2, AddReductionVI,\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);')\n+  match(Set dst ($2 src1 src2));\n@@ -978,2 +1325,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# $1I reduction partial (sve) (may extend)\" %}\n@@ -985,11 +1332,3 @@\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -998,17 +1337,6 @@\n-%}\n-\n-instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (AddReductionVL src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction (sve)\" %}\n-  ins_encode %{\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+%}')dnl\n+dnl\n+dnl REDUCE_L_PARTIAL($1,        $2    )\n+dnl REDUCE_L_PARTIAL(insn_name, op_name)\n+define(`REDUCE_L_PARTIAL', `\n+instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n@@ -1016,2 +1344,7 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AddReductionVL src1 src2));\n+  ifelse($2, AddReductionVL,\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);')\n+  match(Set dst ($2 src1 src2));\n@@ -1019,2 +1352,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# $1L reduction partial (sve)\" %}\n@@ -1024,4 +1357,3 @@\n-    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1030,2 +1362,1 @@\n-%}\n-\n+%}')dnl\n@@ -1036,3 +1367,4 @@\n-instruct $1($3 src1_dst, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set src1_dst (AddReductionV$2 src1_dst src2));\n+instruct reduce_$1($3 src1_dst, vReg src2) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst ($2 src1_dst src2));\n@@ -1052,3 +1384,4 @@\n-instruct $1($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set src1_dst (AddReductionV$2 src1_dst src2));\n+instruct reduce_$1_partial($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst ($2 src1_dst src2));\n@@ -1057,1 +1390,1 @@\n-  format %{ \"sve_reduce_add$2 $src1_dst, $src1_dst, $src2\\t# add$2 reduction partial (sve) ($4)\" %}\n+  format %{ \"sve_reduce_$1 $src1_dst, $src1_dst, $src2\\t# $1 reduction partial (sve) ($4)\" %}\n@@ -1067,12 +1400,13 @@\n-REDUCE_ADDF(reduce_addF, F, vRegF, S)\n-REDUCE_ADDF_PARTIAL(reduce_addF_partial, F, vRegF, S)\n-REDUCE_ADDF(reduce_addD, D, vRegD, D)\n-REDUCE_ADDF_PARTIAL(reduce_addD_partial, D, vRegD, D)\n-\n-\/\/ vector and reduction\n-\n-instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+dnl\n+dnl REDUCE_I_PREDICATE($1,        $2     )\n+dnl REDUCE_I_PREDICATE(insn_name, op_name)\n+define(`REDUCE_I_PREDICATE', `\n+instruct reduce_$1I_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  ifelse($2, AddReductionVI,\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')\n+  match(Set dst ($2 (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1080,1 +1414,1 @@\n-  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andB\/S\/I reduction (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_$1I $dst, $src1, $pg, $src2\\t# $1I reduction predicated (sve) (may extend)\" %}\n@@ -1083,11 +1417,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n@@ -1096,71 +1422,14 @@\n-%}\n-\n-instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction (sve)\" %}\n-  ins_encode %{\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-\/\/ vector or reduction\n-\n-instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+%}')dnl\n+dnl\n+dnl REDUCE_L_PREDICATE($1,        $2    )\n+dnl REDUCE_L_PREDICATE(insn_name, op_name)\n+define(`REDUCE_L_PREDICATE', `\n+instruct reduce_$1L_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, pRegGov pg) %{\n+  ifelse($2, AddReductionVL,\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')\n+  match(Set dst ($2 (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1168,1 +1437,1 @@\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orB\/S\/I reduction (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_$1L $dst, $src1, $pg, $src2\\t# $1L reduction predicated (sve)\" %}\n@@ -1170,12 +1439,3 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n@@ -1184,7 +1444,14 @@\n-%}\n-\n-instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n+%}')dnl\n+dnl\n+dnl REDUCE_I_PREDICATE_PARTIAL($1,        $2     )\n+dnl REDUCE_I_PREDICATE_PARTIAL(insn_name, op_name)\n+define(`REDUCE_I_PREDICATE_PARTIAL', `\n+instruct reduce_$1I_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  ifelse($2, AddReductionVI,\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);')\n+  match(Set dst ($2 (Binary src1 src2) pg));\n@@ -1192,2 +1459,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $pg, $src2\\t# $1I reduction predicated partial (sve) (may extend)\" %}\n@@ -1199,11 +1466,5 @@\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n-               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1212,22 +1473,14 @@\n-%}\n-\n-instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction (sve)\" %}\n-  ins_encode %{\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n+%}')dnl\n+dnl\n+dnl REDUCE_L_PREDICATE_PARTIAL($1,        $2    )\n+dnl REDUCE_L_PREDICATE_PARTIAL(insn_name, op_name)\n+define(`REDUCE_L_PREDICATE_PARTIAL', `\n+instruct reduce_$1L_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  ifelse($2, AddReductionVL,\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);',\n+       `predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);')\n+  match(Set dst ($2 (Binary src1 src2) pg));\n@@ -1235,2 +1488,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $pg, $src2\\t# $1L reduction predicated partial (sve)\" %}\n@@ -1240,58 +1493,5 @@\n-    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n-               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-\/\/ vector xor reduction\n-\n-instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorB\/H\/I reduction (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n-                          Matcher::vector_length(this, $src2));\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n-    if (bt == T_BYTE) {\n-      __ sxtb($dst$$Register, $dst$$Register);\n-    } else if (bt == T_SHORT) {\n-      __ sxth($dst$$Register, $dst$$Register);\n-    } else {\n-      assert(bt == T_INT, \"unsupported type\");\n-    }\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1300,7 +1500,9 @@\n-%}\n-\n-instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+%}')dnl\n+dnl\n+dnl REDUCE_ADDF_PREDICATE($1,        $2,      $3,      $4  )\n+dnl REDUCE_ADDF_PREDICATE(insn_name, op_name, reg_dst, size)\n+define(`REDUCE_ADDF_PREDICATE', `\n+instruct reduce_$1_masked($3 src1_dst, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst ($2 (Binary src1_dst src2) pg));\n@@ -1308,1 +1510,1 @@\n-  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction (sve)\" %}\n+  format %{ \"sve_reduce_$1 $src1_dst, $pg, $src2\\t# $1 reduction predicated (sve)\" %}\n@@ -1310,3 +1512,2 @@\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n+                 as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n@@ -1315,8 +1516,10 @@\n-%}\n-\n-instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+%}')dnl\n+dnl\n+dnl REDUCE_ADDF_PREDICATE_PARTIAL($1,        $2,      $3,      $4  )\n+dnl REDUCE_ADDF_PREDICATE_PARTIAL(insn_name, op_name, reg_dst, size)\n+define(`REDUCE_ADDF_PREDICATE_PARTIAL', `\n+instruct reduce_$1_masked_partial($3 src1_dst, vReg src2, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst ($2 (Binary src1_dst src2) pg));\n+  effect(TEMP ptmp, KILL cr);\n@@ -1324,1 +1527,1 @@\n-  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+  format %{ \"sve_reduce_$1 $src1_dst, $pg, $src2\\t# $1 reduction predicated partial (sve)\" %}\n@@ -1326,1 +1529,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ $4,\n@@ -1328,4 +1531,4 @@\n-    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n-                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1334,1 +1537,58 @@\n-%}\n+%}')dnl\n+dnl\n+\n+\/\/ vector add reduction\n+REDUCE_I(add, AddReductionVI)\n+REDUCE_L(add, AddReductionVL)\n+REDUCE_ADDF(addF, AddReductionVF, vRegF, S)\n+REDUCE_ADDF(addD, AddReductionVD, vRegD, D)\n+REDUCE_I_PARTIAL(add, AddReductionVI)\n+REDUCE_L_PARTIAL(add, AddReductionVL)\n+REDUCE_ADDF_PARTIAL(addF, AddReductionVF, vRegF, S)\n+REDUCE_ADDF_PARTIAL(addD, AddReductionVD, vRegD, D)\n+\n+\/\/ vector add reduction - predicated\n+REDUCE_I_PREDICATE(add, AddReductionVI)\n+REDUCE_L_PREDICATE(add, AddReductionVL)\n+REDUCE_ADDF_PREDICATE(addF, AddReductionVF, vRegF, S)\n+REDUCE_ADDF_PREDICATE(addD, AddReductionVD, vRegD, D)\n+REDUCE_I_PREDICATE_PARTIAL(add, AddReductionVI)\n+REDUCE_L_PREDICATE_PARTIAL(add, AddReductionVL)\n+REDUCE_ADDF_PREDICATE_PARTIAL(addF, AddReductionVF, vRegF, S)\n+REDUCE_ADDF_PREDICATE_PARTIAL(addD, AddReductionVD, vRegD, D)\n+\n+\/\/ vector and reduction\n+REDUCE_I(and, AndReductionV)\n+REDUCE_L(and, AndReductionV)\n+REDUCE_I_PARTIAL(and, AndReductionV)\n+REDUCE_L_PARTIAL(and, AndReductionV)\n+\n+\/\/ vector and reduction - predicated\n+REDUCE_I_PREDICATE(and, AndReductionV)\n+REDUCE_L_PREDICATE(and, AndReductionV)\n+REDUCE_I_PREDICATE_PARTIAL(and, AndReductionV)\n+REDUCE_L_PREDICATE_PARTIAL(and, AndReductionV)\n+\n+\/\/ vector or reduction\n+REDUCE_I(or, OrReductionV)\n+REDUCE_L(or, OrReductionV)\n+REDUCE_I_PARTIAL(or, OrReductionV)\n+REDUCE_L_PARTIAL(or, OrReductionV)\n+\n+\/\/ vector or reduction - predicated\n+REDUCE_I_PREDICATE(or, OrReductionV)\n+REDUCE_L_PREDICATE(or, OrReductionV)\n+REDUCE_I_PREDICATE_PARTIAL(or, OrReductionV)\n+REDUCE_L_PREDICATE_PARTIAL(or, OrReductionV)\n+\n+\/\/ vector xor reduction\n+REDUCE_I(eor, XorReductionV)\n+REDUCE_L(eor, XorReductionV)\n+REDUCE_I_PARTIAL(eor, XorReductionV)\n+REDUCE_L_PARTIAL(eor, XorReductionV)\n+\n+\/\/ vector xor reduction - predicated\n+REDUCE_I_PREDICATE(eor, XorReductionV)\n+REDUCE_L_PREDICATE(eor, XorReductionV)\n+REDUCE_I_PREDICATE_PARTIAL(eor, XorReductionV)\n+REDUCE_L_PREDICATE_PARTIAL(eor, XorReductionV)\n@@ -1337,2 +1597,2 @@\n-dnl REDUCE_MAXMIN_I($1,      $2,      $3 )\n-dnl REDUCE_MAXMIN_I(min_max, op_mame, cmp)\n+dnl REDUCE_MAXMIN_I($1,        $2     )\n+dnl REDUCE_MAXMIN_I(insn_name, op_name)\n@@ -1340,5 +1600,5 @@\n-instruct reduce_$1I(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n-            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+instruct reduce_$1I(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n@@ -1346,1 +1606,1 @@\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1348,1 +1608,1 @@\n-  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# reduce $1B\/S\/I (sve)\" %}\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# $1I reduction (sve)\" %}\n@@ -1351,5 +1611,3 @@\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ cmpw($dst$$Register, $src1$$Register);\n-    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n@@ -1360,2 +1618,2 @@\n-dnl REDUCE_MAXMIN_L($1,      $2,      $3 )\n-dnl REDUCE_MAXMIN_L(min_max, op_name, cmp)\n+dnl REDUCE_MAXMIN_L($1,        $2     )\n+dnl REDUCE_MAXMIN_L(insn_name, op_name)\n@@ -1363,2 +1621,3 @@\n-instruct reduce_$1L(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+instruct reduce_$1L(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -1367,1 +1626,1 @@\n-  effect(TEMP_DEF dst, TEMP vtmp);\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1369,1 +1628,1 @@\n-  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# reduce $1L partial (sve)\" %}\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# $1L reduction (sve)\" %}\n@@ -1371,4 +1630,3 @@\n-    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ cmp($dst$$Register, $src1$$Register);\n-    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           ptrue, as_FloatRegister($tmp$$reg));\n@@ -1379,2 +1637,2 @@\n-dnl REDUCE_MAXMIN_I_PARTIAL($1,      $2,      $3 )\n-dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_mame, cmp)\n+dnl REDUCE_MAXMIN_I_PARTIAL($1     , $2     )\n+dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_name)\n@@ -1384,4 +1642,4 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n@@ -1390,2 +1648,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# reduce $1I partial (sve)\" %}\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# $1I reduction partial (sve)\" %}\n@@ -1397,5 +1655,3 @@\n-    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n-    __ cmpw($dst$$Register, $src1$$Register);\n-    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1406,2 +1662,2 @@\n-dnl REDUCE_MAXMIN_L_PARTIAL($1,      $2,      $3 )\n-dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name, cmp)\n+dnl REDUCE_MAXMIN_L_PARTIAL($1     , $2     )\n+dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name)\n@@ -1411,1 +1667,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n@@ -1415,0 +1672,44 @@\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# $1L reduction  partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_I_PREDICATE($1     , $2     )\n+dnl REDUCE_MAXMIN_I_PREDICATE(min_max, op_name)\n+define(`REDUCE_MAXMIN_I_PREDICATE', `\n+instruct reduce_$1I_masked(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp,\n+                           pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst ($2 (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $pg, $src2\\t# $1I reduction predicated (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_PREDICATE($1     , $2     )\n+dnl REDUCE_MAXMIN_L_PREDICATE(min_max, op_name)\n+define(`REDUCE_MAXMIN_L_PREDICATE', `\n+instruct reduce_$1L_masked(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp,\n+                          pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst ($2 (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1416,1 +1717,48 @@\n-  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# reduce $1L partial (sve)\" %}\n+  format %{ \"sve_reduce_$1L $dst, $src1, $pg, $src2\\t# $1L reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_I_PREDICATE_PARTIAL($1     , $2     )\n+dnl REDUCE_MAXMIN_I_PREDICATE_PARTIAL(min_max, op_name)\n+define(`REDUCE_MAXMIN_I_PREDICATE_PARTIAL', `\n+instruct reduce_$1I_masked_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            is_integral_type(n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type()));\n+  match(Set dst ($2 (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $pg, $src2\\t# $1I reduction predicated partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_PREDICATE_PARTIAL($1     , $2     )\n+dnl REDUCE_MAXMIN_L_PREDICATE_PARTIAL(min_max, op_name)\n+define(`REDUCE_MAXMIN_L_PREDICATE_PARTIAL', `\n+instruct reduce_$1L_masked_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                                  pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst ($2 (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $pg, $src2\\t# $1L reduction predicated partial (sve)\" %}\n@@ -1420,5 +1768,5 @@\n-    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n-    __ cmp($dst$$Register, $src1$$Register);\n-    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $src1$$Register, as_FloatRegister($src2$$reg),\n+                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n@@ -1433,1 +1781,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n@@ -1438,2 +1787,1 @@\n-  format %{ \"sve_f$1v $dst, $src2 # vector (sve) ($4)\\n\\t\"\n-            \"f$1s $dst, $dst, $src1\\t# $1 reduction $2\" %}\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# $1$2 reduction (sve)\" %}\n@@ -1441,2 +1789,1 @@\n-    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src2$$reg));\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src2$$reg));\n@@ -1448,1 +1795,0 @@\n-dnl\n@@ -1454,1 +1800,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n@@ -1459,1 +1806,39 @@\n-  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# reduce $1 $4 partial (sve)\" %}\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# $1$2 reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ $4,\n+                          Matcher::vector_length(this, $src2));\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_FMINMAX_PREDICATE($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX_PREDICATE(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX_PREDICATE', `\n+instruct reduce_$1$2_masked($5 dst, $5 src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV (Binary src1 src2) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $pg, $src2\\t# $1$2 reduction predicated (sve)\" %}\n+  ins_encode %{\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4, as_PRegister($pg$$reg), as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_FMINMAX_PREDICATE_PARTIAL($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX_PREDICATE_PARTIAL(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX_PREDICATE_PARTIAL', `\n+instruct reduce_$1$2_masked_partial($5 dst, $5 src1, vReg src2, pRegGov pg,\n+                                    pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(1)->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV (Binary src1 src2) pg));\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $pg, $src2\\t# $1$2 reduction predicated partial (sve)\" %}\n@@ -1463,0 +1848,2 @@\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n@@ -1464,1 +1851,1 @@\n-         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1469,5 +1856,4 @@\n-\n-REDUCE_MAXMIN_I(max, MaxReductionV, GT)\n-REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV, GT)\n-REDUCE_MAXMIN_L(max, MaxReductionV, GT)\n-REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_MAXMIN_I(max, MaxReductionV)\n+REDUCE_MAXMIN_L(max, MaxReductionV)\n+REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV)\n+REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV)\n@@ -1480,0 +1866,10 @@\n+\/\/ vector max reduction - predicated\n+REDUCE_MAXMIN_I_PREDICATE(max, MaxReductionV)\n+REDUCE_MAXMIN_L_PREDICATE(max, MaxReductionV)\n+REDUCE_MAXMIN_I_PREDICATE_PARTIAL(max, MaxReductionV)\n+REDUCE_MAXMIN_L_PREDICATE_PARTIAL(max, MaxReductionV)\n+REDUCE_FMINMAX_PREDICATE(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PREDICATE(max, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PREDICATE_PARTIAL(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PREDICATE_PARTIAL(max, D, T_DOUBLE, D, vRegD)\n+\n@@ -1481,4 +1877,4 @@\n-REDUCE_MAXMIN_I(min, MinReductionV, LT)\n-REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV, LT)\n-REDUCE_MAXMIN_L(min, MinReductionV, LT)\n-REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV, LT)\n+REDUCE_MAXMIN_I(min, MinReductionV)\n+REDUCE_MAXMIN_L(min, MinReductionV)\n+REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV)\n+REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV)\n@@ -1490,0 +1886,10 @@\n+\/\/ vector min reduction - predicated\n+REDUCE_MAXMIN_I_PREDICATE(min, MinReductionV)\n+REDUCE_MAXMIN_L_PREDICATE(min, MinReductionV)\n+REDUCE_MAXMIN_I_PREDICATE_PARTIAL(min, MinReductionV)\n+REDUCE_MAXMIN_L_PREDICATE_PARTIAL(min, MinReductionV)\n+REDUCE_FMINMAX_PREDICATE(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PREDICATE(min, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PREDICATE_PARTIAL(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PREDICATE_PARTIAL(min, D, T_DOUBLE, D, vRegD)\n+\n@@ -1667,3 +2073,42 @@\n-\/\/ vector sqrt\n-UNARY_OP_TRUE_PREDICATE(vsqrtF, SqrtVF, S, 16, sve_fsqrt)\n-UNARY_OP_TRUE_PREDICATE(vsqrtD, SqrtVD, D, 16, sve_fsqrt)\n+\/\/ vector shift - predicated\n+BINARY_OP_PREDICATE(vasrB, RShiftVB,  B, sve_asr)\n+BINARY_OP_PREDICATE(vasrS, RShiftVS,  H, sve_asr)\n+BINARY_OP_PREDICATE(vasrI, RShiftVI,  S, sve_asr)\n+BINARY_OP_PREDICATE(vasrL, RShiftVL,  D, sve_asr)\n+BINARY_OP_PREDICATE(vlslB, LShiftVB,  B, sve_lsl)\n+BINARY_OP_PREDICATE(vlslS, LShiftVS,  H, sve_lsl)\n+BINARY_OP_PREDICATE(vlslI, LShiftVI,  S, sve_lsl)\n+BINARY_OP_PREDICATE(vlslL, LShiftVL,  D, sve_lsl)\n+BINARY_OP_PREDICATE(vlsrB, URShiftVB, B, sve_lsr)\n+BINARY_OP_PREDICATE(vlsrS, URShiftVS, H, sve_lsr)\n+BINARY_OP_PREDICATE(vlsrI, URShiftVI, S, sve_lsr)\n+BINARY_OP_PREDICATE(vlsrL, URShiftVL, D, sve_lsr)\n+dnl\n+dnl VSHIFT_IMM_PREDICATED($1,        $2,      $3,       $4,   $5,   $6  )\n+dnl VSHIFT_IMM_PREDICATED(insn_name, op_name, op_name2, type, size, insn)\n+define(`VSHIFT_IMM_PREDICATED', `\n+instruct $1_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($2 (Binary dst_src ($3 shift)) pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"$6 $dst_src, $pg, $dst_src, $shift\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    assert(con ifelse(index(`$1', `vlsl'), 0, `>=', `>') 0 && con < $5, \"invalid shift immediate\");\n+    __ $6(as_FloatRegister($dst_src$$reg), __ $4, as_PRegister($pg$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VSHIFT_IMM_PREDICATED(vasrB, RShiftVB,  RShiftCntV, B, 8,  sve_asr)\n+VSHIFT_IMM_PREDICATED(vasrS, RShiftVS,  RShiftCntV, H, 16, sve_asr)\n+VSHIFT_IMM_PREDICATED(vasrI, RShiftVI,  RShiftCntV, S, 32, sve_asr)\n+VSHIFT_IMM_PREDICATED(vasrL, RShiftVL,  RShiftCntV, D, 64, sve_asr)\n+VSHIFT_IMM_PREDICATED(vlsrB, URShiftVB, RShiftCntV, B, 8,  sve_lsr)\n+VSHIFT_IMM_PREDICATED(vlsrS, URShiftVS, RShiftCntV, H, 16, sve_lsr)\n+VSHIFT_IMM_PREDICATED(vlsrI, URShiftVI, RShiftCntV, S, 32, sve_lsr)\n+VSHIFT_IMM_PREDICATED(vlsrL, URShiftVL, RShiftCntV, D, 64, sve_lsr)\n+VSHIFT_IMM_PREDICATED(vlslB, LShiftVB,  LShiftCntV, B, 8,  sve_lsl)\n+VSHIFT_IMM_PREDICATED(vlslS, LShiftVS,  LShiftCntV, H, 16, sve_lsl)\n+VSHIFT_IMM_PREDICATED(vlslI, LShiftVI,  LShiftCntV, S, 32, sve_lsl)\n+VSHIFT_IMM_PREDICATED(vlslL, LShiftVL,  LShiftCntV, D, 64, sve_lsl)\n@@ -1671,7 +2116,3 @@\n-\/\/ vector sub\n-BINARY_OP_UNPREDICATED(vsubB, SubVB, B, 16, sve_sub)\n-BINARY_OP_UNPREDICATED(vsubS, SubVS, H, 8, sve_sub)\n-BINARY_OP_UNPREDICATED(vsubI, SubVI, S, 4, sve_sub)\n-BINARY_OP_UNPREDICATED(vsubL, SubVL, D, 2, sve_sub)\n-BINARY_OP_UNPREDICATED(vsubF, SubVF, S, 4, sve_fsub)\n-BINARY_OP_UNPREDICATED(vsubD, SubVD, D, 2, sve_fsub)\n+\/\/ vector sqrt\n+UNARY_OP_TRUE_PREDICATE(vsqrtF, SqrtVF, S, sve_fsqrt)\n+UNARY_OP_TRUE_PREDICATE(vsqrtD, SqrtVD, D, sve_fsqrt)\n@@ -1679,1 +2120,3 @@\n-\/\/ vector mask cast\n+\/\/ vector sqrt - predicated\n+UNARY_OP_PREDICATE(vsqrtF, SqrtVF, S, sve_fsqrt)\n+UNARY_OP_PREDICATE(vsqrtD, SqrtVD, D, sve_fsqrt)\n@@ -1681,2 +2124,21 @@\n-instruct vmaskcast(vReg dst) %{\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+\/\/ vector sub\n+BINARY_OP_UNPREDICATE(vsubB, SubVB, B, 16, sve_sub)\n+BINARY_OP_UNPREDICATE(vsubS, SubVS, H, 8, sve_sub)\n+BINARY_OP_UNPREDICATE(vsubI, SubVI, S, 4, sve_sub)\n+BINARY_OP_UNPREDICATE(vsubL, SubVL, D, 2, sve_sub)\n+BINARY_OP_UNPREDICATE(vsubF, SubVF, S, 4, sve_fsub)\n+BINARY_OP_UNPREDICATE(vsubD, SubVD, D, 2, sve_fsub)\n+\n+\/\/ vector sub - predicated\n+BINARY_OP_PREDICATE(vsubB, SubVB, B, sve_sub)\n+BINARY_OP_PREDICATE(vsubS, SubVS, H, sve_sub)\n+BINARY_OP_PREDICATE(vsubI, SubVI, S, sve_sub)\n+BINARY_OP_PREDICATE(vsubL, SubVL, D, sve_sub)\n+BINARY_OP_PREDICATE(vsubF, SubVF, S, sve_fsub)\n+BINARY_OP_PREDICATE(vsubD, SubVD, D, sve_fsub)\n+\n+\/\/ ------------------------------ Vector mask cast --------------------------\n+\n+instruct vmaskcast(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n@@ -1684,1 +2146,1 @@\n-  match(Set dst (VectorMaskCast dst));\n+  match(Set dst_src (VectorMaskCast dst_src));\n@@ -1686,1 +2148,1 @@\n-  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+  format %{ \"vmaskcast $dst_src\\t# empty (sve)\" %}\n@@ -1693,0 +2155,33 @@\n+instruct vmaskcast_extend(pRegGov dst, pReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_length_in_bytes(n) == 2 * Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) == 4 * Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) == 8 * Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorMaskCast src));\n+  ins_cost(SVE_COST * 3);\n+  format %{ \"sve_vmaskcast_extend  $dst, $src\\t# extend predicate $src\" %}\n+  ins_encode %{\n+    __ sve_vmaskcast_extend(as_PRegister($dst$$reg), as_PRegister($src$$reg),\n+                            Matcher::vector_length_in_bytes(this), Matcher::vector_length_in_bytes(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcast_narrow(pRegGov dst, pReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_length_in_bytes(n) * 2 == Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) * 4 == Matcher::vector_length_in_bytes(n->in(1)) ||\n+             Matcher::vector_length_in_bytes(n) * 8 == Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorMaskCast src));\n+  ins_cost(SVE_COST * 3);\n+  format %{ \"sve_vmaskcast_narrow  $dst, $src\\t# narrow predicate $src\" %}\n+  ins_encode %{\n+    __ sve_vmaskcast_narrow(as_PRegister($dst$$reg), as_PRegister($src$$reg),\n+                            Matcher::vector_length_in_bytes(this), Matcher::vector_length_in_bytes(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+\n@@ -2061,5 +2556,2 @@\n-dnl\n-dnl VTEST($1,      $2,   $3,  $4  )\n-dnl VTEST(op_name, pred, imm, cond)\n-define(`VTEST', `\n-instruct vtest_$1`'(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)\n+\n+instruct vtest_alltrue(iRegINoSp dst, pRegGov src1, pRegGov src2, pReg ptmp, rFlagsReg cr)\n@@ -2067,2 +2559,3 @@\n-  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n-            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n@@ -2070,1 +2563,19 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eors $ptmp, $src1, $src2\\t# $src2 is all true mask\\n\"\n+            \"csetw $dst, EQ\\t# VectorTest (sve) - alltrue\" %}\n+  ins_encode %{\n+    __ sve_eors(as_PRegister($ptmp$$reg), ptrue,\n+                as_PRegister($src1$$reg), as_PRegister($src2$$reg));\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_anytrue(iRegINoSp dst, pRegGov src1, pRegGov src2, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(KILL cr);\n@@ -2072,2 +2583,2 @@\n-  format %{ \"sve_cmpeq $pTmp, $src1, $3\\n\\t\"\n-            \"csetw $dst, $4\\t# VectorTest (sve) - $1\" %}\n+  format %{ \"sve_ptest $src1\\n\\t\"\n+            \"csetw $dst, NE\\t# VectorTest (sve) - anytrue\" %}\n@@ -2076,5 +2587,2 @@\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src1);\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               ptrue, as_FloatRegister($src1$$reg), $3);\n-    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+    __ sve_ptest(ptrue, as_PRegister($src1$$reg));\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -2083,4 +2591,1 @@\n-%}')dnl\n-dnl\n-VTEST(alltrue, overflow, 0, EQ)\n-VTEST(anytrue, ne,      -1, NE)\n+%}\n@@ -2089,2 +2594,2 @@\n-dnl VTEST_PARTIAL($1,      $2,   $3,  $4  )\n-dnl VTEST_PARTIAL(op_name, pred, imm, cond)\n+dnl VTEST_PARTIAL($1,      $2,   $3,   $4  )\n+dnl VTEST_PARTIAL(op_name, pred, inst, cond)\n@@ -2092,1 +2597,1 @@\n-instruct vtest_$1_partial`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+instruct vtest_$1_partial`'(iRegINoSp dst, pRegGov src1, pRegGov src2, pRegGov ptmp, rFlagsReg cr)\n@@ -2094,1 +2599,2 @@\n-  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n@@ -2097,1 +2603,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -2101,1 +2607,0 @@\n-    \/\/ \"src2\" is not used for sve.\n@@ -2104,1 +2609,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), size,\n@@ -2106,2 +2611,2 @@\n-    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n-               as_PRegister($pTmp$$reg), as_FloatRegister($src1$$reg), $3);\n+    __ $3(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+          as_PRegister($src1$$reg), as_PRegister($src2$$reg));\n@@ -2113,2 +2618,2 @@\n-VTEST_PARTIAL(alltrue, overflow, 0, EQ)\n-VTEST_PARTIAL(anytrue, ne,      -1, NE)\n+VTEST_PARTIAL(alltrue, overflow, sve_eors, EQ)\n+VTEST_PARTIAL(anytrue, ne,       sve_ands, NE)\n@@ -2333,1 +2838,1 @@\n-  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (S)\" %}\n@@ -2348,2 +2853,1 @@\n-  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (D)\" %}\n@@ -2360,1 +2864,1 @@\n-instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -2366,1 +2870,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -2368,2 +2872,1 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (I\/F)\" %}\n+  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (S)\" %}\n@@ -2371,3 +2874,2 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S,\n-                          Matcher::vector_length(this));\n-    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n@@ -2379,1 +2881,1 @@\n-instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -2385,1 +2887,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -2387,3 +2889,55 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (L\/D)\" %}\n+  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather Predicated -------------------------------\n+\n+instruct gatherI_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  ins_cost(SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated (S)\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pg$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated (D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pg$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather Predicated Partial -------------------------------\n+\n+instruct gatherI_masked_partial(vReg dst, indirect mem, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated partial (S)\" %}\n@@ -2391,1 +2945,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n@@ -2393,0 +2947,21 @@\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n+                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL_masked_partial(vReg dst, indirect mem, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"load_vector_gather $dst, $pg, $mem, $idx\\t# vector load gather predicated partial (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n@@ -2394,1 +2969,1 @@\n-    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n@@ -2409,1 +2984,1 @@\n-  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (I\/F)\" %}\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (S)\" %}\n@@ -2424,2 +2999,1 @@\n-  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (L\/D)\" %}\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (D)\" %}\n@@ -2434,1 +3008,1 @@\n-\/\/ ------------------------------ Vector Store Scatter Partial-------------------------------\n+\/\/ ------------------------------ Vector Store Scatter Partial -------------------------------\n@@ -2436,1 +3010,1 @@\n-instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -2442,1 +3016,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -2444,2 +3018,1 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (I\/F)\" %}\n+  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (S)\" %}\n@@ -2447,1 +3020,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n@@ -2449,1 +3022,1 @@\n-    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n@@ -2455,1 +3028,1 @@\n-instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n@@ -2461,1 +3034,1 @@\n-  effect(TEMP pTmp, KILL cr);\n+  effect(TEMP ptmp, KILL cr);\n@@ -2463,3 +3036,1 @@\n-  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n-            \"sve_uunpklo $idx, $idx\\n\\t\"\n-            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (L\/D)\" %}\n+  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (D)\" %}\n@@ -2467,1 +3038,1 @@\n-    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D,\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n@@ -2470,1 +3041,56 @@\n-    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg),\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter Predicated -------------------------------\n+\n+instruct scatterI_masked(indirect mem, vReg src, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  ins_cost(SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicate (S)\" %}\n+  ins_encode %{\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pg$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatterL_masked(indirect mem, vReg src, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicated (D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pg$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter Predicated Partial -------------------------------\n+\n+instruct scatterI_masked_partial(indirect mem, vReg src, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicated partial (S)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S,\n+                          Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n@@ -2476,0 +3102,20 @@\n+instruct scatterL_masked_partial(indirect mem, vReg src, vReg idx, pRegGov pg, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $pg, $idx, $src\\t# vector store scatter predicated partial (D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D,\n+                          Matcher::vector_length(this, $src));\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($pg$$reg), as_PRegister($pg$$reg));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n+                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -2566,1 +3212,1 @@\n-instruct vstoremask_$1(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+instruct vstoremask_$1(iRegINoSp dst, pRegGov src, immI esize, ifelse($1, `truecount', `rFlagsReg cr', `pReg ptmp, rFlagsReg cr')) %{\n@@ -2570,2 +3216,2 @@\n-  effect(TEMP ptmp, KILL cr);\n-  ins_cost($3 * SVE_COST);\n+  effect(ifelse($1, `truecount', `KILL cr', `TEMP ptmp, KILL cr'));\n+  ins_cost($3);\n@@ -2576,3 +3222,6 @@\n-    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           ptrue, as_PRegister($ptmp$$reg), Matcher::vector_length(this, $src));\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);dnl\n+ifelse(`$1', `truecount', `\n+    __ sve_cntp($dst$$Register, variant, ptrue, as_PRegister($src$$reg));', `\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg),\n+                           Matcher::vector_length(this, $src));')\n@@ -2584,3 +3233,3 @@\n-VSTOREMASK_REDUCTION(truecount, VectorMaskTrueCount, 2)\n-VSTOREMASK_REDUCTION(firsttrue, VectorMaskFirstTrue, 3)\n-VSTOREMASK_REDUCTION(lasttrue,  VectorMaskLastTrue, 4)\n+VSTOREMASK_REDUCTION(truecount, VectorMaskTrueCount, SVE_COST)\n+VSTOREMASK_REDUCTION(firsttrue, VectorMaskFirstTrue, 2 * SVE_COST)\n+VSTOREMASK_REDUCTION(lasttrue,  VectorMaskLastTrue, 3 * SVE_COST)\n@@ -2591,1 +3240,2 @@\n-instruct vstoremask_$1_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ifelse($1, `firsttrue', `pgtmp, pReg ptmp', `ptmp'), rFlagsReg cr) %{\n+instruct vstoremask_$1_partial(iRegINoSp dst, pRegGov src, immI esize,\n+                               pRegGov ifelse($1, `firsttrue', `pgtmp, pReg ptmp', `ptmp'), rFlagsReg cr) %{\n@@ -2602,4 +3252,13 @@\n-    __ sve_whilelo_zr_imm(as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), variant,\n-                          Matcher::vector_length(this, $src));\n-    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n-                           as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+    __ sve_whilelo_zr_imm(as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg),\n+                          variant, Matcher::vector_length(this, $src));dnl\n+ifelse($1, `truecount', `\n+    __ sve_cntp($dst$$Register, variant, as_PRegister($ptmp$$reg), as_PRegister($src$$reg));',\n+       $1, `firsttrue', `\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($src$$reg), as_PRegister($pgtmp$$reg),\n+                           as_PRegister($ptmp$$reg), MaxVectorSize \/ size);', `\n+    __ sve_and(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg),\n+               as_PRegister($src$$reg), as_PRegister($src$$reg));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant,\n+                           as_PRegister($ptmp$$reg), ptrue,\n+                           as_PRegister($ptmp$$reg), MaxVectorSize \/ size);')\n@@ -2610,2 +3269,2 @@\n-VSTOREMASK_REDUCTION_PARTIAL(truecount, VectorMaskTrueCount, 3)\n-VSTOREMASK_REDUCTION_PARTIAL(firsttrue, VectorMaskFirstTrue, 4)\n+VSTOREMASK_REDUCTION_PARTIAL(truecount, VectorMaskTrueCount, 2)\n+VSTOREMASK_REDUCTION_PARTIAL(firsttrue, VectorMaskFirstTrue, 3)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":1334,"deletions":675,"binary":false,"changes":2009,"status":"modified"},{"patch":"@@ -2968,0 +2968,26 @@\n+  void sve_shift_imm_encoding(SIMD_RegVariant T, int shift, bool isSHR,\n+                              int& tszh, int& tszl_imm) {\n+    \/* The encodings for the tszh:tszl:imm3 fields\n+     * for shift right is calculated as:\n+     *   0001 xxx       B, shift = 16  - UInt(tszh:tszl:imm3)\n+     *   001x xxx       H, shift = 32  - UInt(tszh:tszl:imm3)\n+     *   01xx xxx       S, shift = 64  - UInt(tszh:tszl:imm3)\n+     *   1xxx xxx       D, shift = 128 - UInt(tszh:tszl:imm3)\n+     * for shift left is calculated as:\n+     *   0001 xxx       B, shift = UInt(tszh:tszl:imm3) - 8\n+     *   001x xxx       H, shift = UInt(tszh:tszl:imm3) - 16\n+     *   01xx xxx       S, shift = UInt(tszh:tszl:imm3) - 32\n+     *   1xxx xxx       D, shift = UInt(tszh:tszl:imm3) - 64\n+     *\/\n+    assert(T != Q, \"Invalid register variant\");\n+    if (isSHR) {\n+      assert(((1 << (T + 3)) >= shift) && (shift > 0) , \"Invalid shift value\");\n+    } else {\n+      assert(((1 << (T + 3)) > shift) && (shift >= 0) , \"Invalid shift value\");\n+    }\n+    int cVal = (1 << ((T + 3) + (isSHR ? 1 : 0)));\n+    int encodedShift = isSHR ? cVal - shift : cVal + shift;\n+    tszh = encodedShift >> 5;\n+    tszl_imm = encodedShift & 0x1f;\n+  }\n+\n@@ -2979,0 +3005,1 @@\n+  INSN(sve_and,  0b00000100, 0b011010000); \/\/ vector and\n@@ -2981,1 +3008,1 @@\n-  INSN(sve_cnt,  0b00000100, 0b011010101)  \/\/ count non-zero bits\n+  INSN(sve_cnt,  0b00000100, 0b011010101); \/\/ count non-zero bits\n@@ -2983,0 +3010,1 @@\n+  INSN(sve_eor,  0b00000100, 0b011001000); \/\/ vector eor\n@@ -2989,0 +3017,1 @@\n+  INSN(sve_orr,  0b00000100, 0b011000000); \/\/ vector or\n@@ -3031,1 +3060,1 @@\n-  INSN(sve_fmla,  0b01100101, 1, 0b000); \/\/ floating-point fused multiply-add: Zda = Zda + Zn * Zm\n+  INSN(sve_fmla,  0b01100101, 1, 0b000); \/\/ floating-point fused multiply-add, writing addend: Zda = Zda + Zn * Zm\n@@ -3035,0 +3064,1 @@\n+  INSN(sve_fmad,  0b01100101, 1, 0b100); \/\/ floating-point fused multiply-add, writing multiplicand: Zda = Zm + Zda * Zn\n@@ -3056,22 +3086,2 @@\n-    \/* The encodings for the tszh:tszl:imm3 fields (bits 23:22 20:19 18:16)     \\\n-     * for shift right is calculated as:                                        \\\n-     *   0001 xxx       B, shift = 16  - UInt(tszh:tszl:imm3)                   \\\n-     *   001x xxx       H, shift = 32  - UInt(tszh:tszl:imm3)                   \\\n-     *   01xx xxx       S, shift = 64  - UInt(tszh:tszl:imm3)                   \\\n-     *   1xxx xxx       D, shift = 128 - UInt(tszh:tszl:imm3)                   \\\n-     * for shift left is calculated as:                                         \\\n-     *   0001 xxx       B, shift = UInt(tszh:tszl:imm3) - 8                     \\\n-     *   001x xxx       H, shift = UInt(tszh:tszl:imm3) - 16                    \\\n-     *   01xx xxx       S, shift = UInt(tszh:tszl:imm3) - 32                    \\\n-     *   1xxx xxx       D, shift = UInt(tszh:tszl:imm3) - 64                    \\\n-     *\/                                                                         \\\n-    assert(T != Q, \"Invalid register variant\");                                 \\\n-    if (isSHR) {                                                                \\\n-      assert(((1 << (T + 3)) >= shift) && (shift > 0) , \"Invalid shift value\"); \\\n-    } else {                                                                    \\\n-      assert(((1 << (T + 3)) > shift) && (shift >= 0) , \"Invalid shift value\"); \\\n-    }                                                                           \\\n-    int cVal = (1 << ((T + 3) + (isSHR ? 1 : 0)));                              \\\n-    int encodedShift = isSHR ? cVal - shift : cVal + shift;                     \\\n-    int tszh = encodedShift >> 5;                                               \\\n-    int tszl_imm = encodedShift & 0x1f;                                         \\\n+    int tszh, tszl_imm;                                                         \\\n+    sve_shift_imm_encoding(T, shift, isSHR, tszh, tszl_imm);                    \\\n@@ -3088,0 +3098,15 @@\n+\/\/ SVE bitwise shift by immediate (predicated)\n+#define INSN(NAME, opc, isSHR)                                                  \\\n+  void NAME(FloatRegister Zdn, SIMD_RegVariant T, PRegister Pg, int shift) {    \\\n+    starti;                                                                     \\\n+    int tszh, tszl_imm;                                                         \\\n+    sve_shift_imm_encoding(T, shift, isSHR, tszh, tszl_imm);                    \\\n+    f(0b00000100, 31, 24), f(tszh, 23, 22), f(0b00, 21, 20), f(opc, 19, 16);    \\\n+    f(0b100, 15, 13), pgrf(Pg, 10), f(tszl_imm, 9, 5), rf(Zdn, 0);              \\\n+  }\n+\n+  INSN(sve_asr, 0b0000, \/* isSHR = *\/ true);\n+  INSN(sve_lsl, 0b0011, \/* isSHR = *\/ false);\n+  INSN(sve_lsr, 0b0001, \/* isSHR = *\/ true);\n+#undef INSN\n+\n@@ -3199,0 +3224,18 @@\n+\/\/ SVE predicate logical operations\n+#define INSN(NAME, op1, op2, op3) \\\n+  void NAME(PRegister Pd, PRegister Pg, PRegister Pn, PRegister Pm) { \\\n+    starti;                                                           \\\n+    f(0b00100101, 31, 24), f(op1, 23, 22), f(0b00, 21, 20);           \\\n+    prf(Pm, 16), f(0b01, 15, 14), prf(Pg, 10), f(op2, 9);             \\\n+    prf(Pn, 5), f(op3, 4), prf(Pd, 0);                                \\\n+  }\n+\n+  INSN(sve_and,  0b00, 0b0, 0b0);\n+  INSN(sve_ands, 0b01, 0b0, 0b0);\n+  INSN(sve_eor,  0b00, 0b1, 0b0);\n+  INSN(sve_eors, 0b01, 0b1, 0b0);\n+  INSN(sve_orr,  0b10, 0b0, 0b0);\n+  INSN(sve_orrs, 0b11, 0b0, 0b0);\n+  INSN(sve_bic,  0b00, 0b0, 0b1);\n+#undef INSN\n+\n@@ -3232,0 +3275,7 @@\n+  \/\/ SVE predicate test\n+  void sve_ptest(PRegister Pg, PRegister Pn) {\n+    starti;\n+    f(0b001001010101000011, 31, 14), prf(Pg, 10), f(0, 9), prf(Pn, 5), f(0, 4, 0);\n+  }\n+\n+  \/\/ SVE predicate initialize\n@@ -3238,0 +3288,28 @@\n+  \/\/ SVE predicate zero\n+  void sve_pfalse(PRegister pd) {\n+    starti;\n+    f(0b00100101, 31, 24), f(0b00, 23, 22), f(0b011000111001, 21, 10);\n+    f(0b000000, 9, 4), prf(pd, 0);\n+  }\n+\n+\/\/ SVE load\/store predicate register\n+#define INSN(NAME, op1)                                                  \\\n+  void NAME(PRegister Pt, const Address &a)  {                           \\\n+    starti;                                                              \\\n+    assert(a.index() == noreg, \"invalid address variant\");               \\\n+    f(op1, 31, 29), f(0b0010110, 28, 22), sf(a.offset() >> 3, 21, 16),   \\\n+    f(0b000, 15, 13), f(a.offset() & 0x7, 12, 10), srf(a.base(), 5),     \\\n+    f(0, 4), prf(Pt, 0);                                                 \\\n+  }\n+\n+  INSN(sve_ldr, 0b100); \/\/ LDR (predicate)\n+  INSN(sve_str, 0b111); \/\/ STR (predicate)\n+#undef INSN\n+\n+  \/\/ SVE move predicate register\n+  void sve_mov(PRegister Pd, PRegister Pn) {\n+    starti;\n+    f(0b001001011000, 31, 20), prf(Pn, 16), f(0b01, 15, 14), prf(Pn, 10);\n+    f(0, 9), prf(Pn, 5), f(0, 4), prf(Pd, 0);\n+  }\n+\n@@ -3340,0 +3418,12 @@\n+\/\/ SVE unpack predicate elements\n+#define INSN(NAME, op) \\\n+  void NAME(PRegister Pd, PRegister Pn) { \\\n+    starti;                                                          \\\n+    f(0b000001010011000, 31, 17), f(op, 16), f(0b0100000, 15, 9);    \\\n+    prf(Pn, 5), f(0b0, 4), prf(Pd, 0);                               \\\n+  }\n+\n+  INSN(sve_punpkhi, 0b1); \/\/ Unpack and widen high half of predicate\n+  INSN(sve_punpklo, 0b0); \/\/ Unpack and widen low half of predicate\n+#undef INSN\n+\n@@ -3353,0 +3443,13 @@\n+\/\/ SVE permute predicate elements\n+#define INSN(NAME, op) \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pn, PRegister Pm) {             \\\n+    starti;                                                                            \\\n+    assert(T != Q, \"invalid size\");                                                    \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10, 21, 20), prf(Pm, 16);                 \\\n+    f(0b01001, 15, 11), f(op, 10), f(0b0, 9), prf(Pn, 5), f(0b0, 4), prf(Pd, 0);       \\\n+  }\n+\n+  INSN(sve_uzp1, 0b0); \/\/ Concatenate even elements from two predicates\n+  INSN(sve_uzp2, 0b1); \/\/ Concatenate odd elements from two predicates\n+#undef INSN\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":127,"deletions":24,"binary":false,"changes":151,"status":"modified"},{"patch":"@@ -976,4 +976,10 @@\n-                                            PRegister pg, PRegister pn, int length) {\n-  assert(pg->is_governing(), \"This register has to be a governing predicate register\");\n-  \/\/ The conditional flags will be clobbered by this function\n-  sve_cmp(Assembler::NE, pn, size, pg, src, 0);\n+                                            PRegister pgtmp, PRegister ptmp) {\n+  assert(pgtmp->is_governing(), \"This register has to be a governing predicate register\");\n+  \/\/ The condition flags will be clobbered by this function\n+  sve_cmp(Assembler::NE, ptmp, size, pgtmp, src, 0);\n+  sve_vmask_reduction(opc, dst, size, ptmp, pgtmp, ptmp, MaxVectorSize);\n+}\n+\n+void C2_MacroAssembler::sve_vmask_reduction(int opc, Register dst, SIMD_RegVariant size, PRegister src,\n+                                            PRegister pgtmp, PRegister ptmp, int length) {\n+  assert(pgtmp->is_governing(), \"This register has to be a governing predicate register\");\n@@ -982,1 +988,1 @@\n-      sve_cntp(dst, size, ptrue, pn);\n+      sve_cntp(dst, size, pgtmp, src);\n@@ -985,2 +991,2 @@\n-      sve_brkb(pn, pg, pn, false);\n-      sve_cntp(dst, size, ptrue, pn);\n+      sve_brkb(ptmp, pgtmp, src, false);\n+      sve_cntp(dst, size, pgtmp, ptmp);\n@@ -989,3 +995,3 @@\n-      sve_rev(pn, size, pn);\n-      sve_brkb(pn, ptrue, pn, false);\n-      sve_cntp(dst, size, ptrue, pn);\n+      sve_rev(ptmp, size, src);\n+      sve_brkb(ptmp, ptrue, ptmp, false);\n+      sve_cntp(dst, size, ptrue, ptmp);\n@@ -1000,0 +1006,139 @@\n+\n+\/\/ Extend src predicate to dst predicate with the same lane count but larger\n+\/\/ element size, e.g. 64Byte -> 512Long\n+void C2_MacroAssembler::sve_vmaskcast_extend(PRegister dst, PRegister src,\n+                                             uint dst_element_length_in_bytes,\n+                                             uint src_element_length_in_bytes) {\n+  if (dst_element_length_in_bytes == 2 * src_element_length_in_bytes) {\n+    sve_punpklo(dst, src);\n+  } else if (dst_element_length_in_bytes == 4 * src_element_length_in_bytes) {\n+    sve_punpklo(dst, src);\n+    sve_punpklo(dst, dst);\n+  } else if (dst_element_length_in_bytes == 8 * src_element_length_in_bytes) {\n+    sve_punpklo(dst, src);\n+    sve_punpklo(dst, dst);\n+    sve_punpklo(dst, dst);\n+  } else {\n+    assert(false, \"unsupported\");\n+    ShouldNotReachHere();\n+  }\n+}\n+\n+\/\/ Narrow src predicate to dst predicate with the same lane count but\n+\/\/ smaller element size, e.g. 512Long -> 64Byte\n+void C2_MacroAssembler::sve_vmaskcast_narrow(PRegister dst, PRegister src,\n+                                             uint dst_element_length_in_bytes, uint src_element_length_in_bytes) {\n+  \/\/ The insignificant bits in src predicate are expected to be zero.\n+  if (dst_element_length_in_bytes * 2 == src_element_length_in_bytes) {\n+    sve_uzp1(dst, B, src, src);\n+  } else if (dst_element_length_in_bytes * 4 == src_element_length_in_bytes) {\n+    sve_uzp1(dst, H, src, src);\n+    sve_uzp1(dst, B, dst, dst);\n+  } else if (dst_element_length_in_bytes * 8 == src_element_length_in_bytes) {\n+    sve_uzp1(dst, S, src, src);\n+    sve_uzp1(dst, H, dst, dst);\n+    sve_uzp1(dst, B, dst, dst);\n+  } else {\n+    assert(false, \"unsupported\");\n+    ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::sve_reduce_integral(int opc, Register dst, BasicType bt, Register src1,\n+                                            FloatRegister src2, PRegister pg, FloatRegister tmp) {\n+  assert(bt == T_BYTE || bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported element type\");\n+  assert(pg->is_governing(), \"This register has to be a governing predicate register\");\n+  assert_different_registers(src1, dst);\n+  \/\/ Register \"dst\" and \"tmp\" are to be clobbered, and \"src1\" and \"src2\" should be preserved.\n+  Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+  switch (opc) {\n+    case Op_AddReductionVI: {\n+      sve_uaddv(tmp, size, pg, src2);\n+      smov(dst, tmp, size, 0);\n+      if (bt == T_BYTE) {\n+        addw(dst, src1, dst, ext::sxtb);\n+      } else if (bt == T_SHORT) {\n+        addw(dst, src1, dst, ext::sxth);\n+      } else {\n+        addw(dst, dst, src1);\n+      }\n+      break;\n+    }\n+    case Op_AddReductionVL: {\n+      sve_uaddv(tmp, size, pg, src2);\n+      umov(dst, tmp, size, 0);\n+      add(dst, dst, src1);\n+      break;\n+    }\n+    case Op_AndReductionV: {\n+      sve_andv(tmp, size, pg, src2);\n+      if (bt == T_LONG) {\n+        umov(dst, tmp, size, 0);\n+        andr(dst, dst, src1);\n+      } else {\n+        smov(dst, tmp, size, 0);\n+        andw(dst, dst, src1);\n+      }\n+      break;\n+    }\n+    case Op_OrReductionV: {\n+      sve_orv(tmp, size, pg, src2);\n+      if (bt == T_LONG) {\n+        umov(dst, tmp, size, 0);\n+        orr(dst, dst, src1);\n+      } else {\n+        smov(dst, tmp, size, 0);\n+        orrw(dst, dst, src1);\n+      }\n+      break;\n+    }\n+    case Op_XorReductionV: {\n+      sve_eorv(tmp, size, pg, src2);\n+      if (bt == T_LONG) {\n+        umov(dst, tmp, size, 0);\n+        eor(dst, dst, src1);\n+      } else {\n+        smov(dst, tmp, size, 0);\n+        eorw(dst, dst, src1);\n+      }\n+      break;\n+    }\n+    case Op_MaxReductionV: {\n+      sve_smaxv(tmp, size, pg, src2);\n+      if (bt == T_LONG) {\n+        umov(dst, tmp, size, 0);\n+        cmp(dst, src1);\n+        csel(dst, dst, src1, Assembler::GT);\n+      } else {\n+        smov(dst, tmp, size, 0);\n+        cmpw(dst, src1);\n+        cselw(dst, dst, src1, Assembler::GT);\n+      }\n+      break;\n+    }\n+    case Op_MinReductionV: {\n+      sve_sminv(tmp, size, pg, src2);\n+      if (bt == T_LONG) {\n+        umov(dst, tmp, size, 0);\n+        cmp(dst, src1);\n+        csel(dst, dst, src1, Assembler::LT);\n+      } else {\n+        smov(dst, tmp, size, 0);\n+        cmpw(dst, src1);\n+        cselw(dst, dst, src1, Assembler::LT);\n+      }\n+      break;\n+    }\n+    default:\n+      assert(false, \"unsupported\");\n+      ShouldNotReachHere();\n+  }\n+\n+  if (opc == Op_AndReductionV || opc == Op_OrReductionV || opc == Op_XorReductionV) {\n+    if (bt == T_BYTE) {\n+      sxtb(dst, dst);\n+    } else if (bt == T_SHORT) {\n+      sxth(dst, dst);\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":155,"deletions":10,"binary":false,"changes":165,"status":"modified"},{"patch":"@@ -2049,0 +2049,76 @@\n+\/\/ Return the number of dwords pushed\n+int MacroAssembler::push_p(unsigned int bitset, Register stack) {\n+  bool use_sve = false;\n+  int sve_predicate_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  if (use_sve) {\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n+#endif\n+\n+  if (!use_sve) {\n+    return 0;\n+  }\n+\n+  const int num_of_regs = PRegisterImpl::number_of_saved_registers;\n+  unsigned char regs[num_of_regs];\n+  int count = 0;\n+  for (int reg = 0; reg < num_of_regs; reg++) {\n+    if (1 & bitset)\n+      regs[count++] = reg;\n+    bitset >>= 1;\n+  }\n+\n+  if (count == 0) {\n+    return 0;\n+  }\n+\n+  int total_push_bytes = align_up(sve_predicate_size_in_slots *\n+                                  VMRegImpl::stack_slot_size * count, 16);\n+  sub(stack, stack, total_push_bytes);\n+  for (int i = 0; i < count; i++) {\n+    sve_str(as_PRegister(regs[i]), Address(stack, i));\n+  }\n+  return total_push_bytes \/ 8;\n+}\n+\n+\/\/ Return the number of dwords poped\n+int MacroAssembler::pop_p(unsigned int bitset, Register stack) {\n+  bool use_sve = false;\n+  int sve_predicate_size_in_slots = 0;\n+\n+#ifdef COMPILER2\n+  use_sve = Matcher::supports_scalable_vector();\n+  if (use_sve) {\n+    sve_predicate_size_in_slots = Matcher::scalable_predicate_reg_slots();\n+  }\n+#endif\n+\n+  if (!use_sve) {\n+    return 0;\n+  }\n+\n+  const int num_of_regs = PRegisterImpl::number_of_saved_registers;\n+  unsigned char regs[num_of_regs];\n+  int count = 0;\n+  for (int reg = 0; reg < num_of_regs; reg++) {\n+    if (1 & bitset)\n+      regs[count++] = reg;\n+    bitset >>= 1;\n+  }\n+\n+  if (count == 0) {\n+    return 0;\n+  }\n+\n+  int total_pop_bytes = align_up(sve_predicate_size_in_slots *\n+                                 VMRegImpl::stack_slot_size * count, 16);\n+  for (int i = count - 1; i >= 0; i--) {\n+    sve_ldr(as_PRegister(regs[i]), Address(stack, i));\n+  }\n+  add(stack, stack, total_pop_bytes);\n+  return total_pop_bytes \/ 8;\n+}\n+\n@@ -2507,1 +2583,1 @@\n-                                    int sve_vector_size_in_bytes) {\n+                                    int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n@@ -2524,0 +2600,6 @@\n+  if (save_vectors && use_sve && total_predicate_in_bytes > 0) {\n+    sub(sp, sp, total_predicate_in_bytes);\n+    for (int i = 0; i < PRegisterImpl::number_of_saved_registers; i++) {\n+      sve_str(as_PRegister(i), Address(sp, i));\n+    }\n+  }\n@@ -2527,1 +2609,7 @@\n-                                   int sve_vector_size_in_bytes) {\n+                                   int sve_vector_size_in_bytes, int total_predicate_in_bytes) {\n+  if (restore_vectors && use_sve && total_predicate_in_bytes > 0) {\n+    for (int i = PRegisterImpl::number_of_saved_registers - 1; i >= 0; i--) {\n+      sve_ldr(as_PRegister(i), Address(sp, i));\n+    }\n+    add(sp, sp, total_predicate_in_bytes);\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":90,"deletions":2,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -1338,0 +1338,69 @@\n+  void evpsllw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsllw(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsllvw(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpslld(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpslld(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsllvd(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsllq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsllq(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsllvq(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrlw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrlw(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsrlvw(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrld(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrld(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsrlvd(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrlq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrlq(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsrlvq(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsraw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsraw(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsravw(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsrad(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsrad(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsravd(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+  void evpsraq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len, bool is_varshift) {\n+    if (!is_varshift) {\n+      Assembler::evpsraq(dst, mask, nds, src, merge, vector_len);\n+    } else {\n+      Assembler::evpsravq(dst, mask, nds, src, merge, vector_len);\n+    }\n+  }\n+\n+  void evpmins(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evpmaxs(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evpmins(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+  void evpmaxs(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n@@ -1627,1 +1696,27 @@\n-  \/\/ Data\n+  \/\/ AVX-512 mask operations.\n+  void kand(BasicType etype, KRegister dst, KRegister src1, KRegister src2);\n+  void kor(BasicType type, KRegister dst, KRegister src1, KRegister src2);\n+  void knot(uint masklen, KRegister dst, KRegister src, KRegister ktmp = knoreg, Register rtmp = noreg);\n+  void kxor(BasicType type, KRegister dst, KRegister src1, KRegister src2);\n+  void kortest(uint masklen, KRegister src1, KRegister src2);\n+  void ktest(uint masklen, KRegister src1, KRegister src2);\n+\n+  void evperm(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evperm(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evand(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evand(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evxor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+  void evxor(BasicType type, XMMRegister dst, KRegister mask, XMMRegister nds, Address src, bool merge, int vector_len);\n+\n+  void evrold(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src, int shift, bool merge, int vlen_enc);\n+  void evrold(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc);\n+  void evrord(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src, int shift, bool merge, int vlen_enc);\n+  void evrord(BasicType type, XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vlen_enc);\n+\n+  void alltrue(Register dst, uint masklen, KRegister src1, KRegister src2, KRegister kscratch);\n+  void anytrue(Register dst, uint masklen, KRegister src, KRegister kscratch);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":96,"deletions":1,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -7673,0 +7673,1 @@\n+    StubRoutines::x86::_vector_int_mask_cmp_bits = generate_vector_mask(\"vector_int_mask_cmp_bits\", 0x0000000100000001);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+address StubRoutines::x86::_vector_int_mask_cmp_bits = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -168,0 +168,1 @@\n+  static address _vector_int_mask_cmp_bits;\n@@ -292,0 +293,4 @@\n+  static address vector_int_mask_cmp_bits() {\n+    return _vector_int_mask_cmp_bits;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -817,1 +817,8 @@\n-   do_signature(vector_unary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/util\/function\/Function;)Ljava\/lang\/Object;\") \\\n+   do_signature(vector_unary_op_sig, \"(I\"                                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;Ljava\/lang\/Class;\"                                                                     \\\n+                                      \"I\"                                                                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$UnaryOperation;)\"                                                 \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                         \\\n@@ -821,2 +828,10 @@\n-   do_signature(vector_binary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                              \\\n-                                       \"Ljava\/util\/function\/BiFunction;)Ljava\/lang\/Object;\")                                                   \\\n+   do_signature(vector_binary_op_sig, \"(I\"                                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"I\"                                                                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\"                                                  \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\"                                                  \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$BinaryOperation;)\"                                               \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                 \\\n@@ -826,2 +841,11 @@\n-   do_signature(vector_ternary_op_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;\"                             \\\n-                                        \"Ljava\/lang\/Object;Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryOperation;)Ljava\/lang\/Object;\")        \\\n+   do_signature(vector_ternary_op_sig, \"(I\"                                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"I\"                                                                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                        \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                        \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                        \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$TernaryOperation;)\"                                             \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                       \\\n@@ -831,2 +855,7 @@\n-   do_signature(vector_broadcast_coerced_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;IJLjdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"      \\\n-                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$BroadcastOperation;)Ljava\/lang\/Object;\")                 \\\n+   do_signature(vector_broadcast_coerced_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"I\"                                                                                             \\\n+                                               \"J\"                                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                          \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$BroadcastOperation;)\"                                    \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                         \\\n@@ -836,2 +865,6 @@\n-   do_signature(vector_shuffle_step_iota_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"        \\\n-                                               \"IIIILjdk\/internal\/vm\/vector\/VectorSupport$ShuffleIotaOperation;)Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\") \\\n+   do_signature(vector_shuffle_step_iota_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                          \\\n+                                               \"IIII\"                                                                                          \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$ShuffleIotaOperation;)\"                                  \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\")                                         \\\n@@ -841,2 +874,6 @@\n-   do_signature(vector_shuffle_to_vector_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\" \\\n-                                               \"ILjdk\/internal\/vm\/vector\/VectorSupport$ShuffleToVectorOperation;)Ljava\/lang\/Object;\")          \\\n+   do_signature(vector_shuffle_to_vector_sig, \"(Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\"                                          \\\n+                                               \"ILjdk\/internal\/vm\/vector\/VectorSupport$ShuffleToVectorOperation;)\"                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                \\\n@@ -846,2 +883,10 @@\n-   do_signature(vector_load_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjava\/lang\/Object;\"                                \\\n-                                     \"ILjdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;Ljdk\/internal\/vm\/vector\/VectorSupport$LoadOperation;)Ljava\/lang\/Object;\") \\\n+   do_signature(vector_load_op_sig, \"(Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"J\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                                    \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$LoadOperation;)\"                                                   \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                   \\\n@@ -850,0 +895,15 @@\n+  do_intrinsic(_VectorLoadMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_load_masked_op_name, vector_load_masked_op_sig, F_S)          \\\n+   do_signature(vector_load_masked_op_sig, \"(Ljava\/lang\/Class;\"                                                                                \\\n+                                            \"Ljava\/lang\/Class;\"                                                                                \\\n+                                            \"Ljava\/lang\/Class;\"                                                                                \\\n+                                            \"I\"                                                                                                \\\n+                                            \"Ljava\/lang\/Object;\"                                                                               \\\n+                                            \"J\"                                                                                                \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                \\\n+                                            \"Ljava\/lang\/Object;\"                                                                               \\\n+                                            \"I\"                                                                                                \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorSpecies;\"                                             \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$LoadVectorMaskedOperation;)\"                                \\\n+                                            \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                   \\\n+   do_name(vector_load_masked_op_name,     \"loadMasked\")                                                                                       \\\n+                                                                                                                                               \\\n@@ -851,2 +911,8 @@\n-   do_signature(vector_store_op_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;JLjdk\/internal\/vm\/vector\/VectorSupport$Vector;\"    \\\n-                                      \"Ljava\/lang\/Object;ILjdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperation;)V\")                      \\\n+   do_signature(vector_store_op_sig, \"(Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"I\"                                                                                                      \\\n+                                      \"Ljava\/lang\/Object;\"                                                                                     \\\n+                                      \"J\"                                                                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljava\/lang\/Object;ILjdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperation;)\"                        \\\n+                                      \"V\")                                                                                                     \\\n@@ -855,2 +921,25 @@\n-  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S) \\\n-   do_signature(vector_reduction_coerced_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljava\/util\/function\/Function;)J\") \\\n+  do_intrinsic(_VectorStoreMaskedOp, jdk_internal_vm_vector_VectorSupport, vector_store_masked_op_name, vector_store_masked_op_sig, F_S)       \\\n+   do_signature(vector_store_masked_op_sig, \"(Ljava\/lang\/Class;\"                                                                               \\\n+                                             \"Ljava\/lang\/Class;\"                                                                               \\\n+                                             \"Ljava\/lang\/Class;\"                                                                               \\\n+                                             \"I\"                                                                                               \\\n+                                             \"Ljava\/lang\/Object;\"                                                                              \\\n+                                             \"J\"                                                                                               \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                   \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                               \\\n+                                             \"Ljava\/lang\/Object;\"                                                                              \\\n+                                             \"I\"                                                                                               \\\n+                                             \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorMaskedOperation;)\"                              \\\n+                                             \"V\")                                                                                              \\\n+   do_name(vector_store_masked_op_name,     \"storeMasked\")                                                                                     \\\n+                                                                                                                                               \\\n+  do_intrinsic(_VectorReductionCoerced, jdk_internal_vm_vector_VectorSupport, vector_reduction_coerced_name, vector_reduction_coerced_sig, F_S)\\\n+   do_signature(vector_reduction_coerced_sig, \"(I\"                                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"Ljava\/lang\/Class;\"                                                                             \\\n+                                               \"I\"                                                                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                 \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                             \\\n+                                               \"Ljdk\/internal\/vm\/vector\/VectorSupport$ReductionOperation;)\"                                    \\\n+                                               \"J\")                                                                                            \\\n@@ -860,1 +949,8 @@\n-   do_signature(vector_test_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;Ljava\/lang\/Object;Ljava\/util\/function\/BiFunction;)Z\") \\\n+   do_signature(vector_test_sig, \"(I\"                                                                                                          \\\n+                                  \"Ljava\/lang\/Class;\"                                                                                          \\\n+                                  \"Ljava\/lang\/Class;\"                                                                                          \\\n+                                  \"I\"                                                                                                          \\\n+                                  \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                          \\\n+                                  \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                          \\\n+                                  \"Ljava\/util\/function\/BiFunction;)\"                                                                           \\\n+                                  \"Z\")                                                                                                         \\\n@@ -864,3 +960,9 @@\n-   do_signature(vector_blend_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                      \\\n-                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\" \\\n-                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBlendOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")       \\\n+   do_signature(vector_blend_sig, \"(Ljava\/lang\/Class;\"                                                                                         \\\n+                                   \"Ljava\/lang\/Class;\"                                                                                         \\\n+                                   \"Ljava\/lang\/Class;\"                                                                                         \\\n+                                   \"I\"                                                                                                         \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                             \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                             \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                         \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBlendOp;)\"                                                     \\\n+                                   \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                            \\\n@@ -870,3 +972,9 @@\n-   do_signature(vector_compare_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                   \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\" \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"           \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorCompareOp;\" \")\" \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\") \\\n+   do_signature(vector_compare_sig, \"(I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;Ljava\/lang\/Class;\"                                                                      \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                           \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                           \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorCompareOp;)\"                                                 \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\")                                                      \\\n@@ -876,3 +984,10 @@\n-   do_signature(vector_rearrange_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                  \\\n-                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\"     \\\n-                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorRearrangeOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\") \\\n+   do_signature(vector_rearrange_sig, \"(Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"Ljava\/lang\/Class;\"                                                                                     \\\n+                                       \"I\"                                                                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                         \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorShuffle;\"                                                  \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                     \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorRearrangeOp;)\"                                             \\\n+                                       \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                        \\\n@@ -882,3 +997,7 @@\n-   do_signature(vector_extract_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                     \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;I\"                                                          \\\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecExtractOp;)J\")                                                  \\\n+   do_signature(vector_extract_sig, \"(Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                           \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecExtractOp;)\"                                                    \\\n+                                     \"J\")                                                                                                      \\\n@@ -888,3 +1007,7 @@\n-   do_signature(vector_insert_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                      \\\n-                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;IJ\"                                                          \\\n-                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecInsertOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")        \\\n+   do_signature(vector_insert_sig, \"(Ljava\/lang\/Class;\"                                                                                        \\\n+                                    \"Ljava\/lang\/Class;\"                                                                                        \\\n+                                    \"I\"                                                                                                        \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                            \\\n+                                    \"IJ\"                                                                                                       \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$VecInsertOp;)\"                                                      \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                           \\\n@@ -894,3 +1017,10 @@\n-   do_signature(vector_broadcast_int_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;I\"                                                              \\\n-                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;I\"                                                    \\\n-                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBroadcastIntOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\") \\\n+   do_signature(vector_broadcast_int_sig, \"(I\"                                                                                                 \\\n+                                           \"Ljava\/lang\/Class;\"                                                                                 \\\n+                                           \"Ljava\/lang\/Class;\"                                                                                 \\\n+                                           \"Ljava\/lang\/Class;\"                                                                                 \\\n+                                           \"I\"                                                                                                 \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                     \\\n+                                           \"I\"                                                                                                 \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                 \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorBroadcastIntOp;)\"                                      \\\n+                                           \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\")                                                    \\\n@@ -900,2 +1030,7 @@\n-   do_signature(vector_convert_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                    \\\n-                                     \"Ljava\/lang\/Class;Ljava\/lang\/Class;I\"                                                                     \\\n+   do_signature(vector_convert_sig, \"(I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n@@ -904,1 +1039,2 @@\n-                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorConvertOp;)Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\") \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorConvertOp;)\"                                                 \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                   \\\n@@ -908,2 +1044,7 @@\n-    do_signature(vector_gather_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                                    \\\n-                                     \"Ljava\/lang\/Object;J\"                                                                                     \\\n+    do_signature(vector_gather_sig, \"(Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"I\"                                                                                                       \\\n+                                     \"Ljava\/lang\/Class;\"                                                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"J\"                                                                                                       \\\n@@ -911,1 +1052,3 @@\n-                                     \"Ljava\/lang\/Object;I[II\"                                                                                  \\\n+                                     \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                       \\\n+                                     \"Ljava\/lang\/Object;\"                                                                                      \\\n+                                     \"I[II\"                                                                                                    \\\n@@ -918,5 +1061,13 @@\n-    do_signature(vector_scatter_sig, \"(Ljava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Class;\"                                                   \\\n-                                      \"Ljava\/lang\/Object;J\"                                                                                    \\\n-                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"             \\\n-                                      \"Ljava\/lang\/Object;I[II\"                                                                                 \\\n-                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperationWithMap;)V\")                                  \\\n+    do_signature(vector_scatter_sig, \"(Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"I\"                                                                                                      \\\n+                                      \"Ljava\/lang\/Class;\"                                                                                      \\\n+                                      \"Ljava\/lang\/Object;\"                                                                                     \\\n+                                      \"J\"                                                                                                      \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$Vector;\"                                                          \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;Ljava\/lang\/Object;\"                                    \\\n+                                      \"I[II\"                                                                                                   \\\n+                                      \"Ljdk\/internal\/vm\/vector\/VectorSupport$StoreVectorOperationWithMap;)\"                                    \\\n+                                      \"V\")                                                                                                     \\\n@@ -926,1 +1077,2 @@\n-   do_alias(vector_rebox_sig, object_object_signature)                                                                                         \\\n+    do_signature(vector_rebox_sig, \"(Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;)\"                                                    \\\n+                                    \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorPayload;\")                                                    \\\n@@ -930,2 +1082,7 @@\n-    do_signature(vector_mask_oper_sig, \"(ILjava\/lang\/Class;Ljava\/lang\/Class;ILjava\/lang\/Object;\"                                               \\\n-                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMaskOp;)I\")                                               \\\n+    do_signature(vector_mask_oper_sig, \"(I\"                                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"Ljava\/lang\/Class;\"                                                                                    \\\n+                                        \"I\"                                                                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMask;\"                                                    \\\n+                                        \"Ljdk\/internal\/vm\/vector\/VectorSupport$VectorMaskOp;)\"                                                 \\\n+                                        \"J\")                                                                                                   \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":207,"deletions":50,"binary":false,"changes":257,"status":"modified"},{"patch":"@@ -682,0 +682,1 @@\n+  case vmIntrinsics::_VectorLoadMaskedOp:\n@@ -683,0 +684,1 @@\n+  case vmIntrinsics::_VectorStoreMaskedOp:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2365,0 +2365,1 @@\n+         n->req() == 2 &&\n@@ -2372,1 +2373,1 @@\n-      return true;\n+      return n->req() == 2;\n@@ -3431,0 +3432,2 @@\n+  case Op_LoadVectorGatherMasked:\n+  case Op_StoreVectorScatterMasked:\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -705,1 +705,2 @@\n-        case Op_StoreVectorScatter:\n+        case Op_StoreVectorScatter:\n+        case Op_StoreVectorScatterMasked:\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -653,0 +653,2 @@\n+  case vmIntrinsics::_VectorLoadMaskedOp:\n+    return inline_vector_mem_masked_operation(\/*is_store*\/false);\n@@ -655,0 +657,2 @@\n+  case vmIntrinsics::_VectorStoreMaskedOp:\n+    return inline_vector_mem_masked_operation(\/*is_store=*\/true);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -321,0 +321,1 @@\n+  bool inline_vector_mem_masked_operation(bool is_store);\n@@ -334,4 +335,5 @@\n-    VecMaskUseLoad,\n-    VecMaskUseStore,\n-    VecMaskUseAll,\n-    VecMaskNotUsed\n+    VecMaskUseLoad  = 1 << 0,\n+    VecMaskUseStore = 1 << 1,\n+    VecMaskUseAll   = VecMaskUseLoad | VecMaskUseStore,\n+    VecMaskUsePred  = 1 << 2,\n+    VecMaskNotUsed  = 1 << 3\n@@ -341,1 +343,1 @@\n-  bool arch_supports_vector_rotate(int opc, int num_elem, BasicType elem_bt, bool has_scalar_args = false);\n+  bool arch_supports_vector_rotate(int opc, int num_elem, BasicType elem_bt, VectorMaskUseType mask_use_type, bool has_scalar_args = false);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":7,"deletions":5,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1138,1 +1138,1 @@\n-      if (store_Opcode() == Op_StoreVector) {\n+      if (st->is_StoreVector()) {\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1000,1 +1000,0 @@\n-\n@@ -2362,1 +2361,4 @@\n-const TypeVect* TypeVect::make(const Type *elem, uint length) {\n+const TypeVect* TypeVect::make(const Type *elem, uint length, bool is_mask) {\n+  if (is_mask) {\n+    return makemask(elem, length);\n+  }\n@@ -2388,1 +2390,3 @@\n-  if (Matcher::has_predicated_vectors()) {\n+  BasicType elem_bt = elem->array_element_basic_type();\n+  if (Matcher::has_predicated_vectors() &&\n+      Matcher::match_rule_supported_vector_masked(Op_VectorLoadMask, length, elem_bt)) {\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -807,1 +807,1 @@\n-  static const TypeVect *make(const BasicType elem_bt, uint length) {\n+  static const TypeVect *make(const BasicType elem_bt, uint length, bool is_mask = false) {\n@@ -809,1 +809,1 @@\n-    return make(get_const_basic_type(elem_bt), length);\n+    return make(get_const_basic_type(elem_bt), length, is_mask);\n@@ -812,1 +812,1 @@\n-  static const TypeVect *make(const Type* elem, uint length);\n+  static const TypeVect *make(const Type* elem, uint length, bool is_mask = false);\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -62,40 +62,78 @@\n-bool LibraryCallKit::arch_supports_vector_rotate(int opc, int num_elem, BasicType elem_bt, bool has_scalar_args) {\n-    bool is_supported = true;\n-    \/\/ has_scalar_args flag is true only for non-constant scalar shift count,\n-    \/\/ since in this case shift needs to be broadcasted.\n-    if (!Matcher::match_rule_supported_vector(opc, num_elem, elem_bt) ||\n-         (has_scalar_args &&\n-           !arch_supports_vector(VectorNode::replicate_opcode(elem_bt), num_elem, elem_bt, VecMaskNotUsed))) {\n-      is_supported = false;\n-    }\n-\n-    int lshiftopc, rshiftopc;\n-    switch(elem_bt) {\n-      case T_BYTE:\n-        lshiftopc = Op_LShiftI;\n-        rshiftopc = Op_URShiftB;\n-        break;\n-      case T_SHORT:\n-        lshiftopc = Op_LShiftI;\n-        rshiftopc = Op_URShiftS;\n-        break;\n-      case T_INT:\n-        lshiftopc = Op_LShiftI;\n-        rshiftopc = Op_URShiftI;\n-        break;\n-      case T_LONG:\n-        lshiftopc = Op_LShiftL;\n-        rshiftopc = Op_URShiftL;\n-        break;\n-      default:\n-        assert(false, \"Unexpected type\");\n-    }\n-    int lshiftvopc = VectorNode::opcode(lshiftopc, elem_bt);\n-    int rshiftvopc = VectorNode::opcode(rshiftopc, elem_bt);\n-    if (!is_supported &&\n-        arch_supports_vector(lshiftvopc, num_elem, elem_bt, VecMaskNotUsed, has_scalar_args) &&\n-        arch_supports_vector(rshiftvopc, num_elem, elem_bt, VecMaskNotUsed, has_scalar_args) &&\n-        arch_supports_vector(Op_OrV, num_elem, elem_bt, VecMaskNotUsed)) {\n-      is_supported = true;\n-    }\n-    return is_supported;\n+static bool is_vector_mask(ciKlass* klass) {\n+  return klass->is_subclass_of(ciEnv::current()->vector_VectorMask_klass());\n+}\n+\n+static bool is_vector_shuffle(ciKlass* klass) {\n+  return klass->is_subclass_of(ciEnv::current()->vector_VectorShuffle_klass());\n+}\n+\n+bool LibraryCallKit::arch_supports_vector_rotate(int opc, int num_elem, BasicType elem_bt,\n+                                                 VectorMaskUseType mask_use_type, bool has_scalar_args) {\n+  bool is_supported = true;\n+\n+  \/\/ has_scalar_args flag is true only for non-constant scalar shift count,\n+  \/\/ since in this case shift needs to be broadcasted.\n+  if (!Matcher::match_rule_supported_vector(opc, num_elem, elem_bt) ||\n+       (has_scalar_args &&\n+         !arch_supports_vector(VectorNode::replicate_opcode(elem_bt), num_elem, elem_bt, VecMaskNotUsed))) {\n+    is_supported = false;\n+  }\n+\n+  if (is_supported) {\n+    \/\/ Check whether mask unboxing is supported.\n+    if ((mask_use_type & VecMaskUseLoad) != 0) {\n+      if (!Matcher::match_rule_supported_vector(Op_VectorLoadMask, num_elem, elem_bt)) {\n+      #ifndef PRODUCT\n+        if (C->print_intrinsics()) {\n+          tty->print_cr(\"  ** Rejected vector mask loading (%s,%s,%d) because architecture does not support it\",\n+                        NodeClassNames[Op_VectorLoadMask], type2name(elem_bt), num_elem);\n+        }\n+      #endif\n+        return false;\n+      }\n+    }\n+\n+    if ((mask_use_type & VecMaskUsePred) != 0) {\n+      if (!Matcher::has_predicated_vectors() ||\n+          !Matcher::match_rule_supported_vector_masked(opc, num_elem, elem_bt)) {\n+      #ifndef PRODUCT\n+        if (C->print_intrinsics()) {\n+          tty->print_cr(\"Rejected vector mask predicate using (%s,%s,%d) because architecture does not support it\",\n+                        NodeClassNames[opc], type2name(elem_bt), num_elem);\n+        }\n+      #endif\n+        return false;\n+      }\n+    }\n+  }\n+\n+  int lshiftopc, rshiftopc;\n+  switch(elem_bt) {\n+    case T_BYTE:\n+      lshiftopc = Op_LShiftI;\n+      rshiftopc = Op_URShiftB;\n+      break;\n+    case T_SHORT:\n+      lshiftopc = Op_LShiftI;\n+      rshiftopc = Op_URShiftS;\n+      break;\n+    case T_INT:\n+      lshiftopc = Op_LShiftI;\n+      rshiftopc = Op_URShiftI;\n+      break;\n+    case T_LONG:\n+      lshiftopc = Op_LShiftL;\n+      rshiftopc = Op_URShiftL;\n+      break;\n+    default:\n+      assert(false, \"Unexpected type\");\n+  }\n+  int lshiftvopc = VectorNode::opcode(lshiftopc, elem_bt);\n+  int rshiftvopc = VectorNode::opcode(rshiftopc, elem_bt);\n+  if (!is_supported &&\n+      arch_supports_vector(lshiftvopc, num_elem, elem_bt, VecMaskNotUsed, has_scalar_args) &&\n+      arch_supports_vector(rshiftvopc, num_elem, elem_bt, VecMaskNotUsed, has_scalar_args) &&\n+      arch_supports_vector(Op_OrV, num_elem, elem_bt, VecMaskNotUsed)) {\n+    is_supported = true;\n+  }\n+  return is_supported;\n@@ -118,1 +156,1 @@\n-  const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+  const TypeVect* vt = TypeVect::make(elem_bt, num_elem, is_vector_mask(vbox_type->klass()));\n@@ -133,1 +171,1 @@\n-  const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+  const TypeVect* vt = TypeVect::make(elem_bt, num_elem, is_vector_mask(vbox_type->klass()));\n@@ -158,1 +196,1 @@\n-    if(!arch_supports_vector_rotate(sopc, num_elem, type, has_scalar_args)) {\n+    if(!arch_supports_vector_rotate(sopc, num_elem, type, mask_use_type, has_scalar_args)) {\n@@ -216,1 +254,1 @@\n-  if (mask_use_type == VecMaskUseAll || mask_use_type == VecMaskUseLoad) {\n+  if ((mask_use_type & VecMaskUseLoad) != 0) {\n@@ -229,1 +267,1 @@\n-  if (mask_use_type == VecMaskUseAll || mask_use_type == VecMaskUseStore) {\n+  if ((mask_use_type & VecMaskUseStore) != 0) {\n@@ -241,6 +279,12 @@\n-  return true;\n-}\n-\n-static bool is_vector_mask(ciKlass* klass) {\n-  return klass->is_subclass_of(ciEnv::current()->vector_VectorMask_klass());\n-}\n+  if ((mask_use_type & VecMaskUsePred) != 0) {\n+    if (!Matcher::has_predicated_vectors() ||\n+        !Matcher::match_rule_supported_vector_masked(sopc, num_elem, type)) {\n+    #ifndef PRODUCT\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"Rejected vector mask predicate using (%s,%s,%d) because architecture does not support it\",\n+                      NodeClassNames[sopc], type2name(type), num_elem);\n+      }\n+    #endif\n+      return false;\n+    }\n+  }\n@@ -248,2 +292,1 @@\n-static bool is_vector_shuffle(ciKlass* klass) {\n-  return klass->is_subclass_of(ciEnv::current()->vector_VectorShuffle_klass());\n+  return true;\n@@ -262,4 +305,6 @@\n-\/\/ <VM>\n-\/\/ VM unaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/            VM vm,\n-\/\/            Function<VM, VM> defaultImpl) {\n+\/\/ <V extends Vector<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ V unaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<E> elementType,\n+\/\/           int length, V v, M m,\n+\/\/           UnaryOperation<V, M> defaultImpl)\n@@ -268,4 +313,6 @@\n-\/\/ <VM>\n-\/\/ VM binaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/             VM vm1, VM vm2,\n-\/\/             BiFunction<VM, VM, VM> defaultImpl) {\n+\/\/ <V,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ V binaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<E> elementType,\n+\/\/            int length, V v1, V v2, M m,\n+\/\/            BinaryOperation<V, M> defaultImpl)\n@@ -274,4 +321,6 @@\n-\/\/ <VM>\n-\/\/ VM ternaryOp(int oprId, Class<? extends VM> vmClass, Class<?> elementType, int length,\n-\/\/              VM vm1, VM vm2, VM vm3,\n-\/\/              TernaryOperation<VM> defaultImpl) {\n+\/\/ <V extends Vector<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ V ternaryOp(int oprId, Class<? extends V> vmClass, Class<? extends M> maskClass, Class<E> elementType,\n+\/\/             int length, V v1, V v2, V v3, M m,\n+\/\/             TernaryOperation<V, M> defaultImpl)\n@@ -282,2 +331,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -291,2 +341,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -296,0 +346,1 @@\n+\n@@ -309,0 +360,28 @@\n+\n+  \/\/ \"argument(n + 5)\" should be the mask object. We assume it is \"null\" when no mask\n+  \/\/ is used to control this operation.\n+  const Type* vmask_type = gvn().type(argument(n + 5));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -331,0 +410,4 @@\n+  if (is_vector_mask(vbox_klass)) {\n+    assert(!is_masked_op, \"mask operations do not need mask to control\");\n+  }\n+\n@@ -353,3 +436,4 @@\n-  \/\/ TODO When mask usage is supported, VecMaskNotUsed needs to be VecMaskUseLoad.\n-  if ((sopc != 0) &&\n-      !arch_supports_vector(sopc, num_elem, elem_bt, is_vector_mask(vbox_klass) ? VecMaskUseAll : VecMaskNotUsed)) {\n+  \/\/ When using mask, mask use type needs to be VecMaskUseLoad.\n+  VectorMaskUseType mask_use_type = is_vector_mask(vbox_klass) ? VecMaskUseAll\n+                                      : is_masked_op ? VecMaskUseLoad : VecMaskNotUsed;\n+  if ((sopc != 0) && !arch_supports_vector(sopc, num_elem, elem_bt, mask_use_type)) {\n@@ -357,1 +441,1 @@\n-      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=%d\",\n+      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=%d is_masked_op=%d\",\n@@ -359,1 +443,1 @@\n-                    is_vector_mask(vbox_klass) ? 1 : 0);\n+                    is_vector_mask(vbox_klass) ? 1 : 0, is_masked_op ? 1 : 0);\n@@ -364,0 +448,10 @@\n+  \/\/ Return true if current platform has implemented the masked operation with predicate feature.\n+  bool use_predicate = is_masked_op && sopc != 0 && arch_supports_vector(sopc, num_elem, elem_bt, VecMaskUsePred);\n+  if (is_masked_op && !use_predicate && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=%d opc=%d vlen=%d etype=%s ismask=0 is_masked_op=1\",\n+                    n, sopc, num_elem, type2name(elem_bt));\n+    }\n+    return false;\n+  }\n+\n@@ -367,1 +461,1 @@\n-      opd3 = unbox_vector(argument(6), vbox_type, elem_bt, num_elem);\n+      opd3 = unbox_vector(argument(7), vbox_type, elem_bt, num_elem);\n@@ -371,1 +465,1 @@\n-                        NodeClassNames[argument(6)->Opcode()]);\n+                        NodeClassNames[argument(7)->Opcode()]);\n@@ -378,1 +472,1 @@\n-      opd2 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n+      opd2 = unbox_vector(argument(6), vbox_type, elem_bt, num_elem);\n@@ -382,1 +476,1 @@\n-                        NodeClassNames[argument(5)->Opcode()]);\n+                        NodeClassNames[argument(6)->Opcode()]);\n@@ -389,1 +483,1 @@\n-      opd1 = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n+      opd1 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n@@ -393,1 +487,1 @@\n-                        NodeClassNames[argument(4)->Opcode()]);\n+                        NodeClassNames[argument(5)->Opcode()]);\n@@ -402,0 +496,15 @@\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    assert(is_vector_mask(mbox_klass), \"argument(2) should be a mask class\");\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(n + 5), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                      NodeClassNames[argument(n + 5)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -416,1 +525,1 @@\n-    const TypeVect* vt = TypeVect::make(elem_bt, num_elem);\n+    const TypeVect* vt = TypeVect::make(elem_bt, num_elem, is_vector_mask(vbox_klass));\n@@ -420,1 +529,1 @@\n-        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, vt));\n+        operation = VectorNode::make(sopc, opd1, opd2, vt, is_vector_mask(vbox_klass));\n@@ -424,1 +533,1 @@\n-        operation = gvn().transform(VectorNode::make(sopc, opd1, opd2, opd3, vt));\n+        operation = VectorNode::make(sopc, opd1, opd2, opd3, vt);\n@@ -430,0 +539,12 @@\n+\n+  if (is_masked_op && mask != NULL) {\n+    if (use_predicate) {\n+      operation->add_req(mask);\n+      operation->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      operation = gvn().transform(operation);\n+      operation = new VectorBlendNode(opd1, operation, mask);\n+    }\n+  }\n+  operation = gvn().transform(operation);\n+\n@@ -438,1 +559,1 @@\n-\/\/  Sh ShuffleIota(Class<?> E, Class<?> ShuffleClass, Vector.Species<E> s, int length,\n+\/\/  Sh ShuffleIota(Class<?> E, Class<?> shuffleClass, Vector.Species<E> s, int length,\n@@ -515,1 +636,2 @@\n-    Node* mask = gvn().transform(new VectorMaskCmpNode(BoolTest::ge, bcast_lane_cnt, res, pred_node, vt));\n+    const TypeVect* vmask_type = TypeVect::makemask(elem_bt, num_elem);\n+    Node* mask = gvn().transform(new VectorMaskCmpNode(BoolTest::ge, bcast_lane_cnt, res, pred_node, vmask_type));\n@@ -534,1 +656,1 @@\n-\/\/ int maskReductionCoerced(int oper, Class<? extends M> maskClass, Class<?> elemClass,\n+\/\/ long maskReductionCoerced(int oper, Class<? extends M> maskClass, Class<?> elemClass,\n@@ -579,2 +701,8 @@\n-  Node* store_mask = gvn().transform(VectorStoreMaskNode::make(gvn(), mask_vec, elem_bt, num_elem));\n-  Node* maskoper = gvn().transform(VectorMaskOpNode::make(store_mask, TypeInt::INT, mopc));\n+  if (mask_vec->bottom_type()->isa_vectmask() == NULL) {\n+    mask_vec = gvn().transform(VectorStoreMaskNode::make(gvn(), mask_vec, elem_bt, num_elem));\n+  }\n+  const Type* maskoper_ty = mopc == Op_VectorMaskToLong ? (const Type*)TypeLong::LONG : (const Type*)TypeInt::INT;\n+  Node* maskoper = gvn().transform(VectorMaskOpNode::make(mask_vec, maskoper_ty, mopc));\n+  if (mopc != Op_VectorMaskToLong) {\n+    maskoper = ConvI2L(maskoper);\n+  }\n@@ -587,3 +715,7 @@\n-\/\/ <VM ,Sh extends VectorShuffle<E>, E>\n-\/\/ VM shuffleToVector(Class<VM> VecClass, Class<?>E , Class<?> ShuffleClass, Sh s, int length,\n-\/\/                    ShuffleToVectorOperation<VM,Sh,E> defaultImpl)\n+\/\/ public static\n+\/\/ <V,\n+\/\/  Sh extends VectorShuffle<E>,\n+\/\/  E>\n+\/\/ V shuffleToVector(Class<? extends Vector<E>> vclass, Class<E> elementType,\n+\/\/                   Class<? extends Sh> shuffleClass, Sh s, int length,\n+\/\/                   ShuffleToVectorOperation<V, Sh, E> defaultImpl)\n@@ -648,4 +780,7 @@\n-\/\/ <V extends Vector<?,?>>\n-\/\/ V broadcastCoerced(Class<?> vectorClass, Class<?> elementType, int vlen,\n-\/\/                    long bits,\n-\/\/                    LongFunction<V> defaultImpl)\n+\/\/ public static\n+\/\/ <M,\n+\/\/  S extends VectorSpecies<E>,\n+\/\/  E>\n+\/\/ M broadcastCoerced(Class<? extends M> vmClass, Class<E> elementType, int length,\n+\/\/                    long bits, S s,\n+\/\/                    BroadcastOperation<M, E, S> defaultImpl)\n@@ -698,1 +833,0 @@\n-\n@@ -725,1 +859,1 @@\n-  Node* broadcast = VectorNode::scalar2vector(elem, num_elem, Type::get_const_basic_type(elem_bt));\n+  Node* broadcast = VectorNode::scalar2vector(elem, num_elem, Type::get_const_basic_type(elem_bt), is_vector_mask(vbox_klass));\n@@ -750,6 +884,9 @@\n-\/\/    <C, V extends Vector<?,?>>\n-\/\/    V load(Class<?> vectorClass, Class<?> elementType, int vlen,\n-\/\/           Object base, long offset,\n-\/\/           \/* Vector.Mask<E,S> m*\/\n-\/\/           Object container, int index,\n-\/\/           LoadOperation<C, VM> defaultImpl) {\n+\/\/ public static\n+\/\/ <C,\n+\/\/  VM,\n+\/\/  E,\n+\/\/  S extends VectorSpecies<E>>\n+\/\/ VM load(Class<? extends VM> vmClass, Class<E> elementType, int length,\n+\/\/         Object base, long offset,    \/\/ Unsafe addressing\n+\/\/         C container, int index, S s,     \/\/ Arguments for default implementation\n+\/\/         LoadOperation<C, VM, E, S> defaultImpl)\n@@ -757,6 +894,8 @@\n-\/\/    <C, V extends Vector<?,?>>\n-\/\/    void store(Class<?> vectorClass, Class<?> elementType, int vlen,\n-\/\/               Object base, long offset,\n-\/\/               V v, \/*Vector.Mask<E,S> m*\/\n-\/\/               Object container, int index,\n-\/\/               StoreVectorOperation<C, V> defaultImpl) {\n+\/\/ public static\n+\/\/ <C,\n+\/\/  V extends Vector<?>>\n+\/\/ void store(Class<?> vectorClass, Class<?> elementType, int length,\n+\/\/            Object base, long offset,    \/\/ Unsafe addressing\n+\/\/            V v,\n+\/\/            C container, int index,      \/\/ Arguments for default implementation\n+\/\/            StoreVectorOperation<C, V> defaultImpl)\n@@ -926,2 +1065,1 @@\n-        const TypeVect* to_vect_type = TypeVect::make(elem_bt, num_elem);\n-        vload = gvn().transform(new VectorLoadMaskNode(vload, to_vect_type));\n+        vload = gvn().transform(new VectorLoadMaskNode(vload, TypeVect::makemask(elem_bt, num_elem)));\n@@ -946,6 +1084,10 @@\n-\/\/   <C, V extends Vector<?>, W extends IntVector, E, S extends VectorSpecies<E>>\n-\/\/   void loadWithMap(Class<?> vectorClass, Class<E> E, int length, Class<?> vectorIndexClass,\n-\/\/                    Object base, long offset, \/\/ Unsafe addressing\n-\/\/                    W index_vector,\n-\/\/                    C container, int index, int[] indexMap, int indexM, S s, \/\/ Arguments for default implementation\n-\/\/                    LoadVectorOperationWithMap<C, V, E, S> defaultImpl)\n+\/\/ public static\n+\/\/ <C,\n+\/\/  V extends Vector<?>,\n+\/\/  E,\n+\/\/  S extends VectorSpecies<E>,\n+\/\/  M extends VectorMask<E>>\n+\/\/ V loadMasked(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType,\n+\/\/              int length, Object base, long offset, M m,\n+\/\/              C container, int index, S s,  \/\/ Arguments for default implementation\n+\/\/              LoadVectorMaskedOperation<C, V, S, M> defaultImpl) {\n@@ -953,6 +1095,249 @@\n-\/\/    <C, V extends Vector<?>, W extends IntVector>\n-\/\/    void storeWithMap(Class<?> vectorClass, Class<?> elementType, int length, Class<?> vectorIndexClass,\n-\/\/                      Object base, long offset,    \/\/ Unsafe addressing\n-\/\/                      W index_vector, V v,\n-\/\/                      C container, int index, int[] indexMap, int indexM, \/\/ Arguments for default implementation\n-\/\/                      StoreVectorOperationWithMap<C, V> defaultImpl) {\n+\/\/ public static\n+\/\/ <C,\n+\/\/  V extends Vector<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ void storeMasked(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType,\n+\/\/                  int length, Object base, long offset,\n+\/\/                  V v, M m,\n+\/\/                  C container, int index,  \/\/ Arguments for default implementation\n+\/\/                  StoreVectorMaskedOperation<C, V, M, E> defaultImpl) {\n+\/\/\n+bool LibraryCallKit::inline_vector_mem_masked_operation(bool is_store) {\n+  const TypeInstPtr* vector_klass = gvn().type(argument(0))->isa_instptr();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(1))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+\n+  if (vector_klass == NULL || mask_klass == NULL || elem_klass == NULL || vlen == NULL ||\n+      vector_klass->const_oop() == NULL || mask_klass->const_oop() == NULL ||\n+      elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** missing constant: vclass=%s mclass=%s etype=%s vlen=%s\",\n+                    NodeClassNames[argument(0)->Opcode()],\n+                    NodeClassNames[argument(1)->Opcode()],\n+                    NodeClassNames[argument(2)->Opcode()],\n+                    NodeClassNames[argument(3)->Opcode()]);\n+    }\n+    return false; \/\/ not enough info for intrinsification\n+  }\n+  if (!is_klass_initialized(vector_klass)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** klass argument not initialized\");\n+    }\n+    return false;\n+  }\n+\n+  if (!is_klass_initialized(mask_klass)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** mask klass argument not initialized\");\n+    }\n+    return false;\n+  }\n+\n+  ciType* elem_type = elem_klass->const_oop()->as_instance()->java_mirror_type();\n+  if (!elem_type->is_primitive_type()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not a primitive bt=%d\", elem_type->basic_type());\n+    }\n+    return false; \/\/ should be primitive type\n+  }\n+\n+  BasicType elem_bt = elem_type->basic_type();\n+  int num_elem = vlen->get_con();\n+\n+  Node* base = argument(4);\n+  Node* offset = ConvL2X(argument(5));\n+\n+  \/\/ Save state and restore on bailout\n+  uint old_sp = sp();\n+  SafePointNode* old_map = clone_map();\n+\n+  Node* addr = make_unsafe_address(base, offset, elem_bt, true);\n+  const TypePtr *addr_type = gvn().type(addr)->isa_ptr();\n+  const TypeAryPtr* arr_type = addr_type->isa_aryptr();\n+\n+  \/\/ Now handle special case where load\/store happens from\/to byte array but element type is not byte.\n+  bool using_byte_array = arr_type != NULL && arr_type->elem()->array_element_basic_type() == T_BYTE && elem_bt != T_BYTE;\n+  \/\/ If there is no consistency between array and vector element types, it must be special byte array case\n+  if (arr_type != NULL && !using_byte_array && !elem_consistent_with_arr(elem_bt, arr_type)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s atype=%s\",\n+                    is_store, is_store ? \"storeMasked\" : \"loadMasked\",\n+                    num_elem, type2name(elem_bt), type2name(arr_type->elem()->array_element_basic_type()));\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  int mem_num_elem = using_byte_array ? num_elem * type2aelembytes(elem_bt) : num_elem;\n+  BasicType mem_elem_bt = using_byte_array ? T_BYTE : elem_bt;\n+  bool use_predicate = arch_supports_vector(is_store ? Op_StoreVectorMasked : Op_LoadVectorMasked,\n+                                            mem_num_elem, mem_elem_bt,\n+                                            (VectorMaskUseType) (VecMaskUseLoad | VecMaskUsePred));\n+  \/\/ Masked vector store operation needs the architecture predicate feature. We need to check\n+  \/\/ whether the predicated vector operation is supported by backend.\n+  if (is_store && !use_predicate) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: op=storeMasked vlen=%d etype=%s using_byte_array=%d\",\n+                    num_elem, type2name(elem_bt), using_byte_array ? 1 : 0);\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  \/\/ This only happens for masked vector load. If predicate is not supported, then check whether\n+  \/\/ the normal vector load and blend operations are supported by backend.\n+  if (!use_predicate && (!arch_supports_vector(Op_LoadVector, mem_num_elem, mem_elem_bt, VecMaskNotUsed) ||\n+      !arch_supports_vector(Op_VectorBlend, mem_num_elem, mem_elem_bt, VecMaskUseLoad))) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: op=loadMasked vlen=%d etype=%s using_byte_array=%d\",\n+                    num_elem, type2name(elem_bt), using_byte_array ? 1 : 0);\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  \/\/ Since we are using byte array, we need to double check that the vector reinterpret operation\n+  \/\/ with byte type is supported by backend.\n+  if (using_byte_array) {\n+    if (!arch_supports_vector(Op_VectorReinterpret, mem_num_elem, T_BYTE, VecMaskNotUsed)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s using_byte_array=1\",\n+                      is_store, is_store ? \"storeMasked\" : \"loadMasked\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      set_map(old_map);\n+      set_sp(old_sp);\n+      return false;\n+    }\n+  }\n+\n+  \/\/ Since it needs to unbox the mask, we need to double check that the related load operations\n+  \/\/ for mask are supported by backend.\n+  if (!arch_supports_vector(Op_LoadVector, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s\",\n+                      is_store, is_store ? \"storeMasked\" : \"loadMasked\",\n+                      num_elem, type2name(elem_bt));\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  \/\/ Can base be NULL? Otherwise, always on-heap access.\n+  bool can_access_non_heap = TypePtr::NULL_PTR->higher_equal(gvn().type(base));\n+  if (can_access_non_heap) {\n+    insert_mem_bar(Op_MemBarCPUOrder);\n+  }\n+\n+  ciKlass* vbox_klass = vector_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+  ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+  assert(!is_vector_mask(vbox_klass) && is_vector_mask(mbox_klass), \"Invalid class type\");\n+  const TypeInstPtr* vbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, vbox_klass);\n+  const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+\n+  Node* mask = unbox_vector(is_store ? argument(8) : argument(7), mbox_type, elem_bt, num_elem);\n+  if (mask == NULL) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** unbox failed mask=%s\",\n+                    is_store ? NodeClassNames[argument(8)->Opcode()]\n+                             : NodeClassNames[argument(7)->Opcode()]);\n+    }\n+    set_map(old_map);\n+    set_sp(old_sp);\n+    return false;\n+  }\n+\n+  if (is_store) {\n+    Node* val = unbox_vector(argument(7), vbox_type, elem_bt, num_elem);\n+    if (val == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed vector=%s\",\n+                      NodeClassNames[argument(7)->Opcode()]);\n+      }\n+      set_map(old_map);\n+      set_sp(old_sp);\n+      return false; \/\/ operand unboxing failed\n+    }\n+    set_all_memory(reset_memory());\n+\n+    if (using_byte_array) {\n+      \/\/ Reinterpret the incoming vector to byte vector.\n+      const TypeVect* to_vect_type = TypeVect::make(mem_elem_bt, mem_num_elem);\n+      val = gvn().transform(new VectorReinterpretNode(val, val->bottom_type()->is_vect(), to_vect_type));\n+      \/\/ Reinterpret the vector mask to byte type.\n+      const TypeVect* from_mask_type = TypeVect::makemask(elem_bt, num_elem);\n+      const TypeVect* to_mask_type = TypeVect::makemask(mem_elem_bt, mem_num_elem);\n+      mask = gvn().transform(new VectorReinterpretNode(mask, from_mask_type, to_mask_type));\n+    }\n+    Node* vstore = gvn().transform(new StoreVectorMaskedNode(control(), memory(addr), addr, val, addr_type, mask));\n+    set_memory(vstore, addr_type);\n+  } else {\n+    Node* vload = NULL;\n+\n+    if (using_byte_array) {\n+      \/\/ Reinterpret the vector mask to byte type.\n+      const TypeVect* from_mask_type = TypeVect::makemask(elem_bt, num_elem);\n+      const TypeVect* to_mask_type = TypeVect::makemask(mem_elem_bt, mem_num_elem);\n+      mask = gvn().transform(new VectorReinterpretNode(mask, from_mask_type, to_mask_type));\n+    }\n+\n+    if (use_predicate) {\n+      \/\/ Generate masked load vector node if predicate feature is supported.\n+      const TypeVect* vt = TypeVect::make(mem_elem_bt, mem_num_elem);\n+      vload = gvn().transform(new LoadVectorMaskedNode(control(), memory(addr), addr, addr_type, vt, mask));\n+    } else {\n+      \/\/ Use the vector blend to implement the masked load vector. The biased elements are zeros.\n+      Node* zero = gvn().transform(gvn().zerocon(mem_elem_bt));\n+      zero = gvn().transform(VectorNode::scalar2vector(zero, mem_num_elem, Type::get_const_basic_type(mem_elem_bt)));\n+      vload = gvn().transform(LoadVectorNode::make(0, control(), memory(addr), addr, addr_type, mem_num_elem, mem_elem_bt));\n+      vload = gvn().transform(new VectorBlendNode(zero, vload, mask));\n+    }\n+\n+    if (using_byte_array) {\n+      const TypeVect* to_vect_type = TypeVect::make(elem_bt, num_elem);\n+      vload = gvn().transform(new VectorReinterpretNode(vload, vload->bottom_type()->is_vect(), to_vect_type));\n+    }\n+\n+    Node* box = box_vector(vload, vbox_type, elem_bt, num_elem);\n+    set_result(box);\n+  }\n+\n+  old_map->destruct(&_gvn);\n+\n+  if (can_access_non_heap) {\n+    insert_mem_bar(Op_MemBarCPUOrder);\n+  }\n+\n+  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n+  return true;\n+}\n+\n+\/\/ <C,\n+\/\/  V extends Vector<?>,\n+\/\/  W extends Vector<Integer>,\n+\/\/  S extends VectorSpecies<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ V loadWithMap(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType, int length,\n+\/\/               Class<? extends Vector<Integer>> vectorIndexClass,\n+\/\/               Object base, long offset, \/\/ Unsafe addressing\n+\/\/               W index_vector, M m,\n+\/\/               C container, int index, int[] indexMap, int indexM, S s, \/\/ Arguments for default implementation\n+\/\/               LoadVectorOperationWithMap<C, V, E, S, M> defaultImpl)\n+\/\/\n+\/\/  <C,\n+\/\/   V extends Vector<E>,\n+\/\/   W extends Vector<Integer>,\n+\/\/   M extends VectorMask<E>,\n+\/\/   E>\n+\/\/  void storeWithMap(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType,\n+\/\/                    int length, Class<? extends Vector<Integer>> vectorIndexClass, Object base, long offset,    \/\/ Unsafe addressing\n+\/\/                    W index_vector, V v, M m,\n+\/\/                    C container, int index, int[] indexMap, int indexM, \/\/ Arguments for default implementation\n+\/\/                    StoreVectorOperationWithMap<C, V, M, E> defaultImpl)\n@@ -962,3 +1347,4 @@\n-  const TypeInstPtr* elem_klass       = gvn().type(argument(1))->isa_instptr();\n-  const TypeInt*     vlen             = gvn().type(argument(2))->isa_int();\n-  const TypeInstPtr* vector_idx_klass = gvn().type(argument(3))->isa_instptr();\n+  const TypeInstPtr* mask_klass       = gvn().type(argument(1))->isa_instptr();\n+  const TypeInstPtr* elem_klass       = gvn().type(argument(2))->isa_instptr();\n+  const TypeInt*     vlen             = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* vector_idx_klass = gvn().type(argument(4))->isa_instptr();\n@@ -971,2 +1357,2 @@\n-                    NodeClassNames[argument(1)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -984,0 +1370,1 @@\n+\n@@ -991,0 +1378,1 @@\n+\n@@ -994,5 +1382,43 @@\n-  if (!arch_supports_vector(is_scatter ? Op_StoreVectorScatter : Op_LoadVectorGather, num_elem, elem_bt, VecMaskNotUsed)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s ismask=no\",\n-                    is_scatter, is_scatter ? \"scatter\" : \"gather\",\n-                    num_elem, type2name(elem_bt));\n+  const Type* vmask_type = gvn().type(is_scatter ? argument(10) : argument(9));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(1)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+\n+    \/\/ Check whether the predicated gather\/scatter node is supported by architecture.\n+    if (!arch_supports_vector(is_scatter ? Op_StoreVectorScatterMasked : Op_LoadVectorGatherMasked, num_elem, elem_bt,\n+                              (VectorMaskUseType) (VecMaskUseLoad | VecMaskUsePred))) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s is_masked_op=1\",\n+                      is_scatter, is_scatter ? \"scatterMasked\" : \"gatherMasked\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n+    }\n+  } else {\n+    \/\/ Check whether the normal gather\/scatter node is supported for non-masked operation.\n+    if (!arch_supports_vector(is_scatter ? Op_StoreVectorScatter : Op_LoadVectorGather, num_elem, elem_bt, VecMaskNotUsed)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s vlen=%d etype=%s is_masked_op=0\",\n+                      is_scatter, is_scatter ? \"scatter\" : \"gather\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n@@ -1000,1 +1426,0 @@\n-    return false; \/\/ not supported\n@@ -1006,1 +1431,1 @@\n-        tty->print_cr(\"  ** not supported: arity=%d op=%s\/loadindex vlen=%d etype=int ismask=no\",\n+        tty->print_cr(\"  ** not supported: arity=%d op=%s\/loadindex vlen=%d etype=int is_masked_op=%d\",\n@@ -1008,1 +1433,1 @@\n-                      num_elem);\n+                      num_elem, is_masked_op ? 1 : 0);\n@@ -1011,1 +1436,1 @@\n-    }\n+  }\n@@ -1013,2 +1438,2 @@\n-  Node* base = argument(4);\n-  Node* offset = ConvL2X(argument(5));\n+  Node* base = argument(5);\n+  Node* offset = ConvL2X(argument(6));\n@@ -1036,0 +1461,1 @@\n+\n@@ -1038,2 +1464,0 @@\n-\n-\n@@ -1048,2 +1472,1 @@\n-\n-  Node* index_vect = unbox_vector(argument(7), vbox_idx_type, T_INT, num_elem);\n+  Node* index_vect = unbox_vector(argument(8), vbox_idx_type, T_INT, num_elem);\n@@ -1055,0 +1478,18 @@\n+\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(is_scatter ? argument(10) : argument(9), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                    is_scatter ? NodeClassNames[argument(10)->Opcode()]\n+                               : NodeClassNames[argument(9)->Opcode()]);\n+      }\n+      set_map(old_map);\n+      set_sp(old_sp);\n+      return false;\n+    }\n+  }\n+\n@@ -1057,1 +1498,1 @@\n-    Node* val = unbox_vector(argument(8), vbox_type, elem_bt, num_elem);\n+    Node* val = unbox_vector(argument(9), vbox_type, elem_bt, num_elem);\n@@ -1065,1 +1506,6 @@\n-    Node* vstore = gvn().transform(new StoreVectorScatterNode(control(), memory(addr), addr, addr_type, val, index_vect));\n+    Node* vstore = NULL;\n+    if (mask != NULL) {\n+      vstore = gvn().transform(new StoreVectorScatterMaskedNode(control(), memory(addr), addr, addr_type, val, index_vect, mask));\n+    } else {\n+      vstore = gvn().transform(new StoreVectorScatterNode(control(), memory(addr), addr, addr_type, val, index_vect));\n+    }\n@@ -1068,2 +1514,6 @@\n-    Node* vload = gvn().transform(new LoadVectorGatherNode(control(), memory(addr), addr, addr_type, vector_type, index_vect));\n-\n+    Node* vload = NULL;\n+    if (mask != NULL) {\n+      vload = gvn().transform(new LoadVectorGatherMaskedNode(control(), memory(addr), addr, addr_type, vector_type, index_vect, mask));\n+    } else {\n+      vload = gvn().transform(new LoadVectorGatherNode(control(), memory(addr), addr, addr_type, vector_type, index_vect));\n+    }\n@@ -1080,5 +1530,7 @@\n-\/\/ <V extends Vector<?,?>>\n-\/\/ long reductionCoerced(int oprId, Class<?> vectorClass, Class<?> elementType, int vlen,\n-\/\/                       V v,\n-\/\/                       Function<V,Long> defaultImpl)\n-\n+\/\/ public static\n+\/\/ <V extends Vector<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ long reductionCoerced(int oprId, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+\/\/                       Class<E> elementType, int length, V v, M m,\n+\/\/                       ReductionOperation<V, M> defaultImpl)\n@@ -1088,2 +1540,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -1097,2 +1550,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -1115,0 +1568,26 @@\n+\n+  const Type* vmask_type = gvn().type(argument(6));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1117,1 +1596,0 @@\n-\n@@ -1121,2 +1599,2 @@\n-  \/\/ TODO When mask usage is supported, VecMaskNotUsed needs to be VecMaskUseLoad.\n-  if (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed)) {\n+  \/\/ When using mask, mask use type needs to be VecMaskUseLoad.\n+  if (!arch_supports_vector(sopc, num_elem, elem_bt, is_masked_op ? VecMaskUseLoad : VecMaskNotUsed)) {\n@@ -1124,1 +1602,11 @@\n-      tty->print_cr(\"  ** not supported: arity=1 op=%d\/reduce vlen=%d etype=%s ismask=no\",\n+      tty->print_cr(\"  ** not supported: arity=1 op=%d\/reduce vlen=%d etype=%s is_masked_op=%d\",\n+                    sopc, num_elem, type2name(elem_bt), is_masked_op ? 1 : 0);\n+    }\n+    return false;\n+  }\n+\n+  \/\/ Return true if current platform has implemented the masked operation with predicate feature.\n+  bool use_predicate = is_masked_op && arch_supports_vector(sopc, num_elem, elem_bt, VecMaskUsePred);\n+  if (is_masked_op && !use_predicate && !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=1 op=%d\/reduce vlen=%d etype=%s is_masked_op=1\",\n@@ -1133,1 +1621,1 @@\n-  Node* opd = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n+  Node* opd = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n@@ -1138,0 +1626,15 @@\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    assert(is_vector_mask(mbox_klass), \"argument(2) should be a mask class\");\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(6), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\",\n+                      NodeClassNames[argument(6)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1139,1 +1642,16 @@\n-  Node* rn = gvn().transform(ReductionNode::make(opc, NULL, init, opd, elem_bt));\n+  Node* value = NULL;\n+  if (mask == NULL) {\n+    assert(!is_masked_op, \"Masked op needs the mask value never null\");\n+    value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+  } else {\n+    if (use_predicate) {\n+      value = ReductionNode::make(opc, NULL, init, opd, elem_bt);\n+      value->add_req(mask);\n+      value->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      Node* reduce_identity = gvn().transform(VectorNode::scalar2vector(init, num_elem, Type::get_const_basic_type(elem_bt)));\n+      value = gvn().transform(new VectorBlendNode(reduce_identity, opd, mask));\n+      value = ReductionNode::make(opc, NULL, init, value, elem_bt);\n+    }\n+  }\n+  value = gvn().transform(value);\n@@ -1146,1 +1664,1 @@\n-      bits = gvn().transform(new ConvI2LNode(rn));\n+      bits = gvn().transform(new ConvI2LNode(value));\n@@ -1150,2 +1668,2 @@\n-      rn   = gvn().transform(new MoveF2INode(rn));\n-      bits = gvn().transform(new ConvI2LNode(rn));\n+      value = gvn().transform(new MoveF2INode(value));\n+      bits  = gvn().transform(new ConvI2LNode(value));\n@@ -1155,1 +1673,1 @@\n-      bits = gvn().transform(new MoveD2LNode(rn));\n+      bits = gvn().transform(new MoveD2LNode(value));\n@@ -1159,1 +1677,1 @@\n-      bits = rn; \/\/ no conversion needed\n+      bits = value; \/\/ no conversion needed\n@@ -1171,1 +1689,1 @@\n-\/\/                                BiFunction<V, V, Boolean> defaultImpl) {\n+\/\/                                BiFunction<V, V, Boolean> defaultImpl)\n@@ -1232,2 +1750,4 @@\n-\/\/ <V extends Vector, M extends Mask>\n-\/\/ V blend(Class<V> vectorClass, Class<M> maskClass, Class<?> elementType, int vlen,\n+\/\/ <V extends Vector<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ V blend(Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType, int vlen,\n@@ -1235,2 +1755,1 @@\n-\/\/         VectorBlendOp<V,M> defaultImpl) { ...\n-\/\/\n+\/\/         VectorBlendOp<V, M, E> defaultImpl)\n@@ -1303,7 +1822,7 @@\n-\/\/  public static <V extends Vector<E,S>,\n-\/\/          M extends Vector.Mask<E,S>,\n-\/\/          S extends Vector.Shape, E>\n-\/\/  M compare(int cond, Class<V> vectorClass, Class<M> maskClass, Class<?> elementType, int vlen,\n-\/\/            V v1, V v2,\n-\/\/            VectorCompareOp<V,M> defaultImpl) { ...\n-\/\/\n+\/\/  public static\n+\/\/  <V extends Vector<E>,\n+\/\/   M extends VectorMask<E>,\n+\/\/   E>\n+\/\/  M compare(int cond, Class<? extends V> vectorClass, Class<M> maskClass, Class<E> elementType, int vlen,\n+\/\/            V v1, V v2, M m,\n+\/\/            VectorCompareOp<V,M> defaultImpl)\n@@ -1377,0 +1896,19 @@\n+  bool is_masked_op = argument(7)->bottom_type() != TypePtr::NULL_PTR;\n+  Node* mask = is_masked_op ? unbox_vector(argument(7), mbox_type, elem_bt, num_elem) : NULL;\n+  if (is_masked_op && mask == NULL) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: mask = null arity=2 op=comp\/%d vlen=%d etype=%s ismask=usestore is_masked_op=1\",\n+                    cond->get_con(), num_elem, type2name(elem_bt));\n+    }\n+    return false;\n+  }\n+\n+  bool use_predicate = is_masked_op && arch_supports_vector(Op_VectorMaskCmp, num_elem, elem_bt, VecMaskUsePred);\n+  if (is_masked_op && !use_predicate && !arch_supports_vector(Op_AndV, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: arity=2 op=comp\/%d vlen=%d etype=%s ismask=usestore is_masked_op=1\",\n+                    cond->get_con(), num_elem, type2name(elem_bt));\n+    }\n+    return false;\n+  }\n+\n@@ -1383,2 +1921,14 @@\n-  const TypeVect* vt = TypeVect::make(mask_bt, num_elem);\n-  Node* operation = gvn().transform(new VectorMaskCmpNode(pred, v1, v2, pred_node, vt));\n+  const TypeVect* vmask_type = TypeVect::makemask(mask_bt, num_elem);\n+  Node* operation = new VectorMaskCmpNode(pred, v1, v2, pred_node, vmask_type);\n+\n+  if (is_masked_op) {\n+    if (use_predicate) {\n+      operation->add_req(mask);\n+      operation->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      operation = gvn().transform(operation);\n+      operation = VectorNode::make(Op_AndV, operation, mask, vmask_type);\n+    }\n+  }\n+\n+  operation = gvn().transform(operation);\n@@ -1393,5 +1943,7 @@\n-\/\/ <V extends Vector, Sh extends Shuffle>\n-\/\/  V rearrangeOp(Class<V> vectorClass, Class<Sh> shuffleClass, Class< ? > elementType, int vlen,\n-\/\/    V v1, Sh sh,\n-\/\/    VectorSwizzleOp<V, Sh, S, E> defaultImpl) { ...\n-\n+\/\/ <V extends Vector<E>,\n+\/\/  Sh extends VectorShuffle<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/ V rearrangeOp(Class<? extends V> vectorClass, Class<Sh> shuffleClass, Class<M> maskClass, Class<E> elementType, int vlen,\n+\/\/               V v1, Sh sh, M m,\n+\/\/               VectorRearrangeOp<V, Sh, M, E> defaultImpl)\n@@ -1401,2 +1953,3 @@\n-  const TypeInstPtr* elem_klass    = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen          = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass    = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass    = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen          = gvn().type(argument(4))->isa_int();\n@@ -1404,1 +1957,1 @@\n-  if (vector_klass == NULL || shuffle_klass == NULL || elem_klass == NULL || vlen == NULL) {\n+  if (vector_klass == NULL  || shuffle_klass == NULL ||  elem_klass == NULL || vlen == NULL) {\n@@ -1407,2 +1960,4 @@\n-  if (shuffle_klass->const_oop() == NULL || vector_klass->const_oop() == NULL ||\n-    elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+  if (shuffle_klass->const_oop() == NULL ||\n+      vector_klass->const_oop()  == NULL ||\n+      elem_klass->const_oop()    == NULL ||\n+      !vlen->is_con()) {\n@@ -1413,2 +1968,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -1418,1 +1973,2 @@\n-  if (!is_klass_initialized(vector_klass) || !is_klass_initialized(shuffle_klass)) {\n+  if (!is_klass_initialized(vector_klass)  ||\n+      !is_klass_initialized(shuffle_klass)) {\n@@ -1442,1 +1998,7 @@\n-  if (!arch_supports_vector(Op_VectorRearrange, num_elem, elem_bt, VecMaskNotUsed)) {\n+\n+  bool is_masked_op = argument(7)->bottom_type() != TypePtr::NULL_PTR;\n+  bool use_predicate = is_masked_op;\n+  if (is_masked_op &&\n+      (mask_klass == NULL ||\n+       mask_klass->const_oop() == NULL ||\n+       !is_klass_initialized(mask_klass))) {\n@@ -1444,2 +2006,15 @@\n-      tty->print_cr(\"  ** not supported: arity=2 op=shuffle\/rearrange vlen=%d etype=%s ismask=no\",\n-                    num_elem, type2name(elem_bt));\n+      tty->print_cr(\"  ** mask_klass argument not initialized\");\n+    }\n+  }\n+  VectorMaskUseType checkFlags = (VectorMaskUseType)(is_masked_op ? (VecMaskUseLoad | VecMaskUsePred) : VecMaskNotUsed);\n+  if (!arch_supports_vector(Op_VectorRearrange, num_elem, elem_bt, checkFlags)) {\n+    use_predicate = false;\n+    if(!is_masked_op ||\n+       (!arch_supports_vector(Op_VectorRearrange, num_elem, elem_bt, VecMaskNotUsed) ||\n+        !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad)     ||\n+        !arch_supports_vector(VectorNode::replicate_opcode(elem_bt), num_elem, elem_bt, VecMaskNotUsed))) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=2 op=shuffle\/rearrange vlen=%d etype=%s ismask=no\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n@@ -1447,1 +2022,0 @@\n-    return false; \/\/ not supported\n@@ -1455,2 +2029,2 @@\n-  Node* v1 = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n-  Node* shuffle = unbox_vector(argument(5), shbox_type, shuffle_bt, num_elem);\n+  Node* v1 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n+  Node* shuffle = unbox_vector(argument(6), shbox_type, shuffle_bt, num_elem);\n@@ -1462,1 +2036,28 @@\n-  Node* rearrange = gvn().transform(new VectorRearrangeNode(v1, shuffle));\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(7), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=3 op=shuffle\/rearrange vlen=%d etype=%s ismask=useload is_masked_op=1\",\n+                      num_elem, type2name(elem_bt));\n+      }\n+      return false;\n+    }\n+  }\n+\n+  Node* rearrange = new VectorRearrangeNode(v1, shuffle);\n+  if (is_masked_op) {\n+    if (use_predicate) {\n+      rearrange->add_req(mask);\n+      rearrange->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      const TypeVect* vt = v1->bottom_type()->is_vect();\n+      rearrange = gvn().transform(rearrange);\n+      Node* zero = gvn().makecon(Type::get_zero_type(elem_bt));\n+      Node* zerovec = gvn().transform(VectorNode::scalar2vector(zero, num_elem, Type::get_const_basic_type(elem_bt)));\n+      rearrange = new VectorBlendNode(zerovec, rearrange, mask);\n+    }\n+  }\n+  rearrange = gvn().transform(rearrange);\n@@ -1528,5 +2129,7 @@\n-\/\/  <V extends Vector<?,?>>\n-\/\/  V broadcastInt(int opr, Class<V> vectorClass, Class<?> elementType, int vlen,\n-\/\/                 V v, int i,\n-\/\/                 VectorBroadcastIntOp<V> defaultImpl) {\n-\/\/\n+\/\/  <V extends Vector<E>,\n+\/\/   M extends VectorMask<E>,\n+\/\/   E>\n+\/\/  V broadcastInt(int opr, Class<? extends V> vectorClass, Class<? extends M> maskClass,\n+\/\/                 Class<E> elementType, int length,\n+\/\/                 V v, int n, M m,\n+\/\/                 VectorBroadcastIntOp<V, M> defaultImpl)\n@@ -1536,2 +2139,3 @@\n-  const TypeInstPtr* elem_klass   = gvn().type(argument(2))->isa_instptr();\n-  const TypeInt*     vlen         = gvn().type(argument(3))->isa_int();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n@@ -1547,2 +2151,2 @@\n-                    NodeClassNames[argument(2)->Opcode()],\n-                    NodeClassNames[argument(3)->Opcode()]);\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n@@ -1558,0 +2162,26 @@\n+\n+  const Type* vmask_type = gvn().type(argument(7));\n+  bool is_masked_op = vmask_type != TypePtr::NULL_PTR;\n+  if (is_masked_op) {\n+    if (mask_klass == NULL || mask_klass->const_oop() == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** missing constant: maskclass=%s\", NodeClassNames[argument(2)->Opcode()]);\n+      }\n+      return false; \/\/ not enough info for intrinsification\n+    }\n+\n+    if (!is_klass_initialized(mask_klass)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** mask klass argument not initialized\");\n+      }\n+      return false;\n+    }\n+\n+    if (vmask_type->maybe_null()) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** null mask values are not allowed for masked op\");\n+      }\n+      return false;\n+    }\n+  }\n+\n@@ -1565,1 +2195,1 @@\n-  BasicType elem_bt = elem_type->basic_type();\n+\n@@ -1567,0 +2197,1 @@\n+  BasicType elem_bt = elem_type->basic_type();\n@@ -1568,0 +2199,1 @@\n+\n@@ -1570,0 +2202,1 @@\n+\n@@ -1576,0 +2209,1 @@\n+\n@@ -1583,1 +2217,2 @@\n-  Node* cnt  = argument(5);\n+\n+  Node* cnt  = argument(6);\n@@ -1592,4 +2227,15 @@\n-  if (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed, has_scalar_args)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=0 op=int\/%d vlen=%d etype=%s ismask=no\",\n-                    sopc, num_elem, type2name(elem_bt));\n+\n+  VectorMaskUseType checkFlags = (VectorMaskUseType)(is_masked_op ? (VecMaskUseLoad | VecMaskUsePred) : VecMaskNotUsed);\n+  bool use_predicate = is_masked_op;\n+\n+  if (!arch_supports_vector(sopc, num_elem, elem_bt, checkFlags, has_scalar_args)) {\n+    use_predicate = false;\n+    if (!is_masked_op ||\n+        (!arch_supports_vector(sopc, num_elem, elem_bt, VecMaskNotUsed, has_scalar_args) ||\n+         !arch_supports_vector(Op_VectorBlend, num_elem, elem_bt, VecMaskUseLoad))) {\n+\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: arity=0 op=int\/%d vlen=%d etype=%s is_masked_op=%d\",\n+                      sopc, num_elem, type2name(elem_bt), is_masked_op ? 1 : 0);\n+      }\n+      return false; \/\/ not supported\n@@ -1597,2 +2243,2 @@\n-    return false; \/\/ not supported\n-  Node* opd1 = unbox_vector(argument(4), vbox_type, elem_bt, num_elem);\n+\n+  Node* opd1 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n@@ -1614,0 +2260,1 @@\n+\n@@ -1617,1 +2264,24 @@\n-  Node* operation = gvn().transform(VectorNode::make(opc, opd1, opd2, num_elem, elem_bt));\n+  Node* mask = NULL;\n+  if (is_masked_op) {\n+    ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+    mask = unbox_vector(argument(7), mbox_type, elem_bt, num_elem);\n+    if (mask == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed mask=%s\", NodeClassNames[argument(7)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n+  Node* operation = VectorNode::make(opc, opd1, opd2, num_elem, elem_bt);\n+  if (is_masked_op && mask != NULL) {\n+    if (use_predicate) {\n+      operation->add_req(mask);\n+      operation->add_flag(Node::Flag_is_predicated_vector);\n+    } else {\n+      operation = gvn().transform(operation);\n+      operation = new VectorBlendNode(opd1, operation, mask);\n+    }\n+  }\n+  operation = gvn().transform(operation);\n@@ -1632,1 +2302,1 @@\n-\/\/           VectorConvertOp<VOUT, VIN, S> defaultImpl) {\n+\/\/           VectorConvertOp<VOUT, VIN, S> defaultImpl)\n@@ -1693,3 +2363,0 @@\n-  if (is_mask && (type2aelembytes(elem_bt_from) != type2aelembytes(elem_bt_to))) {\n-    return false; \/\/ elem size mismatch\n-  }\n@@ -1741,2 +2408,2 @@\n-  const TypeVect* src_type = TypeVect::make(elem_bt_from, num_elem_from);\n-  const TypeVect* dst_type = TypeVect::make(elem_bt_to,   num_elem_to);\n+  const TypeVect* src_type = TypeVect::make(elem_bt_from, num_elem_from, is_mask);\n+  const TypeVect* dst_type = TypeVect::make(elem_bt_to, num_elem_to, is_mask);\n@@ -1746,2 +2413,6 @@\n-    assert(!is_mask, \"masks cannot be casted\");\n-    int cast_vopc = VectorCastNode::opcode(elem_bt_from);\n+    BasicType new_elem_bt_to = elem_bt_to;\n+    BasicType new_elem_bt_from = elem_bt_from;\n+    if (is_mask && is_floating_point_type(elem_bt_from)) {\n+      new_elem_bt_from = elem_bt_from == T_FLOAT ? T_INT : T_LONG;\n+    }\n+    int cast_vopc = VectorCastNode::opcode(new_elem_bt_from);\n@@ -1801,3 +2472,26 @@\n-      \/\/ Since input and output number of elements match, and since we know this vector size is\n-      \/\/ supported, simply do a cast with no resize needed.\n-      op = gvn().transform(VectorCastNode::make(cast_vopc, op, elem_bt_to, num_elem_to));\n+      if (is_mask) {\n+        if((dst_type->isa_vectmask() && src_type->isa_vectmask()) ||\n+           (type2aelembytes(elem_bt_from) == type2aelembytes(elem_bt_to))) {\n+          op = gvn().transform(new VectorMaskCastNode(op, dst_type));\n+        } else {\n+          \/\/ Special handling for casting operation involving floating point types.\n+          \/\/ Case A) F -> X :=  F -> VectorMaskCast (F->I\/L [NOP]) -> VectorCast[I\/L]2X\n+          \/\/ Case B) X -> F :=  X -> VectorCastX2[I\/L] -> VectorMaskCast ([I\/L]->F [NOP])\n+          \/\/ Case C) F -> F :=  VectorMaskCast (F->I\/L [NOP]) -> VectorCast[I\/L]2[L\/I] -> VectotMaskCast (L\/I->F [NOP])\n+          if (is_floating_point_type(elem_bt_from)) {\n+            const TypeVect* new_src_type = TypeVect::make(new_elem_bt_from, num_elem_to, is_mask);\n+            op = gvn().transform(new VectorMaskCastNode(op, new_src_type));\n+          }\n+          if (is_floating_point_type(elem_bt_to)) {\n+            new_elem_bt_to = elem_bt_to == T_FLOAT ? T_INT : T_LONG;\n+          }\n+          op = gvn().transform(VectorCastNode::make(cast_vopc, op, new_elem_bt_to, num_elem_to));\n+          if (new_elem_bt_to != elem_bt_to) {\n+            op = gvn().transform(new VectorMaskCastNode(op, dst_type));\n+          }\n+        }\n+      } else {\n+        \/\/ Since input and output number of elements match, and since we know this vector size is\n+        \/\/ supported, simply do a cast with no resize needed.\n+        op = gvn().transform(VectorCastNode::make(cast_vopc, op, elem_bt_to, num_elem_to));\n+      }\n@@ -1818,2 +2512,3 @@\n-\/\/  <V extends Vector<?>>\n-\/\/  V insert(Class<? extends V> vectorClass, Class<?> elementType, int vlen,\n+\/\/  <V extends Vector<E>,\n+\/\/   E>\n+\/\/  V insert(Class<? extends V> vectorClass, Class<E> elementType, int vlen,\n@@ -1821,2 +2516,1 @@\n-\/\/           VecInsertOp<V> defaultImpl) {\n-\/\/\n+\/\/           VecInsertOp<V> defaultImpl)\n@@ -1911,2 +2605,3 @@\n-\/\/  <V extends Vector<?>>\n-\/\/  long extract(Class<?> vectorClass, Class<?> elementType, int vlen,\n+\/\/  <V extends Vector<E>,\n+\/\/   E>\n+\/\/  long extract(Class<? extends V> vectorClass, Class<E> elementType, int vlen,\n@@ -1914,2 +2609,1 @@\n-\/\/               VecExtractOp<V> defaultImpl) {\n-\/\/\n+\/\/               VecExtractOp<V> defaultImpl)\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":932,"deletions":238,"binary":false,"changes":1170,"status":"modified"},{"patch":"@@ -1848,0 +1848,4 @@\n+  declare_c2_type(MaskAllNode, VectorNode)                                \\\n+  declare_c2_type(AndVMaskNode, VectorNode)                               \\\n+  declare_c2_type(OrVMaskNode, VectorNode)                                \\\n+  declare_c2_type(XorVMaskNode, VectorNode)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1556,0 +1556,17 @@\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, p0, 0);\",                       \"lsl\\tz0.b, p0\/m, z0.b, #0\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, p0, 5);\",                       \"lsl\\tz0.b, p0\/m, z0.b, #5\"],\n+                        [\"lsl\",     \"__ sve_lsl(z1, __ H, p1, 15);\",                      \"lsl\\tz1.h, p1\/m, z1.h, #15\"],\n+                        [\"lsl\",     \"__ sve_lsl(z2, __ S, p2, 31);\",                      \"lsl\\tz2.s, p2\/m, z2.s, #31\"],\n+                        [\"lsl\",     \"__ sve_lsl(z3, __ D, p3, 63);\",                      \"lsl\\tz3.d, p3\/m, z3.d, #63\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, p0, 1);\",                       \"lsr\\tz0.b, p0\/m, z0.b, #1\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, p0, 8);\",                       \"lsr\\tz0.b, p0\/m, z0.b, #8\"],\n+                        [\"lsr\",     \"__ sve_lsr(z1, __ H, p1, 15);\",                      \"lsr\\tz1.h, p1\/m, z1.h, #15\"],\n+                        [\"lsr\",     \"__ sve_lsr(z2, __ S, p2, 7);\",                       \"lsr\\tz2.s, p2\/m, z2.s, #7\"],\n+                        [\"lsr\",     \"__ sve_lsr(z2, __ S, p2, 31);\",                      \"lsr\\tz2.s, p2\/m, z2.s, #31\"],\n+                        [\"lsr\",     \"__ sve_lsr(z3, __ D, p3, 63);\",                      \"lsr\\tz3.d, p3\/m, z3.d, #63\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ B, p0, 1);\",                       \"asr\\tz0.b, p0\/m, z0.b, #1\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ B, p0, 7);\",                       \"asr\\tz0.b, p0\/m, z0.b, #7\"],\n+                        [\"asr\",     \"__ sve_asr(z1, __ H, p1, 5);\",                       \"asr\\tz1.h, p1\/m, z1.h, #5\"],\n+                        [\"asr\",     \"__ sve_asr(z1, __ H, p1, 15);\",                      \"asr\\tz1.h, p1\/m, z1.h, #15\"],\n+                        [\"asr\",     \"__ sve_asr(z2, __ S, p2, 31);\",                      \"asr\\tz2.s, p2\/m, z2.s, #31\"],\n+                        [\"asr\",     \"__ sve_asr(z3, __ D, p3, 63);\",                      \"asr\\tz3.d, p3\/m, z3.d, #63\"],\n@@ -1650,0 +1667,23 @@\n+                        [\"and\",     \"__ sve_and(p0, p1, p2, p3);\",                        \"and\\tp0.b, p1\/z, p2.b, p3.b\"],\n+                        [\"ands\",    \"__ sve_ands(p4, p5, p6, p0);\",                       \"ands\\tp4.b, p5\/z, p6.b, p0.b\"],\n+                        [\"eor\",     \"__ sve_eor(p0, p1, p2, p3);\",                        \"eor\\tp0.b, p1\/z, p2.b, p3.b\"],\n+                        [\"eors\",    \"__ sve_eors(p5, p6, p0, p1);\",                       \"eors\\tp5.b, p6\/z, p0.b, p1.b\"],\n+                        [\"orr\",     \"__ sve_orr(p0, p1, p2, p3);\",                        \"orr\\tp0.b, p1\/z, p2.b, p3.b\"],\n+                        [\"orrs\",    \"__ sve_orrs(p9, p1, p4, p5);\",                       \"orrs\\tp9.b, p1\/z, p4.b, p5.b\"],\n+                        [\"bic\",     \"__ sve_bic(p10, p7, p9, p11);\",                      \"bic\\tp10.b, p7\/z, p9.b, p11.b\"],\n+                        [\"ptest\",   \"__ sve_ptest(p7, p1);\",                              \"ptest\\tp7, p1.b\"],\n+                        [\"ptrue\",   \"__ sve_ptrue(p1, __ B);\",                            \"ptrue\\tp1.b\"],\n+                        [\"ptrue\",   \"__ sve_ptrue(p2, __ H);\",                            \"ptrue\\tp2.h\"],\n+                        [\"ptrue\",   \"__ sve_ptrue(p3, __ S);\",                            \"ptrue\\tp3.s\"],\n+                        [\"ptrue\",   \"__ sve_ptrue(p4, __ D);\",                            \"ptrue\\tp4.d\"],\n+                        [\"pfalse\",  \"__ sve_pfalse(p7);\",                                 \"pfalse\\tp7.b\"],\n+                        [\"uzp1\",    \"__ sve_uzp1(p0, __ B, p0, p1);\",                     \"uzp1\\tp0.b, p0.b, p1.b\"],\n+                        [\"uzp1\",    \"__ sve_uzp1(p0, __ H, p0, p1);\",                     \"uzp1\\tp0.h, p0.h, p1.h\"],\n+                        [\"uzp1\",    \"__ sve_uzp1(p0, __ S, p0, p1);\",                     \"uzp1\\tp0.s, p0.s, p1.s\"],\n+                        [\"uzp1\",    \"__ sve_uzp1(p0, __ D, p0, p1);\",                     \"uzp1\\tp0.d, p0.d, p1.d\"],\n+                        [\"uzp2\",    \"__ sve_uzp2(p0, __ B, p0, p1);\",                     \"uzp2\\tp0.b, p0.b, p1.b\"],\n+                        [\"uzp2\",    \"__ sve_uzp2(p0, __ H, p0, p1);\",                     \"uzp2\\tp0.h, p0.h, p1.h\"],\n+                        [\"uzp2\",    \"__ sve_uzp2(p0, __ S, p0, p1);\",                     \"uzp2\\tp0.s, p0.s, p1.s\"],\n+                        [\"uzp2\",    \"__ sve_uzp2(p0, __ D, p0, p1);\",                     \"uzp2\\tp0.d, p0.d, p1.d\"],\n+                        [\"punpklo\", \"__ sve_punpklo(p1, p0);\",                            \"punpklo\\tp1.h, p0.b\"],\n+                        [\"punpkhi\", \"__ sve_punpkhi(p1, p0);\",                            \"punpkhi\\tp1.h, p0.b\"],\n@@ -1687,0 +1727,1 @@\n+                       [\"and\", \"ZPZ\", \"m\", \"dn\"],\n@@ -1689,0 +1730,1 @@\n+                       [\"eor\", \"ZPZ\", \"m\", \"dn\"],\n@@ -1694,0 +1736,1 @@\n+                       [\"orr\", \"ZPZ\", \"m\", \"dn\"],\n@@ -1709,0 +1752,1 @@\n+                       [\"fmad\", \"ZPZZ\", \"m\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":44,"deletions":0,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -745,0 +745,17 @@\n+    __ sve_lsl(z0, __ B, p0, 0);                       \/\/       lsl     z0.b, p0\/m, z0.b, #0\n+    __ sve_lsl(z0, __ B, p0, 5);                       \/\/       lsl     z0.b, p0\/m, z0.b, #5\n+    __ sve_lsl(z1, __ H, p1, 15);                      \/\/       lsl     z1.h, p1\/m, z1.h, #15\n+    __ sve_lsl(z2, __ S, p2, 31);                      \/\/       lsl     z2.s, p2\/m, z2.s, #31\n+    __ sve_lsl(z3, __ D, p3, 63);                      \/\/       lsl     z3.d, p3\/m, z3.d, #63\n+    __ sve_lsr(z0, __ B, p0, 1);                       \/\/       lsr     z0.b, p0\/m, z0.b, #1\n+    __ sve_lsr(z0, __ B, p0, 8);                       \/\/       lsr     z0.b, p0\/m, z0.b, #8\n+    __ sve_lsr(z1, __ H, p1, 15);                      \/\/       lsr     z1.h, p1\/m, z1.h, #15\n+    __ sve_lsr(z2, __ S, p2, 7);                       \/\/       lsr     z2.s, p2\/m, z2.s, #7\n+    __ sve_lsr(z2, __ S, p2, 31);                      \/\/       lsr     z2.s, p2\/m, z2.s, #31\n+    __ sve_lsr(z3, __ D, p3, 63);                      \/\/       lsr     z3.d, p3\/m, z3.d, #63\n+    __ sve_asr(z0, __ B, p0, 1);                       \/\/       asr     z0.b, p0\/m, z0.b, #1\n+    __ sve_asr(z0, __ B, p0, 7);                       \/\/       asr     z0.b, p0\/m, z0.b, #7\n+    __ sve_asr(z1, __ H, p1, 5);                       \/\/       asr     z1.h, p1\/m, z1.h, #5\n+    __ sve_asr(z1, __ H, p1, 15);                      \/\/       asr     z1.h, p1\/m, z1.h, #15\n+    __ sve_asr(z2, __ S, p2, 31);                      \/\/       asr     z2.s, p2\/m, z2.s, #31\n+    __ sve_asr(z3, __ D, p3, 63);                      \/\/       asr     z3.d, p3\/m, z3.d, #63\n@@ -839,0 +856,23 @@\n+    __ sve_and(p0, p1, p2, p3);                        \/\/       and     p0.b, p1\/z, p2.b, p3.b\n+    __ sve_ands(p4, p5, p6, p0);                       \/\/       ands    p4.b, p5\/z, p6.b, p0.b\n+    __ sve_eor(p0, p1, p2, p3);                        \/\/       eor     p0.b, p1\/z, p2.b, p3.b\n+    __ sve_eors(p5, p6, p0, p1);                       \/\/       eors    p5.b, p6\/z, p0.b, p1.b\n+    __ sve_orr(p0, p1, p2, p3);                        \/\/       orr     p0.b, p1\/z, p2.b, p3.b\n+    __ sve_orrs(p9, p1, p4, p5);                       \/\/       orrs    p9.b, p1\/z, p4.b, p5.b\n+    __ sve_bic(p10, p7, p9, p11);                      \/\/       bic     p10.b, p7\/z, p9.b, p11.b\n+    __ sve_ptest(p7, p1);                              \/\/       ptest   p7, p1.b\n+    __ sve_ptrue(p1, __ B);                            \/\/       ptrue   p1.b\n+    __ sve_ptrue(p2, __ H);                            \/\/       ptrue   p2.h\n+    __ sve_ptrue(p3, __ S);                            \/\/       ptrue   p3.s\n+    __ sve_ptrue(p4, __ D);                            \/\/       ptrue   p4.d\n+    __ sve_pfalse(p7);                                 \/\/       pfalse  p7.b\n+    __ sve_uzp1(p0, __ B, p0, p1);                     \/\/       uzp1    p0.b, p0.b, p1.b\n+    __ sve_uzp1(p0, __ H, p0, p1);                     \/\/       uzp1    p0.h, p0.h, p1.h\n+    __ sve_uzp1(p0, __ S, p0, p1);                     \/\/       uzp1    p0.s, p0.s, p1.s\n+    __ sve_uzp1(p0, __ D, p0, p1);                     \/\/       uzp1    p0.d, p0.d, p1.d\n+    __ sve_uzp2(p0, __ B, p0, p1);                     \/\/       uzp2    p0.b, p0.b, p1.b\n+    __ sve_uzp2(p0, __ H, p0, p1);                     \/\/       uzp2    p0.h, p0.h, p1.h\n+    __ sve_uzp2(p0, __ S, p0, p1);                     \/\/       uzp2    p0.s, p0.s, p1.s\n+    __ sve_uzp2(p0, __ D, p0, p1);                     \/\/       uzp2    p0.d, p0.d, p1.d\n+    __ sve_punpklo(p1, p0);                            \/\/       punpklo p1.h, p0.b\n+    __ sve_punpkhi(p1, p0);                            \/\/       punpkhi p1.h, p0.b\n@@ -982,34 +1022,38 @@\n-    __ sve_asr(z26, __ H, p5, z28);                    \/\/       asr     z26.h, p5\/m, z26.h, z28.h\n-    __ sve_cnt(z13, __ D, p7, z16);                    \/\/       cnt     z13.d, p7\/m, z16.d\n-    __ sve_lsl(z5, __ H, p0, z13);                     \/\/       lsl     z5.h, p0\/m, z5.h, z13.h\n-    __ sve_lsr(z15, __ S, p2, z26);                    \/\/       lsr     z15.s, p2\/m, z15.s, z26.s\n-    __ sve_mul(z11, __ S, p1, z22);                    \/\/       mul     z11.s, p1\/m, z11.s, z22.s\n-    __ sve_neg(z4, __ S, p0, z19);                     \/\/       neg     z4.s, p0\/m, z19.s\n-    __ sve_not(z17, __ H, p3, z14);                    \/\/       not     z17.h, p3\/m, z14.h\n-    __ sve_smax(z2, __ S, p4, z3);                     \/\/       smax    z2.s, p4\/m, z2.s, z3.s\n-    __ sve_smin(z23, __ B, p1, z6);                    \/\/       smin    z23.b, p1\/m, z23.b, z6.b\n-    __ sve_sub(z17, __ S, p3, z27);                    \/\/       sub     z17.s, p3\/m, z17.s, z27.s\n-    __ sve_fabs(z16, __ D, p1, z2);                    \/\/       fabs    z16.d, p1\/m, z2.d\n-    __ sve_fadd(z3, __ D, p1, z6);                     \/\/       fadd    z3.d, p1\/m, z3.d, z6.d\n-    __ sve_fdiv(z19, __ D, p3, z12);                   \/\/       fdiv    z19.d, p3\/m, z19.d, z12.d\n-    __ sve_fmax(z8, __ D, p6, z19);                    \/\/       fmax    z8.d, p6\/m, z8.d, z19.d\n-    __ sve_fmin(z0, __ S, p2, z23);                    \/\/       fmin    z0.s, p2\/m, z0.s, z23.s\n-    __ sve_fmul(z19, __ D, p7, z13);                   \/\/       fmul    z19.d, p7\/m, z19.d, z13.d\n-    __ sve_fneg(z6, __ S, p0, z7);                     \/\/       fneg    z6.s, p0\/m, z7.s\n-    __ sve_frintm(z17, __ S, p6, z8);                  \/\/       frintm  z17.s, p6\/m, z8.s\n-    __ sve_frintn(z22, __ D, p5, z22);                 \/\/       frintn  z22.d, p5\/m, z22.d\n-    __ sve_frintp(z2, __ D, p0, z15);                  \/\/       frintp  z2.d, p0\/m, z15.d\n-    __ sve_fsqrt(z20, __ D, p1, z4);                   \/\/       fsqrt   z20.d, p1\/m, z4.d\n-    __ sve_fsub(z7, __ D, p0, z8);                     \/\/       fsub    z7.d, p0\/m, z7.d, z8.d\n-    __ sve_fmla(z19, __ S, p5, z4, z15);               \/\/       fmla    z19.s, p5\/m, z4.s, z15.s\n-    __ sve_fmls(z22, __ D, p2, z25, z5);               \/\/       fmls    z22.d, p2\/m, z25.d, z5.d\n-    __ sve_fnmla(z16, __ S, p3, z22, z11);             \/\/       fnmla   z16.s, p3\/m, z22.s, z11.s\n-    __ sve_fnmls(z13, __ D, p2, z20, z16);             \/\/       fnmls   z13.d, p2\/m, z20.d, z16.d\n-    __ sve_mla(z15, __ H, p1, z4, z17);                \/\/       mla     z15.h, p1\/m, z4.h, z17.h\n-    __ sve_mls(z6, __ S, p7, z4, z28);                 \/\/       mls     z6.s, p7\/m, z4.s, z28.s\n-    __ sve_and(z29, z26, z9);                          \/\/       and     z29.d, z26.d, z9.d\n-    __ sve_eor(z2, z11, z28);                          \/\/       eor     z2.d, z11.d, z28.d\n-    __ sve_orr(z7, z1, z26);                           \/\/       orr     z7.d, z1.d, z26.d\n-    __ sve_bic(z17, z14, z8);                          \/\/       bic     z17.d, z14.d, z8.d\n-    __ sve_uzp1(z21, __ S, z24, z5);                   \/\/       uzp1    z21.s, z24.s, z5.s\n-    __ sve_uzp2(z21, __ S, z17, z22);                  \/\/       uzp2    z21.s, z17.s, z22.s\n+    __ sve_and(z26, __ H, p5, z28);                    \/\/       and     z26.h, p5\/m, z26.h, z28.h\n+    __ sve_asr(z13, __ D, p7, z16);                    \/\/       asr     z13.d, p7\/m, z13.d, z16.d\n+    __ sve_cnt(z5, __ H, p0, z13);                     \/\/       cnt     z5.h, p0\/m, z13.h\n+    __ sve_eor(z15, __ S, p2, z26);                    \/\/       eor     z15.s, p2\/m, z15.s, z26.s\n+    __ sve_lsl(z11, __ S, p1, z22);                    \/\/       lsl     z11.s, p1\/m, z11.s, z22.s\n+    __ sve_lsr(z4, __ S, p0, z19);                     \/\/       lsr     z4.s, p0\/m, z4.s, z19.s\n+    __ sve_mul(z17, __ H, p3, z14);                    \/\/       mul     z17.h, p3\/m, z17.h, z14.h\n+    __ sve_neg(z2, __ S, p4, z3);                      \/\/       neg     z2.s, p4\/m, z3.s\n+    __ sve_not(z23, __ B, p1, z6);                     \/\/       not     z23.b, p1\/m, z6.b\n+    __ sve_orr(z17, __ S, p3, z27);                    \/\/       orr     z17.s, p3\/m, z17.s, z27.s\n+    __ sve_smax(z16, __ D, p1, z2);                    \/\/       smax    z16.d, p1\/m, z16.d, z2.d\n+    __ sve_smin(z3, __ S, p1, z6);                     \/\/       smin    z3.s, p1\/m, z3.s, z6.s\n+    __ sve_sub(z19, __ S, p3, z12);                    \/\/       sub     z19.s, p3\/m, z19.s, z12.s\n+    __ sve_fabs(z8, __ D, p6, z19);                    \/\/       fabs    z8.d, p6\/m, z19.d\n+    __ sve_fadd(z0, __ S, p2, z23);                    \/\/       fadd    z0.s, p2\/m, z0.s, z23.s\n+    __ sve_fdiv(z19, __ D, p7, z13);                   \/\/       fdiv    z19.d, p7\/m, z19.d, z13.d\n+    __ sve_fmax(z6, __ S, p0, z7);                     \/\/       fmax    z6.s, p0\/m, z6.s, z7.s\n+    __ sve_fmin(z17, __ S, p6, z8);                    \/\/       fmin    z17.s, p6\/m, z17.s, z8.s\n+    __ sve_fmul(z22, __ D, p5, z22);                   \/\/       fmul    z22.d, p5\/m, z22.d, z22.d\n+    __ sve_fneg(z2, __ D, p0, z15);                    \/\/       fneg    z2.d, p0\/m, z15.d\n+    __ sve_frintm(z20, __ D, p1, z4);                  \/\/       frintm  z20.d, p1\/m, z4.d\n+    __ sve_frintn(z7, __ D, p0, z8);                   \/\/       frintn  z7.d, p0\/m, z8.d\n+    __ sve_frintp(z19, __ D, p5, z4);                  \/\/       frintp  z19.d, p5\/m, z4.d\n+    __ sve_fsqrt(z9, __ D, p5, z11);                   \/\/       fsqrt   z9.d, p5\/m, z11.d\n+    __ sve_fsub(z5, __ S, p7, z16);                    \/\/       fsub    z5.s, p7\/m, z5.s, z16.s\n+    __ sve_fmad(z22, __ S, p3, z1, z13);               \/\/       fmad    z22.s, p3\/m, z1.s, z13.s\n+    __ sve_fmla(z20, __ S, p4, z25, z15);              \/\/       fmla    z20.s, p4\/m, z25.s, z15.s\n+    __ sve_fmls(z4, __ D, p4, z8, z6);                 \/\/       fmls    z4.d, p4\/m, z8.d, z6.d\n+    __ sve_fnmla(z4, __ D, p7, z16, z29);              \/\/       fnmla   z4.d, p7\/m, z16.d, z29.d\n+    __ sve_fnmls(z9, __ D, p3, z2, z11);               \/\/       fnmls   z9.d, p3\/m, z2.d, z11.d\n+    __ sve_mla(z3, __ S, p1, z1, z26);                 \/\/       mla     z3.s, p1\/m, z1.s, z26.s\n+    __ sve_mls(z17, __ S, p3, z8, z17);                \/\/       mls     z17.s, p3\/m, z8.s, z17.s\n+    __ sve_and(z24, z5, z19);                          \/\/       and     z24.d, z5.d, z19.d\n+    __ sve_eor(z17, z22, z16);                         \/\/       eor     z17.d, z22.d, z16.d\n+    __ sve_orr(z20, z19, z0);                          \/\/       orr     z20.d, z19.d, z0.d\n+    __ sve_bic(z17, z23, z4);                          \/\/       bic     z17.d, z23.d, z4.d\n+    __ sve_uzp1(z4, __ S, z23, z25);                   \/\/       uzp1    z4.s, z23.s, z25.s\n+    __ sve_uzp2(z2, __ H, z8, z8);                     \/\/       uzp2    z2.h, z8.h, z8.h\n@@ -1018,9 +1062,9 @@\n-    __ sve_andv(v29, __ B, p5, z19);                   \/\/       andv b29, p5, z19.b\n-    __ sve_orv(v4, __ B, p4, z23);                     \/\/       orv b4, p4, z23.b\n-    __ sve_eorv(v19, __ D, p1, z23);                   \/\/       eorv d19, p1, z23.d\n-    __ sve_smaxv(v19, __ H, p0, z8);                   \/\/       smaxv h19, p0, z8.h\n-    __ sve_sminv(v14, __ D, p6, z17);                  \/\/       sminv d14, p6, z17.d\n-    __ sve_fminv(v21, __ S, p1, z30);                  \/\/       fminv s21, p1, z30.s\n-    __ sve_fmaxv(v10, __ S, p5, z12);                  \/\/       fmaxv s10, p5, z12.s\n-    __ sve_fadda(v9, __ D, p1, z24);                   \/\/       fadda d9, p1, d9, z24.d\n-    __ sve_uaddv(v4, __ H, p6, z6);                    \/\/       uaddv d4, p6, z6.h\n+    __ sve_andv(v24, __ S, p4, z30);                   \/\/       andv s24, p4, z30.s\n+    __ sve_orv(v4, __ H, p7, z1);                      \/\/       orv h4, p7, z1.h\n+    __ sve_eorv(v19, __ H, p3, z0);                    \/\/       eorv h19, p3, z0.h\n+    __ sve_smaxv(v7, __ B, p6, z17);                   \/\/       smaxv b7, p6, z17.b\n+    __ sve_sminv(v27, __ D, p1, z9);                   \/\/       sminv d27, p1, z9.d\n+    __ sve_fminv(v23, __ D, p3, z16);                  \/\/       fminv d23, p3, z16.d\n+    __ sve_fmaxv(v22, __ D, p5, z20);                  \/\/       fmaxv d22, p5, z20.d\n+    __ sve_fadda(v28, __ D, p2, z13);                  \/\/       fadda d28, p2, d28, z13.d\n+    __ sve_uaddv(v7, __ H, p5, z28);                   \/\/       uaddv d7, p5, z28.h\n@@ -1045,7 +1089,7 @@\n-    0x14000000,     0x17ffffd7,     0x1400034c,     0x94000000,\n-    0x97ffffd4,     0x94000349,     0x3400000a,     0x34fffa2a,\n-    0x340068ca,     0x35000008,     0x35fff9c8,     0x35006868,\n-    0xb400000b,     0xb4fff96b,     0xb400680b,     0xb500001d,\n-    0xb5fff91d,     0xb50067bd,     0x10000013,     0x10fff8b3,\n-    0x10006753,     0x90000013,     0x36300016,     0x3637f836,\n-    0x363066d6,     0x3758000c,     0x375ff7cc,     0x3758666c,\n+    0x14000000,     0x17ffffd7,     0x14000378,     0x94000000,\n+    0x97ffffd4,     0x94000375,     0x3400000a,     0x34fffa2a,\n+    0x34006e4a,     0x35000008,     0x35fff9c8,     0x35006de8,\n+    0xb400000b,     0xb4fff96b,     0xb4006d8b,     0xb500001d,\n+    0xb5fff91d,     0xb5006d3d,     0x10000013,     0x10fff8b3,\n+    0x10006cd3,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36306c56,     0x3758000c,     0x375ff7cc,     0x37586bec,\n@@ -1056,13 +1100,13 @@\n-    0x54006440,     0x54000001,     0x54fff541,     0x540063e1,\n-    0x54000002,     0x54fff4e2,     0x54006382,     0x54000002,\n-    0x54fff482,     0x54006322,     0x54000003,     0x54fff423,\n-    0x540062c3,     0x54000003,     0x54fff3c3,     0x54006263,\n-    0x54000004,     0x54fff364,     0x54006204,     0x54000005,\n-    0x54fff305,     0x540061a5,     0x54000006,     0x54fff2a6,\n-    0x54006146,     0x54000007,     0x54fff247,     0x540060e7,\n-    0x54000008,     0x54fff1e8,     0x54006088,     0x54000009,\n-    0x54fff189,     0x54006029,     0x5400000a,     0x54fff12a,\n-    0x54005fca,     0x5400000b,     0x54fff0cb,     0x54005f6b,\n-    0x5400000c,     0x54fff06c,     0x54005f0c,     0x5400000d,\n-    0x54fff00d,     0x54005ead,     0x5400000e,     0x54ffefae,\n-    0x54005e4e,     0x5400000f,     0x54ffef4f,     0x54005def,\n+    0x540069c0,     0x54000001,     0x54fff541,     0x54006961,\n+    0x54000002,     0x54fff4e2,     0x54006902,     0x54000002,\n+    0x54fff482,     0x540068a2,     0x54000003,     0x54fff423,\n+    0x54006843,     0x54000003,     0x54fff3c3,     0x540067e3,\n+    0x54000004,     0x54fff364,     0x54006784,     0x54000005,\n+    0x54fff305,     0x54006725,     0x54000006,     0x54fff2a6,\n+    0x540066c6,     0x54000007,     0x54fff247,     0x54006667,\n+    0x54000008,     0x54fff1e8,     0x54006608,     0x54000009,\n+    0x54fff189,     0x540065a9,     0x5400000a,     0x54fff12a,\n+    0x5400654a,     0x5400000b,     0x54fff0cb,     0x540064eb,\n+    0x5400000c,     0x54fff06c,     0x5400648c,     0x5400000d,\n+    0x54fff00d,     0x5400642d,     0x5400000e,     0x54ffefae,\n+    0x540063ce,     0x5400000f,     0x54ffef4f,     0x5400636f,\n@@ -1100,1 +1144,1 @@\n-    0xbd1b1869,     0x58004e3b,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x580053bb,     0x1800000b,     0xf8945060,\n@@ -1192,24 +1236,34 @@\n-    0x0461943e,     0x04a19020,     0x042053ff,     0x047f5401,\n-    0x25208028,     0x2538cfe0,     0x2578d001,     0x25b8efe2,\n-    0x25f8f007,     0x2538dfea,     0x25b8dfeb,     0xa400a3e0,\n-    0xa420a7e0,     0xa4484be0,     0xa467afe0,     0xa4a8a7ea,\n-    0xa547a814,     0xa4084ffe,     0xa55c53e0,     0xa5e1540b,\n-    0xe400fbf6,     0xe408ffff,     0xe420e7e0,     0xe4484be0,\n-    0xe460efe0,     0xe547e400,     0xe4014be0,     0xe4a84fe0,\n-    0xe5f15000,     0x858043e0,     0x85a043ff,     0xe59f5d08,\n-    0x0420e3e9,     0x0460e3ea,     0x04a0e3eb,     0x04e0e3ec,\n-    0x25104042,     0x25104871,     0x25904861,     0x25904c92,\n-    0x05344020,     0x05744041,     0x05b44062,     0x05f44083,\n-    0x252c8840,     0x253c1420,     0x25681572,     0x25a21ce3,\n-    0x25ea1e34,     0x0522c020,     0x05e6c0a4,     0x2401a001,\n-    0x2443a051,     0x24858881,     0x24c78cd1,     0x24850891,\n-    0x24c70cc1,     0x250f9001,     0x25508051,     0x25802491,\n-    0x25df28c1,     0x25850c81,     0x251e10d1,     0x65816001,\n-    0x65c36051,     0x65854891,     0x65c74cc1,     0x05733820,\n-    0x05b238a4,     0x05f138e6,     0x0570396a,     0x65d0a001,\n-    0x65d6a443,     0x65d4a826,     0x6594ac26,     0x6554ac26,\n-    0x6556ac26,     0x6552ac26,     0x65cbac85,     0x65caac01,\n-    0x65dea833,     0x659ca509,     0x65d8a801,     0x65dcac01,\n-    0x655cb241,     0x0520a1e0,     0x0521a601,     0x052281e0,\n-    0x05238601,     0x04a14026,     0x0568aca7,     0x05b23230,\n-    0x853040af,     0xc5b040af,     0xe57080af,     0xe5b080af,\n+    0x0461943e,     0x04a19020,     0x04038100,     0x040381a0,\n+    0x040387e1,     0x04438be2,     0x04c38fe3,     0x040181e0,\n+    0x04018100,     0x04018621,     0x04418b22,     0x04418822,\n+    0x04818c23,     0x040081e0,     0x04008120,     0x04008761,\n+    0x04008621,     0x04408822,     0x04808c23,     0x042053ff,\n+    0x047f5401,     0x25208028,     0x2538cfe0,     0x2578d001,\n+    0x25b8efe2,     0x25f8f007,     0x2538dfea,     0x25b8dfeb,\n+    0xa400a3e0,     0xa420a7e0,     0xa4484be0,     0xa467afe0,\n+    0xa4a8a7ea,     0xa547a814,     0xa4084ffe,     0xa55c53e0,\n+    0xa5e1540b,     0xe400fbf6,     0xe408ffff,     0xe420e7e0,\n+    0xe4484be0,     0xe460efe0,     0xe547e400,     0xe4014be0,\n+    0xe4a84fe0,     0xe5f15000,     0x858043e0,     0x85a043ff,\n+    0xe59f5d08,     0x0420e3e9,     0x0460e3ea,     0x04a0e3eb,\n+    0x04e0e3ec,     0x25104042,     0x25104871,     0x25904861,\n+    0x25904c92,     0x05344020,     0x05744041,     0x05b44062,\n+    0x05f44083,     0x252c8840,     0x253c1420,     0x25681572,\n+    0x25a21ce3,     0x25ea1e34,     0x0522c020,     0x05e6c0a4,\n+    0x2401a001,     0x2443a051,     0x24858881,     0x24c78cd1,\n+    0x24850891,     0x24c70cc1,     0x250f9001,     0x25508051,\n+    0x25802491,     0x25df28c1,     0x25850c81,     0x251e10d1,\n+    0x65816001,     0x65c36051,     0x65854891,     0x65c74cc1,\n+    0x05733820,     0x05b238a4,     0x05f138e6,     0x0570396a,\n+    0x65d0a001,     0x65d6a443,     0x65d4a826,     0x6594ac26,\n+    0x6554ac26,     0x6556ac26,     0x6552ac26,     0x65cbac85,\n+    0x65caac01,     0x65dea833,     0x659ca509,     0x65d8a801,\n+    0x65dcac01,     0x655cb241,     0x0520a1e0,     0x0521a601,\n+    0x052281e0,     0x05238601,     0x04a14026,     0x0568aca7,\n+    0x05b23230,     0x853040af,     0xc5b040af,     0xe57080af,\n+    0xe5b080af,     0x25034440,     0x254054c4,     0x25034640,\n+    0x25415a05,     0x25834440,     0x25c54489,     0x250b5d3a,\n+    0x2550dc20,     0x2518e3e1,     0x2558e3e2,     0x2598e3e3,\n+    0x25d8e3e4,     0x2518e407,     0x05214800,     0x05614800,\n+    0x05a14800,     0x05e14800,     0x05214c00,     0x05614c00,\n+    0x05a14c00,     0x05e14c00,     0x05304001,     0x05314001,\n@@ -1245,12 +1299,13 @@\n-    0x65c80545,     0x0416a63e,     0x04001f8b,     0x0450979a,\n-    0x04dabe0d,     0x045381a5,     0x04918b4f,     0x049006cb,\n-    0x0497a264,     0x045eadd1,     0x04881062,     0x040a04d7,\n-    0x04810f71,     0x04dca450,     0x65c084c3,     0x65cd8d93,\n-    0x65c69a68,     0x65878ae0,     0x65c29db3,     0x049da0e6,\n-    0x6582b911,     0x65c0b6d6,     0x65c1a1e2,     0x65cda494,\n-    0x65c18107,     0x65af1493,     0x65e52b36,     0x65ab4ed0,\n-    0x65f06a8d,     0x0451448f,     0x049c7c86,     0x0429335d,\n-    0x04bc3162,     0x047a3027,     0x04e831d1,     0x05a56b15,\n-    0x05b66e35,     0x041a367d,     0x041832e4,     0x04d926f3,\n-    0x04482113,     0x04ca3a2e,     0x658727d5,     0x6586358a,\n-    0x65d82709,     0x044138c4,\n+    0x65c80545,     0x0416a63e,     0x04001f8b,     0x045a179a,\n+    0x04d09e0d,     0x045aa1a5,     0x04990b4f,     0x049386cb,\n+    0x04918264,     0x04500dd1,     0x0497b062,     0x041ea4d7,\n+    0x04980f71,     0x04c80450,     0x048a04c3,     0x04810d93,\n+    0x04dcba68,     0x65808ae0,     0x65cd9db3,     0x658680e6,\n+    0x65879911,     0x65c296d6,     0x04dda1e2,     0x65c2a494,\n+    0x65c0a107,     0x65c1b493,     0x65cdb569,     0x65819e05,\n+    0x65ad8c36,     0x65af1334,     0x65e63104,     0x65fd5e04,\n+    0x65eb6c49,     0x049a4423,     0x04916d11,     0x043330b8,\n+    0x04b032d1,     0x04603274,     0x04e432f1,     0x05b96ae4,\n+    0x05686d02,     0x049a33d8,     0x04583c24,     0x04592c13,\n+    0x04083a27,     0x04ca253b,     0x65c72e17,     0x65c63696,\n+    0x65d829bc,     0x04413787,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":155,"deletions":100,"binary":false,"changes":255,"status":"modified"}]}