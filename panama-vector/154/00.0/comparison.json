{"files":[{"patch":"@@ -4057,1 +4057,2 @@\n-                                              Register tmp, int masklen, int vec_enc) {\n+                                              Register tmp, int masklen, int masksize,\n+                                              int vec_enc) {\n@@ -4064,0 +4065,3 @@\n+  if (masksize < 16) {\n+    andq(tmp, (((jlong)1 << masklen) - 1));\n+  }\n@@ -4083,1 +4087,2 @@\n-                                              XMMRegister xtmp1, Register tmp, int masklen, int vec_enc) {\n+                                              XMMRegister xtmp1, Register tmp, int masklen, int masksize,\n+                                              int vec_enc) {\n@@ -4088,1 +4093,1 @@\n-  if (masklen < 64) {\n+  if (masksize < 16) {\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -230,1 +230,1 @@\n-  void vector_mask_operation(int opc, Register dst, KRegister mask, Register tmp, int masklen, int vec_enc);\n+  void vector_mask_operation(int opc, Register dst, KRegister mask, Register tmp, int masklen, int masksize, int vec_enc);\n@@ -233,1 +233,1 @@\n-                             Register tmp, int masklen, int vec_enc);\n+                             Register tmp, int masklen, int masksize, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4182,1 +4182,1 @@\n-  predicate(UseAVX > 0);\n+  predicate(UseAVX > 0 && Matcher::vector_length_in_bytes(n) >= 16);\n@@ -7936,1 +7936,1 @@\n-instruct vstoreMask2B(vec dst, vec src, immI_2 size) %{\n+instruct vstoreMask2B(vec dst, vec src, vec xtmp, immI_2 size) %{\n@@ -7939,1 +7939,1 @@\n-  effect(TEMP_DEF dst);\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7944,1 +7944,1 @@\n-    if (vlen <= 8 && UseAVX <= 2) {\n+    if (vlen <= 8) {\n@@ -7946,0 +7946,1 @@\n+      __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7947,1 +7948,1 @@\n-      __ packuswb($dst$$XMMRegister, $dst$$XMMRegister);\n+      __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7958,1 +7959,1 @@\n-instruct vstoreMask4B(vec dst, vec src, immI_4 size) %{\n+instruct vstoreMask4B(vec dst, vec src, vec xtmp, immI_4 size) %{\n@@ -7962,1 +7963,1 @@\n-  effect(TEMP_DEF dst);\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7966,1 +7967,1 @@\n-    if (vlen <= 4 && UseAVX <= 2) {\n+    if (vlen <= 4) {\n@@ -7968,0 +7969,1 @@\n+      __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7969,2 +7971,2 @@\n-      __ packusdw($dst$$XMMRegister, $dst$$XMMRegister);\n-      __ packuswb($dst$$XMMRegister, $dst$$XMMRegister);\n+      __ packusdw($dst$$XMMRegister, $xtmp$$XMMRegister);\n+      __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7973,0 +7975,1 @@\n+      __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n@@ -7975,1 +7978,1 @@\n-      __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+      __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n@@ -7982,1 +7985,1 @@\n-instruct storeMask8B(vec dst, vec src, immI_8 size) %{\n+instruct storeMask8B(vec dst, vec src, vec xtmp, immI_8 size) %{\n@@ -7985,0 +7988,1 @@\n+  effect(TEMP_DEF dst, TEMP xtmp);\n@@ -7988,0 +7992,1 @@\n+    __ pxor($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n@@ -7989,3 +7994,3 @@\n-    __ packssdw($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ packsswb($dst$$XMMRegister, $dst$$XMMRegister);\n-    __ pabsb($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ pabsd($dst$$XMMRegister, $dst$$XMMRegister);\n+    __ packusdw($dst$$XMMRegister, $xtmp$$XMMRegister);\n+    __ packuswb($dst$$XMMRegister, $xtmp$$XMMRegister);\n@@ -8000,1 +8005,1 @@\n-  effect(TEMP dst, TEMP vtmp);\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -8006,2 +8011,3 @@\n-    __ vpackssdw($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vpxor($vtmp$$XMMRegister, $vtmp$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n+    __ vpackssdw($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n+    __ vpacksswb($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n@@ -8652,1 +8658,1 @@\n-instruct vmask_tolong_evex(rRegL dst, kReg mask) %{\n+instruct vmask_tolong_evex(rRegL dst, kReg mask, rFlagsReg cr) %{\n@@ -8655,0 +8661,1 @@\n+  effect(TEMP dst, KILL cr);\n@@ -8657,0 +8664,2 @@\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8660,1 +8669,0 @@\n-      int mask_len = Matcher::vector_length(this, $mask);\n@@ -8664,0 +8672,6 @@\n+    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+    \/\/ operations needs to be clipped.\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    if (mask_size < 16) {\n+      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n+    }\n@@ -8668,1 +8682,1 @@\n-instruct vmask_tolong_avx(rRegL dst, vec mask, vec xtmp) %{\n+instruct vmask_tolong_avx(rRegL dst, vec mask, vec xtmp, rFlagsReg cr) %{\n@@ -8673,1 +8687,1 @@\n-  effect(TEMP xtmp);\n+  effect(TEMP_DEF dst, TEMP xtmp, KILL cr);\n@@ -8675,0 +8689,2 @@\n+    int mask_len = Matcher::vector_length(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8676,3 +8692,9 @@\n-     __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n-     __ vpsubb($xtmp$$XMMRegister, $xtmp$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n-     __ vpmovmskb($dst$$Register, $xtmp$$XMMRegister, vlen_enc);\n+    __ vpxor($xtmp$$XMMRegister, $xtmp$$XMMRegister, $xtmp$$XMMRegister, vlen_enc);\n+    __ vpsubb($xtmp$$XMMRegister, $xtmp$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n+    __ vpmovmskb($dst$$Register, $xtmp$$XMMRegister, vlen_enc);\n+    \/\/ Mask generated out of partial vector comparisons\/replicate\/mask manipulation\n+    \/\/ operations needs to be clipped.\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    if (mask_size < 16) {\n+      __ andq($dst$$Register, (((jlong)1 << mask_len) - 1));\n+    }\n@@ -8690,1 +8712,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8692,1 +8714,4 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len, vlen_enc);\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register,\n+                             mask_len, mask_size, vlen_enc);\n@@ -8704,1 +8729,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8706,0 +8731,2 @@\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n@@ -8707,1 +8734,1 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, vlen_enc);\n+                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n@@ -8720,1 +8747,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8722,1 +8749,4 @@\n-    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len, vlen_enc);\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n+    __ vector_mask_operation(opcode, $dst$$Register, $mask$$KRegister, $tmp$$Register, mask_len,\n+                             mask_size, vlen_enc);\n@@ -8735,1 +8765,1 @@\n-    int vlen_enc = vector_length_encoding(this, $mask);\n+    BasicType mbt = Matcher::vector_element_basic_type(this, $mask);\n@@ -8737,0 +8767,2 @@\n+    int mask_size = mask_len * type2aelembytes(mbt);\n+    int vlen_enc = vector_length_encoding(this, $mask);\n@@ -8738,1 +8770,1 @@\n-                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, vlen_enc);\n+                             $xtmp1$$XMMRegister, $tmp$$Register, mask_len, mask_size, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":65,"deletions":33,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -2411,0 +2411,11 @@\n+  \/\/ Safety check to prevent casting if source mask is of type vector\n+  \/\/ and destination mask of type predicate vector and vice-versa.\n+  \/\/ From X86 standpoint, this case will only arise over KNL target,\n+  \/\/ where certain masks (depending on the species) are either propagated\n+  \/\/ through a vector or predicate register.\n+  if (is_mask &&\n+      ((src_type->isa_vectmask() == NULL && dst_type->isa_vectmask()) ||\n+       (dst_type->isa_vectmask() == NULL && src_type->isa_vectmask()))) {\n+    return false;\n+  }\n+\n@@ -2473,2 +2484,2 @@\n-        if((dst_type->isa_vectmask() && src_type->isa_vectmask()) ||\n-           (type2aelembytes(elem_bt_from) == type2aelembytes(elem_bt_to))) {\n+        if ((dst_type->isa_vectmask() && src_type->isa_vectmask()) ||\n+            (type2aelembytes(elem_bt_from) == type2aelembytes(elem_bt_to))) {\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":13,"deletions":2,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -519,1 +519,1 @@\n-     * @throws IndexOutOfBoundsException if the index is is out of range\n+     * @throws IndexOutOfBoundsException if the index is out of range\n@@ -574,1 +574,1 @@\n-    public abstract <F> VectorMask<F> check(Class<? extends VectorMask<F>> maskClass, Vector<F> vector);\n+    abstract <F> VectorMask<F> check(Class<? extends VectorMask<F>> maskClass, Vector<F> vector);\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/VectorMask.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}