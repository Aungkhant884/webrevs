{"files":[{"patch":"@@ -2508,2 +2508,2 @@\n-  \/\/ Limit the min vector size to 8 bytes for NEON, 16 bytes for SVE\n-  int size = (UseSVE > 0 ? 16 : 8) \/ type2aelembytes(bt);\n+  \/\/ Limit the min vector size to 8 bytes.\n+  int size = 8 \/ type2aelembytes(bt);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -155,3 +155,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n-                                   PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n-                                   int opcode, Register base, int index, int size, int disp) {\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n@@ -218,0 +218,1 @@\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n@@ -220,1 +221,1 @@\n-        \/\/ No multiply reduction instructions\n+      \/\/ No multiply reduction instructions\n@@ -225,1 +226,1 @@\n-        \/\/ Others\n+      \/\/ Others\n@@ -232,3 +233,2 @@\n-        \/\/ Currently the implementation for partial vectors are not implemented yet.\n-        \/\/ Will add them in a separate patch.\n-        return vlen * type2aelembytes(bt) == MaxVectorSize;\n+        \/\/ Partial size of gather\/scatter are not supported for now.\n+        return length_in_bytes == MaxVectorSize;\n@@ -241,0 +241,3 @@\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        return Matcher::vector_size_supported(bt, vlen);\n@@ -245,2 +248,1 @@\n-    int length_in_bytes = vlen * type2aelembytes(bt);\n-    return 16 <= length_in_bytes && length_in_bytes <= MaxVectorSize;\n+    return 16 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;\n@@ -269,3 +271,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -285,3 +287,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n-                         bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -295,2 +297,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 2 &&\n-            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 2);\n@@ -298,1 +299,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -307,2 +308,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 2 &&\n-            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 2);\n@@ -310,1 +310,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -319,2 +319,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 4 &&\n-            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 4);\n@@ -322,1 +321,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -331,2 +330,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 4 &&\n-            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 4);\n@@ -334,1 +332,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -343,2 +341,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 8 &&\n-            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 8);\n@@ -346,1 +343,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -355,2 +352,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 8 &&\n-            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 8);\n@@ -358,1 +354,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -367,2 +363,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 16 &&\n-            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 16);\n@@ -370,1 +365,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -379,2 +374,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 16 &&\n-            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 16);\n@@ -382,1 +376,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -400,1 +394,1 @@\n-            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask (sve)\" %}\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector predicated\" %}\n@@ -407,3 +401,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n-                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -422,1 +416,1 @@\n-            \"sve_str $src, $pTmp, $mem\\t # store vector mask (sve)\" %}\n+            \"sve_str $src, $pTmp, $mem\\t # store vector predicated\" %}\n@@ -429,3 +423,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n-                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -472,0 +466,1 @@\n+\n@@ -1227,2 +1222,1 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n@@ -1238,1 +1232,1 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n@@ -1241,4 +1235,2 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n-                   as_FloatRegister($src$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n-               as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n@@ -1255,2 +1247,2 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n@@ -1259,6 +1251,3 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n-                   as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n-                   as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n-               as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n@@ -1275,3 +1264,3 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n@@ -1280,8 +1269,4 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n-                   as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n-                   as_FloatRegister($dst$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n-                   as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n-               as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n@@ -1311,3 +1296,3 @@\n-  format %{ \"sve_dup $tmp, 0\\n\\t\"\n-            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n-            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (H to B)\" %}\n@@ -1330,4 +1315,4 @@\n-  format %{ \"sve_dup $tmp, 0\\n\\t\"\n-            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (S to B)\" %}\n@@ -1351,5 +1336,5 @@\n-  format %{ \"sve_dup $tmp, 0\\n\\t\"\n-            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n+            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (D to B)\" %}\n@@ -1383,3 +1368,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1402,3 +1387,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1424,3 +1409,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n-                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1445,3 +1430,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n-                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1964,1 +1949,1 @@\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n@@ -1990,1 +1975,1 @@\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n@@ -2168,1 +2153,1 @@\n-  format %{ \"sve_reduce_S $dst, $src1, $src2\\t# reduce max S partial (sve)\" %}\n+  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# reduce max S partial (sve)\" %}\n@@ -2186,1 +2171,1 @@\n-  format %{ \"sve_reduce_D $dst, $src1, $src2\\t# reduce max D partial (sve)\" %}\n+  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# reduce max D partial (sve)\" %}\n@@ -2362,1 +2347,1 @@\n-  format %{ \"sve_reduce_S $dst, $src1, $src2\\t# reduce min S partial (sve)\" %}\n+  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# reduce min S partial (sve)\" %}\n@@ -2380,1 +2365,1 @@\n-  format %{ \"sve_reduce_D $dst, $src1, $src2\\t# reduce min D partial (sve)\" %}\n+  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# reduce min D partial (sve)\" %}\n@@ -3050,0 +3035,14 @@\n+\/\/ vector mask cast\n+\n+instruct vmaskcast(vReg dst) %{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst (VectorMaskCast dst));\n+  ins_cost(0);\n+  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n@@ -3091,1 +3090,0 @@\n-\n@@ -3226,1 +3224,0 @@\n-\n@@ -3247,1 +3244,0 @@\n-\n@@ -3282,1 +3278,0 @@\n-\n@@ -3302,1 +3297,0 @@\n-\n@@ -3339,1 +3333,0 @@\n-\n@@ -3392,1 +3385,0 @@\n-\n@@ -3438,1 +3430,0 @@\n-\n@@ -3475,2 +3466,0 @@\n-\n-\n@@ -3517,2 +3506,0 @@\n-\n-\n@@ -3534,1 +3521,0 @@\n-\n@@ -3760,1 +3746,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -3784,1 +3770,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -3808,1 +3794,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -3832,1 +3818,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -3857,1 +3843,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -3881,1 +3867,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -4003,0 +3989,1 @@\n+\n@@ -4038,2 +4025,2 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to S)\" %}\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\t# vector load shuffle (B to S)\" %}\n@@ -4054,3 +4041,3 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to D)\" %}\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\t# vector load shuffle (B to D)\" %}\n@@ -4070,1 +4057,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n@@ -4084,1 +4071,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 2);\n@@ -4087,1 +4074,1 @@\n-  format %{ \"sve_tbl $dst, H, $src, $shuffle\\t# vector rearrange (S)\" %}\n+  format %{ \"sve_tbl $dst, H, $src, $shuffle\\t# vector rearrange (H)\" %}\n@@ -4098,15 +4085,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n-  match(Set dst (VectorRearrange src shuffle));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_tbl $dst, S, $src, $shuffle\\t# vector rearrange (I)\" %}\n-  ins_encode %{\n-    __ sve_tbl(as_FloatRegister($dst$$reg), __ S,\n-               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct rearrangeF(vReg dst, vReg src, vReg shuffle)\n-%{\n-  predicate(UseSVE > 0 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 4);\n@@ -4115,1 +4088,1 @@\n-  format %{ \"sve_tbl $dst, S, $src, $shuffle\\t# vector rearrange (F)\" %}\n+  format %{ \"sve_tbl $dst, S, $src, $shuffle\\t# vector rearrange (S)\" %}\n@@ -4126,15 +4099,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (VectorRearrange src shuffle));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_tbl $dst, D, $src, $shuffle\\t# vector rearrange (L)\" %}\n-  ins_encode %{\n-    __ sve_tbl(as_FloatRegister($dst$$reg), __ D,\n-               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct rearrangeD(vReg dst, vReg src, vReg shuffle)\n-%{\n-  predicate(UseSVE > 0 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 8);\n@@ -4152,1 +4111,2 @@\n-instruct gatherI(vReg dst, vmemA mem, vReg idx) %{\n+\n+instruct gatherI(vReg dst, indirect mem, vReg idx) %{\n@@ -4165,1 +4125,1 @@\n-instruct gatherL(vReg dst, vmemA mem, vReg idx) %{\n+instruct gatherL(vReg dst, indirect mem, vReg idx) %{\n@@ -4180,14 +4140,0 @@\n-\/\/ vector mask cast\n-\n-instruct vmaskcast(vReg dst) %{\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n-            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n-  match(Set dst (VectorMaskCast dst));\n-  ins_cost(0);\n-  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n-  ins_encode %{\n-    \/\/ empty\n-  %}\n-  ins_pipe(pipe_class_empty);\n-%}\n-\n@@ -4195,1 +4141,2 @@\n-instruct scatterI(vmemA mem, vReg src, vReg idx) %{\n+\n+instruct scatterI(indirect mem, vReg src, vReg idx) %{\n@@ -4208,1 +4155,1 @@\n-instruct scatterL(vmemA mem, vReg src, vReg idx) %{\n+instruct scatterL(indirect mem, vReg src, vReg idx) %{\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":127,"deletions":180,"binary":false,"changes":307,"status":"modified"},{"patch":"@@ -150,3 +150,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n-                                   PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n-                                   int opcode, Register base, int index, int size, int disp) {\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n@@ -213,0 +213,1 @@\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n@@ -215,1 +216,1 @@\n-        \/\/ No multiply reduction instructions\n+      \/\/ No multiply reduction instructions\n@@ -220,1 +221,1 @@\n-        \/\/ Others\n+      \/\/ Others\n@@ -227,3 +228,2 @@\n-        \/\/ Currently the implementation for partial vectors are not implemented yet.\n-        \/\/ Will add them in a separate patch.\n-        return vlen * type2aelembytes(bt) == MaxVectorSize;\n+        \/\/ Partial size of gather\/scatter are not supported for now.\n+        return length_in_bytes == MaxVectorSize;\n@@ -236,0 +236,3 @@\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        return Matcher::vector_size_supported(bt, vlen);\n@@ -240,2 +243,1 @@\n-    int length_in_bytes = vlen * type2aelembytes(bt);\n-    return 16 <= length_in_bytes && length_in_bytes <= MaxVectorSize;\n+    return 16 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;\n@@ -272,3 +274,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -288,3 +290,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n-                         bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -300,2 +302,1 @@\n-  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4 &&\n-            `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() < MaxVectorSize);\n+  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4);\n@@ -303,1 +304,1 @@\n-  ins_cost(4 * SVE_COST);\n+  ins_cost(4 * INSN_COST);\n@@ -330,1 +331,1 @@\n-            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask (sve)\" %}\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector predicated\" %}\n@@ -337,3 +338,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg,\n-                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -352,1 +353,1 @@\n-            \"sve_str $src, $pTmp, $mem\\t # store vector mask (sve)\" %}\n+            \"sve_str $src, $pTmp, $mem\\t # store vector predicated\" %}\n@@ -359,3 +360,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg,\n-                         as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -420,0 +421,1 @@\n+\n@@ -852,2 +854,1 @@\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n-               as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n@@ -863,1 +864,1 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n@@ -866,4 +867,2 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n-                   as_FloatRegister($src$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue,\n-               as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n@@ -880,2 +879,2 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n@@ -884,6 +883,3 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n-                   as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n-                   as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue,\n-               as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n@@ -900,3 +896,3 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n@@ -905,8 +901,4 @@\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H,\n-                   as_FloatRegister($src$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S,\n-                   as_FloatRegister($dst$$reg));\n-    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D,\n-                   as_FloatRegister($dst$$reg));\n-    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue,\n-               as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n@@ -936,3 +928,3 @@\n-  format %{ \"sve_dup $tmp, 0\\n\\t\"\n-            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n-            \"sve_neg $dst, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (H to B)\" %}\n@@ -955,4 +947,4 @@\n-  format %{ \"sve_dup $tmp, 0\\n\\t\"\n-            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (S to B)\" %}\n@@ -976,5 +968,5 @@\n-  format %{ \"sve_dup $tmp, 0\\n\\t\"\n-            \"sve_uzp1 $dst, $src, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n-            \"sve_uzp1 $dst, $dst, $tmp\\n\\t\"\n-            \"sve_neg $dst, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n+            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (D to B)\" %}\n@@ -1010,3 +1002,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1038,3 +1030,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n-                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1441,1 +1433,1 @@\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n@@ -1467,1 +1459,1 @@\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n@@ -1503,2 +1495,2 @@\n-dnl REDUCE_MAXMIN_I_PARTIAL($1\n-dnl REDUCE_MAXMIN_I_PARTIAL(min_max, reg_src,\n+dnl REDUCE_MAXMIN_I_PARTIAL($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_mame, cmp)\n@@ -1530,2 +1522,2 @@\n-dnl REDUCE_MAXMIN_L_PARTIAL($1\n-dnl REDUCE_MAXMIN_L_PARTIAL(min_max, reg_src,\n+dnl REDUCE_MAXMIN_L_PARTIAL($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name, cmp)\n@@ -1583,1 +1575,1 @@\n-  format %{ \"sve_reduce_$4 $dst, $src1, $src2\\t# reduce $1 $4 partial (sve)\" %}\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# reduce $1 $4 partial (sve)\" %}\n@@ -1807,0 +1799,14 @@\n+\/\/ vector mask cast\n+\n+instruct vmaskcast(vReg dst) %{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst (VectorMaskCast dst));\n+  ins_cost(0);\n+  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n@@ -1826,1 +1832,1 @@\n-\n+dnl\n@@ -1912,1 +1918,1 @@\n-\n+dnl\n@@ -1936,1 +1942,1 @@\n-\n+dnl\n@@ -1958,1 +1964,1 @@\n-\n+dnl\n@@ -1981,1 +1987,1 @@\n-\n+dnl\n@@ -2004,1 +2010,1 @@\n-\n+dnl\n@@ -2024,1 +2030,1 @@\n-\n+dnl\n@@ -2045,1 +2051,1 @@\n-\n+dnl\n@@ -2068,2 +2074,1 @@\n-\n-\n+dnl\n@@ -2094,2 +2099,1 @@\n-\n-\n+dnl\n@@ -2114,1 +2118,1 @@\n-\n+dnl\n@@ -2255,1 +2259,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -2285,1 +2289,1 @@\n-            \"sve_cmpeq $pTmp, $dst, ($idx-#16) \/\/ shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n@@ -2337,0 +2341,1 @@\n+\n@@ -2372,2 +2377,2 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to S)\" %}\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\t# vector load shuffle (B to S)\" %}\n@@ -2388,3 +2393,3 @@\n-  format %{ \"sve_uunpklo $dst, $src\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\n\\t\"\n-            \"sve_uunpklo $dst, $dst\\t# vector load shuffle (B to D)\" %}\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\t# vector load shuffle (B to D)\" %}\n@@ -2405,1 +2410,1 @@\n-            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == $2);\n@@ -2408,1 +2413,1 @@\n-  format %{ \"sve_tbl $dst, $2, $src, $shuffle\\t# vector rearrange ($1)\" %}\n+  format %{ \"sve_tbl $dst, $3, $src, $shuffle\\t# vector rearrange ($3)\" %}\n@@ -2410,1 +2415,1 @@\n-    __ sve_tbl(as_FloatRegister($dst$$reg), __ $2,\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ $3,\n@@ -2415,7 +2420,5 @@\n-dnl              $1 $2\n-VECTOR_REARRANGE(B, B)\n-VECTOR_REARRANGE(S, H)\n-VECTOR_REARRANGE(I, S)\n-VECTOR_REARRANGE(F, S)\n-VECTOR_REARRANGE(L, D)\n-VECTOR_REARRANGE(D, D)\n+dnl              $1 $2 $3\n+VECTOR_REARRANGE(B, 1, B)\n+VECTOR_REARRANGE(S, 2, H)\n+VECTOR_REARRANGE(I, 4, S)\n+VECTOR_REARRANGE(L, 8, D)\n@@ -2424,1 +2427,2 @@\n-instruct gatherI(vReg dst, vmemA mem, vReg idx) %{\n+\n+instruct gatherI(vReg dst, indirect mem, vReg idx) %{\n@@ -2437,1 +2441,1 @@\n-instruct gatherL(vReg dst, vmemA mem, vReg idx) %{\n+instruct gatherL(vReg dst, indirect mem, vReg idx) %{\n@@ -2452,14 +2456,0 @@\n-\/\/ vector mask cast\n-\n-instruct vmaskcast(vReg dst) %{\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n-            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n-  match(Set dst (VectorMaskCast dst));\n-  ins_cost(0);\n-  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n-  ins_encode %{\n-    \/\/ empty\n-  %}\n-  ins_pipe(pipe_class_empty);\n-%}\n-\n@@ -2467,1 +2457,2 @@\n-instruct scatterI(vmemA mem, vReg src, vReg idx) %{\n+\n+instruct scatterI(indirect mem, vReg src, vReg idx) %{\n@@ -2480,1 +2471,1 @@\n-instruct scatterL(vmemA mem, vReg src, vReg idx) %{\n+instruct scatterL(indirect mem, vReg src, vReg idx) %{\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":117,"deletions":126,"binary":false,"changes":243,"status":"modified"},{"patch":"@@ -3229,1 +3229,1 @@\n-  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm16) {\n+  void sve_dup(FloatRegister Zd, SIMD_RegVariant T, int imm8) {\n@@ -3233,2 +3233,1 @@\n-    unsigned imm = imm16;\n-    if (imm16 <= 127 && imm16 >= -128) {\n+    if (imm8 <= 127 && imm8 >= -128) {\n@@ -3236,1 +3235,1 @@\n-    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n+    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n@@ -3238,1 +3237,1 @@\n-      imm = (imm >> 8);\n+      imm8 = (imm8 >> 8);\n@@ -3242,2 +3241,0 @@\n-    unsigned mask = (1U << 8) - 1;\n-    imm &= mask;\n@@ -3245,1 +3242,1 @@\n-    f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n+    f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n@@ -3254,2 +3251,10 @@\n-   \/\/ SVE cpy immediate\n-  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm16, bool isMerge) {\n+  \/\/ SVE cpy general-purpose register\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, Register Rn) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b101000101, 21, 13);\n+    pgrf(Pg, 10), srf(Rn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE cpy immediate\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm8, bool isMerge) {\n@@ -3259,2 +3264,1 @@\n-    unsigned imm = imm16;\n-    if (imm16 <= 127 && imm16 >= -128) {\n+    if (imm8 <= 127 && imm8 >= -128) {\n@@ -3262,1 +3266,1 @@\n-    } else if (T != B && imm16 <= 32512 && imm16 >= -32768 && (imm16 & 0xff) == 0) {\n+    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n@@ -3264,1 +3268,1 @@\n-      imm = (imm >> 8);\n+      imm8 = (imm8 >> 8);\n@@ -3268,2 +3272,0 @@\n-    unsigned mask = (1U << 8) - 1;\n-    imm &= mask;\n@@ -3272,1 +3274,1 @@\n-    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), f(imm, 12, 5), rf(Zd, 0);\n+    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n@@ -3275,6 +3277,3 @@\n-  \/\/ SVE vector sel\n-  void sve_sel(FloatRegister Zd,\n-               SIMD_RegVariant T,\n-               PRegister Pg,\n-               FloatRegister Zn,\n-               FloatRegister Zm) {\n+  \/\/ SVE sel (vectors)\n+  void sve_sel(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg,\n+               FloatRegister Zn, FloatRegister Zm) {\n@@ -3287,1 +3286,1 @@\n-\/\/ SVE compare vector\n+\/\/ SVE compare vectors\n@@ -3315,3 +3314,1 @@\n-    if (imm5 > 15 || imm5 < -16) {                                                       \\\n-      guarantee(false, \"invalid immediate\");                                             \\\n-    }                                                                                    \\\n+    guarantee(-16 <= imm5 && imm5 <= 15, \"invalid immediate\");                           \\\n@@ -3345,1 +3342,1 @@\n-\/\/ SVE vector uzp1,uzp2\n+\/\/ SVE uzp1\/uzp2 (vectors)\n@@ -3378,14 +3375,10 @@\n-private:\n-\n-  void encode_cvtf_T(SIMD_RegVariant T_dst, SIMD_RegVariant T_src,\n-                     unsigned& opc, unsigned& opc2) {\n-    assert(T_src != B && T_dst != B &&\n-           T_src != Q && T_dst != Q, \"invalid register variant\");\n-    if (T_dst != D) {\n-      assert(T_dst <= T_src, \"invalid register variant\");\n-    } else {\n-      assert(T_src != H, \"invalid register variant\");\n-    }\n-    \/\/ In most cases we can treat T_dst,T_src as opc,opc2\n-    \/\/ except following four cases. These cases should be converted\n-    \/\/ according to Arm's architecture reference manual:\n+  \/\/ SVE convert signed integer to floating-point (predicated)\n+  void sve_scvtf(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                 FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           (T_src != H || T_dst == T_src), \"invalid register variant\");\n+    int opc = T_dst;\n+    int opc2 = T_src;\n+    \/\/ In most cases we can treat T_dst, T_src as opc, opc2,\n+    \/\/ except for the following two combinations.\n@@ -3395,4 +3388,2 @@\n-    \/\/ |  11 |   00 | 0 | SCVTF — 32-bit to double-precision |\n-    \/\/ |  11 |   00 | 1 | UCVTF — 32-bit to double-precision |\n-    \/\/ |  11 |   10 | 0 | SCVTF — 64-bit to single-precision |\n-    \/\/ |  11 |   10 | 1 | UCVTF — 64-bit to single-precision |\n+    \/\/ |  11 |   00 | 0 | SCVTF - 32-bit to double-precision |\n+    \/\/ |  11 |   10 | 0 | SCVTF - 64-bit to single-precision |\n@@ -3400,59 +3391,6 @@\n-    if (T_dst == S && T_src == D) { \/\/ 64-bit to single-precision\n-      T_dst = D;\n-      T_src = S;\n-    } else if (T_dst == D && T_src == S) { \/\/ 32-bit to double-precision\n-      T_dst = D;\n-      T_src = B;\n-    }\n-    opc = T_dst;\n-    opc2 = T_src;\n-  }\n-public:\n-\n-\/\/ SVE convert integer to floating-point (predicated)\n-#define INSN(NAME, sign)                                                \\\n-  void NAME(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,      \\\n-            FloatRegister Zn, SIMD_RegVariant T_src) {                  \\\n-    starti;                                                             \\\n-    unsigned opc, opc2;                                                 \\\n-    encode_cvtf_T(T_dst, T_src, opc, opc2);                             \\\n-    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b010, 21, 19);            \\\n-    f(opc2, 18, 17), f(sign, 16), f(0b101, 15, 13);                     \\\n-    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);                                 \\\n-  }\n-\n-  INSN(sve_scvtf, 0b0);\n-  INSN(sve_ucvtf, 0b1);\n-#undef INSN\n-\n-private:\n-\n-  void encode_fcvt_T(SIMD_RegVariant T_src,SIMD_RegVariant T_dst,\n-                     unsigned& opc, unsigned& opc2) {\n-    assert(T_src != B && T_dst != B &&\n-           T_src != Q && T_dst != Q, \"invalid register variant\");\n-    assert(T_src != T_dst, \"invalid register variant\");\n-    if (T_src == S) {\n-      if (T_dst == H) {\n-        opc = 0b10;\n-        opc2 = 0b00;\n-      } else if (T_dst == D) {\n-        opc = 0b11;\n-        opc2 = 0b11;\n-      }\n-    } else if (T_src == H) {\n-      if (T_dst == S) {\n-        opc = 0b10;\n-        opc2 = 0b01;\n-      } else if (T_dst == D) {\n-        opc = 0b11;\n-        opc2 = 0b01;\n-      }\n-    } else if (T_src == D) {\n-      if (T_dst == H) {\n-        opc = 0b11;\n-        opc2 = 0b00;\n-      } else if (T_dst == S) {\n-        opc = 0b11;\n-        opc2 = 0b10;\n-      }\n+    if (T_src == S && T_dst == D) {\n+      opc = 0b11;\n+      opc2 = 0b00;\n+    } else if (T_src == D && T_dst == S) {\n+      opc = 0b11;\n+      opc2 = 0b10;\n@@ -3460,11 +3398,2 @@\n-  }\n-public:\n-\n-\/\/ SVE floating-point convert precision (predicated)\n-  void sve_fcvt(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n-            FloatRegister Zn, SIMD_RegVariant T_src) {\n-    starti;\n-    unsigned opc, opc2;\n-    encode_fcvt_T(T_src, T_dst, opc, opc2);\n-    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b0010, 21, 18);\n-    f(opc2, 17, 16), f(0b101, 15, 13);\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b010, 21, 19);\n+    f(opc2, 18, 17), f(0b0101, 16, 13);\n@@ -3474,14 +3403,10 @@\n-private:\n-\n-  void encode_fcvtz_T (SIMD_RegVariant T_dst, SIMD_RegVariant T_src,\n-                       unsigned& opc, unsigned& opc2) {\n-    assert(T_src != B && T_dst != B &&\n-           T_src != Q && T_dst != Q, \"invalid register variant\");\n-    if (T_src != D) {\n-      assert(T_src <= T_dst, \"invalid register variant\");\n-    } else {\n-      assert(T_dst != H, \"invalid register variant\");\n-    }\n-    \/\/ In most cases we can treat T_dst,T_src as opc2,opc\n-    \/\/ except following four cases. These cases should be converted\n-    \/\/ according to Arm's architecture reference manual:\n+  \/\/ SVE floating-point convert to signed integer, rounding toward zero (predicated)\n+  void sve_fcvtzs(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                  FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           (T_dst != H || T_src == H), \"invalid register variant\");\n+    int opc = T_src;\n+    int opc2 = T_dst;\n+    \/\/ In most cases we can treat T_src, T_dst as opc, opc2,\n+    \/\/ except for the following two combinations.\n@@ -3489,1 +3414,1 @@\n-    \/\/ | opc | opc2 | U |        Instruction Details          |\n+    \/\/ | opc | opc2 | U |         Instruction Details         |\n@@ -3491,4 +3416,2 @@\n-    \/\/ |  11 |   10 | 0 | FCVTZS — Single-precision to 64-bit |\n-    \/\/ |  11 |   10 | 1 | FCVTZU — Single-precision to 64-bit |\n-    \/\/ |  11 |   00 | 0 | FCVTZS — Double-precision to 32-bit |\n-    \/\/ |  11 |   00 | 1 | FCVTZU — Double-precision to 32-bit |\n+    \/\/ |  11 |  10  | 0 | FCVTZS - single-precision to 64-bit |\n+    \/\/ |  11 |  00  | 0 | FCVTZS - double-precision to 32-bit |\n@@ -3496,6 +3419,6 @@\n-    if (T_dst == D && T_src == S) { \/\/ Single-precision to 64-bit\n-      T_dst = S;\n-      T_src = D;\n-    } else if (T_dst == S && T_src == D) { \/\/ Double-precision to 32-bit\n-      T_dst = B;\n-      T_src = D;\n+    if (T_src == S && T_dst == D) {\n+      opc = 0b11;\n+      opc2 = 0b10;\n+    } else if (T_src == D && T_dst == S) {\n+      opc = 0b11;\n+      opc2 = 0b00;\n@@ -3503,2 +3426,3 @@\n-    opc = T_src;\n-    opc2 = T_dst;\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b011, 21, 19);\n+    f(opc2, 18, 17), f(0b0101, 16, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n@@ -3506,1 +3430,0 @@\n-public:\n@@ -3508,10 +3431,10 @@\n-\/\/ SVE floating-point convert to integer (predicated)\n-#define INSN(NAME, sign)                                                \\\n-  void NAME(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,      \\\n-            FloatRegister Zn, SIMD_RegVariant T_src) {                  \\\n-    starti;                                                             \\\n-    unsigned opc, opc2;                                                 \\\n-    encode_fcvtz_T(T_dst, T_src, opc, opc2);                            \\\n-    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b011, 21, 19);            \\\n-    f(opc2, 18, 17), f(sign, 16), f(0b101, 15, 13);                     \\\n-    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);                                 \\\n+  \/\/ SVE floating-point convert precision (predicated)\n+  void sve_fcvt(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           T_src != T_dst, \"invalid register variant\");\n+    guarantee(T_src != H && T_dst != H, \"half-precision unsupported\");\n+    f(0b01100101, 31, 24), f(0b11, 23, 22), f(0b0010, 21, 18);\n+    f(T_dst, 17, 16), f(0b101, 15, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n@@ -3520,4 +3443,0 @@\n-  INSN(sve_fcvtzs, 0b0);\n-  INSN(sve_fcvtzu, 0b1);\n-#undef INSN\n-\n@@ -3549,11 +3468,2 @@\n-\/\/ SVE cpy general-purpose register\n-  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, Register Rn) {\n-    starti;\n-    assert(T != Q, \"invalid size\");\n-    f(0b00000101, 31, 24), f(T, 23, 22), f(0b101000101, 21, 13);\n-    pgrf(Pg, 10), srf(Rn, 5), rf(Zd, 0);\n-  }\n-\n-\/\/ SVE INDEX (immediates)\n-  void sve_index(FloatRegister Zd, SIMD_RegVariant T,\n-                 int imm1, int imm2) {\n+  \/\/ SVE INDEX (immediates)\n+  void sve_index(FloatRegister Zd, SIMD_RegVariant T, int imm1, int imm2) {\n@@ -3566,1 +3476,1 @@\n-\/\/ SVE programmable table lookup in single vector table\n+  \/\/ SVE programmable table lookup in single vector table\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":80,"deletions":170,"binary":false,"changes":250,"status":"modified"},{"patch":"@@ -2707,1 +2707,3 @@\n-  if (restore_vectors) {\n+  \/\/ We may use predicate registers and rely on ptrue with SVE,\n+  \/\/ regardless of wide vector (> 8 bytes) used or not.\n+  if (use_sve) {\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -481,1 +481,0 @@\n-  \/\/ TODO shuffle is not supported on SVE\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1594,1 +1594,6 @@\n-                        [\"ucvtf\",   \"__ sve_ucvtf(z3, __ D, p1, z2, __ S);\",              \"ucvtf\\tz3.d, p1\/m, z2.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z3, __ D, p1, z2, __ D);\",              \"scvtf\\tz3.d, p1\/m, z2.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p2, z1, __ D);\",              \"scvtf\\tz6.s, p2\/m, z1.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p3, z1, __ S);\",              \"scvtf\\tz6.s, p3\/m, z1.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ S);\",              \"scvtf\\tz6.h, p3\/m, z1.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ D);\",              \"scvtf\\tz6.h, p3\/m, z1.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ H);\",              \"scvtf\\tz6.h, p3\/m, z1.h\"],\n@@ -1596,2 +1601,6 @@\n-                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z18, __ D);\",           \"fcvtzs\\tz19.d, p2\/m, z18.d\"],\n-                        [\"fcvtzu\",  \"__ sve_fcvtzu(z19, __ D, p2, z18, __ D);\",           \"fcvtzu\\tz19.d, p2\/m, z18.d\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z1, __ S, p3, z0, __ D);\",               \"fcvt\\tz1.s, p3\/m, z0.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z1, __ D);\",            \"fcvtzs\\tz19.d, p2\/m, z1.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z9, __ S, p1, z8, __ S);\",             \"fcvtzs\\tz9.s, p1\/m, z8.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p2, z0, __ D);\",             \"fcvtzs\\tz1.s, p2\/m, z0.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ D, p3, z0, __ S);\",             \"fcvtzs\\tz1.d, p3\/m, z0.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p4, z18, __ H);\",            \"fcvtzs\\tz1.s, p4\/m, z18.h\"],\n@@ -1677,0 +1686,1 @@\n+                       [\"bic\", \"ZZZ\"],\n@@ -1679,1 +1689,0 @@\n-                       [\"bic\", \"ZZZ\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":13,"deletions":4,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -781,1 +781,6 @@\n-    __ sve_ucvtf(z3, __ D, p1, z2, __ S);              \/\/       ucvtf   z3.d, p1\/m, z2.s\n+    __ sve_scvtf(z3, __ D, p1, z2, __ D);              \/\/       scvtf   z3.d, p1\/m, z2.d\n+    __ sve_scvtf(z6, __ S, p2, z1, __ D);              \/\/       scvtf   z6.s, p2\/m, z1.d\n+    __ sve_scvtf(z6, __ S, p3, z1, __ S);              \/\/       scvtf   z6.s, p3\/m, z1.s\n+    __ sve_scvtf(z6, __ H, p3, z1, __ S);              \/\/       scvtf   z6.h, p3\/m, z1.s\n+    __ sve_scvtf(z6, __ H, p3, z1, __ D);              \/\/       scvtf   z6.h, p3\/m, z1.d\n+    __ sve_scvtf(z6, __ H, p3, z1, __ H);              \/\/       scvtf   z6.h, p3\/m, z1.h\n@@ -783,2 +788,6 @@\n-    __ sve_fcvtzs(z19, __ D, p2, z18, __ D);           \/\/       fcvtzs  z19.d, p2\/m, z18.d\n-    __ sve_fcvtzu(z19, __ D, p2, z18, __ D);           \/\/       fcvtzu  z19.d, p2\/m, z18.d\n+    __ sve_fcvt(z1, __ S, p3, z0, __ D);               \/\/       fcvt    z1.s, p3\/m, z0.d\n+    __ sve_fcvtzs(z19, __ D, p2, z1, __ D);            \/\/       fcvtzs  z19.d, p2\/m, z1.d\n+    __ sve_fcvtzs(z9, __ S, p1, z8, __ S);             \/\/       fcvtzs  z9.s, p1\/m, z8.s\n+    __ sve_fcvtzs(z1, __ S, p2, z0, __ D);             \/\/       fcvtzs  z1.s, p2\/m, z0.d\n+    __ sve_fcvtzs(z1, __ D, p3, z0, __ S);             \/\/       fcvtzs  z1.d, p3\/m, z0.s\n+    __ sve_fcvtzs(z1, __ S, p4, z18, __ H);            \/\/       fcvtzs  z1.s, p4\/m, z18.h\n@@ -970,3 +979,3 @@\n-    __ sve_uzp1(z8, __ D, z20, z16);                   \/\/       uzp1    z8.d, z20.d, z16.d\n-    __ sve_uzp2(z15, __ S, z4, z4);                    \/\/       uzp2    z15.s, z4.s, z4.s\n-    __ sve_bic(z8, z6, z29);                           \/\/       bic     z8.d, z6.d, z29.d\n+    __ sve_bic(z8, z20, z16);                          \/\/       bic     z8.d, z20.d, z16.d\n+    __ sve_uzp1(z15, __ S, z4, z4);                    \/\/       uzp1    z15.s, z4.s, z4.s\n+    __ sve_uzp2(z8, __ B, z6, z29);                    \/\/       uzp2    z8.b, z6.b, z29.b\n@@ -1002,7 +1011,7 @@\n-    0x14000000,     0x17ffffd7,     0x1400031f,     0x94000000,\n-    0x97ffffd4,     0x9400031c,     0x3400000a,     0x34fffa2a,\n-    0x3400632a,     0x35000008,     0x35fff9c8,     0x350062c8,\n-    0xb400000b,     0xb4fff96b,     0xb400626b,     0xb500001d,\n-    0xb5fff91d,     0xb500621d,     0x10000013,     0x10fff8b3,\n-    0x100061b3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36306136,     0x3758000c,     0x375ff7cc,     0x375860cc,\n+    0x14000000,     0x17ffffd7,     0x1400032a,     0x94000000,\n+    0x97ffffd4,     0x94000327,     0x3400000a,     0x34fffa2a,\n+    0x3400648a,     0x35000008,     0x35fff9c8,     0x35006428,\n+    0xb400000b,     0xb4fff96b,     0xb40063cb,     0xb500001d,\n+    0xb5fff91d,     0xb500637d,     0x10000013,     0x10fff8b3,\n+    0x10006313,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36306296,     0x3758000c,     0x375ff7cc,     0x3758622c,\n@@ -1013,13 +1022,13 @@\n-    0x54005ea0,     0x54000001,     0x54fff541,     0x54005e41,\n-    0x54000002,     0x54fff4e2,     0x54005de2,     0x54000002,\n-    0x54fff482,     0x54005d82,     0x54000003,     0x54fff423,\n-    0x54005d23,     0x54000003,     0x54fff3c3,     0x54005cc3,\n-    0x54000004,     0x54fff364,     0x54005c64,     0x54000005,\n-    0x54fff305,     0x54005c05,     0x54000006,     0x54fff2a6,\n-    0x54005ba6,     0x54000007,     0x54fff247,     0x54005b47,\n-    0x54000008,     0x54fff1e8,     0x54005ae8,     0x54000009,\n-    0x54fff189,     0x54005a89,     0x5400000a,     0x54fff12a,\n-    0x54005a2a,     0x5400000b,     0x54fff0cb,     0x540059cb,\n-    0x5400000c,     0x54fff06c,     0x5400596c,     0x5400000d,\n-    0x54fff00d,     0x5400590d,     0x5400000e,     0x54ffefae,\n-    0x540058ae,     0x5400000f,     0x54ffef4f,     0x5400584f,\n+    0x54006000,     0x54000001,     0x54fff541,     0x54005fa1,\n+    0x54000002,     0x54fff4e2,     0x54005f42,     0x54000002,\n+    0x54fff482,     0x54005ee2,     0x54000003,     0x54fff423,\n+    0x54005e83,     0x54000003,     0x54fff3c3,     0x54005e23,\n+    0x54000004,     0x54fff364,     0x54005dc4,     0x54000005,\n+    0x54fff305,     0x54005d65,     0x54000006,     0x54fff2a6,\n+    0x54005d06,     0x54000007,     0x54fff247,     0x54005ca7,\n+    0x54000008,     0x54fff1e8,     0x54005c48,     0x54000009,\n+    0x54fff189,     0x54005be9,     0x5400000a,     0x54fff12a,\n+    0x54005b8a,     0x5400000b,     0x54fff0cb,     0x54005b2b,\n+    0x5400000c,     0x54fff06c,     0x54005acc,     0x5400000d,\n+    0x54fff00d,     0x54005a6d,     0x5400000e,     0x54ffefae,\n+    0x54005a0e,     0x5400000f,     0x54ffef4f,     0x540059af,\n@@ -1057,1 +1066,1 @@\n-    0xbd1b1869,     0x5800489b,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x580049fb,     0x1800000b,     0xf8945060,\n@@ -1158,45 +1167,48 @@\n-    0x25eb0d52,     0x65d0a001,     0x65d1a443,     0x65cbac85,\n-    0x65deaa53,     0x65dfaa53,     0x0520a1e0,     0x0521a601,\n-    0x052281e0,     0x05238601,     0x04a14026,     0x0568aca7,\n-    0x05b23230,     0x853040af,     0xc5b040af,     0x1e601000,\n-    0x1e603000,     0x1e621000,     0x1e623000,     0x1e641000,\n-    0x1e643000,     0x1e661000,     0x1e663000,     0x1e681000,\n-    0x1e683000,     0x1e6a1000,     0x1e6a3000,     0x1e6c1000,\n-    0x1e6c3000,     0x1e6e1000,     0x1e6e3000,     0x1e701000,\n-    0x1e703000,     0x1e721000,     0x1e723000,     0x1e741000,\n-    0x1e743000,     0x1e761000,     0x1e763000,     0x1e781000,\n-    0x1e783000,     0x1e7a1000,     0x1e7a3000,     0x1e7c1000,\n-    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8358303,\n-    0xf8280299,     0xf8301051,     0xf8212300,     0xf8243183,\n-    0xf83f515c,     0xf83a4182,     0xf830703f,     0xf82d601d,\n-    0xf8b3822c,     0xf8b6038d,     0xf8be103f,     0xf8ba209c,\n-    0xf8be30c4,     0xf8be51fa,     0xf8a94188,     0xf8a07034,\n-    0xf8b86002,     0xf8e98358,     0xf8f0007e,     0xf8ea1157,\n-    0xf8e42050,     0xf8eb3148,     0xf8ef5051,     0xf8ea418c,\n-    0xf8ef704d,     0xf8e76354,     0xf8708044,     0xf86401ec,\n-    0xf87511f0,     0xf86b22f5,     0xf86c32fa,     0xf87c516e,\n-    0xf8784181,     0xf87f720a,     0xf8676062,     0xb82d8233,\n-    0xb8300023,     0xb82b10be,     0xb82823af,     0xb83e3280,\n-    0xb82752f4,     0xb83c4375,     0xb8397025,     0xb83763f0,\n-    0xb8a5812c,     0xb8bc03af,     0xb8b6127f,     0xb8bf21c5,\n-    0xb8b031ff,     0xb8bb5214,     0xb8ac412b,     0xb8a6723e,\n-    0xb8bb63dc,     0xb8e7828a,     0xb8ea0304,     0xb8f112d1,\n-    0xb8e321fd,     0xb8f63273,     0xb8f651e2,     0xb8e6420c,\n-    0xb8eb72ed,     0xb8e1627e,     0xb8658051,     0xb87001b6,\n-    0xb86a13b5,     0xb87b236c,     0xb86333e1,     0xb8785233,\n-    0xb869437c,     0xb86f72a7,     0xb877633f,     0xce3a47c2,\n-    0xce110aca,     0xce788c11,     0xce8296d9,     0xce7b806c,\n-    0xce70879d,     0xcec080da,     0xce718b89,     0x04670087,\n-    0x042806c9,     0x659e029b,     0x6590081a,     0x65c80723,\n-    0x04d6bb55,     0x04000096,     0x04508071,     0x041aa8c1,\n-    0x04939ce9,     0x045194b6,     0x041013c8,     0x04d7a171,\n-    0x049ea35c,     0x04c80dbc,     0x040a18b0,     0x044109ed,\n-    0x049cb57a,     0x65809096,     0x658d9233,     0x65c68c4e,\n-    0x658796e3,     0x65828626,     0x049db21b,     0x6582bc62,\n-    0x6580b266,     0x65c1b50c,     0x658db013,     0x65c18677,\n-    0x65a010cd,     0x65a8332e,     0x65bb56d6,     0x65b46e23,\n-    0x04405ce4,     0x048476d0,     0x042b32c9,     0x04b033c5,\n-    0x04613176,     0x05f06a88,     0x05a46c8f,     0x04fd30c8,\n-    0x04da33bc,     0x04582c49,     0x041920fc,     0x0448363a,\n-    0x04ca32a8,     0x65c736a5,     0x65c633b6,     0x65d82093,\n-    0x04012677,\n+    0x25eb0d52,     0x65d0a001,     0x65d6a443,     0x65d4a826,\n+    0x6594ac26,     0x6554ac26,     0x6556ac26,     0x6552ac26,\n+    0x65cbac85,     0x65caac01,     0x65dea833,     0x659ca509,\n+    0x65d8a801,     0x65dcac01,     0x655cb241,     0x0520a1e0,\n+    0x0521a601,     0x052281e0,     0x05238601,     0x04a14026,\n+    0x0568aca7,     0x05b23230,     0x853040af,     0xc5b040af,\n+    0xe57080af,     0xe5b080af,     0x1e601000,     0x1e603000,\n+    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n+    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n+    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n+    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n+    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n+    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n+    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n+    0x1e7e1000,     0x1e7e3000,     0xf8358303,     0xf8280299,\n+    0xf8301051,     0xf8212300,     0xf8243183,     0xf83f515c,\n+    0xf83a4182,     0xf830703f,     0xf82d601d,     0xf8b3822c,\n+    0xf8b6038d,     0xf8be103f,     0xf8ba209c,     0xf8be30c4,\n+    0xf8be51fa,     0xf8a94188,     0xf8a07034,     0xf8b86002,\n+    0xf8e98358,     0xf8f0007e,     0xf8ea1157,     0xf8e42050,\n+    0xf8eb3148,     0xf8ef5051,     0xf8ea418c,     0xf8ef704d,\n+    0xf8e76354,     0xf8708044,     0xf86401ec,     0xf87511f0,\n+    0xf86b22f5,     0xf86c32fa,     0xf87c516e,     0xf8784181,\n+    0xf87f720a,     0xf8676062,     0xb82d8233,     0xb8300023,\n+    0xb82b10be,     0xb82823af,     0xb83e3280,     0xb82752f4,\n+    0xb83c4375,     0xb8397025,     0xb83763f0,     0xb8a5812c,\n+    0xb8bc03af,     0xb8b6127f,     0xb8bf21c5,     0xb8b031ff,\n+    0xb8bb5214,     0xb8ac412b,     0xb8a6723e,     0xb8bb63dc,\n+    0xb8e7828a,     0xb8ea0304,     0xb8f112d1,     0xb8e321fd,\n+    0xb8f63273,     0xb8f651e2,     0xb8e6420c,     0xb8eb72ed,\n+    0xb8e1627e,     0xb8658051,     0xb87001b6,     0xb86a13b5,\n+    0xb87b236c,     0xb86333e1,     0xb8785233,     0xb869437c,\n+    0xb86f72a7,     0xb877633f,     0xce3a47c2,     0xce110aca,\n+    0xce788c11,     0xce8296d9,     0xce7b806c,     0xce70879d,\n+    0xcec080da,     0xce718b89,     0x04670087,     0x042806c9,\n+    0x659e029b,     0x6590081a,     0x65c80723,     0x04d6bb55,\n+    0x04000096,     0x04508071,     0x041aa8c1,     0x04939ce9,\n+    0x045194b6,     0x041013c8,     0x04d7a171,     0x049ea35c,\n+    0x04c80dbc,     0x040a18b0,     0x044109ed,     0x049cb57a,\n+    0x65809096,     0x658d9233,     0x65c68c4e,     0x658796e3,\n+    0x65828626,     0x049db21b,     0x6582bc62,     0x6580b266,\n+    0x65c1b50c,     0x658db013,     0x65c18677,     0x65a010cd,\n+    0x65a8332e,     0x65bb56d6,     0x65b46e23,     0x04405ce4,\n+    0x048476d0,     0x042b32c9,     0x04b033c5,     0x04613176,\n+    0x04f03288,     0x05a4688f,     0x053d6cc8,     0x04da33bc,\n+    0x04582c49,     0x041920fc,     0x0448363a,     0x04ca32a8,\n+    0x65c736a5,     0x65c633b6,     0x65d82093,     0x04012677,\n+\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":84,"deletions":72,"binary":false,"changes":156,"status":"modified"}]}