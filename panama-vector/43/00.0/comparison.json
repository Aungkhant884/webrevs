{"files":[{"patch":"@@ -11320,2 +11320,1 @@\n-                         iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,\n-                         rFlagsReg cr) %{\n+                         iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1) %{\n@@ -11339,2 +11338,1 @@\n-                         iRegL src1, iRegL src2, immL_M1 m1,\n-                         rFlagsReg cr) %{\n+                         iRegL src1, iRegL src2, immL_M1 m1) %{\n@@ -11358,2 +11356,1 @@\n-                         iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,\n-                         rFlagsReg cr) %{\n+                         iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1) %{\n@@ -11377,2 +11374,1 @@\n-                         iRegL src1, iRegL src2, immL_M1 m1,\n-                         rFlagsReg cr) %{\n+                         iRegL src1, iRegL src2, immL_M1 m1) %{\n@@ -11396,2 +11392,1 @@\n-                         iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1,\n-                         rFlagsReg cr) %{\n+                         iRegIorL2I src1, iRegIorL2I src2, immI_M1 m1) %{\n@@ -11415,2 +11410,1 @@\n-                         iRegL src1, iRegL src2, immL_M1 m1,\n-                         rFlagsReg cr) %{\n+                         iRegL src1, iRegL src2, immL_M1 m1) %{\n@@ -11433,0 +11427,1 @@\n+\/\/ val & (-1 ^ (val >>> shift)) ==> bicw\n@@ -11435,1 +11430,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11453,0 +11448,1 @@\n+\/\/ val & (-1 ^ (val >>> shift)) ==> bic\n@@ -11455,1 +11451,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11473,0 +11469,1 @@\n+\/\/ val & (-1 ^ (val >> shift)) ==> bicw\n@@ -11475,1 +11472,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11493,0 +11490,1 @@\n+\/\/ val & (-1 ^ (val >> shift)) ==> bic\n@@ -11495,1 +11493,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11513,0 +11511,43 @@\n+\/\/ val & (-1 ^ (val ror shift)) ==> bicw\n+instruct AndI_reg_RotateRight_not_reg(iRegINoSp dst,\n+                         iRegIorL2I src1, iRegIorL2I src2,\n+                         immI src3, immI_M1 src4) %{\n+  match(Set dst (AndI src1 (XorI(RotateRight src2 src3) src4)));\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"bicw  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ bicw(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x1f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+\/\/ val & (-1 ^ (val ror shift)) ==> bic\n+instruct AndL_reg_RotateRight_not_reg(iRegLNoSp dst,\n+                         iRegL src1, iRegL src2,\n+                         immI src3, immL_M1 src4) %{\n+  match(Set dst (AndL src1 (XorL(RotateRight src2 src3) src4)));\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"bic  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ bic(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x3f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+\/\/ val & (-1 ^ (val << shift)) ==> bicw\n@@ -11515,1 +11556,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11533,0 +11574,1 @@\n+\/\/ val & (-1 ^ (val << shift)) ==> bic\n@@ -11535,1 +11577,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11553,0 +11595,1 @@\n+\/\/ val ^ (-1 ^ (val >>> shift)) ==> eonw\n@@ -11555,1 +11598,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11573,0 +11616,1 @@\n+\/\/ val ^ (-1 ^ (val >>> shift)) ==> eon\n@@ -11575,1 +11619,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11593,0 +11637,1 @@\n+\/\/ val ^ (-1 ^ (val >> shift)) ==> eonw\n@@ -11595,1 +11640,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11613,0 +11658,1 @@\n+\/\/ val ^ (-1 ^ (val >> shift)) ==> eon\n@@ -11615,1 +11661,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11633,0 +11679,43 @@\n+\/\/ val ^ (-1 ^ (val ror shift)) ==> eonw\n+instruct XorI_reg_RotateRight_not_reg(iRegINoSp dst,\n+                         iRegIorL2I src1, iRegIorL2I src2,\n+                         immI src3, immI_M1 src4) %{\n+  match(Set dst (XorI src4 (XorI(RotateRight src2 src3) src1)));\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"eonw  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ eonw(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x1f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+\/\/ val ^ (-1 ^ (val ror shift)) ==> eon\n+instruct XorL_reg_RotateRight_not_reg(iRegLNoSp dst,\n+                         iRegL src1, iRegL src2,\n+                         immI src3, immL_M1 src4) %{\n+  match(Set dst (XorL src4 (XorL(RotateRight src2 src3) src1)));\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"eon  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ eon(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x3f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+\/\/ val ^ (-1 ^ (val << shift)) ==> eonw\n@@ -11635,1 +11724,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11653,0 +11742,1 @@\n+\/\/ val ^ (-1 ^ (val << shift)) ==> eon\n@@ -11655,1 +11745,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11673,0 +11763,1 @@\n+\/\/ val | (-1 ^ (val >>> shift)) ==> ornw\n@@ -11675,1 +11766,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11693,0 +11784,1 @@\n+\/\/ val | (-1 ^ (val >>> shift)) ==> orn\n@@ -11695,1 +11787,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11713,0 +11805,1 @@\n+\/\/ val | (-1 ^ (val >> shift)) ==> ornw\n@@ -11715,1 +11808,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11733,0 +11826,1 @@\n+\/\/ val | (-1 ^ (val >> shift)) ==> orn\n@@ -11735,1 +11829,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11753,0 +11847,43 @@\n+\/\/ val | (-1 ^ (val ror shift)) ==> ornw\n+instruct OrI_reg_RotateRight_not_reg(iRegINoSp dst,\n+                         iRegIorL2I src1, iRegIorL2I src2,\n+                         immI src3, immI_M1 src4) %{\n+  match(Set dst (OrI src1 (XorI(RotateRight src2 src3) src4)));\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"ornw  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ ornw(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x1f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+\/\/ val | (-1 ^ (val ror shift)) ==> orn\n+instruct OrL_reg_RotateRight_not_reg(iRegLNoSp dst,\n+                         iRegL src1, iRegL src2,\n+                         immI src3, immL_M1 src4) %{\n+  match(Set dst (OrL src1 (XorL(RotateRight src2 src3) src4)));\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"orn  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ orn(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x3f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+\/\/ val | (-1 ^ (val << shift)) ==> ornw\n@@ -11755,1 +11892,1 @@\n-                         immI src3, immI_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immI_M1 src4) %{\n@@ -11773,0 +11910,1 @@\n+\/\/ val | (-1 ^ (val << shift)) ==> orn\n@@ -11775,1 +11913,1 @@\n-                         immI src3, immL_M1 src4, rFlagsReg cr) %{\n+                         immI src3, immL_M1 src4) %{\n@@ -11795,1 +11933,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11816,1 +11954,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11837,1 +11975,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11858,1 +11996,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11879,1 +12017,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11900,1 +12038,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11917,0 +12055,42 @@\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct AndI_reg_RotateRight_reg(iRegINoSp dst,\n+                         iRegIorL2I src1, iRegIorL2I src2,\n+                         immI src3) %{\n+  match(Set dst (AndI src1 (RotateRight src2 src3)));\n+\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"andw  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ andw(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x1f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct AndL_reg_RotateRight_reg(iRegLNoSp dst,\n+                         iRegL src1, iRegL src2,\n+                         immI src3) %{\n+  match(Set dst (AndL src1 (RotateRight src2 src3)));\n+\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"andr  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ andr(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x3f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n@@ -11921,1 +12101,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11942,1 +12122,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11963,1 +12143,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -11984,1 +12164,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12005,1 +12185,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12026,1 +12206,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12043,0 +12223,42 @@\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct XorI_reg_RotateRight_reg(iRegINoSp dst,\n+                         iRegIorL2I src1, iRegIorL2I src2,\n+                         immI src3) %{\n+  match(Set dst (XorI src1 (RotateRight src2 src3)));\n+\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"eorw  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ eorw(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x1f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct XorL_reg_RotateRight_reg(iRegLNoSp dst,\n+                         iRegL src1, iRegL src2,\n+                         immI src3) %{\n+  match(Set dst (XorL src1 (RotateRight src2 src3)));\n+\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"eor  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ eor(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x3f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n@@ -12047,1 +12269,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12068,1 +12290,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12089,1 +12311,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12110,1 +12332,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12131,1 +12353,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12152,1 +12374,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12169,0 +12391,42 @@\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct OrI_reg_RotateRight_reg(iRegINoSp dst,\n+                         iRegIorL2I src1, iRegIorL2I src2,\n+                         immI src3) %{\n+  match(Set dst (OrI src1 (RotateRight src2 src3)));\n+\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"orrw  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ orrw(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x1f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n+\/\/ This pattern is automatically generated from aarch64_ad.m4\n+\/\/ DO NOT EDIT ANYTHING IN THIS SECTION OF THE FILE\n+instruct OrL_reg_RotateRight_reg(iRegLNoSp dst,\n+                         iRegL src1, iRegL src2,\n+                         immI src3) %{\n+  match(Set dst (OrL src1 (RotateRight src2 src3)));\n+\n+  ins_cost(1.9 * INSN_COST);\n+  format %{ \"orr  $dst, $src1, $src2, ROR $src3\" %}\n+\n+  ins_encode %{\n+    __ orr(as_Register($dst$$reg),\n+              as_Register($src1$$reg),\n+              as_Register($src2$$reg),\n+              Assembler::ROR,\n+              $src3$$constant & 0x3f);\n+  %}\n+\n+  ins_pipe(ialu_reg_reg_shift);\n+%}\n+\n@@ -12173,1 +12437,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12194,1 +12458,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12215,1 +12479,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12236,1 +12500,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12257,1 +12521,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12278,1 +12542,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12299,1 +12563,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12320,1 +12584,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12341,1 +12605,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12362,1 +12626,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12383,1 +12647,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12404,1 +12668,1 @@\n-                         immI src3, rFlagsReg cr) %{\n+                         immI src3) %{\n@@ -12421,1 +12685,0 @@\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":324,"deletions":61,"binary":false,"changes":385,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2014, 2020, Red Hat Inc. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Red Hat Inc. All rights reserved.\n@@ -2660,6 +2660,7 @@\n-#define INSN(NAME, op)                                                     \\\n-  void NAME(Register Rd, FloatRegister Vn, SIMD_RegVariant T, int idx) {   \\\n-    starti;                                                                \\\n-    f(0, 31), f(T==D ? 1:0, 30), f(0b001110000, 29, 21);                   \\\n-    f(((idx<<1)|1)<<(int)T, 20, 16), f(op, 15, 10);                        \\\n-    rf(Vn, 5), rf(Rd, 0);                                                  \\\n+#define INSN(NAME, cond, op1, op2)                                                      \\\n+  void NAME(Register Rd, FloatRegister Vn, SIMD_RegVariant T, int idx) {                \\\n+    starti;                                                                             \\\n+    assert(cond, \"invalid register variant\");                                           \\\n+    f(0, 31), f(op1, 30), f(0b001110000, 29, 21);                                       \\\n+    f(((idx << 1) | 1) << (int)T, 20, 16), f(op2, 15, 10);                              \\\n+    rf(Vn, 5), rf(Rd, 0);                                                               \\\n@@ -2668,2 +2669,3 @@\n-  INSN(umov, 0b001111);\n-  INSN(smov, 0b001011);\n+  INSN(umov, (T != Q), (T == D ? 1 : 0), 0b001111);\n+  INSN(smov, (T < D),  1,                0b001011);\n+\n@@ -2688,0 +2690,1 @@\n+    assert(!isSHR || (isSHR && (shift != 0)), \"Zero right shift\");      \\\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":13,"deletions":10,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -88,0 +88,1 @@\n+  const bool _save_vectors;\n@@ -89,2 +90,4 @@\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors = false);\n-  static void restore_live_registers(MacroAssembler* masm, bool restore_vectors = false);\n+  RegisterSaver(bool save_vectors) : _save_vectors(save_vectors) {}\n+\n+  OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words);\n+  void restore_live_registers(MacroAssembler* masm);\n@@ -96,10 +99,4 @@\n-  static int r0_offset_in_bytes(void)    { return (32 + r0->encoding()) * wordSize; }\n-  static int reg_offset_in_bytes(Register r)    { return r0_offset_in_bytes() + r->encoding() * wordSize; }\n-  static int rmethod_offset_in_bytes(void)    { return reg_offset_in_bytes(rmethod); }\n-  static int rscratch1_offset_in_bytes(void)    { return (32 + rscratch1->encoding()) * wordSize; }\n-  static int v0_offset_in_bytes(void)   { return 0; }\n-  static int return_offset_in_bytes(void) { return (32 \/* floats*\/ + 31 \/* gregs*\/) * wordSize; }\n-\n-  \/\/ During deoptimization only the result registers need to be restored,\n-  \/\/ all the other values have already been extracted.\n-  static void restore_result_registers(MacroAssembler* masm);\n+  int reg_offset_in_bytes(Register r);\n+  int r0_offset_in_bytes()    { return reg_offset_in_bytes(r0); }\n+  int rscratch1_offset_in_bytes()    { return reg_offset_in_bytes(rscratch1); }\n+  int v0_offset_in_bytes(void)   { return 0; }\n@@ -107,1 +104,2 @@\n-    \/\/ Capture info about frame layout\n+  \/\/ Capture info about frame layout\n+  \/\/ Note this is only correct when not saving full vectors.\n@@ -122,1 +120,25 @@\n-OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors) {\n+int RegisterSaver::reg_offset_in_bytes(Register r) {\n+  \/\/ The integer registers are located above the floating point\n+  \/\/ registers in the stack frame pushed by save_live_registers() so the\n+  \/\/ offset depends on whether we are saving full vectors, and whether\n+  \/\/ those vectors are NEON or SVE.\n+\n+  int slots_per_vect = FloatRegisterImpl::save_slots_per_register;\n+\n+#if COMPILER2_OR_JVMCI\n+  if (_save_vectors) {\n+    slots_per_vect = FloatRegisterImpl::slots_per_neon_register;\n+\n+#ifdef COMPILER2\n+    if (Matcher::supports_scalable_vector()) {\n+      slots_per_vect = Matcher::scalable_vector_reg_size(T_FLOAT);\n+    }\n+#endif\n+  }\n+#endif\n+\n+  int r0_offset = (slots_per_vect * FloatRegisterImpl::number_of_registers) * BytesPerInt;\n+  return r0_offset + r->encoding() * wordSize;\n+}\n+\n+OopMap* RegisterSaver::save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words) {\n@@ -134,1 +156,1 @@\n-  if (save_vectors) {\n+  if (_save_vectors) {\n@@ -148,1 +170,1 @@\n-  assert(!save_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  assert(!_save_vectors, \"vectors are generated only by C2 and JVMCI\");\n@@ -163,1 +185,1 @@\n-  __ push_CPU_state(save_vectors, use_sve, sve_vector_size_in_bytes);\n+  __ push_CPU_state(_save_vectors, use_sve, sve_vector_size_in_bytes);\n@@ -188,1 +210,1 @@\n-    if (save_vectors) {\n+    if (_save_vectors) {\n@@ -201,1 +223,1 @@\n-void RegisterSaver::restore_live_registers(MacroAssembler* masm, bool restore_vectors) {\n+void RegisterSaver::restore_live_registers(MacroAssembler* masm) {\n@@ -203,1 +225,1 @@\n-  __ pop_CPU_state(restore_vectors, Matcher::supports_scalable_vector(),\n+  __ pop_CPU_state(_save_vectors, Matcher::supports_scalable_vector(),\n@@ -207,1 +229,1 @@\n-  assert(!restore_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  assert(!_save_vectors, \"vectors are generated only by C2 and JVMCI\");\n@@ -209,1 +231,1 @@\n-  __ pop_CPU_state(restore_vectors);\n+  __ pop_CPU_state(_save_vectors);\n@@ -215,17 +237,0 @@\n-void RegisterSaver::restore_result_registers(MacroAssembler* masm) {\n-\n-  \/\/ Just restore result register. Only used by deoptimization. By\n-  \/\/ now any callee save register that needs to be restored to a c2\n-  \/\/ caller of the deoptee has been extracted into the vframeArray\n-  \/\/ and will be stuffed into the c2i adapter we create for later\n-  \/\/ restoration so only result registers need to be restored here.\n-\n-  \/\/ Restore fp result register\n-  __ ldrd(v0, Address(sp, v0_offset_in_bytes()));\n-  \/\/ Restore integer result register\n-  __ ldr(r0, Address(sp, r0_offset_in_bytes()));\n-\n-  \/\/ Pop all of the register save are off the stack\n-  __ add(sp, sp, align_up(return_offset_in_bytes(), 16));\n-}\n-\n@@ -2175,0 +2180,1 @@\n+  RegisterSaver reg_save(COMPILER2_OR_JVMCI != 0);\n@@ -2212,1 +2218,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2230,1 +2236,1 @@\n-  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  (void) reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2249,1 +2255,1 @@\n-    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+    reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2306,1 +2312,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2387,1 +2393,1 @@\n-  __ str(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ str(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2396,1 +2402,8 @@\n-  RegisterSaver::restore_result_registers(masm);\n+\n+  \/\/ Restore fp result register\n+  __ ldrd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  \/\/ Restore integer result register\n+  __ ldr(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n+\n+  \/\/ Pop all of the register save area off the stack\n+  __ add(sp, sp, frame_size_in_words * wordSize);\n@@ -2477,2 +2490,2 @@\n-  __ strd(v0, Address(sp, RegisterSaver::v0_offset_in_bytes()));\n-  __ str(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ strd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  __ str(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2505,2 +2518,2 @@\n-  __ ldrd(v0, Address(sp, RegisterSaver::v0_offset_in_bytes()));\n-  __ ldr(r0, Address(sp, RegisterSaver::r0_offset_in_bytes()));\n+  __ ldrd(v0, Address(sp, reg_save.v0_offset_in_bytes()));\n+  __ ldr(r0, Address(sp, reg_save.r0_offset_in_bytes()));\n@@ -2752,1 +2765,1 @@\n-  bool save_vectors = (poll_type == POLL_AT_VECTOR_LOOP);\n+  RegisterSaver reg_save(poll_type == POLL_AT_VECTOR_LOOP \/* save_vectors *\/);\n@@ -2755,1 +2768,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, save_vectors);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2800,1 +2813,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  reg_save.restore_live_registers(masm);\n@@ -2832,1 +2845,1 @@\n-  RegisterSaver::restore_live_registers(masm, save_vectors);\n+  reg_save.restore_live_registers(masm);\n@@ -2866,0 +2879,1 @@\n+  RegisterSaver reg_save(false \/* save_vectors *\/);\n@@ -2872,1 +2886,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = reg_save.save_live_registers(masm, 0, &frame_size_in_words);\n@@ -2904,1 +2918,1 @@\n-  __ str(rmethod, Address(sp, RegisterSaver::reg_offset_in_bytes(rmethod)));\n+  __ str(rmethod, Address(sp, reg_save.reg_offset_in_bytes(rmethod)));\n@@ -2907,2 +2921,2 @@\n-  __ str(r0, Address(sp, RegisterSaver::rscratch1_offset_in_bytes()));\n-  RegisterSaver::restore_live_registers(masm);\n+  __ str(r0, Address(sp, reg_save.rscratch1_offset_in_bytes()));\n+  reg_save.restore_live_registers(masm);\n@@ -2918,1 +2932,1 @@\n-  RegisterSaver::restore_live_registers(masm);\n+  reg_save.restore_live_registers(masm);\n@@ -3069,1 +3083,0 @@\n-#endif \/\/ COMPILER2\n@@ -3079,0 +3092,4 @@\n+\n+  int _frame_complete;\n+  int _framesize;\n+  OopMapSet* _oop_maps;\n@@ -3089,1 +3106,8 @@\n-     _output_registers(output_registers) {}\n+     _output_registers(output_registers),\n+     _frame_complete(0),\n+     _framesize(0),\n+     _oop_maps(NULL) {\n+    assert(_output_registers.length() <= 1\n+           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n+  }\n+\n@@ -3092,0 +3116,74 @@\n+  int spill_size_in_bytes() const {\n+    if (_output_registers.length() == 0) {\n+      return 0;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    if (reg->is_Register()) {\n+      return 8;\n+    } else if (reg->is_FloatRegister()) {\n+      bool use_sve = Matcher::supports_scalable_vector();\n+      if (use_sve) {\n+        return Matcher::scalable_vector_reg_size(T_BYTE);\n+      }\n+      return 16;\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+    return 0;\n+  }\n+\n+  void spill_output_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ spill(reg->as_Register(), true, 0);\n+    } else if (reg->is_FloatRegister()) {\n+      bool use_sve = Matcher::supports_scalable_vector();\n+      if (use_sve) {\n+        __ spill_sve_vector(reg->as_FloatRegister(), 0, Matcher::scalable_vector_reg_size(T_BYTE));\n+      } else {\n+        __ spill(reg->as_FloatRegister(), __ Q, 0);\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  void fill_output_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ unspill(reg->as_Register(), true, 0);\n+    } else if (reg->is_FloatRegister()) {\n+      bool use_sve = Matcher::supports_scalable_vector();\n+      if (use_sve) {\n+        __ unspill_sve_vector(reg->as_FloatRegister(), 0, Matcher::scalable_vector_reg_size(T_BYTE));\n+      } else {\n+        __ unspill(reg->as_FloatRegister(), __ Q, 0);\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  int frame_complete() const {\n+    return _frame_complete;\n+  }\n+\n+  int framesize() const {\n+    return (_framesize >> (LogBytesPerWord - LogBytesPerInt));\n+  }\n+\n+  OopMapSet* oop_maps() const {\n+    return _oop_maps;\n+  }\n+\n@@ -3102,10 +3200,6 @@\n-BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n-                                               int shadow_space_bytes,\n-                                               const GrowableArray<VMReg>& input_registers,\n-                                               const GrowableArray<VMReg>& output_registers) {\n-  BufferBlob* _invoke_native_blob =\n-    BufferBlob::create(\"nep_invoker_blob\", native_invoker_code_size);\n-  if (_invoke_native_blob == NULL)\n-    return NULL; \/\/ allocation failure\n-\n-  CodeBuffer code(_invoke_native_blob);\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n+  int locs_size  = 64;\n+  CodeBuffer code(\"nep_invoker_blob\", native_invoker_code_size, locs_size);\n@@ -3116,1 +3210,7 @@\n-  return _invoke_native_blob;\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n+                                  &code,\n+                                  g.frame_complete(),\n+                                  g.framesize(),\n+                                  g.oop_maps(), false);\n+  return stub;\n@@ -3125,0 +3225,13 @@\n+  enum layout {\n+    rbp_off,\n+    rbp_off2,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  assert(_shadow_space_bytes == 0, \"not expecting shadow space on AArch64\");\n+  _framesize = align_up(framesize + (spill_size_in_bytes() >> LogBytesPerInt), 4);\n+  assert(is_even(_framesize\/2), \"sp not 16-byte aligned\");\n+\n+  _oop_maps  = new OopMapSet();\n@@ -3127,1 +3240,1 @@\n-  __ set_last_Java_frame(sp, noreg, lr, rscratch1);\n+  address start = __ pc();\n@@ -3131,6 +3244,9 @@\n-  \/\/ Store a pointer to the previous R29 (RFP) saved on the stack as it\n-  \/\/ may contain an oop if PreserveFramePointer is off. This value is\n-  \/\/ retrieved later by frame::sender_for_entry_frame() when the stack\n-  \/\/ is walked.\n-  __ mov(rscratch1, sp);\n-  __ str(rscratch1, Address(rthread, JavaThread::saved_fp_address_offset()));\n+  \/\/ lr and fp are already in place\n+  __ sub(sp, rfp, ((unsigned)_framesize-4) << LogBytesPerInt); \/\/ prolog\n+\n+  _frame_complete = __ pc() - start;\n+\n+  address the_pc = __ pc();\n+  __ set_last_Java_frame(sp, rfp, the_pc, rscratch1);\n+  OopMap* map = new OopMap(_framesize, 0);\n+  _oop_maps->add_gc_map(the_pc - start, map);\n@@ -3143,2 +3259,0 @@\n-  assert(_shadow_space_bytes == 0, \"not expecting shadow space on AArch64\");\n-\n@@ -3190,13 +3304,1 @@\n-  RegSet spills;\n-  FloatRegSet fp_spills;\n-  for (int i = 0; i < _output_registers.length(); i++) {\n-    VMReg output = _output_registers.at(i);\n-    if (output->is_Register()) {\n-      spills += RegSet::of(output->as_Register());\n-    } else if (output->is_FloatRegister()) {\n-      fp_spills += FloatRegSet::of(output->as_FloatRegister());\n-    }\n-  }\n-\n-  __ push(spills, sp);\n-  __ push_fp(fp_spills, sp);\n+  spill_output_registers();\n@@ -3209,2 +3311,1 @@\n-  __ pop_fp(fp_spills, sp);\n-  __ pop(spills, sp);\n+  fill_output_registers();\n@@ -3220,2 +3321,1 @@\n-  __ push(spills, sp);\n-  __ push_fp(fp_spills, sp);\n+  spill_output_registers();\n@@ -3225,2 +3325,1 @@\n-  __ pop_fp(fp_spills, sp);\n-  __ pop(spills, sp);\n+  fill_output_registers();\n@@ -3236,0 +3335,1 @@\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":199,"deletions":99,"binary":false,"changes":298,"status":"modified"},{"patch":"@@ -1909,4 +1909,5 @@\n-BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n-                                               int shadow_space_bytes,\n-                                               const GrowableArray<VMReg>& input_registers,\n-                                               const GrowableArray<VMReg>& output_registers) {\n+#ifdef COMPILER2\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n@@ -1916,0 +1917,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/arm\/sharedRuntime_arm.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -1379,0 +1379,4 @@\n+\n+  if (C->stub_function() == NULL) {\n+    st->print(\"nmethod entry barrier\\n\\t\");\n+  }\n@@ -1532,0 +1536,5 @@\n+  if (C->stub_function() == NULL) {\n+    BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->nmethod_entry_barrier(&_masm, push_frame_temp);\n+  }\n+\n@@ -3043,30 +3052,0 @@\n-  \/\/ Use release_store for card-marking to ensure that previous\n-  \/\/ oop-stores are visible before the card-mark change.\n-  enc_class enc_cms_card_mark(memory mem, iRegLdst releaseFieldAddr, flagsReg crx) %{\n-    \/\/ FIXME: Implement this as a cmove and use a fixed condition code\n-    \/\/ register which is written on every transition to compiled code,\n-    \/\/ e.g. in call-stub and when returning from runtime stubs.\n-    \/\/\n-    \/\/ Proposed code sequence for the cmove implementation:\n-    \/\/\n-    \/\/ Label skip_release;\n-    \/\/ __ beq(CCRfixed, skip_release);\n-    \/\/ __ release();\n-    \/\/ __ bind(skip_release);\n-    \/\/ __ stb(card mark);\n-\n-    C2_MacroAssembler _masm(&cbuf);\n-    Label skip_storestore;\n-\n-    __ li(R0, 0);\n-    __ membar(Assembler::StoreStore);\n-\n-    \/\/ Do the store.\n-    if ($mem$$index == 0) {\n-      __ stb(R0, $mem$$disp, $mem$$base$$Register);\n-    } else {\n-      assert(0 == $mem$$disp, \"no displacement possible with indexed load\/stores on ppc\");\n-      __ stbx(R0, $mem$$base$$Register, $mem$$index$$Register);\n-    }\n-  %}\n-\n@@ -6609,20 +6588,1 @@\n-\/\/ Card-mark for CMS garbage collection.\n-\/\/ This cardmark does an optimization so that it must not always\n-\/\/ do a releasing store. For this, it gets the address of\n-\/\/ CMSCollectorCardTableBarrierSetBSExt::_requires_release as input.\n-\/\/ (Using releaseFieldAddr in the match rule is a hack.)\n-instruct storeCM_CMS(memory mem, iRegLdst releaseFieldAddr, flagsReg crx) %{\n-  match(Set mem (StoreCM mem releaseFieldAddr));\n-  effect(TEMP crx);\n-  predicate(false);\n-  ins_cost(MEMORY_REF_COST);\n-\n-  \/\/ See loadConP.\n-  ins_cannot_rematerialize(true);\n-\n-  format %{ \"STB     #0, $mem \\t\/\/ CMS card-mark byte (must be 0!), checking requires_release in [$releaseFieldAddr]\" %}\n-  ins_encode( enc_cms_card_mark(mem, releaseFieldAddr, crx) );\n-  ins_pipe(pipe_class_memory);\n-%}\n-\n-instruct storeCM_G1(memory mem, immI_0 zero) %{\n+instruct storeCM(memory mem, immI_0 zero) %{\n@@ -6630,1 +6590,0 @@\n-  predicate(UseG1GC);\n@@ -6633,3 +6592,1 @@\n-  ins_cannot_rematerialize(true);\n-\n-  format %{ \"STB     #0, $mem \\t\/\/ CMS card-mark byte store (G1)\" %}\n+  format %{ \"STB     #0, $mem \\t\/\/ CMS card-mark byte store\" %}\n@@ -6639,1 +6596,1 @@\n-    \/\/__ release(); \/\/ G1: oops are allowed to get visible after dirty marking\n+    \/\/ No release barrier: Oops are allowed to get visible after marking.\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":12,"deletions":55,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -1312,0 +1312,3 @@\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->c2i_entry_barrier(masm, \/* tmp register*\/ ic_klass, \/* tmp register*\/ receiver_klass, \/* tmp register*\/ code);\n+\n@@ -1314,1 +1317,2 @@\n-  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry, c2i_no_clinit_check_entry);\n+  return AdapterHandlerLibrary::new_entry(fingerprint, i2c_entry, c2i_entry, c2i_unverified_entry,\n+                                          c2i_no_clinit_check_entry);\n@@ -1984,0 +1988,4 @@\n+\n+  BarrierSetAssembler* bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+  bs->nmethod_entry_barrier(masm, r_temp_1);\n+\n@@ -3445,4 +3453,5 @@\n-BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n-                                               int shadow_space_bytes,\n-                                               const GrowableArray<VMReg>& input_registers,\n-                                               const GrowableArray<VMReg>& output_registers) {\n+#ifdef COMPILER2\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n@@ -3452,0 +3461,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":15,"deletions":5,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -3479,4 +3479,5 @@\n-BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n-                                               int shadow_space_bytes,\n-                                               const GrowableArray<VMReg>& input_registers,\n-                                               const GrowableArray<VMReg>& output_registers) {\n+#ifdef COMPILER2\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n@@ -3486,0 +3487,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2991,1 +2991,2 @@\n-BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n+#ifdef COMPILER2\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n@@ -2998,0 +2999,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3189,1 +3189,0 @@\n-\n@@ -3438,0 +3437,1 @@\n+#ifdef COMPILER2\n@@ -3446,0 +3446,4 @@\n+\n+  int _frame_complete;\n+  int _framesize;\n+  OopMapSet* _oop_maps;\n@@ -3456,1 +3460,9 @@\n-     _output_registers(output_registers) {}\n+     _output_registers(output_registers),\n+     _frame_complete(0),\n+     _framesize(0),\n+     _oop_maps(NULL) {\n+    assert(_output_registers.length() <= 1\n+           || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n+\n+  }\n+\n@@ -3459,1 +3471,27 @@\n-  void spill_register(VMReg reg) {\n+  int spill_size_in_bytes() const {\n+    if (_output_registers.length() == 0) {\n+      return 0;\n+    }\n+    VMReg reg = _output_registers.at(0);\n+    assert(reg->is_reg(), \"must be a register\");\n+    if (reg->is_Register()) {\n+      return 8;\n+    } else if (reg->is_XMMRegister()) {\n+      if (UseAVX >= 3) {\n+        return 64;\n+      } else if (UseAVX >= 1) {\n+        return 32;\n+      } else {\n+        return 16;\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+    return 0;\n+  }\n+\n+  void spill_out_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n@@ -3463,1 +3501,1 @@\n-      __ push(reg->as_Register());\n+      __ movptr(Address(rsp, 0), reg->as_Register());\n@@ -3466,1 +3504,0 @@\n-        __ subptr(rsp, 64); \/\/ bytes\n@@ -3469,1 +3506,0 @@\n-        __ subptr(rsp, 32);\n@@ -3472,1 +3508,0 @@\n-        __ subptr(rsp, 16);\n@@ -3480,1 +3515,5 @@\n-  void fill_register(VMReg reg) {\n+  void fill_out_registers() {\n+    if (_output_registers.length() == 0) {\n+      return;\n+    }\n+    VMReg reg = _output_registers.at(0);\n@@ -3484,1 +3523,1 @@\n-      __ pop(reg->as_Register());\n+      __ movptr(reg->as_Register(), Address(rsp, 0));\n@@ -3488,1 +3527,0 @@\n-        __ addptr(rsp, 64); \/\/ bytes\n@@ -3491,1 +3529,0 @@\n-        __ addptr(rsp, 32);\n@@ -3494,1 +3531,0 @@\n-        __ addptr(rsp, 16);\n@@ -3501,0 +3537,12 @@\n+  int frame_complete() const {\n+    return _frame_complete;\n+  }\n+\n+  int framesize() const {\n+    return (_framesize >> (LogBytesPerWord - LogBytesPerInt));\n+  }\n+\n+  OopMapSet* oop_maps() const {\n+    return _oop_maps;\n+  }\n+\n@@ -3509,9 +3557,6 @@\n-BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n-                                               int shadow_space_bytes,\n-                                               const GrowableArray<VMReg>& input_registers,\n-                                               const GrowableArray<VMReg>& output_registers) {\n-  BufferBlob* _invoke_native_blob = BufferBlob::create(\"nep_invoker_blob\", native_invoker_code_size);\n-  if (_invoke_native_blob == NULL)\n-    return NULL; \/\/ allocation failure\n-\n-  CodeBuffer code(_invoke_native_blob);\n+RuntimeStub* SharedRuntime::make_native_invoker(address call_target,\n+                                                int shadow_space_bytes,\n+                                                const GrowableArray<VMReg>& input_registers,\n+                                                const GrowableArray<VMReg>& output_registers) {\n+  int locs_size  = 64;\n+  CodeBuffer code(\"nep_invoker_blob\", native_invoker_code_size, locs_size);\n@@ -3522,1 +3567,7 @@\n-  return _invoke_native_blob;\n+  RuntimeStub* stub =\n+    RuntimeStub::new_runtime_stub(\"nep_invoker_blob\",\n+                                  &code,\n+                                  g.frame_complete(),\n+                                  g.framesize(),\n+                                  g.oop_maps(), false);\n+  return stub;\n@@ -3528,0 +3579,12 @@\n+  enum layout {\n+    rbp_off,\n+    rbp_off2,\n+    return_off,\n+    return_off2,\n+    framesize \/\/ inclusive of return address\n+  };\n+\n+  _framesize = align_up(framesize + ((_shadow_space_bytes + spill_size_in_bytes()) >> LogBytesPerInt), 4);\n+  assert(is_even(_framesize\/2), \"sp not 16-byte aligned\");\n+\n+  _oop_maps  = new OopMapSet();\n@@ -3529,4 +3592,1 @@\n-  __ enter();\n-  Address java_pc(r15_thread, JavaThread::last_Java_pc_offset());\n-  __ movptr(rscratch1, Address(rsp, 8)); \/\/ read return address from stack\n-  __ movptr(java_pc, rscratch1);\n+  address start = __ pc();\n@@ -3535,3 +3595,1 @@\n-  __ movptr(rscratch1, rsp);\n-  __ addptr(rscratch1, 16); \/\/ skip return and frame\n-  __ movptr(Address(r15_thread, JavaThread::last_Java_sp_offset()), rscratch1);\n+  __ enter();\n@@ -3539,1 +3597,2 @@\n-  __ movptr(Address(r15_thread, JavaThread::saved_rbp_address_offset()), rsp); \/\/ rsp points at saved RBP\n+  \/\/ return address and rbp are already in place\n+  __ subptr(rsp, (_framesize-4) << LogBytesPerInt); \/\/ prolog\n@@ -3541,2 +3600,1 @@\n-    \/\/ State transition\n-  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n+  _frame_complete = __ pc() - start;\n@@ -3544,4 +3602,1 @@\n-  if (_shadow_space_bytes != 0) {\n-    \/\/ needed here for correct stack args offset on Windows\n-    __ subptr(rsp, _shadow_space_bytes);\n-  }\n+  address the_pc = __ pc();\n@@ -3549,1 +3604,3 @@\n-  __ call(RuntimeAddress(_call_target));\n+  __ set_last_Java_frame(rsp, rbp, (address)the_pc);\n+  OopMap* map = new OopMap(_framesize, 0);\n+  _oop_maps->add_gc_map(the_pc - start, map);\n@@ -3551,4 +3608,2 @@\n-  if (_shadow_space_bytes != 0) {\n-    \/\/ needed here for correct stack args offset on Windows\n-    __ addptr(rsp, _shadow_space_bytes);\n-  }\n+  \/\/ State transition\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n@@ -3556,4 +3611,1 @@\n-  assert(_output_registers.length() <= 1\n-    || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n-  bool need_spills = _output_registers.length() != 0;\n-  VMReg ret_reg = need_spills ? _output_registers.at(0) : VMRegImpl::Bad();\n+  __ call(RuntimeAddress(_call_target));\n@@ -3600,3 +3652,1 @@\n-  if (need_spills) {\n-    spill_register(ret_reg);\n-  }\n+  spill_out_registers();\n@@ -3612,3 +3662,1 @@\n-  if (need_spills) {\n-    fill_register(ret_reg);\n-  }\n+  fill_out_registers();\n@@ -3625,3 +3673,1 @@\n-  if (need_spills) {\n-    spill_register(ret_reg);\n-  }\n+  spill_out_registers();\n@@ -3636,3 +3682,1 @@\n-  if (need_spills) {\n-    fill_register(ret_reg);\n-  }\n+  fill_out_registers();\n@@ -3648,0 +3692,1 @@\n+#endif \/\/ COMPILER2\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":102,"deletions":57,"binary":false,"changes":159,"status":"modified"},{"patch":"@@ -1088,0 +1088,11 @@\n+  address generate_vector_byte_shuffle_mask(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x7070707070707070, relocInfo::none);\n+    __ emit_data64(0x7070707070707070, relocInfo::none);\n+    __ emit_data64(0xF0F0F0F0F0F0F0F0, relocInfo::none);\n+    __ emit_data64(0xF0F0F0F0F0F0F0F0, relocInfo::none);\n+    return start;\n+  }\n+\n@@ -1751,0 +1762,1 @@\n+        __ align(32);\n@@ -1817,0 +1829,1 @@\n+        __ align(32);\n@@ -1956,0 +1969,1 @@\n+        __ align(32);\n@@ -1988,0 +2002,1 @@\n+        __ align(32);\n@@ -2050,1 +2065,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2166,1 +2181,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2277,1 +2292,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2408,1 +2423,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2512,1 +2527,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2623,1 +2638,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2736,1 +2751,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -2846,1 +2861,1 @@\n-    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+    if (VM_Version::supports_avx512vlbw() && VM_Version::supports_bmi2() && MaxVectorSize  >= 32) {\n@@ -7108,0 +7123,1 @@\n+    StubRoutines::x86::_vector_byte_shuffle_mask = generate_vector_byte_shuffle_mask(\"vector_byte_shuffle_mask\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":24,"deletions":8,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -1359,0 +1359,1 @@\n+  static address vector_byte_shufflemask() { return StubRoutines::x86::vector_byte_shuffle_mask(); }\n@@ -1529,1 +1530,1 @@\n-      if (UseAVX < 3) {\n+      if (UseAVX < 3 || !VM_Version::supports_bmi2()) {\n@@ -1701,1 +1702,1 @@\n-      } else if (bt == T_BYTE && size_in_bits >= 256 && !VM_Version::supports_avx512_vbmi())  {\n+      } else if (bt == T_BYTE && size_in_bits > 256 && !VM_Version::supports_avx512_vbmi())  {\n@@ -1703,1 +1704,1 @@\n-      } else if (bt == T_SHORT && size_in_bits >= 256 && !VM_Version::supports_avx512bw())  {\n+      } else if (bt == T_SHORT && size_in_bits > 256 && !VM_Version::supports_avx512bw())  {\n@@ -7512,1 +7513,1 @@\n-instruct rearrangeB_avx(vec dst, vec src, vec shuffle) %{\n+instruct rearrangeB_avx(legVec dst, legVec src, vec shuffle, legVec vtmp1, legVec vtmp2, rRegP scratch) %{\n@@ -7516,1 +7517,2 @@\n-  format %{ \"vector_rearrange $dst, $shuffle, $src\" %}\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n+  format %{ \"vector_rearrange $dst, $shuffle, $src\\t! using $vtmp1, $vtmp2, $scratch as TEMP\" %}\n@@ -7518,1 +7520,11 @@\n-    __ vpshufb($dst$$XMMRegister, $shuffle$$XMMRegister, $src$$XMMRegister, Assembler::AVX_256bit);\n+    assert(UseAVX >= 2, \"required\");\n+    \/\/ Swap src into vtmp1\n+    __ vperm2i128($vtmp1$$XMMRegister, $src$$XMMRegister, $src$$XMMRegister, 1);\n+    \/\/ Shuffle swapped src to get entries from other 128 bit lane\n+    __ vpshufb($vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $shuffle$$XMMRegister, Assembler::AVX_256bit);\n+    \/\/ Shuffle original src to get entries from self 128 bit lane\n+    __ vpshufb($dst$$XMMRegister, $src$$XMMRegister, $shuffle$$XMMRegister, Assembler::AVX_256bit);\n+    \/\/ Create a blend mask by setting high bits for entries coming from other lane in shuffle\n+    __ vpaddb($vtmp2$$XMMRegister, $shuffle$$XMMRegister, ExternalAddress(vector_byte_shufflemask()), Assembler::AVX_256bit, $scratch$$Register);\n+    \/\/ Perform the blend\n+    __ vpblendvb($dst$$XMMRegister, $dst$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, Assembler::AVX_256bit);\n@@ -7539,1 +7551,1 @@\n-            vector_length(n) <= 8 && !VM_Version::supports_avx512bw()); \/\/ NB! aligned with rearrangeS\n+            vector_length(n) <= 16 && !VM_Version::supports_avx512bw()); \/\/ NB! aligned with rearrangeS\n@@ -7546,0 +7558,21 @@\n+    int vlen_in_bytes = vector_length_in_bytes(this);\n+    if (UseAVX == 0) {\n+      assert(vlen_in_bytes <= 16, \"required\");\n+      \/\/ Multiply each shuffle by two to get byte index\n+      __ pmovzxbw($vtmp$$XMMRegister, $src$$XMMRegister);\n+      __ psllw($vtmp$$XMMRegister, 1);\n+\n+      \/\/ Duplicate to create 2 copies of byte index\n+      __ movdqu($dst$$XMMRegister, $vtmp$$XMMRegister);\n+      __ psllw($dst$$XMMRegister, 8);\n+      __ por($dst$$XMMRegister, $vtmp$$XMMRegister);\n+\n+      \/\/ Add one to get alternate byte index\n+      __ movdqu($vtmp$$XMMRegister, ExternalAddress(vector_short_shufflemask()), $scratch$$Register);\n+      __ paddb($dst$$XMMRegister, $vtmp$$XMMRegister);\n+    } else {\n+      assert(UseAVX > 1 || vlen_in_bytes <= 16, \"required\");\n+      int vlen_enc = vector_length_encoding(this);\n+      \/\/ Multiply each shuffle by two to get byte index\n+      __ vpmovzxbw($vtmp$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+      __ vpsllw($vtmp$$XMMRegister, $vtmp$$XMMRegister, 1, vlen_enc);\n@@ -7547,8 +7580,3 @@\n-    \/\/ Multiply each shuffle by two to get byte index\n-    __ pmovzxbw($vtmp$$XMMRegister, $src$$XMMRegister);\n-    __ psllw($vtmp$$XMMRegister, 1);\n-\n-    \/\/ Duplicate to create 2 copies of byte index\n-    __ movdqu($dst$$XMMRegister, $vtmp$$XMMRegister);\n-    __ psllw($dst$$XMMRegister, 8);\n-    __ por($dst$$XMMRegister, $vtmp$$XMMRegister);\n+      \/\/ Duplicate to create 2 copies of byte index\n+      __ vpsllw($dst$$XMMRegister, $vtmp$$XMMRegister,  8, vlen_enc);\n+      __ vpor($dst$$XMMRegister, $dst$$XMMRegister, $vtmp$$XMMRegister, vlen_enc);\n@@ -7556,3 +7584,3 @@\n-    \/\/ Add one to get alternate byte index\n-    __ movdqu($vtmp$$XMMRegister, ExternalAddress(vector_short_shufflemask()), $scratch$$Register);\n-    __ paddb($dst$$XMMRegister, $vtmp$$XMMRegister);\n+      \/\/ Add one to get alternate byte index\n+      __ vpaddb($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_short_shufflemask()), vlen_enc, $scratch$$Register);\n+    }\n@@ -7575,0 +7603,22 @@\n+instruct rearrangeS_avx(legVec dst, legVec src, vec shuffle, legVec vtmp1, legVec vtmp2, rRegP scratch) %{\n+  predicate(vector_element_basic_type(n) == T_SHORT &&\n+            vector_length(n) == 16 && !VM_Version::supports_avx512bw());\n+  match(Set dst (VectorRearrange src shuffle));\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n+  format %{ \"vector_rearrange $dst, $shuffle, $src\\t! using $vtmp1, $vtmp2, $scratch as TEMP\" %}\n+  ins_encode %{\n+    assert(UseAVX >= 2, \"required\");\n+    \/\/ Swap src into vtmp1\n+    __ vperm2i128($vtmp1$$XMMRegister, $src$$XMMRegister, $src$$XMMRegister, 1);\n+    \/\/ Shuffle swapped src to get entries from other 128 bit lane\n+    __ vpshufb($vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $shuffle$$XMMRegister, Assembler::AVX_256bit);\n+    \/\/ Shuffle original src to get entries from self 128 bit lane\n+    __ vpshufb($dst$$XMMRegister, $src$$XMMRegister, $shuffle$$XMMRegister, Assembler::AVX_256bit);\n+    \/\/ Create a blend mask by setting high bits for entries coming from other lane in shuffle\n+    __ vpaddb($vtmp2$$XMMRegister, $shuffle$$XMMRegister, ExternalAddress(vector_byte_shufflemask()), Assembler::AVX_256bit, $scratch$$Register);\n+    \/\/ Perform the blend\n+    __ vpblendvb($dst$$XMMRegister, $dst$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, Assembler::AVX_256bit);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":68,"deletions":18,"binary":false,"changes":86,"status":"modified"},{"patch":"@@ -204,0 +204,1 @@\n+macro(MachNullCheck)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -4795,1 +4795,1 @@\n-void Compile::add_native_invoker(BufferBlob* stub) {\n+void Compile::add_native_invoker(RuntimeStub* stub) {\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2003,3 +2003,3 @@\n-  Node* cnt  = make_load(ctrl, counter_addr, TypeInt::INT, T_INT, adr_type, MemNode::unordered);\n-  Node* incr = _gvn.transform(new AddINode(cnt, _gvn.intcon(1)));\n-  store_to_memory(ctrl, counter_addr, incr, T_INT, adr_type, MemNode::unordered);\n+  Node* cnt  = make_load(ctrl, counter_addr, TypeLong::LONG, T_LONG, adr_type, MemNode::unordered);\n+  Node* incr = _gvn.transform(new AddLNode(cnt, _gvn.longcon(1)));\n+  store_to_memory(ctrl, counter_addr, incr, T_LONG, adr_type, MemNode::unordered);\n@@ -2638,3 +2638,3 @@\n-    BufferBlob* invoker = SharedRuntime::make_native_invoker(call_addr,\n-                                                             nep->shadow_space(),\n-                                                             arg_regs, ret_regs);\n+    RuntimeStub* invoker = SharedRuntime::make_native_invoker(call_addr,\n+                                                              nep->shadow_space(),\n+                                                              arg_regs, ret_regs);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"oops\/klass.inline.hpp\"\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -683,1 +683,5 @@\n-  Node* addr = make_unsafe_address(base, offset, decorators, (is_mask ? T_BOOLEAN : elem_bt), true);\n+  \/\/ Save state and restore on bailout\n+  uint old_sp = sp();\n+  SafePointNode* old_map = clone_map();\n+\n+  Node* addr = make_unsafe_address(base, offset, decorators, (is_mask ? T_BOOLEAN : elem_bt), true);\n@@ -696,0 +700,2 @@\n+    set_map(old_map);\n+    set_sp(old_sp);\n@@ -708,0 +714,2 @@\n+      set_map(old_map);\n+      set_sp(old_sp);\n@@ -718,0 +726,2 @@\n+      set_map(old_map);\n+      set_sp(old_sp);\n@@ -722,0 +732,2 @@\n+        set_map(old_map);\n+        set_sp(old_sp);\n@@ -726,0 +738,2 @@\n+        set_map(old_map);\n+        set_sp(old_sp);\n@@ -740,0 +754,2 @@\n+      set_map(old_map);\n+      set_sp(old_sp);\n@@ -776,0 +792,2 @@\n+  old_map->destruct(&_gvn);\n+\n@@ -853,0 +871,5 @@\n+\n+  \/\/ Save state and restore on bailout\n+  uint old_sp = sp();\n+  SafePointNode* old_map = clone_map();\n+\n@@ -860,0 +883,2 @@\n+    set_map(old_map);\n+    set_sp(old_sp);\n@@ -868,0 +893,2 @@\n+    set_map(old_map);\n+    set_sp(old_sp);\n@@ -875,0 +902,2 @@\n+    set_map(old_map);\n+    set_sp(old_sp);\n@@ -881,0 +910,2 @@\n+      set_map(old_map);\n+      set_sp(old_sp);\n@@ -894,0 +925,2 @@\n+  old_map->destruct(&_gvn);\n+\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":34,"deletions":1,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -142,1 +142,1 @@\n-      address elem_addr = reg_map->location(vreg->next(vslot)) + off;\n+      address elem_addr = reg_map->location(vreg, vslot) + off; \/\/ assumes little endian element order\n","filename":"src\/hotspot\/share\/prims\/vectorSupport.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+#include \"runtime\/flags\/jvmFlagLimit.hpp\"\n@@ -2273,0 +2274,5 @@\n+  \/\/ Make sure the above values match the range set in globals.hpp\n+  const JVMTypedFlagLimit<intx>* limit = JVMFlagLimit::get_range_at(FLAG_MEMBER_ENUM(ThreadStackSize))->cast<intx>();\n+  assert(min_ThreadStackSize == static_cast<julong>(limit->min()), \"must be\");\n+  assert(max_ThreadStackSize == static_cast<julong>(limit->max()), \"must be\");\n+\n@@ -4081,1 +4087,1 @@\n-  if (!EnableVectorSupport) {\n+  if (!FLAG_IS_DEFAULT(EnableVectorSupport) && !EnableVectorSupport) {\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -81,1 +81,1 @@\n-  static int     _nof_megamorphic_calls;         \/\/ total # of megamorphic calls (through vtable)\n+  static int64_t _nof_megamorphic_calls;         \/\/ total # of megamorphic calls (through vtable)\n@@ -524,4 +524,6 @@\n-  static BufferBlob* make_native_invoker(address call_target,\n-                                         int shadow_space_bytes,\n-                                         const GrowableArray<VMReg>& input_registers,\n-                                         const GrowableArray<VMReg>& output_registers);\n+#ifdef COMPILER2\n+  static RuntimeStub* make_native_invoker(address call_target,\n+                                          int shadow_space_bytes,\n+                                          const GrowableArray<VMReg>& input_registers,\n+                                          const GrowableArray<VMReg>& output_registers);\n+#endif\n@@ -572,5 +574,5 @@\n-  static int     _nof_normal_calls;              \/\/ total # of calls\n-  static int     _nof_optimized_calls;           \/\/ total # of statically-bound calls\n-  static int     _nof_inlined_calls;             \/\/ total # of inlined normal calls\n-  static int     _nof_static_calls;              \/\/ total # of calls to static methods or super methods (invokespecial)\n-  static int     _nof_inlined_static_calls;      \/\/ total # of inlined static calls\n+  static int64_t _nof_normal_calls;               \/\/ total # of calls\n+  static int64_t _nof_optimized_calls;            \/\/ total # of statically-bound calls\n+  static int64_t _nof_inlined_calls;              \/\/ total # of inlined normal calls\n+  static int64_t _nof_static_calls;               \/\/ total # of calls to static methods or super methods (invokespecial)\n+  static int64_t _nof_inlined_static_calls;       \/\/ total # of inlined static calls\n@@ -578,4 +580,4 @@\n-  static int     _nof_interface_calls;           \/\/ total # of compiled calls\n-  static int     _nof_optimized_interface_calls; \/\/ total # of statically-bound interface calls\n-  static int     _nof_inlined_interface_calls;   \/\/ total # of inlined interface calls\n-  static int     _nof_megamorphic_interface_calls;\/\/ total # of megamorphic interface calls\n+  static int64_t _nof_interface_calls;            \/\/ total # of compiled calls\n+  static int64_t _nof_optimized_interface_calls;  \/\/ total # of statically-bound interface calls\n+  static int64_t _nof_inlined_interface_calls;    \/\/ total # of inlined interface calls\n+  static int64_t _nof_megamorphic_interface_calls;\/\/ total # of megamorphic interface calls\n@@ -593,1 +595,1 @@\n-  static void print_call_statistics(int comp_total);\n+  static void print_call_statistics(uint64_t comp_total);\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":17,"deletions":15,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -33,0 +33,1 @@\n+#include \"runtime\/safefetch.hpp\"\n@@ -34,1 +35,0 @@\n-#include \"runtime\/stubRoutines.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -822,20 +822,0 @@\n-\/\/ Safefetch allows to load a value from a location that's not known\n-\/\/ to be valid. If the load causes a fault, the error value is returned.\n-inline int SafeFetch32(int* adr, int errValue) {\n-  assert(StubRoutines::SafeFetch32_stub(), \"stub not yet generated\");\n-  return StubRoutines::SafeFetch32_stub()(adr, errValue);\n-}\n-inline intptr_t SafeFetchN(intptr_t* adr, intptr_t errValue) {\n-  assert(StubRoutines::SafeFetchN_stub(), \"stub not yet generated\");\n-  return StubRoutines::SafeFetchN_stub()(adr, errValue);\n-}\n-\n-\n-\/\/ returns true if SafeFetch32 and SafeFetchN can be used safely (stubroutines are already generated)\n-inline bool CanUseSafeFetch32() {\n-  return StubRoutines::SafeFetch32_stub() ? true : false;\n-}\n-\n-inline bool CanUseSafeFetchN() {\n-  return StubRoutines::SafeFetchN_stub() ? true : false;\n-}\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":1,"deletions":21,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -310,1 +310,0 @@\n-  nonproduct_nonstatic_field(Method,           _compiled_invocation_count,                    int)                                   \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -7,1 +7,3 @@\n- * published by the Free Software Foundation.\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/vm\/vector\/VectorSupport.java","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2147,1 +2147,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2060,1 +2060,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2072,1 +2072,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2146,1 +2146,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2017,1 +2017,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2147,1 +2147,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2414,1 +2414,2 @@\n-        S ws = shuffletype.cast(shuffle.wrapIndexes());\n+        @SuppressWarnings(\"unchecked\")\n+        S ws = (S) shuffle.wrapIndexes();\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1488,15 +1488,22 @@\n-generate(SpecialCases, [[\"ccmn\",    \"__ ccmn(zr, zr, 3u, Assembler::LE);\",                \"ccmn\\txzr, xzr, #3, LE\"],\n-                        [\"ccmnw\",   \"__ ccmnw(zr, zr, 5u, Assembler::EQ);\",               \"ccmn\\twzr, wzr, #5, EQ\"],\n-                        [\"ccmp\",    \"__ ccmp(zr, 1, 4u, Assembler::NE);\",                 \"ccmp\\txzr, 1, #4, NE\"],\n-                        [\"ccmpw\",   \"__ ccmpw(zr, 2, 2, Assembler::GT);\",                 \"ccmp\\twzr, 2, #2, GT\"],\n-                        [\"extr\",    \"__ extr(zr, zr, zr, 0);\",                            \"extr\\txzr, xzr, xzr, 0\"],\n-                        [\"stlxp\",   \"__ stlxp(r0, zr, zr, sp);\",                          \"stlxp\\tw0, xzr, xzr, [sp]\"],\n-                        [\"stlxpw\",  \"__ stlxpw(r2, zr, zr, r3);\",                         \"stlxp\\tw2, wzr, wzr, [x3]\"],\n-                        [\"stxp\",    \"__ stxp(r4, zr, zr, r5);\",                           \"stxp\\tw4, xzr, xzr, [x5]\"],\n-                        [\"stxpw\",   \"__ stxpw(r6, zr, zr, sp);\",                          \"stxp\\tw6, wzr, wzr, [sp]\"],\n-                        [\"dup\",     \"__ dup(v0, __ T16B, zr);\",                           \"dup\\tv0.16b, wzr\"],\n-                        [\"mov\",     \"__ mov(v1, __ T1D, 0, zr);\",                         \"mov\\tv1.d[0], xzr\"],\n-                        [\"mov\",     \"__ mov(v1, __ T2S, 1, zr);\",                         \"mov\\tv1.s[1], wzr\"],\n-                        [\"mov\",     \"__ mov(v1, __ T4H, 2, zr);\",                         \"mov\\tv1.h[2], wzr\"],\n-                        [\"mov\",     \"__ mov(v1, __ T8B, 3, zr);\",                         \"mov\\tv1.b[3], wzr\"],\n-                        [\"ld1\",     \"__ ld1(v31, v0, __ T2D, Address(__ post(r1, r0)));\", \"ld1\\t{v31.2d, v0.2d}, [x1], x0\"],\n+generate(SpecialCases, [[\"ccmn\",   \"__ ccmn(zr, zr, 3u, Assembler::LE);\",                \"ccmn\\txzr, xzr, #3, LE\"],\n+                        [\"ccmnw\",  \"__ ccmnw(zr, zr, 5u, Assembler::EQ);\",               \"ccmn\\twzr, wzr, #5, EQ\"],\n+                        [\"ccmp\",   \"__ ccmp(zr, 1, 4u, Assembler::NE);\",                 \"ccmp\\txzr, 1, #4, NE\"],\n+                        [\"ccmpw\",  \"__ ccmpw(zr, 2, 2, Assembler::GT);\",                 \"ccmp\\twzr, 2, #2, GT\"],\n+                        [\"extr\",   \"__ extr(zr, zr, zr, 0);\",                            \"extr\\txzr, xzr, xzr, 0\"],\n+                        [\"stlxp\",  \"__ stlxp(r0, zr, zr, sp);\",                          \"stlxp\\tw0, xzr, xzr, [sp]\"],\n+                        [\"stlxpw\", \"__ stlxpw(r2, zr, zr, r3);\",                         \"stlxp\\tw2, wzr, wzr, [x3]\"],\n+                        [\"stxp\",   \"__ stxp(r4, zr, zr, r5);\",                           \"stxp\\tw4, xzr, xzr, [x5]\"],\n+                        [\"stxpw\",  \"__ stxpw(r6, zr, zr, sp);\",                          \"stxp\\tw6, wzr, wzr, [sp]\"],\n+                        [\"dup\",    \"__ dup(v0, __ T16B, zr);\",                           \"dup\\tv0.16b, wzr\"],\n+                        [\"mov\",    \"__ mov(v1, __ T1D, 0, zr);\",                         \"mov\\tv1.d[0], xzr\"],\n+                        [\"mov\",    \"__ mov(v1, __ T2S, 1, zr);\",                         \"mov\\tv1.s[1], wzr\"],\n+                        [\"mov\",    \"__ mov(v1, __ T4H, 2, zr);\",                         \"mov\\tv1.h[2], wzr\"],\n+                        [\"mov\",    \"__ mov(v1, __ T8B, 3, zr);\",                         \"mov\\tv1.b[3], wzr\"],\n+                        [\"smov\",   \"__ smov(r0, v1, __ S, 0);\",                          \"smov\\tx0, v1.s[0]\"],\n+                        [\"smov\",   \"__ smov(r0, v1, __ H, 1);\",                          \"smov\\tx0, v1.h[1]\"],\n+                        [\"smov\",   \"__ smov(r0, v1, __ B, 2);\",                          \"smov\\tx0, v1.b[2]\"],\n+                        [\"umov\",   \"__ umov(r0, v1, __ D, 0);\",                          \"umov\\tx0, v1.d[0]\"],\n+                        [\"umov\",   \"__ umov(r0, v1, __ S, 1);\",                          \"umov\\tw0, v1.s[1]\"],\n+                        [\"umov\",   \"__ umov(r0, v1, __ H, 2);\",                          \"umov\\tw0, v1.h[2]\"],\n+                        [\"umov\",   \"__ umov(r0, v1, __ B, 3);\",                          \"umov\\tw0, v1.b[3]\"],\n+                        [\"ld1\",    \"__ ld1(v31, v0, __ T2D, Address(__ post(r1, r0)));\", \"ld1\\t{v31.2d, v0.2d}, [x1], x0\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":22,"deletions":15,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -688,0 +688,7 @@\n+    __ smov(r0, v1, __ S, 0);                          \/\/       smov    x0, v1.s[0]\n+    __ smov(r0, v1, __ H, 1);                          \/\/       smov    x0, v1.h[1]\n+    __ smov(r0, v1, __ B, 2);                          \/\/       smov    x0, v1.b[2]\n+    __ umov(r0, v1, __ D, 0);                          \/\/       umov    x0, v1.d[0]\n+    __ umov(r0, v1, __ S, 1);                          \/\/       umov    w0, v1.s[1]\n+    __ umov(r0, v1, __ H, 2);                          \/\/       umov    w0, v1.h[2]\n+    __ umov(r0, v1, __ B, 3);                          \/\/       umov    w0, v1.b[3]\n@@ -976,7 +983,7 @@\n-    0x14000000,     0x17ffffd7,     0x14000307,     0x94000000,\n-    0x97ffffd4,     0x94000304,     0x3400000a,     0x34fffa2a,\n-    0x3400602a,     0x35000008,     0x35fff9c8,     0x35005fc8,\n-    0xb400000b,     0xb4fff96b,     0xb4005f6b,     0xb500001d,\n-    0xb5fff91d,     0xb5005f1d,     0x10000013,     0x10fff8b3,\n-    0x10005eb3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36305e36,     0x3758000c,     0x375ff7cc,     0x37585dcc,\n+    0x14000000,     0x17ffffd7,     0x1400030e,     0x94000000,\n+    0x97ffffd4,     0x9400030b,     0x3400000a,     0x34fffa2a,\n+    0x3400610a,     0x35000008,     0x35fff9c8,     0x350060a8,\n+    0xb400000b,     0xb4fff96b,     0xb400604b,     0xb500001d,\n+    0xb5fff91d,     0xb5005ffd,     0x10000013,     0x10fff8b3,\n+    0x10005f93,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36305f16,     0x3758000c,     0x375ff7cc,     0x37585eac,\n@@ -987,13 +994,13 @@\n-    0x54005ba0,     0x54000001,     0x54fff541,     0x54005b41,\n-    0x54000002,     0x54fff4e2,     0x54005ae2,     0x54000002,\n-    0x54fff482,     0x54005a82,     0x54000003,     0x54fff423,\n-    0x54005a23,     0x54000003,     0x54fff3c3,     0x540059c3,\n-    0x54000004,     0x54fff364,     0x54005964,     0x54000005,\n-    0x54fff305,     0x54005905,     0x54000006,     0x54fff2a6,\n-    0x540058a6,     0x54000007,     0x54fff247,     0x54005847,\n-    0x54000008,     0x54fff1e8,     0x540057e8,     0x54000009,\n-    0x54fff189,     0x54005789,     0x5400000a,     0x54fff12a,\n-    0x5400572a,     0x5400000b,     0x54fff0cb,     0x540056cb,\n-    0x5400000c,     0x54fff06c,     0x5400566c,     0x5400000d,\n-    0x54fff00d,     0x5400560d,     0x5400000e,     0x54ffefae,\n-    0x540055ae,     0x5400000f,     0x54ffef4f,     0x5400554f,\n+    0x54005c80,     0x54000001,     0x54fff541,     0x54005c21,\n+    0x54000002,     0x54fff4e2,     0x54005bc2,     0x54000002,\n+    0x54fff482,     0x54005b62,     0x54000003,     0x54fff423,\n+    0x54005b03,     0x54000003,     0x54fff3c3,     0x54005aa3,\n+    0x54000004,     0x54fff364,     0x54005a44,     0x54000005,\n+    0x54fff305,     0x540059e5,     0x54000006,     0x54fff2a6,\n+    0x54005986,     0x54000007,     0x54fff247,     0x54005927,\n+    0x54000008,     0x54fff1e8,     0x540058c8,     0x54000009,\n+    0x54fff189,     0x54005869,     0x5400000a,     0x54fff12a,\n+    0x5400580a,     0x5400000b,     0x54fff0cb,     0x540057ab,\n+    0x5400000c,     0x54fff06c,     0x5400574c,     0x5400000d,\n+    0x54fff00d,     0x540056ed,     0x5400000e,     0x54ffefae,\n+    0x5400568e,     0x5400000f,     0x54ffef4f,     0x5400562f,\n@@ -1031,1 +1038,1 @@\n-    0xbd1b1869,     0x5800459b,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x5800467b,     0x1800000b,     0xf8945060,\n@@ -1109,62 +1116,64 @@\n-    0x4e071fe1,     0x4cc0ac3f,     0x05a08020,     0x05104fe0,\n-    0x05505001,     0x05906fe2,     0x05d03005,     0x05101fea,\n-    0x05901feb,     0x04b0e3e0,     0x0470e7e1,     0x042f9c20,\n-    0x043f9c35,     0x047f9c20,     0x04ff9c20,     0x04299420,\n-    0x04319160,     0x0461943e,     0x04a19020,     0x042053ff,\n-    0x047f5401,     0x25208028,     0x2538cfe0,     0x2578d001,\n-    0x25b8efe2,     0x25f8f007,     0x2538dfea,     0x25b8dfeb,\n-    0xa400a3e0,     0xa420a7e0,     0xa4484be0,     0xa467afe0,\n-    0xa4a8a7ea,     0xa547a814,     0xa4084ffe,     0xa55c53e0,\n-    0xa5e1540b,     0xe400fbf6,     0xe408ffff,     0xe420e7e0,\n-    0xe4484be0,     0xe460efe0,     0xe547e400,     0xe4014be0,\n-    0xe4a84fe0,     0xe5f15000,     0x858043e0,     0x85a043ff,\n-    0xe59f5d08,     0x0522c020,     0x05e6c0a4,     0x2401a001,\n-    0x2443a051,     0x24858881,     0x24c78cd1,     0x240b8142,\n-    0x24918213,     0x250f9001,     0x25508051,     0x25802491,\n-    0x25df28c1,     0x25850c81,     0x251e10d1,     0x65816001,\n-    0x65c36051,     0x65854891,     0x65c74cc1,     0x658b4152,\n-    0x65d14203,     0x05733820,     0x05b238a4,     0x05f138e6,\n-    0x0570396a,     0x25221420,     0x25640461,     0x25a614b2,\n-    0x25eb0553,     0x25221c24,     0x25640c60,     0x25a61cb1,\n-    0x25eb0d52,     0x65d0a001,     0x65d1a443,     0x65cbac85,\n-    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,\n-    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,\n-    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,\n-    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,\n-    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,\n-    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,\n-    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,\n-    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,\n-    0xf8238358,     0xf83702af,     0xf8231118,     0xf8392214,\n-    0xf8313022,     0xf8205098,     0xf82343ec,     0xf83c734a,\n-    0xf82261ec,     0xf8bf81a1,     0xf8bd0260,     0xf8ac12d1,\n-    0xf8ad23dc,     0xf8bf3341,     0xf8bc53c4,     0xf8a443c6,\n-    0xf8ba7130,     0xf8a8600c,     0xf8f48301,     0xf8e20120,\n-    0xf8f8121a,     0xf8fe2143,     0xf8f7308a,     0xf8f05162,\n-    0xf8e841ea,     0xf8f17142,     0xf8ec61ec,     0xf86d80e2,\n-    0xf874021a,     0xf8641082,     0xf86c22b0,     0xf8703170,\n-    0xf8755197,     0xf87a4397,     0xf86e730b,     0xf86163ec,\n-    0xb82a80f0,     0xb82201a3,     0xb8331211,     0xb8232161,\n-    0xb83e3105,     0xb82f53dd,     0xb82040f4,     0xb8347397,\n-    0xb835633b,     0xb8a582e1,     0xb8b000bf,     0xb8ac1389,\n-    0xb8af22dd,     0xb8bf33f3,     0xb8a551ee,     0xb8bf4370,\n-    0xb8b47190,     0xb8ab60c9,     0xb8fe8371,     0xb8fc00fe,\n-    0xb8ea1154,     0xb8e42238,     0xb8f13076,     0xb8fd52cf,\n-    0xb8f342d3,     0xb8e270cf,     0xb8ec6170,     0xb86d8037,\n-    0xb87e00b3,     0xb8711202,     0xb876214d,     0xb875337d,\n-    0xb86c507b,     0xb861431f,     0xb8737131,     0xb87c61fb,\n-    0xce367a86,     0xce1e6858,     0xce768d51,     0xce910451,\n-    0xce768338,     0xce6c8622,     0xcec08363,     0xce708b9d,\n-    0x04e900da,     0x042404f1,     0x6596012f,     0x65d40b62,\n-    0x65c00745,     0x0456a72e,     0x04c0175b,     0x04109418,\n-    0x041ab006,     0x0413812f,     0x04118b65,     0x04101694,\n-    0x04d7aa0a,     0x045eb046,     0x04c81c5d,     0x044a1dd6,\n-    0x040112fb,     0x04dcad42,     0x65809aca,     0x658d9603,\n-    0x65c69201,     0x65878d8c,     0x65c28290,     0x04dda4e5,\n-    0x65c2be0c,     0x6580a386,     0x65c1a624,     0x658dae6d,\n-    0x65819638,     0x65f318ca,     0x65a030cd,     0x65a8532e,\n-    0x65bb76d6,     0x04144e23,     0x04407ce4,     0x04363270,\n-    0x04b6312f,     0x047e30b9,     0x052b6acd,     0x05b46d0d,\n-    0x041a2c99,     0x04d828d1,     0x04d93e04,     0x040829da,\n-    0x040a3c6b,     0x65c73aa1,     0x65c62a2e,     0x65d82678,\n-    0x04c13611,\n+    0x4e071fe1,     0x4e042c20,     0x4e062c20,     0x4e052c20,\n+    0x4e083c20,     0x0e0c3c20,     0x0e0a3c20,     0x0e073c20,\n+    0x4cc0ac3f,     0x05a08020,     0x05104fe0,     0x05505001,\n+    0x05906fe2,     0x05d03005,     0x05101fea,     0x05901feb,\n+    0x04b0e3e0,     0x0470e7e1,     0x042f9c20,     0x043f9c35,\n+    0x047f9c20,     0x04ff9c20,     0x04299420,     0x04319160,\n+    0x0461943e,     0x04a19020,     0x042053ff,     0x047f5401,\n+    0x25208028,     0x2538cfe0,     0x2578d001,     0x25b8efe2,\n+    0x25f8f007,     0x2538dfea,     0x25b8dfeb,     0xa400a3e0,\n+    0xa420a7e0,     0xa4484be0,     0xa467afe0,     0xa4a8a7ea,\n+    0xa547a814,     0xa4084ffe,     0xa55c53e0,     0xa5e1540b,\n+    0xe400fbf6,     0xe408ffff,     0xe420e7e0,     0xe4484be0,\n+    0xe460efe0,     0xe547e400,     0xe4014be0,     0xe4a84fe0,\n+    0xe5f15000,     0x858043e0,     0x85a043ff,     0xe59f5d08,\n+    0x0522c020,     0x05e6c0a4,     0x2401a001,     0x2443a051,\n+    0x24858881,     0x24c78cd1,     0x240b8142,     0x24918213,\n+    0x250f9001,     0x25508051,     0x25802491,     0x25df28c1,\n+    0x25850c81,     0x251e10d1,     0x65816001,     0x65c36051,\n+    0x65854891,     0x65c74cc1,     0x658b4152,     0x65d14203,\n+    0x05733820,     0x05b238a4,     0x05f138e6,     0x0570396a,\n+    0x25221420,     0x25640461,     0x25a614b2,     0x25eb0553,\n+    0x25221c24,     0x25640c60,     0x25a61cb1,     0x25eb0d52,\n+    0x65d0a001,     0x65d1a443,     0x65cbac85,     0x1e601000,\n+    0x1e603000,     0x1e621000,     0x1e623000,     0x1e641000,\n+    0x1e643000,     0x1e661000,     0x1e663000,     0x1e681000,\n+    0x1e683000,     0x1e6a1000,     0x1e6a3000,     0x1e6c1000,\n+    0x1e6c3000,     0x1e6e1000,     0x1e6e3000,     0x1e701000,\n+    0x1e703000,     0x1e721000,     0x1e723000,     0x1e741000,\n+    0x1e743000,     0x1e761000,     0x1e763000,     0x1e781000,\n+    0x1e783000,     0x1e7a1000,     0x1e7a3000,     0x1e7c1000,\n+    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8238358,\n+    0xf83702af,     0xf8231118,     0xf8392214,     0xf8313022,\n+    0xf8205098,     0xf82343ec,     0xf83c734a,     0xf82261ec,\n+    0xf8bf81a1,     0xf8bd0260,     0xf8ac12d1,     0xf8ad23dc,\n+    0xf8bf3341,     0xf8bc53c4,     0xf8a443c6,     0xf8ba7130,\n+    0xf8a8600c,     0xf8f48301,     0xf8e20120,     0xf8f8121a,\n+    0xf8fe2143,     0xf8f7308a,     0xf8f05162,     0xf8e841ea,\n+    0xf8f17142,     0xf8ec61ec,     0xf86d80e2,     0xf874021a,\n+    0xf8641082,     0xf86c22b0,     0xf8703170,     0xf8755197,\n+    0xf87a4397,     0xf86e730b,     0xf86163ec,     0xb82a80f0,\n+    0xb82201a3,     0xb8331211,     0xb8232161,     0xb83e3105,\n+    0xb82f53dd,     0xb82040f4,     0xb8347397,     0xb835633b,\n+    0xb8a582e1,     0xb8b000bf,     0xb8ac1389,     0xb8af22dd,\n+    0xb8bf33f3,     0xb8a551ee,     0xb8bf4370,     0xb8b47190,\n+    0xb8ab60c9,     0xb8fe8371,     0xb8fc00fe,     0xb8ea1154,\n+    0xb8e42238,     0xb8f13076,     0xb8fd52cf,     0xb8f342d3,\n+    0xb8e270cf,     0xb8ec6170,     0xb86d8037,     0xb87e00b3,\n+    0xb8711202,     0xb876214d,     0xb875337d,     0xb86c507b,\n+    0xb861431f,     0xb8737131,     0xb87c61fb,     0xce367a86,\n+    0xce1e6858,     0xce768d51,     0xce910451,     0xce768338,\n+    0xce6c8622,     0xcec08363,     0xce708b9d,     0x04e900da,\n+    0x042404f1,     0x6596012f,     0x65d40b62,     0x65c00745,\n+    0x0456a72e,     0x04c0175b,     0x04109418,     0x041ab006,\n+    0x0413812f,     0x04118b65,     0x04101694,     0x04d7aa0a,\n+    0x045eb046,     0x04c81c5d,     0x044a1dd6,     0x040112fb,\n+    0x04dcad42,     0x65809aca,     0x658d9603,     0x65c69201,\n+    0x65878d8c,     0x65c28290,     0x04dda4e5,     0x65c2be0c,\n+    0x6580a386,     0x65c1a624,     0x658dae6d,     0x65819638,\n+    0x65f318ca,     0x65a030cd,     0x65a8532e,     0x65bb76d6,\n+    0x04144e23,     0x04407ce4,     0x04363270,     0x04b6312f,\n+    0x047e30b9,     0x052b6acd,     0x05b46d0d,     0x041a2c99,\n+    0x04d828d1,     0x04d93e04,     0x040829da,     0x040a3c6b,\n+    0x65c73aa1,     0x65c62a2e,     0x65d82678,     0x04c13611,\n+\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":92,"deletions":83,"binary":false,"changes":175,"status":"modified"}]}