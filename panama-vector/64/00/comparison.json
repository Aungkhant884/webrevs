{"files":[{"patch":"@@ -4265,0 +4265,10 @@\n+operand immI_gt_1()\n+%{\n+  predicate(n->get_int() > 1);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -46,0 +47,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -60,1 +62,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -74,1 +76,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -83,0 +85,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -85,5 +89,0 @@\n-\/\/ If the vector element size is not the same as memory\n-\/\/ element size, the adddress displacement range is\n-\/\/ different from vmemA_indOffL4\/vmemA_indOffI4.\n-opclass vmemA_narrow_extend(indirect);\n-\n@@ -258,1 +257,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -274,1 +273,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -286,0 +285,96 @@\n+\/\/ Load Vector (16 bits)\n+instruct loadV2_vreg(vReg dst, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 2 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrh   $dst,$mem\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvH(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (16 bits)\n+instruct storeV2_vreg(vReg src, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 2 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strh   $mem,$src\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_strvH(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (32 bits)\n+instruct loadV4_vreg(vReg dst, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 4 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (32 bits)\n+instruct storeV4_vreg(vReg src, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 4 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8_vreg(vReg dst, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 8 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8_vreg(vReg src, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 8 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16_vreg(vReg dst, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(vload_reg_mem128);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16_vreg(vReg src, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(vstore_reg_mem128);\n+%}\n+\n@@ -291,1 +386,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 2 &&\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n@@ -295,1 +390,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(6 * SVE_COST);\n@@ -298,1 +393,1 @@\n-            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask\" %}\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask (sve)\" %}\n@@ -313,1 +408,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 2 &&\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n@@ -317,1 +412,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(5 * SVE_COST);\n@@ -320,1 +415,1 @@\n-            \"sve_str $src, $pTmp, $mem\\t # store vector mask\" %}\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask (sve)\" %}\n@@ -1210,3 +1305,3 @@\n-instruct vloadmask_loadV(vReg dst, vmemA_narrow_extend mem) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 2 &&\n-            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+instruct vloadmask_loadV_byte(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n@@ -1214,1 +1309,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(5 * SVE_COST);\n@@ -1229,3 +1324,22 @@\n-instruct storeV_vstoremask(vmemA_narrow_extend mem, vReg src, vReg tmp, immI esize) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= 2 &&\n-            n->as_StoreVector()->vect_type()->element_basic_type() == T_BOOLEAN);\n+instruct vloadmask_loadV_non_byte(vReg dst, indirect mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                         T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask_byte(vmemA mem, vReg src, vReg tmp, immI_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n@@ -1234,1 +1348,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(5 * SVE_COST);\n@@ -1250,0 +1364,22 @@\n+instruct storeV_vstoremask_non_byte(indirect mem, vReg src, vReg tmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                         ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":159,"deletions":23,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -32,2 +32,0 @@\n-\n-\/\/ 4 bit signed offset -- for predicated load\/store\n@@ -44,2 +42,2 @@\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3     )\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len)\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3       $4   )\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len, scale)\n@@ -49,0 +47,1 @@\n+  \/\/ (esize \/ msize) = $4\n@@ -50,1 +49,1 @@\n-            Matcher::scalable_vector_reg_size(T_BYTE)));\n+            Matcher::scalable_vector_reg_size(T_BYTE)ifelse($4, `1', `', ` \/ $4')));\n@@ -57,2 +56,4 @@\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4)\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4)\n+\n+\/\/ 4 bit signed offset -- for predicated load\/store\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4, 1)\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4, 1)\n@@ -63,1 +64,1 @@\n-operand vmemA_indOff$1$2(iRegP reg, vmemA_imm$1Offset$2 off)\n+operand vmemA_indOff$1$2$3(iRegP reg, vmemA_imm$1Offset$2 off)\n@@ -68,1 +69,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -79,0 +80,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -81,5 +84,0 @@\n-\/\/ If the vector element size is not the same as memory\n-\/\/ element size, the adddress displacement range is\n-\/\/ different from vmemA_indOffL4\/vmemA_indOffI4.\n-opclass vmemA_narrow_extend(indirect);\n-\n@@ -262,1 +260,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -278,1 +276,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -288,1 +286,24 @@\n-%}\n+%}dnl\n+\n+dnl\n+define(`VLoadStore', `\n+\/\/ ifelse(load, $3, Load, Store) Vector ($6 bits)\n+instruct $3V$4_vreg`'(vReg $7, vmem$4 mem)\n+%{\n+  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4 &&\n+            `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() < MaxVectorSize);\n+  match(Set ifelse(load, $3, dst (LoadVector mem), mem (StoreVector mem src)));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"$1   ifelse(load, $3, `$dst,$mem', `$mem,$src')\\t# vector ($6 bits)\" %}\n+  ins_encode( `aarch64_enc_'ifelse(load, $3, ldr, str)v$2($7, mem) );\n+  ins_pipe(v$3`_reg_mem'ifelse(eval($4 * 8), 128, 128, 64));\n+%}')dnl\n+dnl        $1    $2 $3     $4  $5 $6   $7\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst)\n+VLoadStore(strh, H, store, 2,  D, 16,  src)\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst)\n+VLoadStore(strs, S, store, 4,  D, 32,  src)\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst)\n+VLoadStore(strd, D, store, 8,  D, 64,  src)\n+VLoadStore(ldrq, Q, load, 16,  X, 128, dst)\n+VLoadStore(strq, Q, store, 16, X, 128, src)\n@@ -295,1 +316,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 2 &&\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n@@ -299,1 +320,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(6 * SVE_COST);\n@@ -302,1 +323,1 @@\n-            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask\" %}\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector mask (sve)\" %}\n@@ -317,1 +338,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 2 &&\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n@@ -321,1 +342,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(5 * SVE_COST);\n@@ -324,1 +345,1 @@\n-            \"sve_str $src, $pTmp, $mem\\t # store vector mask\" %}\n+            \"sve_str $src, $pTmp, $mem\\t # store vector mask (sve)\" %}\n@@ -915,6 +936,8 @@\n-\n-\/\/ load\/store mask vector\n-\n-instruct vloadmask_loadV(vReg dst, vmemA_narrow_extend mem) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 2 &&\n-            n->in(1)->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN);\n+dnl\n+dnl\n+dnl VLOADMASK_LOADV($1,    $2  )\n+dnl VLOADMASK_LOADV(esize, cond)\n+define(`VLOADMASK_LOADV', `\n+instruct vloadmask_loadV_$1(vReg dst, ifelse($1, `byte', vmemA, indirect) mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) $2);\n@@ -922,1 +945,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(5 * SVE_COST);\n@@ -935,5 +958,11 @@\n-%}\n-\n-instruct storeV_vstoremask(vmemA_narrow_extend mem, vReg src, vReg tmp, immI esize) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->length() >= 2 &&\n-            n->as_StoreVector()->vect_type()->element_basic_type() == T_BOOLEAN);\n+%}')dnl\n+dnl\n+define(`ARGLIST',\n+`ifelse($1, `byte', vmemA, indirect) mem, vReg src, vReg tmp, ifelse($1, `byte', immI_1, immI_gt_1) esize')\n+dnl\n+dnl STOREV_VSTOREMASK($1,  )\n+dnl STOREV_VSTOREMASK(esize)\n+define(`STOREV_VSTOREMASK', `\n+instruct storeV_vstoremask_$1(ARGLIST($1)) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n@@ -942,1 +971,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(5 * SVE_COST);\n@@ -956,1 +985,8 @@\n-%}dnl\n+%}')dnl\n+undefine(ARGLIST)dnl\n+dnl\n+\/\/ load\/store mask vector\n+VLOADMASK_LOADV(byte, == 1)\n+VLOADMASK_LOADV(non_byte, > 1)\n+STOREV_VSTOREMASK(byte)\n+STOREV_VSTOREMASK(non_byte)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":73,"deletions":37,"binary":false,"changes":110,"status":"modified"}]}