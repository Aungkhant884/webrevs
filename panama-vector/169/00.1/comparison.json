{"files":[{"patch":"@@ -2463,0 +2463,1 @@\n+    case Op_CompressV:\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -152,0 +152,2 @@\n+      case Op_CompressV:\n+        return (bt == T_INT || bt == T_LONG);\n@@ -5747,0 +5749,15 @@\n+%}\n+\n+\/\/ ---------------------------- Compress\/Expand Operations ---------------------------\n+\n+instruct vcompress(vReg dst, vReg src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (CompressV src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_compact $dst, $src, $pg\\t# vector compress (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_compact(as_FloatRegister($dst$$reg), size, as_FloatRegister($src$$reg), as_PRegister($pg$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -147,0 +147,2 @@\n+      case Op_CompressV:\n+        return (bt == T_INT || bt == T_LONG);\n@@ -3178,0 +3180,16 @@\n+\n+\n+\/\/ ---------------------------- Compress\/Expand Operations ---------------------------\n+\n+instruct vcompress(vReg dst, vReg src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (CompressV src pg));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_compact $dst, $src, $pg\\t# vector compress (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_compact(as_FloatRegister($dst$$reg), size, as_FloatRegister($src$$reg), as_PRegister($pg$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -3679,0 +3679,8 @@\n+  \/\/ Shuffle active elements of vector to the right and fill with zero\n+  void sve_compact(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, PRegister Pg) {\n+    starti;\n+    assert(T == S || T == D, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b100001100, 21, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -4120,0 +4120,65 @@\n+\n+void C2_MacroAssembler::vector_mask_compress(KRegister dst, KRegister src, Register rtmp1,\n+                                             Register rtmp2, int mask_len) {\n+  kmov(rtmp1, src);\n+  andq(rtmp1, (0xFFFFFFFFFFFFFFFFUL >> (64 - mask_len)));\n+  mov64(rtmp2, -1L);\n+  pext(rtmp2, rtmp2, rtmp1);\n+  kmov(dst, rtmp2);\n+}\n+\n+void C2_MacroAssembler::vector_compress_expand(int opcode, XMMRegister dst, XMMRegister src, KRegister mask,\n+                                               bool merge, BasicType bt, int vec_enc) {\n+  if (opcode == Op_CompressV) {\n+    switch(bt) {\n+    case T_BYTE:\n+      evpcompressb(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evpcompressw(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_INT:\n+      evpcompressd(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_FLOAT:\n+      evcompressps(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_LONG:\n+      evpcompressq(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_DOUBLE:\n+      evcompresspd(dst, mask, src, merge, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type\");\n+      break;\n+    }\n+  } else {\n+    assert(opcode == Op_ExpandV, \"\");\n+    switch(bt) {\n+    case T_BYTE:\n+      evpexpandb(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evpexpandw(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_INT:\n+      evpexpandd(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_FLOAT:\n+      evexpandps(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_LONG:\n+      evpexpandq(dst, mask, src, merge, vec_enc);\n+      break;\n+    case T_DOUBLE:\n+      evexpandpd(dst, mask, src, merge, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type\");\n+      break;\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":65,"deletions":0,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -1602,0 +1602,11 @@\n+    case Op_CompressM:\n+      if (!VM_Version::supports_avx512vl() || !VM_Version::supports_bmi2()) {\n+        return false;\n+      }\n+      break;\n+    case Op_CompressV:\n+    case Op_ExpandV:\n+      if (!VM_Version::supports_avx512vl()) {\n+        return false;\n+      }\n+      break;\n@@ -1810,1 +1821,1 @@\n-      if(is_subword_type(bt)) {\n+      if (is_subword_type(bt)) {\n@@ -1837,0 +1848,17 @@\n+    case Op_CompressM:\n+      if (UseAVX < 3 || !VM_Version::supports_bmi2()) {\n+        return false;\n+      }\n+      break;\n+    case Op_CompressV:\n+    case Op_ExpandV:\n+      if (is_subword_type(bt) && !VM_Version::supports_avx512_vbmi2()) {\n+        return false;\n+      }\n+      if (size_in_bits < 128 ) {\n+        return false;\n+      }\n+      if (size_in_bits < 512 && !VM_Version::supports_avx512vl()) {\n+        return false;\n+      }\n+      break;\n@@ -4567,1 +4595,1 @@\n-    __ insertps($dst$$XMMRegister, $val$$XMMRegister, $idx$$constant);\n+    __ insertps($dst$$XMMRegister, $val$$XMMRegister, $idx$$constant << 4);\n@@ -4587,1 +4615,1 @@\n-      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx);\n+      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx << 4);\n@@ -4593,1 +4621,1 @@\n-      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx);\n+      __ vinsertps($vtmp$$XMMRegister, $vtmp$$XMMRegister, $val$$XMMRegister, x_idx << 4);\n@@ -8760,0 +8788,28 @@\n+\n+\/\/ --------------------------------- Compress\/Expand Operations ---------------------------\n+\n+instruct vcompress_expand_reg_evex(vec dst, vec src, kReg mask) %{\n+  match(Set dst (CompressV src mask));\n+  match(Set dst (ExpandV src mask));\n+  format %{ \"vector_compress_expand $dst, $src, $mask\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    int vector_len = vector_length_encoding(this);\n+    BasicType bt  = Matcher::vector_element_basic_type(this);\n+    __ vector_compress_expand(opcode, $dst$$XMMRegister, $src$$XMMRegister, $mask$$KRegister, false, bt, vector_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcompress_mask_reg_evex(kReg dst, kReg mask, rRegL rtmp1, rRegL rtmp2, rFlagsReg cr) %{\n+  match(Set dst (CompressM mask));\n+  effect(TEMP rtmp1, TEMP rtmp2, KILL cr);\n+  format %{ \"mask_compress_evex $dst, $mask\\t! using $rtmp1 and $rtmp2 as TEMP\" %}\n+  ins_encode %{\n+    assert(this->in(1)->bottom_type()->isa_vectmask(), \"\");\n+    int mask_len = Matcher::vector_length(this);\n+    __ vector_mask_compress($dst$$KRegister, $mask$$KRegister, $rtmp1$$Register, $rtmp2$$Register, mask_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":60,"deletions":4,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -179,0 +179,3 @@\n+class ExpandVNode;\n+class CompressVNode;\n+class CompressMNode;\n@@ -716,0 +719,3 @@\n+        DEFINE_CLASS_ID(CompressV, Vector, 4)\n+        DEFINE_CLASS_ID(ExpandV, Vector, 5)\n+        DEFINE_CLASS_ID(CompressM, Vector, 6)\n@@ -945,1 +951,4 @@\n-  DEFINE_CLASS_QUERY(VectorReinterpret);\n+  DEFINE_CLASS_QUERY(VectorReinterpret)\n+  DEFINE_CLASS_QUERY(CompressV)\n+  DEFINE_CLASS_QUERY(ExpandV)\n+  DEFINE_CLASS_QUERY(CompressM)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -85,1 +85,2 @@\n-      if (!Matcher::match_rule_supported_vector(Op_VectorLoadMask, num_elem, elem_bt)) {\n+      if (!Matcher::match_rule_supported_vector(Op_VectorLoadMask, num_elem, elem_bt) ||\n+          !Matcher::match_rule_supported_vector(Op_LoadVector, num_elem, T_BOOLEAN)) {\n@@ -255,1 +256,2 @@\n-    if (!Matcher::match_rule_supported_vector(Op_VectorLoadMask, num_elem, type)) {\n+    if (!Matcher::match_rule_supported_vector(Op_VectorLoadMask, num_elem, type) ||\n+        !Matcher::match_rule_supported_vector(Op_LoadVector, num_elem, T_BOOLEAN)) {\n@@ -268,1 +270,2 @@\n-    if (!Matcher::match_rule_supported_vector(Op_VectorStoreMask, num_elem, type)) {\n+    if (!Matcher::match_rule_supported_vector(Op_VectorStoreMask, num_elem, type) ||\n+        !Matcher::match_rule_supported_vector(Op_StoreVector, num_elem, T_BOOLEAN)) {\n@@ -680,9 +683,1 @@\n-  if (!arch_supports_vector(Op_LoadVector, num_elem, T_BOOLEAN, VecMaskNotUsed)) {\n-    if (C->print_intrinsics()) {\n-      tty->print_cr(\"  ** not supported: arity=1 op=cast#%d\/3 vlen2=%d etype2=%s\",\n-                    Op_LoadVector, num_elem, type2name(T_BOOLEAN));\n-    }\n-    return false; \/\/ not supported\n-  }\n-\n-  if (!arch_supports_vector(mopc, num_elem, elem_bt, VecMaskNotUsed)) {\n+  if (!arch_supports_vector(mopc, num_elem, elem_bt, VecMaskUseLoad)) {\n@@ -1011,10 +1006,0 @@\n-    if (!arch_supports_vector(Op_LoadVector, num_elem, T_BOOLEAN, VecMaskNotUsed)) {\n-      if (C->print_intrinsics()) {\n-        tty->print_cr(\"  ** not supported: arity=%d op=%s\/mask vlen=%d etype=bit ismask=no\",\n-                      is_store, is_store ? \"store\" : \"load\",\n-                      num_elem);\n-      }\n-      set_map(old_map);\n-      set_sp(old_sp);\n-      return false; \/\/ not supported\n-    }\n@@ -1058,1 +1043,3 @@\n-\n+    if (is_mask) {\n+      val = gvn().transform(VectorStoreMaskNode::make(gvn(), val, elem_bt, num_elem));\n+    }\n@@ -2710,0 +2697,94 @@\n+\/\/ public static\n+\/\/ <V extends Vector<E>,\n+\/\/  M extends VectorMask<E>,\n+\/\/  E>\n+\/\/  V comExpOp(int opr,\n+\/\/             Class<? extends V> vClass, Class<? extends M> mClass, Class<E> eClass,\n+\/\/             int length, V v, M m,\n+\/\/             CmpExpOperation<V, M> defaultImpl)\n+bool LibraryCallKit::inline_vector_compress_expand() {\n+  const TypeInt*     opr          = gvn().type(argument(0))->isa_int();\n+  const TypeInstPtr* vector_klass = gvn().type(argument(1))->isa_instptr();\n+  const TypeInstPtr* mask_klass   = gvn().type(argument(2))->isa_instptr();\n+  const TypeInstPtr* elem_klass   = gvn().type(argument(3))->isa_instptr();\n+  const TypeInt*     vlen         = gvn().type(argument(4))->isa_int();\n+\n+  if (vector_klass == NULL || elem_klass == NULL || mask_klass == NULL || vlen == NULL ||\n+      vector_klass->const_oop() == NULL || mask_klass->const_oop() == NULL ||\n+      elem_klass->const_oop() == NULL || !vlen->is_con()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** missing constant: opr=%s vclass=%s mclass=%s etype=%s vlen=%s\",\n+                    NodeClassNames[argument(0)->Opcode()],\n+                    NodeClassNames[argument(1)->Opcode()],\n+                    NodeClassNames[argument(2)->Opcode()],\n+                    NodeClassNames[argument(3)->Opcode()],\n+                    NodeClassNames[argument(4)->Opcode()]);\n+    }\n+    return false; \/\/ not enough info for intrinsification\n+  }\n+\n+  if (!is_klass_initialized(vector_klass) || !is_klass_initialized(mask_klass)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** klass argument not initialized\");\n+    }\n+    return false;\n+  }\n+\n+  ciType* elem_type = elem_klass->const_oop()->as_instance()->java_mirror_type();\n+  if (!elem_type->is_primitive_type()) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not a primitive bt=%d\", elem_type->basic_type());\n+    }\n+    return false; \/\/ should be primitive type\n+  }\n+\n+  int num_elem = vlen->get_con();\n+  BasicType elem_bt = elem_type->basic_type();\n+  int opc = VectorSupport::vop2ideal(opr->get_con(), elem_bt);\n+\n+  if (!arch_supports_vector(opc, num_elem, elem_bt, VecMaskUseLoad)) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** not supported: opc=%d vlen=%d etype=%s ismask=useload\",\n+                    opc, num_elem, type2name(elem_bt));\n+    }\n+    return false; \/\/ not supported\n+  }\n+\n+  Node* opd1 = NULL;\n+  const TypeInstPtr* vbox_type = NULL;\n+  if (opc != Op_CompressM) {\n+    ciKlass* vbox_klass = vector_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+    vbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, vbox_klass);\n+    opd1 = unbox_vector(argument(5), vbox_type, elem_bt, num_elem);\n+    if (opd1 == NULL) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** unbox failed vector=%s\",\n+                      NodeClassNames[argument(5)->Opcode()]);\n+      }\n+      return false;\n+    }\n+  }\n+\n+  ciKlass* mbox_klass = mask_klass->const_oop()->as_instance()->java_lang_Class_klass();\n+  assert(is_vector_mask(mbox_klass), \"argument(6) should be a mask class\");\n+  const TypeInstPtr* mbox_type = TypeInstPtr::make_exact(TypePtr::NotNull, mbox_klass);\n+\n+  Node* mask = unbox_vector(argument(6), mbox_type, elem_bt, num_elem);\n+  if (mask == NULL) {\n+    if (C->print_intrinsics()) {\n+      tty->print_cr(\"  ** unbox failed mask=%s\",\n+                    NodeClassNames[argument(6)->Opcode()]);\n+    }\n+    return false;\n+  }\n+\n+  const TypeVect* vt = TypeVect::make(elem_bt, num_elem, opc == Op_CompressM);\n+  Node* operation = gvn().transform(VectorNode::make(opc, opd1, mask, vt));\n+\n+  \/\/ Wrap it up in VectorBox to keep object type information.\n+  const TypeInstPtr* box_type = opc == Op_CompressM ? mbox_type : vbox_type;\n+  Node* vbox = box_vector(operation, box_type, elem_bt, num_elem);\n+  set_result(vbox);\n+  C->set_max_vector_size(MAX2(C->max_vector_size(), (uint)(num_elem * type2aelembytes(elem_bt))));\n+  return true;\n+}\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":104,"deletions":23,"binary":false,"changes":127,"status":"modified"},{"patch":"@@ -559,0 +559,4 @@\n+\n+  case Op_ExpandV: return new ExpandVNode(n1, n2, vt);\n+  case Op_CompressV: return new CompressVNode(n1, n2, vt);\n+  case Op_CompressM: assert(n1 == NULL, \"\"); return new CompressMNode(n2, vt);\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -734,0 +734,31 @@\n+\/\/------------------------------CompressVNode--------------------------------------\n+\/\/ Vector compress\n+class CompressVNode: public VectorNode {\n+ public:\n+  CompressVNode(Node* vec, Node* mask, const TypeVect* vt) :\n+      VectorNode(vec, mask, vt) {\n+    init_class_id(Class_CompressV);\n+  }\n+  virtual int Opcode() const;\n+};\n+\n+class CompressMNode: public VectorNode {\n+ public:\n+  CompressMNode(Node* mask, const TypeVect* vt) :\n+      VectorNode(mask, vt) {\n+    init_class_id(Class_CompressM);\n+  }\n+  virtual int Opcode() const;\n+};\n+\n+\/\/------------------------------ExpandVNode--------------------------------------\n+\/\/ Vector expand\n+class ExpandVNode: public VectorNode {\n+ public:\n+  ExpandVNode(Node* vec, Node* mask, const TypeVect* vt) :\n+      VectorNode(vec, mask, vt) {\n+    init_class_id(Class_ExpandV);\n+  }\n+  virtual int Opcode() const;\n+};\n+\n@@ -1349,1 +1380,0 @@\n-    \/\/ assert(mask->is_VectorMask(), \"VectorBlendNode requires that third argument be a mask\");\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":31,"deletions":1,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -446,0 +446,36 @@\n+    case VECTOR_OP_EXPAND: {\n+      switch (bt) {\n+        case T_BYTE:  \/\/ fall-through\n+        case T_SHORT: \/\/ fall-through\n+        case T_INT:   \/\/ fall-through\n+        case T_LONG:  \/\/ fall-through\n+        case T_FLOAT: \/\/ fall-through\n+        case T_DOUBLE: return Op_ExpandV;\n+        default: fatal(\"EXPAND: %s\", type2name(bt));\n+      }\n+      break;\n+    }\n+    case VECTOR_OP_COMPRESS: {\n+      switch (bt) {\n+        case T_BYTE:  \/\/ fall-through\n+        case T_SHORT: \/\/ fall-through\n+        case T_INT:   \/\/ fall-through\n+        case T_LONG:  \/\/ fall-through\n+        case T_FLOAT: \/\/ fall-through\n+        case T_DOUBLE: return Op_CompressV;\n+        default: fatal(\"COMPRESS: %s\", type2name(bt));\n+      }\n+      break;\n+    }\n+    case VECTOR_OP_MASK_COMPRESS: {\n+      switch (bt) {\n+        case T_BYTE:  \/\/ fall-through\n+        case T_SHORT: \/\/ fall-through\n+        case T_INT:   \/\/ fall-through\n+        case T_LONG:  \/\/ fall-through\n+        case T_FLOAT: \/\/ fall-through\n+        case T_DOUBLE: return Op_CompressM;\n+        default: fatal(\"MASK_COMPRESS: %s\", type2name(bt));\n+      }\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/prims\/vectorSupport.cpp","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -1740,0 +1740,2 @@\n+                        [\"compact\", \"__ sve_compact(z16, __ S, z16, p1);\",                \"compact\\tz16.s, p1, z16.s\"],\n+                        [\"compact\", \"__ sve_compact(z16, __ D, z16, p1);\",                \"compact\\tz16.d, p1, z16.d\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"}]}