{"files":[{"patch":"@@ -30,0 +30,6 @@\n+    test {\n+        requires 'org.openjdk.skara.test'\n+        requires 'org.junit.jupiter.api'\n+        opens 'org.openjdk.skara.cli' to 'org.junit.platform.commons'\n+    }\n+\n@@ -45,0 +51,3 @@\n+    implementation project(':process')\n+\n+    testImplementation project(':test')\n","filename":"cli\/build.gradle","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+    requires org.openjdk.skara.process;\n","filename":"cli\/src\/main\/java\/module-info.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -204,0 +204,1 @@\n+        commands.put(\"mlrules\", MLRules::main);\n","filename":"cli\/src\/main\/java\/org\/openjdk\/skara\/cli\/GitSkara.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,708 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package org.openjdk.skara.cli;\n+\n+import org.openjdk.skara.args.*;\n+import org.openjdk.skara.json.*;\n+import org.openjdk.skara.process.Process;\n+import org.openjdk.skara.vcs.*;\n+import org.openjdk.skara.vcs.openjdk.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.http.*;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.*;\n+import java.time.*;\n+import java.time.format.DateTimeFormatter;\n+import java.time.temporal.ChronoUnit;\n+import java.util.*;\n+import java.util.function.Function;\n+import java.util.logging.*;\n+import java.util.regex.Pattern;\n+import java.util.stream.*;\n+\n+public class MLRules {\n+    private final static Pattern rfrSubject = Pattern.compile(\"(?:^Subject: .*?)([78]\\\\d{6})\", Pattern.MULTILINE);\n+    private final static Pattern rfrSubjectOrIssue = Pattern.compile(\"(?:(?:^Subject: .*?)|(?:JDK-))([78]\\\\\\\\d{6})\", Pattern.MULTILINE);\n+    private final static Logger log = Logger.getLogger(\"org.openjdk.skara.mlrules\");\n+\n+    private static Pattern reviewPattern = rfrSubject;\n+    private static int daysOfHistory = 30;\n+    private static int filterDivider = 5;\n+    private static Pattern listFilterPattern = Pattern.compile(\".*\");\n+\n+    private static String archivePageName(ZonedDateTime month) {\n+        return DateTimeFormatter.ofPattern(\"yyyy-MMMM\", Locale.US).format(month);\n+    }\n+\n+    private static List<ZonedDateTime> monthRange(Duration maxAge) {\n+        var now = ZonedDateTime.now();\n+        var start = now.minus(maxAge);\n+        List<ZonedDateTime> ret = new ArrayList<>();\n+\n+        while (start.isBefore(now)) {\n+            ret.add(start);\n+            var next = start.plus(Duration.ofDays(1));\n+            while (start.getMonthValue() == next.getMonthValue()) {\n+                next = next.plus(Duration.ofDays(1));\n+            }\n+            start = next;\n+        }\n+        return ret;\n+    }\n+\n+    private static Set<String> archivePageNames() {\n+        return monthRange(Duration.of(daysOfHistory, ChronoUnit.DAYS)).stream()\n+                                                                      .map(MLRules::archivePageName)\n+                                                                      .collect(Collectors.toSet());\n+    }\n+\n+    private static Set<String> listSubjects(HttpClient client, String list) {\n+        var tmpFolder = Path.of(\"\/tmp\/mlrules\");\n+        try {\n+            Files.createDirectories(tmpFolder);\n+        } catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+        return archivePageNames().parallelStream()\n+                                 .map(name -> HttpRequest.newBuilder(URI.create(\"https:\/\/mail.openjdk.java.net\/pipermail\/\" + list + \"\/\" + name + \".txt\"))\n+                                                         .GET().build())\n+                                 .map(req -> {\n+                                     try {\n+                                         var cacheFile = tmpFolder.resolve(req.uri().getPath().replace(\"\/pipermail\/\", \"\").replace(\"\/\", \"-\"));\n+                                         if (Files.exists(cacheFile)) {\n+                                             log.fine(\"Reading \" + req.uri() + \" from cache\");\n+                                             return Files.readString(cacheFile, StandardCharsets.UTF_8);\n+                                         }\n+                                         System.out.println(\"Fetching \" + req.uri().toString());\n+                                         var body = client.send(req, HttpResponse.BodyHandlers.ofString());\n+                                         System.out.println(\"Done fetching \" + req.uri().toString());\n+                                         Files.writeString(cacheFile, body.body(), StandardCharsets.UTF_8);\n+                                         return body.body();\n+                                     } catch (IOException | InterruptedException e) {\n+                                         throw new RuntimeException(e);\n+                                     }\n+                                 })\n+                                 .flatMap(page -> reviewPattern.matcher(page).results().map(mr -> mr.group(1)))\n+                                 .collect(Collectors.toUnmodifiableSet());\n+    }\n+\n+    private static Map<String, Set<String>> listReviewedIssues(String... lists) {\n+        var ret = new HashMap<String, Set<String>>();\n+        var client = HttpClient.newBuilder()\n+                               .connectTimeout(Duration.ofSeconds(30))\n+                               .build();\n+\n+        var listIssues = Stream.of(lists).parallel()\n+                               .collect(Collectors.toMap(list -> list,\n+                                                         list -> listSubjects(client, list)));\n+\n+        for (var list : listIssues.entrySet()) {\n+            for (var issue : list.getValue()) {\n+                if (!ret.containsKey(issue)) {\n+                    ret.put(issue, new HashSet<>());\n+                }\n+                ret.get(issue).add(list.getKey());\n+            }\n+        }\n+        return ret;\n+    }\n+\n+    private static Map<CommitMetadata, Set<String>> issueLists(List<CommitMetadata> commits, Map<String, Set<String>> listReviewedIssues) {\n+        return commits.stream()\n+                      .map(commit -> new AbstractMap.SimpleEntry<>(commit, CommitMessageParsers.v1.parse(commit)))\n+                      .filter(entry -> !entry.getValue().issues().isEmpty())\n+                      .collect(Collectors.toMap(AbstractMap.SimpleEntry::getKey,\n+                                                entry -> entry.getValue().issues().stream()\n+                                                              .flatMap(issue -> listReviewedIssues.getOrDefault(issue.shortId(), Set.of()).stream())\n+                                                              .collect(Collectors.toSet()),\n+                                                (a, b) -> a,\n+                                                LinkedHashMap::new));\n+    }\n+\n+    private static class ProgressCounter {\n+        int progress;\n+        int progressLen;\n+    }\n+\n+    private static Set<String> commitChanges(ReadOnlyRepository repo, CommitMetadata commit) throws IOException {\n+        var process = Process.capture(\"git\", \"diff-tree\", \"--no-commit-id\", \"--name-only\", \"-r\", commit.hash().hex())\n+                             .workdir(repo.root());\n+        try (var p = process.execute()) {\n+            var res = p.check();\n+            return new HashSet<>(res.stdout());\n+        }\n+    }\n+\n+    private static Map<CommitMetadata, Set<String>> commitPaths(ReadOnlyRepository repo, Collection<CommitMetadata> commits) {\n+        var progress = new ProgressCounter();\n+\n+        return commits.parallelStream()\n+                      .map(commit -> {\n+                          try {\n+                              var changedFiles = commitChanges(repo, commit);\n+                              synchronized (progress) {\n+                                  progress.progress++;\n+                                  var progressStr = String.format(\"(%d\/%d)...\", progress.progress, commits.size());\n+                                  var removalStr = \"\\b\".repeat(progress.progressLen);\n+                                  progress.progressLen = progressStr.length();\n+                                  System.out.print(removalStr + progressStr);\n+                              }\n+                              var changedPaths = changedFiles.stream()\n+                                                             .map(Path::of)\n+                                                             .filter(Objects::nonNull)\n+                                                             .map(Path::toString)\n+                                                             .collect(Collectors.toSet());\n+                              return new AbstractMap.SimpleEntry<>(commit, changedPaths);\n+                          } catch (IOException e) {\n+                              throw new UncheckedIOException(e);\n+                          }\n+                      })\n+                      .collect(Collectors.toMap(AbstractMap.SimpleEntry::getKey,\n+                                                AbstractMap.SimpleEntry::getValue));\n+    }\n+\n+    private static Map<String, List<String>> pathLists(Map<CommitMetadata, Set<String>> commitLists, Map<CommitMetadata, Set<String>> commitPaths) {\n+        var ret = new HashMap<String, List<String>>();\n+\n+        for (var commitPath : commitPaths.entrySet()) {\n+            for (var path : commitPath.getValue()) {\n+                if (!ret.containsKey(path)) {\n+                    ret.put(path, new ArrayList<>());\n+                }\n+                var lists = commitLists.get(commitPath.getKey());\n+                if (lists != null) {\n+                    ret.get(path).addAll(lists);\n+                }\n+            }\n+        }\n+\n+        return ret;\n+    }\n+\n+    private static class TrieEntry {\n+        String key;\n+        TrieEntry parent;\n+        TreeMap<String, TrieEntry> children;\n+        List<String> values;\n+    }\n+\n+    private static TrieEntry mapToTrie(Map<String, List<String>> list) {\n+        var trie = new TrieEntry();\n+        trie.key = \"\";\n+        trie.parent = null;\n+        trie.children = new TreeMap<>();\n+\n+        \/\/ Create a prefix tree\n+        for (var entry : list.entrySet()) {\n+            var curRoot = trie;\n+            var pathElements = entry.getKey().split(\"\/\");\n+            for (var c : pathElements) {\n+                if (curRoot.children.containsKey(c)) {\n+                    curRoot = curRoot.children.get(c);\n+                } else {\n+                    var newRoot = new TrieEntry();\n+                    newRoot.key = c;\n+                    newRoot.parent = curRoot;\n+                    newRoot.children = new TreeMap<>();\n+                    curRoot.children.put(c, newRoot);\n+                    curRoot = newRoot;\n+                }\n+            }\n+            curRoot.values = entry.getValue();\n+        }\n+\n+        return trie;\n+    }\n+\n+    private static Map<String, List<String>> trieToMap(TrieEntry trie, String curPath) {\n+        var ret = new TreeMap<String, List<String>>();\n+\n+        for (var child : trie.children.entrySet()) {\n+            ret.putAll(trieToMap(child.getValue(), curPath + (curPath.length() > 0 ? \"\/\" : \"\") + child.getKey()));\n+        }\n+        if (trie.values != null) {\n+            ret.put(curPath, trie.values);\n+        }\n+\n+        return ret;\n+    }\n+\n+    private static Set<String> relevantLists(List<String> allLists) {\n+        if (allLists == null || allLists.isEmpty()) {\n+            return Set.of();\n+        }\n+\n+        var listWeights = allLists.stream()\n+                                  .collect(Collectors.groupingBy(Function.identity()))\n+                                  .entrySet().stream()\n+                                  .map(entry -> new AbstractMap.SimpleEntry<>(entry.getKey(), entry.getValue().size()))\n+                                  .sorted((e1, e2) -> e2.getValue() - e1.getValue())\n+                                  .collect(Collectors.toList());\n+        var listWeightsMax = listWeights.stream()\n+                                        .map(AbstractMap.SimpleEntry::getValue)\n+                                        .max(Comparator.comparingInt(entry -> entry))\n+                                        .orElseThrow();\n+        var threshold = listWeightsMax \/ filterDivider;\n+        return listWeights.stream()\n+                          .filter(entry -> entry.getValue() > threshold)\n+                          .map(AbstractMap.SimpleEntry::getKey)\n+                          .collect(Collectors.toSet());\n+    }\n+\n+    private static boolean listsMatch(List<String> list1, List<String> list2) {\n+        if (list1 == null || list2 == null) {\n+            return list1 == list2;\n+        }\n+        if (list1.isEmpty() || list2.isEmpty()) {\n+            return list1.isEmpty() == list2.isEmpty();\n+        }\n+\n+        var relevantLists1 = relevantLists(list1);\n+        var relevantLists2 = relevantLists(list2);\n+\n+        return Objects.equals(relevantLists1, relevantLists2);\n+    }\n+\n+    private static TrieEntry pruneEntry(TrieEntry root) {\n+        var newChildren = new TreeMap<String, TrieEntry>();\n+        if (root.children.isEmpty()) {\n+            return root;\n+        }\n+\n+        for (var child : root.children.entrySet()) {\n+            newChildren.put(child.getKey(), pruneEntry(child.getValue()));\n+            root.children = newChildren;\n+        }\n+        var firstChild = root.children.firstEntry().getValue();\n+        var canBePruned = true;\n+        for (var child : root.children.entrySet()) {\n+            if (!child.getValue().children.isEmpty()) {\n+                canBePruned = false;\n+                break;\n+            }\n+            if (!listsMatch(child.getValue().values, firstChild.values)) {\n+                canBePruned = false;\n+                break;\n+            }\n+        }\n+        if (canBePruned) {\n+            if (root.values == null || listsMatch(root.values, firstChild.values)) {\n+                root.children.clear();\n+                root.values = firstChild.values;\n+            }\n+        }\n+\n+        return root;\n+    }\n+\n+    static Map<String, List<String>> stripDuplicatePrefixes(Map<String, List<String>> fullList) {\n+        \/\/ Create a prefix tree\n+        var trie = mapToTrie(fullList);\n+\n+        \/\/ Prune it\n+        var pruned = pruneEntry(trie);\n+\n+        \/\/ Restore the map from the tree\n+        return trieToMap(pruned, \"\");\n+    }\n+\n+    static Map<String, Set<String>> pathListsToListPaths(Map<String, List<String>> pathLists) {\n+        var ret = new TreeMap<String, Set<String>>();\n+\n+        for (var entry : pathLists.entrySet()) {\n+            var relevantLists = relevantLists(entry.getValue());\n+            for (var list : relevantLists) {\n+                if (!ret.containsKey(list)) {\n+                    ret.put(list, new TreeSet<>());\n+                }\n+                ret.get(list).add(entry.getKey());\n+            }\n+        }\n+\n+        return ret;\n+    }\n+\n+    static class RuleParser {\n+        private final Map<String, Set<Pattern>> matchers;\n+        private final Map<String, Set<String>> groups;\n+\n+        RuleParser(String rulesFile) throws IOException {\n+            System.out.println(\"Reading rules file...\");\n+            var rules = JSON.parse(Files.readString(Path.of(rulesFile), StandardCharsets.UTF_8));\n+\n+            matchers = rules.get(\"matchers\").fields().stream()\n+                            .collect(Collectors.toMap(JSONObject.Field::name,\n+                                                      field -> field.value().stream()\n+                                                                    .map(JSONValue::asString)\n+                                                                    .map(s -> Pattern.compile(\"^\" + s, Pattern.CASE_INSENSITIVE))\n+                                                                    .collect(Collectors.toSet())));\n+            groups = rules.get(\"groups\").fields().stream()\n+                          .collect(Collectors.toMap(JSONObject.Field::name,\n+                                                    field -> field.value().stream()\n+                                                                  .map(JSONValue::asString)\n+                                                                  .collect(Collectors.toSet())));\n+        }\n+\n+        Map<String, String> suggestedLists(String path) {\n+            var ret = new HashMap<String, String>();\n+            for (var rule : matchers.entrySet()) {\n+                for (var rulePath : rule.getValue()) {\n+                    var ruleMatcher = rulePath.matcher(path);\n+                    if (ruleMatcher.find()) {\n+                        ret.put(rule.getKey(), rulePath.toString());\n+                        break;\n+                    }\n+                }\n+            }\n+\n+            return ret;\n+        }\n+\n+        TreeSet<String> groupLists(Set<String> ungrouped) {\n+            var ret = new TreeSet<>(ungrouped);\n+            \/\/ If the current labels matches at least two members of a group, use the group instead\n+            for (var group : groups.entrySet()) {\n+                var count = 0;\n+                for (var groupEntry : group.getValue()) {\n+                    if (ret.contains(groupEntry)) {\n+                        count++;\n+                        if (count == 2) {\n+                            ret.add(group.getKey());\n+                            ret.removeAll(group.getValue());\n+                            break;\n+                        }\n+                    }\n+                }\n+            }\n+            return ret;\n+        }\n+    }\n+\n+    private static void verifyInput(String rulesFile, Map<CommitMetadata, Set<String>> issueLists, Map<CommitMetadata, Set<String>> commitPaths) throws IOException {\n+        var ruleParser = new RuleParser(rulesFile);\n+\n+        System.out.println(\"Verifying commits...\");\n+        var matching = 0;\n+        var mismatch = 0;\n+\n+        for (var issueList : issueLists.entrySet()) {\n+            if (issueList.getValue().isEmpty()) {\n+                \/\/ Ignore commits with unknown review list\n+                continue;\n+            }\n+\n+            var suggestedLists = new TreeSet<String>();\n+            var pathMismatch = new HashMap<String, Set<String>>();\n+            for (var path : commitPaths.get(issueList.getKey())) {\n+                var suggestedForPath = ruleParser.suggestedLists(path);\n+\n+                for (var suggested : suggestedForPath.entrySet()) {\n+                    if (!issueList.getValue().contains(suggested.getKey())) {\n+                        if (!pathMismatch.containsKey(path)) {\n+                            pathMismatch.put(path, new HashSet<>());\n+                        }\n+                        pathMismatch.get(path).add(suggested.getKey() + \": \" + suggested.getValue());\n+                    }\n+                }\n+                suggestedLists.addAll(suggestedForPath.keySet());\n+            }\n+\n+            var matchesExpected = issueList.getValue().stream()\n+                                           .anyMatch(l -> listFilterPattern.matcher(l).find());\n+            var matchesSuggested = suggestedLists.stream()\n+                                                 .anyMatch(l -> listFilterPattern.matcher(l).find());\n+            if (!matchesExpected && !matchesSuggested) {\n+                continue;\n+            }\n+\n+            \/\/ Adjust suggestions according to grouping rules\n+            var suggestedListsGrouped = ruleParser.groupLists(suggestedLists);\n+\n+            \/\/ Also see what the expected would look like with grouping\n+            var expectedGrouped = ruleParser.groupLists(issueList.getValue());\n+\n+            if (suggestedListsGrouped.equals(issueList.getValue())) {\n+                System.out.println(\"✅ \" + suggestedListsGrouped + \" \" + issueList.getKey().hash().abbreviate() + \": \" + issueList.getKey().message().get(0));\n+                matching++;\n+            } else {\n+                if (suggestedListsGrouped.equals(expectedGrouped)) {\n+                    System.out.println(\"✅ \" + issueList.getValue() + \" -> \" + suggestedListsGrouped + \" \" + issueList.getKey().hash().abbreviate() + \": \" + issueList.getKey().message().get(0));\n+                    matching++;\n+                } else {\n+                    var missing = issueList.getValue().stream()\n+                                           .filter(value -> !suggestedLists.contains(value))\n+                                           .collect(Collectors.toSet());\n+                    var extra = suggestedLists.stream()\n+                                              .filter(value -> !issueList.getValue().contains(value))\n+                                              .collect(Collectors.toSet());\n+                    System.out.println(\"❌ \" + issueList.getValue() + \" \" + issueList.getKey().hash().abbreviate() + \": \" + issueList.getKey().message().get(0));\n+                    if (suggestedListsGrouped.equals(suggestedLists)) {\n+                        System.out.println(\"    Suggested lists: \" + suggestedListsGrouped);\n+                    } else {\n+                        System.out.println(\"    Suggested lists: \" + suggestedListsGrouped + \" (ungrouped: \" + suggestedLists + \")\");\n+                    }\n+\n+                    \/\/System.out.println(\"Actual lists   : \" + issueList.getValue());\n+                    \/\/commitPaths.get(issueList.getKey()).forEach(s -> System.out.println(\"  \" + s));\n+                    if (!extra.isEmpty()) {\n+                        System.out.println(\"    Rules matching unmentioned lists \" + extra + \":\");\n+                        for (var path : pathMismatch.entrySet()) {\n+                            System.out.println(\"      \" + path.getKey() + \" - \" + path.getValue());\n+                        }\n+                    }\n+                    if (!missing.isEmpty()) {\n+                        var unmatched = commitPaths.get(issueList.getKey()).stream()\n+                                                   .filter(entry -> !pathMismatch.containsKey(entry))\n+                                                   .collect(Collectors.toList());\n+                        if (!unmatched.isEmpty()) {\n+                            System.out.println(\"    Files not matching any rule in \" + missing + \":\");\n+                            unmatched.forEach(s -> System.out.println(\"      \" + s));\n+                        }\n+                    }\n+                    mismatch++;\n+                }\n+            }\n+        }\n+\n+        System.out.println(\"Matches: \" + matching + \" - mismatches: \" + mismatch);\n+    }\n+\n+    public static void main(String[] args) throws IOException {\n+        var flags = List.of(\n+                Option.shortcut(\"d\")\n+                      .fullname(\"days\")\n+                      .describe(\"DAYS\")\n+                      .helptext(\"Number of days to look back\")\n+                      .optional(),\n+                Option.shortcut(\"f\")\n+                      .fullname(\"filter\")\n+                      .describe(\"DIVIDER\")\n+                      .helptext(\"Divider for filter threshold\")\n+                      .optional(),\n+                Option.shortcut(\"o\")\n+                      .fullname(\"output\")\n+                      .describe(\"FILE\")\n+                      .helptext(\"Name of file to write output to\")\n+                      .optional(),\n+                Option.shortcut(\"v\")\n+                      .fullname(\"verify\")\n+                      .describe(\"FILE\")\n+                      .helptext(\"Name of file to verify against\")\n+                      .optional(),\n+                Option.shortcut(\"l\")\n+                      .fullname(\"lists\")\n+                      .describe(\"PATTERN\")\n+                      .helptext(\"Regular expression matching mailing lists to include when verifying (default all known)\")\n+                      .optional(),\n+                Switch.shortcut(\"\")\n+                      .fullname(\"verbose\")\n+                      .helptext(\"Turn on verbose output\")\n+                      .optional(),\n+                Switch.shortcut(\"\")\n+                      .fullname(\"debug\")\n+                      .helptext(\"Turn on debugging output\")\n+                      .optional(),\n+                Switch.shortcut(\"\")\n+                      .fullname(\"relaxed\")\n+                      .helptext(\"Use more relaxed matching when searching for reviews\")\n+                      .optional()\n+        );\n+\n+        var inputs = List.of(\n+                Input.position(0)\n+                     .describe(\"repository root or files\")\n+                     .trailing()\n+                     .required()\n+        );\n+        var parser = new ArgumentParser(\"mlrules\", flags, inputs);\n+        var arguments = parser.parse(args);\n+\n+        if (arguments.contains(\"verbose\") || arguments.contains(\"debug\")) {\n+            var level = arguments.contains(\"debug\") ? Level.FINER : Level.FINE;\n+            Logging.setup(level);\n+        }\n+        if (arguments.contains(\"days\")) {\n+            daysOfHistory = arguments.get(\"days\").asInt();\n+        }\n+        if (arguments.contains(\"filter\")) {\n+            filterDivider = arguments.get(\"filter\").asInt();\n+        }\n+        if (arguments.contains(\"relaxed\")) {\n+            reviewPattern = rfrSubjectOrIssue;\n+        }\n+        if (arguments.contains(\"lists\")) {\n+            listFilterPattern = Pattern.compile(arguments.get(\"lists\").asString());\n+        }\n+\n+        var parsedLists = List.of(\"2d-dev\",\n+                                  \"awt-dev\",\n+                                  \"build-dev\",\n+                                  \"compiler-dev\",\n+                                  \"core-libs-dev\",\n+                                  \"hotspot-compiler-dev\",\n+                                  \"hotspot-gc-dev\",\n+                                  \"hotspot-jfr-dev\",\n+                                  \"hotspot-runtime-dev\",\n+                                  \"i18n-dev\",\n+                                  \"javadoc-dev\",\n+                                  \"jmx-dev\",\n+                                  \"net-dev\",\n+                                  \"nio-dev\",\n+                                  \"security-dev\",\n+                                  \"serviceability-dev\",\n+                                  \"sound-dev\",\n+                                  \"swing-dev\");\n+        if (arguments.contains(\"verify\")) {\n+            parsedLists = Stream.concat(parsedLists.stream(), List.of(\"hotspot-dev\", \"jdk-dev\").stream())\n+                                .collect(Collectors.toList());\n+        }\n+\n+        var repoPath = Path.of(arguments.at(0).asString()).toRealPath();\n+        if (repoPath.toFile().isFile()) {\n+            repoPath = repoPath.getParent();\n+        }\n+        var repo = ReadOnlyRepository.get(repoPath).orElseThrow();\n+        var repoRoot = repo.root();\n+\n+        if (arguments.inputs().size() == 1 && repoPath.equals(repoRoot)) {\n+            System.out.println(\"Fetching commits metadata...\");\n+            var cutoff = ZonedDateTime.now().minus(Duration.ofDays(daysOfHistory));\n+            var commits = repo.commitMetadata().stream()\n+                              .filter(commit -> commit.committed().isAfter(cutoff))\n+                              .collect(Collectors.toList());\n+\n+            System.out.println(\"Done fetching commits metadata: \" + commits.size() + \" commits remaining after date filtering\");\n+\n+            var listReviews = listReviewedIssues(parsedLists.toArray(new String[0]));\n+            System.out.println(\"Done fetching mailing list archive pages\");\n+\n+            var issueLists = issueLists(commits, listReviews);\n+            var noReviewCount = issueLists.entrySet().stream()\n+                                          .filter(entry -> entry.getValue().isEmpty())\n+                                          .count();\n+            System.out.println(\"Done mapping commit issues to lists: \" + noReviewCount + \" commits have no matching review\");\n+\n+            for (var issue : issueLists.entrySet()) {\n+                if (!issue.getValue().isEmpty()) {\n+                    log.fine(issue.getKey().hash().abbreviate() + \": \" + issue.getKey().message().get(0) + \": \" + issue.getValue());\n+                }\n+            }\n+\n+            System.out.print(\"Fetching commit changes: \");\n+            var commitPaths = commitPaths(repo, issueLists.keySet());\n+            for (var commitPath : commitPaths.entrySet()) {\n+                log.fine(commitPath.getKey().hash().abbreviate() + \": \" + commitPath.getValue());\n+            }\n+            System.out.println(\" done\");\n+\n+            System.out.println(\"Fetching list of existing files...\");\n+            var currentPaths = repo.files(repo.head(), List.of()).stream()\n+                                   .map(FileEntry::path)\n+                                   .filter(Objects::nonNull)\n+                                   .map(Path::toString)\n+                                   .collect(Collectors.toSet());\n+\n+\n+            var existingCommitPaths = commitPaths.entrySet().stream()\n+                                                 .collect(Collectors.toMap(Map.Entry::getKey,\n+                                                                           entry -> entry.getValue().stream()\n+                                                                                         .filter(currentPaths::contains)\n+                                                                                         .collect(Collectors.toSet())));\n+\n+            if (arguments.contains(\"verify\")) {\n+                verifyInput(arguments.get(\"verify\").asString(), issueLists, existingCommitPaths);\n+                return;\n+            }\n+\n+            var pathLists = pathLists(issueLists, existingCommitPaths);\n+            var unknownPaths = currentPaths.stream()\n+                                           .filter(p -> !pathLists.containsKey(p))\n+                                           .collect(Collectors.toCollection(TreeSet::new));\n+\n+            var uniquePathLists = stripDuplicatePrefixes(pathLists);\n+            for (var pathList : uniquePathLists.entrySet()) {\n+                var relevantLists = relevantLists(pathList.getValue());\n+                log.fine(pathList.getKey() + \": \" + relevantLists);\n+            }\n+\n+            var listPaths = pathListsToListPaths(uniquePathLists);\n+            listPaths.put(\"unknown\", unknownPaths);\n+\n+            var finalResult = \"{\\n\" + listPaths.entrySet().stream()\n+                                               .map(entry -> \"    \\\"\" + entry.getKey() + \"\\\": [\\n\" +\n+                                                       entry.getValue().stream()\n+                                                            .map(path -> \"        \\\"\" + path + \"\\\"\")\n+                                                            .collect(Collectors.joining(\",\\n\")) +\n+                                                       \"\\n    ]\")\n+                                               .collect(Collectors.joining(\",\\n\")) +\n+                    \"\\n}\";\n+            if (arguments.contains(\"output\")) {\n+                System.out.println(\"Writing final output to \" + arguments.get(\"output\").asString());\n+                Files.writeString(Path.of(arguments.get(\"output\").asString()), finalResult, StandardCharsets.UTF_8);\n+            } else {\n+                System.out.println(finalResult);\n+            }\n+        } else if (arguments.inputs().size() >= 1 && arguments.contains(\"verify\")) {\n+            var requestedFiles = new HashSet<String>();\n+            for (var input : arguments.inputs()) {\n+                var path = Path.of(input.asString()).toRealPath();\n+                if (path.toFile().isFile()) {\n+                    requestedFiles.add(repoRoot.relativize(path).toString());\n+                } else {\n+                    Files.walk(path)\n+                         .filter(p -> p.toFile().isFile())\n+                         .map(p -> repoRoot.relativize(p).toString())\n+                         .forEach(requestedFiles::add);\n+                }\n+            }\n+\n+            var ruleParser = new RuleParser(arguments.get(\"verify\").asString());\n+            var pathLists = requestedFiles.stream()\n+                                          .collect(Collectors.toMap(Function.identity(),\n+                                                                    p -> (List<String>)new ArrayList<>(ruleParser.suggestedLists(p).keySet())));\n+            var uniquePathLists = stripDuplicatePrefixes(pathLists);\n+            var suggestedLists = new TreeSet<String>();\n+            for (var uniquePath : uniquePathLists.entrySet()) {\n+                System.out.println(uniquePath.getKey() + \": \" + uniquePath.getValue());\n+                suggestedLists.addAll(uniquePath.getValue());\n+            }\n+            System.out.println();\n+            System.out.println(\"Combined list suggestion: \" + suggestedLists);\n+            System.out.println(\"Final list suggestion is: \" + ruleParser.groupLists(suggestedLists));\n+        } else {\n+            System.out.println(\"To generate a rules list from parsing review archives:\");\n+            System.out.println(\"  git skara mlrules <repository root> [--filter X] [--days D] [--output FILE]\");\n+            System.out.println();\n+            System.out.println(\"To verify a rules list against historical commits and reviews:\");\n+            System.out.println(\"  git skara mlrules <repository root> [--verify FILE] [--days D]\");\n+            System.out.println();\n+            System.out.println(\"To verify a rules list against a given list of files\/directories in a repository:\");\n+            System.out.println(\"  git skara mlrules --verify FILE <file1\/dir1> [<file2\/dir2> <file3\/dir3>...]\");\n+            System.out.println();\n+            System.out.println(\"For the full list of options:\");\n+            System.out.println(\"  git skara mlrules --help\");\n+        }\n+    }\n+}\n","filename":"cli\/src\/main\/java\/org\/openjdk\/skara\/cli\/MLRules.java","additions":708,"deletions":0,"binary":false,"changes":708,"status":"added"},{"patch":"@@ -0,0 +1,91 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package org.openjdk.skara.cli;\n+\n+import org.junit.jupiter.api.Test;\n+\n+import java.util.*;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+public class TestMLRules {\n+    @Test\n+    void collapseEquals() {\n+        assertEquals(Map.of(\"\", List.of(\"v1\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k1\", List.of(\"v1\"))));\n+    }\n+\n+    @Test\n+    void collapseSameList() {\n+        assertEquals(Map.of(\"\", List.of(\"v1\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k1a\", List.of(\"v1\"),\n+                                                           \"k1b\", List.of(\"v1\"))));\n+    }\n+\n+    @Test\n+    void collapseDifferentList() {\n+        assertEquals(Map.of(\"k1a\", List.of(\"v1\"),\n+                            \"k1b\", List.of(\"v2\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k1a\", List.of(\"v1\"),\n+                                                           \"k1b\", List.of(\"v2\"))));\n+    }\n+\n+    @Test\n+    void collapseMultiple() {\n+        assertEquals(Map.of(\"\", List.of(\"v1\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k1a\", List.of(\"v1\"),\n+                                                           \"k1b\", List.of(\"v1\"),\n+                                                           \"k2bb\", List.of(\"v1\"))));\n+\n+    }\n+\n+    @Test\n+    void collapseMultiple2() {\n+        assertEquals(Map.of(\"\", List.of(\"v1\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k1a\", List.of(\"v1\"),\n+                                                           \"k1b\", List.of(\"v1\"),\n+                                                           \"k2bb\", List.of(\"v1\"),\n+                                                           \"k4\", List.of(\"v1\"))));\n+\n+    }\n+\n+    @Test\n+    void collapseSingle() {\n+        assertEquals(Map.of(\"k1\/a\", List.of(\"v1\"),\n+                            \"k1\/b\", List.of(\"v2\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k1\/a\/a\", List.of(\"v1\"),\n+                                                           \"k1\/b\/b\", List.of(\"v2\"))));\n+\n+    }\n+\n+    @Test\n+    void collapseSingle2() {\n+        assertEquals(Map.of(\"k\/1\", List.of(\"v1\"),\n+                            \"k\/2a\", List.of(\"v2\")),\n+                     MLRules.stripDuplicatePrefixes(Map.of(\"k\/1\/aa\", List.of(\"v1\"),\n+                                                           \"k\/1\/bb\", List.of(\"v1\"),\n+                                                           \"k\/2a\", List.of(\"v2\"))));\n+\n+    }\n+\n+}\n","filename":"cli\/src\/test\/java\/org\/openjdk\/skara\/cli\/TestMLRules.java","additions":91,"deletions":0,"binary":false,"changes":91,"status":"added"}]}