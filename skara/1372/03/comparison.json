{"files":[{"patch":"@@ -29,0 +29,1 @@\n+        requires 'org.openjdk.skara.forge'\n@@ -45,0 +46,1 @@\n+    testImplementation project(':forge')\n","filename":"issuetracker\/build.gradle","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -0,0 +1,164 @@\n+package org.openjdk.skara.issuetracker;\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.time.ZonedDateTime;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Logger;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class IssuePoller {\n+\n+    private static final Logger log = Logger.getLogger(IssuePoller.class.getName());\n+\n+    private final IssueProject issueProject;\n+    private final Duration timeStampQueryPrecision;\n+    private final ZonedDateTime initialUpdatedAt;\n+    private final Map<String, Issue> retryMap = new HashMap<>();\n+\n+    private record QueryResult(Map<String, Issue> issues, ZonedDateTime maxUpdatedAt,\n+                               Instant afterQuery, List<Issue> result) {}\n+    private QueryResult current;\n+    private QueryResult prev;\n+\n+    \/**\n+     * When enough time has passed since the last time we actually returned\n+     * results, it's possible to pad the updatedAt query parameter to avoid\n+     * receiving the same issues over and over, only to then filter them out.\n+     *\/\n+    private boolean paddingPossible = false;\n+\n+    \/**\n+     * @param issueProject The IssueProject to poll from\n+     * @param startUpPadding The amount of historic time to include in the\n+     *                       very first query\n+     *\/\n+    public IssuePoller(IssueProject issueProject, Duration startUpPadding) {\n+        this.issueProject = issueProject;\n+        this.timeStampQueryPrecision = issueProject.issueTracker().timeStampQueryPrecision();\n+        this.initialUpdatedAt = ZonedDateTime.now().minus(startUpPadding);\n+    }\n+\n+    public List<Issue> updatedIssues() {\n+        var beforeQuery = Instant.now();\n+        List<Issue> issues = queryIssues();\n+        var afterQuery = Instant.now();\n+\n+        \/\/ Convert the query result into a map\n+        var issuesMap = issues.stream().collect(Collectors.toMap(Issue::id, i -> i));\n+\n+        \/\/ Find the max updatedAt value in the result set. Fall back on the previous\n+        \/\/ value (happens if no results were returned), or the initialUpdatedAt (if\n+        \/\/ no results have been found at all so far).\n+        var maxUpdatedAt = issues.stream()\n+                .map(Issue::updatedAt)\n+                .max(Comparator.naturalOrder())\n+                .orElseGet(() -> prev != null ? prev.maxUpdatedAt : initialUpdatedAt);\n+\n+        \/\/ Filter the results\n+        var filtered = issues.stream()\n+                .filter(this::isUpdated)\n+                .toList();\n+\n+        var withRetries = addRetries(filtered);\n+\n+        \/\/ If nothing will be returned, update the paddingPossible state if enough time\n+        \/\/ has passed since last we found something.\n+        if (withRetries.isEmpty()) {\n+            if (prev != null && prev.afterQuery.isBefore(beforeQuery.minus(timeStampQueryPrecision))) {\n+                paddingPossible = true;\n+            }\n+        } else {\n+            paddingPossible = false;\n+        }\n+\n+        \/\/ Save the state of the current query results\n+        current = new QueryResult(issuesMap, maxUpdatedAt, afterQuery, withRetries);\n+\n+        log.info(\"Found \" + withRetries.size() + \" updated issues for \" + issueProject.name());\n+        return withRetries;\n+    }\n+\n+    \/**\n+     * After calling getUpdatedIssues(), this method must be called to acknowledge\n+     * that all the issues returned have been handled. If not, the previous results will be\n+     * included in the next call to getUpdatedIssues() again.\n+     *\/\n+    public synchronized void lastBatchHandled() {\n+        if (current != null) {\n+            prev = current;\n+            current = null;\n+            \/\/ Remove any returned PRs from the retry\/quarantine sets\n+            prev.result.forEach(pr -> retryMap.remove(pr.id()));\n+        }\n+    }\n+\n+    public synchronized void retryIssue(Issue issue) {\n+        retryMap.put(issue.id(), issue);\n+    }\n+\n+    private List<Issue> queryIssues() {\n+        ZonedDateTime queryAfter;\n+        if (prev == null || prev.maxUpdatedAt == null) {\n+            queryAfter = initialUpdatedAt;\n+        } else if (paddingPossible) {\n+            \/\/ If we haven't found any actual results for long enough,\n+            \/\/ we can pad on the query precision to avoid fetching the\n+            \/\/ last returned issue over and over.\n+            queryAfter = prev.maxUpdatedAt.plus(timeStampQueryPrecision);\n+        } else {\n+            queryAfter = prev.maxUpdatedAt;\n+        }\n+        log.fine(\"Fetching issues updated after \" + queryAfter);\n+        return queryIssues(issueProject, queryAfter);\n+    }\n+\n+    \/**\n+     * Subclasses can override this method to query for specific kinds of issues.\n+     * @param issueProject IssueProject to run query on\n+     * @param updatedAfter Timestamp for updatedAt query\n+     *\/\n+    protected List<Issue> queryIssues(IssueProject issueProject, ZonedDateTime updatedAfter) {\n+        return issueProject.issues(updatedAfter);\n+    }\n+\n+    \/**\n+     * Evaluates if an issue has been updated since the previous query result.\n+     *\/\n+    private boolean isUpdated(Issue issue) {\n+        if (prev == null) {\n+            return true;\n+        }\n+        var issuePrev = prev.issues.get(issue.id());\n+        if (issuePrev == null || issue.updatedAt().isAfter(issuePrev.updatedAt())) {\n+            return true;\n+        }\n+        if (!issuePrev.equals(issue)) {\n+            return true;\n+        }\n+        return false;\n+    }\n+\n+    \/**\n+     * Returns a list of all prs with retries added.\n+     *\/\n+    private synchronized List<Issue> addRetries(List<Issue> issues) {\n+        if (retryMap.isEmpty()) {\n+            return issues;\n+        } else {\n+            \/\/ Find the retries not already present in the issues list\n+            var retries = retryMap.values().stream()\n+                    .filter(retryIssue -> issues.stream().noneMatch(issue -> issue.id().equals(retryIssue.id())))\n+                    .toList();\n+            if (retries.isEmpty()) {\n+                return issues;\n+            } else {\n+                return Stream.concat(issues.stream(), retries.stream()).toList();\n+            }\n+        }\n+    }\n+}\n","filename":"issuetracker\/src\/main\/java\/org\/openjdk\/skara\/issuetracker\/IssuePoller.java","additions":164,"deletions":0,"binary":false,"changes":164,"status":"added"},{"patch":"@@ -25,0 +25,1 @@\n+import java.time.Duration;\n@@ -35,0 +36,9 @@\n+    \/**\n+     * The precision at which timeStamp based queries are supported for this\n+     * IssueTracker. If this is >0, knowing this can be used to avoid\n+     * re-querying for the same Issues over and over.\n+     *\/\n+    default Duration timeStampQueryPrecision() {\n+        return Duration.ZERO;\n+    }\n+\n","filename":"issuetracker\/src\/main\/java\/org\/openjdk\/skara\/issuetracker\/IssueTracker.java","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+import java.time.Duration;\n@@ -170,0 +171,8 @@\n+\n+    \/**\n+     * Jira can only query on timestamps with minute precision.\n+     *\/\n+    @Override\n+    public Duration timeStampQueryPrecision() {\n+        return Duration.ofMinutes(1);\n+    }\n","filename":"issuetracker\/src\/main\/java\/org\/openjdk\/skara\/issuetracker\/jira\/JiraHost.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -593,0 +593,21 @@\n+\n+    \/**\n+     * Equality for a JiraIssue is based on the data snapshot retrieved when\n+     * the instance was created.\n+     *\/\n+    @Override\n+    public boolean equals(Object o) {\n+        if (this == o) {\n+            return true;\n+        }\n+        if (o == null || getClass() != o.getClass()) {\n+            return false;\n+        }\n+        JiraIssue jiraIssue = (JiraIssue) o;\n+        return Objects.equals(json, jiraIssue.json);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return Objects.hash(json);\n+    }\n","filename":"issuetracker\/src\/main\/java\/org\/openjdk\/skara\/issuetracker\/jira\/JiraIssue.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -0,0 +1,179 @@\n+package org.openjdk.skara.issuetracker;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.ZonedDateTime;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.openjdk.skara.test.HostCredentials;\n+import org.openjdk.skara.test.TestHost;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+public class IssuePollerTests {\n+\n+    @Test\n+    void simple(TestInfo testInfo) throws IOException {\n+        try (var credentials = new HostCredentials(testInfo)) {\n+            var issueProject = credentials.getIssueProject();\n+            var issuePoller = new IssuePoller(issueProject, Duration.ZERO);\n+\n+            \/\/ Poll with no Issues in the project\n+            var issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+\n+            \/\/ Poll again without marking as handled\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Create issue and poll for it\n+            var issue1 = credentials.createIssue(issueProject, \"Issue 1\");\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+\n+            \/\/ Poll again without marking as handled\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Poll again\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Touch issue and poll again\n+            issue1.setBody(\"foo\");\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+\n+            \/\/ Poll again without marking as handled\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Poll again\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+        }\n+    }\n+\n+    @Test\n+    void startUpPadding(TestInfo testInfo) throws IOException {\n+        try (var credentials = new HostCredentials(testInfo)) {\n+            var issueProject = credentials.getIssueProject();\n+            var issuePoller = new IssuePoller(issueProject, Duration.ofDays(2));\n+\n+            \/\/ Create two issues, one with updatedAt before and one after the startup\n+            \/\/ padding limit.\n+            var issue1 = credentials.createIssue(issueProject, \"Issue 1\");\n+            issue1.store().setLastUpdate(ZonedDateTime.now().minus(Duration.ofDays(1)));\n+            var issue2 = credentials.createIssue(issueProject, \"Issue 2\");\n+            issue2.store().setLastUpdate(ZonedDateTime.now().minus(Duration.ofDays(3)));\n+\n+            \/\/ First poll should find issue1 but not issue2.\n+            var issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            assertEquals(issue1.id(), issues.get(0).id());\n+        }\n+    }\n+\n+    @Test\n+    void timeStampPadding(TestInfo testInfo) throws IOException, InterruptedException {\n+        try (var credentials = new HostCredentials(testInfo)) {\n+            var issueProject = credentials.getIssueProject();\n+            var testHost = (TestHost) issueProject.issueTracker();\n+            testHost.setTimeStampQueryPrecision(Duration.ofNanos(2));\n+            var issuePoller = new IssuePoller(issueProject, Duration.ZERO);\n+\n+            \/\/ Create issue and poll for it\n+            var issue1 = credentials.createIssue(issueProject, \"Issue 1\");\n+            var issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Poll again\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Touch issue and poll again\n+            issue1.setBody(\"foo\");\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Poll again\n+            \/\/ Sleep to make it more likely that this and the previous calls to\n+            \/\/ updatedIssues are far enough apart to trigger padding.\n+            Thread.sleep(1);\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ With the extremely short precision of 2 nanos, enough time should now\n+            \/\/ have passed between the two previous polls so that the poller is now\n+            \/\/ padding the fetch query with the precision duration.\n+            \/\/ We can prove that by updating the updatedAt of issue1 to something after\n+            \/\/ the last updatedAt but before last updatedAt + precision. If the fetch\n+            \/\/ call would return it, then isUpdated should also return true, and\n+            \/\/ updatedIssues() would then return issue1.\n+            var lastFoundUpdatedAt = issue1.store().lastUpdate();\n+            issue1.store().setLastUpdate(lastFoundUpdatedAt.plus(Duration.ofNanos(1)));\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Update to something just after the lastUpdate + precision and poll\n+            \/\/ again. Now it should be returned.\n+            issue1.store().setLastUpdate(lastFoundUpdatedAt.plus(Duration.ofNanos(3)));\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+        }\n+    }\n+\n+    @Test\n+    void retries(TestInfo testInfo) throws IOException {\n+        try (var credentials = new HostCredentials(testInfo)) {\n+            var issueProject = credentials.getIssueProject();\n+            var issuePoller = new IssuePoller(issueProject, Duration.ZERO);\n+\n+            \/\/ Create issue\n+            var issue1 = credentials.createIssue(issueProject, \"Issue 1\");\n+            var issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Create another PR and mark the first PR for retry\n+            var issue2 = credentials.createIssue(issueProject, \"Issue 2\");\n+            issuePoller.retryIssue(issue1);\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(2, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Poll again, nothing should not be returned\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(0, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Just mark a PR for retry\n+            issuePoller.retryIssue(issue2);\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+\n+            \/\/ Call again without calling .lastBatchHandled, the retry should be included again\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+\n+            \/\/ Update PR and add it as retry, only one copy should be returned\n+            issue1.addLabel(\"foo\");\n+            issuePoller.retryIssue(issue1);\n+            issues = issuePoller.updatedIssues();\n+            assertEquals(1, issues.size());\n+            issuePoller.lastBatchHandled();\n+        }\n+    }\n+}\n","filename":"issuetracker\/src\/test\/java\/org\/openjdk\/skara\/issuetracker\/IssuePollerTests.java","additions":179,"deletions":0,"binary":false,"changes":179,"status":"added"},{"patch":"@@ -25,0 +25,1 @@\n+import java.time.Duration;\n@@ -54,0 +55,4 @@\n+    \/\/ Setting this field doesn't change the behavior of the TestHost, but it changes\n+    \/\/ what the associated method returns, which triggers different code paths in\n+    \/\/ dependent test code.\n+    private Duration timeStampQueryPrecision = Duration.ZERO;\n@@ -248,1 +253,3 @@\n-                          .filter(i -> i.updatedAt().isAfter(updatedAfter))\n+                          \/\/ Accept updatedAfter == updatedAt to make tests more\n+                          \/\/ resilient on hardware with lower resolution system clocks.\n+                          .filter(i -> !i.updatedAt().isBefore(updatedAfter))\n@@ -269,0 +276,9 @@\n+\n+    public void setTimeStampQueryPrecision(Duration timeStampQueryPrecision) {\n+        this.timeStampQueryPrecision = timeStampQueryPrecision;\n+    }\n+\n+    @Override\n+    public Duration timeStampQueryPrecision() {\n+        return timeStampQueryPrecision;\n+    }\n","filename":"test\/src\/main\/java\/org\/openjdk\/skara\/test\/TestHost.java","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"}]}