{"files":[{"patch":"@@ -3041,0 +3041,54 @@\n+void Assembler::vpmaskmovd(XMMRegister dst, XMMRegister mask, Address src, int vector_len) {\n+  assert((VM_Version::supports_avx2() && vector_len == AVX_256bit), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ false, \/* uses_vl *\/ false);\n+  vex_prefix(src, mask->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0x8C);\n+  emit_operand(dst, src);\n+}\n+\n+void Assembler::vpmaskmovq(XMMRegister dst, XMMRegister mask, Address src, int vector_len) {\n+  assert((VM_Version::supports_avx2() && vector_len == AVX_256bit), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ false, \/* uses_vl *\/ false);\n+  vex_prefix(src, mask->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0x8C);\n+  emit_operand(dst, src);\n+}\n+\n+void Assembler::vmaskmovps(XMMRegister dst, Address src, XMMRegister mask, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src, mask->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8(0x2C);\n+  emit_operand(dst, src);\n+}\n+\n+void Assembler::vmaskmovpd(XMMRegister dst, Address src, XMMRegister mask, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src, mask->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8(0x2D);\n+  emit_operand(dst, src);\n+}\n+\n+void Assembler::vmaskmovps(Address dst, XMMRegister src, XMMRegister mask, int vector_len) {\n+  assert(UseAVX > 0, \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(dst, mask->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8(0x2E);\n+  emit_operand(src, dst);\n+}\n+\n+void Assembler::vmaskmovpd(Address dst, XMMRegister src, XMMRegister mask, int vector_len) {\n+  assert(UseAVX > 0, \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(dst, mask->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8(0x2F);\n+  emit_operand(src, dst);\n+}\n+\n@@ -4397,8 +4451,0 @@\n-void Assembler::vpmaskmovd(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n-  assert((VM_Version::supports_avx2() && vector_len == AVX_256bit), \"\");\n-  InstructionMark im(this);\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n-  vex_prefix(src, nds->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n-  emit_int8((unsigned char)0x8C);\n-  emit_operand(dst, src);\n-}\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":54,"deletions":8,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -1807,0 +1807,7 @@\n+  void vpmaskmovq(XMMRegister dst, XMMRegister mask, Address src, int vector_len);\n+\n+\n+  void vmaskmovps(XMMRegister dst, Address src, XMMRegister mask, int vector_len);\n+  void vmaskmovpd(XMMRegister dst, Address src, XMMRegister mask, int vector_len);\n+  void vmaskmovps(Address dst, XMMRegister src, XMMRegister mask, int vector_len);\n+  void vmaskmovpd(Address dst, XMMRegister src, XMMRegister mask, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1994,0 +1994,33 @@\n+void C2_MacroAssembler::vmovmask(BasicType elem_bt, XMMRegister dst, Address src, XMMRegister mask,\n+                                 int vec_enc) {\n+  switch(elem_bt) {\n+    case T_INT:\n+    case T_FLOAT:\n+      vmaskmovps(dst, src, mask, vec_enc);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      vmaskmovpd(dst, src, mask, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type %s\", type2name(elem_bt));\n+      break;\n+  }\n+}\n+\n+void C2_MacroAssembler::vmovmask(BasicType elem_bt, Address dst, XMMRegister src, XMMRegister mask,\n+                                 int vec_enc) {\n+  switch(elem_bt) {\n+    case T_INT:\n+    case T_FLOAT:\n+      vmaskmovps(dst, src, mask, vec_enc);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      vmaskmovpd(dst, src, mask, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type %s\", type2name(elem_bt));\n+      break;\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -445,0 +445,5 @@\n+\n+  void vmovmask(BasicType elem_bt, XMMRegister dst, Address src, XMMRegister mask, int vec_enc);\n+\n+  void vmovmask(BasicType elem_bt, Address dst, XMMRegister src, XMMRegister mask, int vec_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1592,2 +1592,0 @@\n-    case Op_LoadVectorMasked:\n-    case Op_StoreVectorMasked:\n@@ -1756,2 +1754,0 @@\n-    case Op_LoadVectorMasked:\n-    case Op_StoreVectorMasked:\n@@ -1765,0 +1761,10 @@\n+    case Op_LoadVectorMasked:\n+      if (!VM_Version::supports_avx512bw() && (is_subword_type(bt) || UseAVX < 1)) {\n+        return false;\n+      }\n+      break;\n+    case Op_StoreVectorMasked:\n+      if (!VM_Version::supports_avx512bw() && (is_subword_type(bt) || UseAVX < 1)) {\n+        return false;\n+      }\n+      break;\n@@ -9081,1 +9087,0 @@\n-#ifdef _LP64\n@@ -9083,0 +9088,12 @@\n+instruct vmasked_load_avx_non_subword(vec dst, memory mem, vec mask) %{\n+  predicate(!n->in(3)->bottom_type()->isa_vectmask());\n+  match(Set dst (LoadVectorMasked mem mask));\n+  format %{ \"vector_masked_load $dst, $mem, $mask \\t! vector masked copy\" %}\n+  ins_encode %{\n+    BasicType elmType = this->bottom_type()->is_vect()->element_basic_type();\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vmovmask(elmType, $dst$$XMMRegister, $mem$$Address, $mask$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -9084,0 +9101,39 @@\n+instruct vmasked_load_evex(vec dst, memory mem, kReg mask) %{\n+  predicate(n->in(3)->bottom_type()->isa_vectmask());\n+  match(Set dst (LoadVectorMasked mem mask));\n+  format %{ \"vector_masked_load $dst, $mem, $mask \\t! vector masked copy\" %}\n+  ins_encode %{\n+    BasicType elmType =  this->bottom_type()->is_vect()->element_basic_type();\n+    int vector_len = vector_length_encoding(this);\n+    __ evmovdqu(elmType, $mask$$KRegister, $dst$$XMMRegister, $mem$$Address, false, vector_len);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmasked_store_avx_non_subword(memory mem, vec src, vec mask) %{\n+  predicate(!n->in(3)->in(2)->bottom_type()->isa_vectmask());\n+  match(Set mem (StoreVectorMasked mem (Binary src mask)));\n+  format %{ \"vector_masked_store $mem, $src, $mask \\t! vector masked store\" %}\n+  ins_encode %{\n+    const MachNode* src_node = static_cast<const MachNode*>(this->in(this->operand_index($src)));\n+    int vlen_enc = vector_length_encoding(src_node);\n+    BasicType elmType =  src_node->bottom_type()->is_vect()->element_basic_type();\n+    __ vmovmask(elmType, $mem$$Address, $src$$XMMRegister, $mask$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vmasked_store_evex(memory mem, vec src, kReg mask) %{\n+  predicate(n->in(3)->in(2)->bottom_type()->isa_vectmask());\n+  match(Set mem (StoreVectorMasked mem (Binary src mask)));\n+  format %{ \"vector_masked_store $mem, $src, $mask \\t! vector masked store\" %}\n+  ins_encode %{\n+    const MachNode* src_node = static_cast<const MachNode*>(this->in(this->operand_index($src)));\n+    BasicType elmType =  src_node->bottom_type()->is_vect()->element_basic_type();\n+    int vlen_enc = vector_length_encoding(src_node);\n+    __ evmovdqu(elmType, $mask$$KRegister, $mem$$Address, $src$$XMMRegister, true, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+#ifdef _LP64\n@@ -9110,11 +9166,0 @@\n-instruct vmasked_load64(vec dst, memory mem, kReg mask) %{\n-  match(Set dst (LoadVectorMasked mem mask));\n-  format %{ \"vector_masked_load $dst, $mem, $mask \\t! vector masked copy\" %}\n-  ins_encode %{\n-    BasicType elmType =  this->bottom_type()->is_vect()->element_basic_type();\n-    int vector_len = vector_length_encoding(this);\n-    __ evmovdqu(elmType, $mask$$KRegister, $dst$$XMMRegister, $mem$$Address, false, vector_len);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n@@ -9142,12 +9187,0 @@\n-instruct vmasked_store64(memory mem, vec src, kReg mask) %{\n-  match(Set mem (StoreVectorMasked mem (Binary src mask)));\n-  format %{ \"vector_masked_store $mem, $src, $mask \\t! vector masked store\" %}\n-  ins_encode %{\n-    const MachNode* src_node = static_cast<const MachNode*>(this->in(this->operand_index($src)));\n-    BasicType elmType =  src_node->bottom_type()->is_vect()->element_basic_type();\n-    int vector_len = vector_length_encoding(src_node);\n-    __ evmovdqu(elmType, $mask$$KRegister, $mem$$Address, $src$$XMMRegister, true, vector_len);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":61,"deletions":28,"binary":false,"changes":89,"status":"modified"},{"patch":"@@ -308,0 +308,7 @@\n+    \/\/ Since operation support check is done upfront, we reach here only when target\n+    \/\/ specific checks in match_rule_supported_vector returned a true value\n+    \/\/ for these masked operations over non-predicated targets.\n+    if (!is_supported && (sopc == Op_StoreVectorMasked || sopc == Op_LoadVectorMasked)) {\n+      return true;\n+    }\n+\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -907,2 +907,1 @@\n-    assert(mask->bottom_type()->isa_vectmask(), \"sanity\");\n-    init_class_id(Class_StoreVector);\n+    init_class_id(Class_StoreVectorMasked);\n@@ -927,2 +926,1 @@\n-    assert(mask->bottom_type()->isa_vectmask(), \"sanity\");\n-    init_class_id(Class_LoadVector);\n+    init_class_id(Class_LoadVectorMasked);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -3923,0 +3923,1 @@\n+    @ForceInline\n@@ -3933,0 +3934,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ByteVector.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3534,0 +3534,1 @@\n+    @ForceInline\n@@ -3544,0 +3545,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/DoubleVector.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3484,0 +3484,1 @@\n+    @ForceInline\n@@ -3494,0 +3495,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/FloatVector.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3641,0 +3641,1 @@\n+    @ForceInline\n@@ -3651,0 +3652,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/IntVector.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3576,0 +3576,1 @@\n+    @ForceInline\n@@ -3586,0 +3587,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/LongVector.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3909,0 +3909,1 @@\n+    @ForceInline\n@@ -3919,0 +3920,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/ShortVector.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5136,0 +5136,1 @@\n+    @ForceInline\n@@ -5146,0 +5147,1 @@\n+    @ForceInline\n","filename":"src\/jdk.incubator.vector\/share\/classes\/jdk\/incubator\/vector\/X-Vector.java.template","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -98,1 +98,1 @@\n-            ByteVector.fromArray(bspecies, byteIn, i, mask).intoArray(byteOut, i);\n+            ByteVector.fromArray(bspecies, byteIn, i, mask).intoArray(byteOut, i, mask);\n@@ -106,1 +106,1 @@\n-            ShortVector.fromArray(sspecies, shortIn, i, mask).intoArray(shortOut, i);\n+            ShortVector.fromArray(sspecies, shortIn, i, mask).intoArray(shortOut, i, mask);\n@@ -114,1 +114,1 @@\n-            IntVector.fromArray(ispecies, intIn, i, mask).intoArray(intOut, i);\n+            IntVector.fromArray(ispecies, intIn, i, mask).intoArray(intOut, i, mask);\n@@ -122,1 +122,1 @@\n-            LongVector.fromArray(lspecies, longIn, i, mask).intoArray(longOut, i);\n+            LongVector.fromArray(lspecies, longIn, i, mask).intoArray(longOut, i, mask);\n@@ -130,1 +130,1 @@\n-            FloatVector.fromArray(fspecies, floatIn, i, mask).intoArray(floatOut, i);\n+            FloatVector.fromArray(fspecies, floatIn, i, mask).intoArray(floatOut, i, mask);\n@@ -138,1 +138,1 @@\n-            DoubleVector.fromArray(dspecies, doubleIn, i, mask).intoArray(doubleOut, i);\n+            DoubleVector.fromArray(dspecies, doubleIn, i, mask).intoArray(doubleOut, i, mask);\n","filename":"test\/micro\/org\/openjdk\/bench\/jdk\/incubator\/vector\/LoadMaskedIOOBEBenchmark.java","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"}]}