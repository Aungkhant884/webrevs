{"files":[{"patch":"@@ -1346,0 +1346,168 @@\n+\/\/ Closure for parallelly iterate objects.\n+class ObjectIterateParScanClosure : public BasicOopIterateClosure {\n+private:\n+  MarkBitMap* _bitmap;\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* const _heap;\n+  ShenandoahMarkingContext* const _marking_context;\n+\n+  template <class T>\n+  void do_oop_work(T* p) {\n+    T o = RawAccess<>::oop_load(p);\n+    if (!CompressedOops::is_null(o)) {\n+      oop obj = CompressedOops::decode_not_null(o);\n+      if (_heap->is_concurrent_weak_root_in_progress() && !_marking_context->is_marked(obj)) {\n+        \/\/ There may be dead oops in weak roots in concurrent root phase, do not touch them.\n+        return;\n+      }\n+      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n+\n+      assert(oopDesc::is_oop(obj), \"must be a valid oop\");\n+      \/\/ parallel mark\n+      if (_bitmap->par_mark(obj)) {\n+        _queue->push(ShenandoahMarkTask(obj));\n+      }\n+    }\n+  }\n+public:\n+  ObjectIterateParScanClosure(MarkBitMap* bitmap, ShenandoahObjToScanQueue* q) :\n+    _bitmap(bitmap), _queue(q), _heap(ShenandoahHeap::heap()),\n+    _marking_context(_heap->marking_context()) {}\n+  void do_oop(oop* p)       { do_oop_work(p); }\n+  void do_oop(narrowOop* p) { do_oop_work(p); }\n+};\n+\n+void ShenandoahHeap::scan_roots_for_iteration(Stack<oop, mtGC>* oop_stack) {\n+    assert(oop_stack != NULL, \"root stack must not be NULL\");\n+    \/\/ root marking\n+    ObjectIterateScanRootClosure oops(&_aux_bit_map, oop_stack);\n+    \/\/ Process GC roots according to current GC cycle.\n+    \/\/ This populates the work stack with initial objects.\n+    \/\/ It is important to relinquish the associated locks before diving\n+    \/\/ into heap dumper.\n+    ShenandoahHeapIterationRootScanner rp;\n+    rp.roots_do(&oops);\n+}\n+\n+bool ShenandoahHeap::prepare_aux_bitmap_for_iteration() {\n+    assert(SafepointSynchronize::is_at_safepoint(), \"safe iteration is only available during safepoints\");\n+\n+    if (!_aux_bitmap_region_special && !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {\n+      log_warning(gc)(\"Could not commit native memory for auxiliary marking bitmap for heap iteration\");\n+      return false;\n+    }\n+\n+    \/\/ Reset bitmap\n+    _aux_bit_map.clear();\n+    return true;\n+}\n+\n+void ShenandoahHeap::reclaim_aux_bitmap_for_iteration() {\n+    if (!_aux_bitmap_region_special && !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {\n+      log_warning(gc)(\"Could not uncommit native memory for auxiliary marking bitmap for heap iteration\");\n+    }\n+}\n+\n+\/\/ Object iterator for parallel heap iteraion.\n+\/\/ The root scanning phase happenes in construction as a preparation of\n+\/\/ parallel marking queues.\n+\/\/ Every worker processes it's own marking queue. work-stealing is used\n+\/\/ to balance workload.\n+class ShenandoahParallelObjectIterator : public ParallelObjectIterator {\n+private:\n+  uint                         _num_workers;\n+  bool                         _init_ready;\n+  ShenandoahHeap*              _heap;\n+  Stack<oop, mtGC>             _roots_stack; \/\/ global roots stack\n+  ShenandoahObjToScanQueueSet* _task_queues;\n+public:\n+  ShenandoahParallelObjectIterator(uint num_workers) :\n+        _num_workers(num_workers),\n+        _init_ready(false),\n+        _heap(ShenandoahHeap::heap()) {\n+    \/\/ Initialize bitmap\n+    _init_ready = _heap->prepare_aux_bitmap_for_iteration();\n+    \/\/ Procssing roots\n+    _heap->scan_roots_for_iteration(&_roots_stack);\n+    \/\/ prepare worker stacks\n+    _init_ready &= prepare_worker_queues();\n+  }\n+\n+  ~ShenandoahParallelObjectIterator() {\n+    \/\/ Reclaim bitmap\n+    _heap->reclaim_aux_bitmap_for_iteration();\n+    \/\/ Reclaim queue for workers\n+    if (_task_queues!= NULL) {\n+      for (uint i = 0; i < _num_workers; ++i) {\n+        ShenandoahObjToScanQueue* q = _task_queues->queue(i);\n+        if (q != NULL) {\n+          delete q;\n+          _task_queues->register_queue(i, NULL);\n+        }\n+      }\n+      delete _task_queues;\n+      _task_queues = NULL;\n+    }\n+  }\n+\n+  virtual void object_iterate(ObjectClosure* cl, uint worker_id) {\n+    if (_init_ready) {\n+      _heap->object_iterate_parallel(cl, worker_id, _task_queues);\n+    }\n+  }\n+\n+private:\n+  \/\/ divide global root_stack into worker queues.\n+  bool prepare_worker_queues() {\n+    _task_queues = new ShenandoahObjToScanQueueSet((int) _num_workers);\n+    \/\/ initialize queue for every workers\n+    for (uint i = 0; i < _num_workers; ++i) {\n+      ShenandoahObjToScanQueue* task_queue = new ShenandoahObjToScanQueue();\n+      task_queue->initialize();\n+      _task_queues->register_queue(i, task_queue);\n+    }\n+    \/\/ divide roots to every worker\n+    size_t roots_num = _roots_stack.size();\n+    if (roots_num == 0) {\n+      \/\/ no work to do.\n+      return false;\n+    }\n+    \/\/ assume that object referencing distribution is related with\n+    \/\/ root kind, use round-robin to make every worker have same chance\n+    \/\/ to process every kind of roots\n+    for (uint j = 0; j < roots_num; j++) {\n+      uint stack_id = j % _num_workers;\n+      oop obj = _roots_stack.pop();\n+      _task_queues->queue(stack_id)->push(ShenandoahMarkTask(obj));\n+    }\n+    return true;\n+  }\n+};\n+\n+ParallelObjectIterator* ShenandoahHeap::parallel_object_iterator(uint num_workers) {\n+  return new ShenandoahParallelObjectIterator(num_workers);\n+}\n+\n+void ShenandoahHeap::object_iterate_parallel(ObjectClosure* cl,\n+                                             uint worker_id,\n+                                             ShenandoahObjToScanQueueSet* queue_set) {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"safe iteration is only available during safepoints\");\n+  assert(queue_set != NULL, \"task queue must not be NULL\");\n+\n+  ShenandoahObjToScanQueue* q = queue_set->queue(worker_id);\n+  assert(q != NULL, \"object iterate queue must not be NULL\");\n+  \/\/ Task in queue\n+  ShenandoahMarkTask t;\n+  ObjectIterateParScanClosure oops(&_aux_bit_map, q);\n+\n+  \/\/ Work through the queue to traverse heap.\n+  \/\/ steal when there is no task in queue.\n+  while (q->pop(t) || queue_set->steal(worker_id, t)) {\n+    oop obj = t.obj();\n+    assert(oopDesc::is_oop(obj), \"must be a valid oop\");\n+    cl->do_object(obj);\n+    obj->oop_iterate(&oops);\n+  }\n+  assert(q.is_empty(), \"should be empty\");\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":168,"deletions":0,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -40,0 +40,2 @@\n+#include \"utilities\/stack.hpp\"\n+\n@@ -60,0 +62,1 @@\n+class ShenandoahObjToScanQueueSet;\n@@ -552,0 +555,8 @@\n+  \/\/ parallel heap iteration support\n+  void scan_roots_for_iteration(Stack<oop, mtGC>* oop_stack);\n+  bool prepare_aux_bitmap_for_iteration();\n+  void reclaim_aux_bitmap_for_iteration();\n+  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num);\n+  void object_iterate_parallel(ObjectClosure* cl,\n+                               uint worker_id,\n+                               ShenandoahObjToScanQueueSet* queue_set);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"}]}