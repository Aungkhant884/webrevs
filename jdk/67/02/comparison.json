{"files":[{"patch":"@@ -1309,6 +1309,0 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"safe iteration is only available during safepoints\");\n-  if (!_aux_bitmap_region_special && !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {\n-    log_warning(gc)(\"Could not commit native memory for auxiliary marking bitmap for heap iteration\");\n-    return;\n-  }\n-\n@@ -1316,1 +1310,2 @@\n-  _aux_bit_map.clear();\n+  if (!prepare_aux_bitmap_for_iteration())\n+    return;\n@@ -1319,1 +1314,1 @@\n-\n+  \/\/ root marking\n@@ -1322,8 +1317,1 @@\n-  {\n-    \/\/ First, we process GC roots according to current GC cycle.\n-    \/\/ This populates the work stack with initial objects.\n-    \/\/ It is important to relinquish the associated locks before diving\n-    \/\/ into heap dumper.\n-    ShenandoahHeapIterationRootScanner rp;\n-    rp.roots_do(&oops);\n-  }\n+  scan_roots_for_iteration(&oop_stack, &oops);\n@@ -1340,0 +1328,31 @@\n+  \/\/ Reclaim bitmap\n+  reclaim_aux_bitmap_for_iteration();\n+}\n+\n+bool ShenandoahHeap::prepare_aux_bitmap_for_iteration() {\n+    assert(SafepointSynchronize::is_at_safepoint(), \"safe iteration is only available during safepoints\");\n+\n+    if (!_aux_bitmap_region_special && !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {\n+      log_warning(gc)(\"Could not commit native memory for auxiliary marking bitmap for heap iteration\");\n+      return false;\n+    }\n+\n+    \/\/ Reset bitmap\n+    _aux_bit_map.clear();\n+    return true;\n+}\n+\n+void ShenandoahHeap::scan_roots_for_iteration(Stack<oop, mtGC>* oop_stack, ObjectIterateScanRootClosure* oops) {\n+    \/\/ Process GC roots according to current GC cycle.\n+    \/\/ This populates the work stack with initial objects.\n+    \/\/ It is important to relinquish the associated locks before diving\n+    \/\/ into heap dumper.\n+    ShenandoahHeapIterationRootScanner rp;\n+    rp.roots_do(oops);\n+}\n+\n+void ShenandoahHeap::reclaim_aux_bitmap_for_iteration() {\n+    if (!_aux_bitmap_region_special && !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {\n+      log_warning(gc)(\"Could not uncommit native memory for auxiliary marking bitmap for heap iteration\");\n+    }\n+}\n@@ -1341,2 +1360,25 @@\n-  if (!_aux_bitmap_region_special && !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {\n-    log_warning(gc)(\"Could not uncommit native memory for auxiliary marking bitmap for heap iteration\");\n+\/\/ Closure for parallelly iterate objects.\n+class ShenandoahObjectIterateParScanClosure : public BasicOopIterateClosure {\n+private:\n+  MarkBitMap* _bitmap;\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* const _heap;\n+  ShenandoahMarkingContext* const _marking_context;\n+\n+  template <class T>\n+  void do_oop_work(T* p) {\n+    T o = RawAccess<>::oop_load(p);\n+    if (!CompressedOops::is_null(o)) {\n+      oop obj = CompressedOops::decode_not_null(o);\n+      if (_heap->is_concurrent_weak_root_in_progress() && !_marking_context->is_marked(obj)) {\n+        \/\/ There may be dead oops in weak roots in concurrent root phase, do not touch them.\n+        return;\n+      }\n+      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n+\n+      assert(oopDesc::is_oop(obj), \"must be a valid oop\");\n+      \/\/ parallel mark\n+      if (_bitmap->par_mark(obj)) {\n+        _queue->push(ShenandoahMarkTask(obj));\n+      }\n+    }\n@@ -1344,0 +1386,116 @@\n+public:\n+  ShenandoahObjectIterateParScanClosure(MarkBitMap* bitmap, ShenandoahObjToScanQueue* q) :\n+    _bitmap(bitmap), _queue(q), _heap(ShenandoahHeap::heap()),\n+    _marking_context(_heap->marking_context()) {}\n+  void do_oop(oop* p)       { do_oop_work(p); }\n+  void do_oop(narrowOop* p) { do_oop_work(p); }\n+};\n+\n+\/\/ Object iterator for parallel heap iteraion.\n+\/\/ The root scanning phase happenes in construction as a preparation of\n+\/\/ parallel marking queues.\n+\/\/ Every worker processes it's own marking queue. work-stealing is used\n+\/\/ to balance workload.\n+class ShenandoahParallelObjectIterator : public ParallelObjectIterator {\n+private:\n+  uint                         _num_workers;\n+  bool                         _init_ready;\n+  MarkBitMap*                  _aux_bit_map;\n+  ShenandoahHeap*              _heap;\n+  Stack<oop, mtGC>             _roots_stack; \/\/ global roots stack\n+  ShenandoahObjToScanQueueSet* _task_queues;\n+public:\n+  ShenandoahParallelObjectIterator(uint num_workers, MarkBitMap* bitmap) :\n+        _num_workers(num_workers),\n+        _init_ready(false),\n+        _aux_bit_map(bitmap),\n+        _heap(ShenandoahHeap::heap()) {\n+    \/\/ Initialize bitmap\n+    _init_ready = _heap->prepare_aux_bitmap_for_iteration();\n+    if (!_init_ready) {\n+      return;\n+    }\n+    \/\/ root marking\n+    ObjectIterateScanRootClosure oops(_aux_bit_map, &_roots_stack);\n+    \/\/ Procssing roots\n+    _heap->scan_roots_for_iteration(&_roots_stack, &oops);\n+    \/\/ prepare worker stacks\n+    _init_ready = prepare_worker_queues();\n+  }\n+\n+  ~ShenandoahParallelObjectIterator() {\n+    \/\/ Reclaim bitmap\n+    _heap->reclaim_aux_bitmap_for_iteration();\n+    \/\/ Reclaim queue for workers\n+    if (_task_queues!= NULL) {\n+      for (uint i = 0; i < _num_workers; ++i) {\n+        ShenandoahObjToScanQueue* q = _task_queues->queue(i);\n+        if (q != NULL) {\n+          delete q;\n+          _task_queues->register_queue(i, NULL);\n+        }\n+      }\n+      delete _task_queues;\n+      _task_queues = NULL;\n+    }\n+  }\n+\n+  virtual void object_iterate(ObjectClosure* cl, uint worker_id) {\n+    if (_init_ready) {\n+      object_iterate_parallel(cl, worker_id, _task_queues);\n+    }\n+  }\n+\n+private:\n+  \/\/ divide global root_stack into worker queues.\n+  bool prepare_worker_queues() {\n+    _task_queues = new ShenandoahObjToScanQueueSet((int) _num_workers);\n+    \/\/ initialize queue for every workers\n+    for (uint i = 0; i < _num_workers; ++i) {\n+      ShenandoahObjToScanQueue* task_queue = new ShenandoahObjToScanQueue();\n+      task_queue->initialize();\n+      _task_queues->register_queue(i, task_queue);\n+    }\n+    \/\/ divide roots to every worker\n+    size_t roots_num = _roots_stack.size();\n+    if (roots_num == 0) {\n+      \/\/ no work to do.\n+      return false;\n+    }\n+    \/\/ assume that object referencing distribution is related with\n+    \/\/ root kind, use round-robin to make every worker have same chance\n+    \/\/ to process every kind of roots\n+    for (uint j = 0; j < roots_num; j++) {\n+      uint stack_id = j % _num_workers;\n+      oop obj = _roots_stack.pop();\n+      _task_queues->queue(stack_id)->push(ShenandoahMarkTask(obj));\n+    }\n+    return true;\n+  }\n+\n+  void object_iterate_parallel(ObjectClosure* cl,\n+                               uint worker_id,\n+                               ShenandoahObjToScanQueueSet* queue_set) {\n+    assert(SafepointSynchronize::is_at_safepoint(), \"safe iteration is only available during safepoints\");\n+    assert(queue_set != NULL, \"task queue must not be NULL\");\n+\n+    ShenandoahObjToScanQueue* q = queue_set->queue(worker_id);\n+    assert(q != NULL, \"object iterate queue must not be NULL\");\n+    \/\/ Task in queue\n+    ShenandoahMarkTask t;\n+    ShenandoahObjectIterateParScanClosure oops(_aux_bit_map, q);\n+\n+    \/\/ Work through the queue to traverse heap.\n+    \/\/ steal when there is no task in queue.\n+    while (q->pop(t) || queue_set->steal(worker_id, t)) {\n+      oop obj = t.obj();\n+      assert(oopDesc::is_oop(obj), \"must be a valid oop\");\n+      cl->do_object(obj);\n+      obj->oop_iterate(&oops);\n+    }\n+    assert(q->is_empty(), \"should be empty\");\n+  }\n+};\n+\n+ParallelObjectIterator* ShenandoahHeap::parallel_object_iterator(uint num_workers) {\n+  return new ShenandoahParallelObjectIterator(num_workers, &_aux_bit_map);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":176,"deletions":18,"binary":false,"changes":194,"status":"modified"},{"patch":"@@ -40,0 +40,2 @@\n+#include \"utilities\/stack.hpp\"\n+\n@@ -42,0 +44,1 @@\n+class ObjectIterateScanRootClosure;\n@@ -60,0 +63,1 @@\n+class ShenandoahObjToScanQueueSet;\n@@ -120,1 +124,1 @@\n-\n+  friend class ShenandoahParallelObjectIterator;\n@@ -527,0 +531,4 @@\n+  \/\/ Heap iteration support\n+  void scan_roots_for_iteration(Stack<oop, mtGC>* oop_stack, ObjectIterateScanRootClosure* oops);\n+  bool prepare_aux_bitmap_for_iteration();\n+  void reclaim_aux_bitmap_for_iteration();\n@@ -552,0 +560,2 @@\n+  \/\/ parallel heap iteration support\n+  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"}]}