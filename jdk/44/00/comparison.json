{"files":[{"patch":"@@ -45,2 +45,1 @@\n-\n-\/\/ ======= Concurrent Mark Thread ========\n+#include \"utilities\/ticks.hpp\"\n@@ -52,1 +51,0 @@\n-  _vtime_mark_accum(0.0),\n@@ -80,1 +78,1 @@\n-double G1ConcurrentMarkThread::mmu_delay_end(G1Policy* g1_policy, bool remark) {\n+double G1ConcurrentMarkThread::mmu_delay_end(G1Policy* policy, bool remark) {\n@@ -91,1 +89,1 @@\n-  const G1Analytics* analytics = g1_policy->analytics();\n+  const G1Analytics* analytics = policy->analytics();\n@@ -95,1 +93,1 @@\n-  G1MMUTracker *mmu_tracker = g1_policy->mmu_tracker();\n+  G1MMUTracker *mmu_tracker = policy->mmu_tracker();\n@@ -100,3 +98,5 @@\n-void G1ConcurrentMarkThread::delay_to_keep_mmu(G1Policy* g1_policy, bool remark) {\n-  if (g1_policy->use_adaptive_young_list_length()) {\n-    double delay_end_sec = mmu_delay_end(g1_policy, remark);\n+void G1ConcurrentMarkThread::delay_to_keep_mmu(bool remark) {\n+  G1Policy* policy = G1CollectedHeap::heap()->policy();\n+\n+  if (policy->use_adaptive_young_list_length()) {\n+    double delay_end_sec = mmu_delay_end(policy, remark);\n@@ -105,1 +105,1 @@\n-    while (!_cm->has_aborted()) {\n+    while (!_cm->has_aborted() && !should_terminate()) {\n@@ -112,2 +112,0 @@\n-      } else if (should_terminate()) {\n-        break;                  \/\/ Wakeup for pending termination request.\n@@ -139,9 +137,1 @@\n-  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-  G1Policy* policy = g1h->policy();\n-\n-  while (!should_terminate()) {\n-    \/\/ wait until started is set.\n-    sleep_before_next_cycle();\n-    if (should_terminate()) {\n-      break;\n-    }\n+  while (wait_for_next_cycle()) {\n@@ -150,3 +140,0 @@\n-\n-    _cm->concurrent_cycle_start();\n-\n@@ -154,100 +141,0 @@\n-    {\n-      ResourceMark rm;\n-\n-      double cycle_start = os::elapsedVTime();\n-\n-      {\n-        G1ConcPhaseTimer p(_cm, \"Concurrent Clear Claimed Marks\");\n-        ClassLoaderDataGraph::clear_claimed_marks();\n-      }\n-\n-      \/\/ We have to ensure that we finish scanning the root regions\n-      \/\/ before the next GC takes place. To ensure this we have to\n-      \/\/ make sure that we do not join the STS until the root regions\n-      \/\/ have been scanned. If we did then it's possible that a\n-      \/\/ subsequent GC could block us from joining the STS and proceed\n-      \/\/ without the root regions have been scanned which would be a\n-      \/\/ correctness issue.\n-\n-      {\n-        G1ConcPhaseTimer p(_cm, \"Concurrent Scan Root Regions\");\n-        _cm->scan_root_regions();\n-      }\n-\n-      \/\/ Note: ConcurrentGCBreakpoints before here risk deadlock,\n-      \/\/ because a young GC must wait for root region scanning.\n-\n-      \/\/ It would be nice to use the G1ConcPhaseTimer class here but\n-      \/\/ the \"end\" logging is inside the loop and not at the end of\n-      \/\/ a scope. Also, the timer doesn't support nesting.\n-      \/\/ Mimicking the same log output instead.\n-      jlong mark_start = os::elapsed_counter();\n-      log_info(gc, marking)(\"Concurrent Mark (%.3fs)\",\n-                            TimeHelper::counter_to_seconds(mark_start));\n-      for (uint iter = 1; !_cm->has_aborted(); ++iter) {\n-        \/\/ Concurrent marking.\n-        {\n-          ConcurrentGCBreakpoints::at(\"AFTER MARKING STARTED\");\n-          G1ConcPhaseTimer p(_cm, \"Concurrent Mark From Roots\");\n-          _cm->mark_from_roots();\n-        }\n-        if (_cm->has_aborted()) {\n-          break;\n-        }\n-\n-        if (G1UseReferencePrecleaning) {\n-          G1ConcPhaseTimer p(_cm, \"Concurrent Preclean\");\n-          _cm->preclean();\n-        }\n-        if (_cm->has_aborted()) {\n-          break;\n-        }\n-\n-        \/\/ Delay remark pause for MMU.\n-        double mark_end_time = os::elapsedVTime();\n-        jlong mark_end = os::elapsed_counter();\n-        _vtime_mark_accum += (mark_end_time - cycle_start);\n-        delay_to_keep_mmu(policy, true \/* remark *\/);\n-        if (_cm->has_aborted()) {\n-          break;\n-        }\n-\n-        \/\/ Pause Remark.\n-        ConcurrentGCBreakpoints::at(\"BEFORE MARKING COMPLETED\");\n-        log_info(gc, marking)(\"Concurrent Mark (%.3fs, %.3fs) %.3fms\",\n-                              TimeHelper::counter_to_seconds(mark_start),\n-                              TimeHelper::counter_to_seconds(mark_end),\n-                              TimeHelper::counter_to_millis(mark_end - mark_start));\n-        CMRemark cl(_cm);\n-        VM_G1Concurrent op(&cl, \"Pause Remark\");\n-        VMThread::execute(&op);\n-        if (_cm->has_aborted()) {\n-          break;\n-        } else if (!_cm->restart_for_overflow()) {\n-          break;                \/\/ Exit loop if no restart requested.\n-        } else {\n-          \/\/ Loop to restart for overflow.\n-          log_info(gc, marking)(\"Concurrent Mark Restart for Mark Stack Overflow (iteration #%u)\",\n-                                iter);\n-        }\n-      }\n-\n-      if (!_cm->has_aborted()) {\n-        G1ConcPhaseTimer p(_cm, \"Concurrent Rebuild Remembered Sets\");\n-        _cm->rebuild_rem_set_concurrently();\n-      }\n-\n-      double end_time = os::elapsedVTime();\n-      \/\/ Update the total virtual time before doing this, since it will try\n-      \/\/ to measure it to get the vtime for this marking.\n-      _vtime_accum = (end_time - _vtime_start);\n-\n-      if (!_cm->has_aborted()) {\n-        delay_to_keep_mmu(policy, false \/* cleanup *\/);\n-      }\n-\n-      if (!_cm->has_aborted()) {\n-        CMCleanup cl_cl(_cm);\n-        VM_G1Concurrent op(&cl_cl, \"Pause Cleanup\");\n-        VMThread::execute(&op);\n-      }\n@@ -255,9 +142,3 @@\n-      \/\/ We now want to allow clearing of the marking bitmap to be\n-      \/\/ suspended by a collection pause.\n-      \/\/ We may have aborted just before the remark. Do not bother clearing the\n-      \/\/ bitmap then, as it has been done during mark abort.\n-      if (!_cm->has_aborted()) {\n-        G1ConcPhaseTimer p(_cm, \"Concurrent Cleanup for Next Mark\");\n-        _cm->cleanup_for_next_mark();\n-      }\n-    }\n+    concurrent_cycle_start();\n+    full_concurrent_cycle_do();\n+    concurrent_cycle_end();\n@@ -265,12 +146,1 @@\n-    \/\/ Update the number of full collections that have been\n-    \/\/ completed. This will also notify the G1OldGCCount_lock in case a\n-    \/\/ Java thread is waiting for a full GC to happen (e.g., it\n-    \/\/ called System.gc() with +ExplicitGCInvokesConcurrent).\n-    {\n-      SuspendibleThreadSetJoiner sts_join;\n-      g1h->increment_old_marking_cycles_completed(true \/* concurrent *\/,\n-                                                  !_cm->has_aborted() \/* liveness_completed *\/);\n-\n-      _cm->concurrent_cycle_end();\n-      ConcurrentGCBreakpoints::notify_active_to_idle();\n-    }\n+    _vtime_accum = (os::elapsedVTime() - _vtime_start);\n@@ -286,4 +156,1 @@\n-\n-void G1ConcurrentMarkThread::sleep_before_next_cycle() {\n-  \/\/ We join here because we don't want to do the \"shouldConcurrentMark()\"\n-  \/\/ below while the world is otherwise stopped.\n+bool G1ConcurrentMarkThread::wait_for_next_cycle() {\n@@ -300,0 +167,156 @@\n+\n+  return !should_terminate();\n+}\n+\n+void G1ConcurrentMarkThread::phase_clear_cld_claimed_marks() {\n+  G1ConcPhaseTimer p(_cm, \"Concurrent Clear Claimed Marks\");\n+  ClassLoaderDataGraph::clear_claimed_marks();\n+}\n+\n+bool G1ConcurrentMarkThread::phase_scan_root_regions() {\n+  G1ConcPhaseTimer p(_cm, \"Concurrent Scan Root Regions\");\n+  _cm->scan_root_regions();\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::phase_mark_loop() {\n+  Ticks mark_start = Ticks::now();\n+  log_info(gc, marking)(\"Concurrent Mark\");\n+\n+  for (uint iter = 1; true; ++iter) {\n+    \/\/ Subphase 1: Mark From Roots.\n+    if (subphase_mark_from_roots()) return true;\n+\n+    \/\/ Subphase 2: Preclean (optional)\n+    if (G1UseReferencePrecleaning) {\n+      if (subphase_preclean()) return true;\n+    }\n+\n+    \/\/ Subphase 3: Wait for Remark.\n+    if (subphase_delay_to_keep_mmu_before_remark()) return true;\n+\n+    \/\/ Subphase 4: Remark pause\n+    if (subphase_remark()) return true;\n+\n+    \/\/ Check if we need to restart the marking loop.\n+    if (!mark_loop_needs_restart()) break;\n+\n+    log_info(gc, marking)(\"Concurrent Mark Restart for Mark Stack Overflow (iteration #%u)\",\n+                          iter);\n+  }\n+\n+  log_info(gc, marking)(\"Concurrent Mark %.3fms\",\n+                        (Ticks::now() - mark_start).seconds() * 1000.0);\n+\n+  return false;\n+}\n+\n+bool G1ConcurrentMarkThread::mark_loop_needs_restart() const {\n+  return _cm->has_overflown();\n+}\n+\n+bool G1ConcurrentMarkThread::subphase_mark_from_roots() {\n+  ConcurrentGCBreakpoints::at(\"AFTER MARKING STARTED\");\n+  G1ConcPhaseTimer p(_cm, \"Concurrent Mark From Roots\");\n+  _cm->mark_from_roots();\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::subphase_preclean() {\n+  G1ConcPhaseTimer p(_cm, \"Concurrent Preclean\");\n+  _cm->preclean();\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::subphase_delay_to_keep_mmu_before_remark() {\n+  delay_to_keep_mmu(true \/* remark *\/);\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::subphase_remark() {\n+  ConcurrentGCBreakpoints::at(\"BEFORE MARKING COMPLETED\");\n+  CMRemark cl(_cm);\n+  VM_G1Concurrent op(&cl, \"Pause Remark\");\n+  VMThread::execute(&op);\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::phase_rebuild_remembered_sets() {\n+  G1ConcPhaseTimer p(_cm, \"Concurrent Rebuild Remembered Sets\");\n+  _cm->rebuild_rem_set_concurrently();\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::phase_delay_to_keep_mmu_before_cleanup() {\n+  delay_to_keep_mmu(false \/* cleanup *\/);\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::phase_cleanup() {\n+  CMCleanup cl(_cm);\n+  VM_G1Concurrent op(&cl, \"Pause Cleanup\");\n+  VMThread::execute(&op);\n+  return _cm->has_aborted();\n+}\n+\n+bool G1ConcurrentMarkThread::phase_clear_bitmap_for_next_mark() {\n+  G1ConcPhaseTimer p(_cm, \"Concurrent Cleanup for Next Mark\");\n+  _cm->cleanup_for_next_mark();\n+  return _cm->has_aborted();\n+}\n+\n+void G1ConcurrentMarkThread::concurrent_cycle_start() {\n+  _cm->concurrent_cycle_start();\n+}\n+\n+void G1ConcurrentMarkThread::full_concurrent_cycle_do() {\n+  HandleMark hm(Thread::current());\n+  ResourceMark rm;\n+\n+  \/\/ Phase 1: Clear CLD claimed marks.\n+  phase_clear_cld_claimed_marks();\n+\n+  \/\/ We have to ensure that we finish scanning the root regions\n+  \/\/ before the next GC takes place. To ensure this we have to\n+  \/\/ make sure that we do not join the STS until the root regions\n+  \/\/ have been scanned. If we did then it's possible that a\n+  \/\/ subsequent GC could block us from joining the STS and proceed\n+  \/\/ without the root regions have been scanned which would be a\n+  \/\/ correctness issue.\n+  \/\/\n+  \/\/ So do not return before the scan root regions phase as a GC waits for a\n+  \/\/ notification from it.\n+  \/\/\n+  \/\/ For the same reason ConcurrentGCBreakpoints (in the phase methods) before\n+  \/\/ here risk deadlock, because a young GC must wait for root region scanning.\n+\n+  \/\/ Phase 2: Scan root regions.\n+  if (phase_scan_root_regions()) return;\n+\n+  \/\/ Phase 3: Actual mark loop.\n+  if (phase_mark_loop()) return;\n+\n+  \/\/ Phase 4: Rebuild remembered sets.\n+  if (phase_rebuild_remembered_sets()) return;\n+\n+  \/\/ Phase 5: Wait for Cleanup.\n+  if (phase_delay_to_keep_mmu_before_cleanup()) return;\n+\n+  \/\/ Phase 6: Cleanup pause\n+  if (phase_cleanup()) return;\n+\n+  \/\/ Phase 7: Clear bitmap for next mark.\n+  phase_clear_bitmap_for_next_mark();\n+}\n+\n+void G1ConcurrentMarkThread::concurrent_cycle_end() {\n+  \/\/ Update the number of full collections that have been\n+  \/\/ completed. This will also notify the G1OldGCCount_lock in case a\n+  \/\/ Java thread is waiting for a full GC to happen (e.g., it\n+  \/\/ called System.gc() with +ExplicitGCInvokesConcurrent).\n+  SuspendibleThreadSetJoiner sts_join;\n+  G1CollectedHeap::heap()->increment_old_marking_cycles_completed(true \/* concurrent *\/,\n+                                                                  !_cm->has_aborted());\n+\n+  _cm->concurrent_cycle_end();\n+  ConcurrentGCBreakpoints::notify_active_to_idle();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMarkThread.cpp","additions":172,"deletions":149,"binary":false,"changes":321,"status":"modified"},{"patch":"@@ -40,1 +40,0 @@\n-  double _vtime_mark_accum;\n@@ -44,1 +43,1 @@\n-  enum State {\n+  enum ServiceState {\n@@ -50,1 +49,1 @@\n-  volatile State _state;\n+  volatile ServiceState _state;\n@@ -52,4 +51,32 @@\n-  void sleep_before_next_cycle();\n-  \/\/ Delay marking to meet MMU.\n-  void delay_to_keep_mmu(G1Policy* g1_policy, bool remark);\n-  double mmu_delay_end(G1Policy* g1_policy, bool remark);\n+  \/\/ Wait for next cycle. Returns false if the service should be stopped.\n+  bool wait_for_next_cycle();\n+\n+  bool mark_loop_needs_restart() const;\n+\n+  \/\/ Phases and subphases for the full concurrent marking cycle in order.\n+  \/\/\n+  \/\/ All these methods return true if the marking should be aborted. Except\n+  \/\/ phase_clear_cld_claimed_marks() because we must not abort before\n+  \/\/ scanning the root regions because of a potential deadlock otherwise.\n+  void phase_clear_cld_claimed_marks();\n+  bool phase_scan_root_regions();\n+\n+  bool phase_mark_loop();\n+  bool subphase_mark_from_roots();\n+  bool subphase_preclean();\n+  bool subphase_delay_to_keep_mmu_before_remark();\n+  bool subphase_remark();\n+\n+  bool phase_rebuild_remembered_sets();\n+  bool phase_delay_to_keep_mmu_before_cleanup();\n+  bool phase_cleanup();\n+  bool phase_clear_bitmap_for_next_mark();\n+\n+  void concurrent_cycle_start();\n+\n+  void full_concurrent_cycle_do();\n+  void concurrent_cycle_end();\n+\n+  \/\/ Delay pauses to meet MMU.\n+  void delay_to_keep_mmu(bool remark);\n+  double mmu_delay_end(G1Policy* policy, bool remark);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMarkThread.hpp","additions":34,"deletions":7,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-  return _vtime_mark_accum + _cm->all_task_accum_vtime();\n+  return _cm->all_task_accum_vtime();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMarkThread.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}