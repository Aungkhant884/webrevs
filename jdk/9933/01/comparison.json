{"files":[{"patch":"@@ -12165,1 +12165,1 @@\n-bool Assembler::reachable(AddressLiteral adr) {\n+static bool is_reachable_from(address pc, address target, relocInfo::relocType relocType) {\n@@ -12167,1 +12167,0 @@\n-  relocInfo::relocType relocType = adr.reloc();\n@@ -12201,1 +12200,1 @@\n-    if (CodeCache::find_blob(adr._target) == NULL) {\n+    if (!CodeCache::contains(target)) {\n@@ -12210,4 +12209,8 @@\n-  disp = (int64_t)adr._target - ((int64_t)CodeCache::low_bound() + sizeof(int));\n-  if (!is_simm32(disp)) return false;\n-  disp = (int64_t)adr._target - ((int64_t)CodeCache::high_bound() + sizeof(int));\n-  if (!is_simm32(disp)) return false;\n+  disp = (int64_t)target - ((int64_t)CodeCache::low_bound() + sizeof(int));\n+  if (!Assembler::is_simm32(disp)) {\n+    return false;\n+  }\n+  disp = (int64_t)target - ((int64_t)CodeCache::high_bound() + sizeof(int));\n+  if (!Assembler::is_simm32(disp)) {\n+    return false;\n+  }\n@@ -12215,1 +12218,1 @@\n-  disp = (int64_t)adr._target - ((int64_t)pc() + sizeof(int));\n+  disp = (int64_t)target - ((int64_t)pc + sizeof(int));\n@@ -12230,1 +12233,36 @@\n-  return is_simm32(disp);\n+  return Assembler::is_simm32(disp);\n+}\n+\n+bool Assembler::reachable(AddressLiteral adr) {\n+  bool is_reachable = is_reachable_from(pc(), adr.target(), adr.reloc());\n+  if (!is_reachable) {\n+    assert(!always_reachable(adr), \"sanity\");\n+  }\n+  return is_reachable;\n+}\n+\n+bool Assembler::always_reachable(AddressLiteral adr) {\n+  switch (adr.reloc()) {\n+    \/\/ This should be rip relative and easily reachable.\n+    case relocInfo::internal_word_type: {\n+      return true;\n+    }\n+    \/\/ This should be rip relative within the code cache and easily\n+    \/\/ reachable until we get huge code caches. (At which point\n+    \/\/ IC code is going to have issues).\n+    case relocInfo::virtual_call_type:\n+    case relocInfo::opt_virtual_call_type:\n+    case relocInfo::static_call_type:\n+    case relocInfo::static_stub_type: {\n+      return true;\n+    }\n+    case relocInfo::runtime_call_type:\n+    case relocInfo::external_word_type:\n+    case relocInfo::poll_return_type: \/\/ these are really external_word but need special\n+    case relocInfo::poll_type: {      \/\/ relocs to identify them\n+      return CodeCache::contains(adr._target);\n+    }\n+    default: {\n+      return false;\n+    }\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":47,"deletions":9,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -805,1 +805,1 @@\n-  #ifdef ASSERT\n+#ifdef ASSERT\n@@ -807,1 +807,1 @@\n-  #endif\n+#endif\n@@ -814,1 +814,3 @@\n-  bool reachable(AddressLiteral adr) NOT_LP64({ return true;});\n+  bool always_reachable(AddressLiteral adr) NOT_LP64( { return true; } );\n+  bool        reachable(AddressLiteral adr) NOT_LP64( { return true; } );\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -220,1 +220,1 @@\n-    movptr(tmpReg, ExternalAddress((address) RTMLockingCounters::rtm_calculation_flag_addr()), tmpReg);\n+    movptr(tmpReg, ExternalAddress((address) RTMLockingCounters::rtm_calculation_flag_addr()));\n@@ -970,1 +970,1 @@\n-void C2_MacroAssembler::vabsnegd(int opcode, XMMRegister dst, XMMRegister src, Register scr) {\n+void C2_MacroAssembler::vabsnegd(int opcode, XMMRegister dst, XMMRegister src) {\n@@ -975,1 +975,1 @@\n-    andpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_mask()), scr);\n+    andpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_mask()), noreg);\n@@ -978,1 +978,1 @@\n-    xorpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), scr);\n+    xorpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), noreg);\n@@ -982,1 +982,1 @@\n-void C2_MacroAssembler::vabsnegd(int opcode, XMMRegister dst, XMMRegister src, int vector_len, Register scr) {\n+void C2_MacroAssembler::vabsnegd(int opcode, XMMRegister dst, XMMRegister src, int vector_len) {\n@@ -984,1 +984,1 @@\n-    vandpd(dst, src, ExternalAddress(StubRoutines::x86::vector_double_sign_mask()), vector_len, scr);\n+    vandpd(dst, src, ExternalAddress(StubRoutines::x86::vector_double_sign_mask()), vector_len, noreg);\n@@ -987,1 +987,1 @@\n-    vxorpd(dst, src, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), vector_len, scr);\n+    vxorpd(dst, src, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), vector_len, noreg);\n@@ -991,1 +991,1 @@\n-void C2_MacroAssembler::vabsnegf(int opcode, XMMRegister dst, XMMRegister src, Register scr) {\n+void C2_MacroAssembler::vabsnegf(int opcode, XMMRegister dst, XMMRegister src) {\n@@ -996,1 +996,1 @@\n-    andps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_mask()), scr);\n+    andps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_mask()), noreg);\n@@ -999,1 +999,1 @@\n-    xorps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), scr);\n+    xorps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), noreg);\n@@ -1003,1 +1003,1 @@\n-void C2_MacroAssembler::vabsnegf(int opcode, XMMRegister dst, XMMRegister src, int vector_len, Register scr) {\n+void C2_MacroAssembler::vabsnegf(int opcode, XMMRegister dst, XMMRegister src, int vector_len) {\n@@ -1005,1 +1005,1 @@\n-    vandps(dst, src, ExternalAddress(StubRoutines::x86::vector_float_sign_mask()), vector_len, scr);\n+    vandps(dst, src, ExternalAddress(StubRoutines::x86::vector_float_sign_mask()), vector_len, noreg);\n@@ -1008,1 +1008,1 @@\n-    vxorps(dst, src, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), vector_len, scr);\n+    vxorps(dst, src, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), vector_len, noreg);\n@@ -1181,3 +1181,1 @@\n-void C2_MacroAssembler::signum_fp(int opcode, XMMRegister dst,\n-                                  XMMRegister zero, XMMRegister one,\n-                                  Register scratch) {\n+void C2_MacroAssembler::signum_fp(int opcode, XMMRegister dst, XMMRegister zero, XMMRegister one) {\n@@ -1195,1 +1193,1 @@\n-    xorps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), scratch);\n+    xorps(dst, ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), noreg);\n@@ -1203,1 +1201,1 @@\n-    xorpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), scratch);\n+    xorpd(dst, ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), noreg);\n@@ -1462,1 +1460,1 @@\n-void C2_MacroAssembler::varshiftbw(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp, Register scratch) {\n+void C2_MacroAssembler::varshiftbw(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp) {\n@@ -1471,1 +1469,1 @@\n-  vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_int_to_byte_mask()), 1, scratch);\n+  vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_int_to_byte_mask()), 1, noreg);\n@@ -1477,1 +1475,1 @@\n-void C2_MacroAssembler::evarshiftb(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp, Register scratch) {\n+void C2_MacroAssembler::evarshiftb(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp) {\n@@ -1486,1 +1484,1 @@\n-  vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), ext_vector_len, scratch);\n+  vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_short_to_byte_mask()), ext_vector_len, noreg);\n@@ -1631,2 +1629,1 @@\n-void C2_MacroAssembler::load_vector_mask(KRegister dst, XMMRegister src, XMMRegister xtmp,\n-                                         Register tmp, bool novlbwdq, int vlen_enc) {\n+void C2_MacroAssembler::load_vector_mask(KRegister dst, XMMRegister src, XMMRegister xtmp, bool novlbwdq, int vlen_enc) {\n@@ -1636,1 +1633,1 @@\n-            Assembler::eq, true, vlen_enc, tmp);\n+            Assembler::eq, true, vlen_enc, noreg);\n@@ -1696,1 +1693,1 @@\n-void C2_MacroAssembler::load_iota_indices(XMMRegister dst, Register scratch, int vlen_in_bytes) {\n+void C2_MacroAssembler::load_iota_indices(XMMRegister dst, int vlen_in_bytes) {\n@@ -1703,1 +1700,1 @@\n-    movdqu(dst, addr, scratch);\n+    movdqu(dst, addr, noreg);\n@@ -1705,1 +1702,1 @@\n-    vmovdqu(dst, addr, scratch);\n+    vmovdqu(dst, addr, noreg);\n@@ -1708,1 +1705,1 @@\n-    evmovdqub(dst, k0, addr, false \/*merge*\/, Assembler::AVX_512bit, scratch);\n+    evmovdqub(dst, k0, addr, false \/*merge*\/, Assembler::AVX_512bit, noreg);\n@@ -2340,1 +2337,1 @@\n-void C2_MacroAssembler::get_elem(BasicType typ, XMMRegister dst, XMMRegister src, int elemindex, Register tmp, XMMRegister vtmp) {\n+void C2_MacroAssembler::get_elem(BasicType typ, XMMRegister dst, XMMRegister src, int elemindex, XMMRegister vtmp) {\n@@ -2369,2 +2366,2 @@\n-      assert((vtmp != xnoreg) && (tmp != noreg), \"required.\");\n-      movdqu(vtmp, ExternalAddress(StubRoutines::x86::vector_32_bit_mask()), tmp);\n+      assert(vtmp != xnoreg, \"required.\");\n+      movdqu(vtmp, ExternalAddress(StubRoutines::x86::vector_32_bit_mask()), noreg);\n@@ -2373,2 +2370,1 @@\n-      assert((tmp != noreg), \"required.\");\n-      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_32_bit_mask()), Assembler::AVX_128bit, tmp);\n+      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_32_bit_mask()), Assembler::AVX_128bit, noreg);\n@@ -2403,1 +2399,3 @@\n-void C2_MacroAssembler::evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral adr, int comparison, int vector_len, Register scratch) {\n+void C2_MacroAssembler::evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral adr, int comparison, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(adr), \"missing\");\n+\n@@ -2407,1 +2405,1 @@\n-      evpcmpb(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, scratch);\n+      evpcmpb(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -2411,1 +2409,1 @@\n-      evpcmpw(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, scratch);\n+      evpcmpw(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -2415,1 +2413,1 @@\n-      evpcmpd(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, scratch);\n+      evpcmpd(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -2419,1 +2417,1 @@\n-      evpcmpq(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, scratch);\n+      evpcmpq(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -4368,1 +4366,1 @@\n-  vmovdqu(xtmp1, float_sign_flip, scratch, vec_enc);\n+  vmovdqu(xtmp1, float_sign_flip, vec_enc, scratch);\n@@ -4973,1 +4971,1 @@\n-  vmovdqu(xtmp2, ExternalAddress(StubRoutines::x86::vector_popcount_lut()), rtmp, vec_enc);\n+  vmovdqu(xtmp2, ExternalAddress(StubRoutines::x86::vector_popcount_lut()), vec_enc, noreg);\n@@ -5078,1 +5076,1 @@\n-    vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_reverse_bit_lut()), rtmp, vec_enc);\n+    vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_reverse_bit_lut()), vec_enc, noreg);\n@@ -5092,1 +5090,1 @@\n-    vector_reverse_byte(bt, dst, xtmp2, rtmp, vec_enc);\n+    vector_reverse_byte(bt, dst, xtmp2, vec_enc);\n@@ -5111,1 +5109,1 @@\n-    vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_reverse_bit_lut()), rtmp, vec_enc);\n+    vmovdqu(xtmp1, ExternalAddress(StubRoutines::x86::vector_reverse_bit_lut()), vec_enc, rtmp);\n@@ -5127,1 +5125,1 @@\n-    vector_reverse_byte(bt, dst, xtmp2, rtmp, vec_enc);\n+    vector_reverse_byte(bt, dst, xtmp2, vec_enc);\n@@ -5138,1 +5136,1 @@\n-  vector_reverse_byte(bt, dst, xtmp, rtmp, vec_enc);\n+  vector_reverse_byte(bt, dst, xtmp, vec_enc);\n@@ -5181,1 +5179,1 @@\n-void C2_MacroAssembler::vector_reverse_byte(BasicType bt, XMMRegister dst, XMMRegister src, Register rtmp, int vec_enc) {\n+void C2_MacroAssembler::vector_reverse_byte(BasicType bt, XMMRegister dst, XMMRegister src, int vec_enc) {\n@@ -5194,1 +5192,1 @@\n-      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_long()), rtmp, vec_enc);\n+      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_long()), vec_enc, noreg);\n@@ -5197,1 +5195,1 @@\n-      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_int()), rtmp, vec_enc);\n+      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_int()), vec_enc, noreg);\n@@ -5201,1 +5199,1 @@\n-      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_short()), rtmp, vec_enc);\n+      vmovdqu(dst, ExternalAddress(StubRoutines::x86::vector_reverse_byte_perm_mask_short()), vec_enc, noreg);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":48,"deletions":50,"binary":false,"changes":98,"status":"modified"},{"patch":"@@ -73,4 +73,4 @@\n-  void vabsnegd(int opcode, XMMRegister dst, XMMRegister src, Register scr);\n-  void vabsnegd(int opcode, XMMRegister dst, XMMRegister src, int vector_len, Register scr);\n-  void vabsnegf(int opcode, XMMRegister dst, XMMRegister src, Register scr);\n-  void vabsnegf(int opcode, XMMRegister dst, XMMRegister src, int vector_len, Register scr);\n+  void vabsnegd(int opcode, XMMRegister dst, XMMRegister src);\n+  void vabsnegd(int opcode, XMMRegister dst, XMMRegister src, int vector_len);\n+  void vabsnegf(int opcode, XMMRegister dst, XMMRegister src);\n+  void vabsnegf(int opcode, XMMRegister dst, XMMRegister src, int vector_len);\n@@ -93,3 +93,1 @@\n-  void signum_fp(int opcode, XMMRegister dst,\n-                 XMMRegister zero, XMMRegister one,\n-                 Register scratch);\n+  void signum_fp(int opcode, XMMRegister dst, XMMRegister zero, XMMRegister one);\n@@ -124,2 +122,2 @@\n-  void varshiftbw(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp, Register scratch);\n-  void evarshiftb(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp, Register scratch);\n+  void varshiftbw(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp);\n+  void evarshiftb(int opcode, XMMRegister dst, XMMRegister src, XMMRegister shift, int vector_len, XMMRegister vtmp);\n@@ -140,1 +138,1 @@\n-  void get_elem(BasicType typ, XMMRegister dst, XMMRegister src, int elemindex, Register tmp = noreg, XMMRegister vtmp = xnoreg);\n+  void get_elem(BasicType typ, XMMRegister dst, XMMRegister src, int elemindex, XMMRegister vtmp = xnoreg);\n@@ -153,1 +151,1 @@\n-  void evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral adr, int comparison, int vector_len, Register scratch = rscratch1);\n+  void evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral adr, int comparison, int vector_len, Register rscratch = rscratch1);\n@@ -158,1 +156,1 @@\n-  void load_vector_mask(KRegister dst, XMMRegister src, XMMRegister xtmp, Register tmp, bool novlbwdq, int vlen_enc);\n+  void load_vector_mask(KRegister dst, XMMRegister src, XMMRegister xtmp, bool novlbwdq, int vlen_enc);\n@@ -163,1 +161,1 @@\n-  void load_iota_indices(XMMRegister dst, Register scratch, int vlen_in_bytes);\n+  void load_iota_indices(XMMRegister dst, int vlen_in_bytes);\n@@ -393,1 +391,1 @@\n-  void vector_reverse_byte(BasicType bt, XMMRegister dst, XMMRegister src, Register rtmp, int vec_enc);\n+  void vector_reverse_byte(BasicType bt, XMMRegister dst, XMMRegister src, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":12,"deletions":14,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -313,3 +313,1 @@\n-void MacroAssembler::movptr(Register dst, AddressLiteral src, Register scratch) {\n-  \/\/ scratch register is not used,\n-  \/\/ it is defined to match parameters of 64-bit version of this method.\n+void MacroAssembler::movptr(Register dst, AddressLiteral src) {\n@@ -523,1 +521,1 @@\n-void MacroAssembler::cmp64(Register src1, AddressLiteral src2) {\n+void MacroAssembler::cmp64(Register src1, AddressLiteral src2, Register rscratch) {\n@@ -525,0 +523,1 @@\n+  assert(rscratch != noreg || always_reachable(src2),  \"missing\");\n@@ -664,1 +663,1 @@\n-void MacroAssembler::movptr(Register dst, AddressLiteral src, Register scratch) {\n+void MacroAssembler::movptr(Register dst, AddressLiteral src) {\n@@ -671,2 +670,2 @@\n-      lea(scratch, src);\n-      movq(dst, Address(scratch, 0));\n+      lea(dst, src);\n+      movq(dst, Address(dst, 0));\n@@ -1129,1 +1128,3 @@\n-void MacroAssembler::addsd(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::addsd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -1133,2 +1134,2 @@\n-    lea(rscratch1, src);\n-    Assembler::addsd(dst, Address(rscratch1, 0));\n+    lea(rscratch, src);\n+    Assembler::addsd(dst, Address(rscratch, 0));\n@@ -1138,1 +1139,3 @@\n-void MacroAssembler::addss(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::addss(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -1142,2 +1145,2 @@\n-    lea(rscratch1, src);\n-    addss(dst, Address(rscratch1, 0));\n+    lea(rscratch, src);\n+    addss(dst, Address(rscratch, 0));\n@@ -1147,1 +1150,3 @@\n-void MacroAssembler::addpd(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::addpd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -2131,1 +2136,2 @@\n-void MacroAssembler::mulpd(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::mulpd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n@@ -2476,1 +2482,2 @@\n-void MacroAssembler::movdl(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::movdl(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n@@ -2485,1 +2492,2 @@\n-void MacroAssembler::movq(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::movq(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n@@ -2538,2 +2546,2 @@\n-    assert(((src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n-    Assembler::movdqu(dst, src);\n+  assert(((src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n+  Assembler::movdqu(dst, src);\n@@ -2543,2 +2551,2 @@\n-    assert(((dst->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n-    Assembler::movdqu(dst, src);\n+  assert(((dst->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n+  Assembler::movdqu(dst, src);\n@@ -2548,2 +2556,2 @@\n-    assert(((dst->encoding() < 16  && src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n-    Assembler::movdqu(dst, src);\n+  assert(((dst->encoding() < 16  && src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n+  Assembler::movdqu(dst, src);\n@@ -2552,1 +2560,3 @@\n-void MacroAssembler::movdqu(XMMRegister dst, AddressLiteral src, Register scratchReg) {\n+void MacroAssembler::movdqu(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -2556,2 +2566,2 @@\n-    lea(scratchReg, src);\n-    movdqu(dst, Address(scratchReg, 0));\n+    lea(rscratch, src);\n+    movdqu(dst, Address(rscratch, 0));\n@@ -2562,2 +2572,2 @@\n-    assert(((src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n-    Assembler::vmovdqu(dst, src);\n+  assert(((src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n+  Assembler::vmovdqu(dst, src);\n@@ -2567,2 +2577,2 @@\n-    assert(((dst->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n-    Assembler::vmovdqu(dst, src);\n+  assert(((dst->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n+  Assembler::vmovdqu(dst, src);\n@@ -2572,2 +2582,2 @@\n-    assert(((dst->encoding() < 16  && src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n-    Assembler::vmovdqu(dst, src);\n+  assert(((dst->encoding() < 16  && src->encoding() < 16) || VM_Version::supports_avx512vl()),\"XMM register should be 0-15\");\n+  Assembler::vmovdqu(dst, src);\n@@ -2576,1 +2586,3 @@\n-void MacroAssembler::vmovdqu(XMMRegister dst, AddressLiteral src, Register scratch_reg) {\n+void MacroAssembler::vmovdqu(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -2581,2 +2593,2 @@\n-    lea(scratch_reg, src);\n-    vmovdqu(dst, Address(scratch_reg, 0));\n+    lea(rscratch, src);\n+    vmovdqu(dst, Address(rscratch, 0));\n@@ -2586,1 +2598,3 @@\n-void MacroAssembler::vmovdqu(XMMRegister dst, AddressLiteral src, Register scratch_reg, int vector_len) {\n+void MacroAssembler::vmovdqu(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -2588,1 +2602,1 @@\n-    evmovdquq(dst, src, AVX_512bit, scratch_reg);\n+    evmovdquq(dst, src, AVX_512bit, rscratch);\n@@ -2590,1 +2604,1 @@\n-    vmovdqu(dst, src, scratch_reg);\n+    vmovdqu(dst, src, rscratch);\n@@ -2592,1 +2606,1 @@\n-    movdqu(dst, src, scratch_reg);\n+    movdqu(dst, src, rscratch);\n@@ -2650,1 +2664,3 @@\n-void MacroAssembler::kmovwl(KRegister dst, AddressLiteral src, Register scratch_reg) {\n+void MacroAssembler::kmovwl(KRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -2654,2 +2670,2 @@\n-    lea(scratch_reg, src);\n-    kmovwl(dst, Address(scratch_reg, 0));\n+    lea(rscratch, src);\n+    kmovwl(dst, Address(rscratch, 0));\n@@ -2679,2 +2695,3 @@\n-void MacroAssembler::evmovdqul(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge,\n-                               int vector_len, Register scratch_reg) {\n+void MacroAssembler::evmovdqul(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -2684,2 +2701,2 @@\n-    lea(scratch_reg, src);\n-    Assembler::evmovdqul(dst, mask, Address(scratch_reg, 0), merge, vector_len);\n+    lea(rscratch, src);\n+    Assembler::evmovdqul(dst, mask, Address(rscratch, 0), merge, vector_len);\n@@ -2689,2 +2706,3 @@\n-void MacroAssembler::evmovdquq(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge,\n-                               int vector_len, Register scratch_reg) {\n+void MacroAssembler::evmovdquq(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -2694,2 +2712,2 @@\n-    lea(scratch_reg, src);\n-    Assembler::evmovdquq(dst, mask, Address(scratch_reg, 0), merge, vector_len);\n+    lea(rscratch, src);\n+    Assembler::evmovdquq(dst, mask, Address(rscratch, 0), merge, vector_len);\n@@ -2700,0 +2718,2 @@\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -2717,1 +2737,3 @@\n-void MacroAssembler::movsd(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::movsd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -2721,2 +2743,2 @@\n-    lea(rscratch1, src);\n-    Assembler::movsd(dst, Address(rscratch1, 0));\n+    lea(rscratch, src);\n+    Assembler::movsd(dst, Address(rscratch, 0));\n@@ -2753,1 +2775,3 @@\n-void MacroAssembler::mulsd(XMMRegister dst, AddressLiteral src) {\n+void MacroAssembler::mulsd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -3134,1 +3158,3 @@\n-void MacroAssembler::roundsd(XMMRegister dst, AddressLiteral src, int32_t rmode, Register scratch_reg) {\n+void MacroAssembler::roundsd(XMMRegister dst, AddressLiteral src, int32_t rmode, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -3138,2 +3164,2 @@\n-    lea(scratch_reg, src);\n-    Assembler::roundsd(dst, Address(scratch_reg, 0), rmode);\n+    lea(rscratch, src);\n+    Assembler::roundsd(dst, Address(rscratch, 0), rmode);\n@@ -3170,1 +3196,3 @@\n-void MacroAssembler::xorpd(XMMRegister dst, AddressLiteral src, Register scratch_reg) {\n+void MacroAssembler::xorpd(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -3176,2 +3204,2 @@\n-    lea(scratch_reg, src);\n-    Assembler::xorpd(dst, Address(scratch_reg, 0));\n+    lea(rscratch, src);\n+    Assembler::xorpd(dst, Address(rscratch, 0));\n@@ -3198,1 +3226,3 @@\n-void MacroAssembler::xorps(XMMRegister dst, AddressLiteral src, Register scratch_reg) {\n+void MacroAssembler::xorps(XMMRegister dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -3204,2 +3234,2 @@\n-    lea(scratch_reg, src);\n-    Assembler::xorps(dst, Address(scratch_reg, 0));\n+    lea(rscratch, src);\n+    Assembler::xorps(dst, Address(rscratch, 0));\n@@ -3243,0 +3273,2 @@\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -3253,0 +3285,2 @@\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n@@ -3291,1 +3325,3 @@\n-void MacroAssembler::vpand(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register scratch_reg) {\n+void MacroAssembler::vpand(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src),  \"missing\");\n+\n@@ -3295,2 +3331,2 @@\n-    lea(scratch_reg, src);\n-    Assembler::vpand(dst, nds, Address(scratch_reg, 0), vector_len);\n+    lea(rscratch, src);\n+    Assembler::vpand(dst, nds, Address(rscratch, 0), vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":102,"deletions":66,"binary":false,"changes":168,"status":"modified"},{"patch":"@@ -765,1 +765,1 @@\n-  void cmp64(Register src1, AddressLiteral src);\n+  void cmp64(Register src1, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1029,0 +1029,23 @@\n+ private:\n+  \/\/ Initialized in macroAssembler_x86_constants.cpp\n+  static address ONE;\n+  static address ONEHALF;\n+  static address SIGN_MASK;\n+  static address TWO_POW_55;\n+  static address TWO_POW_M55;\n+  static address SHIFTER;\n+  static address ZERO;\n+  static address NEG_ZERO;\n+  static address PI32INV;\n+  static address PI_INV_TABLE;\n+  static address Ctable;\n+  static address SC_1;\n+  static address SC_2;\n+  static address SC_3;\n+  static address SC_4;\n+  static address PI_4;\n+  static address P_1;\n+  static address P_3;\n+  static address P_2;\n+\n+ public:\n@@ -1035,1 +1058,1 @@\n-                  Register rax, Register rcx, Register rdx, Register r11);\n+                  Register rax, Register rcx, Register rdx, Register r11, Register tmp);\n@@ -1043,2 +1066,1 @@\n-                Register rax, Register rbx, Register rcx, Register rdx, Register tmp1, Register tmp2,\n-                Register tmp3, Register tmp4);\n+                Register rax, Register rbx, Register rcx, Register rdx, Register tmp1);\n@@ -1048,2 +1070,3 @@\n-                Register rax, Register rcx, Register rdx, Register tmp1,\n-                Register tmp2, Register tmp3, Register tmp4);\n+                Register rax, Register rcx, Register rdx, Register r8,\n+                Register  r9, Register r10, Register r11, Register tmp);\n+\n@@ -1052,2 +1075,3 @@\n-                Register rax, Register rcx, Register rdx, Register tmp1,\n-                Register tmp2, Register tmp3, Register tmp4);\n+                Register rax, Register rcx, Register rdx, Register r8,\n+                Register  r9, Register r10, Register r11, Register tmp);\n+\n@@ -1055,0 +1079,9 @@\n+ private:\n+  \/\/ Initialized in macroAssembler_x86_constants.cpp\n+  static address ONES;\n+  static address L_2IL0FLOATPACKET_0;\n+  static address PI4_INV;\n+  static address PI4X3;\n+  static address PI4X4;\n+\n+ public:\n@@ -1105,3 +1138,3 @@\n-  void addsd(XMMRegister dst, XMMRegister src)    { Assembler::addsd(dst, src); }\n-  void addsd(XMMRegister dst, Address src)        { Assembler::addsd(dst, src); }\n-  void addsd(XMMRegister dst, AddressLiteral src);\n+  void addsd(XMMRegister dst, XMMRegister    src) { Assembler::addsd(dst, src); }\n+  void addsd(XMMRegister dst, Address        src) { Assembler::addsd(dst, src); }\n+  void addsd(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1109,3 +1142,3 @@\n-  void addss(XMMRegister dst, XMMRegister src)    { Assembler::addss(dst, src); }\n-  void addss(XMMRegister dst, Address src)        { Assembler::addss(dst, src); }\n-  void addss(XMMRegister dst, AddressLiteral src);\n+  void addss(XMMRegister dst, XMMRegister    src) { Assembler::addss(dst, src); }\n+  void addss(XMMRegister dst, Address        src) { Assembler::addss(dst, src); }\n+  void addss(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1113,3 +1146,3 @@\n-  void addpd(XMMRegister dst, XMMRegister src)    { Assembler::addpd(dst, src); }\n-  void addpd(XMMRegister dst, Address src)        { Assembler::addpd(dst, src); }\n-  void addpd(XMMRegister dst, AddressLiteral src);\n+  void addpd(XMMRegister dst, XMMRegister    src) { Assembler::addpd(dst, src); }\n+  void addpd(XMMRegister dst, Address        src) { Assembler::addpd(dst, src); }\n+  void addpd(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1132,11 +1165,11 @@\n-  void movdqu(Address     dst, XMMRegister src);\n-  void movdqu(XMMRegister dst, Address src);\n-  void movdqu(XMMRegister dst, XMMRegister src);\n-  void movdqu(XMMRegister dst, AddressLiteral src, Register scratchReg = rscratch1);\n-\n-  void kmovwl(KRegister dst, Register src) { Assembler::kmovwl(dst, src); }\n-  void kmovwl(Register dst, KRegister src) { Assembler::kmovwl(dst, src); }\n-  void kmovwl(KRegister dst, Address src) { Assembler::kmovwl(dst, src); }\n-  void kmovwl(KRegister dst, AddressLiteral src, Register scratch_reg = rscratch1);\n-  void kmovwl(Address dst,  KRegister src) { Assembler::kmovwl(dst, src); }\n-  void kmovwl(KRegister dst, KRegister src) { Assembler::kmovwl(dst, src); }\n+  void movdqu(Address     dst, XMMRegister    src);\n+  void movdqu(XMMRegister dst, XMMRegister    src);\n+  void movdqu(XMMRegister dst, Address        src);\n+  void movdqu(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n+\n+  void kmovwl(Register  dst, KRegister      src) { Assembler::kmovwl(dst, src); }\n+  void kmovwl(Address   dst, KRegister      src) { Assembler::kmovwl(dst, src); }\n+  void kmovwl(KRegister dst, KRegister      src) { Assembler::kmovwl(dst, src); }\n+  void kmovwl(KRegister dst, Register       src) { Assembler::kmovwl(dst, src); }\n+  void kmovwl(KRegister dst, Address        src) { Assembler::kmovwl(dst, src); }\n+  void kmovwl(KRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1165,5 +1198,5 @@\n-  void vmovdqu(Address     dst, XMMRegister src);\n-  void vmovdqu(XMMRegister dst, Address src);\n-  void vmovdqu(XMMRegister dst, XMMRegister src);\n-  void vmovdqu(XMMRegister dst, AddressLiteral src, Register scratch_reg = rscratch1);\n-  void vmovdqu(XMMRegister dst, AddressLiteral src, Register scratch_reg, int vector_len);\n+  void vmovdqu(Address     dst, XMMRegister    src);\n+  void vmovdqu(XMMRegister dst, Address        src);\n+  void vmovdqu(XMMRegister dst, XMMRegister    src);\n+  void vmovdqu(XMMRegister dst, AddressLiteral src,                 Register rscratch = rscratch1);\n+  void vmovdqu(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch = rscratch1);\n@@ -1172,2 +1205,2 @@\n-  void evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src,  bool merge, int vector_len);\n-  void evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, bool merge, int vector_len);\n+  void evmovdqu(BasicType type, KRegister kmask, Address     dst, XMMRegister src, bool merge, int vector_len);\n+  void evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address     src, bool merge, int vector_len);\n@@ -1176,1 +1209,2 @@\n-  void evmovdqub(XMMRegister dst, Address src, int vector_len) { Assembler::evmovdqub(dst, src, vector_len); }\n+  void evmovdqub(XMMRegister dst, Address     src, int vector_len) { Assembler::evmovdqub(dst, src, vector_len); }\n+\n@@ -1210,3 +1244,3 @@\n-  void evmovdqul(XMMRegister dst, KRegister mask, Address src, bool merge, int vector_len) { Assembler::evmovdqul(dst, mask, src, merge, vector_len); }\n-  void evmovdqul(Address dst, KRegister mask, XMMRegister src, bool merge, int vector_len) { Assembler::evmovdqul(dst, mask, src, merge, vector_len); }\n-  void evmovdqul(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge, int vector_len, Register scratch_reg);\n+  void evmovdqul(Address     dst, KRegister mask, XMMRegister    src, bool merge, int vector_len) { Assembler::evmovdqul(dst, mask, src, merge, vector_len); }\n+  void evmovdqul(XMMRegister dst, KRegister mask, Address        src, bool merge, int vector_len) { Assembler::evmovdqul(dst, mask, src, merge, vector_len); }\n+  void evmovdqul(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge, int vector_len, Register rscratch);\n@@ -1219,3 +1253,3 @@\n-  void evmovdquq(XMMRegister dst, Address src, int vector_len) { Assembler::evmovdquq(dst, src, vector_len); }\n-  void evmovdquq(Address dst, XMMRegister src, int vector_len) { Assembler::evmovdquq(dst, src, vector_len); }\n-  void evmovdquq(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch);\n+  void evmovdquq(XMMRegister dst, Address        src, int vector_len) { Assembler::evmovdquq(dst, src, vector_len); }\n+  void evmovdquq(Address     dst, XMMRegister    src, int vector_len) { Assembler::evmovdquq(dst, src, vector_len); }\n+  void evmovdquq(XMMRegister dst, AddressLiteral src, int vector_len, Register rscratch = noreg);\n@@ -1228,3 +1262,3 @@\n-  void evmovdquq(XMMRegister dst, KRegister mask, Address src, bool merge, int vector_len) { Assembler::evmovdquq(dst, mask, src, merge, vector_len); }\n-  void evmovdquq(Address dst, KRegister mask, XMMRegister src, bool merge, int vector_len) { Assembler::evmovdquq(dst, mask, src, merge, vector_len); }\n-  void evmovdquq(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge, int vector_len, Register scratch_reg);\n+  void evmovdquq(Address     dst, KRegister mask, XMMRegister    src, bool merge, int vector_len) { Assembler::evmovdquq(dst, mask, src, merge, vector_len); }\n+  void evmovdquq(XMMRegister dst, KRegister mask, Address        src, bool merge, int vector_len) { Assembler::evmovdquq(dst, mask, src, merge, vector_len); }\n+  void evmovdquq(XMMRegister dst, KRegister mask, AddressLiteral src, bool merge, int vector_len, Register rscratch = noreg);\n@@ -1237,4 +1271,4 @@\n-  void movsd(XMMRegister dst, XMMRegister src) { Assembler::movsd(dst, src); }\n-  void movsd(Address dst, XMMRegister src)     { Assembler::movsd(dst, src); }\n-  void movsd(XMMRegister dst, Address src)     { Assembler::movsd(dst, src); }\n-  void movsd(XMMRegister dst, AddressLiteral src);\n+  void movsd(Address     dst, XMMRegister    src) { Assembler::movsd(dst, src); }\n+  void movsd(XMMRegister dst, XMMRegister    src) { Assembler::movsd(dst, src); }\n+  void movsd(XMMRegister dst, Address        src)     { Assembler::movsd(dst, src); }\n+  void movsd(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1242,3 +1276,3 @@\n-  void mulpd(XMMRegister dst, XMMRegister src)    { Assembler::mulpd(dst, src); }\n-  void mulpd(XMMRegister dst, Address src)        { Assembler::mulpd(dst, src); }\n-  void mulpd(XMMRegister dst, AddressLiteral src);\n+  void mulpd(XMMRegister dst, XMMRegister    src) { Assembler::mulpd(dst, src); }\n+  void mulpd(XMMRegister dst, Address        src) { Assembler::mulpd(dst, src); }\n+  void mulpd(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1246,3 +1280,3 @@\n-  void mulsd(XMMRegister dst, XMMRegister src)    { Assembler::mulsd(dst, src); }\n-  void mulsd(XMMRegister dst, Address src)        { Assembler::mulsd(dst, src); }\n-  void mulsd(XMMRegister dst, AddressLiteral src);\n+  void mulsd(XMMRegister dst, XMMRegister    src) { Assembler::mulsd(dst, src); }\n+  void mulsd(XMMRegister dst, Address        src) { Assembler::mulsd(dst, src); }\n+  void mulsd(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1281,3 +1315,3 @@\n-  void roundsd(XMMRegister dst, XMMRegister src, int32_t rmode)    { Assembler::roundsd(dst, src, rmode); }\n-  void roundsd(XMMRegister dst, Address src, int32_t rmode)        { Assembler::roundsd(dst, src, rmode); }\n-  void roundsd(XMMRegister dst, AddressLiteral src, int32_t rmode, Register scratch_reg);\n+  void roundsd(XMMRegister dst, XMMRegister    src, int32_t rmode) { Assembler::roundsd(dst, src, rmode); }\n+  void roundsd(XMMRegister dst, Address        src, int32_t rmode) { Assembler::roundsd(dst, src, rmode); }\n+  void roundsd(XMMRegister dst, AddressLiteral src, int32_t rmode, Register rscratch);\n@@ -1306,3 +1340,3 @@\n-  void xorpd(XMMRegister dst, XMMRegister src);\n-  void xorpd(XMMRegister dst, Address src)     { Assembler::xorpd(dst, src); }\n-  void xorpd(XMMRegister dst, AddressLiteral src, Register scratch_reg = rscratch1);\n+  void xorpd(XMMRegister dst, XMMRegister    src);\n+  void xorpd(XMMRegister dst, Address        src) { Assembler::xorpd(dst, src); }\n+  void xorpd(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1311,3 +1345,3 @@\n-  void xorps(XMMRegister dst, XMMRegister src);\n-  void xorps(XMMRegister dst, Address src)     { Assembler::xorps(dst, src); }\n-  void xorps(XMMRegister dst, AddressLiteral src, Register scratch_reg = rscratch1);\n+  void xorps(XMMRegister dst, XMMRegister    src);\n+  void xorps(XMMRegister dst, Address        src) { Assembler::xorps(dst, src); }\n+  void xorps(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n@@ -1332,2 +1366,2 @@\n-  void vpaddb(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n-  void vpaddb(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n+  void vpaddb(XMMRegister dst, XMMRegister nds, XMMRegister    src, int vector_len);\n+  void vpaddb(XMMRegister dst, XMMRegister nds, Address        src, int vector_len);\n@@ -1339,3 +1373,3 @@\n-  void vpaddd(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) { Assembler::vpaddd(dst, nds, src, vector_len); }\n-  void vpaddd(XMMRegister dst, XMMRegister nds, Address src, int vector_len) { Assembler::vpaddd(dst, nds, src, vector_len); }\n-  void vpaddd(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch);\n+  void vpaddd(XMMRegister dst, XMMRegister nds, XMMRegister    src, int vector_len) { Assembler::vpaddd(dst, nds, src, vector_len); }\n+  void vpaddd(XMMRegister dst, XMMRegister nds, Address        src, int vector_len) { Assembler::vpaddd(dst, nds, src, vector_len); }\n+  void vpaddd(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch = noreg);\n@@ -1343,3 +1377,3 @@\n-  void vpand(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) { Assembler::vpand(dst, nds, src, vector_len); }\n-  void vpand(XMMRegister dst, XMMRegister nds, Address src, int vector_len) { Assembler::vpand(dst, nds, src, vector_len); }\n-  void vpand(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register scratch_reg = rscratch1);\n+  void vpand(XMMRegister dst, XMMRegister nds, XMMRegister    src, int vector_len) { Assembler::vpand(dst, nds, src, vector_len); }\n+  void vpand(XMMRegister dst, XMMRegister nds, Address        src, int vector_len) { Assembler::vpand(dst, nds, src, vector_len); }\n+  void vpand(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch = rscratch1);\n@@ -1815,17 +1849,8 @@\n-  void movptr(ArrayAddress dst, Register src);\n-  \/\/ can this do an lea?\n-  void movptr(Register dst, ArrayAddress src);\n-\n-  void movptr(Register dst, Address src);\n-\n-#ifdef _LP64\n-  void movptr(Register dst, AddressLiteral src, Register scratch=rscratch1);\n-#else\n-  void movptr(Register dst, AddressLiteral src, Register scratch=noreg); \/\/ Scratch reg is ignored in 32-bit\n-#endif\n-\n-  void movptr(Register dst, intptr_t src);\n-  void movptr(Register dst, Register src);\n-  void movptr(Address dst, intptr_t src);\n-\n-  void movptr(Address dst, Register src);\n+  void movptr(Register     dst, Register       src);\n+  void movptr(Register     dst, Address        src);\n+  void movptr(Register     dst, AddressLiteral src);\n+  void movptr(Register     dst, ArrayAddress   src);\n+  void movptr(Register     dst, intptr_t       src);\n+  void movptr(Address      dst, Register       src);\n+  void movptr(Address      dst, intptr_t       src);\n+  void movptr(ArrayAddress dst, Register       src);\n@@ -1861,2 +1886,2 @@\n-  void movdl(XMMRegister dst, AddressLiteral src);\n-  void movq(XMMRegister dst, AddressLiteral src);\n+  void movdl(XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n+  void movq (XMMRegister dst, AddressLiteral src, Register rscratch = rscratch1);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":116,"deletions":91,"binary":false,"changes":207,"status":"modified"},{"patch":"@@ -0,0 +1,265 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"macroAssembler_x86.hpp\"\n+\n+#ifdef _LP64\n+\n+ATTRIBUTE_ALIGNED(8) juint _ONE[] = {\n+    0x00000000UL, 0x3ff00000UL\n+};\n+address MacroAssembler::ONE = (address)_ONE;\n+\n+ATTRIBUTE_ALIGNED(16) juint _ONEHALF[] = {\n+    0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+};\n+address MacroAssembler::ONEHALF = (address)_ONEHALF;\n+\n+ATTRIBUTE_ALIGNED(8) juint _SIGN_MASK[] = {\n+    0x00000000UL, 0x80000000UL\n+};\n+address MacroAssembler::SIGN_MASK = (address)_SIGN_MASK;\n+\n+ATTRIBUTE_ALIGNED(8) juint _TWO_POW_55[] = {\n+    0x00000000UL, 0x43600000UL\n+};\n+address MacroAssembler::TWO_POW_55 = (address)_TWO_POW_55;\n+\n+ATTRIBUTE_ALIGNED(8) juint _TWO_POW_M55[] = {\n+    0x00000000UL, 0x3c800000UL\n+};\n+address MacroAssembler::TWO_POW_M55 = (address)_TWO_POW_M55;\n+\n+ATTRIBUTE_ALIGNED(16) juint _SHIFTER[] = {\n+    0x00000000UL, 0x43380000UL, 0x00000000UL, 0x43380000UL\n+};\n+address MacroAssembler::SHIFTER = (address)_SHIFTER;\n+\n+ATTRIBUTE_ALIGNED(4) juint _ZERO[] = {\n+    0x00000000UL, 0x00000000UL\n+};\n+address MacroAssembler::ZERO = (address)_ZERO;\n+\n+ATTRIBUTE_ALIGNED(16) juint _SC_1[] = {\n+    0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n+};\n+address MacroAssembler::SC_1 = (address)_SC_1;\n+\n+ATTRIBUTE_ALIGNED(16) juint _SC_2[] = {\n+    0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n+};\n+address MacroAssembler::SC_2 = (address)_SC_2;\n+\n+ATTRIBUTE_ALIGNED(16) juint _SC_3[] = {\n+    0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n+};\n+address MacroAssembler::SC_3 = (address)_SC_3;\n+\n+ATTRIBUTE_ALIGNED(16) juint _SC_4[] = {\n+    0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n+};\n+address MacroAssembler::SC_4 = (address)_SC_4;\n+\n+ATTRIBUTE_ALIGNED(8) juint _PI_4[] = {\n+    0x40000000UL, 0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n+};\n+address MacroAssembler::PI_4 = (address)_PI_4;\n+\n+ATTRIBUTE_ALIGNED(8) juint _PI32INV[] = {\n+    0x6dc9c883UL, 0x40245f30UL\n+};\n+address MacroAssembler::PI32INV = (address)_PI32INV;\n+\n+ATTRIBUTE_ALIGNED(8) juint _NEG_ZERO[] = {\n+    0x00000000UL, 0x80000000UL\n+};\n+address MacroAssembler::NEG_ZERO = (address)_NEG_ZERO;\n+\n+ATTRIBUTE_ALIGNED(8) juint _P_1[] = {\n+    0x54400000UL, 0x3fb921fbUL\n+};\n+address MacroAssembler::P_1 = (address)_P_1;\n+\n+ATTRIBUTE_ALIGNED(16) juint _P_2[] = {\n+    0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n+};\n+address MacroAssembler::P_2 = (address)_P_2;\n+\n+ATTRIBUTE_ALIGNED(8) juint _P_3[] = {\n+    0x2e037073UL, 0x3b63198aUL\n+};\n+address MacroAssembler::P_3 = (address)_P_3;\n+\n+\n+ATTRIBUTE_ALIGNED(16) juint _PI_INV_TABLE[] = {\n+    0x00000000UL, 0x00000000UL, 0xa2f9836eUL, 0x4e441529UL, 0xfc2757d1UL,\n+    0xf534ddc0UL, 0xdb629599UL, 0x3c439041UL, 0xfe5163abUL, 0xdebbc561UL,\n+    0xb7246e3aUL, 0x424dd2e0UL, 0x06492eeaUL, 0x09d1921cUL, 0xfe1deb1cUL,\n+    0xb129a73eUL, 0xe88235f5UL, 0x2ebb4484UL, 0xe99c7026UL, 0xb45f7e41UL,\n+    0x3991d639UL, 0x835339f4UL, 0x9c845f8bUL, 0xbdf9283bUL, 0x1ff897ffUL,\n+    0xde05980fUL, 0xef2f118bUL, 0x5a0a6d1fUL, 0x6d367ecfUL, 0x27cb09b7UL,\n+    0x4f463f66UL, 0x9e5fea2dUL, 0x7527bac7UL, 0xebe5f17bUL, 0x3d0739f7UL,\n+    0x8a5292eaUL, 0x6bfb5fb1UL, 0x1f8d5d08UL, 0x56033046UL, 0xfc7b6babUL,\n+    0xf0cfbc21UL\n+};\n+address MacroAssembler::PI_INV_TABLE = (address)_PI_INV_TABLE;\n+\n+\n+ATTRIBUTE_ALIGNED(16) juint _Ctable[] = {\n+    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n+    0x00000000UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL, 0xbf73b92eUL,\n+    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n+    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL,\n+    0xc0000000UL, 0xbc626d19UL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL,\n+    0xbfa60beaUL, 0x2ed59f06UL, 0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL,\n+    0x00000000UL, 0x3ff00000UL, 0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL,\n+    0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL, 0x00000000UL, 0x3ff00000UL,\n+    0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL, 0x20000000UL,\n+    0x3c5e0d89UL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL, 0xbfc59267UL,\n+    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n+    0x3ff00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL,\n+    0x20000000UL, 0x3c68076aUL, 0x00000000UL, 0x3ff00000UL, 0x99fcef32UL,\n+    0x3fca8279UL, 0x667f3bcdUL, 0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL,\n+    0x00000000UL, 0x3fe00000UL, 0x94247758UL, 0x3fc133ccUL, 0x6b151741UL,\n+    0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL, 0x00000000UL, 0x3fe00000UL,\n+    0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL, 0xe0000000UL,\n+    0x3c39f630UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL, 0xbf9d4a2cUL,\n+    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n+    0x3fe00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0x3fed906bUL,\n+    0x20000000UL, 0x3c7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x76acf82dUL,\n+    0x3fa4a031UL, 0x56c62ddaUL, 0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL,\n+    0x00000000UL, 0x3fd00000UL, 0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL,\n+    0x3fef6297UL, 0x20000000UL, 0x3c756217UL, 0x00000000UL, 0x3fd00000UL,\n+    0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL, 0x3fefd88dUL, 0x40000000UL,\n+    0xbc887df6UL, 0x00000000UL, 0x3fc00000UL, 0x00000000UL, 0x00000000UL,\n+    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n+    0x00000000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0x3fefd88dUL,\n+    0x40000000UL, 0xbc887df6UL, 0x00000000UL, 0xbfc00000UL, 0x0e5967d5UL,\n+    0x3fac1d1fUL, 0xcff75cb0UL, 0x3fef6297UL, 0x20000000UL, 0x3c756217UL,\n+    0x00000000UL, 0xbfd00000UL, 0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL,\n+    0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL, 0x00000000UL, 0xbfd00000UL,\n+    0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL, 0x3fed906bUL, 0x20000000UL,\n+    0x3c7457e6UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL, 0x3f9d4a2cUL,\n+    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n+    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL,\n+    0xe0000000UL, 0x3c39f630UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL,\n+    0xbfc133ccUL, 0x6b151741UL, 0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL,\n+    0x00000000UL, 0xbfe00000UL, 0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL,\n+    0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL, 0x00000000UL, 0xbfe00000UL,\n+    0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL, 0x20000000UL,\n+    0x3c68076aUL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL, 0x3fc59267UL,\n+    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n+    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL,\n+    0x20000000UL, 0x3c5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL,\n+    0x3fb37ca1UL, 0xa6aea963UL, 0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL,\n+    0x00000000UL, 0xbff00000UL, 0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL,\n+    0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL, 0x00000000UL, 0xbff00000UL,\n+    0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL, 0xc0000000UL,\n+    0xbc626d19UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL, 0x3f73b92eUL,\n+    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n+    0xbff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n+    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL,\n+    0x3f73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n+    0x00000000UL, 0xbff00000UL, 0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL,\n+    0xbfc8f8b8UL, 0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0xbff00000UL,\n+    0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL,\n+    0x3c75d28dUL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL, 0x3fb37ca1UL,\n+    0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL, 0x3c672cedUL, 0x00000000UL,\n+    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0xbfde2b5dUL,\n+    0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL,\n+    0x3fc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n+    0x00000000UL, 0xbff00000UL, 0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL,\n+    0xbfe44cf3UL, 0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0xbff00000UL,\n+    0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL,\n+    0x3c8bdd34UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL, 0xbfc133ccUL,\n+    0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL, 0x3c82c5e1UL, 0x00000000UL,\n+    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0xbfea9b66UL,\n+    0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL,\n+    0x3f9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n+    0x00000000UL, 0xbfe00000UL, 0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL,\n+    0xbfed906bUL, 0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0xbfe00000UL,\n+    0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL,\n+    0xbc8760b1UL, 0x00000000UL, 0xbfd00000UL, 0x0e5967d5UL, 0x3fac1d1fUL,\n+    0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL, 0xbc756217UL, 0x00000000UL,\n+    0xbfd00000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0xbfefd88dUL,\n+    0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0xbfc00000UL, 0x00000000UL,\n+    0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x00000000UL, 0x00000000UL,\n+    0x00000000UL, 0x00000000UL, 0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL,\n+    0xbfefd88dUL, 0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0x3fc00000UL,\n+    0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL,\n+    0xbc756217UL, 0x00000000UL, 0x3fd00000UL, 0x76acf82dUL, 0x3fa4a031UL,\n+    0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL, 0xbc8760b1UL, 0x00000000UL,\n+    0x3fd00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0xbfed906bUL,\n+    0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL,\n+    0xbf9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n+    0x00000000UL, 0x3fe00000UL, 0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL,\n+    0xbfea9b66UL, 0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0x3fe00000UL,\n+    0x94247758UL, 0x3fc133ccUL, 0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL,\n+    0x3c82c5e1UL, 0x00000000UL, 0x3fe00000UL, 0x99fcef32UL, 0x3fca8279UL,\n+    0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL, 0x3c8bdd34UL, 0x00000000UL,\n+    0x3fe00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0xbfe44cf3UL,\n+    0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL,\n+    0xbfc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n+    0x00000000UL, 0x3ff00000UL, 0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL,\n+    0xbfde2b5dUL, 0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0x3ff00000UL,\n+    0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL,\n+    0x3c672cedUL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL, 0xbfa60beaUL,\n+    0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL, 0x3c75d28dUL, 0x00000000UL,\n+    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0xbfc8f8b8UL,\n+    0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL,\n+    0xbf73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n+    0x00000000UL, 0x3ff00000UL\n+};\n+address MacroAssembler::Ctable = (address)_Ctable;\n+\n+#else \/\/ !_LP64\n+\n+ATTRIBUTE_ALIGNED(16) juint _ONES[] = {\n+    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xbff00000UL\n+};\n+address MacroAssembler::ONES = (address)_ONES;\n+\n+ATTRIBUTE_ALIGNED(16) juint _PI4_INV[] = {\n+    0x6dc9c883UL, 0x3ff45f30UL\n+};\n+address MacroAssembler::PI4_INV = (address)_PI4_INV;\n+\n+ATTRIBUTE_ALIGNED(16) juint _PI4X3[] = {\n+    0x54443000UL, 0xbfe921fbUL, 0x3b39a000UL, 0x3d373dcbUL, 0xe0e68948UL, 0xba845c06UL\n+};\n+address MacroAssembler::PI4X3 = (address)_PI4X3;\n+\n+ATTRIBUTE_ALIGNED(16) juint _PI4X4[] = {\n+    0x54400000UL, 0xbfe921fbUL, 0x1a600000UL, 0xbdc0b461UL, 0x2e000000UL, 0xbb93198aUL, 0x252049c1UL, 0xb96b839aUL\n+};\n+address MacroAssembler::PI4X4 = (address)_PI4X4;\n+\n+ATTRIBUTE_ALIGNED(16) juint _L_2IL0FLOATPACKET_0[] = {\n+    0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n+};\n+address MacroAssembler::L_2IL0FLOATPACKET_0 = (address)_L_2IL0FLOATPACKET_0;\n+\n+#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_constants.cpp","additions":265,"deletions":0,"binary":false,"changes":265,"status":"added"},{"patch":"@@ -179,5 +179,4 @@\n-ATTRIBUTE_ALIGNED(8) juint _ONE[] =\n-{\n-    0x00000000UL, 0x3ff00000UL\n-};\n-void MacroAssembler::fast_cos(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register r8, Register r9, Register r10, Register r11) {\n+void MacroAssembler::fast_cos(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register r8,\n+                              Register  r9, Register r10, Register r11, Register tmp) {\n@@ -190,17 +189,1 @@\n-  assert_different_registers(r8, r9, r10, r11, eax, ecx, edx);\n-\n-  address ONEHALF = StubRoutines::x86::_ONEHALF_addr();\n-  address P_2 = StubRoutines::x86::_P_2_addr();\n-  address SC_4 = StubRoutines::x86::_SC_4_addr();\n-  address Ctable = StubRoutines::x86::_Ctable_addr();\n-  address SC_2 = StubRoutines::x86::_SC_2_addr();\n-  address SC_3 = StubRoutines::x86::_SC_3_addr();\n-  address SC_1 = StubRoutines::x86::_SC_1_addr();\n-  address PI_INV_TABLE = StubRoutines::x86::_PI_INV_TABLE_addr();\n-  address PI_4 = (address)StubRoutines::x86::_PI_4_addr();\n-  address PI32INV = (address)StubRoutines::x86::_PI32INV_addr();\n-  address SIGN_MASK = (address)StubRoutines::x86::_SIGN_MASK_addr();\n-  address P_1 = (address)StubRoutines::x86::_P_1_addr();\n-  address P_3 = (address)StubRoutines::x86::_P_3_addr();\n-  address ONE = (address)_ONE;\n-  address NEG_ZERO = (address)StubRoutines::x86::_NEG_ZERO_addr();\n+  assert_different_registers(eax, ecx, edx, r8, r9, r10, r11, tmp);\n@@ -215,1 +198,1 @@\n-  movq(xmm1, ExternalAddress(PI32INV));    \/\/0x6dc9c883UL, 0x40245f30UL\n+  movq(xmm1, ExternalAddress(PI32INV), tmp \/*rscratch*\/);    \/\/0x6dc9c883UL, 0x40245f30UL\n@@ -221,2 +204,2 @@\n-  movdqu(xmm5, ExternalAddress(ONEHALF));    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-  movq(xmm4, ExternalAddress(SIGN_MASK));    \/\/0x00000000UL, 0x80000000UL\n+  movdqu(xmm5, ExternalAddress(ONEHALF), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+  movq(xmm4, ExternalAddress(SIGN_MASK), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x80000000UL\n@@ -228,2 +211,2 @@\n-  movdqu(xmm2, ExternalAddress(P_2));    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n-  movq(xmm3, ExternalAddress(P_1));    \/\/0x54400000UL, 0x3fb921fbUL\n+  movdqu(xmm2, ExternalAddress(P_2), tmp \/*rscratch*\/);    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n+  movq(xmm3, ExternalAddress(P_1), tmp \/*rscratch*\/);    \/\/0x54400000UL, 0x3fb921fbUL\n@@ -235,1 +218,1 @@\n-  movdqu(xmm5, ExternalAddress(SC_4));    \/\/0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n+  movdqu(xmm5, ExternalAddress(SC_4), tmp \/*rscratch*\/);    \/\/0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n@@ -241,1 +224,1 @@\n-  mulsd(xmm1, ExternalAddress(P_3));    \/\/0x2e037073UL, 0x3b63198aUL\n+  mulsd(xmm1, ExternalAddress(P_3), tmp \/*rscratch*\/);    \/\/0x2e037073UL, 0x3b63198aUL\n@@ -249,1 +232,1 @@\n-  movdqu(xmm6, ExternalAddress(SC_2));    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n+  movdqu(xmm6, ExternalAddress(SC_2), tmp \/*rscratch*\/);    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n@@ -265,1 +248,1 @@\n-  addpd(xmm5, ExternalAddress(SC_3));    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n+  addpd(xmm5, ExternalAddress(SC_3), tmp \/*rscratch*\/);    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n@@ -267,1 +250,1 @@\n-  addpd(xmm6, ExternalAddress(SC_1));    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n+  addpd(xmm6, ExternalAddress(SC_1), tmp \/*rscratch*\/);    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n@@ -295,1 +278,1 @@\n-  movq(xmm1, ExternalAddress(ONE));    \/\/0x00000000UL, 0x3ff00000UL\n+  movq(xmm1, ExternalAddress(ONE), tmp \/*rscratch*\/); \/\/ 0x00000000UL, 0x3ff00000UL\n@@ -443,2 +426,2 @@\n-  movq(xmm2, ExternalAddress(PI_4));    \/\/0x40000000UL, 0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n-  movq(xmm6, ExternalAddress(8 + PI_4));    \/\/0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n+  movq(xmm2, ExternalAddress(PI_4),     tmp \/*rscratch*\/); \/\/0x40000000UL, 0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n+  movq(xmm6, ExternalAddress(PI_4 + 8), tmp \/*rscratch*\/); \/\/0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n@@ -468,1 +451,1 @@\n-  movq(xmm1, ExternalAddress(PI32INV));    \/\/0x6dc9c883UL, 0x40245f30UL\n+  movq(xmm1, ExternalAddress(PI32INV), tmp \/*rscratch*\/);   \/\/0x6dc9c883UL, 0x40245f30UL\n@@ -470,2 +453,2 @@\n-  movq(xmm5, ExternalAddress(ONEHALF));    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-  movq(xmm4, ExternalAddress(SIGN_MASK));    \/\/0x00000000UL, 0x80000000UL\n+  movq(xmm5, ExternalAddress(ONEHALF), tmp \/*rscratch*\/);   \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+  movq(xmm4, ExternalAddress(SIGN_MASK), tmp \/*rscratch*\/); \/\/0x00000000UL, 0x80000000UL\n@@ -477,2 +460,2 @@\n-  movq(xmm3, ExternalAddress(P_1));    \/\/0x54400000UL, 0x3fb921fbUL\n-  movdqu(xmm2, ExternalAddress(P_2));    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n+  movq(xmm3, ExternalAddress(P_1), tmp \/*rscratch*\/);    \/\/0x54400000UL, 0x3fb921fbUL\n+  movdqu(xmm2, ExternalAddress(P_2), tmp \/*rscratch*\/);    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n@@ -486,1 +469,1 @@\n-  movdqu(xmm5, ExternalAddress(SC_4));    \/\/0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n+  movdqu(xmm5, ExternalAddress(SC_4), tmp \/*rscratch*\/);    \/\/0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n@@ -492,1 +475,1 @@\n-  mulsd(xmm1, ExternalAddress(P_3));    \/\/0x2e037073UL, 0x3b63198aUL\n+  mulsd(xmm1, ExternalAddress(P_3), tmp \/*rscratch*\/);    \/\/0x2e037073UL, 0x3b63198aUL\n@@ -511,1 +494,1 @@\n-  movdqu(xmm6, ExternalAddress(SC_2));    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n+  movdqu(xmm6, ExternalAddress(SC_2), tmp \/*rscratch*\/);    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n@@ -517,1 +500,1 @@\n-  addpd(xmm5, ExternalAddress(SC_3));    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n+  addpd(xmm5, ExternalAddress(SC_3), tmp \/*rscratch*\/);    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n@@ -519,1 +502,1 @@\n-  addpd(xmm6, ExternalAddress(SC_1));    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n+  addpd(xmm6, ExternalAddress(SC_1), tmp \/*rscratch*\/);    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n@@ -622,1 +605,1 @@\n-  mulsd(xmm0, ExternalAddress(NEG_ZERO));    \/\/0x00000000UL, 0x80000000UL\n+  mulsd(xmm0, ExternalAddress(NEG_ZERO), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x80000000UL\n@@ -753,1 +736,1 @@\n-\/\/          rax, rdx, rcx, rbx (tmp)\n+\/\/          eax, ecx, edx, ebx (tmp)\n@@ -757,1 +740,3 @@\n-void MacroAssembler::fast_cos(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n+void MacroAssembler::fast_cos(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register tmp) {\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_cos.cpp","additions":33,"deletions":48,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -80,5 +80,0 @@\n-ATTRIBUTE_ALIGNED(16) juint _shifter[] =\n-{\n-    0x00000000UL, 0x43380000UL, 0x00000000UL, 0x43380000UL\n-};\n-\n@@ -176,9 +171,0 @@\n-ATTRIBUTE_ALIGNED(4) juint _ZERO[] =\n-{\n-    0x00000000UL, 0x00000000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) juint _ONE_val[] =\n-{\n-    0x00000000UL, 0x3ff00000UL\n-};\n@@ -194,1 +180,3 @@\n-void MacroAssembler::fast_exp(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n+void MacroAssembler::fast_exp(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register tmp) {\n@@ -198,1 +186,1 @@\n-  Label L_2TAG_PACKET_12_0_2, B1_3, B1_5, start;\n+  Label L_2TAG_PACKET_12_0_2, B1_3, B1_5;\n@@ -201,4 +189,4 @@\n-  address cv = (address)_cv;\n-  address Shifter = (address)_shifter;\n-  address mmask = (address)_mmask;\n-  address bias = (address)_bias;\n+\n+  address cv       = (address)_cv;\n+  address mmask    = (address)_mmask;\n+  address bias     = (address)_bias;\n@@ -206,9 +194,6 @@\n-  address ALLONES = (address)_ALLONES;\n-  address ebias = (address)_ebias;\n-  address XMAX = (address)_XMAX;\n-  address XMIN = (address)_XMIN;\n-  address INF = (address)_INF;\n-  address ZERO = (address)_ZERO;\n-  address ONE_val = (address)_ONE_val;\n-\n-  bind(start);\n+  address ALLONES  = (address)_ALLONES;\n+  address ebias    = (address)_ebias;\n+  address XMAX     = (address)_XMAX;\n+  address XMIN     = (address)_XMIN;\n+  address INF      = (address)_INF;\n+\n@@ -218,4 +203,4 @@\n-  movdqu(xmm1, ExternalAddress(cv));       \/\/ 0x652b82feUL, 0x40571547UL, 0x652b82feUL, 0x40571547UL\n-  movdqu(xmm6, ExternalAddress(Shifter));  \/\/ 0x00000000UL, 0x43380000UL, 0x00000000UL, 0x43380000UL\n-  movdqu(xmm2, ExternalAddress(16 + cv));    \/\/ 0xfefa0000UL, 0x3f862e42UL, 0xfefa0000UL, 0x3f862e42UL\n-  movdqu(xmm3, ExternalAddress(32 + cv));    \/\/ 0xbc9e3b3aUL, 0x3d1cf79aUL, 0xbc9e3b3aUL, 0x3d1cf79aUL\n+  movdqu(xmm1, ExternalAddress(cv),      tmp \/*rscratch*\/); \/\/ 0x652b82feUL, 0x40571547UL, 0x652b82feUL, 0x40571547UL\n+  movdqu(xmm6, ExternalAddress(SHIFTER), tmp \/*rscratch*\/); \/\/ 0x00000000UL, 0x43380000UL, 0x00000000UL, 0x43380000UL\n+  movdqu(xmm2, ExternalAddress(cv + 16), tmp \/*rscratch*\/); \/\/ 0xfefa0000UL, 0x3f862e42UL, 0xfefa0000UL, 0x3f862e42UL\n+  movdqu(xmm3, ExternalAddress(cv + 32), tmp \/*rscratch*\/); \/\/ 0xbc9e3b3aUL, 0x3d1cf79aUL, 0xbc9e3b3aUL, 0x3d1cf79aUL\n@@ -235,1 +220,1 @@\n-  movdqu(xmm4, ExternalAddress(64 + cv));    \/\/ 0xe3289860UL, 0x3f56c15cUL, 0x555b9e25UL, 0x3fa55555UL\n+  movdqu(xmm4, ExternalAddress(cv + 64), tmp \/*rscratch*\/);  \/\/ 0xe3289860UL, 0x3f56c15cUL, 0x555b9e25UL, 0x3fa55555UL\n@@ -237,1 +222,1 @@\n-  movdqu(xmm5, ExternalAddress(80 + cv));    \/\/ 0xc090cf0fUL, 0x3f811115UL, 0x55548ba1UL, 0x3fc55555UL\n+  movdqu(xmm5, ExternalAddress(cv + 80), tmp \/*rscratch*\/);  \/\/ 0xc090cf0fUL, 0x3f811115UL, 0x55548ba1UL, 0x3fc55555UL\n@@ -245,1 +230,1 @@\n-  movdqu(xmm6, ExternalAddress(mmask));    \/\/ 0xffffffc0UL, 0x00000000UL, 0xffffffc0UL, 0x00000000UL\n+  movdqu(xmm6, ExternalAddress(mmask), tmp \/*rscratch*\/);    \/\/ 0xffffffc0UL, 0x00000000UL, 0xffffffc0UL, 0x00000000UL\n@@ -247,1 +232,1 @@\n-  movdqu(xmm6, ExternalAddress(bias));     \/\/ 0x0000ffc0UL, 0x00000000UL, 0x0000ffc0UL, 0x00000000UL\n+  movdqu(xmm6, ExternalAddress(bias), tmp \/*rscratch*\/);     \/\/ 0x0000ffc0UL, 0x00000000UL, 0x0000ffc0UL, 0x00000000UL\n@@ -260,1 +245,1 @@\n-  mulpd(xmm6, ExternalAddress(48 + cv));     \/\/ 0xfffffffeUL, 0x3fdfffffUL, 0xfffffffeUL, 0x3fdfffffUL\n+  mulpd(xmm6, ExternalAddress(cv + 48), tmp \/*rscratch*\/);     \/\/ 0xfffffffeUL, 0x3fdfffffUL, 0xfffffffeUL, 0x3fdfffffUL\n@@ -278,1 +263,1 @@\n-  movdqu(xmm4, ExternalAddress(ALLONES));  \/\/ 0xffffffffUL, 0xffffffffUL, 0xffffffffUL, 0xffffffffUL\n+  movdqu(xmm4, ExternalAddress(ALLONES), tmp \/*rscratch*\/);  \/\/ 0xffffffffUL, 0xffffffffUL, 0xffffffffUL, 0xffffffffUL\n@@ -286,1 +271,1 @@\n-  movdqu(xmm6, ExternalAddress(ebias));    \/\/ 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x3ff00000UL\n+  movdqu(xmm6, ExternalAddress(ebias), tmp \/*rscratch*\/);    \/\/ 0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x3ff00000UL\n@@ -355,1 +340,1 @@\n-  movsd(xmm0, ExternalAddress(XMAX));      \/\/ 0xffffffffUL, 0x7fefffffUL\n+  movsd(xmm0, ExternalAddress(XMAX), tmp \/*rscratch*\/);      \/\/ 0xffffffffUL, 0x7fefffffUL\n@@ -363,1 +348,1 @@\n-  movsd(xmm0, ExternalAddress(XMIN));      \/\/ 0x00000000UL, 0x00100000UL\n+  movsd(xmm0, ExternalAddress(XMIN), tmp \/*rscratch*\/);      \/\/ 0x00000000UL, 0x00100000UL\n@@ -377,1 +362,1 @@\n-  movsd(xmm0, ExternalAddress(INF));       \/\/ 0x00000000UL, 0x7ff00000UL\n+  movsd(xmm0, ExternalAddress(INF), tmp \/*rscratch*\/);       \/\/ 0x00000000UL, 0x7ff00000UL\n@@ -381,1 +366,1 @@\n-  movsd(xmm0, ExternalAddress(ZERO));      \/\/ 0x00000000UL, 0x00000000UL\n+  movsd(xmm0, ExternalAddress(ZERO), tmp \/*rscratch*\/);      \/\/ 0x00000000UL, 0x00000000UL\n@@ -395,1 +380,1 @@\n-  addsd(xmm0, ExternalAddress(ONE_val));   \/\/ 0x00000000UL, 0x3ff00000UL\n+  addsd(xmm0, ExternalAddress(ONE), tmp \/*rscratch*\/); \/\/ 0x00000000UL, 0x3ff00000UL\n@@ -482,1 +467,3 @@\n-void MacroAssembler::fast_exp(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n+void MacroAssembler::fast_exp(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register tmp) {\n@@ -486,1 +473,1 @@\n-  Label L_2TAG_PACKET_12_0_2, start;\n+  Label L_2TAG_PACKET_12_0_2;\n@@ -491,1 +478,0 @@\n-  bind(start);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_exp.cpp","additions":34,"deletions":48,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -186,1 +186,3 @@\n-void MacroAssembler::fast_log(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp1, Register tmp2) {\n+void MacroAssembler::fast_log(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register tmp1, Register tmp2) {\n@@ -190,1 +192,1 @@\n-  Label B1_3, B1_5, start;\n+  Label B1_3, B1_5;\n@@ -194,1 +196,1 @@\n-  address log2 = (address)_log2;\n+  address log2  = (address)_log2;\n@@ -197,1 +199,0 @@\n-  bind(start);\n@@ -236,2 +237,2 @@\n-  movq(xmm6, ExternalAddress(log2));       \/\/ 0xfefa3800UL, 0x3fa62e42UL\n-  movdqu(xmm3, ExternalAddress(coeff));    \/\/ 0x92492492UL, 0x3fc24924UL, 0x00000000UL, 0xbfd00000UL\n+  movq(xmm6, ExternalAddress(log2), tmp1 \/*rscratch*\/);       \/\/ 0xfefa3800UL, 0x3fa62e42UL\n+  movdqu(xmm3, ExternalAddress(coeff), tmp1 \/*rscratch*\/);    \/\/ 0x92492492UL, 0x3fc24924UL, 0x00000000UL, 0xbfd00000UL\n@@ -242,1 +243,1 @@\n-  movdqu(xmm4, ExternalAddress(16 + coeff)); \/\/ 0x3d6fb175UL, 0xbfc5555eUL, 0x55555555UL, 0x3fd55555UL\n+  movdqu(xmm4, ExternalAddress(coeff + 16), tmp1 \/*rscratch*\/); \/\/ 0x3d6fb175UL, 0xbfc5555eUL, 0x55555555UL, 0x3fd55555UL\n@@ -244,1 +245,1 @@\n-  movdqu(xmm2, ExternalAddress(32 + coeff)); \/\/ 0x9999999aUL, 0x3fc99999UL, 0x00000000UL, 0xbfe00000UL\n+  movdqu(xmm2, ExternalAddress(coeff + 32), tmp1 \/*rscratch*\/); \/\/ 0x9999999aUL, 0x3fc99999UL, 0x00000000UL, 0xbfe00000UL\n@@ -253,1 +254,1 @@\n-  mulsd(xmm7, ExternalAddress(8 + log2));    \/\/ 0x93c76730UL, 0x3ceef357UL\n+  mulsd(xmm7, ExternalAddress(log2 + 8), tmp1 \/*rscratch*\/);    \/\/ 0x93c76730UL, 0x3ceef357UL\n@@ -481,1 +482,3 @@\n-void MacroAssembler::fast_log(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n+void MacroAssembler::fast_log(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register tmp) {\n@@ -485,1 +488,1 @@\n-  Label L_2TAG_PACKET_10_0_2, start;\n+  Label L_2TAG_PACKET_10_0_2;\n@@ -490,1 +493,0 @@\n-  bind(start);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_log.cpp","additions":14,"deletions":12,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -194,1 +194,1 @@\n-\/\/          rax, rdx, rcx, tmp - r11\n+\/\/          rax, rdx, rcx, r11, tmp\n@@ -198,1 +198,3 @@\n-void MacroAssembler::fast_log10(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register r11) {\n+void MacroAssembler::fast_log10(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                                Register eax, Register ecx, Register edx, Register r11, Register tmp) {\n@@ -201,1 +203,1 @@\n-  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, B1_2, B1_3, B1_5, start;\n+  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, B1_2, B1_3, B1_5;\n@@ -211,1 +213,0 @@\n-  bind(start);\n@@ -227,1 +228,1 @@\n-  movdqu(xmm5, ExternalAddress(HIGHSIGMASK));    \/\/0xf8000000UL, 0xffffffffUL, 0x00000000UL, 0xffffe000UL\n+  movdqu(xmm5, ExternalAddress(HIGHSIGMASK), tmp \/*rscratch*\/);    \/\/0xf8000000UL, 0xffffffffUL, 0x00000000UL, 0xffffe000UL\n@@ -232,1 +233,1 @@\n-  movdqu(xmm2, ExternalAddress(LOG10_E));    \/\/0x00000000UL, 0x3fdbc000UL, 0xbf2e4108UL, 0x3f5a7a6cUL\n+  movdqu(xmm2, ExternalAddress(LOG10_E), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fdbc000UL, 0xbf2e4108UL, 0x3f5a7a6cUL\n@@ -257,2 +258,2 @@\n-  movq(xmm6, ExternalAddress(log2));    \/\/0x509f7800UL, 0x3f934413UL, 0x1f12b358UL, 0x3cdfef31UL\n-  movdqu(xmm3, ExternalAddress(coeff));    \/\/0xc1a5f12eUL, 0x40358874UL, 0x64d4ef0dUL, 0xc0089309UL\n+  movq(xmm6, ExternalAddress(log2), tmp \/*rscratch*\/);    \/\/0x509f7800UL, 0x3f934413UL, 0x1f12b358UL, 0x3cdfef31UL\n+  movdqu(xmm3, ExternalAddress(coeff), tmp \/*rscratch*\/);    \/\/0xc1a5f12eUL, 0x40358874UL, 0x64d4ef0dUL, 0xc0089309UL\n@@ -263,1 +264,1 @@\n-  movdqu(xmm4, ExternalAddress(16 + coeff));    \/\/0x385593b1UL, 0xc025c917UL, 0xdc963467UL, 0x3ffc6a02UL\n+  movdqu(xmm4, ExternalAddress(coeff + 16), tmp \/*rscratch*\/);    \/\/0x385593b1UL, 0xc025c917UL, 0xdc963467UL, 0x3ffc6a02UL\n@@ -265,1 +266,1 @@\n-  movdqu(xmm2, ExternalAddress(32 + coeff));    \/\/0x7f9d3aa1UL, 0x4016ab9fUL, 0xdc77b115UL, 0xbff27af2UL\n+  movdqu(xmm2, ExternalAddress(coeff + 32), tmp \/*rscratch*\/);    \/\/0x7f9d3aa1UL, 0x4016ab9fUL, 0xdc77b115UL, 0xbff27af2UL\n@@ -268,1 +269,1 @@\n-  mulsd(xmm7, ExternalAddress(8 + log2));    \/\/0x1f12b358UL, 0x3cdfef31UL\n+  mulsd(xmm7, ExternalAddress(log2 + 8), tmp \/*rscratch*\/);    \/\/0x1f12b358UL, 0x3cdfef31UL\n@@ -272,1 +273,1 @@\n-  movq(xmm6, ExternalAddress(8 + LOG10_E));    \/\/0xbf2e4108UL, 0x3f5a7a6cUL\n+  movq(xmm6, ExternalAddress(LOG10_E + 8), tmp \/*rscratch*\/);    \/\/0xbf2e4108UL, 0x3f5a7a6cUL\n@@ -335,1 +336,1 @@\n-  movdqu(xmm2, ExternalAddress(LOG10_E));    \/\/0x00000000UL, 0x3fdbc000UL, 0xbf2e4108UL, 0x3f5a7a6cUL\n+  movdqu(xmm2, ExternalAddress(LOG10_E), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fdbc000UL, 0xbf2e4108UL, 0x3f5a7a6cUL\n@@ -501,1 +502,3 @@\n-void MacroAssembler::fast_log10(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp) {\n+void MacroAssembler::fast_log10(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                                XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                                Register eax, Register ecx, Register edx, Register tmp) {\n@@ -505,1 +508,1 @@\n-  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, L_2TAG_PACKET_10_0_2, start;\n+  Label L_2TAG_PACKET_8_0_2, L_2TAG_PACKET_9_0_2, L_2TAG_PACKET_10_0_2;\n@@ -511,1 +514,0 @@\n-  bind(start);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_log10.cpp","additions":18,"deletions":16,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -786,1 +786,4 @@\n-void MacroAssembler::fast_pow(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register tmp1, Register tmp2, Register tmp3, Register tmp4) {\n+void MacroAssembler::fast_pow(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx,\n+                              Register tmp1, Register tmp2, Register tmp3, Register tmp4) {\n@@ -802,1 +805,1 @@\n-  Label B1_2, B1_3, B1_5, start;\n+  Label B1_2, B1_3, B1_5;\n@@ -821,2 +824,0 @@\n-\n-  bind(start);\n@@ -829,1 +830,1 @@\n-  cmp64(tmp1, ExternalAddress(DOUBLE2));\n+  cmp64(tmp1, ExternalAddress(DOUBLE2), tmp2 \/*rscratch*\/);\n@@ -836,1 +837,1 @@\n-  cmp64(tmp1, ExternalAddress(DOUBLE0DOT5));\n+  cmp64(tmp1, ExternalAddress(DOUBLE0DOT5), tmp2 \/*rscratch*\/);\n@@ -839,1 +840,1 @@\n-  cmp64(tmp2, ExternalAddress(DOUBLE0));\n+  cmp64(tmp2, ExternalAddress(DOUBLE0), tmp3 \/*rscratch*\/);\n@@ -863,1 +864,1 @@\n-  movdqu(xmm6, ExternalAddress(HIGHSIGMASK));    \/\/0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL\n+  movdqu(xmm6, ExternalAddress(HIGHSIGMASK), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL\n@@ -865,1 +866,1 @@\n-  movq(xmm2, ExternalAddress(LOG2_E));    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n+  movq(xmm2, ExternalAddress(LOG2_E), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -905,1 +906,1 @@\n-  movdqu(xmm1, ExternalAddress(coeff));    \/\/0x6dc96112UL, 0xbf836578UL, 0xee241472UL, 0xbf9b0301UL\n+  movdqu(xmm1, ExternalAddress(coeff), tmp2 \/*rscratch*\/);    \/\/0x6dc96112UL, 0xbf836578UL, 0xee241472UL, 0xbf9b0301UL\n@@ -908,1 +909,1 @@\n-  movdqu(xmm4, ExternalAddress(16 + coeff));    \/\/0x9f95985aUL, 0xbfb528dbUL, 0xb3841d2aUL, 0xbfd619b6UL\n+  movdqu(xmm4, ExternalAddress(coeff + 16), tmp2 \/*rscratch*\/);    \/\/0x9f95985aUL, 0xbfb528dbUL, 0xb3841d2aUL, 0xbfd619b6UL\n@@ -916,1 +917,1 @@\n-  movdqu(xmm6, ExternalAddress(32 + coeff));    \/\/0x518775e3UL, 0x3f9004f2UL, 0xac8349bbUL, 0x3fa76c9bUL\n+  movdqu(xmm6, ExternalAddress(coeff + 32), tmp2 \/*rscratch*\/);    \/\/0x518775e3UL, 0x3f9004f2UL, 0xac8349bbUL, 0x3fa76c9bUL\n@@ -921,1 +922,1 @@\n-  movdqu(xmm0, ExternalAddress(48 + coeff));    \/\/0x486ececcUL, 0x3fc4635eUL, 0x161bb241UL, 0xbf5dabe1UL\n+  movdqu(xmm0, ExternalAddress(coeff + 48), tmp2 \/*rscratch*\/);    \/\/0x486ececcUL, 0x3fc4635eUL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -934,1 +935,1 @@\n-  movq(xmm4, ExternalAddress(HIGHMASK_Y));    \/\/0x00000000UL, 0xfffffff8UL, 0x00000000UL, 0xffffffffUL\n+  movq(xmm4, ExternalAddress(HIGHMASK_Y), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xfffffff8UL, 0x00000000UL, 0xffffffffUL\n@@ -969,2 +970,2 @@\n-  movdqu(xmm7, ExternalAddress(e_coeff));    \/\/0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL\n-  movdqu(xmm3, ExternalAddress(16 + e_coeff));    \/\/0x6fba4e77UL, 0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL\n+  movdqu(xmm7, ExternalAddress(e_coeff),      tmp2 \/*rscratch*\/);    \/\/0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL\n+  movdqu(xmm3, ExternalAddress(e_coeff + 16), tmp2 \/*rscratch*\/);    \/\/0x6fba4e77UL, 0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL\n@@ -1029,1 +1030,1 @@\n-  movq(xmm2, ExternalAddress(LOG2_E));    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n+  movq(xmm2, ExternalAddress(LOG2_E), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -1033,1 +1034,1 @@\n-  movdqu(xmm6, ExternalAddress(HIGHSIGMASK));    \/\/0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL\n+  movdqu(xmm6, ExternalAddress(HIGHSIGMASK), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL\n@@ -1075,1 +1076,1 @@\n-  movq(xmm2, ExternalAddress(LOG2_E));    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n+  movq(xmm2, ExternalAddress(LOG2_E), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -1079,1 +1080,1 @@\n-  movdqu(xmm6, ExternalAddress(HIGHSIGMASK));    \/\/0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL\n+  movdqu(xmm6, ExternalAddress(HIGHSIGMASK), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xfffff800UL, 0x00000000UL, 0xfffff800UL\n@@ -1106,1 +1107,1 @@\n-  movq(xmm2, ExternalAddress(HALFMASK));    \/\/0xf8000000UL, 0xffffffffUL, 0xf8000000UL, 0xffffffffUL\n+  movq(xmm2, ExternalAddress(HALFMASK), tmp2 \/*rscratch*\/);    \/\/0xf8000000UL, 0xffffffffUL, 0xf8000000UL, 0xffffffffUL\n@@ -1134,2 +1135,2 @@\n-  movdqu(xmm7, ExternalAddress(e_coeff));    \/\/0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL\n-  movdqu(xmm3, ExternalAddress(16 + e_coeff));    \/\/0x6fba4e77UL, 0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL\n+  movdqu(xmm7, ExternalAddress(e_coeff +  0), tmp2 \/*rscratch*\/);    \/\/0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL\n+  movdqu(xmm3, ExternalAddress(e_coeff + 16), tmp2 \/*rscratch*\/);    \/\/0x6fba4e77UL, 0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL\n@@ -1150,1 +1151,1 @@\n-  movq(xmm1, ExternalAddress(32 + e_coeff));    \/\/0xfefa39efUL, 0x3fe62e42UL, 0x00000000UL, 0x00000000UL\n+  movq(xmm1, ExternalAddress(e_coeff + 32), tmp2 \/*rscratch*\/);    \/\/0xfefa39efUL, 0x3fe62e42UL, 0x00000000UL, 0x00000000UL\n@@ -1407,1 +1408,1 @@\n-  movq(xmm2, ExternalAddress(LOG2_E));    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n+  movq(xmm2, ExternalAddress(LOG2_E), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -1440,1 +1441,1 @@\n-  movq(xmm2, ExternalAddress(LOG2_E));    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n+  movq(xmm2, ExternalAddress(LOG2_E), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff72000UL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -1667,1 +1668,1 @@\n-  movq(xmm4, ExternalAddress(coeff_h));    \/\/0x00000000UL, 0xbfd61a00UL, 0x00000000UL, 0xbf5dabe1UL\n+  movq(xmm4, ExternalAddress(coeff_h), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xbfd61a00UL, 0x00000000UL, 0xbf5dabe1UL\n@@ -1669,1 +1670,1 @@\n-  movq(xmm6, ExternalAddress(coeff_h));    \/\/0x00000000UL, 0xbfd61a00UL, 0x00000000UL, 0xbf5dabe1UL\n+  movq(xmm6, ExternalAddress(coeff_h), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xbfd61a00UL, 0x00000000UL, 0xbf5dabe1UL\n@@ -1671,1 +1672,1 @@\n-  movq(xmm1, ExternalAddress(8 + coeff_h));    \/\/0x00000000UL, 0xbf5dabe1UL\n+  movq(xmm1, ExternalAddress(coeff_h + 8), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xbf5dabe1UL\n@@ -1675,1 +1676,1 @@\n-  movq(xmm0, ExternalAddress(8 + coeff_h));    \/\/0x00000000UL, 0xbf5dabe1UL\n+  movq(xmm0, ExternalAddress(coeff_h + 8), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xbf5dabe1UL\n@@ -1700,1 +1701,1 @@\n-  movdqu(xmm0, ExternalAddress(coeff));    \/\/0x6dc96112UL, 0xbf836578UL, 0xee241472UL, 0xbf9b0301UL\n+  movdqu(xmm0, ExternalAddress(coeff), tmp2 \/*rscratch*\/);    \/\/0x6dc96112UL, 0xbf836578UL, 0xee241472UL, 0xbf9b0301UL\n@@ -1706,1 +1707,1 @@\n-  movdqu(xmm2, ExternalAddress(64 + coeff));    \/\/0x486ececcUL, 0x3fc4635eUL, 0x161bb241UL, 0xbf5dabe1UL\n+  movdqu(xmm2, ExternalAddress(coeff + 64), tmp2 \/*rscratch*\/);    \/\/0x486ececcUL, 0x3fc4635eUL, 0x161bb241UL, 0xbf5dabe1UL\n@@ -1715,1 +1716,1 @@\n-  movdqu(xmm5, ExternalAddress(80 + coeff));    \/\/0x9f95985aUL, 0xbfb528dbUL, 0xf8b5787dUL, 0x3ef2531eUL\n+  movdqu(xmm5, ExternalAddress(coeff + 80), tmp2 \/*rscratch*\/);    \/\/0x9f95985aUL, 0xbfb528dbUL, 0xf8b5787dUL, 0x3ef2531eUL\n@@ -1719,1 +1720,1 @@\n-  movdqu(xmm1, ExternalAddress(32 + coeff));    \/\/0x9f95985aUL, 0xbfb528dbUL, 0xb3841d2aUL, 0xbfd619b6UL\n+  movdqu(xmm1, ExternalAddress(coeff + 32), tmp2 \/*rscratch*\/);    \/\/0x9f95985aUL, 0xbfb528dbUL, 0xb3841d2aUL, 0xbfd619b6UL\n@@ -1727,1 +1728,1 @@\n-  movq(xmm2, ExternalAddress(HIGHMASK_LOG_X));    \/\/0xf8000000UL, 0xffffffffUL, 0x00000000UL, 0xfffff800UL\n+  movq(xmm2, ExternalAddress(HIGHMASK_LOG_X), tmp2 \/*rscratch*\/);    \/\/0xf8000000UL, 0xffffffffUL, 0x00000000UL, 0xfffff800UL\n@@ -1735,1 +1736,1 @@\n-  movq(xmm4, ExternalAddress(8 + HIGHMASK_Y));    \/\/0x00000000UL, 0xffffffffUL\n+  movq(xmm4, ExternalAddress(HIGHMASK_Y + 8), tmp2 \/*rscratch*\/);    \/\/0x00000000UL, 0xffffffffUL\n@@ -1763,1 +1764,1 @@\n-  movdqu(xmm7, ExternalAddress(e_coeff));    \/\/0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL\n+  movdqu(xmm7, ExternalAddress(e_coeff), tmp2 \/*rscratch*\/);    \/\/0xe78a6731UL, 0x3f55d87fUL, 0xd704a0c0UL, 0x3fac6b08UL\n@@ -1767,2 +1768,2 @@\n-  movdqu(xmm3, ExternalAddress(16 + e_coeff));    \/\/0x6fba4e77UL, 0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL\n-  movq(xmm2, ExternalAddress(32 + e_coeff));    \/\/0xfefa39efUL, 0x3fe62e42UL, 0x00000000UL, 0x00000000UL\n+  movdqu(xmm3, ExternalAddress(e_coeff + 16), tmp2 \/*rscratch*\/);    \/\/0x6fba4e77UL, 0x3f83b2abUL, 0xff82c58fUL, 0x3fcebfbdUL\n+  movq(xmm2, ExternalAddress(e_coeff + 32), tmp2 \/*rscratch*\/);    \/\/0xfefa39efUL, 0x3fe62e42UL, 0x00000000UL, 0x00000000UL\n@@ -2553,1 +2554,0 @@\n-  bind(start);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_pow.cpp","additions":40,"deletions":40,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -38,1 +38,1 @@\n-  Label start, done_hash, loop0;\n+  Label done_hash, loop0;\n@@ -43,1 +43,0 @@\n-  bind(start);\n@@ -251,1 +250,1 @@\n-  Label start, done_hash, loop0;\n+  Label done_hash, loop0;\n@@ -256,1 +255,0 @@\n-  bind(start);\n@@ -824,3 +822,3 @@\n-  vmovdqu(BYTE_FLIP_MASK, ExternalAddress(pshuffle_byte_flip_mask_addr +0)); \/\/[PSHUFFLE_BYTE_FLIP_MASK wrt rip]\n-  vmovdqu(SHUF_00BA, ExternalAddress(pshuffle_byte_flip_mask_addr + 32));     \/\/[_SHUF_00BA wrt rip]\n-  vmovdqu(SHUF_DC00, ExternalAddress(pshuffle_byte_flip_mask_addr + 64));     \/\/[_SHUF_DC00 wrt rip]\n+  vmovdqu(BYTE_FLIP_MASK, ExternalAddress(pshuffle_byte_flip_mask_addr +  0)); \/\/ [PSHUFFLE_BYTE_FLIP_MASK wrt rip]\n+  vmovdqu(SHUF_00BA,      ExternalAddress(pshuffle_byte_flip_mask_addr + 32)); \/\/ [_SHUF_00BA wrt rip]\n+  vmovdqu(SHUF_DC00,      ExternalAddress(pshuffle_byte_flip_mask_addr + 64)); \/\/ [_SHUF_DC00 wrt rip]\n@@ -987,3 +985,3 @@\n-  vmovdqu(BYTE_FLIP_MASK, ExternalAddress(pshuffle_byte_flip_mask_addr + 0)); \/\/[PSHUFFLE_BYTE_FLIP_MASK wrt rip]\n-  vmovdqu(SHUF_00BA, ExternalAddress(pshuffle_byte_flip_mask_addr + 32));     \/\/[_SHUF_00BA wrt rip]\n-  vmovdqu(SHUF_DC00, ExternalAddress(pshuffle_byte_flip_mask_addr + 64));     \/\/[_SHUF_DC00 wrt rip]\n+  vmovdqu(BYTE_FLIP_MASK, ExternalAddress(pshuffle_byte_flip_mask_addr +  0)); \/\/ [PSHUFFLE_BYTE_FLIP_MASK wrt rip]\n+  vmovdqu(SHUF_00BA,      ExternalAddress(pshuffle_byte_flip_mask_addr + 32)); \/\/ [_SHUF_00BA wrt rip]\n+  vmovdqu(SHUF_DC00,      ExternalAddress(pshuffle_byte_flip_mask_addr + 64)); \/\/ [_SHUF_DC00 wrt rip]\n@@ -1379,2 +1377,2 @@\n-    vmovdqu(BYTE_FLIP_MASK, ExternalAddress(pshuffle_byte_flip_mask_addr + 0)); \/\/PSHUFFLE_BYTE_FLIP_MASK wrt rip\n-    vmovdqu(YMM_MASK_LO, ExternalAddress(pshuffle_byte_flip_mask_addr + 32));\n+    vmovdqu(BYTE_FLIP_MASK, ExternalAddress(pshuffle_byte_flip_mask_addr +  0)); \/\/ PSHUFFLE_BYTE_FLIP_MASK wrt rip\n+    vmovdqu(YMM_MASK_LO,    ExternalAddress(pshuffle_byte_flip_mask_addr + 32));\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_sha.cpp","additions":10,"deletions":12,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -181,175 +181,0 @@\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_ONEHALF[] =\n-{\n-    0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_P_2[] =\n-{\n-    0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_SC_4[] =\n-{\n-    0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_Ctable[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL, 0xbf73b92eUL,\n-    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n-    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL,\n-    0xc0000000UL, 0xbc626d19UL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL,\n-    0xbfa60beaUL, 0x2ed59f06UL, 0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL,\n-    0x00000000UL, 0x3ff00000UL, 0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL,\n-    0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL, 0x00000000UL, 0x3ff00000UL,\n-    0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL, 0x20000000UL,\n-    0x3c5e0d89UL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL, 0xbfc59267UL,\n-    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n-    0x3ff00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL,\n-    0x20000000UL, 0x3c68076aUL, 0x00000000UL, 0x3ff00000UL, 0x99fcef32UL,\n-    0x3fca8279UL, 0x667f3bcdUL, 0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL,\n-    0x00000000UL, 0x3fe00000UL, 0x94247758UL, 0x3fc133ccUL, 0x6b151741UL,\n-    0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL, 0x00000000UL, 0x3fe00000UL,\n-    0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL, 0xe0000000UL,\n-    0x3c39f630UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL, 0xbf9d4a2cUL,\n-    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n-    0x3fe00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0x3fed906bUL,\n-    0x20000000UL, 0x3c7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x76acf82dUL,\n-    0x3fa4a031UL, 0x56c62ddaUL, 0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL,\n-    0x00000000UL, 0x3fd00000UL, 0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL,\n-    0x3fef6297UL, 0x20000000UL, 0x3c756217UL, 0x00000000UL, 0x3fd00000UL,\n-    0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL, 0x3fefd88dUL, 0x40000000UL,\n-    0xbc887df6UL, 0x00000000UL, 0x3fc00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0x3fefd88dUL,\n-    0x40000000UL, 0xbc887df6UL, 0x00000000UL, 0xbfc00000UL, 0x0e5967d5UL,\n-    0x3fac1d1fUL, 0xcff75cb0UL, 0x3fef6297UL, 0x20000000UL, 0x3c756217UL,\n-    0x00000000UL, 0xbfd00000UL, 0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL,\n-    0x3fee9f41UL, 0xe0000000UL, 0x3c8760b1UL, 0x00000000UL, 0xbfd00000UL,\n-    0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL, 0x3fed906bUL, 0x20000000UL,\n-    0x3c7457e6UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL, 0x3f9d4a2cUL,\n-    0xf180bdb1UL, 0x3fec38b2UL, 0x80000000UL, 0xbc76e0b1UL, 0x00000000UL,\n-    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0x3fea9b66UL,\n-    0xe0000000UL, 0x3c39f630UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL,\n-    0xbfc133ccUL, 0x6b151741UL, 0x3fe8bc80UL, 0x20000000UL, 0xbc82c5e1UL,\n-    0x00000000UL, 0xbfe00000UL, 0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL,\n-    0x3fe6a09eUL, 0x20000000UL, 0xbc8bdd34UL, 0x00000000UL, 0xbfe00000UL,\n-    0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL, 0x3fe44cf3UL, 0x20000000UL,\n-    0x3c68076aUL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL, 0x3fc59267UL,\n-    0x39ae68c8UL, 0x3fe1c73bUL, 0x20000000UL, 0x3c8b25ddUL, 0x00000000UL,\n-    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0x3fde2b5dUL,\n-    0x20000000UL, 0x3c5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL,\n-    0x3fb37ca1UL, 0xa6aea963UL, 0x3fd87de2UL, 0xe0000000UL, 0xbc672cedUL,\n-    0x00000000UL, 0xbff00000UL, 0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL,\n-    0x3fd29406UL, 0xa0000000UL, 0xbc75d28dUL, 0x00000000UL, 0xbff00000UL,\n-    0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL, 0x3fc8f8b8UL, 0xc0000000UL,\n-    0xbc626d19UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL, 0x3f73b92eUL,\n-    0xbc29b42cUL, 0x3fb917a6UL, 0xe0000000UL, 0xbc3e2718UL, 0x00000000UL,\n-    0xbff00000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x176d6d31UL,\n-    0x3f73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n-    0x00000000UL, 0xbff00000UL, 0x011469fbUL, 0x3f93ad06UL, 0x3c69a60bUL,\n-    0xbfc8f8b8UL, 0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0xbff00000UL,\n-    0x939d225aUL, 0x3fa60beaUL, 0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL,\n-    0x3c75d28dUL, 0x00000000UL, 0xbff00000UL, 0x866b95cfUL, 0x3fb37ca1UL,\n-    0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL, 0x3c672cedUL, 0x00000000UL,\n-    0xbff00000UL, 0x73fa1279UL, 0x3fbe3a68UL, 0x3806f63bUL, 0xbfde2b5dUL,\n-    0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0xbff00000UL, 0x5bc57974UL,\n-    0x3fc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n-    0x00000000UL, 0xbff00000UL, 0x53aba2fdUL, 0x3fcd0dfeUL, 0x25091dd6UL,\n-    0xbfe44cf3UL, 0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0xbff00000UL,\n-    0x99fcef32UL, 0xbfca8279UL, 0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL,\n-    0x3c8bdd34UL, 0x00000000UL, 0xbfe00000UL, 0x94247758UL, 0xbfc133ccUL,\n-    0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL, 0x3c82c5e1UL, 0x00000000UL,\n-    0xbfe00000UL, 0x9ae68c87UL, 0xbfac73b3UL, 0x290ea1a3UL, 0xbfea9b66UL,\n-    0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0xbfe00000UL, 0x7f909c4eUL,\n-    0x3f9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n-    0x00000000UL, 0xbfe00000UL, 0x65455a75UL, 0x3fbe0875UL, 0xcf328d46UL,\n-    0xbfed906bUL, 0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0xbfe00000UL,\n-    0x76acf82dUL, 0xbfa4a031UL, 0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL,\n-    0xbc8760b1UL, 0x00000000UL, 0xbfd00000UL, 0x0e5967d5UL, 0x3fac1d1fUL,\n-    0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL, 0xbc756217UL, 0x00000000UL,\n-    0xbfd00000UL, 0x0f592f50UL, 0x3f9ba165UL, 0xa3d12526UL, 0xbfefd88dUL,\n-    0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0xbfc00000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0xbff00000UL, 0x00000000UL, 0x00000000UL,\n-    0x00000000UL, 0x00000000UL, 0x0f592f50UL, 0xbf9ba165UL, 0xa3d12526UL,\n-    0xbfefd88dUL, 0x40000000UL, 0x3c887df6UL, 0x00000000UL, 0x3fc00000UL,\n-    0x0e5967d5UL, 0xbfac1d1fUL, 0xcff75cb0UL, 0xbfef6297UL, 0x20000000UL,\n-    0xbc756217UL, 0x00000000UL, 0x3fd00000UL, 0x76acf82dUL, 0x3fa4a031UL,\n-    0x56c62ddaUL, 0xbfee9f41UL, 0xe0000000UL, 0xbc8760b1UL, 0x00000000UL,\n-    0x3fd00000UL, 0x65455a75UL, 0xbfbe0875UL, 0xcf328d46UL, 0xbfed906bUL,\n-    0x20000000UL, 0xbc7457e6UL, 0x00000000UL, 0x3fe00000UL, 0x7f909c4eUL,\n-    0xbf9d4a2cUL, 0xf180bdb1UL, 0xbfec38b2UL, 0x80000000UL, 0x3c76e0b1UL,\n-    0x00000000UL, 0x3fe00000UL, 0x9ae68c87UL, 0x3fac73b3UL, 0x290ea1a3UL,\n-    0xbfea9b66UL, 0xe0000000UL, 0xbc39f630UL, 0x00000000UL, 0x3fe00000UL,\n-    0x94247758UL, 0x3fc133ccUL, 0x6b151741UL, 0xbfe8bc80UL, 0x20000000UL,\n-    0x3c82c5e1UL, 0x00000000UL, 0x3fe00000UL, 0x99fcef32UL, 0x3fca8279UL,\n-    0x667f3bcdUL, 0xbfe6a09eUL, 0x20000000UL, 0x3c8bdd34UL, 0x00000000UL,\n-    0x3fe00000UL, 0x53aba2fdUL, 0xbfcd0dfeUL, 0x25091dd6UL, 0xbfe44cf3UL,\n-    0x20000000UL, 0xbc68076aUL, 0x00000000UL, 0x3ff00000UL, 0x5bc57974UL,\n-    0xbfc59267UL, 0x39ae68c8UL, 0xbfe1c73bUL, 0x20000000UL, 0xbc8b25ddUL,\n-    0x00000000UL, 0x3ff00000UL, 0x73fa1279UL, 0xbfbe3a68UL, 0x3806f63bUL,\n-    0xbfde2b5dUL, 0x20000000UL, 0xbc5e0d89UL, 0x00000000UL, 0x3ff00000UL,\n-    0x866b95cfUL, 0xbfb37ca1UL, 0xa6aea963UL, 0xbfd87de2UL, 0xe0000000UL,\n-    0x3c672cedUL, 0x00000000UL, 0x3ff00000UL, 0x939d225aUL, 0xbfa60beaUL,\n-    0x2ed59f06UL, 0xbfd29406UL, 0xa0000000UL, 0x3c75d28dUL, 0x00000000UL,\n-    0x3ff00000UL, 0x011469fbUL, 0xbf93ad06UL, 0x3c69a60bUL, 0xbfc8f8b8UL,\n-    0xc0000000UL, 0x3c626d19UL, 0x00000000UL, 0x3ff00000UL, 0x176d6d31UL,\n-    0xbf73b92eUL, 0xbc29b42cUL, 0xbfb917a6UL, 0xe0000000UL, 0x3c3e2718UL,\n-    0x00000000UL, 0x3ff00000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_SC_2[] =\n-{\n-    0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_SC_3[] =\n-{\n-    0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_SC_1[] =\n-{\n-    0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_PI_INV_TABLE[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0xa2f9836eUL, 0x4e441529UL, 0xfc2757d1UL,\n-    0xf534ddc0UL, 0xdb629599UL, 0x3c439041UL, 0xfe5163abUL, 0xdebbc561UL,\n-    0xb7246e3aUL, 0x424dd2e0UL, 0x06492eeaUL, 0x09d1921cUL, 0xfe1deb1cUL,\n-    0xb129a73eUL, 0xe88235f5UL, 0x2ebb4484UL, 0xe99c7026UL, 0xb45f7e41UL,\n-    0x3991d639UL, 0x835339f4UL, 0x9c845f8bUL, 0xbdf9283bUL, 0x1ff897ffUL,\n-    0xde05980fUL, 0xef2f118bUL, 0x5a0a6d1fUL, 0x6d367ecfUL, 0x27cb09b7UL,\n-    0x4f463f66UL, 0x9e5fea2dUL, 0x7527bac7UL, 0xebe5f17bUL, 0x3d0739f7UL,\n-    0x8a5292eaUL, 0x6bfb5fb1UL, 0x1f8d5d08UL, 0x56033046UL, 0xfc7b6babUL,\n-    0xf0cfbc21UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint StubRoutines::x86::_PI_4[] =\n-{\n-    0x40000000UL, 0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint StubRoutines::x86::_PI32INV[] =\n-{\n-    0x6dc9c883UL, 0x40245f30UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint _SHIFTER[] =\n-{\n-    0x00000000UL, 0x43380000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint StubRoutines::x86::_SIGN_MASK[] =\n-{\n-    0x00000000UL, 0x80000000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint StubRoutines::x86::_P_3[] =\n-{\n-    0x2e037073UL, 0x3b63198aUL\n-};\n-\n@@ -361,21 +186,3 @@\n-ATTRIBUTE_ALIGNED(8) juint _TWO_POW_55[] =\n-{\n-    0x00000000UL, 0x43600000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint _TWO_POW_M55[] =\n-{\n-    0x00000000UL, 0x3c800000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint StubRoutines::x86::_P_1[] =\n-{\n-    0x54400000UL, 0x3fb921fbUL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint StubRoutines::x86::_NEG_ZERO[] =\n-{\n-    0x00000000UL, 0x80000000UL\n-};\n-\n-void MacroAssembler::fast_sin(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ebx, Register ecx, Register edx, Register tmp1, Register tmp2, Register tmp3, Register tmp4) {\n+void MacroAssembler::fast_sin(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ebx, Register ecx, Register edx, Register tmp) {\n@@ -386,16 +193,4 @@\n-  Label L_2TAG_PACKET_12_0_1, B1_4, start;\n-\n-  assert_different_registers(tmp1, tmp2, tmp3, tmp4, eax, ebx, ecx, edx);\n-  address ONEHALF = StubRoutines::x86::_ONEHALF_addr();\n-  address P_2 = StubRoutines::x86::_P_2_addr();\n-  address SC_4 = StubRoutines::x86::_SC_4_addr();\n-  address Ctable = StubRoutines::x86::_Ctable_addr();\n-  address SC_2 = StubRoutines::x86::_SC_2_addr();\n-  address SC_3 = StubRoutines::x86::_SC_3_addr();\n-  address SC_1 = StubRoutines::x86::_SC_1_addr();\n-  address PI_INV_TABLE = StubRoutines::x86::_PI_INV_TABLE_addr();\n-  address PI_4 = (address)StubRoutines::x86::_PI_4_addr();\n-  address PI32INV = (address)StubRoutines::x86::_PI32INV_addr();\n-  address SHIFTER = (address)_SHIFTER;\n-  address SIGN_MASK = (address)StubRoutines::x86::_SIGN_MASK_addr();\n-  address P_3 = (address)StubRoutines::x86::_P_3_addr();\n+  Label L_2TAG_PACKET_12_0_1, B1_4;\n+\n+  assert_different_registers(tmp, eax, ebx, ecx, edx);\n+\n@@ -403,4 +198,0 @@\n-  address TWO_POW_55 = (address)_TWO_POW_55;\n-  address TWO_POW_M55 = (address)_TWO_POW_M55;\n-  address P_1 = (address)StubRoutines::x86::_P_1_addr();\n-  address NEG_ZERO = (address)StubRoutines::x86::_NEG_ZERO_addr();\n@@ -408,1 +199,0 @@\n-  bind(start);\n@@ -413,2 +203,2 @@\n-  movq(xmm1, ExternalAddress(PI32INV));    \/\/0x6dc9c883UL, 0x40245f30UL\n-  movq(xmm2, ExternalAddress(SHIFTER));    \/\/0x00000000UL, 0x43380000UL\n+  movq(xmm1, ExternalAddress(PI32INV), tmp \/*rscratch*\/); \/\/0x6dc9c883UL, 0x40245f30UL\n+  movq(xmm2, ExternalAddress(SHIFTER), tmp \/*rscratch*\/); \/\/0x00000000UL, 0x43380000UL\n@@ -420,2 +210,2 @@\n-  movdqu(xmm5, ExternalAddress(ONEHALF));    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-  movq(xmm4, ExternalAddress(SIGN_MASK));    \/\/0x00000000UL, 0x80000000UL\n+  movdqu(xmm5, ExternalAddress(ONEHALF), tmp \/*rscratch*\/); \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+  movq(xmm4, ExternalAddress(SIGN_MASK), tmp \/*rscratch*\/); \/\/0x00000000UL, 0x80000000UL\n@@ -427,1 +217,1 @@\n-  movdqu(xmm6, ExternalAddress(P_2));    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n+  movdqu(xmm6, ExternalAddress(P_2), tmp \/*rscratch*\/); \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n@@ -430,1 +220,1 @@\n-  movdqu(xmm5, ExternalAddress(SC_4));    \/\/0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n+  movdqu(xmm5, ExternalAddress(SC_4), tmp \/*rscratch*\/); \/\/0xa556c734UL, 0x3ec71de3UL, 0x1a01a01aUL, 0x3efa01a0UL\n@@ -435,2 +225,1 @@\n-  }\n-  else {\n+  } else {\n@@ -444,1 +233,1 @@\n-  mulsd(xmm1, ExternalAddress(P_3));    \/\/0x2e037073UL, 0x3b63198aUL\n+  mulsd(xmm1, ExternalAddress(P_3), tmp \/*rscratch*\/); \/\/0x2e037073UL, 0x3b63198aUL\n@@ -450,2 +239,1 @@\n-  }\n-  else {\n+  } else {\n@@ -465,1 +253,1 @@\n-  movdqu(xmm6, ExternalAddress(SC_2));    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n+  movdqu(xmm6, ExternalAddress(SC_2), tmp \/*rscratch*\/); \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n@@ -475,1 +263,1 @@\n-  addpd(xmm5, ExternalAddress(SC_3));    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n+  addpd(xmm5, ExternalAddress(SC_3), tmp \/*rscratch*\/); \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n@@ -477,1 +265,1 @@\n-  addpd(xmm6, ExternalAddress(SC_1));    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n+  addpd(xmm6, ExternalAddress(SC_1), tmp \/*rscratch*\/); \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n@@ -506,1 +294,1 @@\n-  mulsd(xmm0, ExternalAddress(ALL_ONES));    \/\/0xffffffffUL, 0x3fefffffUL\n+  mulsd(xmm0, ExternalAddress(ALL_ONES), tmp \/*rscratch*\/); \/\/0xffffffffUL, 0x3fefffffUL\n@@ -510,1 +298,1 @@\n-  movq(xmm3, ExternalAddress(TWO_POW_55));    \/\/0x00000000UL, 0x43600000UL\n+  movq(xmm3, ExternalAddress(TWO_POW_55), tmp \/*rscratch*\/); \/\/0x00000000UL, 0x43600000UL\n@@ -513,1 +301,1 @@\n-  mulsd(xmm3, ExternalAddress(TWO_POW_M55));    \/\/0x00000000UL, 0x3c800000UL\n+  mulsd(xmm3, ExternalAddress(TWO_POW_M55), tmp \/*rscratch*\/); \/\/0x00000000UL, 0x3c800000UL\n@@ -660,2 +448,2 @@\n-  movq(xmm2, ExternalAddress(PI_4));    \/\/0x40000000UL, 0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n-  movq(xmm6, ExternalAddress(8 + PI_4));    \/\/0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n+  movq(xmm2, ExternalAddress(PI_4),     tmp \/*rscratch*\/); \/\/0x40000000UL, 0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n+  movq(xmm6, ExternalAddress(PI_4 + 8), tmp \/*rscratch*\/); \/\/0x3fe921fbUL, 0x18469899UL, 0x3e64442dUL\n@@ -685,1 +473,1 @@\n-  movq(xmm1, ExternalAddress(PI32INV));    \/\/0x6dc9c883UL, 0x40245f30UL\n+  movq(xmm1, ExternalAddress(PI32INV), tmp \/*rscratch*\/);    \/\/0x6dc9c883UL, 0x40245f30UL\n@@ -687,2 +475,2 @@\n-  movq(xmm5, ExternalAddress(ONEHALF));    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-  movq(xmm4, ExternalAddress(SIGN_MASK));    \/\/0x00000000UL, 0x80000000UL\n+  movq(xmm5, ExternalAddress(ONEHALF), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+  movq(xmm4, ExternalAddress(SIGN_MASK), tmp \/*rscratch*\/);  \/\/0x00000000UL, 0x80000000UL\n@@ -694,2 +482,2 @@\n-  movq(xmm3, ExternalAddress(P_1));    \/\/0x54400000UL, 0x3fb921fbUL\n-  movdqu(xmm2, ExternalAddress(P_2));    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n+  movq(xmm3, ExternalAddress(P_1), tmp \/*rscratch*\/);      \/\/0x54400000UL, 0x3fb921fbUL\n+  movdqu(xmm2, ExternalAddress(P_2), tmp \/*rscratch*\/);    \/\/0x1a600000UL, 0x3d90b461UL, 0x1a600000UL, 0x3d90b461UL\n@@ -703,1 +491,1 @@\n-  movdqu(xmm5, ExternalAddress(SC_4));    \/\/0x54400000UL, 0x3fb921fbUL\n+  movdqu(xmm5, ExternalAddress(SC_4), tmp \/*rscratch*\/);    \/\/0x54400000UL, 0x3fb921fbUL\n@@ -709,1 +497,1 @@\n-  mulsd(xmm1, ExternalAddress(P_3));    \/\/0x2e037073UL, 0x3b63198aUL\n+  mulsd(xmm1, ExternalAddress(P_3), tmp \/*rscratch*\/);    \/\/0x2e037073UL, 0x3b63198aUL\n@@ -728,1 +516,1 @@\n-  movdqu(xmm6, ExternalAddress(SC_2));    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n+  movdqu(xmm6, ExternalAddress(SC_2), tmp \/*rscratch*\/);    \/\/0x11111111UL, 0x3f811111UL, 0x55555555UL, 0x3fa55555UL\n@@ -734,1 +522,1 @@\n-  addpd(xmm5, ExternalAddress(SC_3));    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n+  addpd(xmm5, ExternalAddress(SC_3), tmp \/*rscratch*\/);    \/\/0x1a01a01aUL, 0xbf2a01a0UL, 0x16c16c17UL, 0xbf56c16cUL\n@@ -736,1 +524,1 @@\n-  addpd(xmm6, ExternalAddress(SC_1));    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n+  addpd(xmm6, ExternalAddress(SC_1), tmp \/*rscratch*\/);    \/\/0x55555555UL, 0xbfc55555UL, 0x00000000UL, 0xbfe00000UL\n@@ -840,1 +628,1 @@\n-  mulsd(xmm0, ExternalAddress(NEG_ZERO));    \/\/0x00000000UL, 0x80000000UL\n+  mulsd(xmm0, ExternalAddress(NEG_ZERO), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x80000000UL\n@@ -1231,9 +1019,9 @@\n-  address zero_none = (address)_zero_none;\n-  address _4onpi_d = (address)__4onpi_d;\n-  address TWO_32H = (address)_TWO_32H;\n-  address pi04_3d = (address)_pi04_3d;\n-  address pi04_5d = (address)_pi04_5d;\n-  address SCALE = (address)_SCALE;\n-  address zeros = (address)_zeros;\n-  address pi04_2d = (address)_pi04_2d;\n-  address TWO_12H = (address)_TWO_12H;\n+  address zero_none  = (address)_zero_none;\n+  address _4onpi_d   = (address)__4onpi_d;\n+  address TWO_32H    = (address)_TWO_32H;\n+  address pi04_3d    = (address)_pi04_3d;\n+  address pi04_5d    = (address)_pi04_5d;\n+  address SCALE      = (address)_SCALE;\n+  address zeros      = (address)_zeros;\n+  address pi04_2d    = (address)_pi04_2d;\n+  address TWO_12H    = (address)_TWO_12H;\n@@ -1627,21 +1415,0 @@\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_L_2il0floatpacket_0[] =\n-{\n-    0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_Pi4Inv[] =\n-{\n-    0x6dc9c883UL, 0x3ff45f30UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_Pi4x3[] =\n-{\n-    0x54443000UL, 0xbfe921fbUL, 0x3b39a000UL, 0x3d373dcbUL, 0xe0e68948UL,\n-    0xba845c06UL\n-};\n-\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_Pi4x4[] =\n-{\n-    0x54400000UL, 0xbfe921fbUL, 0x1a600000UL, 0xbdc0b461UL, 0x2e000000UL,\n-    0xbb93198aUL, 0x252049c1UL, 0xb96b839aUL\n-};\n@@ -1667,5 +1434,0 @@\n-ATTRIBUTE_ALIGNED(16) juint StubRoutines::x86::_ones[] =\n-{\n-    0x00000000UL, 0x3ff00000UL, 0x00000000UL, 0xbff00000UL\n-};\n-\n@@ -1680,5 +1442,0 @@\n-  address L_2il0floatpacket_0 = StubRoutines::x86::_L_2il0floatpacket_0_addr();\n-  address Pi4Inv = StubRoutines::x86::_Pi4Inv_addr();\n-  address Pi4x3 = StubRoutines::x86::_Pi4x3_addr();\n-  address Pi4x4 = StubRoutines::x86::_Pi4x4_addr();\n-  address ones = StubRoutines::x86::_ones_addr();\n@@ -1709,1 +1466,1 @@\n-  andps(xmm1, ExternalAddress(L_2il0floatpacket_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n+  andps(xmm1, ExternalAddress(L_2IL0FLOATPACKET_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n@@ -1717,1 +1474,1 @@\n-  movsd(xmm0, ExternalAddress(Pi4Inv));    \/\/0x6dc9c883UL, 0x3ff45f30UL\n+  movsd(xmm0, ExternalAddress(PI4_INV));    \/\/0x6dc9c883UL, 0x3ff45f30UL\n@@ -1774,1 +1531,1 @@\n-  fld_d(ExternalAddress(Pi4x3));    \/\/0x54443000UL, 0xbfe921fbUL\n+  fld_d(ExternalAddress(PI4X3));    \/\/0x54443000UL, 0xbfe921fbUL\n@@ -1777,1 +1534,1 @@\n-  fld_d(ExternalAddress(8 + Pi4x3));    \/\/0x3b39a000UL, 0x3d373dcbUL\n+  fld_d(ExternalAddress(PI4X3 + 8));    \/\/0x3b39a000UL, 0x3d373dcbUL\n@@ -1780,1 +1537,1 @@\n-  fld_d(ExternalAddress(16 + Pi4x3));    \/\/0xe0e68948UL, 0xba845c06UL\n+  fld_d(ExternalAddress(PI4X3 + 16));    \/\/0xe0e68948UL, 0xba845c06UL\n@@ -1786,1 +1543,1 @@\n-  fld_d(ExternalAddress(Pi4x4));    \/\/0x54400000UL, 0xbfe921fbUL\n+  fld_d(ExternalAddress(PI4X4));    \/\/0x54400000UL, 0xbfe921fbUL\n@@ -1789,1 +1546,1 @@\n-  fld_d(ExternalAddress(8 + Pi4x4));    \/\/0x1a600000UL, 0xbdc0b461UL\n+  fld_d(ExternalAddress(PI4X4 + 8));    \/\/0x1a600000UL, 0xbdc0b461UL\n@@ -1792,1 +1549,1 @@\n-  fld_d(ExternalAddress(16 + Pi4x4));    \/\/0x2e000000UL, 0xbb93198aUL\n+  fld_d(ExternalAddress(PI4X4 + 16));    \/\/0x2e000000UL, 0xbb93198aUL\n@@ -1795,1 +1552,1 @@\n-  fld_d(ExternalAddress(24 + Pi4x4));    \/\/0x252049c1UL, 0xb96b839aUL\n+  fld_d(ExternalAddress(PI4X4 + 24));    \/\/0x252049c1UL, 0xb96b839aUL\n@@ -1899,2 +1656,2 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(esi, Address::times_8));\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(esi, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -2000,1 +1757,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(rsi, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(rsi, Address::times_8));\n@@ -2049,1 +1806,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(rsi, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(rsi, Address::times_8));\n@@ -2110,1 +1867,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -2161,1 +1918,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -2314,1 +2071,3 @@\n-void MacroAssembler::fast_sin(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ebx, Register edx) {\n+void MacroAssembler::fast_sin(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ebx, Register edx) {\n@@ -2317,1 +2076,2 @@\n-  Label L_2TAG_PACKET_4_0_2, start;\n+  Label L_2TAG_PACKET_4_0_2;\n+\n@@ -2319,0 +2079,1 @@\n+\n@@ -2321,1 +2082,0 @@\n-  bind(start);\n@@ -2443,1 +2203,1 @@\n-#endif\n+#endif \/\/ _LP64\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_sin.cpp","additions":66,"deletions":306,"binary":false,"changes":372,"status":"modified"},{"patch":"@@ -105,4 +105,0 @@\n-ATTRIBUTE_ALIGNED(16) juint _ONEHALF_tan[] =\n-{\n-    0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-};\n@@ -456,13 +452,0 @@\n-ATTRIBUTE_ALIGNED(16) juint _PI_INV_TABLE_tan[] =\n-{\n-    0x00000000UL, 0x00000000UL, 0xa2f9836eUL, 0x4e441529UL, 0xfc2757d1UL,\n-    0xf534ddc0UL, 0xdb629599UL, 0x3c439041UL, 0xfe5163abUL, 0xdebbc561UL,\n-    0xb7246e3aUL, 0x424dd2e0UL, 0x06492eeaUL, 0x09d1921cUL, 0xfe1deb1cUL,\n-    0xb129a73eUL, 0xe88235f5UL, 0x2ebb4484UL, 0xe99c7026UL, 0xb45f7e41UL,\n-    0x3991d639UL, 0x835339f4UL, 0x9c845f8bUL, 0xbdf9283bUL, 0x1ff897ffUL,\n-    0xde05980fUL, 0xef2f118bUL, 0x5a0a6d1fUL, 0x6d367ecfUL, 0x27cb09b7UL,\n-    0x4f463f66UL, 0x9e5fea2dUL, 0x7527bac7UL, 0xebe5f17bUL, 0x3d0739f7UL,\n-    0x8a5292eaUL, 0x6bfb5fb1UL, 0x1f8d5d08UL, 0x56033046UL, 0xfc7b6babUL,\n-    0xf0cfbc21UL\n-};\n-\n@@ -479,21 +462,4 @@\n-ATTRIBUTE_ALIGNED(8) juint _ONE_tan[] =\n-{\n-    0x00000000UL, 0x3ff00000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(8) juint _TWO_POW_55_tan[] =\n-{\n-    0x00000000UL, 0x43600000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) juint _TWO_POW_M55_tan[] =\n-{\n-    0x00000000UL, 0x3c800000UL\n-};\n-\n-ATTRIBUTE_ALIGNED(4) juint _NEG_ZERO_tan[] =\n-{\n-    0x00000000UL, 0x80000000UL\n-};\n-\n-void MacroAssembler::fast_tan(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3, XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7, Register eax, Register ecx, Register edx, Register r8, Register r9, Register r10, Register r11) {\n+void MacroAssembler::fast_tan(XMMRegister xmm0, XMMRegister xmm1, XMMRegister xmm2, XMMRegister xmm3,\n+                              XMMRegister xmm4, XMMRegister xmm5, XMMRegister xmm6, XMMRegister xmm7,\n+                              Register eax, Register ecx, Register edx, Register r8, Register r9,\n+                              Register r10, Register r11, Register tmp) {\n@@ -504,1 +470,3 @@\n-  Label L_2TAG_PACKET_12_0_1, L_2TAG_PACKET_13_0_1, L_2TAG_PACKET_14_0_1, B1_2, B1_4, start;\n+  Label L_2TAG_PACKET_12_0_1, L_2TAG_PACKET_13_0_1, L_2TAG_PACKET_14_0_1, B1_2, B1_4;\n+\n+  assert_different_registers(eax, ecx, edx, r8, r9, r10, r11, tmp);\n@@ -506,2 +474,1 @@\n-  address ONEHALF = (address)_ONEHALF_tan;\n-  address MUL16 = (address)_MUL16;\n+  address MUL16     = (address)_MUL16;\n@@ -509,20 +476,14 @@\n-  address PI32INV = (address)_PI32INV_tan;\n-  address P_1 = (address)_P_1_tan;\n-  address P_2 = (address)_P_2_tan;\n-  address P_3 = (address)_P_3_tan;\n-  address Ctable = (address)_Ctable_tan;\n-  address MASK_35 = (address)_MASK_35_tan;\n-  address Q_11 = (address)_Q_11_tan;\n-  address Q_9 = (address)_Q_9_tan;\n-  address Q_7 = (address)_Q_7_tan;\n-  address Q_5 = (address)_Q_5_tan;\n-  address Q_3 = (address)_Q_3_tan;\n-  address PI_INV_TABLE = (address)_PI_INV_TABLE_tan;\n-  address PI_4 = (address)_PI_4_tan;\n-  address QQ_2 = (address)_QQ_2_tan;\n-  address ONE = (address)_ONE_tan;\n-  address TWO_POW_55 = (address)_TWO_POW_55_tan;\n-  address TWO_POW_M55 = (address)_TWO_POW_M55_tan;\n-  address NEG_ZERO = (address)_NEG_ZERO_tan;\n-\n-  bind(start);\n+  address PI32INV   = (address)_PI32INV_tan;\n+  address P_1       = (address)_P_1_tan;\n+  address P_2       = (address)_P_2_tan;\n+  address P_3       = (address)_P_3_tan;\n+  address Ctable    = (address)_Ctable_tan;\n+  address MASK_35   = (address)_MASK_35_tan;\n+  address Q_11      = (address)_Q_11_tan;\n+  address Q_9       = (address)_Q_9_tan;\n+  address Q_7       = (address)_Q_7_tan;\n+  address Q_5       = (address)_Q_5_tan;\n+  address Q_3       = (address)_Q_3_tan;\n+  address PI_4      = (address)_PI_4_tan;\n+  address QQ_2      = (address)_QQ_2_tan;\n+\n@@ -539,2 +500,2 @@\n-  movdqu(xmm5, ExternalAddress(ONEHALF));    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-  movdqu(xmm6, ExternalAddress(MUL16));    \/\/0x00000000UL, 0x40300000UL, 0x00000000UL, 0x3ff00000UL\n+  movdqu(xmm5, ExternalAddress(ONEHALF), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+  movdqu(xmm6, ExternalAddress(MUL16), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x40300000UL, 0x00000000UL, 0x3ff00000UL\n@@ -542,1 +503,1 @@\n-  movdqu(xmm4, ExternalAddress(sign_mask));    \/\/0x00000000UL, 0x80000000UL, 0x00000000UL, 0x80000000UL\n+  movdqu(xmm4, ExternalAddress(sign_mask), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x80000000UL, 0x00000000UL, 0x80000000UL\n@@ -544,1 +505,1 @@\n-  movdqu(xmm1, ExternalAddress(PI32INV));    \/\/0x6dc9c883UL, 0x3fe45f30UL, 0x6dc9c883UL, 0x40245f30UL\n+  movdqu(xmm1, ExternalAddress(PI32INV), tmp \/*rscratch*\/);    \/\/0x6dc9c883UL, 0x3fe45f30UL, 0x6dc9c883UL, 0x40245f30UL\n@@ -554,2 +515,2 @@\n-  movdqu(xmm3, ExternalAddress(P_1));    \/\/0x54444000UL, 0x3fb921fbUL, 0x54440000UL, 0x3fb921fbUL\n-  movq(xmm5, ExternalAddress(QQ_2));    \/\/0x676733afUL, 0x3d32e7b9UL\n+  movdqu(xmm3, ExternalAddress(P_1), tmp \/*rscratch*\/);    \/\/0x54444000UL, 0x3fb921fbUL, 0x54440000UL, 0x3fb921fbUL\n+  movq(xmm5, ExternalAddress(QQ_2), tmp \/*rscratch*\/);    \/\/0x676733afUL, 0x3d32e7b9UL\n@@ -557,1 +518,1 @@\n-  movdqu(xmm4, ExternalAddress(P_2));    \/\/0x67674000UL, 0xbd32e7b9UL, 0x4c4c0000UL, 0x3d468c23UL\n+  movdqu(xmm4, ExternalAddress(P_2), tmp \/*rscratch*\/);    \/\/0x67674000UL, 0xbd32e7b9UL, 0x4c4c0000UL, 0x3d468c23UL\n@@ -565,1 +526,1 @@\n-  mulpd(xmm1, ExternalAddress(P_3));    \/\/0x3707344aUL, 0x3aa8a2e0UL, 0x03707345UL, 0x3ae98a2eUL\n+  mulpd(xmm1, ExternalAddress(P_3), tmp \/*rscratch*\/);    \/\/0x3707344aUL, 0x3aa8a2e0UL, 0x03707345UL, 0x3ae98a2eUL\n@@ -572,1 +533,1 @@\n-  movq(xmm6, ExternalAddress(ONE));    \/\/0x00000000UL, 0x3ff00000UL\n+  movq(xmm6, ExternalAddress(ONE), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff00000UL\n@@ -575,1 +536,1 @@\n-  andpd(xmm5, ExternalAddress(MASK_35));    \/\/0xfffc0000UL, 0xffffffffUL, 0x00000000UL, 0x00000000UL\n+  andpd(xmm5, ExternalAddress(MASK_35), tmp \/*rscratch*\/);    \/\/0xfffc0000UL, 0xffffffffUL, 0x00000000UL, 0x00000000UL\n@@ -628,1 +589,1 @@\n-  movq(xmm7, ExternalAddress(ONE));    \/\/0x00000000UL, 0x3ff00000UL\n+  movq(xmm7, ExternalAddress(ONE), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff00000UL\n@@ -658,1 +619,1 @@\n-  movq(xmm1, ExternalAddress(Q_11));    \/\/0xb8fe4d77UL, 0x3f82609aUL\n+  movq(xmm1, ExternalAddress(Q_11), tmp \/*rscratch*\/);    \/\/0xb8fe4d77UL, 0x3f82609aUL\n@@ -662,1 +623,1 @@\n-  addsd(xmm1, ExternalAddress(Q_9));    \/\/0xbf847a43UL, 0x3f9664a0UL\n+  addsd(xmm1, ExternalAddress(Q_9), tmp \/*rscratch*\/);    \/\/0xbf847a43UL, 0x3f9664a0UL\n@@ -664,1 +625,1 @@\n-  addsd(xmm1, ExternalAddress(Q_7));    \/\/0x52c4c8abUL, 0x3faba1baUL\n+  addsd(xmm1, ExternalAddress(Q_7), tmp \/*rscratch*\/);    \/\/0x52c4c8abUL, 0x3faba1baUL\n@@ -666,1 +627,1 @@\n-  addsd(xmm1, ExternalAddress(Q_5));    \/\/0x11092746UL, 0x3fc11111UL\n+  addsd(xmm1, ExternalAddress(Q_5), tmp \/*rscratch*\/);    \/\/0x11092746UL, 0x3fc11111UL\n@@ -668,1 +629,1 @@\n-  addsd(xmm1, ExternalAddress(Q_3));    \/\/0x55555612UL, 0x3fd55555UL\n+  addsd(xmm1, ExternalAddress(Q_3), tmp \/*rscratch*\/);    \/\/0x55555612UL, 0x3fd55555UL\n@@ -674,1 +635,1 @@\n-  movq(xmm3, ExternalAddress(TWO_POW_55));    \/\/0x00000000UL, 0x43600000UL\n+  movq(xmm3, ExternalAddress(TWO_POW_55), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x43600000UL\n@@ -677,1 +638,1 @@\n-  mulsd(xmm0, ExternalAddress(TWO_POW_M55));    \/\/0x00000000UL, 0x3c800000UL\n+  mulsd(xmm0, ExternalAddress(TWO_POW_M55), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3c800000UL\n@@ -828,2 +789,2 @@\n-  movq(xmm2, ExternalAddress(PI_4));    \/\/0x00000000UL, 0x3fe921fbUL, 0x4611a626UL, 0x3e85110bUL\n-  movq(xmm7, ExternalAddress(8 + PI_4));    \/\/0x3fe921fbUL, 0x4611a626UL, 0x3e85110bUL\n+  movq(xmm2, ExternalAddress(PI_4),     tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fe921fbUL, 0x4611a626UL, 0x3e85110bUL\n+  movq(xmm7, ExternalAddress(PI_4 + 8), tmp \/*rscratch*\/);    \/\/0x3fe921fbUL, 0x4611a626UL, 0x3e85110bUL\n@@ -851,1 +812,1 @@\n-  movdqu(xmm1, ExternalAddress(PI32INV));    \/\/0x6dc9c883UL, 0x3fe45f30UL, 0x6dc9c883UL, 0x40245f30UL\n+  movdqu(xmm1, ExternalAddress(PI32INV), tmp \/*rscratch*\/);    \/\/0x6dc9c883UL, 0x3fe45f30UL, 0x6dc9c883UL, 0x40245f30UL\n@@ -858,1 +819,1 @@\n-  movdqu(xmm4, ExternalAddress(sign_mask));    \/\/0x00000000UL, 0x80000000UL, 0x00000000UL, 0x80000000UL\n+  movdqu(xmm4, ExternalAddress(sign_mask), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x80000000UL, 0x00000000UL, 0x80000000UL\n@@ -867,2 +828,2 @@\n-  movdqu(xmm5, ExternalAddress(ONEHALF));    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n-  movdqu(xmm6, ExternalAddress(MUL16));    \/\/0x00000000UL, 0x40300000UL, 0x00000000UL, 0x3ff00000UL\n+  movdqu(xmm5, ExternalAddress(ONEHALF), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3fe00000UL, 0x00000000UL, 0x3fe00000UL\n+  movdqu(xmm6, ExternalAddress(MUL16), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x40300000UL, 0x00000000UL, 0x3ff00000UL\n@@ -877,2 +838,2 @@\n-  movdqu(xmm3, ExternalAddress(P_1));    \/\/0x54444000UL, 0x3fb921fbUL, 0x54440000UL, 0x3fb921fbUL\n-  movq(xmm5, ExternalAddress(QQ_2));    \/\/0x676733afUL, 0x3d32e7b9UL\n+  movdqu(xmm3, ExternalAddress(P_1), tmp \/*rscratch*\/);    \/\/0x54444000UL, 0x3fb921fbUL, 0x54440000UL, 0x3fb921fbUL\n+  movq(xmm5, ExternalAddress(QQ_2), tmp \/*rscratch*\/);    \/\/0x676733afUL, 0x3d32e7b9UL\n@@ -881,1 +842,1 @@\n-  movdqu(xmm4, ExternalAddress(P_2));    \/\/0x67674000UL, 0xbd32e7b9UL, 0x4c4c0000UL, 0x3d468c23UL\n+  movdqu(xmm4, ExternalAddress(P_2), tmp \/*rscratch*\/);    \/\/0x67674000UL, 0xbd32e7b9UL, 0x4c4c0000UL, 0x3d468c23UL\n@@ -890,1 +851,1 @@\n-  mulpd(xmm1, ExternalAddress(P_3));    \/\/0x3707344aUL, 0x3aa8a2e0UL, 0x03707345UL, 0x3ae98a2eUL\n+  mulpd(xmm1, ExternalAddress(P_3), tmp \/*rscratch*\/);    \/\/0x3707344aUL, 0x3aa8a2e0UL, 0x03707345UL, 0x3ae98a2eUL\n@@ -897,1 +858,1 @@\n-  movq(xmm6, ExternalAddress(ONE));    \/\/0x00000000UL, 0x3ff00000UL\n+  movq(xmm6, ExternalAddress(ONE), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff00000UL\n@@ -900,1 +861,1 @@\n-  andpd(xmm5, ExternalAddress(MASK_35));    \/\/0xfffc0000UL, 0xffffffffUL, 0x00000000UL, 0x00000000UL\n+  andpd(xmm5, ExternalAddress(MASK_35), tmp \/*rscratch*\/);    \/\/0xfffc0000UL, 0xffffffffUL, 0x00000000UL, 0x00000000UL\n@@ -954,1 +915,1 @@\n-  movq(xmm7, ExternalAddress(ONE));    \/\/0x00000000UL, 0x3ff00000UL\n+  movq(xmm7, ExternalAddress(ONE), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x3ff00000UL\n@@ -1051,1 +1012,1 @@\n-  mulsd(xmm0, ExternalAddress(NEG_ZERO));    \/\/0x00000000UL, 0x80000000UL\n+  mulsd(xmm0, ExternalAddress(NEG_ZERO), tmp \/*rscratch*\/);    \/\/0x00000000UL, 0x80000000UL\n@@ -1062,0 +1023,1 @@\n+\n@@ -1096,5 +1058,0 @@\n-  address L_2il0floatpacket_0 = StubRoutines::x86::_L_2il0floatpacket_0_addr();\n-  address Pi4Inv = StubRoutines::x86::_Pi4Inv_addr();\n-  address Pi4x3 = StubRoutines::x86::_Pi4x3_addr();\n-  address Pi4x4 = StubRoutines::x86::_Pi4x4_addr();\n-  address ones = StubRoutines::x86::_ones_addr();\n@@ -1134,1 +1091,1 @@\n-  andps(xmm1, ExternalAddress(L_2il0floatpacket_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n+  andps(xmm1, ExternalAddress(L_2IL0FLOATPACKET_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n@@ -1136,1 +1093,1 @@\n-  movsd(xmm0, ExternalAddress(Pi4Inv));    \/\/\/\/0x6dc9c883UL, 0x3ff45f30UL\n+  movsd(xmm0, ExternalAddress(PI4_INV));    \/\/\/\/0x6dc9c883UL, 0x3ff45f30UL\n@@ -1191,1 +1148,1 @@\n-  fld_d(ExternalAddress(Pi4x3));    \/\/0x54443000UL, 0xbfe921fbUL\n+  fld_d(ExternalAddress(PI4X3));    \/\/0x54443000UL, 0xbfe921fbUL\n@@ -1194,1 +1151,1 @@\n-  fld_d(ExternalAddress(8 + Pi4x3));    \/\/0x3b39a000UL, 0x3d373dcbUL\n+  fld_d(ExternalAddress(PI4X3 + 8));    \/\/0x3b39a000UL, 0x3d373dcbUL\n@@ -1197,1 +1154,1 @@\n-  fld_d(ExternalAddress(16 + Pi4x3));    \/\/0xe0e68948UL, 0xba845c06UL\n+  fld_d(ExternalAddress(PI4X3 + 16));    \/\/0xe0e68948UL, 0xba845c06UL\n@@ -1203,1 +1160,1 @@\n-  fld_d(ExternalAddress(Pi4x4));    \/\/0x54400000UL, 0xbfe921fbUL\n+  fld_d(ExternalAddress(PI4X4));    \/\/0x54400000UL, 0xbfe921fbUL\n@@ -1206,1 +1163,1 @@\n-  fld_d(ExternalAddress(8 + Pi4x4));    \/\/0x1a600000UL, 0xbdc0b461UL\n+  fld_d(ExternalAddress(PI4X4 + 8));    \/\/0x1a600000UL, 0xbdc0b461UL\n@@ -1209,1 +1166,1 @@\n-  fld_d(ExternalAddress(16 + Pi4x4));    \/\/0x2e000000UL, 0xbb93198aUL\n+  fld_d(ExternalAddress(PI4X4 + 16));    \/\/0x2e000000UL, 0xbb93198aUL\n@@ -1212,1 +1169,1 @@\n-  fld_d(ExternalAddress(24 + Pi4x4));    \/\/0x252049c1UL, 0xb96b839aUL\n+  fld_d(ExternalAddress(PI4X4 + 24));    \/\/0x252049c1UL, 0xb96b839aUL\n@@ -1237,1 +1194,1 @@\n-  andps(xmm0, ExternalAddress(L_2il0floatpacket_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n+  andps(xmm0, ExternalAddress(L_2IL0FLOATPACKET_0));    \/\/0xffffffffUL, 0x7fffffffUL, 0x00000000UL, 0x00000000UL\n@@ -1262,1 +1219,1 @@\n-  fld_d(ExternalAddress(ones));\n+  fld_d(ExternalAddress(ONES));\n@@ -1348,1 +1305,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -1370,1 +1327,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -1415,1 +1372,1 @@\n-  fld_d(ExternalAddress(ones));\n+  fld_d(ExternalAddress(ONES));\n@@ -1467,1 +1424,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -1501,1 +1458,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -1564,1 +1521,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -1573,1 +1530,1 @@\n-  fld_d(ExternalAddress(ones));\n+  fld_d(ExternalAddress(ONES));\n@@ -1624,1 +1581,1 @@\n-  fld_d(Address(ones, RelocationHolder::none).plus_disp(eax, Address::times_8));\n+  fld_d(Address(ONES, RelocationHolder::none).plus_disp(eax, Address::times_8));\n@@ -1970,1 +1927,0 @@\n-  Label start;\n@@ -1976,1 +1932,0 @@\n-  bind(start);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_tan.cpp","additions":74,"deletions":119,"binary":false,"changes":193,"status":"modified"},{"patch":"@@ -4121,9 +4121,0 @@\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin) ||\n-          vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos) ||\n-          vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {\n-        StubRoutines::x86::_L_2il0floatpacket_0_adr = (address)StubRoutines::x86::_L_2il0floatpacket_0;\n-        StubRoutines::x86::_Pi4Inv_adr = (address)StubRoutines::x86::_Pi4Inv;\n-        StubRoutines::x86::_Pi4x3_adr = (address)StubRoutines::x86::_Pi4x3;\n-        StubRoutines::x86::_Pi4x4_adr = (address)StubRoutines::x86::_Pi4x4;\n-        StubRoutines::x86::_ones_adr = (address)StubRoutines::x86::_ones;\n-      }\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -7266,12 +7266,0 @@\n-    const XMMRegister x0  = xmm0;\n-    const XMMRegister x1  = xmm1;\n-    const XMMRegister x2  = xmm2;\n-    const XMMRegister x3  = xmm3;\n-\n-    const XMMRegister x4  = xmm4;\n-    const XMMRegister x5  = xmm5;\n-    const XMMRegister x6  = xmm6;\n-    const XMMRegister x7  = xmm7;\n-\n-    const Register tmp   = r11;\n-\n@@ -7281,1 +7269,2 @@\n-    __ fast_exp(x0, x1, x2, x3, x4, x5, x6, x7, rax, rcx, rdx, tmp);\n+    __ fast_exp(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                rax, rcx, rdx, r11);\n@@ -7295,13 +7284,0 @@\n-    const XMMRegister x0 = xmm0;\n-    const XMMRegister x1 = xmm1;\n-    const XMMRegister x2 = xmm2;\n-    const XMMRegister x3 = xmm3;\n-\n-    const XMMRegister x4 = xmm4;\n-    const XMMRegister x5 = xmm5;\n-    const XMMRegister x6 = xmm6;\n-    const XMMRegister x7 = xmm7;\n-\n-    const Register tmp1 = r11;\n-    const Register tmp2 = r8;\n-\n@@ -7311,1 +7287,2 @@\n-    __ fast_log(x0, x1, x2, x3, x4, x5, x6, x7, rax, rcx, rdx, tmp1, tmp2);\n+    __ fast_log(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                rax, rcx, rdx, r11, r8);\n@@ -7325,12 +7302,0 @@\n-    const XMMRegister x0 = xmm0;\n-    const XMMRegister x1 = xmm1;\n-    const XMMRegister x2 = xmm2;\n-    const XMMRegister x3 = xmm3;\n-\n-    const XMMRegister x4 = xmm4;\n-    const XMMRegister x5 = xmm5;\n-    const XMMRegister x6 = xmm6;\n-    const XMMRegister x7 = xmm7;\n-\n-    const Register tmp = r11;\n-\n@@ -7340,1 +7305,2 @@\n-    __ fast_log10(x0, x1, x2, x3, x4, x5, x6, x7, rax, rcx, rdx, tmp);\n+    __ fast_log10(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                  rax, rcx, rdx, r11, r8);\n@@ -7354,15 +7320,0 @@\n-    const XMMRegister x0 = xmm0;\n-    const XMMRegister x1 = xmm1;\n-    const XMMRegister x2 = xmm2;\n-    const XMMRegister x3 = xmm3;\n-\n-    const XMMRegister x4 = xmm4;\n-    const XMMRegister x5 = xmm5;\n-    const XMMRegister x6 = xmm6;\n-    const XMMRegister x7 = xmm7;\n-\n-    const Register tmp1 = r8;\n-    const Register tmp2 = r9;\n-    const Register tmp3 = r10;\n-    const Register tmp4 = r11;\n-\n@@ -7372,1 +7323,2 @@\n-    __ fast_pow(x0, x1, x2, x3, x4, x5, x6, x7, rax, rcx, rdx, tmp1, tmp2, tmp3, tmp4);\n+    __ fast_pow(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                rax, rcx, rdx, r8, r9, r10, r11);\n@@ -7386,15 +7338,0 @@\n-    const XMMRegister x0 = xmm0;\n-    const XMMRegister x1 = xmm1;\n-    const XMMRegister x2 = xmm2;\n-    const XMMRegister x3 = xmm3;\n-\n-    const XMMRegister x4 = xmm4;\n-    const XMMRegister x5 = xmm5;\n-    const XMMRegister x6 = xmm6;\n-    const XMMRegister x7 = xmm7;\n-\n-    const Register tmp1 = r8;\n-    const Register tmp2 = r9;\n-    const Register tmp3 = r10;\n-    const Register tmp4 = r11;\n-\n@@ -7408,1 +7345,2 @@\n-    __ fast_sin(x0, x1, x2, x3, x4, x5, x6, x7, rax, rbx, rcx, rdx, tmp1, tmp2, tmp3, tmp4);\n+    __ fast_sin(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                rax, rbx, rcx, rdx, r8);\n@@ -7427,15 +7365,0 @@\n-    const XMMRegister x0 = xmm0;\n-    const XMMRegister x1 = xmm1;\n-    const XMMRegister x2 = xmm2;\n-    const XMMRegister x3 = xmm3;\n-\n-    const XMMRegister x4 = xmm4;\n-    const XMMRegister x5 = xmm5;\n-    const XMMRegister x6 = xmm6;\n-    const XMMRegister x7 = xmm7;\n-\n-    const Register tmp1 = r8;\n-    const Register tmp2 = r9;\n-    const Register tmp3 = r10;\n-    const Register tmp4 = r11;\n-\n@@ -7449,1 +7372,2 @@\n-    __ fast_cos(x0, x1, x2, x3, x4, x5, x6, x7, rax, rcx, rdx, tmp1, tmp2, tmp3, tmp4);\n+    __ fast_cos(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                rax, rcx, rdx, r8, r9, r10, r11, rbx);\n@@ -7468,15 +7392,0 @@\n-    const XMMRegister x0 = xmm0;\n-    const XMMRegister x1 = xmm1;\n-    const XMMRegister x2 = xmm2;\n-    const XMMRegister x3 = xmm3;\n-\n-    const XMMRegister x4 = xmm4;\n-    const XMMRegister x5 = xmm5;\n-    const XMMRegister x6 = xmm6;\n-    const XMMRegister x7 = xmm7;\n-\n-    const Register tmp1 = r8;\n-    const Register tmp2 = r9;\n-    const Register tmp3 = r10;\n-    const Register tmp4 = r11;\n-\n@@ -7490,1 +7399,2 @@\n-    __ fast_tan(x0, x1, x2, x3, x4, x5, x6, x7, rax, rcx, rdx, tmp1, tmp2, tmp3, tmp4);\n+    __ fast_tan(xmm0, xmm1, xmm2, xmm3, xmm4, xmm5, xmm6, xmm7,\n+                rax, rcx, rdx, r8, r9, r10, r11, rbx);\n@@ -7936,18 +7846,0 @@\n-      if (vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dsin) ||\n-          vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dcos) ||\n-          vmIntrinsics::is_intrinsic_available(vmIntrinsics::_dtan)) {\n-        StubRoutines::x86::_ONEHALF_adr = (address)StubRoutines::x86::_ONEHALF;\n-        StubRoutines::x86::_P_2_adr = (address)StubRoutines::x86::_P_2;\n-        StubRoutines::x86::_SC_4_adr = (address)StubRoutines::x86::_SC_4;\n-        StubRoutines::x86::_Ctable_adr = (address)StubRoutines::x86::_Ctable;\n-        StubRoutines::x86::_SC_2_adr = (address)StubRoutines::x86::_SC_2;\n-        StubRoutines::x86::_SC_3_adr = (address)StubRoutines::x86::_SC_3;\n-        StubRoutines::x86::_SC_1_adr = (address)StubRoutines::x86::_SC_1;\n-        StubRoutines::x86::_PI_INV_TABLE_adr = (address)StubRoutines::x86::_PI_INV_TABLE;\n-        StubRoutines::x86::_PI_4_adr = (address)StubRoutines::x86::_PI_4;\n-        StubRoutines::x86::_PI32INV_adr = (address)StubRoutines::x86::_PI32INV;\n-        StubRoutines::x86::_SIGN_MASK_adr = (address)StubRoutines::x86::_SIGN_MASK;\n-        StubRoutines::x86::_P_1_adr = (address)StubRoutines::x86::_P_1;\n-        StubRoutines::x86::_P_3_adr = (address)StubRoutines::x86::_P_3;\n-        StubRoutines::x86::_NEG_ZERO_adr = (address)StubRoutines::x86::_NEG_ZERO;\n-      }\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":14,"deletions":122,"binary":false,"changes":136,"status":"modified"},{"patch":"@@ -94,23 +94,0 @@\n-\/\/tables common for sin and cos\n-address StubRoutines::x86::_ONEHALF_adr = NULL;\n-address StubRoutines::x86::_P_2_adr = NULL;\n-address StubRoutines::x86::_SC_4_adr = NULL;\n-address StubRoutines::x86::_Ctable_adr = NULL;\n-address StubRoutines::x86::_SC_2_adr = NULL;\n-address StubRoutines::x86::_SC_3_adr = NULL;\n-address StubRoutines::x86::_SC_1_adr = NULL;\n-address StubRoutines::x86::_PI_INV_TABLE_adr = NULL;\n-address StubRoutines::x86::_PI_4_adr = NULL;\n-address StubRoutines::x86::_PI32INV_adr = NULL;\n-address StubRoutines::x86::_SIGN_MASK_adr = NULL;\n-address StubRoutines::x86::_P_1_adr = NULL;\n-address StubRoutines::x86::_P_3_adr = NULL;\n-address StubRoutines::x86::_NEG_ZERO_adr = NULL;\n-\n-\/\/tables common for sincos and tancot\n-address StubRoutines::x86::_L_2il0floatpacket_0_adr = NULL;\n-address StubRoutines::x86::_Pi4Inv_adr = NULL;\n-address StubRoutines::x86::_Pi4x3_adr = NULL;\n-address StubRoutines::x86::_Pi4x4_adr = NULL;\n-address StubRoutines::x86::_ones_adr = NULL;\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":0,"deletions":23,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -214,42 +214,0 @@\n-  \/\/tables common for LIBM sin and cos\n-  static juint _ONEHALF[];\n-  static address _ONEHALF_adr;\n-  static juint _P_2[];\n-  static address _P_2_adr;\n-  static juint _SC_4[];\n-  static address _SC_4_adr;\n-  static juint _Ctable[];\n-  static address _Ctable_adr;\n-  static juint _SC_2[];\n-  static address _SC_2_adr;\n-  static juint _SC_3[];\n-  static address _SC_3_adr;\n-  static juint _SC_1[];\n-  static address _SC_1_adr;\n-  static juint _PI_INV_TABLE[];\n-  static address _PI_INV_TABLE_adr;\n-  static juint _PI_4[];\n-  static address _PI_4_adr;\n-  static juint _PI32INV[];\n-  static address _PI32INV_adr;\n-  static juint _SIGN_MASK[];\n-  static address _SIGN_MASK_adr;\n-  static juint _P_1[];\n-  static address _P_1_adr;\n-  static juint _P_3[];\n-  static address _P_3_adr;\n-  static juint _NEG_ZERO[];\n-  static address _NEG_ZERO_adr;\n-\n-  \/\/tables common for LIBM sincos and tancot\n-  static juint _L_2il0floatpacket_0[];\n-  static address _L_2il0floatpacket_0_adr;\n-  static juint _Pi4Inv[];\n-  static address _Pi4Inv_adr;\n-  static juint _Pi4x3[];\n-  static address _Pi4x3_adr;\n-  static juint _Pi4x4[];\n-  static address _Pi4x4_adr;\n-  static juint _ones[];\n-  static address _ones_adr;\n-\n@@ -394,20 +352,0 @@\n-  static address _ONEHALF_addr()      { return _ONEHALF_adr; }\n-  static address _P_2_addr()      { return _P_2_adr; }\n-  static address _SC_4_addr()      { return _SC_4_adr; }\n-  static address _Ctable_addr()      { return _Ctable_adr; }\n-  static address _SC_2_addr()      { return _SC_2_adr; }\n-  static address _SC_3_addr()      { return _SC_3_adr; }\n-  static address _SC_1_addr()      { return _SC_1_adr; }\n-  static address _PI_INV_TABLE_addr()      { return _PI_INV_TABLE_adr; }\n-  static address _PI_4_addr()      { return _PI_4_adr; }\n-  static address _PI32INV_addr()      { return _PI32INV_adr; }\n-  static address _SIGN_MASK_addr()      { return _SIGN_MASK_adr; }\n-  static address _P_1_addr()      { return _P_1_adr; }\n-  static address _P_3_addr()      { return _P_3_adr; }\n-  static address _NEG_ZERO_addr()      { return _NEG_ZERO_adr; }\n-  static address _L_2il0floatpacket_0_addr()      { return _L_2il0floatpacket_0_adr; }\n-  static address _Pi4Inv_addr()      { return _Pi4Inv_adr; }\n-  static address _Pi4x3_addr()      { return _Pi4x3_adr; }\n-  static address _Pi4x4_addr()      { return _Pi4x4_adr; }\n-  static address _ones_addr()      { return _ones_adr; }\n-\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":0,"deletions":62,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -3749,1 +3749,1 @@\n-instruct reinterpret_expand(vec dst, vec src, rRegP scratch) %{\n+instruct reinterpret_expand(vec dst, vec src) %{\n@@ -3754,2 +3754,2 @@\n-  effect(TEMP dst, TEMP scratch);\n-  format %{ \"vector_reinterpret_expand $dst,$src\\t! using $scratch as TEMP\" %}\n+  effect(TEMP dst);\n+  format %{ \"vector_reinterpret_expand $dst,$src\" %}\n@@ -3762,1 +3762,1 @@\n-      __ movdqu($dst$$XMMRegister, ExternalAddress(vector_32_bit_mask()), $scratch$$Register);\n+      __ movdqu($dst$$XMMRegister, ExternalAddress(vector_32_bit_mask()), noreg);\n@@ -3765,1 +3765,1 @@\n-      __ movdqu($dst$$XMMRegister, ExternalAddress(vector_64_bit_mask()), $scratch$$Register);\n+      __ movdqu($dst$$XMMRegister, ExternalAddress(vector_64_bit_mask()), noreg);\n@@ -3772,1 +3772,1 @@\n-instruct vreinterpret_expand4(legVec dst, vec src, rRegP scratch) %{\n+instruct vreinterpret_expand4(legVec dst, vec src) %{\n@@ -3779,2 +3779,1 @@\n-  effect(TEMP scratch);\n-  format %{ \"vector_reinterpret_expand $dst,$src\\t! using $scratch as TEMP\" %}\n+  format %{ \"vector_reinterpret_expand $dst,$src\" %}\n@@ -3782,1 +3781,1 @@\n-    __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_32_bit_mask()), 0, $scratch$$Register);\n+    __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_32_bit_mask()), 0, noreg);\n@@ -3850,1 +3849,1 @@\n-instruct roundD_imm(legRegD dst, immD con, immU8 rmode, rRegI scratch_reg) %{\n+instruct roundD_imm(legRegD dst, immD con, immU8 rmode) %{\n@@ -3852,1 +3851,0 @@\n-  effect(TEMP scratch_reg);\n@@ -3857,1 +3855,1 @@\n-    __ roundsd($dst$$XMMRegister, $constantaddress($con), $rmode$$constant, $scratch_reg$$Register);\n+    __ roundsd($dst$$XMMRegister, $constantaddress($con), $rmode$$constant, noreg);\n@@ -4018,1 +4016,1 @@\n-      __ movdqu($mask$$XMMRegister, ExternalAddress(vector_all_bits_set()));\n+      __ movdqu($mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), noreg);\n@@ -4020,1 +4018,1 @@\n-      __ vmovdqu($mask$$XMMRegister, ExternalAddress(vector_all_bits_set()));\n+      __ vmovdqu($mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), noreg);\n@@ -4041,1 +4039,1 @@\n-    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n+    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), noreg);\n@@ -4082,1 +4080,1 @@\n-    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n+    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), noreg);\n@@ -5620,1 +5618,1 @@\n-instruct mulB_reg(vec dst, vec src1, vec src2, vec tmp, rRegI scratch) %{\n+instruct mulB_reg(vec dst, vec src1, vec src2, vec tmp) %{\n@@ -5624,1 +5622,1 @@\n-  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp);\n@@ -5631,1 +5629,1 @@\n-    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -5638,1 +5636,1 @@\n-instruct mul16B_reg(vec dst, vec src1, vec src2, vec tmp1, vec tmp2, rRegI scratch) %{\n+instruct mul16B_reg(vec dst, vec src1, vec src2, vec tmp1, vec tmp2) %{\n@@ -5641,1 +5639,1 @@\n-  effect(TEMP dst, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp1, TEMP tmp2);\n@@ -5653,1 +5651,1 @@\n-    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -5661,1 +5659,1 @@\n-instruct vmul16B_reg_avx(vec dst, vec src1, vec src2, vec tmp, rRegI scratch) %{\n+instruct vmul16B_reg_avx(vec dst, vec src1, vec src2, vec tmp) %{\n@@ -5664,1 +5662,1 @@\n-  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp);\n@@ -5671,1 +5669,1 @@\n-    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -5679,1 +5677,1 @@\n-instruct vmul32B_reg_avx(vec dst, vec src1, vec src2, vec tmp1, vec tmp2, rRegI scratch) %{\n+instruct vmul32B_reg_avx(vec dst, vec src1, vec src2, vec tmp1, vec tmp2) %{\n@@ -5682,1 +5680,1 @@\n-  effect(TEMP dst, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp1, TEMP tmp2);\n@@ -5695,1 +5693,1 @@\n-    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -5705,1 +5703,1 @@\n-instruct vmul64B_reg_avx(vec dst, vec src1, vec src2, vec tmp1, vec tmp2, rRegI scratch) %{\n+instruct vmul64B_reg_avx(vec dst, vec src1, vec src2, vec tmp1, vec tmp2) %{\n@@ -5708,1 +5706,1 @@\n-  effect(TEMP dst, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp1, TEMP tmp2);\n@@ -5721,1 +5719,1 @@\n-    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -5726,1 +5724,1 @@\n-    __ evmovdquq($tmp2$$XMMRegister, ExternalAddress(vector_byte_perm_mask()), vlen_enc, $scratch$$Register);\n+    __ evmovdquq($tmp2$$XMMRegister, ExternalAddress(vector_byte_perm_mask()), vlen_enc, noreg);\n@@ -6190,1 +6188,1 @@\n-instruct signumF_reg(regF dst, regF zero, regF one, rRegP scratch, rFlagsReg cr) %{\n+instruct signumF_reg(regF dst, regF zero, regF one, rFlagsReg cr) %{\n@@ -6192,2 +6190,2 @@\n-  effect(TEMP scratch, KILL cr);\n-  format %{ \"signumF $dst, $dst\\t! using $scratch as TEMP\" %}\n+  effect(KILL cr);\n+  format %{ \"signumF $dst, $dst\" %}\n@@ -6196,1 +6194,1 @@\n-    __ signum_fp(opcode, $dst$$XMMRegister, $zero$$XMMRegister, $one$$XMMRegister, $scratch$$Register);\n+    __ signum_fp(opcode, $dst$$XMMRegister, $zero$$XMMRegister, $one$$XMMRegister);\n@@ -6201,1 +6199,1 @@\n-instruct signumD_reg(regD dst, regD zero, regD one, rRegP scratch, rFlagsReg cr) %{\n+instruct signumD_reg(regD dst, regD zero, regD one, rFlagsReg cr) %{\n@@ -6203,2 +6201,2 @@\n-  effect(TEMP scratch, KILL cr);\n-  format %{ \"signumD $dst, $dst\\t! using $scratch as TEMP\" %}\n+  effect(KILL cr);\n+  format %{ \"signumD $dst, $dst\" %}\n@@ -6207,1 +6205,1 @@\n-    __ signum_fp(opcode, $dst$$XMMRegister, $zero$$XMMRegister, $one$$XMMRegister, $scratch$$Register);\n+    __ signum_fp(opcode, $dst$$XMMRegister, $zero$$XMMRegister, $one$$XMMRegister);\n@@ -6400,1 +6398,1 @@\n-instruct vshiftB(vec dst, vec src, vec shift, vec tmp, rRegI scratch) %{\n+instruct vshiftB(vec dst, vec src, vec shift, vec tmp) %{\n@@ -6405,1 +6403,1 @@\n-  effect(TEMP dst, USE src, USE shift, TEMP tmp, TEMP scratch);\n+  effect(TEMP dst, USE src, USE shift, TEMP tmp);\n@@ -6413,1 +6411,1 @@\n-    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -6420,1 +6418,1 @@\n-instruct vshift16B(vec dst, vec src, vec shift, vec tmp1, vec tmp2, rRegI scratch) %{\n+instruct vshift16B(vec dst, vec src, vec shift, vec tmp1, vec tmp2) %{\n@@ -6426,1 +6424,1 @@\n-  effect(TEMP dst, USE src, USE shift, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  effect(TEMP dst, USE src, USE shift, TEMP tmp1, TEMP tmp2);\n@@ -6437,1 +6435,1 @@\n-    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -6445,1 +6443,1 @@\n-instruct vshift16B_avx(vec dst, vec src, vec shift, vec tmp, rRegI scratch) %{\n+instruct vshift16B_avx(vec dst, vec src, vec shift, vec tmp) %{\n@@ -6451,1 +6449,1 @@\n-  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp);\n@@ -6459,1 +6457,1 @@\n-    __ vpand($tmp$$XMMRegister, $tmp$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($tmp$$XMMRegister, $tmp$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, noreg);\n@@ -6466,1 +6464,1 @@\n-instruct vshift32B_avx(vec dst, vec src, vec shift, vec tmp, rRegI scratch) %{\n+instruct vshift32B_avx(vec dst, vec src, vec shift, vec tmp) %{\n@@ -6471,1 +6469,1 @@\n-  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp);\n@@ -6483,2 +6481,2 @@\n-    __ vpand($tmp$$XMMRegister, $tmp$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n-    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($tmp$$XMMRegister, $tmp$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, noreg);\n+    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, noreg);\n@@ -6491,1 +6489,1 @@\n-instruct vshift64B_avx(vec dst, vec src, vec shift, vec tmp1, vec tmp2, rRegI scratch) %{\n+instruct vshift64B_avx(vec dst, vec src, vec shift, vec tmp1, vec tmp2) %{\n@@ -6496,1 +6494,1 @@\n-  effect(TEMP dst, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp1, TEMP tmp2);\n@@ -6508,1 +6506,1 @@\n-    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), noreg);\n@@ -6513,1 +6511,1 @@\n-    __ evmovdquq($tmp2$$XMMRegister, ExternalAddress(vector_byte_perm_mask()), vlen_enc, $scratch$$Register);\n+    __ evmovdquq($tmp2$$XMMRegister, ExternalAddress(vector_byte_perm_mask()), vlen_enc, noreg);\n@@ -6650,1 +6648,1 @@\n-instruct vshiftL_arith_reg(vec dst, vec src, vec shift, vec tmp, rRegI scratch) %{\n+instruct vshiftL_arith_reg(vec dst, vec src, vec shift, vec tmp) %{\n@@ -6653,1 +6651,1 @@\n-  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  effect(TEMP dst, TEMP tmp);\n@@ -6661,1 +6659,1 @@\n-      __ movdqu($tmp$$XMMRegister, ExternalAddress(vector_long_sign_mask()), $scratch$$Register);\n+      __ movdqu($tmp$$XMMRegister, ExternalAddress(vector_long_sign_mask()), noreg);\n@@ -6670,1 +6668,1 @@\n-      __ vmovdqu($tmp$$XMMRegister, ExternalAddress(vector_long_sign_mask()), $scratch$$Register);\n+      __ vmovdqu($tmp$$XMMRegister, ExternalAddress(vector_long_sign_mask()), noreg);\n@@ -6692,1 +6690,1 @@\n-instruct vshift8B_var_nobw(vec dst, vec src, vec shift, vec vtmp, rRegP scratch) %{\n+instruct vshift8B_var_nobw(vec dst, vec src, vec shift, vec vtmp) %{\n@@ -6699,2 +6697,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp, $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp as TEMP\" %}\n@@ -6706,1 +6704,1 @@\n-    __ varshiftbw(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp$$XMMRegister);\n@@ -6712,1 +6710,1 @@\n-instruct vshift16B_var_nobw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2, rRegP scratch) %{\n+instruct vshift16B_var_nobw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2) %{\n@@ -6719,2 +6717,2 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n-  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp1, $vtmp2 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp1, $vtmp2 as TEMP\" %}\n@@ -6727,1 +6725,1 @@\n-    __ varshiftbw(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp1$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp1$$XMMRegister);\n@@ -6732,1 +6730,1 @@\n-    __ varshiftbw(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister);\n@@ -6740,1 +6738,1 @@\n-instruct vshift32B_var_nobw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2, vec vtmp3, vec vtmp4, rRegP scratch) %{\n+instruct vshift32B_var_nobw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2, vec vtmp3, vec vtmp4) %{\n@@ -6747,2 +6745,2 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP vtmp3, TEMP vtmp4, TEMP scratch);\n-  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t using $vtmp1, $vtmp2, $vtmp3, $vtmp4 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP vtmp3, TEMP vtmp4);\n+  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t using $vtmp1, $vtmp2, $vtmp3, $vtmp4 as TEMP\" %}\n@@ -6755,1 +6753,1 @@\n-    __ varshiftbw(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp1$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp1$$XMMRegister);\n@@ -6758,1 +6756,1 @@\n-    __ varshiftbw(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister);\n@@ -6764,1 +6762,1 @@\n-    __ varshiftbw(opcode, $vtmp3$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp4$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $vtmp3$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp4$$XMMRegister);\n@@ -6767,1 +6765,1 @@\n-    __ varshiftbw(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister, $scratch$$Register);\n+    __ varshiftbw(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister);\n@@ -6776,1 +6774,1 @@\n-instruct vshiftB_var_evex_bw(vec dst, vec src, vec shift, vec vtmp, rRegP scratch) %{\n+instruct vshiftB_var_evex_bw(vec dst, vec src, vec shift, vec vtmp) %{\n@@ -6783,2 +6781,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp, $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp as TEMP\" %}\n@@ -6790,1 +6788,1 @@\n-    __ evarshiftb(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp$$XMMRegister, $scratch$$Register);\n+    __ evarshiftb(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp$$XMMRegister);\n@@ -6795,1 +6793,1 @@\n-instruct vshift64B_var_evex_bw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2, rRegP scratch) %{\n+instruct vshift64B_var_evex_bw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2) %{\n@@ -6802,2 +6800,2 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n-  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp1, $vtmp2 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_varshift_byte $dst, $src, $shift\\n\\t! using $vtmp1, $vtmp2 as TEMP\" %}\n@@ -6809,1 +6807,1 @@\n-    __ evarshiftb(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp1$$XMMRegister, $scratch$$Register);\n+    __ evarshiftb(opcode, $dst$$XMMRegister, $src$$XMMRegister, $shift$$XMMRegister, vlen_enc, $vtmp1$$XMMRegister);\n@@ -6812,1 +6810,1 @@\n-    __ evarshiftb(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister, $scratch$$Register);\n+    __ evarshiftb(opcode, $vtmp1$$XMMRegister, $vtmp1$$XMMRegister, $vtmp2$$XMMRegister, vlen_enc, $vtmp2$$XMMRegister);\n@@ -6819,1 +6817,1 @@\n-instruct vshift8S_var_nobw(vec dst, vec src, vec shift, vec vtmp, rRegP scratch) %{\n+instruct vshift8S_var_nobw(vec dst, vec src, vec shift, vec vtmp) %{\n@@ -6826,1 +6824,1 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n+  effect(TEMP dst, TEMP vtmp);\n@@ -6837,1 +6835,1 @@\n-    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, noreg);\n@@ -6844,1 +6842,1 @@\n-instruct vshift16S_var_nobw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2, rRegP scratch) %{\n+instruct vshift16S_var_nobw(vec dst, vec src, vec shift, vec vtmp1, vec vtmp2) %{\n@@ -6851,1 +6849,1 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n@@ -6863,1 +6861,1 @@\n-    __ vpand($vtmp2$$XMMRegister, $vtmp2$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($vtmp2$$XMMRegister, $vtmp2$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, noreg);\n@@ -6871,1 +6869,1 @@\n-    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, noreg);\n@@ -7083,1 +7081,1 @@\n-instruct castStoX(vec dst, vec src, rRegP scratch) %{\n+instruct castStoX(vec dst, vec src) %{\n@@ -7087,1 +7085,0 @@\n-  effect(TEMP scratch);\n@@ -7089,1 +7086,1 @@\n-  format %{ \"vector_cast_s2x $dst,$src\\t! using $scratch as TEMP\" %}\n+  format %{ \"vector_cast_s2x $dst,$src\" %}\n@@ -7093,1 +7090,1 @@\n-    __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), 0, $scratch$$Register);\n+    __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), 0, noreg);\n@@ -7099,1 +7096,1 @@\n-instruct vcastStoX(vec dst, vec src, vec vtmp, rRegP scratch) %{\n+instruct vcastStoX(vec dst, vec src, vec vtmp) %{\n@@ -7103,1 +7100,1 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n+  effect(TEMP dst, TEMP vtmp);\n@@ -7105,1 +7102,1 @@\n-  format %{ \"vector_cast_s2x $dst,$src\\t! using $vtmp, $scratch as TEMP\" %}\n+  format %{ \"vector_cast_s2x $dst,$src\\t! using $vtmp as TEMP\" %}\n@@ -7110,1 +7107,1 @@\n-    __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, noreg);\n@@ -7156,1 +7153,1 @@\n-instruct castItoX(vec dst, vec src, rRegP scratch) %{\n+instruct castItoX(vec dst, vec src) %{\n@@ -7161,2 +7158,1 @@\n-  format %{ \"vector_cast_i2x $dst,$src\\t! using $scratch as TEMP\" %}\n-  effect(TEMP scratch);\n+  format %{ \"vector_cast_i2x $dst,$src\" %}\n@@ -7170,1 +7166,1 @@\n-      __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_byte_mask()), vlen_enc, $scratch$$Register);\n+      __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_byte_mask()), vlen_enc, noreg);\n@@ -7175,1 +7171,1 @@\n-      __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, $scratch$$Register);\n+      __ vpand($dst$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, noreg);\n@@ -7182,1 +7178,1 @@\n-instruct vcastItoX(vec dst, vec src, vec vtmp, rRegP scratch) %{\n+instruct vcastItoX(vec dst, vec src, vec vtmp) %{\n@@ -7187,2 +7183,2 @@\n-  format %{ \"vector_cast_i2x $dst,$src\\t! using $vtmp and $scratch as TEMP\" %}\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n+  format %{ \"vector_cast_i2x $dst,$src\\t! using $vtmp as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n@@ -7196,1 +7192,1 @@\n-      __ vpand($vtmp$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_byte_mask()), vlen_enc, $scratch$$Register);\n+      __ vpand($vtmp$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_byte_mask()), vlen_enc, noreg);\n@@ -7202,1 +7198,1 @@\n-      __ vpand($vtmp$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, $scratch$$Register);\n+      __ vpand($vtmp$$XMMRegister, $src$$XMMRegister, ExternalAddress(vector_int_to_short_mask()), vlen_enc, noreg);\n@@ -7250,1 +7246,1 @@\n-instruct vcastLtoBS(vec dst, vec src, rRegP scratch) %{\n+instruct vcastLtoBS(vec dst, vec src) %{\n@@ -7254,2 +7250,1 @@\n-  effect(TEMP scratch);\n-  format %{ \"vector_cast_l2x  $dst,$src\\t! using $scratch as TEMP\" %}\n+  format %{ \"vector_cast_l2x  $dst,$src\" %}\n@@ -7265,1 +7260,1 @@\n-      __ vpand($dst$$XMMRegister, $dst$$XMMRegister, mask_addr, Assembler::AVX_128bit, $scratch$$Register);\n+      __ vpand($dst$$XMMRegister, $dst$$XMMRegister, mask_addr, Assembler::AVX_128bit, noreg);\n@@ -7271,1 +7266,1 @@\n-      __ vpand($dst$$XMMRegister, $dst$$XMMRegister, mask_addr, Assembler::AVX_128bit, $scratch$$Register);\n+      __ vpand($dst$$XMMRegister, $dst$$XMMRegister, mask_addr, Assembler::AVX_128bit, noreg);\n@@ -7353,1 +7348,1 @@\n-instruct castFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rRegP scratch, rFlagsReg cr) %{\n+instruct castFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rFlagsReg cr) %{\n@@ -7360,2 +7355,2 @@\n-  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, TEMP scratch, KILL cr);\n-  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, KILL cr);\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4 as TEMP\" %}\n@@ -7366,1 +7361,1 @@\n-                          ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n+                          ExternalAddress(vector_float_signflip()), noreg, vlen_enc);\n@@ -7371,1 +7366,1 @@\n-instruct castFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+instruct castFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rFlagsReg cr) %{\n@@ -7376,2 +7371,2 @@\n-  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n-  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, KILL cr);\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n@@ -7382,1 +7377,1 @@\n-                           ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n+                           ExternalAddress(vector_float_signflip()), noreg, vlen_enc);\n@@ -7387,1 +7382,1 @@\n-instruct castFtoX_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+instruct castFtoX_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rFlagsReg cr) %{\n@@ -7393,2 +7388,2 @@\n-  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n-  format %{ \"vector_cast_f2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, KILL cr);\n+  format %{ \"vector_cast_f2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n@@ -7401,1 +7396,1 @@\n-                             ExternalAddress(vector_double_signflip()), $scratch$$Register, vlen_enc);\n+                             ExternalAddress(vector_double_signflip()), noreg, vlen_enc);\n@@ -7406,1 +7401,1 @@\n-                             ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n+                             ExternalAddress(vector_float_signflip()), noreg, vlen_enc);\n@@ -7429,1 +7424,1 @@\n-instruct castDtoX_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+instruct castDtoX_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rFlagsReg cr) %{\n@@ -7432,2 +7427,2 @@\n-  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n-  format %{ \"vector_cast_d2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, KILL cr);\n+  format %{ \"vector_cast_d2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n@@ -7439,1 +7434,1 @@\n-                           ExternalAddress(vector_double_signflip()), $scratch$$Register, vlen_enc);\n+                           ExternalAddress(vector_double_signflip()), noreg, vlen_enc);\n@@ -7531,1 +7526,1 @@\n-instruct evcmpFD64(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n+instruct evcmpFD64(vec dst, vec src1, vec src2, immI8 cond, kReg ktmp) %{\n@@ -7536,2 +7531,2 @@\n-  effect(TEMP scratch, TEMP ktmp);\n-  format %{ \"vector_compare $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  effect(TEMP ktmp);\n+  format %{ \"vector_compare $dst,$src1,$src2,$cond\" %}\n@@ -7544,1 +7539,1 @@\n-      __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n+      __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, noreg);\n@@ -7547,1 +7542,1 @@\n-      __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n+      __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, noreg);\n@@ -7640,1 +7635,1 @@\n-instruct vcmp64(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n+instruct vcmp64(vec dst, vec src1, vec src2, immI8 cond, kReg ktmp) %{\n@@ -7645,2 +7640,2 @@\n-  effect(TEMP scratch, TEMP ktmp);\n-  format %{ \"vector_compare $dst,$src1,$src2,$cond\\t! using $scratch as TEMP\" %}\n+  effect(TEMP ktmp);\n+  format %{ \"vector_compare $dst,$src1,$src2,$cond\" %}\n@@ -7660,1 +7655,1 @@\n-        __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, noreg);\n@@ -7665,1 +7660,1 @@\n-        __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, noreg);\n@@ -7782,1 +7777,1 @@\n-instruct extractF(legRegF dst, legVec src, immU8 idx, rRegI tmp, legVec vtmp) %{\n+instruct extractF(legRegF dst, legVec src, immU8 idx, legVec vtmp) %{\n@@ -7785,2 +7780,2 @@\n-  effect(TEMP dst, TEMP tmp, TEMP vtmp);\n-  format %{ \"extractF $dst,$src,$idx\\t! using $tmp, $vtmp as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"extractF $dst,$src,$idx\\t! using $vtmp as TEMP\" %}\n@@ -7790,1 +7785,1 @@\n-    __ get_elem(T_FLOAT, $dst$$XMMRegister, $src$$XMMRegister, $idx$$constant, $tmp$$Register, $vtmp$$XMMRegister);\n+    __ get_elem(T_FLOAT, $dst$$XMMRegister, $src$$XMMRegister, $idx$$constant, $vtmp$$XMMRegister);\n@@ -7795,1 +7790,1 @@\n-instruct vextractF(legRegF dst, legVec src, immU8 idx, rRegI tmp, legVec vtmp) %{\n+instruct vextractF(legRegF dst, legVec src, immU8 idx, legVec vtmp) %{\n@@ -7799,2 +7794,2 @@\n-  effect(TEMP tmp, TEMP vtmp);\n-  format %{ \"vextractF $dst,$src,$idx\\t! using $tmp, $vtmp as TEMP\" %}\n+  effect(TEMP vtmp);\n+  format %{ \"vextractF $dst,$src,$idx\\t! using $vtmp as TEMP\" %}\n@@ -7805,1 +7800,1 @@\n-    __ get_elem(T_FLOAT, $dst$$XMMRegister, lane_reg, $idx$$constant, $tmp$$Register);\n+    __ get_elem(T_FLOAT, $dst$$XMMRegister, lane_reg, $idx$$constant);\n@@ -7883,1 +7878,1 @@\n-instruct evblendvp64(vec dst, vec src1, vec src2, vec mask, rRegP scratch, kReg ktmp) %{\n+instruct evblendvp64(vec dst, vec src1, vec src2, vec mask, kReg ktmp) %{\n@@ -7887,2 +7882,2 @@\n-  format %{ \"vector_blend  $dst,$src1,$src2,$mask\\t! using $scratch and k2 as TEMP\" %}\n-  effect(TEMP scratch, TEMP ktmp);\n+  format %{ \"vector_blend  $dst,$src1,$src2,$mask\\t! using k2 as TEMP\" %}\n+  effect(TEMP ktmp);\n@@ -7892,1 +7887,1 @@\n-    __ evpcmp(elem_bt, $ktmp$$KRegister, k0, $mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), Assembler::eq, vlen_enc, $scratch$$Register);\n+    __ evpcmp(elem_bt, $ktmp$$KRegister, k0, $mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), Assembler::eq, vlen_enc, noreg);\n@@ -7899,1 +7894,1 @@\n-instruct evblendvp64_masked(vec dst, vec src1, vec src2, kReg mask, rRegP scratch) %{\n+instruct evblendvp64_masked(vec dst, vec src1, vec src2, kReg mask) %{\n@@ -7904,2 +7899,1 @@\n-  format %{ \"vector_blend  $dst,$src1,$src2,$mask\\t! using $scratch and k2 as TEMP\" %}\n-  effect(TEMP scratch);\n+  format %{ \"vector_blend  $dst,$src1,$src2,$mask\\t! using k2 as TEMP\" %}\n@@ -7981,1 +7975,1 @@\n-instruct vabsnegF(vec dst, vec src, rRegI scratch) %{\n+instruct vabsnegF(vec dst, vec src) %{\n@@ -7985,1 +7979,0 @@\n-  effect(TEMP scratch);\n@@ -7992,1 +7985,1 @@\n-      __ vabsnegf(opcode, $dst$$XMMRegister, $src$$XMMRegister, $scratch$$Register);\n+      __ vabsnegf(opcode, $dst$$XMMRegister, $src$$XMMRegister);\n@@ -7996,1 +7989,1 @@\n-      __ vabsnegf(opcode, $dst$$XMMRegister, $src$$XMMRegister, vlen_enc, $scratch$$Register);\n+      __ vabsnegf(opcode, $dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n@@ -8002,1 +7995,1 @@\n-instruct vabsneg4F(vec dst, rRegI scratch) %{\n+instruct vabsneg4F(vec dst) %{\n@@ -8006,1 +7999,0 @@\n-  effect(TEMP scratch);\n@@ -8011,1 +8003,1 @@\n-    __ vabsnegf(opcode, $dst$$XMMRegister, $dst$$XMMRegister, $scratch$$Register);\n+    __ vabsnegf(opcode, $dst$$XMMRegister, $dst$$XMMRegister);\n@@ -8016,1 +8008,1 @@\n-instruct vabsnegD(vec dst, vec src, rRegI scratch) %{\n+instruct vabsnegD(vec dst, vec src) %{\n@@ -8019,1 +8011,0 @@\n-  effect(TEMP scratch);\n@@ -8026,1 +8017,1 @@\n-      __ vabsnegd(opcode, $dst$$XMMRegister, $src$$XMMRegister, $scratch$$Register);\n+      __ vabsnegd(opcode, $dst$$XMMRegister, $src$$XMMRegister);\n@@ -8029,1 +8020,1 @@\n-      __ vabsnegd(opcode, $dst$$XMMRegister, $src$$XMMRegister, vlen_enc, $scratch$$Register);\n+      __ vabsnegd(opcode, $dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n@@ -8221,1 +8212,1 @@\n-instruct loadMask64(kReg dst, vec src, vec xtmp, rRegI tmp) %{\n+instruct loadMask64(kReg dst, vec src, vec xtmp) %{\n@@ -8224,2 +8215,2 @@\n-  effect(TEMP xtmp, TEMP tmp);\n-  format %{ \"vector_loadmask_64byte $dst, $src\\t! using $xtmp and $tmp as TEMP\" %}\n+  effect(TEMP xtmp);\n+  format %{ \"vector_loadmask_64byte $dst, $src\\t! using $xtmp as TEMP\" %}\n@@ -8228,1 +8219,1 @@\n-                        $tmp$$Register, true, Assembler::AVX_512bit);\n+                        true, Assembler::AVX_512bit);\n@@ -8241,1 +8232,1 @@\n-                        noreg, false, vlen_enc);\n+                        false, vlen_enc);\n@@ -8381,1 +8372,1 @@\n-instruct vstoreMask_evex_vectmask(vec dst, kReg mask, immI size, rRegI tmp) %{\n+instruct vstoreMask_evex_vectmask(vec dst, kReg mask, immI size) %{\n@@ -8384,1 +8375,1 @@\n-  effect(TEMP_DEF dst, TEMP tmp);\n+  effect(TEMP_DEF dst);\n@@ -8389,1 +8380,1 @@\n-                 false, Assembler::AVX_512bit, $tmp$$Register);\n+                 false, Assembler::AVX_512bit, noreg);\n@@ -8433,1 +8424,1 @@\n-instruct loadIotaIndices(vec dst, immI_0 src, rRegP scratch) %{\n+instruct loadIotaIndices(vec dst, immI_0 src) %{\n@@ -8436,1 +8427,0 @@\n-  effect(TEMP scratch);\n@@ -8440,1 +8430,1 @@\n-     __ load_iota_indices($dst$$XMMRegister, $scratch$$Register, vlen_in_bytes);\n+     __ load_iota_indices($dst$$XMMRegister, vlen_in_bytes);\n@@ -8446,1 +8436,1 @@\n-instruct VectorPopulateIndex(vec dst, rRegI src1, immI_1 src2, vec vtmp, rRegP scratch) %{\n+instruct VectorPopulateIndex(vec dst, rRegI src1, immI_1 src2, vec vtmp) %{\n@@ -8448,2 +8438,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_populate_index $dst $src1 $src2\\t! using $vtmp and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_populate_index $dst $src1 $src2\\t! using $vtmp as TEMP\" %}\n@@ -8456,1 +8446,1 @@\n-     __ load_iota_indices($dst$$XMMRegister, $scratch$$Register, vlen);\n+     __ load_iota_indices($dst$$XMMRegister, vlen);\n@@ -8465,1 +8455,1 @@\n-instruct VectorPopulateLIndex(vec dst, rRegL src1, immI_1 src2, vec vtmp, rRegP scratch) %{\n+instruct VectorPopulateLIndex(vec dst, rRegL src1, immI_1 src2, vec vtmp) %{\n@@ -8467,2 +8457,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_populate_index $dst $src1 $src2\\t! using $vtmp and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_populate_index $dst $src1 $src2\\t! using $vtmp as TEMP\" %}\n@@ -8475,1 +8465,1 @@\n-     __ load_iota_indices($dst$$XMMRegister, $scratch$$Register, vlen);\n+     __ load_iota_indices($dst$$XMMRegister, vlen);\n@@ -8510,1 +8500,1 @@\n-instruct rearrangeB_avx(legVec dst, legVec src, vec shuffle, legVec vtmp1, legVec vtmp2, rRegP scratch) %{\n+instruct rearrangeB_avx(legVec dst, legVec src, vec shuffle, legVec vtmp1, legVec vtmp2) %{\n@@ -8514,2 +8504,2 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n-  format %{ \"vector_rearrange $dst, $shuffle, $src\\t! using $vtmp1, $vtmp2, $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_rearrange $dst, $shuffle, $src\\t! using $vtmp1, $vtmp2 as TEMP\" %}\n@@ -8525,1 +8515,1 @@\n-    __ vpaddb($vtmp2$$XMMRegister, $shuffle$$XMMRegister, ExternalAddress(vector_byte_shufflemask()), Assembler::AVX_256bit, $scratch$$Register);\n+    __ vpaddb($vtmp2$$XMMRegister, $shuffle$$XMMRegister, ExternalAddress(vector_byte_shufflemask()), Assembler::AVX_256bit, noreg);\n@@ -8546,1 +8536,1 @@\n-instruct loadShuffleS(vec dst, vec src, vec vtmp, rRegP scratch) %{\n+instruct loadShuffleS(vec dst, vec src, vec vtmp) %{\n@@ -8550,2 +8540,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_load_shuffle $dst, $src\\t! using $vtmp and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_load_shuffle $dst, $src\\t! using $vtmp as TEMP\" %}\n@@ -8568,1 +8558,1 @@\n-      __ movdqu($vtmp$$XMMRegister, ExternalAddress(vector_short_shufflemask()), $scratch$$Register);\n+      __ movdqu($vtmp$$XMMRegister, ExternalAddress(vector_short_shufflemask()), noreg);\n@@ -8582,1 +8572,1 @@\n-      __ vpaddb($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_short_shufflemask()), vlen_enc, $scratch$$Register);\n+      __ vpaddb($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_short_shufflemask()), vlen_enc, noreg);\n@@ -8600,1 +8590,1 @@\n-instruct rearrangeS_avx(legVec dst, legVec src, vec shuffle, legVec vtmp1, legVec vtmp2, rRegP scratch) %{\n+instruct rearrangeS_avx(legVec dst, legVec src, vec shuffle, legVec vtmp1, legVec vtmp2) %{\n@@ -8604,2 +8594,2 @@\n-  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2, TEMP scratch);\n-  format %{ \"vector_rearrange $dst, $shuffle, $src\\t! using $vtmp1, $vtmp2, $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp1, TEMP vtmp2);\n+  format %{ \"vector_rearrange $dst, $shuffle, $src\\t! using $vtmp1, $vtmp2 as TEMP\" %}\n@@ -8615,1 +8605,1 @@\n-    __ vpaddb($vtmp2$$XMMRegister, $shuffle$$XMMRegister, ExternalAddress(vector_byte_shufflemask()), Assembler::AVX_256bit, $scratch$$Register);\n+    __ vpaddb($vtmp2$$XMMRegister, $shuffle$$XMMRegister, ExternalAddress(vector_byte_shufflemask()), Assembler::AVX_256bit, noreg);\n@@ -8654,1 +8644,1 @@\n-instruct loadShuffleI(vec dst, vec src, vec vtmp, rRegP scratch) %{\n+instruct loadShuffleI(vec dst, vec src, vec vtmp) %{\n@@ -8658,2 +8648,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_load_shuffle $dst, $src\\t! using $vtmp and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_load_shuffle $dst, $src\\t! using $vtmp as TEMP\" %}\n@@ -8678,1 +8668,1 @@\n-    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_int_shufflemask()), $scratch$$Register);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_int_shufflemask()), noreg);\n@@ -8725,1 +8715,1 @@\n-instruct loadShuffleL(vec dst, vec src, vec vtmp, rRegP scratch) %{\n+instruct loadShuffleL(vec dst, vec src, vec vtmp) %{\n@@ -8729,2 +8719,2 @@\n-  effect(TEMP dst, TEMP vtmp, TEMP scratch);\n-  format %{ \"vector_load_shuffle $dst, $src\\t! using $vtmp and $scratch as TEMP\" %}\n+  effect(TEMP dst, TEMP vtmp);\n+  format %{ \"vector_load_shuffle $dst, $src\\t! using $vtmp as TEMP\" %}\n@@ -8747,1 +8737,1 @@\n-    __ vpaddd($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_long_shufflemask()), vlen_enc, $scratch$$Register);\n+    __ vpaddd($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_long_shufflemask()), vlen_enc, noreg);\n@@ -9382,1 +9372,1 @@\n-instruct vreverse_reg_gfni(vec dst, vec src, vec xtmp, rRegI rtmp) %{\n+instruct vreverse_reg_gfni(vec dst, vec src, vec xtmp) %{\n@@ -9385,2 +9375,2 @@\n-  effect(TEMP dst, TEMP xtmp, TEMP rtmp);\n-  format %{ \"vector_reverse_bit_gfni $dst, $src!\\t using $rtmp and $xtmp as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp);\n+  format %{ \"vector_reverse_bit_gfni $dst, $src!\\t using $xtmp as TEMP\" %}\n@@ -9392,1 +9382,1 @@\n-                               addr, $rtmp$$Register, vec_enc);\n+                               addr, noreg, vec_enc);\n@@ -9397,1 +9387,1 @@\n-instruct vreverse_byte_reg(vec dst, vec src, rRegI rtmp) %{\n+instruct vreverse_byte_reg(vec dst, vec src) %{\n@@ -9400,2 +9390,2 @@\n-  effect(TEMP dst, TEMP rtmp);\n-  format %{ \"vector_reverse_byte $dst, $src!\\t using $rtmp as TEMP\" %}\n+  effect(TEMP dst);\n+  format %{ \"vector_reverse_byte $dst, $src\" %}\n@@ -9405,1 +9395,1 @@\n-    __ vector_reverse_byte(bt, $dst$$XMMRegister, $src$$XMMRegister, $rtmp$$Register, vec_enc);\n+    __ vector_reverse_byte(bt, $dst$$XMMRegister, $src$$XMMRegister, vec_enc);\n@@ -10084,1 +10074,1 @@\n-instruct evcmp_masked(kReg dst, vec src1, vec src2, immI8 cond, kReg mask, rRegP scratch) %{\n+instruct evcmp_masked(kReg dst, vec src1, vec src2, immI8 cond, kReg mask) %{\n@@ -10086,2 +10076,1 @@\n-  effect(TEMP scratch);\n-  format %{ \"vcmp_masked $dst, $src1, $src2, $cond, $mask\\t! using $scratch as TEMP\" %}\n+  format %{ \"vcmp_masked $dst, $src1, $src2, $cond, $mask\" %}\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":209,"deletions":220,"binary":false,"changes":429,"status":"modified"}]}