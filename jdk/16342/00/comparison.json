{"files":[{"patch":"@@ -81,1 +81,0 @@\n-#include \"gc\/shared\/gcLocker.inline.hpp\"\n@@ -415,4 +414,3 @@\n-  \/\/ We will loop until a) we manage to successfully perform the\n-  \/\/ allocation or b) we successfully schedule a collection which\n-  \/\/ fails to perform the allocation. b) is the only case when we'll\n-  \/\/ return null.\n+  \/\/ We will loop until a) we manage to successfully perform the allocation or b)\n+  \/\/ successfully schedule a collection which fails to perform the allocation.\n+  \/\/ Case b) is the only case when we'll return null.\n@@ -420,2 +418,1 @@\n-  for (uint try_count = 1, gclocker_retry_count = 0; \/* we'll return *\/; try_count += 1) {\n-    bool should_try_gc;\n+  for (uint try_count = 1; \/* we'll return *\/; try_count++) {\n@@ -434,16 +431,0 @@\n-      \/\/ If the GCLocker is active and we are bound for a GC, try expanding young gen.\n-      \/\/ This is different to when only GCLocker::needs_gc() is set: try to avoid\n-      \/\/ waiting because the GCLocker is active to not wait too long.\n-      if (GCLocker::is_active_and_needs_gc() && policy()->can_expand_young_list()) {\n-        \/\/ No need for an ergo message here, can_expand_young_list() does this when\n-        \/\/ it returns true.\n-        result = _allocator->attempt_allocation_force(word_size);\n-        if (result != nullptr) {\n-          return result;\n-        }\n-      }\n-\n-      \/\/ Only try a GC if the GCLocker does not signal the need for a GC. Wait until\n-      \/\/ the GCLocker initiated GC has been performed and then retry. This includes\n-      \/\/ the case when the GC Locker is not active but has not been performed.\n-      should_try_gc = !GCLocker::needs_gc();\n@@ -454,32 +435,7 @@\n-    if (should_try_gc) {\n-      bool succeeded;\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_inc_collection_pause);\n-      if (result != nullptr) {\n-        assert(succeeded, \"only way to get back a non-null result\");\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n-                             Thread::current()->name(), p2i(result));\n-        return result;\n-      }\n-\n-      if (succeeded) {\n-        \/\/ We successfully scheduled a collection which failed to allocate. No\n-        \/\/ point in trying to allocate further. We'll just return null.\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection failing to allocate \"\n-                             SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \" words\",\n-                           Thread::current()->name(), word_size);\n-    } else {\n-      \/\/ Failed to schedule a collection.\n-      if (gclocker_retry_count > GCLockerRetryAllocationCount) {\n-        log_warning(gc, alloc)(\"%s: Retried waiting for GCLocker too often allocating \"\n-                               SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Stall until clear\", Thread::current()->name());\n-      \/\/ The GCLocker is either active or the GCLocker initiated\n-      \/\/ GC has not yet been performed. Stall until it is and\n-      \/\/ then retry the allocation.\n-      GCLocker::stall_until_clear();\n-      gclocker_retry_count += 1;\n+    bool succeeded;\n+    result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_inc_collection_pause);\n+    if (result != nullptr) {\n+      assert(succeeded, \"only way to get back a non-null result\");\n+      log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n+                           Thread::current()->name(), p2i(result));\n+      return result;\n@@ -488,7 +444,15 @@\n-    \/\/ We can reach here if we were unsuccessful in scheduling a\n-    \/\/ collection (because another thread beat us to it) or if we were\n-    \/\/ stalled due to the GC locker. In either can we should retry the\n-    \/\/ allocation attempt in case another thread successfully\n-    \/\/ performed a collection and reclaimed enough space. We do the\n-    \/\/ first attempt (without holding the Heap_lock) here and the\n-    \/\/ follow-on attempt will be at the start of the next loop\n+    if (succeeded) {\n+      \/\/ We successfully scheduled a collection which failed to allocate. No\n+      \/\/ point in trying to allocate further. We'll just return null.\n+      log_trace(gc, alloc)(\"%s: Successfully scheduled collection failing to allocate \"\n+                           SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n+      return nullptr;\n+    }\n+    log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \" words\",\n+                         Thread::current()->name(), word_size);\n+\n+    \/\/ We can reach here if we were unsuccessful in scheduling a collection (because\n+    \/\/ another thread beat us to it). In this case immeditealy retry the allocation\n+    \/\/ attempt because another thread successfully performed a collection and possibly\n+    \/\/ reclaimed enough space. The first attempt (without holding the Heap_lock) is\n+    \/\/ here and the follow-on attempt will be at the start of the next loop\n@@ -677,4 +641,3 @@\n-  \/\/ We will loop until a) we manage to successfully perform the\n-  \/\/ allocation or b) we successfully schedule a collection which\n-  \/\/ fails to perform the allocation. b) is the only case when we'll\n-  \/\/ return null.\n+  \/\/ We will loop until a) we manage to successfully perform the allocation or b)\n+  \/\/ successfully schedule a collection which fails to perform the allocation.\n+  \/\/ Case b) is the only case when we'll return null.\n@@ -682,2 +645,1 @@\n-  for (uint try_count = 1, gclocker_retry_count = 0; \/* we'll return *\/; try_count += 1) {\n-    bool should_try_gc;\n+  for (uint try_count = 1; \/* we'll return *\/; try_count++) {\n@@ -701,4 +663,0 @@\n-      \/\/ Only try a GC if the GCLocker does not signal the need for a GC. Wait until\n-      \/\/ the GCLocker initiated GC has been performed and then retry. This includes\n-      \/\/ the case when the GC Locker is not active but has not been performed.\n-      should_try_gc = !GCLocker::needs_gc();\n@@ -709,35 +667,10 @@\n-    if (should_try_gc) {\n-      bool succeeded;\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_humongous_allocation);\n-      if (result != nullptr) {\n-        assert(succeeded, \"only way to get back a non-null result\");\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n-                             Thread::current()->name(), p2i(result));\n-        size_t size_in_regions = humongous_obj_size_in_regions(word_size);\n-        policy()->old_gen_alloc_tracker()->\n-          record_collection_pause_humongous_allocation(size_in_regions * HeapRegion::GrainBytes);\n-        return result;\n-      }\n-\n-      if (succeeded) {\n-        \/\/ We successfully scheduled a collection which failed to allocate. No\n-        \/\/ point in trying to allocate further. We'll just return null.\n-        log_trace(gc, alloc)(\"%s: Successfully scheduled collection failing to allocate \"\n-                             SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \"\",\n-                           Thread::current()->name(), word_size);\n-    } else {\n-      \/\/ Failed to schedule a collection.\n-      if (gclocker_retry_count > GCLockerRetryAllocationCount) {\n-        log_warning(gc, alloc)(\"%s: Retried waiting for GCLocker too often allocating \"\n-                               SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n-        return nullptr;\n-      }\n-      log_trace(gc, alloc)(\"%s: Stall until clear\", Thread::current()->name());\n-      \/\/ The GCLocker is either active or the GCLocker initiated\n-      \/\/ GC has not yet been performed. Stall until it is and\n-      \/\/ then retry the allocation.\n-      GCLocker::stall_until_clear();\n-      gclocker_retry_count += 1;\n+    bool succeeded;\n+    result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_humongous_allocation);\n+    if (result != nullptr) {\n+      assert(succeeded, \"only way to get back a non-null result\");\n+      log_trace(gc, alloc)(\"%s: Successfully scheduled collection returning \" PTR_FORMAT,\n+                           Thread::current()->name(), p2i(result));\n+      size_t size_in_regions = humongous_obj_size_in_regions(word_size);\n+      policy()->old_gen_alloc_tracker()->\n+        record_collection_pause_humongous_allocation(size_in_regions * HeapRegion::GrainBytes);\n+      return result;\n@@ -746,0 +679,9 @@\n+    if (succeeded) {\n+      \/\/ We successfully scheduled a collection which failed to allocate. No\n+      \/\/ point in trying to allocate further. We'll just return null.\n+      log_trace(gc, alloc)(\"%s: Successfully scheduled collection failing to allocate \"\n+                           SIZE_FORMAT \" words\", Thread::current()->name(), word_size);\n+      return nullptr;\n+    }\n+    log_trace(gc, alloc)(\"%s: Unsuccessfully scheduled collection allocating \" SIZE_FORMAT \"\",\n+                         Thread::current()->name(), word_size);\n@@ -747,5 +689,2 @@\n-    \/\/ We can reach here if we were unsuccessful in scheduling a\n-    \/\/ collection (because another thread beat us to it) or if we were\n-    \/\/ stalled due to the GC locker. In either can we should retry the\n-    \/\/ allocation attempt in case another thread successfully\n-    \/\/ performed a collection and reclaimed enough space.\n+    \/\/ We can reach here if we were unsuccessful in scheduling a collection (because\n+    \/\/ another thread beat us to it).\n@@ -758,1 +697,1 @@\n-      log_warning(gc, alloc)(\"%s: Retried allocation %u times for \" SIZE_FORMAT \" words\",\n+      log_warning(gc, alloc)(\"%s: Retried allocation %u times for %zu words\",\n@@ -912,5 +851,0 @@\n-  if (GCLocker::check_active_before_gc()) {\n-    \/\/ Full GC was not completed.\n-    return false;\n-  }\n-\n@@ -1273,3 +1207,5 @@\n-  \/\/ Override the default _filler_array_max_size so that no humongous filler\n-  \/\/ objects are created.\n-  _filler_array_max_size = _humongous_object_threshold_in_words;\n+  \/\/ Since filler arrays are never referenced, we can make them region sized.\n+  \/\/ This simplifies filling up the region in case we have some potentially\n+  \/\/ unreferenced (by Java code, but still in use by native code) pinned objects\n+  \/\/ in there.\n+  _filler_array_max_size = HeapRegion::GrainWords;\n@@ -1908,6 +1844,0 @@\n-    if (GCLocker::is_active_and_needs_gc()) {\n-      \/\/ If GCLocker is active, wait until clear before retrying.\n-      LOG_COLLECT_CONCURRENTLY(cause, \"gc-locker stall\");\n-      GCLocker::stall_until_clear();\n-    }\n-\n@@ -1939,5 +1869,0 @@\n-\n-    if (GCLocker::is_active_and_needs_gc()) {\n-      \/\/ If GCLocker is active, wait until clear before retrying.\n-      GCLocker::stall_until_clear();\n-    }\n@@ -1953,5 +1878,0 @@\n-  } else if (GCLocker::should_discard(cause, counters_before.total_collections())) {\n-    \/\/ Indicate failure to be consistent with VMOp failure due to\n-    \/\/ another collection slipping in after our gc_count but before\n-    \/\/ our request is processed.\n-    return false;\n@@ -2183,8 +2103,0 @@\n-void G1CollectedHeap::pin_object(JavaThread* thread, oop obj) {\n-  GCLocker::lock_critical(thread);\n-}\n-\n-void G1CollectedHeap::unpin_object(JavaThread* thread, oop obj) {\n-  GCLocker::unlock_critical(thread);\n-}\n-\n@@ -2493,4 +2405,0 @@\n-  if (GCLocker::check_active_before_gc()) {\n-    return false;\n-  }\n-\n@@ -2651,0 +2559,2 @@\n+  assert(!hr->has_pinned_objects(),\n+         \"must not free a region which contains pinned objects\");\n@@ -3056,2 +2966,2 @@\n-void G1CollectedHeap::update_used_after_gc(bool evacuation_failed) {\n-  if (evacuation_failed) {\n+void G1CollectedHeap::update_used_after_gc(bool retained) {\n+  if (retained) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":61,"deletions":151,"binary":false,"changes":212,"status":"modified"},{"patch":"@@ -563,0 +563,3 @@\n+  void pin_object(JavaThread* thread, oop obj) override;\n+  void unpin_object(JavaThread* thread, oop obj) override;\n+\n@@ -616,1 +619,1 @@\n-    _region_attr.set_in_young(r->hrm_index());\n+    _region_attr.set_in_young(r->hrm_index(), r->has_pinned_objects());\n@@ -1258,1 +1261,1 @@\n-  void update_used_after_gc(bool evacuation_failed);\n+  void update_used_after_gc(bool retained);\n@@ -1295,3 +1298,0 @@\n-  void pin_object(JavaThread* thread, oop obj) override;\n-  void unpin_object(JavaThread* thread, oop obj) override;\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -212,0 +212,2 @@\n+  assert(!region_at(index)->has_pinned_objects(), \"must be\");\n+  assert(region_at(index)->rem_set()->is_complete(), \"must be\");\n@@ -221,0 +223,1 @@\n+  _region_attr.set_is_pinned(r->hrm_index(), r->has_pinned_objects());\n@@ -224,0 +227,2 @@\n+  assert(!r->has_pinned_objects(), \"must be\");\n+  assert(r->rem_set()->is_complete(), \"must be\");\n@@ -260,0 +265,15 @@\n+inline void G1CollectedHeap::pin_object(JavaThread* thread, oop obj) {\n+  assert(obj != NULL, \"obj must not be null\");\n+  assert(!is_gc_active(), \"must not pin objects during a GC\");\n+  assert(obj->is_typeArray(), \"must be typeArray\");\n+  HeapRegion *r = heap_region_containing(obj);\n+  r->increment_pinned_object_count();\n+}\n+\n+inline void G1CollectedHeap::unpin_object(JavaThread* thread, oop obj) {\n+  assert(obj != NULL, \"obj must not be null\");\n+  assert(!is_gc_active(), \"must not unpin objects during a GC\");\n+  HeapRegion *r = heap_region_containing(obj);\n+  r->decrement_pinned_object_count();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.inline.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -328,0 +328,2 @@\n+    G1CollectionCandidateRegionList pinned_marking_regions;\n+    G1CollectionCandidateRegionList pinned_retained_regions;\n@@ -333,1 +335,2 @@\n-                                                                  &_optional_old_regions);\n+                                                                  &_optional_old_regions,\n+                                                                  &pinned_marking_regions);\n@@ -341,1 +344,2 @@\n-                                             &_optional_old_regions);\n+                                             &_optional_old_regions,\n+                                             &pinned_retained_regions);\n@@ -347,0 +351,13 @@\n+    \/\/ Move pinned marking regions we came across to retained candidates so that\n+    \/\/ there is progress in the mixed gc phase.\n+    move_pinned_marking_to_retained(&pinned_marking_regions);\n+    \/\/ Drop pinned retained regions to make progress with retained regions. Regions\n+    \/\/ in that list have must have been pinned for at least two GCs and hence are\n+    \/\/ considered \"long lived\".\n+    \/\/ Two GCs because:\n+    \/\/ * the GC the region it has been put in the retained regions list. Either due\n+    \/\/   due to being a pinned young region or observing a real evacuation failure.\n+    \/\/ * (if it started off as marking region, the GC it has been moved to the\n+    \/\/   retained candidates)\n+    \/\/ * the GC it has been detected to be pinned (again), i.e. this GC.\n+    drop_pinned_retained_regions(&pinned_retained_regions);\n@@ -381,0 +398,26 @@\n+void G1CollectionSet::move_pinned_marking_to_retained(G1CollectionCandidateRegionList* regions) {\n+  if (regions->length() == 0) {\n+    return;\n+  }\n+  candidates()->remove(regions);\n+\n+  for (HeapRegion* r : *regions) {\n+    assert(r->has_pinned_objects(), \"must be pinned\");\n+    assert(r->rem_set()->is_complete(), \"must be complete\");\n+    candidates()->add_retained_region_unsorted(r);\n+  }\n+  candidates()->sort_by_efficiency();\n+}\n+\n+void G1CollectionSet::drop_pinned_retained_regions(G1CollectionCandidateRegionList* regions) {\n+  if (regions->length() == 0) {\n+    return;\n+  }\n+  candidates()->remove(regions);\n+\n+  \/\/ We can now drop these region's remembered sets.\n+  for (HeapRegion* r : *regions) {\n+    r->rem_set()->clear(true \/* only_cardset *\/);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSet.cpp","additions":45,"deletions":2,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -180,0 +180,6 @@\n+  \/\/ Moves given old regions from the marking candidates to the retained candidates.\n+  \/\/ This makes sure that marking candidates will not remain there to unnecessarily\n+  \/\/ prolong the mixed phase.\n+  void move_pinned_marking_to_retained(G1CollectionCandidateRegionList* regions);\n+  \/\/ Removes the given list of regions from the retained candidates.\n+  void drop_pinned_retained_regions(G1CollectionCandidateRegionList* regions);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSet.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-void G1CollectionCandidateList::set(G1CollectionCandidateList::CandidateInfo* candidate_infos, uint num_infos) {\n+void G1CollectionCandidateList::set(G1CollectionSetCandidateInfo* candidate_infos, uint num_infos) {\n@@ -37,1 +37,1 @@\n-  GrowableArrayFromArray<G1CollectionCandidateList::CandidateInfo> a(candidate_infos, (int)num_infos);\n+  GrowableArrayFromArray<G1CollectionSetCandidateInfo> a(candidate_infos, (int)num_infos);\n@@ -42,1 +42,1 @@\n-  CandidateInfo c(r, r->calc_gc_efficiency());\n+  G1CollectionSetCandidateInfo c(r, r->calc_gc_efficiency());\n@@ -61,1 +61,1 @@\n-  GrowableArray<CandidateInfo> new_list(new_length, mtGC);\n+  GrowableArray<G1CollectionSetCandidateInfo> new_list(new_length, mtGC);\n@@ -84,1 +84,1 @@\n-  CandidateInfo* prev = nullptr;\n+  G1CollectionSetCandidateInfo* prev = nullptr;\n@@ -87,1 +87,1 @@\n-    CandidateInfo& ci = _candidates.at(i);\n+    G1CollectionSetCandidateInfo& ci = _candidates.at(i);\n@@ -97,1 +97,1 @@\n-int G1CollectionCandidateList::compare(CandidateInfo* ci1, CandidateInfo* ci2) {\n+int G1CollectionCandidateList::compare(G1CollectionSetCandidateInfo* ci1, G1CollectionSetCandidateInfo* ci2) {\n@@ -185,1 +185,1 @@\n-void G1CollectionSetCandidates::set_candidates_from_marking(G1CollectionCandidateList::CandidateInfo* candidate_infos,\n+void G1CollectionSetCandidates::set_candidates_from_marking(G1CollectionSetCandidateInfo* candidate_infos,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSetCandidates.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -29,0 +29,2 @@\n+#include \"gc\/g1\/g1_globals.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n@@ -67,0 +69,14 @@\n+struct G1CollectionSetCandidateInfo {\n+  HeapRegion* _r;\n+  double _gc_efficiency;\n+  uint _num_unreclaimed;          \/\/ Number of GCs this region has been found unreclaimable.\n+\n+  G1CollectionSetCandidateInfo() : G1CollectionSetCandidateInfo(nullptr, 0.0) { }\n+  G1CollectionSetCandidateInfo(HeapRegion* r, double gc_efficiency) : _r(r), _gc_efficiency(gc_efficiency), _num_unreclaimed(0) { }\n+\n+  bool update_num_unreclaimed() {\n+    ++_num_unreclaimed;\n+    return _num_unreclaimed < G1NumCollectionsKeepUnreclaimable;\n+  }\n+};\n+\n@@ -75,1 +91,1 @@\n-  HeapRegion* operator*();\n+  G1CollectionSetCandidateInfo* operator*();\n@@ -86,11 +102,1 @@\n-public:\n-  struct CandidateInfo {\n-    HeapRegion* _r;\n-    double _gc_efficiency;\n-\n-    CandidateInfo() : CandidateInfo(nullptr, 0.0) { }\n-    CandidateInfo(HeapRegion* r, double gc_efficiency) : _r(r), _gc_efficiency(gc_efficiency) { }\n-  };\n-\n-private:\n-  GrowableArray<CandidateInfo> _candidates;\n+  GrowableArray<G1CollectionSetCandidateInfo> _candidates;\n@@ -102,1 +108,1 @@\n-  void set(CandidateInfo* candidate_infos, uint num_infos);\n+  void set(G1CollectionSetCandidateInfo* candidate_infos, uint num_infos);\n@@ -117,1 +123,1 @@\n-  CandidateInfo& at(uint position) { return _candidates.at(position); }\n+  G1CollectionSetCandidateInfo& at(uint position) { return _candidates.at(position); }\n@@ -126,1 +132,1 @@\n-  static int compare(CandidateInfo* ci1, CandidateInfo* ci2);\n+  static int compare(G1CollectionSetCandidateInfo* ci1, G1CollectionSetCandidateInfo* ci2);\n@@ -141,1 +147,1 @@\n-  uint _position;\n+    uint _position;\n@@ -143,1 +149,1 @@\n-public:\n+  public:\n@@ -201,1 +207,1 @@\n-  void set_candidates_from_marking(G1CollectionCandidateList::CandidateInfo* candidate_infos,\n+  void set_candidates_from_marking(G1CollectionSetCandidateInfo* candidate_infos,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSetCandidates.hpp","additions":24,"deletions":18,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -41,2 +41,2 @@\n-inline HeapRegion* G1CollectionCandidateListIterator::operator*() {\n-  return _which->_candidates.at(_position)._r;\n+inline G1CollectionSetCandidateInfo* G1CollectionCandidateListIterator::operator*() {\n+  return &_which->_candidates.at(_position);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSetCandidates.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  using CandidateInfo = G1CollectionCandidateList::CandidateInfo;\n+  using CandidateInfo = G1CollectionSetCandidateInfo;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSetChooser.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1373,1 +1373,4 @@\n-      if (hr->used() > 0 && hr->live_bytes() == 0 && !hr->is_young()) {\n+      bool can_reclaim = hr->used() > 0 && hr->live_bytes() == 0 &&\n+                         !hr->is_young() && !hr->has_pinned_objects();\n+\n+      if (can_reclaim) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -196,1 +197,1 @@\n-  _num_evac_fail_regions = _evac_failure_regions->num_regions_failed_evacuation();\n+  _num_evac_fail_regions = _evac_failure_regions->num_regions_retained();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -36,0 +36,2 @@\n+  _regions_retained(mtGC),\n+  _regions_pinned(mtGC),\n@@ -37,2 +39,4 @@\n-  _evac_failure_regions(nullptr),\n-  _evac_failure_regions_cur_length(0) { }\n+  _evac_retained_regions(nullptr),\n+  _evac_retained_regions_cur_length(0),\n+  _evac_failure_regions_pinned(0),\n+  _evac_failure_regions_failed_evacuation(0) { }\n@@ -41,1 +45,1 @@\n-  assert(_evac_failure_regions == nullptr, \"not cleaned up\");\n+  assert(_evac_retained_regions == nullptr, \"not cleaned up\");\n@@ -45,1 +49,5 @@\n-  Atomic::store(&_evac_failure_regions_cur_length, 0u);\n+  Atomic::store(&_evac_retained_regions_cur_length, 0u);\n+  Atomic::store(&_evac_failure_regions_pinned, 0u);\n+  Atomic::store(&_evac_failure_regions_failed_evacuation, 0u);\n+  _regions_retained.resize(max_regions);\n+  _regions_pinned.resize(max_regions);\n@@ -47,1 +55,1 @@\n-  _evac_failure_regions = NEW_C_HEAP_ARRAY(uint, max_regions, mtGC);\n+  _evac_retained_regions = NEW_C_HEAP_ARRAY(uint, max_regions, mtGC);\n@@ -51,0 +59,2 @@\n+  _regions_retained.resize(0);\n+  _regions_pinned.resize(0);\n@@ -53,2 +63,2 @@\n-  FREE_C_HEAP_ARRAY(uint, _evac_failure_regions);\n-  _evac_failure_regions = nullptr;\n+  FREE_C_HEAP_ARRAY(uint, _evac_retained_regions);\n+  _evac_retained_regions = nullptr;\n@@ -58,1 +68,1 @@\n-  return _regions_failed_evacuation.par_at(region_idx, memory_order_relaxed);\n+  return _regions_retained.par_at(region_idx, memory_order_relaxed);\n@@ -66,2 +76,2 @@\n-                                                     _evac_failure_regions,\n-                                                     Atomic::load(&_evac_failure_regions_cur_length),\n+                                                     _evac_retained_regions,\n+                                                     Atomic::load(&_evac_retained_regions_cur_length),\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.cpp","additions":20,"deletions":10,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -36,3 +36,3 @@\n-\/\/ This class records for every region on the heap whether evacuation failed for it,\n-\/\/ and records for every evacuation failure region to speed up iteration of these\n-\/\/ regions in post evacuation phase.\n+\/\/ This class records for every region on the heap whether it has to be retained\n+\/\/ (i.e. pinned or evacuation failure or both) and records for every such region\n+\/\/ information to speed up iteration of these regions in various gc phases.\n@@ -40,1 +40,5 @@\n-  \/\/ Records for every region on the heap whether evacuation failed for it.\n+  \/\/ Records for every region on the heap whether the region has been retained.\n+  CHeapBitMap _regions_retained;\n+  \/\/ Records for every region on the heap whether the evacuation failure cause\n+  \/\/ has been region pinning.\n+  CHeapBitMap _regions_pinned;\n@@ -42,4 +46,7 @@\n-  \/\/ Regions (index) of evacuation failed in the current collection.\n-  uint* _evac_failure_regions;\n-  \/\/ Number of regions evacuation failed in the current collection.\n-  volatile uint _evac_failure_regions_cur_length;\n+  \/\/ Retained regions (indexes) in the current collection.\n+  uint* _evac_retained_regions;\n+  \/\/ Number of regions evacuation retained in the current collection.\n+  volatile uint _evac_retained_regions_cur_length;\n+  \/\/ Number of regions evacuation failed due to pinning in the current collection.\n+  volatile uint _evac_failure_regions_pinned;\n+  volatile uint _evac_failure_regions_failed_evacuation;\n@@ -52,2 +59,2 @@\n-    assert(idx < _evac_failure_regions_cur_length, \"precondition\");\n-    return _evac_failure_regions[idx];\n+    assert(idx < _evac_retained_regions_cur_length, \"precondition\");\n+    return _evac_retained_regions[idx];\n@@ -69,2 +76,2 @@\n-  uint num_regions_failed_evacuation() const {\n-    return Atomic::load(&_evac_failure_regions_cur_length);\n+  uint num_regions_retained() const {\n+    return Atomic::load(&_evac_retained_regions_cur_length);\n@@ -73,2 +80,18 @@\n-  bool evacuation_failed() const {\n-    return num_regions_failed_evacuation() > 0;\n+  uint num_regions_pinned() const {\n+    return Atomic::load(&_evac_failure_regions_pinned);\n+  }\n+\n+  uint num_regions_evac_failed() const {\n+      return Atomic::load(&_evac_failure_regions_failed_evacuation);\n+  }\n+\n+  bool has_regions_retained() const {\n+    return num_regions_retained() > 0;\n+  }\n+\n+  bool has_regions_evac_pinned() const {\n+    return num_regions_pinned() > 0;\n+  }\n+\n+  bool has_regions_evac_failed() const {\n+    return num_regions_evac_failed() > 0;\n@@ -80,1 +103,1 @@\n-  inline bool record(uint region_idx);\n+  inline bool record(uint region_idx, bool cause_pinned);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.hpp","additions":38,"deletions":15,"binary":false,"changes":53,"status":"modified"},{"patch":"@@ -32,2 +32,2 @@\n-bool G1EvacFailureRegions::record(uint region_idx) {\n-  bool success = _regions_failed_evacuation.par_set_bit(region_idx,\n+bool G1EvacFailureRegions::record(uint region_idx, bool cause_pinned) {\n+  bool success = _regions_retained.par_set_bit(region_idx,\n@@ -36,2 +36,2 @@\n-    size_t offset = Atomic::fetch_then_add(&_evac_failure_regions_cur_length, 1u);\n-    _evac_failure_regions[offset] = region_idx;\n+    size_t offset = Atomic::fetch_then_add(&_evac_retained_regions_cur_length, 1u);\n+    _evac_retained_regions[offset] = region_idx;\n@@ -43,0 +43,10 @@\n+\n+  if (cause_pinned) {\n+    if (_regions_pinned.par_set_bit(region_idx, memory_order_relaxed)) {\n+      Atomic::inc(&_evac_failure_regions_pinned, memory_order_relaxed);\n+    }\n+  } else {\n+    if (_regions_failed_evacuation.par_set_bit(region_idx, memory_order_relaxed)) {\n+      Atomic::inc(&_evac_failure_regions_failed_evacuation, memory_order_relaxed);\n+    }\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.inline.hpp","additions":14,"deletions":4,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -259,3 +259,3 @@\n-  } else if (hr->is_humongous()) {\n-    \/\/ Humongous objects will never be moved in the \"main\" compaction phase, but\n-    \/\/ afterwards in a special phase if needed.\n+  } else if (hr->is_humongous() || hr->has_pinned_objects()) {\n+    \/\/ Humongous objects or pinned regions will never be moved in the \"main\"\n+    \/\/ compaction phase, but non-pinned regions might afterwards in a special phase.\n@@ -456,2 +456,7 @@\n-      uint num_regions = humongous_cp->forward_humongous(hr);\n-      region_index += num_regions; \/\/ Skip over the continues humongous regions.\n+      size_t obj_size = cast_to_oop(hr->bottom())->size();\n+      uint num_regions = (uint)G1CollectedHeap::humongous_obj_size_in_regions(obj_size);\n+      \/\/ Even during last-ditch compaction we should not move pinned humongous objects.\n+      if (!hr->has_pinned_objects()) {\n+        humongous_cp->forward_humongous(hr);\n+      }\n+      region_index += num_regions; \/\/ Advance over all humongous regions.\n@@ -460,0 +465,1 @@\n+      assert(!hr->has_pinned_objects(), \"pinned objects should not be compaction targets\");\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -70,0 +70,1 @@\n+  assert(!hr->has_pinned_objects(), \"Should be no region with pinned objects in compaction queue\");\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactTask.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -148,1 +148,1 @@\n-uint G1FullGCCompactionPoint::forward_humongous(HeapRegion* hr) {\n+void G1FullGCCompactionPoint::forward_humongous(HeapRegion* hr) {\n@@ -156,1 +156,1 @@\n-    return num_regions;\n+    return;\n@@ -164,1 +164,1 @@\n-    return num_regions;\n+    return;\n@@ -180,1 +180,1 @@\n-  return num_regions;\n+  return;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-  uint forward_humongous(HeapRegion* hr);\n+  void forward_humongous(HeapRegion* hr);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -45,1 +45,1 @@\n-  if (hr->is_humongous()) {\n+  if (hr->is_humongous() || hr->has_pinned_objects()) {\n@@ -82,1 +82,8 @@\n-    if (hr->is_humongous()) {\n+    if (hr->has_pinned_objects() ||\n+        (hr->is_humongous() && hr->humongous_start_region()->has_pinned_objects())) {\n+      \/\/ First check regions with pinned objects: they need to be skipped regardless\n+      \/\/ of region type and never be considered for reclamation.\n+      assert(_collector->is_skip_compacting(hr->hrm_index()), \"pinned region %u must be skip_compacting\", hr->hrm_index());\n+      log_trace(gc, phases)(\"Phase 2: skip compaction region index: %u (%s), has pinned objects\",\n+                            hr->hrm_index(), hr->get_short_type_str());\n+    } else if (hr->is_humongous()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.inline.hpp","additions":9,"deletions":2,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -92,1 +92,2 @@\n-    assert(_collector->mark_bitmap()->is_marked(obj), \"must be live\");\n+    assert(hr->humongous_start_region()->has_pinned_objects() ||\n+           _collector->mark_bitmap()->is_marked(obj), \"must be live\");\n@@ -94,2 +95,2 @@\n-    assert(_collector->live_words(region_index) > _collector->scope()->region_compaction_threshold(),\n-           \"should be quite full\");\n+    assert(hr->has_pinned_objects() || _collector->live_words(region_index) > _collector->scope()->region_compaction_threshold(),\n+           \"should be quite full or pinned %u\", region_index);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCResetMetadataTask.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -136,1 +136,2 @@\n-  _gc_par_phases[RestoreRetainedRegions]->create_thread_work_items(\"New Retained Regions:\", RestoreRetainedRegionsRetainedNum);\n+  _gc_par_phases[RestoreRetainedRegions]->create_thread_work_items(\"Pinned Regions:\", RestoreRetainedRegionsPinnedNum);\n+  _gc_par_phases[RestoreRetainedRegions]->create_thread_work_items(\"Retained Regions:\", RestoreRetainedRegionsRetainedNum);\n@@ -481,1 +482,1 @@\n-double G1GCPhaseTimes::print_post_evacuate_collection_set(bool evacuation_failed) const {\n+double G1GCPhaseTimes::print_post_evacuate_collection_set(bool evacuation_retained) const {\n@@ -504,1 +505,1 @@\n-  if (evacuation_failed) {\n+  if (evacuation_retained) {\n@@ -510,1 +511,1 @@\n-  if (evacuation_failed) {\n+  if (evacuation_retained) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.cpp","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -151,0 +151,1 @@\n+    RestoreRetainedRegionsPinnedNum,\n@@ -243,1 +244,1 @@\n-  double print_post_evacuate_collection_set(bool evacuation_failed) const;\n+  double print_post_evacuate_collection_set(bool evacuation_retained) const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+  bool _is_pinned;\n@@ -62,3 +63,2 @@\n-  G1HeapRegionAttr(region_type_t type = NotInCSet, bool remset_is_tracked = false) :\n-    _remset_is_tracked(remset_is_tracked), _type(type) {\n-\n+  G1HeapRegionAttr(region_type_t type = NotInCSet, bool remset_is_tracked = false, bool is_pinned = false) :\n+    _remset_is_tracked(remset_is_tracked), _type(type), _is_pinned(is_pinned) {\n@@ -85,0 +85,2 @@\n+  bool is_pinned() const               { return _is_pinned; }\n+\n@@ -90,0 +92,1 @@\n+\n@@ -91,0 +94,1 @@\n+  void set_is_pinned(bool value)       { _is_pinned = value; }\n@@ -139,1 +143,3 @@\n-    set_by_index(index, G1HeapRegionAttr(G1HeapRegionAttr::HumongousCandidate, remset_is_tracked));\n+    \/\/ Humongous candidates can not be pinned.\n+    const bool region_is_pinned = false;\n+    set_by_index(index, G1HeapRegionAttr(G1HeapRegionAttr::HumongousCandidate, remset_is_tracked, region_is_pinned));\n@@ -154,1 +160,5 @@\n-  void set_in_young(uintptr_t index) {\n+  void set_is_pinned(uintptr_t index, bool is_pinned) {\n+    get_ref_by_index(index)->set_is_pinned(is_pinned);\n+  }\n+\n+  void set_in_young(uintptr_t index, bool is_pinned) {\n@@ -157,1 +167,1 @@\n-    set_by_index(index, G1HeapRegionAttr(G1HeapRegionAttr::Young, true));\n+    set_by_index(index, G1HeapRegionAttr(G1HeapRegionAttr::Young, true, is_pinned));\n@@ -163,1 +173,3 @@\n-    set_by_index(index, G1HeapRegionAttr(G1HeapRegionAttr::Old, remset_is_tracked));\n+    \/\/ We do not select regions with pinned objects into the collection set.\n+    const bool region_is_pinned = false;\n+    set_by_index(index, G1HeapRegionAttr(G1HeapRegionAttr::Old, remset_is_tracked, region_is_pinned));\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionAttr.hpp","additions":19,"deletions":7,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -250,5 +250,4 @@\n-  \/\/ Max length includes any potential extensions to the young gen\n-  \/\/ we'll do when the GC locker is active.\n-  uint young_list_max_length = _g1h->policy()->young_list_max_length();\n-  assert(young_list_max_length >= survivor_list_length, \"invariant\");\n-  uint eden_list_max_length = young_list_max_length - survivor_list_length;\n+\n+  uint young_list_target_length = _g1h->policy()->young_list_target_length();\n+  assert(young_list_target_length >= survivor_list_length, \"invariant\");\n+  uint eden_list_max_length = young_list_target_length - survivor_list_length;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonitoringSupport.cpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -464,0 +464,4 @@\n+  if (region_attr.is_pinned() && klass->is_typeArray_klass()) {\n+    return handle_evacuation_failure_par(old, old_mark, word_sz, true \/* cause_pinned *\/);\n+  }\n+\n@@ -478,1 +482,1 @@\n-      return handle_evacuation_failure_par(old, old_mark, word_sz);\n+      return handle_evacuation_failure_par(old, old_mark, word_sz, false \/* cause_pinned *\/);\n@@ -490,1 +494,1 @@\n-    return handle_evacuation_failure_par(old, old_mark, word_sz);\n+    return handle_evacuation_failure_par(old, old_mark, word_sz, true \/* cause_pinned *\/);\n@@ -627,1 +631,1 @@\n-oop G1ParScanThreadState::handle_evacuation_failure_par(oop old, markWord m, size_t word_sz) {\n+oop G1ParScanThreadState::handle_evacuation_failure_par(oop old, markWord m, size_t word_sz, bool cause_pinned) {\n@@ -635,1 +639,1 @@\n-    if (_evac_failure_regions->record(r->hrm_index())) {\n+    if (_evac_failure_regions->record(r->hrm_index(), cause_pinned)) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -234,1 +234,1 @@\n-  oop handle_evacuation_failure_par(oop obj, markWord m, size_t word_sz);\n+  oop handle_evacuation_failure_par(oop obj, markWord m, size_t word_sz, bool cause_pinned);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,1 +66,0 @@\n-  _young_list_max_length(0),\n@@ -201,1 +200,0 @@\n-  uint new_young_list_max_length = calculate_young_max_length(new_young_list_target_length);\n@@ -203,1 +201,1 @@\n-  log_trace(gc, ergo, heap)(\"Young list length update: pending cards %zu card_rs_length %zu old target %u desired: %u target: %u max: %u\",\n+  log_trace(gc, ergo, heap)(\"Young list length update: pending cards %zu card_rs_length %zu old target %u desired: %u target: %u\",\n@@ -208,2 +206,1 @@\n-                            new_young_list_target_length,\n-                            new_young_list_max_length);\n+                            new_young_list_target_length);\n@@ -220,1 +217,0 @@\n-  Atomic::store(&_young_list_max_length, new_young_list_max_length);\n@@ -324,2 +320,1 @@\n-    \/\/ young list length concurrently, or caused by gclocker). Do not allow more,\n-    \/\/ potentially resulting in GC.\n+    \/\/ young list length concurrently). Do not allow more, potentially resulting in GC.\n@@ -499,1 +494,3 @@\n-  for (HeapRegion* r : candidates()->marking_regions()) {\n+  for (G1CollectionSetCandidateInfo* ci : candidates()->marking_regions()) {\n+    \/\/ We optimistically assume that any of these marking candidate regions will\n+    \/\/ not be pinned, so just consider them as normal.\n@@ -503,1 +500,1 @@\n-    predicted_region_evac_time_ms += predict_region_total_time_ms(r, false \/* for_young_only_phase *\/);\n+    predicted_region_evac_time_ms += predict_region_total_time_ms(ci->_r, false \/* for_young_only_phase *\/);\n@@ -526,0 +523,2 @@\n+  uint num_unreclaimable_regions = 0;\n+\n@@ -532,1 +531,7 @@\n-  for (HeapRegion* r : list) {\n+  for (G1CollectionSetCandidateInfo* ci : list) {\n+    HeapRegion* r = ci->_r;\n+    \/\/ We optimistically assume that any of these marking candidate regions will\n+    \/\/ be reclaimable the next gc, so just consider them as normal.\n+    if (!r->can_reclaim()) {\n+      num_unreclaimable_regions++;\n+    }\n@@ -542,2 +547,2 @@\n-  log_trace(gc, ergo, heap)(\"Selected %u of %u retained candidates taking %1.3fms additional time\",\n-                            num_regions, list.length(), result);\n+  log_trace(gc, ergo, heap)(\"Selected %u of %u retained candidates (unreclaimable %u) taking %1.3fms additional time\",\n+                            num_regions, list.length(), num_unreclaimable_regions, result);\n@@ -658,1 +663,1 @@\n-  size_t live_bytes= _g1h->region_at(index)->live_bytes();\n+  size_t live_bytes = _g1h->region_at(index)->live_bytes();\n@@ -660,0 +665,2 @@\n+#ifdef ASSERT\n+  HeapRegion* r = _g1h->region_at(index);\n@@ -661,3 +668,3 @@\n-         \"live bytes not set for %u used %zu garbage %zu cm-live %zu\",\n-         index, _g1h->region_at(index)->used(), _g1h->region_at(index)->garbage_bytes(), live_bytes);\n-\n+         \"live bytes not set for %u used %zu garbage %zu cm-live %zu pinned %d\",\n+         index, r->used(), r->garbage_bytes(), live_bytes, r->has_pinned_objects());\n+#endif\n@@ -1045,1 +1052,1 @@\n-void G1Policy::record_young_gc_pause_end(bool evacuation_failed) {\n+void G1Policy::record_young_gc_pause_end(bool evacuation_retained) {\n@@ -1047,1 +1054,1 @@\n-  phase_times()->print(evacuation_failed);\n+  phase_times()->print(evacuation_retained);\n@@ -1156,5 +1163,0 @@\n-bool G1Policy::can_expand_young_list() const {\n-  uint young_list_length = _g1h->young_regions_count();\n-  return young_list_length < young_list_max_length();\n-}\n-\n@@ -1184,14 +1186,0 @@\n-uint G1Policy::calculate_young_max_length(uint target_young_length) const {\n-  uint expansion_region_num = 0;\n-  if (GCLockerEdenExpansionPercent > 0) {\n-    double perc = GCLockerEdenExpansionPercent \/ 100.0;\n-    double expansion_region_num_d = perc * young_list_target_length();\n-    \/\/ We use ceiling so that if expansion_region_num_d is > 0.0 (but\n-    \/\/ less than 1.0) we'll get 1.\n-    expansion_region_num = (uint) ceil(expansion_region_num_d);\n-  }\n-  uint max_length = target_young_length + expansion_region_num;\n-  assert(target_young_length <= max_length, \"overflow\");\n-  return max_length;\n-}\n-\n@@ -1480,1 +1468,2 @@\n-                                                G1CollectionCandidateRegionList* optional_old_regions) {\n+                                                G1CollectionCandidateRegionList* optional_old_regions,\n+                                                G1CollectionCandidateRegionList* pinned_old_regions) {\n@@ -1487,0 +1476,1 @@\n+  uint num_unreclaimable_regions = 0;\n@@ -1499,1 +1489,1 @@\n-                            \"Min %u regions, max %u regions, \"\n+                            \"Min %u regions, max %u regions, available %u regions\"\n@@ -1501,1 +1491,1 @@\n-                            min_old_cset_length, max_old_cset_length, time_remaining_ms, optional_threshold_ms);\n+                            min_old_cset_length, max_old_cset_length, marking_list->length(), time_remaining_ms, optional_threshold_ms);\n@@ -1510,1 +1500,12 @@\n-    HeapRegion* hr = *iter;\n+    HeapRegion* hr = (*iter)->_r;\n+    \/\/ Skip evacuating pinned marking regions because we are not getting any free\n+    \/\/ space from them (and we expect to get free space from marking candidates).\n+    \/\/ Also prepare to move them to retained regions to be evacuated optionally later\n+    \/\/ to not impact the mixed phase too much.\n+    if (!hr->can_reclaim()) {\n+      num_unreclaimable_regions++;\n+      (*iter)->update_num_unreclaimed();\n+      log_trace(gc, ergo, cset)(\"Marking candidate %u can not be reclaimed currently. Skipping.\", hr->hrm_index());\n+      pinned_old_regions->append(hr);\n+      continue;\n+    }\n@@ -1554,1 +1555,1 @@\n-  log_debug(gc, ergo, cset)(\"Finish adding marking candidates to collection set. Initial: %u, optional: %u, \"\n+  log_debug(gc, ergo, cset)(\"Finish adding marking candidates to collection set. Initial: %u, optional: %u, unreclaimable: %u, \"\n@@ -1556,1 +1557,1 @@\n-                            num_initial_regions_selected, num_optional_regions_selected,\n+                            num_initial_regions_selected, num_optional_regions_selected, num_unreclaimable_regions,\n@@ -1567,1 +1568,2 @@\n-                                               G1CollectionCandidateRegionList* optional_old_regions) {\n+                                               G1CollectionCandidateRegionList* optional_old_regions,\n+                                               G1CollectionCandidateRegionList* pinned_old_regions) {\n@@ -1574,0 +1576,1 @@\n+  uint num_unreclaimable_regions = 0;\n@@ -1587,1 +1590,1 @@\n-                            \"Min %u regions, \"\n+                            \"Min %u regions, available %u, \"\n@@ -1589,1 +1592,1 @@\n-                            min_regions, time_remaining_ms, optional_time_remaining_ms);\n+                            min_regions, retained_list->length(), time_remaining_ms, optional_time_remaining_ms);\n@@ -1591,1 +1594,2 @@\n-  for (HeapRegion* r : *retained_list) {\n+  for (G1CollectionSetCandidateInfo* ci : *retained_list) {\n+    HeapRegion* r = ci->_r;\n@@ -1594,0 +1598,11 @@\n+    \/\/ If we can't reclaim that region ignore it for now.\n+    if (!r->can_reclaim()) {\n+      num_unreclaimable_regions++;\n+      if (ci->update_num_unreclaimed()) {\n+        log_trace(gc, ergo, cset)(\"Retained candidate %u can not be reclaimed currently. Skipping.\", r->hrm_index());\n+      } else {\n+        log_trace(gc, ergo, cset)(\"Retained candidate %u can not be reclaimed currently. Dropping.\", r->hrm_index());\n+        pinned_old_regions->append(r);\n+      }\n+      continue;\n+    }\n@@ -1623,1 +1638,1 @@\n-  log_debug(gc, ergo, cset)(\"Finish adding retained candidates to collection set. Initial: %u, optional: %u, \"\n+  log_debug(gc, ergo, cset)(\"Finish adding retained candidates to collection set. Initial: %u, optional: %u, unreclaimable: %u, \"\n@@ -1626,1 +1641,1 @@\n-                            num_initial_regions_selected, num_optional_regions_selected,\n+                            num_initial_regions_selected, num_optional_regions_selected, num_unreclaimable_regions,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":65,"deletions":50,"binary":false,"changes":115,"status":"modified"},{"patch":"@@ -246,3 +246,0 @@\n-  \/\/ The GCLocker might cause us to need more regions than the target. Calculate\n-  \/\/ the maximum number of regions to use in that case.\n-  uint calculate_young_max_length(uint target_young_length) const;\n@@ -307,1 +304,1 @@\n-  void record_young_gc_pause_end(bool evacuation_failed);\n+  void record_young_gc_pause_end(bool evacuation_retained);\n@@ -338,1 +335,1 @@\n-  \/\/ Calculate and fill in the initial and optional old gen candidate regions from\n+  \/\/ Calculate and fill in the initial, optional and pinned old gen candidate regions from\n@@ -344,1 +341,2 @@\n-                                        G1CollectionCandidateRegionList* optional_old_regions);\n+                                        G1CollectionCandidateRegionList* optional_old_regions,\n+                                        G1CollectionCandidateRegionList* pinned_old_regions);\n@@ -349,1 +347,2 @@\n-                                       G1CollectionCandidateRegionList* optional_old_regions);\n+                                       G1CollectionCandidateRegionList* optional_old_regions,\n+                                       G1CollectionCandidateRegionList* pinned_old_regions);\n@@ -386,1 +385,0 @@\n-  uint young_list_max_length() const { return Atomic::load(&_young_list_max_length); }\n@@ -390,2 +388,0 @@\n-  bool can_expand_young_list() const;\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.hpp","additions":6,"deletions":10,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -71,5 +71,3 @@\n-  \/\/ got scheduled and prevented the scheduling of the concurrent start GC. The\n-  \/\/ second is that the GC locker may be active and the heap can't be expanded.\n-  \/\/ In both cases we want to retry the GC so that the concurrent start pause is\n-  \/\/ actually scheduled. In the second case, however, we should stall until\n-  \/\/ until the GC locker is no longer active and then retry the concurrent start GC.\n+  \/\/ got scheduled and prevented the scheduling of the concurrent start GC.\n+  \/\/ In this case we want to retry the GC so that the concurrent start pause is\n+  \/\/ actually scheduled.\n@@ -106,8 +104,0 @@\n-  } else if (!g1h->do_collection_pause_at_safepoint()) {\n-    \/\/ Failure to perform the collection at all occurs because GCLocker is\n-    \/\/ active, and we have the bad luck to be the collection request that\n-    \/\/ makes a later _gc_locker collection needed.  (Else we would have hit\n-    \/\/ the GCLocker check in the prologue.)\n-    _transient_failure = true;\n-  } else if (g1h->should_upgrade_to_full_gc()) {\n-    _gc_succeeded = g1h->upgrade_to_full_collection();\n@@ -115,1 +105,2 @@\n-    _gc_succeeded = true;\n+    _gc_succeeded = g1h->do_collection_pause_at_safepoint();\n+    assert(_gc_succeeded, \"No reason to fail\");\n@@ -128,16 +119,0 @@\n-  if (_word_size > 0) {\n-    \/\/ An allocation has been requested. So, try to do that first.\n-    \/\/ During the execution of this VM operation, there may have been a concurrent active\n-    \/\/ GCLocker, potentially leading to expansion of the Eden space by other mutators.\n-    \/\/ If the Eden space were expanded, this allocation request might succeed without\n-    \/\/ the need for triggering a garbage collection.\n-    _result = g1h->attempt_allocation_at_safepoint(_word_size,\n-                                                   false \/* expect_null_cur_alloc_region *\/);\n-    if (_result != nullptr) {\n-      \/\/ If we can successfully allocate before we actually do the\n-      \/\/ pause then we will consider this pause successful.\n-      _gc_succeeded = true;\n-      return;\n-    }\n-  }\n-\n@@ -147,0 +122,1 @@\n+  assert(_gc_succeeded, \"no reason to fail\");\n@@ -148,11 +124,9 @@\n-  if (_gc_succeeded) {\n-    if (_word_size > 0) {\n-      \/\/ An allocation had been requested. Do it, eventually trying a stronger\n-      \/\/ kind of GC.\n-      _result = g1h->satisfy_failed_allocation(_word_size, &_gc_succeeded);\n-    } else if (g1h->should_upgrade_to_full_gc()) {\n-      \/\/ There has been a request to perform a GC to free some space. We have no\n-      \/\/ information on how much memory has been asked for. In case there are\n-      \/\/ absolutely no regions left to allocate into, do a full compaction.\n-      _gc_succeeded = g1h->upgrade_to_full_collection();\n-    }\n+  if (_word_size > 0) {\n+    \/\/ An allocation had been requested. Do it, eventually trying a stronger\n+    \/\/ kind of GC.\n+    _result = g1h->satisfy_failed_allocation(_word_size, &_gc_succeeded);\n+  } else if (g1h->should_upgrade_to_full_gc()) {\n+    \/\/ There has been a request to perform a GC to free some space. We have no\n+    \/\/ information on how much memory has been asked for. In case there are\n+    \/\/ absolutely no regions left to allocate into, do a full compaction.\n+    _gc_succeeded = g1h->upgrade_to_full_collection();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1VMOperations.cpp","additions":15,"deletions":41,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -82,1 +82,1 @@\n-             \"Pause Young (%s) (%s)%s\",\n+             \"Pause Young (%s) (%s)%s%s\",\n@@ -85,0 +85,1 @@\n+             _collector->evacuation_pinned() ? \" (Pinned)\" : \"\",\n@@ -116,1 +117,1 @@\n-    G1CollectedHeap::heap()->policy()->record_young_gc_pause_end(_collector->evacuation_failed());\n+    G1CollectedHeap::heap()->policy()->record_young_gc_pause_end(_collector->evacuation_retained());\n@@ -167,1 +168,1 @@\n-    if (_collector->evacuation_failed()) {\n+    if (_collector->evacuation_retained()) {\n@@ -317,0 +318,4 @@\n+      \/\/ We also cannot collect the humongous object if it is pinned.\n+      if (region->has_pinned_objects()) {\n+        return false;\n+      }\n@@ -389,1 +394,2 @@\n-      log_debug(gc, humongous)(\"Humongous region %u (object size %zu @ \" PTR_FORMAT \") remset %zu code roots %zu marked %d reclaim candidate %d type array %d\",\n+      log_debug(gc, humongous)(\"Humongous region %u (object size %zu @ \" PTR_FORMAT \") remset %zu code roots %zu \"\n+                               \"marked %d pinned count %u reclaim candidate %d type array %d\",\n@@ -396,0 +402,1 @@\n+                               hr->pinned_count(),\n@@ -422,1 +429,1 @@\n-    _humongous_candidates(0) { }\n+    _humongous_candidates(0)  { }\n@@ -1012,0 +1019,8 @@\n+bool G1YoungCollector::evacuation_retained() const {\n+  return _evac_failure_regions.has_regions_retained();\n+}\n+\n+bool G1YoungCollector::evacuation_pinned() const {\n+  return _evac_failure_regions.has_regions_evac_pinned();\n+}\n+\n@@ -1013,1 +1028,1 @@\n-  return _evac_failure_regions.evacuation_failed();\n+  return _evac_failure_regions.has_regions_evac_failed();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungCollector.cpp","additions":21,"deletions":6,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -134,0 +134,4 @@\n+  \/\/ True iff an evacuation required retaining in the most-recent collection.\n+  bool evacuation_retained() const;\n+  \/\/ True iff an evacuation has pinned in the most-recent collection.\n+  bool evacuation_pinned() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungCollector.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-  bool _evacuation_failed;\n+  bool _retained;\n@@ -61,1 +61,1 @@\n-  RecalculateUsedTask(bool evacuation_failed) : G1AbstractSubTask(G1GCPhaseTimes::RecalculateUsed), _evacuation_failed(evacuation_failed) { }\n+  RecalculateUsedTask(bool retained) : G1AbstractSubTask(G1GCPhaseTimes::RecalculateUsed), _retained(retained) { }\n@@ -65,1 +65,1 @@\n-    return _evacuation_failed ? 1.0 : AlmostNoWork;\n+    return _retained ? 1.0 : AlmostNoWork;\n@@ -68,1 +68,1 @@\n-  void do_work(uint worker_id) override { G1CollectedHeap::heap()->update_used_after_gc(_evacuation_failed); }\n+  void do_work(uint worker_id) override { G1CollectedHeap::heap()->update_used_after_gc(_retained); }\n@@ -107,1 +107,1 @@\n-    assert(_evac_failure_regions->evacuation_failed(), \"Should not call this if not executed\");\n+    assert(_evac_failure_regions->has_regions_retained(), \"Should not call this if not executed\");\n@@ -110,1 +110,1 @@\n-    return workers_per_region * _evac_failure_regions->num_regions_failed_evacuation();\n+    return workers_per_region * _evac_failure_regions->num_regions_retained();\n@@ -122,1 +122,1 @@\n-  bool evacuation_failed = evac_failure_regions->evacuation_failed();\n+  bool retained = evac_failure_regions->has_regions_retained();\n@@ -125,1 +125,1 @@\n-  add_serial_task(new RecalculateUsedTask(evacuation_failed));\n+  add_serial_task(new RecalculateUsedTask(retained));\n@@ -130,1 +130,1 @@\n-  if (evacuation_failed) {\n+  if (retained) {\n@@ -383,1 +383,1 @@\n-    return _evac_failure_regions->num_regions_failed_evacuation();\n+    return _evac_failure_regions->num_regions_retained();\n@@ -571,0 +571,2 @@\n+    bool is_pinned = r->has_pinned_objects();\n+\n@@ -574,1 +576,2 @@\n-                                      G1GCPhaseTimes::RestoreRetainedRegionsFailedNum);\n+                                      is_pinned ? G1GCPhaseTimes::RestoreRetainedRegionsPinnedNum\n+                                                : G1GCPhaseTimes::RestoreRetainedRegionsFailedNum);\n@@ -769,1 +772,1 @@\n-  if (evac_failure_regions->evacuation_failed()) {\n+  if (evac_failure_regions->has_regions_retained()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":15,"deletions":12,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -327,0 +327,4 @@\n+  product(uint, G1NumCollectionsKeepUnreclaimable, 8, DIAGNOSTIC,           \\\n+          \"After how many GCs a region has been found unreclaimable G1 \"    \\\n+          \"should give up reclaiming it.\")                                  \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -235,1 +235,2 @@\n-  _node_index(G1NUMA::UnknownNodeIndex)\n+  _node_index(G1NUMA::UnknownNodeIndex),\n+  _pinned_object_count(0)\n@@ -426,0 +427,1 @@\n+  st->print(\"|%3u\", Atomic::load(&_pinned_object_count));\n@@ -729,3 +731,9 @@\n-  \/\/ Fill the dead range with objects. G1 might need to create two objects if\n-  \/\/ the range is larger than half a region, which is the max_fill_size().\n-  CollectedHeap::fill_with_objects(start, range_size);\n+  \/\/ We must be a bit careful with regions that contain pinned objects. While the\n+  \/\/ ranges passed in here corresponding to the space between live objects, it is\n+  \/\/ possible that there is a pinned object that is not any more referenced by\n+  \/\/ Java code (only by native).\n+  \/\/ In this case we must not zap contents of such an array but we can overwrite\n+  \/\/ the header; since only pinned typearrays are allowed, this fits nicely with\n+  \/\/ putting filler arrays into the dead range as the object header sizes match and\n+  \/\/ no user data is overwritten.\n+  CollectedHeap::fill_with_objects(start, range_size, !has_pinned_objects());\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -252,0 +252,3 @@\n+  \/\/ Number of objects in this region that are currently pinned.\n+  volatile uint _pinned_object_count;\n+\n@@ -295,0 +298,3 @@\n+  inline void increment_pinned_object_count();\n+  inline void decrement_pinned_object_count();\n+\n@@ -398,0 +404,5 @@\n+  uint pinned_count() const { return Atomic::load(&_pinned_object_count); }\n+  bool has_pinned_objects() const { return pinned_count() > 0; }\n+\n+  bool can_reclaim() const;\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -262,0 +262,4 @@\n+inline bool HeapRegion::can_reclaim() const {\n+  return !has_pinned_objects();\n+}\n+\n@@ -551,0 +555,8 @@\n+inline void HeapRegion::increment_pinned_object_count() {\n+  Atomic::add(&_pinned_object_count, 1u, memory_order_relaxed);\n+}\n+\n+inline void HeapRegion::decrement_pinned_object_count() {\n+  Atomic::sub(&_pinned_object_count, 1u, memory_order_relaxed);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+  nonstatic_field(HeapRegion, _pinned_object_count, volatile uint)            \\\n","filename":"src\/hotspot\/share\/gc\/g1\/vmStructs_g1.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -168,1 +168,2 @@\n-  static inline size_t filler_array_min_size();\n+public:\n+  static size_t filler_array_min_size();\n@@ -170,0 +171,1 @@\n+protected:\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -404,1 +404,1 @@\n-    return !(hr->is_young());\n+    return hr->is_old_or_humongous();\n@@ -2606,0 +2606,26 @@\n+WB_ENTRY(void, WB_PinObject(JNIEnv* env, jobject wb, jobject o))\n+#if INCLUDE_G1GC\n+  if (!UseG1GC) {\n+    ShouldNotReachHere();\n+    return;\n+  }\n+  oop obj = JNIHandles::resolve(o);\n+  G1CollectedHeap::heap()->pin_object(thread, obj);\n+#else\n+  ShouldNotReachHere();\n+#endif \/\/ INCLUDE_G1GC\n+WB_END\n+\n+WB_ENTRY(void, WB_UnpinObject(JNIEnv* env, jobject wb, jobject o))\n+#if INCLUDE_G1GC\n+  if (!UseG1GC) {\n+    ShouldNotReachHere();\n+    return;\n+  }\n+  oop obj = JNIHandles::resolve(o);\n+  G1CollectedHeap::heap()->unpin_object(thread, obj);\n+#else\n+  ShouldNotReachHere();\n+#endif \/\/ INCLUDE_G1GC\n+WB_END\n+\n@@ -2914,0 +2940,2 @@\n+  {CC\"pinObject\",       CC\"(Ljava\/lang\/Object;)V\",    (void*)&WB_PinObject},\n+  {CC\"unpinObject\",     CC\"(Ljava\/lang\/Object;)V\",    (void*)&WB_UnpinObject},\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":29,"deletions":1,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -1115,0 +1115,1 @@\n+  declare_unsigned_integer_type(volatile uint)                            \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1114,0 +1114,3 @@\n+                          if (!bad && region.isPinned()) {\n+                            anno += \"Pinned \";\n+                          }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/HSDB.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+    private static CIntegerField pinnedCountField;\n+\n@@ -74,0 +76,2 @@\n+        pinnedCountField = type.getCIntegerField(\"_pinned_object_count\");\n+\n@@ -127,0 +131,4 @@\n+    public boolean isPinned() {\n+        return pinnedCountField.getValue(addr) != 0;\n+    }\n+\n@@ -137,1 +145,1 @@\n-        tty.println(\":\" + type.typeAnnotation());\n+        tty.println(\":\" + type.typeAnnotation() + (isPinned() ? \" Pinned\" : \"\"));\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/gc\/g1\/HeapRegion.java","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -90,2 +90,2 @@\n-gc\/stress\/gclocker\/TestGCLockerWithG1.java 8180622 generic-all\n-gc\/stress\/TestJNIBlockFullGC\/TestJNIBlockFullGC.java 8192647 generic-all\n+gc\/stress\/gclocker\/TestGCLockerWithSerial.java 8180622 generic-all\n+gc\/stress\/gclocker\/TestGCLockerWithShenandoah.java 8180622 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -270,1 +270,2 @@\n-        new LogMessageWithLevel(\"New Retained Regions\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Pinned Regions\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Retained Regions\", Level.DEBUG),\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestGCLogMessages.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,126 @@\n+\/*\n+\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2016, 2018, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+ \/*\n+ * @test id=g1\n+ * @summary Make sure G1 can handle humongous allocation fragmentation with region pinning in the mix,\n+ *          i.e. moving humongous objects around other pinned humongous objects even in a last resort\n+ *          full gc.\n+ *          Adapted from gc\/TestAllocHumongousFragment.java\n+ * @key randomness\n+ * @requires vm.gc.G1\n+ * @library \/test\/lib\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -Xlog:gc+region=trace -XX:+UnlockDiagnosticVMOptions -XX:+UnlockExperimentalVMOptions -Xmx1g -Xms1g\n+ *      -XX:VerifyGCType=full -XX:+VerifyDuringGC -XX:+VerifyAfterGC -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      TestPinnedHumongousFragmentation\n+ *\/\n+\n+import java.util.*;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.Utils;\n+\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class TestPinnedHumongousFragmentation {\n+\n+    private static final WhiteBox wb = WhiteBox.getWhiteBox();\n+\n+    static final long TARGET_MB = 30_000; \/\/ 30 Gb allocations\n+    static final long LIVE_MB   = 700;    \/\/ 700 Mb alive\n+    static final int  PINNED_PERCENT = 5; \/\/ 5% of objects pinned\n+\n+    static volatile Object sink;\n+\n+    class PinInformation {\n+        int[] object;\n+        long address;\n+\n+        PinInformation(int[] object) {\n+            this.object = object;\n+            wb.pinObject(object);\n+            this.address = wb.getObjectAddress(object);\n+        }\n+\n+        void release() {\n+            long newAddress = wb.getObjectAddress(object);\n+            if (address != newAddress) {\n+                Asserts.fail(\"Object at \" + address + \" moved to \" + newAddress);\n+            }\n+            wb.unpinObject(object);\n+            object = null;\n+        }\n+    }\n+\n+    static List<int[]> objects;\n+    static List<PinInformation> pinnedObjects;\n+\n+    public static void main(String[] args) throws Exception {\n+        (new TestPinnedHumongousFragmentation()).run();\n+    }\n+\n+    void run() throws Exception {\n+        final int min = 128 * 1024;\n+        final int max = 16 * 1024 * 1024;\n+        final long count = TARGET_MB * 1024 * 1024 \/ (16 + 4 * (min + (max - min) \/ 2));\n+\n+        objects = new ArrayList<int[]>();\n+        pinnedObjects = new ArrayList<PinInformation>();\n+        long current = 0;\n+\n+        Random rng = Utils.getRandomInstance();\n+        for (long c = 0; c < count; c++) {\n+            while (current > LIVE_MB * 1024 * 1024) {\n+                int idx = rng.nextInt(objects.size());\n+                int[] remove = objects.remove(idx);\n+                current -= remove.length * 4 + 16;\n+            }\n+\n+            \/\/ Pin random objects before the allocation that is (likely) going to\n+            \/\/ cause full gcs. Remember them for unpinning.\n+            for (int i = 0; i < objects.size() * PINNED_PERCENT \/ 100; i++) {\n+                int[] target = objects.get(rng.nextInt(objects.size()));\n+                pinnedObjects.add(new PinInformation(target));\n+            }\n+\n+            int[] newObj = new int[min + rng.nextInt(max - min)];\n+            current += newObj.length * 4 + 16;\n+            objects.add(newObj);\n+            sink = new Object();\n+\n+            \/\/ Unpin and clear remembered objects afterwards.\n+            for (int i = 0; i < pinnedObjects.size(); i++) {\n+                pinnedObjects.get(i).release();\n+            }\n+            pinnedObjects.clear();\n+\n+            System.out.println(\"Allocated: \" + (current \/ 1024 \/ 1024) + \" Mb\");\n+        }\n+    }\n+\n+}\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/pinnedobjs\/TestPinnedHumongousFragmentation.java","additions":126,"deletions":0,"binary":false,"changes":126,"status":"added"},{"patch":"@@ -0,0 +1,90 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/* @test\n+ * @summary Test that pinned objects we lost all Java references to keep\n+ *          the region and contents alive.\n+ *          This test simulates this behavior using Whitebox\/Unsafe methods\n+ *          and not real native code for simplicity.\n+ * @requires vm.gc.G1\n+ * @requires vm.debug\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc:+open\n+ *          java.management\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:. -XX:+ZapUnusedHeapArea -Xlog:gc,gc+ergo+cset=trace gc.g1.TestPinnedObjectContents\n+ *\/\n+\n+package gc.g1;\n+\n+import jdk.internal.misc.Unsafe;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class TestPinnedObjectContents {\n+\n+    private static final jdk.internal.misc.Unsafe unsafe = Unsafe.getUnsafe();\n+    private static final WhiteBox wb = WhiteBox.getWhiteBox();\n+\n+    public static long pinAndGetAddress(Object o) {\n+        wb.pinObject(o);\n+        return wb.getObjectAddress(o);\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+        \/\/ Remove garbage from VM initialization.\n+        wb.fullGC();\n+\n+        \/\/ Allocate to-be pinned object and fill with \"random\" data.\n+        final int ArraySize = 100;\n+        int[] o = new int[ArraySize];\n+        for (int i = 0; i < o.length; i++) {\n+            o[i] = i;\n+        }\n+\n+        Asserts.assertTrue(!wb.isObjectInOldGen(o), \"should not be in old gen already\");\n+\n+        \/\/ Remember memory offsets.\n+        long baseOffset = unsafe.arrayBaseOffset(o.getClass());\n+        long indexScale = unsafe.arrayIndexScale(o.getClass());\n+        long address = pinAndGetAddress(o);\n+\n+        o = null; \/\/ And forget the (Java) reference to the int array.\n+\n+        \/\/ Do garbage collections to zap the data surrounding the \"dead\" object.\n+        wb.youngGC();\n+        wb.youngGC();\n+\n+        for (int i = 0; i < ArraySize; i++) {\n+            int actual = unsafe.getInt(null, address + baseOffset + i * indexScale);\n+            if (actual != i) {\n+                Asserts.fail(\"Pinned array at offset \" + i + \" should contain the value \" + i + \" but is \" + actual);\n+            }\n+        }\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/pinnedobjs\/TestPinnedObjectContents.java","additions":90,"deletions":0,"binary":false,"changes":90,"status":"added"},{"patch":"@@ -0,0 +1,86 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/* @test\n+ * @summary Test whether different object type can be pinned or not.\n+ * @requires vm.gc.G1\n+ * @requires vm.debug\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run driver gc.g1.TestPinnedObjectTypes\n+ *\/\n+\n+package gc.g1;\n+\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class TestPinnedObjectTypes {\n+\n+    public static void main(String[] args) throws Exception {\n+        testPinning(\"Object\", false);\n+        testPinning(\"TypeArray\", true);\n+        testPinning(\"ObjArray\", false);\n+    }\n+\n+    private static void testPinning(String type, boolean shouldSucceed) throws Exception {\n+        ProcessBuilder pb = ProcessTools.createJavaProcessBuilder(\"-XX:+UseG1GC\",\n+                                                                  \"-XX:+UnlockDiagnosticVMOptions\",\n+                                                                  \"-XX:+WhiteBoxAPI\",\n+                                                                  \"-Xbootclasspath\/a:.\",\n+                                                                  \"-Xmx32M\",\n+                                                                  \"-Xmn16M\",\n+                                                                  \"-Xlog:gc\",\n+                                                                  TestObjectPin.class.getName(),\n+                                                                  type);\n+\n+        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+        System.out.println(output.getStdout());\n+        if (shouldSucceed) {\n+          output.shouldHaveExitValue(0);\n+        } else {\n+          output.shouldNotHaveExitValue(0);\n+        }\n+    }\n+\n+}\n+\n+class TestObjectPin {\n+\n+    private static final WhiteBox wb = WhiteBox.getWhiteBox();\n+\n+    public static void main(String[] args) {\n+        Object o = switch (args[0]) {\n+            case \"Object\" -> new Object();\n+            case \"TypeArray\" -> new int[100];\n+            case \"ObjArray\" -> new Object[100];\n+            default -> null;\n+        };\n+        wb.pinObject(o);\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/pinnedobjs\/TestPinnedObjectTypes.java","additions":86,"deletions":0,"binary":false,"changes":86,"status":"added"},{"patch":"@@ -0,0 +1,131 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/* @test\n+ * @summary Test pinned objects lifecycle from young gen to eventual reclamation.\n+ * @requires vm.gc.G1\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run driver gc.g1.TestPinnedObjectsEvacuation\n+ *\/\n+\n+package gc.g1;\n+\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class TestPinnedObjectsEvacuation {\n+\n+    public static void main(String[] args) throws Exception {\n+        testPinnedEvacuation(0, 0, 0, 1);\n+        testPinnedEvacuation(1, 1, 0, 1);\n+        testPinnedEvacuation(2, 1, 1, 0);\n+        testPinnedEvacuation(3, 1, 1, 0);\n+    }\n+\n+    private static int numMatches(String stringToMatch, String pattern) {\n+        Pattern r = Pattern.compile(pattern);\n+        Matcher m = r.matcher(stringToMatch);\n+        return (int)m.results().count();\n+    }\n+\n+    private static void assertMatches(int expected, int actual, String what) {\n+        if (expected != actual) {\n+          Asserts.fail(\"Expected \" + expected + \" \" + what + \" events but got \" + actual);\n+        }\n+    }\n+\n+    private static void testPinnedEvacuation(int younGCsBeforeUnpin, int expectedSkipEvents, int expectedDropEvents, int expectedReclaimEvents) throws Exception {\n+        ProcessBuilder pb = ProcessTools.createJavaProcessBuilder(\"-XX:+UseG1GC\",\n+                                                                  \"-XX:+UnlockDiagnosticVMOptions\",\n+                                                                  \"-XX:+WhiteBoxAPI\",\n+                                                                  \"-Xbootclasspath\/a:.\",\n+                                                                  \"-Xmx32M\",\n+                                                                  \"-Xmn16M\",\n+                                                                  \"-XX:G1NumCollectionsKeepUnreclaimable=2\",\n+                                                                  \"-XX:+VerifyAfterGC\",\n+                                                                  \"-Xlog:gc,gc+ergo+cset=trace\",\n+                                                                  TestObjectPin.class.getName(),\n+                                                                  String.valueOf(younGCsBeforeUnpin));\n+\n+        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+        System.out.println(output.getStdout());\n+        output.shouldHaveExitValue(0);\n+\n+        assertMatches(expectedSkipEvents, numMatches(output.getStdout(), \".*Retained candidate \\\\d+ can not be reclaimed currently. Skipping.*\"), \"skip\");\n+        assertMatches(expectedDropEvents, numMatches(output.getStdout(), \".*Retained candidate \\\\d+ can not be reclaimed currently. Dropping.*\"), \"drop\");\n+        assertMatches(expectedReclaimEvents, numMatches(output.getStdout(), \".*Finish adding retained candidates to collection set. Initial: 1,.*\"), \"reclaim\");\n+    }\n+\n+}\n+\n+class TestObjectPin {\n+\n+    private static final WhiteBox wb = WhiteBox.getWhiteBox();\n+\n+    public static long pinAndGetAddress(Object o) {\n+        wb.pinObject(o);\n+        return wb.getObjectAddress(o);\n+    }\n+\n+    public static void unpinAndCompareAddress(Object o, long expectedAddress) {\n+        Asserts.assertEQ(expectedAddress, wb.getObjectAddress(o), \"Object has moved during pinning.\");\n+        wb.unpinObject(o);\n+    }\n+\n+    public static void main(String[] args) {\n+\n+        int youngGCBeforeUnpin = Integer.parseInt(args[0]);\n+\n+        \/\/ Remove garbage from VM initialization.\n+        wb.fullGC();\n+\n+        Object o = new int[100];\n+        Asserts.assertTrue(!wb.isObjectInOldGen(o), \"should not be pinned in old gen\");\n+\n+        long address = pinAndGetAddress(o);\n+\n+        \/\/ First young GC: should move the object into old gen.\n+        wb.youngGC();\n+        Asserts.assertTrue(wb.isObjectInOldGen(o), \"Pinned object not in old gen after young GC\");\n+\n+        \/\/ The object is (still) pinned. Do some configurable young gcs that fail to add it to the\n+        \/\/ collection set candidates.\n+        for (int i = 0; i < youngGCBeforeUnpin; i++) {\n+          wb.youngGC();\n+        }\n+        unpinAndCompareAddress(o, address);\n+\n+        \/\/ Unpinned the object. This next gc should take the region if not dropped.\n+        wb.youngGC();\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/pinnedobjs\/TestPinnedObjectsEvacuation.java","additions":131,"deletions":0,"binary":false,"changes":131,"status":"added"},{"patch":"@@ -0,0 +1,148 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/* @test\n+ * @summary Test pinned objects lifecycle from old gen to eventual reclamation.\n+ * @requires vm.gc.G1\n+ * @library \/test\/lib\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @build jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run driver gc.g1.TestPinnedOldObjectsEvacuation\n+ *\/\n+\n+package gc.g1;\n+\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import jdk.test.lib.Asserts;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.whitebox.WhiteBox;\n+\n+public class TestPinnedOldObjectsEvacuation {\n+\n+    public static void main(String[] args) throws Exception {\n+        \/\/ younGCsBeforeUnpin, expectedMarkingSkipEvents, expectedRetainedSkipEvents, expectedDropEvents, expectedMarkingReclaimEvents, expectedRetainedReclaimEvents\n+        testPinnedEvacuation(0, 0, 0, 0, 1, 0);\n+        testPinnedEvacuation(1, 1, 0, 0, 0, 1);\n+        testPinnedEvacuation(2, 1, 1, 0, 0, 1);\n+        testPinnedEvacuation(3, 1, 2, 0, 0, 1);\n+        testPinnedEvacuation(4, 1, 2, 1, 0, 0);\n+    }\n+\n+    private static int numMatches(String stringToMatch, String pattern) {\n+        Pattern r = Pattern.compile(pattern);\n+        Matcher m = r.matcher(stringToMatch);\n+        return (int)m.results().count();\n+    }\n+\n+    private static void assertMatches(int expected, int actual, String what) {\n+        if (expected != actual) {\n+          Asserts.fail(\"Expected \" + expected + \" \" + what + \" events but got \" + actual);\n+        }\n+    }\n+\n+    private static void testPinnedEvacuation(int younGCsBeforeUnpin,\n+                                             int expectedMarkingSkipEvents,\n+                                             int expectedRetainedSkipEvents,\n+                                             int expectedDropEvents,\n+                                             int expectedMarkingReclaimEvents,\n+                                             int expectedRetainedReclaimEvents) throws Exception {\n+        ProcessBuilder pb = ProcessTools.createJavaProcessBuilder(\"-XX:+UseG1GC\",\n+                                                                  \"-XX:+UnlockDiagnosticVMOptions\",\n+                                                                  \"-XX:+WhiteBoxAPI\",\n+                                                                  \"-Xbootclasspath\/a:.\",\n+                                                                  \"-Xmx32M\",\n+                                                                  \"-Xmn16M\",\n+                                                                  \"-XX:MarkSweepDeadRatio=0\",\n+                                                                  \"-XX:G1NumCollectionsKeepUnreclaimable=3\",\n+                                                                  \"-XX:+UnlockExperimentalVMOptions\",\n+                                                                  \/\/ We only want the one region containing the pinned object to be part of the collection set.\n+                                                                  \"-XX:G1MixedGCLiveThresholdPercent=2\",\n+                                                                  \"-XX:+VerifyAfterGC\",\n+                                                                  \"-Xlog:gc,gc+ergo+cset=trace\",\n+                                                                  TestObjectPin.class.getName(),\n+                                                                  String.valueOf(younGCsBeforeUnpin));\n+\n+        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+        System.out.println(output.getStdout());\n+        output.shouldHaveExitValue(0);\n+\n+        assertMatches(expectedMarkingSkipEvents, numMatches(output.getStdout(), \".*Marking candidate \\\\d+ can not be reclaimed currently. Skipping.*\"), \"skipMarking\");\n+        assertMatches(expectedRetainedSkipEvents, numMatches(output.getStdout(), \".*Retained candidate \\\\d+ can not be reclaimed currently. Skipping.*\"), \"skipRetained\");\n+        assertMatches(expectedDropEvents, numMatches(output.getStdout(), \".*Retained candidate \\\\d+ can not be reclaimed currently. Dropping.*\"), \"drop\");\n+        assertMatches(expectedMarkingReclaimEvents, numMatches(output.getStdout(), \".*Finish adding marking candidates to collection set. Initial: 1,.*\"), \"reclaimMarking\");\n+        assertMatches(expectedRetainedReclaimEvents, numMatches(output.getStdout(), \".*Finish adding retained candidates to collection set. Initial: 1,.*\"), \"reclaimRetained\");\n+    }\n+\n+}\n+\n+class TestObjectPin {\n+\n+    private static final WhiteBox wb = WhiteBox.getWhiteBox();\n+\n+    public static long pinAndGetAddress(Object o) {\n+        wb.pinObject(o);\n+        return wb.getObjectAddress(o);\n+    }\n+\n+    public static void unpinAndCompareAddress(Object o, long expectedAddress) {\n+        Asserts.assertEQ(expectedAddress, wb.getObjectAddress(o), \"Object has moved during pinning.\");\n+        wb.unpinObject(o);\n+    }\n+\n+    public static void main(String[] args) {\n+\n+        int youngGCBeforeUnpin = Integer.parseInt(args[0]);\n+        \/\/ Remove garbage from VM initialization\n+        wb.fullGC();\n+\n+        Object o = new int[100];\n+        Asserts.assertTrue(!wb.isObjectInOldGen(o), \"should not be pinned in old gen\");\n+\n+        long address = pinAndGetAddress(o);\n+\n+        \/\/ Move pinned object into old gen. That region containing it should be almost completely empty,\n+        \/\/ so it will be picked up as collection set candidate.\n+        wb.fullGC();\n+        Asserts.assertTrue(wb.isObjectInOldGen(o), \"Pinned object not in old gen after young GC\");\n+\n+        \/\/ Do a concurrent cycle to move the region into the marking candidates.\n+        wb.g1RunConcurrentGC();\n+        \/\/ Perform the \"Prepare Mixed\" GC.\n+        wb.youngGC();\n+        \/\/ The object is (still) pinned. Do some configurable young gcs that fail to add it to the\n+        \/\/ collection set candidates.\n+        for (int i = 0; i < youngGCBeforeUnpin; i++) {\n+          wb.youngGC();\n+        }\n+        unpinAndCompareAddress(o, address);\n+\n+        \/\/ Unpinned the object. This next gc should take the region if not dropped.\n+        wb.youngGC();\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/pinnedobjs\/TestPinnedOldObjectsEvacuation.java","additions":148,"deletions":0,"binary":false,"changes":148,"status":"added"},{"patch":"@@ -1,191 +0,0 @@\n-\/*\n- * Copyright (c) 2017, 2023, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2017 SAP SE and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.stress.TestJNIBlockFullGC;\n-\n-\/*\n- * @test TestJNIBlockFullGC\n- * @summary Check that in G1 a Full GC to reclaim space can not be blocked out by the GC locker.\n- * @key randomness\n- * @requires vm.gc.G1\n- * @library \/test\/lib\n- * @run main\/othervm\/native -Xmx64m -XX:+UseG1GC -Xlog:gc=info,gc+alloc=trace -XX:MaxGCPauseMillis=10 gc.stress.TestJNIBlockFullGC.TestJNIBlockFullGC 10 10000 10000 10000 30000 10000 0.7\n- *\/\n-\n-import java.lang.ref.SoftReference;\n-import java.util.Random;\n-import jdk.test.lib.Utils;\n-\n-public class TestJNIBlockFullGC {\n-    private static final Random rng = Utils.getRandomInstance();\n-\n-    static {\n-        System.loadLibrary(\"TestJNIBlockFullGC\");\n-    }\n-\n-    public static volatile Object tmp;\n-\n-    public static volatile boolean hadError = false;\n-\n-    private static native int TestCriticalArray0(int[] x);\n-\n-    public static class Node {\n-        public SoftReference<Node> next;\n-        long payload1;\n-        long payload2;\n-        long payload3;\n-        long payload4;\n-\n-        public Node(int load) {\n-            payload1 = payload2 = payload3 = payload4 = load;\n-        }\n-    }\n-\n-    public static void warmUp(long warmupEndTimeNanos, int size, long seed) {\n-        Random r = new Random(seed);\n-        \/\/ First let the GC assume most of our objects will die.\n-        Node[] roots = new Node[size];\n-\n-        while (System.nanoTime() - warmupEndTimeNanos < 0) {\n-            int index = (int) (r.nextDouble() * roots.length);\n-            roots[index] = new Node(1);\n-        }\n-\n-        \/\/ Make sure the young generation is empty.\n-        for (int i = 0; i < roots.length; ++i) {\n-            roots[i] = null;\n-        }\n-    }\n-\n-    public static void runTest(long endTimeNanos, int size, double alive, long seed) {\n-        Random r = new Random(seed);\n-        final int length = 10000;\n-        int[] array1 = new int[length];\n-        for (int x = 1; x < length; x++) {\n-            array1[x] = x;\n-        }\n-\n-        Node[] roots = new Node[size];\n-        try {\n-            int index = 0;\n-            roots[0] = new Node(0);\n-\n-            while (!hadError && (System.nanoTime() - endTimeNanos < 0)) {\n-                int test_val1 = TestCriticalArray0(array1);\n-\n-                if (r.nextDouble() > alive) {\n-                    tmp = new Node(test_val1);\n-                } else {\n-                    index = (int) (r.nextDouble() * roots.length);\n-\n-                    if (roots[index] != null) {\n-                        Node node = new Node(test_val1);\n-                        node.next = new SoftReference<Node>(roots[index]);\n-                        roots[index] = node;\n-                    } else {\n-                        roots[index] = new Node(test_val1);\n-                    }\n-                }\n-            }\n-        } catch (OutOfMemoryError e) {\n-            hadError = true;\n-            e.printStackTrace();\n-        }\n-    }\n-\n-    private static void joinThreads(Thread[] threads) throws Exception {\n-        for (int i = 0; i < threads.length; i++) {\n-            try {\n-                if (threads[i] != null) {\n-                  threads[i].join();\n-                }\n-            } catch (InterruptedException e) {\n-                e.printStackTrace();\n-                throw e;\n-            }\n-        }\n-    }\n-\n-    public static void main(String[] args) throws Exception {\n-        if (args.length < 7){\n-            System.out.println(\"Usage: java TestJNIBlockFullGC <warmupThreads> <warmup-time-in-millis> <warmup iterations> <threads> <time-in-millis> <iterations> <aliveFrac>\");\n-            System.exit(0);\n-        }\n-\n-        int warmupThreads = Integer.parseInt(args[0]);\n-        System.out.println(\"# Warmup Threads = \" + warmupThreads);\n-\n-        long warmupDurationNanos = 1_000_000L * Integer.parseInt(args[1]);\n-        System.out.println(\"WarmUp Duration Millis = \" + args[1]);\n-        int warmupIterations = Integer.parseInt(args[2]);\n-        System.out.println(\"# Warmup Iterations = \"+ warmupIterations);\n-\n-        int mainThreads = Integer.parseInt(args[3]);\n-        System.out.println(\"# Main Threads = \" + mainThreads);\n-        long mainDurationNanos = 1_000_000L * Integer.parseInt(args[4]);\n-        System.out.println(\"Main Duration Millis = \" + args[4]);\n-        int mainIterations = Integer.parseInt(args[5]);\n-        System.out.println(\"# Main Iterations = \" + mainIterations);\n-\n-        double liveFrac = Double.parseDouble(args[6]);\n-        System.out.println(\"Live Fraction = \" + liveFrac);\n-\n-        Thread threads[] = new Thread[Math.max(warmupThreads, mainThreads)];\n-\n-        System.out.println(\"Start warm-up threads!\");\n-        long warmupStartTimeNanos = System.nanoTime();\n-        for (int i = 0; i < warmupThreads; i++) {\n-            long seed = rng.nextLong();\n-            threads[i] = new Thread() {\n-                public void run() {\n-                    warmUp(warmupStartTimeNanos + warmupDurationNanos, warmupIterations, seed);\n-                };\n-            };\n-            threads[i].start();\n-        }\n-\n-        joinThreads(threads);\n-\n-        System.gc();\n-        System.out.println(\"Keep alive a lot\");\n-\n-        long startTimeNanos = System.nanoTime();\n-        for (int i = 0; i < mainThreads; i++) {\n-            long seed = rng.nextLong();\n-            threads[i] = new Thread() {\n-                public void run() {\n-                    runTest(startTimeNanos + mainDurationNanos, mainIterations, liveFrac, seed);\n-                };\n-            };\n-            threads[i].start();\n-        }\n-        System.out.println(\"All threads started\");\n-\n-        joinThreads(threads);\n-\n-        if (hadError) {\n-            throw new RuntimeException(\"Experienced an OoME during execution.\");\n-        }\n-    }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/TestJNIBlockFullGC\/TestJNIBlockFullGC.java","additions":0,"deletions":191,"binary":false,"changes":191,"status":"deleted"},{"patch":"@@ -1,47 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2017 SAP SE and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"jni.h\"\n-\n-JNIEXPORT jint JNICALL\n-Java_gc_stress_TestJNIBlockFullGC_TestJNIBlockFullGC_TestCriticalArray0(JNIEnv *env, jclass jCls, jintArray jIn) {\n-  jint *bufIn = NULL;\n-  jint jInLen = (*env)->GetArrayLength(env, jIn);\n-  jint result = 0;\n-  jint i;\n-\n-  if (jInLen != 0) {\n-    bufIn = (jint*)(*env)->GetPrimitiveArrayCritical(env, jIn, 0);\n-  }\n-\n-  for (i = 0; i < jInLen; ++i) {\n-    result += bufIn[i]; \/\/ result = sum of all array elements\n-  }\n-\n-  if (bufIn != NULL) {\n-    (*env)->ReleasePrimitiveArrayCritical(env, jIn, bufIn, 0);\n-  }\n-\n-  return result;\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/TestJNIBlockFullGC\/libTestJNIBlockFullGC.c","additions":0,"deletions":47,"binary":false,"changes":47,"status":"deleted"},{"patch":"@@ -34,0 +34,2 @@\n+ * @requires vm.gc != \"G1\"\n+ * @requires vm.gc != null\n@@ -154,1 +156,1 @@\n-        \"-Xmx1G\", \"-Xms1G\", \"-Xmn256M\", \"-Xlog:gc\" };\n+        \"-Xmx1G\", \"-Xms1G\", \"-Xmn256M\", \"-Xlog:gc,gc+ergo*=debug,gc+ergo+cset=trace:x.log\", \"-XX:+UnlockDiagnosticVMOptions\", \"-XX:+VerifyAfterGC\"};\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/gclocker\/TestExcessGCLockerCollections.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,1 +29,2 @@\n- * @requires vm.gc.G1\n+ * @requires vm.gc.Serial | vm.gc.Parallel\n+ * @requires vm.gc != null\n@@ -33,1 +34,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xmx32m -Xms32m -Xmn12m -XX:+UseG1GC jdk.jfr.event.gc.detailed.TestGCLockerEvent\n+ * @run main\/othervm -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xmx32m -Xms32m -Xmn12m jdk.jfr.event.gc.detailed.TestGCLockerEvent\n","filename":"test\/jdk\/jdk\/jfr\/event\/gc\/detailed\/TestGCLockerEvent.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -787,0 +787,4 @@\n+  public native void pinObject(Object o);\n+\n+  public native void unpinObject(Object o);\n+\n","filename":"test\/lib\/jdk\/test\/whitebox\/WhiteBox.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}