{"files":[{"patch":"@@ -32,1 +32,1 @@\n-const jint ShenandoahEvacOOMHandler::OOM_MARKER_MASK = 0x80000000;\n+const jint ShenandoahEvacOOMCounter::OOM_MARKER_MASK = 0x80000000;\n@@ -34,2 +34,2 @@\n-ShenandoahEvacOOMHandler::ShenandoahEvacOOMHandler() :\n-  _threads_in_evac(0) {\n+ShenandoahEvacOOMCounter::ShenandoahEvacOOMCounter()\n+  : _bits(0) {\n@@ -38,3 +38,26 @@\n-void ShenandoahEvacOOMHandler::wait_for_no_evac_threads() {\n-  while ((Atomic::load_acquire(&_threads_in_evac) & ~OOM_MARKER_MASK) != 0) {\n-    os::naked_short_sleep(1);\n+void ShenandoahEvacOOMCounter::decrement() {\n+  assert(unmasked_count() > 0, \"sanity\");\n+  \/\/ NOTE: It's ok to simply decrement, even with mask set, because unmasked value is positive.\n+  Atomic::dec(&_bits);\n+}\n+\n+void ShenandoahEvacOOMCounter::clear() {\n+  assert(unmasked_count() == 0, \"sanity\");\n+  Atomic::release_store_fence(&_bits, (jint)0);\n+}\n+\n+void ShenandoahEvacOOMCounter::set_oom_bit(bool decrement) {\n+  jint threads_in_evac = Atomic::load_acquire(&_bits);\n+  while (true) {\n+    jint newval = decrement\n+      ? (threads_in_evac - 1) | OOM_MARKER_MASK\n+      : threads_in_evac | OOM_MARKER_MASK;\n+\n+    jint other = Atomic::cmpxchg(&_bits, threads_in_evac, newval);\n+    if (other == threads_in_evac) {\n+      \/\/ Success: wait for other threads to get out of the protocol and return.\n+      break;\n+    } else {\n+      \/\/ Failure: try again with updated new value.\n+      threads_in_evac = other;\n+    }\n@@ -42,4 +65,0 @@\n-  \/\/ At this point we are sure that no threads can evacuate anything. Raise\n-  \/\/ the thread-local oom_during_evac flag to indicate that any attempt\n-  \/\/ to evacuate should simply return the forwarding pointer instead (which is safe now).\n-  ShenandoahThreadLocalData::set_oom_during_evac(Thread::current(), true);\n@@ -48,2 +67,3 @@\n-void ShenandoahEvacOOMHandler::register_thread(Thread* thr) {\n-  jint threads_in_evac = Atomic::load_acquire(&_threads_in_evac);\n+bool ShenandoahEvacOOMCounter::try_increment()\n+{\n+  jint threads_in_evac = Atomic::load_acquire(&_bits);\n@@ -51,1 +71,0 @@\n-  assert(!ShenandoahThreadLocalData::is_oom_during_evac(Thread::current()), \"TL oom-during-evac must not be set\");\n@@ -53,2 +72,1 @@\n-    \/\/ Check for OOM.\n-    \/\/ If offender has OOM_MARKER_MASK, then loop until no more threads in evac\n+    \/\/ Cannot enter evacuation if OOM_MARKER_MASK is set.\n@@ -56,2 +74,1 @@\n-      wait_for_no_evac_threads();\n-      return;\n+      return false;\n@@ -60,1 +77,1 @@\n-    jint other = Atomic::cmpxchg(&_threads_in_evac, threads_in_evac, threads_in_evac + 1);\n+    jint other = Atomic::cmpxchg(&_bits, threads_in_evac, threads_in_evac + 1);\n@@ -63,1 +80,1 @@\n-      return;\n+      return true;\n@@ -70,0 +87,67 @@\n+ShenandoahEvacOOMHandler::ShenandoahEvacOOMHandler()\n+  : _num_counters(calc_num_counters()) {\n+\n+  assert(_num_counters > 0, \"sanity\");\n+  _threads_in_evac = NEW_C_HEAP_ARRAY(ShenandoahEvacOOMCounter, _num_counters, mtGC);\n+  for (int i = 0; i < _num_counters; i++) {\n+    new (&_threads_in_evac[i]) ShenandoahEvacOOMCounter;\n+  }\n+}\n+\n+int ShenandoahEvacOOMHandler::calc_num_counters() {\n+  \/\/ Scale the number of counter buckets with the number of CPUs to\n+  \/\/ minimise contention.  Also make sure the number is a power of two\n+  \/\/ so we can map hash values to buckets with a simple mask.\n+  const int nproc = os::active_processor_count();\n+  const int clamped = MAX2(1, MIN2(nproc, 128));\n+  return round_up_power_of_2(clamped);\n+}\n+\n+uint64_t ShenandoahEvacOOMHandler::hash_pointer(const void* p) {\n+  \/\/ Bit mixing function from MurmurHash3\n+  uint64_t key = (uintptr_t)p;\n+  key ^= (key >> 33);\n+  key *= UINT64_C(0xff51afd7ed558ccd);\n+  key ^= (key >> 33);\n+  key *= UINT64_C(0xc4ceb9fe1a85ec53);\n+  key ^= (key >> 33);\n+  return key;\n+}\n+\n+ShenandoahEvacOOMCounter* ShenandoahEvacOOMHandler::counter_for_thread(Thread* t) {\n+  const uint64_t key = hash_pointer(t);\n+  assert(is_power_of_2(_num_counters), \"must be\");\n+  return &_threads_in_evac[key & (_num_counters - 1)];\n+}\n+\n+void ShenandoahEvacOOMHandler::wait_for_one_counter(ShenandoahEvacOOMCounter* ptr) {\n+  \/\/ We might be racing against handle_out_of_memory_during_evacuation()\n+  \/\/ setting the OOM_MARKER_MASK bit so we must make sure it is set here\n+  \/\/ *and* the counter is zero.\n+  while (ptr->load_acquire() != ShenandoahEvacOOMCounter::OOM_MARKER_MASK) {\n+    os::naked_short_sleep(1);\n+  }\n+}\n+\n+void ShenandoahEvacOOMHandler::wait_for_no_evac_threads() {\n+  \/\/ Once the OOM_MARKER_MASK bit is set the counter can only decrease\n+  \/\/ so it's safe to check each bucket in turn.\n+  for (int i = 0; i < _num_counters; i++) {\n+    wait_for_one_counter(&_threads_in_evac[i]);\n+  }\n+  \/\/ At this point we are sure that no threads can evacuate anything. Raise\n+  \/\/ the thread-local oom_during_evac flag to indicate that any attempt\n+  \/\/ to evacuate should simply return the forwarding pointer instead (which is safe now).\n+  ShenandoahThreadLocalData::set_oom_during_evac(Thread::current(), true);\n+}\n+\n+void ShenandoahEvacOOMHandler::register_thread(Thread* thr) {\n+  assert(!ShenandoahThreadLocalData::is_oom_during_evac(Thread::current()), \"TL oom-during-evac must not be set\");\n+\n+  ShenandoahEvacOOMCounter* counter = counter_for_thread(thr);\n+  if (!counter->try_increment()) {\n+    \/\/ Counter has OOM_MARKER_MASK set, loop until no more threads in evac\n+    wait_for_no_evac_threads();\n+  }\n+}\n+\n@@ -72,3 +156,1 @@\n-    assert((Atomic::load_acquire(&_threads_in_evac) & ~OOM_MARKER_MASK) > 0, \"sanity\");\n-    \/\/ NOTE: It's ok to simply decrement, even with mask set, because unmasked value is positive.\n-    Atomic::dec(&_threads_in_evac);\n+    counter_for_thread(thr)->decrement();\n@@ -88,11 +170,6 @@\n-  jint threads_in_evac = Atomic::load_acquire(&_threads_in_evac);\n-  while (true) {\n-    jint other = Atomic::cmpxchg(&_threads_in_evac, threads_in_evac, (threads_in_evac - 1) | OOM_MARKER_MASK);\n-    if (other == threads_in_evac) {\n-      \/\/ Success: wait for other threads to get out of the protocol and return.\n-      wait_for_no_evac_threads();\n-      return;\n-    } else {\n-      \/\/ Failure: try again with updated new value.\n-      threads_in_evac = other;\n-    }\n+  ShenandoahEvacOOMCounter* self = counter_for_thread(Thread::current());\n+  assert(self->unmasked_count() > 0, \"sanity\");\n+\n+  for (int i = 0; i < _num_counters; i++) {\n+    ShenandoahEvacOOMCounter* counter = &_threads_in_evac[i];\n+    counter->set_oom_bit(counter == self);\n@@ -100,0 +177,2 @@\n+\n+  wait_for_no_evac_threads();\n@@ -104,2 +183,3 @@\n-  assert((Atomic::load_acquire(&_threads_in_evac) & ~OOM_MARKER_MASK) == 0, \"sanity\");\n-  Atomic::release_store_fence(&_threads_in_evac, (jint)0);\n+  for (int i = 0; i < _num_counters; i++) {\n+    _threads_in_evac[i].clear();\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahEvacOOMHandler.cpp","additions":115,"deletions":35,"binary":false,"changes":150,"status":"modified"},{"patch":"@@ -33,0 +33,25 @@\n+\/**\n+ * Striped counter used to implement the OOM protocol described below.\n+ *\/\n+class ShenandoahEvacOOMCounter {\n+private:\n+  \/\/ Combination of a 31-bit counter and 1-bit OOM marker.\n+  volatile jint _bits;\n+\n+  \/\/ This class must be at least a cache line in size to prevent false sharing.\n+  shenandoah_padding_minus_size(0, sizeof(jint));\n+\n+public:\n+  static const jint OOM_MARKER_MASK;\n+\n+  ShenandoahEvacOOMCounter();\n+\n+  void decrement();\n+  bool try_increment();\n+  void clear();\n+  void set_oom_bit(bool decrement);\n+\n+  inline jint unmasked_count();\n+  inline jint load_acquire();\n+};\n+\n@@ -60,1 +85,3 @@\n- * for current threads to leave, and blocks other threads from entering.\n+ * for current threads to leave, and blocks other threads from entering. The counter state\n+ * is striped across multiple cache lines to reduce contention when many threads attempt\n+ * to enter or leave the protocol at the same time.\n@@ -84,1 +111,1 @@\n-  static const jint OOM_MARKER_MASK;\n+  const int _num_counters;\n@@ -87,2 +114,3 @@\n-  volatile jint _threads_in_evac;\n-  shenandoah_padding(1);\n+  ShenandoahEvacOOMCounter* _threads_in_evac;\n+\n+  ShenandoahEvacOOMCounter* counter_for_thread(Thread* t);\n@@ -91,0 +119,1 @@\n+  void wait_for_one_counter(ShenandoahEvacOOMCounter* ptr);\n@@ -92,0 +121,2 @@\n+  static uint64_t hash_pointer(const void* p);\n+  static int calc_num_counters();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahEvacOOMHandler.hpp","additions":35,"deletions":4,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -34,2 +34,3 @@\n-void ShenandoahEvacOOMHandler::enter_evacuation(Thread* thr) {\n-  jint threads_in_evac = Atomic::load_acquire(&_threads_in_evac);\n+jint ShenandoahEvacOOMCounter::load_acquire() {\n+  return Atomic::load_acquire(&_bits);\n+}\n@@ -37,0 +38,5 @@\n+jint ShenandoahEvacOOMCounter::unmasked_count() {\n+  return Atomic::load_acquire(&_bits) & ~OOM_MARKER_MASK;\n+}\n+\n+void ShenandoahEvacOOMHandler::enter_evacuation(Thread* thr) {\n@@ -42,1 +48,2 @@\n-   jint threads_in_evac = Atomic::load_acquire(&_threads_in_evac);\n+   ShenandoahEvacOOMCounter* counter = counter_for_thread(thr);\n+   jint threads_in_evac = counter->load_acquire();\n@@ -44,3 +51,2 @@\n-   if ((threads_in_evac & OOM_MARKER_MASK) != 0) {\n-     assert((threads_in_evac & ~OOM_MARKER_MASK) > 0, \"sanity\");\n-     Atomic::dec(&_threads_in_evac);\n+   if ((threads_in_evac & ShenandoahEvacOOMCounter::OOM_MARKER_MASK) != 0) {\n+     counter->decrement();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahEvacOOMHandler.inline.hpp","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -40,0 +40,3 @@\n+#define shenandoah_padding_minus_size(id, size) \\\n+  DEFINE_PAD_MINUS_SIZE(id, SHENANDOAH_CACHE_LINE_SIZE, size)\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPadding.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"}]}