{"files":[{"patch":"@@ -30,0 +30,1 @@\n+#include \"jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdLoadBarrier.inline.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"jfr\/recorder\/storage\/jfrBuffer.hpp\"\n@@ -326,0 +328,1 @@\n+  const size_t _min_valid_free_size_bytes; \/\/ for enqueue buffer monitoring\n@@ -330,0 +333,3 @@\n+  const JfrBuffer* get_enqueue_buffer();\n+  const JfrBuffer* renew_if_full(const JfrBuffer* enqueue_buffer);\n+\n@@ -399,0 +405,1 @@\n+  _min_valid_free_size_bytes(JfrOptionSet::stackdepth() * sizeof(intptr_t)),\n@@ -523,0 +530,9 @@\n+const JfrBuffer* JfrThreadSampler::get_enqueue_buffer() {\n+  const JfrBuffer* buffer = JfrTraceIdLoadBarrier::get_enqueue_buffer(this);\n+  return buffer != nullptr ? buffer : JfrTraceIdLoadBarrier::renew_enqueue_buffer(this);\n+}\n+\n+const JfrBuffer* JfrThreadSampler::renew_if_full(const JfrBuffer* enqueue_buffer) {\n+  assert(enqueue_buffer != nullptr, \"invariant\");\n+  return enqueue_buffer->free_size() < _min_valid_free_size_bytes ? JfrTraceIdLoadBarrier::renew_enqueue_buffer(this) : enqueue_buffer;\n+}\n@@ -545,0 +561,8 @@\n+      \/\/ Explicitly monitor the available space of the thread-local buffer used for enqueuing klasses as part of tagging methods.\n+      \/\/ We do this because if space becomes sparse, we cannot rely on the implicit allocation of a new buffer as part of the\n+      \/\/ regular tag mechanism. If the free list is empty, a malloc could result, and the problem with that is that the thread\n+      \/\/ we have suspended could be the holder of the malloc lock. Instead, the buffer is pre-emptively renewed before thread suspension.\n+      const JfrBuffer* enqueue_buffer = get_enqueue_buffer();\n+      assert(enqueue_buffer != nullptr, \"invariant\");\n+      enqueue_buffer = renew_if_full(enqueue_buffer);\n+\n@@ -556,0 +580,1 @@\n+        assert(enqueue_buffer->free_size() >= _min_valid_free_size_bytes, \"invariant\");\n@@ -559,0 +584,1 @@\n+        enqueue_buffer = renew_if_full(enqueue_buffer);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampler.cpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+class JfrBuffer;\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampler.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -250,0 +250,8 @@\n+JfrBuffer* JfrTraceIdKlassQueue::get_enqueue_buffer(Thread* thread) {\n+  return _queue->thread_local_storage(thread);\n+}\n+\n+JfrBuffer* JfrTraceIdKlassQueue::renew_enqueue_buffer(Thread* thread) {\n+  return _queue->renew_enqueue_buffer(thread);\n+}\n+\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdKlassQueue.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+class JfrBuffer;\n@@ -50,1 +51,1 @@\n-class JfrEpochQueueKlassPolicy {\n+class JfrEpochQueueKlassPolicy : public JfrCHeapObj {\n@@ -67,0 +68,1 @@\n+  friend class JfrTraceIdLoadBarrier;\n@@ -69,0 +71,2 @@\n+  JfrBuffer* get_enqueue_buffer(Thread* thread);\n+  JfrBuffer* renew_enqueue_buffer(Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdKlassQueue.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -71,0 +71,8 @@\n+\n+JfrBuffer* JfrTraceIdLoadBarrier::get_enqueue_buffer(Thread* thread) {\n+  return klass_queue().get_enqueue_buffer(thread);\n+}\n+\n+JfrBuffer* JfrTraceIdLoadBarrier::renew_enqueue_buffer(Thread* thread) {\n+  return klass_queue().renew_enqueue_buffer(thread);\n+}\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdLoadBarrier.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+class JfrBuffer;\n@@ -72,0 +73,2 @@\n+  friend class JfrStackTrace;\n+  friend class JfrThreadSampler;\n@@ -78,0 +81,2 @@\n+  static JfrBuffer* get_enqueue_buffer(Thread* thread);\n+  static JfrBuffer* renew_enqueue_buffer(Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdLoadBarrier.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"jfr\/recorder\/storage\/jfrBuffer.hpp\"\n@@ -178,0 +179,6 @@\n+static const size_t min_valid_free_size_bytes = 16;\n+\n+static inline bool is_full(const JfrBuffer* enqueue_buffer) {\n+  return enqueue_buffer->free_size() < min_valid_free_size_bytes;\n+}\n+\n@@ -179,0 +186,6 @@\n+  \/\/ Explicitly monitor the available space of the thread-local buffer used for enqueuing klasses as part of tagging methods.\n+  \/\/ We do this because if space becomes sparse, we cannot rely on the implicit allocation of a new buffer as part of the\n+  \/\/ regular tag mechanism. If the free list is empty, a malloc could result, and the problem with that is that the thread\n+  \/\/ we have suspended could be the holder of the malloc lock. If there is no more available space, the attempt is aborted.\n+  const JfrBuffer* const enqueue_buffer = JfrTraceIdLoadBarrier::get_enqueue_buffer(Thread::current());\n+  assert(enqueue_buffer != nullptr, \"invariant\");\n@@ -182,1 +195,0 @@\n-\n@@ -190,1 +202,1 @@\n-    if (!Method::is_valid_method(method)) {\n+    if (!Method::is_valid_method(method) || is_full(enqueue_buffer)) {\n","filename":"src\/hotspot\/share\/jfr\/recorder\/stacktrace\/jfrStackTrace.cpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+class Thread;\n+\n@@ -46,1 +48,1 @@\n-class JfrEpochQueue : public JfrCHeapObj {\n+class JfrEpochQueue : public ElementPolicy<typename JfrEpochStorage::Buffer> {\n@@ -56,0 +58,1 @@\n+  BufferPtr renew_enqueue_buffer(Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/utilities\/jfrEpochQueue.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-\n@@ -49,0 +48,16 @@\n+template <template <typename> class ElementPolicy>\n+inline typename JfrEpochQueue<ElementPolicy>::BufferPtr\n+JfrEpochQueue<ElementPolicy>::renew_enqueue_buffer(Thread* thread) {\n+  assert(thread != nullptr, \"invariant\");\n+  BufferPtr buffer = _policy.thread_local_storage(thread);\n+  if (buffer == nullptr) {\n+    buffer = _storage->acquire(0, thread);\n+    _policy.set_thread_local_storage(buffer, thread);\n+    return buffer;\n+  }\n+  _storage->release(buffer);\n+  buffer = _storage->acquire(0, thread);\n+  _policy.set_thread_local_storage(buffer, thread);\n+  return buffer;\n+}\n+\n@@ -55,1 +70,1 @@\n-  if (buffer == NULL) {\n+  if (buffer == nullptr) {\n@@ -70,1 +85,1 @@\n-  assert(t != NULL, \"invariant\");\n+  assert(t != nullptr, \"invariant\");\n@@ -73,1 +88,1 @@\n-  assert(buffer != NULL, \"invariant\");\n+  assert(buffer != nullptr, \"invariant\");\n@@ -86,1 +101,1 @@\n-  assert(element != NULL, \"invariant\");\n+  assert(element != nullptr, \"invariant\");\n","filename":"src\/hotspot\/share\/jfr\/utilities\/jfrEpochQueue.inline.hpp","additions":20,"deletions":5,"binary":false,"changes":25,"status":"modified"}]}