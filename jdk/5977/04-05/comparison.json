{"files":[{"patch":"@@ -328,1 +328,2 @@\n-  const size_t _min_valid_free_size_bytes; \/\/ for enqueue buffer monitoring\n+  const size_t _min_size; \/\/ for enqueue buffer monitoring\n+  const size_t _renew_size;\n@@ -405,1 +406,2 @@\n-  _min_valid_free_size_bytes(JfrOptionSet::stackdepth() * sizeof(intptr_t)),\n+  _min_size(JfrOptionSet::stackdepth() * sizeof(intptr_t)),\n+  _renew_size(_min_size * 2),\n@@ -532,1 +534,1 @@\n-  return buffer != nullptr ? renew_if_full(buffer) : JfrTraceIdLoadBarrier::renew_enqueue_buffer(this);\n+  return buffer != nullptr ? renew_if_full(buffer) : JfrTraceIdLoadBarrier::renew_enqueue_buffer(_renew_size, this);\n@@ -537,1 +539,1 @@\n-  return enqueue_buffer->free_size() < _min_valid_free_size_bytes ? JfrTraceIdLoadBarrier::renew_enqueue_buffer(this) : enqueue_buffer;\n+  return enqueue_buffer->free_size() < _min_size ? JfrTraceIdLoadBarrier::renew_enqueue_buffer(_renew_size, this) : enqueue_buffer;\n@@ -560,4 +562,6 @@\n-      \/\/ Explicitly monitor the available space of the thread-local buffer used for enqueuing klasses as part of tagging methods.\n-      \/\/ We do this because if space becomes sparse, we cannot rely on the implicit allocation of a new buffer as part of the\n-      \/\/ regular tag mechanism. If the free list is empty, a malloc could result, and the problem with that is that the thread\n-      \/\/ we have suspended could be the holder of the malloc lock. Instead, the buffer is pre-emptively renewed before thread suspension.\n+      \/\/ Explicitly monitor the available space of the thread-local buffer used by the load barrier\n+      \/\/ for enqueuing klasses as part of tagging methods. We do this because if space becomes sparse,\n+      \/\/ we cannot rely on the implicit allocation of a new buffer as part of the regular tag mechanism.\n+      \/\/ If the free list is empty, a malloc could result, and the problem with that is that the thread\n+      \/\/ we have suspended could be the holder of the malloc lock. Instead, the buffer is pre-emptively\n+      \/\/ renewed before thread suspension.\n@@ -578,1 +582,1 @@\n-        assert(enqueue_buffer->free_size() >= _min_valid_free_size_bytes, \"invariant\");\n+        assert(enqueue_buffer->free_size() >= _min_size, \"invariant\");\n","filename":"src\/hotspot\/share\/jfr\/periodic\/sampling\/jfrThreadSampler.cpp","additions":13,"deletions":9,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -254,2 +254,2 @@\n-JfrBuffer* JfrTraceIdKlassQueue::renew_enqueue_buffer(Thread* thread) {\n-  return _queue->renew(thread);\n+JfrBuffer* JfrTraceIdKlassQueue::renew_enqueue_buffer(size_t size, Thread* thread) {\n+  return _queue->renew(size, thread);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdKlassQueue.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -72,1 +72,1 @@\n-  JfrBuffer* renew_enqueue_buffer(Thread* thread);\n+  JfrBuffer* renew_enqueue_buffer(size_t size, Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdKlassQueue.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -76,2 +76,2 @@\n-JfrBuffer* JfrTraceIdLoadBarrier::renew_enqueue_buffer(Thread* thread) {\n-  return klass_queue().renew_enqueue_buffer(thread);\n+JfrBuffer* JfrTraceIdLoadBarrier::renew_enqueue_buffer(size_t size, Thread* thread) {\n+  return klass_queue().renew_enqueue_buffer(size, thread);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdLoadBarrier.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -82,1 +82,1 @@\n-  static JfrBuffer* renew_enqueue_buffer(Thread* thread);\n+  static JfrBuffer* renew_enqueue_buffer(size_t size, Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/recorder\/checkpoint\/types\/traceid\/jfrTraceIdLoadBarrier.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,1 +58,1 @@\n-  BufferPtr renew(Thread* thread);\n+  BufferPtr renew(size_t size, Thread* thread);\n","filename":"src\/hotspot\/share\/jfr\/utilities\/jfrEpochQueue.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-JfrEpochQueue<ElementPolicy>::renew(Thread* thread) {\n+JfrEpochQueue<ElementPolicy>::renew(size_t size, Thread* thread) {\n@@ -56,1 +56,3 @@\n-  buffer = _storage->acquire(0, thread);\n+  buffer = _storage->acquire(size, thread);\n+  assert(buffer != nullptr, \"invariant\");\n+  assert(buffer->free_size() >= size, \"invariant\");\n","filename":"src\/hotspot\/share\/jfr\/utilities\/jfrEpochQueue.inline.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"}]}