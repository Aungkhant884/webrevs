{"files":[{"patch":"@@ -2325,0 +2325,34 @@\n+  \/\/ Single-structure load\/store method (all addressing variants)\n+  void ld_st(FloatRegister Vt, SIMD_RegVariant T, int index, Address a,\n+             int op1, int op2, int regs) {\n+    int expectedImmediate = (regVariant_to_elemBits(T) >> 3) * regs;\n+    int sVal = (T < D) ? (index >> (2 - T)) & 0x01 : 0;\n+    int opcode = (T < D) ? (T << 2) : ((T & 0x02) << 2);\n+    int size = (T < D) ? (index & (0x3 << T)) : 1;  \/\/ only care about low 2b\n+    Register Xn = a.base();\n+    int Rm;\n+\n+    switch (a.getMode()) {\n+    case Address::base_plus_offset:\n+      guarantee(a.offset() == 0, \"no offset allowed here\");\n+      Rm = 0;\n+      break;\n+    case Address::post:\n+      guarantee(a.offset() == expectedImmediate, \"bad offset\");\n+      op1 |= 0b100;\n+      Rm = 0b11111;\n+      break;\n+    case Address::post_reg:\n+      op1 |= 0b100;\n+      Rm = a.index()->encoding();\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n+    starti;\n+    f(0,31), f((index >> (3 - T)), 30);\n+    f(op1, 29, 21), f(Rm, 20, 16), f(op2 | opcode | sVal, 15, 12);\n+    f(size, 11, 10), srf(Xn, 5), rf(Vt, 0);\n+  }\n+\n@@ -2382,0 +2416,60 @@\n+\/\/ Handle common single-structure ld\/st parameter sanity checks\n+\/\/ for all variations (1 to 4) of SIMD reigster inputs.  This\n+\/\/ method will call the routine that generates the opcode.\n+template<typename R, typename... Rx>\n+  void ldst_sstr(SIMD_RegVariant T, int index, const Address &a,\n+            int op1, int op2, R firstReg, Rx... otherRegs) {\n+    const FloatRegister vtSet[] = { firstReg, otherRegs... };\n+    const int regCount = sizeof...(otherRegs) + 1;\n+    assert(index >= 0 && (T <= D) && ((T == B && index <= 15) ||\n+              (T == H && index <= 7) || (T == S && index <= 3) ||\n+              (T == D && index <= 1)), \"invalid index\");\n+    assert(regCount >= 1 && regCount <= 4, \"illegal register count\");\n+\n+    \/\/ Check to make sure when multiple SIMD registers are used\n+    \/\/ that they are in successive order.\n+    for (int i = 0; i < regCount - 1; i++) {\n+      assert(vtSet[i]->successor() == vtSet[i + 1],\n+             \"Registers must be ordered\");\n+    }\n+\n+    ld_st(firstReg, T, index, a, op1, op2, regCount);\n+  }\n+\n+\/\/ Define a set of INSN1\/2\/3\/4 macros to handle single-structure\n+\/\/ load\/store instructions.\n+#define INSN1(NAME, op1, op2)                                           \\\n+  void NAME(FloatRegister Vt, SIMD_RegVariant T, int index,             \\\n+            const Address &a) {                                         \\\n+    ldst_sstr(T, index, a, op1, op2, Vt);                               \\\n+ }\n+\n+#define INSN2(NAME, op1, op2)                                           \\\n+  void NAME(FloatRegister Vt, FloatRegister Vt2, SIMD_RegVariant T,     \\\n+            int index, const Address &a) {                              \\\n+    ldst_sstr(T, index, a, op1, op2, Vt, Vt2);                          \\\n+  }\n+\n+#define INSN3(NAME, op1, op2)                                           \\\n+  void NAME(FloatRegister Vt, FloatRegister Vt2, FloatRegister Vt3,     \\\n+            SIMD_RegVariant T, int index, const Address &a) {           \\\n+    ldst_sstr(T, index, a, op1, op2, Vt, Vt2, Vt3);                     \\\n+  }\n+\n+#define INSN4(NAME, op1, op2)                                           \\\n+  void NAME(FloatRegister Vt, FloatRegister Vt2, FloatRegister Vt3,     \\\n+            FloatRegister Vt4, SIMD_RegVariant T, int index,            \\\n+            const Address &a) {                                         \\\n+    ldst_sstr(T, index, a, op1, op2, Vt, Vt2, Vt3, Vt4);                \\\n+  }\n+\n+  INSN1(st1, 0b001101000, 0b0000);\n+  INSN2(st2, 0b001101001, 0b0000);\n+  INSN3(st3, 0b001101000, 0b0010);\n+  INSN4(st4, 0b001101001, 0b0010);\n+\n+#undef INSN1\n+#undef INSN2\n+#undef INSN3\n+#undef INSN4\n+\n@@ -2752,0 +2846,1 @@\n+  INSN(sli,  1, 0b010101, \/* isSHR = *\/ false);\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":95,"deletions":0,"binary":false,"changes":95,"status":"modified"},{"patch":"@@ -1453,0 +1453,7 @@\n+  \/\/ ChaCha20 functions support block\n+  void cc20_quarter_round(FloatRegister aVec, FloatRegister bVec,\n+          FloatRegister cVec, FloatRegister dVec, FloatRegister scratch,\n+          FloatRegister tbl);\n+  void cc20_shift_lane_org(FloatRegister bVec, FloatRegister cVec,\n+          FloatRegister dVec, bool colToDiag);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -0,0 +1,90 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"asm\/assembler.hpp\"\n+#include \"asm\/assembler.inline.hpp\"\n+#include \"macroAssembler_aarch64.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n+\n+\/**\n+ * Perform the quarter round calculations on values contained within\n+ * four SIMD registers.\n+ *\n+ * @param aVec the SIMD register containing only the \"a\" values\n+ * @param bVec the SIMD register containing only the \"b\" values\n+ * @param cVec the SIMD register containing only the \"c\" values\n+ * @param dVec the SIMD register containing only the \"d\" values\n+ * @param scratch scratch SIMD register used for 12 and 7 bit left rotations\n+ * @param table the SIMD register used as a table for 8 bit left rotations\n+ *\/\n+void MacroAssembler::cc20_quarter_round(FloatRegister aVec, FloatRegister bVec,\n+    FloatRegister cVec, FloatRegister dVec, FloatRegister scratch,\n+     FloatRegister table) {\n+\n+  \/\/ a += b, d ^= a, d <<<= 16\n+  addv(aVec, T4S, aVec, bVec);\n+  eor(dVec, T16B, dVec, aVec);\n+  rev32(dVec, T8H, dVec);\n+\n+  \/\/ c += d, b ^= c, b <<<= 12\n+  addv(cVec, T4S, cVec, dVec);\n+  eor(scratch, T16B, bVec, cVec);\n+  ushr(bVec, T4S, scratch, 20);\n+  sli(bVec, T4S, scratch, 12);\n+\n+  \/\/ a += b, d ^= a, d <<<= 8\n+  addv(aVec, T4S, aVec, bVec);\n+  eor(dVec, T16B, dVec, aVec);\n+  tbl(dVec, T16B, dVec,  1, table);\n+\n+  \/\/ c += d, b ^= c, b <<<= 7\n+  addv(cVec, T4S, cVec, dVec);\n+  eor(scratch, T16B, bVec, cVec);\n+  ushr(bVec, T4S, scratch, 25);\n+  sli(bVec, T4S, scratch, 7);\n+}\n+\n+\/**\n+ * Shift the b, c, and d vectors between columnar and diagonal representations.\n+ * Note that the \"a\" vector does not shift.\n+ *\n+ * @param bVec the SIMD register containing only the \"b\" values\n+ * @param cVec the SIMD register containing only the \"c\" values\n+ * @param dVec the SIMD register containing only the \"d\" values\n+ * @param colToDiag true if moving columnar to diagonal, false if\n+ *                  moving diagonal back to columnar.\n+ *\/\n+void MacroAssembler::cc20_shift_lane_org(FloatRegister bVec, FloatRegister cVec,\n+    FloatRegister dVec, bool colToDiag) {\n+  int bShift = colToDiag ? 4 : 12;\n+  int cShift = 8;\n+  int dShift = colToDiag ? 12 : 4;\n+\n+  ext(bVec, T16B, bVec, bVec, bShift);\n+  ext(cVec, T16B, cVec, cVec, cShift);\n+  ext(dVec, T16B, dVec, dVec, dShift);\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64_chacha.cpp","additions":90,"deletions":0,"binary":false,"changes":90,"status":"added"},{"patch":"@@ -4084,0 +4084,126 @@\n+  \/\/ ChaCha20 block function.  This version parallelizes by loading\n+  \/\/ individual 32-bit state elements into vectors for four blocks\n+  \/\/ (e.g. all four blocks' worth of state[0] in one register, etc.)\n+  \/\/\n+  \/\/ state (int[16]) = c_rarg0\n+  \/\/ keystream (byte[1024]) = c_rarg1\n+  \/\/ return - number of bytes of keystream (always 256)\n+  address generate_chacha20Block_blockpar() {\n+    Label L_twoRounds, L_cc20_const;\n+    \/\/ The constant data is broken into two 128-bit segments to be loaded\n+    \/\/ onto FloatRegisters.  The first 128 bits are a counter add overlay\n+    \/\/ that adds +0\/+1\/+2\/+3 to the vector holding replicated state[12].\n+    \/\/ The second 128-bits is a table constant used for 8-bit left rotations.\n+    __ BIND(L_cc20_const);\n+    __ emit_int64(0x0000000100000000UL);\n+    __ emit_int64(0x0000000300000002UL);\n+    __ emit_int64(0x0605040702010003UL);\n+    __ emit_int64(0x0E0D0C0F0A09080BUL);\n+\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"chacha20Block\");\n+    address start = __ pc();\n+    __ enter();\n+\n+    int i, j;\n+    const Register state = c_rarg0;\n+    const Register keystream = c_rarg1;\n+    const Register loopCtr = r10;\n+    const Register tmpAddr = r11;\n+\n+    const FloatRegister stateFirst = v0;\n+    const FloatRegister stateSecond = v1;\n+    const FloatRegister stateThird = v2;\n+    const FloatRegister stateFourth = v3;\n+    const FloatRegister origCtrState = v28;\n+    const FloatRegister scratch = v29;\n+    const FloatRegister lrot8Tbl = v30;\n+\n+    \/\/ Organize SIMD registers in an array that facilitates\n+    \/\/ putting repetitive opcodes into loop structures.  It is\n+    \/\/ important that each grouping of 4 registers is monotonically\n+    \/\/ increasing to support the requirements of multi-register\n+    \/\/ instructions (e.g. ld4r, st4, etc.)\n+    const FloatRegister workSt[16] = {\n+         v4,  v5,  v6,  v7, v16, v17, v18, v19,\n+        v20, v21, v22, v23, v24, v25, v26, v27\n+    };\n+\n+    \/\/ Load from memory and interlace across 16 SIMD registers,\n+    \/\/ With each word from memory being broadcast to all lanes of\n+    \/\/ each successive SIMD register.\n+    \/\/      Addr(0) -> All lanes in workSt[i]\n+    \/\/      Addr(4) -> All lanes workSt[i + 1], etc.\n+    __ mov(tmpAddr, state);\n+    for (i = 0; i < 16; i += 4) {\n+      __ ld4r(workSt[i], workSt[i + 1], workSt[i + 2], workSt[i + 3], __ T4S,\n+          __ post(tmpAddr, 16));\n+    }\n+\n+    \/\/ Pull in constant data.  The first 16 bytes are the add overlay\n+    \/\/ which is applied to the vector holding the counter (state[12]).\n+    \/\/ The second 16 bytes is the index register for the 8-bit left\n+    \/\/ rotation tbl instruction.\n+    __ adr(tmpAddr, L_cc20_const);\n+    __ ldpq(origCtrState, lrot8Tbl, Address(tmpAddr));\n+    __ addv(workSt[12], __ T4S, workSt[12], origCtrState);\n+\n+    \/\/ Set up the 10 iteration loop and perform all 8 quarter round ops\n+    __ mov(loopCtr, 10);\n+    __ BIND(L_twoRounds);\n+\n+    __ cc20_quarter_round(workSt[0], workSt[4], workSt[8], workSt[12],\n+        scratch, lrot8Tbl);\n+    __ cc20_quarter_round(workSt[1], workSt[5], workSt[9], workSt[13],\n+        scratch, lrot8Tbl);\n+    __ cc20_quarter_round(workSt[2], workSt[6], workSt[10], workSt[14],\n+        scratch, lrot8Tbl);\n+    __ cc20_quarter_round(workSt[3], workSt[7], workSt[11], workSt[15],\n+        scratch, lrot8Tbl);\n+\n+    __ cc20_quarter_round(workSt[0], workSt[5], workSt[10], workSt[15],\n+        scratch, lrot8Tbl);\n+    __ cc20_quarter_round(workSt[1], workSt[6], workSt[11], workSt[12],\n+        scratch, lrot8Tbl);\n+    __ cc20_quarter_round(workSt[2], workSt[7], workSt[8], workSt[13],\n+        scratch, lrot8Tbl);\n+    __ cc20_quarter_round(workSt[3], workSt[4], workSt[9], workSt[14],\n+        scratch, lrot8Tbl);\n+\n+    \/\/ Decrement and iterate\n+    __ sub(loopCtr, loopCtr, 1);\n+    __ cbnz(loopCtr, L_twoRounds);\n+\n+    __ mov(tmpAddr, state);\n+\n+    \/\/ Add the starting state back to the post-loop keystream\n+    \/\/ state.  We read\/interlace the state array from memory into\n+    \/\/ 4 registers similar to what we did in the beginning.  Then\n+    \/\/ add the counter overlay onto workSt[12] at the end.\n+    for (i = 0; i < 16; i += 4) {\n+      __ ld4r(stateFirst, stateSecond, stateThird, stateFourth, __ T4S,\n+          __ post(tmpAddr, 16));\n+      __ addv(workSt[i], __ T4S, workSt[i], stateFirst);\n+      __ addv(workSt[i + 1], __ T4S, workSt[i + 1], stateSecond);\n+      __ addv(workSt[i + 2], __ T4S, workSt[i + 2], stateThird);\n+      __ addv(workSt[i + 3], __ T4S, workSt[i + 3], stateFourth);\n+    }\n+    __ addv(workSt[12], __ T4S, workSt[12], origCtrState);    \/\/ Add ctr mask\n+\n+    \/\/ Write to key stream, storing the same element out of workSt[0..15]\n+    \/\/ to consecutive 4-byte offsets in the key stream buffer, then repeating\n+    \/\/ for the next element position.\n+    for (i = 0; i < 4; i++) {\n+      for (j = 0; j < 16; j += 4) {\n+        __ st4(workSt[j], workSt[j + 1], workSt[j + 2], workSt[j + 3], __ S, i,\n+            __ post(keystream, 16));\n+      }\n+    }\n+\n+    __ mov(r0, 256);             \/\/ Return length of output keystream\n+    __ leave();\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n@@ -7922,0 +8048,4 @@\n+    if (UseChaCha20Intrinsics) {\n+      StubRoutines::_chacha20Block = generate_chacha20Block_blockpar();\n+    }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":130,"deletions":0,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -370,0 +370,11 @@\n+  if (_features & CPU_ASIMD) {\n+      if (FLAG_IS_DEFAULT(UseChaCha20Intrinsics)) {\n+          UseChaCha20Intrinsics = true;\n+      }\n+  } else if (UseChaCha20Intrinsics) {\n+      if (!FLAG_IS_DEFAULT(UseChaCha20Intrinsics)) {\n+          warning(\"ChaCha20 intrinsic requires ASIMD instructions\");\n+      }\n+      FLAG_SET_DEFAULT(UseChaCha20Intrinsics, false);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -5272,0 +5272,10 @@\n+void Assembler::vpshufhw(XMMRegister dst, XMMRegister src, int mode, int vector_len) {\n+    assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :\n+            (vector_len == AVX_256bit ? VM_Version::supports_avx2() :\n+            (vector_len == AVX_512bit ? VM_Version::supports_avx512bw() : false)), \"\");\n+    NOT_LP64(assert(VM_Version::supports_sse2(), \"\"));\n+    InstructionAttr attributes(vector_len, \/* rex_w *\/ false, \/* legacy_mode *\/ _legacy_mode_bw, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+    int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_F3, VEX_OPCODE_0F, &attributes);\n+    emit_int24(0x70, (0xC0 | encode), mode & 0xFF);\n+}\n+\n@@ -5293,0 +5303,10 @@\n+void Assembler::vpshuflw(XMMRegister dst, XMMRegister src, int mode, int vector_len) {\n+    assert(vector_len == AVX_128bit ? VM_Version::supports_avx() :\n+            (vector_len == AVX_256bit ? VM_Version::supports_avx2() :\n+            (vector_len == AVX_512bit ? VM_Version::supports_avx512bw() : false)), \"\");\n+    NOT_LP64(assert(VM_Version::supports_sse2(), \"\"));\n+    InstructionAttr attributes(vector_len, \/* rex_w *\/ false, \/* legacy_mode *\/ _legacy_mode_bw, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+    int encode = simd_prefix_and_encode(dst, xnoreg, src, VEX_SIMD_F2, VEX_OPCODE_0F, &attributes);\n+    emit_int24(0x70, (0xC0 | encode), mode & 0xFF);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1949,0 +1949,2 @@\n+  void vpshufhw(XMMRegister dst, XMMRegister src, int mode, int vector_len);\n+  void vpshuflw(XMMRegister dst, XMMRegister src, int mode, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -3812,0 +3812,2 @@\n+  generate_chacha_stubs();\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -390,0 +390,12 @@\n+  \/\/ ChaCha20 stubs and helper functions\n+  void generate_chacha_stubs();\n+  address generate_chacha20Block_avx();\n+  address generate_chacha20Block_avx512();\n+  void cc20_quarter_round_avx(XMMRegister aVec, XMMRegister bVec,\n+    XMMRegister cVec, XMMRegister dVec, XMMRegister scratch,\n+    XMMRegister lrot8, XMMRegister lrot16, int vector_len);\n+  void cc20_shift_lane_org(XMMRegister bVec, XMMRegister cVec,\n+    XMMRegister dVec, int vector_len, bool colToDiag);\n+  void cc20_keystream_collate_avx512(XMMRegister aVec, XMMRegister bVec,\n+    XMMRegister cVec, XMMRegister dVec, Register baseAddr, int baseOffset);\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,582 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"asm\/assembler.hpp\"\n+#include \"asm\/assembler.inline.hpp\"\n+#include \"runtime\/stubRoutines.hpp\"\n+#include \"macroAssembler_x86.hpp\"\n+#include \"stubGenerator_x86_64.hpp\"\n+\n+#define __ _masm->\n+\n+#ifdef PRODUCT\n+#define BLOCK_COMMENT(str) \/* nothing *\/\n+#else\n+#define BLOCK_COMMENT(str) __ block_comment(str)\n+#endif \/\/ PRODUCT\n+\n+#define BIND(label) bind(label); BLOCK_COMMENT(#label \":\")\n+\n+\/\/ Constants\n+\n+\/**\n+ * This AVX\/AVX2 add mask generation can be used for multiple duties:\n+ *      1.) Provide +0\/+1 counter increments by loading 256 bits\n+ *          at offset 0\n+ *      2.) Provide +2\/+2 counter increments for the second set\n+ *          of 4 AVX2 registers at offset 32 (256-bit load)\n+ *      3.) Provide a +1 increment for the second set of 4 AVX\n+ *          registers at offset 16 (128-bit load)\n+ *\/\n+ATTRIBUTE_ALIGNED(64) uint64_t CC20_COUNTER_ADD_AVX[] = {\n+    0x0000000000000000UL, 0x0000000000000000UL,\n+    0x0000000000000001UL, 0x0000000000000000UL,\n+    0x0000000000000002UL, 0x0000000000000000UL,\n+    0x0000000000000002UL, 0x0000000000000000UL,\n+};\n+static address chacha20_ctradd_avx() {\n+  return (address)CC20_COUNTER_ADD_AVX;\n+}\n+\n+\/**\n+ * Add masks for 4-block ChaCha20 Block calculations\n+ * The first 512 bits creates a +0\/+1\/+2\/+3 add overlay.\n+ * The second 512 bits is a +4\/+4\/+4\/+4 add overlay.  This\n+ * can be used to increment the counter fields for the next 4 blocks.\n+ *\/\n+ATTRIBUTE_ALIGNED(64) uint64_t CC20_COUNTER_ADD_AVX512[] = {\n+    0x0000000000000000UL, 0x0000000000000000UL,\n+    0x0000000000000001UL, 0x0000000000000000UL,\n+    0x0000000000000002UL, 0x0000000000000000UL,\n+    0x0000000000000003UL, 0x0000000000000000UL,\n+\n+    0x0000000000000004UL, 0x0000000000000000UL,\n+    0x0000000000000004UL, 0x0000000000000000UL,\n+    0x0000000000000004UL, 0x0000000000000000UL,\n+    0x0000000000000004UL, 0x0000000000000000UL\n+};\n+static address chacha20_ctradd_avx512() {\n+  return (address)CC20_COUNTER_ADD_AVX512;\n+}\n+\n+\/**\n+ * The first 256 bits represents a byte-wise permutation\n+ * for an 8-bit left-rotation on 32-bit lanes.\n+ * The second 256 bits is a 16-bit rotation on 32-bit lanes.\n+ *\/\n+ATTRIBUTE_ALIGNED(64) uint64_t CC20_LROT_CONSTS[] = {\n+    0x0605040702010003UL, 0x0E0D0C0F0A09080BUL,\n+    0x0605040702010003UL, 0x0E0D0C0F0A09080BUL,\n+\n+    0x0504070601000302UL, 0x0D0C0F0E09080B0AUL,\n+    0x0504070601000302UL, 0x0D0C0F0E09080B0AUL\n+};\n+static address chacha20_lrot_consts() {\n+  return (address)CC20_LROT_CONSTS;\n+}\n+\n+\n+\n+void StubGenerator::generate_chacha_stubs() {\n+  \/\/ Generate ChaCha20 intrinsics code\n+  if (UseChaCha20Intrinsics) {\n+    if (VM_Version::supports_evex()) {\n+      StubRoutines::_chacha20Block = generate_chacha20Block_avx512();\n+    } else {    \/\/ Either AVX or AVX2 is supported\n+      assert(VM_Version::supports_avx() == true, \"Must at least support AVX instructions\");\n+      StubRoutines::_chacha20Block = generate_chacha20Block_avx();\n+    }\n+  }\n+}\n+\n+\/* The 2-block AVX\/AVX2-enabled ChaCha20 block function implementation *\/\n+address StubGenerator::generate_chacha20Block_avx() {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", \"chacha20Block\");\n+  address start = __ pc();\n+\n+  Label L_twoRounds;\n+  const Register state        = c_rarg0;\n+  const Register result       = c_rarg1;\n+  const Register loopCounter  = r8;\n+  const Register rotAddr      = r9;\n+\n+  const XMMRegister aState = xmm0;\n+  const XMMRegister bState = xmm1;\n+  const XMMRegister cState = xmm2;\n+  const XMMRegister dState = xmm3;\n+  const XMMRegister a1Vec = xmm4;\n+  const XMMRegister b1Vec = xmm5;\n+  const XMMRegister c1Vec = xmm6;\n+  const XMMRegister d1Vec = xmm7;\n+  const XMMRegister a2Vec = xmm8;\n+  const XMMRegister b2Vec = xmm9;\n+  const XMMRegister c2Vec = xmm10;\n+  const XMMRegister d2Vec = xmm11;\n+  const XMMRegister scratch = xmm12;\n+  const XMMRegister d2State = xmm13;\n+  const XMMRegister lrot8 = xmm14;\n+  const XMMRegister lrot16 = xmm15;\n+\n+  int vector_len;\n+  int outlen;\n+\n+  \/\/ This function will only be called if AVX2 or AVX are supported\n+  \/\/ AVX512 uses a different function.\n+  if (VM_Version::supports_avx2()) {\n+    vector_len = Assembler::AVX_256bit;\n+    outlen = 256;\n+  } else if (VM_Version::supports_avx()) {\n+    vector_len = Assembler::AVX_128bit;\n+    outlen = 128;\n+  }\n+\n+  __ enter();\n+\n+  \/\/ Load the initial state in columnar orientation and then copy\n+  \/\/ that starting state to the working register set.\n+  \/\/ Also load the address of the add mask for later use in handling\n+  \/\/ multi-block counter increments.\n+  __ lea(rotAddr, ExternalAddress(chacha20_lrot_consts()));\n+  __ lea(rax, ExternalAddress(chacha20_ctradd_avx()));\n+  if (vector_len == Assembler::AVX_128bit) {\n+    __ movdqu(aState, Address(state, 0));       \/\/ Bytes 0 - 15 -> a1Vec\n+    __ movdqu(bState, Address(state, 16));      \/\/ Bytes 16 - 31 -> b1Vec\n+    __ movdqu(cState, Address(state, 32));      \/\/ Bytes 32 - 47 -> c1Vec\n+    __ movdqu(dState, Address(state, 48));      \/\/ Bytes 48 - 63 -> d1Vec\n+\n+    __ movdqu(a1Vec, aState);\n+    __ movdqu(b1Vec, bState);\n+    __ movdqu(c1Vec, cState);\n+    __ movdqu(d1Vec, dState);\n+\n+    __ movdqu(a2Vec, aState);\n+    __ movdqu(b2Vec, bState);\n+    __ movdqu(c2Vec, cState);\n+    __ vpaddd(d2State, dState, Address(rax, 16), vector_len);\n+    __ movdqu(d2Vec, d2State);\n+    __ movdqu(lrot8, Address(rotAddr, 0));      \/\/ Load 8-bit lrot const\n+    __ movdqu(lrot16, Address(rotAddr, 32));    \/\/ Load 16-bit lrot const\n+  } else {\n+    \/\/ We will broadcast each 128-bit segment of the state array into\n+    \/\/ the high and low halves of ymm state registers.  Then apply the add\n+    \/\/ mask to the dState register.  These will then be copied into the\n+    \/\/ a\/b\/c\/d1Vec working registers.\n+    __ vbroadcastf128(aState, Address(state, 0), vector_len);\n+    __ vbroadcastf128(bState, Address(state, 16), vector_len);\n+    __ vbroadcastf128(cState, Address(state, 32), vector_len);\n+    __ vbroadcastf128(dState, Address(state, 48), vector_len);\n+    __ vpaddd(dState, dState, Address(rax, 0), vector_len);\n+    __ vpaddd(d2State, dState, Address(rax, 32), vector_len);\n+\n+    __ vmovdqu(a1Vec, aState);\n+    __ vmovdqu(b1Vec, bState);\n+    __ vmovdqu(c1Vec, cState);\n+    __ vmovdqu(d1Vec, dState);\n+\n+    __ vmovdqu(a2Vec, aState);\n+    __ vmovdqu(b2Vec, bState);\n+    __ vmovdqu(c2Vec, cState);\n+    __ vmovdqu(d2Vec, d2State);\n+    __ vmovdqu(lrot8, Address(rotAddr, 0));      \/\/ Load 8-bit lrot const\n+    __ vmovdqu(lrot16, Address(rotAddr, 32));    \/\/ Load 16-bit lrot const\n+  }\n+\n+  __ movl(loopCounter, 10);                   \/\/ Set 10 2-round iterations\n+  __ BIND(L_twoRounds);\n+\n+  \/\/ The first quarter round macro call covers the first 4 QR operations:\n+  \/\/  Qround(state, 0, 4, 8,12)\n+  \/\/  Qround(state, 1, 5, 9,13)\n+  \/\/  Qround(state, 2, 6,10,14)\n+  \/\/  Qround(state, 3, 7,11,15)\n+  cc20_quarter_round_avx(a1Vec, b1Vec, c1Vec, d1Vec, scratch,\n+      lrot8, lrot16, vector_len);\n+  cc20_quarter_round_avx(a2Vec, b2Vec, c2Vec, d2Vec, scratch,\n+      lrot8, lrot16, vector_len);\n+\n+  \/\/ Shuffle the b1Vec\/c1Vec\/d1Vec to reorganize the state vectors\n+  \/\/ to diagonals.  The a1Vec does not need to change orientation.\n+  cc20_shift_lane_org(b1Vec, c1Vec, d1Vec, vector_len, true);\n+  cc20_shift_lane_org(b2Vec, c2Vec, d2Vec, vector_len, true);\n+\n+  \/\/ The second set of operations on the vectors covers the second 4 quarter\n+  \/\/ round operations, now acting on the diagonals:\n+  \/\/  Qround(state, 0, 5,10,15)\n+  \/\/  Qround(state, 1, 6,11,12)\n+  \/\/  Qround(state, 2, 7, 8,13)\n+  \/\/  Qround(state, 3, 4, 9,14)\n+  cc20_quarter_round_avx(a1Vec, b1Vec, c1Vec, d1Vec, scratch,\n+      lrot8, lrot16, vector_len);\n+  cc20_quarter_round_avx(a2Vec, b2Vec, c2Vec, d2Vec, scratch,\n+      lrot8, lrot16, vector_len);\n+\n+  \/\/ Before we start the next iteration, we need to perform shuffles\n+  \/\/ on the b\/c\/d vectors to move them back to columnar organizations\n+  \/\/ from their current diagonal orientation.\n+  cc20_shift_lane_org(b1Vec, c1Vec, d1Vec, vector_len, false);\n+  cc20_shift_lane_org(b2Vec, c2Vec, d2Vec, vector_len, false);\n+\n+  __ decrement(loopCounter);\n+  __ jcc(Assembler::notZero, L_twoRounds);\n+\n+  \/\/ Add the original start state back into the current state.\n+  __ vpaddd(a1Vec, a1Vec, aState, vector_len);\n+  __ vpaddd(b1Vec, b1Vec, bState, vector_len);\n+  __ vpaddd(c1Vec, c1Vec, cState, vector_len);\n+  __ vpaddd(d1Vec, d1Vec, dState, vector_len);\n+\n+  __ vpaddd(a2Vec, a2Vec, aState, vector_len);\n+  __ vpaddd(b2Vec, b2Vec, bState, vector_len);\n+  __ vpaddd(c2Vec, c2Vec, cState, vector_len);\n+  __ vpaddd(d2Vec, d2Vec, d2State, vector_len);\n+\n+  \/\/ Write the data to the keystream array\n+  if (vector_len == Assembler::AVX_128bit) {\n+    __ movdqu(Address(result, 0), a1Vec);\n+    __ movdqu(Address(result, 16), b1Vec);\n+    __ movdqu(Address(result, 32), c1Vec);\n+    __ movdqu(Address(result, 48), d1Vec);\n+    __ movdqu(Address(result, 64), a2Vec);\n+    __ movdqu(Address(result, 80), b2Vec);\n+    __ movdqu(Address(result, 96), c2Vec);\n+    __ movdqu(Address(result, 112), d2Vec);\n+  } else {\n+    \/\/ Each half of the YMM has to be written 64 bytes apart from\n+    \/\/ each other in memory so the final keystream buffer holds\n+    \/\/ two consecutive keystream blocks.\n+    __ vextracti128(Address(result, 0), a1Vec, 0);\n+    __ vextracti128(Address(result, 64), a1Vec, 1);\n+    __ vextracti128(Address(result, 16), b1Vec, 0);\n+    __ vextracti128(Address(result, 80), b1Vec, 1);\n+    __ vextracti128(Address(result, 32), c1Vec, 0);\n+    __ vextracti128(Address(result, 96), c1Vec, 1);\n+    __ vextracti128(Address(result, 48), d1Vec, 0);\n+    __ vextracti128(Address(result, 112), d1Vec, 1);\n+\n+    __ vextracti128(Address(result, 128), a2Vec, 0);\n+    __ vextracti128(Address(result, 192), a2Vec, 1);\n+    __ vextracti128(Address(result, 144), b2Vec, 0);\n+    __ vextracti128(Address(result, 208), b2Vec, 1);\n+    __ vextracti128(Address(result, 160), c2Vec, 0);\n+    __ vextracti128(Address(result, 224), c2Vec, 1);\n+    __ vextracti128(Address(result, 176), d2Vec, 0);\n+    __ vextracti128(Address(result, 240), d2Vec, 1);\n+  }\n+\n+  \/\/ This function will always write 128 or 256 bytes into the\n+  \/\/ key stream buffer, depending on the length of the SIMD\n+  \/\/ registers.  That length should be returned through %rax.\n+  __ mov64(rax, outlen);\n+\n+  __ leave();\n+  __ ret(0);\n+  return start;\n+}\n+\n+\/* The 4-block AVX512-enabled ChaCha20 block function implementation *\/\n+address StubGenerator::generate_chacha20Block_avx512() {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", \"chacha20Block\");\n+  address start = __ pc();\n+\n+  Label L_twoRounds;\n+  const Register state        = c_rarg0;\n+  const Register result       = c_rarg1;\n+  const Register loopCounter  = r8;\n+\n+  const XMMRegister aState = xmm0;\n+  const XMMRegister bState = xmm1;\n+  const XMMRegister cState = xmm2;\n+  const XMMRegister dState = xmm3;\n+  const XMMRegister a1Vec = xmm4;\n+  const XMMRegister b1Vec = xmm5;\n+  const XMMRegister c1Vec = xmm6;\n+  const XMMRegister d1Vec = xmm7;\n+  const XMMRegister a2Vec = xmm8;\n+  const XMMRegister b2Vec = xmm9;\n+  const XMMRegister c2Vec = xmm10;\n+  const XMMRegister d2Vec = xmm11;\n+  const XMMRegister a3Vec = xmm12;\n+  const XMMRegister b3Vec = xmm13;\n+  const XMMRegister c3Vec = xmm14;\n+  const XMMRegister d3Vec = xmm15;\n+  const XMMRegister a4Vec = xmm16;\n+  const XMMRegister b4Vec = xmm17;\n+  const XMMRegister c4Vec = xmm18;\n+  const XMMRegister d4Vec = xmm19;\n+  const XMMRegister d2State = xmm20;\n+  const XMMRegister d3State = xmm21;\n+  const XMMRegister d4State = xmm22;\n+  const XMMRegister scratch = xmm23;\n+\n+  __ enter();\n+\n+  \/\/ Load the initial state in columnar orientation.\n+  \/\/ We will broadcast each 128-bit segment of the state array into\n+  \/\/ all four double-quadword slots on ZMM State registers.  They will\n+  \/\/ be copied into the working ZMM registers and then added back in\n+  \/\/ at the very end of the block function.  The add mask should be\n+  \/\/ applied to the dState register so it does not need to be fetched\n+  \/\/ when adding the start state back into the final working state.\n+  __ lea(rax, ExternalAddress(chacha20_ctradd_avx512()));\n+  __ evbroadcasti32x4(aState, Address(state, 0), Assembler::AVX_512bit);\n+  __ evbroadcasti32x4(bState, Address(state, 16), Assembler::AVX_512bit);\n+  __ evbroadcasti32x4(cState, Address(state, 32), Assembler::AVX_512bit);\n+  __ evbroadcasti32x4(dState, Address(state, 48), Assembler::AVX_512bit);\n+  __ vpaddd(dState, dState, Address(rax, 0), Assembler::AVX_512bit);\n+  __ evmovdqul(scratch, Address(rax, 64), Assembler::AVX_512bit);\n+  __ vpaddd(d2State, dState, scratch, Assembler::AVX_512bit);\n+  __ vpaddd(d3State, d2State, scratch, Assembler::AVX_512bit);\n+  __ vpaddd(d4State, d3State, scratch, Assembler::AVX_512bit);\n+\n+  __ evmovdqul(a1Vec, aState, Assembler::AVX_512bit);\n+  __ evmovdqul(b1Vec, bState, Assembler::AVX_512bit);\n+  __ evmovdqul(c1Vec, cState, Assembler::AVX_512bit);\n+  __ evmovdqul(d1Vec, dState, Assembler::AVX_512bit);\n+\n+  __ evmovdqul(a2Vec, aState, Assembler::AVX_512bit);\n+  __ evmovdqul(b2Vec, bState, Assembler::AVX_512bit);\n+  __ evmovdqul(c2Vec, cState, Assembler::AVX_512bit);\n+  __ evmovdqul(d2Vec, d2State, Assembler::AVX_512bit);\n+\n+  __ evmovdqul(a3Vec, aState, Assembler::AVX_512bit);\n+  __ evmovdqul(b3Vec, bState, Assembler::AVX_512bit);\n+  __ evmovdqul(c3Vec, cState, Assembler::AVX_512bit);\n+  __ evmovdqul(d3Vec, d3State, Assembler::AVX_512bit);\n+\n+  __ evmovdqul(a4Vec, aState, Assembler::AVX_512bit);\n+  __ evmovdqul(b4Vec, bState, Assembler::AVX_512bit);\n+  __ evmovdqul(c4Vec, cState, Assembler::AVX_512bit);\n+  __ evmovdqul(d4Vec, d4State, Assembler::AVX_512bit);\n+\n+  __ movl(loopCounter, 10);                       \/\/ Set 10 2-round iterations\n+  __ BIND(L_twoRounds);\n+\n+  \/\/ The first set of operations on the vectors covers the first 4 quarter\n+  \/\/ round operations:\n+  \/\/  Qround(state, 0, 4, 8,12)\n+  \/\/  Qround(state, 1, 5, 9,13)\n+  \/\/  Qround(state, 2, 6,10,14)\n+  \/\/  Qround(state, 3, 7,11,15)\n+  cc20_quarter_round_avx(a1Vec, b1Vec, c1Vec, d1Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+  cc20_quarter_round_avx(a2Vec, b2Vec, c2Vec, d2Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+  cc20_quarter_round_avx(a3Vec, b3Vec, c3Vec, d3Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+  cc20_quarter_round_avx(a4Vec, b4Vec, c4Vec, d4Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+\n+  \/\/ Shuffle the b1Vec\/c1Vec\/d1Vec to reorganize the state vectors\n+  \/\/ to diagonals.  The a1Vec does not need to change orientation.\n+  cc20_shift_lane_org(b1Vec, c1Vec, d1Vec, Assembler::AVX_512bit, true);\n+  cc20_shift_lane_org(b2Vec, c2Vec, d2Vec, Assembler::AVX_512bit, true);\n+  cc20_shift_lane_org(b3Vec, c3Vec, d3Vec, Assembler::AVX_512bit, true);\n+  cc20_shift_lane_org(b4Vec, c4Vec, d4Vec, Assembler::AVX_512bit, true);\n+\n+  \/\/ The second set of operations on the vectors covers the second 4 quarter\n+  \/\/ round operations, now acting on the diagonals:\n+  \/\/  Qround(state, 0, 5,10,15)\n+  \/\/  Qround(state, 1, 6,11,12)\n+  \/\/  Qround(state, 2, 7, 8,13)\n+  \/\/  Qround(state, 3, 4, 9,14)\n+  cc20_quarter_round_avx(a1Vec, b1Vec, c1Vec, d1Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+  cc20_quarter_round_avx(a2Vec, b2Vec, c2Vec, d2Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+  cc20_quarter_round_avx(a3Vec, b3Vec, c3Vec, d3Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+  cc20_quarter_round_avx(a4Vec, b4Vec, c4Vec, d4Vec, scratch,\n+      xnoreg, xnoreg, Assembler::AVX_512bit);\n+\n+  \/\/ Before we start the next iteration, we need to perform shuffles\n+  \/\/ on the b\/c\/d vectors to move them back to columnar organizations\n+  \/\/ from their current diagonal orientation.\n+  cc20_shift_lane_org(b1Vec, c1Vec, d1Vec, Assembler::AVX_512bit, false);\n+  cc20_shift_lane_org(b2Vec, c2Vec, d2Vec, Assembler::AVX_512bit, false);\n+  cc20_shift_lane_org(b3Vec, c3Vec, d3Vec, Assembler::AVX_512bit, false);\n+  cc20_shift_lane_org(b4Vec, c4Vec, d4Vec, Assembler::AVX_512bit, false);\n+\n+  __ decrement(loopCounter);\n+  __ jcc(Assembler::notZero, L_twoRounds);\n+\n+  \/\/ Add the initial state now held on the a\/b\/c\/dState registers to the\n+  \/\/ final working register values.  We will also add in the counter add\n+  \/\/ mask onto zmm3 after adding in the start state.\n+  __ vpaddd(a1Vec, a1Vec, aState, Assembler::AVX_512bit);\n+  __ vpaddd(b1Vec, b1Vec, bState, Assembler::AVX_512bit);\n+  __ vpaddd(c1Vec, c1Vec, cState, Assembler::AVX_512bit);\n+  __ vpaddd(d1Vec, d1Vec, dState, Assembler::AVX_512bit);\n+\n+  __ vpaddd(a2Vec, a2Vec, aState, Assembler::AVX_512bit);\n+  __ vpaddd(b2Vec, b2Vec, bState, Assembler::AVX_512bit);\n+  __ vpaddd(c2Vec, c2Vec, cState, Assembler::AVX_512bit);\n+  __ vpaddd(d2Vec, d2Vec, d2State, Assembler::AVX_512bit);\n+\n+  __ vpaddd(a3Vec, a3Vec, aState, Assembler::AVX_512bit);\n+  __ vpaddd(b3Vec, b3Vec, bState, Assembler::AVX_512bit);\n+  __ vpaddd(c3Vec, c3Vec, cState, Assembler::AVX_512bit);\n+  __ vpaddd(d3Vec, d3Vec, d3State, Assembler::AVX_512bit);\n+\n+  __ vpaddd(a4Vec, a4Vec, aState, Assembler::AVX_512bit);\n+  __ vpaddd(b4Vec, b4Vec, bState, Assembler::AVX_512bit);\n+  __ vpaddd(c4Vec, c4Vec, cState, Assembler::AVX_512bit);\n+  __ vpaddd(d4Vec, d4Vec, d4State, Assembler::AVX_512bit);\n+\n+  \/\/ Write the ZMM state registers out to the key stream buffer\n+  \/\/ Each ZMM is divided into 4 128-bit segments.  Each segment\n+  \/\/ is written to memory at 64-byte displacements from one\n+  \/\/ another.  The result is that all 4 blocks will be in their\n+  \/\/ proper order when serialized.\n+  cc20_keystream_collate_avx512(a1Vec, b1Vec, c1Vec, d1Vec, result, 0);\n+  cc20_keystream_collate_avx512(a2Vec, b2Vec, c2Vec, d2Vec, result, 256);\n+  cc20_keystream_collate_avx512(a3Vec, b3Vec, c3Vec, d3Vec, result, 512);\n+  cc20_keystream_collate_avx512(a4Vec, b4Vec, c4Vec, d4Vec, result, 768);\n+\n+  \/\/ This function will always write 1024 bytes into the key stream buffer\n+  \/\/ and that length should be returned through %rax.\n+  __ mov64(rax, 1024);\n+\n+  __ leave();\n+  __ ret(0);\n+  return start;\n+}\n+\n+\/**\n+ * Provide a function that implements the ChaCha20 quarter round function.\n+ *\n+ * @param aVec the SIMD register containing only the \"a\" values\n+ * @param bVec the SIMD register containing only the \"b\" values\n+ * @param cVec the SIMD register containing only the \"c\" values\n+ * @param dVec the SIMD register containing only the \"d\" values\n+ * @param scratch SIMD register used for non-byte-aligned left rotations\n+ * @param lrot8 shuffle control mask for an 8-byte left rotation (32-bit lane)\n+ * @param lrot16 shuffle control mask for a 16-byte left rotation (32-bit lane)\n+ * @param vector_len the length of the vector\n+ *\/\n+void StubGenerator::cc20_quarter_round_avx(XMMRegister aVec, XMMRegister bVec,\n+    XMMRegister cVec, XMMRegister dVec, XMMRegister scratch,\n+    XMMRegister lrot8, XMMRegister lrot16, int vector_len) {\n+\n+  \/\/ a += b; d ^= a; d <<<= 16\n+  __ vpaddd(aVec, aVec, bVec, vector_len);\n+  __ vpxor(dVec, dVec, aVec, vector_len);\n+  if (vector_len == Assembler::AVX_512bit) {\n+    __ evprold(dVec, dVec, 16, vector_len);\n+  } else {\n+    __ vpshufb(dVec, dVec, lrot16, vector_len);\n+  }\n+\n+  \/\/ c += d; b ^= c; b <<<= 12 (b << 12 | scratch >>> 20)\n+  __ vpaddd(cVec, cVec, dVec, vector_len);\n+  __ vpxor(bVec, bVec, cVec, vector_len);\n+  if (vector_len == Assembler::AVX_512bit) {\n+    __ evprold(bVec, bVec, 12, vector_len);\n+  } else {\n+    __ vpsrld(scratch, bVec, 20, vector_len);\n+    __ vpslld(bVec, bVec, 12, vector_len);\n+    __ vpor(bVec, bVec, scratch, vector_len);\n+  }\n+\n+  \/\/ a += b; d ^= a; d <<<= 8 (d << 8 | scratch >>> 24)\n+  __ vpaddd(aVec, aVec, bVec, vector_len);\n+  __ vpxor(dVec, dVec, aVec, vector_len);\n+  if (vector_len == Assembler::AVX_512bit) {\n+    __ evprold(dVec, dVec, 8, vector_len);\n+  } else {\n+    __ vpshufb(dVec, dVec, lrot8, vector_len);\n+  }\n+\n+  \/\/ c += d; b ^= c; b <<<= 7 (b << 7 | scratch >>> 25)\n+  __ vpaddd(cVec, cVec, dVec, vector_len);\n+  __ vpxor(bVec, bVec, cVec, vector_len);\n+  if (vector_len == Assembler::AVX_512bit) {\n+    __ evprold(bVec, bVec, 7, vector_len);\n+  } else {\n+    __ vpsrld(scratch, bVec, 25, vector_len);\n+    __ vpslld(bVec, bVec, 7, vector_len);\n+    __ vpor(bVec, bVec, scratch, vector_len);\n+  }\n+}\n+\n+\/**\n+ * Shift the b, c, and d vectors between columnar and diagonal representations.\n+ * Note that the \"a\" vector does not shift.\n+ *\n+ * @param bVec the SIMD register containing only the \"b\" values\n+ * @param cVec the SIMD register containing only the \"c\" values\n+ * @param dVec the SIMD register containing only the \"d\" values\n+ * @param vector_len the size of the SIMD register to operate upon\n+ * @param colToDiag true if moving columnar to diagonal, false if\n+ *                  moving diagonal back to columnar.\n+ *\/\n+void StubGenerator::cc20_shift_lane_org(XMMRegister bVec, XMMRegister cVec,\n+    XMMRegister dVec, int vector_len, bool colToDiag) {\n+  int bShift = colToDiag ? 0x39 : 0x93;\n+  int cShift = 0x4E;\n+  int dShift = colToDiag ? 0x93 : 0x39;\n+\n+  __ vpshufd(bVec, bVec, bShift, vector_len);\n+  __ vpshufd(cVec, cVec, cShift, vector_len);\n+  __ vpshufd(dVec, dVec, dShift, vector_len);\n+}\n+\n+\/**\n+ * Write 256 bytes of keystream output held in 4 AVX512 SIMD registers\n+ * in a quarter round parallel organization.\n+ *\n+ * @param aVec the SIMD register containing only the \"a\" values\n+ * @param bVec the SIMD register containing only the \"b\" values\n+ * @param cVec the SIMD register containing only the \"c\" values\n+ * @param dVec the SIMD register containing only the \"d\" values\n+ * @param baseAddr the register holding the base output address\n+ * @param baseOffset the offset from baseAddr for writes\n+ *\/\n+void StubGenerator::cc20_keystream_collate_avx512(XMMRegister aVec, XMMRegister\n+bVec,\n+    XMMRegister cVec, XMMRegister dVec, Register baseAddr, int baseOffset) {\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 0), aVec, 0);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 64), aVec, 1);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 128), aVec, 2);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 192), aVec, 3);\n+\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 16), bVec, 0);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 80), bVec, 1);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 144), bVec, 2);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 208), bVec, 3);\n+\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 32), cVec, 0);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 96), cVec, 1);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 160), cVec, 2);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 224), cVec, 3);\n+\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 48), dVec, 0);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 112), dVec, 1);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 176), dVec, 2);\n+  __ vextracti32x4(Address(baseAddr, baseOffset + 240), dVec, 3);\n+}\n+\n+#undef __\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_chacha.cpp","additions":582,"deletions":0,"binary":false,"changes":582,"status":"added"},{"patch":"@@ -1125,0 +1125,16 @@\n+  \/\/ ChaCha20 Intrinsics\n+  \/\/ As long as the system supports AVX as a baseline we can do a\n+  \/\/ SIMD-enabled block function.  StubGenerator makes the determination\n+  \/\/ based on the VM capabilities whether to use an AVX2 or AVX512-enabled\n+  \/\/ version.\n+  if (UseAVX >= 1) {\n+      if (FLAG_IS_DEFAULT(UseChaCha20Intrinsics)) {\n+          UseChaCha20Intrinsics = true;\n+      }\n+  } else if (UseChaCha20Intrinsics) {\n+      if (!FLAG_IS_DEFAULT(UseChaCha20Intrinsics)) {\n+          warning(\"ChaCha20 intrinsic requires AVX instructions\");\n+      }\n+      FLAG_SET_DEFAULT(UseChaCha20Intrinsics, false);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -478,0 +478,3 @@\n+  case vmIntrinsics::_chacha20Block:\n+    if (!UseChaCha20Intrinsics) return true;\n+    break;\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -534,0 +534,6 @@\n+                                                                                                                        \\\n+  \/* support for com.sun.crypto.provider.ChaCha20Cipher *\/                                                              \\\n+  do_class(com_sun_crypto_provider_chacha20cipher,      \"com\/sun\/crypto\/provider\/ChaCha20Cipher\")                       \\\n+  do_intrinsic(_chacha20Block, com_sun_crypto_provider_chacha20cipher, chacha20Block_name, chacha20Block_signature, F_S) \\\n+   do_name(chacha20Block_name,                                 \"implChaCha20Block\")                                         \\\n+   do_signature(chacha20Block_signature, \"([I[B)I\")                                                                    \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -321,0 +321,1 @@\n+  static_field(StubRoutines,                _chacha20Block,                                   address)                               \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -740,0 +740,1 @@\n+  case vmIntrinsics::_chacha20Block:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1171,0 +1171,1 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"chacha20Block\") == 0 ||\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -611,0 +611,2 @@\n+  case vmIntrinsics::_chacha20Block:\n+    return inline_chacha20Block();\n@@ -6900,0 +6902,30 @@\n+\/\/------------------------------inline_chacha20Block\n+bool LibraryCallKit::inline_chacha20Block() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UseChaCha20Intrinsics, \"need ChaCha20 intrinsics support\");\n+\n+  stubAddr = StubRoutines::chacha20Block();\n+  stubName = \"chacha20Block\";\n+\n+  Node* state          = argument(0);\n+  Node* result         = argument(1);\n+\n+  state = must_be_not_null(state, true);\n+  result = must_be_not_null(result, true);\n+\n+  Node* state_start  = array_element_address(state, intcon(0), T_INT);\n+  assert(state_start, \"state is NULL\");\n+  Node* result_start  = array_element_address(result, intcon(0), T_BYTE);\n+  assert(result_start, \"result is NULL\");\n+\n+  Node* cc20Blk = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                                  OptoRuntime::chacha20Block_Type(),\n+                                  stubAddr, stubName, TypePtr::BOTTOM,\n+                                  state_start, result_start);\n+  \/\/ return key stream length (int)\n+  Node* retvalue = _gvn.transform(new ProjNode(cc20Blk, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -294,0 +294,1 @@\n+  bool inline_chacha20Block();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1225,0 +1225,20 @@\n+\n+\/\/ ChaCha20 Block function\n+const TypeFunc* OptoRuntime::chacha20Block_Type() {\n+    int argcnt = 2;\n+\n+    const Type** fields = TypeTuple::fields(argcnt);\n+    int argp = TypeFunc::Parms;\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ state\n+    fields[argp++] = TypePtr::NOTNULL;      \/\/ result\n+\n+    assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+    const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+\n+    \/\/ result type needed\n+    fields = TypeTuple::fields(1);\n+    fields[TypeFunc::Parms + 0] = TypeInt::INT;     \/\/ key stream outlen as int\n+    const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+    return TypeFunc::make(domain, range);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -281,0 +281,1 @@\n+  static const TypeFunc* chacha20Block_Type();\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -326,0 +326,3 @@\n+  product(bool, UseChaCha20Intrinsics, false, DIAGNOSTIC,                   \\\n+          \"Use intrinsics for the vectorized version of ChaCha20\")          \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -131,0 +131,1 @@\n+address StubRoutines::_chacha20Block                       = NULL;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -212,0 +212,1 @@\n+  static address _chacha20Block;\n@@ -391,0 +392,1 @@\n+  static address chacha20Block()         { return _chacha20Block; }\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -545,0 +545,1 @@\n+     static_field(StubRoutines,                _chacha20Block,                                address)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -42,0 +42,3 @@\n+\n+import jdk.internal.vm.annotation.ForceInline;\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n@@ -61,2 +64,3 @@\n-    private static final int KEYSTREAM_SIZE = 64;\n-    private static final int KS_SIZE_INTS = KEYSTREAM_SIZE \/ Integer.BYTES;\n+    private static final int KS_MAX_LEN = 1024;\n+    private static final int KS_BLK_SIZE = 64;\n+    private static final int KS_SIZE_INTS = KS_BLK_SIZE \/ Integer.BYTES;\n@@ -88,4 +92,3 @@\n-    \/\/ Two arrays, both implemented as 16-element integer arrays:\n-    \/\/ The base state, created at initialization time, and a working\n-    \/\/ state which is a clone of the start state, and is then modified\n-    \/\/ with the counter and the ChaCha20 block function.\n+    \/\/ The base state is created at initialization time as a 16-int array\n+    \/\/ and then is copied into either local variables for computations (Java) or\n+    \/\/ into SIMD registers (intrinsics).\n@@ -93,1 +96,0 @@\n-    private final byte[] keyStream = new byte[KEYSTREAM_SIZE];\n@@ -95,1 +97,7 @@\n-    \/\/ The offset into the current keystream\n+    \/\/ The output keystream array is sized to hold keystream output from the\n+    \/\/ implChaCha20Block method.  This can range from a single block at a time\n+    \/\/ (Java software) up to 16 blocks on x86_64 with AVX512 support.\n+    private final byte[] keyStream = new byte[KS_MAX_LEN];\n+\n+    \/\/ The keystream buffer limit and offset\n+    private int keyStrLimit;\n@@ -564,1 +572,2 @@\n-        \/\/ We can also get one block's worth of keystream created\n+        \/\/ We can also generate the first block (or blocks if intrinsics\n+        \/\/ are capable of doing multiple blocks at a time) of keystream.\n@@ -566,1 +575,3 @@\n-        generateKeystream();\n+        this.keyStrLimit = chaCha20Block(startState, counter, keyStream);\n+        this.keyStrOffset = 0;\n+        this.counter += (keyStrLimit \/ KS_BLK_SIZE);\n@@ -569,1 +580,0 @@\n-        this.keyStrOffset = 0;\n@@ -834,9 +844,12 @@\n-    \/**\n-     * Using the current state and counter create the next set of keystream\n-     * bytes.  This method will generate the next 512 bits of keystream and\n-     * return it in the {@code keyStream} parameter.  Following the\n-     * block function the counter will be incremented.\n-     *\/\n-    private void generateKeystream() {\n-        chaCha20Block(startState, counter, keyStream);\n-        counter++;\n+    @ForceInline\n+    private static int chaCha20Block(int[] initState, long counter,\n+            byte[] result) {\n+        if (initState.length != KS_SIZE_INTS || result.length != KS_MAX_LEN) {\n+            throw new IllegalArgumentException(\n+                    \"Illegal state or keystream buffer length\");\n+        }\n+\n+        \/\/ Set the counter value before sending into the underlying\n+        \/\/ private block method\n+        initState[12] = (int)counter;\n+        return implChaCha20Block(initState, result);\n@@ -848,3 +861,1 @@\n-     * @param initState the starting state, not including the counter\n-     *      value.\n-     * @param counter the counter value to apply\n+     * @param initState the starting state using the current counter value.\n@@ -854,2 +865,4 @@\n-     * @note it is the caller's responsibility to ensure that the workState\n-     * is sized the same as the initState, no checking is performed internally.\n+     * @return the number of keystream bytes generated.  In a pure Java method\n+     *      this will always be 64 bytes, but intrinsics that make use of\n+     *      AVX2 or AVX512 registers may generate multiple blocks of keystream\n+     *      in a single call and therefore may be a larger multiple of 64.\n@@ -857,2 +870,2 @@\n-    private static void chaCha20Block(int[] initState, long counter,\n-                                      byte[] result) {\n+    @IntrinsicCandidate\n+    private static int implChaCha20Block(int[] initState, byte[] result) {\n@@ -872,1 +885,1 @@\n-        int ws12 = (int)counter;\n+        int ws12 = initState[12];\n@@ -989,2 +1002,1 @@\n-        \/\/ Add the counter back into workState[12]\n-        asIntLittleEndian.set(result, 48, ws12 + (int)counter);\n+        asIntLittleEndian.set(result, 48, ws12 + initState[12]);\n@@ -994,0 +1006,2 @@\n+\n+        return KS_BLK_SIZE;\n@@ -1012,1 +1026,1 @@\n-            int ksRemain = keyStream.length - keyStrOffset;\n+            int ksRemain = keyStrLimit - keyStrOffset;\n@@ -1015,1 +1029,10 @@\n-                    generateKeystream();\n+                    \/\/ Intrinsics can do multiple blocks at once.  This means\n+                    \/\/ it may overrun the counter. In order to prevent key\n+                    \/\/ stream reuse, we adjust the key stream limit to only the\n+                    \/\/ key stream length that is calculated from unique\n+                    \/\/ counter values.\n+                    keyStrLimit = chaCha20Block(startState, counter, keyStream);\n+                    counter += (keyStrLimit \/ KS_BLK_SIZE);\n+                    if (counter > finalCounterValue) {\n+                        keyStrLimit -= (int)(counter - finalCounterValue) * 64;\n+                    }\n@@ -1017,1 +1040,1 @@\n-                    ksRemain = keyStream.length;\n+                    ksRemain = keyStrLimit;\n@@ -1063,3 +1086,4 @@\n-        \/\/ Derive the Poly1305 key from the starting state\n-        byte[] serializedKey = new byte[KEYSTREAM_SIZE];\n-        chaCha20Block(startState, 0, serializedKey);\n+        \/\/ Derive the Poly1305 key from the starting state with the counter\n+        \/\/ value forced to zero.\n+        byte[] serializedKey = new byte[KS_MAX_LEN];\n+        chaCha20Block(startState, 0L, serializedKey);\n","filename":"src\/java.base\/share\/classes\/com\/sun\/crypto\/provider\/ChaCha20Cipher.java","additions":60,"deletions":36,"binary":false,"changes":96,"status":"modified"},{"patch":"@@ -0,0 +1,317 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.intrinsics.chacha;\n+\n+import javax.crypto.Cipher;\n+import javax.crypto.spec.ChaCha20ParameterSpec;\n+import javax.crypto.spec.SecretKeySpec;\n+import java.security.GeneralSecurityException;\n+import java.util.*;\n+\n+public class ExerciseChaCha20 {\n+\n+    private static final int WARMUP_CYCLES = 200000;\n+\n+    \/\/ Use the test vectors from RFC 7539 to exercise the ChaCha20 block\n+    \/\/ intrinsic\n+    public static final List<TestData> testList = List.of(\n+        new TestData(\"RFC 7539 Sample Test Vector\",\n+            \"000102030405060708090a0b0c0d0e0f101112131415161718191a1b1c1d1e1f\",\n+            \"000000000000004a00000000\",\n+            1, Cipher.ENCRYPT_MODE,\n+            \"4c616469657320616e642047656e746c656d656e206f662074686520636c6173\" +\n+            \"73206f66202739393a204966204920636f756c64206f6666657220796f75206f\" +\n+            \"6e6c79206f6e652074697020666f7220746865206675747572652c2073756e73\" +\n+            \"637265656e20776f756c642062652069742e\",\n+            null,\n+            \"6e2e359a2568f98041ba0728dd0d6981e97e7aec1d4360c20a27afccfd9fae0b\" +\n+            \"f91b65c5524733ab8f593dabcd62b3571639d624e65152ab8f530c359f0861d8\" +\n+            \"07ca0dbf500d6a6156a38e088a22b65e52bc514d16ccf806818ce91ab7793736\" +\n+            \"5af90bbf74a35be6b40b8eedf2785e42874d\"),\n+        new TestData(\"RFC 7539 Test Vector 1 (all zeroes)\",\n+            \"0000000000000000000000000000000000000000000000000000000000000000\",\n+            \"000000000000000000000000\",\n+            0, Cipher.ENCRYPT_MODE,\n+            \"0000000000000000000000000000000000000000000000000000000000000000\" +\n+            \"0000000000000000000000000000000000000000000000000000000000000000\",\n+            null,\n+            \"76b8e0ada0f13d90405d6ae55386bd28bdd219b8a08ded1aa836efcc8b770dc7\" +\n+            \"da41597c5157488d7724e03fb8d84a376a43b8f41518a11cc387b669b2ee6586\"),\n+        new TestData(\"RFC 7539 Test Vector 2\",\n+            \"0000000000000000000000000000000000000000000000000000000000000001\",\n+            \"000000000000000000000002\",\n+            1, Cipher.ENCRYPT_MODE,\n+            \"416e79207375626d697373696f6e20746f20746865204945544620696e74656e\" +\n+            \"6465642062792074686520436f6e7472696275746f7220666f72207075626c69\" +\n+            \"636174696f6e20617320616c6c206f722070617274206f6620616e2049455446\" +\n+            \"20496e7465726e65742d4472616674206f722052464320616e6420616e792073\" +\n+            \"746174656d656e74206d6164652077697468696e2074686520636f6e74657874\" +\n+            \"206f6620616e204945544620616374697669747920697320636f6e7369646572\" +\n+            \"656420616e20224945544620436f6e747269627574696f6e222e205375636820\" +\n+            \"73746174656d656e747320696e636c756465206f72616c2073746174656d656e\" +\n+            \"747320696e20494554462073657373696f6e732c2061732077656c6c20617320\" +\n+            \"7772697474656e20616e6420656c656374726f6e696320636f6d6d756e696361\" +\n+            \"74696f6e73206d61646520617420616e792074696d65206f7220706c6163652c\" +\n+            \"207768696368206172652061646472657373656420746f\",\n+            null,\n+            \"a3fbf07df3fa2fde4f376ca23e82737041605d9f4f4f57bd8cff2c1d4b7955ec\" +\n+            \"2a97948bd3722915c8f3d337f7d370050e9e96d647b7c39f56e031ca5eb6250d\" +\n+            \"4042e02785ececfa4b4bb5e8ead0440e20b6e8db09d881a7c6132f420e527950\" +\n+            \"42bdfa7773d8a9051447b3291ce1411c680465552aa6c405b7764d5e87bea85a\" +\n+            \"d00f8449ed8f72d0d662ab052691ca66424bc86d2df80ea41f43abf937d3259d\" +\n+            \"c4b2d0dfb48a6c9139ddd7f76966e928e635553ba76c5c879d7b35d49eb2e62b\" +\n+            \"0871cdac638939e25e8a1e0ef9d5280fa8ca328b351c3c765989cbcf3daa8b6c\" +\n+            \"cc3aaf9f3979c92b3720fc88dc95ed84a1be059c6499b9fda236e7e818b04b0b\" +\n+            \"c39c1e876b193bfe5569753f88128cc08aaa9b63d1a16f80ef2554d7189c411f\" +\n+            \"5869ca52c5b83fa36ff216b9c1d30062bebcfd2dc5bce0911934fda79a86f6e6\" +\n+            \"98ced759c3ff9b6477338f3da4f9cd8514ea9982ccafb341b2384dd902f3d1ab\" +\n+            \"7ac61dd29c6f21ba5b862f3730e37cfdc4fd806c22f221\"),\n+        new TestData(\"RFC 7539 Test Vector 3\",\n+            \"1c9240a5eb55d38af333888604f6b5f0473917c1402b80099dca5cbc207075c0\",\n+            \"000000000000000000000002\",\n+            42, Cipher.ENCRYPT_MODE,\n+            \"2754776173206272696c6c69672c20616e642074686520736c6974687920746f\" +\n+            \"7665730a446964206779726520616e642067696d626c6520696e207468652077\" +\n+            \"6162653a0a416c6c206d696d737920776572652074686520626f726f676f7665\" +\n+            \"732c0a416e6420746865206d6f6d65207261746873206f757467726162652e\",\n+            null,\n+            \"62e6347f95ed87a45ffae7426f27a1df5fb69110044c0d73118effa95b01e5cf\" +\n+            \"166d3df2d721caf9b21e5fb14c616871fd84c54f9d65b283196c7fe4f60553eb\" +\n+            \"f39c6402c42234e32a356b3e764312a61a5532055716ead6962568f87d3f3f77\" +\n+            \"04c6a8d1bcd1bf4d50d6154b6da731b187b58dfd728afa36757a797ac188d1\")\n+    );\n+\n+    public static class TestData {\n+        public TestData(String name, String keyStr, String nonceStr, int ctr,\n+                        int dir, String inputStr, String aadStr, String outStr) {\n+            testName = Objects.requireNonNull(name);\n+            HexFormat hex = HexFormat.of();\n+            key = hex.parseHex(Objects.requireNonNull(keyStr));\n+            nonce = hex.parseHex(Objects.requireNonNull(nonceStr));\n+            if ((counter = ctr) < 0) {\n+                throw new IllegalArgumentException(\n+                        \"counter must be 0 or greater\");\n+            }\n+            direction = dir;\n+            if ((direction != Cipher.ENCRYPT_MODE) &&\n+                    (direction != Cipher.DECRYPT_MODE)) {\n+                throw new IllegalArgumentException(\n+                        \"Direction must be ENCRYPT_MODE or DECRYPT_MODE\");\n+            }\n+            input = hex.parseHex(Objects.requireNonNull(inputStr));\n+            aad = (aadStr != null) ? hex.parseHex(aadStr) : null;\n+            expOutput = hex.parseHex(Objects.requireNonNull(outStr));\n+        }\n+\n+        public final String testName;\n+        public final byte[] key;\n+        public final byte[] nonce;\n+        public final int counter;\n+        public final int direction;\n+        public final byte[] input;\n+        public final byte[] aad;\n+        public final byte[] expOutput;\n+    }\n+\n+    public static void main(String[] args) throws Exception {\n+        int testsPassed = 0;\n+        int testNumber = 0;\n+\n+        \/\/ Use the first test vector to warm up the JVM and activate\n+        \/\/ the intrinsics.\n+        System.out.println(\"Running \" + WARMUP_CYCLES + \" warm up cycles\");\n+        for (int i = 0; i < WARMUP_CYCLES; i++) {\n+            runSinglePartTest(testList.get(0));\n+        }\n+\n+        System.out.println(\"----- Single-part Tests -----\");\n+        for (TestData test : testList) {\n+            System.out.println(\"*** Test \" + ++testNumber + \": \" +\n+                    test.testName);\n+            if (runSinglePartTest(test)) {\n+                testsPassed++;\n+            }\n+        }\n+        System.out.println();\n+\n+        System.out.println(\"----- Multi-part Tests -----\");\n+        for (TestData test : testList) {\n+            System.out.println(\"*** Test \" + ++testNumber + \": \" +\n+                    test.testName);\n+            if (runMultiPartTest(test)) {\n+                testsPassed++;\n+            }\n+        }\n+        System.out.println();\n+\n+        System.out.println(\"Total tests: \" + testNumber +\n+                \", Passed: \" + testsPassed + \", Failed: \" +\n+                (testNumber - testsPassed));\n+        if (testsPassed != testNumber) {\n+            throw new RuntimeException(\"One or more tests failed.  \" +\n+                    \"Check output for details\");\n+        }\n+    }\n+\n+    private static boolean runSinglePartTest(TestData testData)\n+            throws GeneralSecurityException {\n+        boolean encRes = false;\n+        boolean decRes = false;\n+        byte[] encryptedResult;\n+        byte[] decryptedResult;\n+\n+        \/\/ Get a Cipher instance and set up the parameters\n+        Cipher mambo = Cipher.getInstance(\"ChaCha20\");\n+        SecretKeySpec mamboKey = new SecretKeySpec(testData.key, \"ChaCha20\");\n+        ChaCha20ParameterSpec mamboSpec = new ChaCha20ParameterSpec(\n+                testData.nonce, testData.counter);\n+\n+        \/\/ Encrypt our input\n+        mambo.init(Cipher.ENCRYPT_MODE, mamboKey, mamboSpec);\n+        encryptedResult = mambo.doFinal(testData.input);\n+\n+        if (!Arrays.equals(encryptedResult, testData.expOutput)) {\n+            System.out.println(\"ERROR - Output Mismatch!\");\n+            System.out.println(\"Expected:\\n\" +\n+                    dumpHexBytes(testData.expOutput, 16, \"\\n\", \" \"));\n+            System.out.println(\"Actual:\\n\" +\n+                    dumpHexBytes(encryptedResult, 16, \"\\n\", \" \"));\n+            System.out.println();\n+        } else {\n+            encRes = true;\n+        }\n+\n+        \/\/ Decrypt the result of the encryption operation\n+        mambo = Cipher.getInstance(\"ChaCha20\");\n+        mambo.init(Cipher.DECRYPT_MODE, mamboKey, mamboSpec);\n+        decryptedResult = mambo.doFinal(encryptedResult);\n+\n+        if (!Arrays.equals(decryptedResult, testData.input)) {\n+            System.out.println(\"ERROR - Output Mismatch!\");\n+            System.out.println(\"Expected:\\n\" +\n+                    dumpHexBytes(testData.input, 16, \"\\n\", \" \"));\n+            System.out.println(\"Actual:\\n\" +\n+                    dumpHexBytes(decryptedResult, 16, \"\\n\", \" \"));\n+            System.out.println();\n+        } else {\n+            decRes = true;\n+        }\n+\n+        return (encRes && decRes);\n+    }\n+\n+    private static boolean runMultiPartTest(TestData testData)\n+            throws GeneralSecurityException {\n+        boolean encRes = false;\n+        boolean decRes = false;\n+\n+        \/\/ Get a cipher instance and initialize it\n+        Cipher mambo = Cipher.getInstance(\"ChaCha20\");\n+        SecretKeySpec mamboKey = new SecretKeySpec(testData.key, \"ChaCha20\");\n+        ChaCha20ParameterSpec mamboSpec = new ChaCha20ParameterSpec(\n+                testData.nonce, testData.counter);\n+\n+        byte[] encryptedResult = new byte[testData.input.length];\n+        mambo.init(Cipher.ENCRYPT_MODE, mamboKey, mamboSpec);\n+        System.out.print(\"Encrypt - \");\n+        doMulti(mambo, testData.input, encryptedResult);\n+\n+        if (!Arrays.equals(encryptedResult, testData.expOutput)) {\n+            System.out.println(\"ERROR - Output Mismatch!\");\n+            System.out.println(\"Expected:\\n\" +\n+                    dumpHexBytes(testData.expOutput));\n+            System.out.println(\"Actual:\\n\" +\n+                    dumpHexBytes(encryptedResult));\n+            System.out.println();\n+        } else {\n+            encRes = true;\n+        }\n+\n+        \/\/ Decrypt the result of the encryption operation\n+        mambo = Cipher.getInstance(\"ChaCha20\");\n+        byte[] decryptedResult = new byte[encryptedResult.length];\n+        mambo.init(Cipher.DECRYPT_MODE, mamboKey, mamboSpec);\n+        System.out.print(\"Decrypt - \");\n+        doMulti(mambo, encryptedResult, decryptedResult);\n+\n+        if (!Arrays.equals(decryptedResult, testData.input)) {\n+            System.out.println(\"ERROR - Output Mismatch!\");\n+            System.out.println(\"Expected:\\n\" + dumpHexBytes(testData.input));\n+            System.out.println(\"Actual:\\n\" + dumpHexBytes(decryptedResult));\n+            System.out.println();\n+        } else {\n+            decRes = true;\n+        }\n+\n+        return (encRes && decRes);\n+    }\n+\n+    private static void doMulti(Cipher c, byte[] input, byte[] output)\n+            throws GeneralSecurityException {\n+        int offset = 0;\n+        boolean done = false;\n+        Random randIn = new Random(System.currentTimeMillis());\n+\n+        \/\/ Send small updates between 1 - 8 bytes in length until we get\n+        \/\/ 8 or less bytes from the end of the input, then finalize.\n+        System.out.println(\"Input length: \" + input.length);\n+        System.out.print(\"Multipart (bytes in\/out): \");\n+        while (!done) {\n+            int mPartLen = randIn.nextInt(8) + 1;\n+            int bytesLeft = input.length - offset;\n+            int processed;\n+            if (mPartLen < bytesLeft) {\n+                System.out.print(mPartLen + \"\/\");\n+                processed = c.update(input, offset, mPartLen,\n+                        output, offset);\n+                offset += processed;\n+                System.out.print(processed + \" \");\n+            } else {\n+                processed = c.doFinal(input, offset, bytesLeft,\n+                        output, offset);\n+                System.out.print(bytesLeft + \"\/\" + processed + \" \");\n+                done = true;\n+            }\n+        }\n+        System.out.println();\n+    }\n+\n+    private static String dumpHexBytes(byte[] data) {\n+        return dumpHexBytes(data, 16, \"\\n\", \" \");\n+    }\n+\n+    private static String dumpHexBytes(byte[] data, int itemsPerLine,\n+           String lineDelim, String itemDelim) {\n+        StringBuilder sb = new StringBuilder();\n+        if (data != null) {\n+            for (int i = 0; i < data.length; i++) {\n+                if (i % itemsPerLine == 0 && i != 0) {\n+                    sb.append(lineDelim);\n+                }\n+                sb.append(String.format(\"%02X\", data[i])).append(itemDelim);\n+            }\n+        }\n+        return sb.toString();\n+    }\n+}\n\\ No newline at end of file\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/chacha\/ExerciseChaCha20.java","additions":317,"deletions":0,"binary":false,"changes":317,"status":"added"},{"patch":"@@ -0,0 +1,171 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.intrinsics.chacha;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import jdk.test.lib.Platform;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+import jdk.test.whitebox.cpuinfo.CPUInfo;\n+\n+\/**\n+ * @test\n+ * @bug 8247645\n+ * @summary ChaCha20 Intrinsics\n+ * @library \/test\/lib\n+ * @build   compiler.intrinsics.chacha.ExerciseChaCha20\n+ *          jdk.test.whitebox.WhiteBox\n+ * @run driver jdk.test.lib.helpers.ClassFileInstaller jdk.test.whitebox.WhiteBox\n+ * @run main\/othervm\/timeout=7200\n+ *      -Xbootclasspath\/a:. -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI\n+ *      compiler.intrinsics.chacha.TestChaCha20\n+ *\/\n+public class TestChaCha20 {\n+\n+    \/\/ Default to 1\/4 of the CPUs, and allow users to override.\n+    static final int MAX_PARALLELISM = Integer.getInteger(\"maxParallelism\",\n+        Math.max(1, Runtime.getRuntime().availableProcessors() \/ 4));\n+\n+    private static List<String> mix(List<String> o, String... mix) {\n+        List<String> n = new ArrayList<>(o);\n+        for (String m : mix) {\n+            n.add(m);\n+        }\n+        return n;\n+    }\n+\n+    private static boolean containsFuzzy(List<String> list, String sub) {\n+        for (String s : list) {\n+            if (s.contains(sub)) return true;\n+        }\n+        return false;\n+    }\n+\n+    public static void main(String... args) throws Exception {\n+        List<List<String>> configs = new ArrayList<>();\n+        List<String> cpuFeatures = CPUInfo.getFeatures();\n+\n+        System.out.print(\"CPU Features: \");\n+        cpuFeatures.forEach(f -> System.out.print(f + \" \"));\n+        System.out.println();\n+\n+        if (Platform.isX64()) {\n+            \/\/ If CPU features were not found, provide a default config.\n+            if (cpuFeatures.isEmpty()) {\n+                configs.add(new ArrayList());\n+            }\n+\n+            \/\/ Otherwise, select the tests that make sense on current platform.\n+            if (containsFuzzy(cpuFeatures, \"avx512\")) {\n+                System.out.println(\"Setting up AVX512 worker\");\n+                configs.add(List.of(\"-XX:UseAVX=3\"));\n+            }\n+            if (containsFuzzy(cpuFeatures, \"avx2\")) {\n+                System.out.println(\"Setting up AVX2 worker\");\n+                configs.add(List.of(\"-XX:UseAVX=2\"));\n+            }\n+            if (containsFuzzy(cpuFeatures, \"avx\")) {\n+                System.out.println(\"Setting up AVX worker\");\n+                configs.add(List.of(\"-XX:UseAVX=1\"));\n+            }\n+        } else if (Platform.isAArch64()) {\n+            \/\/ AArch64 intrinsics require the advanced simd instructions\n+            if (containsFuzzy(cpuFeatures, \"simd\")) {\n+                System.out.println(\"Setting up ASIMD worker\");\n+                configs.add(new ArrayList());\n+            }\n+        } else {\n+            \/\/ We only have ChaCha20 intrinsics on x64 and aarch64\n+            \/\/ currently.  If the platform is neither of these then\n+            \/\/ the ChaCha20 known answer tests in\n+            \/\/ com\/sun\/crypto\/provider\/Cipher are sufficient.\n+            return;\n+        }\n+\n+        \/\/ If by this point we have no configs, it means we are running\n+        \/\/ on a platform that intrinsics have been written for, but does\n+        \/\/ not possess the necessary instruction sets for that processor.\n+        \/\/ We can exit out if that is the case.\n+        if (configs.isEmpty()) {\n+            System.out.println(\"No intrinsics-capable configurations found\");\n+            return;\n+        }\n+\n+        \/\/ We can expand this array later to include other tests if new\n+        \/\/ ChaCha20 intrinsics are developed.\n+        String[] classNames = {\n+            \"compiler.intrinsics.chacha.ExerciseChaCha20\"\n+        };\n+\n+        ArrayList<Fork> forks = new ArrayList<>();\n+        int jobs = 0;\n+\n+        for (List<String> c : configs) {\n+            for (String className : classNames) {\n+                \/\/ Start a new job\n+                {\n+                    ProcessBuilder pb = ProcessTools.createTestJvm(\n+                            mix(c, \"-Xmx256m\", className));\n+                    Process p = pb.start();\n+                    OutputAnalyzer oa = new OutputAnalyzer(p);\n+                    forks.add(new Fork(p, oa));\n+                    jobs++;\n+                }\n+\n+                \/\/ Wait for the completion of other jobs\n+                while (jobs >= MAX_PARALLELISM) {\n+                    Fork f = findDone(forks);\n+                    if (f != null) {\n+                        OutputAnalyzer oa = f.oa();\n+                        oa.shouldHaveExitValue(0);\n+                        forks.remove(f);\n+                        jobs--;\n+                    } else {\n+                        \/\/ Nothing is done, wait a little.\n+                        Thread.sleep(200);\n+                    }\n+                }\n+            }\n+        }\n+\n+        \/\/ Drain the rest\n+        for (Fork f : forks) {\n+            OutputAnalyzer oa = f.oa();\n+            oa.shouldHaveExitValue(0);\n+        }\n+    }\n+\n+    private static Fork findDone(List<Fork> forks) {\n+        for (Fork f : forks) {\n+            if (!f.p().isAlive()) {\n+                return f;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    private static record Fork(Process p, OutputAnalyzer oa) {};\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/chacha\/TestChaCha20.java","additions":171,"deletions":0,"binary":false,"changes":171,"status":"added"},{"patch":"@@ -201,1 +201,1 @@\n-        @Param({\"1024\", \"\" + 16 * 1024})\n+        @Param({\"256\", \"1024\", \"4096\", \"16384\"})\n@@ -226,1 +226,1 @@\n-        @Param({\"1024\", \"\" + 16 * 1024})\n+        @Param({\"256\", \"1024\", \"4096\", \"16384\"})\n","filename":"test\/micro\/org\/openjdk\/bench\/javax\/crypto\/full\/CipherBench.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}