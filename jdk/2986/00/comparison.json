{"files":[{"patch":"@@ -48,0 +48,1 @@\n+#include \"utilities\/lockFreeQueue.inline.hpp\"\n@@ -119,101 +120,0 @@\n-#ifdef ASSERT\n-G1DirtyCardQueueSet::Queue::~Queue() {\n-  assert(_head == NULL, \"precondition\");\n-  assert(_tail == NULL, \"precondition\");\n-}\n-#endif \/\/ ASSERT\n-\n-BufferNode* G1DirtyCardQueueSet::Queue::top() const {\n-  return Atomic::load(&_head);\n-}\n-\n-\/\/ An append operation atomically exchanges the new tail with the queue tail.\n-\/\/ It then sets the \"next\" value of the old tail to the head of the list being\n-\/\/ appended; it is an invariant that the old tail's \"next\" value is NULL.\n-\/\/ But if the old tail is NULL then the queue was empty.  In this case the\n-\/\/ head of the list being appended is instead stored in the queue head; it is\n-\/\/ an invariant that the queue head is NULL in this case.\n-\/\/\n-\/\/ This means there is a period between the exchange and the old tail update\n-\/\/ where the queue sequence is split into two parts, the list from the queue\n-\/\/ head to the old tail, and the list being appended.  If there are concurrent\n-\/\/ push\/append operations, each may introduce another such segment.  But they\n-\/\/ all eventually get resolved by their respective updates of their old tail's\n-\/\/ \"next\" value.  This also means that pop operations must handle a buffer\n-\/\/ with a NULL \"next\" value specially.\n-\/\/\n-\/\/ A push operation is just a degenerate append, where the buffer being pushed\n-\/\/ is both the head and the tail of the list being appended.\n-void G1DirtyCardQueueSet::Queue::append(BufferNode& first, BufferNode& last) {\n-  assert(last.next() == NULL, \"precondition\");\n-  BufferNode* old_tail = Atomic::xchg(&_tail, &last);\n-  if (old_tail == NULL) {       \/\/ Was empty.\n-    Atomic::store(&_head, &first);\n-  } else {\n-    assert(old_tail->next() == NULL, \"invariant\");\n-    old_tail->set_next(&first);\n-  }\n-}\n-\n-BufferNode* G1DirtyCardQueueSet::Queue::pop() {\n-  Thread* current_thread = Thread::current();\n-  while (true) {\n-    \/\/ Use a critical section per iteration, rather than over the whole\n-    \/\/ operation.  We're not guaranteed to make progress.  Lingering in one\n-    \/\/ CS could lead to excessive allocation of buffers, because the CS\n-    \/\/ blocks return of released buffers to the free list for reuse.\n-    GlobalCounter::CriticalSection cs(current_thread);\n-\n-    BufferNode* result = Atomic::load_acquire(&_head);\n-    if (result == NULL) return NULL; \/\/ Queue is empty.\n-\n-    BufferNode* next = Atomic::load_acquire(BufferNode::next_ptr(*result));\n-    if (next != NULL) {\n-      \/\/ The \"usual\" lock-free pop from the head of a singly linked list.\n-      if (result == Atomic::cmpxchg(&_head, result, next)) {\n-        \/\/ Former head successfully taken; it is not the last.\n-        assert(Atomic::load(&_tail) != result, \"invariant\");\n-        assert(result->next() != NULL, \"invariant\");\n-        result->set_next(NULL);\n-        return result;\n-      }\n-      \/\/ Lost the race; try again.\n-      continue;\n-    }\n-\n-    \/\/ next is NULL.  This case is handled differently from the \"usual\"\n-    \/\/ lock-free pop from the head of a singly linked list.\n-\n-    \/\/ If _tail == result then result is the only element in the list. We can\n-    \/\/ remove it from the list by first setting _tail to NULL and then setting\n-    \/\/ _head to NULL, the order being important.  We set _tail with cmpxchg in\n-    \/\/ case of a concurrent push\/append\/pop also changing _tail.  If we win\n-    \/\/ then we've claimed result.\n-    if (Atomic::cmpxchg(&_tail, result, (BufferNode*)NULL) == result) {\n-      assert(result->next() == NULL, \"invariant\");\n-      \/\/ Now that we've claimed result, also set _head to NULL.  But we must\n-      \/\/ be careful of a concurrent push\/append after we NULLed _tail, since\n-      \/\/ it may have already performed its list-was-empty update of _head,\n-      \/\/ which we must not overwrite.\n-      Atomic::cmpxchg(&_head, result, (BufferNode*)NULL);\n-      return result;\n-    }\n-\n-    \/\/ If _head != result then we lost the race to take result; try again.\n-    if (result != Atomic::load_acquire(&_head)) {\n-      continue;\n-    }\n-\n-    \/\/ An in-progress concurrent operation interfered with taking the head\n-    \/\/ element when it was the only element.  A concurrent pop may have won\n-    \/\/ the race to clear the tail but not yet cleared the head. Alternatively,\n-    \/\/ a concurrent push\/append may have changed the tail but not yet linked\n-    \/\/ result->next().  We cannot take result in either case.  We don't just\n-    \/\/ try again, because we could spin for a long time waiting for that\n-    \/\/ concurrent operation to finish.  In the first case, returning NULL is\n-    \/\/ fine; we lost the race for the only element to another thread.  We\n-    \/\/ also return NULL for the second case, and let the caller cope.\n-    return NULL;\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.cpp","additions":1,"deletions":101,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"memory\/padded.hpp\"\n+#include \"utilities\/lockFreeQueue.hpp\"\n@@ -79,11 +79,1 @@\n-  \/\/ A lock-free FIFO of BufferNodes, linked through their next() fields.\n-  \/\/ This class has a restriction that pop() may return NULL when there are\n-  \/\/ buffers in the queue if there is a concurrent push\/append operation.\n-  class Queue {\n-    BufferNode* volatile _head;\n-    DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(BufferNode*));\n-    BufferNode* volatile _tail;\n-    DEFINE_PAD_MINUS_SIZE(2, DEFAULT_CACHE_LINE_SIZE, sizeof(BufferNode*));\n-\n-    NONCOPYABLE(Queue);\n-\n+  class Queue: public LockFreeQueue<BufferNode, &BufferNode::next_ptr, true \/*rcu_pop*\/> {\n@@ -91,20 +81,0 @@\n-    Queue() : _head(NULL), _tail(NULL) {}\n-    DEBUG_ONLY(~Queue();)\n-\n-    \/\/ Return the first buffer in the queue.\n-    \/\/ Thread-safe, but the result may change immediately.\n-    BufferNode* top() const;\n-\n-    \/\/ Thread-safe add the buffer to the end of the queue.\n-    void push(BufferNode& node) { append(node, node); }\n-\n-    \/\/ Thread-safe add the buffers from first to last to the end of the queue.\n-    void append(BufferNode& first, BufferNode& last);\n-\n-    \/\/ Thread-safe attempt to remove and return the first buffer in the queue.\n-    \/\/ Returns NULL if the queue is empty, or if a concurrent push\/append\n-    \/\/ interferes.  Uses GlobalCounter critical sections to address the ABA\n-    \/\/ problem; this works with the buffer allocator's use of GlobalCounter\n-    \/\/ synchronization.\n-    BufferNode* pop();\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.hpp","additions":2,"deletions":32,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -0,0 +1,118 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n+#define SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n+\n+#include \"memory\/padded.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+\/\/ The LockFreeQueue template provides a lock-free FIFO. Its structure\n+\/\/ and usage is similar to LockFreeStack. It has inner paddings, and\n+\/\/ optionally use GlobalCounter critical section in pop() to address\n+\/\/ the ABA problem. This class has a restriction that pop() may return\n+\/\/ NULL when there are objects in the queue if there is a concurrent\n+\/\/ push\/append operation.\n+\/\/\n+\/\/ \\tparam T is the class of the elements in the queue.\n+\/\/\n+\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n+\/\/ an object of type T must return a pointer to the list entry member\n+\/\/ of the object associated with the LockFreeQueue type.\n+\/\/\n+\/\/ \\tparam rcu_pop true if use GlobalCounter critical section in pop().\n+template<typename T, T* volatile* (*next_ptr)(T&), bool rcu_pop>\n+class LockFreeQueue {\n+  NONCOPYABLE(LockFreeQueue);\n+\n+protected:\n+  T* volatile _head;\n+  DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(T*));\n+  T* volatile _tail;\n+  DEFINE_PAD_MINUS_SIZE(2, DEFAULT_CACHE_LINE_SIZE, sizeof(T*));\n+\n+public:\n+  LockFreeQueue() : _head(NULL), _tail(NULL) {}\n+#ifdef ASSERT\n+  ~LockFreeQueue() {\n+    assert(_head == NULL, \"precondition\");\n+    assert(_tail == NULL, \"precondition\");\n+  }\n+#endif \/\/ ASSERT\n+\n+  \/\/ Return the first object in the queue.\n+  \/\/ Thread-safe, but the result may change immediately.\n+  T* top() const {\n+    return Atomic::load(&_head);\n+  }\n+\n+  \/\/ Thread-safe add the object to the end of the queue.\n+  void push(T& node) { append(node, node); }\n+\n+  \/\/ Thread-safe add the objects from first to last to the end of the queue.\n+  \/\/ An append operation atomically exchanges the new tail with the queue tail.\n+  \/\/ It then sets the \"next\" value of the old tail to the head of the list being\n+  \/\/ appended; it is an invariant that the old tail's \"next\" value is NULL.\n+  \/\/ But if the old tail is NULL then the queue was empty.  In this case the\n+  \/\/ head of the list being appended is instead stored in the queue head; it is\n+  \/\/ an invariant that the queue head is NULL in this case.\n+  \/\/\n+  \/\/ This means there is a period between the exchange and the old tail update\n+  \/\/ where the queue sequence is split into two parts, the list from the queue\n+  \/\/ head to the old tail, and the list being appended.  If there are concurrent\n+  \/\/ push\/append operations, each may introduce another such segment.  But they\n+  \/\/ all eventually get resolved by their respective updates of their old tail's\n+  \/\/ \"next\" value.  This also means that pop operations must handle an object\n+  \/\/ with a NULL \"next\" value specially.\n+  \/\/\n+  \/\/ A push operation is just a degenerate append, where the object being pushed\n+  \/\/ is both the head and the tail of the list being appended.\n+  void append(T& first, T& last) {\n+    assert(get_next(last) == NULL, \"precondition\");\n+    T* old_tail = Atomic::xchg(&_tail, &last);\n+    if (old_tail == NULL) {       \/\/ Was empty.\n+      Atomic::store(&_head, &first);\n+    } else {\n+      assert(get_next(*old_tail) == NULL, \"invariant\");\n+      Atomic::store(next_ptr(*old_tail), &first);\n+    }\n+  }\n+\n+  \/\/ Thread-safe attempt to remove and return the first object in the queue.\n+  \/\/ Returns NULL if the queue is empty, or if a concurrent push\/append\n+  \/\/ interferes.\n+  \/\/ If rcu_pop is true, it applies GlobalCounter critical sections to\n+  \/\/ address the ABA problem. This requires the object's\n+  \/\/ allocator use GlobalCounter synchronization to defer reusing object.\n+  T* pop();\n+\n+  \/\/ Return the entry following value in the list used by the\n+  \/\/ specialized LockFreeQueue class.\n+  static T* get_next(const T& value) {\n+    return Atomic::load(next_ptr(const_cast<T&>(value)));\n+  }\n+};\n+\n+#endif \/\/ SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n","filename":"src\/hotspot\/share\/utilities\/lockFreeQueue.hpp","additions":118,"deletions":0,"binary":false,"changes":118,"status":"added"},{"patch":"@@ -0,0 +1,113 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n+#define SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n+\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/thread.inline.hpp\"\n+#include \"utilities\/globalCounter.inline.hpp\"\n+#include \"utilities\/lockFreeQueue.hpp\"\n+\n+template<bool enable> class LockFreeQueueCriticalSection: public StackObj {\n+  Thread* _thread;\n+  GlobalCounter::CSContext _context;\n+public:\n+  inline LockFreeQueueCriticalSection(Thread* thread) {\n+    if (enable) {\n+      _thread = thread;\n+      _context = GlobalCounter::critical_section_begin(thread);\n+    }\n+  }\n+  inline ~LockFreeQueueCriticalSection() {\n+    if (enable) {\n+      GlobalCounter::critical_section_end(_thread, _context);\n+    }\n+  }\n+};\n+\n+template<typename T, T* volatile* (*next_ptr)(T&), bool rcu_pop>\n+T* LockFreeQueue<T, next_ptr, rcu_pop>::pop() {\n+  Thread* current_thread = Thread::current();\n+  while (true) {\n+    \/\/ Use a critical section per iteration, rather than over the whole\n+    \/\/ operation.  We're not guaranteed to make progress.  Lingering in one\n+    \/\/ CS could lead to excessive allocation of objects, because the CS\n+    \/\/ may block return of released objects to a free list for reuse.\n+    LockFreeQueueCriticalSection<rcu_pop> cs(current_thread);\n+\n+    T* result = Atomic::load_acquire(&_head);\n+    if (result == NULL) return NULL; \/\/ Queue is empty.\n+\n+    T* next = Atomic::load_acquire(next_ptr(*result));\n+    if (next != NULL) {\n+      \/\/ The \"usual\" lock-free pop from the head of a singly linked list.\n+      if (result == Atomic::cmpxchg(&_head, result, next)) {\n+        \/\/ Former head successfully taken; it is not the last.\n+        assert(Atomic::load(&_tail) != result, \"invariant\");\n+        assert(get_next(*result) != NULL, \"invariant\");\n+        *next_ptr(*result) = NULL;\n+        return result;\n+      }\n+      \/\/ Lost the race; try again.\n+      continue;\n+    }\n+\n+    \/\/ next is NULL.  This case is handled differently from the \"usual\"\n+    \/\/ lock-free pop from the head of a singly linked list.\n+\n+    \/\/ If _tail == result then result is the only element in the list. We can\n+    \/\/ remove it from the list by first setting _tail to NULL and then setting\n+    \/\/ _head to NULL, the order being important.  We set _tail with cmpxchg in\n+    \/\/ case of a concurrent push\/append\/pop also changing _tail.  If we win\n+    \/\/ then we've claimed result.\n+    if (Atomic::cmpxchg(&_tail, result, (T*)NULL) == result) {\n+      assert(get_next(*result) == NULL, \"invariant\");\n+      \/\/ Now that we've claimed result, also set _head to NULL.  But we must\n+      \/\/ be careful of a concurrent push\/append after we NULLed _tail, since\n+      \/\/ it may have already performed its list-was-empty update of _head,\n+      \/\/ which we must not overwrite.\n+      Atomic::cmpxchg(&_head, result, (T*)NULL);\n+      return result;\n+    }\n+\n+    \/\/ If _head != result then we lost the race to take result; try again.\n+    if (result != Atomic::load_acquire(&_head)) {\n+      continue;\n+    }\n+\n+    \/\/ An in-progress concurrent operation interfered with taking the head\n+    \/\/ element when it was the only element.  A concurrent pop may have won\n+    \/\/ the race to clear the tail but not yet cleared the head. Alternatively,\n+    \/\/ a concurrent push\/append may have changed the tail but not yet linked\n+    \/\/ result->next().  We cannot take result in either case.  We don't just\n+    \/\/ try again, because we could spin for a long time waiting for that\n+    \/\/ concurrent operation to finish.  In the first case, returning NULL is\n+    \/\/ fine; we lost the race for the only element to another thread.  We\n+    \/\/ also return NULL for the second case, and let the caller cope.\n+    return NULL;\n+  }\n+}\n+\n+#endif \/\/ SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n","filename":"src\/hotspot\/share\/utilities\/lockFreeQueue.inline.hpp","additions":113,"deletions":0,"binary":false,"changes":113,"status":"added"}]}