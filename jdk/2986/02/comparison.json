{"files":[{"patch":"@@ -48,0 +48,1 @@\n+#include \"utilities\/lockFreeQueue.inline.hpp\"\n@@ -49,0 +50,1 @@\n+#include \"utilities\/pair.hpp\"\n@@ -119,109 +121,0 @@\n-#ifdef ASSERT\n-G1DirtyCardQueueSet::Queue::~Queue() {\n-  assert(_head == NULL, \"precondition\");\n-  assert(_tail == NULL, \"precondition\");\n-}\n-#endif \/\/ ASSERT\n-\n-BufferNode* G1DirtyCardQueueSet::Queue::top() const {\n-  return Atomic::load(&_head);\n-}\n-\n-\/\/ An append operation atomically exchanges the new tail with the queue tail.\n-\/\/ It then sets the \"next\" value of the old tail to the head of the list being\n-\/\/ appended; it is an invariant that the old tail's \"next\" value is NULL.\n-\/\/ But if the old tail is NULL then the queue was empty.  In this case the\n-\/\/ head of the list being appended is instead stored in the queue head; it is\n-\/\/ an invariant that the queue head is NULL in this case.\n-\/\/\n-\/\/ This means there is a period between the exchange and the old tail update\n-\/\/ where the queue sequence is split into two parts, the list from the queue\n-\/\/ head to the old tail, and the list being appended.  If there are concurrent\n-\/\/ push\/append operations, each may introduce another such segment.  But they\n-\/\/ all eventually get resolved by their respective updates of their old tail's\n-\/\/ \"next\" value.  This also means that pop operations must handle a buffer\n-\/\/ with a NULL \"next\" value specially.\n-\/\/\n-\/\/ A push operation is just a degenerate append, where the buffer being pushed\n-\/\/ is both the head and the tail of the list being appended.\n-void G1DirtyCardQueueSet::Queue::append(BufferNode& first, BufferNode& last) {\n-  assert(last.next() == NULL, \"precondition\");\n-  BufferNode* old_tail = Atomic::xchg(&_tail, &last);\n-  if (old_tail == NULL) {       \/\/ Was empty.\n-    Atomic::store(&_head, &first);\n-  } else {\n-    assert(old_tail->next() == NULL, \"invariant\");\n-    old_tail->set_next(&first);\n-  }\n-}\n-\n-BufferNode* G1DirtyCardQueueSet::Queue::pop() {\n-  Thread* current_thread = Thread::current();\n-  while (true) {\n-    \/\/ Use a critical section per iteration, rather than over the whole\n-    \/\/ operation.  We're not guaranteed to make progress.  Lingering in one\n-    \/\/ CS could lead to excessive allocation of buffers, because the CS\n-    \/\/ blocks return of released buffers to the free list for reuse.\n-    GlobalCounter::CriticalSection cs(current_thread);\n-\n-    BufferNode* result = Atomic::load_acquire(&_head);\n-    if (result == NULL) return NULL; \/\/ Queue is empty.\n-\n-    BufferNode* next = Atomic::load_acquire(BufferNode::next_ptr(*result));\n-    if (next != NULL) {\n-      \/\/ The \"usual\" lock-free pop from the head of a singly linked list.\n-      if (result == Atomic::cmpxchg(&_head, result, next)) {\n-        \/\/ Former head successfully taken; it is not the last.\n-        assert(Atomic::load(&_tail) != result, \"invariant\");\n-        assert(result->next() != NULL, \"invariant\");\n-        result->set_next(NULL);\n-        return result;\n-      }\n-      \/\/ Lost the race; try again.\n-      continue;\n-    }\n-\n-    \/\/ next is NULL.  This case is handled differently from the \"usual\"\n-    \/\/ lock-free pop from the head of a singly linked list.\n-\n-    \/\/ If _tail == result then result is the only element in the list. We can\n-    \/\/ remove it from the list by first setting _tail to NULL and then setting\n-    \/\/ _head to NULL, the order being important.  We set _tail with cmpxchg in\n-    \/\/ case of a concurrent push\/append\/pop also changing _tail.  If we win\n-    \/\/ then we've claimed result.\n-    if (Atomic::cmpxchg(&_tail, result, (BufferNode*)NULL) == result) {\n-      assert(result->next() == NULL, \"invariant\");\n-      \/\/ Now that we've claimed result, also set _head to NULL.  But we must\n-      \/\/ be careful of a concurrent push\/append after we NULLed _tail, since\n-      \/\/ it may have already performed its list-was-empty update of _head,\n-      \/\/ which we must not overwrite.\n-      Atomic::cmpxchg(&_head, result, (BufferNode*)NULL);\n-      return result;\n-    }\n-\n-    \/\/ If _head != result then we lost the race to take result; try again.\n-    if (result != Atomic::load_acquire(&_head)) {\n-      continue;\n-    }\n-\n-    \/\/ An in-progress concurrent operation interfered with taking the head\n-    \/\/ element when it was the only element.  A concurrent pop may have won\n-    \/\/ the race to clear the tail but not yet cleared the head. Alternatively,\n-    \/\/ a concurrent push\/append may have changed the tail but not yet linked\n-    \/\/ result->next().  We cannot take result in either case.  We don't just\n-    \/\/ try again, because we could spin for a long time waiting for that\n-    \/\/ concurrent operation to finish.  In the first case, returning NULL is\n-    \/\/ fine; we lost the race for the only element to another thread.  We\n-    \/\/ also return NULL for the second case, and let the caller cope.\n-    return NULL;\n-  }\n-}\n-\n-G1DirtyCardQueueSet::HeadTail G1DirtyCardQueueSet::Queue::take_all() {\n-  assert_at_safepoint();\n-  HeadTail result(Atomic::load(&_head), Atomic::load(&_tail));\n-  Atomic::store(&_head, (BufferNode*)NULL);\n-  Atomic::store(&_tail, (BufferNode*)NULL);\n-  return result;\n-}\n-\n@@ -240,0 +133,38 @@\n+\/\/ Thread-safe attempt to remove and return the first buffer from\n+\/\/ the _completed queue, using the LockFreeQueue::try_pop() underneath.\n+\/\/ It has a restriction that it may return NULL when there are objects\n+\/\/ in the queue if there is a concurrent push\/append operation.\n+BufferNode* G1DirtyCardQueueSet::dequeue_completed_buffer() {\n+  using Status = LockFreeQueuePopStatus;\n+  Thread* current_thread = Thread::current();\n+  while (true) {\n+    \/\/ Use GlobalCounter critical section to avoid ABA problem.\n+    \/\/ The release of a buffer to its allocator's free list uses\n+    \/\/ GlobalCounter::write_synchronize() to coordinate with this\n+    \/\/ dequeuing operation.\n+    \/\/ We use a CS per iteration, rather than over the whole loop,\n+    \/\/ because we're not guaranteed to make progress. Lingering in\n+    \/\/ one CS could defer releasing buffer to the free list for reuse,\n+    \/\/ leading to excessive allocations.\n+    GlobalCounter::CriticalSection cs(current_thread);\n+    Pair<Status, BufferNode*> pop_result = _completed.try_pop();\n+    switch (pop_result.first) {\n+      case Status::success:\n+        return pop_result.second;\n+      case Status::operation_in_progress:\n+        \/\/ This could happen when a concurrent operation interferes with\n+        \/\/ this try_pop() taking the only element in the queue, in two cases:\n+        \/\/ (1) A concurrent try_pop() may have won the race to take the\n+        \/\/ element, but has not finished updating the queue. It is fine to\n+        \/\/ return NULL in this case.\n+        \/\/ (2) A concurrent push\/append is ongoing. We cannot take result,\n+        \/\/ and we don't just try again, because we could spin for a long time\n+        \/\/ waiting for the push\/append to finish. We just return NULL, which\n+        \/\/ is OK for a thread getting a buffer to refine.\n+        return NULL;\n+      case Status::lost_race:\n+        break;  \/\/ Try again.\n+    }\n+  }\n+}\n+\n@@ -241,1 +172,1 @@\n-  BufferNode* result = _completed.pop();\n+  BufferNode* result = dequeue_completed_buffer();\n@@ -244,1 +175,1 @@\n-    result = _completed.pop();\n+    result = dequeue_completed_buffer();\n@@ -428,1 +359,1 @@\n-  HeadTail buffers = _completed.take_all();\n+  Pair<BufferNode*, BufferNode*> pair = _completed.take_all();\n@@ -431,1 +362,1 @@\n-  return G1BufferNodeList(buffers._head, buffers._tail, num_cards);\n+  return G1BufferNodeList(pair.first, pair.second, num_cards);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.cpp","additions":44,"deletions":113,"binary":false,"changes":157,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"utilities\/lockFreeQueue.hpp\"\n@@ -79,37 +80,0 @@\n-  \/\/ A lock-free FIFO of BufferNodes, linked through their next() fields.\n-  \/\/ This class has a restriction that pop() may return NULL when there are\n-  \/\/ buffers in the queue if there is a concurrent push\/append operation.\n-  class Queue {\n-    BufferNode* volatile _head;\n-    DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(BufferNode*));\n-    BufferNode* volatile _tail;\n-    DEFINE_PAD_MINUS_SIZE(2, DEFAULT_CACHE_LINE_SIZE, sizeof(BufferNode*));\n-\n-    NONCOPYABLE(Queue);\n-\n-  public:\n-    Queue() : _head(NULL), _tail(NULL) {}\n-    DEBUG_ONLY(~Queue();)\n-\n-    \/\/ Return the first buffer in the queue.\n-    \/\/ Thread-safe, but the result may change immediately.\n-    BufferNode* top() const;\n-\n-    \/\/ Thread-safe add the buffer to the end of the queue.\n-    void push(BufferNode& node) { append(node, node); }\n-\n-    \/\/ Thread-safe add the buffers from first to last to the end of the queue.\n-    void append(BufferNode& first, BufferNode& last);\n-\n-    \/\/ Thread-safe attempt to remove and return the first buffer in the queue.\n-    \/\/ Returns NULL if the queue is empty, or if a concurrent push\/append\n-    \/\/ interferes.  Uses GlobalCounter critical sections to address the ABA\n-    \/\/ problem; this works with the buffer allocator's use of GlobalCounter\n-    \/\/ synchronization.\n-    BufferNode* pop();\n-\n-    \/\/ Take all the buffers from the queue, leaving the queue empty.\n-    \/\/ Not thread-safe.\n-    HeadTail take_all();\n-  };\n-\n@@ -203,1 +167,2 @@\n-  Queue _completed;           \/\/ Has inner padding, including trailer.\n+  \/\/ LockFreeQueue has inner padding, including trailer.\n+  LockFreeQueue<BufferNode, &BufferNode::next_ptr> _completed;\n@@ -205,1 +170,2 @@\n-  PausedBuffers _paused;      \/\/ Has inner padding, including trailer.\n+  \/\/ PausedBuffers has inner padding, including trailer.\n+  PausedBuffers _paused;\n@@ -251,0 +217,5 @@\n+  \/\/ Thread-safe attempt to remove and return the first buffer from\n+  \/\/ the _completed queue.\n+  \/\/ Returns NULL if the queue is empty, or if a concurrent push\/append\n+  \/\/ interferes. It uses GlobalCounter critical section to avoid ABA problem.\n+  BufferNode* dequeue_completed_buffer();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.hpp","additions":10,"deletions":39,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -0,0 +1,117 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n+#define SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n+\n+#include \"memory\/padded.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/pair.hpp\"\n+\n+\/\/ Return status of a LockFreeQueue::try_pop() call.\n+\/\/ See description for try_pop() below.\n+enum class LockFreeQueuePopStatus {\n+  success,\n+  lost_race,\n+  operation_in_progress\n+};\n+\n+\/\/ The LockFreeQueue template provides a lock-free FIFO. Its structure\n+\/\/ and usage is similar to LockFreeStack. It has inner paddings, and\n+\/\/ provides a try_pop() function for the client to implement pop()\n+\/\/ according to its need (e.g., whether or not to retry or prevent\n+\/\/ ABA problem).\n+\/\/\n+\/\/ \\tparam T is the class of the elements in the queue.\n+\/\/\n+\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n+\/\/ an object of type T must return a pointer to the list entry member\n+\/\/ of the object associated with the LockFreeQueue type.\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+class LockFreeQueue {\n+  T* volatile _head;\n+  DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(T*));\n+  T* volatile _tail;\n+  DEFINE_PAD_MINUS_SIZE(2, DEFAULT_CACHE_LINE_SIZE, sizeof(T*));\n+\n+  NONCOPYABLE(LockFreeQueue);\n+\n+  \/\/ Return the entry following node in the list used by the\n+  \/\/ specialized LockFreeQueue class.\n+  static inline T* next(const T& node);\n+\n+  \/\/ Set the entry following node to new_next in the list used by the\n+  \/\/ specialized LockFreeQueue class. Not thread-safe, as it cannot\n+  \/\/ concurrently run with push or try_pop operations that modify this\n+  \/\/ node.\n+  static inline void set_next(T& node, T* new_next);\n+\n+public:\n+  inline LockFreeQueue();\n+  DEBUG_ONLY(~LockFreeQueue();)\n+\n+  \/\/ Return the first object in the queue.\n+  \/\/ Thread-safe, but the result may change immediately.\n+  inline T* top() const;\n+\n+  \/\/ Return true if the queue is empty.\n+  inline bool empty() const { return top() == NULL; }\n+\n+  \/\/ Return the number of objects in the queue.\n+  \/\/ Not thread-safe. There must be no concurrent modification\n+  \/\/ while the length is being determined.\n+  inline size_t length() const;\n+\n+  \/\/ Thread-safe add the object to the end of the queue.\n+  inline void push(T& node) { append(node, node); }\n+\n+  \/\/ Thread-safe add the objects from first to last to the end of the queue.\n+  inline void append(T& first, T& last);\n+\n+  \/\/ Thread-safe attempt to remove and return the first object in the queue.\n+  \/\/ Returns a <LockFreeQueuePopStatus, T*> pair for the caller to determine\n+  \/\/ further operation. 3 possible cases depending on pair.first:\n+  \/\/ - success:\n+  \/\/   The operation succeeded. If pair.second is NULL, the queue is empty;\n+  \/\/   otherwise caller can assume ownership of the object pointed by\n+  \/\/   pair.second. Note that this case still subjects to ABA behavior;\n+  \/\/   callers must ensure usage is safe.\n+  \/\/ - lost_race:\n+  \/\/   An atomic operation failed. pair.second is NULL.\n+  \/\/   The caller can typically retry in this case.\n+  \/\/ - operation_in_progress:\n+  \/\/   An in-progress concurrent operation interfered with taking the element\n+  \/\/   when it was the only element in the queue. pair.second is NULL.\n+  \/\/   Retrying in this case has a higher chance of waiting for a long time\n+  \/\/   before succeeding, compared to the \"lost_race\" case.\n+  inline Pair<LockFreeQueuePopStatus, T*> try_pop();\n+\n+  \/\/ Take all the objects from the queue, leaving the queue empty.\n+  \/\/ Not thread-safe. It should only be used when there is no concurrent\n+  \/\/ push\/append\/try_pop operation.\n+  \/\/ Returns a pair of <head, tail> pointers to the current queue.\n+  inline Pair<T*, T*> take_all();\n+};\n+\n+#endif \/\/ SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n","filename":"src\/hotspot\/share\/utilities\/lockFreeQueue.hpp","additions":117,"deletions":0,"binary":false,"changes":117,"status":"added"},{"patch":"@@ -0,0 +1,164 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n+#define SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n+\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/lockFreeQueue.hpp\"\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* LockFreeQueue<T, next_ptr>::next(const T& node) {\n+  return Atomic::load(next_ptr(const_cast<T&>(node)));\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+void LockFreeQueue<T, next_ptr>::set_next(T& node, T* new_next) {\n+    Atomic::store(next_ptr(node), new_next);\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+LockFreeQueue<T, next_ptr>::LockFreeQueue() : _head(NULL), _tail(NULL) {}\n+\n+#ifdef ASSERT\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+LockFreeQueue<T, next_ptr>::~LockFreeQueue() {\n+  assert(_head == NULL, \"precondition\");\n+  assert(_tail == NULL, \"precondition\");\n+}\n+#endif\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* LockFreeQueue<T, next_ptr>::top() const {\n+  return Atomic::load(&_head);\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+size_t LockFreeQueue<T, next_ptr>::length() const {\n+  size_t result = 0;\n+  for (const T* current = top(); current != NULL; current = next(*current)) {\n+    ++result;\n+  }\n+  return result;\n+}\n+\n+\/\/ An append operation atomically exchanges the new tail with the queue tail.\n+\/\/ It then sets the \"next\" value of the old tail to the head of the list being\n+\/\/ appended; it is an invariant that the old tail's \"next\" value is NULL.\n+\/\/ But if the old tail is NULL then the queue was empty.  In this case the\n+\/\/ head of the list being appended is instead stored in the queue head; it is\n+\/\/ an invariant that the queue head is NULL in this case.\n+\/\/\n+\/\/ This means there is a period between the exchange and the old tail update\n+\/\/ where the queue sequence is split into two parts, the list from the queue\n+\/\/ head to the old tail, and the list being appended.  If there are concurrent\n+\/\/ push\/append operations, each may introduce another such segment.  But they\n+\/\/ all eventually get resolved by their respective updates of their old tail's\n+\/\/ \"next\" value.  This also means that try_pop operation must handle an object\n+\/\/ with a NULL \"next\" value specially.\n+\/\/\n+\/\/ A push operation is just a degenerate append, where the object being pushed\n+\/\/ is both the head and the tail of the list being appended.\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+void LockFreeQueue<T, next_ptr>::append(T& first, T& last) {\n+  assert(next(last) == NULL, \"precondition\");\n+  T* old_tail = Atomic::xchg(&_tail, &last);\n+  if (old_tail == NULL) {       \/\/ Was empty.\n+    Atomic::store(&_head, &first);\n+  } else {\n+    assert(next(*old_tail) == NULL, \"invariant\");\n+    set_next(*old_tail, &first);\n+  }\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+Pair<LockFreeQueuePopStatus, T*> LockFreeQueue<T, next_ptr>::try_pop() {\n+  typedef Pair<LockFreeQueuePopStatus, T*> StatusPair;\n+  \/\/ We only need memory_order_consume. Upgrade it to \"load_acquire\"\n+  \/\/ as the memory_order_consume API is not ready for use yet.\n+  T* result = Atomic::load_acquire(&_head);\n+  if (result == NULL) {\n+    \/\/ Queue is empty.\n+    return StatusPair(LockFreeQueuePopStatus::success, NULL);\n+  }\n+\n+  \/\/ This relaxed load is always followed by a cmpxchg(), thus it\n+  \/\/ is OK as the reader-side of the release-acquire ordering.\n+  T* next_node = Atomic::load(next_ptr(*result));\n+  if (next_node != NULL) {\n+    \/\/ The \"usual\" lock-free pop from the head of a singly linked list.\n+    if (result == Atomic::cmpxchg(&_head, result, next_node)) {\n+      \/\/ Former head successfully taken; it is not the last.\n+      assert(Atomic::load(&_tail) != result, \"invariant\");\n+      assert(next(*result) != NULL, \"invariant\");\n+      set_next(*result, NULL);\n+      return StatusPair(LockFreeQueuePopStatus::success, result);\n+    }\n+    \/\/ Lost the race; the caller should try again.\n+    return StatusPair(LockFreeQueuePopStatus::lost_race, NULL);\n+  }\n+\n+  \/\/ next is NULL.  This case is handled differently from the \"usual\"\n+  \/\/ lock-free pop from the head of a singly linked list.\n+\n+  \/\/ If _tail == result then result is the only element in the list. We can\n+  \/\/ remove it from the list by first setting _tail to NULL and then setting\n+  \/\/ _head to NULL, the order being important.  We set _tail with cmpxchg in\n+  \/\/ case of a concurrent push\/append\/try_pop also changing _tail.  If we win\n+  \/\/ then we've claimed result.\n+  if (Atomic::cmpxchg(&_tail, result, (T*)NULL) == result) {\n+    assert(next(*result) == NULL, \"invariant\");\n+    \/\/ Now that we've claimed result, also set _head to NULL.  But we must\n+    \/\/ be careful of a concurrent push\/append after we NULLed _tail, since\n+    \/\/ it may have already performed its list-was-empty update of _head,\n+    \/\/ which we must not overwrite.\n+    Atomic::cmpxchg(&_head, result, (T*)NULL);\n+    return StatusPair(LockFreeQueuePopStatus::success, result);\n+  }\n+\n+  \/\/ If _head != result then we lost the race to take result;\n+  \/\/ the caller should try again.\n+  if (result != Atomic::load_acquire(&_head)) {\n+    return StatusPair(LockFreeQueuePopStatus::lost_race, NULL);\n+  }\n+\n+  \/\/ An in-progress concurrent operation interfered with taking the head\n+  \/\/ element when it was the only element.  A concurrent try_pop may have won\n+  \/\/ the race to clear the tail but not yet cleared the head. Alternatively,\n+  \/\/ a concurrent push\/append may have changed the tail but not yet linked\n+  \/\/ result->next(). This case slightly differs from the \"lost_race\" case,\n+  \/\/ because the caller could wait for a long time for the other concurrent\n+  \/\/ operation to finish.\n+  return StatusPair(LockFreeQueuePopStatus::operation_in_progress, NULL);\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+Pair<T*, T*> LockFreeQueue<T, next_ptr>::take_all() {\n+  Pair<T*, T*> result(Atomic::load(&_head), Atomic::load(&_tail));\n+  Atomic::store(&_head, (T*)NULL);\n+  Atomic::store(&_tail, (T*)NULL);\n+  return result;\n+}\n+\n+#endif \/\/ SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n","filename":"src\/hotspot\/share\/utilities\/lockFreeQueue.inline.hpp","additions":164,"deletions":0,"binary":false,"changes":164,"status":"added"},{"patch":"@@ -0,0 +1,302 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/allocation.inline.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/lockFreeQueue.inline.hpp\"\n+#include \"utilities\/pair.hpp\"\n+#include \"threadHelper.inline.hpp\"\n+#include \"unittest.hpp\"\n+#include <new>\n+\n+class LockFreeQueueTestElement {\n+  typedef LockFreeQueueTestElement Element;\n+\n+  Element* volatile _entry;\n+  Element* volatile _entry1;\n+  size_t _id;\n+\n+  static Element* volatile* entry_ptr(Element& e) { return &e._entry; }\n+  static Element* volatile* entry1_ptr(Element& e) { return &e._entry1; }\n+\n+public:\n+  class TestQueue: public LockFreeQueue<Element, &entry_ptr> {\n+  public:\n+    Element* pop() {\n+      using Status = LockFreeQueuePopStatus;\n+      while (true) {\n+        Pair<Status, Element*> pop_result = try_pop();\n+        if (pop_result.first == Status::success) {\n+          return pop_result.second;\n+        }\n+        \/\/ Retry until success.\n+      }\n+    }\n+  };\n+  class TestQueue1: public LockFreeQueue<Element, &entry1_ptr> {\n+  public:\n+    Element* pop() {\n+      using Status = LockFreeQueuePopStatus;\n+      while (true) {\n+        Pair<Status, Element*> pop_result = try_pop();\n+        if (pop_result.first == Status::success) {\n+          return pop_result.second;\n+        }\n+        \/\/ Retry until success.\n+      }\n+    }\n+  };\n+\n+  LockFreeQueueTestElement(size_t id = 0) : _entry(), _entry1(), _id(id) {}\n+  size_t id() const { return _id; }\n+  void set_id(size_t value) { _id = value; }\n+  Element* next() { return _entry; }\n+  Element* next1() { return _entry1; }\n+};\n+\n+typedef LockFreeQueueTestElement Element;\n+typedef Element::TestQueue TestQueue;\n+typedef Element::TestQueue1 TestQueue1;\n+\n+static void initialize(Element* elements, size_t size, TestQueue* queue) {\n+  for (size_t i = 0; i < size; ++i) {\n+    elements[i].set_id(i);\n+  }\n+  ASSERT_TRUE(queue->empty());\n+  ASSERT_EQ(0u, queue->length());\n+  ASSERT_TRUE(queue->pop() == NULL);\n+  ASSERT_TRUE(queue->top() == NULL);\n+\n+  for (size_t id = 0; id < size; ++id) {\n+    ASSERT_EQ(id, queue->length());\n+    Element* e = &elements[id];\n+    ASSERT_EQ(id, e->id());\n+    queue->push(*e);\n+    ASSERT_FALSE(queue->empty());\n+    \/\/ top() is always the oldest element.\n+    ASSERT_EQ(&elements[0], queue->top());\n+  }\n+}\n+\n+class LockFreeQueueTestBasics : public ::testing::Test {\n+public:\n+  LockFreeQueueTestBasics();\n+\n+  static const size_t nelements = 10;\n+  Element elements[nelements];\n+  TestQueue queue;\n+};\n+\n+const size_t LockFreeQueueTestBasics::nelements;\n+\n+LockFreeQueueTestBasics::LockFreeQueueTestBasics() : queue() {\n+  initialize(elements, nelements, &queue);\n+}\n+\n+TEST_F(LockFreeQueueTestBasics, pop) {\n+  for (size_t i = 0; i < nelements; ++i) {\n+    ASSERT_FALSE(queue.empty());\n+    ASSERT_EQ(nelements - i, queue.length());\n+    Element* e = queue.pop();\n+    ASSERT_TRUE(e != NULL);\n+    ASSERT_EQ(&elements[i], e);\n+    ASSERT_EQ(i, e->id());\n+  }\n+  ASSERT_TRUE(queue.empty());\n+  ASSERT_EQ(0u, queue.length());\n+  ASSERT_TRUE(queue.pop() == NULL);\n+}\n+\n+TEST_F(LockFreeQueueTestBasics, append) {\n+  TestQueue other_queue;\n+  ASSERT_TRUE(other_queue.empty());\n+  ASSERT_EQ(0u, other_queue.length());\n+  ASSERT_TRUE(other_queue.top() == NULL);\n+  ASSERT_TRUE(other_queue.pop() == NULL);\n+\n+  Pair<Element*, Element*> pair = queue.take_all();\n+  other_queue.append(*pair.first, *pair.second);\n+  ASSERT_EQ(nelements, other_queue.length());\n+  ASSERT_TRUE(queue.empty());\n+  ASSERT_EQ(0u, queue.length());\n+  ASSERT_TRUE(queue.pop() == NULL);\n+  ASSERT_TRUE(queue.top() == NULL);\n+\n+  for (size_t i = 0; i < nelements; ++i) {\n+    ASSERT_EQ(nelements - i, other_queue.length());\n+    Element* e = other_queue.pop();\n+    ASSERT_TRUE(e != NULL);\n+    ASSERT_EQ(&elements[i], e);\n+    ASSERT_EQ(i, e->id());\n+  }\n+  ASSERT_EQ(0u, other_queue.length());\n+  ASSERT_TRUE(other_queue.pop() == NULL);\n+}\n+\n+TEST_F(LockFreeQueueTestBasics, two_queues) {\n+  TestQueue1 queue1;\n+  ASSERT_TRUE(queue1.pop() == NULL);\n+\n+  for (size_t id = 0; id < nelements; ++id) {\n+    queue1.push(elements[id]);\n+  }\n+  ASSERT_EQ(nelements, queue1.length());\n+  Element* e0 = queue.top();\n+  Element* e1 = queue1.top();\n+  while (true) {\n+    ASSERT_EQ(e0, e1);\n+    if (e0 == NULL) break;\n+    e0 = e0->next();\n+    e1 = e1->next1();\n+  }\n+\n+  for (size_t i = 0; i < nelements; ++i) {\n+    ASSERT_EQ(nelements - i, queue.length());\n+    ASSERT_EQ(nelements - i, queue1.length());\n+\n+    Element* e = queue.pop();\n+    ASSERT_TRUE(e != NULL);\n+    ASSERT_EQ(&elements[i], e);\n+    ASSERT_EQ(i, e->id());\n+\n+    Element* e1 = queue1.pop();\n+    ASSERT_TRUE(e1 != NULL);\n+    ASSERT_EQ(&elements[i], e1);\n+    ASSERT_EQ(i, e1->id());\n+\n+    ASSERT_EQ(e, e1);\n+  }\n+  ASSERT_EQ(0u, queue.length());\n+  ASSERT_EQ(0u, queue1.length());\n+  ASSERT_TRUE(queue.pop() == NULL);\n+  ASSERT_TRUE(queue1.pop() == NULL);\n+}\n+\n+class LockFreeQueueTestThread : public JavaTestThread {\n+  uint _id;\n+  TestQueue* _from;\n+  TestQueue* _to;\n+  volatile size_t* _processed;\n+  size_t _process_limit;\n+  size_t _local_processed;\n+  volatile bool _ready;\n+\n+public:\n+  LockFreeQueueTestThread(Semaphore* post,\n+                          uint id,\n+                          TestQueue* from,\n+                          TestQueue* to,\n+                          volatile size_t* processed,\n+                          size_t process_limit) :\n+    JavaTestThread(post),\n+    _id(id),\n+    _from(from),\n+    _to(to),\n+    _processed(processed),\n+    _process_limit(process_limit),\n+    _local_processed(0),\n+    _ready(false)\n+  {}\n+\n+  virtual void main_run() {\n+    Atomic::release_store_fence(&_ready, true);\n+    while (true) {\n+      Element* e = _from->pop();\n+      if (e != NULL) {\n+        _to->push(*e);\n+        Atomic::inc(_processed);\n+        ++_local_processed;\n+      } else if (Atomic::load_acquire(_processed) == _process_limit) {\n+        tty->print_cr(\"thread %u processed \" SIZE_FORMAT, _id, _local_processed);\n+        return;\n+      }\n+    }\n+  }\n+\n+  bool ready() const { return Atomic::load_acquire(&_ready); }\n+};\n+\n+TEST_VM(LockFreeQueueTest, stress) {\n+  Semaphore post;\n+  TestQueue initial_queue;\n+  TestQueue start_queue;\n+  TestQueue middle_queue;\n+  TestQueue final_queue;\n+  volatile size_t stage1_processed = 0;\n+  volatile size_t stage2_processed = 0;\n+\n+  const size_t nelements = 10000;\n+  Element* elements = NEW_C_HEAP_ARRAY(Element, nelements, mtOther);\n+  for (size_t id = 0; id < nelements; ++id) {\n+    ::new (&elements[id]) Element(id);\n+    initial_queue.push(elements[id]);\n+  }\n+  ASSERT_EQ(nelements, initial_queue.length());\n+\n+  \/\/ - stage1 threads pop from start_queue and push to middle_queue.\n+  \/\/ - stage2 threads pop from middle_queue and push to final_queue.\n+  \/\/ - all threads in a stage count the number of elements processed in\n+  \/\/   their corresponding stageN_processed counter.\n+\n+  const uint stage1_threads = 2;\n+  const uint stage2_threads = 2;\n+  const uint nthreads = stage1_threads + stage2_threads;\n+  LockFreeQueueTestThread* threads[nthreads] = {};\n+\n+  for (uint i = 0; i < ARRAY_SIZE(threads); ++i) {\n+    TestQueue* from = &start_queue;\n+    TestQueue* to = &middle_queue;\n+    volatile size_t* processed = &stage1_processed;\n+    if (i >= stage1_threads) {\n+      from = &middle_queue;\n+      to = &final_queue;\n+      processed = &stage2_processed;\n+    }\n+    threads[i] =\n+      new LockFreeQueueTestThread(&post, i, from, to, processed, nelements);\n+    threads[i]->doit();\n+    while (!threads[i]->ready()) {} \/\/ Wait until ready to start test.\n+  }\n+\n+  \/\/ Transfer elements to start_queue to start test.\n+  Pair<Element*, Element*> pair = initial_queue.take_all();\n+  start_queue.append(*pair.first, *pair.second);\n+\n+  \/\/ Wait for all threads to complete.\n+  for (uint i = 0; i < nthreads; ++i) {\n+    post.wait();\n+  }\n+\n+  \/\/ Verify expected state.\n+  ASSERT_EQ(nelements, stage1_processed);\n+  ASSERT_EQ(nelements, stage2_processed);\n+  ASSERT_EQ(0u, initial_queue.length());\n+  ASSERT_EQ(0u, start_queue.length());\n+  ASSERT_EQ(0u, middle_queue.length());\n+  ASSERT_EQ(nelements, final_queue.length());\n+  while (final_queue.pop() != NULL) {}\n+\n+  FREE_C_HEAP_ARRAY(Element, elements);\n+}\n","filename":"test\/hotspot\/gtest\/utilities\/test_lockFreeQueue.cpp","additions":302,"deletions":0,"binary":false,"changes":302,"status":"added"}]}