{"files":[{"patch":"@@ -243,2 +243,2 @@\n-      CFLAGS := $(CFLAGS_JDKLIB) -mavx512f -mavx512dq, \\\n-      CXXFLAGS := $(CXXFLAGS_JDKLIB) -mavx512f -mavx512dq, \\\n+      CFLAGS := $(CFLAGS_JDKLIB), \\\n+      CXXFLAGS := $(CXXFLAGS_JDKLIB), \\\n","filename":"make\/modules\/java.base\/Lib.gmk","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -390,0 +390,3 @@\n+        \"arraysort_stub\",\n+        { { TypeFunc::Parms, ShenandoahLoad },   { TypeFunc::Parms+1, ShenandoahStore },  { TypeFunc::Parms+2, ShenandoahLoad },\n+          { TypeFunc::Parms+4, ShenandoahLoad }, { TypeFunc::Parms+5, ShenandoahLoad } },\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -499,17 +499,0 @@\n-template <typename vtype, typename type_t>\n-static void qselect_32bit_(type_t *arr, int64_t pos, int64_t left,\n-                           int64_t right, int64_t max_iters) {\n-    \/*\n-     * Resort to std::sort if quicksort isnt making any progress\n-     *\/\n-    if (max_iters <= 0) {\n-        std::sort(arr + left, arr + right + 1);\n-        return;\n-    }\n-    \/*\n-     * Base case: use bitonic networks to sort arrays <= 128\n-     *\/\n-    if (right + 1 - left <= 128) {\n-        sort_128_32bit<vtype>(arr + left, (int32_t)(right + 1 - left));\n-        return;\n-    }\n@@ -517,10 +500,0 @@\n-    type_t pivot = get_pivot_32bit<vtype>(arr, left, right);\n-    type_t smallest = vtype::type_max();\n-    type_t biggest = vtype::type_min();\n-    int64_t pivot_index = partition_avx512_unrolled<vtype, 2>(\n-        arr, left, right + 1, pivot, &smallest, &biggest);\n-    if ((pivot != smallest) && (pos < pivot_index))\n-        qselect_32bit_<vtype>(arr, pos, left, pivot_index - 1, max_iters - 1);\n-    else if ((pivot != biggest) && (pos >= pivot_index))\n-        qselect_32bit_<vtype>(arr, pos, pivot_index, right, max_iters - 1);\n-}\n@@ -553,30 +526,0 @@\n-template <>\n-void avx512_qselect<int32_t>(int32_t *arr, int64_t k, int64_t arrsize,\n-                             bool hasnan) {\n-    if (arrsize > 1) {\n-        qselect_32bit_<zmm_vector<int32_t>, int32_t>(\n-            arr, k, 0, arrsize - 1, 2 * (int64_t)log2(arrsize));\n-    }\n-}\n-\n-template <>\n-void avx512_qselect<uint32_t>(uint32_t *arr, int64_t k, int64_t arrsize,\n-                              bool hasnan) {\n-    if (arrsize > 1) {\n-        qselect_32bit_<zmm_vector<uint32_t>, uint32_t>(\n-            arr, k, 0, arrsize - 1, 2 * (int64_t)log2(arrsize));\n-    }\n-}\n-\n-template <>\n-void avx512_qselect<float>(float *arr, int64_t k, int64_t arrsize,\n-                           bool hasnan) {\n-    int64_t indx_last_elem = arrsize - 1;\n-    if (UNLIKELY(hasnan)) {\n-        indx_last_elem = move_nans_to_end_of_array(arr, arrsize);\n-    }\n-    if (indx_last_elem >= k) {\n-        qselect_32bit_<zmm_vector<float>, float>(\n-            arr, k, 0, indx_last_elem, 2 * (int64_t)log2(indx_last_elem));\n-    }\n-}\n","filename":"src\/java.base\/linux\/native\/libavx512_x86_64\/avx512-32bit-qsort.hpp","additions":0,"deletions":57,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -145,90 +145,0 @@\n-struct ymm_vector<uint32_t> {\n-    using type_t = uint32_t;\n-    using zmm_t = __m256i;\n-    using zmmi_t = __m256i;\n-    using opmask_t = __mmask8;\n-    static const uint8_t numlanes = 8;\n-\n-    static type_t type_max() { return X86_SIMD_SORT_MAX_UINT32; }\n-    static type_t type_min() { return 0; }\n-    static zmm_t zmm_max() { return _mm256_set1_epi32(type_max()); }\n-\n-    static zmmi_t seti(int v1, int v2, int v3, int v4, int v5, int v6, int v7,\n-                       int v8) {\n-        return _mm256_set_epi32(v1, v2, v3, v4, v5, v6, v7, v8);\n-    }\n-    static opmask_t kxor_opmask(opmask_t x, opmask_t y) {\n-        return _kxor_mask8(x, y);\n-    }\n-    static opmask_t knot_opmask(opmask_t x) { return _knot_mask8(x); }\n-    static opmask_t le(zmm_t x, zmm_t y) {\n-        return _mm256_cmp_epu32_mask(x, y, _MM_CMPINT_LE);\n-    }\n-    static opmask_t ge(zmm_t x, zmm_t y) {\n-        return _mm256_cmp_epu32_mask(x, y, _MM_CMPINT_NLT);\n-    }\n-    static opmask_t eq(zmm_t x, zmm_t y) {\n-        return _mm256_cmp_epu32_mask(x, y, _MM_CMPINT_EQ);\n-    }\n-    template <int scale>\n-    static zmm_t mask_i64gather(zmm_t src, opmask_t mask, __m512i index,\n-                                void const *base) {\n-        return _mm512_mask_i64gather_epi32(src, mask, index, base, scale);\n-    }\n-    template <int scale>\n-    static zmm_t i64gather(__m512i index, void const *base) {\n-        return _mm512_i64gather_epi32(index, base, scale);\n-    }\n-    static zmm_t loadu(void const *mem) {\n-        return _mm256_loadu_si256((__m256i *)mem);\n-    }\n-    static zmm_t max(zmm_t x, zmm_t y) { return _mm256_max_epu32(x, y); }\n-    static void mask_compressstoreu(void *mem, opmask_t mask, zmm_t x) {\n-        return _mm256_mask_compressstoreu_epi32(mem, mask, x);\n-    }\n-    static zmm_t maskz_loadu(opmask_t mask, void const *mem) {\n-        return _mm256_maskz_loadu_epi32(mask, mem);\n-    }\n-    static zmm_t mask_loadu(zmm_t x, opmask_t mask, void const *mem) {\n-        return _mm256_mask_loadu_epi32(x, mask, mem);\n-    }\n-    static zmm_t mask_mov(zmm_t x, opmask_t mask, zmm_t y) {\n-        return _mm256_mask_mov_epi32(x, mask, y);\n-    }\n-    static void mask_storeu(void *mem, opmask_t mask, zmm_t x) {\n-        return _mm256_mask_storeu_epi32(mem, mask, x);\n-    }\n-    static zmm_t min(zmm_t x, zmm_t y) { return _mm256_min_epu32(x, y); }\n-    static zmm_t permutexvar(__m256i idx, zmm_t zmm) {\n-        return _mm256_permutexvar_epi32(idx, zmm);\n-    }\n-    static type_t reducemax(zmm_t v) {\n-        __m128i v128 = _mm_max_epu32(_mm256_castsi256_si128(v),\n-                                     _mm256_extracti128_si256(v, 1));\n-        __m128i v64 = _mm_max_epu32(\n-            v128, _mm_shuffle_epi32(v128, _MM_SHUFFLE(1, 0, 3, 2)));\n-        __m128i v32 =\n-            _mm_max_epu32(v64, _mm_shuffle_epi32(v64, _MM_SHUFFLE(0, 0, 0, 1)));\n-        return (type_t)_mm_cvtsi128_si32(v32);\n-    }\n-    static type_t reducemin(zmm_t v) {\n-        __m128i v128 = _mm_min_epu32(_mm256_castsi256_si128(v),\n-                                     _mm256_extracti128_si256(v, 1));\n-        __m128i v64 = _mm_min_epu32(\n-            v128, _mm_shuffle_epi32(v128, _MM_SHUFFLE(1, 0, 3, 2)));\n-        __m128i v32 =\n-            _mm_min_epu32(v64, _mm_shuffle_epi32(v64, _MM_SHUFFLE(0, 0, 0, 1)));\n-        return (type_t)_mm_cvtsi128_si32(v32);\n-    }\n-    static zmm_t set1(type_t v) { return _mm256_set1_epi32(v); }\n-    template <uint8_t mask, bool = (mask == 0b01010101)>\n-    static zmm_t shuffle(zmm_t zmm) {\n-        \/* Hack!: have to make shuffles within 128-bit lanes work for both\n-         * 32-bit and 64-bit *\/\n-        return _mm256_shuffle_epi32(zmm, 0b10110001);\n-    }\n-    static void storeu(void *mem, zmm_t x) {\n-        _mm256_storeu_si256((__m256i *)mem, x);\n-    }\n-};\n-template <>\n@@ -400,62 +310,0 @@\n-struct zmm_vector<uint64_t> {\n-    using type_t = uint64_t;\n-    using zmm_t = __m512i;\n-    using zmmi_t = __m512i;\n-    using ymm_t = __m512i;\n-    using opmask_t = __mmask8;\n-    static const uint8_t numlanes = 8;\n-\n-    static type_t type_max() { return X86_SIMD_SORT_MAX_UINT64; }\n-    static type_t type_min() { return 0; }\n-    static zmm_t zmm_max() { return _mm512_set1_epi64(type_max()); }\n-\n-    static zmmi_t seti(int v1, int v2, int v3, int v4, int v5, int v6, int v7,\n-                       int v8) {\n-        return _mm512_set_epi64(v1, v2, v3, v4, v5, v6, v7, v8);\n-    }\n-    template <int scale>\n-    static zmm_t mask_i64gather(zmm_t src, opmask_t mask, __m512i index,\n-                                void const *base) {\n-        return _mm512_mask_i64gather_epi64(src, mask, index, base, scale);\n-    }\n-    template <int scale>\n-    static zmm_t i64gather(__m512i index, void const *base) {\n-        return _mm512_i64gather_epi64(index, base, scale);\n-    }\n-    static opmask_t knot_opmask(opmask_t x) { return _knot_mask8(x); }\n-    static opmask_t ge(zmm_t x, zmm_t y) {\n-        return _mm512_cmp_epu64_mask(x, y, _MM_CMPINT_NLT);\n-    }\n-    static opmask_t eq(zmm_t x, zmm_t y) {\n-        return _mm512_cmp_epu64_mask(x, y, _MM_CMPINT_EQ);\n-    }\n-    static zmm_t loadu(void const *mem) { return _mm512_loadu_si512(mem); }\n-    static zmm_t max(zmm_t x, zmm_t y) { return _mm512_max_epu64(x, y); }\n-    static void mask_compressstoreu(void *mem, opmask_t mask, zmm_t x) {\n-        return _mm512_mask_compressstoreu_epi64(mem, mask, x);\n-    }\n-    static zmm_t mask_loadu(zmm_t x, opmask_t mask, void const *mem) {\n-        return _mm512_mask_loadu_epi64(x, mask, mem);\n-    }\n-    static zmm_t mask_mov(zmm_t x, opmask_t mask, zmm_t y) {\n-        return _mm512_mask_mov_epi64(x, mask, y);\n-    }\n-    static void mask_storeu(void *mem, opmask_t mask, zmm_t x) {\n-        return _mm512_mask_storeu_epi64(mem, mask, x);\n-    }\n-    static zmm_t min(zmm_t x, zmm_t y) { return _mm512_min_epu64(x, y); }\n-    static zmm_t permutexvar(__m512i idx, zmm_t zmm) {\n-        return _mm512_permutexvar_epi64(idx, zmm);\n-    }\n-    static type_t reducemax(zmm_t v) { return _mm512_reduce_max_epu64(v); }\n-    static type_t reducemin(zmm_t v) { return _mm512_reduce_min_epu64(v); }\n-    static zmm_t set1(type_t v) { return _mm512_set1_epi64(v); }\n-    template <uint8_t mask>\n-    static zmm_t shuffle(zmm_t zmm) {\n-        __m512d temp = _mm512_castsi512_pd(zmm);\n-        return _mm512_castpd_si512(\n-            _mm512_shuffle_pd(temp, temp, (_MM_PERM_ENUM)mask));\n-    }\n-    static void storeu(void *mem, zmm_t x) { _mm512_storeu_si512(mem, x); }\n-};\n-template <>\n","filename":"src\/java.base\/linux\/native\/libavx512_x86_64\/avx512-64bit-common.h","additions":0,"deletions":152,"binary":false,"changes":152,"status":"modified"},{"patch":"@@ -756,60 +756,0 @@\n-template <typename vtype, typename type_t>\n-static void qselect_64bit_(type_t *arr, int64_t pos, int64_t left,\n-                           int64_t right, int64_t max_iters) {\n-    \/*\n-     * Resort to std::sort if quicksort isnt making any progress\n-     *\/\n-    if (max_iters <= 0) {\n-        std::sort(arr + left, arr + right + 1);\n-        return;\n-    }\n-    \/*\n-     * Base case: use bitonic networks to sort arrays <= 128\n-     *\/\n-    if (right + 1 - left <= 128) {\n-        sort_128_64bit<vtype>(arr + left, (int32_t)(right + 1 - left));\n-        return;\n-    }\n-\n-    type_t pivot = get_pivot_64bit<vtype>(arr, left, right);\n-    type_t smallest = vtype::type_max();\n-    type_t biggest = vtype::type_min();\n-    int64_t pivot_index = partition_avx512_unrolled<vtype, 8>(\n-        arr, left, right + 1, pivot, &smallest, &biggest);\n-    if ((pivot != smallest) && (pos < pivot_index))\n-        qselect_64bit_<vtype>(arr, pos, left, pivot_index - 1, max_iters - 1);\n-    else if ((pivot != biggest) && (pos >= pivot_index))\n-        qselect_64bit_<vtype>(arr, pos, pivot_index, right, max_iters - 1);\n-}\n-\n-template <>\n-void avx512_qselect<int64_t>(int64_t *arr, int64_t k, int64_t arrsize,\n-                             bool hasnan) {\n-    if (arrsize > 1) {\n-        qselect_64bit_<zmm_vector<int64_t>, int64_t>(\n-            arr, k, 0, arrsize - 1, 2 * (int64_t)log2(arrsize));\n-    }\n-}\n-\n-template <>\n-void avx512_qselect<uint64_t>(uint64_t *arr, int64_t k, int64_t arrsize,\n-                              bool hasnan) {\n-    if (arrsize > 1) {\n-        qselect_64bit_<zmm_vector<uint64_t>, uint64_t>(\n-            arr, k, 0, arrsize - 1, 2 * (int64_t)log2(arrsize));\n-    }\n-}\n-\n-template <>\n-void avx512_qselect<double>(double *arr, int64_t k, int64_t arrsize,\n-                            bool hasnan) {\n-    int64_t indx_last_elem = arrsize - 1;\n-    if (UNLIKELY(hasnan)) {\n-        indx_last_elem = move_nans_to_end_of_array(arr, arrsize);\n-    }\n-    if (indx_last_elem >= k) {\n-        qselect_64bit_<zmm_vector<double>, double>(\n-            arr, k, 0, indx_last_elem, 2 * (int64_t)log2(indx_last_elem));\n-    }\n-}\n-\n@@ -824,8 +764,0 @@\n-template <>\n-void avx512_qsort<uint64_t>(uint64_t *arr, int64_t arrsize) {\n-    if (arrsize > 1) {\n-        qsort_64bit_<zmm_vector<uint64_t>, uint64_t>(\n-            arr, 0, arrsize - 1, 2 * (int64_t)log2(arrsize));\n-    }\n-}\n-\n","filename":"src\/java.base\/linux\/native\/libavx512_x86_64\/avx512-64bit-qsort.hpp","additions":0,"deletions":68,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -121,22 +121,0 @@\n-void avx512_qsort_fp16(uint16_t *arr, int64_t arrsize);\n-\n-template <typename T>\n-void avx512_qselect(T *arr, int64_t k, int64_t arrsize, bool hasnan = false);\n-void avx512_qselect_fp16(uint16_t *arr, int64_t k, int64_t arrsize,\n-                         bool hasnan = false);\n-\n-template <typename T>\n-inline void avx512_partial_qsort(T *arr, int64_t k, int64_t arrsize,\n-                                 bool hasnan = false) {\n-    avx512_qselect<T>(arr, k - 1, arrsize, hasnan);\n-    avx512_qsort<T>(arr, k - 1);\n-}\n-inline void avx512_partial_qsort_fp16(uint16_t *arr, int64_t k, int64_t arrsize,\n-                                      bool hasnan = false) {\n-    avx512_qselect_fp16(arr, k - 1, arrsize, hasnan);\n-    avx512_qsort_fp16(arr, k - 1);\n-}\n-\n-\/\/ key-value sort routines\n-template <typename T>\n-void avx512_qsort_kv(T *keys, uint64_t *indexes, int64_t arrsize);\n@@ -392,162 +370,0 @@\n-\/\/ Key-value sort helper functions\n-\n-template <typename vtype1, typename vtype2,\n-          typename zmm_t1 = typename vtype1::zmm_t,\n-          typename zmm_t2 = typename vtype2::zmm_t>\n-static void COEX(zmm_t1 &key1, zmm_t1 &key2, zmm_t2 &index1, zmm_t2 &index2) {\n-    zmm_t1 key_t1 = vtype1::min(key1, key2);\n-    zmm_t1 key_t2 = vtype1::max(key1, key2);\n-\n-    zmm_t2 index_t1 =\n-        vtype2::mask_mov(index2, vtype1::eq(key_t1, key1), index1);\n-    zmm_t2 index_t2 =\n-        vtype2::mask_mov(index1, vtype1::eq(key_t1, key1), index2);\n-\n-    key1 = key_t1;\n-    key2 = key_t2;\n-    index1 = index_t1;\n-    index2 = index_t2;\n-}\n-template <typename vtype1, typename vtype2,\n-          typename zmm_t1 = typename vtype1::zmm_t,\n-          typename zmm_t2 = typename vtype2::zmm_t,\n-          typename opmask_t = typename vtype1::opmask_t>\n-static inline zmm_t1 cmp_merge(zmm_t1 in1, zmm_t1 in2, zmm_t2 &indexes1,\n-                               zmm_t2 indexes2, opmask_t mask) {\n-    zmm_t1 tmp_keys = cmp_merge<vtype1>(in1, in2, mask);\n-    indexes1 = vtype2::mask_mov(indexes2, vtype1::eq(tmp_keys, in1), indexes1);\n-    return tmp_keys;  \/\/ 0 -> min, 1 -> max\n-}\n-\n-\/*\n- * Parition one ZMM register based on the pivot and returns the index of the\n- * last element that is less than equal to the pivot.\n- *\/\n-template <typename vtype1, typename vtype2,\n-          typename type_t1 = typename vtype1::type_t,\n-          typename type_t2 = typename vtype2::type_t,\n-          typename zmm_t1 = typename vtype1::zmm_t,\n-          typename zmm_t2 = typename vtype2::zmm_t>\n-static inline int32_t partition_vec(type_t1 *keys, type_t2 *indexes,\n-                                    int64_t left, int64_t right,\n-                                    const zmm_t1 keys_vec,\n-                                    const zmm_t2 indexes_vec,\n-                                    const zmm_t1 pivot_vec,\n-                                    zmm_t1 *smallest_vec, zmm_t1 *biggest_vec) {\n-    \/* which elements are larger than the pivot *\/\n-    typename vtype1::opmask_t gt_mask = vtype1::ge(keys_vec, pivot_vec);\n-    int32_t amount_gt_pivot = _mm_popcnt_u32((int32_t)gt_mask);\n-    vtype1::mask_compressstoreu(keys + left, vtype1::knot_opmask(gt_mask),\n-                                keys_vec);\n-    vtype1::mask_compressstoreu(keys + right - amount_gt_pivot, gt_mask,\n-                                keys_vec);\n-    vtype2::mask_compressstoreu(indexes + left, vtype2::knot_opmask(gt_mask),\n-                                indexes_vec);\n-    vtype2::mask_compressstoreu(indexes + right - amount_gt_pivot, gt_mask,\n-                                indexes_vec);\n-    *smallest_vec = vtype1::min(keys_vec, *smallest_vec);\n-    *biggest_vec = vtype1::max(keys_vec, *biggest_vec);\n-    return amount_gt_pivot;\n-}\n-\/*\n- * Parition an array based on the pivot and returns the index of the\n- * last element that is less than equal to the pivot.\n- *\/\n-template <typename vtype1, typename vtype2,\n-          typename type_t1 = typename vtype1::type_t,\n-          typename type_t2 = typename vtype2::type_t,\n-          typename zmm_t1 = typename vtype1::zmm_t,\n-          typename zmm_t2 = typename vtype2::zmm_t>\n-static inline int64_t partition_avx512(type_t1 *keys, type_t2 *indexes,\n-                                       int64_t left, int64_t right,\n-                                       type_t1 pivot, type_t1 *smallest,\n-                                       type_t1 *biggest) {\n-    \/* make array length divisible by vtype1::numlanes , shortening the array *\/\n-    for (int32_t i = (right - left) % vtype1::numlanes; i > 0; --i) {\n-        *smallest = std::min(*smallest, keys[left]);\n-        *biggest = std::max(*biggest, keys[left]);\n-        if (keys[left] > pivot) {\n-            right--;\n-            std::swap(keys[left], keys[right]);\n-            std::swap(indexes[left], indexes[right]);\n-        } else {\n-            ++left;\n-        }\n-    }\n-\n-    if (left == right)\n-        return left; \/* less than vtype1::numlanes elements in the array *\/\n-\n-    zmm_t1 pivot_vec = vtype1::set1(pivot);\n-    zmm_t1 min_vec = vtype1::set1(*smallest);\n-    zmm_t1 max_vec = vtype1::set1(*biggest);\n-\n-    if (right - left == vtype1::numlanes) {\n-        zmm_t1 keys_vec = vtype1::loadu(keys + left);\n-        int32_t amount_gt_pivot;\n-\n-        zmm_t2 indexes_vec = vtype2::loadu(indexes + left);\n-        amount_gt_pivot = partition_vec<vtype1, vtype2>(\n-            keys, indexes, left, left + vtype1::numlanes, keys_vec, indexes_vec,\n-            pivot_vec, &min_vec, &max_vec);\n-\n-        *smallest = vtype1::reducemin(min_vec);\n-        *biggest = vtype1::reducemax(max_vec);\n-        return left + (vtype1::numlanes - amount_gt_pivot);\n-    }\n-\n-    \/\/ first and last vtype1::numlanes values are partitioned at the end\n-    zmm_t1 keys_vec_left = vtype1::loadu(keys + left);\n-    zmm_t1 keys_vec_right = vtype1::loadu(keys + (right - vtype1::numlanes));\n-    zmm_t2 indexes_vec_left;\n-    zmm_t2 indexes_vec_right;\n-    indexes_vec_left = vtype2::loadu(indexes + left);\n-    indexes_vec_right = vtype2::loadu(indexes + (right - vtype1::numlanes));\n-\n-    \/\/ store points of the vectors\n-    int64_t r_store = right - vtype1::numlanes;\n-    int64_t l_store = left;\n-    \/\/ indices for loading the elements\n-    left += vtype1::numlanes;\n-    right -= vtype1::numlanes;\n-    while (right - left != 0) {\n-        zmm_t1 keys_vec;\n-        zmm_t2 indexes_vec;\n-        \/*\n-         * if fewer elements are stored on the right side of the array,\n-         * then next elements are loaded from the right side,\n-         * otherwise from the left side\n-         *\/\n-        if ((r_store + vtype1::numlanes) - right < left - l_store) {\n-            right -= vtype1::numlanes;\n-            keys_vec = vtype1::loadu(keys + right);\n-            indexes_vec = vtype2::loadu(indexes + right);\n-        } else {\n-            keys_vec = vtype1::loadu(keys + left);\n-            indexes_vec = vtype2::loadu(indexes + left);\n-            left += vtype1::numlanes;\n-        }\n-        \/\/ partition the current vector and save it on both sides of the array\n-        int32_t amount_gt_pivot;\n-\n-        amount_gt_pivot = partition_vec<vtype1, vtype2>(\n-            keys, indexes, l_store, r_store + vtype1::numlanes, keys_vec,\n-            indexes_vec, pivot_vec, &min_vec, &max_vec);\n-        r_store -= amount_gt_pivot;\n-        l_store += (vtype1::numlanes - amount_gt_pivot);\n-    }\n-\n-    \/* partition and save vec_left and vec_right *\/\n-    int32_t amount_gt_pivot;\n-    amount_gt_pivot = partition_vec<vtype1, vtype2>(\n-        keys, indexes, l_store, r_store + vtype1::numlanes, keys_vec_left,\n-        indexes_vec_left, pivot_vec, &min_vec, &max_vec);\n-    l_store += (vtype1::numlanes - amount_gt_pivot);\n-    amount_gt_pivot = partition_vec<vtype1, vtype2>(\n-        keys, indexes, l_store, l_store + vtype1::numlanes, keys_vec_right,\n-        indexes_vec_right, pivot_vec, &min_vec, &max_vec);\n-    l_store += (vtype1::numlanes - amount_gt_pivot);\n-    *smallest = vtype1::reducemin(min_vec);\n-    *biggest = vtype1::reducemax(max_vec);\n-    return l_store;\n-}\n","filename":"src\/java.base\/linux\/native\/libavx512_x86_64\/avx512-common-qsort.h","additions":0,"deletions":184,"binary":false,"changes":184,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#pragma GCC target(\"avx512dq\", \"avx512f\")\n","filename":"src\/java.base\/linux\/native\/libavx512_x86_64\/avxsort_linux_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-\n@@ -54,2 +53,0 @@\n-@Warmup(iterations = 3, time=60)\n-@Measurement(iterations = 3, time=120)\n@@ -59,4 +56,0 @@\n-\n-    @Param({\"10\",\"25\",\"50\",\"75\",\"100\", \"1000\", \"10000\", \"100000\"})\n-    private int size;\n-\n@@ -74,2 +67,1 @@\n-    @Setup\n-    public void setup() throws UnsupportedEncodingException, ClassNotFoundException, NoSuchMethodException, Throwable {\n+    public void initialize(int size) {\n@@ -101,1 +93,1 @@\n-    public void init() {\n+    public void clear() {\n@@ -132,0 +124,48 @@\n+    @Warmup(iterations = 3, time=2)\n+    @Measurement(iterations = 3, time=5)\n+    public static class Small extends ArraysSort {\n+        @Param({\"10\",\"25\",\"50\",\"75\",\"100\"})\n+        private int size;\n+\n+        @Setup\n+        public void setup() throws UnsupportedEncodingException, ClassNotFoundException, NoSuchMethodException, Throwable {\n+            initialize(size);\n+        }\n+    }\n+\n+    @Warmup(iterations = 3, time=2)\n+    @Measurement(iterations = 3, time=5)\n+    public static class Medium extends ArraysSort {\n+        @Param({\"1000\", \"10000\"})\n+        private int size;\n+\n+        @Setup\n+        public void setup() throws UnsupportedEncodingException, ClassNotFoundException, NoSuchMethodException, Throwable {\n+            initialize(size);\n+        }\n+    }\n+\n+    @Warmup(iterations = 3, time=20)\n+    @Measurement(iterations = 3, time=30)\n+    public static class Large extends ArraysSort {\n+        @Param({\"50000\", \"100000\"})\n+        private int size;\n+\n+        @Setup\n+        public void setup() throws UnsupportedEncodingException, ClassNotFoundException, NoSuchMethodException, Throwable {\n+            initialize(size);\n+        }\n+    }\n+\n+    @Warmup(iterations = 3, time=120)\n+    @Measurement(iterations = 3, time=30)\n+    public static class VeryLarge extends ArraysSort {\n+        @Param({\"1000000\"})\n+        private int size;\n+\n+        @Setup\n+        public void setup() throws UnsupportedEncodingException, ClassNotFoundException, NoSuchMethodException, Throwable {\n+            initialize(size);\n+        }\n+    }\n+\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/util\/ArraysSort.java","additions":50,"deletions":10,"binary":false,"changes":60,"status":"modified"}]}