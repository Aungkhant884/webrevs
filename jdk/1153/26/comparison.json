{"files":[{"patch":"@@ -2346,0 +2346,3 @@\n+  st->print(\"Page Sizes: \");\n+  _page_sizes.print_on(st);\n+  st->cr();\n@@ -3578,5 +3581,2 @@\n-size_t os::Linux::find_default_large_page_size() {\n-  if (_default_large_page_size != 0) {\n-    return _default_large_page_size;\n-  }\n-  size_t large_page_size = 0;\n+static size_t scan_default_large_page_size() {\n+  size_t default_large_page_size = 0;\n@@ -3587,1 +3587,1 @@\n-  \/\/ page as large as 256M.\n+  \/\/ page as large as 1G.\n@@ -3594,13 +3594,1 @@\n-  \/\/ format has been changed), we'll use the largest page size supported by\n-  \/\/ the processor.\n-\n-#ifndef ZERO\n-  large_page_size =\n-    AARCH64_ONLY(2 * M)\n-    AMD64_ONLY(2 * M)\n-    ARM32_ONLY(2 * M)\n-    IA32_ONLY(4 * M)\n-    IA64_ONLY(256 * M)\n-    PPC_ONLY(4 * M)\n-    S390_ONLY(1 * M);\n-#endif \/\/ ZERO\n+  \/\/ format has been changed), we'll set largest page size to 0\n@@ -3615,2 +3603,2 @@\n-          large_page_size = x * K;\n-          break;\n+          default_large_page_size = x * K;\n+          return default_large_page_size;\n@@ -3628,1 +3616,2 @@\n-  return large_page_size;\n+\n+  return default_large_page_size;\n@@ -3631,5 +3620,2 @@\n-size_t os::Linux::find_large_page_size(size_t large_page_size) {\n-  if (_default_large_page_size == 0) {\n-    _default_large_page_size = Linux::find_default_large_page_size();\n-  }\n-  \/\/ We need to scan \/sys\/kernel\/mm\/hugepages\n+static os::PageSizes scan_multiple_page_support() {\n+  \/\/ Scan \/sys\/kernel\/mm\/hugepages\n@@ -3638,0 +3624,1 @@\n+  static os::PageSizes page_sizes;\n@@ -3640,3 +3627,0 @@\n-  if (dir == NULL) {\n-    return _default_large_page_size;\n-  }\n@@ -3650,4 +3634,2 @@\n-      if (large_page_size == page_size * K) {\n-        closedir(dir);\n-        return large_page_size;\n-      }\n+      \/\/ Add each found Large Page Size to page_sizes\n+      page_sizes.add(page_size * K);\n@@ -3657,24 +3639,1 @@\n-  return _default_large_page_size;\n-}\n-\n-size_t os::Linux::setup_large_page_size() {\n-  _default_large_page_size = Linux::find_default_large_page_size();\n-\n-  if (!FLAG_IS_DEFAULT(LargePageSizeInBytes) && LargePageSizeInBytes != _default_large_page_size ) {\n-    _large_page_size = find_large_page_size(LargePageSizeInBytes);\n-    if (_large_page_size == _default_large_page_size) {\n-      warning(\"Setting LargePageSizeInBytes=\" SIZE_FORMAT \" has no effect on this OS. Using the default large page size \"\n-              SIZE_FORMAT \"%s.\",\n-              LargePageSizeInBytes,\n-              byte_size_in_proper_unit(_large_page_size), proper_unit_for_byte_size(_large_page_size));\n-    }\n-  } else {\n-    _large_page_size = _default_large_page_size;\n-  }\n-\n-  const size_t default_page_size = (size_t)Linux::page_size();\n-  if (_large_page_size > default_page_size) {\n-    _page_sizes.add(_large_page_size);\n-  }\n-\n-  return _large_page_size;\n+  return page_sizes;\n@@ -3736,0 +3695,2 @@\n+  \/\/ 1) Handle the case where we do not want to use huge pages and hence\n+  \/\/    there is no need to scan the OS for related info\n@@ -3753,2 +3714,50 @@\n-  size_t large_page_size = Linux::setup_large_page_size();\n-  UseLargePages          = Linux::setup_large_page_type(large_page_size);\n+  \/\/ 2) Scan OS info\n+  size_t default_large_page_size = scan_default_large_page_size();\n+  os::Linux::_default_large_page_size = default_large_page_size;\n+  if (default_large_page_size == 0) {\n+    \/\/ No large pages configured, return.\n+    UseTransparentHugePages = false;\n+    UseHugeTLBFS = false;\n+    UseSHM = false;\n+    return;\n+  }\n+  os::PageSizes all_large_pages = scan_multiple_page_support();\n+\n+  \/\/ 3) Consistency check and post-processing\n+\n+  \/\/ It is unclear if \/sys\/kernel\/mm\/hugepages\/ and \/proc\/meminfo could disagree. Manually\n+  \/\/ re-add the default page size to the list of page sizes to be sure.\n+  all_large_pages.add(default_large_page_size);\n+\n+  \/\/ Populate large page sizes to _page_sizes\n+  for (size_t page_size = all_large_pages.largest(); page_size != 0;\n+         page_size = all_large_pages.next_smaller(page_size)) {\n+    _page_sizes.add(page_size);\n+  }\n+\n+  LogTarget(Info, pagesize) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+    ls.print(\"Available page sizes: \");\n+    _page_sizes.print_on(&ls);\n+  }\n+\n+  \/\/ Handle LargePageSizeInBytes\n+  if (!FLAG_IS_DEFAULT(LargePageSizeInBytes) && LargePageSizeInBytes != default_large_page_size) {\n+    if (all_large_pages.contains(LargePageSizeInBytes)) {\n+      _large_page_size = LargePageSizeInBytes;\n+      log_info(os)(\"Overriding default large page size using LargePageSizeInBytes\");\n+    } else {\n+      _large_page_size = default_large_page_size;\n+      warning(\"Setting LargePageSizeInBytes=\" SIZE_FORMAT \" has no effect on this OS. Using the default large page size \"\n+              SIZE_FORMAT \"%s.\",\n+              LargePageSizeInBytes,\n+              byte_size_in_proper_unit(_large_page_size), proper_unit_for_byte_size(_large_page_size));\n+\n+    }\n+  } else {\n+      _large_page_size = default_large_page_size;\n+  }\n+\n+  \/\/ Now determine the type of large pages to use:\n+  UseLargePages = os::Linux::setup_large_page_type(_large_page_size);\n@@ -3903,2 +3912,2 @@\n-static void warn_on_large_pages_failure(char* req_addr, size_t bytes,\n-                                        int error) {\n+static void warn_on_commit_special_failure(char* req_addr, size_t bytes,\n+                                           size_t page_size, int error) {\n@@ -3914,2 +3923,4 @@\n-    jio_snprintf(msg, sizeof(msg), \"Failed to reserve large pages memory req_addr: \"\n-                 PTR_FORMAT \" bytes: \" SIZE_FORMAT \" (errno = %d).\", req_addr, bytes, error);\n+    jio_snprintf(msg, sizeof(msg), \"Failed to reserve and commit memory. req_addr: \"\n+                                   PTR_FORMAT \" bytes: \" SIZE_FORMAT \" page size: \"\n+                                   SIZE_FORMAT \" (errno = %d).\",\n+                                   req_addr, bytes, page_size, error);\n@@ -3920,6 +3931,8 @@\n-char* os::Linux::reserve_memory_special_huge_tlbfs_only(size_t bytes,\n-                                                        char* req_addr,\n-                                                        bool exec) {\n-  assert(UseLargePages && UseHugeTLBFS, \"only for Huge TLBFS large pages\");\n-  assert(is_aligned(bytes, os::large_page_size()), \"Unaligned size\");\n-  assert(is_aligned(req_addr, os::large_page_size()), \"Unaligned address\");\n+bool os::Linux::commit_memory_special(size_t bytes,\n+                                      size_t page_size,\n+                                      char* req_addr,\n+                                      bool exec) {\n+  assert(UseLargePages && UseHugeTLBFS, \"Should only get here when HugeTLBFS large pages are used\");\n+  assert(is_aligned(bytes, page_size), \"Unaligned size\");\n+  assert(is_aligned(req_addr, page_size), \"Unaligned address\");\n+  assert(req_addr != NULL, \"Must have a requested address for special mappings\");\n@@ -3928,3 +3941,1 @@\n-  int flags = MAP_PRIVATE|MAP_ANONYMOUS|MAP_HUGETLB;\n-  \/\/ Ensure the correct page size flag is used when needed.\n-  flags |= hugetlbfs_page_size_flag(os::large_page_size());\n+  int flags = MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED;\n@@ -3932,0 +3943,4 @@\n+  \/\/ For large pages additional flags are required.\n+  if (page_size > (size_t) os::vm_page_size()) {\n+    flags |= MAP_HUGETLB | hugetlbfs_page_size_flag(page_size);\n+  }\n@@ -3935,2 +3950,2 @@\n-    warn_on_large_pages_failure(req_addr, bytes, errno);\n-    return NULL;\n+    warn_on_commit_special_failure(req_addr, bytes, page_size, errno);\n+    return false;\n@@ -3939,3 +3954,8 @@\n-  assert(is_aligned(addr, os::large_page_size()), \"Must be\");\n-\n-  return addr;\n+  log_debug(pagesize)(\"Commit special mapping: \" PTR_FORMAT \", size=\" SIZE_FORMAT \"%s, page size=\"\n+                      SIZE_FORMAT \"%s\",\n+                      p2i(addr), byte_size_in_exact_unit(bytes),\n+                      exact_unit_for_byte_size(bytes),\n+                      byte_size_in_exact_unit(page_size),\n+                      exact_unit_for_byte_size(page_size));\n+  assert(is_aligned(addr, page_size), \"Must be\");\n+  return true;\n@@ -3944,14 +3964,14 @@\n-\/\/ Reserve memory using mmap(MAP_HUGETLB).\n-\/\/  - bytes shall be a multiple of alignment.\n-\/\/  - req_addr can be NULL. If not NULL, it must be a multiple of alignment.\n-\/\/  - alignment sets the alignment at which memory shall be allocated.\n-\/\/     It must be a multiple of allocation granularity.\n-\/\/ Returns address of memory or NULL. If req_addr was not NULL, will only return\n-\/\/  req_addr or NULL.\n-char* os::Linux::reserve_memory_special_huge_tlbfs_mixed(size_t bytes,\n-                                                         size_t alignment,\n-                                                         char* req_addr,\n-                                                         bool exec) {\n-  size_t large_page_size = os::large_page_size();\n-  assert(bytes >= large_page_size, \"Shouldn't allocate large pages for small sizes\");\n-\n+char* os::Linux::reserve_memory_special_huge_tlbfs(size_t bytes,\n+                                                   size_t alignment,\n+                                                   char* req_addr,\n+                                                   bool exec) {\n+  \/\/ Select large_page_size from _page_sizes\n+  \/\/ that is smaller than size_t bytes\n+  size_t large_page_size = os::page_size_for_region_aligned(bytes, 1);\n+\n+  assert(large_page_size > (size_t)os::vm_page_size(), \"large page size: \"\n+                                                        SIZE_FORMAT \" not larger than small page size: \"\n+                                                        SIZE_FORMAT,\n+                                                        large_page_size,\n+                                                        (size_t)os::vm_page_size());\n+  assert(UseLargePages && UseHugeTLBFS, \"only for Huge TLBFS large pages\");\n@@ -3959,20 +3979,4 @@\n-  assert(is_aligned(bytes, alignment), \"Must be\");\n-\n-  \/\/ First reserve - but not commit - the address range in small pages.\n-  char* const start = anon_mmap_aligned(req_addr, bytes, alignment);\n-\n-  if (start == NULL) {\n-    return NULL;\n-  }\n-\n-  assert(is_aligned(start, alignment), \"Must be\");\n-\n-  char* end = start + bytes;\n-\n-  \/\/ Find the regions of the allocated chunk that can be promoted to large pages.\n-  char* lp_start = align_up(start, large_page_size);\n-  char* lp_end   = align_down(end, large_page_size);\n-\n-  size_t lp_bytes = lp_end - lp_start;\n-\n-  assert(is_aligned(lp_bytes, large_page_size), \"Must be\");\n+  assert(is_aligned(req_addr, large_page_size), \"Must be\");\n+  assert(is_aligned(alignment, os::vm_allocation_granularity()), \"Must be\");\n+  assert(is_power_of_2(large_page_size), \"Must be\");\n+  assert(bytes >= large_page_size, \"Shouldn't allocate large pages for small sizes\");\n@@ -3980,4 +3984,11 @@\n-  if (lp_bytes == 0) {\n-    \/\/ The mapped region doesn't even span the start and the end of a large page.\n-    \/\/ Fall back to allocate a non-special area.\n-    ::munmap(start, end - start);\n+  \/\/ We only end up here when at least 1 large page can be used.\n+  \/\/ If the size is not a multiple of the large page size, we\n+  \/\/ will mix the type of pages used, but in a decending order.\n+  \/\/ Start off by reserving a range of the given size that is\n+  \/\/ properly aligned. At this point no pages are committed. If\n+  \/\/ a requested address is given it will be used and it must be\n+  \/\/ aligned to both the large page size and the given alignment.\n+  \/\/ The larger of the two will be used.\n+  size_t required_alignment = MAX(large_page_size, alignment);\n+  char* const aligned_start = anon_mmap_aligned(req_addr, bytes, required_alignment);\n+  if (aligned_start == NULL) {\n@@ -3987,3 +3998,3 @@\n-  int prot = exec ? PROT_READ|PROT_WRITE|PROT_EXEC : PROT_READ|PROT_WRITE;\n-  int flags = MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED;\n-  void* result;\n+  \/\/ First commit using large pages.\n+  size_t large_bytes = align_down(bytes, large_page_size);\n+  bool large_committed = commit_memory_special(large_bytes, large_page_size, aligned_start, exec);\n@@ -3991,7 +4002,4 @@\n-  \/\/ Commit small-paged leading area.\n-  if (start != lp_start) {\n-    result = ::mmap(start, lp_start - start, prot, flags, -1, 0);\n-    if (result == MAP_FAILED) {\n-      ::munmap(lp_start, end - lp_start);\n-      return NULL;\n-    }\n+  if (large_committed && bytes == large_bytes) {\n+    \/\/ The size was large page aligned so no additional work is\n+    \/\/ needed even if the commit failed.\n+    return aligned_start;\n@@ -4000,15 +4008,7 @@\n-  \/\/ Commit large-paged area.\n-  flags |= MAP_HUGETLB | hugetlbfs_page_size_flag(os::large_page_size());\n-\n-  result = ::mmap(lp_start, lp_bytes, prot, flags, -1, 0);\n-  if (result == MAP_FAILED) {\n-    warn_on_large_pages_failure(lp_start, lp_bytes, errno);\n-    \/\/ If the mmap above fails, the large pages region will be unmapped and we\n-    \/\/ have regions before and after with small pages. Release these regions.\n-    \/\/\n-    \/\/ |  mapped  |  unmapped  |  mapped  |\n-    \/\/ ^          ^            ^          ^\n-    \/\/ start      lp_start     lp_end     end\n-    \/\/\n-    ::munmap(start, lp_start - start);\n-    ::munmap(lp_end, end - lp_end);\n+  \/\/ The requested size requires some small pages as well.\n+  char* small_start = aligned_start + large_bytes;\n+  size_t small_size = bytes - large_bytes;\n+  if (!large_committed) {\n+    \/\/ Failed to commit large pages, so we need to unmap the\n+    \/\/ reminder of the orinal reservation.\n+    ::munmap(small_start, small_size);\n@@ -4018,28 +4018,7 @@\n-  \/\/ Commit small-paged trailing area.\n-  if (lp_end != end) {\n-    result = ::mmap(lp_end, end - lp_end, prot,\n-                    MAP_PRIVATE|MAP_ANONYMOUS|MAP_FIXED,\n-                    -1, 0);\n-    if (result == MAP_FAILED) {\n-      ::munmap(start, lp_end - start);\n-      return NULL;\n-    }\n-  }\n-\n-  return start;\n-}\n-\n-char* os::Linux::reserve_memory_special_huge_tlbfs(size_t bytes,\n-                                                   size_t alignment,\n-                                                   char* req_addr,\n-                                                   bool exec) {\n-  assert(UseLargePages && UseHugeTLBFS, \"only for Huge TLBFS large pages\");\n-  assert(is_aligned(req_addr, alignment), \"Must be\");\n-  assert(is_aligned(alignment, os::vm_allocation_granularity()), \"Must be\");\n-  assert(is_power_of_2(os::large_page_size()), \"Must be\");\n-  assert(bytes >= os::large_page_size(), \"Shouldn't allocate large pages for small sizes\");\n-\n-  if (is_aligned(bytes, os::large_page_size()) && alignment <= os::large_page_size()) {\n-    return reserve_memory_special_huge_tlbfs_only(bytes, req_addr, exec);\n-  } else {\n-    return reserve_memory_special_huge_tlbfs_mixed(bytes, alignment, req_addr, exec);\n+  \/\/ Commit the remaining bytes using small pages.\n+  bool small_committed = commit_memory_special(small_size, os::vm_page_size(), small_start, exec);\n+  if (!small_committed) {\n+    \/\/ Failed to commit the remaining size, need to unmap\n+    \/\/ the large pages part of the reservation.\n+    ::munmap(aligned_start, large_bytes);\n+    return NULL;\n@@ -4047,0 +4026,1 @@\n+  return aligned_start;\n","filename":"src\/hotspot\/os\/linux\/os_linux.cpp","additions":149,"deletions":169,"binary":false,"changes":318,"status":"modified"},{"patch":"@@ -81,3 +81,2 @@\n-  static size_t find_default_large_page_size();\n-  static size_t find_large_page_size(size_t page_size);\n-  static size_t setup_large_page_size();\n+  static size_t scan_default_large_page_size();\n+  static os::PageSizes scan_multiple_page_support();\n@@ -94,2 +93,1 @@\n-  static char* reserve_memory_special_huge_tlbfs_only(size_t bytes, char* req_addr, bool exec);\n-  static char* reserve_memory_special_huge_tlbfs_mixed(size_t bytes, size_t alignment, char* req_addr, bool exec);\n+  static bool commit_memory_special(size_t bytes, size_t page_size, char* req_addr, bool exec);\n","filename":"src\/hotspot\/os\/linux\/os_linux.hpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1481,1 +1481,1 @@\n-      if (page_size <= max_page_size) {\n+      if (page_size <= max_page_size && page_size > (size_t)vm_page_size()) {\n","filename":"src\/hotspot\/share\/runtime\/os.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -50,5 +50,2 @@\n-    static char* reserve_memory_special_huge_tlbfs_only(size_t bytes, char* req_addr, bool exec) {\n-      return os::Linux::reserve_memory_special_huge_tlbfs_only(bytes, req_addr, exec);\n-    }\n-    static char* reserve_memory_special_huge_tlbfs_mixed(size_t bytes, size_t alignment, char* req_addr, bool exec) {\n-      return os::Linux::reserve_memory_special_huge_tlbfs_mixed(bytes, alignment, req_addr, exec);\n+    static char* reserve_memory_special_huge_tlbfs(size_t bytes, size_t alignment, char* req_addr, bool exec) {\n+      return os::Linux::reserve_memory_special_huge_tlbfs(bytes, alignment, req_addr, exec);\n@@ -99,1 +96,1 @@\n-TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_only) {\n+TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_size_aligned) {\n@@ -106,1 +103,1 @@\n-    char* addr = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs_only(size, NULL, false);\n+    char* addr = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs(size, lp, NULL, false);\n@@ -115,1 +112,1 @@\n-TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_mixed_without_addr) {\n+TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_size_not_aligned_without_addr) {\n@@ -132,1 +129,1 @@\n-      char* p = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs_mixed(size, alignment, NULL, false);\n+      char* p = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs(size, alignment, NULL, false);\n@@ -142,1 +139,1 @@\n-TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_mixed_with_good_req_addr) {\n+TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_size_not_aligned_with_good_req_addr) {\n@@ -170,2 +167,3 @@\n-      char* const req_addr = align_up(mapping, alignment);\n-      char* p = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs_mixed(size, alignment, req_addr, false);\n+      \/\/ req_addr must be at least large page aligned.\n+      char* const req_addr = align_up(mapping, MAX2(alignment, lp));\n+      char* p = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs(size, alignment, req_addr, false);\n@@ -182,1 +180,1 @@\n-TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_mixed_with_bad_req_addr) {\n+TEST_VM(os_linux, reserve_memory_special_huge_tlbfs_size_not_aligned_with_bad_req_addr) {\n@@ -219,2 +217,3 @@\n-      char* const req_addr = align_up(mapping, alignment);\n-      char* p = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs_mixed(size, alignment, req_addr, false);\n+      \/\/ req_addr must be at least large page aligned.\n+      char* const req_addr = align_up(mapping, MAX2(alignment, lp));\n+      char* p = HugeTlbfsMemory::reserve_memory_special_huge_tlbfs(size, alignment, req_addr, false);\n@@ -257,1 +256,1 @@\n-  static void test_reserve_memory_special_huge_tlbfs_only(size_t size) {\n+  static void test_reserve_memory_special_huge_tlbfs_size_aligned(size_t size, size_t alignment) {\n@@ -262,1 +261,1 @@\n-    char* addr = os::Linux::reserve_memory_special_huge_tlbfs_only(size, NULL, false);\n+    char* addr = os::Linux::reserve_memory_special_huge_tlbfs(size, alignment, NULL, false);\n@@ -271,1 +270,1 @@\n-  static void test_reserve_memory_special_huge_tlbfs_only() {\n+  static void test_reserve_memory_special_huge_tlbfs_size_aligned() {\n@@ -279,1 +278,1 @@\n-      test_reserve_memory_special_huge_tlbfs_only(size);\n+      test_reserve_memory_special_huge_tlbfs_size_aligned(size, lp);\n@@ -283,1 +282,1 @@\n-  static void test_reserve_memory_special_huge_tlbfs_mixed() {\n+  static void test_reserve_memory_special_huge_tlbfs_size_not_aligned() {\n@@ -323,1 +322,1 @@\n-        char* p = os::Linux::reserve_memory_special_huge_tlbfs_mixed(size, alignment, NULL, false);\n+        char* p = os::Linux::reserve_memory_special_huge_tlbfs(size, alignment, NULL, false);\n@@ -336,2 +335,3 @@\n-        char* const req_addr = align_up(mapping1, alignment);\n-        char* p = os::Linux::reserve_memory_special_huge_tlbfs_mixed(size, alignment, req_addr, false);\n+        \/\/ req_addr must be at least large page aligned.\n+        char* const req_addr = align_up(mapping1, MAX2(alignment, lp));\n+        char* p = os::Linux::reserve_memory_special_huge_tlbfs(size, alignment, req_addr, false);\n@@ -350,2 +350,3 @@\n-        char* const req_addr = align_up(mapping2, alignment);\n-        char* p = os::Linux::reserve_memory_special_huge_tlbfs_mixed(size, alignment, req_addr, false);\n+        \/\/ req_addr must be at least large page aligned.\n+        char* const req_addr = align_up(mapping2, MAX2(alignment, lp));\n+        char* p = os::Linux::reserve_memory_special_huge_tlbfs(size, alignment, req_addr, false);\n@@ -367,2 +368,2 @@\n-    test_reserve_memory_special_huge_tlbfs_only();\n-    test_reserve_memory_special_huge_tlbfs_mixed();\n+    test_reserve_memory_special_huge_tlbfs_size_aligned();\n+    test_reserve_memory_special_huge_tlbfs_size_not_aligned();\n","filename":"test\/hotspot\/gtest\/runtime\/test_os_linux.cpp","additions":28,"deletions":27,"binary":false,"changes":55,"status":"modified"}]}