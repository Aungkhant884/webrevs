{"files":[{"patch":"@@ -33,0 +33,2 @@\n+#include \"utilities\/align.hpp\"\n+#include \"utilities\/debug.hpp\"\n@@ -35,0 +37,7 @@\n+\/\/ Pre-defined default chunk sizes must be arena-aligned, see Chunk::operator new()\n+STATIC_ASSERT(is_aligned((int)Chunk::tiny_size, ARENA_AMALLOC_ALIGNMENT));\n+STATIC_ASSERT(is_aligned((int)Chunk::init_size, ARENA_AMALLOC_ALIGNMENT));\n+STATIC_ASSERT(is_aligned((int)Chunk::medium_size, ARENA_AMALLOC_ALIGNMENT));\n+STATIC_ASSERT(is_aligned((int)Chunk::size, ARENA_AMALLOC_ALIGNMENT));\n+STATIC_ASSERT(is_aligned((int)Chunk::non_pool_size, ARENA_AMALLOC_ALIGNMENT));\n+\n@@ -174,7 +183,24 @@\n-void* Chunk::operator new (size_t requested_size, AllocFailType alloc_failmode, size_t length) throw() {\n-  \/\/ requested_size is equal to sizeof(Chunk) but in order for the arena\n-  \/\/ allocations to come out aligned as expected the size must be aligned\n-  \/\/ to expected arena alignment.\n-  \/\/ expect requested_size but if sizeof(Chunk) doesn't match isn't proper size we must align it.\n-  assert(ARENA_ALIGN(requested_size) == aligned_overhead_size(), \"Bad alignment\");\n-  size_t bytes = ARENA_ALIGN(requested_size) + length;\n+void* Chunk::operator new (size_t sizeofChunk, AllocFailType alloc_failmode, size_t length) throw() {\n+\n+  \/\/ - requested_size = sizeof(Chunk)\n+  \/\/ - length = payload size\n+  \/\/ We must ensure that the boundaries of the payload (C and D) are aligned to 64-bit:\n+  \/\/\n+  \/\/ +-----------+--+--------------------------------------------+\n+  \/\/ |           |g |                                            |\n+  \/\/ | Chunk     |a |               Payload                      |\n+  \/\/ |           |p |                                            |\n+  \/\/ +-----------+--+--------------------------------------------+\n+  \/\/ A           B  C                                            D\n+  \/\/\n+  \/\/ - The Chunk is allocated from C-heap, therefore its start address (A) should be\n+  \/\/   64-bit aligned on all our platforms, including 32-bit.\n+  \/\/ - sizeof(Chunk) (B) may not be aligned to 64-bit, and we have to take that into\n+  \/\/   account when calculating the Payload bottom (C) (see Chunk::bottom())\n+  \/\/ - the payload size (length) must be aligned to 64-bit, which takes care of 64-bit\n+  \/\/   aligning (D)\n+\n+  assert(sizeofChunk == sizeof(Chunk), \"weird request size\");\n+  assert(is_aligned(length, ARENA_AMALLOC_ALIGNMENT), \"chunk payload length misaligned: \"\n+         SIZE_FORMAT \".\", length);\n+  size_t bytes = ARENA_ALIGN(sizeofChunk) + length;\n@@ -191,0 +217,2 @@\n+     \/\/ We rely on arena alignment <= malloc alignment.\n+     assert(is_aligned(p, ARENA_AMALLOC_ALIGNMENT), \"Chunk start address misaligned.\");\n@@ -242,2 +270,1 @@\n-  size_t round_size = (sizeof (char *)) - 1;\n-  init_size = (init_size+round_size) & ~round_size;\n+  init_size = ARENA_ALIGN(init_size);\n@@ -343,1 +370,2 @@\n-  size_t len = MAX2(x, (size_t) Chunk::size);\n+  \/\/ (Note: all chunk sizes have to be 64-bit aligned)\n+  size_t len = MAX2(ARENA_ALIGN(x), (size_t) Chunk::size);\n","filename":"src\/hotspot\/share\/memory\/arena.cpp","additions":38,"deletions":10,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+    \/\/ Note: please keep these constants 64-bit aligned.\n@@ -59,1 +60,1 @@\n-    slack      = 20,            \/\/ suspected sizeof(Chunk) + internal malloc headers\n+    slack      = 24,            \/\/ suspected sizeof(Chunk) + internal malloc headers\n@@ -137,0 +138,5 @@\n+    \/\/ Amalloc guarantees 64-bit alignment and we need to ensure that in case the preceding\n+    \/\/ allocation was AmallocWords. Only needed on 32-bit - on 64-bit Amalloc and AmallocWords are\n+    \/\/ identical.\n+    assert(is_aligned(_max, ARENA_AMALLOC_ALIGNMENT), \"chunk end unaligned?\");\n+    NOT_LP64(_hwm = ARENA_ALIGN(_hwm));\n","filename":"src\/hotspot\/share\/memory\/arena.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -0,0 +1,70 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021 SAP SE. All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/arena.hpp\"\n+#include \"utilities\/align.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"unittest.hpp\"\n+\n+#ifndef LP64\n+\/\/ These tests below are about alignment issues when mixing Amalloc and AmallocWords.\n+\/\/ Since on 64-bit these APIs offer the same alignment, they only matter for 32-bit.\n+\n+TEST_VM(Arena, mixed_alignment_allocation) {\n+  \/\/ Test that mixed alignment allocations work and provide allocations with the correct\n+  \/\/ alignment\n+  Arena ar(mtTest);\n+  void* p1 = ar.AmallocWords(BytesPerWord);\n+  void* p2 = ar.Amalloc(BytesPerLong);\n+  ASSERT_TRUE(is_aligned(p1, BytesPerWord));\n+  ASSERT_TRUE(is_aligned(p2, ARENA_AMALLOC_ALIGNMENT));\n+}\n+\n+TEST_VM(Arena, Arena_with_crooked_initial_size) {\n+  \/\/ Test that an arena with a crooked, not 64-bit aligned initial size\n+  \/\/ works\n+  Arena ar(mtTest, 4097);\n+  void* p1 = ar.AmallocWords(BytesPerWord);\n+  void* p2 = ar.Amalloc(BytesPerLong);\n+  ASSERT_TRUE(is_aligned(p1, BytesPerWord));\n+  ASSERT_TRUE(is_aligned(p2, ARENA_AMALLOC_ALIGNMENT));\n+}\n+\n+TEST_VM(Arena, Arena_grows_large_unaligned) {\n+  \/\/ Test that if the arena grows with a large unaligned value, nothing bad happens.\n+  \/\/ We trigger allocation of a new, large, unaligned chunk with a non-standard size\n+  \/\/ (only possible on 32-bit when allocating with word alignment).\n+  \/\/ Then we alloc some more. If Arena::grow() does not correctly align, on 32-bit\n+  \/\/ something should assert at some point.\n+  Arena ar(mtTest, 100); \/\/ first chunk is small\n+  void* p = ar.AmallocWords(Chunk::size + BytesPerWord); \/\/ if Arena::grow() misaligns, this asserts\n+  \/\/ some more allocations for good measure\n+  for (int i = 0; i < 100; i ++) {\n+    ar.Amalloc(1);\n+  }\n+}\n+\n+#endif \/\/  LP64\n","filename":"test\/hotspot\/gtest\/memory\/test_arena.cpp","additions":70,"deletions":0,"binary":false,"changes":70,"status":"added"}]}