{"files":[{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 1997, 2018, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2012, 2015 SAP SE. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2021 SAP SE. All rights reserved.\n@@ -347,0 +347,22 @@\n+\/\/ Generate prefixed or non-prefixed addi, or addis based on the immediate value\n+\/\/ Emit a nop if a prefixed addi is going to cross a 64-byte boundary.\n+\/\/ (See Section 1.6 of Power ISA Version 3.1)\n+void Assembler::paddi_or_addi(Register d, Register s, long si34) {\n+  if (is_simm16(si34)) {\n+    addi_r0ok(d, s, (int)si34);\n+  } else if (is_simm32(si34) && (si34 & 0xffff) == 0) {\n+    addis_r0ok(d, s, (int)si34 >> 16);\n+  } else {\n+    if (is_aligned(reinterpret_cast<uintptr_t>(pc()) + BytesPerInstWord, 64) ||\n+        code_section()->scratch_emit()) {\n+      \/\/ Always emit a nop if the target is a scratch buffer, otherwise fill_buffer() may raise\n+      \/\/ an assertion failure because the size of actually generated code can be larger than that\n+      \/\/ in scratch_emit phase. A difference of code buffer addresses for the two phases can result\n+      \/\/ in different number of nops for alignment. By emitting a nop before every paddi, we avoid\n+      \/\/ buffer overrun in acrual code generation phase.\n+      nop();\n+    }\n+    paddi_r0ok(d, s, si34);\n+  }\n+}\n+\n@@ -350,1 +372,2 @@\n-int Assembler::load_const_optimized(Register d, long x, Register tmp, bool return_simm16_rest) {\n+int Assembler::load_const_optimized(Register d, long x, Register tmp,\n+                                    bool return_simm16_rest, bool fixed_size) {\n@@ -372,0 +395,4 @@\n+  \/\/ pli can require a nop for alignement depending on the code address, so we don't use pli\n+  \/\/ when the caller expects the number of generated code is always the same.\n+  bool use_pli = (PowerArchitecturePPC64 >= 10 && !fixed_size);\n+\n@@ -374,6 +401,0 @@\n-      lis(d, x >> 16);\n-      if (xd) ori(d, d, (unsigned short)xd);\n-    } else {\n-      \/\/ 64-bit value: x = xa xb xc xd\n-      xa = (x >> 48) & 0xffff;\n-      xb = (x >> 32) & 0xffff;\n@@ -381,5 +402,4 @@\n-      bool xa_loaded = (xb & 0x8000) ? (xa != -1) : (xa != 0);\n-      if (tmp == noreg || (xc == 0 && xd == 0)) {\n-        if (xa_loaded) {\n-          lis(d, xa);\n-          if (xb) { ori(d, d, (unsigned short)xb); }\n+      bool xc_loaded = (xd & 0x8000) ? (xc != -1) : (xc != 0);\n+      if (xc_loaded) {\n+        if (xd && use_pli) {\n+          pli_or_li(d, x);\n@@ -387,13 +407,1 @@\n-          li(d, xb);\n-        }\n-        sldi(d, d, 32);\n-        if (xc) { oris(d, d, (unsigned short)xc); }\n-        if (xd) { ori( d, d, (unsigned short)xd); }\n-      } else {\n-        \/\/ Exploit instruction level parallelism if we have a tmp register.\n-        bool xc_loaded = (xd & 0x8000) ? (xc != -1) : (xc != 0);\n-        if (xa_loaded) {\n-          lis(tmp, xa);\n-        }\n-        if (xc_loaded) {\n-          lis(d, xc);\n+          lis(d, x >> 16);\n@@ -401,2 +409,19 @@\n-        if (xa_loaded) {\n-          if (xb) { ori(tmp, tmp, (unsigned short)xb); }\n+      }\n+      if (xd && !use_pli) ori(d, d, (unsigned short)xd);\n+    } else {\n+      if (use_pli) {\n+        \/\/ 64-bit value: x = xA xB\n+        int32_t xA, xB; \/\/ Two 32-bit chunks of const.\n+        xA = (x >> 32) & 0xffffffff;\n+        xB = x & 0xffffffff;    \/\/ Lower 32-bit chunk.\n+        bool xA_loaded = (xB & 0x80000000) ? (xA != -1) : (xA != 0);\n+        if (tmp == noreg || xB == 0) {\n+          if (xA_loaded) {\n+            pli_or_li(d, xA);\n+            xc = (x >> 16) & 0xffff;\n+            sldi(d, d, 32);\n+            if (xc) { oris(d, d, (unsigned short)xc); }\n+            if (xd) { ori( d, d, (unsigned short)xd); }\n+          } else if (xB) {\n+            pli_or_li(d, xB);\n+          }\n@@ -404,1 +429,7 @@\n-          li(tmp, xb);\n+          if (xA_loaded) {\n+            pli_or_li(tmp, xA);\n+            pli_or_li(d, xB);\n+            insrdi(d, tmp, 32, 0);\n+          } else {\n+            pli_or_li(d, xB);\n+          }\n@@ -406,2 +437,16 @@\n-        if (xc_loaded) {\n-          if (xd) { ori(d, d, (unsigned short)xd); }\n+      } else {\n+        \/\/ 64-bit value: x = xa xb xc xd\n+        xa = (x >> 48) & 0xffff;\n+        xb = (x >> 32) & 0xffff;\n+        xc = (x >> 16) & 0xffff;\n+        bool xa_loaded = (xb & 0x8000) ? (xa != -1) : (xa != 0);\n+        if (tmp == noreg || (xc == 0 && xd == 0)) {\n+          if (xa_loaded) {\n+            lis(d, xa);\n+            if (xb) { ori(d, d, (unsigned short)xb); }\n+          } else {\n+            li(d, xb);\n+          }\n+          sldi(d, d, 32);\n+          if (xc) { oris(d, d, (unsigned short)xc); }\n+          if (xd) { ori( d, d, (unsigned short)xd); }\n@@ -409,1 +454,19 @@\n-          li(d, xd);\n+          \/\/ Exploit instruction level parallelism if we have a tmp register.\n+          bool xc_loaded = (xd & 0x8000) ? (xc != -1) : (xc != 0);\n+          if (xa_loaded) {\n+            lis(tmp, xa);\n+          }\n+          if (xc_loaded) {\n+            lis(d, xc);\n+          }\n+          if (xa_loaded) {\n+            if (xb) { ori(tmp, tmp, (unsigned short)xb); }\n+          } else {\n+            li(tmp, xb);\n+          }\n+          if (xc_loaded) {\n+            if (xd) { ori(d, d, (unsigned short)xd); }\n+          } else {\n+            li(d, xd);\n+          }\n+          insrdi(d, tmp, 32, 0);\n@@ -411,1 +474,0 @@\n-        insrdi(d, tmp, 32, 0);\n@@ -421,1 +483,6 @@\n-    lis(d, xc);\n+    if (use_pli) {\n+      pli_or_li(d, x);\n+      return retval;\n+    } else {\n+      lis(d, xc);\n+    }\n@@ -426,9 +493,14 @@\n-      xa = (x >> 48) & 0xffff;\n-      xb = (x >> 32) & 0xffff; \/\/ No sign compensation, we use lis+ori or li to allow usage of R0.\n-      bool xa_loaded = (xb & 0x8000) ? (xa != -1) : (xa != 0);\n-      bool return_xd = false;\n-\n-      if (xa_loaded) { lis(tmp, xa); }\n-      if (xc) { lis(d, xc); }\n-      if (xa_loaded) {\n-        if (xb) { ori(tmp, tmp, (unsigned short)xb); } \/\/ No addi, we support tmp == R0.\n+      if (use_pli) {\n+        \/\/ 64-bit value: x = xA xB\n+        int32_t xA, xB; \/\/ Two 32-bit chunks of const.\n+        xA = (x >> 32) & 0xffffffff;\n+        xB = x & 0xffffffff;    \/\/ Lower 32-bit chunk.\n+        bool xA_loaded = (xB & 0x80000000) ? (xA != -1) : (xA != 0);\n+        if (xA_loaded) {\n+          pli_or_li(tmp, xA);\n+          pli_or_li(d, xB);\n+          insrdi(d, tmp, 32, 0);\n+        } else {\n+          pli_or_li(d, xB);\n+        }\n+        return retval;\n@@ -436,1 +508,19 @@\n-        li(tmp, xb);\n+        xa = (x >> 48) & 0xffff;\n+        xb = (x >> 32) & 0xffff; \/\/ No sign compensation, we use lis+ori or li to allow usage of R0.\n+        bool xa_loaded = (xb & 0x8000) ? (xa != -1) : (xa != 0);\n+        bool return_xd = false;\n+\n+        if (xa_loaded) { lis(tmp, xa); }\n+        if (xc) { lis(d, xc); }\n+        if (xa_loaded) {\n+          if (xb) { ori(tmp, tmp, (unsigned short)xb); } \/\/ No addi, we support tmp == R0.\n+        } else {\n+          li(tmp, xb);\n+        }\n+        if (xc) {\n+          if (xd) { addi(d, d, xd); }\n+        } else {\n+          li(d, xd);\n+        }\n+        insrdi(d, tmp, 32, 0);\n+        return retval;\n@@ -438,2 +528,13 @@\n-      if (xc) {\n-        if (xd) { addi(d, d, xd); }\n+    }\n+\n+    if (use_pli) {\n+      int32_t xA, xB; \/\/ Two 32-bit chunks of const.\n+      xA = (x >> 32) & 0xffffffff;\n+      xB = x & 0xffffffff;    \/\/ Lower 32-bit chunk.\n+      bool xA_loaded = (xB & 0x80000000) ? (xA != -1) : (xA != 0);\n+      if (xA_loaded) {\n+        pli_or_li(d, xA);\n+        xc = (x >> 16) & 0xffff;\n+        sldi(d, d, 32);\n+        if (xc) { oris(d, d, (unsigned short)xc); }\n+        if (xd) { ori( d, d, (unsigned short)xd); }\n@@ -441,1 +542,1 @@\n-        li(d, xd);\n+        pli_or_li(d, xB);\n@@ -443,1 +544,0 @@\n-      insrdi(d, tmp, 32, 0);\n@@ -445,4 +545,3 @@\n-    }\n-\n-    xb = rem & 0xFFFF; \/\/ Next 16-bit chunk.\n-    rem = (rem >> 16) + ((unsigned short)xb >> 15); \/\/ Compensation for sign extend.\n+    } else {\n+      xb = rem & 0xFFFF; \/\/ Next 16-bit chunk.\n+      rem = (rem >> 16) + ((unsigned short)xb >> 15); \/\/ Compensation for sign extend.\n@@ -450,1 +549,1 @@\n-    xa = rem & 0xFFFF; \/\/ Highest 16-bit chunk.\n+      xa = rem & 0xFFFF; \/\/ Highest 16-bit chunk.\n@@ -452,6 +551,9 @@\n-    \/\/ opt 4: avoid adding 0\n-    if (xa) { \/\/ Highest 16-bit needed?\n-      lis(d, xa);\n-      if (xb) { addi(d, d, xb); }\n-    } else {\n-      li(d, xb);\n+      \/\/ opt 4: avoid adding 0\n+      if (xa) { \/\/ Highest 16-bit needed?\n+        lis(d, xa);\n+        if (xb) { addi(d, d, xb); }\n+      } else {\n+        li(d, xb);\n+      }\n+      sldi(d, d, 32);\n+      if (xc) { addis(d, d, xc); }\n@@ -459,2 +561,0 @@\n-    sldi(d, d, 32);\n-    if (xc) { addis(d, d, xc); }\n@@ -463,1 +563,1 @@\n-  if (xd) { addi(d, d, xd); }\n+  if (xd && !use_pli) { addi(d, d, xd); }\n@@ -468,1 +568,2 @@\n-int Assembler::add_const_optimized(Register d, Register s, long x, Register tmp, bool return_simm16_rest) {\n+int Assembler::add_const_optimized(Register d, Register s, long x, Register tmp,\n+                                   bool return_simm16_rest, bool fixed_size) {\n@@ -497,0 +598,12 @@\n+  \/\/ Case 3: Can use paddi. (However, paddi can require a nop for alignement depending\n+  \/\/                         on the code address, so we don't use paddi when the caller\n+  \/\/                         expects the number of generated code is always the same.\n+  if (PowerArchitecturePPC64 >= 10 && !fixed_size) {\n+    long xd = x & 0x3FFFFFFFFL; \/\/ Lowest 34-bit chunk.\n+    rem = (x >> 34) + (xd >> 33);\n+    if (rem == 0) {\n+      paddi_or_addi(d, s, xd);\n+      return 0;\n+    }\n+  }\n+\n@@ -505,1 +618,1 @@\n-  int simm16_rest = load_const_optimized(tmp1, x, tmp2, return_simm16_rest);\n+  int simm16_rest = load_const_optimized(tmp1, x, tmp2, return_simm16_rest, fixed_size);\n","filename":"src\/hotspot\/cpu\/ppc\/assembler_ppc.cpp","additions":178,"deletions":65,"binary":false,"changes":243,"status":"modified"},{"patch":"@@ -818,0 +818,2 @@\n+    PLD_PREFIX_OPCODE_MASK    = PREFIX_OPCODE_TYPEx0_MASK,\n+    PLD_SUFFIX_OPCODE_MASK    = (63u << OPCODE_SHIFT),\n@@ -826,0 +828,6 @@\n+    PLFS_PREFIX_OPCODE    = PREFIX_PRIMARY_OPCODE | (2u << PRE_TYPE_SHIFT),\n+    PLFS_SUFFIX_OPCODE    = (48u << OPCODE_SHIFT),\n+    PLFD_PREFIX_OPCODE    = PREFIX_PRIMARY_OPCODE | (2u << PRE_TYPE_SHIFT),\n+    PLFD_SUFFIX_OPCODE    = (50u << OPCODE_SHIFT),\n+    PLD_PREFIX_OPCODE     = PREFIX_PRIMARY_OPCODE,\n+    PLD_SUFFIX_OPCODE     = (57u << OPCODE_SHIFT),\n@@ -1306,0 +1314,4 @@\n+  static int get_imm18(address a, int instruction_number) {\n+    return (((int *)a)[instruction_number] << 14) >> 14;\n+  }\n+\n@@ -1500,0 +1512,6 @@\n+  static bool is_pld_prefix(int x) {\n+     return PLD_PREFIX_OPCODE == (x & PLD_PREFIX_OPCODE_MASK);\n+  }\n+  static bool is_pld_suffix(int x) {\n+     return PLD_SUFFIX_OPCODE == (x & PLD_SUFFIX_OPCODE_MASK);\n+  }\n@@ -1735,0 +1753,9 @@\n+  \/\/ Prefixed load\n+  inline void pld( Register d, long si34, Register s1, bool r);\n+  inline void pld( Register d, long si34, Register s1);\n+  inline void pld( Register d, long si34);\n+  inline void plfs(FloatRegister d, long si34, Register s1, bool r);\n+  inline void plfs(FloatRegister d, long si34, Register s1);\n+  inline void plfd(FloatRegister d, long si34, Register s1, bool r);\n+  inline void plfd(FloatRegister d, long si34, Register s1);\n+\n@@ -2567,3 +2594,5 @@\n-         int load_const_optimized(Register d, long a,  Register tmp = noreg, bool return_simm16_rest = false);\n-  inline int load_const_optimized(Register d, void* a, Register tmp = noreg, bool return_simm16_rest = false) {\n-    return load_const_optimized(d, (long)(unsigned long)a, tmp, return_simm16_rest);\n+         int load_const_optimized(Register d, long a,  Register tmp = noreg,\n+                                  bool return_simm16_rest = false, bool fixed_size = false);\n+  inline int load_const_optimized(Register d, void* a, Register tmp = noreg,\n+                                  bool return_simm16_rest = false, bool fixed_size = false) {\n+    return load_const_optimized(d, (long)(unsigned long)a, tmp, return_simm16_rest, fixed_size);\n@@ -2573,3 +2602,5 @@\n-         int add_const_optimized(Register d, Register s, long x, Register tmp = R0, bool return_simm16_rest = false);\n-  inline int add_const_optimized(Register d, Register s, void* a, Register tmp = R0, bool return_simm16_rest = false) {\n-    return add_const_optimized(d, s, (long)(unsigned long)a, tmp, return_simm16_rest);\n+         int add_const_optimized(Register d, Register s, long x, Register tmp = R0,\n+                                 bool return_simm16_rest = false, bool fixed_size = false);\n+  inline int add_const_optimized(Register d, Register s, void* a, Register tmp = R0,\n+                                 bool return_simm16_rest = false, bool fixed_size = false) {\n+    return add_const_optimized(d, s, (long)(unsigned long)a, tmp, return_simm16_rest, fixed_size);\n@@ -2586,0 +2617,8 @@\n+ private:\n+  \/\/ Helper function used in load_const_optimized() and add_const_optimized()\n+  void paddi_or_addi(Register d, Register s, long si34);\n+  void pli_or_li(    Register d, long si34) {\n+    paddi_or_addi(d, R0, si34);\n+  }\n+\n+ public:\n","filename":"src\/hotspot\/cpu\/ppc\/assembler_ppc.hpp","additions":45,"deletions":6,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -3,1 +3,1 @@\n- * Copyright (c) 2012, 2020 SAP SE. All rights reserved.\n+ * Copyright (c) 2012, 2021 SAP SE. All rights reserved.\n@@ -388,0 +388,36 @@\n+\/\/ Prefixed instructions, introduced by POWER10\n+inline void Assembler::plfs( FloatRegister d, long si34, Register s1, bool r) {\n+  emit_int32(PLFS_PREFIX_OPCODE | r_eo(r) | d0_eo(si34));\n+  emit_int32(PLFS_SUFFIX_OPCODE | frt(d)  | ra0mem(s1) | d1_eo(si34));\n+}\n+\n+inline void Assembler::plfs( FloatRegister d, long si34, Register s1) {\n+  emit_int32(PLFS_PREFIX_OPCODE | r_eo(0) | d0_eo(si34));\n+  emit_int32(PLFS_SUFFIX_OPCODE | frt(d)  | ra0mem(s1) | d1_eo(si34));\n+}\n+\n+inline void Assembler::plfd( FloatRegister d, long si34, Register s1, bool r) {\n+  emit_int32(PLFD_PREFIX_OPCODE | r_eo(r) | d0_eo(si34));\n+  emit_int32(PLFD_SUFFIX_OPCODE | frt(d)  | ra0mem(s1) | d1_eo(si34));\n+}\n+\n+inline void Assembler::plfd( FloatRegister d, long si34, Register s1) {\n+  emit_int32(PLFD_PREFIX_OPCODE | r_eo(0) | d0_eo(si34));\n+  emit_int32(PLFD_SUFFIX_OPCODE | frt(d)  | ra0mem(s1) | d1_eo(si34));\n+}\n+\n+inline void Assembler::pld( Register d, long si34, Register s1, bool r) {\n+  emit_int32(PLD_PREFIX_OPCODE  | r_eo(r) | d0_eo(si34));\n+  emit_int32(PLD_SUFFIX_OPCODE  | rt(d)   | ra0mem(s1) | d1_eo(si34));\n+}\n+\n+inline void Assembler::pld( Register d, long si34, Register s1) {\n+  emit_int32(PLD_PREFIX_OPCODE  | r_eo(0) | d0_eo(si34));\n+  emit_int32(PLD_SUFFIX_OPCODE  | rt(d)   | ra0mem(s1) | d1_eo(si34));\n+}\n+\n+inline void Assembler::pld( Register d, long si34) {\n+  emit_int32(PLD_PREFIX_OPCODE  | r_eo(1) | d0_eo(si34));\n+  emit_int32(PLD_SUFFIX_OPCODE  | rt(d)   | d1_eo(si34));\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/assembler_ppc.inline.hpp","additions":37,"deletions":1,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -286,0 +286,12 @@\n+   if (PowerArchitecturePPC64 >= 10) {\n+     const address inst2_addr = inst1_addr + BytesPerInstWord;\n+     const int inst2 = *(int *)inst2_addr;\n+\n+     \/\/ The case a relocation points to a pld.  Currently, CallDynamicJavaDirectSched_ExNode and\n+     \/\/ CallLeaf(NoFP)Direct_ExNode are the only nodes that require relocation and use pld, and\n+     \/\/ call this function\n+     if (is_pld_prefix(inst1) && is_pld_suffix(inst2)) {\n+       return true;\n+     }\n+   }\n+\n@@ -299,0 +311,5 @@\n+  } else if (PowerArchitecturePPC64 >= 10 && is_pld_prefix(inst1)) {\n+    \/\/ The case a relocation points to a pld.  Currently, CallDynamicJavaDirectSched_ExNode and\n+    \/\/ CallLeaf(NoFP)Direct_ExNode are the only nodes that require relocation and use pld, and\n+    \/\/ call this function\n+    return (get_imm18(inst1_addr, 0) << 16) + (get_imm(inst1_addr, 1) & 0xffff);\n@@ -3242,1 +3259,1 @@\n-    add_const_optimized(dst, shifted_src, CompressedKlassPointers::base(), R0);\n+    add_const_optimized(dst, shifted_src, CompressedKlassPointers::base(), R0, false, true);\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":18,"deletions":1,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1177,0 +1177,16 @@\n+int loadConLNode::compute_padding(int current_offset) const {\n+  return compute_prefix_padding(current_offset);\n+}\n+\n+int loadConPNode::compute_padding(int current_offset) const {\n+  return compute_prefix_padding(current_offset);\n+}\n+\n+int loadConFNode::compute_padding(int current_offset) const {\n+  return compute_prefix_padding(current_offset);\n+}\n+\n+int loadConDNode::compute_padding(int current_offset) const {\n+  return compute_prefix_padding(current_offset);\n+}\n+\n@@ -2624,8 +2640,9 @@\n-    address const_toc_addr;\n-    \/\/ Create a non-oop constant, no relocation needed.\n-    \/\/ If it is an IC, it has a virtual_call_Relocation.\n-    const_toc_addr = __ long_constant((jlong)$src$$constant);\n-    if (const_toc_addr == NULL) {\n-      ciEnv::current()->record_out_of_memory_failure();\n-      return;\n-    }\n+    if (!ra_->C->output()->in_scratch_emit_size()) {\n+      address const_toc_addr;\n+      \/\/ Create a non-oop constant, no relocation needed.\n+      \/\/ If it is an IC, it has a virtual_call_Relocation.\n+      const_toc_addr = __ long_constant((jlong)$src$$constant);\n+      if (const_toc_addr == NULL) {\n+        ciEnv::current()->record_out_of_memory_failure();\n+        return;\n+      }\n@@ -2633,2 +2650,2 @@\n-    \/\/ Get the constant's TOC offset.\n-    toc_offset = __ offset_to_method_toc(const_toc_addr);\n+      \/\/ Get the constant's TOC offset.\n+      toc_offset = __ offset_to_method_toc(const_toc_addr);\n@@ -2636,2 +2653,3 @@\n-    \/\/ Keep the current instruction offset in mind.\n-    ((loadConLNode*)this)->_cbuf_insts_offset = __ offset();\n+      \/\/ Keep the current instruction offset in mind.\n+      ((loadConLNode*)this)->_cbuf_insts_offset = __ offset();\n+    }\n@@ -2639,1 +2657,5 @@\n-    __ ld($dst$$Register, toc_offset, $toc$$Register);\n+    if(Assembler::is_simm16(toc_offset) || PowerArchitecturePPC64 <= 9) {\n+      __ ld($dst$$Register, toc_offset, $toc$$Register);\n+    } else {\n+      __ pld($dst$$Register, toc_offset, $toc$$Register);\n+    }\n@@ -2684,1 +2706,1 @@\n-  if (large_constant_pool) {\n+  if (large_constant_pool && PowerArchitecturePPC64 <= 9) {\n@@ -2762,1 +2784,1 @@\n-  if (large_constant_pool) {\n+  if (large_constant_pool && PowerArchitecturePPC64 <= 9) {\n@@ -2820,0 +2842,2 @@\n+    m3->add_req(NULL, m2);\n+    m4->add_req(NULL, m3);\n@@ -2868,0 +2892,1 @@\n+    if (loadConLNodes._small)    nodes->push(loadConLNodes._small);\n@@ -2869,1 +2894,1 @@\n-    if (loadConLNodes._last)     nodes->push(loadConLNodes._last);\n+    if (loadConLNodes._large_lo) nodes->push(loadConLNodes._large_lo);\n@@ -2881,16 +2906,17 @@\n-    intptr_t val = $src$$constant;\n-    relocInfo::relocType constant_reloc = $src->constant_reloc();  \/\/ src\n-    address const_toc_addr;\n-    if (constant_reloc == relocInfo::oop_type) {\n-      \/\/ Create an oop constant and a corresponding relocation.\n-      AddressLiteral a = __ allocate_oop_address((jobject)val);\n-      const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);\n-      __ relocate(a.rspec());\n-    } else if (constant_reloc == relocInfo::metadata_type) {\n-      AddressLiteral a = __ constant_metadata_address((Metadata *)val);\n-      const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);\n-      __ relocate(a.rspec());\n-    } else {\n-      \/\/ Create a non-oop constant, no relocation needed.\n-      const_toc_addr = __ long_constant((jlong)$src$$constant);\n-    }\n+    if (!ra_->C->output()->in_scratch_emit_size()) {\n+      intptr_t val = $src$$constant;\n+      relocInfo::relocType constant_reloc = $src->constant_reloc();  \/\/ src\n+      address const_toc_addr;\n+      if (constant_reloc == relocInfo::oop_type) {\n+        \/\/ Create an oop constant and a corresponding relocation.\n+        AddressLiteral a = __ allocate_oop_address((jobject)val);\n+        const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);\n+        __ relocate(a.rspec());\n+      } else if (constant_reloc == relocInfo::metadata_type) {\n+        AddressLiteral a = __ constant_metadata_address((Metadata *)val);\n+        const_toc_addr = __ address_constant((address)a.value(), RelocationHolder::none);\n+        __ relocate(a.rspec());\n+      } else {\n+        \/\/ Create a non-oop constant, no relocation needed.\n+        const_toc_addr = __ long_constant((jlong)$src$$constant);\n+      }\n@@ -2898,3 +2924,6 @@\n-    if (const_toc_addr == NULL) {\n-      ciEnv::current()->record_out_of_memory_failure();\n-      return;\n+      if (const_toc_addr == NULL) {\n+        ciEnv::current()->record_out_of_memory_failure();\n+        return;\n+      }\n+      \/\/ Get the constant's TOC offset.\n+      toc_offset = __ offset_to_method_toc(const_toc_addr);\n@@ -2902,2 +2931,0 @@\n-    \/\/ Get the constant's TOC offset.\n-    toc_offset = __ offset_to_method_toc(const_toc_addr);\n@@ -2905,1 +2932,5 @@\n-    __ ld($dst$$Register, toc_offset, $toc$$Register);\n+    if(Assembler::is_simm16(toc_offset) || PowerArchitecturePPC64 <= 9) {\n+      __ ld($dst$$Register, toc_offset, $toc$$Register);\n+    } else {\n+      __ pld($dst$$Register, toc_offset, $toc$$Register);\n+    }\n@@ -2947,1 +2978,1 @@\n-    if (large_constant_pool) {\n+    if (large_constant_pool && PowerArchitecturePPC64 <= 9) {\n@@ -3000,1 +3031,1 @@\n-    if (large_constant_pool) {\n+    if (large_constant_pool && PowerArchitecturePPC64 <= 9) {\n@@ -3024,1 +3055,1 @@\n-    if (large_constant_pool) {\n+    if (large_constant_pool && PowerArchitecturePPC64 <= 9) {\n@@ -3407,0 +3438,1 @@\n+    if (loadConLNodes._small)    nodes->push(loadConLNodes._small);\n@@ -3408,1 +3440,1 @@\n-    if (loadConLNodes._last)     nodes->push(loadConLNodes._last);\n+    if (loadConLNodes._large_lo) nodes->push(loadConLNodes._large_lo);\n@@ -3427,0 +3459,1 @@\n+    if (loadConLNodes._small)    { nodes->push(loadConLNodes._small); }\n@@ -3637,0 +3670,1 @@\n+    if (loadConLNodes_IC._small)    nodes->push(loadConLNodes_IC._small);\n@@ -3638,1 +3672,1 @@\n-    if (loadConLNodes_IC._last)     nodes->push(loadConLNodes_IC._last);\n+    if (loadConLNodes_IC._large_lo) nodes->push(loadConLNodes_IC._large_lo);\n@@ -3828,0 +3862,1 @@\n+    if (loadConLNodes_Entry._small)    nodes->push(loadConLNodes_Entry._small);\n@@ -3829,1 +3864,1 @@\n-    if (loadConLNodes_Entry._last)     nodes->push(loadConLNodes_Entry._last);\n+    if (loadConLNodes_Entry._large_lo) nodes->push(loadConLNodes_Entry._large_lo);\n@@ -3831,0 +3866,1 @@\n+    if (loadConLNodes_Env._small)      nodes->push(loadConLNodes_Env._small);\n@@ -3832,1 +3868,2 @@\n-    if (loadConLNodes_Env._last)       nodes->push(loadConLNodes_Env._last);\n+    if (loadConLNodes_Env._large_lo)   nodes->push(loadConLNodes_Env._large_lo);\n+    if (loadConLNodes_Toc._small)      nodes->push(loadConLNodes_Toc._small);\n@@ -3834,1 +3871,1 @@\n-    if (loadConLNodes_Toc._last)       nodes->push(loadConLNodes_Toc._last);\n+    if (loadConLNodes_Toc._large_lo)   nodes->push(loadConLNodes_Toc._large_lo);\n@@ -4259,0 +4296,11 @@\n+\/\/ Operand to avoid match of loadConL.\n+\/\/ This operand can be used to avoid matching of an instruct\n+\/\/ with chain rule.\n+operand immL_NM() %{\n+  match(ConL);\n+  predicate(false);\n+  op_cost(40);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4381,0 +4429,11 @@\n+\/\/ Operand to avoid match of loadConF.\n+\/\/ This operand can be used to avoid matching of an instruct\n+\/\/ with chain rule.\n+operand immF_NM() %{\n+  match(ConF);\n+  predicate(false);\n+  op_cost(40);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -4399,0 +4458,11 @@\n+\/\/ Operand to avoid match of loadConD.\n+\/\/ This operand can be used to avoid matching of an instruct\n+\/\/ with chain rule.\n+operand immD_NM() %{\n+  match(ConD);\n+  predicate(false);\n+  op_cost(40);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -5967,2 +6037,9 @@\n-instruct loadConL(iRegLdst dst, immL src, iRegLdst toc) %{\n-  effect(DEF dst, USE src, USE toc);\n+\/\/ The match rule is needed to generate alignment_required() and compute_padding(),\n+\/\/ however this node should never match. The use of predicate is not\n+\/\/ possible since ADLC forbids predicates for chain rules. The higher\n+\/\/ costs do not prevent matching in this case. For that reason the\n+\/\/ operand immL_NM with predicate(false) is used.\n+\/\/ On Power 10 and up, this instruction is also used for larger offset upto signed 32-bit.\n+instruct loadConL(iRegLdst dst, immL_NM src, iRegLdst toc) %{\n+  match(Set dst src);\n+  effect(TEMP toc);\n@@ -5977,1 +6054,1 @@\n-  size(4);\n+  size(8);\n@@ -5980,0 +6057,1 @@\n+  ins_alignment(2);\n@@ -6249,0 +6327,1 @@\n+\/\/ On Power 10 and up, this instruction is also used for larger offset upto signed 32-bit.\n@@ -6256,1 +6335,1 @@\n-  size(4);\n+  size(8);\n@@ -6259,0 +6338,1 @@\n+  ins_alignment(2);\n@@ -6312,2 +6392,9 @@\n-instruct loadConF(regF dst, immF src, iRegLdst toc) %{\n-  effect(DEF dst, USE src, USE toc);\n+\/\/ The match rule is needed to generate alignment_required() and compute_padding(),\n+\/\/ however this node should never match. The use of predicate is not\n+\/\/ possible since ADLC forbids predicates for chain rules. The higher\n+\/\/ costs do not prevent matching in this case. For that reason the\n+\/\/ operand immF_NM with predicate(false) is used.\n+\/\/ On Power 10 and up, this instruction is also used for larger offset upto signed 32-bit.\n+instruct loadConF(regF dst, immF_NM src, iRegLdst toc) %{\n+  match(Set dst src);\n+  effect(TEMP toc);\n@@ -6319,1 +6406,1 @@\n-  size(4);\n+  size(8);\n@@ -6326,1 +6413,6 @@\n-    __ lfs($dst$$FloatRegister, __ offset_to_method_toc(float_address), $toc$$Register);\n+    int offset = __ offset_to_method_toc(float_address);\n+    if (Assembler::is_simm16(offset) || PowerArchitecturePPC64 <= 9) {\n+      __ lfs($dst$$FloatRegister, offset, $toc$$Register);\n+    } else {\n+      __ plfs($dst$$FloatRegister, offset, $toc$$Register);\n+    }\n@@ -6329,0 +6421,1 @@\n+  ins_alignment(2);\n@@ -6374,2 +6467,9 @@\n-instruct loadConD(regD dst, immD src, iRegLdst toc) %{\n-  effect(DEF dst, USE src, USE toc);\n+\/\/ The match rule is needed to generate alignment_required() and compute_padding(),\n+\/\/ however this node should never match. The use of predicate is not\n+\/\/ possible since ADLC forbids predicates for chain rules. The higher\n+\/\/ costs do not prevent matching in this case. For that reason the\n+\/\/ operand immD_NM with predicate(false) is used.\n+\/\/ On Power 10 and up, this instruction is also used for larger offset upto signed 32-bit.\n+instruct loadConD(regD dst, immD_NM src, iRegLdst toc) %{\n+  match(Set dst src);\n+  effect(TEMP toc);\n@@ -6381,1 +6481,1 @@\n-  size(4);\n+  size(8);\n@@ -6389,1 +6489,5 @@\n-    __ lfd($dst$$FloatRegister, offset, $toc$$Register);\n+    if (Assembler::is_simm16(offset) || PowerArchitecturePPC64 <= 9) {\n+      __ lfd($dst$$FloatRegister, offset, $toc$$Register);\n+    } else {\n+      __ plfd($dst$$FloatRegister, offset, $toc$$Register);\n+    }\n@@ -6392,0 +6496,1 @@\n+  ins_alignment(2);\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":163,"deletions":58,"binary":false,"changes":221,"status":"modified"}]}