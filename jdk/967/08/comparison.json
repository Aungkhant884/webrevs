{"files":[{"patch":"@@ -87,1 +87,1 @@\n-      jvmtiClassFileReconstituter.cpp\n+      jvmtiClassFileReconstituter.cpp jvmtiTagMapTable.cpp\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -99,17 +99,0 @@\n-const double _resize_factor    = 2.0;     \/\/ by how much we will resize using current number of entries\n-const int _resize_max_size     = 40423;   \/\/ the max dictionary size allowed\n-const int _primelist[] = {107, 1009, 2017, 4049, 5051, 10103, 20201, _resize_max_size};\n-const int _prime_array_size = sizeof(_primelist)\/sizeof(int);\n-\n-\/\/ Calculate next \"good\" dictionary size based on requested count\n-static int calculate_dictionary_size(int requested) {\n-  int newsize = _primelist[0];\n-  int index = 0;\n-  for (newsize = _primelist[index]; index < (_prime_array_size - 1);\n-       newsize = _primelist[++index]) {\n-    if (requested <= newsize) {\n-      break;\n-    }\n-  }\n-  return newsize;\n-}\n@@ -131,0 +114,1 @@\n+  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n@@ -133,7 +117,5 @@\n-    desired_size = calculate_dictionary_size((int)(_resize_factor*number_of_entries()));\n-    if (desired_size >= _resize_max_size) {\n-      desired_size = _resize_max_size;\n-      \/\/ We have reached the limit, turn resizing off\n-      _resizable = false;\n-    }\n-    if ((desired_size != 0) && (desired_size != table_size())) {\n+    desired_size = calculate_resize(false);\n+    assert(desired_size != 0, \"bug in calculate_resize\");\n+    if (desired_size == table_size()) {\n+      _resizable = false; \/\/ hit max\n+    } else {\n","filename":"src\/hotspot\/share\/classfile\/dictionary.cpp","additions":6,"deletions":24,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-  static const uint weak_count = 5 JFR_ONLY(+ 1);\n+  static const uint weak_count = 5 JVMTI_ONLY(+ 1) JFR_ONLY(+ 1);\n","filename":"src\/hotspot\/share\/gc\/shared\/oopStorageSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -40,6 +40,19 @@\n-void WeakProcessor::do_serial_parts(BoolObjectClosure* is_alive,\n-                                    OopClosure* keep_alive) {\n-  WeakProcessorPhases::Iterator it = WeakProcessorPhases::serial_iterator();\n-  for ( ; !it.is_end(); ++it) {\n-    WeakProcessorPhases::processor(*it)(is_alive, keep_alive);\n-  }\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiTagMap.hpp\"\n+#endif \/\/ INCLUDE_JVMTI\n+\n+void notify_jvmti_tagmaps() {\n+#if INCLUDE_JVMTI\n+  \/\/ Notify JVMTI tagmaps that a STW weak reference processing might be\n+  \/\/ clearing entries, so the tagmaps need cleaning.  Doing this here allows\n+  \/\/ the tagmap's oopstorage notification handler to not care whether it's\n+  \/\/ invoked by STW or concurrent reference processing.\n+  JvmtiTagMap::set_needs_cleaning();\n+\n+  \/\/ Notify JVMTI tagmaps that a STW collection may have moved objects, so\n+  \/\/ the tagmaps need rehashing.  This isn't the right place for this, but\n+  \/\/ is convenient because all the STW collectors use WeakProcessor.  One\n+  \/\/ problem is that the end of a G1 concurrent collection also comes here,\n+  \/\/ possibly triggering unnecessary rehashes.\n+  JvmtiTagMap::set_needs_rehashing();\n+#endif \/\/ INCLUDE_JVMTI\n@@ -49,1 +62,2 @@\n-  do_serial_parts(is_alive, keep_alive);\n+\n+  notify_jvmti_tagmaps();\n@@ -64,2 +78,0 @@\n-  AlwaysTrueClosure always_true;\n-  do_serial_parts(&always_true, closure);\n@@ -109,0 +121,1 @@\n+  notify_jvmti_tagmaps();\n@@ -114,1 +127,0 @@\n-  _serial_phases_done(WeakProcessorPhases::serial_phase_count),\n@@ -123,1 +135,0 @@\n-  _serial_phases_done(WeakProcessorPhases::serial_phase_count),\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessor.cpp","additions":23,"deletions":12,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -75,2 +75,0 @@\n-\n-  static void do_serial_parts(BoolObjectClosure* is_alive, OopClosure* keep_alive);\n@@ -84,1 +82,0 @@\n-  SubTasksDone _serial_phases_done;\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessor.hpp","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -99,13 +99,0 @@\n-  for (Iterator it = WeakProcessorPhases::serial_iterator(); !it.is_end(); ++it) {\n-    WeakProcessorPhase phase = *it;\n-    CountingIsAliveClosure<IsAlive> cl(is_alive);\n-    uint serial_index = WeakProcessorPhases::serial_index(phase);\n-    if (_serial_phases_done.try_claim_task(serial_index)) {\n-      WeakProcessorPhaseTimeTracker pt(_phase_times, phase);\n-      WeakProcessorPhases::processor(phase)(&cl, keep_alive);\n-      if (_phase_times != NULL) {\n-        _phase_times->record_phase_items(phase, cl.num_dead(), cl.num_total());\n-      }\n-    }\n-  }\n-\n@@ -116,2 +103,1 @@\n-    uint oopstorage_index = WeakProcessorPhases::oopstorage_index(phase);\n-    StorageState* cur_state = _storage_states.par_state(oopstorage_index);\n+    StorageState* cur_state = _storage_states.par_state(phase);\n@@ -124,2 +110,0 @@\n-\n-  _serial_phases_done.all_tasks_completed(_nworkers);\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessor.inline.hpp","additions":1,"deletions":17,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -36,18 +36,0 @@\n-static uint serial_phase_index(WeakProcessorPhase phase) {\n-  return WeakProcessorPhases::serial_index(phase);\n-}\n-\n-static bool is_serial_phase(WeakProcessorPhase phase) {\n-  return WeakProcessorPhases::is_serial(phase);\n-}\n-\n-static void assert_serial_phase(WeakProcessorPhase phase) {\n-  assert(is_serial_phase(phase),\n-         \"Not a serial phase %u\", static_cast<uint>(phase));\n-}\n-\n-static void assert_oopstorage_phase(WeakProcessorPhase phase) {\n-  assert(WeakProcessorPhases::is_oopstorage(phase),\n-         \"Not an oopstorage phase %u\", static_cast<uint>(phase));\n-}\n-\n@@ -58,1 +40,0 @@\n-static bool is_initialized_items(size_t i) { return i != 0; }\n@@ -61,17 +42,0 @@\n-static void reset_times(double* times, size_t ntimes) {\n-  for (size_t i = 0; i < ntimes; ++i) {\n-    times[i] = uninitialized_time;\n-  }\n-}\n-\n-static void reset_items(size_t* items, size_t nitems) {\n-  for (size_t i = 0; i < nitems; ++i) {\n-    items[i] = 0;\n-  }\n-}\n-\n-void WeakProcessorPhaseTimes::reset_phase_data() {\n-  reset_times(_phase_times_sec, ARRAY_SIZE(_phase_times_sec));\n-  reset_items(_phase_dead_items, ARRAY_SIZE(_phase_dead_items));\n-  reset_items(_phase_total_items, ARRAY_SIZE(_phase_total_items));\n-}\n@@ -87,2 +51,0 @@\n-  reset_phase_data();\n-\n@@ -125,1 +87,0 @@\n-  reset_phase_data();\n@@ -141,25 +102,0 @@\n-double WeakProcessorPhaseTimes::phase_time_sec(WeakProcessorPhase phase) const {\n-  assert_serial_phase(phase);\n-  assert(is_initialized_time(_phase_times_sec[serial_phase_index(phase)]),\n-         \"phase time not set %u\", serial_phase_index(phase));\n-  return _phase_times_sec[serial_phase_index(phase)];\n-}\n-\n-void WeakProcessorPhaseTimes::record_phase_time_sec(WeakProcessorPhase phase, double time_sec) {\n-  assert_serial_phase(phase);\n-  assert(!is_initialized_time(_phase_times_sec[serial_phase_index(phase)]),\n-         \"Already set time for phase %u\", serial_phase_index(phase));\n-  _phase_times_sec[serial_phase_index(phase)] = time_sec;\n-}\n-\n-void WeakProcessorPhaseTimes::record_phase_items(WeakProcessorPhase phase, size_t num_dead, size_t num_total) {\n-  assert_serial_phase(phase);\n-  uint p = serial_phase_index(phase);\n-  assert(!is_initialized_items(_phase_dead_items[p]),\n-         \"Already set dead items for phase %u\", p);\n-  assert(!is_initialized_items(_phase_total_items[p]),\n-         \"Already set total items for phase %u\", p);\n-  _phase_dead_items[p] = num_dead;\n-  _phase_total_items[p] = num_total;\n-}\n-\n@@ -167,2 +103,1 @@\n-  assert_oopstorage_phase(phase);\n-  return _worker_data[WeakProcessorPhases::oopstorage_index(phase)];\n+  return _worker_data[phase];\n@@ -216,1 +151,0 @@\n-  assert_oopstorage_phase(_phase);\n@@ -221,9 +155,0 @@\n-WeakProcessorPhaseTimeTracker::WeakProcessorPhaseTimeTracker(WeakProcessorPhaseTimes* times,\n-                                                             WeakProcessorPhase phase) :\n-  _times(times),\n-  _phase(phase),\n-  _worker_id(0),\n-  _start_time(Ticks::now())\n-{\n-  assert_serial_phase(phase);\n-}\n@@ -234,5 +159,1 @@\n-    if (is_serial_phase(_phase)) {\n-      _times->record_phase_time_sec(_phase, time_sec);\n-    } else {\n-      _times->record_worker_time_sec(_worker_id, _phase, time_sec);\n-    }\n+    _times->record_worker_time_sec(_worker_id, _phase, time_sec);\n@@ -254,19 +175,0 @@\n-void WeakProcessorPhaseTimes::log_st_phase(WeakProcessorPhase phase,\n-                                           uint indent) const {\n-  assert_serial_phase(phase);\n-  log_debug(gc, phases)(\"%s%s: \" TIME_FORMAT,\n-                        indent_str(indent),\n-                        WeakProcessorPhases::description(phase),\n-                        phase_time_sec(phase) * MILLIUNITS);\n-\n-  log_debug(gc, phases)(\"%s%s: \" SIZE_FORMAT,\n-                        indent_str(indent + 1),\n-                        \"Dead\",\n-                        _phase_dead_items[serial_phase_index(phase)]);\n-\n-  log_debug(gc, phases)(\"%s%s: \" SIZE_FORMAT,\n-                        indent_str(indent + 1),\n-                        \"Total\",\n-                        _phase_total_items[serial_phase_index(phase)]);\n-}\n-\n@@ -305,3 +207,0 @@\n-    for (Iterator it = WeakProcessorPhases::serial_iterator(); !it.is_end(); ++it) {\n-      log_st_phase(*it, indent);\n-    }\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessorPhaseTimes.cpp","additions":3,"deletions":104,"binary":false,"changes":107,"status":"modified"},{"patch":"@@ -46,9 +46,0 @@\n-  \/\/ Total time and associated items for each serially processed phase.\n-  static const uint phase_data_count = WeakProcessorPhases::serial_phase_count;\n-  \/\/ +1 because serial_phase_count == 0 in some build configurations.\n-  \/\/ Simpler to always allocate extra space than conditionalize.\n-  double _phase_times_sec[phase_data_count + 1];\n-  size_t _phase_dead_items[phase_data_count + 1];\n-  size_t _phase_total_items[phase_data_count + 1];\n-  void reset_phase_data();\n-\n@@ -111,5 +102,0 @@\n-  \/\/ For tracking serial phase times.\n-  \/\/ Precondition: WeakProcessorPhases::is_serial(phase)\n-  WeakProcessorPhaseTimeTracker(WeakProcessorPhaseTimes* times,\n-                                WeakProcessorPhase phase);\n-\n@@ -118,1 +104,0 @@\n-  \/\/ Precondition: WeakProcessorPhases::is_oopstorage(phase)\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessorPhaseTimes.hpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -30,57 +30,0 @@\n-#if INCLUDE_JVMTI\n-#include \"prims\/jvmtiExport.hpp\"\n-#endif \/\/ INCLUDE_JVMTI\n-\n-\/\/ serial_phase_count is 0 if JVMTI is not built,\n-\/\/ requiring some code to be careful to avoid tautological checks\n-\/\/ that some compilers warn about.\n-\n-#define HAVE_SERIAL_PHASES INCLUDE_JVMTI\n-\n-WeakProcessorPhases::Phase WeakProcessorPhases::serial_phase(uint value) {\n-#if HAVE_SERIAL_PHASES\n-  assert(value < serial_phase_count, \"Invalid serial phase value %u\", value);\n-  return static_cast<Phase>(value + serial_phase_start);\n-#else\n-  STATIC_ASSERT(serial_phase_count == 0);\n-  fatal(\"invalid serial phase value %u\", value);\n-  return static_cast<Phase>(serial_phase_start);\n-#endif \/\/ HAVE_SERIAL_PHASES\n-}\n-\n-WeakProcessorPhases::Phase WeakProcessorPhases::oopstorage_phase(uint value) {\n-  assert(value < oopstorage_phase_count, \"Invalid oopstorage phase value %u\", value);\n-  return static_cast<Phase>(value + oopstorage_phase_start);\n-}\n-\n-static uint raw_phase_index(WeakProcessorPhases::Phase phase) {\n-  return static_cast<uint>(phase);\n-}\n-\n-uint WeakProcessorPhases::serial_index(Phase phase) {\n-  assert(is_serial(phase), \"not serial phase %u\", raw_phase_index(phase));\n-  return raw_phase_index(phase) - serial_phase_start;\n-}\n-\n-uint WeakProcessorPhases::oopstorage_index(Phase phase) {\n-  assert(is_oopstorage(phase), \"not oopstorage phase %u\", raw_phase_index(phase));\n-  return raw_phase_index(phase) - oopstorage_phase_start;\n-}\n-\n-static bool is_phase(WeakProcessorPhases::Phase phase, uint start, uint count) {\n-  return (raw_phase_index(phase) - start) < count;\n-}\n-\n-bool WeakProcessorPhases::is_serial(Phase phase) {\n-#if HAVE_SERIAL_PHASES\n-  return is_phase(phase, serial_phase_start, serial_phase_count);\n-#else\n-  STATIC_ASSERT(serial_phase_count == 0);\n-  return false;\n-#endif \/\/ HAVE_SERIAL_PHASES\n-}\n-\n-bool WeakProcessorPhases::is_oopstorage(Phase phase) {\n-  return is_phase(phase, oopstorage_phase_start, oopstorage_phase_count);\n-}\n-\n@@ -104,18 +47,0 @@\n-\n-const char* WeakProcessorPhases::description(Phase phase) {\n-  switch (phase) {\n-  JVMTI_ONLY(case jvmti: return \"JVMTI weak processing\";)\n-  default:\n-    ShouldNotReachHere();\n-    return \"Invalid serial weak processing phase\";\n-  }\n-}\n-\n-WeakProcessorPhases::Processor WeakProcessorPhases::processor(Phase phase) {\n-  switch (phase) {\n-  JVMTI_ONLY(case jvmti: return &JvmtiExport::weak_oops_do;)\n-  default:\n-    ShouldNotReachHere();\n-    return NULL;\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessorPhases.cpp","additions":0,"deletions":75,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -41,2 +41,0 @@\n-  typedef void (*Processor)(BoolObjectClosure*, OopClosure*);\n-\n@@ -44,4 +42,1 @@\n-    \/\/ Serial phase.\n-    JVMTI_ONLY(jvmti)\n-\n-    \/\/ Additional implicit phase values follow for oopstorages.\n+    \/\/ Implicit phase values for oopstorages.\n@@ -50,3 +45,1 @@\n-  static const uint serial_phase_start = 0;\n-  static const uint serial_phase_count = 0 JVMTI_ONLY(+ 1);\n-  static const uint oopstorage_phase_start = serial_phase_count;\n+  static const uint oopstorage_phase_start = 0;\n@@ -54,15 +47,1 @@\n-  static const uint phase_count = serial_phase_count + oopstorage_phase_count;\n-\n-  \/\/ Precondition: value < serial_phase_count\n-  static Phase serial_phase(uint value);\n-\n-  \/\/ Precondition: value < oopstorage_phase_count\n-  static Phase oopstorage_phase(uint value);\n-\n-  \/\/ Indexes relative to the corresponding phase_start constant.\n-  \/\/ Precondition: is_serial(phase) or is_oopstorage(phase) accordingly\n-  static uint serial_index(Phase phase);\n-  static uint oopstorage_index(Phase phase);\n-\n-  static bool is_serial(Phase phase);\n-  static bool is_oopstorage(Phase phase);\n+  static const uint phase_count = oopstorage_phase_count;\n@@ -70,1 +49,0 @@\n-  static Iterator serial_iterator();\n@@ -72,6 +50,0 @@\n-\n-  \/\/ Precondition: is_serial(phase)\n-  static const char* description(Phase phase);\n-\n-  \/\/ Precondition: is_serial(phase)\n-  static Processor processor(Phase phase);\n@@ -114,1 +86,1 @@\n-  Phase operator*() const {\n+  WeakProcessorPhase operator*() const {\n@@ -116,1 +88,1 @@\n-    return static_cast<Phase>(_index);\n+    return static_cast<WeakProcessorPhase>(_index);\n@@ -120,1 +92,0 @@\n-\n@@ -143,4 +114,0 @@\n-inline WeakProcessorPhases::Iterator WeakProcessorPhases::serial_iterator() {\n-  return Iterator(serial_phase_start, serial_phase_start + serial_phase_count);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/weakProcessorPhases.hpp","additions":6,"deletions":39,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+#include \"prims\/jvmtiTagMap.hpp\"\n@@ -1691,0 +1692,3 @@\n+    \/\/ Notify JVMTI that the tagmap table will need cleaning.\n+    JvmtiTagMap::set_needs_cleaning();\n+\n@@ -1753,0 +1757,3 @@\n+      \/\/ Notify JVMTI that oops are changed.\n+      JvmtiTagMap::set_needs_rehashing();\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -41,1 +41,0 @@\n-  ShenandoahSerialWeakRoots _serial_weak_roots;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahParallelCleaning.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -42,1 +42,1 @@\n-  _phase(phase), _weak_processing_task(num_workers), _serial_weak_roots(phase),\n+  _phase(phase), _weak_processing_task(num_workers),\n@@ -63,2 +63,0 @@\n-  } else {\n-    _serial_weak_roots.weak_oops_do(_is_alive, _keep_alive, worker_id);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahParallelCleaning.inline.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -43,1 +43,0 @@\n-  f(CNT_PREFIX ## JVMTIWeakRoots,           DESC_PREFIX \"JVMTI Weak Roots\")            \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -39,27 +39,0 @@\n-ShenandoahWeakSerialRoot::ShenandoahWeakSerialRoot(ShenandoahWeakSerialRoot::WeakOopsDo weak_oops_do,\n-  ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase) :\n-  _weak_oops_do(weak_oops_do), _phase(phase), _par_phase(par_phase) {\n-}\n-\n-void ShenandoahWeakSerialRoot::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id) {\n-  if (_claimed.try_set()) {\n-    ShenandoahWorkerTimingsTracker timer(_phase, _par_phase, worker_id);\n-    _weak_oops_do(is_alive, keep_alive);\n-  }\n-}\n-\n-#if INCLUDE_JVMTI\n-ShenandoahJVMTIWeakRoot::ShenandoahJVMTIWeakRoot(ShenandoahPhaseTimings::Phase phase) :\n-  ShenandoahWeakSerialRoot(&JvmtiExport::weak_oops_do, phase, ShenandoahPhaseTimings::JVMTIWeakRoots) {\n-}\n-#endif \/\/ INCLUDE_JVMTI\n-\n-void ShenandoahSerialWeakRoots::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id) {\n-  JVMTI_ONLY(_jvmti_weak_roots.weak_oops_do(is_alive, keep_alive, worker_id);)\n-}\n-\n-void ShenandoahSerialWeakRoots::weak_oops_do(OopClosure* cl, uint worker_id) {\n-  AlwaysTrueClosure always_true;\n-  weak_oops_do(&always_true, cl, worker_id);\n-}\n-\n@@ -191,1 +164,0 @@\n-  _serial_weak_roots(phase),\n@@ -207,3 +179,0 @@\n-  \/\/ Process serial-claiming roots first\n-  _serial_weak_roots.weak_oops_do(oops, worker_id);\n-\n@@ -235,1 +204,0 @@\n-  _serial_weak_roots(phase),\n@@ -246,1 +214,0 @@\n-  _serial_weak_roots(phase),\n@@ -262,3 +229,0 @@\n-  \/\/ Process serial-claiming roots first\n-  _serial_weak_roots.weak_oops_do(oops, worker_id);\n-\n@@ -281,1 +245,0 @@\n-   _serial_weak_roots(ShenandoahPhaseTimings::heap_iteration_roots),\n@@ -297,3 +260,0 @@\n-   \/\/ Process serial-claiming roots first\n-   _serial_weak_roots.weak_oops_do(oops, 0);\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.cpp","additions":0,"deletions":40,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -37,33 +37,0 @@\n-class ShenandoahWeakSerialRoot {\n-  typedef void (*WeakOopsDo)(BoolObjectClosure*, OopClosure*);\n-private:\n-  ShenandoahSharedFlag                   _claimed;\n-  const WeakOopsDo                       _weak_oops_do;\n-  const ShenandoahPhaseTimings::Phase    _phase;\n-  const ShenandoahPhaseTimings::ParPhase _par_phase;\n-\n-public:\n-  ShenandoahWeakSerialRoot(WeakOopsDo oops_do,\n-          ShenandoahPhaseTimings::Phase phase, ShenandoahPhaseTimings::ParPhase par_phase);\n-  void weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id);\n-};\n-\n-#if INCLUDE_JVMTI\n-class ShenandoahJVMTIWeakRoot : public ShenandoahWeakSerialRoot {\n-public:\n-  ShenandoahJVMTIWeakRoot(ShenandoahPhaseTimings::Phase phase);\n-};\n-#endif \/\/ INCLUDE_JVMTI\n-\n-class ShenandoahSerialWeakRoots {\n-private:\n-  JVMTI_ONLY(ShenandoahJVMTIWeakRoot _jvmti_weak_roots;)\n-public:\n-  ShenandoahSerialWeakRoots(ShenandoahPhaseTimings::Phase phase)\n-  JVMTI_ONLY(: _jvmti_weak_roots(phase))\n-  {};\n-\n-  void weak_oops_do(BoolObjectClosure* is_alive, OopClosure* keep_alive, uint worker_id);\n-  void weak_oops_do(OopClosure* cl, uint worker_id);\n-};\n-\n@@ -221,1 +188,0 @@\n-  ShenandoahSerialWeakRoots                                _serial_weak_roots;\n@@ -239,1 +205,0 @@\n-  ShenandoahSerialWeakRoots                                 _serial_weak_roots;\n@@ -259,1 +224,0 @@\n-  ShenandoahSerialWeakRoots                                 _serial_weak_roots;\n@@ -278,1 +242,0 @@\n-  ShenandoahSerialWeakRoots                                 _serial_weak_roots;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.hpp","additions":0,"deletions":37,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -201,3 +201,0 @@\n-  \/\/ Process serial-claiming roots first\n-  _serial_weak_roots.weak_oops_do(is_alive, keep_alive, worker_id);\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.inline.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -105,3 +105,0 @@\n-  } else if (verify(SerialWeakRoots)) {\n-    shenandoah_assert_safepoint();\n-    serial_weak_roots_do(oops);\n@@ -163,8 +160,0 @@\n-void ShenandoahRootVerifier::serial_weak_roots_do(OopClosure* cl) {\n-  WeakProcessorPhases::Iterator itr = WeakProcessorPhases::serial_iterator();\n-  AlwaysTrueClosure always_true;\n-  for ( ; !itr.is_end(); ++itr) {\n-    WeakProcessorPhases::processor(*itr)(&always_true, cl);\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootVerifier.cpp","additions":0,"deletions":11,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -75,1 +75,0 @@\n-  void serial_weak_roots_do(OopClosure* cl);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootVerifier.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"prims\/jvmtiTagMap.hpp\"\n@@ -303,3 +304,0 @@\n-  \/\/ Process weak roots\n-  _weak_roots_processor.process_weak_roots();\n-\n@@ -309,0 +307,3 @@\n+  \/\/ Notify JVMTI that some tagmap entry objects may have died.\n+  JvmtiTagMap::set_needs_cleaning();\n+\n@@ -449,2 +450,2 @@\n-  \/\/ Remap\/Relocate roots\n-  _relocate.start();\n+  \/\/ Notify JVMTI\n+  JvmtiTagMap::set_needs_rehashing();\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.cpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -166,1 +166,0 @@\n-    _weak_roots(),\n@@ -293,3 +292,0 @@\n-\n-  AlwaysTrueClosure is_alive;\n-  _weak_roots.apply(&is_alive, &cl);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -56,1 +56,0 @@\n-  ZWeakRootsIterator           _weak_roots;\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n","filename":"src\/hotspot\/share\/gc\/z\/zOopClosures.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -58,26 +58,0 @@\n-class ZRelocateRootsTask : public ZTask {\n-private:\n-  ZRelocateRootsIteratorClosure _cl;\n-\n-public:\n-  ZRelocateRootsTask() :\n-      ZTask(\"ZRelocateRootsTask\") {}\n-\n-  virtual void work() {\n-    \/\/ Allocation path assumes that relocating GC threads are ZWorkers\n-    assert(ZThread::is_worker(), \"Relocation code needs to be run as a worker\");\n-    assert(ZThread::worker_id() == 0, \"No multi-thread support\");\n-\n-    \/\/ During relocation we need to visit the JVMTI\n-    \/\/ tag map to rehash the entries with the new oop addresses.\n-    ZStatTimer timer(ZSubPhasePauseRootsJVMTITagMap);\n-    AlwaysTrueClosure always_alive;\n-    JvmtiTagMap::weak_oops_do(&always_alive, &_cl);\n-  }\n-};\n-\n-void ZRelocate::start() {\n-  ZRelocateRootsTask task;\n-  _workers->run_serial(&task);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zRelocate.cpp","additions":0,"deletions":26,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-static const ZStatSubPhase ZSubPhasePauseWeakRootsJVMTITagMap(\"Pause Weak Roots JVMTITagMap\");\n@@ -56,6 +55,0 @@\n-template <typename Iterator>\n-void ZSerialWeakApply<Iterator>::apply(BoolObjectClosure* is_alive, OopClosure* cl) {\n-  if (!Atomic::load(&_claimed) && Atomic::cmpxchg(&_claimed, false, true) == false) {\n-    _iter.apply(is_alive, cl);\n-  }\n-}\n@@ -132,14 +125,0 @@\n-ZWeakRootsIterator::ZWeakRootsIterator() :\n-    _jvmti_tag_map() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Should be at safepoint\");\n-}\n-\n-void ZWeakRootsIterator::apply(BoolObjectClosure* is_alive, OopClosure* cl) {\n-  _jvmti_tag_map.apply(is_alive, cl);\n-}\n-\n-void ZJVMTITagMapIterator::apply(BoolObjectClosure* is_alive, OopClosure* cl) {\n-  ZStatTimer timer(ZSubPhasePauseWeakRootsJVMTITagMap);\n-  JvmtiTagMap::weak_oops_do(is_alive, cl);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zRootsIterator.cpp","additions":0,"deletions":21,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -51,14 +51,0 @@\n-template <typename Iterator>\n-class ZSerialWeakApply {\n-private:\n-  Iterator      _iter;\n-  volatile bool _claimed;\n-\n-public:\n-  ZSerialWeakApply() :\n-      _iter(),\n-      _claimed(false) {}\n-\n-  void apply(BoolObjectClosure* is_alive, OopClosure* cl);\n-};\n-\n@@ -128,15 +114,0 @@\n-class ZJVMTITagMapIterator {\n-public:\n-  void apply(BoolObjectClosure* is_alive, OopClosure* cl);\n-};\n-\n-class ZWeakRootsIterator {\n-private:\n-  ZSerialWeakApply<ZJVMTITagMapIterator> _jvmti_tag_map;\n-\n-public:\n-  ZWeakRootsIterator();\n-\n-  void apply(BoolObjectClosure* is_alive, OopClosure* cl);\n-};\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zRootsIterator.hpp","additions":0,"deletions":29,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"gc\/z\/zOopClosures.hpp\"\n+#include \"gc\/z\/zOopClosures.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/z\/zUnload.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -267,7 +267,0 @@\n-void ZVerify::roots_weak() {\n-  AlwaysTrueClosure is_alive;\n-  ZVerifyRootClosure cl(true \/* verify_fixed *\/);\n-  ZWeakRootsIterator iter;\n-  iter.apply(&is_alive, &cl);\n-}\n-\n@@ -287,1 +280,0 @@\n-      roots_weak();\n","filename":"src\/hotspot\/share\/gc\/z\/zVerify.cpp","additions":0,"deletions":8,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-  static void roots_weak();\n","filename":"src\/hotspot\/share\/gc\/z\/zVerify.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -32,21 +32,0 @@\n-class ZProcessWeakRootsTask : public ZTask {\n-private:\n-  ZWeakRootsIterator _weak_roots;\n-\n-public:\n-  ZProcessWeakRootsTask() :\n-      ZTask(\"ZProcessWeakRootsTask\"),\n-      _weak_roots() {}\n-\n-  virtual void work() {\n-    ZPhantomIsAliveObjectClosure is_alive;\n-    ZPhantomKeepAliveOopClosure keep_alive;\n-    _weak_roots.apply(&is_alive, &keep_alive);\n-  }\n-};\n-\n-void ZWeakRootsProcessor::process_weak_roots() {\n-  ZProcessWeakRootsTask task;\n-  _workers->run_serial(&task);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/z\/zWeakRootsProcessor.cpp","additions":0,"deletions":21,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"prims\/jvmtiTagMap.hpp\"\n@@ -307,0 +308,2 @@\n+\n+  static void flush_object_free_events(JvmtiEnvBase *env);\n@@ -397,0 +400,12 @@\n+void\n+JvmtiEventControllerPrivate::flush_object_free_events(JvmtiEnvBase* env) {\n+  \/\/ Some of the objects recorded by this env may have died.  If we're\n+  \/\/ (potentially) changing the enable state for ObjectFree events, we\n+  \/\/ need to ensure the env is cleaned up and any events that should\n+  \/\/ be posted are posted.\n+  JvmtiTagMap* tag_map = env->tag_map_acquire();\n+  if (tag_map != NULL) {\n+    tag_map->flush_object_free_events();\n+  }\n+}\n+\n@@ -688,0 +703,3 @@\n+  \/\/ May be changing the event handler for ObjectFree.\n+  flush_object_free_events(env);\n+\n@@ -800,0 +818,4 @@\n+  if (event_type == JVMTI_EVENT_OBJECT_FREE) {\n+    flush_object_free_events(env);\n+  }\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiEventController.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -683,0 +683,1 @@\n+static OopStorage* _weak_tag_storage = NULL;\n@@ -689,0 +690,5 @@\n+OopStorage* JvmtiExport::weak_tag_storage() {\n+  assert(_weak_tag_storage != NULL, \"not yet initialized\");\n+  return _weak_tag_storage;\n+}\n+\n@@ -693,0 +699,2 @@\n+  _weak_tag_storage  = OopStorageSet::create_weak(\"JVMTI Tag Weak OopStorage\");\n+  _weak_tag_storage->register_num_dead_callback(&JvmtiTagMap::gc_notification);\n@@ -1482,1 +1490,0 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be executed at safepoint\");\n@@ -2639,4 +2646,0 @@\n-void JvmtiExport::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {\n-  JvmtiTagMap::weak_oops_do(is_alive, f);\n-}\n-\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -170,0 +170,1 @@\n+  static OopStorage* weak_tag_storage();\n@@ -410,2 +411,0 @@\n-  static void weak_oops_do(BoolObjectClosure* b, OopClosure* f) NOT_JVMTI_RETURN;\n-\n","filename":"src\/hotspot\/share\/prims\/jvmtiExport.hpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"prims\/jvmtiTagMapTable.hpp\"\n@@ -53,0 +54,1 @@\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n@@ -58,0 +60,2 @@\n+#include \"runtime\/safepoint.hpp\"\n+#include \"runtime\/timerTrace.hpp\"\n@@ -64,3 +68,0 @@\n-#if INCLUDE_ZGC\n-#include \"gc\/z\/zGlobals.hpp\"\n-#endif\n@@ -68,369 +69,1 @@\n-\/\/ JvmtiTagHashmapEntry\n-\/\/\n-\/\/ Each entry encapsulates a reference to the tagged object\n-\/\/ and the tag value. In addition an entry includes a next pointer which\n-\/\/ is used to chain entries together.\n-\n-class JvmtiTagHashmapEntry : public CHeapObj<mtInternal> {\n- private:\n-  friend class JvmtiTagMap;\n-\n-  oop _object;                          \/\/ tagged object\n-  jlong _tag;                           \/\/ the tag\n-  JvmtiTagHashmapEntry* _next;          \/\/ next on the list\n-\n-  inline void init(oop object, jlong tag) {\n-    _object = object;\n-    _tag = tag;\n-    _next = NULL;\n-  }\n-\n-  \/\/ constructor\n-  JvmtiTagHashmapEntry(oop object, jlong tag) { init(object, tag); }\n-\n- public:\n-\n-  \/\/ accessor methods\n-  inline oop* object_addr() { return &_object; }\n-  inline oop object()       { return NativeAccess<ON_PHANTOM_OOP_REF>::oop_load(object_addr()); }\n-  \/\/ Peek at the object without keeping it alive. The returned object must be\n-  \/\/ kept alive using a normal access if it leaks out of a thread transition from VM.\n-  inline oop object_peek()  {\n-    return NativeAccess<ON_PHANTOM_OOP_REF | AS_NO_KEEPALIVE>::oop_load(object_addr());\n-  }\n-\n-  inline oop object_raw() {\n-    return RawAccess<>::oop_load(object_addr());\n-  }\n-\n-  inline jlong tag() const  { return _tag; }\n-\n-  inline void set_tag(jlong tag) {\n-    assert(tag != 0, \"can't be zero\");\n-    _tag = tag;\n-  }\n-\n-  inline bool equals(oop object) {\n-    return object == object_peek();\n-  }\n-\n-  inline JvmtiTagHashmapEntry* next() const        { return _next; }\n-  inline void set_next(JvmtiTagHashmapEntry* next) { _next = next; }\n-};\n-\n-\n-\/\/ JvmtiTagHashmap\n-\/\/\n-\/\/ A hashmap is essentially a table of pointers to entries. Entries\n-\/\/ are hashed to a location, or position in the table, and then\n-\/\/ chained from that location. The \"key\" for hashing is address of\n-\/\/ the object, or oop. The \"value\" is the tag value.\n-\/\/\n-\/\/ A hashmap maintains a count of the number entries in the hashmap\n-\/\/ and resizes if the number of entries exceeds a given threshold.\n-\/\/ The threshold is specified as a percentage of the size - for\n-\/\/ example a threshold of 0.75 will trigger the hashmap to resize\n-\/\/ if the number of entries is >75% of table size.\n-\/\/\n-\/\/ A hashmap provides functions for adding, removing, and finding\n-\/\/ entries. It also provides a function to iterate over all entries\n-\/\/ in the hashmap.\n-\n-class JvmtiTagHashmap : public CHeapObj<mtInternal> {\n- private:\n-  friend class JvmtiTagMap;\n-\n-  enum {\n-    small_trace_threshold  = 10000,                  \/\/ threshold for tracing\n-    medium_trace_threshold = 100000,\n-    large_trace_threshold  = 1000000,\n-    initial_trace_threshold = small_trace_threshold\n-  };\n-\n-  static int _sizes[];                  \/\/ array of possible hashmap sizes\n-  int _size;                            \/\/ actual size of the table\n-  int _size_index;                      \/\/ index into size table\n-\n-  int _entry_count;                     \/\/ number of entries in the hashmap\n-\n-  float _load_factor;                   \/\/ load factor as a % of the size\n-  int _resize_threshold;                \/\/ computed threshold to trigger resizing.\n-  bool _resizing_enabled;               \/\/ indicates if hashmap can resize\n-\n-  int _trace_threshold;                 \/\/ threshold for trace messages\n-\n-  JvmtiTagHashmapEntry** _table;        \/\/ the table of entries.\n-\n-  \/\/ private accessors\n-  int resize_threshold() const                  { return _resize_threshold; }\n-  int trace_threshold() const                   { return _trace_threshold; }\n-\n-  \/\/ initialize the hashmap\n-  void init(int size_index=0, float load_factor=4.0f) {\n-    int initial_size =  _sizes[size_index];\n-    _size_index = size_index;\n-    _size = initial_size;\n-    _entry_count = 0;\n-    _trace_threshold = initial_trace_threshold;\n-    _load_factor = load_factor;\n-    _resize_threshold = (int)(_load_factor * _size);\n-    _resizing_enabled = true;\n-    size_t s = initial_size * sizeof(JvmtiTagHashmapEntry*);\n-    _table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);\n-    if (_table == NULL) {\n-      vm_exit_out_of_memory(s, OOM_MALLOC_ERROR,\n-        \"unable to allocate initial hashtable for jvmti object tags\");\n-    }\n-    for (int i=0; i<initial_size; i++) {\n-      _table[i] = NULL;\n-    }\n-  }\n-\n-  \/\/ hash a given key (oop) with the specified size\n-  static unsigned int hash(oop key, int size) {\n-    const unsigned int hash = Universe::heap()->hash_oop(key);\n-    return hash % size;\n-  }\n-\n-  \/\/ hash a given key (oop)\n-  unsigned int hash(oop key) {\n-    return hash(key, _size);\n-  }\n-\n-  \/\/ resize the hashmap - allocates a large table and re-hashes\n-  \/\/ all entries into the new table.\n-  void resize() {\n-    int new_size_index = _size_index+1;\n-    int new_size = _sizes[new_size_index];\n-    if (new_size < 0) {\n-      \/\/ hashmap already at maximum capacity\n-      return;\n-    }\n-\n-    \/\/ allocate new table\n-    size_t s = new_size * sizeof(JvmtiTagHashmapEntry*);\n-    JvmtiTagHashmapEntry** new_table = (JvmtiTagHashmapEntry**)os::malloc(s, mtInternal);\n-    if (new_table == NULL) {\n-      warning(\"unable to allocate larger hashtable for jvmti object tags\");\n-      set_resizing_enabled(false);\n-      return;\n-    }\n-\n-    \/\/ initialize new table\n-    int i;\n-    for (i=0; i<new_size; i++) {\n-      new_table[i] = NULL;\n-    }\n-\n-    \/\/ rehash all entries into the new table\n-    for (i=0; i<_size; i++) {\n-      JvmtiTagHashmapEntry* entry = _table[i];\n-      while (entry != NULL) {\n-        JvmtiTagHashmapEntry* next = entry->next();\n-        oop key = entry->object_peek();\n-        assert(key != NULL, \"jni weak reference cleared!!\");\n-        unsigned int h = hash(key, new_size);\n-        JvmtiTagHashmapEntry* anchor = new_table[h];\n-        if (anchor == NULL) {\n-          new_table[h] = entry;\n-          entry->set_next(NULL);\n-        } else {\n-          entry->set_next(anchor);\n-          new_table[h] = entry;\n-        }\n-        entry = next;\n-      }\n-    }\n-\n-    \/\/ free old table and update settings.\n-    os::free((void*)_table);\n-    _table = new_table;\n-    _size_index = new_size_index;\n-    _size = new_size;\n-\n-    \/\/ compute new resize threshold\n-    _resize_threshold = (int)(_load_factor * _size);\n-  }\n-\n-\n-  \/\/ internal remove function - remove an entry at a given position in the\n-  \/\/ table.\n-  inline void remove(JvmtiTagHashmapEntry* prev, int pos, JvmtiTagHashmapEntry* entry) {\n-    assert(pos >= 0 && pos < _size, \"out of range\");\n-    if (prev == NULL) {\n-      _table[pos] = entry->next();\n-    } else {\n-      prev->set_next(entry->next());\n-    }\n-    assert(_entry_count > 0, \"checking\");\n-    _entry_count--;\n-  }\n-\n-  \/\/ resizing switch\n-  bool is_resizing_enabled() const          { return _resizing_enabled; }\n-  void set_resizing_enabled(bool enable)    { _resizing_enabled = enable; }\n-\n-  \/\/ debugging\n-  void print_memory_usage();\n-  void compute_next_trace_threshold();\n-\n- public:\n-\n-  \/\/ create a JvmtiTagHashmap of a preferred size and optionally a load factor.\n-  \/\/ The preferred size is rounded down to an actual size.\n-  JvmtiTagHashmap(int size, float load_factor=0.0f) {\n-    int i=0;\n-    while (_sizes[i] < size) {\n-      if (_sizes[i] < 0) {\n-        assert(i > 0, \"sanity check\");\n-        i--;\n-        break;\n-      }\n-      i++;\n-    }\n-\n-    \/\/ if a load factor is specified then use it, otherwise use default\n-    if (load_factor > 0.01f) {\n-      init(i, load_factor);\n-    } else {\n-      init(i);\n-    }\n-  }\n-\n-  \/\/ create a JvmtiTagHashmap with default settings\n-  JvmtiTagHashmap() {\n-    init();\n-  }\n-\n-  \/\/ release table when JvmtiTagHashmap destroyed\n-  ~JvmtiTagHashmap() {\n-    if (_table != NULL) {\n-      os::free((void*)_table);\n-      _table = NULL;\n-    }\n-  }\n-\n-  \/\/ accessors\n-  int size() const                              { return _size; }\n-  JvmtiTagHashmapEntry** table() const          { return _table; }\n-  int entry_count() const                       { return _entry_count; }\n-\n-  \/\/ find an entry in the hashmap, returns NULL if not found.\n-  inline JvmtiTagHashmapEntry* find(oop key) {\n-    unsigned int h = hash(key);\n-    JvmtiTagHashmapEntry* entry = _table[h];\n-    while (entry != NULL) {\n-      if (entry->equals(key)) {\n-         return entry;\n-      }\n-      entry = entry->next();\n-    }\n-    return NULL;\n-  }\n-\n-\n-  \/\/ add a new entry to hashmap\n-  inline void add(oop key, JvmtiTagHashmapEntry* entry) {\n-    assert(key != NULL, \"checking\");\n-    assert(find(key) == NULL, \"duplicate detected\");\n-    unsigned int h = hash(key);\n-    JvmtiTagHashmapEntry* anchor = _table[h];\n-    if (anchor == NULL) {\n-      _table[h] = entry;\n-      entry->set_next(NULL);\n-    } else {\n-      entry->set_next(anchor);\n-      _table[h] = entry;\n-    }\n-\n-    _entry_count++;\n-    if (log_is_enabled(Debug, jvmti, objecttagging) && entry_count() >= trace_threshold()) {\n-      print_memory_usage();\n-      compute_next_trace_threshold();\n-    }\n-\n-    \/\/ if the number of entries exceed the threshold then resize\n-    if (entry_count() > resize_threshold() && is_resizing_enabled()) {\n-      resize();\n-    }\n-  }\n-\n-  \/\/ remove an entry with the given key.\n-  inline JvmtiTagHashmapEntry* remove(oop key) {\n-    unsigned int h = hash(key);\n-    JvmtiTagHashmapEntry* entry = _table[h];\n-    JvmtiTagHashmapEntry* prev = NULL;\n-    while (entry != NULL) {\n-      if (entry->equals(key)) {\n-        break;\n-      }\n-      prev = entry;\n-      entry = entry->next();\n-    }\n-    if (entry != NULL) {\n-      remove(prev, h, entry);\n-    }\n-    return entry;\n-  }\n-\n-  \/\/ iterate over all entries in the hashmap\n-  void entry_iterate(JvmtiTagHashmapEntryClosure* closure);\n-};\n-\n-\/\/ possible hashmap sizes - odd primes that roughly double in size.\n-\/\/ To avoid excessive resizing the odd primes from 4801-76831 and\n-\/\/ 76831-307261 have been removed. The list must be terminated by -1.\n-int JvmtiTagHashmap::_sizes[] =  { 4801, 76831, 307261, 614563, 1228891,\n-    2457733, 4915219, 9830479, 19660831, 39321619, 78643219, -1 };\n-\n-\n-\/\/ A supporting class for iterating over all entries in Hashmap\n-class JvmtiTagHashmapEntryClosure {\n- public:\n-  virtual void do_entry(JvmtiTagHashmapEntry* entry) = 0;\n-};\n-\n-\n-\/\/ iterate over all entries in the hashmap\n-void JvmtiTagHashmap::entry_iterate(JvmtiTagHashmapEntryClosure* closure) {\n-  for (int i=0; i<_size; i++) {\n-    JvmtiTagHashmapEntry* entry = _table[i];\n-    JvmtiTagHashmapEntry* prev = NULL;\n-    while (entry != NULL) {\n-      \/\/ obtain the next entry before invoking do_entry - this is\n-      \/\/ necessary because do_entry may remove the entry from the\n-      \/\/ hashmap.\n-      JvmtiTagHashmapEntry* next = entry->next();\n-      closure->do_entry(entry);\n-      entry = next;\n-     }\n-  }\n-}\n-\n-\/\/ debugging\n-void JvmtiTagHashmap::print_memory_usage() {\n-  intptr_t p = (intptr_t)this;\n-  tty->print(\"[JvmtiTagHashmap @ \" INTPTR_FORMAT, p);\n-\n-  \/\/ table + entries in KB\n-  int hashmap_usage = (size()*sizeof(JvmtiTagHashmapEntry*) +\n-    entry_count()*sizeof(JvmtiTagHashmapEntry))\/K;\n-\n-  int weak_globals_usage = (int)(JNIHandles::weak_global_handle_memory_usage()\/K);\n-  tty->print_cr(\", %d entries (%d KB) <JNI weak globals: %d KB>]\",\n-    entry_count(), hashmap_usage, weak_globals_usage);\n-}\n-\n-\/\/ compute threshold for the next trace message\n-void JvmtiTagHashmap::compute_next_trace_threshold() {\n-  _trace_threshold = entry_count();\n-  if (trace_threshold() < medium_trace_threshold) {\n-    _trace_threshold += small_trace_threshold;\n-  } else {\n-    if (trace_threshold() < large_trace_threshold) {\n-      _trace_threshold += medium_trace_threshold;\n-    } else {\n-      _trace_threshold += large_trace_threshold;\n-    }\n-  }\n-}\n+bool JvmtiTagMap::_has_object_free_events = false;\n@@ -441,4 +74,5 @@\n-  _lock(Mutex::nonleaf+2, \"JvmtiTagMap._lock\", false),\n-  _free_entries(NULL),\n-  _free_entries_count(0)\n-{\n+  _lock(Mutex::nonleaf+1, \"JvmtiTagMap_lock\", Mutex::_allow_vm_block_flag,\n+        Mutex::_safepoint_check_never),\n+  _needs_rehashing(false),\n+  _needs_cleaning(false) {\n+\n@@ -448,1 +82,1 @@\n-  _hashmap = new JvmtiTagHashmap();\n+  _hashmap = new JvmtiTagMapTable();\n@@ -454,1 +88,0 @@\n-\n@@ -459,1 +92,1 @@\n-  \/\/ also being destroryed.\n+  \/\/ also being destroyed.\n@@ -462,10 +95,0 @@\n-  JvmtiTagHashmapEntry** table = _hashmap->table();\n-  for (int j = 0; j < _hashmap->size(); j++) {\n-    JvmtiTagHashmapEntry* entry = table[j];\n-    while (entry != NULL) {\n-      JvmtiTagHashmapEntry* next = entry->next();\n-      delete entry;\n-      entry = next;\n-    }\n-  }\n-\n@@ -475,45 +98,0 @@\n-\n-  \/\/ remove any entries on the free list\n-  JvmtiTagHashmapEntry* entry = _free_entries;\n-  while (entry != NULL) {\n-    JvmtiTagHashmapEntry* next = entry->next();\n-    delete entry;\n-    entry = next;\n-  }\n-  _free_entries = NULL;\n-}\n-\n-\/\/ create a hashmap entry\n-\/\/ - if there's an entry on the (per-environment) free list then this\n-\/\/ is returned. Otherwise an new entry is allocated.\n-JvmtiTagHashmapEntry* JvmtiTagMap::create_entry(oop ref, jlong tag) {\n-  assert(Thread::current()->is_VM_thread() || is_locked(), \"checking\");\n-\n-  \/\/ ref was read with AS_NO_KEEPALIVE, or equivalent.\n-  \/\/ The object needs to be kept alive when it is published.\n-  Universe::heap()->keep_alive(ref);\n-\n-  JvmtiTagHashmapEntry* entry;\n-  if (_free_entries == NULL) {\n-    entry = new JvmtiTagHashmapEntry(ref, tag);\n-  } else {\n-    assert(_free_entries_count > 0, \"mismatched _free_entries_count\");\n-    _free_entries_count--;\n-    entry = _free_entries;\n-    _free_entries = entry->next();\n-    entry->init(ref, tag);\n-  }\n-  return entry;\n-}\n-\n-\/\/ destroy an entry by returning it to the free list\n-void JvmtiTagMap::destroy_entry(JvmtiTagHashmapEntry* entry) {\n-  assert(SafepointSynchronize::is_at_safepoint() || is_locked(), \"checking\");\n-  \/\/ limit the size of the free list\n-  if (_free_entries_count >= max_free_entries) {\n-    delete entry;\n-  } else {\n-    entry->set_next(_free_entries);\n-    _free_entries = entry;\n-    _free_entries_count++;\n-  }\n@@ -539,1 +117,1 @@\n-void JvmtiTagMap::entry_iterate(JvmtiTagHashmapEntryClosure* closure) {\n+void JvmtiTagMap::entry_iterate(JvmtiTagMapEntryClosure* closure) {\n@@ -546,1 +124,22 @@\n-  return hashmap()->entry_count() == 0;\n+  return hashmap()->is_empty();\n+}\n+\n+\/\/ This checks for posting and rehashing before operations that\n+\/\/ this tagmap table.  The calls from a JavaThread only rehash, posting is\n+\/\/ only done before heap walks.\n+void JvmtiTagMap::check_hashmap(bool post_events) {\n+  assert(!post_events || SafepointSynchronize::is_at_safepoint(), \"precondition\");\n+  assert(is_locked(), \"checking\");\n+\n+  if (is_empty()) { return; }\n+\n+  if (_needs_cleaning &&\n+      post_events &&\n+      env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+    remove_dead_entries(true \/* post_object_free *\/);\n+  }\n+  if (_needs_rehashing) {\n+    log_info(jvmti, table)(\"TagMap table needs rehashing\");\n+    hashmap()->rehash();\n+    _needs_rehashing = false;\n+  }\n@@ -549,0 +148,16 @@\n+\/\/ This checks for posting and rehashing and is called from the heap walks.\n+void JvmtiTagMap::check_hashmaps_for_heapwalk() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"called from safepoints\");\n+\n+  \/\/ Verify that the tag map tables are valid and unconditionally post events\n+  \/\/ that are expected to be posted before gc_notification.\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      \/\/ The ZDriver may be walking the hashmaps concurrently so this lock is needed.\n+      MutexLocker ml(tag_map->lock(), Mutex::_no_safepoint_check_flag);\n+      tag_map->check_hashmap(\/*post_events*\/ true);\n+    }\n+  }\n+}\n@@ -554,1 +169,1 @@\n-  JvmtiTagHashmapEntry* entry = tag_map->hashmap()->find(o);\n+  JvmtiTagMapEntry* entry = tag_map->hashmap()->find(o);\n@@ -558,0 +173,2 @@\n+    jlong tag = entry->tag();\n+    assert(tag != 0, \"should not be zero\");\n@@ -580,2 +197,2 @@\n-  JvmtiTagHashmap* _hashmap;\n-  JvmtiTagHashmapEntry* _entry;\n+  JvmtiTagMapTable* _hashmap;\n+  JvmtiTagMapEntry* _entry;\n@@ -591,2 +208,2 @@\n-  void inline post_callback_tag_update(oop o, JvmtiTagHashmap* hashmap,\n-                                       JvmtiTagHashmapEntry* entry, jlong obj_tag);\n+  void inline post_callback_tag_update(oop o, JvmtiTagMapTable* hashmap,\n+                                       JvmtiTagMapEntry* entry, jlong obj_tag);\n@@ -632,2 +249,2 @@\n-                                                      JvmtiTagHashmap* hashmap,\n-                                                      JvmtiTagHashmapEntry* entry,\n+                                                      JvmtiTagMapTable* hashmap,\n+                                                      JvmtiTagMapEntry* entry,\n@@ -639,2 +256,1 @@\n-      entry = tag_map()->create_entry(o, obj_tag);\n-      hashmap->add(o, entry);\n+      hashmap->add(o, obj_tag);\n@@ -646,5 +262,1 @@\n-\n-      JvmtiTagHashmapEntry* entry_removed = hashmap->remove(o);\n-      assert(entry_removed == entry, \"checking\");\n-      tag_map()->destroy_entry(entry);\n-\n+      hashmap->remove(o);\n@@ -677,2 +289,2 @@\n-  JvmtiTagHashmap* _referrer_hashmap;\n-  JvmtiTagHashmapEntry* _referrer_entry;\n+  JvmtiTagMapTable* _referrer_hashmap;\n+  JvmtiTagMapEntry* _referrer_entry;\n@@ -734,1 +346,6 @@\n-  MutexLocker ml(lock());\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ SetTag should not post events because the JavaThread has to\n+  \/\/ transition to native for the callback and this cannot stop for\n+  \/\/ safepoints with the hashmap lock held.\n+  check_hashmap(\/*post_events*\/ false);\n@@ -740,2 +357,2 @@\n-  JvmtiTagHashmap* hashmap = _hashmap;\n-  JvmtiTagHashmapEntry* entry = hashmap->find(o);\n+  JvmtiTagMapTable* hashmap = _hashmap;\n+  JvmtiTagMapEntry* entry = hashmap->find(o);\n@@ -746,2 +363,1 @@\n-      entry = create_entry(o, tag);\n-      hashmap->add(o, entry);\n+      hashmap->add(o, tag);\n@@ -757,1 +373,0 @@\n-      destroy_entry(entry);\n@@ -766,1 +381,6 @@\n-  MutexLocker ml(lock());\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ GetTag should not post events because the JavaThread has to\n+  \/\/ transition to native for the callback and this cannot stop for\n+  \/\/ safepoints with the hashmap lock held.\n+  check_hashmap(\/*post_events*\/ false);\n@@ -1269,0 +889,2 @@\n+    JvmtiTagMap::check_hashmaps_for_heapwalk();\n+\n@@ -1334,0 +956,8 @@\n+\n+  \/\/ skip if object is a dormant shared object whose mirror hasn't been loaded\n+  if (o != NULL && o->klass()->java_mirror() == NULL) {\n+    log_debug(cds, heap)(\"skipped dormant archived object \" INTPTR_FORMAT \" (%s)\", p2i(o),\n+                         o->klass()->external_name());\n+    return;\n+  }\n+\n@@ -1413,0 +1043,7 @@\n+  \/\/ skip if object is a dormant shared object whose mirror hasn't been loaded\n+  if (obj != NULL &&   obj->klass()->java_mirror() == NULL) {\n+    log_debug(cds, heap)(\"skipped dormant archived object \" INTPTR_FORMAT \" (%s)\", p2i(obj),\n+                         obj->klass()->external_name());\n+    return;\n+  }\n+\n@@ -1521,0 +1158,52 @@\n+void JvmtiTagMap::remove_dead_entries(bool post_object_free) {\n+  assert(is_locked(), \"precondition\");\n+  if (_needs_cleaning) {\n+    log_info(jvmti, table)(\"TagMap table needs cleaning%s\",\n+                           (post_object_free ? \" and posting\" : \"\"));\n+    hashmap()->remove_dead_entries(env(), post_object_free);\n+    _needs_cleaning = false;\n+  }\n+}\n+\n+void JvmtiTagMap::remove_dead_entries_locked(bool post_object_free) {\n+  MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+  remove_dead_entries(post_object_free);\n+}\n+\n+class VM_JvmtiPostObjectFree: public VM_Operation {\n+  JvmtiTagMap* _tag_map;\n+ public:\n+  VM_JvmtiPostObjectFree(JvmtiTagMap* tag_map) : _tag_map(tag_map) {}\n+  VMOp_Type type() const { return VMOp_Cleanup; }\n+  void doit() {\n+    _tag_map->remove_dead_entries_locked(true \/* post_object_free *\/);\n+  }\n+\n+  \/\/ Doesn't need a safepoint, just the VM thread\n+  virtual bool evaluate_at_safepoint() const { return false; }\n+};\n+\n+\/\/ PostObjectFree can't be called by JavaThread, so call it from the VM thread.\n+void JvmtiTagMap::post_dead_objects_on_vm_thread() {\n+  VM_JvmtiPostObjectFree op(this);\n+  VMThread::execute(&op);\n+}\n+\n+void JvmtiTagMap::flush_object_free_events() {\n+  assert_not_at_safepoint();\n+  if (env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+    {\n+      MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+      if (!_needs_cleaning || is_empty()) {\n+        _needs_cleaning = false;\n+        return;\n+      }\n+    } \/\/ Drop the lock so we can do the cleaning on the VM thread.\n+    \/\/ Needs both cleaning and event posting (up to some other thread\n+    \/\/ getting there first after we dropped the lock).\n+    post_dead_objects_on_vm_thread();\n+  } else {\n+    remove_dead_entries_locked(false);\n+  }\n+}\n+\n@@ -1523,1 +1212,1 @@\n-class TagObjectCollector : public JvmtiTagHashmapEntryClosure {\n+class TagObjectCollector : public JvmtiTagMapEntryClosure {\n@@ -1526,0 +1215,1 @@\n+  JavaThread* _thread;\n@@ -1528,0 +1218,1 @@\n+  bool _some_dead_found;\n@@ -1533,7 +1224,8 @@\n-  TagObjectCollector(JvmtiEnv* env, const jlong* tags, jint tag_count) {\n-    _env = env;\n-    _tags = (jlong*)tags;\n-    _tag_count = tag_count;\n-    _object_results = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jobject>(1, mtServiceability);\n-    _tag_results = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<uint64_t>(1, mtServiceability);\n-  }\n+  TagObjectCollector(JvmtiEnv* env, const jlong* tags, jint tag_count) :\n+    _env(env),\n+    _thread(JavaThread::current()),\n+    _tags((jlong*)tags),\n+    _tag_count(tag_count),\n+    _some_dead_found(false),\n+    _object_results(new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<jobject>(1, mtServiceability)),\n+    _tag_results(new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<uint64_t>(1, mtServiceability)) { }\n@@ -1546,0 +1238,2 @@\n+  bool some_dead_found() const { return _some_dead_found; }\n+\n@@ -1550,1 +1244,1 @@\n-  void do_entry(JvmtiTagHashmapEntry* entry) {\n+  void do_entry(JvmtiTagMapEntry* entry) {\n@@ -1558,0 +1252,5 @@\n+        if (o == NULL) {\n+          _some_dead_found = true;\n+          \/\/ skip this whole entry\n+          return;\n+        }\n@@ -1559,1 +1258,1 @@\n-        jobject ref = JNIHandles::make_local(JavaThread::current(), o);\n+        jobject ref = JNIHandles::make_local(_thread, o);\n@@ -1612,1 +1311,5 @@\n-    MutexLocker ml(lock());\n+    MutexLocker ml(lock(), Mutex::_no_safepoint_check_flag);\n+    \/\/ Can't post ObjectFree events here from a JavaThread, so this\n+    \/\/ will race with the gc_notification thread in the tiny\n+    \/\/ window where the object is not marked but hasn't been notified that\n+    \/\/ it is collected yet.\n@@ -1615,0 +1318,3 @@\n+  if (collector.some_dead_found() && env()->is_enabled(JVMTI_EVENT_OBJECT_FREE)) {\n+    post_dead_objects_on_vm_thread();\n+  }\n@@ -1675,0 +1381,1 @@\n+  assert(SafepointSynchronize::is_at_safepoint(), \"must be at a safepoint\");\n@@ -3215,0 +2922,2 @@\n+  JvmtiTagMap::check_hashmaps_for_heapwalk();\n+\n@@ -3301,0 +3010,5 @@\n+\/\/ Concurrent GC needs to call this in relocation pause, so after the objects are moved\n+\/\/ and have their new addresses, the table can be rehashed.\n+void JvmtiTagMap::set_needs_rehashing() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"called in gc pause\");\n+  assert(Thread::current()->is_VM_thread(), \"should be the VM thread\");\n@@ -3302,14 +3016,5 @@\n-void JvmtiTagMap::weak_oops_do(BoolObjectClosure* is_alive, OopClosure* f) {\n-  \/\/ No locks during VM bring-up (0 threads) and no safepoints after main\n-  \/\/ thread creation and before VMThread creation (1 thread); initial GC\n-  \/\/ verification can happen in that window which gets to here.\n-  assert(Threads::number_of_threads() <= 1 ||\n-         SafepointSynchronize::is_at_safepoint(),\n-         \"must be executed at a safepoint\");\n-  if (JvmtiEnv::environments_might_exist()) {\n-    JvmtiEnvIterator it;\n-    for (JvmtiEnvBase* env = it.first(); env != NULL; env = it.next(env)) {\n-      JvmtiTagMap* tag_map = env->tag_map_acquire();\n-      if (tag_map != NULL && !tag_map->is_empty()) {\n-        tag_map->do_weak_oops(is_alive, f);\n-      }\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      tag_map->_needs_rehashing = true;\n@@ -3320,10 +3025,2 @@\n-void JvmtiTagMap::do_weak_oops(BoolObjectClosure* is_alive, OopClosure* f) {\n-\n-  \/\/ does this environment have the OBJECT_FREE event enabled\n-  bool post_object_free = env()->is_enabled(JVMTI_EVENT_OBJECT_FREE);\n-\n-  \/\/ counters used for trace message\n-  int freed = 0;\n-  int moved = 0;\n-\n-  JvmtiTagHashmap* hashmap = this->hashmap();\n+\/\/ Verify gc_notification follows set_needs_cleaning.\n+DEBUG_ONLY(static bool notified_needs_cleaning = false;)\n@@ -3331,2 +3028,6 @@\n-  \/\/ reenable sizing (if disabled)\n-  hashmap->set_resizing_enabled(true);\n+void JvmtiTagMap::set_needs_cleaning() {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"called in gc pause\");\n+  assert(Thread::current()->is_VM_thread(), \"should be the VM thread\");\n+  \/\/ Can't assert !notified_needs_cleaning; a partial GC might be upgraded\n+  \/\/ to a full GC and do this twice without intervening gc_notification.\n+  DEBUG_ONLY(notified_needs_cleaning = true;)\n@@ -3334,3 +3035,6 @@\n-  \/\/ if the hashmap is empty then we can skip it\n-  if (hashmap->_entry_count == 0) {\n-    return;\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      tag_map->_needs_cleaning = !tag_map->is_empty();\n+    }\n@@ -3338,0 +3042,1 @@\n+}\n@@ -3339,24 +3044,3 @@\n-  \/\/ now iterate through each entry in the table\n-\n-  JvmtiTagHashmapEntry** table = hashmap->table();\n-  int size = hashmap->size();\n-\n-  JvmtiTagHashmapEntry* delayed_add = NULL;\n-\n-  for (int pos = 0; pos < size; ++pos) {\n-    JvmtiTagHashmapEntry* entry = table[pos];\n-    JvmtiTagHashmapEntry* prev = NULL;\n-\n-    while (entry != NULL) {\n-      JvmtiTagHashmapEntry* next = entry->next();\n-\n-      \/\/ has object been GC'ed\n-      if (!is_alive->do_object_b(entry->object_raw())) {\n-        \/\/ grab the tag\n-        jlong tag = entry->tag();\n-        guarantee(tag != 0, \"checking\");\n-\n-        \/\/ remove GC'ed entry from hashmap and return the\n-        \/\/ entry to the free list\n-        hashmap->remove(prev, pos, entry);\n-        destroy_entry(entry);\n+void JvmtiTagMap::gc_notification(size_t num_dead_entries) {\n+  assert(notified_needs_cleaning, \"missing GC notification\");\n+  DEBUG_ONLY(notified_needs_cleaning = false;)\n@@ -3364,4 +3048,6 @@\n-        \/\/ post the event to the profiler\n-        if (post_object_free) {\n-          JvmtiExport::post_object_free(env(), tag);\n-        }\n+  \/\/ Notify ServiceThread if there's work to do.\n+  {\n+    MonitorLocker ml(Service_lock, Mutex::_no_safepoint_check_flag);\n+    _has_object_free_events = (num_dead_entries != 0);\n+    if (_has_object_free_events) ml.notify_all();\n+  }\n@@ -3369,28 +3055,8 @@\n-        ++freed;\n-      } else {\n-        f->do_oop(entry->object_addr());\n-        oop new_oop = entry->object_raw();\n-\n-        \/\/ if the object has moved then re-hash it and move its\n-        \/\/ entry to its new location.\n-        unsigned int new_pos = JvmtiTagHashmap::hash(new_oop, size);\n-        if (new_pos != (unsigned int)pos) {\n-          if (prev == NULL) {\n-            table[pos] = next;\n-          } else {\n-            prev->set_next(next);\n-          }\n-          if (new_pos < (unsigned int)pos) {\n-            entry->set_next(table[new_pos]);\n-            table[new_pos] = entry;\n-          } else {\n-            \/\/ Delay adding this entry to it's new position as we'd end up\n-            \/\/ hitting it again during this iteration.\n-            entry->set_next(delayed_add);\n-            delayed_add = entry;\n-          }\n-          moved++;\n-        } else {\n-          \/\/ object didn't move\n-          prev = entry;\n-        }\n+  \/\/ If no dead entries then cancel cleaning requests.\n+  if (num_dead_entries == 0) {\n+    JvmtiEnvIterator it;\n+    for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+      JvmtiTagMap* tag_map = env->tag_map_acquire();\n+      if (tag_map != NULL) {\n+        MutexLocker ml (tag_map->lock(), Mutex::_no_safepoint_check_flag);\n+        tag_map->_needs_cleaning = false;\n@@ -3398,2 +3064,0 @@\n-\n-      entry = next;\n@@ -3402,0 +3066,1 @@\n+}\n@@ -3403,8 +3068,7 @@\n-  \/\/ Re-add all the entries which were kept aside\n-  while (delayed_add != NULL) {\n-    JvmtiTagHashmapEntry* next = delayed_add->next();\n-    unsigned int pos = JvmtiTagHashmap::hash(delayed_add->object_raw(), size);\n-    delayed_add->set_next(table[pos]);\n-    table[pos] = delayed_add;\n-    delayed_add = next;\n-  }\n+\/\/ Used by ServiceThread to discover there is work to do.\n+bool JvmtiTagMap::has_object_free_events_and_reset() {\n+  assert_lock_strong(Service_lock);\n+  bool result = _has_object_free_events;\n+  _has_object_free_events = false;\n+  return result;\n+}\n@@ -3412,2 +3076,11 @@\n-  log_debug(jvmti, objecttagging)(\"(%d->%d, %d freed, %d total moves)\",\n-                                  hashmap->_entry_count + freed, hashmap->_entry_count, freed, moved);\n+\/\/ Used by ServiceThread to clean up tagmaps.\n+void JvmtiTagMap::flush_all_object_free_events() {\n+  JavaThread* thread = JavaThread::current();\n+  JvmtiEnvIterator it;\n+  for (JvmtiEnv* env = it.first(); env != NULL; env = it.next(env)) {\n+    JvmtiTagMap* tag_map = env->tag_map_acquire();\n+    if (tag_map != NULL) {\n+      tag_map->flush_object_free_events();\n+      ThreadBlockInVM tbiv(thread); \/\/ Be safepoint-polite while looping.\n+    }\n+  }\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.cpp","additions":240,"deletions":567,"binary":false,"changes":807,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,1 +30,0 @@\n-#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -32,1 +31,0 @@\n-#include \"jvmtifiles\/jvmtiEnv.hpp\"\n@@ -35,4 +33,3 @@\n-\/\/ forward references\n-class JvmtiTagHashmap;\n-class JvmtiTagHashmapEntry;\n-class JvmtiTagHashmapEntryClosure;\n+class JvmtiEnv;\n+class JvmtiTagMapTable;\n+class JvmtiTagMapEntryClosure;\n@@ -43,4 +40,0 @@\n-  enum{\n-    max_free_entries = 4096         \/\/ maximum number of free entries per env\n-  };\n-\n@@ -49,1 +42,3 @@\n-  JvmtiTagHashmap*      _hashmap;                   \/\/ the hashmap\n+  JvmtiTagMapTable*     _hashmap;                   \/\/ the hashmap for tags\n+  bool                  _needs_rehashing;\n+  bool                  _needs_cleaning;\n@@ -51,2 +46,1 @@\n-  JvmtiTagHashmapEntry* _free_entries;              \/\/ free list for this environment\n-  int _free_entries_count;                          \/\/ number of entries on the free list\n+  static bool           _has_object_free_events;\n@@ -61,1 +55,1 @@\n-  void do_weak_oops(BoolObjectClosure* is_alive, OopClosure* f);\n+  void check_hashmap(bool post_events);\n@@ -63,2 +57,2 @@\n-  \/\/ iterate over all entries in this tag map\n-  void entry_iterate(JvmtiTagHashmapEntryClosure* closure);\n+  void entry_iterate(JvmtiTagMapEntryClosure* closure);\n+  void post_dead_objects_on_vm_thread();\n@@ -67,1 +61,0 @@\n-\n@@ -71,5 +64,1 @@\n-  JvmtiTagHashmap* hashmap() { return _hashmap; }\n-\n-  \/\/ create\/destroy entries\n-  JvmtiTagHashmapEntry* create_entry(oop ref, jlong tag);\n-  void destroy_entry(JvmtiTagHashmapEntry* entry);\n+  JvmtiTagMapTable* hashmap() { return _hashmap; }\n@@ -123,2 +112,14 @@\n-  static void weak_oops_do(\n-      BoolObjectClosure* is_alive, OopClosure* f) NOT_JVMTI_RETURN;\n+\n+  void remove_dead_entries(bool post_object_free);\n+  void remove_dead_entries_locked(bool post_object_free);\n+\n+  static void check_hashmaps_for_heapwalk();\n+  static void set_needs_rehashing() NOT_JVMTI_RETURN;\n+  static void set_needs_cleaning() NOT_JVMTI_RETURN;\n+  static void gc_notification(size_t num_dead_entries) NOT_JVMTI_RETURN;\n+\n+  void flush_object_free_events();\n+\n+  \/\/ For ServiceThread\n+  static void flush_all_object_free_events();\n+  static bool has_object_free_events_and_reset();\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMap.hpp","additions":26,"deletions":25,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -0,0 +1,261 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shared\/oopStorage.hpp\"\n+#include \"jvmtifiles\/jvmtiEnv.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"memory\/universe.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"oops\/weakHandle.inline.hpp\"\n+#include \"prims\/jvmtiEventController.inline.hpp\"\n+#include \"prims\/jvmtiExport.hpp\"\n+#include \"prims\/jvmtiTagMapTable.hpp\"\n+#include \"utilities\/hashtable.inline.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+oop JvmtiTagMapEntry::object() {\n+  return literal().resolve();\n+}\n+\n+oop JvmtiTagMapEntry::object_no_keepalive() {\n+  \/\/ Just peek at the object without keeping it alive.\n+  return literal().peek();\n+}\n+\n+JvmtiTagMapTable::JvmtiTagMapTable()\n+  : Hashtable<WeakHandle, mtServiceability>(_table_size, sizeof(JvmtiTagMapEntry)) {}\n+\n+JvmtiTagMapTable::~JvmtiTagMapTable() {\n+  \/\/ Delete this table\n+  log_debug(jvmti, table)(\"JvmtiTagMapTable deleted\");\n+  for (int i = 0; i < table_size(); ++i) {\n+    for (JvmtiTagMapEntry* m = bucket(i); m != NULL;) {\n+      JvmtiTagMapEntry* entry = m;\n+      \/\/ read next before freeing.\n+      m = m->next();\n+      free_entry(entry);\n+    }\n+  }\n+  assert(number_of_entries() == 0, \"should have removed all entries\");\n+  assert(new_entry_free_list() == NULL, \"entry present on JvmtiTagMapTable's free list\");\n+}\n+\n+\/\/ Entries are C_Heap allocated\n+JvmtiTagMapEntry* JvmtiTagMapTable::new_entry(unsigned int hash, WeakHandle w, jlong tag) {\n+  JvmtiTagMapEntry* entry = (JvmtiTagMapEntry*)Hashtable<WeakHandle, mtServiceability>::allocate_new_entry(hash, w);\n+  entry->set_tag(tag);\n+  return entry;\n+}\n+\n+void JvmtiTagMapTable::free_entry(JvmtiTagMapEntry* entry) {\n+  unlink_entry(entry);\n+  entry->literal().release(JvmtiExport::weak_tag_storage()); \/\/ release to OopStorage\n+  FREE_C_HEAP_ARRAY(char, entry);\n+}\n+\n+unsigned int JvmtiTagMapTable::compute_hash(oop obj) {\n+  assert(obj != NULL, \"obj is null\");\n+  return Universe::heap()->hash_oop(obj);\n+}\n+\n+JvmtiTagMapEntry* JvmtiTagMapTable::find(int index, unsigned int hash, oop obj) {\n+  assert(obj != NULL, \"Cannot search for a NULL object\");\n+\n+  for (JvmtiTagMapEntry* p = bucket(index); p != NULL; p = p->next()) {\n+    if (p->hash() == hash) {\n+\n+      \/\/ Peek the object to check if it is the right target.\n+      oop target = p->object_no_keepalive();\n+\n+      \/\/ The obj is in the table as a target already\n+      if (target == obj) {\n+        ResourceMark rm;\n+        log_trace(jvmti, table)(\"JvmtiTagMap entry found for %s index %d\",\n+                                obj->print_value_string(), index);\n+        \/\/ The object() accessor makes sure the target object is kept alive before\n+        \/\/ leaking out.\n+        (void)p->object();\n+        return p;\n+      }\n+    }\n+  }\n+  return NULL;\n+}\n+\n+JvmtiTagMapEntry* JvmtiTagMapTable::find(oop obj) {\n+  unsigned int hash = compute_hash(obj);\n+  int index = hash_to_index(hash);\n+  return find(index, hash, obj);\n+}\n+\n+JvmtiTagMapEntry* JvmtiTagMapTable::add(oop obj, jlong tag) {\n+  unsigned int hash = compute_hash(obj);\n+  int index = hash_to_index(hash);\n+  \/\/ One was added while acquiring the lock\n+  assert(find(index, hash, obj) == NULL, \"shouldn't already be present\");\n+\n+  \/\/ obj was read with AS_NO_KEEPALIVE, or equivalent.\n+  \/\/ The object needs to be kept alive when it is published.\n+  Universe::heap()->keep_alive(obj);\n+\n+  WeakHandle w(JvmtiExport::weak_tag_storage(), obj);\n+  JvmtiTagMapEntry* p = new_entry(hash, w, tag);\n+  Hashtable<WeakHandle, mtServiceability>::add_entry(index, p);\n+  ResourceMark rm;\n+  log_trace(jvmti, table)(\"JvmtiTagMap entry added for %s index %d\",\n+                          obj->print_value_string(), index);\n+\n+  \/\/ Resize if the table is getting too big.\n+  resize_if_needed();\n+\n+  return p;\n+}\n+\n+void JvmtiTagMapTable::remove(oop obj) {\n+  unsigned int hash = compute_hash(obj);\n+  int index = hash_to_index(hash);\n+  JvmtiTagMapEntry** p = bucket_addr(index);\n+  JvmtiTagMapEntry* entry = bucket(index);\n+  while (entry != NULL) {\n+    oop target = entry->object_no_keepalive();\n+    if (target != NULL && target == obj) {\n+      log_trace(jvmti, table)(\"JvmtiTagMap entry removed for index %d\", index);\n+      *p = entry->next();\n+      free_entry(entry);\n+      return; \/\/ done\n+    }\n+    \/\/ get next entry and address\n+    p = entry->next_addr();\n+    entry = entry->next();\n+  }\n+}\n+\n+void JvmtiTagMapTable::entry_iterate(JvmtiTagMapEntryClosure* closure) {\n+  for (int i = 0; i < table_size(); ++i) {\n+    for (JvmtiTagMapEntry* p = bucket(i); p != NULL; p = p->next()) {\n+      closure->do_entry(p);\n+    }\n+  }\n+}\n+\n+const int _resize_load_trigger = 5;       \/\/ load factor that will trigger the resize\n+static bool _resizable = true;\n+\n+void JvmtiTagMapTable::resize_if_needed() {\n+  if (_resizable && number_of_entries() > (_resize_load_trigger*table_size())) {\n+    int desired_size = calculate_resize(true);\n+    if (desired_size == table_size()) {\n+      _resizable = false; \/\/ hit max\n+    } else {\n+      if (!resize(desired_size)) {\n+        \/\/ Something went wrong, turn resizing off\n+        _resizable = false;\n+      }\n+      log_info(jvmti, table) (\"JvmtiTagMap table resized to %d\", table_size());\n+    }\n+  }\n+}\n+\n+\/\/ Serially remove entries for dead oops from the table, and notify jvmti.\n+void JvmtiTagMapTable::remove_dead_entries(JvmtiEnv* env, bool post_object_free) {\n+  int oops_removed = 0;\n+  int oops_counted = 0;\n+  for (int i = 0; i < table_size(); ++i) {\n+    JvmtiTagMapEntry** p = bucket_addr(i);\n+    JvmtiTagMapEntry* entry = bucket(i);\n+    while (entry != NULL) {\n+      oops_counted++;\n+      oop l = entry->object_no_keepalive();\n+      if (l != NULL) {\n+        p = entry->next_addr();\n+      } else {\n+        \/\/ Entry has been removed.\n+        oops_removed++;\n+        log_trace(jvmti, table)(\"JvmtiTagMap entry removed for index %d\", i);\n+        jlong tag = entry->tag();\n+        *p = entry->next();\n+        free_entry(entry);\n+\n+        \/\/ post the event to the profiler\n+        if (post_object_free) {\n+          JvmtiExport::post_object_free(env, tag);\n+        }\n+\n+      }\n+      \/\/ get next entry\n+      entry = (JvmtiTagMapEntry*)HashtableEntry<WeakHandle, mtServiceability>::make_ptr(*p);\n+    }\n+  }\n+\n+  log_info(jvmti, table) (\"JvmtiTagMap entries counted %d removed %d; %s\",\n+                          oops_counted, oops_removed, post_object_free ? \"free object posted\" : \"no posting\");\n+}\n+\n+\/\/ Rehash oops in the table\n+void JvmtiTagMapTable::rehash() {\n+  ResourceMark rm;\n+  GrowableArray<JvmtiTagMapEntry*> moved_entries;\n+\n+  int oops_counted = 0;\n+  for (int i = 0; i < table_size(); ++i) {\n+    JvmtiTagMapEntry** p = bucket_addr(i);\n+    JvmtiTagMapEntry* entry = bucket(i);\n+    while (entry != NULL) {\n+      oops_counted++;\n+      oop l = entry->object_no_keepalive();\n+      if (l != NULL) {\n+        \/\/ Check if oop has moved, ie its hashcode is different\n+        \/\/ than the one entered in the table.\n+        unsigned int new_hash = compute_hash(l);\n+        if (entry->hash() != new_hash) {\n+          *p = entry->next();\n+          entry->set_hash(new_hash);\n+          unlink_entry(entry);\n+          moved_entries.push(entry);\n+        } else {\n+          p = entry->next_addr();\n+        }\n+      } else {\n+        \/\/ Skip removed oops. They may still have to be posted.\n+        p = entry->next_addr();\n+      }\n+      \/\/ get next entry\n+      entry = (JvmtiTagMapEntry*)HashtableEntry<WeakHandle, mtServiceability>::make_ptr(*p);\n+    }\n+  }\n+\n+  int rehash_len = moved_entries.length();\n+  \/\/ Now add back in the entries that were removed.\n+  for (int i = 0; i < rehash_len; i++) {\n+    JvmtiTagMapEntry* moved_entry = moved_entries.at(i);\n+    int index = hash_to_index(moved_entry->hash());\n+    Hashtable<WeakHandle, mtServiceability>::add_entry(index, moved_entry);\n+  }\n+\n+  log_info(jvmti, table) (\"JvmtiTagMap entries counted %d rehashed %d\",\n+                          oops_counted, rehash_len);\n+}\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMapTable.cpp","additions":261,"deletions":0,"binary":false,"changes":261,"status":"added"},{"patch":"@@ -0,0 +1,101 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_VM_PRIMS_TAGMAPTABLE_HPP\n+#define SHARE_VM_PRIMS_TAGMAPTABLE_HPP\n+\n+#include \"oops\/weakHandle.hpp\"\n+#include \"utilities\/hashtable.hpp\"\n+\n+class JvmtiEnv;\n+\n+\/\/ Hashtable to record oops used for JvmtiTagMap\n+class JvmtiTagMapEntryClosure;\n+\n+class JvmtiTagMapEntry : public HashtableEntry<WeakHandle, mtServiceability> {\n+  jlong _tag;                           \/\/ the tag\n+ public:\n+  JvmtiTagMapEntry* next() const {\n+    return (JvmtiTagMapEntry*)HashtableEntry<WeakHandle, mtServiceability>::next();\n+  }\n+\n+  JvmtiTagMapEntry** next_addr() {\n+    return (JvmtiTagMapEntry**)HashtableEntry<WeakHandle, mtServiceability>::next_addr();\n+  }\n+\n+  oop object();\n+  oop object_no_keepalive();\n+  jlong tag() const       { return _tag; }\n+  void set_tag(jlong tag) { _tag = tag; }\n+};\n+\n+class JvmtiTagMapTable : public Hashtable<WeakHandle, mtServiceability> {\n+  enum Constants {\n+    _table_size  = 1007\n+  };\n+\n+private:\n+  JvmtiTagMapEntry* bucket(int i) {\n+    return (JvmtiTagMapEntry*) Hashtable<WeakHandle, mtServiceability>::bucket(i);\n+  }\n+\n+  JvmtiTagMapEntry** bucket_addr(int i) {\n+    return (JvmtiTagMapEntry**) Hashtable<WeakHandle, mtServiceability>::bucket_addr(i);\n+  }\n+\n+  JvmtiTagMapEntry* new_entry(unsigned int hash, WeakHandle w, jlong tag);\n+  void free_entry(JvmtiTagMapEntry* entry);\n+\n+  unsigned int compute_hash(oop obj);\n+\n+  JvmtiTagMapEntry* find(int index, unsigned int hash, oop obj);\n+\n+  void resize_if_needed();\n+\n+public:\n+  JvmtiTagMapTable();\n+  ~JvmtiTagMapTable();\n+\n+  JvmtiTagMapEntry* find(oop obj);\n+  JvmtiTagMapEntry* add(oop obj, jlong tag);\n+\n+  void remove(oop obj);\n+\n+  \/\/ iterate over all entries in the hashmap\n+  void entry_iterate(JvmtiTagMapEntryClosure* closure);\n+\n+  bool is_empty() const { return number_of_entries() == 0; }\n+\n+  \/\/ Cleanup cleared entries and post\n+  void remove_dead_entries(JvmtiEnv* env, bool post_object_free);\n+  void rehash();\n+};\n+\n+\/\/ A supporting class for iterating over all entries in Hashmap\n+class JvmtiTagMapEntryClosure {\n+ public:\n+  virtual void do_entry(JvmtiTagMapEntry* entry) = 0;\n+};\n+\n+#endif \/\/ SHARE_VM_PRIMS_TAGMAPTABLE_HPP\n","filename":"src\/hotspot\/share\/prims\/jvmtiTagMapTable.hpp","additions":101,"deletions":0,"binary":false,"changes":101,"status":"added"},{"patch":"@@ -44,0 +44,1 @@\n+#include \"prims\/jvmtiTagMap.hpp\"\n@@ -150,0 +151,1 @@\n+    bool jvmti_tagmap_work = false;\n@@ -178,1 +180,2 @@\n-              (deflate_idle_monitors = ObjectSynchronizer::is_async_deflation_needed())\n+              (deflate_idle_monitors = ObjectSynchronizer::is_async_deflation_needed()) |\n+              (jvmti_tagmap_work = JvmtiTagMap::has_object_free_events_and_reset())\n@@ -247,0 +250,4 @@\n+\n+    if (jvmti_tagmap_work) {\n+      JvmtiTagMap::flush_all_object_free_events();\n+    }\n","filename":"src\/hotspot\/share\/runtime\/serviceThread.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -114,0 +114,1 @@\n+  template(JvmtiPostObjectFree)\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -40,0 +40,1 @@\n+#include \"prims\/jvmtiTagMapTable.hpp\"\n@@ -139,0 +140,25 @@\n+const double _resize_factor    = 2.0;     \/\/ by how much we will resize using current number of entries\n+const int _small_table_sizes[] = { 107, 1009, 2017, 4049, 5051, 10103, 20201, 40423 } ;\n+const int _small_array_size = sizeof(_small_table_sizes)\/sizeof(int);\n+\n+\/\/ possible hashmap sizes - odd primes that roughly double in size.\n+\/\/ To avoid excessive resizing the odd primes from 4801-76831 and\n+\/\/ 76831-307261 have been removed.\n+const int _large_table_sizes[] =  { 4801, 76831, 307261, 614563, 1228891,\n+    2457733, 4915219, 9830479, 19660831, 39321619, 78643219 };\n+const int _large_array_size = sizeof(_large_table_sizes)\/sizeof(int);\n+\n+\/\/ Calculate next \"good\" hashtable size based on requested count\n+template <MEMFLAGS F> int BasicHashtable<F>::calculate_resize(bool use_large_table_sizes) const {\n+  int requested = (int)(_resize_factor*number_of_entries());\n+  const int* primelist = use_large_table_sizes ? _large_table_sizes : _small_table_sizes;\n+  int arraysize =  use_large_table_sizes ? _large_array_size  : _small_array_size;\n+  int newsize;\n+  for (int i = 0; i < arraysize; i++) {\n+    newsize = primelist[i];\n+    if (newsize >= requested)\n+      break;\n+  }\n+  return newsize;\n+}\n+\n@@ -140,1 +166,0 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"must be at safepoint\");\n@@ -295,0 +320,1 @@\n+template class Hashtable<WeakHandle, mtServiceability>;\n@@ -312,0 +338,1 @@\n+template class BasicHashtable<mtServiceability>;\n","filename":"src\/hotspot\/share\/utilities\/hashtable.cpp","additions":28,"deletions":1,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -220,0 +220,1 @@\n+  int calculate_resize(bool use_large_table_sizes) const;\n","filename":"src\/hotspot\/share\/utilities\/hashtable.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,0 +46,5 @@\n+    static String oom_message = \"**> debuggee: caught:  OutOfMemoryError\";\n+    private static void log_oom() {\n+        log.display(oom_message);\n+    }\n+\n@@ -129,1 +134,4 @@\n-                               log1(\"caught:  OutOfMemoryError\");\n+                               for (int k = 0; k < 100; k++) {\n+                                   arr2[k] = null;\n+                               }\n+                               log_oom();\n@@ -135,1 +143,1 @@\n-                           log1(\"runTime.gc();\");\n+                           log1(\"runTime.gc(); called\");\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jdi\/ObjectReference\/disableCollection\/disablecollection002a.java","additions":11,"deletions":3,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -72,1 +72,9 @@\n-    nsk_jvmti_aod_disableEventAndFinish(agentName, JVMTI_EVENT_OBJECT_FREE, success, jvmti, jni);\n+\n+    \/* Flush any pending ObjectFree events, which may set success to 1 *\/\n+    if (jvmti->SetEventNotificationMode(JVMTI_DISABLE,\n+                                        JVMTI_EVENT_OBJECT_FREE,\n+                                        NULL) != JVMTI_ERROR_NONE) {\n+        success = 0;\n+    }\n+\n+    nsk_aod_agentFinished(jni, agentName, success);\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/AttachOnDemand\/attach021\/attach021Agent00.cpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -68,0 +68,5 @@\n+\n+    \/\/ Flush any pending ObjectFree events.\n+    if (!nsk_jvmti_aod_disableEvents(jvmti, testEvents, testEventsNumber))\n+        success = 0;\n+\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/AttachOnDemand\/attach022\/attach022Agent00.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -55,0 +55,2 @@\n+    private native void flushObjectFreeEvents();\n+\n@@ -105,0 +107,2 @@\n+        flushObjectFreeEvents();\n+\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/scenarios\/allocation\/AP01\/ap01t001.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -194,0 +194,10 @@\n+JNIEXPORT void JNICALL\n+Java_nsk_jvmti_scenarios_allocation_AP01_ap01t001_flushObjectFreeEvents(JNIEnv* jni, jobject obj) {\n+    \/\/ Already enabled, but this triggers flush of pending events.\n+    if (!NSK_JVMTI_VERIFY(jvmti->SetEventNotificationMode(JVMTI_ENABLE,\n+                                                          JVMTI_EVENT_OBJECT_FREE,\n+                                                          NULL))) {\n+        nsk_jvmti_setFailStatus();\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/scenarios\/allocation\/AP01\/ap01t001\/ap01t001.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+    private native void flushObjectFreeEvents();\n@@ -76,0 +77,1 @@\n+        flushObjectFreeEvents();\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/scenarios\/allocation\/AP12\/ap12t001.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -87,0 +87,10 @@\n+JNIEXPORT void JNICALL\n+Java_nsk_jvmti_scenarios_allocation_AP12_ap12t001_flushObjectFreeEvents(JNIEnv* jni, jobject obj) {\n+    \/\/ Already enabled, but this triggers flush of pending events.\n+    if (!NSK_JVMTI_VERIFY(jvmti->SetEventNotificationMode(JVMTI_ENABLE,\n+                                                          JVMTI_EVENT_OBJECT_FREE,\n+                                                          NULL))) {\n+        nsk_jvmti_setFailStatus();\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/scenarios\/allocation\/AP12\/ap12t001\/ap12t001.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2004, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2004, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -63,0 +63,4 @@\n+static jobject testedObject = NULL;\n+const jlong TESTED_TAG_VALUE = 5555555L;\n+static bool testedObjectNotified = false;\n+\n@@ -262,0 +266,4 @@\n+\n+    if (tag == TESTED_TAG_VALUE) {\n+      testedObjectNotified = true;\n+    }\n@@ -419,0 +427,65 @@\n+\/\/ Create the jni local ref in a new frame so it\n+\/\/ doesn't stay alive.\n+class NewFrame {\n+  JNIEnv* _jni;\n+ public:\n+  NewFrame(JNIEnv* jni) : _jni(jni) {\n+    _jni->PushLocalFrame(16);\n+  }\n+  ~NewFrame() {\n+    _jni->PopLocalFrame(NULL);\n+  }\n+};\n+\n+static int checkObjectTagEvent(jvmtiEnv* jvmti, JNIEnv* jni) {\n+    jlong tag = TESTED_TAG_VALUE;\n+    jint count;\n+    jobject *res_objects = NULL;\n+    jlong *res_tags = NULL;\n+\n+    NewFrame local_frame(jni);\n+\n+    \/\/ Create a tested object to tag.\n+    if (!NSK_JNI_VERIFY(jni, (testedObject = jni->NewStringUTF(\"abcde\")) != NULL))\n+        return NSK_FALSE;\n+\n+    NSK_DISPLAY0(\"Checking positive: SetTag\\n\");\n+    if (!NSK_JVMTI_VERIFY(jvmti->SetTag(testedObject, TESTED_TAG_VALUE)))\n+        return NSK_FALSE;\n+\n+    NSK_DISPLAY0(\"Checking positive: GetObjectsWithTags\\n\");\n+    if (!NSK_JVMTI_VERIFY(jvmti->GetObjectsWithTags(1, &tag, &count, &res_objects, &res_tags)))\n+        return NSK_FALSE;\n+\n+    if (!NSK_VERIFY(count == 1))\n+        return NSK_FALSE;\n+\n+    return NSK_TRUE;\n+}\n+\n+\n+\/\/ Test that after GC, the object was removed from the tag map table.\n+static int checkObjectFreeEvent(jvmtiEnv* jvmti) {\n+    jlong tag = TESTED_TAG_VALUE;\n+    jint count;\n+    jobject *res_objects = NULL;\n+    jlong *res_tags = NULL;\n+\n+    \/\/ Make some GCs happen\n+    for (int i = 0; i < 5; i++) {\n+        if (!NSK_JVMTI_VERIFY(jvmti->ForceGarbageCollection()))\n+            return NSK_FALSE;\n+    }\n+\n+    if (!NSK_JVMTI_VERIFY(jvmti->GetObjectsWithTags(1, &tag, &count, &res_objects, &res_tags)))\n+        return NSK_FALSE;\n+\n+    if (!NSK_VERIFY(count == 0))\n+        return NSK_FALSE;\n+\n+    if (!NSK_VERIFY(testedObjectNotified))\n+        return NSK_FALSE;\n+\n+    return NSK_TRUE;\n+}\n+\n@@ -625,0 +698,3 @@\n+    if (!checkObjectTagEvent(jvmti, jni))\n+        nsk_jvmti_setFailStatus();\n+\n@@ -633,1 +709,7 @@\n-    NSK_DISPLAY0(\"Testcase #3: check if the events are generated\\n\");\n+    \/* this will also flush any pending ObjectFree events for event check *\/\n+    NSK_DISPLAY0(\"Testcase #3: check if the object is freed in the tag map\\n\");\n+    if (!checkObjectFreeEvent(jvmti)) {\n+        nsk_jvmti_setFailStatus();\n+    }\n+\n+    NSK_DISPLAY0(\"Testcase #4: check if the events are generated\\n\");\n","filename":"test\/hotspot\/jtreg\/vmTestbase\/nsk\/jvmti\/scenarios\/capability\/CM02\/cm02t001\/cm02t001.cpp","additions":84,"deletions":2,"binary":false,"changes":86,"status":"modified"}]}