{"files":[{"patch":"@@ -5011,0 +5011,34 @@\n+void Assembler::evpmadd52luq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len) {\n+  evpmadd52luq(dst, k0, src1, src2, false, vector_len);\n+}\n+\n+void Assembler::evpmadd52luq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512ifma(), \"\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xB4, (0xC0 | encode));\n+}\n+\n+void Assembler::evpmadd52huq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len) {\n+  evpmadd52huq(dst, k0, src1, src2, false, vector_len);\n+}\n+\n+void Assembler::evpmadd52huq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512ifma(), \"\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xB5, (0xC0 | encode));\n+}\n+\n@@ -5428,0 +5462,36 @@\n+void Assembler::evpunpcklqdq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len) {\n+  evpunpcklqdq(dst, k0, src1, src2, false, vector_len);\n+}\n+\n+void Assembler::evpunpcklqdq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len) {\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x6C, (0xC0 | encode));\n+}\n+\n+void Assembler::evpunpckhqdq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len) {\n+  evpunpckhqdq(dst, k0, src1, src2, false, vector_len);\n+}\n+\n+void Assembler::evpunpckhqdq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len) {\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x6D, (0xC0 | encode));\n+}\n+\n@@ -5872,0 +5942,12 @@\n+#ifdef _LP64\n+void Assembler::shldq(Register dst, Register src, int8_t imm8) {\n+  int encode = prefixq_and_encode(src->encoding(), dst->encoding());\n+  emit_int32(0x0F, (unsigned char)0xA4, (0xC0 | encode), imm8);\n+}\n+\n+void Assembler::shrdq(Register dst, Register src, int8_t imm8) {\n+  int encode = prefixq_and_encode(src->encoding(), dst->encoding());\n+  emit_int32(0x0F, (unsigned char)0xAC, (0xC0 | encode), imm8);\n+}\n+#endif\n+\n@@ -7743,5 +7825,6 @@\n-void Assembler::vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n-  assert(VM_Version::supports_evex(), \"\");\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n-  emit_int16((unsigned char)0xDB, (0xC0 | encode));\n+void Assembler::evpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  evpandq(dst, k0, nds, src, false, vector_len);\n+}\n+\n+void Assembler::evpandq(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  evpandq(dst, k0, nds, src, false, vector_len);\n@@ -7860,5 +7943,2 @@\n-void Assembler::vporq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n-  assert(VM_Version::supports_evex(), \"\");\n-  InstructionAttr attributes(vector_len, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n-  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n-  emit_int16((unsigned char)0xEB, (0xC0 | encode));\n+void Assembler::evporq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  evporq(dst, k0, nds, src, false, vector_len);\n@@ -7867,0 +7947,3 @@\n+void Assembler::evporq(XMMRegister dst, XMMRegister nds, Address src, int vector_len) {\n+  evporq(dst, k0, nds, src, false, vector_len);\n+}\n@@ -8007,1 +8090,2 @@\n-  assert(VM_Version::supports_evex(), \"\");\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n@@ -8019,1 +8103,2 @@\n-  assert(vector_len == AVX_512bit || VM_Version::supports_avx512vl(), \"\");\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n@@ -8034,1 +8119,2 @@\n-  assert(VM_Version::supports_evex(), \"\");\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n@@ -8046,1 +8132,2 @@\n-  assert(vector_len == AVX_512bit || VM_Version::supports_avx512vl(), \"\");\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n@@ -8204,2 +8291,2 @@\n-  assert(VM_Version::supports_evex(), \"requires EVEX support\");\n-  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires VL support\");\n+  assert(VM_Version::supports_evex(), \"requires AVX512F\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires AVX512VL\");\n@@ -8214,0 +8301,14 @@\n+void Assembler::vpternlogq(XMMRegister dst, int imm8, XMMRegister src2, Address src3, int vector_len) {\n+  assert(VM_Version::supports_evex(), \"requires EVEX support\");\n+  assert(vector_len == Assembler::AVX_512bit || VM_Version::supports_avx512vl(), \"requires VL support\");\n+  assert(dst != xnoreg, \"sanity\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FV, \/* input_size_in_bits *\/ EVEX_64bit);\n+  vex_prefix(src3, src2->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  emit_int8(0x25);\n+  emit_operand(dst, src3, 1);\n+  emit_int8(imm8);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":117,"deletions":16,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -1894,0 +1894,4 @@\n+  void evpmadd52luq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len);\n+  void evpmadd52luq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len);\n+  void evpmadd52huq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len);\n+  void evpmadd52huq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len);\n@@ -1993,0 +1997,5 @@\n+  void evpunpcklqdq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len);\n+  void evpunpcklqdq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len);\n+  void evpunpckhqdq(XMMRegister dst, XMMRegister src1, XMMRegister src2, int vector_len);\n+  void evpunpckhqdq(XMMRegister dst, KRegister mask, XMMRegister src1, XMMRegister src2, bool merge, int vector_len);\n+\n@@ -2095,0 +2104,4 @@\n+#ifdef _LP64\n+  void shldq(Register dst, Register src, int8_t imm8);\n+  void shrdq(Register dst, Register src, int8_t imm8);\n+#endif\n@@ -2619,1 +2632,2 @@\n-  void vpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evpandq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evpandq(XMMRegister dst, XMMRegister nds, Address src, int vector_len);\n@@ -2629,1 +2643,2 @@\n-  void vporq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evporq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evporq(XMMRegister dst, XMMRegister nds, Address     src, int vector_len);\n@@ -2643,0 +2658,1 @@\n+  void vpternlogq(XMMRegister dst, int imm8, XMMRegister src2, Address     src3, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":18,"deletions":2,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -5282,1 +5282,1 @@\n-    vpandq(dst, xtmp2, src, vec_enc);\n+    evpandq(dst, xtmp2, src, vec_enc);\n@@ -5293,1 +5293,1 @@\n-    vporq(xtmp2, dst, xtmp2, vec_enc);\n+    evporq(xtmp2, dst, xtmp2, vec_enc);\n@@ -5348,1 +5348,1 @@\n-  vpandq(dst, xtmp1, src, vec_enc);\n+  evpandq(dst, xtmp1, src, vec_enc);\n@@ -5352,1 +5352,1 @@\n-  vporq(dst, dst, xtmp1, vec_enc);\n+  evporq(dst, dst, xtmp1, vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1220,0 +1220,11 @@\n+void MacroAssembler::andq(Register dst, AddressLiteral src, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n+  if (reachable(src)) {\n+    andq(dst, as_Address(src));\n+  } else {\n+    lea(rscratch, src);\n+    andq(dst, Address(rscratch, 0));\n+  }\n+}\n+\n@@ -9108,0 +9119,34 @@\n+\n+void MacroAssembler::evpandq(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n+  if (reachable(src)) {\n+    evpandq(dst, nds, as_Address(src), vector_len);\n+  } else {\n+    lea(rscratch, src);\n+    evpandq(dst, nds, Address(rscratch, 0), vector_len);\n+  }\n+}\n+\n+void MacroAssembler::evporq(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src), \"missing\");\n+\n+  if (reachable(src)) {\n+    evporq(dst, nds, as_Address(src), vector_len);\n+  } else {\n+    lea(rscratch, src);\n+    evporq(dst, nds, Address(rscratch, 0), vector_len);\n+  }\n+}\n+\n+void MacroAssembler::vpternlogq(XMMRegister dst, int imm8, XMMRegister src2, AddressLiteral src3, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(src3), \"missing\");\n+\n+  if (reachable(src3)) {\n+    vpternlogq(dst, imm8, src2, as_Address(src3), vector_len);\n+  } else {\n+    lea(rscratch, src3);\n+    vpternlogq(dst, imm8, src2, Address(rscratch, 0), vector_len);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -733,0 +733,3 @@\n+  using Assembler::andq;\n+  void andq(Register dst, AddressLiteral src, Register rscratch = noreg);\n+\n@@ -1757,0 +1760,9 @@\n+  using Assembler::evpandq;\n+  void evpandq(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch = noreg);\n+\n+  using Assembler::evporq;\n+  void evporq(XMMRegister dst, XMMRegister nds, AddressLiteral src, int vector_len, Register rscratch = noreg);\n+\n+  using Assembler::vpternlogq;\n+  void vpternlogq(XMMRegister dst, int imm8, XMMRegister src2, AddressLiteral src3, int vector_len, Register rscratch = noreg);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2522,1 +2522,1 @@\n-    __ vporq(mask, tmp, input_initial_valid_b64, Assembler::AVX_512bit);\n+    __ evporq(mask, tmp, input_initial_valid_b64, Assembler::AVX_512bit);\n@@ -3712,0 +3712,4 @@\n+  if (UsePolyIntrinsics) {\n+    StubRoutines::_poly1305_processBlocks = generate_poly1305_processBlocks();\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -390,0 +390,13 @@\n+  \/\/ Poly1305 multiblock using IFMA instructions\n+  address generate_poly1305_processBlocks();\n+  void poly1305_process_blocks_avx512(const Register input, const Register length,\n+                                      const Register A0, const Register A1, const Register A2,\n+                                      const Register R0, const Register R1, const Register C1);\n+  void poly1305_multiply_scalar(const Register A0, const Register A1, const Register A2,\n+                                const Register R0, const Register R1, const Register C1, bool only128);\n+  void poly1305_multiply8_avx512(const XMMRegister A0, const XMMRegister A1, const XMMRegister A2,\n+                                 const XMMRegister R0, const XMMRegister R1, const XMMRegister R2, const XMMRegister R1P, const XMMRegister R2P);\n+  void poly1305_limbs(const Register limbs, const Register a0, const Register a1, const Register a2, bool only128);\n+  void poly1305_limbs_out(const Register a0, const Register a1, const Register a2, const Register limbs);\n+  void poly1305_limbs_avx512(const XMMRegister D0, const XMMRegister D1,\n+                             const XMMRegister L0, const XMMRegister L1, const XMMRegister L2, bool padMSG);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -0,0 +1,1025 @@\n+\/*\n+ * Copyright (c) 2022, Intel Corporation. All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"macroAssembler_x86.hpp\"\n+#include \"stubGenerator_x86_64.hpp\"\n+\n+#define __ _masm->\n+\n+\/\/ References:\n+\/\/  - (Normative) RFC7539 - ChaCha20 and Poly1305 for IETF Protocols\n+\/\/  - M. Goll and S. Gueron, \"Vectorization of Poly1305 Message Authentication Code\"\n+\/\/  - \"The design of Poly1305\" https:\/\/loup-vaillant.fr\/tutorials\/poly1305-design\n+\n+\/\/ Explanation for the 'well known' modular arithmetic optimization, reduction by pseudo-Mersene prime 2^130-5:\n+\/\/\n+\/\/ Reduction by 2^130-5 can be expressed as follows:\n+\/\/    ( a×2^130 + b ) mod 2^130-5     \/\/i.e. number split along the 130-bit boundary\n+\/\/                                 = ( a×2^130 - 5×a + 5×a + b ) mod 2^130-5\n+\/\/                                 = ( a×(2^130 - 5) + 5×a + b ) mod 2^130-5 \/\/ i.e. adding multiples of modulus is a noop\n+\/\/                                 = ( 5×a + b ) mod 2^130-5\n+\/\/ QED: shows mathematically the well known algorithm of 'split the number down the middle, multiply upper and add'\n+\/\/ This is particularly useful to understand when combining with 'odd-sized' limbs that might cause misallignment\n+\/\/\n+\n+\/\/ Pseudocode for this file (in general):\n+\/\/    * used for poly1305_multiply_scalar\n+\/\/    × used for poly1305_multiply8_avx512\n+\/\/    lower-case variables are scalar numbers in 3×44-bit limbs (in gprs)\n+\/\/    upper-case variables are 8-element vector numbers in 3×44-bit limbs (in zmm registers)\n+\/\/    [ ] used to denote vector numbers (with their elements)\n+\n+\/\/ Register Map:\n+\/\/ GPRs:\n+\/\/   input        = rdi\n+\/\/   length       = rbx\n+\/\/   accumulator  = rcx\n+\/\/   R   = r8\n+\/\/   a0  = rsi\n+\/\/   a1  = r9\n+\/\/   a2  = r10\n+\/\/   r0  = r11\n+\/\/   r1  = r12\n+\/\/   c1  = r8;\n+\/\/   t1  = r13\n+\/\/   t2  = r14\n+\/\/   t3  = r15\n+\/\/   t0  = r14\n+\/\/   polyCP = r13\n+\/\/   stack(rsp, rbp)\n+\/\/   imul(rax, rdx)\n+\/\/ ZMMs:\n+\/\/   T: xmm0-6\n+\/\/   C: xmm7-9\n+\/\/   A: xmm13-18\n+\/\/   B: xmm19-24\n+\/\/   R: xmm25-29\n+\n+\/\/ Constant Pool:\n+ATTRIBUTE_ALIGNED(64) uint64_t POLY1305_PAD_MSG[] = {\n+  0x0000010000000000, 0x0000010000000000,\n+  0x0000010000000000, 0x0000010000000000,\n+  0x0000010000000000, 0x0000010000000000,\n+  0x0000010000000000, 0x0000010000000000,\n+};\n+static address poly1305_pad_msg() {\n+  return (address)POLY1305_PAD_MSG;\n+}\n+\n+ATTRIBUTE_ALIGNED(64) uint64_t POLY1305_MASK42[] = {\n+  0x000003ffffffffff, 0x000003ffffffffff,\n+  0x000003ffffffffff, 0x000003ffffffffff,\n+  0x000003ffffffffff, 0x000003ffffffffff,\n+  0x000003ffffffffff, 0x000003ffffffffff\n+};\n+static address poly1305_mask42() {\n+  return (address)POLY1305_MASK42;\n+}\n+\n+ATTRIBUTE_ALIGNED(64) uint64_t POLY1305_MASK44[] = {\n+  \/\/ OFFSET 64: mask_44\n+  0x00000fffffffffff, 0x00000fffffffffff,\n+  0x00000fffffffffff, 0x00000fffffffffff,\n+  0x00000fffffffffff, 0x00000fffffffffff,\n+  0x00000fffffffffff, 0x00000fffffffffff,\n+};\n+static address poly1305_mask44() {\n+  return (address)POLY1305_MASK44;\n+}\n+\n+\/\/ Compute product for 8 16-byte message blocks,\n+\/\/ i.e. For each block, compute [a2 a1 a0] = [a2 a1 a0] × [r2 r1 r0]\n+\/\/\n+\/\/ Each block\/number is represented by 3 44-bit limb digits, start with multiplication\n+\/\/\n+\/\/      a2       a1       a0\n+\/\/ ×    r2       r1       r0\n+\/\/ ----------------------------------\n+\/\/     a2×r0    a1×r0    a0×r0\n+\/\/ +   a1×r1    a0×r1  5×a2×r1'     (r1' = r1<<2)\n+\/\/ +   a0×r2  5×a2×r2' 5×a1×r2'     (r2' = r2<<2)\n+\/\/ ----------------------------------\n+\/\/        p2       p1       p0\n+\/\/\n+\/\/ Then, propagate the carry (bits after bit 44) from lower limbs into higher limbs.\n+\/\/ Then, modular reduction from upper limb wrapped to lower limbs\n+\/\/\n+\/\/ Math Note 1: 'carry propagation' from p2 to p0 involves multiplication by 5 (i.e. slightly modified modular reduction from above):\n+\/\/    ( p2×2^88 ) mod 2^130-5\n+\/\/                             = ( p2'×2^88 + p2''×2^130) mod 2^130-5 \/\/ Split on 130-bit boudary\n+\/\/                             = ( p2'×2^88 + p2''×2^130 - 5×p2'' + 5×p2'') mod 2^130-5\n+\/\/                             = ( p2'×2^88 + p2''×(2^130 - 5) + 5×p2'') mod 2^130-5 \/\/ i.e. adding multiples of modulus is a noop\n+\/\/                             = ( p2'×2^88 + 5×p2'') mod 2^130-5\n+\/\/\n+\/\/ Math Note 2: R1P = 4*5*R1 and R2P = 4*5*R2; This precomputation allows simultaneous reduction and multiplication.\n+\/\/ This is not the standard 'multiply-upper-by-5', here is why the factor is 4*5 instead of 5.\n+\/\/ For example, partial product (a2×r2):\n+\/\/    (a2×2^88)×(r2×2^88) mod 2^130-5\n+\/\/                                    = (a2×r2 × 2^176) mod 2^130-5\n+\/\/                                    = (a2×r2 × 2^46×2^130) mod 2^130-5\n+\/\/                                    = (a2×r2×2^46 × 2^130- 5×a2×r2×2^46 + 5×a2×r2×2^46) mod 2^130-5\n+\/\/                                    = (a2×r2×2^46 × (2^130- 5) + 5×a2×r2×2^46) mod 2^130-5 \/\/ i.e. adding multiples of modulus is a noop\n+\/\/                                    = (5×a2×r2×2^46) mod 2^130-5\n+\/\/                                    = (a2×5×r2×2^2 × 2^44) mod 2^130-5 \/\/ Align to limb boudary\n+\/\/                                    = (a2×[5×r2×4] × 2^44) mod 2^130-5\n+\/\/                                    = (a2×R2P × 2^44) mod 2^130-5 \/\/ i.e. R2P = 4*5*R2\n+\/\/\n+void StubGenerator::poly1305_multiply8_avx512(\n+  const XMMRegister A0, const XMMRegister A1, const XMMRegister A2,\n+  const XMMRegister R0, const XMMRegister R1, const XMMRegister R2, const XMMRegister R1P, const XMMRegister R2P)\n+{\n+  const XMMRegister P0_L = xmm0;\n+  const XMMRegister P0_H = xmm1;\n+  const XMMRegister P1_L = xmm2;\n+  const XMMRegister P1_H = xmm3;\n+  const XMMRegister P2_L = xmm4;\n+  const XMMRegister P2_H = xmm5;\n+  const XMMRegister TMP1 = xmm6;\n+  const Register polyCP = r13;\n+\n+  \/\/ Reset partial sums\n+  __ evpxorq(P0_L, P0_L, P0_L, Assembler::AVX_512bit);\n+  __ evpxorq(P0_H, P0_H, P0_H, Assembler::AVX_512bit);\n+  __ evpxorq(P1_L, P1_L, P1_L, Assembler::AVX_512bit);\n+  __ evpxorq(P1_H, P1_H, P1_H, Assembler::AVX_512bit);\n+  __ evpxorq(P2_L, P2_L, P2_L, Assembler::AVX_512bit);\n+  __ evpxorq(P2_H, P2_H, P2_H, Assembler::AVX_512bit);\n+\n+  \/\/ Calculate partial products\n+  __ evpmadd52luq(P0_L, A2, R1P, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P0_H, A2, R1P, Assembler::AVX_512bit);\n+  __ evpmadd52luq(P1_L, A2, R2P, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P1_H, A2, R2P, Assembler::AVX_512bit);\n+  __ evpmadd52luq(P2_L, A2, R0, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P2_H, A2, R0, Assembler::AVX_512bit);\n+\n+  __ evpmadd52luq(P1_L, A0, R1, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P1_H, A0, R1, Assembler::AVX_512bit);\n+  __ evpmadd52luq(P2_L, A0, R2, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P2_H, A0, R2, Assembler::AVX_512bit);\n+  __ evpmadd52luq(P0_L, A0, R0, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P0_H, A0, R0, Assembler::AVX_512bit);\n+\n+  __ evpmadd52luq(P0_L, A1, R2P, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P0_H, A1, R2P, Assembler::AVX_512bit);\n+  __ evpmadd52luq(P1_L, A1, R0, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P1_H, A1, R0, Assembler::AVX_512bit);\n+  __ evpmadd52luq(P2_L, A1, R1, Assembler::AVX_512bit);\n+  __ evpmadd52huq(P2_H, A1, R1, Assembler::AVX_512bit);\n+\n+  \/\/ Carry propagation:\n+  \/\/ (Not quite aligned)                           | More mathematically correct:\n+  \/\/          P2_L   P1_L   P0_L                   |                  P2_L×2^88 + P1_L×2^44 + P0_L×2^0\n+  \/\/ + P2_H   P1_H   P0_H                          |   + P2_H×2^140 + P1_H×2^96 + P0_H×2^52\n+  \/\/ ---------------------------                   |   -----------------------------------------------\n+  \/\/ = P2_H    A2    A1     A0                     |   = P2_H×2^130 +   A2×2^88 +   A1×2^44 +   A0×2^0\n+  \/\/\n+  __ vpsrlq(TMP1, P0_L, 44, Assembler::AVX_512bit);\n+  __ evpandq(A0, P0_L, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP); \/\/ Clear top 20 bits\n+\n+  __ vpsllq(P0_H, P0_H, 8, Assembler::AVX_512bit);\n+  __ vpaddq(P0_H, P0_H, TMP1, Assembler::AVX_512bit);\n+  __ vpaddq(P1_L, P1_L, P0_H, Assembler::AVX_512bit);\n+  __ evpandq(A1, P1_L, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP); \/\/ Clear top 20 bits\n+\n+  __ vpsrlq(TMP1, P1_L, 44, Assembler::AVX_512bit);\n+  __ vpsllq(P1_H, P1_H, 8, Assembler::AVX_512bit);\n+  __ vpaddq(P1_H, P1_H, TMP1, Assembler::AVX_512bit);\n+  __ vpaddq(P2_L, P2_L, P1_H, Assembler::AVX_512bit);\n+  __ evpandq(A2, P2_L, ExternalAddress(poly1305_mask42()), Assembler::AVX_512bit, polyCP); \/\/ Clear top 22 bits\n+\n+  __ vpsrlq(TMP1, P2_L, 42, Assembler::AVX_512bit);\n+  __ vpsllq(P2_H, P2_H, 10, Assembler::AVX_512bit);\n+  __ vpaddq(P2_H, P2_H, TMP1, Assembler::AVX_512bit);\n+\n+  \/\/ Reduction: p2->a0->a1\n+  \/\/ Multiply by 5 the highest bits (p2 is above 130 bits)\n+  __ vpaddq(A0, A0, P2_H, Assembler::AVX_512bit);\n+  __ vpsllq(P2_H, P2_H, 2, Assembler::AVX_512bit);\n+  __ vpaddq(A0, A0, P2_H, Assembler::AVX_512bit);\n+  __ vpsrlq(TMP1, A0, 44, Assembler::AVX_512bit);\n+  __ evpandq(A0, A0, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP);\n+  __ vpaddq(A1, A1, TMP1, Assembler::AVX_512bit);\n+}\n+\n+\/\/ Compute product for a single 16-byte message blocks\n+\/\/ - Assumes that r = [r1 r0] is only 128 bits (not 130)\n+\/\/ - When only128 is set, Input [a2 a1 a0] is 128 bits (i.e. a2==0)\n+\/\/ - Output [a2 a1 a0] is at least 130 bits (i.e. a2 is used)\n+\/\/\n+\/\/ Note 1: a2 here is only two bits so anything above is subject of reduction.\n+\/\/ Note 2: Constant c1 = 5xr1 = r1 + (r1 << 2) simplifies multiply with less operations\n+\/\/\n+\/\/ Flow of the code below is as follows:\n+\/\/\n+\/\/          a2        a1        a0\n+\/\/        x           r1        r0\n+\/\/   -----------------------------\n+\/\/       a2×r0     a1×r0     a0×r0\n+\/\/   +             a0×r1\n+\/\/   +           5xa2xr1   5xa1xr1\n+\/\/   -----------------------------\n+\/\/     [0|L2L] [L1H|L1L] [L0H|L0L]\n+\/\/\n+\/\/   Registers:  t3:t2     t1:a0\n+\/\/\n+\/\/ Completing the multiply and adding (with carry) 3x128-bit limbs into\n+\/\/ 192-bits again (3x64-bits):\n+\/\/ a0 = L0L\n+\/\/ a1 = L0H + L1L\n+\/\/ t3 = L1H + L2L\n+void StubGenerator::poly1305_multiply_scalar(\n+  const Register a0, const Register a1, const Register a2,\n+  const Register r0, const Register r1, const Register c1, bool only128)\n+{\n+  const Register t1 = r13;\n+  const Register t2 = r14;\n+  const Register t3 = r15;\n+  \/\/ Note mulq instruction requires\/clobers rax, rdx\n+\n+  \/\/ t3:t2 = (a0 * r1)\n+  __ movq(rax, r1);\n+  __ mulq(a0);\n+  __ movq(t2, rax);\n+  __ movq(t3, rdx);\n+\n+  \/\/ t1:a0 = (a0 * r0)\n+  __ movq(rax, r0);\n+  __ mulq(a0);\n+  __ movq(a0, rax); \/\/ a0 not used in other operations\n+  __ movq(t1, rdx);\n+\n+  \/\/ t3:t2 += (a1 * r0)\n+  __ movq(rax, r0);\n+  __ mulq(a1);\n+  __ addq(t2, rax);\n+  __ adcq(t3, rdx);\n+\n+  \/\/ t1:a0 += (a1 * r1x5)\n+  __ movq(rax, c1);\n+  __ mulq(a1);\n+  __ addq(a0, rax);\n+  __ adcq(t1, rdx);\n+\n+  \/\/ Note: a2 is clamped to 2-bits,\n+  \/\/       r1\/r0 is clamped to 60-bits,\n+  \/\/       their product is less than 2^64.\n+\n+  if (only128) { \/\/ Accumulator only 128 bits, i.e. a2 == 0\n+    \/\/ just move and add t1-t2 to a1\n+    __ movq(a1, t1);\n+    __ addq(a1, t2);\n+    __ adcq(t3, 0);\n+  } else {\n+    \/\/ t3:t2 += (a2 * r1x5)\n+    __ movq(a1, a2); \/\/ use a1 for a2\n+    __ imulq(a1, c1);\n+    __ addq(t2, a1);\n+    __ adcq(t3, 0);\n+\n+    __ movq(a1, t1); \/\/ t1:a0 => a1:a0\n+\n+    \/\/ t3:a1 += (a2 * r0):t2\n+    __ imulq(a2, r0);\n+    __ addq(a1, t2);\n+    __ adcq(t3, a2);\n+  }\n+\n+  \/\/ At this point, 3 64-bit limbs are in t3:a1:a0\n+  \/\/ t3 can span over more than 2 bits so final partial reduction step is needed.\n+  \/\/\n+  \/\/ Partial reduction (just to fit into 130 bits)\n+  \/\/    a2 = t3 & 3\n+  \/\/    k = (t3 & ~3) + (t3 >> 2)\n+  \/\/         Y    x4  +  Y    x1\n+  \/\/    a2:a1:a0 += k\n+  \/\/\n+  \/\/ Result will be in a2:a1:a0\n+  __ movq(t1, t3);\n+  __ movl(a2, t3); \/\/ DWORD\n+  __ andq(t1, ~3);\n+  __ shrq(t3, 2);\n+  __ addq(t1, t3);\n+  __ andl(a2, 3); \/\/ DWORD\n+\n+  \/\/ a2:a1:a0 += k (kept in t1)\n+  __ addq(a0, t1);\n+  __ adcq(a1, 0);\n+  __ adcl(a2, 0); \/\/ DWORD\n+}\n+\n+\/\/ Convert array of 128-bit numbers in quadwords (in D0:D1) into 128-bit numbers across 44-bit limbs (in L0:L1:L2)\n+\/\/ Optionally pad all the numbers (i.e. add 2^128)\n+\/\/\n+\/\/         +-------------------------+-------------------------+\n+\/\/  D0:D1  | h0 h1 g0 g1 f0 f1 e0 e1 | d0 d1 c0 c1 b0 b1 a0 a1 |\n+\/\/         +-------------------------+-------------------------+\n+\/\/         +-------------------------+\n+\/\/  L2     | h2 d2 g2 c2 f2 b2 e2 a2 |\n+\/\/         +-------------------------+\n+\/\/         +-------------------------+\n+\/\/  L1     | h1 d1 g1 c1 f1 b1 e1 a1 |\n+\/\/         +-------------------------+\n+\/\/         +-------------------------+\n+\/\/  L0     | h0 d0 g0 c0 f0 b0 e0 a0 |\n+\/\/         +-------------------------+\n+\/\/\n+void StubGenerator::poly1305_limbs_avx512(\n+    const XMMRegister D0, const XMMRegister D1,\n+    const XMMRegister L0, const XMMRegister L1, const XMMRegister L2, bool padMSG)\n+{\n+  const XMMRegister TMP1 = xmm0;\n+  const XMMRegister TMP2 = xmm1;\n+  const Register polyCP = r13;\n+\n+  \/\/ Interleave blocks of data\n+  __ evpunpckhqdq(TMP1, D0, D1, Assembler::AVX_512bit);\n+  __ evpunpcklqdq(L0, D0, D1, Assembler::AVX_512bit);\n+\n+  \/\/ Highest 42-bit limbs of new blocks\n+  __ vpsrlq(L2, TMP1, 24, Assembler::AVX_512bit);\n+  if (padMSG) {\n+    __ evporq(L2, L2, ExternalAddress(poly1305_pad_msg()), Assembler::AVX_512bit, polyCP); \/\/ Add 2^128 to all 8 final qwords of the message\n+  }\n+\n+  \/\/ Middle 44-bit limbs of new blocks\n+  __ vpsrlq(L1, L0, 44, Assembler::AVX_512bit);\n+  __ vpsllq(TMP2, TMP1, 20, Assembler::AVX_512bit);\n+  __ vpternlogq(L1, 0xA8, TMP2, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP); \/\/ (A OR B AND C)\n+\n+  \/\/ Lowest 44-bit limbs of new blocks\n+  __ evpandq(L0, L0, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP);\n+}\n+\n+\/**\n+ * Copy 5×26-bit (unreduced) limbs stored at Register limbs into  a2:a1:a0 (3×64-bit limbs)\n+ *\n+ * a2 is optional. When only128 is set, limbs are expected to fit into 128-bits (i.e. a1:a0 such as clamped R)\n+ *\/\n+void StubGenerator::poly1305_limbs(const Register limbs, const Register a0, const Register a1, const Register a2, bool only128)\n+{\n+  const Register t1 = r13;\n+  const Register t2 = r14;\n+\n+  __ movq(a0, Address(limbs, 0));\n+  __ movq(t1, Address(limbs, 8));\n+  __ shlq(t1, 26);\n+  __ addq(a0, t1);\n+  __ movq(t1, Address(limbs, 16));\n+  __ movq(t2, Address(limbs, 24));\n+  __ movq(a1, t1);\n+  __ shlq(t1, 52);\n+  __ shrq(a1, 12);\n+  __ shlq(t2, 14);\n+  __ addq(a0, t1);\n+  __ adcq(a1, t2);\n+  __ movq(t1, Address(limbs, 32));\n+  if (!only128) {\n+    __ movq(a2, t1);\n+    __ shrq(a2, 24);\n+  }\n+  __ shlq(t1, 40);\n+  __ addq(a1, t1);\n+  if (only128) {\n+    return;\n+  }\n+  __ adcq(a2, 0);\n+\n+  \/\/ One round of reduction\n+  \/\/ Take bits above 130 in a2, multiply by 5 and add to a2:a1:a0\n+  __ movq(t1, a2);\n+  __ andq(t1, ~3);\n+  __ andq(a2, 3);\n+  __ movq(t2, t1);\n+  __ shrq(t2, 2);\n+  __ addq(t1, t2);\n+\n+  __ addq(a0, t1);\n+  __ adcq(a1, 0);\n+  __ adcq(a2, 0);\n+}\n+\n+\/**\n+ * Break 3×64-bit a2:a1:a0 limbs into 5×26-bit limbs and store out into 5 quadwords at address `limbs`\n+ *\/\n+void StubGenerator::poly1305_limbs_out(const Register a0, const Register a1, const Register a2, const Register limbs)\n+{\n+  const Register t1 = r13;\n+  const Register t2 = r14;\n+\n+  \/\/ Extra round of reduction\n+  \/\/ Take bits above 130 in a2, multiply by 5 and add to a2:a1:a0\n+  __ movq(t1, a2);\n+  __ andq(t1, ~3);\n+  __ andq(a2, 3);\n+  __ movq(t2, t1);\n+  __ shrq(t2, 2);\n+  __ addq(t1, t2);\n+\n+  __ addq(a0, t1);\n+  __ adcq(a1, 0);\n+  __ adcq(a2, 0);\n+\n+  \/\/ Chop a2:a1:a0 into 26-bit limbs\n+  __ movl(t1, a0);\n+  __ andl(t1, 0x3ffffff);\n+  __ movq(Address(limbs, 0), t1);\n+\n+  __ shrq(a0, 26);\n+  __ movl(t1, a0);\n+  __ andl(t1, 0x3ffffff);\n+  __ movq(Address(limbs, 8), t1);\n+\n+  __ shrq(a0, 26); \/\/ 12 bits left in a0, concatenate 14 from a1\n+  __ movl(t1, a1);\n+  __ shll(t1, 12);\n+  __ addl(t1, a0);\n+  __ andl(t1, 0x3ffffff);\n+  __ movq(Address(limbs, 16), t1);\n+\n+  __ shrq(a1, 14); \/\/ already used up 14 bits\n+  __ shlq(a2, 50); \/\/ a2 contains 2 bits when reduced, but $Element.limbs dont have to be fully reduced\n+  __ addq(a1, a2); \/\/ put remaining bits into a1\n+\n+  __ movl(t1, a1);\n+  __ andl(t1, 0x3ffffff);\n+  __ movq(Address(limbs, 24), t1);\n+\n+  __ shrq(a1, 26);\n+  __ movl(t1, a1);\n+  \/\/andl(t1, 0x3ffffff); doesnt have to be fully reduced, leave remaining bit(s)\n+  __ movq(Address(limbs, 32), t1);\n+}\n+\n+\/\/ This function consumes as many whole 16*16-byte blocks as available in input\n+\/\/ After execution, input and length will point at remaining (unprocessed) data\n+\/\/ and [a2 a1 a0] will contain the current accumulator value\n+\/\/\n+\/\/ Math Note:\n+\/\/    Put simply, main loop in this function multiplies each message block by r^16; why this works? 'Math' happens before and after.. why as follows:\n+\/\/\n+\/\/     hash = ((((m1*r + m2)*r + m3)*r ...  mn)*r\n+\/\/          = m1*r^n + m2*r^(n-1) + ... +mn_1*r^2 + mn*r  \/\/ Horner's rule\n+\/\/\n+\/\/          = m1*r^n     + m4*r^(n-4) + m8*r^(n-8) ...    \/\/ split into 4 groups for brevity, same applies to 16\n+\/\/          + m2*r^(n-1) + m5*r^(n-5) + m9*r^(n-9) ...\n+\/\/          + m3*r^(n-2) + m6*r^(n-6) + m10*r^(n-10) ...\n+\/\/          + m4*r^(n-3) + m7*r^(n-7) + m11*r^(n-11) ...\n+\/\/\n+\/\/          = r^4 * (m1*r^(n-4) + m4*r^(n-8) + m8 *r^(n-16) ... + mn_3)   \/\/ factor out r^4..r; same applies to 16 but r^16..r factors\n+\/\/          + r^3 * (m2*r^(n-4) + m5*r^(n-8) + m9 *r^(n-16) ... + mn_2)\n+\/\/          + r^2 * (m3*r^(n-4) + m6*r^(n-8) + m10*r^(n-16) ... + mn_1)\n+\/\/          + r^1 * (m4*r^(n-4) + m7*r^(n-8) + m11*r^(n-16) ... + mn_0)   \/\/ Note last message group has no multiplier\n+\/\/\n+\/\/          = r^4 * (((m1*r^4 + m4)*r^4 + m8 )*r^4 ... + mn_3)   \/\/ reverse Horner's rule, for each group\n+\/\/          + r^3 * (((m2*r^4 + m5)*r^4 + m9 )*r^4 ... + mn_2)\n+\/\/          + r^2 * (((m3*r^4 + m6)*r^4 + m10)*r^4 ... + mn_1)\n+\/\/          + r^1 * (((m4*r^4 + m7)*r^4 + m11)*r^4 ... + mn_0)\n+\/\/\n+\/\/ Also see M. Goll and S. Gueron, \"Vectorization of Poly1305 Message Authentication Code\"\n+\/\/\n+\/\/ Pseudocode for this function:\n+\/\/  * used for poly1305_multiply_scalar\n+\/\/  × used for poly1305_multiply8_avx512\n+\/\/  lower-case variables are scalar numbers in 3×44-bit limbs (in gprs)\n+\/\/  upper-case variables are 8&16-element vector numbers in 3×44-bit limbs (in zmm registers)\n+\/\/\n+\/\/    C = a       \/\/ [0 0 0 0 0 0 0 a]\n+\/\/    AL = limbs(input)\n+\/\/    AH = limbs(input+8)\n+\/\/    AL = AL + C\n+\/\/    input+=16, length-=16\n+\/\/\n+\/\/    a = r\n+\/\/    a = a*r\n+\/\/  r^2 = a\n+\/\/    a = a*r\n+\/\/  r^3 = a\n+\/\/    r = a*r\n+\/\/  r^4 = a\n+\/\/\n+\/\/    T = r^4 || r^3 || r^2 || r\n+\/\/    B = limbs(T)           \/\/ [r^4  0  r^3  0  r^2  0  r^1  0 ]\n+\/\/    C = B >> 1             \/\/ [ 0  r^4  0  r^3  0  r^2  0  r^1]\n+\/\/    R = r^4 || r^4 || ..   \/\/ [r^4 r^4 r^4 r^4 r^4 r^4 r^4 r^4]\n+\/\/    B = B×R                \/\/ [r^8  0  r^7  0  r^6  0  r^5  0 ]\n+\/\/    B = B | C              \/\/ [r^8 r^4 r^7 r^3 r^6 r^2 r^5 r^1]\n+\/\/    push(B)\n+\/\/    R = r^8 || r^8 || ..   \/\/ [r^8 r^8 r^8 r^8 r^8 r^8 r^8 r^8]\n+\/\/    B = B × R              \/\/ [r^16 r^12 r^15 r^11 r^14 r^10 r^13 r^9]\n+\/\/    push(B)\n+\/\/    R = r^16 || r^16 || .. \/\/ [r^16 r^16 r^16 r^16 r^16 r^16 r^16 r^16]\n+\/\/\n+\/\/ for (;length>=16; input+=16, length-=16)\n+\/\/     BL = limbs(input)\n+\/\/     BH = limbs(input+8)\n+\/\/     AL = AL × R\n+\/\/     AH = AH × R\n+\/\/     AL = AL + BL\n+\/\/     AH = AH + BH\n+\/\/\n+\/\/  B = pop()\n+\/\/  R = pop()\n+\/\/  AL = AL × R\n+\/\/  AH = AH × B\n+\/\/  A = AL + AH \/\/ 16->8 blocks\n+\/\/  T = A >> 4  \/\/ 8 ->4 blocks\n+\/\/  A = A + T\n+\/\/  T = A >> 2  \/\/ 4 ->2 blocks\n+\/\/  A = A + T\n+\/\/  T = A >> 1  \/\/ 2 ->1 blocks\n+\/\/  A = A + T\n+\/\/  a = A\n+void StubGenerator::poly1305_process_blocks_avx512(const Register input, const Register length,\n+  const Register a0, const Register a1, const Register a2,\n+  const Register r0, const Register r1, const Register c1)\n+{\n+  Label L_process256Loop, L_process256LoopDone;\n+  \/\/ Register Map:\n+  \/\/ reserved: rsp, rbp, rcx\n+  \/\/ PARAMs: rdi, rbx, rsi, r8-r12\n+  \/\/ poly1305_multiply_scalar clobbers: r13-r15, rax, rdx\n+  const Register t0 = r14;\n+  const Register t1 = r13;\n+  const Register polyCP = r13;\n+\n+  \/\/ poly1305_limbs_avx512 clobbers: xmm0, xmm1\n+  \/\/ poly1305_multiply8_avx512 clobbers: xmm0-xmm6\n+  const XMMRegister T0 = xmm2;\n+  const XMMRegister T1 = xmm3;\n+  const XMMRegister T2 = xmm4;\n+\n+  const XMMRegister C0 = xmm7;\n+  const XMMRegister C1 = xmm8;\n+  const XMMRegister C2 = xmm9;\n+\n+  const XMMRegister A0 = xmm13;\n+  const XMMRegister A1 = xmm14;\n+  const XMMRegister A2 = xmm15;\n+  const XMMRegister A3 = xmm16;\n+  const XMMRegister A4 = xmm17;\n+  const XMMRegister A5 = xmm18;\n+\n+  const XMMRegister B0 = xmm19;\n+  const XMMRegister B1 = xmm20;\n+  const XMMRegister B2 = xmm21;\n+  const XMMRegister B3 = xmm22;\n+  const XMMRegister B4 = xmm23;\n+  const XMMRegister B5 = xmm24;\n+\n+  const XMMRegister R0 = xmm25;\n+  const XMMRegister R1 = xmm26;\n+  const XMMRegister R2 = xmm27;\n+  const XMMRegister R1P = xmm28;\n+  const XMMRegister R2P = xmm29;\n+\n+  __ subq(rsp, 512\/8*6); \/\/ Make room to store 6 zmm registers (powers of R)\n+\n+  \/\/ Spread accumulator into 44-bit limbs in quadwords C0,C1,C2\n+  __ movq(t0, a0);\n+  __ andq(t0, ExternalAddress(poly1305_mask44()), polyCP); \/\/ First limb (Acc[43:0])\n+  __ movq(C0, t0);\n+\n+  __ movq(t0, a1);\n+  __ shrdq(a0, t0, 44);\n+  __ andq(a0, ExternalAddress(poly1305_mask44()), polyCP); \/\/ Second limb (Acc[77:52])\n+  __ movq(C1, a0);\n+\n+  __ shrdq(a1, a2, 24);\n+  __ andq(a1, ExternalAddress(poly1305_mask42()), polyCP); \/\/ Third limb (Acc[129:88])\n+  __ movq(C2, a1);\n+\n+  \/\/ To add accumulator, we must unroll first loop iteration\n+\n+  \/\/ Load first block of data (128 bytes) and pad\n+  \/\/ A0 to have bits 0-43 of all 8 blocks in 8 qwords\n+  \/\/ A1 to have bits 87-44 of all 8 blocks in 8 qwords\n+  \/\/ A2 to have bits 127-88 of all 8 blocks in 8 qwords\n+  __ evmovdquq(T0, Address(input, 0), Assembler::AVX_512bit);\n+  __ evmovdquq(T1, Address(input, 64), Assembler::AVX_512bit);\n+  poly1305_limbs_avx512(T0, T1, A0, A1, A2, true);\n+\n+  \/\/ Add accumulator to the fist message block\n+  __ vpaddq(A0, A0, C0, Assembler::AVX_512bit);\n+  __ vpaddq(A1, A1, C1, Assembler::AVX_512bit);\n+  __ vpaddq(A2, A2, C2, Assembler::AVX_512bit);\n+\n+  \/\/ Load next blocks of data (128 bytes)  and pad\n+  \/\/ A3 to have bits 0-43 of all 8 blocks in 8 qwords\n+  \/\/ A4 to have bits 87-44 of all 8 blocks in 8 qwords\n+  \/\/ A5 to have bits 127-88 of all 8 blocks in 8 qwords\n+  __ evmovdquq(T0, Address(input, 64*2), Assembler::AVX_512bit);\n+  __ evmovdquq(T1, Address(input, 64*3), Assembler::AVX_512bit);\n+  poly1305_limbs_avx512(T0, T1, A3, A4, A5, true);\n+\n+  __ subl(length, 16*16);\n+  __ lea(input, Address(input,16*16));\n+\n+  \/\/ Compute the powers of R^1..R^4 and form 44-bit limbs of each\n+  \/\/ T0 to have bits 0-127 in 4 quadword pairs\n+  \/\/ T1 to have bits 128-129 in alternating 8 qwords\n+  __ vpxorq(T1, T1, T1, Assembler::AVX_512bit);\n+  __ movq(T2, r0);\n+  __ vpinsrq(T2, T2, r1, 1);\n+  __ vinserti32x4(T0, T0, T2, 3);\n+\n+  \/\/ Calculate R^2\n+  __ movq(a0, r0);\n+  __ movq(a1, r1);\n+  \/\/ \"Clever\": a2 not set because poly1305_multiply_scalar has a flag to indicate 128-bit accumulator\n+  poly1305_multiply_scalar(a0, a1, a2, r0, r1, c1, true);\n+\n+  __ movq(T2, a0);\n+  __ vpinsrq(T2, T2, a1, 1);\n+  __ vinserti32x4(T0, T0, T2, 2);\n+  __ movq(T2, a2);\n+  __ vinserti32x4(T1, T1, T2, 2);\n+\n+  \/\/ Calculate R^3\n+  poly1305_multiply_scalar(a0, a1, a2, r0, r1, c1, false);\n+\n+  __ movq(T2, a0);\n+  __ vpinsrq(T2, T2, a1, 1);\n+  __ vinserti32x4(T0, T0, T2, 1);\n+  __ movq(T2, a2);\n+  __ vinserti32x4(T1, T1, T2, 1);\n+\n+  \/\/ Calculate R^4\n+  poly1305_multiply_scalar(a0, a1, a2, r0, r1, c1, false);\n+\n+  __ movq(T2, a0);\n+  __ vpinsrq(T2, T2, a1, 1);\n+  __ vinserti32x4(T0, T0, T2, 0);\n+  __ movq(T2, a2);\n+  __ vinserti32x4(T1, T1, T2, 0);\n+\n+  \/\/ Interleave the powers of R^1..R^4 to form 44-bit limbs (half-empty)\n+  \/\/ B0 to have bits 0-43 of all 4 blocks in alternating 8 qwords\n+  \/\/ B1 to have bits 87-44 of all 4 blocks in alternating 8 qwords\n+  \/\/ B2 to have bits 127-88 of all 4 blocks in alternating 8 qwords\n+  __ vpxorq(T2, T2, T2, Assembler::AVX_512bit);\n+  poly1305_limbs_avx512(T0, T2, B0, B1, B2, false);\n+\n+  \/\/ T1 contains the 2 highest bits of the powers of R\n+  __ vpsllq(T1, T1, 40, Assembler::AVX_512bit);\n+  __ evporq(B2, B2, T1, Assembler::AVX_512bit);\n+\n+  \/\/ Broadcast 44-bit limbs of R^4 into R0,R1,R2\n+  __ mov(t0, a0);\n+  __ andq(t0, ExternalAddress(poly1305_mask44()), polyCP); \/\/ First limb (R^4[43:0])\n+  __ evpbroadcastq(R0, t0, Assembler::AVX_512bit);\n+\n+  __ movq(t0, a1);\n+  __ shrdq(a0, t0, 44);\n+  __ andq(a0, ExternalAddress(poly1305_mask44()), polyCP); \/\/ Second limb (R^4[87:44])\n+  __ evpbroadcastq(R1, a0, Assembler::AVX_512bit);\n+\n+  __ shrdq(a1, a2, 24);\n+  __ andq(a1, ExternalAddress(poly1305_mask42()), polyCP); \/\/ Third limb (R^4[129:88])\n+  __ evpbroadcastq(R2, a1, Assembler::AVX_512bit);\n+\n+  \/\/ Generate 4*5*R^4 into {R2P,R1P}\n+  \/\/ Used as multiplier in poly1305_multiply8_avx512 so can\n+  \/\/ ignore bottom limb and carry propagation\n+  __ vpsllq(R1P, R1, 2, Assembler::AVX_512bit);    \/\/ 4*R^4\n+  __ vpsllq(R2P, R2, 2, Assembler::AVX_512bit);\n+  __ vpaddq(R1P, R1P, R1, Assembler::AVX_512bit);  \/\/ 5*R^4\n+  __ vpaddq(R2P, R2P, R2, Assembler::AVX_512bit);\n+  __ vpsllq(R1P, R1P, 2, Assembler::AVX_512bit);   \/\/ 4*5*R^4\n+  __ vpsllq(R2P, R2P, 2, Assembler::AVX_512bit);\n+\n+  \/\/ Move R^4..R^1 one element over\n+  __ vpslldq(C0, B0, 8, Assembler::AVX_512bit);\n+  __ vpslldq(C1, B1, 8, Assembler::AVX_512bit);\n+  __ vpslldq(C2, B2, 8, Assembler::AVX_512bit);\n+\n+  \/\/ Calculate R^8-R^5\n+  poly1305_multiply8_avx512(B0, B1, B2,             \/\/ ACC=R^4..R^1\n+                            R0, R1, R2, R1P, R2P);  \/\/ R^4..R^4, 4*5*R^4\n+\n+  \/\/ Interleave powers of R: R^8 R^4 R^7 R^3 R^6 R^2 R^5 R\n+  __ evporq(B0, B0, C0, Assembler::AVX_512bit);\n+  __ evporq(B1, B1, C1, Assembler::AVX_512bit);\n+  __ evporq(B2, B2, C2, Assembler::AVX_512bit);\n+\n+  \/\/ Broadcast R^8\n+  __ vpbroadcastq(R0, B0, Assembler::AVX_512bit);\n+  __ vpbroadcastq(R1, B1, Assembler::AVX_512bit);\n+  __ vpbroadcastq(R2, B2, Assembler::AVX_512bit);\n+\n+  \/\/ Generate 4*5*R^8\n+  __ vpsllq(R1P, R1, 2, Assembler::AVX_512bit);\n+  __ vpsllq(R2P, R2, 2, Assembler::AVX_512bit);\n+  __ vpaddq(R1P, R1P, R1, Assembler::AVX_512bit);    \/\/ 5*R^8\n+  __ vpaddq(R2P, R2P, R2, Assembler::AVX_512bit);\n+  __ vpsllq(R1P, R1P, 2, Assembler::AVX_512bit);     \/\/ 4*5*R^8\n+  __ vpsllq(R2P, R2P, 2, Assembler::AVX_512bit);\n+\n+  \/\/ Store R^8-R for later use\n+  __ evmovdquq(Address(rsp, 64*0), B0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*1), B1, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*2), B2, Assembler::AVX_512bit);\n+\n+  \/\/ Calculate R^16-R^9\n+  poly1305_multiply8_avx512(B0, B1, B2,            \/\/ ACC=R^8..R^1\n+                            R0, R1, R2, R1P, R2P); \/\/ R^8..R^8, 4*5*R^8\n+\n+  \/\/ Store R^16-R^9 for later use\n+  __ evmovdquq(Address(rsp, 64*3), B0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*4), B1, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*5), B2, Assembler::AVX_512bit);\n+\n+  \/\/ Broadcast R^16\n+  __ vpbroadcastq(R0, B0, Assembler::AVX_512bit);\n+  __ vpbroadcastq(R1, B1, Assembler::AVX_512bit);\n+  __ vpbroadcastq(R2, B2, Assembler::AVX_512bit);\n+\n+  \/\/ Generate 4*5*R^16\n+  __ vpsllq(R1P, R1, 2, Assembler::AVX_512bit);\n+  __ vpsllq(R2P, R2, 2, Assembler::AVX_512bit);\n+  __ vpaddq(R1P, R1P, R1, Assembler::AVX_512bit);  \/\/ 5*R^16\n+  __ vpaddq(R2P, R2P, R2, Assembler::AVX_512bit);\n+  __ vpsllq(R1P, R1P, 2, Assembler::AVX_512bit);   \/\/ 4*5*R^16\n+  __ vpsllq(R2P, R2P, 2, Assembler::AVX_512bit);\n+\n+  \/\/ VECTOR LOOP: process 16 * 16-byte message block at a time\n+  __ bind(L_process256Loop);\n+  __ cmpl(length, 16*16);\n+  __ jcc(Assembler::less, L_process256LoopDone);\n+\n+  \/\/ Load and interleave next block of data (128 bytes)\n+  __ evmovdquq(T0, Address(input, 0), Assembler::AVX_512bit);\n+  __ evmovdquq(T1, Address(input, 64), Assembler::AVX_512bit);\n+  poly1305_limbs_avx512(T0, T1, B0, B1, B2, true);\n+\n+  \/\/ Load and interleave next block of data (128 bytes)\n+  __ evmovdquq(T0, Address(input, 64*2), Assembler::AVX_512bit);\n+  __ evmovdquq(T1, Address(input, 64*3), Assembler::AVX_512bit);\n+  poly1305_limbs_avx512(T0, T1, B3, B4, B5, true);\n+\n+  poly1305_multiply8_avx512(A0, A1, A2,            \/\/ MSG\/ACC 16 blocks\n+                            R0, R1, R2, R1P, R2P); \/\/R^16..R^16, 4*5*R^16\n+  poly1305_multiply8_avx512(A3, A4, A5,            \/\/ MSG\/ACC 16 blocks\n+                            R0, R1, R2, R1P, R2P); \/\/R^16..R^16, 4*5*R^16\n+\n+  __ vpaddq(A0, A0, B0, Assembler::AVX_512bit); \/\/ Add low 42-bit bits from new blocks to accumulator\n+  __ vpaddq(A1, A1, B1, Assembler::AVX_512bit); \/\/ Add medium 42-bit bits from new blocks to accumulator\n+  __ vpaddq(A2, A2, B2, Assembler::AVX_512bit); \/\/Add highest bits from new blocks to accumulator\n+  __ vpaddq(A3, A3, B3, Assembler::AVX_512bit); \/\/ Add low 42-bit bits from new blocks to accumulator\n+  __ vpaddq(A4, A4, B4, Assembler::AVX_512bit); \/\/ Add medium 42-bit bits from new blocks to accumulator\n+  __ vpaddq(A5, A5, B5, Assembler::AVX_512bit); \/\/ Add highest bits from new blocks to accumulator\n+\n+  __ subl(length, 16*16);\n+  __ lea(input, Address(input,16*16));\n+  __ jmp(L_process256Loop);\n+\n+  __ bind(L_process256LoopDone);\n+\n+  \/\/ Tail processing: Need to multiply ACC by R^16..R^1 and add it all up into a single scalar value\n+  \/\/ Read R^16-R^9\n+  __ evmovdquq(B0, Address(rsp, 64*3), Assembler::AVX_512bit);\n+  __ evmovdquq(B1, Address(rsp, 64*4), Assembler::AVX_512bit);\n+  __ evmovdquq(B2, Address(rsp, 64*5), Assembler::AVX_512bit);\n+  \/\/ Read R^8-R\n+  __ evmovdquq(R0, Address(rsp, 64*0), Assembler::AVX_512bit);\n+  __ evmovdquq(R1, Address(rsp, 64*1), Assembler::AVX_512bit);\n+  __ evmovdquq(R2, Address(rsp, 64*2), Assembler::AVX_512bit);\n+\n+  \/\/ Generate 4*5*[R^16..R^9] (ignore lowest limb)\n+  __ vpsllq(T0, B1, 2, Assembler::AVX_512bit);\n+  __ vpaddq(B3, B1, T0, Assembler::AVX_512bit); \/\/ R1' (R1*5)\n+  __ vpsllq(T0, B2, 2, Assembler::AVX_512bit);\n+  __ vpaddq(B4, B2, T0, Assembler::AVX_512bit); \/\/ R2' (R2*5)\n+  __ vpsllq(B3, B3, 2, Assembler::AVX_512bit);  \/\/ 4*5*R\n+  __ vpsllq(B4, B4, 2, Assembler::AVX_512bit);\n+\n+  \/\/ Generate 4*5*[R^8..R^1] (ignore lowest limb)\n+  __ vpsllq(T0, R1, 2, Assembler::AVX_512bit);\n+  __ vpaddq(R1P, R1, T0, Assembler::AVX_512bit); \/\/ R1' (R1*5)\n+  __ vpsllq(T0, R2, 2, Assembler::AVX_512bit);\n+  __ vpaddq(R2P, R2, T0, Assembler::AVX_512bit); \/\/ R2' (R2*5)\n+  __ vpsllq(R1P, R1P, 2, Assembler::AVX_512bit); \/\/ 4*5*R\n+  __ vpsllq(R2P, R2P, 2, Assembler::AVX_512bit);\n+\n+  poly1305_multiply8_avx512(A0, A1, A2,            \/\/ MSG\/ACC 16 blocks\n+                              B0, B1, B2, B3, B4); \/\/ R^16-R^9, R1P, R2P\n+  poly1305_multiply8_avx512(A3, A4, A5,              \/\/ MSG\/ACC 16 blocks\n+                              R0, R1, R2, R1P, R2P); \/\/ R^8-R, R1P, R2P\n+\n+  \/\/ Add all blocks (horizontally)\n+  \/\/ 16->8 blocks\n+  __ vpaddq(A0, A0, A3, Assembler::AVX_512bit);\n+  __ vpaddq(A1, A1, A4, Assembler::AVX_512bit);\n+  __ vpaddq(A2, A2, A5, Assembler::AVX_512bit);\n+\n+  \/\/ 8 -> 4 blocks\n+  __ vextracti64x4(T0, A0, 1);\n+  __ vextracti64x4(T1, A1, 1);\n+  __ vextracti64x4(T2, A2, 1);\n+  __ vpaddq(A0, A0, T0, Assembler::AVX_256bit);\n+  __ vpaddq(A1, A1, T1, Assembler::AVX_256bit);\n+  __ vpaddq(A2, A2, T2, Assembler::AVX_256bit);\n+\n+  \/\/ 4 -> 2 blocks\n+  __ vextracti32x4(T0, A0, 1);\n+  __ vextracti32x4(T1, A1, 1);\n+  __ vextracti32x4(T2, A2, 1);\n+  __ vpaddq(A0, A0, T0, Assembler::AVX_128bit);\n+  __ vpaddq(A1, A1, T1, Assembler::AVX_128bit);\n+  __ vpaddq(A2, A2, T2, Assembler::AVX_128bit);\n+\n+  \/\/ 2 -> 1 blocks\n+  __ vpsrldq(T0, A0, 8, Assembler::AVX_128bit);\n+  __ vpsrldq(T1, A1, 8, Assembler::AVX_128bit);\n+  __ vpsrldq(T2, A2, 8, Assembler::AVX_128bit);\n+\n+  \/\/ Finish folding and clear second qword\n+  __ mov64(t0, 0xfd);\n+  __ kmovql(k1, t0);\n+  __ evpaddq(A0, k1, A0, T0, false, Assembler::AVX_512bit);\n+  __ evpaddq(A1, k1, A1, T1, false, Assembler::AVX_512bit);\n+  __ evpaddq(A2, k1, A2, T2, false, Assembler::AVX_512bit);\n+\n+  \/\/ Carry propagation\n+  __ vpsrlq(T0, A0, 44, Assembler::AVX_512bit);\n+  __ evpandq(A0, A0, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP); \/\/ Clear top 20 bits\n+  __ vpaddq(A1, A1, T0, Assembler::AVX_512bit);\n+  __ vpsrlq(T0, A1, 44, Assembler::AVX_512bit);\n+  __ evpandq(A1, A1, ExternalAddress(poly1305_mask44()), Assembler::AVX_512bit, polyCP); \/\/ Clear top 20 bits\n+  __ vpaddq(A2, A2, T0, Assembler::AVX_512bit);\n+  __ vpsrlq(T0, A2, 42, Assembler::AVX_512bit);\n+  __ evpandq(A2, A2, ExternalAddress(poly1305_mask42()), Assembler::AVX_512bit, polyCP); \/\/ Clear top 22 bits\n+  __ vpsllq(T1, T0, 2, Assembler::AVX_512bit);\n+  __ vpaddq(T0, T0, T1, Assembler::AVX_512bit);\n+  __ vpaddq(A0, A0, T0, Assembler::AVX_512bit);\n+\n+  \/\/ Put together A (accumulator)\n+  __ movq(a0, A0);\n+\n+  __ movq(t0, A1);\n+  __ movq(t1, t0);\n+  __ shlq(t1, 44);\n+  __ orq(a0, t1);\n+\n+  __ shrq(t0, 20);\n+  __ movq(a2, A2);\n+  __ movq(a1, a2);\n+  __ shlq(a1, 24);\n+  __ orq(a1, t0);\n+  __ shrq(a2, 40);\n+\n+  \/\/ Cleanup\n+  __ vpxorq(xmm0, xmm0, xmm0, Assembler::AVX_512bit);\n+  __ vpxorq(xmm1, xmm1, xmm1, Assembler::AVX_512bit);\n+  __ vpxorq(T0, T0, T0, Assembler::AVX_512bit);\n+  __ vpxorq(T1, T1, T1, Assembler::AVX_512bit);\n+  __ vpxorq(T2, T2, T2, Assembler::AVX_512bit);\n+  __ vpxorq(C0, C0, C0, Assembler::AVX_512bit);\n+  __ vpxorq(C1, C1, C1, Assembler::AVX_512bit);\n+  __ vpxorq(C2, C2, C2, Assembler::AVX_512bit);\n+  __ vpxorq(A0, A0, A0, Assembler::AVX_512bit);\n+  __ vpxorq(A1, A1, A1, Assembler::AVX_512bit);\n+  __ vpxorq(A2, A2, A2, Assembler::AVX_512bit);\n+  __ vpxorq(A3, A3, A3, Assembler::AVX_512bit);\n+  __ vpxorq(A4, A4, A4, Assembler::AVX_512bit);\n+  __ vpxorq(A5, A5, A5, Assembler::AVX_512bit);\n+  __ vpxorq(B0, B0, B0, Assembler::AVX_512bit);\n+  __ vpxorq(B1, B1, B1, Assembler::AVX_512bit);\n+  __ vpxorq(B2, B2, B2, Assembler::AVX_512bit);\n+  __ vpxorq(B3, B3, B3, Assembler::AVX_512bit);\n+  __ vpxorq(B4, B4, B4, Assembler::AVX_512bit);\n+  __ vpxorq(B5, B5, B5, Assembler::AVX_512bit);\n+  __ vpxorq(R0, R0, R0, Assembler::AVX_512bit);\n+  __ vpxorq(R1, R1, R1, Assembler::AVX_512bit);\n+  __ vpxorq(R2, R2, R2, Assembler::AVX_512bit);\n+  __ vpxorq(R1P, R1P, R1P, Assembler::AVX_512bit);\n+  __ vpxorq(R2P, R2P, R2P, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*3), A0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*4), A0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*5), A0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*0), A0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*1), A0, Assembler::AVX_512bit);\n+  __ evmovdquq(Address(rsp, 64*2), A0, Assembler::AVX_512bit);\n+  __ addq(rsp, 512\/8*6); \/\/ (powers of R)\n+}\n+\n+\/\/ This function consumes as many whole 16-byte blocks as available in input\n+\/\/ After execution, input and length will point at remaining (unprocessed) data\n+\/\/ and accumulator will point to the current accumulator value\n+address StubGenerator::generate_poly1305_processBlocks() {\n+  __ align(CodeEntryAlignment);\n+  StubCodeMark mark(this, \"StubRoutines\", \"poly1305_processBlocks\");\n+  address start = __ pc();\n+  __ enter();\n+\n+  \/\/ Save all 'SOE' registers\n+  __ push(rbx);\n+  #ifdef _WIN64\n+  __ push(rsi);\n+  __ push(rdi);\n+  #endif\n+  __ push(r12);\n+  __ push(r13);\n+  __ push(r14);\n+  __ push(r15);\n+\n+  \/\/ void processBlocks(byte[] input, int len, int[5] a, int[5] r)\n+  const Register input        = rdi; \/\/input+offset\n+  const Register length       = rbx;\n+  const Register accumulator  = rcx;\n+  const Register R            = r8;\n+\n+  #ifdef _WIN64\n+  __ mov(input, c_rarg0);\n+  __ mov(length, c_rarg1);\n+  __ mov(accumulator, c_rarg2);\n+  __ mov(R, c_rarg3);\n+  #else  \/\/ input already in correct position for linux; dont clobber R, args copied out-of-order\n+  __ mov(length, c_rarg1);\n+  __ mov(R, c_rarg3);\n+  __ mov(accumulator, c_rarg2);\n+  #endif\n+\n+  const Register a0 = rsi;  \/\/ [in\/out] accumulator bits 63..0\n+  const Register a1 = r9;   \/\/ [in\/out] accumulator bits 127..64\n+  const Register a2 = r10;  \/\/ [in\/out] accumulator bits 195..128\n+  const Register r0 = r11;  \/\/ R constant bits 63..0\n+  const Register r1 = r12;  \/\/ R constant bits 127..64\n+  const Register c1 = r8;   \/\/ 5*R (upper limb only)\n+\n+  Label L_process16Loop, L_process16LoopDone;\n+\n+  \/\/ Load R into r1:r0\n+  poly1305_limbs(R, r0, r1, r1, true);\n+\n+  \/\/ Compute 5*R (Upper limb only)\n+  __ movq(c1, r1);\n+  __ shrq(c1, 2);\n+  __ addq(c1, r1); \/\/ c1 = r1 + (r1 >> 2)\n+\n+  \/\/ Load accumulator into a2:a1:a0\n+  poly1305_limbs(accumulator, a0, a1, a2, false);\n+\n+  \/\/ VECTOR LOOP: Minimum of 256 bytes to run vectorized code\n+  __ cmpl(length, 16*16);\n+  __ jcc(Assembler::less, L_process16Loop);\n+\n+  poly1305_process_blocks_avx512(input, length,\n+                                  a0, a1, a2,\n+                                  r0, r1, c1);\n+\n+  \/\/ SCALAR LOOP: process one 16-byte message block at a time\n+  __ bind(L_process16Loop);\n+  __ cmpl(length, 16);\n+  __ jcc(Assembler::less, L_process16LoopDone);\n+\n+  __ addq(a0, Address(input,0));\n+  __ adcq(a1, Address(input,8));\n+  __ adcq(a2,1);\n+  poly1305_multiply_scalar(a0, a1, a2, r0, r1, c1, false);\n+\n+  __ subl(length, 16);\n+  __ lea(input, Address(input,16));\n+  __ jmp(L_process16Loop);\n+  __ bind(L_process16LoopDone);\n+\n+  \/\/ Write output\n+  poly1305_limbs_out(a0, a1, a2, accumulator);\n+\n+  __ pop(r15);\n+  __ pop(r14);\n+  __ pop(r13);\n+  __ pop(r12);\n+  #ifdef _WIN64\n+  __ pop(rdi);\n+  __ pop(rsi);\n+  #endif\n+  __ pop(rbx);\n+\n+  __ leave();\n+  __ ret(0);\n+  return start;\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_poly.cpp","additions":1025,"deletions":0,"binary":false,"changes":1025,"status":"added"},{"patch":"@@ -36,1 +36,1 @@\n-  code_size2 = 35300 LP64_ONLY(+35000) WINDOWS_ONLY(+2048) \/\/ simply increase if too small (assembler will crash if too small)\n+  code_size2 = 35300 LP64_ONLY(+45000) WINDOWS_ONLY(+2048) \/\/ simply increase if too small (assembler will crash if too small)\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -953,0 +953,1 @@\n+    _features &= ~CPU_AVX512_IFMA;\n@@ -984,0 +985,1 @@\n+      _features &= ~CPU_AVX512_IFMA;\n@@ -1336,0 +1338,12 @@\n+#ifdef _LP64\n+  if (supports_avx512ifma() & supports_avx512vlbw() & MaxVectorSize >= 64) {\n+    if (FLAG_IS_DEFAULT(UsePolyIntrinsics)) {\n+      FLAG_SET_DEFAULT(UsePolyIntrinsics, true);\n+    }\n+  } else\n+#endif\n+  if (UsePolyIntrinsics) {\n+    warning(\"Intrinsics for Poly1305 crypto hash functions not available on this CPU.\");\n+    FLAG_SET_DEFAULT(UsePolyIntrinsics, false);\n+  }\n+\n@@ -2900,0 +2914,2 @@\n+      if (_cpuid_info.sef_cpuid7_ebx.bits.avx512ifma != 0)\n+        result |= CPU_AVX512_IFMA;\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -226,1 +226,3 @@\n-                        : 3,\n+                        : 1,\n+             avx512ifma : 1,\n+                        : 1,\n@@ -390,1 +392,2 @@\n-    decl(CET_SS,            \"cet_ss\",            57) \/* Control Flow Enforcement - Shadow Stack *\/\n+    decl(CET_SS,            \"cet_ss\",            57) \/* Control Flow Enforcement - Shadow Stack *\/ \\\n+    decl(AVX512_IFMA,       \"avx512_ifma\",       58) \/* Integer Vector FMA instructions*\/\n@@ -670,0 +673,1 @@\n+  static bool supports_avx512ifma()   { return (_features & CPU_AVX512_IFMA) != 0; }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.hpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -482,0 +482,3 @@\n+  case vmIntrinsics::_poly1305_processBlocks:\n+    if (!UsePolyIntrinsics) return true;\n+    break;\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -522,1 +522,1 @@\n-   do_signature(decodeBlock_signature, \"([BII[BIZZ)I\")                                                                   \\\n+   do_signature(decodeBlock_signature, \"([BII[BIZZ)I\")                                                                  \\\n@@ -529,0 +529,5 @@\n+                                                                                                                        \\\n+  \/* support for com.sun.crypto.provider.Poly1305 *\/                                                                    \\\n+  do_class(com_sun_crypto_provider_Poly1305, \"com\/sun\/crypto\/provider\/Poly1305\")                                        \\\n+  do_intrinsic(_poly1305_processBlocks, com_sun_crypto_provider_Poly1305, processMultipleBlocks_name, ghash_processBlocks_signature, F_R) \\\n+   do_name(processMultipleBlocks_name, \"processMultipleBlocks\")                                                         \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -742,0 +742,1 @@\n+  case vmIntrinsics::_poly1305_processBlocks:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1171,0 +1171,1 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"poly1305_processBlocks\") == 0 ||\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -615,0 +615,2 @@\n+  case vmIntrinsics::_poly1305_processBlocks:\n+    return inline_poly1305_processBlocks();\n@@ -6970,0 +6972,34 @@\n+bool LibraryCallKit::inline_poly1305_processBlocks() {\n+  address stubAddr;\n+  const char *stubName;\n+  assert(UsePolyIntrinsics, \"need Poly intrinsics support\");\n+  assert(callee()->signature()->size() == 5, \"poly1305_processBlocks has %d parameters\", callee()->signature()->size());\n+  stubAddr = StubRoutines::poly1305_processBlocks();\n+  stubName = \"poly1305_processBlocks\";\n+\n+  if (!stubAddr) return false;\n+  Node* polyObj = argument(0);\n+  Node* input = argument(1);\n+  Node* input_offset = argument(2);\n+  Node* len = argument(3);\n+  Node* alimbs = argument(4);\n+  Node* rlimbs = argument(5);\n+\n+  input = must_be_not_null(input, true);\n+  alimbs = must_be_not_null(alimbs, true);\n+  rlimbs = must_be_not_null(rlimbs, true);\n+\n+  Node* input_start = array_element_address(input, input_offset, T_BYTE);\n+  assert(input_start, \"input array is NULL\");\n+  Node* acc_start = array_element_address(alimbs, intcon(0), T_LONG);\n+  assert(acc_start, \"acc array is NULL\");\n+  Node* r_start = array_element_address(rlimbs, intcon(0), T_LONG);\n+  assert(r_start, \"r array is NULL\");\n+\n+  Node* call = make_runtime_call(RC_LEAF | RC_NO_FP,\n+                                 OptoRuntime::poly1305_processBlocks_Type(),\n+                                 stubAddr, stubName, TypePtr::BOTTOM,\n+                                 input_start, len, acc_start, r_start);\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -296,0 +296,1 @@\n+  bool inline_poly1305_processBlocks();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1269,0 +1269,20 @@\n+\/\/ Poly1305 processMultipleBlocks function\n+const TypeFunc* OptoRuntime::poly1305_processBlocks_Type() {\n+  int argcnt = 4;\n+\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ input array\n+  fields[argp++] = TypeInt::INT;        \/\/ input length\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ accumulator array\n+  fields[argp++] = TypePtr::NOTNULL;    \/\/ r array\n+  assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms+argcnt, fields);\n+\n+  \/\/ result type needed\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms + 0] = NULL; \/\/ void\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms, fields);\n+  return TypeFunc::make(domain, range);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -283,0 +283,1 @@\n+  static const TypeFunc* poly1305_processBlocks_Type();\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -241,0 +241,3 @@\n+  product(bool, UsePolyIntrinsics, false, DIAGNOSTIC,                       \\\n+          \"Use intrinsics for sun.security.util.math.intpoly\")              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -133,0 +133,1 @@\n+address StubRoutines::_poly1305_processBlocks              = NULL;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -214,0 +214,1 @@\n+  static address _poly1305_processBlocks;\n@@ -387,0 +388,1 @@\n+  static address poly1305_processBlocks()               { return _poly1305_processBlocks; }\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -547,0 +547,1 @@\n+     static_field(StubRoutines,                _poly1305_processBlocks,                       address)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import java.lang.reflect.Field;\n@@ -37,0 +38,2 @@\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n+import jdk.internal.vm.annotation.ForceInline;\n@@ -62,0 +65,1 @@\n+    private final boolean checkWeakKey;\n@@ -63,1 +67,2 @@\n-    Poly1305() { }\n+    Poly1305() { this(true); }\n+    Poly1305(boolean checkKey) { checkWeakKey = checkKey; }\n@@ -168,5 +173,9 @@\n-        while (len >= BLOCK_LENGTH) {\n-            processBlock(input, offset, BLOCK_LENGTH);\n-            offset += BLOCK_LENGTH;\n-            len -= BLOCK_LENGTH;\n-        }\n+\n+        int blockMultipleLength = len & (~(BLOCK_LENGTH-1));\n+        long[] aLimbs = a.getLimbs();\n+        long[] rLimbs = r.getLimbs();\n+        processMultipleBlocksCheck(input, offset, blockMultipleLength, aLimbs, rLimbs);\n+        processMultipleBlocks(input, offset, blockMultipleLength, aLimbs, rLimbs);\n+        offset += blockMultipleLength;\n+        len -= blockMultipleLength;\n+\n@@ -238,0 +247,23 @@\n+    @ForceInline\n+    @IntrinsicCandidate\n+    private void processMultipleBlocks(byte[] input, int offset, int length, long[] aLimbs, long[] rLimbs) {\n+        while (length >= BLOCK_LENGTH) {\n+            n.setValue(input, offset, BLOCK_LENGTH, (byte)0x01);\n+            a.setSum(n);                    \/\/ A += (temp | 0x01)\n+            a.setProduct(r);                \/\/ A =  (A * R) % p\n+            offset += BLOCK_LENGTH;\n+            length -= BLOCK_LENGTH;\n+        }\n+    }\n+\n+    private static void processMultipleBlocksCheck(byte[] input, int offset, int length, long[] aLimbs, long[] rLimbs) {\n+        Objects.checkFromIndexSize(offset, length, input.length);\n+        final int numLimbs = 5; \/\/ Intrinsic expects exactly 5 limbs\n+        if (aLimbs.length != numLimbs) {\n+            throw new RuntimeException(\"invalid accumulator length: \" + aLimbs.length);\n+        }\n+        if (rLimbs.length != numLimbs) {\n+            throw new RuntimeException(\"invalid R length: \" + rLimbs.length);\n+        }\n+    }\n+\n@@ -243,1 +275,1 @@\n-    private void setRSVals() {\n+    private void setRSVals() throws InvalidKeyException {\n@@ -253,0 +285,18 @@\n+        if (checkWeakKey) {\n+            byte keyIsZero = 0;\n+            for (int i = 0; i < RS_LENGTH; i++) {\n+                keyIsZero |= keyBytes[i];\n+            }\n+            if (keyIsZero == 0) {\n+                throw new InvalidKeyException(\"R is set to zero\");\n+            }\n+\n+            keyIsZero = 0;\n+            for (int i = RS_LENGTH; i < 2*RS_LENGTH; i++) {\n+                keyIsZero |= keyBytes[i];\n+            }\n+            if (keyIsZero == 0) {\n+                throw new InvalidKeyException(\"S is set to zero\");\n+            }\n+        }\n+\n","filename":"src\/java.base\/share\/classes\/com\/sun\/crypto\/provider\/Poly1305.java","additions":57,"deletions":7,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -211,0 +211,4 @@\n+    \/**\n+     * Break encapsulation, used for IntrinsicCandidate functions\n+     *\/\n+    long[] getLimbs();\n","filename":"src\/java.base\/share\/classes\/sun\/security\/util\/math\/IntegerModuloP.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -629,0 +629,4 @@\n+\n+        public long[] getLimbs() {\n+            return limbs;\n+        }\n","filename":"src\/java.base\/share\/classes\/sun\/security\/util\/math\/intpoly\/IntegerPolynomial.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -234,0 +234,1 @@\n+        AVX512_IFMA,\n","filename":"src\/jdk.internal.vm.ci\/share\/classes\/jdk.vm.ci.amd64\/src\/jdk\/vm\/ci\/amd64\/AMD64.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -31,0 +31,38 @@\n+\n+\/*\n+ * @test\n+ * @modules java.base\/com.sun.crypto.provider\n+ * @run main java.base\/com.sun.crypto.provider.Poly1305IntrinsicFuzzTest\n+ * @summary Unit test for com.sun.crypto.provider.Poly1305.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @modules java.base\/com.sun.crypto.provider\n+ * @run main java.base\/com.sun.crypto.provider.Poly1305KAT\n+ * @summary Unit test for com.sun.crypto.provider.Poly1305.\n+ *\/\n+\n+\/*\n+ * @test\n+ * @modules java.base\/com.sun.crypto.provider\n+ * @run main java.base\/com.sun.crypto.provider.Poly1305IntrinsicFuzzTest\n+ * @summary Unit test for IntrinsicCandidate in com.sun.crypto.provider.Poly1305.\n+ * @run main\/othervm -Xcomp -XX:-TieredCompilation com.sun.crypto.provider.Cipher.ChaCha20.Poly1305UnitTestDriver\n+ *\/\n+\n+\/*\n+ * @test\n+ * @modules java.base\/com.sun.crypto.provider\n+ * @run main java.base\/com.sun.crypto.provider.Poly1305KAT\n+ * @summary Unit test for IntrinsicCandidate in com.sun.crypto.provider.Poly1305.\n+ * @run main\/othervm -Xcomp -XX:-TieredCompilation com.sun.crypto.provider.Cipher.ChaCha20.Poly1305UnitTestDriver\n+ *\/\n+\n+package com.sun.crypto.provider.Cipher.ChaCha20;\n+\n+public class Poly1305UnitTestDriver {\n+    static public void main(String[] args) {\n+        System.out.println(\"Passed\");\n+    }\n+}\n","filename":"test\/jdk\/com\/sun\/crypto\/provider\/Cipher\/ChaCha20\/unittest\/Poly1305UnitTestDriver.java","additions":39,"deletions":1,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -0,0 +1,94 @@\n+\/*\n+ * Copyright (c) 2022, Intel Corporation. All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package com.sun.crypto.provider;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+\n+\/\/ This test case relies on the fact that single-byte Poly1305.engineUpdate(byte) does not have an intrinsic\n+\/\/ In this way we can compare if the intrinsic and pure java produce same result\n+\/\/ This test case is NOT entirely deterministic, it uses a random seed for pseudo-random number generator\n+\/\/ If a failure occurs, hardcode the seed to make the test case deterministic\n+public class Poly1305IntrinsicFuzzTest {\n+        public static void main(String[] args) throws Exception {\n+                \/\/Note: it might be useful to increase this number during development of new Poly1305 intrinsics\n+                final int repeat = 100;\n+                for (int i = 0; i < repeat; i++) {\n+                        run();\n+                }\n+        }\n+\n+        public static void run() throws Exception {\n+                java.util.Random rnd = new java.util.Random();\n+                long seed = rnd.nextLong();\n+                rnd.setSeed(seed);\n+\n+                byte[] key = new byte[32];\n+                rnd.nextBytes(key);\n+                int msgLen = rnd.nextInt(128, 4096); \/\/ x86_64 intrinsic requires 256 bytes minimum\n+                byte[] message = new byte[msgLen];\n+\n+                Poly1305 authenticator = new Poly1305();\n+                Poly1305 authenticatorSlow = new Poly1305();\n+                if (authenticator.engineGetMacLength() != 16) {\n+                        throw new RuntimeException(\"The length of Poly1305 MAC must be 16-bytes.\");\n+                }\n+\n+                authenticator.engineInit(new SecretKeySpec(key, 0, 32, \"Poly1305\"), null);\n+                authenticatorSlow.engineInit(new SecretKeySpec(key, 0, 32, \"Poly1305\"), null);\n+\n+                if (rnd.nextBoolean()) {\n+                        \/\/ Prime just the buffer and\/or accumulator (buffer can keep at most 16 bytes from previous engineUpdate)\n+                        int initDataLen = rnd.nextInt(8, 24);\n+                        authenticator.engineUpdate(message, 0, initDataLen);\n+                        slowUpdate(authenticatorSlow, message, 0, initDataLen);\n+                }\n+\n+                if (rnd.nextBoolean()) {\n+                        \/\/ Multiple calls to engineUpdate\n+                        authenticator.engineUpdate(message, 0, message.length);\n+                        slowUpdate(authenticatorSlow, message, 0, message.length);\n+                }\n+\n+                authenticator.engineUpdate(message, 0, message.length);\n+                slowUpdate(authenticatorSlow, message, 0, message.length);\n+\n+                byte[] tag = authenticator.engineDoFinal();\n+                byte[] tagSlow = authenticatorSlow.engineDoFinal();\n+\n+                if (!Arrays.equals(tag, tagSlow)) {\n+                        throw new RuntimeException(\"[Seed \"+seed+\"] Tag mismatch: \" + Arrays.toString(tag) + \" != \" + Arrays.toString(tagSlow));\n+                }\n+        }\n+\n+        static void slowUpdate(Poly1305 authenticator, byte[] message, int offset, int len) {\n+                len = Math.min(message.length, offset + len);\n+                for (int i = offset; i < len; i++) {\n+                        authenticator.engineUpdate(message[i]);\n+                }\n+        }\n+}\n","filename":"test\/jdk\/com\/sun\/crypto\/provider\/Cipher\/ChaCha20\/unittest\/java.base\/com\/sun\/crypto\/provider\/Poly1305IntrinsicFuzzTest.java","additions":94,"deletions":0,"binary":false,"changes":94,"status":"added"},{"patch":"@@ -0,0 +1,199 @@\n+\/*\n+ * Copyright (c) 2022, Intel Corporation. All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package com.sun.crypto.provider;\n+\n+import java.util.*;\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+\n+import javax.crypto.spec.SecretKeySpec;\n+\n+public class Poly1305KAT {\n+    public static class TestData {\n+        public TestData(String name, String keyStr, String inputStr, String outStr) {\n+            HexFormat hex = HexFormat.of();\n+            testName = Objects.requireNonNull(name);\n+            key = hex.parseHex(Objects.requireNonNull(keyStr));\n+            input = hex.parseHex(Objects.requireNonNull(inputStr));\n+            expOutput = hex.parseHex(Objects.requireNonNull(outStr));\n+        }\n+\n+        public final String testName;\n+        public final byte[] key;\n+        public final byte[] input;\n+        public final byte[] expOutput;\n+    }\n+\n+    public static final List<TestData> testList = new LinkedList<TestData>() {{\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #1\",\n+            \"0000000000000000000000000000000000000000000000000000000000000000\",\n+            \"0000000000000000000000000000000000000000000000000000000000000000\" +\n+            \"0000000000000000000000000000000000000000000000000000000000000000\",\n+            \"00000000000000000000000000000000\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #2\",\n+            \"0000000000000000000000000000000036e5f6b5c5e06070f0efca96227a863e\",\n+            \"416e79207375626d697373696f6e20746f20746865204945544620696e74656e\" +\n+            \"6465642062792074686520436f6e7472696275746f7220666f72207075626c69\" +\n+            \"636174696f6e20617320616c6c206f722070617274206f6620616e2049455446\" +\n+            \"20496e7465726e65742d4472616674206f722052464320616e6420616e792073\" +\n+            \"746174656d656e74206d6164652077697468696e2074686520636f6e74657874\" +\n+            \"206f6620616e204945544620616374697669747920697320636f6e7369646572\" +\n+            \"656420616e20224945544620436f6e747269627574696f6e222e205375636820\" +\n+            \"73746174656d656e747320696e636c756465206f72616c2073746174656d656e\" +\n+            \"747320696e20494554462073657373696f6e732c2061732077656c6c20617320\" +\n+            \"7772697474656e20616e6420656c656374726f6e696320636f6d6d756e696361\" +\n+            \"74696f6e73206d61646520617420616e792074696d65206f7220706c6163652c\" +\n+            \"207768696368206172652061646472657373656420746f\",\n+            \"36e5f6b5c5e06070f0efca96227a863e\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #3\",\n+            \"36e5f6b5c5e06070f0efca96227a863e00000000000000000000000000000000\",\n+             \"416e79207375626d697373696f6e20746f20746865204945544620696e74656e\" +\n+             \"6465642062792074686520436f6e7472696275746f7220666f72207075626c69\" +\n+             \"636174696f6e20617320616c6c206f722070617274206f6620616e2049455446\" +\n+             \"20496e7465726e65742d4472616674206f722052464320616e6420616e792073\" +\n+             \"746174656d656e74206d6164652077697468696e2074686520636f6e74657874\" +\n+             \"206f6620616e204945544620616374697669747920697320636f6e7369646572\" +\n+             \"656420616e20224945544620436f6e747269627574696f6e222e205375636820\" +\n+             \"73746174656d656e747320696e636c756465206f72616c2073746174656d656e\" +\n+             \"747320696e20494554462073657373696f6e732c2061732077656c6c20617320\" +\n+             \"7772697474656e20616e6420656c656374726f6e696320636f6d6d756e696361\" +\n+             \"74696f6e73206d61646520617420616e792074696d65206f7220706c6163652c\" +\n+             \"207768696368206172652061646472657373656420746f\",\n+             \"f3477e7cd95417af89a6b8794c310cf0\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #4\",\n+            \"1c9240a5eb55d38af333888604f6b5f0473917c1402b80099dca5cbc207075c0\",\n+            \"2754776173206272696c6c69672c20616e642074686520736c6974687920746f\" +\n+            \"7665730a446964206779726520616e642067696d626c6520696e207468652077\" +\n+            \"6162653a0a416c6c206d696d737920776572652074686520626f726f676f7665\" +\n+            \"732c0a416e6420746865206d6f6d65207261746873206f757467726162652e\",\n+            \"4541669a7eaaee61e708dc7cbcc5eb62\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #5: If one uses 130-bit partial reduction, does the code handle the case where partially reducedfinal result is not fully reduced?\",\n+            \"0200000000000000000000000000000000000000000000000000000000000000\",\n+            \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\",\n+            \"03000000000000000000000000000000\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #6: What happens if addition of s overflows modulo 2^128?\",\n+            \"02000000000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\",\n+            \"02000000000000000000000000000000\",\n+            \"03000000000000000000000000000000\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #7: What happens if data limb is all ones and there is carry from lower limb?\",\n+            \"0100000000000000000000000000000000000000000000000000000000000000\",\n+            \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF0FFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\" +\n+            \"11000000000000000000000000000000\",\n+             \"05000000000000000000000000000000\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #8: What happens if final result from polynomial part is exactly 2^130-5?\",\n+            \"0100000000000000000000000000000000000000000000000000000000000000\",\n+            \"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFBFEFEFEFEFEFEFEFEFEFEFEFEFEFEFE\" +\n+            \"01010101010101010101010101010101\",\n+            \"00000000000000000000000000000000\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #9: What happens if final result from polynomial part is exactly 2^130-6?\",\n+            \"0200000000000000000000000000000000000000000000000000000000000000\",\n+            \"FDFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\",\n+            \"FAFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #10: What happens if 5*H+L-type reduction produces 131-bit intermediate result?\",\n+            \"0100000000000000040000000000000000000000000000000000000000000000\",\n+            \"E33594D7505E43B900000000000000003394D7505E4379CD0100000000000000\" +\n+            \"0000000000000000000000000000000001000000000000000000000000000000\",\n+            \"14000000000000005500000000000000\"));\n+        add(new TestData(\"RFC 7539 A.3 Test Vector #11: What happens if 5*H+L-type reduction produces 131-bit final result?\",\n+            \"0100000000000000040000000000000000000000000000000000000000000000\",\n+            \"E33594D7505E43B900000000000000003394D7505E4379CD0100000000000000\" +\n+            \"00000000000000000000000000000000\",\n+            \"13000000000000000000000000000000\"));\n+    }};\n+\n+    public static void main(String args[]) throws Exception {\n+        int testsPassed = 0;\n+        int testNumber = 0;\n+\n+        for (TestData test : testList) {\n+            System.out.println(\"*** Test \" + ++testNumber + \": \" +\n+                    test.testName);\n+            if (runSingleTest(test)) {\n+                testsPassed++;\n+            }\n+        }\n+        System.out.println();\n+\n+        if (testsPassed != testNumber) {\n+            throw new RuntimeException(\"One or more tests failed.  \" +\n+                    \"Check output for details\");\n+        }\n+    }\n+\n+    private static boolean runSingleTest(TestData testData) throws Exception {\n+        Poly1305 authenticator = new Poly1305(false);\n+        authenticator.engineInit(new SecretKeySpec(testData.key, 0, testData.key.length, \"Poly1305\"), null);\n+        authenticator.engineUpdate(testData.input, 0, testData.input.length);\n+        byte[] tag = authenticator.engineDoFinal();\n+        if (!Arrays.equals(tag, testData.expOutput)) {\n+                System.out.println(\"ERROR - Output Mismatch!\");\n+                System.out.println(\"Expected:\\n\" +\n+                        dumpHexBytes(testData.expOutput, testData.expOutput.length, \"\\n\", \" \"));\n+                System.out.println(\"Actual:\\n\" +\n+                        dumpHexBytes(tag, tag.length, \"\\n\", \" \"));\n+                System.out.println();\n+                return false;\n+        }\n+        return true;\n+    }\n+\n+    \/**\n+     * Dump the hex bytes of a buffer into string form.\n+     *\n+     * @param data The array of bytes to dump to stdout.\n+     * @param itemsPerLine The number of bytes to display per line\n+     *      if the {@code lineDelim} character is blank then all bytes\n+     *      will be printed on a single line.\n+     * @param lineDelim The delimiter between lines\n+     * @param itemDelim The delimiter between bytes\n+     *\n+     * @return The hexdump of the byte array\n+     *\/\n+    private static String dumpHexBytes(byte[] data, int itemsPerLine,\n+            String lineDelim, String itemDelim) {\n+        return dumpHexBytes(ByteBuffer.wrap(data), itemsPerLine, lineDelim,\n+                itemDelim);\n+    }\n+\n+    private static String dumpHexBytes(ByteBuffer data, int itemsPerLine,\n+            String lineDelim, String itemDelim) {\n+        StringBuilder sb = new StringBuilder();\n+        if (data != null) {\n+            data.mark();\n+            int i = 0;\n+            while (data.remaining() > 0) {\n+                if (i % itemsPerLine == 0 && i != 0) {\n+                    sb.append(lineDelim);\n+                }\n+                sb.append(String.format(\"%02X\", data.get())).append(itemDelim);\n+                i++;\n+            }\n+            data.reset();\n+        }\n+\n+        return sb.toString();\n+    }\n+}\n+\n","filename":"test\/jdk\/com\/sun\/crypto\/provider\/Cipher\/ChaCha20\/unittest\/java.base\/com\/sun\/crypto\/provider\/Poly1305KAT.java","additions":199,"deletions":0,"binary":false,"changes":199,"status":"added"},{"patch":"@@ -68,1 +68,1 @@\n-                    \"cet_ss\"\n+                    \"cet_ss\",       \"avx512_ifma\"\n","filename":"test\/lib-test\/jdk\/test\/whitebox\/CPUInfoTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -0,0 +1,97 @@\n+\/*\n+ * Copyright (c) 2022, Intel Corporation. All rights reserved.\n+ *\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package org.openjdk.bench.javax.crypto.full;\n+\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Setup;\n+\n+import java.lang.invoke.MethodHandle;\n+import java.lang.invoke.MethodHandles;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Constructor;\n+import java.security.Key;\n+import java.security.spec.AlgorithmParameterSpec;\n+import javax.crypto.spec.SecretKeySpec;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.annotations.Measurement;\n+\n+@Measurement(iterations = 3, time = 10)\n+@Warmup(iterations = 3, time = 10)\n+@Fork(value = 1, jvmArgsAppend = {\"--add-opens\", \"java.base\/com.sun.crypto.provider=ALL-UNNAMED\"})\n+public class Poly1305DigestBench extends CryptoBase {\n+    public static final int SET_SIZE = 128;\n+\n+    @Param({\"64\", \"256\", \"1024\", \"\" + 16*1024, \"\" + 1024*1024})\n+    int dataSize;\n+\n+    private byte[][] data;\n+    int index = 0;\n+    private static MethodHandle polyEngineInit, polyEngineUpdate, polyEngineFinal;\n+    private static Object polyObj;\n+\n+    static {\n+        try {\n+            MethodHandles.Lookup lookup = MethodHandles.lookup();\n+            Class<?> polyClazz = Class.forName(\"com.sun.crypto.provider.Poly1305\");\n+            Constructor<?> constructor = polyClazz.getDeclaredConstructor();\n+            constructor.setAccessible(true);\n+            polyObj = constructor.newInstance();\n+\n+            Method m = polyClazz.getDeclaredMethod(\"engineInit\", Key.class, AlgorithmParameterSpec.class);\n+            m.setAccessible(true);\n+            polyEngineInit = lookup.unreflect(m);\n+\n+            m = polyClazz.getDeclaredMethod(\"engineUpdate\", byte[].class, int.class, int.class);\n+            m.setAccessible(true);\n+            polyEngineUpdate = lookup.unreflect(m);\n+\n+            m = polyClazz.getDeclaredMethod(\"engineDoFinal\");\n+            m.setAccessible(true);\n+            polyEngineFinal = lookup.unreflect(m);\n+        } catch (Throwable ex) {\n+            throw new RuntimeException(ex);\n+        }\n+    }\n+\n+    @Setup\n+    public void setup() {\n+        setupProvider();\n+        data = fillRandom(new byte[SET_SIZE][dataSize]);\n+    }\n+\n+    @Benchmark\n+    public byte[] digest() {\n+        try {\n+            byte[] d = data[index];\n+            index = (index +1) % SET_SIZE;\n+            polyEngineInit.invoke(polyObj, new SecretKeySpec(d, 0, 32, \"Poly1305\"), null);\n+            polyEngineUpdate.invoke(polyObj, d, 0, d.length);\n+            return (byte[])polyEngineFinal.invoke(polyObj);\n+        } catch (Throwable ex) {\n+            throw new RuntimeException(ex);\n+        }\n+    }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/javax\/crypto\/full\/Poly1305DigestBench.java","additions":97,"deletions":0,"binary":false,"changes":97,"status":"added"}]}