{"files":[{"patch":"@@ -4019,68 +4019,0 @@\n-  void do_lxvl(VectorRegister vreg_ret, Register addr, Register length, Register gpr_tmp1, VectorRegister vreg_tmp1, VectorRegister vreg_tmp2) {\n-     Label no_clamp, lxvl_done, skip_second_load, no_load, done;\n-\n-     VectorRegister vreg_lo = vreg_tmp1;\n-     VectorRegister vreg_hi = vreg_tmp2;\n-     VectorRegister vreg_shift_amt = vreg_tmp1;\n-     VectorRegister vreg_mask = vreg_tmp2;\n-\n-     if (PowerArchitecturePPC64 >= 10) {\n-       \/\/ Shift the length into the upper 8 bits of tmp1 for lxvl\n-       __ rldicr(gpr_tmp1, length, 56, 7);\n-       __ lxvl(vreg_ret->to_vsr(), addr, gpr_tmp1);\n-     } else {\n-       \/\/ On P9, lxvl has performance problems in about 68% of the alignment\n-       \/\/ vs. length cases.  In those cases where it's slow, it's about\n-       \/\/ 5.4X slower.  So on P9, we replace lxvl with a conditional\n-       \/\/ unaligned load sequence, based on the alignment of the address\n-       \/\/ and the length of the data requested.\n-       \/\/\n-       \/\/ If the length is zero or negative, don't read anything.\n-       __ cmpdi(CCR7, length, 0);\n-       __ ble_predict_not_taken(CCR7, no_load);\n-\n-       \/\/ For an exact emulation of lxvl, we should clamp the length at 16,\n-       \/\/ but we know that this code is only used when the length is 16 or less.\n-\n-       \/\/ Do the first read\n-       __ lvx(vreg_hi, addr);\n-       \/\/ set the permute reg\n-       __ lvsr(vreg_ret, addr);\n-\n-       \/\/ max length of data readable for one lvx instruction = 16 - (addr & 0xf)\n-       \/\/\n-       \/\/ Note: When the second load isn't needed, skipping it is NOT\n-       \/\/ optional.  Reading past a page boundary into an inaccessible page\n-       \/\/ will cause a seg fault.\n-       \/\/\n-       __ andi_(gpr_tmp1, addr, 0xf);\n-       __ subfic(gpr_tmp1, gpr_tmp1, 16);\n-       __ cmpd(CCR7, length, gpr_tmp1);\n-       __ ble_predict_taken(CCR7, skip_second_load);\n-\n-       \/\/ Load at addr + 16 to get the next quadword\n-       __ li(gpr_tmp1, 16);\n-       __ lvx(vreg_lo, gpr_tmp1, addr);\n-\n-       __ bind(skip_second_load);\n-       __ vperm(vreg_ret, vreg_lo, vreg_hi, vreg_ret);\n-\n-       \/\/ Zero out the remaining bytes\n-       __ subfic(gpr_tmp1, length, 16);\n-       \/\/ The goal of the following two instructions is to get the shift amount\n-       \/\/ into bits 121:124 of vreg_shift_amt\n-       __ sldi(gpr_tmp1, gpr_tmp1, 3);\n-       __ mtvsrdd(vreg_shift_amt->to_vsr(), gpr_tmp1, gpr_tmp1);\n-       __ xxspltib(vreg_mask->to_vsr(), 0xff);\n-       __ vsro(vreg_mask, vreg_mask, vreg_shift_amt);\n-       __ vand(vreg_ret, vreg_ret, vreg_mask);\n-       __ b(done);\n-\n-       __ bind(no_load);\n-       \/\/ Zero out all of the bytes\n-       __ xxspltib(vreg_ret->to_vsr(), 0);\n-       __ bind(done);\n-\n-     }\n-  }\n-\n@@ -4351,2 +4283,1 @@\n-    Register lxvl_gpr_tmp1  = R7;  \/\/ temp register for do_lxvl (reuse dp's register)\n-    Register tmp1           = R7;  \/\/ gpr tmp (reuse lxvl_gpr_tmp1's register)\n+    Register tmp1           = R7;  \/\/ temp register for lxvl length (reuse dp's register)\n@@ -4397,1 +4328,1 @@\n-    __ load_const(const_ptr, (address)&expand_permute_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&expand_permute_val, tmp_reg);\n@@ -4399,1 +4330,1 @@\n-    __ load_const(const_ptr, (address)&expand_rshift_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&expand_rshift_val, tmp_reg);\n@@ -4401,1 +4332,1 @@\n-    __ load_const(const_ptr, (address)&expand_rshift_mask_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&expand_rshift_mask_val, tmp_reg);\n@@ -4403,1 +4334,1 @@\n-    __ load_const(const_ptr, (address)&expand_lshift_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&expand_lshift_val, tmp_reg);\n@@ -4405,1 +4336,1 @@\n-    __ load_const(const_ptr, (address)&expand_lshift_mask_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&expand_lshift_mask_val, tmp_reg);\n@@ -4418,1 +4349,1 @@\n-    __ load_const(const_ptr, (address)&offsetLUT_URL_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&offsetLUT_URL_val, tmp_reg);\n@@ -4423,1 +4354,1 @@\n-    __ load_const(const_ptr, (address)&offsetLUT_val, tmp_reg);\n+    __ load_const_optimized(const_ptr, (address)&offsetLUT_val, tmp_reg);\n@@ -4484,1 +4415,2 @@\n-    do_lxvl(input, in, remaining, lxvl_gpr_tmp1, lxvl_vreg_tmp1, lxvl_vreg_tmp2);\n+    __ rldicr(tmp1, remaining, 56, 7);\n+    __ lxvl(input->to_vsr(), in, tmp1);\n@@ -4504,1 +4436,2 @@\n-    do_lxvl(input, in, remaining, lxvl_gpr_tmp1, lxvl_vreg_tmp1, lxvl_vreg_tmp2);\n+    __ rldicr(tmp1, bytes_to_write, 56, 7);\n+    __ lxvl(input->to_vsr(), in, tmp1);\n","filename":"src\/hotspot\/cpu\/ppc\/stubGenerator_ppc.cpp","additions":12,"deletions":79,"binary":false,"changes":91,"status":"modified"}]}