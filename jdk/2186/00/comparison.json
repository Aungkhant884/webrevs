{"files":[{"patch":"@@ -445,1 +445,0 @@\n-  int cpu_load(int which_logical_cpu, double* cpu_load);\n@@ -447,2 +446,1 @@\n-  int cpu_load_total_process(double* cpu_load);\n-  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad);\n+  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime);\n@@ -490,23 +488,0 @@\n-int CPUPerformanceInterface::CPUPerformance::cpu_load(int which_logical_cpu, double* cpu_load) {\n-  double u, s;\n-  u = get_cpu_load(which_logical_cpu, &_counters, &s, CPU_LOAD_GLOBAL);\n-  if (u < 0) {\n-    *cpu_load = 0.0;\n-    return OS_ERR;\n-  }\n-  \/\/ Cap total systemload to 1.0\n-  *cpu_load = MIN2<double>((u + s), 1.0);\n-  return OS_OK;\n-}\n-\n-int CPUPerformanceInterface::CPUPerformance::cpu_load_total_process(double* cpu_load) {\n-  double u, s;\n-  u = get_cpu_load(-1, &_counters, &s, CPU_LOAD_VM_ONLY);\n-  if (u < 0) {\n-    *cpu_load = 0.0;\n-    return OS_ERR;\n-  }\n-  *cpu_load = u + s;\n-  return OS_OK;\n-}\n-\n@@ -528,1 +503,7 @@\n-  cpu_load(-1, &t);\n+  t = get_cpu_load(-1, &counters, &s, CPU_LOAD_GLOBAL);\n+  if (t < 0) {\n+    *pjvmUserLoad = 0.0;\n+    *pjvmKernelLoad = 0.0;\n+    *psystemTotalLoad = 0.0;\n+    return OS_ERR;\n+  }\n@@ -560,9 +541,1 @@\n-int CPUPerformanceInterface::cpu_load(int which_logical_cpu, double* cpu_load) const {\n-  return _impl->cpu_load(which_logical_cpu, cpu_load);\n-}\n-\n-int CPUPerformanceInterface::cpu_load_total_process(double* cpu_load) const {\n-  return _impl->cpu_load_total_process(cpu_load);\n-}\n-\n-int CPUPerformanceInterface::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad) const {\n+int CPUPerformanceInterface::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime) const {\n","filename":"src\/hotspot\/os\/aix\/os_perf_aix.cpp","additions":9,"deletions":36,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+  long _nanos_per_tick;\n@@ -71,1 +72,0 @@\n-  int cpu_load(int which_logical_cpu, double* cpu_load);\n@@ -73,2 +73,2 @@\n-  int cpu_load_total_process(double* cpu_load);\n-  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad);\n+  int cpu_load_time_total_process(double* cpu_load, uint64_t* cpu_time);\n+  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime);\n@@ -96,0 +96,11 @@\n+  int mib[2];\n+\n+  mib[0] = CTL_KERN;\n+  mib[1] = KERN_CLOCKRATE;\n+  clockinfo cinfo;\n+  size_t len = sizeof(cinfo);\n+\n+  if (sysctl(mib, 2, &cinfo, &len, NULL, 0) == -1) {\n+    return false;\n+  }\n+  _nanos_per_tick = cinfo.tick * 1000; \/\/ tick is in u-seconds per tick; need to upscale it to nanoseconds\n@@ -102,5 +113,1 @@\n-int CPUPerformanceInterface::CPUPerformance::cpu_load(int which_logical_cpu, double* cpu_load) {\n-  return FUNCTIONALITY_NOT_IMPLEMENTED;\n-}\n-\n-int CPUPerformanceInterface::CPUPerformance::cpu_load_total_process(double* cpu_load) {\n+int CPUPerformanceInterface::CPUPerformance::cpu_load_time_total_process(double* cpu_load, uint64_t* cpu_time) {\n@@ -134,0 +141,3 @@\n+  if (cpu_time != NULL) {\n+    *cpu_time = _used_ticks * _nanos_per_tick;\n+  }\n@@ -147,1 +157,1 @@\n-int CPUPerformanceInterface::CPUPerformance::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad) {\n+int CPUPerformanceInterface::CPUPerformance::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime) {\n@@ -149,1 +159,1 @@\n-  int result = cpu_load_total_process(psystemTotalLoad);\n+  int result = cpu_load_time_total_process(psystemTotalLoad, psystemTotalTime);\n@@ -179,2 +189,4 @@\n-  *pjvmUserLoad = normalize((double)(jvm_user_nanos - _jvm_user_nanos)\/delta_nanos);\n-  *pjvmKernelLoad = normalize((double)(jvm_system_nanos - _jvm_system_nanos)\/delta_nanos);\n+  *pjvmUserTime = jvm_user_nanos - _jvm_user_nanos;\n+  *pjvmKernelTime = jvm_system_nanos - _jvm_system_nanos;\n+  *pjvmUserLoad = normalize((double)(*pjvmUserTime)\/delta_nanos);\n+  *pjvmKernelLoad = normalize((double)(*pjvmKernelTime)\/delta_nanos);\n@@ -247,10 +259,2 @@\n-int CPUPerformanceInterface::cpu_load(int which_logical_cpu, double* cpu_load) const {\n-  return _impl->cpu_load(which_logical_cpu, cpu_load);\n-}\n-\n-int CPUPerformanceInterface::cpu_load_total_process(double* cpu_load) const {\n-  return _impl->cpu_load_total_process(cpu_load);\n-}\n-\n-int CPUPerformanceInterface::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad) const {\n-  return _impl->cpu_loads_process(pjvmUserLoad, pjvmKernelLoad, psystemTotalLoad);\n+int CPUPerformanceInterface::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime) const {\n+  return _impl->cpu_loads_process(pjvmUserLoad, pjvmKernelLoad, psystemTotalLoad, pjvmUserTime, pjvmKernelTime, psystemTotalTime);\n","filename":"src\/hotspot\/os\/bsd\/os_perf_bsd.cpp","additions":26,"deletions":22,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -222,0 +222,18 @@\n+struct CPUPerfData {\n+  double jvmUserLoad;\n+  double jvmKernelLoad;\n+  double systemLoad;\n+\n+  uint64_t jvmUserTime;\n+  uint64_t jvmKernelTime;\n+  uint64_t systemTime;\n+};\n+\n+struct CPUPerfTicksEx {\n+  uint64_t jvmUser;\n+  uint64_t jvmKernel;\n+  uint64_t totalUser;\n+  uint64_t totalKernel;\n+  uint64_t total;\n+};\n+\n@@ -224,2 +242,2 @@\n-  os::Linux::CPUPerfTicks jvmTicks;\n-  os::Linux::CPUPerfTicks* cpus;\n+  CPUPerfTicksEx jvmTicks;\n+  CPUPerfTicksEx* cpus;\n@@ -228,1 +246,3 @@\n-static double get_cpu_load(int which_logical_cpu, CPUPerfCounters* counters, double* pkernelLoad, CpuLoadTarget target);\n+static double _clock_nsec_per_tick = (double)1000000000 \/ sysconf(_SC_CLK_TCK);\n+\n+static OSReturn read_cpu_perf(int which_logical_cpu, CPUPerfCounters* counters, CpuLoadTarget target, CPUPerfData* pperfData);\n@@ -314,1 +334,1 @@\n-static OSReturn get_jvm_ticks(os::Linux::CPUPerfTicks* pticks) {\n+static OSReturn read_all_ticks(CPUPerfTicksEx* pticks) {\n@@ -326,2 +346,3 @@\n-  \/\/ get the total\n-  if (! os::Linux::get_tick_information(pticks, -1)) {\n+  \/\/ get the machine total\n+  os::Linux::CPUPerfTicks machine_pticks;\n+  if (! os::Linux::get_tick_information(&machine_pticks, -1)) {\n@@ -331,2 +352,5 @@\n-  pticks->used       = userTicks;\n-  pticks->usedKernel = systemTicks;\n+  pticks->jvmUser       = MAX2<uint64_t>(userTicks, 0);\n+  pticks->jvmKernel     = MAX2<uint64_t>(systemTicks, 0);\n+  pticks->totalUser     = MAX2<uint64_t>(machine_pticks.used, 0);\n+  pticks->totalKernel   = MAX2<uint64_t>(machine_pticks.usedKernel, 0);\n+  pticks->total         = MAX2<uint64_t>(machine_pticks.total, 0);\n@@ -337,12 +361,3 @@\n-\/**\n- * Return the load of the CPU as a double. 1.0 means the CPU process uses all\n- * available time for user or system processes, 0.0 means the CPU uses all time\n- * being idle.\n- *\n- * Returns a negative value if there is a problem in determining the CPU load.\n- *\/\n-static double get_cpu_load(int which_logical_cpu, CPUPerfCounters* counters, double* pkernelLoad, CpuLoadTarget target) {\n-  uint64_t udiff, kdiff, tdiff;\n-  os::Linux::CPUPerfTicks* pticks;\n-  os::Linux::CPUPerfTicks  tmp;\n-  double user_load;\n+static OSReturn read_core_ticks(CPUPerfTicksEx* pticks, int core) {\n+  uint64_t userTicks;\n+  uint64_t systemTicks;\n@@ -350,1 +365,22 @@\n-  *pkernelLoad = 0.0;\n+  if (get_systemtype() != LINUX26_NPTL) {\n+    return OS_ERR;\n+  }\n+\n+  \/\/ get the machine total\n+  os::Linux::CPUPerfTicks machine_pticks;\n+  if (! os::Linux::get_tick_information(&machine_pticks, core)) {\n+    return OS_ERR;\n+  }\n+\n+  pticks->jvmUser       = 0;\n+  pticks->jvmKernel     = 0;\n+  pticks->totalUser     = MAX2<uint64_t>(machine_pticks.used, 0);\n+  pticks->totalKernel   = MAX2<uint64_t>(machine_pticks.usedKernel, 0);\n+  pticks->total         = MAX2<uint64_t>(machine_pticks.total, 0);\n+\n+  return OS_OK;\n+}\n+\n+static OSReturn read_ticks_diff(int which_logical_cpu, CPUPerfCounters* counters, CpuLoadTarget target, CPUPerfTicksEx* pticks_diff) {\n+  CPUPerfTicksEx* pticks;\n+  CPUPerfTicksEx  tmp;\n@@ -362,6 +398,2 @@\n-  if (target == CPU_LOAD_VM_ONLY) {\n-    if (get_jvm_ticks(pticks) != OS_OK) {\n-      return -1.0;\n-    }\n-  } else if (! os::Linux::get_tick_information(pticks, which_logical_cpu)) {\n-    return -1.0;\n+  if (read_all_ticks(pticks) != OS_OK) {\n+    return OS_ERR;\n@@ -372,4 +404,29 @@\n-  if (pticks->usedKernel < tmp.usedKernel) {\n-    kdiff = 0;\n-  } else {\n-    kdiff = pticks->usedKernel - tmp.usedKernel;\n+  pticks_diff->jvmKernel = MAX2<uint64_t>(pticks->jvmKernel - tmp.jvmKernel, 0);\n+  pticks_diff->jvmUser = MAX2<uint64_t>(pticks->jvmUser - tmp.jvmUser, 0);\n+  pticks_diff->totalKernel = MAX2<uint64_t>(pticks->totalKernel - tmp.totalKernel, 0);\n+  pticks_diff->totalUser = MAX2<uint64_t>(pticks->totalUser - tmp.totalUser, 0);\n+  pticks_diff->total = MAX2<uint64_t>(pticks->total - tmp.total, 0);\n+\n+  return OS_OK;\n+}\n+\n+\/**\n+ * Return the load of the CPU as a double. 1.0 means the CPU process uses all\n+ * available time for user or system processes, 0.0 means the CPU being idle.\n+ *\n+ * Returns a negative value if there is a problem in determining the CPU load.\n+ *\/\n+static OSReturn read_cpu_perf(int which_logical_cpu, CPUPerfCounters* counters, CpuLoadTarget target, CPUPerfData* pperfData) {\n+  uint64_t udiff, kdiff, tdiff;\n+\n+  CPUPerfTicksEx pticks_diff;\n+\n+  pperfData->jvmUserTime = 0;\n+  pperfData->jvmUserLoad = 0.0;\n+  pperfData->jvmKernelTime = 0;\n+  pperfData->jvmKernelLoad = 0.0;\n+  pperfData->systemLoad = 0.0;\n+  pperfData->systemTime = 0;\n+\n+  if (read_ticks_diff(which_logical_cpu, counters, target, &pticks_diff) != OS_OK) {\n+    return OS_ERR;\n@@ -377,2 +434,0 @@\n-  tdiff = pticks->total - tmp.total;\n-  udiff = pticks->used - tmp.used;\n@@ -380,4 +435,5 @@\n-  if (tdiff == 0) {\n-    return 0.0;\n-  } else if (tdiff < (udiff + kdiff)) {\n-    tdiff = udiff + kdiff;\n+  if (pticks_diff.total == 0) {\n+    \/\/ no ticks on any CPU\n+    return OS_OK;\n+  } else if (pticks_diff.total < (pticks_diff.jvmUser + pticks_diff.jvmKernel)) {\n+    pticks_diff.total = pticks_diff.jvmUser + pticks_diff.jvmKernel;\n@@ -385,4 +441,0 @@\n-  *pkernelLoad = (kdiff \/ (double)tdiff);\n-  \/\/ BUG9044876, normalize return values to sane values\n-  *pkernelLoad = MAX2<double>(*pkernelLoad, 0.0);\n-  *pkernelLoad = MIN2<double>(*pkernelLoad, 1.0);\n@@ -390,1 +442,1 @@\n-  user_load = (udiff \/ (double)tdiff);\n+  double user_load = (pticks_diff.jvmUser \/ (double)pticks_diff.total);\n@@ -394,1 +446,19 @@\n-  return user_load;\n+  pperfData->jvmUserTime = pticks_diff.jvmUser * _clock_nsec_per_tick;\n+  pperfData->jvmUserLoad = user_load;\n+\n+  pperfData->jvmKernelTime = pticks_diff.jvmKernel * _clock_nsec_per_tick;\n+  pperfData->jvmKernelLoad = (pticks_diff.jvmKernel \/ (double)pticks_diff.total);\n+  \/\/ BUG9044876, normalize return values to sane values\n+  pperfData->jvmKernelLoad = MAX2<double>(pperfData->jvmKernelLoad, 0.0);\n+  pperfData->jvmKernelLoad = MIN2<double>(pperfData->jvmKernelLoad, 1.0);\n+\n+  uint64_t machineActiveTicks = pticks_diff.totalKernel + pticks_diff.totalUser;\n+  pperfData->systemLoad = machineActiveTicks \/ (double)pticks_diff.total;\n+  if (pperfData->systemLoad < pperfData->jvmUserLoad + pperfData->jvmKernelLoad) {\n+    pperfData->systemLoad = pperfData->jvmUserLoad + pperfData->jvmKernelLoad;\n+    pperfData->systemLoad = MAX2<double>(pperfData->systemLoad, 0.0);\n+    pperfData->systemLoad = MIN2<double>(pperfData->systemLoad, 1.0);\n+  }\n+  pperfData->systemTime = machineActiveTicks * _clock_nsec_per_tick;\n+\n+  return OS_OK;\n@@ -505,1 +575,0 @@\n-  int cpu_load(int which_logical_cpu, double* cpu_load);\n@@ -507,2 +576,1 @@\n-  int cpu_load_total_process(double* cpu_load);\n-  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad);\n+  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime);\n@@ -523,1 +591,1 @@\n-  _counters.cpus = NEW_C_HEAP_ARRAY(os::Linux::CPUPerfTicks, array_entry_count, mtInternal);\n+  _counters.cpus = NEW_C_HEAP_ARRAY(CPUPerfTicksEx, array_entry_count, mtInternal);\n@@ -527,1 +595,1 @@\n-  os::Linux::get_tick_information(&_counters.cpus[_counters.nProcs], -1);\n+  read_core_ticks(&_counters.cpus[_counters.nProcs], -1);\n@@ -531,1 +599,1 @@\n-    os::Linux::get_tick_information(&_counters.cpus[i], i);\n+    read_core_ticks(&_counters.cpus[i], i);\n@@ -534,1 +602,1 @@\n-  get_jvm_ticks(&_counters.jvmTicks);\n+  read_all_ticks(&_counters.jvmTicks);\n@@ -550,26 +618,1 @@\n-int CPUPerformanceInterface::CPUPerformance::cpu_load(int which_logical_cpu, double* cpu_load) {\n-  double u, s;\n-  u = get_cpu_load(which_logical_cpu, &_counters, &s, CPU_LOAD_GLOBAL);\n-  if (u < 0) {\n-    *cpu_load = 0.0;\n-    return OS_ERR;\n-  }\n-  \/\/ Cap total systemload to 1.0\n-  *cpu_load = MIN2<double>((u + s), 1.0);\n-  return OS_OK;\n-}\n-\n-int CPUPerformanceInterface::CPUPerformance::cpu_load_total_process(double* cpu_load) {\n-  double u, s;\n-  u = get_cpu_load(-1, &_counters, &s, CPU_LOAD_VM_ONLY);\n-  if (u < 0) {\n-    *cpu_load = 0.0;\n-    return OS_ERR;\n-  }\n-  *cpu_load = u + s;\n-  return OS_OK;\n-}\n-\n-int CPUPerformanceInterface::CPUPerformance::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad) {\n-  double u, s, t;\n-\n+int CPUPerformanceInterface::CPUPerformance::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime) {\n@@ -578,0 +621,2 @@\n+  assert(pjvmUserTime != NULL, \"pjvmUserTime not inited\");\n+  assert(pjvmKernelTime != NULL, \"pjvmKernelTime not inited\");\n@@ -579,0 +624,1 @@\n+  assert(psystemTotalTime != NULL, \"psystemTotalTime not inited\");\n@@ -580,2 +626,2 @@\n-  u = get_cpu_load(-1, &_counters, &s, CPU_LOAD_VM_ONLY);\n-  if (u < 0) {\n+  CPUPerfData perfData;\n+  if (read_cpu_perf(-1, &_counters, CPU_LOAD_VM_ONLY, &perfData) != OS_OK) {\n@@ -584,0 +630,2 @@\n+    *pjvmUserTime = -1;\n+    *pjvmKernelTime = -1;\n@@ -585,0 +633,1 @@\n+    *psystemTotalTime = -1;\n@@ -588,9 +637,6 @@\n-  cpu_load(-1, &t);\n-  \/\/ clamp at user+system and 1.0\n-  if (u + s > t) {\n-    t = MIN2<double>(u + s, 1.0);\n-  }\n-\n-  *pjvmUserLoad = u;\n-  *pjvmKernelLoad = s;\n-  *psystemTotalLoad = t;\n+  *pjvmUserLoad = perfData.jvmUserLoad;\n+  *pjvmUserTime = perfData.jvmUserTime;\n+  *pjvmKernelLoad = perfData.jvmKernelLoad;\n+  *pjvmKernelTime = perfData.jvmKernelTime;\n+  *psystemTotalLoad = perfData.systemLoad;\n+  *psystemTotalTime = perfData.systemTime;\n@@ -620,10 +666,2 @@\n-int CPUPerformanceInterface::cpu_load(int which_logical_cpu, double* cpu_load) const {\n-  return _impl->cpu_load(which_logical_cpu, cpu_load);\n-}\n-\n-int CPUPerformanceInterface::cpu_load_total_process(double* cpu_load) const {\n-  return _impl->cpu_load_total_process(cpu_load);\n-}\n-\n-int CPUPerformanceInterface::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad) const {\n-  return _impl->cpu_loads_process(pjvmUserLoad, pjvmKernelLoad, psystemTotalLoad);\n+int CPUPerformanceInterface::cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime) const {\n+  return _impl->cpu_loads_process(pjvmUserLoad, pjvmKernelLoad, psystemTotalLoad, pjvmUserTime, pjvmKernelTime, psystemTotalTime);\n","filename":"src\/hotspot\/os\/linux\/os_perf_linux.cpp","additions":135,"deletions":97,"binary":false,"changes":232,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include <inttypes.h>\n@@ -40,0 +41,2 @@\n+#include <processthreadsapi.h>\n+#include <profileapi.h>\n@@ -92,0 +95,2 @@\n+static const uint64_t NSECS_PER_TICK = 100;\n+\n@@ -1082,2 +1087,5 @@\n-  ProcessQueryP _process_cpu_load;\n-  MultiCounterQueryP _machine_cpu_load;\n+  double _counter_multiplier;\n+  uint64_t _jvm_user_time;\n+  uint64_t _jvm_kernel_time;\n+  uint64_t _machine_time;\n+  uint64_t _wall_time;\n@@ -1085,1 +1093,0 @@\n-  int cpu_load(int which_logical_cpu, double* cpu_load);\n@@ -1087,2 +1094,2 @@\n-  int cpu_load_total_process(double* cpu_load);\n-  int cpu_loads_process(double* jvm_user_load, double* jvm_kernel_load, double* system_total_load);\n+  int cpu_loads_process(double* jvm_user_load, double* jvm_kernel_load, double* machine_load, uint64_t* jvm_user_time, uint64_t* jvm_kernel_time, uint64_t* machine_time);\n+  int cpu_times_process(uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* systemTotalTime, uint64_t* wallTime);\n@@ -1094,1 +1101,1 @@\n-CPUPerformanceInterface::CPUPerformance::CPUPerformance() : _context_switches(NULL), _process_cpu_load(NULL), _machine_cpu_load(NULL) {}\n+CPUPerformanceInterface::CPUPerformance::CPUPerformance() : _context_switches(NULL) {}\n@@ -1097,0 +1104,5 @@\n+  LARGE_INTEGER frequency;\n+  if (!QueryPerformanceFrequency(&frequency)) {\n+    return false;\n+  }\n+  _counter_multiplier = 1.0e9 \/ static_cast<double>(frequency.QuadPart);\n@@ -1106,11 +1118,1 @@\n-  _process_cpu_load = create_process_query();\n-  if (_process_cpu_load == NULL) {\n-    return false;\n-  }\n-  if (initialize_process_query(_process_cpu_load) != OS_OK) {\n-    return false;\n-  }\n-  assert(_process_cpu_load->set.initialized, \"invariant\");\n-  _machine_cpu_load = create_multi_counter_query();\n-  assert(_machine_cpu_load != NULL, \"invariant\");\n-  if (initialize_cpu_query(_machine_cpu_load) != OS_OK) {\n+  if (cpu_times_process(&_jvm_user_time, &_jvm_kernel_time, &_machine_time, &_wall_time) != OS_OK) {\n@@ -1119,1 +1121,0 @@\n-  assert(_machine_cpu_load->initialized, \"invariant\");\n@@ -1128,8 +1129,0 @@\n-  if (_process_cpu_load != NULL) {\n-    destroy(_process_cpu_load);\n-    _process_cpu_load = NULL;\n-  }\n-  if (_machine_cpu_load != NULL) {\n-    destroy(_machine_cpu_load);\n-    _machine_cpu_load = NULL;\n-  }\n@@ -1152,4 +1145,0 @@\n-int CPUPerformanceInterface::cpu_load(int which_logical_cpu, double* cpu_load) const {\n-  return _impl->cpu_load(which_logical_cpu, cpu_load);\n-}\n-\n@@ -1160,4 +1149,0 @@\n-int CPUPerformanceInterface::cpu_load_total_process(double* cpu_load) const {\n-  return _impl->cpu_load_total_process(cpu_load);\n-}\n-\n@@ -1166,40 +1151,5 @@\n-                                               double* system_total_load) const {\n-  return _impl->cpu_loads_process(jvm_user_load, jvm_kernel_load, system_total_load);\n-}\n-\n-int CPUPerformanceInterface::CPUPerformance::cpu_load(int which_logical_cpu, double* cpu_load) {\n-  *cpu_load = .0;\n-  if (_machine_cpu_load == NULL || !_machine_cpu_load->initialized) {\n-    return OS_ERR;\n-  }\n-  assert(which_logical_cpu < _machine_cpu_load->noOfCounters, \"invariant\");\n-  if (collect(_machine_cpu_load) != OS_OK) {\n-    return OS_ERR;\n-  }\n-  \/\/ -1 is total (all cpus)\n-  const int counter_idx = -1 == which_logical_cpu ? _machine_cpu_load->noOfCounters - 1 : which_logical_cpu;\n-  PDH_FMT_COUNTERVALUE counter_value;\n-  if (read_counter(_machine_cpu_load, counter_idx, PDH_FMT_DOUBLE, &counter_value) != OS_OK) {\n-    return OS_ERR;\n-  }\n-  *cpu_load = counter_value.doubleValue \/ 100;\n-  return OS_OK;\n-}\n-\n-int CPUPerformanceInterface::CPUPerformance::cpu_load_total_process(double* cpu_load) {\n-  *cpu_load = .0;\n-  if (_process_cpu_load == NULL || !_process_cpu_load->set.initialized) {\n-    return OS_ERR;\n-  }\n-  if (collect(_process_cpu_load) != OS_OK) {\n-    return OS_ERR;\n-  }\n-  PDH_FMT_COUNTERVALUE counter_value;\n-  if (read_counter(_process_cpu_load, 0, PDH_FMT_DOUBLE | PDH_FMT_NOCAP100, &counter_value) != OS_OK) {\n-    return OS_ERR;\n-  }\n-  double process_load = counter_value.doubleValue \/ cpu_factor();\n-  process_load = MIN2<double>(1, process_load);\n-  process_load = MAX2<double>(0, process_load);\n-  *cpu_load = process_load;\n-  return OS_OK;\n+                                               double* machine_load,\n+                                               uint64_t* jvm_user_time,\n+                                               uint64_t* jvm_kernel_time,\n+                                               uint64_t* machine_time) const {\n+  return _impl->cpu_loads_process(jvm_user_load, jvm_kernel_load, machine_load, jvm_user_time, jvm_kernel_time, machine_time);\n@@ -1210,1 +1160,5 @@\n-                                                               double* system_total_load) {\n+                                                               double* machine_load,\n+                                                               uint64_t* jvm_user_time,\n+                                                               uint64_t* jvm_kernel_time,\n+                                                               uint64_t* machine_time\n+                                                               ) {\n@@ -1213,1 +1167,4 @@\n-  assert(system_total_load != NULL, \"system_total_load is NULL!\");\n+  assert(jvm_user_time != NULL, \"jvm_user_time is NULL!\");\n+  assert(jvm_kernel_time != NULL, \"jvm_kernel_time is NULL!\");\n+  assert(machine_load != NULL, \"machine_load is NULL!\");\n+  assert(machine_time != NULL, \"machine_time is NULL!\");\n@@ -1216,1 +1173,23 @@\n-  *system_total_load = .0;\n+  *jvm_user_time = 0;\n+  *jvm_kernel_time = 0;\n+  *machine_load = .0;\n+  *machine_time = 0;\n+\n+  uint64_t tmp_jvm_user_time = _jvm_user_time;\n+  uint64_t tmp_jvm_kernel_time = _jvm_kernel_time;\n+  uint64_t tmp_machine_time = _machine_time;\n+  uint64_t tmp_wall_time = _wall_time;\n+\n+  int err = cpu_times_process(&_jvm_user_time, &_jvm_kernel_time, &_machine_time, &_wall_time);\n+  if (err != OS_OK) {\n+    return err;\n+  }\n+  *jvm_user_time = _jvm_user_time - tmp_jvm_user_time;\n+  *jvm_kernel_time = _jvm_kernel_time - tmp_jvm_kernel_time;\n+  *machine_time = _machine_time - tmp_machine_time;\n+  uint64_t wall_time = _wall_time - tmp_wall_time;\n+\n+  double time_budget = (double)(wall_time * number_of_logical_cpus());\n+  *jvm_user_load = *jvm_user_time \/ time_budget;\n+  *jvm_kernel_load = *jvm_kernel_time \/ time_budget;\n+  *machine_load = *machine_time \/ time_budget;\n@@ -1218,11 +1197,4 @@\n-  if (_process_cpu_load == NULL || !_process_cpu_load->set.initialized) {\n-    return OS_ERR;\n-  }\n-  if (collect(_process_cpu_load) != OS_OK) {\n-    return OS_ERR;\n-  }\n-  double process_load = .0;\n-  PDH_FMT_COUNTERVALUE counter_value;\n-  \/\/ Read PDH_PROCESSOR_TIME_IDX as counter_idx == 0\n-  if (read_counter(_process_cpu_load, 0, PDH_FMT_DOUBLE | PDH_FMT_NOCAP100, &counter_value) != OS_OK) {\n-    return OS_ERR;\n+  assert(machine_load >= 0, \"machine_load is negative!\");\n+  \/\/ clamp machine load at user+system and 1.0\n+  if (*jvm_kernel_load + *jvm_user_load > *machine_load) {\n+    *machine_load = MIN2(*jvm_kernel_load + *jvm_user_load, 1.0);\n@@ -1230,5 +1202,14 @@\n-  process_load = counter_value.doubleValue \/ cpu_factor();\n-  process_load = MIN2<double>(1, process_load);\n-  process_load = MAX2<double>(0, process_load);\n-  \/\/ Read PDH_PRIV_PROCESSOR_TIME_IDX as counter_idx == 1\n-  if (read_counter(_process_cpu_load, 1, PDH_FMT_DOUBLE | PDH_FMT_NOCAP100, &counter_value) != OS_OK) {\n+\n+  return OS_OK;\n+}\n+\n+int CPUPerformanceInterface::CPUPerformance::cpu_times_process(uint64_t* jvm_user_time, uint64_t* jvm_kernel_time, uint64_t* machine_time, uint64_t* wall_time) {\n+  FILETIME creation_time;\n+  FILETIME exit_time;\n+  FILETIME kernel_time;\n+  FILETIME user_time;\n+  FILETIME idle_time;\n+\n+  LARGE_INTEGER walltime_counter;\n+\n+  if (!QueryPerformanceCounter(&walltime_counter)) {\n@@ -1237,4 +1218,0 @@\n-  double process_kernel_load = counter_value.doubleValue \/ cpu_factor();\n-  process_kernel_load = MIN2<double>(1, process_kernel_load);\n-  process_kernel_load = MAX2<double>(0, process_kernel_load);\n-  *jvm_kernel_load = process_kernel_load;\n@@ -1242,5 +1219,1 @@\n-  double user_load = process_load - process_kernel_load;\n-  user_load = MIN2<double>(1, user_load);\n-  user_load = MAX2<double>(0, user_load);\n-  *jvm_user_load = user_load;\n-  if (collect(_machine_cpu_load) != OS_OK) {\n+  if (!GetSystemTimes(&idle_time, &kernel_time, &user_time)) {\n@@ -1249,2 +1222,2 @@\n-  \/\/ Read PDH_PROCESSOR_IDX as counter_idx == _machine_cpu_load->noOfCounters - 1\n-  if (read_counter(_machine_cpu_load, _machine_cpu_load->noOfCounters - 1, PDH_FMT_DOUBLE, &counter_value) != OS_OK) {\n+\n+  if (!GetProcessTimes(GetCurrentProcess(), &creation_time, &exit_time, &kernel_time, &user_time)) {\n@@ -1253,7 +1226,30 @@\n-  double machine_load = counter_value.doubleValue \/ 100;\n-  assert(machine_load >= 0, \"machine_load is negative!\");\n-  \/\/ clamp at user+system and 1.0\n-  if (*jvm_kernel_load + *jvm_user_load > machine_load) {\n-    machine_load = MIN2(*jvm_kernel_load + *jvm_user_load, 1.0);\n-  }\n-  *system_total_load = machine_load;\n+\n+  LARGE_INTEGER li_jvm_user_time;\n+  LARGE_INTEGER li_jvm_kernel_time;\n+  LARGE_INTEGER li_system_user_time;\n+  LARGE_INTEGER li_system_kernel_time;\n+  LARGE_INTEGER li_system_idle_time;\n+\n+  li_jvm_user_time.LowPart = user_time.dwLowDateTime;\n+  li_jvm_user_time.HighPart = user_time.dwHighDateTime;\n+\n+  li_jvm_kernel_time.LowPart = kernel_time.dwLowDateTime;\n+  li_jvm_kernel_time.HighPart = kernel_time.dwHighDateTime;\n+\n+  li_system_user_time.LowPart = user_time.dwLowDateTime;\n+  li_system_user_time.HighPart = user_time.dwHighDateTime;\n+\n+  li_system_kernel_time.LowPart = kernel_time.dwLowDateTime;\n+  li_system_kernel_time.HighPart = kernel_time.dwHighDateTime;\n+\n+  li_system_idle_time.LowPart = idle_time.dwLowDateTime;\n+  li_system_idle_time.HighPart = idle_time.dwHighDateTime;\n+\n+  \/\/ convert user ticks to nanoseconds\n+  *jvm_user_time = li_jvm_user_time.QuadPart * NSECS_PER_TICK;\n+  \/\/ convert kernel ticks to nanoseconds\n+  *jvm_kernel_time = li_jvm_kernel_time.QuadPart * NSECS_PER_TICK;\n+  \/\/ convert the walltime counter to nanoscends\n+  *wall_time = walltime_counter.QuadPart * _counter_multiplier;\n+  *machine_time = (li_system_user_time.QuadPart + li_system_kernel_time.QuadPart - li_system_idle_time.QuadPart) * NSECS_PER_TICK;\n+\n","filename":"src\/hotspot\/os\/windows\/os_perf_windows.cpp","additions":107,"deletions":111,"binary":false,"changes":218,"status":"modified"},{"patch":"@@ -701,0 +701,3 @@\n+    <Field type=\"long\" contentType=\"nanos\" name=\"jvmUserTime\" label=\"Elapsed JVM User CPU Time\"\/>\n+    <Field type=\"long\" contentType=\"nanos\" name=\"jvmSystemTime\" label=\"Elapsed JVM System CPU Time\"\/>\n+    <Field type=\"long\" contentType=\"nanos\" name=\"machineTotalTime\" label=\"Elapsed Total CPU Time\"\/>\n@@ -706,0 +709,2 @@\n+    <Field type=\"long\" contentType=\"nanos\" name=\"userTime\" label=\"Elapsed User CPU Time\"\/>\n+    <Field type=\"long\" contentType=\"nanos\" name=\"systemTime\" label=\"Elapsed System CPU Time\"\/>\n","filename":"src\/hotspot\/share\/jfr\/metadata\/metadata.xml","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -85,1 +85,0 @@\n-  int cpu_load(int which_logical_cpu, double* cpu_load);\n@@ -87,2 +86,1 @@\n-  int cpu_load_total_process(double* cpu_load);\n-  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotal);\n+  int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime);\n@@ -176,5 +174,0 @@\n-int JfrOSInterface::JfrOSInterfaceImpl::cpu_load(int which_logical_cpu, double* cpu_load) {\n-  CPUPerformanceInterface* const iface = cpu_perf_interface();\n-  return iface == NULL ? OS_ERR : iface->cpu_load(which_logical_cpu, cpu_load);\n-}\n-\n@@ -186,5 +179,0 @@\n-int JfrOSInterface::JfrOSInterfaceImpl::cpu_load_total_process(double* cpu_load) {\n-  CPUPerformanceInterface* const iface = cpu_perf_interface();\n-  return iface == NULL ? OS_ERR : iface->cpu_load_total_process(cpu_load);\n-}\n-\n@@ -193,1 +181,5 @@\n-                                                          double* psystemTotal) {\n+                                                          double* psystemTotalLoad,\n+                                                          uint64_t* pjvmUserTime,\n+                                                          uint64_t* pjvmKernelTime,\n+                                                          uint64_t* psystemTotalTime\n+                                                          ) {\n@@ -195,1 +187,1 @@\n-  return iface == NULL ? OS_ERR : iface->cpu_loads_process(pjvmUserLoad, pjvmKernelLoad, psystemTotal);\n+  return iface == NULL ? OS_ERR : iface->cpu_loads_process(pjvmUserLoad, pjvmKernelLoad, psystemTotalLoad, pjvmUserTime, pjvmKernelTime, psystemTotalTime);\n@@ -240,4 +232,0 @@\n-int JfrOSInterface::cpu_load(int which_logical_cpu, double* cpu_load) {\n-  return instance()._impl->cpu_load(which_logical_cpu, cpu_load);\n-}\n-\n@@ -248,6 +236,2 @@\n-int JfrOSInterface::cpu_load_total_process(double* cpu_load) {\n-  return instance()._impl->cpu_load_total_process(cpu_load);\n-}\n-\n-int JfrOSInterface::cpu_loads_process(double* jvm_user_load, double* jvm_kernel_load, double* system_total_load){\n-  return instance()._impl->cpu_loads_process(jvm_user_load, jvm_kernel_load, system_total_load);\n+int JfrOSInterface::cpu_loads_process(double* jvm_user_load, double* jvm_kernel_load, double* system_total_load, uint64_t* jvm_user_time, uint64_t* jvm_kernel_time, uint64_t* system_total_time){\n+  return instance()._impl->cpu_loads_process(jvm_user_load, jvm_kernel_load, system_total_load, jvm_user_time, jvm_kernel_time, system_total_time);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/jfrOSInterface.cpp","additions":9,"deletions":25,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -50,1 +50,0 @@\n-  static int cpu_load(int which_logical_cpu, double* cpu_load);\n@@ -52,2 +51,1 @@\n-  static int cpu_load_total_process(double* cpu_load);\n-  static int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad);\n+  static int cpu_loads_process(double* pjvmUserLoad, double* pjvmKernelLoad, double* psystemTotalLoad, uint64_t* pjvmUserTime, uint64_t* pjvmKernelTime, uint64_t* psystemTotalTime);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/jfrOSInterface.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -176,3 +176,6 @@\n-  double u = 0; \/\/ user time\n-  double s = 0; \/\/ kernel time\n-  double t = 0; \/\/ total time\n+  double u = 0; \/\/ user load\n+  double s = 0; \/\/ kernel load\n+  double t = 0; \/\/ total load\n+  uint64_t u_time = 0; \/\/ user time\n+  uint64_t k_time = 0; \/\/ kernel time\n+  uint64_t t_time = 0; \/\/ total time\n@@ -184,1 +187,1 @@\n-    ret_val = JfrOSInterface::cpu_loads_process(&u, &s, &t);\n+    ret_val = JfrOSInterface::cpu_loads_process(&u, &s, &t, &u_time, &k_time, &t_time);\n@@ -195,0 +198,3 @@\n+    event.set_jvmUserTime(u_time);\n+    event.set_jvmSystemTime(k_time);\n+    event.set_machineTotalTime(t_time);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/jfrPeriodic.cpp","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -103,0 +103,2 @@\n+  event.set_userTime(user_time);\n+  event.set_systemTime(system_time);\n","filename":"src\/hotspot\/share\/jfr\/periodic\/jfrThreadCPULoadEvent.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -246,1 +246,0 @@\n-  int cpu_load(int which_logical_cpu, double* const cpu_load) const;\n@@ -248,1 +247,0 @@\n-  int cpu_load_total_process(double* const cpu_load) const;\n@@ -251,1 +249,5 @@\n-                        double* const psystemTotalLoad) const;\n+                        double* const psystemTotalLoad,\n+                        uint64_t* const pjvmUserTime,\n+                        uint64_t* const pjvmKernelTime,\n+                        uint64_t* const psystemTotalTime\n+                        ) const;\n","filename":"src\/hotspot\/share\/runtime\/os_perf.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -28,0 +28,2 @@\n+import static jdk.test.lib.Asserts.assertTrue;\n+\n@@ -29,0 +31,2 @@\n+import java.util.Map;\n+import java.util.concurrent.atomic.AtomicLong;\n@@ -32,0 +36,1 @@\n+import jdk.test.lib.jfr.EventField;\n@@ -50,0 +55,16 @@\n+        final AtomicLong sum = new AtomicLong(0);\n+        Thread[] threads = new Thread[16];\n+        for (int i = 0; i < 16; i++) {\n+            threads[i] = new Thread(() -> {\n+                \/\/ do some busy work here\n+                for (int j = 0; j < 5000000; j++) {\n+                    sum.addAndGet(j);\n+                }\n+            });\n+            threads[i].start();\n+        }\n+        for (int i = 0; i < 16; i++) {\n+            threads[i].join();\n+        }\n+\n+        System.out.println(sum.get());\n@@ -67,3 +88,7 @@\n-            System.out.println(\"Event: \" + event);\n-            for (String loadName : loadNames) {\n-                Events.assertField(event, loadName).atLeast(0.0f).atMost(1.0f);\n+            for (String metricName : metricNames) {\n+                String loadName = metricName;\n+                String cpuTimeName = metricName + \"Time\";\n+\n+                EventField loadField = Events.assertField(event, loadName).atLeast(0.0f).atMost(1.0f);\n+                EventField timeField = Events.assertField(event, cpuTimeName).atLeast((Float)loadField.getValue() > 0.0f ? 1L : 0L);\n+                System.out.println(\"time: \" + timeField.getValue());\n@@ -74,1 +99,1 @@\n-    private static final String[] loadNames = {\"jvmUser\", \"jvmSystem\", \"machineTotal\"};\n+    private static final String[] metricNames = {\"jvmUser\", \"jvmSystem\", \"machineTotal\"};\n","filename":"test\/jdk\/jdk\/jfr\/event\/os\/TestCPULoad.java","additions":29,"deletions":4,"binary":false,"changes":33,"status":"modified"}]}