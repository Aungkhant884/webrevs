{"files":[{"patch":"@@ -2442,0 +2442,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return &_PR_REG_mask;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return new TypeVectMask(elemTy, length);\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2008, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2008, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -996,0 +996,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return NULL;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -2163,0 +2163,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return NULL;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1549,0 +1549,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return NULL;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return NULL;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -52,1 +52,1 @@\n-void C2_MacroAssembler::setvectmask(Register dst, Register src) {\n+void C2_MacroAssembler::setvectmask(Register dst, Register src, KRegister mask) {\n@@ -57,1 +57,1 @@\n-  Assembler::kmovdl(k1, dst);\n+  Assembler::kmovdl(mask, dst);\n@@ -61,1 +61,1 @@\n-void C2_MacroAssembler::restorevectmask() {\n+void C2_MacroAssembler::restorevectmask(KRegister mask) {\n@@ -63,1 +63,1 @@\n-  Assembler::knotwl(k1, k0);\n+  Assembler::knotwl(mask, k0);\n@@ -1896,1 +1896,1 @@\n-void C2_MacroAssembler::genmask(Register dst, Register len, Register temp) {\n+void C2_MacroAssembler::genmask(KRegister dst, Register len, Register temp) {\n@@ -1898,2 +1898,3 @@\n-  mov64(dst, -1L);\n-  bzhiq(dst, dst, len);\n+  mov64(temp, -1L);\n+  bzhiq(temp, temp, len);\n+  kmovql(dst, temp);\n@@ -2157,1 +2158,2 @@\n-void C2_MacroAssembler::vectortest(int bt, int vlen, XMMRegister src1, XMMRegister src2, XMMRegister vtmp1, XMMRegister vtmp2) {\n+void C2_MacroAssembler::vectortest(int bt, int vlen, XMMRegister src1, XMMRegister src2,\n+                                   XMMRegister vtmp1, XMMRegister vtmp2, KRegister mask) {\n@@ -2195,1 +2197,0 @@\n-        KRegister ktemp = k2; \/\/ Use a hardcoded temp due to no k register allocation.\n@@ -2197,1 +2198,1 @@\n-        evpcmpeqb(ktemp, src1, src2, Assembler::AVX_512bit);\n+        evpcmpeqb(mask, src1, src2, Assembler::AVX_512bit);\n@@ -2199,1 +2200,1 @@\n-          ktestql(ktemp, ktemp);\n+          ktestql(mask, mask);\n@@ -2202,1 +2203,1 @@\n-          kortestql(ktemp, ktemp);\n+          kortestql(mask, mask);\n@@ -2919,1 +2920,1 @@\n-                                       XMMRegister vec1, int ae) {\n+                                       XMMRegister vec1, int ae, KRegister mask) {\n@@ -3072,1 +3073,1 @@\n-        evpcmpeqb(k7, vec1, Address(str2, result, scale), Assembler::AVX_512bit); \/\/ k7 == 11..11, if operands equal, otherwise k7 has some 0\n+        evpcmpeqb(mask, vec1, Address(str2, result, scale), Assembler::AVX_512bit); \/\/ k7 == 11..11, if operands equal, otherwise k7 has some 0\n@@ -3075,1 +3076,1 @@\n-        evpcmpeqb(k7, vec1, Address(str2, result, scale2), Assembler::AVX_512bit); \/\/ k7 == 11..11, if operands equal, otherwise k7 has some 0\n+        evpcmpeqb(mask, vec1, Address(str2, result, scale2), Assembler::AVX_512bit); \/\/ k7 == 11..11, if operands equal, otherwise k7 has some 0\n@@ -3077,1 +3078,1 @@\n-      kortestql(k7, k7);\n+      kortestql(mask, mask);\n@@ -3261,1 +3262,1 @@\n-    kmovql(cnt1, k7);\n+    kmovql(cnt1, mask);\n@@ -3310,1 +3311,1 @@\n-  XMMRegister vec1, XMMRegister vec2) {\n+  XMMRegister vec1, XMMRegister vec2, KRegister mask1, KRegister mask2) {\n@@ -3342,2 +3343,2 @@\n-    evpcmpgtb(k2, vec2, Address(ary1, len, Address::times_1), Assembler::AVX_512bit);\n-    kortestql(k2, k2);\n+    evpcmpgtb(mask1, vec2, Address(ary1, len, Address::times_1), Assembler::AVX_512bit);\n+    kortestql(mask1, mask1);\n@@ -3360,1 +3361,1 @@\n-    kmovql(k3, tmp3_aliased);\n+    kmovql(mask2, tmp3_aliased);\n@@ -3385,1 +3386,1 @@\n-    evpcmpgtb(k3, vec1, Address(len, 0), Assembler::AVX_512bit);\n+    evpcmpgtb(mask2, vec1, Address(len, 0), Assembler::AVX_512bit);\n@@ -3388,2 +3389,2 @@\n-    evpcmpgtb(k2, k3, vec2, Address(ary1, 0), Assembler::AVX_512bit);\n-    ktestq(k2, k3);\n+    evpcmpgtb(mask1, mask2, vec2, Address(ary1, 0), Assembler::AVX_512bit);\n+    ktestq(mask1, mask2);\n@@ -3516,1 +3517,1 @@\n-                                      XMMRegister vec1, XMMRegister vec2, bool is_char) {\n+                                      XMMRegister vec1, XMMRegister vec2, bool is_char, KRegister mask) {\n@@ -3579,2 +3580,2 @@\n-      evpcmpeqb(k7, vec1, Address(ary2, limit, Address::times_1), Assembler::AVX_512bit);\n-      kortestql(k7, k7);\n+      evpcmpeqb(mask, vec1, Address(ary2, limit, Address::times_1), Assembler::AVX_512bit);\n+      kortestql(mask, mask);\n@@ -3597,2 +3598,2 @@\n-      evpcmpeqb(k7, vec1, Address(ary2, result, Address::times_1), Assembler::AVX_512bit);\n-      kortestql(k7, k7);\n+      evpcmpeqb(mask, vec1, Address(ary2, result, Address::times_1), Assembler::AVX_512bit);\n+      kortestql(mask, mask);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":31,"deletions":30,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -34,2 +34,2 @@\n-  void setvectmask(Register dst, Register src);\n-  void restorevectmask();\n+  void setvectmask(Register dst, Register src, KRegister mask);\n+  void restorevectmask(KRegister mask);\n@@ -134,1 +134,1 @@\n-                  XMMRegister vtmp1 = xnoreg, XMMRegister vtmp2 = xnoreg);\n+                  XMMRegister vtmp1 = xnoreg, XMMRegister vtmp2 = xnoreg, KRegister mask = knoreg);\n@@ -149,1 +149,1 @@\n-  void genmask(Register dst, Register len, Register temp);\n+  void genmask(KRegister dst, Register len, Register temp);\n@@ -247,1 +247,1 @@\n-                      XMMRegister vec1, int ae);\n+                      XMMRegister vec1, int ae, KRegister mask = knoreg);\n@@ -253,1 +253,1 @@\n-                     XMMRegister vec1, XMMRegister vec2);\n+                     XMMRegister vec1, XMMRegister vec2, KRegister mask1 = knoreg, KRegister mask2 = knoreg);\n@@ -258,1 +258,1 @@\n-                     XMMRegister vec1, XMMRegister vec2, bool is_char);\n+                     XMMRegister vec1, XMMRegister vec2, bool is_char, KRegister mask = knoreg);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-LP64_ONLY(extern void reg_mask_init();)\n+extern void reg_mask_init();\n@@ -64,1 +64,1 @@\n-  LP64_ONLY(reg_mask_init();)\n+  reg_mask_init();\n","filename":"src\/hotspot\/cpu\/x86\/c2_init_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -152,1 +152,0 @@\n-  \/\/ Restore registers\n@@ -397,0 +396,1 @@\n+  GrowableArray<KRegister>       _opmask_registers;\n@@ -453,0 +453,5 @@\n+  void opmask_register_save(KRegister reg) {\n+    _spill_offset -= 8;\n+    __ kmovql(Address(rsp, _spill_offset), reg);\n+  }\n+\n@@ -458,0 +463,5 @@\n+  void opmask_register_restore(KRegister reg) {\n+    __ kmovql(reg, Address(rsp, _spill_offset));\n+    _spill_offset += 8;\n+  }\n+\n@@ -480,0 +490,1 @@\n+    int opmask_spill_size = 0;\n@@ -493,0 +504,5 @@\n+      } else if (vm_reg->is_KRegister()) {\n+        \/\/ All opmask registers are caller saved, thus spill the ones\n+        \/\/ which are live.\n+        _opmask_registers.append(vm_reg->as_KRegister());\n+        opmask_spill_size += 8;\n@@ -523,1 +539,1 @@\n-    _spill_offset = _spill_size = align_up(xmm_spill_size + gp_spill_size + arg_spill_size, 16);\n+    _spill_offset = _spill_size = align_up(xmm_spill_size + gp_spill_size + opmask_spill_size + arg_spill_size, 16);\n@@ -530,0 +546,1 @@\n+      _opmask_registers(),\n@@ -579,0 +596,5 @@\n+\n+    \/\/ Save opmask registers\n+    for (int i = 0; i < _opmask_registers.length(); i++) {\n+      opmask_register_save(_opmask_registers.at(i));\n+    }\n@@ -582,0 +604,5 @@\n+    \/\/ Restore opmask registers\n+    for (int i = _opmask_registers.length() - 1; i >= 0; i--) {\n+      opmask_register_restore(_opmask_registers.at(i));\n+    }\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zBarrierSetAssembler_x86.cpp","additions":30,"deletions":3,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -2528,0 +2528,8 @@\n+void MacroAssembler::kmovql(KRegister dst, AddressLiteral src, Register scratch_reg) {\n+  if (reachable(src)) {\n+    kmovql(dst, as_Address(src));\n+  } else {\n+    lea(scratch_reg, src);\n+    kmovql(dst, Address(scratch_reg, 0));\n+  }\n+}\n@@ -4943,1 +4951,1 @@\n-void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp) {\n+void MacroAssembler::xmm_clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, KRegister mask) {\n@@ -4976,1 +4984,1 @@\n-    fill64_masked_avx(3, base, 0, xtmp, k2, cnt, rtmp, true);\n+    fill64_masked_avx(3, base, 0, xtmp, mask, cnt, rtmp, true);\n@@ -4995,1 +5003,1 @@\n-    fill32_masked_avx(3, base, 0, xtmp, k2, cnt, rtmp);\n+    fill32_masked_avx(3, base, 0, xtmp, mask, cnt, rtmp);\n@@ -5009,1 +5017,1 @@\n-void MacroAssembler::clear_mem(Register base, int cnt, Register rtmp, XMMRegister xtmp) {\n+void MacroAssembler::clear_mem(Register base, int cnt, Register rtmp, XMMRegister xtmp, KRegister mask) {\n@@ -5034,2 +5042,2 @@\n-        kmovwl(k2, rtmp);\n-        evmovdqu(T_LONG, k2, Address(base, disp), xtmp, Assembler::AVX_256bit);\n+        kmovwl(mask, rtmp);\n+        evmovdqu(T_LONG, mask, Address(base, disp), xtmp, Assembler::AVX_256bit);\n@@ -5043,2 +5051,2 @@\n-          kmovwl(k2, rtmp);\n-          evmovdqu(T_LONG, k2, Address(base, disp), xtmp, Assembler::AVX_512bit);\n+          kmovwl(mask, rtmp);\n+          evmovdqu(T_LONG, mask, Address(base, disp), xtmp, Assembler::AVX_512bit);\n@@ -5053,2 +5061,2 @@\n-          kmovwl(k2, rtmp);\n-          evmovdqu(T_LONG, k2, Address(base, disp), xtmp, Assembler::AVX_512bit);\n+          kmovwl(mask, rtmp);\n+          evmovdqu(T_LONG, mask, Address(base, disp), xtmp, Assembler::AVX_512bit);\n@@ -5063,2 +5071,2 @@\n-          kmovwl(k2, rtmp);\n-          evmovdqu(T_LONG, k2, Address(base, disp), xtmp, Assembler::AVX_512bit);\n+          kmovwl(mask, rtmp);\n+          evmovdqu(T_LONG, mask, Address(base, disp), xtmp, Assembler::AVX_512bit);\n@@ -5068,2 +5076,2 @@\n-          kmovwl(k2, rtmp);\n-          evmovdqu(T_LONG, k2, Address(base, disp + 32), xtmp, Assembler::AVX_256bit);\n+          kmovwl(mask, rtmp);\n+          evmovdqu(T_LONG, mask, Address(base, disp + 32), xtmp, Assembler::AVX_256bit);\n@@ -5079,1 +5087,2 @@\n-void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp, bool is_large) {\n+void MacroAssembler::clear_mem(Register base, Register cnt, Register tmp, XMMRegister xtmp,\n+                               bool is_large, KRegister mask) {\n@@ -5119,1 +5128,1 @@\n-    xmm_clear_mem(base, cnt, tmp, xtmp);\n+    xmm_clear_mem(base, cnt, tmp, xtmp, mask);\n@@ -7751,1 +7760,1 @@\n-  Register tmp5, Register result) {\n+  Register tmp5, Register result, KRegister mask1, KRegister mask2) {\n@@ -7803,1 +7812,1 @@\n-    kmovdl(k3, result);\n+    kmovdl(mask2, result);\n@@ -7805,3 +7814,3 @@\n-    evmovdquw(tmp1Reg, k3, Address(src, 0), \/*merge*\/ false, Assembler::AVX_512bit);\n-    evpcmpuw(k2, k3, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n-    ktestd(k2, k3);\n+    evmovdquw(tmp1Reg, mask2, Address(src, 0), \/*merge*\/ false, Assembler::AVX_512bit);\n+    evpcmpuw(mask1, mask2, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n+    ktestd(mask1, mask2);\n@@ -7810,1 +7819,1 @@\n-    evpmovwb(Address(dst, 0), k3, tmp1Reg, Assembler::AVX_512bit);\n+    evpmovwb(Address(dst, 0), mask2, tmp1Reg, Assembler::AVX_512bit);\n@@ -7831,2 +7840,2 @@\n-    evpcmpuw(k2, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n-    kortestdl(k2, k2);\n+    evpcmpuw(mask1, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n+    kortestdl(mask1, mask1);\n@@ -7853,1 +7862,1 @@\n-    kmovdl(k3, result);\n+    kmovdl(mask2, result);\n@@ -7855,3 +7864,3 @@\n-    evmovdquw(tmp1Reg, k3, Address(src, 0), \/*merge*\/ false, Assembler::AVX_512bit);\n-    evpcmpuw(k2, k3, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n-    ktestd(k2, k3);\n+    evmovdquw(tmp1Reg, mask2, Address(src, 0), \/*merge*\/ false, Assembler::AVX_512bit);\n+    evpcmpuw(mask1, mask2, tmp1Reg, tmp2Reg, Assembler::le, Assembler::AVX_512bit);\n+    ktestd(mask1, mask2);\n@@ -7860,1 +7869,1 @@\n-    evpmovwb(Address(dst, 0), k3, tmp1Reg, Assembler::AVX_512bit);\n+    evpmovwb(Address(dst, 0), mask2, tmp1Reg, Assembler::AVX_512bit);\n@@ -7960,1 +7969,1 @@\n-  XMMRegister tmp1, Register tmp2) {\n+  XMMRegister tmp1, Register tmp2, KRegister mask) {\n@@ -8013,3 +8022,3 @@\n-    kmovdl(k2, tmp3_aliased);\n-    evpmovzxbw(tmp1, k2, Address(src, 0), Assembler::AVX_512bit);\n-    evmovdquw(Address(dst, 0), k2, tmp1, \/*merge*\/ true, Assembler::AVX_512bit);\n+    kmovdl(mask, tmp3_aliased);\n+    evpmovzxbw(tmp1, mask, Address(src, 0), Assembler::AVX_512bit);\n+    evmovdquw(Address(dst, 0), mask, tmp1, \/*merge*\/ true, Assembler::AVX_512bit);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":42,"deletions":33,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -1094,0 +1094,7 @@\n+  void kmovql(KRegister dst, KRegister src) { Assembler::kmovql(dst, src); }\n+  void kmovql(KRegister dst, Register src) { Assembler::kmovql(dst, src); }\n+  void kmovql(Register dst, KRegister src) { Assembler::kmovql(dst, src); }\n+  void kmovql(KRegister dst, Address src) { Assembler::kmovql(dst, src); }\n+  void kmovql(Address  dst, KRegister src) { Assembler::kmovql(dst, src); }\n+  void kmovql(KRegister dst, AddressLiteral src, Register scratch_reg = rscratch1);\n+\n@@ -1686,1 +1693,1 @@\n-  void clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, bool is_large);\n+  void clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, bool is_large, KRegister mask=knoreg);\n@@ -1689,1 +1696,1 @@\n-  void clear_mem(Register base, int cnt, Register rtmp, XMMRegister xtmp);\n+  void clear_mem(Register base, int cnt, Register rtmp, XMMRegister xtmp, KRegister mask=knoreg);\n@@ -1692,1 +1699,1 @@\n-  void xmm_clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp);\n+  void xmm_clear_mem(Register base, Register cnt, Register rtmp, XMMRegister xtmp, KRegister mask=knoreg);\n@@ -1805,1 +1812,2 @@\n-                           XMMRegister tmp4, Register tmp5, Register result);\n+                           XMMRegister tmp4, Register tmp5, Register result,\n+                           KRegister mask1 = knoreg, KRegister mask2 = knoreg);\n@@ -1809,1 +1817,1 @@\n-                          XMMRegister tmp1, Register tmp2);\n+                          XMMRegister tmp1, Register tmp2, KRegister mask = knoreg);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":13,"deletions":5,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -221,1 +221,1 @@\n-    max_slots_per_register = 1\n+    max_slots_per_register = 2\n@@ -260,1 +260,1 @@\n-      2 * FloatRegisterImpl::number_of_registers +\n+      2 * FloatRegisterImpl::number_of_registers + NOT_LP64(8) LP64_ONLY(0) +\n@@ -262,1 +262,1 @@\n-      KRegisterImpl::number_of_registers + \/\/ mask registers\n+      KRegisterImpl::number_of_registers * KRegisterImpl::max_slots_per_register + \/\/ mask registers\n","filename":"src\/hotspot\/cpu\/x86\/register_x86.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -134,0 +134,1 @@\n+  int opmask_state_bytes = KRegisterImpl::number_of_registers * 8;\n@@ -142,0 +143,1 @@\n+      additional_frame_words += opmask_state_bytes \/ wordSize;\n@@ -232,0 +234,5 @@\n+      __ subptr(rsp, opmask_state_bytes);\n+      \/\/ Save opmask registers\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmovql(Address(rsp, n*8), as_KRegister(n));\n+      }\n@@ -254,0 +261,1 @@\n+\n@@ -278,0 +286,2 @@\n+  int opmask_state_bytes = 0;\n+  int additional_frame_bytes = 0;\n@@ -282,1 +292,0 @@\n-  int additional_frame_bytes = 0;\n@@ -292,0 +301,2 @@\n+      opmask_state_bytes = KRegisterImpl::number_of_registers * 8;\n+      additional_frame_bytes += opmask_state_bytes;\n@@ -325,1 +336,0 @@\n-\n@@ -328,0 +338,1 @@\n+      off = opmask_state_bytes;\n@@ -329,1 +340,4 @@\n-        __ vinsertf64x4_high(as_XMMRegister(n), Address(rsp, n*32));\n+        __ vinsertf64x4_high(as_XMMRegister(n), Address(rsp, n*32+off));\n+      }\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmovql(as_KRegister(n), Address(rsp, n*8));\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":17,"deletions":3,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -93,0 +93,1 @@\n+#define XSAVE_AREA_OPMASK_BEGIN 1088\n@@ -98,0 +99,1 @@\n+#define DEF_OPMASK_OFFS(regnum)    opmask ## regnum ## _off = opmask_off + (regnum)*8\/BytesPerInt,     opmask ## regnum ## H_off\n@@ -109,0 +111,4 @@\n+    opmask_off         = xmm_off + (XSAVE_AREA_OPMASK_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_OPMASK_OFFS(0),\n+    DEF_OPMASK_OFFS(1),\n+    \/\/ 2..7 are implied in range usage\n@@ -216,0 +222,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmovql(Address(rsp, base_addr+(off++*8)), as_KRegister(n));\n+      }\n+#endif\n@@ -225,0 +238,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for(int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmovql(Address(rsp, base_addr+(off++*8)), as_KRegister(n));\n+      }\n+#endif\n@@ -384,0 +404,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmovql(as_KRegister(n), Address(rsp, base_addr+(off++*8)));\n+      }\n+#endif\n@@ -393,0 +420,7 @@\n+#if COMPILER2_OR_JVMCI\n+      base_addr = XSAVE_AREA_OPMASK_BEGIN;\n+      off = 0;\n+      for (int n = 0; n < KRegisterImpl::number_of_registers; n++) {\n+        __ kmovql(as_KRegister(n), Address(rsp, base_addr+(off++*8)));\n+      }\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":34,"deletions":0,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2006, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2006, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -75,0 +75,1 @@\n+\/\/TODO: Case for KRegisters\n","filename":"src\/hotspot\/cpu\/x86\/vmreg_x86.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2006, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2006, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -85,1 +85,1 @@\n-  return ::as_KRegister((value() - ConcreteRegisterImpl::max_xmm));\n+  return ::as_KRegister((value() - ConcreteRegisterImpl::max_xmm) >> 1);\n","filename":"src\/hotspot\/cpu\/x86\/vmreg_x86.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2006, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2006, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,1 +46,1 @@\n-  return VMRegImpl::as_VMReg(encoding() + ConcreteRegisterImpl::max_xmm);\n+  return VMRegImpl::as_VMReg((encoding() << 1) + ConcreteRegisterImpl::max_xmm);\n","filename":"src\/hotspot\/cpu\/x86\/vmreg_x86.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -631,0 +631,23 @@\n+\/\/ AVX3 Mask Registers.\n+reg_def K1   (SOC, SOC, Op_RegI,  1, k1->as_VMReg());\n+reg_def K1_H (SOC, SOC, Op_RegI,  1, k1->as_VMReg()->next());\n+\n+reg_def K2   (SOC, SOC, Op_RegI,  2, k2->as_VMReg());\n+reg_def K2_H (SOC, SOC, Op_RegI,  2, k2->as_VMReg()->next());\n+\n+reg_def K3   (SOC, SOC, Op_RegI,  3, k3->as_VMReg());\n+reg_def K3_H (SOC, SOC, Op_RegI,  3, k3->as_VMReg()->next());\n+\n+reg_def K4   (SOC, SOC, Op_RegI,  4, k4->as_VMReg());\n+reg_def K4_H (SOC, SOC, Op_RegI,  4, k4->as_VMReg()->next());\n+\n+reg_def K5   (SOC, SOC, Op_RegI,  5, k5->as_VMReg());\n+reg_def K5_H (SOC, SOC, Op_RegI,  5, k5->as_VMReg()->next());\n+\n+reg_def K6   (SOC, SOC, Op_RegI,  6, k6->as_VMReg());\n+reg_def K6_H (SOC, SOC, Op_RegI,  6, k6->as_VMReg()->next());\n+\n+reg_def K7   (SOC, SOC, Op_RegI,  7, k7->as_VMReg());\n+reg_def K7_H (SOC, SOC, Op_RegI,  7, k7->as_VMReg()->next());\n+\n+\n@@ -667,0 +690,24 @@\n+alloc_class chunk2(K7, K7_H,\n+                   K6, K6_H,\n+                   K5, K5_H,\n+                   K4, K4_H,\n+                   K3, K3_H,\n+                   K2, K2_H,\n+                   K1, K1_H);\n+\n+reg_class  opmask_reg(K1, K1_H,\n+                      K2, K2_H,\n+                      K3, K3_H,\n+                      K4, K4_H,\n+                      K5, K5_H,\n+                      K6, K6_H,\n+                      K7, K7_H);\n+\n+reg_class opmask_reg_K1(K1, K1_H);\n+reg_class opmask_reg_K2(K2, K2_H);\n+reg_class opmask_reg_K3(K3, K3_H);\n+reg_class opmask_reg_K4(K4, K4_H);\n+reg_class opmask_reg_K5(K5, K5_H);\n+reg_class opmask_reg_K6(K6, K6_H);\n+reg_class opmask_reg_K7(K7, K7_H);\n+\n@@ -668,1 +715,2 @@\n-alloc_class chunk2(RFLAGS);\n+alloc_class chunk3(RFLAGS);\n+\n@@ -1371,0 +1419,1 @@\n+  const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);\n@@ -1527,0 +1576,1 @@\n+\n@@ -1530,1 +1580,1 @@\n-      if (UseAVX < 3 || !VM_Version::supports_bmi2()) {\n+      if (!is_LP64  || UseAVX < 3 || !VM_Version::supports_bmi2()) {\n@@ -1561,0 +1611,1 @@\n+  const bool is_LP64 = LP64_ONLY(true) NOT_LP64(false);\n@@ -1611,1 +1662,1 @@\n-      if (!VM_Version::supports_avx512bw()) {\n+      if (!is_LP64 || !VM_Version::supports_avx512bw()) {\n@@ -1834,0 +1885,8 @@\n+const RegMask* Matcher::predicate_reg_mask(void) {\n+  return &_OPMASK_REG_mask;\n+}\n+\n+const TypeVect* Matcher::predicate_reg_type(const Type* elemTy, int length) {\n+  return new TypeVectMask(TypeInt::BOOL, length);\n+}\n+\n@@ -2555,3 +2614,7 @@\n-\n-instruct setMask(rRegI dst, rRegI src) %{\n-  predicate(Matcher::has_predicated_vectors());\n+\/\/ Existing partial implementation for post-loop multi-versioning computes\n+\/\/ the mask corresponding to tail loop in K1 opmask register. This may then be\n+\/\/ used for predicating instructions in loop body during last post-loop iteration.\n+\/\/ TODO: Remove hard-coded K1 usage while fixing existing post-loop\n+\/\/ multiversioning support.\n+instruct setMask(rRegI dst, rRegI src, kReg_K1 mask) %{\n+  predicate(PostLoopMultiversioning && Matcher::has_predicated_vectors());\n@@ -2562,1 +2625,1 @@\n-    __ setvectmask($dst$$Register, $src$$Register);\n+    __ setvectmask($dst$$Register, $src$$Register, $mask$$KRegister);\n@@ -3602,1 +3665,1 @@\n-instruct evgather(vec dst, memory mem, vec idx, rRegP tmp) %{\n+instruct evgather(vec dst, memory mem, vec idx, rRegP tmp, kReg ktmp) %{\n@@ -3605,1 +3668,1 @@\n-  effect(TEMP dst, TEMP tmp);\n+  effect(TEMP dst, TEMP tmp, TEMP ktmp);\n@@ -3615,2 +3678,1 @@\n-    KRegister ktmp = k2;\n-    __ kmovwl(k2, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n+    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n@@ -3618,1 +3680,1 @@\n-    __ evgather(elem_bt, $dst$$XMMRegister, ktmp, $tmp$$Register, $idx$$XMMRegister, vlen_enc);\n+    __ evgather(elem_bt, $dst$$XMMRegister, $ktmp$$KRegister, $tmp$$Register, $idx$$XMMRegister, vlen_enc);\n@@ -3627,1 +3689,1 @@\n-instruct scatter(memory mem, vec src, vec idx, rRegP tmp) %{\n+instruct scatter(memory mem, vec src, vec idx, rRegP tmp, kReg ktmp) %{\n@@ -3629,1 +3691,1 @@\n-  effect(TEMP tmp);\n+  effect(TEMP tmp, TEMP ktmp);\n@@ -3640,2 +3702,1 @@\n-    KRegister ktmp = k2;\n-    __ kmovwl(k2, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n+    __ kmovwl($ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), $tmp$$Register);\n@@ -3643,1 +3704,1 @@\n-    __ evscatter(elem_bt, $tmp$$Register, $idx$$XMMRegister, ktmp, $src$$XMMRegister, vlen_enc);\n+    __ evscatter(elem_bt, $tmp$$Register, $idx$$XMMRegister, $ktmp$$KRegister, $src$$XMMRegister, vlen_enc);\n@@ -5744,1 +5805,1 @@\n-instruct evminmaxFP_reg_eavx(vec dst, vec a, vec b, vec atmp, vec btmp) %{\n+instruct evminmaxFP_reg_eavx(vec dst, vec a, vec b, vec atmp, vec btmp, kReg ktmp) %{\n@@ -5749,1 +5810,1 @@\n-  effect(TEMP dst, USE a, USE b, TEMP atmp, TEMP btmp);\n+  effect(TEMP dst, USE a, USE b, TEMP atmp, TEMP btmp, TEMP ktmp);\n@@ -5758,1 +5819,0 @@\n-    KRegister ktmp = k1;\n@@ -5761,1 +5821,1 @@\n-                   ktmp, $atmp$$XMMRegister , $btmp$$XMMRegister, vlen_enc);\n+                   $ktmp$$KRegister, $atmp$$XMMRegister , $btmp$$XMMRegister, vlen_enc);\n@@ -6826,1 +6886,1 @@\n-instruct evcmpFD(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch) %{\n+instruct evcmpFD(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n@@ -6830,1 +6890,1 @@\n-  effect(TEMP scratch);\n+  effect(TEMP scratch, TEMP ktmp);\n@@ -6835,1 +6895,0 @@\n-    KRegister ktmp = k2; \/\/ Use a hardcoded temp due to no k register allocation.\n@@ -6838,2 +6897,2 @@\n-      __ evcmpps(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-      __ evmovdqul($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n+      __ evcmpps($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+      __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n@@ -6841,2 +6900,2 @@\n-      __ evcmppd(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-      __ evmovdquq($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n+      __ evcmppd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+      __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), false, vlen_enc, $scratch$$Register);\n@@ -6864,1 +6923,1 @@\n-instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch) %{\n+instruct evcmp(vec dst, vec src1, vec src2, immI8 cond, rRegP scratch, kReg ktmp) %{\n@@ -6868,1 +6927,1 @@\n-  effect(TEMP scratch);\n+  effect(TEMP scratch, TEMP ktmp);\n@@ -6875,1 +6934,0 @@\n-    KRegister ktmp = k2; \/\/ Use a hardcoded temp due to no k register allocation.\n@@ -6882,2 +6940,2 @@\n-        __ evpcmpb(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdqub($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpb($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdqub($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -6887,2 +6945,2 @@\n-        __ evpcmpw(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdquw($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpw($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdquw($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -6892,2 +6950,2 @@\n-        __ evpcmpd(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdqul($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpd($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdqul($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -6897,2 +6955,2 @@\n-        __ evpcmpq(ktmp, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n-        __ evmovdquq($dst$$XMMRegister, ktmp, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n+        __ evpcmpq($ktmp$$KRegister, mask, $src1$$XMMRegister, $src2$$XMMRegister, cmp, vlen_enc);\n+        __ evmovdquq($dst$$XMMRegister, $ktmp$$KRegister, ExternalAddress(vector_all_bits_set()), merge, vlen_enc, $scratch$$Register);\n@@ -7076,1 +7134,1 @@\n-instruct evblendvp64(vec dst, vec src1, vec src2, vec mask, rRegP scratch) %{\n+instruct evblendvp64(vec dst, vec src1, vec src2, vec mask, rRegP scratch, kReg ktmp) %{\n@@ -7080,1 +7138,1 @@\n-  effect(TEMP scratch);\n+  effect(TEMP scratch, TEMP ktmp);\n@@ -7084,3 +7142,2 @@\n-     KRegister ktmp = k2;\n-    __ evpcmp(elem_bt, ktmp, k0, $mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), Assembler::eq, vlen_enc, $scratch$$Register);\n-    __ evpblend(elem_bt, $dst$$XMMRegister, ktmp, $src1$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n+    __ evpcmp(elem_bt, $ktmp$$KRegister, k0, $mask$$XMMRegister, ExternalAddress(vector_all_bits_set()), Assembler::eq, vlen_enc, $scratch$$Register);\n+    __ evpblend(elem_bt, $dst$$XMMRegister, $ktmp$$KRegister, $src1$$XMMRegister, $src2$$XMMRegister, true, vlen_enc);\n@@ -7227,1 +7284,1 @@\n-instruct vptest_alltrue(rRegI dst, legVec src1, legVec src2, rFlagsReg cr) %{\n+instruct vptest_alltrue(rRegI dst, legVec src1, legVec src2, kReg ktmp, rFlagsReg cr) %{\n@@ -7231,1 +7288,1 @@\n-  effect(KILL cr);\n+  effect(KILL cr, TEMP ktmp);\n@@ -7235,1 +7292,1 @@\n-    __ vectortest(BoolTest::overflow, vlen, $src1$$XMMRegister, $src2$$XMMRegister); \n+    __ vectortest(BoolTest::overflow, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n@@ -7258,1 +7315,1 @@\n-instruct vptest_anytrue(rRegI dst, legVec src1, legVec src2, rFlagsReg cr) %{\n+instruct vptest_anytrue(rRegI dst, legVec src1, legVec src2, kReg ktmp, rFlagsReg cr) %{\n@@ -7262,1 +7319,1 @@\n-  effect(KILL cr);\n+  effect(KILL cr, TEMP ktmp);\n@@ -7266,1 +7323,1 @@\n-    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister);\n+    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n@@ -7287,1 +7344,1 @@\n-instruct cmpvptest_anytrue(rFlagsReg cr, legVec src1, legVec src2, immI_0 zero) %{\n+instruct cmpvptest_anytrue(rFlagsReg cr, legVec src1, legVec src2, immI_0 zero, kReg ktmp) %{\n@@ -7291,0 +7348,1 @@\n+  effect(TEMP ktmp);\n@@ -7294,1 +7352,1 @@\n-    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister);\n+    __ vectortest(BoolTest::ne, vlen, $src1$$XMMRegister, $src2$$XMMRegister, xnoreg, xnoreg, $ktmp$$KRegister);\n@@ -7947,2 +8005,1 @@\n-\n-instruct vmasked_load64(vec dst, memory mem, rRegL mask) %{\n+instruct vmasked_load64(vec dst, memory mem, kReg mask) %{\n@@ -7954,2 +8011,1 @@\n-    __ kmovql(k2, $mask$$Register);\n-    __ evmovdqu(elmType, k2, $dst$$XMMRegister, $mem$$Address, vector_len);\n+    __ evmovdqu(elmType, $mask$$KRegister, $dst$$XMMRegister, $mem$$Address, vector_len);\n@@ -7960,1 +8016,1 @@\n-instruct vmask_gen(rRegL dst, rRegL len, rRegL tempLen) %{\n+instruct vmask_gen(kReg dst, rRegL len, rRegL temp) %{\n@@ -7962,2 +8018,2 @@\n-  effect(TEMP_DEF dst, TEMP tempLen);\n-  format %{ \"vector_mask_gen $len \\t! vector mask generator\" %}\n+  effect(TEMP temp);\n+  format %{ \"vector_mask_gen32 $dst, $len \\t! vector mask generator\" %}\n@@ -7965,1 +8021,1 @@\n-    __ genmask($dst$$Register, $len$$Register, $tempLen$$Register);\n+    __ genmask($dst$$KRegister, $len$$Register, $temp$$Register);\n@@ -7970,1 +8026,1 @@\n-instruct vmask_gen_imm(rRegL dst, immL len) %{\n+instruct vmask_gen_imm(kReg dst, immL len, rRegL temp) %{\n@@ -7973,0 +8029,1 @@\n+  effect(TEMP temp);\n@@ -7974,1 +8031,2 @@\n-    __ mov64($dst$$Register, (0xFFFFFFFFFFFFFFFFUL >> (64 -$len$$constant)));\n+    __ mov64($temp$$Register, (0xFFFFFFFFFFFFFFFFUL >> (64 -$len$$constant)));\n+    __ kmovql($dst$$KRegister, $temp$$Register);\n@@ -7979,1 +8037,1 @@\n-instruct vmasked_store64(memory mem, vec src, rRegL mask) %{\n+instruct vmasked_store64(memory mem, vec src, kReg mask) %{\n@@ -7986,2 +8044,1 @@\n-    __ kmovql(k2, $mask$$Register);\n-    __ evmovdqu(elmType, k2, $mem$$Address, $src$$XMMRegister, vector_len);\n+    __ evmovdqu(elmType, $mask$$KRegister, $mem$$Address, $src$$XMMRegister, vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":122,"deletions":65,"binary":false,"changes":187,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -263,0 +263,12 @@\n+void reg_mask_init() {\n+  if (Matcher::has_predicated_vectors()) {\n+    \/\/ Post-loop multi-versioning expects mask to be present in K1 register, till the time\n+    \/\/ its fixed, RA should not be allocting K1 register, this shall prevent any accidental\n+    \/\/ curruption of value held in K1 register.\n+    if (PostLoopMultiversioning) {\n+      const_cast<RegMask*>(&_OPMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()));\n+      const_cast<RegMask*>(&_OPMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()->next()));\n+    }\n+  }\n+}\n+\n@@ -734,1 +746,1 @@\n-enum RC { rc_bad, rc_int, rc_float, rc_xmm, rc_stack };\n+enum RC { rc_bad, rc_int, rc_kreg, rc_float, rc_xmm, rc_stack };\n@@ -1053,1 +1065,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() != NULL && bottom_type()->isa_vectmask() == NULL) {\n@@ -1106,1 +1118,1 @@\n-  if( dst_first_rc == rc_int && src_first_rc == rc_stack )\n+  if( src_first_rc == rc_stack && dst_first_rc == rc_int )\n@@ -1195,1 +1207,1 @@\n-    return impl_x_helper(cbuf,do_size,false,ra_->reg2offset(dst_first),src_first, src_second, size, st);\n+    return impl_x_helper(cbuf,do_size,false,ra_->reg2offset(dst_first), src_first, src_second, size, st);\n@@ -1199,1 +1211,1 @@\n-  if( dst_first_rc == rc_xmm && src_first_rc == rc_stack ) {\n+  if( src_first_rc == rc_stack && dst_first_rc == rc_xmm ) {\n@@ -1204,1 +1216,1 @@\n-  if( dst_first_rc == rc_xmm && src_first_rc == rc_float ) {\n+  if( src_first_rc == rc_float && dst_first_rc == rc_xmm ) {\n@@ -1260,0 +1272,36 @@\n+  \/\/ AVX-512 opmask specific spilling.\n+  if (src_first_rc == rc_stack && dst_first_rc == rc_kreg) {\n+    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n+    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n+    MacroAssembler _masm(cbuf);\n+    int offset = ra_->reg2offset(src_first);\n+    __ kmovql(as_KRegister(Matcher::_regEncode[dst_first]), Address(rsp, offset));\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_kreg && dst_first_rc == rc_stack) {\n+    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n+    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n+    MacroAssembler _masm(cbuf);\n+    int offset = ra_->reg2offset(dst_first);\n+    __ kmovql(Address(rsp, offset), as_KRegister(Matcher::_regEncode[src_first]));\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_kreg && dst_first_rc == rc_int) {\n+    Unimplemented();\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_int && dst_first_rc == rc_kreg) {\n+    Unimplemented();\n+    return 0;\n+  }\n+\n+  if (src_first_rc == rc_kreg && dst_first_rc == rc_kreg) {\n+    assert((src_first & 1) == 0 && src_first + 1 == src_second, \"invalid register pair\");\n+    assert((dst_first & 1) == 0 && dst_first + 1 == dst_second, \"invalid register pair\");\n+    MacroAssembler _masm(cbuf);\n+    __ kmovql(as_KRegister(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n+    return 0;\n+  }\n@@ -3577,0 +3625,66 @@\n+operand kReg()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K1()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K1));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K2()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K2));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K3()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K3));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K4()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K4));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K5()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K5));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K6()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K6));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K7()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K7));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n@@ -4958,0 +5072,9 @@\n+\/\/ ============================= NOTE =====================================\n+\/\/ Temporary kReg operand in following instruction patterns gets used only\n+\/\/ for targets supporting AVX-512 feature, it's existing here to save\n+\/\/ redundant pattern replication for non-AVX512 targets.\n+\/\/ Patterns: rep_stos, rep_stos_large, string_compareL, string_compareU,\n+\/\/ string_compareLU, string_compareUL, string_equals, array_equalsB,\n+\/\/ array_equalsC, has_negatives, string_compress, string_inflate\n+\/\/ =======================================================================\n+\n@@ -11413,1 +11536,1 @@\n-instruct rep_stos(eCXRegI cnt, eDIRegP base, regD tmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n+instruct rep_stos(eCXRegI cnt, eDIRegP base, regD tmp, kReg ktmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n@@ -11416,1 +11539,1 @@\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n@@ -11467,1 +11590,1 @@\n-                 $tmp$$XMMRegister, false);\n+                 $tmp$$XMMRegister, false, $ktmp$$KRegister);\n@@ -11472,1 +11595,1 @@\n-instruct rep_stos_large(eCXRegI cnt, eDIRegP base, regD tmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n+instruct rep_stos_large(eCXRegI cnt, eDIRegP base, regD tmp, kReg ktmp, eAXRegI zero, Universe dummy, eFlagsReg cr) %{\n@@ -11475,1 +11598,1 @@\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n@@ -11516,1 +11639,1 @@\n-                 $tmp$$XMMRegister, true);\n+                 $tmp$$XMMRegister, true, $ktmp$$KRegister);\n@@ -11521,1 +11644,1 @@\n-instruct rep_stos_im(immI cnt, eRegP base, regD tmp, rRegI zero, Universe dummy, eFlagsReg cr)\n+instruct rep_stos_im(immI cnt, kReg ktmp, eRegP base, regD tmp, rRegI zero, Universe dummy, eFlagsReg cr)\n@@ -11525,1 +11648,1 @@\n-  effect(TEMP tmp, TEMP zero, KILL cr);\n+  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n@@ -11528,1 +11651,1 @@\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister);\n+   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n@@ -11534,1 +11657,1 @@\n-                         eAXRegI result, regD tmp1, eFlagsReg cr) %{\n+                         eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n@@ -11537,1 +11660,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -11543,1 +11666,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, $ktmp$$KRegister);\n@@ -11549,1 +11672,1 @@\n-                         eAXRegI result, regD tmp1, eFlagsReg cr) %{\n+                         eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n@@ -11552,1 +11675,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -11558,1 +11681,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, $ktmp$$KRegister);\n@@ -11564,1 +11687,1 @@\n-                          eAXRegI result, regD tmp1, eFlagsReg cr) %{\n+                          eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n@@ -11567,1 +11690,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -11573,1 +11696,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, $ktmp$$KRegister);\n@@ -11579,1 +11702,1 @@\n-                          eAXRegI result, regD tmp1, eFlagsReg cr) %{\n+                          eAXRegI result, regD tmp1, kReg ktmp, eFlagsReg cr) %{\n@@ -11582,1 +11705,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -11588,1 +11711,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, $ktmp$$KRegister);\n@@ -11595,1 +11718,1 @@\n-                       regD tmp1, regD tmp2, eBXRegI tmp3, eFlagsReg cr) %{\n+                       regD tmp1, regD tmp2, kReg ktmp, eBXRegI tmp3, eFlagsReg cr) %{\n@@ -11597,1 +11720,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n@@ -11603,1 +11726,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11770,1 +11893,1 @@\n-                       regD tmp1, regD tmp2, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n+                       regD tmp1, regD tmp2, kReg ktmp, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n@@ -11774,1 +11897,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n@@ -11781,1 +11904,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11787,1 +11910,1 @@\n-                       regD tmp1, regD tmp2, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n+                       regD tmp1, regD tmp2, kReg ktmp, eCXRegI tmp3, eBXRegI tmp4, eFlagsReg cr)\n@@ -11791,1 +11914,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n@@ -11798,1 +11921,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, $ktmp$$KRegister);\n@@ -11804,1 +11927,1 @@\n-                      regD tmp1, regD tmp2, eBXRegI tmp3, eFlagsReg cr)\n+                      regD tmp1, regD tmp2, kReg ktmp1, kReg ktmp2, eBXRegI tmp3, eFlagsReg cr)\n@@ -11807,1 +11930,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp1, TEMP ktmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n@@ -11813,1 +11936,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11819,2 +11942,2 @@\n-instruct string_compress(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2, regD tmp3, regD tmp4,\n-                         eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n+instruct string_compress(eSIRegP src, eDIRegP dst, eDXRegI len, regD tmp1, regD tmp2,\n+                         regD tmp3, regD tmp4, kReg ktmp1, kReg ktmp2, eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n@@ -11822,1 +11945,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ktmp1, TEMP ktmp2, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n@@ -11828,1 +11951,2 @@\n-                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register);\n+                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n+                           $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11835,1 +11959,1 @@\n-                        regD tmp1, eCXRegI tmp2, eFlagsReg cr) %{\n+                        regD tmp1, kReg ktmp, eCXRegI tmp2, eFlagsReg cr) %{\n@@ -11837,1 +11961,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n@@ -11842,1 +11966,1 @@\n-                          $tmp1$$XMMRegister, $tmp2$$Register);\n+                          $tmp1$$XMMRegister, $tmp2$$Register, $ktmp$$KRegister);\n@@ -12270,2 +12394,4 @@\n-instruct jmpLoopEnd_and_restoreMask(cmpOp cop, eFlagsReg cr, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEnd_and_restoreMask(cmpOp cop, kReg_K1 ktmp, eFlagsReg cr, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12273,1 +12399,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12282,1 +12408,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12288,2 +12414,4 @@\n-instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, eFlagsRegU cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, kReg_K1 ktmp, eFlagsRegU cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12291,1 +12419,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12300,1 +12428,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12305,2 +12433,4 @@\n-instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, eFlagsRegUCF cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, kReg_K1 ktmp, eFlagsRegUCF cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12308,1 +12438,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12317,1 +12447,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":189,"deletions":59,"binary":false,"changes":248,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -427,0 +427,10 @@\n+\n+  if (Matcher::has_predicated_vectors()) {\n+    \/\/ Post-loop multi-versioning expects mask to be present in K1 register, till the time\n+    \/\/ its fixed, RA should not be allocting K1 register, this shall prevent any accidental\n+    \/\/ curruption of value held in K1 register.\n+    if (PostLoopMultiversioning) {\n+      const_cast<RegMask*>(&_OPMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()));\n+      const_cast<RegMask*>(&_OPMASK_REG_mask)->Remove(OptoReg::as_OptoReg(k1->as_VMReg()->next()));\n+    }\n+  }\n@@ -1017,0 +1027,1 @@\n+  rc_kreg,\n@@ -1031,0 +1042,2 @@\n+  if (r->is_KRegister()) return rc_kreg;\n+\n@@ -1144,1 +1157,1 @@\n-  if (bottom_type()->isa_vect() != NULL) {\n+  if (bottom_type()->isa_vect() != NULL && bottom_type()->isa_vectmask() == NULL) {\n@@ -1274,0 +1287,18 @@\n+#endif\n+        }\n+      }\n+      return 0;\n+    } else if (dst_first_rc == rc_kreg) {\n+      \/\/ mem -> kreg\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        int offset = ra_->reg2offset(src_first);\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmovql(as_KRegister(Matcher::_regEncode[dst_first]), Address(rsp, offset));\n+#ifndef PRODUCT\n+        } else {\n+          st->print(\"kmovq   %s, [rsp + #%d]\\t# spill\",\n+                     Matcher::regName[dst_first],\n+                     offset);\n@@ -1379,0 +1410,17 @@\n+    } else if (dst_first_rc == rc_kreg) {\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmovql(as_KRegister(Matcher::_regEncode[dst_first]), as_Register(Matcher::_regEncode[src_first]));\n+  #ifndef PRODUCT\n+        } else {\n+           st->print(\"kmovq   %s, %s\\t# spill\",\n+                       Matcher::regName[dst_first],\n+                       Matcher::regName[src_first]);\n+  #endif\n+        }\n+      }\n+      Unimplemented();\n+      return 0;\n@@ -1479,0 +1527,59 @@\n+    } else if (dst_first_rc == rc_kreg) {\n+      assert(false, \"Illegal spilling\");\n+      return 0;\n+    }\n+  } else if (src_first_rc == rc_kreg) {\n+    if (dst_first_rc == rc_stack) {\n+      \/\/ mem -> kreg\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        int offset = ra_->reg2offset(dst_first);\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmovql(Address(rsp, offset), as_KRegister(Matcher::_regEncode[src_first]));\n+#ifndef PRODUCT\n+        } else {\n+          st->print(\"kmovq   [rsp + #%d] , %s\\t# spill\",\n+                     offset,\n+                     Matcher::regName[src_first]);\n+#endif\n+        }\n+      }\n+      return 0;\n+    } else if (dst_first_rc == rc_int) {\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmovql(as_Register(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n+#ifndef PRODUCT\n+        } else {\n+         st->print(\"kmovq   %s, %s\\t# spill\",\n+                     Matcher::regName[dst_first],\n+                     Matcher::regName[src_first]);\n+#endif\n+        }\n+      }\n+      Unimplemented();\n+      return 0;\n+    } else if (dst_first_rc == rc_kreg) {\n+      if ((src_first & 1) == 0 && src_first + 1 == src_second &&\n+          (dst_first & 1) == 0 && dst_first + 1 == dst_second) {\n+        \/\/ 64-bit\n+        if (cbuf) {\n+          MacroAssembler _masm(cbuf);\n+          __ kmovql(as_KRegister(Matcher::_regEncode[dst_first]), as_KRegister(Matcher::_regEncode[src_first]));\n+#ifndef PRODUCT\n+        } else {\n+         st->print(\"kmovq   %s, %s\\t# spill\",\n+                     Matcher::regName[dst_first],\n+                     Matcher::regName[src_first]);\n+#endif\n+        }\n+      }\n+      return 0;\n+    } else if (dst_first_rc == rc_float) {\n+      assert(false, \"Illegal spill\");\n+      return 0;\n@@ -3294,0 +3401,66 @@\n+operand kReg()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K1()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K1));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K2()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K2));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K3()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K3));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K4()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K4));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K5()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K5));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+operand kReg_K6()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K6));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ Special Registers\n+operand kReg_K7()\n+%{\n+  constraint(ALLOC_IN_RC(opmask_reg_K7));\n+  match(RegVMask);\n+  format %{%}\n+  interface(REG_INTER);\n+%}\n+\n@@ -4705,0 +4878,9 @@\n+\/\/ ============================= NOTE =====================================\n+\/\/ Temporary kReg operand in following instruction patterns gets used only\n+\/\/ for targets supporting AVX-512 feature, it's existing here to save\n+\/\/ redundant pattern replication for non-AVX512 targets.\n+\/\/ Patterns: rep_stos, rep_stos_large, string_compareL, string_compareU,\n+\/\/ string_compareLU, string_compareUL, string_equals, array_equalsB,\n+\/\/ array_equalsC, has_negatives, string_compress, string_inflate\n+\/\/ =======================================================================\n+\n@@ -10771,4 +10953,2 @@\n-\n-\/\/ =======================================================================\n-\/\/ fast clearing of an array\n-instruct rep_stos(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegI zero,\n+\/\/ Fast clearing of an array\n+instruct rep_stos(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegI zero,\n@@ -10779,1 +10959,1 @@\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n@@ -10828,1 +11008,1 @@\n-                 $tmp$$XMMRegister, false);\n+                 $tmp$$XMMRegister, false, $ktmp$$KRegister);\n@@ -10833,1 +11013,1 @@\n-instruct rep_stos_large(rcx_RegL cnt, rdi_RegP base, regD tmp, rax_RegI zero,\n+instruct rep_stos_large(rcx_RegL cnt, rdi_RegP base, regD tmp, kReg ktmp, rax_RegI zero,\n@@ -10838,1 +11018,1 @@\n-  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, KILL zero, KILL cr);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP tmp, TEMP ktmp, KILL zero, KILL cr);\n@@ -10878,1 +11058,1 @@\n-                 $tmp$$XMMRegister, true);\n+                 $tmp$$XMMRegister, true, $ktmp$$KRegister);\n@@ -10883,1 +11063,1 @@\n-instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rRegI zero, Universe dummy, rFlagsReg cr)\n+instruct rep_stos_im(immL cnt, rRegP base, regD tmp, rRegI zero, kReg ktmp, Universe dummy, rFlagsReg cr)\n@@ -10887,1 +11067,1 @@\n-  effect(TEMP tmp, TEMP zero, KILL cr);\n+  effect(TEMP tmp, TEMP zero, TEMP ktmp, KILL cr);\n@@ -10890,1 +11070,1 @@\n-   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister);\n+   __ clear_mem($base$$Register, $cnt$$constant, $zero$$Register, $tmp$$XMMRegister, $ktmp$$KRegister);\n@@ -10896,1 +11076,1 @@\n-                         rax_RegI result, legRegD tmp1, rFlagsReg cr)\n+                         rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n@@ -10900,1 +11080,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -10906,1 +11086,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LL, $ktmp$$KRegister);\n@@ -10912,1 +11092,1 @@\n-                         rax_RegI result, legRegD tmp1, rFlagsReg cr)\n+                         rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n@@ -10916,1 +11096,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -10922,1 +11102,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UU, $ktmp$$KRegister);\n@@ -10928,1 +11108,1 @@\n-                          rax_RegI result, legRegD tmp1, rFlagsReg cr)\n+                          rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n@@ -10932,1 +11112,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -10938,1 +11118,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::LU);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::LU, $ktmp$$KRegister);\n@@ -10944,1 +11124,1 @@\n-                          rax_RegI result, legRegD tmp1, rFlagsReg cr)\n+                          rax_RegI result, legRegD tmp1, kReg ktmp, rFlagsReg cr)\n@@ -10948,1 +11128,1 @@\n-  effect(TEMP tmp1, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+  effect(TEMP tmp1, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n@@ -10954,1 +11134,1 @@\n-                      $tmp1$$XMMRegister, StrIntrinsicNode::UL);\n+                      $tmp1$$XMMRegister, StrIntrinsicNode::UL, $ktmp$$KRegister);\n@@ -11127,1 +11307,1 @@\n-                       legRegD tmp1, legRegD tmp2, rbx_RegI tmp3, rFlagsReg cr)\n+                       legRegD tmp1, legRegD tmp2, kReg ktmp, rbx_RegI tmp3, rFlagsReg cr)\n@@ -11130,1 +11310,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL str1, USE_KILL str2, USE_KILL cnt, KILL tmp3, KILL cr);\n@@ -11136,1 +11316,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11143,1 +11323,1 @@\n-                       legRegD tmp1, legRegD tmp2, rcx_RegI tmp3, rbx_RegI tmp4, rFlagsReg cr)\n+                       legRegD tmp1, legRegD tmp2, kReg ktmp, rcx_RegI tmp3, rbx_RegI tmp4, rFlagsReg cr)\n@@ -11147,1 +11327,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n@@ -11153,1 +11333,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, false \/* char *\/, $ktmp$$KRegister);\n@@ -11159,1 +11339,1 @@\n-                       legRegD tmp1, legRegD tmp2, rcx_RegI tmp3, rbx_RegI tmp4, rFlagsReg cr)\n+                       legRegD tmp1, legRegD tmp2, kReg ktmp, rcx_RegI tmp3, rbx_RegI tmp4, rFlagsReg cr)\n@@ -11163,1 +11343,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL ary1, USE_KILL ary2, KILL tmp3, KILL tmp4, KILL cr);\n@@ -11169,1 +11349,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, true \/* char *\/, $ktmp$$KRegister);\n@@ -11175,1 +11355,1 @@\n-                       legRegD tmp1, legRegD tmp2, rbx_RegI tmp3, rFlagsReg cr)\n+                       legRegD tmp1, legRegD tmp2, kReg ktmp1, kReg ktmp2, rbx_RegI tmp3, rFlagsReg cr,)\n@@ -11178,1 +11358,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp1, TEMP ktmp2, USE_KILL ary1, USE_KILL len, KILL tmp3, KILL cr);\n@@ -11184,1 +11364,1 @@\n-                     $tmp1$$XMMRegister, $tmp2$$XMMRegister);\n+                     $tmp1$$XMMRegister, $tmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11190,2 +11370,2 @@\n-instruct string_compress(rsi_RegP src, rdi_RegP dst, rdx_RegI len, legRegD tmp1, legRegD tmp2, legRegD tmp3, legRegD tmp4,\n-                         rcx_RegI tmp5, rax_RegI result, rFlagsReg cr) %{\n+instruct string_compress(rsi_RegP src, rdi_RegP dst, rdx_RegI len, legRegD tmp1, legRegD tmp2, legRegD tmp3,\n+                         legRegD tmp4, kReg ktmp1, kReg ktmp2, rcx_RegI tmp5, rax_RegI result, rFlagsReg cr) %{\n@@ -11193,1 +11373,2 @@\n-  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ktmp1, TEMP ktmp2, USE_KILL src, USE_KILL dst,\n+         USE_KILL len, KILL tmp5, KILL cr);\n@@ -11199,1 +11380,2 @@\n-                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register);\n+                           $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register,\n+                           $ktmp1$$KRegister, $ktmp2$$KRegister);\n@@ -11206,1 +11388,1 @@\n-                        legRegD tmp1, rcx_RegI tmp2, rFlagsReg cr) %{\n+                        legRegD tmp1, kReg ktmp, rcx_RegI tmp2, rFlagsReg cr) %{\n@@ -11208,1 +11390,1 @@\n-  effect(TEMP tmp1, TEMP tmp2, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n+  effect(TEMP tmp1, TEMP tmp2, TEMP ktmp, USE_KILL src, USE_KILL dst, USE_KILL len, KILL cr);\n@@ -11213,1 +11395,1 @@\n-                          $tmp1$$XMMRegister, $tmp2$$Register);\n+                          $tmp1$$XMMRegister, $tmp2$$Register, $ktmp$$KRegister);\n@@ -12005,1 +12187,3 @@\n-instruct jmpLoopEnd_and_restoreMask(cmpOp cop, rFlagsReg cr, label labl)\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEnd_and_restoreMask(cmpOp cop, kReg_K1 ktmp, rFlagsReg cr, label labl)\n@@ -12007,1 +12191,1 @@\n-  predicate(n->has_vector_mask_set());\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12009,1 +12193,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12018,1 +12202,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12024,2 +12208,4 @@\n-instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, rFlagsRegU cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndU_and_restoreMask(cmpOpU cop, kReg_K1 ktmp, rFlagsRegU cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12027,1 +12213,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12036,1 +12222,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n@@ -12041,2 +12227,4 @@\n-instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, rFlagsRegUCF cmp, label labl) %{\n-  predicate(n->has_vector_mask_set());\n+\/\/ Bounded mask operand used in following patten is needed for\n+\/\/ post-loop multiversioning.\n+instruct jmpLoopEndUCF_and_restoreMask(cmpOpUCF cop, kReg_K1 ktmp, rFlagsRegUCF cmp, label labl) %{\n+  predicate(PostLoopMultiversioning && n->has_vector_mask_set());\n@@ -12044,1 +12232,1 @@\n-  effect(USE labl);\n+  effect(USE labl, TEMP ktmp);\n@@ -12053,1 +12241,1 @@\n-    __ restorevectmask();\n+    __ restorevectmask($ktmp$$KRegister);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":245,"deletions":57,"binary":false,"changes":302,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -949,1 +949,1 @@\n-    return \"Type::BOTTOM\";\n+    return \"TypeVect::VMASK\";\n","filename":"src\/hotspot\/share\/adlc\/archDesc.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -2268,0 +2268,1 @@\n+    if (strcmp(rep_var,\"$KRegister\") == 0)     return \"as_KRegister\";\n","filename":"src\/hotspot\/share\/adlc\/output_c.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -827,1 +827,2 @@\n-        assert(n_type->isa_vect() == NULL || lrg._is_vector || ireg == Op_RegD || ireg == Op_RegL,\n+        assert(n_type->isa_vect() == NULL || lrg._is_vector ||\n+               ireg == Op_RegD || ireg == Op_RegL  || ireg == Op_RegVMask,\n@@ -920,0 +921,4 @@\n+        case Op_RegVMask:\n+          lrg.set_num_regs(RegMask::SlotsPerRegVMask);\n+          lrg.set_reg_pressure(1);\n+          break;\n@@ -1039,2 +1044,2 @@\n-        assert(n->in(k)->bottom_type()->isa_vect() == NULL ||\n-               is_vect || kreg == Op_RegD || kreg == Op_RegL,\n+        assert(n->in(k)->bottom_type()->isa_vect() == NULL || is_vect ||\n+               kreg == Op_RegD || kreg == Op_RegL || kreg == Op_RegVMask,\n","filename":"src\/hotspot\/share\/opto\/chaitin.cpp","additions":9,"deletions":4,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2443,1 +2443,1 @@\n-  if (!is_vector_bitwise_op(n)) {\n+  if (n->bottom_type()->isa_vectmask() || !is_vector_bitwise_op(n)) {\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -412,1 +412,3 @@\n-        lrg.mask().overlap(*Matcher::idealreg2regmask[Op_RegI])) {\n+        (lrg.mask().overlap(*Matcher::idealreg2regmask[Op_RegI]) ||\n+         (Matcher::has_predicated_vectors() &&\n+          lrg.mask().overlap(*Matcher::idealreg2regmask[Op_RegVMask])))) {\n@@ -448,1 +450,3 @@\n-      if (r.overlap(*Matcher::idealreg2regmask[Op_RegI])) {\n+      if (r.overlap(*Matcher::idealreg2regmask[Op_RegI]) ||\n+           (Matcher::has_predicated_vectors() &&\n+            r.overlap(*Matcher::idealreg2regmask[Op_RegVMask]))) {\n@@ -503,1 +507,3 @@\n-      if (rm.overlap(*Matcher::idealreg2regmask[Op_RegI])) {\n+      if (rm.overlap(*Matcher::idealreg2regmask[Op_RegI]) ||\n+           (Matcher::has_predicated_vectors() &&\n+            rm.overlap(*Matcher::idealreg2regmask[Op_RegVMask]))) {\n","filename":"src\/hotspot\/share\/opto\/ifg.cpp","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -106,0 +106,6 @@\n+  KRegister  as_KRegister(PhaseRegAlloc *ra_, const Node *node)   const {\n+    return ::as_KRegister(reg(ra_, node));\n+  }\n+  KRegister  as_KRegister(PhaseRegAlloc *ra_, const Node *node, int idx)   const {\n+    return ::as_KRegister(reg(ra_, node, idx));\n+  }\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -236,1 +236,1 @@\n-  Node* mask_gen =  new VectorMaskGenNode(length, TypeLong::LONG, Type::get_const_basic_type(type));\n+  Node* mask_gen =  new VectorMaskGenNode(length, TypeVect::VMASK, Type::get_const_basic_type(type));\n","filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -98,0 +98,1 @@\n+  idealreg2spillmask  [Op_RegVMask] = NULL;\n@@ -112,0 +113,1 @@\n+  idealreg2debugmask  [Op_RegVMask] = NULL;\n@@ -126,0 +128,1 @@\n+  idealreg2mhdebugmask[Op_RegVMask] = NULL;\n@@ -433,1 +436,1 @@\n-#define NOF_STACK_MASKS (3*12)\n+#define NOF_STACK_MASKS (3*13)\n@@ -490,0 +493,4 @@\n+  idealreg2spillmask  [Op_RegVMask] = &rms[36];\n+  idealreg2debugmask  [Op_RegVMask] = &rms[37];\n+  idealreg2mhdebugmask[Op_RegVMask] = &rms[38];\n+\n@@ -534,0 +541,5 @@\n+  if (Matcher::has_predicated_vectors()) {\n+    *idealreg2spillmask[Op_RegVMask] = *idealreg2regmask[Op_RegVMask];\n+     idealreg2spillmask[Op_RegVMask]->OR(aligned_stack_mask);\n+  }\n+\n@@ -652,0 +664,1 @@\n+  *idealreg2debugmask  [Op_RegVMask] = *idealreg2spillmask[Op_RegVMask];\n@@ -666,0 +679,1 @@\n+  *idealreg2mhdebugmask[Op_RegVMask] = *idealreg2spillmask[Op_RegVMask];\n@@ -686,0 +700,1 @@\n+  idealreg2debugmask[Op_RegVMask]->SUBTRACT(*caller_save_mask);\n@@ -700,0 +715,1 @@\n+  idealreg2mhdebugmask[Op_RegVMask]->SUBTRACT(*mh_caller_save_mask);\n@@ -968,0 +984,1 @@\n+  idealreg2regmask[Op_RegVMask] = regmask_for_ideal_register(Op_RegVMask, ret);\n@@ -2562,0 +2579,1 @@\n+    case Op_RegVMask: return Matcher::predicate_reg_mask();\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":20,"deletions":2,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -322,0 +322,2 @@\n+  static const RegMask* predicate_reg_mask(void);\n+  static const TypeVect* predicate_reg_type(const Type* elemTy, int length);\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -696,0 +696,2 @@\n+      DEFINE_CLASS_ID(Vector, Type, 7)\n+        DEFINE_CLASS_ID(VectorMaskCmp, Vector, 0)\n@@ -740,2 +742,0 @@\n-    DEFINE_CLASS_ID(Vector,   Node, 13)\n-      DEFINE_CLASS_ID(VectorMaskCmp, Vector, 0)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2006, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2006, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,1 +39,1 @@\n-\/\/ Stack-slots (spill locations) start at the nest Chunk past the last machine\n+\/\/ Stack-slots (spill locations) start at the next Chunk past the last machine\n","filename":"src\/hotspot\/share\/opto\/optoreg.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -70,0 +70,2 @@\n+    case Op_RegVMask:\n+      return SlotsPerRegVMask;\n","filename":"src\/hotspot\/share\/opto\/regmask.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -108,0 +108,1 @@\n+         SlotsPerRegVMask = X86_ONLY(2) NOT_X86(1)\n","filename":"src\/hotspot\/share\/opto\/regmask.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -66,0 +66,1 @@\n+  { Bad,             T_ILLEGAL,    \"vectorm:\",      false, Op_RegVMask,          relocInfo::none          },  \/\/ VectorM.\n@@ -73,0 +74,1 @@\n+  { Bad,             T_ILLEGAL,    \"vectorm:\",      false, Op_RegVMask,          relocInfo::none          },  \/\/ VectorM.\n@@ -80,0 +82,1 @@\n+  { Bad,             T_ILLEGAL,    \"vectorm:\",      false, Op_RegVMask,          relocInfo::none          },  \/\/ VectorM.\n@@ -661,0 +664,3 @@\n+  TypeVect::VMASK = (TypeVect*)(new TypeVectMask(TypeInt::BOOL, MaxVectorSize))->hashcons();\n+  mreg2type[Op_RegVMask] = TypeVect::VMASK;\n+\n@@ -2379,0 +2385,1 @@\n+const TypeVect *TypeVect::VMASK = NULL; \/\/ predicate\/mask vector\n@@ -2406,0 +2413,9 @@\n+const TypeVect *TypeVect::makemask(const Type* elem, uint length) {\n+  if (Matcher::has_predicated_vectors()) {\n+    const TypeVect* mtype = Matcher::predicate_reg_type(elem, length);\n+    return (TypeVect*)(const_cast<TypeVect*>(mtype))->hashcons();\n+  } else {\n+    return make(elem, length);\n+  }\n+}\n+\n@@ -2420,0 +2436,7 @@\n+  case VectorM: {\n+    const TypeVectMask* v = t->is_vectmask();\n+    assert(  base() == v->base(), \"\");\n+    assert(length() == v->length(), \"\");\n+    assert(element_basic_type() == v->element_basic_type(), \"\");\n+    return TypeVect::makemask(_elem->xmeet(v->_elem), _length);\n+  }\n@@ -2487,0 +2510,2 @@\n+  case VectorM:\n+    st->print(\"vectorm[\"); break;\n@@ -2496,0 +2521,8 @@\n+bool TypeVectMask::eq(const Type *t) const {\n+  const TypeVectMask *v = t->is_vectmask();\n+  return (element_type() == v->element_type()) && (length() == v->length());\n+}\n+\n+const Type *TypeVectMask::xdual() const {\n+  return new TypeVectMask(element_type()->dual(), length());\n+}\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -63,0 +63,1 @@\n+class     TypeVectMask;\n@@ -92,0 +93,2 @@\n+\n+    VectorM,                    \/\/ Vector predicate\/mask type\n@@ -302,0 +305,2 @@\n+  const TypeVectMask *is_vectmask() const;       \/\/ Predicate\/Mask Vector\n+  const TypeVectMask *isa_vectmask() const;      \/\/ Returns NULL if not a Vector Predicate\/Mask\n@@ -803,0 +808,7 @@\n+  static const TypeVect *makemask(const BasicType elem_bt, uint length) {\n+    \/\/ Use bottom primitive type.\n+    return makemask(get_const_basic_type(elem_bt), length);\n+  }\n+  static const TypeVect *makemask(const Type* elem, uint length);\n+\n+\n@@ -812,0 +824,1 @@\n+  static const TypeVect *VMASK;\n@@ -848,0 +861,8 @@\n+class TypeVectMask : public TypeVect {\n+public:\n+  friend class TypeVect;\n+  TypeVectMask(const Type* elem, uint length) : TypeVect(VectorM, elem, length) {}\n+  virtual bool eq(const Type *t) const;\n+  virtual const Type *xdual() const;\n+};\n+\n@@ -1685,0 +1706,9 @@\n+inline const TypeVectMask *Type::is_vectmask() const {\n+  assert( _base == VectorM, \"Not a Vector Mask\" );\n+  return (TypeVectMask*)this;\n+}\n+\n+inline const TypeVectMask *Type::isa_vectmask() const {\n+  return (_base == VectorM) ? (TypeVectMask*)this : NULL;\n+}\n+\n@@ -1686,1 +1716,1 @@\n-  assert( _base >= VectorA && _base <= VectorZ, \"Not a Vector\" );\n+  assert( _base >= VectorM && _base <= VectorZ, \"Not a Vector\" );\n@@ -1691,1 +1721,1 @@\n-  return (_base >= VectorA && _base <= VectorZ) ? (TypeVect*)this : NULL;\n+  return (_base >= VectorM && _base <= VectorZ) ? (TypeVect*)this : NULL;\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":32,"deletions":2,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -807,1 +807,1 @@\n-    assert(mask->bottom_type()->is_long(), \"sanity\");\n+    assert(mask->bottom_type()->is_vectmask(), \"sanity\");\n@@ -825,1 +825,1 @@\n-    assert(mask->bottom_type()->is_long(), \"sanity\");\n+    assert(mask->bottom_type()->is_vectmask(), \"sanity\");\n@@ -848,0 +848,3 @@\n+  virtual uint  ideal_reg() const {\n+    return Op_RegVMask;\n+  }\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"}]}