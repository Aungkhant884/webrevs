{"files":[{"patch":"@@ -91,0 +91,4 @@\n+  \/\/ Perform an allocation out of a new allocation region, retiring the current one.\n+  inline HeapWord* attempt_allocation_using_new_region(size_t min_word_size,\n+                                                       size_t desired_word_size,\n+                                                       size_t* actual_word_size);\n@@ -175,5 +179,0 @@\n-  \/\/ Perform an allocation out of a new allocation region, retiring the current one.\n-  inline HeapWord* attempt_allocation_using_new_region(size_t min_word_size,\n-                                                       size_t desired_word_size,\n-                                                       size_t* actual_word_size);\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1AllocRegion.hpp","additions":4,"deletions":5,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -257,2 +257,2 @@\n-                                                                              desired_word_size,\n-                                                                              actual_word_size);\n+                                                                               desired_word_size,\n+                                                                               actual_word_size);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -120,4 +120,0 @@\n-  \/\/ Attempt allocation, retiring the current region and allocating a new one. It is\n-  \/\/ assumed that attempt_allocation() has been tried and failed already first.\n-  inline HeapWord* attempt_allocation_using_new_region(size_t word_size);\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -65,10 +65,0 @@\n-inline HeapWord* G1Allocator::attempt_allocation_using_new_region(size_t word_size) {\n-  uint node_index = current_node_index();\n-  size_t temp;\n-  HeapWord* result = mutator_alloc_region(node_index)->attempt_allocation_using_new_region(word_size, word_size, &temp);\n-  assert(result != NULL || mutator_alloc_region(node_index)->get() == NULL,\n-         \"Must not have a mutator alloc region if there is no memory, but is \" PTR_FORMAT,\n-         p2i(mutator_alloc_region(node_index)->get()));\n-  return result;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.inline.hpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -401,1 +401,0 @@\n-    bool preventive_collection_required = false;\n@@ -409,2 +408,1 @@\n-      size_t actual_size;\n-      result = _allocator->attempt_allocation(word_size, word_size, &actual_size);\n+      result = _allocator->attempt_allocation_locked(word_size);\n@@ -415,5 +413,7 @@\n-      preventive_collection_required = policy()->preventive_collection_required(1);\n-      if (!preventive_collection_required) {\n-        \/\/ We've already attempted a lock-free allocation above, so we don't want to\n-        \/\/ do it again. Let's jump straight to replacing the active region.\n-        result = _allocator->attempt_allocation_using_new_region(word_size);\n+      \/\/ If the GCLocker is active and we are bound for a GC, try expanding young gen.\n+      \/\/ This is different to when only GCLocker::needs_gc() is set: try to avoid\n+      \/\/ waiting because the GCLocker is active to not wait too long.\n+      if (GCLocker::is_active_and_needs_gc() && policy()->can_expand_young_list()) {\n+        \/\/ No need for an ergo message here, can_expand_young_list() does this when\n+        \/\/ it returns true.\n+        result = _allocator->attempt_allocation_force(word_size);\n@@ -423,12 +423,0 @@\n-\n-        \/\/ If the GCLocker is active and we are bound for a GC, try expanding young gen.\n-        \/\/ This is different to when only GCLocker::needs_gc() is set: try to avoid\n-        \/\/ waiting because the GCLocker is active to not wait too long.\n-        if (GCLocker::is_active_and_needs_gc() && policy()->can_expand_young_list()) {\n-          \/\/ No need for an ergo message here, can_expand_young_list() does this when\n-          \/\/ it returns true.\n-          result = _allocator->attempt_allocation_force(word_size);\n-          if (result != NULL) {\n-            return result;\n-          }\n-        }\n@@ -446,2 +434,0 @@\n-      GCCause::Cause gc_cause = preventive_collection_required ? GCCause::_g1_preventive_collection\n-                                                               : GCCause::_g1_inc_collection_pause;\n@@ -449,1 +435,1 @@\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded, gc_cause);\n+      result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_inc_collection_pause);\n@@ -863,1 +849,0 @@\n-    bool preventive_collection_required = false;\n@@ -871,11 +856,8 @@\n-      preventive_collection_required = policy()->preventive_collection_required((uint)size_in_regions);\n-      if (!preventive_collection_required) {\n-        \/\/ Given that humongous objects are not allocated in young\n-        \/\/ regions, we'll first try to do the allocation without doing a\n-        \/\/ collection hoping that there's enough space in the heap.\n-        result = humongous_obj_allocate(word_size);\n-        if (result != NULL) {\n-          policy()->old_gen_alloc_tracker()->\n-            add_allocated_humongous_bytes_since_last_gc(size_in_regions * HeapRegion::GrainBytes);\n-          return result;\n-        }\n+      \/\/ Given that humongous objects are not allocated in young\n+      \/\/ regions, we'll first try to do the allocation without doing a\n+      \/\/ collection hoping that there's enough space in the heap.\n+      result = humongous_obj_allocate(word_size);\n+      if (result != NULL) {\n+        policy()->old_gen_alloc_tracker()->\n+          add_allocated_humongous_bytes_since_last_gc(size_in_regions * HeapRegion::GrainBytes);\n+        return result;\n@@ -893,2 +875,0 @@\n-      GCCause::Cause gc_cause = preventive_collection_required ? GCCause::_g1_preventive_collection\n-                                                              : GCCause::_g1_humongous_allocation;\n@@ -896,1 +876,1 @@\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded, gc_cause);\n+      result = do_collection_pause(word_size, gc_count_before, &succeeded, GCCause::_g1_humongous_allocation);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":18,"deletions":38,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -103,4 +103,0 @@\n-bool G1CollectionSet::has_candidates() {\n-  return _candidates != NULL && !_candidates->is_empty();\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSet.cpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -226,1 +226,0 @@\n-  bool has_candidates();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSet.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -74,2 +74,0 @@\n-  _predicted_surviving_bytes_from_survivor(0),\n-  _predicted_surviving_bytes_from_old(0),\n@@ -586,1 +584,0 @@\n-  update_survival_estimates_for_next_collection();\n@@ -901,2 +898,0 @@\n-  update_survival_estimates_for_next_collection();\n-\n@@ -1581,82 +1576,0 @@\n-\/\/ Number of regions required to store the given number of bytes, taking\n-\/\/ into account the target amount of wasted space in PLABs.\n-static size_t get_num_regions_adjust_for_plab_waste(size_t byte_count) {\n-  size_t byte_count_adjusted = byte_count * (size_t)(100 + TargetPLABWastePct) \/ 100.0;\n-\n-  \/\/ Round up the region count\n-  return (byte_count_adjusted + HeapRegion::GrainBytes - 1) \/ HeapRegion::GrainBytes;\n-}\n-\n-bool G1Policy::preventive_collection_required(uint alloc_region_count) {\n-  if (!G1UsePreventiveGC || !Universe::is_fully_initialized()) {\n-    \/\/ Don't attempt any preventive GC's if the feature is disabled,\n-    \/\/ or before initialization is complete.\n-    return false;\n-  }\n-\n-  if (_g1h->young_regions_count() == 0 && !_collection_set->has_candidates()) {\n-    return false;\n-  }\n-\n-  uint eden_count = _g1h->eden_regions_count();\n-  size_t const eden_surv_bytes_pred = _eden_surv_rate_group->accum_surv_rate_pred(eden_count) * HeapRegion::GrainBytes;\n-  size_t const total_young_predicted_surviving_bytes = eden_surv_bytes_pred + _predicted_surviving_bytes_from_survivor;\n-\n-  uint required_regions = (uint)(get_num_regions_adjust_for_plab_waste(total_young_predicted_surviving_bytes) +\n-                                get_num_regions_adjust_for_plab_waste(_predicted_surviving_bytes_from_old));\n-\n-  if (required_regions > _g1h->num_free_or_available_regions() - alloc_region_count) {\n-    log_debug(gc, ergo, cset)(\"Preventive GC, insufficient free or available regions. \"\n-                              \"Predicted need %u. Curr Eden %u (Pred %u). Curr Survivor %u (Pred %u). Curr Old %u (Pred %u) Free or Avail %u (Free %u) Alloc %u\",\n-                              required_regions,\n-                              eden_count,\n-                              (uint)get_num_regions_adjust_for_plab_waste(eden_surv_bytes_pred),\n-                              _g1h->survivor_regions_count(),\n-                              (uint)get_num_regions_adjust_for_plab_waste(_predicted_surviving_bytes_from_survivor),\n-                              _g1h->old_regions_count(),\n-                              (uint)get_num_regions_adjust_for_plab_waste(_predicted_surviving_bytes_from_old),\n-                              _g1h->num_free_or_available_regions(),\n-                              _g1h->num_free_regions(),\n-                              alloc_region_count);\n-\n-    return true;\n-  }\n-\n-  return false;\n-}\n-\n-void G1Policy::update_survival_estimates_for_next_collection() {\n-  \/\/ Predict the number of bytes of surviving objects from survivor and old\n-  \/\/ regions and update the associated members.\n-\n-  \/\/ Survivor regions\n-  size_t survivor_bytes = 0;\n-  const GrowableArray<HeapRegion*>* survivor_regions = _g1h->survivor()->regions();\n-  for (GrowableArrayIterator<HeapRegion*> it = survivor_regions->begin();\n-       it != survivor_regions->end();\n-       ++it) {\n-    survivor_bytes += predict_bytes_to_copy(*it);\n-  }\n-\n-  _predicted_surviving_bytes_from_survivor = survivor_bytes;\n-\n-  \/\/ Old regions\n-  if (!_collection_set->has_candidates()) {\n-    _predicted_surviving_bytes_from_old = 0;\n-    return;\n-  }\n-\n-  \/\/ Use the minimum old gen collection set as conservative estimate for the number\n-  \/\/ of regions to take for this calculation.\n-  G1CollectionSetCandidates *candidates = _collection_set->candidates();\n-  uint iterate_count = MIN2(candidates->num_remaining(), calc_min_old_cset_length(candidates));\n-  uint current_index = candidates->cur_idx();\n-  size_t old_bytes = 0;\n-  for (uint i = 0; i < iterate_count; i++) {\n-    HeapRegion *region = candidates->at(current_index + i);\n-    old_bytes += predict_bytes_to_copy(region);\n-  }\n-\n-  _predicted_surviving_bytes_from_old = old_bytes;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":0,"deletions":87,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -104,5 +104,0 @@\n-  \/\/ These values are predictions of how much we think will survive in each\n-  \/\/ section of the heap.\n-  size_t _predicted_surviving_bytes_from_survivor;\n-  size_t _predicted_surviving_bytes_from_old;\n-\n@@ -363,5 +358,0 @@\n-  \/\/ Returns whether a collection should be done proactively, taking into\n-  \/\/ account the current number of free regions and the expected survival\n-  \/\/ rates in each section of the heap.\n-  bool preventive_collection_required(uint region_count);\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.hpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -126,5 +126,0 @@\n-bool VM_G1CollectForAllocation::should_try_allocation_before_gc() {\n-  \/\/ Don't allocate before a preventive GC.\n-  return _gc_cause != GCCause::_g1_preventive_collection;\n-}\n-\n@@ -134,1 +129,1 @@\n-  if (should_try_allocation_before_gc() && _word_size > 0) {\n+  if (_word_size > 0) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1VMOperations.cpp","additions":1,"deletions":6,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -80,3 +80,0 @@\n-\n-private:\n-  bool should_try_allocation_before_gc();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1VMOperations.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -102,3 +102,0 @@\n-    case _g1_preventive_collection:\n-      return \"G1 Preventive Collection\";\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/gcCause.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -77,1 +77,0 @@\n-    _g1_preventive_collection,\n","filename":"src\/hotspot\/share\/gc\/shared\/gcCause.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -53,1 +53,0 @@\n-                                                                  \"-XX:-G1UsePreventiveGC\",\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestEvacuationFailure.java","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -281,1 +281,0 @@\n-                                                                  \"-XX:-G1UsePreventiveGC\",\n@@ -294,1 +293,0 @@\n-                                                   \"-XX:-G1UsePreventiveGC\",\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestGCLogMessages.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -128,2 +128,1 @@\n-                                                        \"-XX:+UnlockDiagnosticVMOptions\",\n-                                                        \"-XX:-G1UsePreventiveGC\"});\n+                                                        \"-XX:+UnlockDiagnosticVMOptions\"});\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestVerifyGCType.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"}]}