{"files":[{"patch":"@@ -29,1 +29,1 @@\n-#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n+#include \"gc\/g1\/g1MonotonicArena.inline.hpp\"\n@@ -35,3 +35,3 @@\n-                                       G1CardSetFreeList* free_segment_list) :\n-  _segmented_array(alloc_options, free_segment_list),\n-  _free_slots_list(name, &_segmented_array)\n+                                       SegmentFreeList* segment_free_list) :\n+  _arena(alloc_options, segment_free_list),\n+  _free_slots_list(name, &_arena)\n@@ -39,1 +39,1 @@\n-  uint slot_size = _segmented_array.slot_size();\n+  uint slot_size = _arena.slot_size();\n@@ -54,1 +54,1 @@\n-  _segmented_array.drop_all();\n+  _arena.drop_all();\n@@ -59,2 +59,2 @@\n-         num_segments() * sizeof(G1CardSetSegment) +\n-         _segmented_array.num_total_slots() * _segmented_array.slot_size();\n+         num_segments() * sizeof(Segment) +\n+         _arena.num_total_slots() * _arena.slot_size();\n@@ -64,1 +64,1 @@\n-  uint num_unused_slots = (_segmented_array.num_total_slots() - _segmented_array.num_allocated_slots()) +\n+  uint num_unused_slots = (_arena.num_total_slots() - _arena.num_allocated_slots()) +\n@@ -66,1 +66,1 @@\n-  return num_unused_slots * _segmented_array.slot_size();\n+  return num_unused_slots * _arena.slot_size();\n@@ -70,1 +70,1 @@\n-  return _segmented_array.num_segments();\n+  return _arena.num_segments();\n@@ -126,2 +126,2 @@\n-G1SegmentedArrayMemoryStats G1CardSetMemoryManager::memory_stats() const {\n-  G1SegmentedArrayMemoryStats result;\n+G1MonotonicArenaMemoryStats G1CardSetMemoryManager::memory_stats() const {\n+  G1MonotonicArenaMemoryStats result;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.cpp","additions":13,"deletions":13,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -30,2 +30,2 @@\n-#include \"gc\/g1\/g1SegmentedArray.hpp\"\n-#include \"gc\/g1\/g1SegmentedArrayFreePool.hpp\"\n+#include \"gc\/g1\/g1MonotonicArena.hpp\"\n+#include \"gc\/g1\/g1MonotonicArenaFreePool.hpp\"\n@@ -40,2 +40,2 @@\n-\/\/ to determine the next size of the allocated G1CardSetSegment.\n-class G1CardSetAllocOptions : public G1SegmentedArrayAllocOptions {\n+\/\/ to determine the next size of the allocated memory Segment.\n+class G1CardSetAllocOptions : public G1MonotonicArena::AllocOptions {\n@@ -53,1 +53,1 @@\n-    G1SegmentedArrayAllocOptions(mtGCCardSet, slot_size, initial_num_slots, max_num_slots, SlotAlignment) {\n+    G1MonotonicArena::AllocOptions(mtGCCardSet, slot_size, initial_num_slots, max_num_slots, SlotAlignment) {\n@@ -61,4 +61,0 @@\n-using G1CardSetSegment = G1SegmentedArraySegment;\n-\n-using G1CardSetFreeList = G1SegmentedArrayFreeList;\n-\n@@ -68,1 +64,1 @@\n-\/\/ empty then tries to allocate from the G1SegmentedArray.\n+\/\/ empty then tries to allocate from the G1MonotonicArena.\n@@ -70,1 +66,3 @@\n-  G1SegmentedArray _segmented_array;\n+  using Segment = G1MonotonicArena::Segment;\n+  using SegmentFreeList = G1MonotonicArena::SegmentFreeList;\n+  G1MonotonicArena _arena;\n@@ -76,1 +74,1 @@\n-                     G1CardSetFreeList* free_segment_list);\n+                     SegmentFreeList* segment_free_list);\n@@ -94,1 +92,1 @@\n-using G1CardSetFreePool = G1SegmentedArrayFreePool;\n+using G1CardSetFreePool = G1MonotonicArenaFreePool;\n@@ -121,1 +119,1 @@\n-  G1SegmentedArrayMemoryStats memory_stats() const;\n+  G1MonotonicArenaMemoryStats memory_stats() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.hpp","additions":12,"deletions":14,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -30,1 +30,1 @@\n-#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n+#include \"gc\/g1\/g1MonotonicArena.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+#include \"gc\/g1\/g1MonotonicArenaFreeMemoryTask.hpp\"\n@@ -67,1 +68,0 @@\n-#include \"gc\/g1\/g1SegmentedArrayFreeMemoryTask.hpp\"\n@@ -1432,1 +1432,1 @@\n-  _free_segmented_array_memory_task(NULL),\n+  _free_monotonic_arena_memory_task(NULL),\n@@ -1723,2 +1723,2 @@\n-  _free_segmented_array_memory_task = new G1SegmentedArrayFreeMemoryTask(\"Card Set Free Memory Task\");\n-  _service_thread->register_task(_free_segmented_array_memory_task);\n+  _free_monotonic_arena_memory_task = new G1MonotonicArenaFreeMemoryTask(\"Card Set Free Memory Task\");\n+  _service_thread->register_task(_free_monotonic_arena_memory_task);\n@@ -2622,1 +2622,1 @@\n-  _free_segmented_array_memory_task->notify_new_stats(&_young_gen_card_set_stats,\n+  _free_monotonic_arena_memory_task->notify_new_stats(&_young_gen_card_set_stats,\n@@ -2935,1 +2935,1 @@\n-void G1CollectedHeap::set_collection_set_candidates_stats(G1SegmentedArrayMemoryStats& stats) {\n+void G1CollectedHeap::set_collection_set_candidates_stats(G1MonotonicArenaMemoryStats& stats) {\n@@ -2939,1 +2939,1 @@\n-void G1CollectedHeap::set_young_gen_card_set_stats(const G1SegmentedArrayMemoryStats& stats) {\n+void G1CollectedHeap::set_young_gen_card_set_stats(const G1MonotonicArenaMemoryStats& stats) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -43,0 +43,1 @@\n+#include \"gc\/g1\/g1MonotonicArenaFreeMemoryTask.hpp\"\n@@ -44,1 +45,0 @@\n-#include \"gc\/g1\/g1SegmentedArrayFreeMemoryTask.hpp\"\n@@ -148,1 +148,1 @@\n-  G1SegmentedArrayFreeMemoryTask* _free_segmented_array_memory_task;\n+  G1MonotonicArenaFreeMemoryTask* _free_monotonic_arena_memory_task;\n@@ -165,1 +165,1 @@\n-  G1SegmentedArrayMemoryStats _young_gen_card_set_stats;\n+  G1MonotonicArenaMemoryStats _young_gen_card_set_stats;\n@@ -167,1 +167,1 @@\n-  G1SegmentedArrayMemoryStats _collection_set_candidates_card_set_stats;\n+  G1MonotonicArenaMemoryStats _collection_set_candidates_card_set_stats;\n@@ -242,2 +242,2 @@\n-  void set_collection_set_candidates_stats(G1SegmentedArrayMemoryStats& stats);\n-  void set_young_gen_card_set_stats(const G1SegmentedArrayMemoryStats& stats);\n+  void set_collection_set_candidates_stats(G1MonotonicArenaMemoryStats& stats);\n+  void set_young_gen_card_set_stats(const G1MonotonicArenaMemoryStats& stats);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,252 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1MonotonicArena.inline.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/vmOperations.hpp\"\n+#include \"utilities\/globalCounter.inline.hpp\"\n+\n+G1MonotonicArena::Segment::Segment(uint slot_size, uint num_slots, Segment* next, MEMFLAGS flag) :\n+  _slot_size(slot_size),\n+  _num_slots(num_slots),\n+  _next(next),\n+  _next_allocate(0),\n+  _mem_flag(flag) {\n+  _bottom = ((char*) this) + header_size();\n+}\n+\n+G1MonotonicArena::Segment* G1MonotonicArena::Segment::create_segment(uint slot_size,\n+                                                                     uint num_slots,\n+                                                                     Segment* next,\n+                                                                     MEMFLAGS mem_flag) {\n+  size_t block_size = size_in_bytes(slot_size, num_slots);\n+  char* alloc_block = NEW_C_HEAP_ARRAY(char, block_size, mem_flag);\n+  return new (alloc_block) Segment(slot_size, num_slots, next, mem_flag);\n+}\n+\n+void G1MonotonicArena::Segment::delete_segment(Segment* segment) {\n+  \/\/ Wait for concurrent readers of the segment to exit before freeing; but only if the VM\n+  \/\/ isn't exiting.\n+  if (!VM_Exit::vm_exited()) {\n+    GlobalCounter::write_synchronize();\n+  }\n+  segment->~Segment();\n+  FREE_C_HEAP_ARRAY(_mem_flag, segment);\n+}\n+\n+void G1MonotonicArena::SegmentFreeList::bulk_add(Segment& first,\n+                                                 Segment& last,\n+                                                 size_t num,\n+                                                 size_t mem_size) {\n+  _list.prepend(first, last);\n+  Atomic::add(&_num_segments, num, memory_order_relaxed);\n+  Atomic::add(&_mem_size, mem_size, memory_order_relaxed);\n+}\n+\n+void G1MonotonicArena::SegmentFreeList::print_on(outputStream* out, const char* prefix) {\n+  out->print_cr(\"%s: segments %zu size %zu\",\n+                prefix, Atomic::load(&_num_segments), Atomic::load(&_mem_size));\n+}\n+\n+G1MonotonicArena::Segment* G1MonotonicArena::SegmentFreeList::get_all(size_t& num_segments,\n+                                                                      size_t& mem_size) {\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+\n+  Segment* result = _list.pop_all();\n+  num_segments = Atomic::load(&_num_segments);\n+  mem_size = Atomic::load(&_mem_size);\n+\n+  if (result != nullptr) {\n+    Atomic::sub(&_num_segments, num_segments, memory_order_relaxed);\n+    Atomic::sub(&_mem_size, mem_size, memory_order_relaxed);\n+  }\n+  return result;\n+}\n+\n+void G1MonotonicArena::SegmentFreeList::free_all() {\n+  size_t num_freed = 0;\n+  size_t mem_size_freed = 0;\n+  Segment* cur;\n+\n+  while ((cur = _list.pop()) != nullptr) {\n+    mem_size_freed += cur->mem_size();\n+    num_freed++;\n+    Segment::delete_segment(cur);\n+  }\n+\n+  Atomic::sub(&_num_segments, num_freed, memory_order_relaxed);\n+  Atomic::sub(&_mem_size, mem_size_freed, memory_order_relaxed);\n+}\n+\n+G1MonotonicArena::Segment* G1MonotonicArena::new_segment(Segment* const prev) {\n+  \/\/ Take an existing segment if available.\n+  Segment* next = _segment_free_list->get();\n+  if (next == nullptr) {\n+    uint prev_num_slots = (prev != nullptr) ? prev->num_slots() : 0;\n+    uint num_slots = _alloc_options->next_num_slots(prev_num_slots);\n+\n+    next = Segment::create_segment(slot_size(), num_slots, prev, _alloc_options->mem_flag());\n+  } else {\n+    assert(slot_size() == next->slot_size() ,\n+           \"Mismatch %d != %d\", slot_size(), next->slot_size());\n+    next->reset(prev);\n+  }\n+\n+  \/\/ Install it as current allocation segment.\n+  Segment* old = Atomic::cmpxchg(&_first, prev, next);\n+  if (old != prev) {\n+    \/\/ Somebody else installed the segment, use that one.\n+    Segment::delete_segment(next);\n+    return old;\n+  } else {\n+    \/\/ Did we install the first segment in the list? If so, this is also the last.\n+    if (prev == nullptr) {\n+      _last = next;\n+    }\n+    \/\/ Successfully installed the segment into the list.\n+    Atomic::inc(&_num_segments, memory_order_relaxed);\n+    Atomic::add(&_mem_size, next->mem_size(), memory_order_relaxed);\n+    Atomic::add(&_num_total_slots, next->num_slots(), memory_order_relaxed);\n+    return next;\n+  }\n+}\n+\n+G1MonotonicArena::G1MonotonicArena(const AllocOptions* alloc_options,\n+                                   SegmentFreeList* segment_free_list) :\n+  _alloc_options(alloc_options),\n+  _first(nullptr),\n+  _last(nullptr),\n+  _num_segments(0),\n+  _mem_size(0),\n+  _segment_free_list(segment_free_list),\n+  _num_total_slots(0),\n+  _num_allocated_slots(0) {\n+  assert(_segment_free_list != nullptr, \"precondition!\");\n+}\n+\n+G1MonotonicArena::~G1MonotonicArena() {\n+  drop_all();\n+}\n+\n+uint G1MonotonicArena::slot_size() const {\n+  return _alloc_options->slot_size();\n+}\n+\n+void G1MonotonicArena::drop_all() {\n+  Segment* cur = Atomic::load_acquire(&_first);\n+\n+  if (cur != nullptr) {\n+    assert(_last != nullptr, \"If there is at least one segment, there must be a last one.\");\n+\n+    Segment* first = cur;\n+#ifdef ASSERT\n+    \/\/ Check list consistency.\n+    Segment* last = cur;\n+    uint num_segments = 0;\n+    size_t mem_size = 0;\n+    while (cur != nullptr) {\n+      mem_size += cur->mem_size();\n+      num_segments++;\n+\n+      Segment* next = cur->next();\n+      last = cur;\n+      cur = next;\n+    }\n+#endif\n+    assert(num_segments == _num_segments, \"Segment count inconsistent %u %u\", num_segments, _num_segments);\n+    assert(mem_size == _mem_size, \"Memory size inconsistent\");\n+    assert(last == _last, \"Inconsistent last segment\");\n+\n+    _segment_free_list->bulk_add(*first, *_last, _num_segments, _mem_size);\n+  }\n+\n+  _first = nullptr;\n+  _last = nullptr;\n+  _num_segments = 0;\n+  _mem_size = 0;\n+  _num_total_slots = 0;\n+  _num_allocated_slots = 0;\n+}\n+\n+void* G1MonotonicArena::allocate() {\n+  assert(slot_size() > 0, \"instance size not set.\");\n+\n+  Segment* cur = Atomic::load_acquire(&_first);\n+  if (cur == nullptr) {\n+    cur = new_segment(cur);\n+  }\n+\n+  while (true) {\n+    void* slot = cur->allocate_slot();\n+    if (slot != nullptr) {\n+      Atomic::inc(&_num_allocated_slots, memory_order_relaxed);\n+      guarantee(is_aligned(slot, _alloc_options->slot_alignment()),\n+                \"result \" PTR_FORMAT \" not aligned at %u\", p2i(slot), _alloc_options->slot_alignment());\n+      return slot;\n+    }\n+    \/\/ The segment is full. Next round.\n+    assert(cur->is_full(), \"must be\");\n+    cur = new_segment(cur);\n+  }\n+}\n+\n+uint G1MonotonicArena::num_segments() const {\n+  return Atomic::load(&_num_segments);\n+}\n+\n+#ifdef ASSERT\n+class LengthClosure {\n+  uint _total;\n+public:\n+  LengthClosure() : _total(0) {}\n+  void do_segment(G1MonotonicArena::Segment* segment, uint limit) {\n+    _total += limit;\n+  }\n+  uint length() const {\n+    return _total;\n+  }\n+};\n+\n+uint G1MonotonicArena::calculate_length() const {\n+  LengthClosure closure;\n+  iterate_segments(closure);\n+  return closure.length();\n+}\n+#endif\n+\n+template <typename SegmentClosure>\n+void G1MonotonicArena::iterate_segments(SegmentClosure& closure) const {\n+  Segment* cur = Atomic::load_acquire(&_first);\n+\n+  assert((cur != nullptr) == (_last != nullptr),\n+         \"If there is at least one segment, there must be a last one\");\n+\n+  while (cur != nullptr) {\n+    closure.do_segment(cur, cur->length());\n+    cur = cur->next();\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArena.cpp","additions":252,"deletions":0,"binary":false,"changes":252,"status":"added"},{"patch":"@@ -0,0 +1,258 @@\n+\/*\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1MONOTONICARENA_HPP\n+#define SHARE_GC_G1_G1MONOTONICARENA_HPP\n+\n+#include \"gc\/shared\/freeListAllocator.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/lockFreeStack.hpp\"\n+\n+\/\/ A G1MonotonicArena extends the FreeListConfig, memory\n+\/\/ blocks allocated from the OS are managed as a linked-list of Segments.\n+\/\/\n+\/\/ Implementation details as below:\n+\/\/\n+\/\/ Allocation arena for (card set, or ...) heap memory objects (Slot slots).\n+\/\/\n+\/\/ Actual allocation from the C heap occurs as memory blocks called Segments.\n+\/\/ The allocation pattern for these Segments is assumed to be strictly two-phased:\n+\/\/\n+\/\/ - in the first phase, Segment are allocated from the C heap (or a free\n+\/\/ list given at initialization time). This allocation may occur in parallel. This\n+\/\/ typically corresponds to a single mutator phase, but may extend over multiple.\n+\/\/\n+\/\/ - in the second phase, Segments are added in bulk to the free list.\n+\/\/ This is typically done during a GC pause.\n+\/\/\n+\/\/ Some third party is responsible for giving back memory from the free list to\n+\/\/ the operating system.\n+\/\/\n+\/\/ Allocation and deallocation in the first phase basis may occur by multiple threads concurrently.\n+\/\/\n+\/\/ The class also manages a few counters for statistics using atomic operations.\n+\/\/ Their values are only consistent within each other with extra global\n+\/\/ synchronization.\n+\n+class G1MonotonicArena : public FreeListConfig {\n+public:\n+  class AllocOptions;\n+  class Segment;\n+  class SegmentFreeList;\n+private:\n+  \/\/ AllocOptions provides parameters for allocation segment\n+  \/\/ sizing and expansion.\n+  const AllocOptions* _alloc_options;\n+\n+  Segment* volatile _first;       \/\/ The (start of the) list of all segments.\n+  Segment* _last;                 \/\/ The last segment of the list of all segments.\n+  volatile uint _num_segments;    \/\/ Number of assigned segments to this allocator.\n+  volatile size_t _mem_size;      \/\/ Memory used by all segments.\n+\n+  SegmentFreeList* _segment_free_list;   \/\/ The global free segment list to preferentially\n+                                      \/\/ get new segments from.\n+\n+  volatile uint _num_total_slots; \/\/ Number of slots available in all segments (allocated + not yet used).\n+  volatile uint _num_allocated_slots; \/\/ Number of total slots allocated ever (including free and pending).\n+\n+  inline Segment* new_segment(Segment* const prev);\n+\n+  DEBUG_ONLY(uint calculate_length() const;)\n+\n+public:\n+  const Segment* first_segment() const { return Atomic::load(&_first); }\n+\n+  uint num_total_slots() const { return Atomic::load(&_num_total_slots); }\n+  uint num_allocated_slots() const {\n+    uint allocated = Atomic::load(&_num_allocated_slots);\n+    assert(calculate_length() == allocated, \"Must be\");\n+    return allocated;\n+  }\n+\n+  uint slot_size() const;\n+\n+  G1MonotonicArena(const AllocOptions* alloc_options,\n+                   SegmentFreeList* segment_free_list);\n+  ~G1MonotonicArena();\n+\n+  \/\/ Deallocate all segments to the free segment list and reset this allocator. Must\n+  \/\/ be called in a globally synchronized area.\n+  void drop_all();\n+\n+  uint num_segments() const;\n+\n+  template<typename SegmentClosure>\n+  void iterate_segments(SegmentClosure& closure) const;\n+protected:\n+  void* allocate() override;\n+  \/\/ We do not deallocate individual slots\n+  void deallocate(void* slot) override { ShouldNotReachHere(); }\n+};\n+\n+\/\/ A single segment\/arena containing _num_slots blocks of memory of _slot_size.\n+\/\/ Segments can be linked together using a singly linked list.\n+class G1MonotonicArena::Segment {\n+  const uint _slot_size;\n+  const uint _num_slots;\n+  Segment* volatile _next;\n+  \/\/ Index into the next free slot to allocate into. Full if equal (or larger)\n+  \/\/ to _num_slots (can be larger because we atomically increment this value and\n+  \/\/ check only afterwards if the allocation has been successful).\n+  uint volatile _next_allocate;\n+  const MEMFLAGS _mem_flag;\n+\n+  char* _bottom;  \/\/ Actual data.\n+  \/\/ Do not add class member variables beyond this point\n+\n+  static size_t header_size() { return align_up(sizeof(Segment), DEFAULT_CACHE_LINE_SIZE); }\n+\n+  static size_t payload_size(uint slot_size, uint num_slots) {\n+    \/\/ The cast (size_t) is required to guard against overflow wrap around.\n+    return (size_t)slot_size * num_slots;\n+  }\n+\n+  size_t payload_size() const { return payload_size(_slot_size, _num_slots); }\n+\n+  NONCOPYABLE(Segment);\n+\n+  Segment(uint slot_size, uint num_slots, Segment* next, MEMFLAGS flag);\n+  ~Segment() = default;\n+public:\n+  Segment* volatile* next_addr() { return &_next; }\n+\n+  void* allocate_slot();\n+\n+  uint num_slots() const { return _num_slots; }\n+\n+  Segment* next() const { return _next; }\n+\n+  void set_next(Segment* next) {\n+    assert(next != this, \" loop condition\");\n+    _next = next;\n+  }\n+\n+  void reset(Segment* next) {\n+    _next_allocate = 0;\n+    assert(next != this, \" loop condition\");\n+    set_next(next);\n+    memset((void*)_bottom, 0, payload_size());\n+  }\n+\n+  uint slot_size() const { return _slot_size; }\n+\n+  size_t mem_size() const { return header_size() + payload_size(); }\n+\n+  uint length() const {\n+    \/\/ _next_allocate might grow larger than _num_slots in multi-thread environments\n+    \/\/ due to races.\n+    return MIN2(_next_allocate, _num_slots);\n+  }\n+\n+  static size_t size_in_bytes(uint slot_size, uint num_slots) {\n+    return header_size() + payload_size(slot_size, num_slots);\n+  }\n+\n+  static Segment* create_segment(uint slot_size, uint num_slots, Segment* next, MEMFLAGS mem_flag);\n+  static void delete_segment(Segment* segment);\n+\n+  \/\/ Copies the contents of this segment into the destination.\n+  void copy_to(void* dest) const {\n+    ::memcpy(dest, _bottom, length() * _slot_size);\n+  }\n+\n+  bool is_full() const { return _next_allocate >= _num_slots; }\n+};\n+\n+\n+\/\/ Set of (free) Segments. The assumed usage is that allocation\n+\/\/ to it and removal of segments is strictly separate, but every action may be\n+\/\/ performed by multiple threads concurrently.\n+\/\/ Counts and memory usage are current on a best-effort basis if accessed concurrently.\n+class G1MonotonicArena::SegmentFreeList {\n+  static Segment* volatile* next_ptr(Segment& segment) {\n+    return segment.next_addr();\n+  }\n+  using SegmentStack = LockFreeStack<Segment, &SegmentFreeList::next_ptr>;\n+\n+  SegmentStack _list;\n+\n+  volatile size_t _num_segments;\n+  volatile size_t _mem_size;\n+\n+public:\n+  SegmentFreeList() : _list(), _num_segments(0), _mem_size(0) { }\n+  ~SegmentFreeList() { free_all(); }\n+\n+  void bulk_add(Segment& first, Segment& last, size_t num, size_t mem_size);\n+\n+  Segment* get();\n+  Segment* get_all(size_t& num_segments, size_t& mem_size);\n+\n+  \/\/ Give back all memory to the OS.\n+  void free_all();\n+\n+  void print_on(outputStream* out, const char* prefix = \"\");\n+\n+  size_t num_segments() const { return Atomic::load(&_num_segments); }\n+  size_t mem_size() const { return Atomic::load(&_mem_size); }\n+};\n+\n+\/\/ Configuration for G1MonotonicArena, e.g slot size, slot number of next Segment.\n+class G1MonotonicArena::AllocOptions {\n+\n+protected:\n+  const MEMFLAGS _mem_flag;\n+  const uint _slot_size;\n+  const uint _initial_num_slots;\n+  \/\/ Defines a limit to the number of slots in the segment\n+  const uint _max_num_slots;\n+  const uint _slot_alignment;\n+\n+public:\n+  AllocOptions(MEMFLAGS mem_flag, uint slot_size, uint initial_num_slots, uint max_num_slots, uint alignment) :\n+    _mem_flag(mem_flag),\n+    _slot_size(align_up(slot_size, alignment)),\n+    _initial_num_slots(initial_num_slots),\n+    _max_num_slots(max_num_slots),\n+    _slot_alignment(alignment) {\n+    assert(_slot_size > 0, \"Must be\");\n+    assert(_initial_num_slots > 0, \"Must be\");\n+    assert(_max_num_slots > 0, \"Must be\");\n+    assert(_slot_alignment > 0, \"Must be\");\n+  }\n+\n+  virtual uint next_num_slots(uint prev_num_slots) const {\n+    return _initial_num_slots;\n+  }\n+\n+  uint slot_size() const { return _slot_size; }\n+\n+  uint slot_alignment() const { return _slot_alignment; }\n+\n+  MEMFLAGS mem_flag() const {return _mem_flag; }\n+};\n+\n+#endif \/\/SHARE_GC_G1_MONOTONICARENA_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArena.hpp","additions":258,"deletions":0,"binary":false,"changes":258,"status":"added"},{"patch":"@@ -0,0 +1,56 @@\n+\/*\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1MONOTONICARENA_INLINE_HPP\n+#define SHARE_GC_G1_G1MONOTONICARENA_INLINE_HPP\n+\n+#include \"gc\/g1\/g1MonotonicArena.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/globalCounter.inline.hpp\"\n+\n+inline void* G1MonotonicArena::Segment::allocate_slot() {\n+  if (_next_allocate >= _num_slots) {\n+    return nullptr;\n+  }\n+  uint result = Atomic::fetch_and_add(&_next_allocate, 1u, memory_order_relaxed);\n+  if (result >= _num_slots) {\n+    return nullptr;\n+  }\n+  void* r = _bottom + (size_t)result * _slot_size;\n+  return r;\n+}\n+\n+inline G1MonotonicArena::Segment* G1MonotonicArena::SegmentFreeList::get() {\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+\n+  Segment* result = _list.pop();\n+  if (result != nullptr) {\n+    Atomic::dec(&_num_segments, memory_order_relaxed);\n+    Atomic::sub(&_mem_size, result->mem_size(), memory_order_relaxed);\n+  }\n+  return result;\n+}\n+\n+#endif \/\/SHARE_GC_G1_G1MONOTONICARENA_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArena.inline.hpp","additions":56,"deletions":0,"binary":false,"changes":56,"status":"added"},{"patch":"@@ -0,0 +1,205 @@\n+\/*\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"ci\/ciUtilities.hpp\"\n+#include \"gc\/g1\/g1CardSetMemory.inline.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1MonotonicArenaFreeMemoryTask.hpp\"\n+#include \"gc\/g1\/g1_globals.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n+#include \"runtime\/os.hpp\"\n+\n+constexpr const char* G1MonotonicArenaFreeMemoryTask::_state_names[];\n+\n+const char* G1MonotonicArenaFreeMemoryTask::get_state_name(State value) const {\n+  return _state_names[static_cast<std::underlying_type_t<State>>(value)];\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::deadline_exceeded(jlong deadline) {\n+  return os::elapsed_counter() >= deadline;\n+}\n+\n+static size_t keep_size(size_t free, size_t used, double percent) {\n+  size_t to_keep = used * percent;\n+  return MIN2(free, to_keep);\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::calculate_return_infos(jlong deadline) {\n+  \/\/ Ignore the deadline in this step as it is very short.\n+\n+  G1MonotonicArenaMemoryStats used = _total_used;\n+  G1MonotonicArenaMemoryStats free = G1MonotonicArenaFreePool::free_list_sizes();\n+\n+  _return_info = new G1ReturnMemoryProcessorSet(used.num_pools());\n+  for (uint i = 0; i < used.num_pools(); i++) {\n+    size_t return_to_vm_size = keep_size(free._num_mem_sizes[i],\n+                                         used._num_mem_sizes[i],\n+                                         G1RemSetFreeMemoryKeepExcessRatio);\n+    log_trace(gc, task)(\"Monotonic Arena Free Memory: Type %s: Free: %zu (%zu) \"\n+                        \"Used: %zu Keep: %zu\",\n+                        G1CardSetConfiguration::mem_object_type_name_str(i),\n+                        free._num_mem_sizes[i], free._num_segments[i],\n+                        used._num_mem_sizes[i], return_to_vm_size);\n+\n+    _return_info->append(new G1ReturnMemoryProcessor(return_to_vm_size));\n+  }\n+\n+  G1MonotonicArenaFreePool::update_unlink_processors(_return_info);\n+  return false;\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::return_memory_to_vm(jlong deadline) {\n+  for (int i = 0; i < _return_info->length(); i++) {\n+    G1ReturnMemoryProcessor* info = _return_info->at(i);\n+    if (!info->finished_return_to_vm()) {\n+      if (info->return_to_vm(deadline)) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::return_memory_to_os(jlong deadline) {\n+  for (int i = 0; i < _return_info->length(); i++) {\n+    G1ReturnMemoryProcessor* info = _return_info->at(i);\n+    if (!info->finished_return_to_os()) {\n+      if (info->return_to_os(deadline)) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::cleanup_return_infos() {\n+  for (int i = 0; i < _return_info->length(); i++) {\n+     G1ReturnMemoryProcessor* info = _return_info->at(i);\n+     delete info;\n+  }\n+  delete _return_info;\n+\n+  _return_info = nullptr;\n+  return false;\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::free_excess_monotonic_arena_memory() {\n+  jlong start = os::elapsed_counter();\n+  jlong end = start +\n+              (os::elapsed_frequency() \/ 1000) * G1RemSetFreeMemoryStepDurationMillis;\n+\n+  log_trace(gc, task)(\"Monotonic Arena Free Memory: Step start %1.3f end %1.3f\",\n+                      TimeHelper::counter_to_millis(start), TimeHelper::counter_to_millis(end));\n+\n+  State next_state;\n+\n+  do {\n+    switch (_state) {\n+      case State::CalculateUsed: {\n+        if (calculate_return_infos(end)) {\n+          next_state = _state;\n+          return true;\n+        }\n+        next_state = State::ReturnToVM;\n+        break;\n+      }\n+      case State::ReturnToVM: {\n+        if (return_memory_to_vm(end)) {\n+          next_state = _state;\n+          return true;\n+        }\n+        next_state = State::ReturnToOS;\n+        break;\n+      }\n+      case State::ReturnToOS: {\n+        if (return_memory_to_os(end)) {\n+          next_state = _state;\n+          return true;\n+        }\n+        next_state = State::Cleanup;\n+        break;\n+      }\n+      case State::Cleanup: {\n+        cleanup_return_infos();\n+        next_state = State::Inactive;\n+        break;\n+      }\n+      default:\n+        log_error(gc, task)(\"Should not try to free excess monotonic area memory in %s state\", get_state_name(_state));\n+        ShouldNotReachHere();\n+        break;\n+    }\n+\n+    set_state(next_state);\n+  } while (_state != State::Inactive && !deadline_exceeded(end));\n+\n+  log_trace(gc, task)(\"Monotonic Arena Free Memory: Step took %1.3fms, done %s\",\n+                      TimeHelper::counter_to_millis(os::elapsed_counter() - start),\n+                      bool_to_str(_state == State::CalculateUsed));\n+\n+  return is_active();\n+}\n+\n+void G1MonotonicArenaFreeMemoryTask::set_state(State new_state) {\n+  log_trace(gc, task)(\"Monotonic Arena Free Memory: State change from %s to %s\",\n+                      get_state_name(_state),\n+                      get_state_name(new_state));\n+  _state = new_state;\n+}\n+\n+bool G1MonotonicArenaFreeMemoryTask::is_active() const {\n+  return _state != State::Inactive;\n+}\n+\n+jlong G1MonotonicArenaFreeMemoryTask::reschedule_delay_ms() const {\n+  return G1RemSetFreeMemoryRescheduleDelayMillis;\n+}\n+\n+G1MonotonicArenaFreeMemoryTask::G1MonotonicArenaFreeMemoryTask(const char* name) :\n+  G1ServiceTask(name), _state(State::CalculateUsed), _return_info(nullptr) { }\n+\n+void G1MonotonicArenaFreeMemoryTask::execute() {\n+  SuspendibleThreadSetJoiner sts;\n+\n+  if (free_excess_monotonic_arena_memory()) {\n+    schedule(reschedule_delay_ms());\n+  }\n+}\n+\n+void G1MonotonicArenaFreeMemoryTask::notify_new_stats(G1MonotonicArenaMemoryStats* young_gen_stats,\n+                                                      G1MonotonicArenaMemoryStats* collection_set_candidate_stats) {\n+  assert_at_safepoint_on_vm_thread();\n+\n+  _total_used = *young_gen_stats;\n+  _total_used.add(*collection_set_candidate_stats);\n+\n+  if (!is_active()) {\n+    set_state(State::CalculateUsed);\n+    G1CollectedHeap::heap()->service_thread()->schedule_task(this, 0);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArenaFreeMemoryTask.cpp","additions":205,"deletions":0,"binary":false,"changes":205,"status":"added"},{"patch":"@@ -0,0 +1,96 @@\n+\/*\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1MONOTONICARENAFREEMEMORYTASK_HPP\n+#define SHARE_GC_G1_G1MONOTONICARENAFREEMEMORYTASK_HPP\n+\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n+#include \"gc\/g1\/g1MonotonicArenaFreePool.hpp\"\n+#include \"gc\/g1\/g1ServiceThread.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"utilities\/growableArray.hpp\"\n+#include \"utilities\/ticks.hpp\"\n+\n+\/\/ Task handling deallocation of free G1MonotonicArena memory.\n+class G1MonotonicArenaFreeMemoryTask : public G1ServiceTask {\n+\n+  enum class State : uint {\n+    Inactive,\n+    CalculateUsed,\n+    ReturnToVM,\n+    ReturnToOS,\n+    Cleanup\n+  };\n+\n+  static constexpr const char* _state_names[] = { \"Invalid\",\n+                                                  \"CalculateUsed\",\n+                                                  \"ReturnToVM\",\n+                                                  \"ReturnToOS\",\n+                                                  \"Cleanup\" };\n+\n+  const char* get_state_name(State value) const;\n+\n+  State _state;\n+\n+  \/\/ Current total monotonic arena  memory usage.\n+  G1MonotonicArenaMemoryStats _total_used;\n+\n+  using G1ReturnMemoryProcessor = G1MonotonicArenaFreePool::G1ReturnMemoryProcessor;\n+  using G1ReturnMemoryProcessorSet = G1MonotonicArenaFreePool::G1ReturnMemoryProcessorSet;\n+\n+  G1ReturnMemoryProcessorSet* _return_info;\n+\n+  \/\/ Returns whether the given deadline has passed.\n+  bool deadline_exceeded(jlong deadline);\n+\n+  \/\/ Methods for the tasks to be done. They all return true if that step has\n+  \/\/ completed.\n+  bool calculate_return_infos(jlong deadline);\n+  bool return_memory_to_vm(jlong deadline);\n+  bool return_memory_to_os(jlong deadline);\n+  bool cleanup_return_infos();\n+\n+  \/\/ Free excess monotonic arena memory, main method. Returns true if there is more work\n+  \/\/ to do.\n+  bool free_excess_monotonic_arena_memory();\n+\n+  void set_state(State new_state);\n+  \/\/ Returns whether we are currently processing a recent request.\n+  bool is_active() const;\n+\n+  \/\/ The delay used to reschedule this task if not all work has been completed.\n+  jlong reschedule_delay_ms() const;\n+\n+public:\n+  explicit G1MonotonicArenaFreeMemoryTask(const char* name);\n+\n+  void execute() override;\n+\n+  \/\/ Notify the task of new used remembered set memory statistics for the young\n+  \/\/ generation and the collection set candidate sets.\n+  void notify_new_stats(G1MonotonicArenaMemoryStats* young_gen_stats,\n+                        G1MonotonicArenaMemoryStats* collection_set_candidate_stats);\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1MONOTONICARENAFREEMEMORYTASK_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArenaFreeMemoryTask.hpp","additions":96,"deletions":0,"binary":false,"changes":96,"status":"added"},{"patch":"@@ -0,0 +1,193 @@\n+\/*\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1MonotonicArena.inline.hpp\"\n+#include \"gc\/g1\/g1MonotonicArenaFreePool.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/os.hpp\"\n+#include \"utilities\/formatBuffer.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+\n+G1MonotonicArenaMemoryStats::G1MonotonicArenaMemoryStats() {\n+  clear();\n+}\n+\n+void G1MonotonicArenaMemoryStats::clear() {\n+  for (uint i = 0; i < num_pools(); i++) {\n+    _num_mem_sizes[i] = 0;\n+    _num_segments[i] = 0;\n+  }\n+}\n+\n+void G1MonotonicArenaFreePool::update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processor) {\n+  uint num_free_lists = _freelist_pool.num_free_lists();\n+\n+  for (uint i = 0; i < num_free_lists; i++) {\n+    unlink_processor->at(i)->visit_free_list(_freelist_pool.free_list(i));\n+  }\n+}\n+\n+void G1MonotonicArenaFreePool::G1ReturnMemoryProcessor::visit_free_list(G1MonotonicArena::SegmentFreeList* source) {\n+  assert(_source == nullptr, \"already visited\");\n+  if (_return_to_vm_size > 0) {\n+    _source = source;\n+  } else {\n+    assert(_source == nullptr, \"must be\");\n+  }\n+  if (source->mem_size() > _return_to_vm_size) {\n+    _first = source->get_all(_num_unlinked, _unlinked_bytes);\n+  } else {\n+    assert(_first == nullptr, \"must be\");\n+  }\n+  \/\/ Above we were racing with other threads getting the contents of the free list,\n+  \/\/ so while we might have been asked to return something to the OS initially,\n+  \/\/ the free list might be empty anyway. In this case just reset internal values\n+  \/\/ used for checking whether there is work available.\n+  if (_first == nullptr) {\n+    _source = nullptr;\n+    _return_to_vm_size = 0;\n+  }\n+}\n+\n+bool G1MonotonicArenaFreePool::G1ReturnMemoryProcessor::return_to_vm(jlong deadline) {\n+  assert(!finished_return_to_vm(), \"already returned everything to the VM\");\n+  assert(_first != nullptr, \"must have segment to return\");\n+\n+  size_t keep_size = 0;\n+  size_t keep_num = 0;\n+\n+  Segment* cur = _first;\n+  Segment* last = nullptr;\n+\n+  while (cur != nullptr && _return_to_vm_size > 0) {\n+    size_t cur_size = cur->mem_size();\n+    _return_to_vm_size -= MIN2(_return_to_vm_size, cur_size);\n+\n+    keep_size += cur_size;\n+    keep_num++;\n+\n+    last = cur;\n+    cur = cur->next();\n+    \/\/ To ensure progress, perform the deadline check here.\n+    if (os::elapsed_counter() > deadline) {\n+      break;\n+    }\n+  }\n+\n+  assert(_first != nullptr, \"must be\");\n+  assert(last != nullptr, \"must be\");\n+\n+  last->set_next(nullptr);\n+\n+  \/\/ Wait for any in-progress pops to avoid ABA for them.\n+  GlobalCounter::write_synchronize();\n+  _source->bulk_add(*_first, *last, keep_num, keep_size);\n+  _first = cur;\n+\n+  log_trace(gc, task)(\"Monotonic Arena Free Memory: Returned to VM %zu segments size %zu\", keep_num, keep_size);\n+\n+  \/\/ _return_to_vm_size may be larger than what is available in the list at the\n+  \/\/ time we actually get the list. I.e. the list and _return_to_vm_size may be\n+  \/\/ inconsistent.\n+  \/\/ So also check if we actually already at the end of the list for the exit\n+  \/\/ condition.\n+  if (_return_to_vm_size == 0 || _first == nullptr) {\n+    _source = nullptr;\n+    _return_to_vm_size = 0;\n+  }\n+  return _source != nullptr;\n+}\n+\n+bool G1MonotonicArenaFreePool::G1ReturnMemoryProcessor::return_to_os(jlong deadline) {\n+  assert(finished_return_to_vm(), \"not finished returning to VM\");\n+  assert(!finished_return_to_os(), \"already returned everything to the OS\");\n+\n+  \/\/ Now delete the rest.\n+  size_t num_delete = 0;\n+  size_t mem_size_deleted = 0;\n+\n+  while (_first != nullptr) {\n+    Segment* next = _first->next();\n+    num_delete++;\n+    mem_size_deleted += _first->mem_size();\n+    Segment::delete_segment(_first);\n+    _first = next;\n+\n+    \/\/ To ensure progress, perform the deadline check here.\n+    if (os::elapsed_counter() > deadline) {\n+      break;\n+    }\n+  }\n+\n+  log_trace(gc, task)(\"Monotonic Arena Free Memory: Return to OS %zu segments size %zu\", num_delete, mem_size_deleted);\n+\n+  return _first != nullptr;\n+}\n+\n+G1MonotonicArenaFreePool G1MonotonicArenaFreePool::_freelist_pool(G1CardSetConfiguration::num_mem_object_types());\n+\n+G1MonotonicArenaFreePool::G1MonotonicArenaFreePool(uint num_free_lists) :\n+  _num_free_lists(num_free_lists) {\n+\n+  _free_lists = NEW_C_HEAP_ARRAY(SegmentFreeList, _num_free_lists, mtGC);\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    new (&_free_lists[i]) SegmentFreeList();\n+  }\n+}\n+\n+G1MonotonicArenaFreePool::~G1MonotonicArenaFreePool() {\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    _free_lists[i].~SegmentFreeList();\n+  }\n+  FREE_C_HEAP_ARRAY(mtGC, _free_lists);\n+}\n+\n+G1MonotonicArenaMemoryStats G1MonotonicArenaFreePool::memory_sizes() const {\n+  G1MonotonicArenaMemoryStats free_list_stats;\n+  assert(free_list_stats.num_pools() == num_free_lists(), \"must be\");\n+  for (uint i = 0; i < num_free_lists(); i++) {\n+    free_list_stats._num_mem_sizes[i] = _free_lists[i].mem_size();\n+    free_list_stats._num_segments[i] = _free_lists[i].num_segments();\n+  }\n+  return free_list_stats;\n+}\n+\n+size_t G1MonotonicArenaFreePool::mem_size() const {\n+  size_t result = 0;\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    result += _free_lists[i].mem_size();\n+  }\n+  return result;\n+}\n+\n+void G1MonotonicArenaFreePool::print_on(outputStream* out) {\n+  out->print_cr(\"  Free Pool: size %zu\", free_list_pool()->mem_size());\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    FormatBuffer<> fmt(\"    %s\", G1CardSetConfiguration::mem_object_type_name_str(i));\n+    _free_lists[i].print_on(out, fmt);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArenaFreePool.cpp","additions":193,"deletions":0,"binary":false,"changes":193,"status":"added"},{"patch":"@@ -0,0 +1,129 @@\n+\/*\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1MONOTONICARENAFREEPOOL_HPP\n+#define SHARE_GC_G1_G1MONOTONICARENAFREEPOOL_HPP\n+\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"gc\/g1\/g1MonotonicArena.hpp\"\n+#include \"utilities\/growableArray.hpp\"\n+\n+\/\/ Statistics for a monotonic arena. Contains the number of segments and memory\n+\/\/ used for each. Note that statistics are typically not taken atomically so there\n+\/\/ can be inconsistencies. The user must be prepared for them.\n+class G1MonotonicArenaMemoryStats {\n+public:\n+\n+  size_t _num_mem_sizes[G1CardSetConfiguration::num_mem_object_types()];\n+  size_t _num_segments[G1CardSetConfiguration::num_mem_object_types()];\n+\n+  \/\/ Returns all-zero statistics.\n+  G1MonotonicArenaMemoryStats();\n+\n+  void add(G1MonotonicArenaMemoryStats const other) {\n+    STATIC_ASSERT(ARRAY_SIZE(_num_segments) == ARRAY_SIZE(_num_mem_sizes));\n+    for (uint i = 0; i < ARRAY_SIZE(_num_mem_sizes); i++) {\n+      _num_mem_sizes[i] += other._num_mem_sizes[i];\n+      _num_segments[i] += other._num_segments[i];\n+    }\n+  }\n+\n+  void clear();\n+\n+  uint num_pools() const { return G1CardSetConfiguration::num_mem_object_types(); }\n+};\n+\n+\/\/ A set of free lists holding freed segments for use by G1MonotonicArena,\n+\/\/ e.g. G1CardSetAllocators::_arena\n+class G1MonotonicArenaFreePool {\n+  using SegmentFreeList = G1MonotonicArena::SegmentFreeList;\n+  \/\/ The global free pool.\n+  static G1MonotonicArenaFreePool _freelist_pool;\n+\n+  const uint _num_free_lists;\n+  SegmentFreeList* _free_lists;\n+\n+public:\n+  static G1MonotonicArenaFreePool* free_list_pool() { return &_freelist_pool; }\n+  static G1MonotonicArenaMemoryStats free_list_sizes() { return _freelist_pool.memory_sizes(); }\n+\n+  class G1ReturnMemoryProcessor;\n+  typedef GrowableArrayCHeap<G1ReturnMemoryProcessor*, mtGC> G1ReturnMemoryProcessorSet;\n+\n+  static void update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processors);\n+\n+  explicit G1MonotonicArenaFreePool(uint num_free_lists);\n+  ~G1MonotonicArenaFreePool();\n+\n+  SegmentFreeList* free_list(uint i) {\n+    assert(i < _num_free_lists, \"must be\");\n+    return &_free_lists[i];\n+  }\n+\n+  uint num_free_lists() const { return _num_free_lists; }\n+\n+  G1MonotonicArenaMemoryStats memory_sizes() const;\n+  size_t mem_size() const;\n+\n+  void print_on(outputStream* out);\n+};\n+\n+\/\/ Data structure containing current in-progress state for returning memory to the\n+\/\/ operating system for a single G1SegmentFreeList.\n+class G1MonotonicArenaFreePool::G1ReturnMemoryProcessor : public CHeapObj<mtGC> {\n+  using SegmentFreeList = G1MonotonicArena::SegmentFreeList;\n+  using Segment = G1MonotonicArena::Segment;\n+  SegmentFreeList* _source;\n+  size_t _return_to_vm_size;\n+\n+  Segment* _first;\n+  size_t _unlinked_bytes;\n+  size_t _num_unlinked;\n+\n+public:\n+  explicit G1ReturnMemoryProcessor(size_t return_to_vm) :\n+    _source(nullptr), _return_to_vm_size(return_to_vm), _first(nullptr), _unlinked_bytes(0), _num_unlinked(0) {\n+  }\n+\n+  \/\/ Updates the instance members about the given free list for\n+  \/\/ the purpose of giving back memory. Only necessary members are updated,\n+  \/\/ e.g. if there is nothing to return to the VM, do not set the source list.\n+  void visit_free_list(SegmentFreeList* source);\n+\n+  bool finished_return_to_vm() const { return _return_to_vm_size == 0; }\n+  bool finished_return_to_os() const { return _first == nullptr; }\n+\n+  \/\/ Returns memory to the VM until the given deadline expires. Returns true if\n+  \/\/ there is no more work. Guarantees forward progress, i.e. at least one segment\n+  \/\/ has been processed after returning.\n+  \/\/ return_to_vm() re-adds segments to the respective free list.\n+  bool return_to_vm(jlong deadline);\n+  \/\/ Returns memory to the VM until the given deadline expires. Returns true if\n+  \/\/ there is no more work. Guarantees forward progress, i.e. at least one segment\n+  \/\/ has been processed after returning.\n+  \/\/ return_to_os() gives back segments to the OS.\n+  bool return_to_os(jlong deadline);\n+};\n+\n+#endif \/\/SHARE_GC_G1_G1MONOTONICARENAFREEPOOL_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1MonotonicArenaFreePool.hpp","additions":129,"deletions":0,"binary":false,"changes":129,"status":"added"},{"patch":"@@ -1,252 +0,0 @@\n-\/*\n- * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-\n-#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"runtime\/atomic.hpp\"\n-#include \"runtime\/vmOperations.hpp\"\n-#include \"utilities\/globalCounter.inline.hpp\"\n-\n-G1SegmentedArraySegment::G1SegmentedArraySegment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next, MEMFLAGS flag) :\n-  _slot_size(slot_size),\n-  _num_slots(num_slots),\n-  _next(next),\n-  _next_allocate(0),\n-  _mem_flag(flag) {\n-  _bottom = ((char*) this) + header_size();\n-}\n-\n-G1SegmentedArraySegment* G1SegmentedArraySegment::create_segment(uint slot_size,\n-                                                                 uint num_slots,\n-                                                                 G1SegmentedArraySegment* next,\n-                                                                 MEMFLAGS mem_flag) {\n-  size_t block_size = size_in_bytes(slot_size, num_slots);\n-  char* alloc_block = NEW_C_HEAP_ARRAY(char, block_size, mem_flag);\n-  return new (alloc_block) G1SegmentedArraySegment(slot_size, num_slots, next, mem_flag);\n-}\n-\n-void G1SegmentedArraySegment::delete_segment(G1SegmentedArraySegment* segment) {\n-  \/\/ Wait for concurrent readers of the segment to exit before freeing; but only if the VM\n-  \/\/ isn't exiting.\n-  if (!VM_Exit::vm_exited()) {\n-    GlobalCounter::write_synchronize();\n-  }\n-  segment->~G1SegmentedArraySegment();\n-  FREE_C_HEAP_ARRAY(_mem_flag, segment);\n-}\n-\n-void G1SegmentedArrayFreeList::bulk_add(G1SegmentedArraySegment& first,\n-                                        G1SegmentedArraySegment& last,\n-                                        size_t num,\n-                                        size_t mem_size) {\n-  _list.prepend(first, last);\n-  Atomic::add(&_num_segments, num, memory_order_relaxed);\n-  Atomic::add(&_mem_size, mem_size, memory_order_relaxed);\n-}\n-\n-void G1SegmentedArrayFreeList::print_on(outputStream* out, const char* prefix) {\n-  out->print_cr(\"%s: segments %zu size %zu\",\n-                prefix, Atomic::load(&_num_segments), Atomic::load(&_mem_size));\n-}\n-\n-G1SegmentedArraySegment* G1SegmentedArrayFreeList::get_all(size_t& num_segments,\n-                                                           size_t& mem_size) {\n-  GlobalCounter::CriticalSection cs(Thread::current());\n-\n-  G1SegmentedArraySegment* result = _list.pop_all();\n-  num_segments = Atomic::load(&_num_segments);\n-  mem_size = Atomic::load(&_mem_size);\n-\n-  if (result != nullptr) {\n-    Atomic::sub(&_num_segments, num_segments, memory_order_relaxed);\n-    Atomic::sub(&_mem_size, mem_size, memory_order_relaxed);\n-  }\n-  return result;\n-}\n-\n-void G1SegmentedArrayFreeList::free_all() {\n-  size_t num_freed = 0;\n-  size_t mem_size_freed = 0;\n-  G1SegmentedArraySegment* cur;\n-\n-  while ((cur = _list.pop()) != nullptr) {\n-    mem_size_freed += cur->mem_size();\n-    num_freed++;\n-    G1SegmentedArraySegment::delete_segment(cur);\n-  }\n-\n-  Atomic::sub(&_num_segments, num_freed, memory_order_relaxed);\n-  Atomic::sub(&_mem_size, mem_size_freed, memory_order_relaxed);\n-}\n-\n-G1SegmentedArraySegment* G1SegmentedArray::create_new_segment(G1SegmentedArraySegment* const prev) {\n-  \/\/ Take an existing segment if available.\n-  G1SegmentedArraySegment* next = _free_segment_list->get();\n-  if (next == nullptr) {\n-    uint prev_num_slots = (prev != nullptr) ? prev->num_slots() : 0;\n-    uint num_slots = _alloc_options->next_num_slots(prev_num_slots);\n-\n-    next = G1SegmentedArraySegment::create_segment(slot_size(), num_slots, prev, _alloc_options->mem_flag());\n-  } else {\n-    assert(slot_size() == next->slot_size() ,\n-           \"Mismatch %d != %d\", slot_size(), next->slot_size());\n-    next->reset(prev);\n-  }\n-\n-  \/\/ Install it as current allocation segment.\n-  G1SegmentedArraySegment* old = Atomic::cmpxchg(&_first, prev, next);\n-  if (old != prev) {\n-    \/\/ Somebody else installed the segment, use that one.\n-    G1SegmentedArraySegment::delete_segment(next);\n-    return old;\n-  } else {\n-    \/\/ Did we install the first segment in the list? If so, this is also the last.\n-    if (prev == nullptr) {\n-      _last = next;\n-    }\n-    \/\/ Successfully installed the segment into the list.\n-    Atomic::inc(&_num_segments, memory_order_relaxed);\n-    Atomic::add(&_mem_size, next->mem_size(), memory_order_relaxed);\n-    Atomic::add(&_num_total_slots, next->num_slots(), memory_order_relaxed);\n-    return next;\n-  }\n-}\n-\n-G1SegmentedArray::G1SegmentedArray(const G1SegmentedArrayAllocOptions* alloc_options,\n-                                   G1SegmentedArrayFreeList* free_segment_list) :\n-  _alloc_options(alloc_options),\n-  _first(nullptr),\n-  _last(nullptr),\n-  _num_segments(0),\n-  _mem_size(0),\n-  _free_segment_list(free_segment_list),\n-  _num_total_slots(0),\n-  _num_allocated_slots(0) {\n-  assert(_free_segment_list != nullptr, \"precondition!\");\n-}\n-\n-G1SegmentedArray::~G1SegmentedArray() {\n-  drop_all();\n-}\n-\n-uint G1SegmentedArray::slot_size() const {\n-  return _alloc_options->slot_size();\n-}\n-\n-void G1SegmentedArray::drop_all() {\n-  G1SegmentedArraySegment* cur = Atomic::load_acquire(&_first);\n-\n-  if (cur != nullptr) {\n-    assert(_last != nullptr, \"If there is at least one segment, there must be a last one.\");\n-\n-    G1SegmentedArraySegment* first = cur;\n-#ifdef ASSERT\n-    \/\/ Check list consistency.\n-    G1SegmentedArraySegment* last = cur;\n-    uint num_segments = 0;\n-    size_t mem_size = 0;\n-    while (cur != nullptr) {\n-      mem_size += cur->mem_size();\n-      num_segments++;\n-\n-      G1SegmentedArraySegment* next = cur->next();\n-      last = cur;\n-      cur = next;\n-    }\n-#endif\n-    assert(num_segments == _num_segments, \"Segment count inconsistent %u %u\", num_segments, _num_segments);\n-    assert(mem_size == _mem_size, \"Memory size inconsistent\");\n-    assert(last == _last, \"Inconsistent last segment\");\n-\n-    _free_segment_list->bulk_add(*first, *_last, _num_segments, _mem_size);\n-  }\n-\n-  _first = nullptr;\n-  _last = nullptr;\n-  _num_segments = 0;\n-  _mem_size = 0;\n-  _num_total_slots = 0;\n-  _num_allocated_slots = 0;\n-}\n-\n-void* G1SegmentedArray::allocate() {\n-  assert(slot_size() > 0, \"instance size not set.\");\n-\n-  G1SegmentedArraySegment* cur = Atomic::load_acquire(&_first);\n-  if (cur == nullptr) {\n-    cur = create_new_segment(cur);\n-  }\n-\n-  while (true) {\n-    void* slot = cur->get_new_slot();\n-    if (slot != nullptr) {\n-      Atomic::inc(&_num_allocated_slots, memory_order_relaxed);\n-      guarantee(is_aligned(slot, _alloc_options->slot_alignment()),\n-                \"result \" PTR_FORMAT \" not aligned at %u\", p2i(slot), _alloc_options->slot_alignment());\n-      return slot;\n-    }\n-    \/\/ The segment is full. Next round.\n-    assert(cur->is_full(), \"must be\");\n-    cur = create_new_segment(cur);\n-  }\n-}\n-\n-uint G1SegmentedArray::num_segments() const {\n-  return Atomic::load(&_num_segments);\n-}\n-\n-#ifdef ASSERT\n-class LengthClosure {\n-  uint _total;\n-public:\n-  LengthClosure() : _total(0) {}\n-  void do_segment(G1SegmentedArraySegment* segment, uint limit) {\n-    _total += limit;\n-  }\n-  uint length() const {\n-    return _total;\n-  }\n-};\n-\n-uint G1SegmentedArray::calculate_length() const {\n-  LengthClosure closure;\n-  iterate_segments(closure);\n-  return closure.length();\n-}\n-#endif\n-\n-template <typename SegmentClosure>\n-void G1SegmentedArray::iterate_segments(SegmentClosure& closure) const {\n-  G1SegmentedArraySegment* cur = Atomic::load_acquire(&_first);\n-\n-  assert((cur != nullptr) == (_last != nullptr),\n-         \"If there is at least one segment, there must be a last one\");\n-\n-  while (cur != nullptr) {\n-    closure.do_segment(cur, cur->length());\n-    cur = cur->next();\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.cpp","additions":0,"deletions":252,"binary":false,"changes":252,"status":"deleted"},{"patch":"@@ -1,257 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1SEGMENTEDARRAY_HPP\n-#define SHARE_GC_G1_G1SEGMENTEDARRAY_HPP\n-\n-#include \"gc\/shared\/freeListAllocator.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/lockFreeStack.hpp\"\n-\n-\/\/ A single segment\/arena containing _num_slots blocks of memory of _slot_size.\n-\/\/ G1SegmentedArraySegments can be linked together using a singly linked list.\n-class G1SegmentedArraySegment {\n-  const uint _slot_size;\n-  const uint _num_slots;\n-  G1SegmentedArraySegment* volatile _next;\n-  \/\/ Index into the next free slot to allocate into. Full if equal (or larger)\n-  \/\/ to _num_slots (can be larger because we atomically increment this value and\n-  \/\/ check only afterwards if the allocation has been successful).\n-  uint volatile _next_allocate;\n-  const MEMFLAGS _mem_flag;\n-\n-  char* _bottom;  \/\/ Actual data.\n-  \/\/ Do not add class member variables beyond this point\n-\n-  static size_t header_size() { return align_up(sizeof(G1SegmentedArraySegment), DEFAULT_CACHE_LINE_SIZE); }\n-\n-  static size_t payload_size(uint slot_size, uint num_slots) {\n-    \/\/ The cast (size_t) is required to guard against overflow wrap around.\n-    return (size_t)slot_size * num_slots;\n-  }\n-\n-  size_t payload_size() const { return payload_size(_slot_size, _num_slots); }\n-\n-  NONCOPYABLE(G1SegmentedArraySegment);\n-\n-  G1SegmentedArraySegment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next, MEMFLAGS flag);\n-  ~G1SegmentedArraySegment() = default;\n-public:\n-  G1SegmentedArraySegment* volatile* next_addr() { return &_next; }\n-\n-  void* get_new_slot();\n-\n-  uint num_slots() const { return _num_slots; }\n-\n-  G1SegmentedArraySegment* next() const { return _next; }\n-\n-  void set_next(G1SegmentedArraySegment* next) {\n-    assert(next != this, \" loop condition\");\n-    _next = next;\n-  }\n-\n-  void reset(G1SegmentedArraySegment* next) {\n-    _next_allocate = 0;\n-    assert(next != this, \" loop condition\");\n-    set_next(next);\n-    memset((void*)_bottom, 0, payload_size());\n-  }\n-\n-  uint slot_size() const { return _slot_size; }\n-\n-  size_t mem_size() const { return header_size() + payload_size(); }\n-\n-  uint length() const {\n-    \/\/ _next_allocate might grow larger than _num_slots in multi-thread environments\n-    \/\/ due to races.\n-    return MIN2(_next_allocate, _num_slots);\n-  }\n-\n-  static size_t size_in_bytes(uint slot_size, uint num_slots) {\n-    return header_size() + payload_size(slot_size, num_slots);\n-  }\n-\n-  static G1SegmentedArraySegment* create_segment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next, MEMFLAGS mem_flag);\n-  static void delete_segment(G1SegmentedArraySegment* segment);\n-\n-  \/\/ Copies the (valid) contents of this segment into the destination.\n-  void copy_to(void* dest) const {\n-    ::memcpy(dest, _bottom, length() * _slot_size);\n-  }\n-\n-  bool is_full() const { return _next_allocate >= _num_slots; }\n-};\n-\n-\/\/ Set of (free) G1SegmentedArraySegments. The assumed usage is that allocation\n-\/\/ to it and removal of segments is strictly separate, but every action may be\n-\/\/ performed by multiple threads at the same time.\n-\/\/ Counts and memory usage are current on a best-effort basis if accessed concurrently.\n-class G1SegmentedArrayFreeList {\n-  static G1SegmentedArraySegment* volatile* next_ptr(G1SegmentedArraySegment& segment) {\n-    return segment.next_addr();\n-  }\n-  using SegmentStack = LockFreeStack<G1SegmentedArraySegment, &G1SegmentedArrayFreeList::next_ptr>;\n-\n-  SegmentStack _list;\n-\n-  volatile size_t _num_segments;\n-  volatile size_t _mem_size;\n-\n-public:\n-  G1SegmentedArrayFreeList() : _list(), _num_segments(0), _mem_size(0) { }\n-  ~G1SegmentedArrayFreeList() { free_all(); }\n-\n-  void bulk_add(G1SegmentedArraySegment& first, G1SegmentedArraySegment& last, size_t num, size_t mem_size);\n-\n-  G1SegmentedArraySegment* get();\n-  G1SegmentedArraySegment* get_all(size_t& num_segments, size_t& mem_size);\n-\n-  \/\/ Give back all memory to the OS.\n-  void free_all();\n-\n-  void print_on(outputStream* out, const char* prefix = \"\");\n-\n-  size_t num_segments() const { return Atomic::load(&_num_segments); }\n-  size_t mem_size() const { return Atomic::load(&_mem_size); }\n-};\n-\n-\/\/ Configuration for G1SegmentedArray, e.g slot size, slot number of next G1SegmentedArraySegment.\n-class G1SegmentedArrayAllocOptions {\n-\n-protected:\n-  const MEMFLAGS _mem_flag;\n-  const uint _slot_size;\n-  const uint _initial_num_slots;\n-  \/\/ Defines a limit to the number of slots in the segment\n-  const uint _max_num_slots;\n-  const uint _slot_alignment;\n-\n-public:\n-  G1SegmentedArrayAllocOptions(MEMFLAGS mem_flag, uint slot_size, uint initial_num_slots, uint max_num_slots, uint alignment) :\n-    _mem_flag(mem_flag),\n-    _slot_size(align_up(slot_size, alignment)),\n-    _initial_num_slots(initial_num_slots),\n-    _max_num_slots(max_num_slots),\n-    _slot_alignment(alignment) {\n-    assert(_slot_size > 0, \"Must be\");\n-    assert(_initial_num_slots > 0, \"Must be\");\n-    assert(_max_num_slots > 0, \"Must be\");\n-    assert(_slot_alignment > 0, \"Must be\");\n-  }\n-\n-  virtual uint next_num_slots(uint prev_num_slots) const {\n-    return _initial_num_slots;\n-  }\n-\n-  uint slot_size() const { return _slot_size; }\n-\n-  uint slot_alignment() const { return _slot_alignment; }\n-\n-  MEMFLAGS mem_flag() const {return _mem_flag; }\n-};\n-\n-\/\/ A segmented array where G1SegmentedArraySegment is the segment, and\n-\/\/ G1SegmentedArrayFreeList is the free list to cache G1SegmentedArraySegments,\n-\/\/ and G1SegmentedArrayAllocOptions is the configuration for G1SegmentedArray\n-\/\/ attributes.\n-\/\/\n-\/\/ Implementation details as below:\n-\/\/\n-\/\/ Arena-like allocator for (card set, or ...) heap memory objects (Slot slots).\n-\/\/\n-\/\/ Actual allocation from the C heap occurs on G1SegmentedArraySegment basis, i.e. segments\n-\/\/ of slots. The assumed allocation pattern for these G1SegmentedArraySegment slots\n-\/\/ is assumed to be strictly two-phased:\n-\/\/\n-\/\/ - in the first phase, G1SegmentedArraySegments are allocated from the C heap (or a free\n-\/\/ list given at initialization time). This allocation may occur in parallel. This\n-\/\/ typically corresponds to a single mutator phase, but may extend over multiple.\n-\/\/\n-\/\/ - in the second phase, G1SegmentedArraySegments are given back in bulk to the free list.\n-\/\/ This is typically done during a GC pause.\n-\/\/\n-\/\/ Some third party is responsible for giving back memory from the free list to\n-\/\/ the operating system.\n-\/\/\n-\/\/ Allocation and deallocation in the first phase basis may occur by multiple threads at once.\n-\/\/\n-\/\/ The class also manages a few counters for statistics using atomic operations.\n-\/\/ Their values are only consistent within each other with extra global\n-\/\/ synchronization.\n-\n-class G1SegmentedArray : public FreeListConfig  {\n-  \/\/ G1SegmentedArrayAllocOptions provides parameters for allocation segment\n-  \/\/ sizing and expansion.\n-  const G1SegmentedArrayAllocOptions* _alloc_options;\n-\n-  G1SegmentedArraySegment* volatile _first;       \/\/ The (start of the) list of all segments.\n-  G1SegmentedArraySegment* _last;                 \/\/ The last segment of the list of all segments.\n-  volatile uint _num_segments;                    \/\/ Number of assigned segments to this allocator.\n-  volatile size_t _mem_size;                      \/\/ Memory used by all segments.\n-\n-  G1SegmentedArrayFreeList* _free_segment_list;   \/\/ The global free segment list to preferentially\n-                                                  \/\/ get new segments from.\n-\n-  volatile uint _num_total_slots; \/\/ Number of slots available in all segments (allocated + not yet used).\n-  volatile uint _num_allocated_slots; \/\/ Number of total slots allocated ever (including free and pending).\n-\n-private:\n-  inline G1SegmentedArraySegment* create_new_segment(G1SegmentedArraySegment* const prev);\n-\n-  DEBUG_ONLY(uint calculate_length() const;)\n-\n-public:\n-  const G1SegmentedArraySegment* first_array_segment() const { return Atomic::load(&_first); }\n-\n-  uint num_total_slots() const { return Atomic::load(&_num_total_slots); }\n-  uint num_allocated_slots() const {\n-    uint allocated = Atomic::load(&_num_allocated_slots);\n-    assert(calculate_length() == allocated, \"Must be\");\n-    return allocated;\n-  }\n-\n-  uint slot_size() const;\n-\n-  G1SegmentedArray(const G1SegmentedArrayAllocOptions* alloc_options,\n-                   G1SegmentedArrayFreeList* free_segment_list);\n-  ~G1SegmentedArray();\n-\n-  \/\/ Deallocate all segments to the free segment list and reset this allocator. Must\n-  \/\/ be called in a globally synchronized area.\n-  void drop_all();\n-\n-  inline void* allocate() override;\n-\n-  \/\/ We do not deallocate individual slots\n-  inline void deallocate(void* node) override { ShouldNotReachHere(); }\n-\n-  uint num_segments() const;\n-\n-  template<typename SegmentClosure>\n-  void iterate_segments(SegmentClosure& closure) const;\n-};\n-\n-#endif \/\/SHARE_GC_G1_G1SEGMENTEDARRAY_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.hpp","additions":0,"deletions":257,"binary":false,"changes":257,"status":"deleted"},{"patch":"@@ -1,56 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2021, 2022, Huawei Technologies Co., Ltd. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1SEGMENTEDARRAY_INLINE_HPP\n-#define SHARE_GC_G1_G1SEGMENTEDARRAY_INLINE_HPP\n-\n-#include \"gc\/g1\/g1SegmentedArray.hpp\"\n-#include \"runtime\/atomic.hpp\"\n-#include \"utilities\/globalCounter.inline.hpp\"\n-\n-inline void* G1SegmentedArraySegment::get_new_slot() {\n-  if (_next_allocate >= _num_slots) {\n-    return nullptr;\n-  }\n-  uint result = Atomic::fetch_and_add(&_next_allocate, 1u, memory_order_relaxed);\n-  if (result >= _num_slots) {\n-    return nullptr;\n-  }\n-  void* r = _bottom + (size_t)result * _slot_size;\n-  return r;\n-}\n-\n-inline G1SegmentedArraySegment* G1SegmentedArrayFreeList::get() {\n-  GlobalCounter::CriticalSection cs(Thread::current());\n-\n-  G1SegmentedArraySegment* result = _list.pop();\n-  if (result != nullptr) {\n-    Atomic::dec(&_num_segments, memory_order_relaxed);\n-    Atomic::sub(&_mem_size, result->mem_size(), memory_order_relaxed);\n-  }\n-  return result;\n-}\n-\n-#endif \/\/SHARE_GC_G1_G1SEGMENTEDARRAY_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.inline.hpp","additions":0,"deletions":56,"binary":false,"changes":56,"status":"deleted"},{"patch":"@@ -1,205 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"ci\/ciUtilities.hpp\"\n-#include \"gc\/g1\/g1CardSetMemory.inline.hpp\"\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n-#include \"gc\/g1\/g1SegmentedArrayFreeMemoryTask.hpp\"\n-#include \"gc\/g1\/g1_globals.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n-#include \"gc\/shared\/gc_globals.hpp\"\n-#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n-#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n-#include \"runtime\/os.hpp\"\n-\n-constexpr const char* G1SegmentedArrayFreeMemoryTask::_state_names[];\n-\n-const char* G1SegmentedArrayFreeMemoryTask::get_state_name(State value) const {\n-  return _state_names[static_cast<std::underlying_type_t<State>>(value)];\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::deadline_exceeded(jlong deadline) {\n-  return os::elapsed_counter() >= deadline;\n-}\n-\n-static size_t keep_size(size_t free, size_t used, double percent) {\n-  size_t to_keep = used * percent;\n-  return MIN2(free, to_keep);\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::calculate_return_infos(jlong deadline) {\n-  \/\/ Ignore the deadline in this step as it is very short.\n-\n-  G1SegmentedArrayMemoryStats used = _total_used;\n-  G1SegmentedArrayMemoryStats free = G1SegmentedArrayFreePool::free_list_sizes();\n-\n-  _return_info = new G1ReturnMemoryProcessorSet(used.num_pools());\n-  for (uint i = 0; i < used.num_pools(); i++) {\n-    size_t return_to_vm_size = keep_size(free._num_mem_sizes[i],\n-                                         used._num_mem_sizes[i],\n-                                         G1RemSetFreeMemoryKeepExcessRatio);\n-    log_trace(gc, task)(\"Segmented Array Free Memory: Type %s: Free: %zu (%zu) \"\n-                        \"Used: %zu Keep: %zu\",\n-                        G1CardSetConfiguration::mem_object_type_name_str(i),\n-                        free._num_mem_sizes[i], free._num_segments[i],\n-                        used._num_mem_sizes[i], return_to_vm_size);\n-\n-    _return_info->append(new G1ReturnMemoryProcessor(return_to_vm_size));\n-  }\n-\n-  G1SegmentedArrayFreePool::update_unlink_processors(_return_info);\n-  return false;\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::return_memory_to_vm(jlong deadline) {\n-  for (int i = 0; i < _return_info->length(); i++) {\n-    G1ReturnMemoryProcessor* info = _return_info->at(i);\n-    if (!info->finished_return_to_vm()) {\n-      if (info->return_to_vm(deadline)) {\n-        return true;\n-      }\n-    }\n-  }\n-  return false;\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::return_memory_to_os(jlong deadline) {\n-  for (int i = 0; i < _return_info->length(); i++) {\n-    G1ReturnMemoryProcessor* info = _return_info->at(i);\n-    if (!info->finished_return_to_os()) {\n-      if (info->return_to_os(deadline)) {\n-        return true;\n-      }\n-    }\n-  }\n-  return false;\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::cleanup_return_infos() {\n-  for (int i = 0; i < _return_info->length(); i++) {\n-     G1ReturnMemoryProcessor* info = _return_info->at(i);\n-     delete info;\n-  }\n-  delete _return_info;\n-\n-  _return_info = nullptr;\n-  return false;\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::free_excess_segmented_array_memory() {\n-  jlong start = os::elapsed_counter();\n-  jlong end = start +\n-              (os::elapsed_frequency() \/ 1000) * G1RemSetFreeMemoryStepDurationMillis;\n-\n-  log_trace(gc, task)(\"Segmented Array Free Memory: Step start %1.3f end %1.3f\",\n-                      TimeHelper::counter_to_millis(start), TimeHelper::counter_to_millis(end));\n-\n-  State next_state;\n-\n-  do {\n-    switch (_state) {\n-      case State::CalculateUsed: {\n-        if (calculate_return_infos(end)) {\n-          next_state = _state;\n-          return true;\n-        }\n-        next_state = State::ReturnToVM;\n-        break;\n-      }\n-      case State::ReturnToVM: {\n-        if (return_memory_to_vm(end)) {\n-          next_state = _state;\n-          return true;\n-        }\n-        next_state = State::ReturnToOS;\n-        break;\n-      }\n-      case State::ReturnToOS: {\n-        if (return_memory_to_os(end)) {\n-          next_state = _state;\n-          return true;\n-        }\n-        next_state = State::Cleanup;\n-        break;\n-      }\n-      case State::Cleanup: {\n-        cleanup_return_infos();\n-        next_state = State::Inactive;\n-        break;\n-      }\n-      default:\n-        log_error(gc, task)(\"Should not try to free excess segmented array memory in %s state\", get_state_name(_state));\n-        ShouldNotReachHere();\n-        break;\n-    }\n-\n-    set_state(next_state);\n-  } while (_state != State::Inactive && !deadline_exceeded(end));\n-\n-  log_trace(gc, task)(\"Segmented Array Free Memory: Step took %1.3fms, done %s\",\n-                      TimeHelper::counter_to_millis(os::elapsed_counter() - start),\n-                      bool_to_str(_state == State::CalculateUsed));\n-\n-  return is_active();\n-}\n-\n-void G1SegmentedArrayFreeMemoryTask::set_state(State new_state) {\n-  log_trace(gc, task)(\"Segmented Array Free Memory: State change from %s to %s\",\n-                      get_state_name(_state),\n-                      get_state_name(new_state));\n-  _state = new_state;\n-}\n-\n-bool G1SegmentedArrayFreeMemoryTask::is_active() const {\n-  return _state != State::Inactive;\n-}\n-\n-jlong G1SegmentedArrayFreeMemoryTask::reschedule_delay_ms() const {\n-  return G1RemSetFreeMemoryRescheduleDelayMillis;\n-}\n-\n-G1SegmentedArrayFreeMemoryTask::G1SegmentedArrayFreeMemoryTask(const char* name) :\n-  G1ServiceTask(name), _state(State::CalculateUsed), _return_info(nullptr) { }\n-\n-void G1SegmentedArrayFreeMemoryTask::execute() {\n-  SuspendibleThreadSetJoiner sts;\n-\n-  if (free_excess_segmented_array_memory()) {\n-    schedule(reschedule_delay_ms());\n-  }\n-}\n-\n-void G1SegmentedArrayFreeMemoryTask::notify_new_stats(G1SegmentedArrayMemoryStats* young_gen_stats,\n-                                                      G1SegmentedArrayMemoryStats* collection_set_candidate_stats) {\n-  assert_at_safepoint_on_vm_thread();\n-\n-  _total_used = *young_gen_stats;\n-  _total_used.add(*collection_set_candidate_stats);\n-\n-  if (!is_active()) {\n-    set_state(State::CalculateUsed);\n-    G1CollectedHeap::heap()->service_thread()->schedule_task(this, 0);\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreeMemoryTask.cpp","additions":0,"deletions":205,"binary":false,"changes":205,"status":"deleted"},{"patch":"@@ -1,96 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1SEGMENTEDARRAYFREEMEMORYTASK_HPP\n-#define SHARE_GC_G1_G1SEGMENTEDARRAYFREEMEMORYTASK_HPP\n-\n-#include \"gc\/g1\/g1CardSetMemory.hpp\"\n-#include \"gc\/g1\/g1SegmentedArrayFreePool.hpp\"\n-#include \"gc\/g1\/g1ServiceThread.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n-#include \"utilities\/growableArray.hpp\"\n-#include \"utilities\/ticks.hpp\"\n-\n-\/\/ Task handling deallocation of free segmented array memory.\n-class G1SegmentedArrayFreeMemoryTask : public G1ServiceTask {\n-\n-  enum class State : uint {\n-    Inactive,\n-    CalculateUsed,\n-    ReturnToVM,\n-    ReturnToOS,\n-    Cleanup\n-  };\n-\n-  static constexpr const char* _state_names[] = { \"Invalid\",\n-                                                  \"CalculateUsed\",\n-                                                  \"ReturnToVM\",\n-                                                  \"ReturnToOS\",\n-                                                  \"Cleanup\" };\n-\n-  const char* get_state_name(State value) const;\n-\n-  State _state;\n-\n-  \/\/ Current total segmented array memory usage.\n-  G1SegmentedArrayMemoryStats _total_used;\n-\n-  using G1ReturnMemoryProcessor = G1SegmentedArrayFreePool::G1ReturnMemoryProcessor;\n-  using G1ReturnMemoryProcessorSet = G1SegmentedArrayFreePool::G1ReturnMemoryProcessorSet;\n-\n-  G1ReturnMemoryProcessorSet* _return_info;\n-\n-  \/\/ Returns whether the given deadline has passed.\n-  bool deadline_exceeded(jlong deadline);\n-\n-  \/\/ Methods for the tasks to be done. They all return true if that step has\n-  \/\/ completed.\n-  bool calculate_return_infos(jlong deadline);\n-  bool return_memory_to_vm(jlong deadline);\n-  bool return_memory_to_os(jlong deadline);\n-  bool cleanup_return_infos();\n-\n-  \/\/ Free excess segmented array memory, main method. Returns true if there is more work\n-  \/\/ to do.\n-  bool free_excess_segmented_array_memory();\n-\n-  void set_state(State new_state);\n-  \/\/ Returns whether we are currently processing a recent request.\n-  bool is_active() const;\n-\n-  \/\/ The delay used to reschedule this task if not all work has been completed.\n-  jlong reschedule_delay_ms() const;\n-\n-public:\n-  explicit G1SegmentedArrayFreeMemoryTask(const char* name);\n-\n-  void execute() override;\n-\n-  \/\/ Notify the task of new used remembered set memory statistics for the young\n-  \/\/ generation and the collection set candidate sets.\n-  void notify_new_stats(G1SegmentedArrayMemoryStats* young_gen_stats,\n-                        G1SegmentedArrayMemoryStats* collection_set_candidate_stats);\n-};\n-\n-#endif \/\/ SHARE_GC_G1_G1SEGMENTEDARRAYFREEMEMORYTASK_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreeMemoryTask.hpp","additions":0,"deletions":96,"binary":false,"changes":96,"status":"deleted"},{"patch":"@@ -1,193 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-\n-#include \"gc\/g1\/g1SegmentedArrayFreePool.hpp\"\n-#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n-#include \"logging\/log.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"runtime\/os.hpp\"\n-#include \"utilities\/formatBuffer.hpp\"\n-#include \"utilities\/ostream.hpp\"\n-\n-G1SegmentedArrayMemoryStats::G1SegmentedArrayMemoryStats() {\n-  clear();\n-}\n-\n-void G1SegmentedArrayMemoryStats::clear() {\n-  for (uint i = 0; i < num_pools(); i++) {\n-    _num_mem_sizes[i] = 0;\n-    _num_segments[i] = 0;\n-  }\n-}\n-\n-void G1SegmentedArrayFreePool::update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processor) {\n-  uint num_free_lists = _freelist_pool.num_free_lists();\n-\n-  for (uint i = 0; i < num_free_lists; i++) {\n-    unlink_processor->at(i)->visit_free_list(_freelist_pool.free_list(i));\n-  }\n-}\n-\n-void G1SegmentedArrayFreePool::G1ReturnMemoryProcessor::visit_free_list(G1SegmentedArrayFreeList* source) {\n-  assert(_source == nullptr, \"already visited\");\n-  if (_return_to_vm_size > 0) {\n-    _source = source;\n-  } else {\n-    assert(_source == nullptr, \"must be\");\n-  }\n-  if (source->mem_size() > _return_to_vm_size) {\n-    _first = source->get_all(_num_unlinked, _unlinked_bytes);\n-  } else {\n-    assert(_first == nullptr, \"must be\");\n-  }\n-  \/\/ Above we were racing with other threads getting the contents of the free list,\n-  \/\/ so while we might have been asked to return something to the OS initially,\n-  \/\/ the free list might be empty anyway. In this case just reset internal values\n-  \/\/ used for checking whether there is work available.\n-  if (_first == nullptr) {\n-    _source = nullptr;\n-    _return_to_vm_size = 0;\n-  }\n-}\n-\n-bool G1SegmentedArrayFreePool::G1ReturnMemoryProcessor::return_to_vm(jlong deadline) {\n-  assert(!finished_return_to_vm(), \"already returned everything to the VM\");\n-  assert(_first != nullptr, \"must have segment to return\");\n-\n-  size_t keep_size = 0;\n-  size_t keep_num = 0;\n-\n-  G1SegmentedArraySegment* cur = _first;\n-  G1SegmentedArraySegment* last = nullptr;\n-\n-  while (cur != nullptr && _return_to_vm_size > 0) {\n-    size_t cur_size = cur->mem_size();\n-    _return_to_vm_size -= MIN2(_return_to_vm_size, cur_size);\n-\n-    keep_size += cur_size;\n-    keep_num++;\n-\n-    last = cur;\n-    cur = cur->next();\n-    \/\/ To ensure progress, perform the deadline check here.\n-    if (os::elapsed_counter() > deadline) {\n-      break;\n-    }\n-  }\n-\n-  assert(_first != nullptr, \"must be\");\n-  assert(last != nullptr, \"must be\");\n-\n-  last->set_next(nullptr);\n-\n-  \/\/ Wait for any in-progress pops to avoid ABA for them.\n-  GlobalCounter::write_synchronize();\n-  _source->bulk_add(*_first, *last, keep_num, keep_size);\n-  _first = cur;\n-\n-  log_trace(gc, task)(\"Segmented Array Free Memory: Returned to VM %zu segments size %zu\", keep_num, keep_size);\n-\n-  \/\/ _return_to_vm_size may be larger than what is available in the list at the\n-  \/\/ time we actually get the list. I.e. the list and _return_to_vm_size may be\n-  \/\/ inconsistent.\n-  \/\/ So also check if we actually already at the end of the list for the exit\n-  \/\/ condition.\n-  if (_return_to_vm_size == 0 || _first == nullptr) {\n-    _source = nullptr;\n-    _return_to_vm_size = 0;\n-  }\n-  return _source != nullptr;\n-}\n-\n-bool G1SegmentedArrayFreePool::G1ReturnMemoryProcessor::return_to_os(jlong deadline) {\n-  assert(finished_return_to_vm(), \"not finished returning to VM\");\n-  assert(!finished_return_to_os(), \"already returned everything to the OS\");\n-\n-  \/\/ Now delete the rest.\n-  size_t num_delete = 0;\n-  size_t mem_size_deleted = 0;\n-\n-  while (_first != nullptr) {\n-    G1SegmentedArraySegment* next = _first->next();\n-    num_delete++;\n-    mem_size_deleted += _first->mem_size();\n-    G1SegmentedArraySegment::delete_segment(_first);\n-    _first = next;\n-\n-    \/\/ To ensure progress, perform the deadline check here.\n-    if (os::elapsed_counter() > deadline) {\n-      break;\n-    }\n-  }\n-\n-  log_trace(gc, task)(\"Segmented Array Free Memory: Return to OS %zu segments size %zu\", num_delete, mem_size_deleted);\n-\n-  return _first != nullptr;\n-}\n-\n-G1SegmentedArrayFreePool G1SegmentedArrayFreePool::_freelist_pool(G1CardSetConfiguration::num_mem_object_types());\n-\n-G1SegmentedArrayFreePool::G1SegmentedArrayFreePool(uint num_free_lists) :\n-  _num_free_lists(num_free_lists) {\n-\n-  _free_lists = NEW_C_HEAP_ARRAY(G1SegmentedArrayFreeList, _num_free_lists, mtGC);\n-  for (uint i = 0; i < _num_free_lists; i++) {\n-    new (&_free_lists[i]) G1SegmentedArrayFreeList();\n-  }\n-}\n-\n-G1SegmentedArrayFreePool::~G1SegmentedArrayFreePool() {\n-  for (uint i = 0; i < _num_free_lists; i++) {\n-    _free_lists[i].~G1SegmentedArrayFreeList();\n-  }\n-  FREE_C_HEAP_ARRAY(mtGC, _free_lists);\n-}\n-\n-G1SegmentedArrayMemoryStats G1SegmentedArrayFreePool::memory_sizes() const {\n-  G1SegmentedArrayMemoryStats free_list_stats;\n-  assert(free_list_stats.num_pools() == num_free_lists(), \"must be\");\n-  for (uint i = 0; i < num_free_lists(); i++) {\n-    free_list_stats._num_mem_sizes[i] = _free_lists[i].mem_size();\n-    free_list_stats._num_segments[i] = _free_lists[i].num_segments();\n-  }\n-  return free_list_stats;\n-}\n-\n-size_t G1SegmentedArrayFreePool::mem_size() const {\n-  size_t result = 0;\n-  for (uint i = 0; i < _num_free_lists; i++) {\n-    result += _free_lists[i].mem_size();\n-  }\n-  return result;\n-}\n-\n-void G1SegmentedArrayFreePool::print_on(outputStream* out) {\n-  out->print_cr(\"  Free Pool: size %zu\", free_list_pool()->mem_size());\n-  for (uint i = 0; i < _num_free_lists; i++) {\n-    FormatBuffer<> fmt(\"    %s\", G1CardSetConfiguration::mem_object_type_name_str(i));\n-    _free_lists[i].print_on(out, fmt);\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreePool.cpp","additions":0,"deletions":193,"binary":false,"changes":193,"status":"deleted"},{"patch":"@@ -1,126 +0,0 @@\n-\/*\n- * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1SEGMENTEDARRAYFREEPOOL_HPP\n-#define SHARE_GC_G1_G1SEGMENTEDARRAYFREEPOOL_HPP\n-\n-#include \"gc\/g1\/g1CardSet.hpp\"\n-#include \"gc\/g1\/g1SegmentedArray.hpp\"\n-#include \"utilities\/growableArray.hpp\"\n-\n-\/\/ Statistics for a segmented array. Contains the number of segments and memory\n-\/\/ used for each. Note that statistics are typically not taken atomically so there\n-\/\/ can be inconsistencies. The user must be prepared for them.\n-class G1SegmentedArrayMemoryStats {\n-public:\n-\n-  size_t _num_mem_sizes[G1CardSetConfiguration::num_mem_object_types()];\n-  size_t _num_segments[G1CardSetConfiguration::num_mem_object_types()];\n-\n-  \/\/ Returns all-zero statistics.\n-  G1SegmentedArrayMemoryStats();\n-\n-  void add(G1SegmentedArrayMemoryStats const other) {\n-    STATIC_ASSERT(ARRAY_SIZE(_num_segments) == ARRAY_SIZE(_num_mem_sizes));\n-    for (uint i = 0; i < ARRAY_SIZE(_num_mem_sizes); i++) {\n-      _num_mem_sizes[i] += other._num_mem_sizes[i];\n-      _num_segments[i] += other._num_segments[i];\n-    }\n-  }\n-\n-  void clear();\n-\n-  uint num_pools() const { return G1CardSetConfiguration::num_mem_object_types(); }\n-};\n-\n-\/\/ A set of free lists holding freed segments for use by G1SegmentedArray,\n-\/\/ e.g. G1CardSetAllocators::SegmentedArray\n-class G1SegmentedArrayFreePool {\n-  \/\/ The global free pool.\n-  static G1SegmentedArrayFreePool _freelist_pool;\n-\n-  const uint _num_free_lists;\n-  G1SegmentedArrayFreeList* _free_lists;\n-\n-public:\n-  static G1SegmentedArrayFreePool* free_list_pool() { return &_freelist_pool; }\n-  static G1SegmentedArrayMemoryStats free_list_sizes() { return _freelist_pool.memory_sizes(); }\n-\n-  class G1ReturnMemoryProcessor;\n-  typedef GrowableArrayCHeap<G1ReturnMemoryProcessor*, mtGC> G1ReturnMemoryProcessorSet;\n-\n-  static void update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processors);\n-\n-  explicit G1SegmentedArrayFreePool(uint num_free_lists);\n-  ~G1SegmentedArrayFreePool();\n-\n-  G1SegmentedArrayFreeList* free_list(uint i) {\n-    assert(i < _num_free_lists, \"must be\");\n-    return &_free_lists[i];\n-  }\n-\n-  uint num_free_lists() const { return _num_free_lists; }\n-\n-  G1SegmentedArrayMemoryStats memory_sizes() const;\n-  size_t mem_size() const;\n-\n-  void print_on(outputStream* out);\n-};\n-\n-\/\/ Data structure containing current in-progress state for returning memory to the\n-\/\/ operating system for a single G1SegmentedArrayFreeList.\n-class G1SegmentedArrayFreePool::G1ReturnMemoryProcessor : public CHeapObj<mtGC> {\n-  G1SegmentedArrayFreeList* _source;\n-  size_t _return_to_vm_size;\n-\n-  G1SegmentedArraySegment* _first;\n-  size_t _unlinked_bytes;\n-  size_t _num_unlinked;\n-\n-public:\n-  explicit G1ReturnMemoryProcessor(size_t return_to_vm) :\n-    _source(nullptr), _return_to_vm_size(return_to_vm), _first(nullptr), _unlinked_bytes(0), _num_unlinked(0) {\n-  }\n-\n-  \/\/ Updates the instance members about the given free list for\n-  \/\/ the purpose of giving back memory. Only necessary members are updated,\n-  \/\/ e.g. if there is nothing to return to the VM, do not set the source list.\n-  void visit_free_list(G1SegmentedArrayFreeList* source);\n-\n-  bool finished_return_to_vm() const { return _return_to_vm_size == 0; }\n-  bool finished_return_to_os() const { return _first == nullptr; }\n-\n-  \/\/ Returns memory to the VM until the given deadline expires. Returns true if\n-  \/\/ there is no more work. Guarantees forward progress, i.e. at least one segment\n-  \/\/ has been processed after returning.\n-  \/\/ return_to_vm() re-adds segments to the respective free list.\n-  bool return_to_vm(jlong deadline);\n-  \/\/ Returns memory to the VM until the given deadline expires. Returns true if\n-  \/\/ there is no more work. Guarantees forward progress, i.e. at least one segment\n-  \/\/ has been processed after returning.\n-  \/\/ return_to_os() gives back segments to the OS.\n-  bool return_to_os(jlong deadline);\n-};\n-\n-#endif \/\/SHARE_GC_G1_G1SEGMENTEDARRAYFREEPOOL_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreePool.hpp","additions":0,"deletions":126,"binary":false,"changes":126,"status":"deleted"},{"patch":"@@ -293,1 +293,1 @@\n-    G1SegmentedArrayMemoryStats _card_set_stats;\n+    G1MonotonicArenaMemoryStats _card_set_stats;\n@@ -407,1 +407,1 @@\n-    G1SegmentedArrayMemoryStats card_set_stats() const {\n+    G1MonotonicArenaMemoryStats card_set_stats() const {\n@@ -417,1 +417,1 @@\n-  G1SegmentedArrayMemoryStats _all_card_set_stats;\n+  G1MonotonicArenaMemoryStats _all_card_set_stats;\n@@ -451,1 +451,1 @@\n-  const G1SegmentedArrayMemoryStats all_card_set_stats() const {\n+  const G1MonotonicArenaMemoryStats all_card_set_stats() const {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungCollector.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+class G1MonotonicArenaMemoryStats;\n@@ -51,1 +52,0 @@\n-class G1SegmentedArrayMemoryStats;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungCollector.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -85,1 +85,1 @@\n-      G1SegmentedArrayMemoryStats _total;\n+      G1MonotonicArenaMemoryStats _total;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"gc\/g1\/g1MonotonicArena.inline.hpp\"\n@@ -35,1 +36,0 @@\n-#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-  _card_set_mm(config, G1SegmentedArrayFreePool::free_list_pool()),\n+  _card_set_mm(config, G1MonotonicArenaFreePool::free_list_pool()),\n@@ -86,1 +86,1 @@\n-G1SegmentedArrayMemoryStats HeapRegionRemSet::card_set_memory_stats() const {\n+G1MonotonicArenaMemoryStats HeapRegionRemSet::card_set_memory_stats() const {\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -125,1 +125,1 @@\n-  G1SegmentedArrayMemoryStats card_set_memory_stats() const;\n+  G1MonotonicArenaMemoryStats card_set_memory_stats() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"gc\/g1\/g1SegmentedArrayFreePool.hpp\"\n+#include \"gc\/g1\/g1MonotonicArenaFreePool.hpp\"\n","filename":"test\/hotspot\/gtest\/gc\/g1\/test_g1CardSet.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}