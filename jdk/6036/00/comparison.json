{"files":[{"patch":"@@ -319,18 +319,5 @@\n-  int num_nodes_purged = 0;\n-\n-  \/\/ We purge to return unused memory to the Operating System. We do this in\n-  \/\/  two independent steps.\n-\n-  \/\/ 1) We purge the virtual space list: any memory mappings which are\n-  \/\/   completely deserted can be potentially unmapped. We iterate over the list\n-  \/\/   of mappings (VirtualSpaceList::purge) and delete every node whose memory\n-  \/\/   only contains free chunks. Deleting that node includes unmapping its memory,\n-  \/\/   so all chunk vanish automatically.\n-  \/\/   Of course we need to remove the chunk headers of those vanished chunks from\n-  \/\/   the ChunkManager freelist.\n-  num_nodes_purged = _vslist->purge(&_chunks);\n-  InternalStats::inc_num_purges();\n-\n-  \/\/ 2) Since (1) is rather ineffective - it is rare that a whole node only contains\n-  \/\/   free chunks - we now iterate over all remaining free chunks and\n-  \/\/   and uncommit those which can be uncommitted (>= commit granule size).\n+\n+  \/\/ We return unused memory to the Operating System: we iterate over all\n+  \/\/  free chunks and uncommit the backing memory of those large enough to\n+  \/\/  contain one or multiple commit granules (chunks larger than a granule\n+  \/\/  always cover a whole number of granules and start at a granule boundary).\n@@ -368,1 +355,0 @@\n-      ls.print_cr(\"full nodes purged: %d\", num_nodes_purged);\n","filename":"src\/hotspot\/share\/memory\/metaspace\/chunkManager.cpp","additions":5,"deletions":19,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -95,3 +95,0 @@\n-  \/* Number of times we did a purge *\/              \\\n-  x(num_purges)                                     \\\n-                                                    \\\n","filename":"src\/hotspot\/share\/memory\/metaspace\/internalStats.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -484,10 +484,0 @@\n-\/\/ Returns true if all areas in this area table are free (only contain free chunks).\n-bool RootChunkAreaLUT::is_free() const {\n-  for (int i = 0; i < _num; i++) {\n-    if (!_arr[i].is_free()) {\n-      return false;\n-    }\n-  }\n-  return true;\n-}\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace\/rootChunkArea.cpp","additions":0,"deletions":10,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -110,4 +110,0 @@\n-  \/\/ Direct access to the first chunk (use with care)\n-  Metachunk* first_chunk()              { return _first_chunk; }\n-  const Metachunk* first_chunk() const  { return _first_chunk; }\n-\n@@ -185,5 +181,0 @@\n-  \/\/ Access area by its index\n-  int number_of_areas() const                               { return _num; }\n-  RootChunkArea* get_area_by_index(int index)               { assert(index >= 0 && index < _num, \"oob\"); return _arr + index; }\n-  const RootChunkArea* get_area_by_index(int index) const   { assert(index >= 0 && index < _num, \"oob\"); return _arr + index; }\n-\n@@ -196,3 +187,0 @@\n-  \/\/ Returns true if all areas in this area table are free (only contain free chunks).\n-  bool is_free() const;\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace\/rootChunkArea.hpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -137,37 +137,0 @@\n-\/\/ Attempts to purge nodes. This will remove and delete nodes which only contain free chunks.\n-\/\/ The free chunks are removed from the freelists before the nodes are deleted.\n-\/\/ Return number of purged nodes.\n-int VirtualSpaceList::purge(FreeChunkListVector* freelists) {\n-  assert_lock_strong(Metaspace_lock);\n-  UL(debug, \"purging.\");\n-\n-  VirtualSpaceNode* vsn = _first_node;\n-  VirtualSpaceNode* prev_vsn = NULL;\n-  int num = 0, num_purged = 0;\n-  while (vsn != NULL) {\n-    VirtualSpaceNode* next_vsn = vsn->next();\n-    bool purged = vsn->attempt_purge(freelists);\n-    if (purged) {\n-      \/\/ Note: from now on do not dereference vsn!\n-      UL2(debug, \"purged node @\" PTR_FORMAT \".\", p2i(vsn));\n-      if (_first_node == vsn) {\n-        _first_node = next_vsn;\n-      }\n-      DEBUG_ONLY(vsn = (VirtualSpaceNode*)((uintptr_t)(0xdeadbeef));)\n-      if (prev_vsn != NULL) {\n-        prev_vsn->set_next(next_vsn);\n-      }\n-      num_purged++;\n-      _nodes_counter.decrement();\n-    } else {\n-      prev_vsn = vsn;\n-    }\n-    vsn = next_vsn;\n-    num ++;\n-  }\n-\n-  UL2(debug, \"purged %d nodes (before: %d, now: %d)\",\n-      num_purged, num, num_nodes());\n-  return num_purged;\n-}\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceList.cpp","additions":0,"deletions":37,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -51,4 +51,0 @@\n-\/\/\n-\/\/ Beyond access to those nodes and the ability to grow new nodes\n-\/\/  (if expandable) it allows for purging: purging this list means\n-\/\/  removing and unmapping all memory regions which are unused.\n@@ -104,5 +100,0 @@\n-  \/\/ Attempts to purge nodes. This will remove and delete nodes which only contain free chunks.\n-  \/\/ The free chunks are removed from the freelists before the nodes are deleted.\n-  \/\/ Return number of purged nodes.\n-  int purge(FreeChunkListVector* freelists);\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceList.hpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -372,42 +372,0 @@\n-\/\/ Attempts to purge the node:\n-\/\/\n-\/\/ If all chunks living in this node are free, they will all be removed from\n-\/\/  the freelist they currently reside in. Then, the node will be deleted.\n-\/\/\n-\/\/ Returns true if the node has been deleted, false if not.\n-\/\/ !! If this returns true, do not access the node from this point on. !!\n-bool VirtualSpaceNode::attempt_purge(FreeChunkListVector* freelists) {\n-  assert_lock_strong(Metaspace_lock);\n-\n-  if (!_owns_rs) {\n-    \/\/ We do not allow purging of nodes if we do not own the\n-    \/\/ underlying ReservedSpace (CompressClassSpace case).\n-    return false;\n-  }\n-\n-  \/\/ First find out if all areas are empty. Since empty chunks collapse to root chunk\n-  \/\/ size, if all chunks in this node are free root chunks we are good to go.\n-  if (!_root_chunk_area_lut.is_free()) {\n-    return false;\n-  }\n-\n-  UL(debug, \": purging.\");\n-\n-  \/\/ Okay, we can purge. Before we can do this, we need to remove all chunks from the freelist.\n-  for (int narea = 0; narea < _root_chunk_area_lut.number_of_areas(); narea++) {\n-    RootChunkArea* ra = _root_chunk_area_lut.get_area_by_index(narea);\n-    Metachunk* c = ra->first_chunk();\n-    if (c != NULL) {\n-      UL2(trace, \"removing chunk from to-be-purged node: \"\n-          METACHUNK_FULL_FORMAT \".\", METACHUNK_FULL_FORMAT_ARGS(c));\n-      assert(c->is_free() && c->is_root_chunk(), \"Sanity\");\n-      freelists->remove(c);\n-    }\n-  }\n-\n-  \/\/ Now, delete the node, then right away return since this object is invalid.\n-  delete this;\n-\n-  return true;\n-}\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceNode.cpp","additions":0,"deletions":42,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -211,9 +211,0 @@\n-  \/\/ Attempts to purge the node:\n-  \/\/\n-  \/\/ If all chunks living in this node are free, they will all be removed from\n-  \/\/  the freelist they currently reside in. Then, the node will be deleted.\n-  \/\/\n-  \/\/ Returns true if the node has been deleted, false if not.\n-  \/\/ !! If this returns true, do not access the node from this point on. !!\n-  bool attempt_purge(FreeChunkListVector* freelists);\n-\n","filename":"src\/hotspot\/share\/memory\/metaspace\/virtualSpaceNode.hpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -62,0 +62,13 @@\n+        \/\/ This deletes the arenas, which will cause them to return all their accumulated\n+        \/\/ metaspace chunks into the context' chunk manager (freelist) before vanishing.\n+        \/\/ It then purges the context.\n+        \/\/ We may return memory to the operating system:\n+        \/\/ - with -XX:MetaspaceReclaimPolicy=balanced|aggressive (balanced is the default),\n+        \/\/   we will scourge the freelist for chunks larger than a commit granule, and uncommit\n+        \/\/   their backing memory. Note that since we deleted all arenas, all their chunks are\n+        \/\/   in the freelist, should have been maximally folded by the buddy allocator, and\n+        \/\/   therefore should all be eligible for uncommitting. Meaning the context should\n+        \/\/   retain no memory at all, its committed counter should be zero.\n+        \/\/ - with -XX:MetaspaceReclaimPolicy=none, we omit the purging and retain memory in the\n+        \/\/   metaspace allocator, so the context should retain its memory.\n+\n@@ -67,13 +80,0 @@\n-\n-        context.checkStatistics();\n-\n-        \/\/ After deleting all arenas, we should have no committed space left: all arena chunks have been returned to\n-        \/\/ the freelist amd should have been maximally merged to a bunch of root chunks, which should be uncommitted\n-        \/\/ in one go.\n-        \/\/ Exception: if reclamation policy is none.\n-        if (Settings.settings().doesReclaim()) {\n-            if (context.committedWords() > 0) {\n-                throw new RuntimeException(\"Expected no committed words after purging empty metaspace context (was: \" + context.committedWords() + \")\");\n-            }\n-        }\n-\n@@ -84,7 +84,1 @@\n-        \/\/ After purging - if all arenas had been deleted before - we should have no committed space left even in\n-        \/\/   recmalation=none mode:\n-        \/\/ purging deletes all nodes with only free chunks, and in this case no node should still house in-use chunks,\n-        \/\/  so all nodes would have been unmapped.\n-        \/\/ This is independent on reclamation policy. Only one exception: if the area was created with a reserve limit\n-        \/\/ (mimicking compressed class space), the underlying virtual space list cannot be purged.\n-        if (context.reserveLimit == 0) {\n+        if (Settings.settings().doesReclaim()) {\n@@ -95,1 +89,0 @@\n-\n","filename":"test\/hotspot\/jtreg\/runtime\/Metaspace\/elastic\/MetaspaceTestWithThreads.java","additions":14,"deletions":21,"binary":false,"changes":35,"status":"modified"}]}