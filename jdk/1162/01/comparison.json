{"files":[{"patch":"@@ -4626,1 +4626,1 @@\n-  if (!FLAG_IS_DEFAULT(AllocateHeapAt) || !FLAG_IS_DEFAULT(AllocateOldGenAt)) {\n+  if (!FLAG_IS_DEFAULT(AllocateHeapAt)) {\n","filename":"src\/hotspot\/os\/linux\/os_linux.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,3 +39,0 @@\n-static const double MaxRamFractionForYoung = 0.8;\n-size_t G1Arguments::MaxMemoryForYoung;\n-\n@@ -197,30 +194,0 @@\n-static size_t calculate_reasonable_max_memory_for_young(FormatBuffer<100> &calc_str, double max_ram_fraction_for_young) {\n-  julong phys_mem;\n-  \/\/ If MaxRam is specified, we use that as maximum physical memory available.\n-  if (FLAG_IS_DEFAULT(MaxRAM)) {\n-    phys_mem = os::physical_memory();\n-    calc_str.append(\"Physical_Memory\");\n-  } else {\n-    phys_mem = (julong)MaxRAM;\n-    calc_str.append(\"MaxRAM\");\n-  }\n-\n-  julong reasonable_max = phys_mem;\n-\n-  \/\/ If either MaxRAMFraction or MaxRAMPercentage is specified, we use them to calculate\n-  \/\/ reasonable max size of young generation.\n-  if (!FLAG_IS_DEFAULT(MaxRAMFraction)) {\n-    reasonable_max = (julong)(phys_mem \/ MaxRAMFraction);\n-    calc_str.append(\" \/ MaxRAMFraction\");\n-  }  else if (!FLAG_IS_DEFAULT(MaxRAMPercentage)) {\n-    reasonable_max = (julong)((phys_mem * MaxRAMPercentage) \/ 100);\n-    calc_str.append(\" * MaxRAMPercentage \/ 100\");\n-  }  else {\n-    \/\/ We use our own fraction to calculate max size of young generation.\n-    reasonable_max = phys_mem * max_ram_fraction_for_young;\n-    calc_str.append(\" * %0.2f\", max_ram_fraction_for_young);\n-  }\n-\n-  return (size_t)reasonable_max;\n-}\n-\n@@ -228,4 +195,0 @@\n-  if (AllocateOldGenAt != NULL) {\n-    initialize_heterogeneous();\n-  }\n-\n@@ -235,25 +198,0 @@\n-void G1Arguments::initialize_heterogeneous() {\n-  FormatBuffer<100> calc_str(\"\");\n-\n-  MaxMemoryForYoung = calculate_reasonable_max_memory_for_young(calc_str, MaxRamFractionForYoung);\n-\n-  if (MaxNewSize > MaxMemoryForYoung) {\n-    if (FLAG_IS_CMDLINE(MaxNewSize)) {\n-      log_warning(gc, ergo)(\"Setting MaxNewSize to \" SIZE_FORMAT \" based on dram available (calculation = align(%s))\",\n-                            MaxMemoryForYoung, calc_str.buffer());\n-    } else {\n-      log_info(gc, ergo)(\"Setting MaxNewSize to \" SIZE_FORMAT \" based on dram available (calculation = align(%s)). \"\n-                         \"Dram usage can be lowered by setting MaxNewSize to a lower value\", MaxMemoryForYoung, calc_str.buffer());\n-    }\n-    MaxNewSize = MaxMemoryForYoung;\n-  }\n-  if (NewSize > MaxMemoryForYoung) {\n-    if (FLAG_IS_CMDLINE(NewSize)) {\n-      log_warning(gc, ergo)(\"Setting NewSize to \" SIZE_FORMAT \" based on dram available (calculation = align(%s))\",\n-                            MaxMemoryForYoung, calc_str.buffer());\n-    }\n-    NewSize = MaxMemoryForYoung;\n-  }\n-\n-}\n-\n@@ -264,8 +202,0 @@\n-bool G1Arguments::is_heterogeneous_heap() {\n-  return AllocateOldGenAt != NULL;\n-}\n-\n-size_t G1Arguments::reasonable_max_memory_for_young() {\n-  return MaxMemoryForYoung;\n-}\n-\n@@ -273,4 +203,0 @@\n-  return (is_heterogeneous_heap() ? 2 : 1) * MaxHeapSize;\n-}\n-\n-size_t G1Arguments::heap_max_size_bytes() {\n@@ -279,0 +205,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Arguments.cpp","additions":1,"deletions":74,"binary":false,"changes":75,"status":"modified"},{"patch":"@@ -36,3 +36,0 @@\n-private:\n-  static size_t MaxMemoryForYoung;\n-\n@@ -46,2 +43,0 @@\n-  void initialize_heterogeneous();\n-\n@@ -53,3 +48,0 @@\n-  \/\/ Heterogeneous heap support\n-  static bool is_heterogeneous_heap();\n-  static size_t reasonable_max_memory_for_young();\n@@ -57,1 +49,0 @@\n-  static size_t heap_max_size_bytes();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Arguments.hpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -187,1 +187,1 @@\n-  HeapRegion* res = _hrm->allocate_free_region(type, node_index);\n+  HeapRegion* res = _hrm.allocate_free_region(type, node_index);\n@@ -207,1 +207,1 @@\n-      res = _hrm->allocate_free_region(type, node_index);\n+      res = _hrm.allocate_free_region(type, node_index);\n@@ -349,1 +349,1 @@\n-  HeapRegion* humongous_start = _hrm->allocate_humongous(obj_regions);\n+  HeapRegion* humongous_start = _hrm.allocate_humongous(obj_regions);\n@@ -354,1 +354,1 @@\n-    humongous_start = _hrm->expand_and_allocate_humongous(obj_regions);\n+    humongous_start = _hrm.expand_and_allocate_humongous(obj_regions);\n@@ -548,1 +548,1 @@\n-  MemRegion reserved = _hrm->reserved();\n+  MemRegion reserved = _hrm.reserved();\n@@ -565,1 +565,1 @@\n-  MemRegion reserved = _hrm->reserved();\n+  MemRegion reserved = _hrm.reserved();\n@@ -595,1 +595,1 @@\n-    HeapRegion* start_region = _hrm->addr_to_region(start_address);\n+    HeapRegion* start_region = _hrm.addr_to_region(start_address);\n@@ -605,1 +605,1 @@\n-      start_region = _hrm->addr_to_region(start_address);\n+      start_region = _hrm.addr_to_region(start_address);\n@@ -610,1 +610,1 @@\n-    if (!_hrm->allocate_containing_regions(curr_range, &commits, workers())) {\n+    if (!_hrm.allocate_containing_regions(curr_range, &commits, workers())) {\n@@ -622,2 +622,2 @@\n-    HeapRegion* curr_region = _hrm->addr_to_region(start_address);\n-    HeapRegion* last_region = _hrm->addr_to_region(last_address);\n+    HeapRegion* curr_region = _hrm.addr_to_region(start_address);\n+    HeapRegion* last_region = _hrm.addr_to_region(last_address);\n@@ -640,1 +640,1 @@\n-        next_region = _hrm->next_region_in_heap(curr_region);\n+        next_region = _hrm.next_region_in_heap(curr_region);\n@@ -656,1 +656,1 @@\n-  MemRegion reserved = _hrm->reserved();\n+  MemRegion reserved = _hrm.reserved();\n@@ -676,2 +676,2 @@\n-    HeapRegion* start_region = _hrm->addr_to_region(start_address);\n-    HeapRegion* last_region = _hrm->addr_to_region(last_address);\n+    HeapRegion* start_region = _hrm.addr_to_region(start_address);\n+    HeapRegion* last_region = _hrm.addr_to_region(last_address);\n@@ -693,1 +693,1 @@\n-        curr_region = _hrm->next_region_in_heap(curr_region);\n+        curr_region = _hrm.next_region_in_heap(curr_region);\n@@ -742,1 +742,1 @@\n-  MemRegion reserved = _hrm->reserved();\n+  MemRegion reserved = _hrm.reserved();\n@@ -764,2 +764,2 @@\n-    HeapRegion* start_region = _hrm->addr_to_region(start_address);\n-    HeapRegion* last_region = _hrm->addr_to_region(last_address);\n+    HeapRegion* start_region = _hrm.addr_to_region(start_address);\n+    HeapRegion* last_region = _hrm.addr_to_region(last_address);\n@@ -776,1 +776,1 @@\n-      start_region = _hrm->addr_to_region(start_address);\n+      start_region = _hrm.addr_to_region(start_address);\n@@ -791,1 +791,1 @@\n-        curr_region = _hrm->next_region_in_heap(curr_region);\n+        curr_region = _hrm.next_region_in_heap(curr_region);\n@@ -795,1 +795,1 @@\n-      _hrm->shrink_at(curr_index, 1);\n+      _hrm.shrink_at(curr_index, 1);\n@@ -1008,2 +1008,1 @@\n-  hrm()->remove_all_free_regions();\n-  hrm()->prepare_for_full_collection_start();\n+  _hrm.remove_all_free_regions();\n@@ -1021,2 +1020,0 @@\n-  hrm()->prepare_for_full_collection_end();\n-\n@@ -1061,1 +1058,1 @@\n-  _hrm->verify_optional();\n+  _hrm.verify_optional();\n@@ -1237,1 +1234,1 @@\n-    _hrm->verify_optional();\n+    _hrm.verify_optional();\n@@ -1262,1 +1259,1 @@\n-  uint expanded_by = _hrm->expand_by(regions_to_expand, pretouch_workers);\n+  uint expanded_by = _hrm.expand_by(regions_to_expand, pretouch_workers);\n@@ -1277,1 +1274,1 @@\n-        _hrm->available() >= regions_to_expand) {\n+        _hrm.available() >= regions_to_expand) {\n@@ -1286,1 +1283,1 @@\n-  uint expanded_by = _hrm->expand_on_preferred_node(node_index);\n+  uint expanded_by = _hrm.expand_on_preferred_node(node_index);\n@@ -1289,1 +1286,1 @@\n-    assert(is_maximal_no_gc(), \"Should be no regions left, available: %u\", _hrm->available());\n+    assert(is_maximal_no_gc(), \"Should be no regions left, available: %u\", _hrm.available());\n@@ -1305,1 +1302,1 @@\n-  uint num_regions_removed = _hrm->shrink_by(num_regions_to_remove);\n+  uint num_regions_removed = _hrm.shrink_by(num_regions_to_remove);\n@@ -1328,1 +1325,1 @@\n-  hrm()->remove_all_free_regions();\n+  _hrm.remove_all_free_regions();\n@@ -1332,1 +1329,1 @@\n-  _hrm->verify_optional();\n+  _hrm.verify_optional();\n@@ -1411,1 +1408,1 @@\n-  _hrm(NULL),\n+  _hrm(),\n@@ -1431,1 +1428,1 @@\n-  _policy(G1Policy::create_policy(_gc_timer_stw)),\n+  _policy(new G1Policy(_gc_timer_stw)),\n@@ -1606,6 +1603,6 @@\n-    G1RegionToSpaceMapper::create_heap_mapper(heap_rs,\n-                                              heap_rs.size(),\n-                                              page_size,\n-                                              HeapRegion::GrainBytes,\n-                                              1,\n-                                              mtJavaHeap);\n+    G1RegionToSpaceMapper::create_mapper(heap_rs,\n+                                         heap_rs.size(),\n+                                         page_size,\n+                                         HeapRegion::GrainBytes,\n+                                         1,\n+                                         mtJavaHeap);\n@@ -1647,3 +1644,1 @@\n-  _hrm = HeapRegionManager::create_manager(this);\n-\n-  _hrm->initialize(heap_storage, prev_bitmap_storage, next_bitmap_storage, bot_storage, cardtable_storage, card_counts_storage);\n+  _hrm.initialize(heap_storage, prev_bitmap_storage, next_bitmap_storage, bot_storage, cardtable_storage, card_counts_storage);\n@@ -1726,1 +1721,1 @@\n-  HeapRegion* dummy_region = _hrm->get_dummy_region();\n+  HeapRegion* dummy_region = _hrm.get_dummy_region();\n@@ -1845,1 +1840,1 @@\n-  return _hrm->length() * HeapRegion::GrainBytes;\n+  return _hrm.length() * HeapRegion::GrainBytes;\n@@ -1849,1 +1844,1 @@\n-  return _hrm->total_free_bytes();\n+  return _hrm.total_free_bytes();\n@@ -1905,3 +1900,1 @@\n-  if (policy()->force_upgrade_to_full()) {\n-    return true;\n-  } else if (should_do_concurrent_full_gc(_gc_cause)) {\n+  if (should_do_concurrent_full_gc(_gc_cause)) {\n@@ -2241,1 +2234,1 @@\n-  return is_in_reserved(p) && _hrm->is_available(addr_to_region((HeapWord*)p));\n+  return is_in_reserved(p) && _hrm.is_available(addr_to_region((HeapWord*)p));\n@@ -2294,1 +2287,1 @@\n-  _hrm->iterate(cl);\n+  _hrm.iterate(cl);\n@@ -2300,1 +2293,1 @@\n-  _hrm->par_iterate(cl, hrclaimer, hrclaimer->offset_for_worker(worker_id));\n+  _hrm.par_iterate(cl, hrclaimer, hrclaimer->offset_for_worker(worker_id));\n@@ -2305,1 +2298,1 @@\n-  _hrm->par_iterate(cl, hrclaimer, 0);\n+  _hrm.par_iterate(cl, hrclaimer, 0);\n@@ -2372,4 +2365,0 @@\n-bool G1CollectedHeap::is_heterogeneous_heap() const {\n-  return G1Arguments::is_heterogeneous_heap();\n-}\n-\n@@ -2424,7 +2413,5 @@\n-  if (_hrm != NULL) {\n-    st->print(\" total \" SIZE_FORMAT \"K, used \" SIZE_FORMAT \"K\",\n-              capacity()\/K, heap_used\/K);\n-    st->print(\" [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n-              p2i(_hrm->reserved().start()),\n-              p2i(_hrm->reserved().end()));\n-  }\n+  st->print(\" total \" SIZE_FORMAT \"K, used \" SIZE_FORMAT \"K\",\n+            capacity()\/K, heap_used\/K);\n+  st->print(\" [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n+            p2i(_hrm.reserved().start()),\n+            p2i(_hrm.reserved().end()));\n@@ -2445,1 +2432,1 @@\n-      uint num_free_regions = (_hrm != NULL ? _hrm->num_free_regions(node_index) : 0);\n+      uint num_free_regions = _hrm.num_free_regions(node_index);\n@@ -2454,4 +2441,0 @@\n-  if (_hrm == NULL) {\n-    return;\n-  }\n-\n@@ -2471,4 +2454,2 @@\n-  if (_hrm != NULL) {\n-    st->cr();\n-    print_regions_on(st);\n-  }\n+  st->cr();\n+  print_regions_on(st);\n@@ -3050,1 +3031,1 @@\n-    _hrm->verify_optional();\n+    _hrm.verify_optional();\n@@ -4012,1 +3993,1 @@\n-  assert(_hrm->is_available(hr->hrm_index()), \"region should be committed\");\n+  assert(_hrm.is_available(hr->hrm_index()), \"region should be committed\");\n@@ -4057,1 +4038,1 @@\n-    _hrm->insert_list_into_free_list(list);\n+    _hrm.insert_list_into_free_list(list);\n@@ -4338,1 +4319,1 @@\n-  hrm()->rebuild_free_list(workers());\n+  _hrm.rebuild_free_list(workers());\n@@ -4641,1 +4622,1 @@\n-  RebuildRegionSetsClosure cl(free_list_only, &_old_set, _hrm);\n+  RebuildRegionSetsClosure cl(free_list_only, &_old_set, &_hrm);\n@@ -4758,1 +4739,1 @@\n-  uint index = _hrm->find_highest_free(&expanded);\n+  uint index = _hrm.find_highest_free(&expanded);\n@@ -4765,1 +4746,1 @@\n-    return _hrm->allocate_free_regions_starting_at(index, 1);\n+    return _hrm.allocate_free_regions_starting_at(index, 1);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":64,"deletions":83,"binary":false,"changes":147,"status":"modified"},{"patch":"@@ -50,1 +50,0 @@\n-#include \"gc\/g1\/heterogeneousHeapRegionManager.hpp\"\n@@ -197,1 +196,1 @@\n-  HeapRegionManager* _hrm;\n+  HeapRegionManager _hrm;\n@@ -1019,2 +1018,0 @@\n-  HeapRegionManager* hrm() const { return _hrm; }\n-\n@@ -1066,1 +1063,1 @@\n-    return _hrm->available() == 0;\n+    return _hrm.available() == 0;\n@@ -1075,1 +1072,1 @@\n-  uint num_regions() const { return _hrm->length(); }\n+  uint num_regions() const { return _hrm.length(); }\n@@ -1079,1 +1076,1 @@\n-  uint max_reserved_regions() const { return _hrm->reserved_length(); }\n+  uint max_reserved_regions() const { return _hrm.reserved_length(); }\n@@ -1082,1 +1079,1 @@\n-  uint max_regions() const { return _hrm->max_length(); }\n+  uint max_regions() const { return _hrm.max_length(); }\n@@ -1085,1 +1082,1 @@\n-  uint num_free_regions() const { return _hrm->num_free_regions(); }\n+  uint num_free_regions() const { return _hrm.num_free_regions(); }\n@@ -1088,1 +1085,1 @@\n-  uint num_free_or_available_regions() const { return num_free_regions() + _hrm->available(); }\n+  uint num_free_or_available_regions() const { return num_free_regions() + _hrm.available(); }\n@@ -1091,1 +1088,1 @@\n-    return _hrm->get_auxiliary_data_memory_usage();\n+    return _hrm.get_auxiliary_data_memory_usage();\n@@ -1099,1 +1096,1 @@\n-    return _hrm->is_free(hr);\n+    return _hrm.is_free(hr);\n@@ -1154,1 +1151,1 @@\n-    return _hrm->reserved();\n+    return _hrm.reserved();\n@@ -1417,1 +1414,0 @@\n-  bool is_heterogeneous_heap() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":10,"deletions":14,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-inline HeapRegion* G1CollectedHeap::region_at(uint index) const { return _hrm->at(index); }\n+inline HeapRegion* G1CollectedHeap::region_at(uint index) const { return _hrm.at(index); }\n@@ -70,1 +70,1 @@\n-inline HeapRegion* G1CollectedHeap::region_at_or_null(uint index) const { return _hrm->at_or_null(index); }\n+inline HeapRegion* G1CollectedHeap::region_at_or_null(uint index) const { return _hrm.at_or_null(index); }\n@@ -73,1 +73,1 @@\n-  return _hrm->next_region_in_humongous(hr);\n+  return _hrm.next_region_in_humongous(hr);\n@@ -84,1 +84,1 @@\n-  return _hrm->reserved().start() + index * HeapRegion::GrainWords;\n+  return _hrm.reserved().start() + index * HeapRegion::GrainWords;\n@@ -93,1 +93,1 @@\n-  return _hrm->addr_to_region((HeapWord*)(void*) addr);\n+  return _hrm.addr_to_region((HeapWord*)(void*) addr);\n@@ -293,1 +293,1 @@\n-  assert(_hrm->at(region)->is_starts_humongous(), \"Must start a humongous object\");\n+  assert(_hrm.at(region)->is_starts_humongous(), \"Must start a humongous object\");\n@@ -298,1 +298,1 @@\n-  assert(_hrm->at(region)->is_starts_humongous(), \"Must start a humongous object\");\n+  assert(_hrm.at(region)->is_starts_humongous(), \"Must start a humongous object\");\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.inline.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -600,1 +600,1 @@\n-  _g1h->_hrm->verify();\n+  _g1h->_hrm.verify();\n@@ -605,1 +605,1 @@\n-  VerifyRegionListsClosure cl(&_g1h->_old_set, &_g1h->_archive_set, &_g1h->_humongous_set, _g1h->_hrm);\n+  VerifyRegionListsClosure cl(&_g1h->_old_set, &_g1h->_archive_set, &_g1h->_humongous_set, &_g1h->_hrm);\n@@ -607,1 +607,1 @@\n-  cl.verify_counts(&_g1h->_old_set, &_g1h->_archive_set, &_g1h->_humongous_set, _g1h->_hrm);\n+  cl.verify_counts(&_g1h->_old_set, &_g1h->_archive_set, &_g1h->_humongous_set, &_g1h->_hrm);\n@@ -848,1 +848,1 @@\n-  _g1h->_hrm->iterate(&cl);\n+  _g1h->_hrm.iterate(&cl);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapVerifier.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1,58 +0,0 @@\n-\/*\n- * Copyright (c) 2018, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n-#include \"gc\/g1\/g1HeterogeneousHeapPolicy.hpp\"\n-#include \"gc\/g1\/g1Policy.hpp\"\n-#include \"gc\/g1\/heterogeneousHeapRegionManager.hpp\"\n-\n-G1HeterogeneousHeapPolicy::G1HeterogeneousHeapPolicy(STWGCTimer* gc_timer) :\n-  G1Policy(gc_timer), _manager(NULL) {}\n-\n-\/\/ We call the super class init(), after which we provision young_list_target_length() regions in dram.\n-void G1HeterogeneousHeapPolicy::init(G1CollectedHeap* g1h, G1CollectionSet* collection_set) {\n-  G1Policy::init(g1h, collection_set);\n-  _manager = HeterogeneousHeapRegionManager::manager();\n-  _manager->adjust_dram_regions((uint)young_list_target_length(), G1CollectedHeap::heap()->workers());\n-}\n-\n-\/\/ After a collection pause, young list target length is updated. So we need to make sure we have enough regions in dram for young gen.\n-void G1HeterogeneousHeapPolicy::record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark) {\n-  G1Policy::record_collection_pause_end(pause_time_ms, concurrent_operation_is_full_mark);\n-  _manager->adjust_dram_regions((uint)young_list_target_length(), G1CollectedHeap::heap()->workers());\n-}\n-\n-\/\/ After a full collection, young list target length is updated. So we need to make sure we have enough regions in dram for young gen.\n-void G1HeterogeneousHeapPolicy::record_full_collection_end() {\n-  G1Policy::record_full_collection_end();\n-  _manager->adjust_dram_regions((uint)young_list_target_length(), G1CollectedHeap::heap()->workers());\n-}\n-\n-bool G1HeterogeneousHeapPolicy::force_upgrade_to_full() {\n-  if (_manager->has_borrowed_regions()) {\n-    return true;\n-  }\n-  return false;\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeterogeneousHeapPolicy.cpp","additions":0,"deletions":58,"binary":false,"changes":58,"status":"deleted"},{"patch":"@@ -1,47 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1HETEROGENEOUSHEAPPOLICY_HPP\n-#define SHARE_GC_G1_G1HETEROGENEOUSHEAPPOLICY_HPP\n-\n-#include \"gc\/g1\/g1Policy.hpp\"\n-#include \"gc\/g1\/heterogeneousHeapRegionManager.hpp\"\n-\n-class G1HeterogeneousHeapPolicy : public G1Policy {\n-  \/\/ Stash a pointer to the hrm.\n-  HeterogeneousHeapRegionManager* _manager;\n-\n-public:\n-  G1HeterogeneousHeapPolicy(STWGCTimer* gc_timer);\n-\n-  \/\/ initialize policy\n-  virtual void init(G1CollectedHeap* g1h, G1CollectionSet* collection_set);\n-  \/\/ Record end of an evacuation pause.\n-  virtual void record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark);\n-  \/\/ Record the end of full collection.\n-  virtual void record_full_collection_end();\n-\n-  virtual bool force_upgrade_to_full();\n-};\n-#endif \/\/ SHARE_GC_G1_G1HETEROGENEOUSHEAPPOLICY_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeterogeneousHeapPolicy.hpp","additions":0,"deletions":47,"binary":false,"changes":47,"status":"deleted"},{"patch":"@@ -1,51 +0,0 @@\n-\/*\n- * Copyright (c) 2018, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/g1\/g1Arguments.hpp\"\n-#include \"gc\/g1\/g1HeterogeneousHeapYoungGenSizer.hpp\"\n-#include \"gc\/g1\/heapRegion.hpp\"\n-\n-G1HeterogeneousHeapYoungGenSizer::G1HeterogeneousHeapYoungGenSizer() : G1YoungGenSizer() {\n-  \/\/ will be used later when min and max young size is calculated.\n-  _max_young_length = (uint)(G1Arguments::reasonable_max_memory_for_young() \/ HeapRegion::GrainBytes);\n-}\n-\n-\/\/ Since heap is sized potentially to larger value accounting for dram + nvdimm, we need to limit\n-\/\/ max young gen size to the available dram.\n-\/\/ Call parent class method first and then adjust sizes based on available dram\n-void G1HeterogeneousHeapYoungGenSizer::adjust_max_new_size(uint number_of_heap_regions) {\n-  G1YoungGenSizer::adjust_max_new_size(number_of_heap_regions);\n-  adjust_lengths_based_on_dram_memory();\n-}\n-\n-void G1HeterogeneousHeapYoungGenSizer::heap_size_changed(uint new_number_of_heap_regions) {\n-  G1YoungGenSizer::heap_size_changed(new_number_of_heap_regions);\n-  adjust_lengths_based_on_dram_memory();\n-}\n-\n-void G1HeterogeneousHeapYoungGenSizer::adjust_lengths_based_on_dram_memory() {\n-  _min_desired_young_length = MIN2(_min_desired_young_length, _max_young_length);\n-  _max_desired_young_length = MIN2(_max_desired_young_length, _max_young_length);\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeterogeneousHeapYoungGenSizer.cpp","additions":0,"deletions":51,"binary":false,"changes":51,"status":"deleted"},{"patch":"@@ -1,51 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1HETEROGENEOUSHEAPYOUNGGENSIZER_HPP\n-#define SHARE_GC_G1_G1HETEROGENEOUSHEAPYOUNGGENSIZER_HPP\n-\n-#include \"gc\/g1\/g1YoungGenSizer.hpp\"\n-\n-\/\/ This class prevents the size of young generation of G1 heap to exceed dram\n-\/\/ memory available. If set on command line, MaxRAM and MaxRAMFraction\/MaxRAMPercentage\n-\/\/ are used to determine the maximum size that young generation can grow.\n-\/\/ Else we set the maximum size to 80% of dram available in the system.\n-\n-class G1HeterogeneousHeapYoungGenSizer : public G1YoungGenSizer {\n-private:\n-  \/\/ maximum no of regions that young generation can grow to. Calculated in constructor.\n-  uint _max_young_length;\n-  void adjust_lengths_based_on_dram_memory();\n-\n-public:\n-  G1HeterogeneousHeapYoungGenSizer();\n-\n-  \/\/ Calculate the maximum length of the young gen given the number of regions\n-  \/\/ depending on the sizing algorithm.\n-  virtual void adjust_max_new_size(uint number_of_heap_regions);\n-\n-  virtual void heap_size_changed(uint new_number_of_heap_regions);\n-};\n-\n-#endif \/\/ SHARE_GC_G1_G1HETEROGENEOUSHEAPYOUNGGENSIZER_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeterogeneousHeapYoungGenSizer.hpp","additions":0,"deletions":51,"binary":false,"changes":51,"status":"deleted"},{"patch":"@@ -104,6 +104,0 @@\n-void G1PageBasedVirtualSpace::commit_and_set_special() {\n-  commit_internal(addr_to_page_index(_low_boundary), addr_to_page_index(_high_boundary));\n-  _special = true;\n-  _dirty.initialize(reserved_size()\/_page_size);\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1PageBasedVirtualSpace.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -137,2 +137,0 @@\n-  void commit_and_set_special();\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1PageBasedVirtualSpace.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -36,1 +36,0 @@\n-#include \"gc\/g1\/g1HeterogeneousHeapPolicy.hpp\"\n@@ -71,1 +70,1 @@\n-  _young_gen_sizer(G1YoungGenSizer::create_gen_sizer()),\n+  _young_gen_sizer(),\n@@ -91,9 +90,0 @@\n-  delete _young_gen_sizer;\n-}\n-\n-G1Policy* G1Policy::create_policy(STWGCTimer* gc_timer_stw) {\n-  if (G1Arguments::is_heterogeneous_heap()) {\n-    return new G1HeterogeneousHeapPolicy(gc_timer_stw);\n-  } else {\n-    return new G1Policy(gc_timer_stw);\n-  }\n@@ -111,1 +101,1 @@\n-    _young_list_fixed_length = _young_gen_sizer->min_desired_young_length();\n+    _young_list_fixed_length = _young_gen_sizer.min_desired_young_length();\n@@ -113,1 +103,1 @@\n-  _young_gen_sizer->adjust_max_new_size(_g1h->max_regions());\n+  _young_gen_sizer.adjust_max_new_size(_g1h->max_regions());\n@@ -187,1 +177,1 @@\n-  _young_gen_sizer->heap_size_changed(new_number_of_regions);\n+  _young_gen_sizer.heap_size_changed(new_number_of_regions);\n@@ -206,1 +196,1 @@\n-  return MAX2(_young_gen_sizer->min_desired_young_length(), desired_min_length);\n+  return MAX2(_young_gen_sizer.min_desired_young_length(), desired_min_length);\n@@ -213,1 +203,1 @@\n-  return _young_gen_sizer->max_desired_young_length();\n+  return _young_gen_sizer.max_desired_young_length();\n@@ -979,1 +969,1 @@\n-  return _young_gen_sizer->use_adaptive_young_list_length();\n+  return _young_gen_sizer.use_adaptive_young_list_length();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":7,"deletions":17,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -52,1 +52,0 @@\n-class G1YoungGenSizer;\n@@ -98,1 +97,1 @@\n-  G1YoungGenSizer* _young_gen_sizer;\n+  G1YoungGenSizer _young_gen_sizer;\n@@ -305,2 +304,0 @@\n-  static G1Policy* create_policy(STWGCTimer* gc_timer_stw);\n-\n@@ -319,1 +316,1 @@\n-  virtual void init(G1CollectedHeap* g1h, G1CollectionSet* collection_set);\n+  void init(G1CollectedHeap* g1h, G1CollectionSet* collection_set);\n@@ -331,1 +328,1 @@\n-  virtual void record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark);\n+  void record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark);\n@@ -335,1 +332,1 @@\n-  virtual void record_full_collection_end();\n+  void record_full_collection_end();\n@@ -452,4 +449,0 @@\n-\n-  virtual bool force_upgrade_to_full() {\n-    return false;\n-  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.hpp","additions":4,"deletions":11,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"logging\/log.hpp\"\n@@ -32,2 +31,0 @@\n-#include \"runtime\/java.hpp\"\n-#include \"runtime\/os.inline.hpp\"\n@@ -37,1 +34,0 @@\n-#include \"utilities\/formatBuffer.hpp\"\n@@ -215,138 +211,0 @@\n-static bool map_nvdimm_space(ReservedSpace rs) {\n-  assert(AllocateOldGenAt != NULL, \"\");\n-  int _backing_fd = os::create_file_for_heap(AllocateOldGenAt);\n-  if (_backing_fd == -1) {\n-    log_error(gc, init)(\"Could not create file for Old generation at location %s\", AllocateOldGenAt);\n-    return false;\n-  }\n-  \/\/ commit this memory in nv-dimm\n-  char* ret = os::attempt_map_memory_to_file_at(rs.base(), rs.size(), _backing_fd);\n-\n-  if (ret != rs.base()) {\n-    if (ret != NULL) {\n-      os::unmap_memory(rs.base(), rs.size());\n-    }\n-    log_error(gc, init)(\"Error in mapping Old Gen to given AllocateOldGenAt = %s\", AllocateOldGenAt);\n-    os::close(_backing_fd);\n-    return false;\n-  }\n-\n-  os::close(_backing_fd);\n-  return true;\n-}\n-\n-G1RegionToHeteroSpaceMapper::G1RegionToHeteroSpaceMapper(ReservedSpace rs,\n-                                                         size_t actual_size,\n-                                                         size_t page_size,\n-                                                         size_t alloc_granularity,\n-                                                         size_t commit_factor,\n-                                                         MEMFLAGS type) :\n-  G1RegionToSpaceMapper(rs, actual_size, page_size, alloc_granularity, commit_factor, type),\n-  _rs(rs),\n-  _dram_mapper(NULL),\n-  _num_committed_dram(0),\n-  _num_committed_nvdimm(0),\n-  _start_index_of_dram(0),\n-  _page_size(page_size),\n-  _commit_factor(commit_factor),\n-  _type(type) {\n-  assert(actual_size == 2 * MaxHeapSize, \"For 2-way heterogenuous heap, reserved space is two times MaxHeapSize\");\n-}\n-\n-bool G1RegionToHeteroSpaceMapper::initialize() {\n-  \/\/ Since we need to re-map the reserved space - 'Xmx' to nv-dimm and 'Xmx' to dram, we need to release the reserved memory first.\n-  \/\/ Because on some OSes (e.g. Windows) you cannot do a file mapping on memory reserved with regular mapping.\n-  os::release_memory(_rs.base(), _rs.size());\n-  \/\/ First half of size Xmx is for nv-dimm.\n-  ReservedSpace rs_nvdimm = _rs.first_part(MaxHeapSize);\n-  assert(rs_nvdimm.base() == _rs.base(), \"We should get the same base address\");\n-\n-  \/\/ Second half of reserved memory is mapped to dram.\n-  ReservedSpace rs_dram = _rs.last_part(MaxHeapSize);\n-\n-  assert(rs_dram.size() == rs_nvdimm.size() && rs_nvdimm.size() == MaxHeapSize, \"They all should be same\");\n-\n-  \/\/ Reserve dram memory\n-  char* base = os::attempt_reserve_memory_at(rs_dram.base(), rs_dram.size());\n-  if (base != rs_dram.base()) {\n-    if (base != NULL) {\n-      os::release_memory(base, rs_dram.size());\n-    }\n-    log_error(gc, init)(\"Error in re-mapping memory on dram during G1 heterogenous memory initialization\");\n-    return false;\n-  }\n-\n-  \/\/ We reserve and commit this entire space to NV-DIMM.\n-  if (!map_nvdimm_space(rs_nvdimm)) {\n-    log_error(gc, init)(\"Error in re-mapping memory to nv-dimm during G1 heterogenous memory initialization\");\n-    return false;\n-  }\n-\n-  if (_region_granularity >= (_page_size * _commit_factor)) {\n-    _dram_mapper = new G1RegionsLargerThanCommitSizeMapper(rs_dram, rs_dram.size(), _page_size, _region_granularity, _commit_factor, _type);\n-  } else {\n-    _dram_mapper = new G1RegionsSmallerThanCommitSizeMapper(rs_dram, rs_dram.size(), _page_size, _region_granularity, _commit_factor, _type);\n-  }\n-\n-  _start_index_of_dram = (uint)(rs_nvdimm.size() \/ _region_granularity);\n-  return true;\n-}\n-\n-void G1RegionToHeteroSpaceMapper::commit_regions(uint start_idx, size_t num_regions, WorkGang* pretouch_gang) {\n-  uint end_idx = (start_idx + (uint)num_regions - 1);\n-\n-  uint num_dram = end_idx >= _start_index_of_dram ? MIN2((end_idx - _start_index_of_dram + 1), (uint)num_regions) : 0;\n-  uint num_nvdimm = (uint)num_regions - num_dram;\n-\n-  if (num_nvdimm > 0) {\n-    \/\/ We do not need to commit nv-dimm regions, since they are committed in the beginning.\n-    _num_committed_nvdimm += num_nvdimm;\n-  }\n-  if (num_dram > 0) {\n-    _dram_mapper->commit_regions(start_idx > _start_index_of_dram ? (start_idx - _start_index_of_dram) : 0, num_dram, pretouch_gang);\n-    _num_committed_dram += num_dram;\n-  }\n-}\n-\n-void G1RegionToHeteroSpaceMapper::uncommit_regions(uint start_idx, size_t num_regions) {\n-  uint end_idx = (start_idx + (uint)num_regions - 1);\n-  uint num_dram = end_idx >= _start_index_of_dram ? MIN2((end_idx - _start_index_of_dram + 1), (uint)num_regions) : 0;\n-  uint num_nvdimm = (uint)num_regions - num_dram;\n-\n-  if (num_nvdimm > 0) {\n-    \/\/ We do not uncommit memory for nv-dimm regions.\n-    _num_committed_nvdimm -= num_nvdimm;\n-  }\n-\n-  if (num_dram > 0) {\n-    _dram_mapper->uncommit_regions(start_idx > _start_index_of_dram ? (start_idx - _start_index_of_dram) : 0, num_dram);\n-    _num_committed_dram -= num_dram;\n-  }\n-}\n-\n-uint G1RegionToHeteroSpaceMapper::num_committed_dram() const {\n-  return _num_committed_dram;\n-}\n-\n-uint G1RegionToHeteroSpaceMapper::num_committed_nvdimm() const {\n-  return _num_committed_nvdimm;\n-}\n-\n-G1RegionToSpaceMapper* G1RegionToSpaceMapper::create_heap_mapper(ReservedSpace rs,\n-                                                                 size_t actual_size,\n-                                                                 size_t page_size,\n-                                                                 size_t region_granularity,\n-                                                                 size_t commit_factor,\n-                                                                 MEMFLAGS type) {\n-  if (AllocateOldGenAt != NULL) {\n-    G1RegionToHeteroSpaceMapper* mapper = new G1RegionToHeteroSpaceMapper(rs, actual_size, page_size, region_granularity, commit_factor, type);\n-    if (!mapper->initialize()) {\n-      delete mapper;\n-      return NULL;\n-    }\n-    return (G1RegionToSpaceMapper*)mapper;\n-  } else {\n-    return create_mapper(rs, actual_size, page_size, region_granularity, commit_factor, type);\n-  }\n-}\n-\n@@ -365,4 +223,0 @@\n-\n-void G1RegionToSpaceMapper::commit_and_set_special() {\n-  _storage.commit_and_set_special();\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RegionToSpaceMapper.cpp","additions":0,"deletions":146,"binary":false,"changes":146,"status":"modified"},{"patch":"@@ -71,1 +71,0 @@\n-  void commit_and_set_special();\n@@ -89,7 +88,0 @@\n-\n-  static G1RegionToSpaceMapper* create_heap_mapper(ReservedSpace rs,\n-                                                   size_t actual_size,\n-                                                   size_t page_size,\n-                                                   size_t region_granularity,\n-                                                   size_t byte_translation_factor,\n-                                                   MEMFLAGS type);\n@@ -98,22 +90,0 @@\n-\/\/ G1RegionToSpaceMapper implementation where\n-\/\/ part of space is mapped to dram and part to nv-dimm\n-class G1RegionToHeteroSpaceMapper : public G1RegionToSpaceMapper {\n-private:\n-  ReservedSpace _rs;\n-  G1RegionToSpaceMapper* _dram_mapper;\n-  uint _num_committed_dram;\n-  uint _num_committed_nvdimm;\n-  uint _start_index_of_dram;\n-  size_t _page_size;\n-  size_t _commit_factor;\n-  MEMFLAGS _type;\n-\n-public:\n-  G1RegionToHeteroSpaceMapper(ReservedSpace rs, size_t used_size, size_t page_size, size_t region_granularity, size_t commit_factor, MEMFLAGS type);\n-  bool initialize();\n-  uint num_committed_dram() const;\n-  uint num_committed_nvdimm() const;\n-\n-  virtual void commit_regions(uint start_idx, size_t num_regions = 1, WorkGang* pretouch_workers = NULL);\n-  virtual void uncommit_regions(uint start_idx, size_t num_regions = 1);\n-};\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RegionToSpaceMapper.hpp","additions":0,"deletions":30,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -27,1 +27,0 @@\n-#include \"gc\/g1\/g1HeterogeneousHeapYoungGenSizer.hpp\"\n@@ -133,8 +132,0 @@\n-\n-G1YoungGenSizer* G1YoungGenSizer::create_gen_sizer() {\n-  if (G1Arguments::is_heterogeneous_heap()) {\n-    return new G1HeterogeneousHeapYoungGenSizer();\n-  } else {\n-    return new G1YoungGenSizer();\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGenSizer.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-class G1YoungGenSizer : public CHeapObj<mtGC> {\n+class G1YoungGenSizer {\n@@ -81,0 +81,3 @@\n+  uint _min_desired_young_length;\n+  uint _max_desired_young_length;\n+\n@@ -88,4 +91,0 @@\n-protected:\n-  uint _min_desired_young_length;\n-  uint _max_desired_young_length;\n-\n@@ -109,2 +108,0 @@\n-\n-  static G1YoungGenSizer* create_gen_sizer();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGenSizer.hpp","additions":4,"deletions":7,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -305,10 +305,1 @@\n-          range(0.0, (double)max_uintx)                                     \\\n-                                                                            \\\n-  product(uintx, G1YoungExpansionBufferPercent, 10, EXPERIMENTAL,           \\\n-               \"When heterogenous heap is enabled by AllocateOldGenAt \"     \\\n-               \"option, after every GC, young gen is re-sized which \"       \\\n-               \"involves system calls to commit\/uncommit memory. To \"       \\\n-               \"reduce these calls, we keep a buffer of extra regions to \"  \\\n-               \"absorb small changes in young gen length. This flag takes \" \\\n-               \"the buffer size as an percentage of young gen length\")      \\\n-               range(0, 100)\n+          range(0.0, (double)max_uintx)\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":1,"deletions":10,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -33,1 +33,0 @@\n-#include \"gc\/g1\/heterogeneousHeapRegionManager.hpp\"\n@@ -80,7 +79,0 @@\n-HeapRegionManager* HeapRegionManager::create_manager(G1CollectedHeap* heap) {\n-  if (G1Arguments::is_heterogeneous_heap()) {\n-    return new HeterogeneousHeapRegionManager((uint)(G1Arguments::heap_max_size_bytes() \/ HeapRegion::GrainBytes) \/*heap size as num of regions*\/);\n-  }\n-  return new HeapRegionManager();\n-}\n-\n@@ -672,1 +664,1 @@\n-    _n_workers(n_workers), _n_regions(G1CollectedHeap::heap()->_hrm->_allocated_heapregions_length), _claims(NULL) {\n+    _n_workers(n_workers), _n_regions(G1CollectedHeap::heap()->_hrm._allocated_heapregions_length), _claims(NULL) {\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionManager.cpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -138,1 +138,0 @@\n-protected:\n@@ -151,2 +150,2 @@\n-  virtual HeapRegion* allocate_humongous_from_free_list(uint num_regions);\n-  virtual HeapRegion* allocate_humongous_allow_expand(uint num_regions);\n+  HeapRegion* allocate_humongous_from_free_list(uint num_regions);\n+  HeapRegion* allocate_humongous_allow_expand(uint num_regions);\n@@ -165,13 +164,6 @@\n-  static HeapRegionManager* create_manager(G1CollectedHeap* heap);\n-\n-  virtual void initialize(G1RegionToSpaceMapper* heap_storage,\n-                          G1RegionToSpaceMapper* prev_bitmap,\n-                          G1RegionToSpaceMapper* next_bitmap,\n-                          G1RegionToSpaceMapper* bot,\n-                          G1RegionToSpaceMapper* cardtable,\n-                          G1RegionToSpaceMapper* card_counts);\n-\n-  \/\/ Prepare heap regions before and after full collection.\n-  \/\/ Nothing to be done in this class.\n-  virtual void prepare_for_full_collection_start() {}\n-  virtual void prepare_for_full_collection_end() {}\n+  void initialize(G1RegionToSpaceMapper* heap_storage,\n+                  G1RegionToSpaceMapper* prev_bitmap,\n+                  G1RegionToSpaceMapper* next_bitmap,\n+                  G1RegionToSpaceMapper* bot,\n+                  G1RegionToSpaceMapper* cardtable,\n+                  G1RegionToSpaceMapper* card_counts);\n@@ -183,1 +175,1 @@\n-  virtual HeapRegion* get_dummy_region() { return new_heap_region(0); }\n+  HeapRegion* get_dummy_region() { return new_heap_region(0); }\n@@ -216,1 +208,1 @@\n-  virtual HeapRegion* allocate_free_region(HeapRegionType type, uint requested_node_index);\n+  HeapRegion* allocate_free_region(HeapRegionType type, uint requested_node_index);\n@@ -254,1 +246,1 @@\n-  virtual uint max_length() const { return reserved_length(); }\n+  uint max_length() const { return reserved_length(); }\n@@ -264,1 +256,1 @@\n-  virtual uint expand_by(uint num_regions, WorkGang* pretouch_workers);\n+  uint expand_by(uint num_regions, WorkGang* pretouch_workers);\n@@ -269,1 +261,1 @@\n-  virtual uint expand_at(uint start, uint num_regions, WorkGang* pretouch_workers);\n+  uint expand_at(uint start, uint num_regions, WorkGang* pretouch_workers);\n@@ -272,1 +264,1 @@\n-  virtual uint expand_on_preferred_node(uint node_index);\n+  uint expand_on_preferred_node(uint node_index);\n@@ -279,1 +271,1 @@\n-  virtual uint find_highest_free(bool* expanded);\n+  uint find_highest_free(bool* expanded);\n@@ -294,1 +286,1 @@\n-  virtual uint shrink_by(uint num_regions_to_remove);\n+  uint shrink_by(uint num_regions_to_remove);\n@@ -300,1 +292,1 @@\n-  virtual void verify();\n+  void verify();\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionManager.hpp","additions":17,"deletions":25,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -290,15 +290,0 @@\n-uint FreeRegionList::num_of_regions_in_range(uint start, uint end) const {\n-  HeapRegion* cur = _head;\n-  uint num = 0;\n-  while (cur != NULL) {\n-    uint index = cur->hrm_index();\n-    if (index > end) {\n-      break;\n-    } else if (index >= start) {\n-      num++;\n-    }\n-    cur = cur->next();\n-  }\n-  return num;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionSet.cpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -237,2 +237,0 @@\n-  uint num_of_regions_in_range(uint start, uint end) const;\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionSet.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -120,1 +120,1 @@\n-  \/\/ Private constructor used static constants\n+  \/\/ Private constructor used for static constants\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionType.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1,533 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n-#include \"gc\/g1\/g1ConcurrentRefine.hpp\"\n-#include \"gc\/g1\/heapRegion.hpp\"\n-#include \"gc\/g1\/heapRegionManager.inline.hpp\"\n-#include \"gc\/g1\/heapRegionSet.inline.hpp\"\n-#include \"gc\/g1\/heterogeneousHeapRegionManager.hpp\"\n-#include \"memory\/allocation.hpp\"\n-\n-\n-HeterogeneousHeapRegionManager* HeterogeneousHeapRegionManager::manager() {\n-  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-  assert(g1h != NULL, \"Uninitialized access to HeterogeneousHeapRegionManager::manager()\");\n-\n-  HeapRegionManager* hrm = g1h->hrm();\n-  assert(hrm != NULL, \"Uninitialized access to HeterogeneousHeapRegionManager::manager()\");\n-  return (HeterogeneousHeapRegionManager*)hrm;\n-}\n-\n-void HeterogeneousHeapRegionManager::initialize(G1RegionToSpaceMapper* heap_storage,\n-                                                G1RegionToSpaceMapper* prev_bitmap,\n-                                                G1RegionToSpaceMapper* next_bitmap,\n-                                                G1RegionToSpaceMapper* bot,\n-                                                G1RegionToSpaceMapper* cardtable,\n-                                                G1RegionToSpaceMapper* card_counts) {\n-  HeapRegionManager::initialize(heap_storage, prev_bitmap, next_bitmap, bot, cardtable, card_counts);\n-\n-  \/\/ We commit bitmap for all regions during initialization and mark the bitmap space as special.\n-  \/\/ This allows regions to be un-committed while concurrent-marking threads are accessing the bitmap concurrently.\n-  _prev_bitmap_mapper->commit_and_set_special();\n-  _next_bitmap_mapper->commit_and_set_special();\n-}\n-\n-\/\/ expand_by() is called to grow the heap. We grow into nvdimm now.\n-\/\/ Dram regions are committed later as needed during mutator region allocation or\n-\/\/ when young list target length is determined after gc cycle.\n-uint HeterogeneousHeapRegionManager::expand_by(uint num_regions, WorkGang* pretouch_workers) {\n-  uint num_regions_possible = total_regions_committed() >= max_length() ? 0 : max_length() - total_regions_committed();\n-  uint num_expanded = expand_nvdimm(MIN2(num_regions, num_regions_possible), pretouch_workers);\n-  return num_expanded;\n-}\n-\n-\/\/ Expands heap starting from 'start' index. The question is should we expand from one memory (e.g. nvdimm) to another (e.g. dram).\n-\/\/ Looking at the code, expand_at() is called for humongous allocation where 'start' is in nv-dimm.\n-\/\/ So we only allocate regions in the same kind of memory as 'start'.\n-uint HeterogeneousHeapRegionManager::expand_at(uint start, uint num_regions, WorkGang* pretouch_workers) {\n-  if (num_regions == 0) {\n-    return 0;\n-  }\n-  uint target_num_regions = MIN2(num_regions, max_length() - total_regions_committed());\n-  uint end = is_in_nvdimm(start) ? end_index_of_nvdimm() : end_index_of_dram();\n-\n-  uint num_expanded = expand_in_range(start, end, target_num_regions, pretouch_workers);\n-  assert(total_regions_committed() <= max_length(), \"must be\");\n-  return num_expanded;\n-}\n-\n-\/\/ This function ensures that there are 'expected_num_regions' committed regions in dram.\n-\/\/ If new regions are committed, it un-commits that many regions from nv-dimm.\n-\/\/ If there are already more regions committed in dram, extra regions are un-committed.\n-void HeterogeneousHeapRegionManager::adjust_dram_regions(uint expected_num_regions, WorkGang* pretouch_workers) {\n-\n-  \/\/ Release back the extra regions allocated in evacuation failure scenario.\n-  if(_no_borrowed_regions > 0) {\n-    _no_borrowed_regions -= shrink_dram(_no_borrowed_regions);\n-    _no_borrowed_regions -= shrink_nvdimm(_no_borrowed_regions);\n-  }\n-\n-  if(expected_num_regions > free_list_dram_length()) {\n-    \/\/ If we are going to expand DRAM, we expand a little more so that we can absorb small variations in Young gen sizing.\n-    uint targeted_dram_regions = expected_num_regions * (1 + (double)G1YoungExpansionBufferPercent \/ 100);\n-    uint to_be_made_available = targeted_dram_regions - free_list_dram_length();\n-\n-#ifdef ASSERT\n-    uint total_committed_before = total_regions_committed();\n-#endif\n-    uint can_be_made_available = shrink_nvdimm(to_be_made_available);\n-    uint ret = expand_dram(can_be_made_available, pretouch_workers);\n-#ifdef ASSERT\n-    assert(ret == can_be_made_available, \"should be equal\");\n-    assert(total_committed_before == total_regions_committed(), \"invariant not met\");\n-#endif\n-  } else {\n-    uint to_be_released = free_list_dram_length() - expected_num_regions;\n-    \/\/ if number of extra DRAM regions is small, do not shrink.\n-    if (to_be_released < expected_num_regions * G1YoungExpansionBufferPercent \/ 100) {\n-      return;\n-    }\n-\n-#ifdef ASSERT\n-    uint total_committed_before = total_regions_committed();\n-#endif\n-    uint ret = shrink_dram(to_be_released);\n-    assert(ret == to_be_released, \"Should be able to shrink by given amount\");\n-    ret = expand_nvdimm(to_be_released, pretouch_workers);\n-#ifdef ASSERT\n-    assert(ret == to_be_released, \"Should be able to expand by given amount\");\n-    assert(total_committed_before == total_regions_committed(), \"invariant not met\");\n-#endif\n-  }\n-}\n-\n-uint HeterogeneousHeapRegionManager::total_regions_committed() const {\n-  return num_committed_dram() + num_committed_nvdimm();\n-}\n-\n-uint HeterogeneousHeapRegionManager::num_committed_dram() const {\n-  \/\/ This class does not keep count of committed regions in dram and nv-dimm.\n-  \/\/ G1RegionToHeteroSpaceMapper keeps this information.\n-  return static_cast<G1RegionToHeteroSpaceMapper*>(_heap_mapper)->num_committed_dram();\n-}\n-\n-uint HeterogeneousHeapRegionManager::num_committed_nvdimm() const {\n-  \/\/ See comment for num_committed_dram()\n-  return static_cast<G1RegionToHeteroSpaceMapper*>(_heap_mapper)->num_committed_nvdimm();\n-}\n-\n-\/\/ Return maximum number of regions that heap can expand to.\n-uint HeterogeneousHeapRegionManager::max_length() const {\n-  return _max_regions;\n-}\n-\n-uint HeterogeneousHeapRegionManager::find_unavailable_in_range(uint start_idx, uint end_idx, uint* res_idx) const {\n-  guarantee(res_idx != NULL, \"checking\");\n-  guarantee(start_idx <= (reserved_length() + 1), \"checking\");\n-\n-  uint num_regions = 0;\n-\n-  uint cur = start_idx;\n-  while (cur <= end_idx && is_available(cur)) {\n-    cur++;\n-  }\n-  if (cur == end_idx + 1) {\n-    return num_regions;\n-  }\n-  *res_idx = cur;\n-  while (cur <= end_idx && !is_available(cur)) {\n-    cur++;\n-  }\n-  num_regions = cur - *res_idx;\n-\n-#ifdef ASSERT\n-  for (uint i = *res_idx; i < (*res_idx + num_regions); i++) {\n-    assert(!is_available(i), \"just checking\");\n-  }\n-  assert(cur == end_idx + 1 || num_regions == 0 || is_available(cur),\n-    \"The region at the current position %u must be available or at the end\", cur);\n-#endif\n-  return num_regions;\n-}\n-\n-uint HeterogeneousHeapRegionManager::expand_dram(uint num_regions, WorkGang* pretouch_workers) {\n-  return expand_in_range(start_index_of_dram(), end_index_of_dram(), num_regions, pretouch_workers);\n-}\n-\n-uint HeterogeneousHeapRegionManager::expand_nvdimm(uint num_regions, WorkGang* pretouch_workers) {\n-  return expand_in_range(start_index_of_nvdimm(), end_index_of_nvdimm(), num_regions, pretouch_workers);\n-}\n-\n-\/\/ Follows same logic as expand_at() form HeapRegionManager.\n-uint HeterogeneousHeapRegionManager::expand_in_range(uint start, uint end, uint num_regions, WorkGang* pretouch_gang) {\n-\n-  uint so_far = 0;\n-  uint chunk_start = 0;\n-  uint num_last_found = 0;\n-  while (so_far < num_regions &&\n-         (num_last_found = find_unavailable_in_range(start, end, &chunk_start)) > 0) {\n-    uint to_commit = MIN2(num_regions - so_far, num_last_found);\n-    make_regions_available(chunk_start, to_commit, pretouch_gang);\n-    so_far += to_commit;\n-    start = chunk_start + to_commit + 1;\n-  }\n-\n-  return so_far;\n-}\n-\n-\/\/ Shrink in the range of indexes which are reserved for dram.\n-uint HeterogeneousHeapRegionManager::shrink_dram(uint num_regions, bool update_free_list) {\n-  return shrink_in_range(start_index_of_dram(), end_index_of_dram(), num_regions, update_free_list);\n-}\n-\n-\/\/ Shrink in the range of indexes which are reserved for nv-dimm.\n-uint HeterogeneousHeapRegionManager::shrink_nvdimm(uint num_regions, bool update_free_list) {\n-  return shrink_in_range(start_index_of_nvdimm(), end_index_of_nvdimm(), num_regions, update_free_list);\n-}\n-\n-\/\/ Find empty regions in given range, un-commit them and return the count.\n-uint HeterogeneousHeapRegionManager::shrink_in_range(uint start, uint end, uint num_regions, bool update_free_list) {\n-\n-  if (num_regions == 0) {\n-    return 0;\n-  }\n-  uint so_far = 0;\n-  uint idx_last_found = 0;\n-  uint num_last_found;\n-  while (so_far < num_regions &&\n-         (num_last_found = find_empty_in_range_reverse(start, end, &idx_last_found)) > 0) {\n-    uint to_uncommit = MIN2(num_regions - so_far, num_last_found);\n-    if(update_free_list) {\n-      _free_list.remove_starting_at(at(idx_last_found + num_last_found - to_uncommit), to_uncommit);\n-    }\n-    uncommit_regions(idx_last_found + num_last_found - to_uncommit, to_uncommit);\n-    so_far += to_uncommit;\n-    end = idx_last_found;\n-  }\n-  return so_far;\n-}\n-\n-uint HeterogeneousHeapRegionManager::find_empty_in_range_reverse(uint start_idx, uint end_idx, uint* res_idx) {\n-  guarantee(res_idx != NULL, \"checking\");\n-  guarantee(start_idx < reserved_length(), \"checking\");\n-  guarantee(end_idx < reserved_length(), \"checking\");\n-  if(start_idx > end_idx) {\n-    return 0;\n-  }\n-\n-  uint num_regions_found = 0;\n-\n-  jlong cur = end_idx;\n-  while (cur >= start_idx && !(is_available(cur) && at(cur)->is_empty())) {\n-    cur--;\n-  }\n-  if (cur == start_idx - 1) {\n-    return num_regions_found;\n-  }\n-  jlong old_cur = cur;\n-  \/\/ cur indexes the first empty region\n-  while (cur >= start_idx && is_available(cur) && at(cur)->is_empty()) {\n-    cur--;\n-  }\n-  *res_idx = cur + 1;\n-  num_regions_found = old_cur - cur;\n-\n-#ifdef ASSERT\n-  for (uint i = *res_idx; i < (*res_idx + num_regions_found); i++) {\n-    assert(at(i)->is_empty(), \"just checking\");\n-  }\n-#endif\n-  return num_regions_found;\n-}\n-\n-HeapRegion* HeterogeneousHeapRegionManager::allocate_free_region(HeapRegionType type, uint node_index) {\n-\n-  \/\/ We want to prevent mutators from proceeding when we have borrowed regions from the last collection. This\n-  \/\/ will force a full collection to remedy the situation.\n-  \/\/ Free region requests from GC threads can proceed.\n-  if(type.is_eden() || type.is_humongous()) {\n-    if(has_borrowed_regions()) {\n-      return NULL;\n-    }\n-  }\n-\n-  \/\/ old and humongous regions are allocated from nv-dimm; eden and survivor regions are allocated from dram\n-  \/\/ assumption: dram regions take higher indexes\n-  bool from_nvdimm = (type.is_old() || type.is_humongous()) ? true : false;\n-  bool from_head = from_nvdimm;\n-  HeapRegion* hr = _free_list.remove_region(from_head);\n-\n-  if (hr != NULL && ( (from_nvdimm && !is_in_nvdimm(hr->hrm_index())) || (!from_nvdimm && !is_in_dram(hr->hrm_index())) ) ) {\n-    _free_list.add_ordered(hr);\n-    hr = NULL;\n-  }\n-\n-#ifdef ASSERT\n-  uint total_committed_before = total_regions_committed();\n-#endif\n-\n-  if (hr == NULL) {\n-    if (!from_nvdimm) {\n-      uint ret = shrink_nvdimm(1);\n-      if (ret == 1) {\n-        ret = expand_dram(1, NULL);\n-        assert(ret == 1, \"We should be able to commit one region\");\n-        hr = _free_list.remove_region(from_head);\n-      }\n-    }\n-    else { \/*is_old*\/\n-      uint ret = shrink_dram(1);\n-      if (ret == 1) {\n-        ret = expand_nvdimm(1, NULL);\n-        assert(ret == 1, \"We should be able to commit one region\");\n-        hr = _free_list.remove_region(from_head);\n-      }\n-    }\n-  }\n-#ifdef ASSERT\n-  assert(total_committed_before == total_regions_committed(), \"invariant not met\");\n-#endif\n-\n-  \/\/ When an old region is requested (which happens during collection pause) and we can't find any empty region\n-  \/\/ in the set of available regions (which is an evacuation failure scenario), we borrow (or pre-allocate) an unavailable region\n-  \/\/ from nv-dimm. This region is used to evacuate surviving objects from eden, survivor or old.\n-  if(hr == NULL && type.is_old()) {\n-    hr = borrow_old_region_for_gc();\n-  }\n-\n-  if (hr != NULL) {\n-    assert(hr->next() == NULL, \"Single region should not have next\");\n-    assert(is_available(hr->hrm_index()), \"Must be committed\");\n-  }\n-  return hr;\n-}\n-\n-HeapRegion* HeterogeneousHeapRegionManager::allocate_humongous_from_free_list(uint num_regions) {\n-  if (has_borrowed_regions()) {\n-      return NULL;\n-  }\n-  uint candidate = find_contiguous(start_index_of_nvdimm(), end_index_of_nvdimm(), num_regions, true);\n-  if (candidate == G1_NO_HRM_INDEX) {\n-    return NULL;\n-  }\n-  return allocate_free_regions_starting_at(candidate, num_regions);\n-}\n-\n-HeapRegion* HeterogeneousHeapRegionManager::allocate_humongous_allow_expand(uint num_regions) {\n-  if (has_borrowed_regions()) {\n-    return NULL;\n-  }\n-  uint candidate = find_contiguous(start_index_of_nvdimm(), end_index_of_nvdimm(), num_regions, false);\n-  if (candidate == G1_NO_HRM_INDEX) {\n-    return NULL;\n-  }\n-\n-  expand_exact(candidate, num_regions, NULL);\n-  return allocate_free_regions_starting_at(candidate, num_regions);\n-}\n-\n-uint HeterogeneousHeapRegionManager::find_contiguous(size_t start, size_t end, size_t num, bool empty_only) {\n-  uint found = 0;\n-  size_t length_found = 0;\n-  uint cur = (uint)start;\n-  uint length_unavailable = 0;\n-\n-  while (length_found < num && cur <= end) {\n-    HeapRegion* hr = _regions.get_by_index(cur);\n-    if ((!empty_only && !is_available(cur)) || (is_available(cur) && hr != NULL && hr->is_empty())) {\n-      \/\/ This region is a potential candidate for allocation into.\n-      if (!is_available(cur)) {\n-        if(shrink_dram(1) == 1) {\n-          uint ret = expand_in_range(cur, cur, 1, NULL);\n-          assert(ret == 1, \"We should be able to expand at this index\");\n-        } else {\n-          length_unavailable++;\n-        }\n-      }\n-      length_found++;\n-    }\n-    else {\n-      \/\/ This region is not a candidate. The next region is the next possible one.\n-      found = cur + 1;\n-      length_found = 0;\n-    }\n-    cur++;\n-  }\n-\n-  if (length_found == num) {\n-    for (uint i = found; i < (found + num); i++) {\n-      HeapRegion* hr = _regions.get_by_index(i);\n-      \/\/ sanity check\n-      guarantee((!empty_only && !is_available(i)) || (is_available(i) && hr != NULL && hr->is_empty()),\n-                \"Found region sequence starting at \" UINT32_FORMAT \", length \" SIZE_FORMAT\n-                \" that is not empty at \" UINT32_FORMAT \". Hr is \" PTR_FORMAT, found, num, i, p2i(hr));\n-    }\n-    if (!empty_only && length_unavailable > (max_length() - total_regions_committed())) {\n-      \/\/ if 'length_unavailable' number of regions will be made available, we will exceed max regions.\n-      return G1_NO_HRM_INDEX;\n-    }\n-    return found;\n-  }\n-  else {\n-    return G1_NO_HRM_INDEX;\n-  }\n-}\n-\n-uint HeterogeneousHeapRegionManager::find_highest_free(bool* expanded) {\n-  \/\/ Loop downwards from the highest dram region index, looking for an\n-  \/\/ entry which is either free or not yet committed.  If not yet\n-  \/\/ committed, expand_at that index.\n-  uint curr = end_index_of_dram();\n-  while (true) {\n-    HeapRegion *hr = _regions.get_by_index(curr);\n-    if (hr == NULL && !(total_regions_committed() < _max_regions)) {\n-      uint res = shrink_nvdimm(1);\n-      if (res == 1) {\n-        res = expand_in_range(curr, curr, 1, NULL);\n-        assert(res == 1, \"We should be able to expand since shrink was successful\");\n-        *expanded = true;\n-        return curr;\n-      }\n-    }\n-    else {\n-      if (hr->is_free()) {\n-        *expanded = false;\n-        return curr;\n-      }\n-    }\n-    if (curr == start_index_of_dram()) {\n-      return G1_NO_HRM_INDEX;\n-    }\n-    curr--;\n-  }\n-}\n-\n-\/\/ We need to override this since region 0 which serves are dummy region in base class may not be available here.\n-\/\/ This is a corner condition when either number of regions is small. When adaptive sizing is used, initial heap size\n-\/\/ could be just one region.  This region is commited in dram to be used for young generation, leaving region 0 (which is in nvdimm)\n-\/\/ unavailable.\n-HeapRegion* HeterogeneousHeapRegionManager::get_dummy_region() {\n-  uint curr = 0;\n-\n-  while (curr < _regions.length()) {\n-    if (is_available(curr)) {\n-      return new_heap_region(curr);\n-    }\n-    curr++;\n-  }\n-  assert(false, \"We should always find a region available for dummy region\");\n-  return NULL;\n-}\n-\n-\/\/ First shrink in dram, then in nv-dimm.\n-uint HeterogeneousHeapRegionManager::shrink_by(uint num_regions) {\n-  \/\/ This call is made at end of full collection. Before making this call the region sets are tore down (tear_down_region_sets()).\n-  \/\/ So shrink() calls below do not need to remove uncomitted regions from free list.\n-  uint ret = shrink_dram(num_regions, false \/* update_free_list *\/);\n-  ret += shrink_nvdimm(num_regions - ret, false \/* update_free_list *\/);\n-  return ret;\n-}\n-\n-void HeterogeneousHeapRegionManager::verify() {\n-  HeapRegionManager::verify();\n-}\n-\n-uint HeterogeneousHeapRegionManager::free_list_dram_length() const {\n-  return _free_list.num_of_regions_in_range(start_index_of_dram(), end_index_of_dram());\n-}\n-\n-uint HeterogeneousHeapRegionManager::free_list_nvdimm_length() const {\n-  return _free_list.num_of_regions_in_range(start_index_of_nvdimm(), end_index_of_nvdimm());\n-}\n-\n-bool HeterogeneousHeapRegionManager::is_in_nvdimm(uint index) const {\n-  return index >= start_index_of_nvdimm() && index <= end_index_of_nvdimm();\n-}\n-\n-bool HeterogeneousHeapRegionManager::is_in_dram(uint index) const {\n-  return index >= start_index_of_dram() && index <= end_index_of_dram();\n-}\n-\n-\/\/ We have to make sure full collection copies all surviving objects to NV-DIMM.\n-\/\/ We might not have enough regions in nvdimm_set, so we need to make more regions on NV-DIMM available for full collection.\n-\/\/ Note: by doing this we are breaking the in-variant that total number of committed regions is equal to current heap size.\n-\/\/ After full collection ends, we will re-establish this in-variant by freeing DRAM regions.\n-void HeterogeneousHeapRegionManager::prepare_for_full_collection_start() {\n-  _total_commited_before_full_gc = total_regions_committed() - _no_borrowed_regions;\n-  _no_borrowed_regions = 0;\n-  expand_nvdimm(num_committed_dram(), NULL);\n-  remove_all_free_regions();\n-}\n-\n-\/\/ We need to bring back the total committed regions to before full collection start.\n-\/\/ Unless we are close to OOM, all regular (not pinned) regions in DRAM should be free.\n-\/\/ We shrink all free regions in DRAM and if needed from NV-DIMM (when there are pinned DRAM regions)\n-\/\/ If we can't bring back committed regions count to _total_commited_before_full_gc, we keep the extra count in _no_borrowed_regions.\n-\/\/ When this GC finishes, new regions won't be allocated since has_borrowed_regions() is true. VM will be forced to re-try GC\n-\/\/ with clear soft references followed by OOM error in worst case.\n-void HeterogeneousHeapRegionManager::prepare_for_full_collection_end() {\n-  uint shrink_size = total_regions_committed() - _total_commited_before_full_gc;\n-  uint so_far = 0;\n-  uint idx_last_found = 0;\n-  uint num_last_found;\n-  uint end = (uint)_regions.length() - 1;\n-  while (so_far < shrink_size &&\n-         (num_last_found = find_empty_in_range_reverse(0, end, &idx_last_found)) > 0) {\n-    uint to_uncommit = MIN2(shrink_size - so_far, num_last_found);\n-    uncommit_regions(idx_last_found + num_last_found - to_uncommit, to_uncommit);\n-    so_far += to_uncommit;\n-    end = idx_last_found;\n-  }\n-  \/\/ See comment above the function.\n-  _no_borrowed_regions = shrink_size - so_far;\n-}\n-\n-uint HeterogeneousHeapRegionManager::start_index_of_dram() const { return _max_regions;}\n-\n-uint HeterogeneousHeapRegionManager::end_index_of_dram() const { return 2*_max_regions - 1; }\n-\n-uint HeterogeneousHeapRegionManager::start_index_of_nvdimm() const { return 0; }\n-\n-uint HeterogeneousHeapRegionManager::end_index_of_nvdimm() const { return _max_regions - 1; }\n-\n-\/\/ This function is called when there are no free nv-dimm regions.\n-\/\/ It borrows a region from the set of unavailable regions in nv-dimm for GC purpose.\n-HeapRegion* HeterogeneousHeapRegionManager::borrow_old_region_for_gc() {\n-  assert(free_list_nvdimm_length() == 0, \"this function should be called only when there are no nv-dimm regions in free list\");\n-\n-  uint ret = expand_nvdimm(1, NULL);\n-  if(ret != 1) {\n-    return NULL;\n-  }\n-  HeapRegion* hr = _free_list.remove_region(true \/*from_head*\/);\n-  assert(is_in_nvdimm(hr->hrm_index()), \"allocated region should be in nv-dimm\");\n-  _no_borrowed_regions++;\n-  return hr;\n-}\n-\n-bool HeterogeneousHeapRegionManager::has_borrowed_regions() const {\n-  return _no_borrowed_regions > 0;\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/heterogeneousHeapRegionManager.cpp","additions":0,"deletions":533,"binary":false,"changes":533,"status":"deleted"},{"patch":"@@ -1,146 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_HETEROGENEOUSHEAPREGIONMANAGER_HPP\n-#define SHARE_GC_G1_HETEROGENEOUSHEAPREGIONMANAGER_HPP\n-\n-#include \"gc\/g1\/heapRegionManager.hpp\"\n-\n-\/\/ This class manages heap regions on heterogenous memory comprising of dram and nv-dimm.\n-\/\/ Regions in dram (dram_set) are used for young objects and archive regions (CDS).\n-\/\/ Regions in nv-dimm (nvdimm_set) are used for old objects and humongous objects.\n-\/\/ At any point there are some regions committed on dram and some on nv-dimm with the following guarantees:\n-\/\/   1. The total number of regions committed in dram and nv-dimm equals the current size of heap.\n-\/\/   2. Consequently, total number of regions committed is less than or equal to Xmx.\n-\/\/   3. To maintain the guarantee stated by 1., whenever one set grows (new regions committed), the other set shrinks (regions un-committed).\n-\/\/      3a. If more dram regions are needed (young generation expansion), corresponding number of regions in nv-dimm are un-committed.\n-\/\/      3b. When old generation or humongous set grows, and new regions need to be committed to nv-dimm, corresponding number of regions\n-\/\/            are un-committed in dram.\n-class HeterogeneousHeapRegionManager : public HeapRegionManager {\n-  const uint _max_regions;\n-  uint _max_dram_regions;\n-  uint _max_nvdimm_regions;\n-  uint _start_index_of_nvdimm;\n-  uint _total_commited_before_full_gc;\n-  uint _no_borrowed_regions;\n-\n-  uint total_regions_committed() const;\n-  uint num_committed_dram() const;\n-  uint num_committed_nvdimm() const;\n-\n-  \/\/ Similar to find_unavailable_from_idx() function from base class, difference is this function searches in range [start, end].\n-  uint find_unavailable_in_range(uint start_idx, uint end_idx, uint* res_idx) const;\n-\n-  \/\/ Expand into dram. Maintains the invariant that total number of committed regions is less than current heap size.\n-  uint expand_dram(uint num_regions, WorkGang* pretouch_workers);\n-\n-  \/\/ Expand into nv-dimm.\n-  uint expand_nvdimm(uint num_regions, WorkGang* pretouch_workers);\n-\n-  \/\/ Expand by finding unavailable regions in [start, end] range.\n-  uint expand_in_range(uint start, uint end, uint num_regions, WorkGang* pretouch_workers);\n-\n-  \/\/ Shrink dram set of regions.\n-  uint shrink_dram(uint num_regions, bool update_free_list = true);\n-\n-  \/\/ Shrink nv-dimm set of regions.\n-  uint shrink_nvdimm(uint num_regions, bool update_free_list = true);\n-\n-  \/\/ Shrink regions from [start, end] range.\n-  uint shrink_in_range(uint start, uint end, uint num_regions, bool update_free_list = true);\n-\n-  \/\/ Similar to find_empty_from_idx_reverse() in base class. Only here it searches in a range.\n-  uint find_empty_in_range_reverse(uint start_idx, uint end_idx, uint* res_idx);\n-\n-  \/\/ Similar to find_contiguous() in base class, with [start, end] range\n-  uint find_contiguous(size_t start, size_t end, size_t num, bool empty_only);\n-\n-  \/\/ This function is called when there are no free nv-dimm regions.\n-  \/\/ It borrows a region from the set of unavailable regions in nv-dimm for GC purpose.\n-  HeapRegion* borrow_old_region_for_gc();\n-\n-  uint free_list_dram_length() const;\n-  uint free_list_nvdimm_length() const;\n-\n-  \/\/ is region with given index in nv-dimm?\n-  bool is_in_nvdimm(uint index) const;\n-  bool is_in_dram(uint index) const;\n-\n-public:\n-\n-  \/\/ Empty constructor, we'll initialize it with the initialize() method.\n-  HeterogeneousHeapRegionManager(uint num_regions) : _max_regions(num_regions), _max_dram_regions(0),\n-                                                     _max_nvdimm_regions(0), _start_index_of_nvdimm(0),\n-                                                     _total_commited_before_full_gc(0), _no_borrowed_regions(0)\n-  {}\n-\n-  static HeterogeneousHeapRegionManager* manager();\n-\n-  virtual void initialize(G1RegionToSpaceMapper* heap_storage,\n-                          G1RegionToSpaceMapper* prev_bitmap,\n-                          G1RegionToSpaceMapper* next_bitmap,\n-                          G1RegionToSpaceMapper* bot,\n-                          G1RegionToSpaceMapper* cardtable,\n-                          G1RegionToSpaceMapper* card_counts);\n-\n-  uint start_index_of_nvdimm() const;\n-  uint start_index_of_dram() const;\n-  uint end_index_of_nvdimm() const;\n-  uint end_index_of_dram() const;\n-\n-  \/\/ Override.\n-  HeapRegion* get_dummy_region();\n-\n-  \/\/ Adjust dram_set to provision 'expected_num_regions' regions.\n-  void adjust_dram_regions(uint expected_num_regions, WorkGang* pretouch_workers);\n-\n-  \/\/ Prepare heap regions before and after full collection.\n-  void prepare_for_full_collection_start();\n-  void prepare_for_full_collection_end();\n-\n-  virtual HeapRegion* allocate_free_region(HeapRegionType type, uint node_index);\n-  virtual HeapRegion* allocate_humongous_from_free_list(uint num_regions);\n-  virtual HeapRegion* allocate_humongous_allow_expand(uint num_regions);\n-\n-  \/\/ Return maximum number of regions that heap can expand to.\n-  uint max_length() const;\n-\n-  \/\/ Override. Expand in nv-dimm.\n-  uint expand_by(uint num_regions, WorkGang* pretouch_workers);\n-\n-  \/\/ Override.\n-  uint expand_at(uint start, uint num_regions, WorkGang* pretouch_workers);\n-\n-  \/\/ Overrides base class implementation to find highest free region in dram.\n-  uint find_highest_free(bool* expanded);\n-\n-  \/\/ Override. This fuction is called to shrink the heap, we shrink in dram first then in nv-dimm.\n-  uint shrink_by(uint num_regions_to_remove);\n-\n-  bool has_borrowed_regions() const;\n-\n-  void verify();\n-};\n-\n-#endif \/\/ SHARE_GC_G1_HETEROGENEOUSHEAPREGIONMANAGER_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/heterogeneousHeapRegionManager.hpp","additions":0,"deletions":146,"binary":false,"changes":146,"status":"deleted"},{"patch":"@@ -58,1 +58,1 @@\n-  nonstatic_field(G1CollectedHeap, _hrm,                HeapRegionManager*)   \\\n+  nonstatic_field(G1CollectedHeap, _hrm,                HeapRegionManager)    \\\n","filename":"src\/hotspot\/share\/gc\/g1\/vmStructs_g1.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -40,2 +40,0 @@\n-static const double MaxRamFractionForYoung = 0.8;\n-\n@@ -119,4 +117,0 @@\n-  if (is_heterogeneous_heap()) {\n-    initialize_heterogeneous();\n-  }\n-\n@@ -139,55 +133,0 @@\n-\/\/ Check the available dram memory to limit NewSize and MaxNewSize before\n-\/\/ calling base class initialize_flags().\n-void ParallelArguments::initialize_heterogeneous() {\n-  FormatBuffer<100> calc_str(\"\");\n-\n-  julong phys_mem;\n-  \/\/ If MaxRam is specified, we use that as maximum physical memory available.\n-  if (FLAG_IS_DEFAULT(MaxRAM)) {\n-    phys_mem = os::physical_memory();\n-    calc_str.append(\"Physical_Memory\");\n-  } else {\n-    phys_mem = (julong)MaxRAM;\n-    calc_str.append(\"MaxRAM\");\n-  }\n-\n-  julong reasonable_max = phys_mem;\n-\n-  \/\/ If either MaxRAMFraction or MaxRAMPercentage is specified, we use them to calculate\n-  \/\/ reasonable max size of young generation.\n-  if (!FLAG_IS_DEFAULT(MaxRAMFraction)) {\n-    reasonable_max = (julong)(phys_mem \/ MaxRAMFraction);\n-    calc_str.append(\" \/ MaxRAMFraction\");\n-  } else if (!FLAG_IS_DEFAULT(MaxRAMPercentage)) {\n-    reasonable_max = (julong)((phys_mem * MaxRAMPercentage) \/ 100);\n-    calc_str.append(\" * MaxRAMPercentage \/ 100\");\n-  } else {\n-    \/\/ We use our own fraction to calculate max size of young generation.\n-    reasonable_max = phys_mem * MaxRamFractionForYoung;\n-    calc_str.append(\" * %0.2f\", MaxRamFractionForYoung);\n-  }\n-  reasonable_max = align_up(reasonable_max, GenAlignment);\n-\n-  if (MaxNewSize > reasonable_max) {\n-    if (FLAG_IS_CMDLINE(MaxNewSize)) {\n-      log_warning(gc, ergo)(\"Setting MaxNewSize to \" SIZE_FORMAT \" based on dram available (calculation = align(%s))\",\n-                            (size_t)reasonable_max, calc_str.buffer());\n-    } else {\n-      log_info(gc, ergo)(\"Setting MaxNewSize to \" SIZE_FORMAT \" based on dram available (calculation = align(%s)). \"\n-                         \"Dram usage can be lowered by setting MaxNewSize to a lower value\", (size_t)reasonable_max, calc_str.buffer());\n-    }\n-    MaxNewSize = reasonable_max;\n-  }\n-  if (NewSize > reasonable_max) {\n-    if (FLAG_IS_CMDLINE(NewSize)) {\n-      log_warning(gc, ergo)(\"Setting NewSize to \" SIZE_FORMAT \" based on dram available (calculation = align(%s))\",\n-                            (size_t)reasonable_max, calc_str.buffer());\n-    }\n-    NewSize = reasonable_max;\n-  }\n-}\n-\n-bool ParallelArguments::is_heterogeneous_heap() {\n-  return AllocateOldGenAt != NULL;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelArguments.cpp","additions":0,"deletions":61,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -39,1 +39,0 @@\n-  void initialize_heterogeneous();\n@@ -46,2 +45,0 @@\n-  \/\/ Heterogeneous heap support\n-  static bool is_heterogeneous_heap();\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelArguments.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -86,2 +86,1 @@\n-  \/\/ If OldGen is allocated on nv-dimm, we need to split the reservation (this is required for windows).\n-  ReservedSpace old_rs   = heap_rs.first_part(MaxOldSize, ParallelArguments::is_heterogeneous_heap() \/* split *\/);\n+  ReservedSpace old_rs   = heap_rs.first_part(MaxOldSize);\n@@ -126,2 +125,1 @@\n-  assert(ParallelArguments::is_heterogeneous_heap() ||\n-         (old_gen()->virtual_space()->high_boundary() ==\n+  assert((old_gen()->virtual_space()->high_boundary() ==\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1,83 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/parallel\/psFileBackedVirtualspace.hpp\"\n-#include \"memory\/virtualspace.hpp\"\n-#include \"runtime\/os.inline.hpp\"\n-\n-PSFileBackedVirtualSpace::PSFileBackedVirtualSpace(ReservedSpace rs, size_t alignment, const char* path) : PSVirtualSpace(rs, alignment),\n-                                                   _file_path(path), _fd(-1), _mapping_succeeded(false) {\n-  assert(!rs.special(), \"ReservedSpace passed to PSFileBackedVirtualSpace cannot be special\");\n-}\n-\n-bool PSFileBackedVirtualSpace::initialize() {\n-  _fd = os::create_file_for_heap(_file_path);\n-  if (_fd == -1) {\n-    return false;\n-  }\n-  \/\/ We map the reserved space to a file at initialization.\n-  char* ret = os::replace_existing_mapping_with_file_mapping(reserved_low_addr(), reserved_size(), _fd);\n-  if (ret != reserved_low_addr()) {\n-    os::close(_fd);\n-    return false;\n-  }\n-  \/\/ _mapping_succeeded is false if we return before this point.\n-  \/\/ expand calls later check value of this flag and return error if it is false.\n-  _mapping_succeeded = true;\n-  _special = true;\n-  os::close(_fd);\n-  return true;\n-}\n-\n-bool PSFileBackedVirtualSpace::expand_by(size_t bytes) {\n-  assert(special(), \"Since entire space is committed at initialization, _special should always be true for PSFileBackedVirtualSpace\");\n-\n-  \/\/ if mapping did not succeed during intialization return false\n-  if (!_mapping_succeeded) {\n-    return false;\n-  }\n-  return PSVirtualSpace::expand_by(bytes);\n-\n-}\n-\n-bool PSFileBackedVirtualSpace::shrink_by(size_t bytes) {\n-  assert(special(), \"Since entire space is committed at initialization, _special should always be true for PSFileBackedVirtualSpace\");\n-  return PSVirtualSpace::shrink_by(bytes);\n-}\n-\n-size_t PSFileBackedVirtualSpace::expand_into(PSVirtualSpace* space, size_t bytes) {\n-  \/\/ not supported. Since doing this will change page mapping which will lead to large TLB penalties.\n-  assert(false, \"expand_into() should not be called for PSFileBackedVirtualSpace\");\n-  return 0;\n-}\n-\n-void PSFileBackedVirtualSpace::release() {\n-  os::close(_fd);\n-  _fd = -1;\n-  _file_path = NULL;\n-\n-  PSVirtualSpace::release();\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psFileBackedVirtualspace.cpp","additions":0,"deletions":83,"binary":false,"changes":83,"status":"deleted"},{"patch":"@@ -1,44 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_PARALLEL_PSFILEBACKEDVIRTUALSPACE_HPP\n-#define SHARE_GC_PARALLEL_PSFILEBACKEDVIRTUALSPACE_HPP\n-\n-#include \"gc\/parallel\/psVirtualspace.hpp\"\n-\n-class PSFileBackedVirtualSpace : public PSVirtualSpace {\n-private:\n-  const char* _file_path;\n-  int _fd;\n-  bool _mapping_succeeded;\n-public:\n-  PSFileBackedVirtualSpace(ReservedSpace rs, size_t alignment, const char* file_path);\n-\n-  bool   initialize();\n-  bool   expand_by(size_t bytes);\n-  bool   shrink_by(size_t bytes);\n-  size_t expand_into(PSVirtualSpace* space, size_t bytes);\n-  void   release();\n-};\n-#endif \/\/ SHARE_GC_PARALLEL_PSFILEBACKEDVIRTUALSPACE_HPP\n","filename":"src\/hotspot\/share\/gc\/parallel\/psFileBackedVirtualspace.hpp","additions":0,"deletions":44,"binary":false,"changes":44,"status":"deleted"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"gc\/parallel\/psFileBackedVirtualspace.hpp\"\n@@ -65,8 +64,1 @@\n-  if(ParallelArguments::is_heterogeneous_heap()) {\n-    _virtual_space = new PSFileBackedVirtualSpace(rs, alignment, AllocateOldGenAt);\n-    if (!(static_cast <PSFileBackedVirtualSpace*>(_virtual_space))->initialize()) {\n-      vm_exit_during_initialization(\"Could not map space for PSOldGen at given AllocateOldGenAt path\");\n-    }\n-  } else {\n-    _virtual_space = new PSVirtualSpace(rs, alignment);\n-  }\n+  _virtual_space = new PSVirtualSpace(rs, alignment);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.cpp","additions":1,"deletions":9,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -33,1 +33,0 @@\n-#include \"utilities\/defaultStream.hpp\"\n@@ -62,9 +61,0 @@\n-\n-  if (!FLAG_IS_DEFAULT(AllocateOldGenAt)) {\n-    \/\/ CompressedOops not supported when AllocateOldGenAt is set.\n-    LP64_ONLY(FLAG_SET_DEFAULT(UseCompressedOops, false));\n-    LP64_ONLY(FLAG_SET_DEFAULT(UseCompressedClassPointers, false));\n-    \/\/ When AllocateOldGenAt is set, we cannot use largepages for entire heap memory.\n-    \/\/ Only young gen which is allocated in dram can use large pages, but we currently don't support that.\n-    FLAG_SET_DEFAULT(UseLargePages, false);\n-  }\n@@ -97,15 +87,0 @@\n-bool GCArguments::check_args_consistency() {\n-  bool status = true;\n-  if (!FLAG_IS_DEFAULT(AllocateHeapAt) && !FLAG_IS_DEFAULT(AllocateOldGenAt)) {\n-    jio_fprintf(defaultStream::error_stream(),\n-      \"AllocateHeapAt and AllocateOldGenAt cannot be used together.\\n\");\n-    status = false;\n-  }\n-  if (!FLAG_IS_DEFAULT(AllocateOldGenAt) && (UseSerialGC || UseEpsilonGC || UseZGC)) {\n-    jio_fprintf(defaultStream::error_stream(),\n-      \"AllocateOldGenAt is not supported for selected GC.\\n\");\n-    status = false;\n-  }\n-  return status;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/shared\/gcArguments.cpp","additions":0,"deletions":25,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -59,2 +59,0 @@\n-\n-  static bool check_args_consistency();\n","filename":"src\/hotspot\/share\/gc\/shared\/gcArguments.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -100,1 +100,0 @@\n-#include \"gc\/g1\/heterogeneousHeapRegionManager.hpp\"\n@@ -510,109 +509,0 @@\n-#if INCLUDE_G1GC || INCLUDE_PARALLELGC\n-WB_ENTRY(jlong, WB_DramReservedStart(JNIEnv* env, jobject o))\n-#if INCLUDE_G1GC\n-  if (UseG1GC) {\n-    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-    HeapWord* base = g1h->reserved().start();\n-    if (g1h->is_heterogeneous_heap()) {\n-      uint start_region = HeterogeneousHeapRegionManager::manager()->start_index_of_dram();\n-      return (jlong)(base + start_region * HeapRegion::GrainBytes);\n-    } else {\n-      return (jlong)base;\n-    }\n-  }\n-#endif \/\/ INCLUDE_G1GC\n-#if INCLUDE_PARALLELGC\n-  if (UseParallelGC) {\n-    ParallelScavengeHeap* ps_heap = ParallelScavengeHeap::heap();\n-    if (AllocateOldGenAt != NULL) {\n-      MemRegion reserved = ps_heap->young_gen()->reserved();\n-      return (jlong)reserved.start();\n-    } else {\n-      return (jlong)ps_heap->base();\n-    }\n-  }\n-#endif \/\/ INCLUDE_PARALLELGC\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_DramReservedStart: enabled only for G1 and Parallel GC\");\n-WB_END\n-\n-WB_ENTRY(jlong, WB_DramReservedEnd(JNIEnv* env, jobject o))\n-#if INCLUDE_G1GC\n-  if (UseG1GC) {\n-    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-    HeapWord* base = g1h->reserved().start();\n-    if (g1h->is_heterogeneous_heap()) {\n-      uint end_region = HeterogeneousHeapRegionManager::manager()->end_index_of_dram();\n-      return (jlong)(base + (end_region + 1) * HeapRegion::GrainBytes - 1);\n-    } else {\n-      return (jlong)base + G1Arguments::heap_max_size_bytes();\n-    }\n-  }\n-#endif \/\/ INCLUDE_G1GC\n-#if INCLUDE_PARALLELGC\n-  if (UseParallelGC) {\n-    ParallelScavengeHeap* ps_heap = ParallelScavengeHeap::heap();\n-    if (AllocateOldGenAt != NULL) {\n-      MemRegion reserved = ps_heap->young_gen()->reserved();\n-      return (jlong)reserved.end();\n-    } else {\n-      return (jlong)ps_heap->reserved_region().end();\n-    }\n-  }\n-#endif \/\/ INCLUDE_PARALLELGC\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_DramReservedEnd: enabled only for G1 and Parallel GC\");\n-WB_END\n-\n-WB_ENTRY(jlong, WB_NvdimmReservedStart(JNIEnv* env, jobject o))\n-#if INCLUDE_G1GC\n-  if (UseG1GC) {\n-    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-    if (g1h->is_heterogeneous_heap()) {\n-      uint start_region = HeterogeneousHeapRegionManager::manager()->start_index_of_nvdimm();\n-      return (jlong)(g1h->reserved().start() + start_region * HeapRegion::GrainBytes);\n-    } else {\n-      THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_NvdimmReservedStart: Old gen is not allocated on NV-DIMM using AllocateOldGenAt flag\");\n-    }\n-  }\n-#endif \/\/ INCLUDE_G1GC\n-#if INCLUDE_PARALLELGC\n-  if (UseParallelGC) {\n-    ParallelScavengeHeap* ps_heap = ParallelScavengeHeap::heap();\n-    if (AllocateOldGenAt != NULL) {\n-      MemRegion reserved = ps_heap->old_gen()->reserved();\n-      return (jlong)reserved.start();\n-    } else {\n-      THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_NvdimmReservedStart: Old gen is not allocated on NV-DIMM using AllocateOldGenAt flag\");\n-    }\n-  }\n-#endif \/\/ INCLUDE_PARALLELGC\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_NvdimmReservedStart: enabled only for G1 and Parallel GC\");\n-WB_END\n-\n-WB_ENTRY(jlong, WB_NvdimmReservedEnd(JNIEnv* env, jobject o))\n-#if INCLUDE_G1GC\n-  if (UseG1GC) {\n-    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-    if (g1h->is_heterogeneous_heap()) {\n-      uint end_region = HeterogeneousHeapRegionManager::manager()->start_index_of_nvdimm();\n-      return (jlong)(g1h->reserved().start() + (end_region + 1) * HeapRegion::GrainBytes - 1);\n-    } else {\n-      THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_NvdimmReservedEnd: Old gen is not allocated on NV-DIMM using AllocateOldGenAt flag\");\n-    }\n-  }\n-#endif \/\/ INCLUDE_G1GC\n-#if INCLUDE_PARALLELGC\n-  if (UseParallelGC) {\n-    ParallelScavengeHeap* ps_heap = ParallelScavengeHeap::heap();\n-    if (AllocateOldGenAt != NULL) {\n-      MemRegion reserved = ps_heap->old_gen()->reserved();\n-      return (jlong)reserved.end();\n-      } else {\n-      THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_NvdimmReservedEnd: Old gen is not allocated on NV-DIMM using AllocateOldGenAt flag\");\n-    }\n-  }\n-#endif \/\/ INCLUDE_PARALLELGC\n-  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_NvdimmReservedEnd: enabled only for G1 and Parallel GC\");\n-WB_END\n-\n-#endif \/\/ INCLUDE_G1GC || INCLUDE_PARALLELGC\n-\n@@ -2421,6 +2311,0 @@\n-#if INCLUDE_G1GC || INCLUDE_PARALLELGC\n-  {CC\"dramReservedStart\",   CC\"()J\",                  (void*)&WB_DramReservedStart },\n-  {CC\"dramReservedEnd\",     CC\"()J\",                  (void*)&WB_DramReservedEnd },\n-  {CC\"nvdimmReservedStart\", CC\"()J\",                  (void*)&WB_NvdimmReservedStart },\n-  {CC\"nvdimmReservedEnd\",   CC\"()J\",                  (void*)&WB_NvdimmReservedEnd },\n-#endif \/\/ INCLUDE_G1GC || INCLUDE_PARALLELGC\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":0,"deletions":116,"binary":false,"changes":116,"status":"modified"},{"patch":"@@ -2164,2 +2164,0 @@\n-  status = status && GCArguments::check_args_consistency();\n-\n@@ -4083,1 +4081,0 @@\n-  UNSUPPORTED_OPTION_NULL(AllocateOldGenAt);\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2459,6 +2459,0 @@\n-  product(ccstr, AllocateOldGenAt, NULL, EXPERIMENTAL,                      \\\n-          \"Path to the directoy where a temporary file will be \"            \\\n-          \"created to use as the backing store for old generation.\"         \\\n-          \"File of size Xmx is pre-allocated for performance reason, so\"    \\\n-          \"we need that much space available\")                              \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -51,1 +51,1 @@\n-    static private AddressField hrmField;\n+    static private long hrmFieldOffset;\n@@ -76,1 +76,1 @@\n-        hrmField = type.getAddressField(\"_hrm\");\n+        hrmFieldOffset = type.getField(\"_hrm\").getOffset();\n@@ -97,1 +97,1 @@\n-        Address hrmAddr = hrmField.getValue(addr);\n+        Address hrmAddr = addr.addOffsetTo(hrmFieldOffset);\n@@ -99,1 +99,1 @@\n-                                                         hrmAddr);\n+                                                             hrmAddr);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/gc\/g1\/G1CollectedHeap.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -78,1 +78,0 @@\n-    test.vm.gc.nvdimm \\\n","filename":"test\/hotspot\/jtreg\/TEST.ROOT","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -45,2 +45,1 @@\n-  gc \\\n-  -gc\/nvdimm\n+  gc\n@@ -69,1 +68,0 @@\n- -gc\/nvdimm \\\n@@ -206,2 +204,1 @@\n-  -gc\/shenandoah \\\n-  -gc\/nvdimm\n+  -gc\/shenandoah\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1,67 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.nvdimm;\n-\n-\/* @test TestAllocateOldGenAt.java\n- * @summary Test to check allocation of Java Heap with AllocateOldGenAt option\n- * @requires vm.gc==\"null\" & os.family != \"aix\"\n- * @requires test.vm.gc.nvdimm\n- * @library \/test\/lib\n- * @modules java.base\/jdk.internal.misc\n- * @run driver gc.nvdimm.TestAllocateOldGenAt\n- *\/\n-\n-import jdk.test.lib.JDKToolFinder;\n-import jdk.test.lib.process.ProcessTools;\n-import jdk.test.lib.process.OutputAnalyzer;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-\n-public class TestAllocateOldGenAt {\n-  private static String[] commonFlags;\n-\n-  public static void main(String args[]) throws Exception {\n-    String test_dir = System.getProperty(\"test.dir\", \".\");\n-    commonFlags = new String[] {\n-        \"-XX:+UnlockExperimentalVMOptions\",\n-        \"-XX:AllocateOldGenAt=\" + test_dir,\n-        \"-Xmx32m\",\n-        \"-Xms32m\",\n-        \"-version\"};\n-\n-    runTest(\"-XX:+UseG1GC\");\n-    runTest(\"-XX:+UseParallelGC\");\n-  }\n-\n-  private static void runTest(String... extraFlags) throws Exception {\n-    ArrayList<String> flags = new ArrayList<>();\n-    Collections.addAll(flags, commonFlags);\n-    Collections.addAll(flags, extraFlags);\n-    ProcessBuilder pb = ProcessTools.createTestJvm(flags);\n-    OutputAnalyzer output = new OutputAnalyzer(pb.start());\n-\n-    output.shouldHaveExitValue(0);\n-\n-  }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/nvdimm\/TestAllocateOldGenAt.java","additions":0,"deletions":67,"binary":false,"changes":67,"status":"deleted"},{"patch":"@@ -1,95 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.nvdimm;\n-\n-\/* @test TestAllocateOldGenAtError.java\n- * @summary Test to check correct handling of non-existent directory passed to AllocateOldGenAt option\n- * @requires vm.gc==\"null\" & os.family != \"aix\"\n- * @requires test.vm.gc.nvdimm\n- * @library \/test\/lib\n- * @modules java.base\/jdk.internal.misc\n- * @run driver gc.nvdimm.TestAllocateOldGenAtError\n- *\/\n-\n-import java.io.File;\n-import jdk.test.lib.JDKToolFinder;\n-import jdk.test.lib.process.ProcessTools;\n-import jdk.test.lib.process.OutputAnalyzer;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.UUID;\n-\n-public class TestAllocateOldGenAtError {\n-  private static String[] commonFlags;\n-\n-  public static void main(String args[]) throws Exception {\n-    String test_dir = System.getProperty(\"test.dir\", \".\");\n-\n-    File f = null;\n-    do {\n-      f = new File(test_dir, UUID.randomUUID().toString());\n-    } while(f.exists());\n-\n-    commonFlags = new String[] {\n-        \"-XX:+UnlockExperimentalVMOptions\",\n-        \"-XX:AllocateOldGenAt=\" + f.getName(),\n-        \"-Xlog:gc+heap=info\",\n-        \"-Xmx32m\",\n-        \"-Xms32m\",\n-        \"-version\"};\n-\n-    testG1();\n-    testParallelOld();\n-  }\n-\n-  private static void testG1() throws Exception {\n-    System.out.println(\"Testing G1 GC\");\n-\n-    OutputAnalyzer output = runTest(\"-XX:+UseG1GC\");\n-\n-    output.shouldContain(\"Could not initialize G1 heap\");\n-    output.shouldContain(\"Error occurred during initialization of VM\");\n-    output.shouldNotHaveExitValue(0);\n-\n-  }\n-\n-  private static void testParallelOld() throws Exception {\n-    System.out.println(\"Testing Parallel GC\");\n-\n-    OutputAnalyzer output = runTest(\"-XX:+UseParallelGC\");\n-\n-    output.shouldContain(\"Error occurred during initialization of VM\");\n-    output.shouldNotHaveExitValue(0);\n-  }\n-\n-  private static OutputAnalyzer runTest(String... extraFlags) throws Exception {\n-    ArrayList<String> flags = new ArrayList<>();\n-    Collections.addAll(flags, commonFlags);\n-    Collections.addAll(flags, extraFlags);\n-\n-    ProcessBuilder pb = ProcessTools.createTestJvm(flags);\n-    OutputAnalyzer output = new OutputAnalyzer(pb.start());\n-    return output;\n-  }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/nvdimm\/TestAllocateOldGenAtError.java","additions":0,"deletions":95,"binary":false,"changes":95,"status":"deleted"},{"patch":"@@ -1,73 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.nvdimm;\n-\n-\/* @test TestAllocateOldGenAtMultiple.java\n- * @summary Test to check allocation of Java Heap with AllocateOldGenAt option. Has multiple sub-tests to cover different code paths.\n- * @requires vm.gc==\"null\" & os.family != \"aix\"\n- * @requires test.vm.gc.nvdimm\n- * @library \/test\/lib\n- * @modules java.base\/jdk.internal.misc\n- * @requires vm.bits == \"64\"\n- * @run driver gc.nvdimm.TestAllocateOldGenAtMultiple\n- *\/\n-\n-import jdk.test.lib.JDKToolFinder;\n-import jdk.test.lib.process.ProcessTools;\n-import jdk.test.lib.process.OutputAnalyzer;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-\n-public class TestAllocateOldGenAtMultiple {\n-  public static void main(String args[]) throws Exception {\n-    ArrayList<String> flags = new ArrayList<>();\n-    String test_dir = System.getProperty(\"test.dir\", \".\");\n-\n-    \/\/ Extra flags for each of the sub-tests\n-    String[][] extraFlagsList = {\n-      {\"-Xmx32m\", \"-Xms32m\", \"-XX:+UseCompressedOops\"},     \/\/ 1. With compressedoops enabled.\n-      {\"-Xmx32m\", \"-Xms32m\", \"-XX:-UseCompressedOops\"},     \/\/ 2. With compressedoops disabled.\n-      {\"-Xmx32m\", \"-Xms32m\", \"-XX:HeapBaseMinAddress=3g\"},  \/\/ 3. With user specified HeapBaseMinAddress.\n-      {\"-Xmx4g\",  \"-Xms4g\"},                                \/\/ 4. With larger heap size (UnscaledNarrowOop not possible).\n-      {\"-Xmx4g\",  \"-Xms4g\",  \"-XX:+UseLargePages\"},         \/\/ 5. Set UseLargePages.\n-      {\"-Xmx4g\",  \"-Xms4g\",  \"-XX:+UseNUMA\"}                \/\/ 6. Set UseNUMA.\n-    };\n-\n-    for (String[] extraFlags : extraFlagsList) {\n-      flags.clear();\n-      \/\/ Add extra flags specific to the sub-test.\n-      Collections.addAll(flags, extraFlags);\n-      \/\/ Add common flags\n-      Collections.addAll(flags, new String[] {\"-XX:+UnlockExperimentalVMOptions\",\n-                                               \"-XX:AllocateOldGenAt=\" + test_dir,\n-                                               \"-version\"});\n-      ProcessBuilder pb = ProcessTools.createTestJvm(flags);\n-      OutputAnalyzer output = new OutputAnalyzer(pb.start());\n-\n-      System.out.println(\"Output:\\n\" + output.getOutput());\n-\n-      output.shouldHaveExitValue(0);\n-    }\n-  }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/nvdimm\/TestAllocateOldGenAtMultiple.java","additions":0,"deletions":73,"binary":false,"changes":73,"status":"deleted"},{"patch":"@@ -1,109 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.nvdimm;\n-\n-\/*\n- * @test TestHumongousObjectsOnNvdimm\n- * @summary Check that humongous objects reside in nv-dimm\n- * @library \/test\/lib \/\n- * @requires vm.gc==\"null\" & os.family != \"aix\"\n- * @requires test.vm.gc.nvdimm\n- * @build sun.hotspot.WhiteBox\n- * @run driver ClassFileInstaller sun.hotspot.WhiteBox\n- * @run driver gc.nvdimm.TestHumongousObjectsOnNvdimm\n- *\/\n-\n-import jdk.test.lib.process.OutputAnalyzer;\n-import jdk.test.lib.process.ProcessTools;\n-import jdk.test.lib.Asserts;\n-import sun.hotspot.WhiteBox;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import gc.testlibrary.Helpers;\n-\n-\/**\n- * Test spawns HumongousObjectTest in a separate VM and expects that it\n- * completes without a RuntimeException.\n- *\/\n-public class TestHumongousObjectsOnNvdimm {\n-\n-    private static String[] commonFlags;\n-\n-    public static void main(String args[]) throws Exception {\n-        commonFlags = new String[] {\n-            \"-Xbootclasspath\/a:.\",\n-            \"-XX:+UnlockExperimentalVMOptions\",\n-            \"-XX:+UnlockDiagnosticVMOptions\",\n-            \"-XX:+WhiteBoxAPI\",\n-            \"-XX:AllocateOldGenAt=\" + System.getProperty(\"test.dir\", \".\"),\n-            \"-Xms10M\", \"-Xmx10M\",\n-            \"-XX:G1HeapRegionSize=1m\"\n-        };\n-\n-        \/\/ Test with G1 GC\n-        runTest(\"-XX:+UseG1GC\");\n-    }\n-\n-    private static void runTest(String... extraFlags) throws Exception {\n-        ArrayList<String> flags = new ArrayList<>();\n-        Collections.addAll(flags, commonFlags);\n-        Collections.addAll(flags, extraFlags);\n-        flags.add(HumongousObjectTest.class.getName());\n-\n-        ProcessBuilder pb = ProcessTools.createTestJvm(flags);\n-\n-        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n-        output.shouldHaveExitValue(0);\n-    }\n-}\n-\n-\/**\n- * This class tests that a humongous object resides in NVDIMM.\n- *\/\n-class HumongousObjectTest {\n-    private static final WhiteBox WB = WhiteBox.getWhiteBox();\n-\n-    private static void validateObject(Object o) {\n-        Asserts.assertTrue(WB.isObjectInOldGen(o),\n-                \"Object is supposed to be in OldGen\");\n-\n-        long obj_addr = WB.getObjectAddress(o);\n-        long nvdimm_heap_start = WB.nvdimmReservedStart();\n-        long nvdimm_heap_end = WB.nvdimmReservedEnd();\n-\n-        Asserts.assertTrue(WB.g1BelongsToHumongousRegion(obj_addr), \"Object address should be in Humongous set\");\n-        Asserts.assertTrue(obj_addr >= nvdimm_heap_start && obj_addr < nvdimm_heap_end,\n-                \"Humongous object does not reside in NVDIMM\");\n-    }\n-\n-    public static void main(String args[]) throws Exception {\n-        \/\/ allocate an humongous object\n-        int byteArrayMemoryOverhead = Helpers.detectByteArrayAllocationOverhead();\n-        int MinByteArrayHumongousSize = (WB.g1RegionSize() \/ 2) - byteArrayMemoryOverhead + 1;\n-        byte[] obj = new byte[MinByteArrayHumongousSize];\n-\n-        validateObject(obj);\n-    }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/nvdimm\/TestHumongousObjectsOnNvdimm.java","additions":0,"deletions":109,"binary":false,"changes":109,"status":"deleted"},{"patch":"@@ -1,109 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.nvdimm;\n-\n-\/*\n- * @test TestOldObjectsOnNvdimm\n- * @summary Check that objects in old generation reside in dram.\n- * @requires vm.gc==\"null\" & os.family != \"aix\"\n- * @requires test.vm.gc.nvdimm\n- * @library \/test\/lib\n- * @build sun.hotspot.WhiteBox\n- * @run driver ClassFileInstaller sun.hotspot.WhiteBox\n- * @run driver gc.nvdimm.TestOldObjectsOnNvdimm\n- *\/\n-\n-import jdk.test.lib.process.OutputAnalyzer;\n-import jdk.test.lib.process.ProcessTools;\n-import jdk.test.lib.Asserts;\n-import sun.hotspot.WhiteBox;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-\n-\/*\n- * Test spawns OldObjectTest in a separate VM and expects that it\n- * completes without a RuntimeException.\n- *\/\n-public class TestOldObjectsOnNvdimm {\n-\n-    public static final int ALLOCATION_SIZE = 100;\n-    private static String[] commonFlags;\n-\n-    public static void main(String args[]) throws Exception {\n-        commonFlags = new String[] {\n-            \"-Xbootclasspath\/a:.\",\n-            \"-XX:+UnlockExperimentalVMOptions\",\n-            \"-XX:+UnlockDiagnosticVMOptions\",\n-            \"-XX:+WhiteBoxAPI\",\n-            \"-XX:AllocateOldGenAt=\" + System.getProperty(\"test.dir\", \".\"),\n-            \"-Xms10M\", \"-Xmx10M\",\n-            \"-XX:MaxTenuringThreshold=1\" \/\/ Promote objects to Old Gen\n-        };\n-        runTest(\"-XX:+UseG1GC\");\n-        runTest(\"-XX:+UseParallelGC\");\n-    }\n-\n-    private static void runTest(String... extraFlags) throws Exception {\n-        ArrayList<String> flags = new ArrayList<>();\n-        Collections.addAll(flags, commonFlags);\n-        Collections.addAll(flags, extraFlags);\n-        flags.add(OldObjectTest.class.getName());\n-\n-        ProcessBuilder pb = ProcessTools.createTestJvm(flags);\n-\n-        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n-        System.out.println(output.getStdout());\n-        output.shouldHaveExitValue(0);\n-    }\n-}\n-\n-\/*\n- * This class tests that object is in Old generation after tenuring and resides in NVDIMM.\n- * The necessary condition for this test is running in VM with the following flags:\n- * -XX:AllocateOldGenAt=, -XX:MaxTenuringThreshold=1\n- *\/\n-class OldObjectTest {\n-    private static final WhiteBox WB = WhiteBox.getWhiteBox();\n-\n-    private static void validateOldObject(Object o) {\n-        Asserts.assertTrue(WB.isObjectInOldGen(o),\n-                \"Object is supposed to be in OldGen\");\n-\n-        long oldObj_addr = WB.getObjectAddress(o);\n-        long nvdimm_heap_start = WB.nvdimmReservedStart();\n-        long nvdimm_heap_end = WB.nvdimmReservedEnd();\n-\n-        Asserts.assertTrue(oldObj_addr >= nvdimm_heap_start && oldObj_addr <= nvdimm_heap_end,\n-                \"Old object does not reside in NVDIMM\");\n-    }\n-\n-    public static void main(String args[]) throws Exception {\n-        \/\/ allocate an object and perform Young GCs to promote it to Old\n-        byte[] oldObj = new byte[TestOldObjectsOnNvdimm.ALLOCATION_SIZE];\n-        WB.youngGC();\n-        WB.youngGC();\n-        validateOldObject(oldObj);\n-    }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/nvdimm\/TestOldObjectsOnNvdimm.java","additions":0,"deletions":109,"binary":false,"changes":109,"status":"deleted"},{"patch":"@@ -1,113 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-package gc.nvdimm;\n-\n-\/*\n- * @test TestYoungObjectsOnDram\n- * @summary Check that objects in young generation reside in dram.\n- * @requires vm.gc==\"null\" & os.family != \"aix\"\n- * @requires test.vm.gc.nvdimm\n- * @library \/test\/lib\n- * @build sun.hotspot.WhiteBox\n- * @run driver ClassFileInstaller sun.hotspot.WhiteBox\n- * @run driver gc.nvdimm.TestYoungObjectsOnDram\n- *\/\n-\n-import jdk.test.lib.process.OutputAnalyzer;\n-import jdk.test.lib.process.ProcessTools;\n-import jdk.test.lib.Asserts;\n-import sun.hotspot.WhiteBox;\n-\n-import java.util.ArrayList;\n-import java.util.Collections;\n-\n-\/**\n- * Test spawns YoungObjectTest in a separate VM and expects that it\n- * completes without a RuntimeException.\n- *\/\n-public class TestYoungObjectsOnDram {\n-\n-    public static final int ALLOCATION_SIZE = 100;\n-    private static String[] commonFlags;\n-\n-    public static void main(String args[]) throws Exception {\n-        commonFlags = new String[] {\n-            \"-Xbootclasspath\/a:.\",\n-            \"-XX:+UnlockExperimentalVMOptions\",\n-            \"-XX:+UnlockDiagnosticVMOptions\",\n-            \"-XX:+WhiteBoxAPI\",\n-            \"-XX:AllocateOldGenAt=\" + System.getProperty(\"test.dir\", \".\"),\n-            \"-XX:SurvivorRatio=1\", \/\/ Survivor-to-eden ratio is 1:1\n-            \"-Xms10M\", \"-Xmx10M\",\n-            \"-XX:InitialTenuringThreshold=15\" \/\/ avoid promotion of objects to Old Gen\n-        };\n-        runTest(\"-XX:+UseG1GC\");\n-        runTest(\"-XX:+UseParallelGC\");\n-    }\n-\n-    private static void runTest(String... extraFlags) throws Exception {\n-        ArrayList<String> flags = new ArrayList<>();\n-        Collections.addAll(flags, commonFlags);\n-        Collections.addAll(flags, extraFlags);\n-        flags.add(YoungObjectTest.class.getName());\n-\n-        ProcessBuilder pb = ProcessTools.createTestJvm(flags);\n-\n-        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n-        System.out.println(output.getStdout());\n-        output.shouldHaveExitValue(0);\n-    }\n-}\n-\n-\/**\n- * This class tests that newly created object is in Young generation and resides in DRAM.\n- * The necessary condition for this test is running in VM with the following flags:\n- * -XX:AllocateOldGenAt=, -XX:InitialTenuringThreshold=15, -XX:SurvivorRatio=1\n- *\/\n-class YoungObjectTest {\n-    private static final WhiteBox WB = WhiteBox.getWhiteBox();\n-\n-    private static void validateYoungObject(Object o) {\n-        Asserts.assertTrue(!WB.isObjectInOldGen(o),\n-                \"Object is supposed to be in YoungGen\");\n-\n-        long youngObj_addr = WB.getObjectAddress(o);\n-        long dram_heap_start = WB.dramReservedStart();\n-        long dram_heap_end = WB.dramReservedEnd();\n-\n-        Asserts.assertTrue(youngObj_addr >= dram_heap_start && youngObj_addr <= dram_heap_end,\n-                \"Young object does not reside in DRAM\");\n-    }\n-\n-    public static void main(String args[]) throws Exception {\n-        \/\/ allocate an object\n-        byte[] youngObj = new byte[TestYoungObjectsOnDram.ALLOCATION_SIZE];\n-        validateYoungObject(youngObj);\n-\n-        \/\/ Start a Young GC and check that object is still in DRAM.\n-        \/\/ We have used -XX:InitialTenuringThreshold=15 to invoke this test\n-        WB.youngGC();\n-        validateYoungObject(youngObj);\n-    }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/nvdimm\/TestYoungObjectsOnDram.java","additions":0,"deletions":113,"binary":false,"changes":113,"status":"deleted"},{"patch":"@@ -120,1 +120,0 @@\n-        map.put(\"test.vm.gc.nvdimm\", this::isNvdimmTestEnabled);\n@@ -544,5 +543,0 @@\n-    private String isNvdimmTestEnabled() {\n-        String isEnabled = System.getenv(\"TEST_VM_GC_NVDIMM\");\n-        return \"\" + \"true\".equalsIgnoreCase(isEnabled);\n-    }\n-\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -192,4 +192,0 @@\n-  public native long    dramReservedStart();\n-  public native long    dramReservedEnd();\n-  public native long    nvdimmReservedStart();\n-  public native long    nvdimmReservedEnd();\n","filename":"test\/lib\/sun\/hotspot\/WhiteBox.java","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"}]}