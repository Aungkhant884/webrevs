{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"logging\/logAsyncFlusher.hpp\"\n@@ -1948,0 +1949,1 @@\n+  LogAsyncFlusher::abort();\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"logging\/logAsyncFlusher.hpp\"\n@@ -1101,0 +1102,1 @@\n+  LogAsyncFlusher::abort();\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -66,0 +66,1 @@\n+  \/\/ notify async log thread if occupancy is over 3\/4\n@@ -67,1 +68,1 @@\n-  if (sz == (AsyncLogBufferSize >> 1) || sz == AsyncLogBufferSize) {\n+  if (sz > (AsyncLogBufferSize >> 2) * 3 ) {\n@@ -76,0 +77,3 @@\n+    \/\/ The rank of _lock is same as _tty_lock on purpuse.\n+    \/\/ if logging thread is holding _tty_lock now, temporarily yield to _lock.\n+    ttyUnlocker ttyul;\n@@ -84,0 +88,1 @@\n+  ttyUnlocker ttyul;\n@@ -93,1 +98,1 @@\n-  : _should_terminate(false),\n+  : _state(ThreadState::Running),\n@@ -117,1 +122,9 @@\n-void LogAsyncFlusher::flush() {\n+void LogAsyncFlusher::writeback(const LinkedList<AsyncLogMessage>& logs) {\n+  LinkedListIterator<AsyncLogMessage> it(logs.head());\n+  while (!it.is_empty()) {\n+    AsyncLogMessage* e = it.next();\n+    e->writeback();\n+  }\n+}\n+\n+void LogAsyncFlusher::flush(bool with_lock) {\n@@ -120,1 +133,4 @@\n-  { \/\/ critical area\n+  if (with_lock) { \/\/ critical area\n+    \/\/ Caveat: current thread must not hold _tty_lock or other lower rank lockers.\n+    \/\/ Cannot install ttyUnlocker here because flush() may be invoked before defaultStream\n+    \/\/ initialization.\n@@ -123,1 +139,5 @@\n-\n+    AsyncLogMapIterator iter;\n+    _stats.iterate(&iter);\n+  } else {\n+    \/\/ C++ lambda can simplify the code snippet.\n+    _buffer.pop_all(&logs);\n@@ -128,5 +148,1 @@\n-  LinkedListIterator<AsyncLogMessage> it(logs.head());\n-  while (!it.is_empty()) {\n-    AsyncLogMessage* e = it.next();\n-    e->writeback();\n-  }\n+  writeback(logs);\n@@ -136,1 +152,1 @@\n-  while (!_should_terminate) {\n+  while (_state == ThreadState::Running) {\n@@ -139,1 +155,1 @@\n-      m.wait(LogAsyncInterval);\n+      m.wait(500 \/* ms, timeout*\/);\n@@ -143,0 +159,5 @@\n+\n+  \/\/ Signal thread has terminated\n+  MonitorLocker ml(Terminator_lock);\n+  Atomic::release_store(&_state, ThreadState::Terminated);\n+  ml.notify_all();\n@@ -157,0 +178,1 @@\n+\/\/ 4. wait until asynclog thread exits.\n@@ -162,1 +184,0 @@\n-    \/\/ make sure no new log entry will be enqueued after.\n@@ -166,3 +187,9 @@\n-      MonitorLocker m(&self->_lock, Mutex::_no_safepoint_check_flag);\n-      self->_should_terminate = true;\n-      m.notify();\n+      MonitorLocker ml(&self->_lock, Mutex::_no_safepoint_check_flag);\n+      Atomic::release_store(&self->_state, ThreadState::Terminating);\n+      ml.notify();\n+    }\n+    {\n+      MonitorLocker ml(Terminator_lock, Mutex::_no_safepoint_check_flag);\n+      while (self->_state != ThreadState::Terminated) {\n+        ml.wait();\n+      }\n@@ -181,0 +208,20 @@\n+\n+\/\/ Different from terminate(), abort is invoked by os::abort().\n+\/\/ There are 2 constraints:\n+\/\/ 1. must be async-safe because os::abort may be invoked by a signal handler while other\n+\/\/ threads are executing.\n+\/\/ 2. must not obtain _lock. eg. gtest.MutexRank.mutex_lock_access_leaf(test_mutex_rank.cpp)\n+\/\/ holds assess lock and then traps SIGSEGV on purpose.\n+\/\/\n+\/\/ Unlike terminate, abort() just ensures all pending log messages are flushed.\n+void LogAsyncFlusher::abort() {\n+  if (_instance != nullptr) {\n+    \/\/ to meet prior constraints, I borrow the idea in LogConfiguration::disable_outputs(),\n+    \/\/ the following code shut down all outputs for all tagsets with RCU synchroniziation.\n+    \/\/ After then, I can flush pending queue without a lock.\n+    for (LogTagSet* ts = LogTagSet::first(); ts != NULL; ts = ts->next()) {\n+      ts->disable_outputs();\n+    }\n+    _instance->flush(false \/*with_lock*\/);\n+  }\n+}\n","filename":"src\/hotspot\/share\/logging\/logAsyncFlusher.cpp","additions":63,"deletions":16,"binary":false,"changes":79,"status":"modified"},{"patch":"@@ -130,8 +130,10 @@\n-  volatile bool _should_terminate;\n-  \/\/ The semantics of _lock is like JVM monitor.\n-  \/\/ This thread sleeps and only wakes up by the monitor if any of events happen.\n-  \/\/   1. buffer is half-full\n-  \/\/   2. buffer is full\n-  \/\/   3. timeout defined by LogAsyncInterval\n-  \/\/\n-  \/\/ It also roles as a lock to consolidate buffer's MT-safety.\n+  enum class ThreadState {\n+    Running = 0,\n+    Terminating,\n+    Terminated\n+  };\n+\n+  volatile ThreadState _state;\n+  \/\/ The semantics of _lock is more like a Java monitor.\n+  \/\/ AssyncLog thread sleeps on _lock until the occupancy of the buffer is over 3\/4, or timeout\n+  \/\/ It also acts as a mutex to consolidate buffer's MT-safety.\n@@ -144,0 +146,1 @@\n+  static void writeback(const LinkedList<AsyncLogMessage>& logs);\n@@ -146,0 +149,1 @@\n+\n@@ -149,1 +153,1 @@\n-  void flush();\n+  void flush(bool with_lock = true);\n@@ -155,0 +159,1 @@\n+  static void abort();\n","filename":"src\/hotspot\/share\/logging\/logAsyncFlusher.hpp","additions":14,"deletions":9,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -288,1 +288,1 @@\n-    async->flush();\n+    async->flush(false \/* with_lock *\/);\n","filename":"src\/hotspot\/share\/logging\/logConfiguration.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -136,12 +136,0 @@\n-JVMFlag::Error LogAsyncIntervalConstraintFunc(intx value, bool verbose) {\n-    if ((value % PeriodicTask::interval_gran) != 0) {\n-    JVMFlag::printError(verbose,\n-                        \"LogAsyncInterval (\" INTX_FORMAT \") must be \"\n-                        \"evenly divisible by PeriodicTask::interval_gran (%d)\\n\",\n-                        value, PeriodicTask::interval_gran);\n-    return JVMFlag::VIOLATES_CONSTRAINT;\n-  } else {\n-    return JVMFlag::SUCCESS;\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlagConstraintsRuntime.cpp","additions":0,"deletions":12,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -44,1 +44,0 @@\n-  f(intx,   LogAsyncIntervalConstraintFunc)           \\\n","filename":"src\/hotspot\/share\/runtime\/flags\/jvmFlagConstraintsRuntime.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2027,5 +2027,0 @@\n-  product(intx, LogAsyncInterval, 300,                                      \\\n-          \"Milliseconds between asynchronous log flushing\")                 \\\n-          range(PeriodicTask::min_interval, max_jint)                       \\\n-          constraint(LogAsyncIntervalConstraintFunc, AtParse)               \\\n-                                                                            \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"logging\/logAsyncFlusher.hpp\"\n@@ -974,5 +973,0 @@\n-  LogAsyncFlusher* async = LogAsyncFlusher::instance();\n-  if (async != NULL) {\n-    async->flush();\n-  }\n-\n","filename":"src\/hotspot\/share\/utilities\/ostream.cpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -214,0 +214,1 @@\n+  \/\/ shrink async buffer.\n@@ -215,0 +216,1 @@\n+  LogMessage(logging) lm;\n@@ -216,2 +218,3 @@\n-  for (size_t i=0; i < sz * 1000; ++i) {\n-    log_debug(logging)(\"a lot of log...\");\n+  \/\/ write 100x more messages than its capacity in burst\n+  for (size_t i = 0; i < sz * 100; ++i) {\n+    lm.debug(\"a lot of log...\");\n@@ -219,0 +222,1 @@\n+  lm.flush();\n","filename":"test\/hotspot\/gtest\/logging\/test_asynclog.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"}]}