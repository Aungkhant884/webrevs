{"files":[{"patch":"@@ -123,1 +123,0 @@\n-      cdsProtectionDomain.cpp \\\n@@ -126,3 +125,0 @@\n-      dumpTimeSharedClassInfo.cpp \\\n-      lambdaProxyClassDictionary.cpp \\\n-      runTimeSharedClassInfo.cpp \\\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,437 @@\n+\/*\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"cds\/archiveHeapLoader.inline.hpp\"\n+#include \"cds\/filemap.hpp\"\n+#include \"cds\/heapShared.hpp\"\n+#include \"cds\/metaspaceShared.hpp\"\n+#include \"classfile\/classLoaderDataShared.hpp\"\n+#include \"classfile\/systemDictionaryShared.hpp\"\n+#include \"gc\/shared\/collectedHeap.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"memory\/iterator.inline.hpp\"\n+#include \"memory\/resourceArea.hpp\"\n+#include \"memory\/universe.hpp\"\n+#include \"utilities\/bitMap.inline.hpp\"\n+#include \"utilities\/copy.hpp\"\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+\n+bool ArchiveHeapLoader::_closed_regions_mapped = false;\n+bool ArchiveHeapLoader::_open_regions_mapped = false;\n+bool ArchiveHeapLoader::_is_loaded = false;\n+address ArchiveHeapLoader::_narrow_oop_base;\n+int     ArchiveHeapLoader::_narrow_oop_shift;\n+\n+\/\/ Support for loaded heap.\n+uintptr_t ArchiveHeapLoader::_loaded_heap_bottom = 0;\n+uintptr_t ArchiveHeapLoader::_loaded_heap_top = 0;\n+uintptr_t ArchiveHeapLoader::_dumptime_base_0 = UINTPTR_MAX;\n+uintptr_t ArchiveHeapLoader::_dumptime_base_1 = UINTPTR_MAX;\n+uintptr_t ArchiveHeapLoader::_dumptime_base_2 = UINTPTR_MAX;\n+uintptr_t ArchiveHeapLoader::_dumptime_base_3 = UINTPTR_MAX;\n+uintptr_t ArchiveHeapLoader::_dumptime_top    = 0;\n+intx ArchiveHeapLoader::_runtime_offset_0 = 0;\n+intx ArchiveHeapLoader::_runtime_offset_1 = 0;\n+intx ArchiveHeapLoader::_runtime_offset_2 = 0;\n+intx ArchiveHeapLoader::_runtime_offset_3 = 0;\n+bool ArchiveHeapLoader::_loading_failed = false;\n+\n+\/\/ Support for mapped heap (!UseCompressedOops only)\n+ptrdiff_t ArchiveHeapLoader::_runtime_delta = 0;\n+\n+void ArchiveHeapLoader::init_narrow_oop_decoding(address base, int shift) {\n+  _narrow_oop_base = base;\n+  _narrow_oop_shift = shift;\n+}\n+\n+void ArchiveHeapLoader::fixup_regions() {\n+  FileMapInfo* mapinfo = FileMapInfo::current_info();\n+  if (is_mapped()) {\n+    mapinfo->fixup_mapped_heap_regions();\n+  } else if (_loading_failed) {\n+    fill_failed_loaded_region();\n+  }\n+  if (is_fully_available()) {\n+    if (!MetaspaceShared::use_full_module_graph()) {\n+      \/\/ Need to remove all the archived java.lang.Module objects from HeapShared::roots().\n+      ClassLoaderDataShared::clear_archived_oops();\n+    }\n+  }\n+  SystemDictionaryShared::update_archived_mirror_native_pointers();\n+}\n+\n+\/\/ ------------------ Support for Region MAPPING -----------------------------------------\n+\n+\/\/ Patch all the embedded oop pointers inside an archived heap region,\n+\/\/ to be consistent with the runtime oop encoding.\n+class PatchCompressedEmbeddedPointers: public BitMapClosure {\n+  narrowOop* _start;\n+\n+ public:\n+  PatchCompressedEmbeddedPointers(narrowOop* start) : _start(start) {}\n+\n+  bool do_bit(size_t offset) {\n+    narrowOop* p = _start + offset;\n+    narrowOop v = *p;\n+    assert(!CompressedOops::is_null(v), \"null oops should have been filtered out at dump time\");\n+    oop o = ArchiveHeapLoader::decode_from_archive(v);\n+    RawAccess<IS_NOT_NULL>::oop_store(p, o);\n+    return true;\n+  }\n+};\n+\n+class PatchUncompressedEmbeddedPointers: public BitMapClosure {\n+  oop* _start;\n+\n+ public:\n+  PatchUncompressedEmbeddedPointers(oop* start) : _start(start) {}\n+\n+  bool do_bit(size_t offset) {\n+    oop* p = _start + offset;\n+    intptr_t dumptime_oop = (intptr_t)((void*)*p);\n+    assert(dumptime_oop != 0, \"null oops should have been filtered out at dump time\");\n+    intptr_t runtime_oop = dumptime_oop + ArchiveHeapLoader::runtime_delta();\n+    RawAccess<IS_NOT_NULL>::oop_store(p, cast_to_oop(runtime_oop));\n+    return true;\n+  }\n+};\n+\n+\/\/ Patch all the non-null pointers that are embedded in the archived heap objects\n+\/\/ in this (mapped) region\n+void ArchiveHeapLoader::patch_embedded_pointers(MemRegion region, address oopmap,\n+                                                size_t oopmap_size_in_bits) {\n+  BitMapView bm((BitMap::bm_word_t*)oopmap, oopmap_size_in_bits);\n+\n+#ifndef PRODUCT\n+  ResourceMark rm;\n+  ResourceBitMap checkBm = HeapShared::calculate_oopmap(region);\n+  assert(bm.is_same(checkBm), \"sanity\");\n+#endif\n+\n+  if (UseCompressedOops) {\n+    PatchCompressedEmbeddedPointers patcher((narrowOop*)region.start());\n+    bm.iterate(&patcher);\n+  } else {\n+    PatchUncompressedEmbeddedPointers patcher((oop*)region.start());\n+    bm.iterate(&patcher);\n+  }\n+}\n+\n+\/\/ ------------------ Support for Region LOADING -----------------------------------------\n+\n+\/\/ The CDS archive remembers each heap object by its address at dump time, but\n+\/\/ the heap object may be loaded at a different address at run time. This structure is used\n+\/\/ to translate the dump time addresses for all objects in FileMapInfo::space_at(region_index)\n+\/\/ to their runtime addresses.\n+struct LoadedArchiveHeapRegion {\n+  int       _region_index;   \/\/ index for FileMapInfo::space_at(index)\n+  size_t    _region_size;    \/\/ number of bytes in this region\n+  uintptr_t _dumptime_base;  \/\/ The dump-time (decoded) address of the first object in this region\n+  intx      _runtime_offset; \/\/ If an object's dump time address P is within in this region, its\n+                             \/\/ runtime address is P + _runtime_offset\n+\n+  static int comparator(const void* a, const void* b) {\n+    LoadedArchiveHeapRegion* reg_a = (LoadedArchiveHeapRegion*)a;\n+    LoadedArchiveHeapRegion* reg_b = (LoadedArchiveHeapRegion*)b;\n+    if (reg_a->_dumptime_base < reg_b->_dumptime_base) {\n+      return -1;\n+    } else if (reg_a->_dumptime_base == reg_b->_dumptime_base) {\n+      return 0;\n+    } else {\n+      return 1;\n+    }\n+  }\n+\n+  uintptr_t top() {\n+    return _dumptime_base + _region_size;\n+  }\n+};\n+\n+void ArchiveHeapLoader::init_loaded_heap_relocation(LoadedArchiveHeapRegion* loaded_regions,\n+                                             int num_loaded_regions) {\n+  _dumptime_base_0 = loaded_regions[0]._dumptime_base;\n+  _dumptime_base_1 = loaded_regions[1]._dumptime_base;\n+  _dumptime_base_2 = loaded_regions[2]._dumptime_base;\n+  _dumptime_base_3 = loaded_regions[3]._dumptime_base;\n+  _dumptime_top = loaded_regions[num_loaded_regions-1].top();\n+\n+  _runtime_offset_0 = loaded_regions[0]._runtime_offset;\n+  _runtime_offset_1 = loaded_regions[1]._runtime_offset;\n+  _runtime_offset_2 = loaded_regions[2]._runtime_offset;\n+  _runtime_offset_3 = loaded_regions[3]._runtime_offset;\n+\n+  assert(2 <= num_loaded_regions && num_loaded_regions <= 4, \"must be\");\n+  if (num_loaded_regions < 4) {\n+    _dumptime_base_3 = UINTPTR_MAX;\n+  }\n+  if (num_loaded_regions < 3) {\n+    _dumptime_base_2 = UINTPTR_MAX;\n+  }\n+}\n+\n+bool ArchiveHeapLoader::can_load() {\n+  return Universe::heap()->can_load_archived_objects();\n+}\n+\n+template <int NUM_LOADED_REGIONS>\n+class PatchLoadedRegionPointers: public BitMapClosure {\n+  narrowOop* _start;\n+  intx _offset_0;\n+  intx _offset_1;\n+  intx _offset_2;\n+  intx _offset_3;\n+  uintptr_t _base_0;\n+  uintptr_t _base_1;\n+  uintptr_t _base_2;\n+  uintptr_t _base_3;\n+  uintptr_t _top;\n+\n+  static_assert(MetaspaceShared::max_num_heap_regions == 4, \"can't handle more than 4 regions\");\n+  static_assert(NUM_LOADED_REGIONS >= 2, \"we have at least 2 loaded regions\");\n+  static_assert(NUM_LOADED_REGIONS <= 4, \"we have at most 4 loaded regions\");\n+\n+ public:\n+  PatchLoadedRegionPointers(narrowOop* start, LoadedArchiveHeapRegion* loaded_regions)\n+    : _start(start),\n+      _offset_0(loaded_regions[0]._runtime_offset),\n+      _offset_1(loaded_regions[1]._runtime_offset),\n+      _offset_2(loaded_regions[2]._runtime_offset),\n+      _offset_3(loaded_regions[3]._runtime_offset),\n+      _base_0(loaded_regions[0]._dumptime_base),\n+      _base_1(loaded_regions[1]._dumptime_base),\n+      _base_2(loaded_regions[2]._dumptime_base),\n+      _base_3(loaded_regions[3]._dumptime_base) {\n+    _top = loaded_regions[NUM_LOADED_REGIONS-1].top();\n+  }\n+\n+  bool do_bit(size_t offset) {\n+    narrowOop* p = _start + offset;\n+    narrowOop v = *p;\n+    assert(!CompressedOops::is_null(v), \"null oops should have been filtered out at dump time\");\n+    uintptr_t o = cast_from_oop<uintptr_t>(ArchiveHeapLoader::decode_from_archive(v));\n+    assert(_base_0 <= o && o < _top, \"must be\");\n+\n+\n+    \/\/ We usually have only 2 regions for the default archive. Use template to avoid unnecessary comparisons.\n+    if (NUM_LOADED_REGIONS > 3 && o >= _base_3) {\n+      o += _offset_3;\n+    } else if (NUM_LOADED_REGIONS > 2 && o >= _base_2) {\n+      o += _offset_2;\n+    } else if (o >= _base_1) {\n+      o += _offset_1;\n+    } else {\n+      o += _offset_0;\n+    }\n+    ArchiveHeapLoader::assert_in_loaded_heap(o);\n+    RawAccess<IS_NOT_NULL>::oop_store(p, cast_to_oop(o));\n+    return true;\n+  }\n+};\n+\n+int ArchiveHeapLoader::init_loaded_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n+                                           MemRegion& archive_space) {\n+  size_t total_bytes = 0;\n+  int num_loaded_regions = 0;\n+  for (int i = MetaspaceShared::first_archive_heap_region;\n+       i <= MetaspaceShared::last_archive_heap_region; i++) {\n+    FileMapRegion* r = mapinfo->space_at(i);\n+    r->assert_is_heap_region();\n+    if (r->used() > 0) {\n+      assert(is_aligned(r->used(), HeapWordSize), \"must be\");\n+      total_bytes += r->used();\n+      LoadedArchiveHeapRegion* ri = &loaded_regions[num_loaded_regions++];\n+      ri->_region_index = i;\n+      ri->_region_size = r->used();\n+      ri->_dumptime_base = (uintptr_t)mapinfo->start_address_as_decoded_from_archive(r);\n+    }\n+  }\n+\n+  assert(is_aligned(total_bytes, HeapWordSize), \"must be\");\n+  size_t word_size = total_bytes \/ HeapWordSize;\n+  HeapWord* buffer = Universe::heap()->allocate_loaded_archive_space(word_size);\n+  if (buffer == nullptr) {\n+    return 0;\n+  }\n+\n+  archive_space = MemRegion(buffer, word_size);\n+  _loaded_heap_bottom = (uintptr_t)archive_space.start();\n+  _loaded_heap_top    = _loaded_heap_bottom + total_bytes;\n+\n+  return num_loaded_regions;\n+}\n+\n+void ArchiveHeapLoader::sort_loaded_regions(LoadedArchiveHeapRegion* loaded_regions, int num_loaded_regions,\n+                                            uintptr_t buffer) {\n+  \/\/ Find the relocation offset of the pointers in each region\n+  qsort(loaded_regions, num_loaded_regions, sizeof(LoadedArchiveHeapRegion),\n+        LoadedArchiveHeapRegion::comparator);\n+\n+  uintptr_t p = buffer;\n+  for (int i = 0; i < num_loaded_regions; i++) {\n+    \/\/ This region will be loaded at p, so all objects inside this\n+    \/\/ region will be shifted by ri->offset\n+    LoadedArchiveHeapRegion* ri = &loaded_regions[i];\n+    ri->_runtime_offset = p - ri->_dumptime_base;\n+    p += ri->_region_size;\n+  }\n+  assert(p == _loaded_heap_top, \"must be\");\n+}\n+\n+bool ArchiveHeapLoader::load_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n+                                     int num_loaded_regions, uintptr_t buffer) {\n+  uintptr_t bitmap_base = (uintptr_t)mapinfo->map_bitmap_region();\n+  if (bitmap_base == 0) {\n+    _loading_failed = true;\n+    return false; \/\/ OOM or CRC error\n+  }\n+  uintptr_t load_address = buffer;\n+  for (int i = 0; i < num_loaded_regions; i++) {\n+    LoadedArchiveHeapRegion* ri = &loaded_regions[i];\n+    FileMapRegion* r = mapinfo->space_at(ri->_region_index);\n+\n+    if (!mapinfo->read_region(ri->_region_index, (char*)load_address, r->used(), \/* do_commit = *\/ false)) {\n+      \/\/ There's no easy way to free the buffer, so we will fill it with zero later\n+      \/\/ in fill_failed_loaded_region(), and it will eventually be GC'ed.\n+      log_warning(cds)(\"Loading of heap region %d has failed. Archived objects are disabled\", i);\n+      _loading_failed = true;\n+      return false;\n+    }\n+    log_info(cds)(\"Loaded heap    region #%d at base \" INTPTR_FORMAT \" top \" INTPTR_FORMAT\n+                  \" size \" SIZE_FORMAT_W(6) \" delta \" INTX_FORMAT,\n+                  ri->_region_index, load_address, load_address + ri->_region_size,\n+                  ri->_region_size, ri->_runtime_offset);\n+\n+    uintptr_t oopmap = bitmap_base + r->oopmap_offset();\n+    BitMapView bm((BitMap::bm_word_t*)oopmap, r->oopmap_size_in_bits());\n+\n+    if (num_loaded_regions == 4) {\n+      PatchLoadedRegionPointers<4> patcher((narrowOop*)load_address, loaded_regions);\n+      bm.iterate(&patcher);\n+    } else if (num_loaded_regions == 3) {\n+      PatchLoadedRegionPointers<3> patcher((narrowOop*)load_address, loaded_regions);\n+      bm.iterate(&patcher);\n+    } else {\n+      assert(num_loaded_regions == 2, \"must be\");\n+      PatchLoadedRegionPointers<2> patcher((narrowOop*)load_address, loaded_regions);\n+      bm.iterate(&patcher);\n+    }\n+\n+    load_address += r->used();\n+  }\n+\n+  return true;\n+}\n+\n+bool ArchiveHeapLoader::load_heap_regions(FileMapInfo* mapinfo) {\n+  init_narrow_oop_decoding(mapinfo->narrow_oop_base(), mapinfo->narrow_oop_shift());\n+\n+  LoadedArchiveHeapRegion loaded_regions[MetaspaceShared::max_num_heap_regions];\n+  memset(loaded_regions, 0, sizeof(loaded_regions));\n+\n+  MemRegion archive_space;\n+  int num_loaded_regions = init_loaded_regions(mapinfo, loaded_regions, archive_space);\n+  if (num_loaded_regions <= 0) {\n+    return false;\n+  }\n+  sort_loaded_regions(loaded_regions, num_loaded_regions, (uintptr_t)archive_space.start());\n+  if (!load_regions(mapinfo, loaded_regions, num_loaded_regions, (uintptr_t)archive_space.start())) {\n+    assert(_loading_failed, \"must be\");\n+    return false;\n+  }\n+\n+  init_loaded_heap_relocation(loaded_regions, num_loaded_regions);\n+  _is_loaded = true;\n+\n+  return true;\n+}\n+\n+class VerifyLoadedHeapEmbeddedPointers: public BasicOopIterateClosure {\n+  ResourceHashtable<uintptr_t, bool>* _table;\n+\n+ public:\n+  VerifyLoadedHeapEmbeddedPointers(ResourceHashtable<uintptr_t, bool>* table) : _table(table) {}\n+\n+  virtual void do_oop(narrowOop* p) {\n+    \/\/ This should be called before the loaded regions are modified, so all the embedded pointers\n+    \/\/ must be NULL, or must point to a valid object in the loaded regions.\n+    narrowOop v = *p;\n+    if (!CompressedOops::is_null(v)) {\n+      oop o = CompressedOops::decode_not_null(v);\n+      uintptr_t u = cast_from_oop<uintptr_t>(o);\n+      ArchiveHeapLoader::assert_in_loaded_heap(u);\n+      guarantee(_table->contains(u), \"must point to beginning of object in loaded archived regions\");\n+    }\n+  }\n+  virtual void do_oop(oop* p) {\n+    ShouldNotReachHere();\n+  }\n+};\n+\n+void ArchiveHeapLoader::finish_initialization() {\n+  if (is_loaded()) {\n+    HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n+    HeapWord* top    = (HeapWord*)_loaded_heap_top;\n+\n+    MemRegion archive_space = MemRegion(bottom, top);\n+    Universe::heap()->complete_loaded_archive_space(archive_space);\n+  }\n+\n+  if (VerifyArchivedFields <= 0 || !is_loaded()) {\n+    return;\n+  }\n+\n+  log_info(cds, heap)(\"Verify all oops and pointers in loaded heap\");\n+\n+  ResourceMark rm;\n+  ResourceHashtable<uintptr_t, bool> table;\n+  VerifyLoadedHeapEmbeddedPointers verifier(&table);\n+  HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n+  HeapWord* top    = (HeapWord*)_loaded_heap_top;\n+\n+  for (HeapWord* p = bottom; p < top; ) {\n+    oop o = cast_to_oop(p);\n+    table.put(cast_from_oop<uintptr_t>(o), true);\n+    p += o->size();\n+  }\n+\n+  for (HeapWord* p = bottom; p < top; ) {\n+    oop o = cast_to_oop(p);\n+    o->oop_iterate(&verifier);\n+    p += o->size();\n+  }\n+}\n+\n+void ArchiveHeapLoader::fill_failed_loaded_region() {\n+  assert(_loading_failed, \"must be\");\n+  if (_loaded_heap_bottom != 0) {\n+    assert(_loaded_heap_top != 0, \"must be\");\n+    HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n+    HeapWord* top = (HeapWord*)_loaded_heap_top;\n+    Universe::heap()->fill_with_objects(bottom, top - bottom);\n+  }\n+}\n+\n+#endif \/\/ INCLUDE_CDS_JAVA_HEAP\n","filename":"src\/hotspot\/share\/cds\/archiveHeapLoader.cpp","additions":437,"deletions":0,"binary":false,"changes":437,"status":"added"},{"patch":"@@ -0,0 +1,170 @@\n+\/*\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_CDS_ARCHIVEHEAPLOADER_HPP\n+#define SHARE_CDS_ARCHIVEHEAPLOADER_HPP\n+\n+#include \"gc\/shared\/gc_globals.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"memory\/allStatic.hpp\"\n+#include \"runtime\/globals.hpp\"\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"memory\/memRegion.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+class  FileMapInfo;\n+struct LoadedArchiveHeapRegion;\n+\n+class ArchiveHeapLoader : AllStatic {\n+public:\n+  \/\/ At runtime, heap regions in the CDS archive can be used in two different ways,\n+  \/\/ depending on the GC type:\n+  \/\/ - Mapped: (G1 only) the regions are directly mapped into the Java heap\n+  \/\/ - Loaded: At VM start-up, the objects in the heap regions are copied into the\n+  \/\/           Java heap. This is easier to implement than mapping but\n+  \/\/           slightly less efficient, as the embedded pointers need to be relocated.\n+  static bool can_use() { return can_map() || can_load(); }\n+\n+  \/\/ Can this VM map archived heap regions? Currently only G1+compressed{oops,cp}\n+  static bool can_map() {\n+    CDS_JAVA_HEAP_ONLY(return (UseG1GC && UseCompressedClassPointers);)\n+    NOT_CDS_JAVA_HEAP(return false;)\n+  }\n+  static bool is_mapped() {\n+    return closed_regions_mapped() && open_regions_mapped();\n+  }\n+\n+  \/\/ Can this VM load the objects from archived heap regions into the heap at start-up?\n+  static bool can_load()  NOT_CDS_JAVA_HEAP_RETURN_(false);\n+  static void finish_initialization() NOT_CDS_JAVA_HEAP_RETURN;\n+  static bool is_loaded() {\n+    CDS_JAVA_HEAP_ONLY(return _is_loaded;)\n+    NOT_CDS_JAVA_HEAP(return false;)\n+  }\n+\n+  static bool are_archived_strings_available() {\n+    return is_loaded() || closed_regions_mapped();\n+  }\n+  static bool are_archived_mirrors_available() {\n+    return is_fully_available();\n+  }\n+  static bool is_fully_available() {\n+    return is_loaded() || is_mapped();\n+  }\n+\n+  static ptrdiff_t runtime_delta() {\n+    assert(!UseCompressedOops, \"must be\");\n+    CDS_JAVA_HEAP_ONLY(return _runtime_delta;)\n+    NOT_CDS_JAVA_HEAP_RETURN_(0L);\n+  }\n+\n+  static void set_closed_regions_mapped() {\n+    CDS_JAVA_HEAP_ONLY(_closed_regions_mapped = true;)\n+    NOT_CDS_JAVA_HEAP_RETURN;\n+  }\n+  static bool closed_regions_mapped() {\n+    CDS_JAVA_HEAP_ONLY(return _closed_regions_mapped;)\n+    NOT_CDS_JAVA_HEAP_RETURN_(false);\n+  }\n+  static void set_open_regions_mapped() {\n+    CDS_JAVA_HEAP_ONLY(_open_regions_mapped = true;)\n+    NOT_CDS_JAVA_HEAP_RETURN;\n+  }\n+  static bool open_regions_mapped() {\n+    CDS_JAVA_HEAP_ONLY(return _open_regions_mapped;)\n+    NOT_CDS_JAVA_HEAP_RETURN_(false);\n+  }\n+\n+  \/\/ NarrowOops stored in the CDS archive may use a different encoding scheme\n+  \/\/ than CompressedOops::{base,shift} -- see FileMapInfo::map_heap_regions_impl.\n+  \/\/ To decode them, do not use CompressedOops::decode_not_null. Use this\n+  \/\/ function instead.\n+  inline static oop decode_from_archive(narrowOop v) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n+\n+  static void init_narrow_oop_decoding(address base, int shift) NOT_CDS_JAVA_HEAP_RETURN;\n+\n+  static void patch_embedded_pointers(MemRegion region, address oopmap,\n+                                      size_t oopmap_in_bits) NOT_CDS_JAVA_HEAP_RETURN;\n+\n+  static void fixup_regions() NOT_CDS_JAVA_HEAP_RETURN;\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+private:\n+  static bool _closed_regions_mapped;\n+  static bool _open_regions_mapped;\n+  static bool _is_loaded;\n+\n+  \/\/ Support for loaded archived heap. These are cached values from\n+  \/\/ LoadedArchiveHeapRegion's.\n+  static uintptr_t _dumptime_base_0;\n+  static uintptr_t _dumptime_base_1;\n+  static uintptr_t _dumptime_base_2;\n+  static uintptr_t _dumptime_base_3;\n+  static uintptr_t _dumptime_top;\n+  static intx _runtime_offset_0;\n+  static intx _runtime_offset_1;\n+  static intx _runtime_offset_2;\n+  static intx _runtime_offset_3;\n+\n+  static uintptr_t _loaded_heap_bottom;\n+  static uintptr_t _loaded_heap_top;\n+  static bool _loading_failed;\n+\n+  \/\/ UseCompressedOops only: Used by decode_from_archive\n+  static address _narrow_oop_base;\n+  static int     _narrow_oop_shift;\n+\n+  \/\/ !UseCompressedOops only: used to relocate pointers to the archived objects\n+  static ptrdiff_t _runtime_delta;\n+\n+  static int init_loaded_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n+                                 MemRegion& archive_space);\n+  static void sort_loaded_regions(LoadedArchiveHeapRegion* loaded_regions, int num_loaded_regions,\n+                                  uintptr_t buffer);\n+  static bool load_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n+                           int num_loaded_regions, uintptr_t buffer);\n+  static void init_loaded_heap_relocation(LoadedArchiveHeapRegion* reloc_info,\n+                                          int num_loaded_regions);\n+  static void fill_failed_loaded_region();\n+\n+  static bool is_in_loaded_heap(uintptr_t o) {\n+    return (_loaded_heap_bottom <= o && o < _loaded_heap_top);\n+  }\n+\n+public:\n+\n+  static bool load_heap_regions(FileMapInfo* mapinfo);\n+  static void assert_in_loaded_heap(uintptr_t o) {\n+    assert(is_in_loaded_heap(o), \"must be\");\n+  }\n+\n+  static void set_runtime_delta(ptrdiff_t delta) {\n+    assert(!UseCompressedOops, \"must be\");\n+    _runtime_delta = delta;\n+  }\n+#endif \/\/ INCLUDE_CDS_JAVA_HEAP\n+\n+};\n+\n+#endif \/\/ SHARE_CDS_ARCHIVEHEAPLOADER_HPP\n","filename":"src\/hotspot\/share\/cds\/archiveHeapLoader.hpp","additions":170,"deletions":0,"binary":false,"changes":170,"status":"added"},{"patch":"@@ -0,0 +1,58 @@\n+\/*\n+ * Copyright (c) 2018, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_CDS_ARCHIVEHEAPLOADER_INLINE_HPP\n+#define SHARE_CDS_ARCHIVEHEAPLOADER_INLINE_HPP\n+\n+#include \"cds\/archiveHeapLoader.hpp\"\n+\n+#include \"oops\/compressedOops.inline.hpp\"\n+#include \"utilities\/align.hpp\"\n+\n+#if INCLUDE_CDS_JAVA_HEAP\n+\n+inline oop ArchiveHeapLoader::decode_from_archive(narrowOop v) {\n+  assert(!CompressedOops::is_null(v), \"narrow oop value can never be zero\");\n+  uintptr_t p = ((uintptr_t)_narrow_oop_base) + ((uintptr_t)v << _narrow_oop_shift);\n+  if (p >= _dumptime_base_0) {\n+    assert(p < _dumptime_top, \"must be\");\n+    if (p >= _dumptime_base_3) {\n+      p += _runtime_offset_3;\n+    } else if (p >= _dumptime_base_2) {\n+      p += _runtime_offset_2;\n+    } else if (p >= _dumptime_base_1) {\n+      p += _runtime_offset_1;\n+    } else {\n+      p += _runtime_offset_0;\n+    }\n+  }\n+\n+  oop result = cast_to_oop((uintptr_t)p);\n+  assert(is_object_aligned(result), \"address not aligned: \" INTPTR_FORMAT, p2i((void*) result));\n+  return result;\n+}\n+\n+#endif\n+\n+#endif \/\/ SHARE_CDS_ARCHIVEHEAPLOADER_INLINE_HPP\n","filename":"src\/hotspot\/share\/cds\/archiveHeapLoader.inline.hpp","additions":58,"deletions":0,"binary":false,"changes":58,"status":"added"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/archiveHeapLoader.inline.hpp\"\n@@ -32,1 +33,1 @@\n-#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -318,1 +319,1 @@\n-    if (CompressedOops::is_null(o) || !HeapShared::is_fully_available()) {\n+    if (CompressedOops::is_null(o) || !ArchiveHeapLoader::is_fully_available()) {\n@@ -321,3 +322,3 @@\n-      assert(HeapShared::can_use(), \"sanity\");\n-      assert(HeapShared::is_fully_available(), \"must be\");\n-      *p = HeapShared::decode_from_archive(o);\n+      assert(ArchiveHeapLoader::can_use(), \"sanity\");\n+      assert(ArchiveHeapLoader::is_fully_available(), \"must be\");\n+      *p = ArchiveHeapLoader::decode_from_archive(o);\n@@ -327,1 +328,1 @@\n-    if (dumptime_oop == 0 || !HeapShared::is_fully_available()) {\n+    if (dumptime_oop == 0 || !ArchiveHeapLoader::is_fully_available()) {\n@@ -330,1 +331,1 @@\n-      intptr_t runtime_oop = dumptime_oop + HeapShared::runtime_delta();\n+      intptr_t runtime_oop = dumptime_oop + ArchiveHeapLoader::runtime_delta();\n","filename":"src\/hotspot\/share\/cds\/archiveUtils.cpp","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/archiveHeapLoader.inline.hpp\"\n@@ -32,1 +33,1 @@\n-#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -1972,1 +1973,1 @@\n-    return cast_from_oop<address>(HeapShared::decode_from_archive(n));\n+    return cast_from_oop<address>(ArchiveHeapLoader::decode_from_archive(n));\n@@ -2018,1 +2019,1 @@\n-    if (HeapShared::can_map()) {\n+    if (ArchiveHeapLoader::can_map()) {\n@@ -2020,2 +2021,2 @@\n-    } else if (HeapShared::can_load()) {\n-      success = HeapShared::load_heap_regions(this);\n+    } else if (ArchiveHeapLoader::can_load()) {\n+      success = ArchiveHeapLoader::load_heap_regions(this);\n@@ -2087,1 +2088,1 @@\n-    return header()->heap_begin() + spc->mapping_offset() + HeapShared::runtime_delta();\n+    return header()->heap_begin() + spc->mapping_offset() + ArchiveHeapLoader::runtime_delta();\n@@ -2093,1 +2094,1 @@\n-    HeapShared::init_narrow_oop_decoding(narrow_oop_base() + delta, narrow_oop_shift());\n+    ArchiveHeapLoader::init_narrow_oop_decoding(narrow_oop_base() + delta, narrow_oop_shift());\n@@ -2095,1 +2096,1 @@\n-    HeapShared::set_runtime_delta(delta);\n+    ArchiveHeapLoader::set_runtime_delta(delta);\n@@ -2211,1 +2212,1 @@\n-    HeapShared::set_closed_regions_mapped();\n+    ArchiveHeapLoader::set_closed_regions_mapped();\n@@ -2218,1 +2219,1 @@\n-      HeapShared::set_open_regions_mapped();\n+      ArchiveHeapLoader::set_open_regions_mapped();\n@@ -2226,1 +2227,1 @@\n-  if (!HeapShared::closed_regions_mapped()) {\n+  if (!ArchiveHeapLoader::closed_regions_mapped()) {\n@@ -2231,1 +2232,1 @@\n-  if (!HeapShared::open_regions_mapped()) {\n+  if (!ArchiveHeapLoader::open_regions_mapped()) {\n@@ -2338,1 +2339,1 @@\n-    HeapShared::patch_embedded_pointers(\n+    ArchiveHeapLoader::patch_embedded_pointers(\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":14,"deletions":13,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -29,2 +30,1 @@\n-#include \"cds\/filemap.hpp\"\n-#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -48,2 +48,0 @@\n-#include \"memory\/metadataFactory.hpp\"\n-#include \"memory\/metaspaceClosure.hpp\"\n@@ -59,1 +57,0 @@\n-#include \"runtime\/globals_extension.hpp\"\n@@ -61,1 +58,0 @@\n-#include \"runtime\/java.hpp\"\n@@ -72,3 +68,0 @@\n-bool HeapShared::_closed_regions_mapped = false;\n-bool HeapShared::_open_regions_mapped = false;\n-bool HeapShared::_is_loaded = false;\n@@ -76,2 +69,0 @@\n-address   HeapShared::_narrow_oop_base;\n-int       HeapShared::_narrow_oop_shift;\n@@ -80,17 +71,0 @@\n-\/\/ Support for loaded heap.\n-uintptr_t HeapShared::_loaded_heap_bottom = 0;\n-uintptr_t HeapShared::_loaded_heap_top = 0;\n-uintptr_t HeapShared::_dumptime_base_0 = UINTPTR_MAX;\n-uintptr_t HeapShared::_dumptime_base_1 = UINTPTR_MAX;\n-uintptr_t HeapShared::_dumptime_base_2 = UINTPTR_MAX;\n-uintptr_t HeapShared::_dumptime_base_3 = UINTPTR_MAX;\n-uintptr_t HeapShared::_dumptime_top    = 0;\n-intx HeapShared::_runtime_offset_0 = 0;\n-intx HeapShared::_runtime_offset_1 = 0;\n-intx HeapShared::_runtime_offset_2 = 0;\n-intx HeapShared::_runtime_offset_3 = 0;\n-bool HeapShared::_loading_failed = false;\n-\n-\/\/ Support for mapped heap (!UseCompressedOops only)\n-ptrdiff_t HeapShared::_runtime_delta = 0;\n-\n@@ -165,16 +139,0 @@\n-void HeapShared::fixup_regions() {\n-  FileMapInfo* mapinfo = FileMapInfo::current_info();\n-  if (is_mapped()) {\n-    mapinfo->fixup_mapped_heap_regions();\n-  } else if (_loading_failed) {\n-    fill_failed_loaded_region();\n-  }\n-  if (is_fully_available()) {\n-    if (!MetaspaceShared::use_full_module_graph()) {\n-      \/\/ Need to remove all the archived java.lang.Module objects from HeapShared::roots().\n-      ClassLoaderDataShared::clear_archived_oops();\n-    }\n-  }\n-  SystemDictionaryShared::update_archived_mirror_native_pointers();\n-}\n-\n@@ -296,1 +254,1 @@\n-  if (is_fully_available()) {\n+  if (ArchiveHeapLoader::is_fully_available()) {\n@@ -441,1 +399,1 @@\n-  if (!is_fully_available()) {\n+  if (!ArchiveHeapLoader::is_fully_available()) {\n@@ -588,5 +546,0 @@\n-void HeapShared::init_narrow_oop_decoding(address base, int shift) {\n-  _narrow_oop_base = base;\n-  _narrow_oop_shift = shift;\n-}\n-\n@@ -813,1 +766,1 @@\n-      assert(HeapShared::is_fully_available(), \"must be\");\n+      assert(ArchiveHeapLoader::is_fully_available(), \"must be\");\n@@ -859,1 +812,1 @@\n-  if (!is_fully_available()) {\n+  if (!ArchiveHeapLoader::is_fully_available()) {\n@@ -897,1 +850,1 @@\n-  if (!is_fully_available()) {\n+  if (!ArchiveHeapLoader::is_fully_available()) {\n@@ -1666,347 +1619,0 @@\n-\/\/ Patch all the embedded oop pointers inside an archived heap region,\n-\/\/ to be consistent with the runtime oop encoding.\n-class PatchCompressedEmbeddedPointers: public BitMapClosure {\n-  narrowOop* _start;\n-\n- public:\n-  PatchCompressedEmbeddedPointers(narrowOop* start) : _start(start) {}\n-\n-  bool do_bit(size_t offset) {\n-    narrowOop* p = _start + offset;\n-    narrowOop v = *p;\n-    assert(!CompressedOops::is_null(v), \"null oops should have been filtered out at dump time\");\n-    oop o = HeapShared::decode_from_archive(v);\n-    RawAccess<IS_NOT_NULL>::oop_store(p, o);\n-    return true;\n-  }\n-};\n-\n-class PatchUncompressedEmbeddedPointers: public BitMapClosure {\n-  oop* _start;\n-\n- public:\n-  PatchUncompressedEmbeddedPointers(oop* start) : _start(start) {}\n-\n-  bool do_bit(size_t offset) {\n-    oop* p = _start + offset;\n-    intptr_t dumptime_oop = (intptr_t)((void*)*p);\n-    assert(dumptime_oop != 0, \"null oops should have been filtered out at dump time\");\n-    intptr_t runtime_oop = dumptime_oop + HeapShared::runtime_delta();\n-    RawAccess<IS_NOT_NULL>::oop_store(p, cast_to_oop(runtime_oop));\n-    return true;\n-  }\n-};\n-\n-\/\/ Patch all the non-null pointers that are embedded in the archived heap objects\n-\/\/ in this region\n-void HeapShared::patch_embedded_pointers(MemRegion region, address oopmap,\n-                                         size_t oopmap_size_in_bits) {\n-  BitMapView bm((BitMap::bm_word_t*)oopmap, oopmap_size_in_bits);\n-\n-#ifndef PRODUCT\n-  ResourceMark rm;\n-  ResourceBitMap checkBm = calculate_oopmap(region);\n-  assert(bm.is_same(checkBm), \"sanity\");\n-#endif\n-\n-  if (UseCompressedOops) {\n-    PatchCompressedEmbeddedPointers patcher((narrowOop*)region.start());\n-    bm.iterate(&patcher);\n-  } else {\n-    PatchUncompressedEmbeddedPointers patcher((oop*)region.start());\n-    bm.iterate(&patcher);\n-  }\n-}\n-\n-\/\/ The CDS archive remembers each heap object by its address at dump time, but\n-\/\/ the heap object may be loaded at a different address at run time. This structure is used\n-\/\/ to translate the dump time addresses for all objects in FileMapInfo::space_at(region_index)\n-\/\/ to their runtime addresses.\n-struct LoadedArchiveHeapRegion {\n-  int       _region_index;   \/\/ index for FileMapInfo::space_at(index)\n-  size_t    _region_size;    \/\/ number of bytes in this region\n-  uintptr_t _dumptime_base;  \/\/ The dump-time (decoded) address of the first object in this region\n-  intx      _runtime_offset; \/\/ If an object's dump time address P is within in this region, its\n-                             \/\/ runtime address is P + _runtime_offset\n-\n-  static int comparator(const void* a, const void* b) {\n-    LoadedArchiveHeapRegion* reg_a = (LoadedArchiveHeapRegion*)a;\n-    LoadedArchiveHeapRegion* reg_b = (LoadedArchiveHeapRegion*)b;\n-    if (reg_a->_dumptime_base < reg_b->_dumptime_base) {\n-      return -1;\n-    } else if (reg_a->_dumptime_base == reg_b->_dumptime_base) {\n-      return 0;\n-    } else {\n-      return 1;\n-    }\n-  }\n-\n-  uintptr_t top() {\n-    return _dumptime_base + _region_size;\n-  }\n-};\n-\n-void HeapShared::init_loaded_heap_relocation(LoadedArchiveHeapRegion* loaded_regions,\n-                                             int num_loaded_regions) {\n-  _dumptime_base_0 = loaded_regions[0]._dumptime_base;\n-  _dumptime_base_1 = loaded_regions[1]._dumptime_base;\n-  _dumptime_base_2 = loaded_regions[2]._dumptime_base;\n-  _dumptime_base_3 = loaded_regions[3]._dumptime_base;\n-  _dumptime_top = loaded_regions[num_loaded_regions-1].top();\n-\n-  _runtime_offset_0 = loaded_regions[0]._runtime_offset;\n-  _runtime_offset_1 = loaded_regions[1]._runtime_offset;\n-  _runtime_offset_2 = loaded_regions[2]._runtime_offset;\n-  _runtime_offset_3 = loaded_regions[3]._runtime_offset;\n-\n-  assert(2 <= num_loaded_regions && num_loaded_regions <= 4, \"must be\");\n-  if (num_loaded_regions < 4) {\n-    _dumptime_base_3 = UINTPTR_MAX;\n-  }\n-  if (num_loaded_regions < 3) {\n-    _dumptime_base_2 = UINTPTR_MAX;\n-  }\n-}\n-\n-bool HeapShared::can_load() {\n-  return Universe::heap()->can_load_archived_objects();\n-}\n-\n-template <int NUM_LOADED_REGIONS>\n-class PatchLoadedRegionPointers: public BitMapClosure {\n-  narrowOop* _start;\n-  intx _offset_0;\n-  intx _offset_1;\n-  intx _offset_2;\n-  intx _offset_3;\n-  uintptr_t _base_0;\n-  uintptr_t _base_1;\n-  uintptr_t _base_2;\n-  uintptr_t _base_3;\n-  uintptr_t _top;\n-\n-  static_assert(MetaspaceShared::max_num_heap_regions == 4, \"can't handle more than 4 regions\");\n-  static_assert(NUM_LOADED_REGIONS >= 2, \"we have at least 2 loaded regions\");\n-  static_assert(NUM_LOADED_REGIONS <= 4, \"we have at most 4 loaded regions\");\n-\n- public:\n-  PatchLoadedRegionPointers(narrowOop* start, LoadedArchiveHeapRegion* loaded_regions)\n-    : _start(start),\n-      _offset_0(loaded_regions[0]._runtime_offset),\n-      _offset_1(loaded_regions[1]._runtime_offset),\n-      _offset_2(loaded_regions[2]._runtime_offset),\n-      _offset_3(loaded_regions[3]._runtime_offset),\n-      _base_0(loaded_regions[0]._dumptime_base),\n-      _base_1(loaded_regions[1]._dumptime_base),\n-      _base_2(loaded_regions[2]._dumptime_base),\n-      _base_3(loaded_regions[3]._dumptime_base) {\n-    _top = loaded_regions[NUM_LOADED_REGIONS-1].top();\n-  }\n-\n-  bool do_bit(size_t offset) {\n-    narrowOop* p = _start + offset;\n-    narrowOop v = *p;\n-    assert(!CompressedOops::is_null(v), \"null oops should have been filtered out at dump time\");\n-    uintptr_t o = cast_from_oop<uintptr_t>(HeapShared::decode_from_archive(v));\n-    assert(_base_0 <= o && o < _top, \"must be\");\n-\n-\n-    \/\/ We usually have only 2 regions for the default archive. Use template to avoid unnecessary comparisons.\n-    if (NUM_LOADED_REGIONS > 3 && o >= _base_3) {\n-      o += _offset_3;\n-    } else if (NUM_LOADED_REGIONS > 2 && o >= _base_2) {\n-      o += _offset_2;\n-    } else if (o >= _base_1) {\n-      o += _offset_1;\n-    } else {\n-      o += _offset_0;\n-    }\n-    HeapShared::assert_in_loaded_heap(o);\n-    RawAccess<IS_NOT_NULL>::oop_store(p, cast_to_oop(o));\n-    return true;\n-  }\n-};\n-\n-int HeapShared::init_loaded_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n-                                    MemRegion& archive_space) {\n-  size_t total_bytes = 0;\n-  int num_loaded_regions = 0;\n-  for (int i = MetaspaceShared::first_archive_heap_region;\n-       i <= MetaspaceShared::last_archive_heap_region; i++) {\n-    FileMapRegion* r = mapinfo->space_at(i);\n-    r->assert_is_heap_region();\n-    if (r->used() > 0) {\n-      assert(is_aligned(r->used(), HeapWordSize), \"must be\");\n-      total_bytes += r->used();\n-      LoadedArchiveHeapRegion* ri = &loaded_regions[num_loaded_regions++];\n-      ri->_region_index = i;\n-      ri->_region_size = r->used();\n-      ri->_dumptime_base = (uintptr_t)mapinfo->start_address_as_decoded_from_archive(r);\n-    }\n-  }\n-\n-  assert(is_aligned(total_bytes, HeapWordSize), \"must be\");\n-  size_t word_size = total_bytes \/ HeapWordSize;\n-  HeapWord* buffer = Universe::heap()->allocate_loaded_archive_space(word_size);\n-  if (buffer == nullptr) {\n-    return 0;\n-  }\n-\n-  archive_space = MemRegion(buffer, word_size);\n-  _loaded_heap_bottom = (uintptr_t)archive_space.start();\n-  _loaded_heap_top    = _loaded_heap_bottom + total_bytes;\n-\n-  return num_loaded_regions;\n-}\n-\n-void HeapShared::sort_loaded_regions(LoadedArchiveHeapRegion* loaded_regions, int num_loaded_regions,\n-                                     uintptr_t buffer) {\n-  \/\/ Find the relocation offset of the pointers in each region\n-  qsort(loaded_regions, num_loaded_regions, sizeof(LoadedArchiveHeapRegion),\n-        LoadedArchiveHeapRegion::comparator);\n-\n-  uintptr_t p = buffer;\n-  for (int i = 0; i < num_loaded_regions; i++) {\n-    \/\/ This region will be loaded at p, so all objects inside this\n-    \/\/ region will be shifted by ri->offset\n-    LoadedArchiveHeapRegion* ri = &loaded_regions[i];\n-    ri->_runtime_offset = p - ri->_dumptime_base;\n-    p += ri->_region_size;\n-  }\n-  assert(p == _loaded_heap_top, \"must be\");\n-}\n-\n-bool HeapShared::load_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n-                              int num_loaded_regions, uintptr_t buffer) {\n-  uintptr_t bitmap_base = (uintptr_t)mapinfo->map_bitmap_region();\n-  if (bitmap_base == 0) {\n-    _loading_failed = true;\n-    return false; \/\/ OOM or CRC error\n-  }\n-  uintptr_t load_address = buffer;\n-  for (int i = 0; i < num_loaded_regions; i++) {\n-    LoadedArchiveHeapRegion* ri = &loaded_regions[i];\n-    FileMapRegion* r = mapinfo->space_at(ri->_region_index);\n-\n-    if (!mapinfo->read_region(ri->_region_index, (char*)load_address, r->used(), \/* do_commit = *\/ false)) {\n-      \/\/ There's no easy way to free the buffer, so we will fill it with zero later\n-      \/\/ in fill_failed_loaded_region(), and it will eventually be GC'ed.\n-      log_warning(cds)(\"Loading of heap region %d has failed. Archived objects are disabled\", i);\n-      _loading_failed = true;\n-      return false;\n-    }\n-    log_info(cds)(\"Loaded heap    region #%d at base \" INTPTR_FORMAT \" top \" INTPTR_FORMAT\n-                  \" size \" SIZE_FORMAT_W(6) \" delta \" INTX_FORMAT,\n-                  ri->_region_index, load_address, load_address + ri->_region_size,\n-                  ri->_region_size, ri->_runtime_offset);\n-\n-    uintptr_t oopmap = bitmap_base + r->oopmap_offset();\n-    BitMapView bm((BitMap::bm_word_t*)oopmap, r->oopmap_size_in_bits());\n-\n-    if (num_loaded_regions == 4) {\n-      PatchLoadedRegionPointers<4> patcher((narrowOop*)load_address, loaded_regions);\n-      bm.iterate(&patcher);\n-    } else if (num_loaded_regions == 3) {\n-      PatchLoadedRegionPointers<3> patcher((narrowOop*)load_address, loaded_regions);\n-      bm.iterate(&patcher);\n-    } else {\n-      assert(num_loaded_regions == 2, \"must be\");\n-      PatchLoadedRegionPointers<2> patcher((narrowOop*)load_address, loaded_regions);\n-      bm.iterate(&patcher);\n-    }\n-\n-    load_address += r->used();\n-  }\n-\n-  return true;\n-}\n-\n-bool HeapShared::load_heap_regions(FileMapInfo* mapinfo) {\n-  init_narrow_oop_decoding(mapinfo->narrow_oop_base(), mapinfo->narrow_oop_shift());\n-\n-  LoadedArchiveHeapRegion loaded_regions[MetaspaceShared::max_num_heap_regions];\n-  memset(loaded_regions, 0, sizeof(loaded_regions));\n-\n-  MemRegion archive_space;\n-  int num_loaded_regions = init_loaded_regions(mapinfo, loaded_regions, archive_space);\n-  if (num_loaded_regions <= 0) {\n-    return false;\n-  }\n-  sort_loaded_regions(loaded_regions, num_loaded_regions, (uintptr_t)archive_space.start());\n-  if (!load_regions(mapinfo, loaded_regions, num_loaded_regions, (uintptr_t)archive_space.start())) {\n-    assert(_loading_failed, \"must be\");\n-    return false;\n-  }\n-\n-  init_loaded_heap_relocation(loaded_regions, num_loaded_regions);\n-  _is_loaded = true;\n-\n-  return true;\n-}\n-\n-class VerifyLoadedHeapEmbeddedPointers: public BasicOopIterateClosure {\n-  ResourceHashtable<uintptr_t, bool>* _table;\n-\n- public:\n-  VerifyLoadedHeapEmbeddedPointers(ResourceHashtable<uintptr_t, bool>* table) : _table(table) {}\n-\n-  virtual void do_oop(narrowOop* p) {\n-    \/\/ This should be called before the loaded regions are modified, so all the embedded pointers\n-    \/\/ must be NULL, or must point to a valid object in the loaded regions.\n-    narrowOop v = *p;\n-    if (!CompressedOops::is_null(v)) {\n-      oop o = CompressedOops::decode_not_null(v);\n-      uintptr_t u = cast_from_oop<uintptr_t>(o);\n-      HeapShared::assert_in_loaded_heap(u);\n-      guarantee(_table->contains(u), \"must point to beginning of object in loaded archived regions\");\n-    }\n-  }\n-  virtual void do_oop(oop* p) {\n-    ShouldNotReachHere();\n-  }\n-};\n-\n-void HeapShared::finish_initialization() {\n-  if (is_loaded()) {\n-    HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n-    HeapWord* top    = (HeapWord*)_loaded_heap_top;\n-\n-    MemRegion archive_space = MemRegion(bottom, top);\n-    Universe::heap()->complete_loaded_archive_space(archive_space);\n-  }\n-\n-  if (VerifyArchivedFields <= 0 || !is_loaded()) {\n-    return;\n-  }\n-\n-  log_info(cds, heap)(\"Verify all oops and pointers in loaded heap\");\n-\n-  ResourceMark rm;\n-  ResourceHashtable<uintptr_t, bool> table;\n-  VerifyLoadedHeapEmbeddedPointers verifier(&table);\n-  HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n-  HeapWord* top    = (HeapWord*)_loaded_heap_top;\n-\n-  for (HeapWord* p = bottom; p < top; ) {\n-    oop o = cast_to_oop(p);\n-    table.put(cast_from_oop<uintptr_t>(o), true);\n-    p += o->size();\n-  }\n-\n-  for (HeapWord* p = bottom; p < top; ) {\n-    oop o = cast_to_oop(p);\n-    o->oop_iterate(&verifier);\n-    p += o->size();\n-  }\n-}\n-\n-void HeapShared::fill_failed_loaded_region() {\n-  assert(_loading_failed, \"must be\");\n-  if (_loaded_heap_bottom != 0) {\n-    assert(_loaded_heap_top != 0, \"must be\");\n-    HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n-    HeapWord* top = (HeapWord*)_loaded_heap_top;\n-    Universe::heap()->fill_with_objects(bottom, top - bottom);\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":7,"deletions":401,"binary":false,"changes":408,"status":"modified"},{"patch":"@@ -32,1 +32,0 @@\n-#include \"classfile\/systemDictionary.hpp\"\n@@ -35,0 +34,1 @@\n+#include \"memory\/allStatic.hpp\"\n@@ -36,1 +36,0 @@\n-#include \"oops\/objArrayKlass.hpp\"\n@@ -40,2 +39,0 @@\n-#include \"oops\/typeArrayKlass.hpp\"\n-#include \"utilities\/bitMap.hpp\"\n@@ -49,0 +46,1 @@\n+class ResourceBitMap;\n@@ -151,8 +149,0 @@\n-  \/\/ At runtime, heap regions in the CDS archive can be used in two different ways,\n-  \/\/ depending on the GC type:\n-  \/\/ - Mapped: (G1 only) the regions are directly mapped into the Java heap\n-  \/\/ - Loaded: At VM start-up, the objects in the heap regions are copied into the\n-  \/\/           Java heap. This is easier to implement than mapping but\n-  \/\/           slightly less efficient, as the embedded pointers need to be relocated.\n-  static bool can_use() { return can_map() || can_load(); }\n-\n@@ -173,8 +163,0 @@\n-  \/\/ Can this VM map archived heap regions? Currently only G1+compressed{oops,cp}\n-  static bool can_map() {\n-    CDS_JAVA_HEAP_ONLY(return (UseG1GC && UseCompressedClassPointers);)\n-    NOT_CDS_JAVA_HEAP(return false;)\n-  }\n-  static bool is_mapped() {\n-    return closed_regions_mapped() && open_regions_mapped();\n-  }\n@@ -182,17 +164,0 @@\n-  \/\/ Can this VM load the objects from archived heap regions into the heap at start-up?\n-  static bool can_load()  NOT_CDS_JAVA_HEAP_RETURN_(false);\n-  static void finish_initialization() NOT_CDS_JAVA_HEAP_RETURN;\n-  static bool is_loaded() {\n-    CDS_JAVA_HEAP_ONLY(return _is_loaded;)\n-    NOT_CDS_JAVA_HEAP(return false;)\n-  }\n-\n-  static bool are_archived_strings_available() {\n-    return is_loaded() || closed_regions_mapped();\n-  }\n-  static bool are_archived_mirrors_available() {\n-    return is_fully_available();\n-  }\n-  static bool is_fully_available() {\n-    return is_loaded() || is_mapped();\n-  }\n@@ -203,3 +168,0 @@\n-  static bool _closed_regions_mapped;\n-  static bool _open_regions_mapped;\n-  static bool _is_loaded;\n@@ -208,15 +170,0 @@\n-  \/\/ Support for loaded archived heap. These are cached values from\n-  \/\/ LoadedArchiveHeapRegion's.\n-  static uintptr_t _dumptime_base_0;\n-  static uintptr_t _dumptime_base_1;\n-  static uintptr_t _dumptime_base_2;\n-  static uintptr_t _dumptime_base_3;\n-  static uintptr_t _dumptime_top;\n-  static intx _runtime_offset_0;\n-  static intx _runtime_offset_1;\n-  static intx _runtime_offset_2;\n-  static intx _runtime_offset_3;\n-  static uintptr_t _loaded_heap_bottom;\n-  static uintptr_t _loaded_heap_top;\n-  static bool _loading_failed;\n-\n@@ -229,5 +176,0 @@\n-  static bool load_heap_regions(FileMapInfo* mapinfo);\n-  static void assert_in_loaded_heap(uintptr_t o) {\n-    assert(is_in_loaded_heap(o), \"must be\");\n-  }\n-\n@@ -246,3 +188,0 @@\n-  static bool is_in_loaded_heap(uintptr_t o) {\n-    return (_loaded_heap_bottom <= o && o < _loaded_heap_top);\n-  }\n@@ -460,5 +399,0 @@\n-  static void set_runtime_delta(ptrdiff_t delta) {\n-    assert(!UseCompressedOops, \"must be\");\n-    _runtime_delta = delta;\n-  }\n-\n@@ -468,6 +402,0 @@\n-  static ptrdiff_t runtime_delta() {\n-    assert(!UseCompressedOops, \"must be\");\n-    CDS_JAVA_HEAP_ONLY(return _runtime_delta;)\n-    NOT_CDS_JAVA_HEAP_RETURN_(0L);\n-  }\n-\n@@ -482,19 +410,0 @@\n-  static void set_closed_regions_mapped() {\n-    CDS_JAVA_HEAP_ONLY(_closed_regions_mapped = true;)\n-    NOT_CDS_JAVA_HEAP_RETURN;\n-  }\n-  static bool closed_regions_mapped() {\n-    CDS_JAVA_HEAP_ONLY(return _closed_regions_mapped;)\n-    NOT_CDS_JAVA_HEAP_RETURN_(false);\n-  }\n-  static void set_open_regions_mapped() {\n-    CDS_JAVA_HEAP_ONLY(_open_regions_mapped = true;)\n-    NOT_CDS_JAVA_HEAP_RETURN;\n-  }\n-  static bool open_regions_mapped() {\n-    CDS_JAVA_HEAP_ONLY(return _open_regions_mapped;)\n-    NOT_CDS_JAVA_HEAP_RETURN_(false);\n-  }\n-\n-  static void fixup_regions() NOT_CDS_JAVA_HEAP_RETURN;\n-\n@@ -505,11 +414,0 @@\n-\n-  \/\/ NarrowOops stored in the CDS archive may use a different encoding scheme\n-  \/\/ than CompressedOops::{base,shift} -- see FileMapInfo::map_heap_regions_impl.\n-  \/\/ To decode them, do not use CompressedOops::decode_not_null. Use this\n-  \/\/ function instead.\n-  inline static oop decode_from_archive(narrowOop v) NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n-\n-  static void init_narrow_oop_decoding(address base, int shift) NOT_CDS_JAVA_HEAP_RETURN;\n-\n-  static void patch_embedded_pointers(MemRegion region, address oopmap,\n-                                      size_t oopmap_in_bits) NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/cds\/heapShared.hpp","additions":2,"deletions":104,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -1,57 +0,0 @@\n-\/*\n- * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_CDS_HEAPSHARED_INLINE_HPP\n-#define SHARE_CDS_HEAPSHARED_INLINE_HPP\n-\n-#include \"cds\/heapShared.hpp\"\n-#include \"oops\/compressedOops.inline.hpp\"\n-#include \"utilities\/align.hpp\"\n-\n-#if INCLUDE_CDS_JAVA_HEAP\n-\n-inline oop HeapShared::decode_from_archive(narrowOop v) {\n-  assert(!CompressedOops::is_null(v), \"narrow oop value can never be zero\");\n-  uintptr_t p = ((uintptr_t)_narrow_oop_base) + ((uintptr_t)v << _narrow_oop_shift);\n-  if (p >= _dumptime_base_0) {\n-    assert(p < _dumptime_top, \"must be\");\n-    if (p >= _dumptime_base_3) {\n-      p += _runtime_offset_3;\n-    } else if (p >= _dumptime_base_2) {\n-      p += _runtime_offset_2;\n-    } else if (p >= _dumptime_base_1) {\n-      p += _runtime_offset_1;\n-    } else {\n-      p += _runtime_offset_0;\n-    }\n-  }\n-\n-  oop result = cast_to_oop((uintptr_t)p);\n-  assert(is_object_aligned(result), \"address not aligned: \" INTPTR_FORMAT, p2i((void*) result));\n-  return result;\n-}\n-\n-#endif\n-\n-#endif \/\/ SHARE_CDS_HEAPSHARED_INLINE_HPP\n","filename":"src\/hotspot\/share\/cds\/heapShared.inline.hpp","additions":0,"deletions":57,"binary":false,"changes":57,"status":"deleted"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -1473,1 +1474,1 @@\n-  HeapShared::finish_initialization();\n+  ArchiveHeapLoader::finish_initialization();\n@@ -1560,1 +1561,1 @@\n-    result &= HeapShared::can_use();\n+    result &= ArchiveHeapLoader::can_use();\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -29,1 +29,0 @@\n-#include \"cds\/heapShared.inline.hpp\"\n","filename":"src\/hotspot\/share\/classfile\/compactHashtable.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,1 +28,2 @@\n-#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/archiveHeapLoader.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -58,0 +59,1 @@\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -897,1 +899,1 @@\n-    if (HeapShared::are_archived_mirrors_available()) {\n+    if (ArchiveHeapLoader::are_archived_mirrors_available()) {\n@@ -1324,1 +1326,1 @@\n-  if (HeapShared::is_mapped()) {\n+  if (ArchiveHeapLoader::is_mapped()) {\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/archiveHeapLoader.inline.hpp\"\n@@ -28,1 +29,1 @@\n-#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -77,1 +78,1 @@\n-    return HeapShared::decode_from_archive(v);\n+    return ArchiveHeapLoader::decode_from_archive(v);\n@@ -83,1 +84,1 @@\n-                           (intptr_t)HeapShared::runtime_delta();\n+                           (intptr_t)ArchiveHeapLoader::runtime_delta();\n@@ -834,1 +835,1 @@\n-  } else if (!HeapShared::are_archived_strings_available()) {\n+  } else if (!ArchiveHeapLoader::are_archived_strings_available()) {\n@@ -864,1 +865,1 @@\n-  assert(HeapShared::is_loaded(), \"must be\");\n+  assert(ArchiveHeapLoader::is_loaded(), \"must be\");\n","filename":"src\/hotspot\/share\/classfile\/stringTable.cpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -26,1 +26,0 @@\n-#include \"cds\/archiveUtils.hpp\"\n@@ -28,0 +27,2 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n+#include \"cds\/archiveUtils.hpp\"\n@@ -32,1 +33,0 @@\n-#include \"cds\/heapShared.hpp\"\n@@ -63,0 +63,1 @@\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -1602,1 +1603,1 @@\n-  if (!HeapShared::are_archived_mirrors_available()) {\n+  if (!ArchiveHeapLoader::are_archived_mirrors_available()) {\n","filename":"src\/hotspot\/share\/classfile\/systemDictionaryShared.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -26,1 +26,1 @@\n-#include \"cds\/heapShared.hpp\"\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -30,0 +30,1 @@\n+#include \"classfile\/javaClasses.hpp\"\n@@ -138,1 +139,1 @@\n-    \/\/ HeapShared::fixup_regions() fills the empty\n+    \/\/ ArchiveHeapLoader::fixup_regions fills the empty\n@@ -144,1 +145,1 @@\n-    HeapShared::fixup_regions();\n+    ArchiveHeapLoader::fixup_regions();\n","filename":"src\/hotspot\/share\/classfile\/vmClasses.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -454,1 +455,1 @@\n-        HeapShared::are_archived_mirrors_available() &&\n+        ArchiveHeapLoader::are_archived_mirrors_available() &&\n@@ -456,1 +457,1 @@\n-      assert(HeapShared::can_use(), \"Sanity\");\n+      assert(ArchiveHeapLoader::can_use(), \"Sanity\");\n@@ -809,1 +810,1 @@\n-    if (HeapShared::is_loaded()) {\n+    if (ArchiveHeapLoader::is_loaded()) {\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -349,1 +350,1 @@\n-    if (HeapShared::is_fully_available() &&\n+    if (ArchiveHeapLoader::is_fully_available() &&\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -46,0 +47,1 @@\n+#include \"oops\/objArrayKlass.hpp\"\n@@ -608,1 +610,1 @@\n-    if (HeapShared::are_archived_mirrors_available()) {\n+    if (ArchiveHeapLoader::are_archived_mirrors_available()) {\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"cds\/archiveHeapLoader.hpp\"\n@@ -30,1 +31,1 @@\n-#include \"cds\/heapShared.inline.hpp\"\n+#include \"cds\/heapShared.hpp\"\n@@ -1995,1 +1996,1 @@\n-  return HeapShared::closed_regions_mapped();\n+  return ArchiveHeapLoader::closed_regions_mapped();\n@@ -2020,1 +2021,1 @@\n-  return HeapShared::open_regions_mapped();\n+  return ArchiveHeapLoader::open_regions_mapped();\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"}]}