{"files":[{"patch":"@@ -1059,1 +1059,1 @@\n-\/\/ we only support positive index scale value (K > 0) to simplify the logic for clamping 32-bit bounds (L2, R2).\n+\/\/ we only support positive index scale value (K > 0) to simplify the logic for clamping 32-bit bounds (L_2, R_2).\n@@ -1067,1 +1067,1 @@\n-\/\/ variable j (inner_iv), j ranges over a shorter interval j:[0,Z2), where the limit is chosen to prevent various cases\n+\/\/ variable j (inner_iv), j ranges over a shorter interval j:[0,Z_2), where the limit is chosen to prevent various cases\n@@ -1069,1 +1069,1 @@\n-\/\/ 64-bit constant C, so i ranges in i:C+[0,Z2).\n+\/\/ 64-bit constant C, so i ranges in i:C+[0,Z_2).\n@@ -1071,3 +1071,3 @@\n-\/\/ The union of all the C+[0,Z2) ranges from the sub-loops must be identical to the whole range [A,B].  Assuming S>0,\n-\/\/ the first C must be A itself, and the next C value is the previous C+Z2.  In each sub-loop, j counts up from zero\n-\/\/ and exits just before i=C+Z2.\n+\/\/ The union of all the C+[0,Z_2) ranges from the sub-loops must be identical to the whole range [A,B].  Assuming S>0,\n+\/\/ the first C must be A itself, and the next C value is the previous C+Z_2.  In each sub-loop, j counts up from zero\n+\/\/ and exits just before i=C+Z_2.\n@@ -1084,2 +1084,2 @@\n-\/\/ the form j*K+L2 <u32 R2.  Note that L2 and R2 must be loop-invariant, but only with respect to the sub-loop.  Thus, the\n-\/\/ problem reduces to computing values for L2 and R2 (for each R.C. in the loop) in the loop header for the sub-loop.\n+\/\/ the form j*K+L_2 <u32 R_2.  Note that L_2 and R_2 must be loop-invariant, but only with respect to the sub-loop.  Thus, the\n+\/\/ problem reduces to computing values for L_2 and R_2 (for each R.C. in the loop) in the loop header for the sub-loop.\n@@ -1089,1 +1089,1 @@\n-\/\/ So, given j*K+Q <u R, we need to find some j*K+L2 <u32 R2, where L2 and R2 fit in 32 bits, and the 32-bit operations do\n+\/\/ So, given j*K+Q <u R, we need to find some j*K+L_2 <u32 R_2, where L_2 and R_2 fit in 32 bits, and the 32-bit operations do\n@@ -1093,1 +1093,1 @@\n-\/\/ If 32-bit multiplication j*K might overflow, we adjust the sub-loop limit Z2 closer to zero to reduce j's range.\n+\/\/ If 32-bit multiplication j*K might overflow, we adjust the sub-loop limit Z_2 closer to zero to reduce j's range.\n@@ -1096,2 +1096,2 @@\n-\/\/ Q_min=Q and Q_max=Z2*K+Q.  Making the upper limit Q_max be exclusive helps it integrate correctly with the strict\n-\/\/ comparisons against R and R2.  Sometimes a very high R will be replaced by an R2 derived from the more moderate\n+\/\/ Q_min=Q and Q_max=Z_2*K+Q.  Making the upper limit Q_max be exclusive helps it integrate correctly with the strict\n+\/\/ comparisons against R and R_2.  Sometimes a very high R will be replaced by an R_2 derived from the more moderate\n@@ -1112,1 +1112,1 @@\n-\/\/ If the 32-bit truncation loses information, no harm is done, since certainly the clamp also returns R2=zero.\n+\/\/ If the 32-bit truncation loses information, no harm is done, since certainly the clamp also returns R_2=zero.\n@@ -1163,0 +1163,4 @@\n+    if (rc_cmp->Opcode() == Op_CmpU) {\n+      \/\/ could be shared and have already been taken care of\n+      continue;\n+    }\n@@ -1167,1 +1171,0 @@\n-    CallStaticJavaNode* call = proj->is_uncommon_trap_if_pattern(Deoptimization::Reason_none);\n@@ -1175,2 +1178,2 @@\n-    Node* Z2 = new ConvI2LNode(inner_iters_actual_int, TypeLong::LONG);\n-    register_new_node(Z2, entry_control);\n+    Node* Z_2 = new ConvI2LNode(inner_iters_actual_int, TypeLong::LONG);\n+    register_new_node(Z_2, entry_control);\n@@ -1181,5 +1184,5 @@\n-    \/\/   j*K + L2 <u64 R    where L2 = C*K+L\n-    Node* L2 = new MulLNode(C, K);\n-    register_new_node(L2, entry_control);\n-    L2 = new AddLNode(L2, L);\n-    register_new_node(L2, entry_control);\n+    \/\/   j*K + L_2 <u64 R    where L_2 = C*K+L\n+    Node* L_2 = new MulLNode(C, K);\n+    register_new_node(L_2, entry_control);\n+    L_2 = new AddLNode(L_2, L);\n+    register_new_node(L_2, entry_control);\n@@ -1188,3 +1191,3 @@\n-    \/\/  Q_min = (j=0)*K + L2;  Q_max = (j=Z2)*K + L2\n-    Node* Q_min = L2;\n-    Node* Q_max = new MulLNode(Z2, K);\n+    \/\/  Q_min = (j=0)*K + L_2;  Q_max = (j=Z_2)*K + L_2\n+    Node* Q_min = L_2;\n+    Node* Q_max = new MulLNode(Z_2, K);\n@@ -1192,1 +1195,1 @@\n-    Q_max = new AddLNode(Q_max, L2);\n+    Q_max = new AddLNode(Q_max, L_2);\n@@ -1211,8 +1214,8 @@\n-    \/\/ R2 = clamp(R, L_clamp, H_clamp) - L_clamp\n-    \/\/ that is: R2 = clamp(R, L_clamp, H_clamp) if Q_min < 0\n-    \/\/ or:      R2 = clamp(R, L_clamp, H_clamp) - Q_min if Q_min > 0\n-    Node* R2 = clamp(R, L_clamp, H_clamp);\n-    R2 = new SubLNode(R2, L_clamp);\n-    register_new_node(R2, entry_control);\n-    R2 = new ConvL2INode(R2, TypeInt::INT);\n-    register_new_node(R2, entry_control);\n+    \/\/ R_2 = clamp(R, L_clamp, H_clamp) - L_clamp\n+    \/\/ that is: R_2 = clamp(R, L_clamp, H_clamp) if Q_min < 0\n+    \/\/ or:      R_2 = clamp(R, L_clamp, H_clamp) - Q_min if Q_min > 0\n+    Node* R_2 = clamp(R, L_clamp, H_clamp);\n+    R_2 = new SubLNode(R_2, L_clamp);\n+    register_new_node(R_2, entry_control);\n+    R_2 = new ConvL2INode(R_2, TypeInt::POS);\n+    register_new_node(R_2, entry_control);\n@@ -1236,1 +1239,1 @@\n-    Node* new_rc_cmp = new CmpUNode(scaled_iv_plus_offset, R2);\n+    Node* new_rc_cmp = new CmpUNode(scaled_iv_plus_offset, R_2);\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":37,"deletions":34,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -0,0 +1,63 @@\n+\/*\n+ * Copyright (c) 2021, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.c2.irTests;\n+\n+import compiler.lib.ir_framework.*;\n+import java.util.Objects;\n+\n+\/*\n+ * @test\n+ * @bug 8259609\n+ * @summary C2: optimize long range checks in long counted loops\n+ * @library \/test\/lib \/\n+ * @run driver compiler.c2.irTests.TestLongRangeChecks\n+ *\/\n+\n+public class TestLongRangeChecks {\n+    public static void main(String[] args) {\n+        TestFramework.run();\n+    }\n+\n+\n+    @Test\n+    @IR(counts = { IRNode.LOOP, \"1\"})\n+    @IR(failOn = { IRNode.COUNTEDLOOP})\n+    public static void testStridePosScalePos(long start, long stop, long length, long offset) {\n+        final long scale = 1;\n+        final long stride = 1;\n+\n+        \/\/ Loop is first transformed into a loop nest, long range\n+        \/\/ check into an int range check, the range check is hoisted\n+        \/\/ and the inner counted loop becomes empty so is optimized\n+        \/\/ out.\n+        for (long i = start; i < stop; i += stride) {\n+            Objects.checkIndex(scale * i + offset, length);\n+        }\n+    }\n+\n+    @Run(test = \"testStridePosScalePos\")\n+    private void testStridePosScalePos_runner() {\n+        testStridePosScalePos(0, 100, 100, 0);\n+    }    \n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/irTests\/TestLongRangeChecks.java","additions":63,"deletions":0,"binary":false,"changes":63,"status":"added"}]}