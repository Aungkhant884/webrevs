{"files":[{"patch":"@@ -142,0 +142,52 @@\n+\/\/ Given a byte size, a desired page size and an allowed overdraft factor, return true if this page size should be used.\n+static bool is_page_size_viable(size_t bytes, size_t pagesize, double allowed_overdraft_factor) {\n+  bool rc = false;\n+  if (pagesize > os::vm_page_size()) {\n+    const size_t allowed_overdraft = (size_t)((double)bytes * allowed_overdraft_factor);\n+    const size_t bytes_page_aligned = align_up(bytes, pagesize);\n+    rc = bytes_page_aligned <= (bytes + allowed_overdraft);\n+  } else {\n+    rc = true; \/\/ allocating system-pagesize-pages is always allowed\n+  }\n+  return rc;\n+}\n+\n+static bool pagesize_is_special(size_t page_size) {\n+  return page_size > os::vm_page_size() && !os::can_commit_large_page_memory();\n+}\n+\n+\/\/ Given a byte size and a desired page size, attempt to allocate a region in that particular\n+\/\/ page size as either special or normal memory, depending on VM LP settings.\n+\/\/ On success, returns region. Region may be larger due to pagesize requirement.\n+\/\/ On error, returns empty region.\n+static SubSpace attempt_reserve_any(size_t bytes, size_t pagesize) {\n+  SubSpace result;\n+  const size_t bytes_page_aligned = align_up(bytes, pagesize);\n+  bool special = false;\n+  char* p = nullptr;\n+  if (UseLargePages && pagesize_is_special(pagesize)) {\n+    p = os::reserve_memory_special(bytes_page_aligned, pagesize, pagesize, nullptr, false);\n+    special = true;\n+  } else {\n+    p = os::reserve_memory_aligned(bytes_page_aligned, pagesize, false);\n+  }\n+  if (p != nullptr) {\n+    assert(is_aligned(p, pagesize), \"Sanity\");\n+    MemTracker::record_virtual_memory_type(p, mtGC);\n+    result = SubSpace(MemRegion((HeapWord*)p, bytes_page_aligned \/ BytesPerWord), special, pagesize);\n+  }\n+  return result;\n+}\n+\n+static SubSpace attempt_reserve_and_log(const char* what, size_t bytes, size_t pagesize) {\n+  size_t actual_size = 0;\n+  SubSpace result = attempt_reserve_any(bytes, pagesize);\n+  if (!result.is_null()) {\n+    os::trace_page_sizes_for_requested_size(what,\n+                                            bytes, pagesize,\n+                                            (const char*) result.start(),\n+                                            result.byte_size(), pagesize);\n+  }\n+  return result;\n+}\n+\n@@ -181,2 +233,0 @@\n-  size_t bitmap_page_size = UseLargePages ? os::large_page_size() : os::vm_page_size();\n-  size_t region_page_size = UseLargePages ? os::large_page_size() : os::vm_page_size();\n@@ -195,0 +245,4 @@\n+  os::trace_page_sizes_for_requested_size(\"Heap\",\n+                                          max_byte_size, heap_alignment,\n+                                          heap_rs.base(),\n+                                          heap_rs.size(), heap_rs.page_size());\n@@ -215,1 +269,1 @@\n-  \/\/ Reserve and commit memory for bitmap(s)\n+  \/\/ Reserve memory for bitmap(s) and region storage\n@@ -218,2 +272,106 @@\n-  _bitmap_size = ShenandoahMarkBitMap::compute_size(heap_rs.size());\n-  _bitmap_size = align_up(_bitmap_size, bitmap_page_size);\n+  const os::PageSizes pagesizes = os::page_sizes();\n+  assert(pagesizes.contains(os::vm_page_size()), \"Must be\");\n+\n+  SubSpace leftover; \/\/ Leftover from bitmap allocation\n+\n+  \/\/ Bitmap size, not page aligned (since we don't know yet what pages we get), aligned to words\n+  \/\/ for compatibility with MemRegion\n+  const size_t bitmap_size = align_up(ShenandoahMarkBitMap::compute_size(heap_rs.size()), BytesPerWord);\n+  SubSpace ss_veri_bitmap;\n+\n+  \/\/ Region storage\n+  const size_t region_align = align_up(sizeof(ShenandoahHeapRegion), SHENANDOAH_CACHE_LINE_SIZE);\n+  const size_t region_storage_size = region_align * _num_regions;\n+  SubSpace ss_region_storage;\n+\n+  const double allowed_overdraft_factor = 0.2f;\n+\n+  for (size_t pagesize = pagesizes.largest();\n+      pagesize != 0;\n+      pagesize = pagesizes.next_smaller(pagesize)) {\n+\n+    \/\/ If pagesize is large and pre-committed, attempt to place both mark- and aux-bitmap into a contiguous\n+    \/\/ range to make best use of possibly very large pages. Since this is pre-committed memory, we don't\n+    \/\/ have to care for alignment. In addition, we try to reuse any leftover space.\n+    const size_t mark_plus_aux_combined = bitmap_size * 2;\n+\n+    if (_bitmap_region.is_null() && _aux_bitmap_region.is_null() &&\n+        pagesize_is_special(pagesize) &&\n+        is_page_size_viable(mark_plus_aux_combined, pagesize, allowed_overdraft_factor))\n+    {\n+      SubSpace ss_combined = attempt_reserve_and_log(\"Mark+Aux Bitmap\", mark_plus_aux_combined, pagesize);\n+      if (!ss_combined.is_null()) {\n+        assert(ss_combined.special(), \"Should have been special\");\n+        ss_combined.split(mark_plus_aux_combined, ss_combined, leftover);  \/\/ save leftovers\n+        ss_combined.split(bitmap_size, _bitmap_region, _aux_bitmap_region);\n+      }\n+    }\n+\n+    \/\/ Reattempt with the same page size, but individual allocations.\n+    if (is_page_size_viable(bitmap_size, pagesize, allowed_overdraft_factor)) {\n+      if (_bitmap_region.is_null()) {\n+        _bitmap_region = attempt_reserve_and_log(\"Mark Bitmap\", bitmap_size, pagesize);\n+        if (_bitmap_region.special()) {\n+          _bitmap_region.split(bitmap_size, _bitmap_region, leftover); \/\/ save leftovers\n+        }\n+      }\n+\n+      if (_aux_bitmap_region.is_null() && is_page_size_viable(bitmap_size, pagesize, allowed_overdraft_factor)) {\n+        _aux_bitmap_region = attempt_reserve_and_log(\"Aux Bitmap\", bitmap_size, pagesize);\n+      }\n+\n+      if (ShenandoahVerify) {\n+        if (ss_veri_bitmap.is_null() && is_page_size_viable(bitmap_size, pagesize, allowed_overdraft_factor)) {\n+          ss_veri_bitmap = attempt_reserve_and_log(\"Veri Bitmap\", bitmap_size, pagesize);\n+        }\n+      }\n+    }\n+\n+    \/\/ Reserve memory for region storage. If possibly, piggy-back on the leftovers from the mark bitmap.\n+    if (ss_region_storage.is_null() && !leftover.is_null() && leftover.special()) {\n+      leftover = leftover.aligned_start(region_align);\n+      leftover.split(region_storage_size, ss_region_storage, leftover);\n+      if (!ss_region_storage.is_null()) {\n+        log_info(pagesize)(\"Region Storage: piggy-backing on Mark Bitmap: base=\" PTR_FORMAT \" size=\" SIZE_FORMAT,\n+                           p2i(ss_region_storage.start()), ss_region_storage.byte_size());\n+      }\n+    }\n+\n+    \/\/ Otherwise, allocate region storage individually\n+    if (ss_region_storage.is_null() && is_page_size_viable(region_storage_size, pagesize, allowed_overdraft_factor)) {\n+      ss_region_storage = attempt_reserve_and_log(\"Region Storage\", region_storage_size, pagesize);\n+    }\n+  }\n+\n+  \/\/ At this point we expect all reservations apart from cset reservations to have succeeded.\n+  if (_bitmap_region.is_null()) {\n+    vm_exit_out_of_memory(bitmap_size, OOM_MMAP_ERROR, \"Mark bitmap\");\n+  } else if (_aux_bitmap_region.is_null()) {\n+    vm_exit_out_of_memory(bitmap_size, OOM_MMAP_ERROR, \"Aux bitmap\");\n+  } else if (ShenandoahVerify && ss_veri_bitmap.is_null()) {\n+    vm_exit_out_of_memory(bitmap_size, OOM_MMAP_ERROR, \"Verification bitmap\");\n+  } else if (ss_region_storage.is_null()) {\n+    vm_exit_out_of_memory(region_storage_size, OOM_MMAP_ERROR, \"Region storage\");\n+  }\n+\n+#ifdef ASSERT\n+  \/\/ Some more verifications\n+  _bitmap_region.verify_not_null();\n+  assert(_bitmap_region.byte_size() >= bitmap_size, \"Sanity\");\n+  _aux_bitmap_region.verify_not_null();\n+  assert(_aux_bitmap_region.byte_size() >= bitmap_size, \"Sanity\");\n+  if (!ShenandoahVerify) {\n+    _bitmap_region.verify_not_null();\n+  }\n+  assert(!ShenandoahVerify || _aux_bitmap_region.byte_size() >= bitmap_size, \"Sanity\");\n+  ss_region_storage.verify_not_null();\n+  assert(ss_region_storage.byte_size() >= region_storage_size, \"Sanity\");\n+#endif\n+\n+  \/\/\n+  \/\/ Commit memory for bitmap(s)\n+  \/\/\n+  \/\/ only if bitmaps had not been placed onto precommitted memory:\n+  \/\/ - We commit the marking bitmap to cover initially committed regions.\n+  \/\/ - We leave the aux bitmap uncommitted. Will be committed on demand using small pages.\n+  \/\/ - We fully commit the verification bitmap (if it exists)\n@@ -228,3 +386,3 @@\n-  if (bitmap_page_size > bitmap_bytes_per_region) {\n-    _bitmap_regions_per_slice = bitmap_page_size \/ bitmap_bytes_per_region;\n-    _bitmap_bytes_per_slice = bitmap_page_size;\n+  if (_bitmap_region.pagesize() > bitmap_bytes_per_region) {\n+    _bitmap_regions_per_slice = _bitmap_region.pagesize() \/ bitmap_bytes_per_region;\n+    _bitmap_bytes_per_slice = _bitmap_region.pagesize();\n@@ -240,8 +398,4 @@\n-  guarantee(((_bitmap_bytes_per_slice) % bitmap_page_size) == 0,\n-            \"Bitmap slices should be page-granular: bps = \" SIZE_FORMAT \", page size = \" SIZE_FORMAT,\n-            _bitmap_bytes_per_slice, bitmap_page_size);\n-\n-  ReservedSpace bitmap(_bitmap_size, bitmap_page_size);\n-  MemTracker::record_virtual_memory_type(bitmap.base(), mtGC);\n-  _bitmap_region = MemRegion((HeapWord*) bitmap.base(), bitmap.size() \/ HeapWordSize);\n-  _bitmap_region_special = bitmap.special();\n+  if (!_bitmap_region.special()) {\n+    guarantee(((_bitmap_bytes_per_slice) % _bitmap_region.pagesize()) == 0,\n+              \"Bitmap slices should be page-granular: bps = \" SIZE_FORMAT \", page size = \" SIZE_FORMAT,\n+              _bitmap_bytes_per_slice, _bitmap_region.pagesize());\n@@ -249,5 +403,4 @@\n-  size_t bitmap_init_commit = _bitmap_bytes_per_slice *\n-                              align_up(num_committed_regions, _bitmap_regions_per_slice) \/ _bitmap_regions_per_slice;\n-  bitmap_init_commit = MIN2(_bitmap_size, bitmap_init_commit);\n-  if (!_bitmap_region_special) {\n-    os::commit_memory_or_exit((char *) _bitmap_region.start(), bitmap_init_commit, bitmap_page_size, false,\n+    size_t bitmap_init_commit = _bitmap_bytes_per_slice *\n+                                align_up(num_committed_regions, _bitmap_regions_per_slice) \/ _bitmap_regions_per_slice;\n+    bitmap_init_commit = align_up(MIN2(bitmap_size, bitmap_init_commit), _bitmap_region.pagesize());\n+    os::commit_memory_or_exit((char *) _bitmap_region.start(), bitmap_init_commit, _bitmap_region.pagesize(), false,\n@@ -257,1 +410,1 @@\n-  _marking_context = new ShenandoahMarkingContext(_heap_region, _bitmap_region, _num_regions, _max_workers);\n+  _marking_context = new ShenandoahMarkingContext(_heap_region, _bitmap_region.mr(), _num_regions, _max_workers);\n@@ -260,3 +413,2 @@\n-    ReservedSpace verify_bitmap(_bitmap_size, bitmap_page_size);\n-    if (!verify_bitmap.special()) {\n-      os::commit_memory_or_exit(verify_bitmap.base(), verify_bitmap.size(), bitmap_page_size, false,\n+    if (!ss_veri_bitmap.special()) {\n+      os::commit_memory_or_exit((char*)ss_veri_bitmap.start(), ss_veri_bitmap.byte_size(), ss_veri_bitmap.pagesize(), false,\n@@ -265,3 +417,1 @@\n-    MemTracker::record_virtual_memory_type(verify_bitmap.base(), mtGC);\n-    MemRegion verify_bitmap_region = MemRegion((HeapWord *) verify_bitmap.base(), verify_bitmap.size() \/ HeapWordSize);\n-    _verification_bit_map.initialize(_heap_region, verify_bitmap_region);\n+    _verification_bit_map.initialize(_heap_region, ss_veri_bitmap.mr());\n@@ -272,5 +422,1 @@\n-  ReservedSpace aux_bitmap(_bitmap_size, bitmap_page_size);\n-  MemTracker::record_virtual_memory_type(aux_bitmap.base(), mtGC);\n-  _aux_bitmap_region = MemRegion((HeapWord*) aux_bitmap.base(), aux_bitmap.size() \/ HeapWordSize);\n-  _aux_bitmap_region_special = aux_bitmap.special();\n-  _aux_bit_map.initialize(_heap_region, _aux_bitmap_region);\n+  _aux_bit_map.initialize(_heap_region, _aux_bitmap_region.mr());\n@@ -281,8 +427,2 @@\n-  size_t region_align = align_up(sizeof(ShenandoahHeapRegion), SHENANDOAH_CACHE_LINE_SIZE);\n-  size_t region_storage_size = align_up(region_align * _num_regions, region_page_size);\n-  region_storage_size = align_up(region_storage_size, os::vm_allocation_granularity());\n-\n-  ReservedSpace region_storage(region_storage_size, region_page_size);\n-  MemTracker::record_virtual_memory_type(region_storage.base(), mtGC);\n-  if (!region_storage.special()) {\n-    os::commit_memory_or_exit(region_storage.base(), region_storage_size, region_page_size, false,\n+  if (!ss_region_storage.special()) {\n+    os::commit_memory_or_exit((char*)ss_region_storage.start(), region_storage_size, ss_region_storage.pagesize(), false,\n@@ -328,1 +468,1 @@\n-      void* loc = region_storage.base() + i * region_align;\n+      void* loc = ((char*)ss_region_storage.start()) + (i * region_align);\n@@ -351,1 +491,1 @@\n-    _pretouch_bitmap_page_size = bitmap_page_size;\n+    _pretouch_bitmap_page_size = _bitmap_region.pagesize();\n@@ -366,1 +506,1 @@\n-    ShenandoahPretouchBitmapTask bcl(bitmap.base(), _bitmap_size, _pretouch_bitmap_page_size);\n+    ShenandoahPretouchBitmapTask bcl((char*)_bitmap_region.start(), bitmap_size, _pretouch_bitmap_page_size);\n@@ -487,1 +627,0 @@\n-  _bitmap_size(0),\n@@ -490,2 +629,0 @@\n-  _bitmap_region_special(false),\n-  _aux_bitmap_region_special(false),\n@@ -1310,1 +1447,3 @@\n-  if (!_aux_bitmap_region_special && !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {\n+  \/\/ Note: we disregard the pagesize hint here since this bitmap will get uncommitted again, therefore THP coalescation\n+  \/\/ would be wasted work.\n+  if (!_aux_bitmap_region.special() && !os::commit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size(), false)) {\n@@ -1330,1 +1469,1 @@\n-  if (!_aux_bitmap_region_special && !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {\n+  if (!_aux_bitmap_region.special() && !os::uncommit_memory((char*)_aux_bitmap_region.start(), _aux_bitmap_region.byte_size())) {\n@@ -2145,1 +2284,1 @@\n-  if (_bitmap_region_special) {\n+  if (_bitmap_region.special()) {\n@@ -2176,1 +2315,1 @@\n-  if (_bitmap_region_special) {\n+  if (_bitmap_region.special()) {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":190,"deletions":51,"binary":false,"changes":241,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/shenandoah\/shenandoahReservedSubSpace.hpp\"\n@@ -550,2 +551,2 @@\n-  MemRegion  _bitmap_region;\n-  MemRegion  _aux_bitmap_region;\n+  SubSpace   _bitmap_region;\n+  SubSpace   _aux_bitmap_region;\n@@ -555,1 +556,0 @@\n-  size_t _bitmap_size;\n@@ -562,3 +562,0 @@\n-  bool _bitmap_region_special;\n-  bool _aux_bitmap_region_special;\n-\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -552,2 +552,4 @@\n-  \/\/ heap size is large enough to accommodate minimal number of regions. Otherwise, we align\n-  \/\/ region size to regular page size.\n+  \/\/ heap size is large enough to accommodate minimal number of regions. Otherwise, multiple\n+  \/\/ regions may share one large page. This is allowed, but prevents us from uncommitting\n+  \/\/ individual regions. Typically, this does not matter, since on most OSes large pages are\n+  \/\/ \"special\": hotspot pre-commits them, and they cannot be uncommitted.\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeapRegion.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,84 @@\n+\/*\n+ * Copyright (c) 2023, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/shenandoah\/shenandoahReservedSubSpace.hpp\"\n+\n+#include \"runtime\/os.hpp\"\n+#include \"utilities\/align.hpp\"\n+\n+\n+void SubSpace::split(size_t bytes, SubSpace& left, SubSpace& right) const {\n+  assert(is_aligned(bytes, BytesPerWord), \"Sanity\");\n+  size_t words = bytes \/ BytesPerWord;\n+  if (is_null()) {\n+    left = right = SubSpace();\n+  } else {\n+    SubSpace tmp = *this;\n+    clamp(words, (size_t)0, word_size());\n+    if (bytes == 0) {\n+      left = SubSpace();\n+      right = tmp;\n+    } else if (bytes == byte_size()) {\n+      left = tmp;\n+      right = SubSpace();\n+    } else {\n+      left = SubSpace(MemRegion(start(), words), _special, _pagesize);\n+      right = SubSpace(MemRegion(start() + words, word_size() - words), _special, _pagesize);\n+    }\n+  }\n+}\n+\n+SubSpace SubSpace::first_part(size_t bytes) const {\n+  SubSpace right, left;\n+  split(bytes, right, left);\n+  return right;\n+}\n+\n+SubSpace SubSpace::aligned_start(size_t alignment) const {\n+  SubSpace ss;\n+  if (!is_null()) {\n+    char* p = align_up((char*)start(), alignment);\n+    if (p > (char*)end()) {\n+      return SubSpace();\n+    }\n+    SubSpace dummy;\n+    split(p - (char*)start(), dummy, ss);\n+  }\n+  return ss;\n+}\n+\n+#ifdef ASSERT\n+void SubSpace::verify() const {\n+  if (!is_null()) {\n+    assert(pagesize() > 0, \"unknown pagesize\");\n+    assert(special() || is_aligned(start(), pagesize()), \"must be special or page-aligned\");\n+  }\n+}\n+void SubSpace::verify_not_null() const {\n+  assert(!is_empty() && !is_null(), \"Empty\");\n+  verify();\n+}\n+#endif\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReservedSubSpace.cpp","additions":84,"deletions":0,"binary":false,"changes":84,"status":"added"},{"patch":"@@ -0,0 +1,77 @@\n+\/*\n+ * Copyright (c) 2023, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHRESERVEDSUBSPACE_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHRESERVEDSUBSPACE_HPP\n+\n+#include \"memory\/memRegion.hpp\"\n+#include \"utilities\/debug.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+\/\/ Memory region that may or may not be its own page-aligned reserved space.\n+\/\/ If \"special\", it may share a page with adjacent data and will be pre-committed.\n+\/\/ If not \"special\", it is page-aligned and committable.\n+class SubSpace : private MemRegion {\n+\n+  bool _special;\n+  size_t _pagesize;\n+\n+public:\n+\n+  SubSpace() : MemRegion(), _special(false), _pagesize(0) {}\n+  \/\/SubSpace(const SubSpace& other) : MemRegion(other), _special(other._special), _pagesize(other._pagesize) {}\n+  SubSpace(MemRegion mr, bool special, size_t pagesize) :\n+    MemRegion(mr), _special(special), _pagesize(pagesize) {}\n+\n+  using MemRegion::is_empty;\n+  using MemRegion::byte_size;\n+  using MemRegion::word_size;\n+  using MemRegion::start;\n+  using MemRegion::end;\n+\n+  bool is_null() const      { return start() == nullptr; }\n+  bool special() const      { return _special; }\n+  size_t pagesize() const   { return _pagesize; }\n+\n+  MemRegion mr() const  { return (MemRegion) (*this); }\n+\n+  \/\/ Split region such that first_part=[orig.start, x), last_part=[x, orig.end).\n+  \/\/ Splitting an empty regions results in two null regions.\n+  \/\/ If x is end, last_part will be null. If x is 0, first part will be null.\n+  void split(size_t byte_size, SubSpace& left, SubSpace& right) const;\n+\n+  \/\/ Returns a region whose start address is aligned up to alignment. If region\n+  \/\/ is too small (or null), returns null region.\n+  SubSpace aligned_start(size_t alignment) const;\n+\n+  SubSpace first_part(size_t byte_size) const;\n+\n+#ifdef ASSERT\n+  void verify() const;\n+  void verify_not_null() const;\n+#endif\n+};\n+\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHRESERVEDSUBSPACE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahReservedSubSpace.hpp","additions":77,"deletions":0,"binary":false,"changes":77,"status":"added"}]}