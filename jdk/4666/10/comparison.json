{"files":[{"patch":"@@ -62,1 +62,1 @@\n-                            writeHeapRecordPrologue();\n+                            writeHeapRecordPrologue(calculateOopDumpRecordSize(oop));\n@@ -130,0 +130,2 @@\n+    abstract protected int calculateOopDumpRecordSize(Oop oop) throws IOException;\n+\n@@ -423,0 +425,3 @@\n+    protected void writeHeapRecordPrologue(int size) throws IOException {\n+    }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/utilities\/AbstractHeapGraphWriter.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -278,0 +278,5 @@\n+    @Override\n+    protected int calculateOopDumpRecordSize(Oop oop) throws IOException {\n+        return 0;\n+    }\n+\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/utilities\/HeapGXLWriter.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -412,2 +412,1 @@\n-        hprofBufferedOut = null;\n-        OutputStream dataOut = fos;\n+        hprofBufferedOut = fos;\n@@ -416,1 +415,1 @@\n-                dataOut = new GZIPOutputStream(fos) {\n+                hprofBufferedOut = new GZIPOutputStream(fos) {\n@@ -422,3 +421,0 @@\n-            hprofBufferedOut = new SegmentedOutputStream(dataOut);\n-        } else {\n-            hprofBufferedOut = new SegmentedOutputStream(fos, false \/* allowSegmented *\/);\n@@ -475,1 +471,0 @@\n-\n@@ -477,1 +472,0 @@\n-            \/\/ Fill in final length.\n@@ -480,1 +474,0 @@\n-            hprofBufferedOut.finish();\n@@ -486,1 +479,0 @@\n-\n@@ -492,0 +484,1 @@\n+        currentSegmentStart = 0;\n@@ -494,8 +487,26 @@\n-    @Override\n-    protected void writeHeapRecordPrologue() throws IOException {\n-        if (useSegmentedHeapDump) {\n-            hprofBufferedOut.enterSegmentMode();\n-        } else if (currentSegmentStart == 0) {\n-            \/\/ write heap data header\n-            out.writeByte((byte) (HPROF_HEAP_DUMP));\n-            out.writeInt(0);\n+    protected int calculateOopDumpRecordSize(Oop oop) throws IOException {\n+        if (oop instanceof TypeArray taOop) {\n+            return calculatePrimitiveArrayDumpRecordSize(taOop);\n+        } else if (oop instanceof ObjArray oaOop) {\n+            Klass klass = oop.getKlass();\n+            ObjArrayKlass oak = (ObjArrayKlass) klass;\n+            Klass bottomType = oak.getBottomKlass();\n+            if (bottomType instanceof InstanceKlass ||\n+                bottomType instanceof TypeArrayKlass) {\n+                return calculateObjectArrayDumpRecordSize(oaOop);\n+            } else {\n+                \/\/ Internal object, nothing to write.\n+                return 0;\n+            }\n+        } else if (oop instanceof Instance instance) {\n+            Klass klass = instance.getKlass();\n+            Symbol name = klass.getName();\n+            if (name.equals(javaLangClass)) {\n+                return calculateClassInstanceDumpRecordSize(instance);\n+            }\n+            return calculateInstanceDumpRecordSize(instance);\n+        } else {\n+            \/\/ not-a-Java-visible oop\n+            return 0;\n+        }\n+    }\n@@ -503,6 +514,55 @@\n-            \/\/ remember position of dump length, we will fixup\n-            \/\/ length later - hprof format requires length.\n-            out.flush();\n-            currentSegmentStart = fos.getChannel().position();\n-            \/\/ write dummy length of 0 and we'll fix it later.\n-            out.writeInt(0);\n+    private int calculateInstanceDumpRecordSize(Instance instance) {\n+        Klass klass = instance.getKlass();\n+        if (klass.getClassLoaderData() == null) {\n+            \/\/ Ignoring this object since the corresponding Klass is not loaded.\n+            \/\/ Might be a dormant archive object.\n+            return 0;\n+        }\n+\n+        ClassData cd = (ClassData) classDataCache.get(klass);\n+        if (Assert.ASSERTS_ENABLED) {\n+            Assert.that(cd != null, \"can not get class data for \" + klass.getName().asString() + klass.getAddress());\n+        }\n+        List<Field> fields = cd.fields;\n+        return (int) BYTE_SIZE + (int)OBJ_ID_SIZE * 2 + (int)INT_SIZE * 2 + getSizeForFields(fields);\n+    }\n+\n+    private int calculateClassDumpRecordSize(Klass k) {\n+        \/\/ tag + javaMirror + DUMMY_STACK_TRACE_ID + super\n+        int size = (int)BYTE_SIZE + (int)INT_SIZE + (int)OBJ_ID_SIZE * 2;\n+        if (k instanceof InstanceKlass ik) {\n+            List<Field> fields = getInstanceFields(ik);\n+            List<Field> declaredFields = ik.getImmediateFields();\n+            List<Field> staticFields = new ArrayList<>();\n+            List<Field> instanceFields = new ArrayList<>();\n+            Iterator<Field> itr = null;\n+            \/\/ loader + signer + protectionDomain + 2 reserved + fieldSize + cpool entris number\n+            size += OBJ_ID_SIZE * 5 + INT_SIZE + SHORT_SIZE;\n+            for (itr = declaredFields.iterator(); itr.hasNext();) {\n+                Field field = itr.next();\n+                if (field.isStatic()) {\n+                    staticFields.add(field);\n+                } else {\n+                    instanceFields.add(field);\n+                }\n+            }\n+            \/\/ size of static field descriptors\n+            size += calculateFieldDescriptorsDumpRecordSize(staticFields, ik);\n+            \/\/ size of instance field descriptors\n+            size += calculateFieldDescriptorsDumpRecordSize(instanceFields, null);\n+        } else {\n+            size += OBJ_ID_SIZE * 5  + INT_SIZE + SHORT_SIZE * 3;\n+        }\n+        return size;\n+    }\n+\n+    private int calculateFieldDescriptorsDumpRecordSize(List<Field> fields, InstanceKlass ik) {\n+        int size = 0;\n+        size += SHORT_SIZE;\n+        for (Field field : fields) {\n+            size += OBJ_ID_SIZE + BYTE_SIZE;\n+            \/\/ ik == null for instance fields\n+            if (ik != null) {\n+                \/\/ static field\n+                size += getSizeForField(field);\n+            }\n@@ -510,0 +570,33 @@\n+        return size;\n+    }\n+\n+    private int calculateClassInstanceDumpRecordSize(Instance instance) {\n+        Klass reflectedKlass = java_lang_Class.asKlass(instance);\n+        \/\/ Dump instance record only for primitive type Class objects.\n+        \/\/ All other Class objects are covered by writeClassDumpRecords.\n+        if (reflectedKlass == null) {\n+            return calculateInstanceDumpRecordSize(instance);\n+        }\n+        return 0;\n+    }\n+\n+    private int calculateObjectArrayDumpRecordSize(ObjArray array) {\n+        int headerSize = getArrayHeaderSize(true);\n+        final int length = calculateArrayMaxLength(array.getLength(),\n+                headerSize,\n+                OBJ_ID_SIZE,\n+                \"Object\");\n+        return headerSize + length * OBJ_ID_SIZE;\n+    }\n+\n+    private int calculatePrimitiveArrayDumpRecordSize(TypeArray array) throws IOException {\n+        int headerSize = getArrayHeaderSize(false);\n+        TypeArrayKlass tak = (TypeArrayKlass) array.getKlass();\n+        final int type = (int) tak.getElementType();\n+        final String typeName = tak.getElementTypeName();\n+        final long typeSize = getSizeForType(type);\n+        final int length = calculateArrayMaxLength(array.getLength(),\n+                                                   headerSize,\n+                                                   typeSize,\n+                                                   typeName);\n+        return headerSize + (int)typeSize * length;\n@@ -513,1 +606,5 @@\n-    protected void writeHeapRecordEpilogue() throws IOException {\n+    protected void writeHeapRecordPrologue(int size) throws IOException {\n+        if (size == 0 || currentSegmentStart > 0) {\n+            return;\n+        }\n+        \/\/ write heap data header\n@@ -515,1 +612,10 @@\n-            hprofBufferedOut.exitSegmentMode();\n+            out.writeByte((byte)HPROF_HEAP_DUMP_SEGMENT);\n+            out.writeInt(0);\n+            out.writeInt(size);\n+        } else {\n+            out.writeByte((byte)HPROF_HEAP_DUMP);\n+            out.writeInt(0);\n+            \/\/ record the current position in file, it will be use for calculating the size of written data\n+            currentSegmentStart = fos.getChannel().position();\n+            \/\/ write dummy zero for length\n+            out.writeInt(0);\n@@ -579,1 +685,2 @@\n-    \/\/ Check if we need to truncate an array\n+    \/\/ Check if we need to truncate an array.\n+    \/\/ The limitation is that the size of \"heap dump\" or \"heap dump segment\" must be <= MAX_U4_VALUE.\n@@ -583,1 +690,1 @@\n-                                        String typeName) throws IOException {\n+                                        String typeName) {\n@@ -586,0 +693,1 @@\n+\n@@ -587,1 +695,0 @@\n-        long currentRecordLength = 0;\n@@ -589,15 +696,0 @@\n-        \/\/ There is an U4 slot that contains the data size written in the dump file.\n-        \/\/ Need to truncate the array length if the size exceeds the MAX_U4_VALUE.\n-        if (!useSegmentedHeapDump) {\n-            \/\/ now get the current position to calculate length\n-            long dumpEnd = fos.getChannel().position();\n-            \/\/ calculate the length of heap data\n-            currentRecordLength = (dumpEnd - currentSegmentStart - 4L);\n-            if (currentRecordLength > 0 &&\n-                (currentRecordLength + headerSize + originalLengthInBytes) > MAX_U4_VALUE) {\n-                fillInHeapRecordLength();\n-                currentSegmentStart = 0;\n-                writeHeapRecordPrologue();\n-                currentRecordLength = 0;\n-            }\n-        }\n@@ -605,1 +697,1 @@\n-        long maxBytes = (MAX_U4_VALUE - (headerSize + currentRecordLength));\n+        long maxBytes = MAX_U4_VALUE - headerSize;\n@@ -613,8 +705,0 @@\n-\n-        \/\/ Now the total size of data to dump is known and can be filled to segment header.\n-        \/\/ Disable buffer mode to avoid memory consumption and internal buffer copies.\n-        if (useSegmentedHeapDump) {\n-            int size = (int) (length * typeSize + headerSize);\n-            hprofBufferedOut.fillSegmentSizeAndDisableBufferMode(size);\n-        }\n-\n@@ -630,1 +714,1 @@\n-                                    writeHeapRecordPrologue();\n+                                    writeHeapRecordPrologue(calculateClassDumpRecordSize(k));\n@@ -799,0 +883,2 @@\n+        int size = (int)BYTE_SIZE + (int)OBJ_ID_SIZE + (int)INT_SIZE * 2;\n+        writeHeapRecordPrologue(size);\n@@ -819,0 +905,2 @@\n+                                           int size = (int)BYTE_SIZE + (int)OBJ_ID_SIZE + (int)INT_SIZE * 2;\n+                                           writeHeapRecordPrologue(size);\n@@ -845,0 +933,2 @@\n+            int size = (int)BYTE_SIZE + (int)OBJ_ID_SIZE * 2;\n+            writeHeapRecordPrologue(size);\n@@ -1224,0 +1314,24 @@\n+    \/\/ get size in bytes (in stream) required for given field.\n+    private int getSizeForField(Field field) {\n+        char typeCode = (char)field.getSignature().getByteAt(0);\n+        switch (typeCode) {\n+        case JVM_SIGNATURE_BOOLEAN:\n+        case JVM_SIGNATURE_BYTE:\n+            return 1;\n+        case JVM_SIGNATURE_CHAR:\n+        case JVM_SIGNATURE_SHORT:\n+            return 2;\n+        case JVM_SIGNATURE_INT:\n+        case JVM_SIGNATURE_FLOAT:\n+            return 4;\n+        case JVM_SIGNATURE_CLASS:\n+        case JVM_SIGNATURE_ARRAY:\n+            return OBJ_ID_SIZE;\n+        case JVM_SIGNATURE_LONG:\n+        case JVM_SIGNATURE_DOUBLE:\n+            return 8;\n+        default:\n+            throw new RuntimeException(\"should not reach here\");\n+        }\n+    }\n+\n@@ -1229,27 +1343,2 @@\n-        for (Iterator<Field> itr = fields.iterator(); itr.hasNext();) {\n-            Field field = itr.next();\n-            char typeCode = (char) field.getSignature().getByteAt(0);\n-            switch (typeCode) {\n-            case JVM_SIGNATURE_BOOLEAN:\n-            case JVM_SIGNATURE_BYTE:\n-                size++;\n-                break;\n-            case JVM_SIGNATURE_CHAR:\n-            case JVM_SIGNATURE_SHORT:\n-                size += 2;\n-                break;\n-            case JVM_SIGNATURE_INT:\n-            case JVM_SIGNATURE_FLOAT:\n-                size += 4;\n-                break;\n-            case JVM_SIGNATURE_CLASS:\n-            case JVM_SIGNATURE_ARRAY:\n-                size += OBJ_ID_SIZE;\n-                break;\n-            case JVM_SIGNATURE_LONG:\n-            case JVM_SIGNATURE_DOUBLE:\n-                size += 8;\n-                break;\n-            default:\n-                throw new RuntimeException(\"should not reach here\");\n-            }\n+        for (Field field : fields) {\n+            size += getSizeForField(field);\n@@ -1279,1 +1368,1 @@\n-    private SegmentedOutputStream hprofBufferedOut;\n+    private OutputStream hprofBufferedOut;\n@@ -1322,261 +1411,0 @@\n-\n-    \/**\n-     * The class implements a buffered output stream for segmented data dump.\n-     * It is used inside HeapHprofBinWritter only for heap dump.\n-     * Because the current implementation of segmented heap dump needs to update\n-     * the segment size at segment header, and because it is hard to modify the\n-     * compressed data after they are written to file, this class first saves the\n-     * uncompressed data into an internal buffer, and then writes through to the\n-     * GZIPOutputStream when the whole segmented data are ready and the size is updated.\n-     * If the data to be written are larger than internal buffer, or the internal buffer\n-     * is full, the internal buffer will be extend to a larger one.\n-     * This class defines a switch to turn on\/off the segmented mode. If turned off,\n-     * it behaves the same as BufferedOutputStream.\n-     * *\/\n-    private class SegmentedOutputStream extends BufferedOutputStream {\n-        \/**\n-         * Creates a new buffered output stream to support segmented heap dump data.\n-         *\n-         * @param   out                 the underlying output stream.\n-         * @param   allowSegmented      whether allow segmental dump.\n-         *\/\n-        public SegmentedOutputStream(OutputStream out, boolean allowSegmented) {\n-            super(out, 8192);\n-            segmentMode = false;\n-            bufferMode = true;\n-            this.allowSegmented = allowSegmented;\n-            segmentBuffer = new byte[SEGMENT_BUFFER_SIZE];\n-            segmentWritten = 0;\n-        }\n-\n-        \/**\n-         * Creates a new buffered output stream to support segmented heap dump data.\n-         *\n-         * @param   out      the underlying output stream.\n-         *\/\n-        public SegmentedOutputStream(OutputStream out) {\n-            this(out, true);\n-        }\n-\n-        \/**\n-         * Writes the specified byte to this buffered output stream.\n-         *\n-         * @param      b   the byte to be written.\n-         * @throws     IOException  if an I\/O error occurs.\n-         *\/\n-        @Override\n-        public synchronized void write(int b) throws IOException {\n-           if (segmentMode && bufferMode) {\n-               if (segmentWritten == 0) {\n-                   \/\/ At the begining of the segment.\n-                   writeSegmentHeader();\n-               } else if (segmentWritten == segmentBuffer.length) {\n-                   \/\/ Internal buffer is full, extend a larger one.\n-                   int newSize = segmentBuffer.length + SEGMENT_BUFFER_INC_SIZE;\n-                   byte newBuf[] = new byte[newSize];\n-                   System.arraycopy(segmentBuffer, 0, newBuf, 0, segmentWritten);\n-                   segmentBuffer = newBuf;\n-               }\n-               segmentBuffer[segmentWritten++] = (byte)b;\n-               return;\n-           }\n-           super.write(b);\n-        }\n-\n-        \/**\n-         * Writes {@code len} bytes from the specified byte array\n-         * starting at offset {@code off} to this output stream.\n-         *\n-         * @param      b     the data.\n-         * @param      off   the start offset in the data.\n-         * @param      len   the number of bytes to write.\n-         * @throws     IOException  if an I\/O error occurs.\n-         *\/\n-        @Override\n-        public synchronized void write(byte b[], int off, int len) throws IOException {\n-            if (segmentMode && bufferMode) {\n-                if (segmentWritten == 0) {\n-                    writeSegmentHeader();\n-                }\n-                \/\/ Data size is larger than segment buffer length, extend segment buffer.\n-                if (segmentWritten + len > segmentBuffer.length) {\n-                    int newSize = segmentBuffer.length + Math.max(SEGMENT_BUFFER_INC_SIZE, len);\n-                    byte newBuf[] = new byte[newSize];\n-                    System.arraycopy(segmentBuffer, 0, newBuf, 0, segmentWritten);\n-                    segmentBuffer = newBuf;\n-                }\n-                System.arraycopy(b, off, segmentBuffer, segmentWritten, len);\n-                segmentWritten += len;\n-                return;\n-            }\n-            super.write(b, off, len);\n-        }\n-\n-        \/**\n-         * Flushes this buffered output stream. This forces any buffered\n-         * output bytes to be written out to the underlying output stream.\n-         *\n-         * @throws     IOException  if an I\/O error occurs.\n-         * @see        java.io.FilterOutputStream#out\n-         *\/\n-        @Override\n-        public synchronized void flush() throws IOException {\n-            if (segmentMode && bufferMode) {\n-                \/\/ The case that nothing has been written in segment.\n-                if (segmentWritten == 0) return;\n-                \/\/ There must be more data than just header size written for non-empty segment.\n-                assert segmentWritten > SEGMENT_HEADER_SIZE\n-                        : \"invalid header in segmented mode\";\n-\n-                if (segmentWritten > (segmentBuffer.length)) {\n-                    throw new RuntimeException(\"Heap segment size overflow.\");\n-                }\n-\n-                if (segmentWritten > SEGMENT_HEADER_SIZE) {\n-                    fillSegmentSize(segmentWritten - SEGMENT_HEADER_SIZE);\n-                    super.write(segmentBuffer, 0, segmentWritten);\n-                    super.flush();\n-                    segmentWritten = 0;\n-                }\n-                return;\n-            }\n-            super.flush();\n-        }\n-\n-        \/**\n-         * Enters segmented mode, flush buffered data and set flag.\n-         *\/\n-        public void enterSegmentMode() throws IOException {\n-            if (allowSegmented && !segmentMode && segmentWritten == 0) {\n-                super.flush();\n-                segmentMode = true;\n-                segmentWritten = 0;\n-            }\n-        }\n-\n-        \/**\n-         * Before finish, flush all data in buffer.\n-         *\/\n-        public void finish() throws IOException {\n-            if (allowSegmented && segmentMode) {\n-                flush();\n-                assert segmentWritten == 0;\n-                segmentMode = false;\n-                bufferMode = true;\n-            }\n-        }\n-\n-        \/**\n-         * Exits segmented mode, flush segmented data.\n-         * @param    force    flush data regardless whether the buffer is full\n-         *\/\n-        public void exitSegmentMode() throws IOException {\n-            if (!bufferMode) {\n-                \/\/ no data in internal buffer.\n-                assert segmentWritten == 0;\n-                bufferMode = true;\n-            }\n-            if (allowSegmented && segmentMode && shouldFlush()) {\n-                flush();\n-                assert segmentWritten == 0;\n-                segmentMode = false;\n-            }\n-        }\n-\n-        \/**\n-         * Fill segment size and disable bufferMode\n-         * @param    size    size of data to be written\n-         *\/\n-        public void fillSegmentSizeAndDisableBufferMode(int size) throws IOException {\n-            assert segmentMode == true;\n-            assert bufferMode == true;\n-            if (segmentWritten != 0) {\n-                \/\/ flush previous written data and clear the internal buffer.\n-                flush();\n-            }\n-            \/\/ disable buffer mode to write data through to underlying file.\n-            bufferMode = false;\n-            writeSegmentHeader(size);\n-        }\n-\n-        \/**\n-         * Check whether the data should be flush based on data saved in\n-         * segmentBuffer.\n-         * This method is used to control the segments number and the memory usage.\n-         * If segment is too small, there will be lots segments in final dump file.\n-         * If it is too large, lots of memory is used in RAM.\n-         *\/\n-        private boolean shouldFlush() {\n-            \/\/ flushes data if not in bufferMode.\n-            if (!bufferMode) return true;\n-            \/\/ return true if data in segmentBuffer has been extended.\n-            return segmentWritten > SEGMENT_BUFFER_SIZE;\n-        }\n-\n-        \/**\n-         * Writes the segment header with given data size.\n-         *\/\n-        private void writeSegmentHeader(int size) throws IOException {\n-            assert segmentWritten == 0 : \"initializing non empty segment\";\n-            byte flag = (byte)HPROF_HEAP_DUMP_SEGMENT;\n-            if (!bufferMode) {\n-                super.write(flag);\n-            } else {\n-                segmentBuffer[segmentWritten++] = flag;\n-            }\n-            \/\/ write the timestamp (dummy value 0).\n-            writeInteger(0);\n-            \/\/ write the segment data size.\n-            writeInteger(size);\n-        }\n-\n-        \/**\n-         * Writes the segment header with dummy length of 0.\n-         *\/\n-        private void writeSegmentHeader() throws IOException {\n-            writeSegmentHeader(0);\n-        }\n-\n-        \/**\n-         * Fills the segmented data size into the header.\n-         *\/\n-        private void fillSegmentSize(int size) {\n-            assert bufferMode == true;\n-            byte[] lenBytes = genByteArrayFromInt(size);\n-            System.arraycopy(lenBytes, 0, segmentBuffer, 5, 4);\n-        }\n-\n-        \/**\n-         * Writes an {@code int} to the internal segment buffer\n-         * {@code written} is incremented by {@code 4}.\n-         *\/\n-        private final void writeInteger(int value) throws IOException {\n-            byte[] intBytes = genByteArrayFromInt(value);\n-            if (bufferMode) {\n-                System.arraycopy(intBytes, 0, segmentBuffer, segmentWritten, 4);\n-                segmentWritten += 4;\n-            } else {\n-                super.write(intBytes, 0, 4);\n-            }\n-        }\n-\n-        \/\/ The buffer size for segmentBuffer.\n-        \/\/ Since it is hard to calculate and fill the data size of an segment in compressed\n-        \/\/ data, making the segmented data stored in this buffer could help rewrite the data\n-        \/\/ size before the segmented data are written to underlying GZIPOutputStream.\n-        private static final int SEGMENT_BUFFER_SIZE = 1 << 20;\n-        \/\/ Buffer size used to extend the segment buffer.\n-        private static final int SEGMENT_BUFFER_INC_SIZE = 1 << 10;\n-        \/\/ Headers:\n-        \/\/    1 byte for HPROF_HEAP_DUMP_SEGMENT\n-        \/\/    4 bytes for timestamp\n-        \/\/    4 bytes for size\n-        private static final int SEGMENT_HEADER_SIZE = 9;\n-        \/\/ Segment support.\n-        private boolean segmentMode;\n-        private boolean allowSegmented;\n-        \/\/ Write data directly to underlying stream. Don't use internal buffer.\n-        private boolean bufferMode;\n-        private byte segmentBuffer[];\n-        private int segmentWritten;\n-    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/utilities\/HeapHprofBinWriter.java","additions":171,"deletions":343,"binary":false,"changes":514,"status":"modified"}]}