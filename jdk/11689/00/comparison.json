{"files":[{"patch":"@@ -1731,0 +1731,8 @@\n+\n+  bool clone_cmp_down(Node* n, const Node* blk1, const Node* blk2);\n+\n+  void process_load_klass_helper(const Node* n, Node* cmp, int i);\n+\n+  bool process_cmp_loadklass(Node* n, const Node* blk1, const Node* blk2);\n+\n+  bool at_relevant_ctrl(Node* n, const Node* blk1, const Node* blk2);\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -25,0 +25,2 @@\n+#include \"opto\/addnode.hpp\"\n+#include \"opto\/node.hpp\"\n@@ -72,1 +74,1 @@\n-  if( get_ctrl(n) != blk1 && get_ctrl(n) != blk2 )\n+  if (!at_relevant_ctrl(n, blk1,blk2))\n@@ -86,0 +88,4 @@\n+  if (process_cmp_loadklass(n, blk1, blk2)) {\n+    return true;\n+  }\n+\n@@ -88,0 +94,219 @@\n+  if (clone_cmp_down(n, blk1, blk2)) {\n+    return true;\n+  }\n+\n+  if (subgraph_has_opaque(n)) {\n+    Unique_Node_List wq;\n+    wq.push(n);\n+    for (uint i = 0; i < wq.size(); i++) {\n+      Node* m = wq.at(i);\n+      if (m->is_If()) {\n+        assert(skeleton_predicate_has_opaque(m->as_If()), \"opaque node not reachable from if?\");\n+        Node* bol = clone_skeleton_predicate_bool(m, NULL, NULL, m->in(0));\n+        _igvn.replace_input_of(m, 1, bol);\n+      } else {\n+        assert(!m->is_CFG(), \"not CFG expected\");\n+        for (DUIterator_Fast jmax, j = m->fast_outs(jmax); j < jmax; j++) {\n+          Node* u = m->fast_out(j);\n+          wq.push(u);\n+        }\n+      }\n+    }\n+  }\n+\n+  if (n->Opcode() == Op_OpaqueZeroTripGuard) {\n+    \/\/ If this Opaque1 is part of the zero trip guard for a loop:\n+    \/\/ 1- it can't be shared\n+    \/\/ 2- the zero trip guard can't be the if that's being split\n+    \/\/ As a consequence, this node could be assigned control anywhere between its current control and the zero trip guard.\n+    \/\/ Move it down to get it out of the way of split if and avoid breaking the zero trip guard shape.\n+    Node* cmp = n->unique_out();\n+    assert(cmp->Opcode() == Op_CmpI, \"bad zero trip guard shape\");\n+    Node* bol = cmp->unique_out();\n+    assert(bol->Opcode() == Op_Bool, \"bad zero trip guard shape\");\n+    Node* iff = bol->unique_out();\n+    assert(iff->Opcode() == Op_If, \"bad zero trip guard shape\");\n+    set_ctrl(n, iff->in(0));\n+    set_ctrl(cmp, iff->in(0));\n+    set_ctrl(bol, iff->in(0));\n+    return true;\n+  }\n+\n+  \/\/ See if splitting-up a Store.  Any anti-dep loads must go up as\n+  \/\/ well.  An anti-dep load might be in the wrong block, because in\n+  \/\/ this particular layout\/schedule we ignored anti-deps and allow\n+  \/\/ memory to be alive twice.  This only works if we do the same\n+  \/\/ operations on anti-dep loads as we do their killing stores.\n+  if( n->is_Store() && n->in(MemNode::Memory)->in(0) == n->in(0) ) {\n+    \/\/ Get store's memory slice\n+    int alias_idx = C->get_alias_index(_igvn.type(n->in(MemNode::Address))->is_ptr());\n+\n+    \/\/ Get memory-phi anti-dep loads will be using\n+    Node *memphi = n->in(MemNode::Memory);\n+    assert( memphi->is_Phi(), \"\" );\n+    \/\/ Hoist any anti-dep load to the splitting block;\n+    \/\/ it will then \"split-up\".\n+    for (DUIterator_Fast imax,i = memphi->fast_outs(imax); i < imax; i++) {\n+      Node *load = memphi->fast_out(i);\n+      if( load->is_Load() && alias_idx == C->get_alias_index(_igvn.type(load->in(MemNode::Address))->is_ptr()) )\n+        set_ctrl(load,blk1);\n+    }\n+  }\n+\n+  \/\/ Found some other Node; must clone it up\n+#ifndef PRODUCT\n+  if( PrintOpto && VerifyLoopOptimizations ) {\n+    tty->print(\"Cloning up: \");\n+    n->dump();\n+  }\n+#endif\n+\n+  \/\/ ConvI2L may have type information on it which becomes invalid if\n+  \/\/ it moves up in the graph so change any clones so widen the type\n+  \/\/ to TypeLong::INT when pushing it up.\n+  const Type* rtype = NULL;\n+  if (n->Opcode() == Op_ConvI2L && n->bottom_type() != TypeLong::INT) {\n+    rtype = TypeLong::INT;\n+  }\n+\n+  \/\/ Now actually split-up this guy.  One copy per control path merging.\n+  Node *phi = PhiNode::make_blank(blk1, n);\n+  for( uint j = 1; j < blk1->req(); j++ ) {\n+    Node *x = n->clone();\n+    \/\/ Widen the type of the ConvI2L when pushing up.\n+    if (rtype != NULL) x->as_Type()->set_type(rtype);\n+    if( n->in(0) && n->in(0) == blk1 )\n+      x->set_req( 0, blk1->in(j) );\n+    for( uint i = 1; i < n->req(); i++ ) {\n+      Node *m = n->in(i);\n+      if( get_ctrl(m) == blk1 ) {\n+        assert( m->in(0) == blk1, \"\" );\n+        x->set_req( i, m->in(j) );\n+      }\n+    }\n+    register_new_node( x, blk1->in(j) );\n+    phi->init_req( j, x );\n+  }\n+  \/\/ Announce phi to optimizer\n+  register_new_node(phi, blk1);\n+\n+  \/\/ Remove cloned-up value from optimizer; use phi instead\n+  _igvn.replace_node( n, phi );\n+\n+  \/\/ (There used to be a self-recursive call to split_up() here,\n+  \/\/ but it is not needed.  All necessary forward walking is done\n+  \/\/ by do_split_if() below.)\n+\n+  return true;\n+}\n+\n+\/\/ Look for a (If .. (Bool(CmpP (LoadKlass .. (AddP obj ..)) ..))) and clone all of it down.\n+\/\/ There's likely a CheckCastPP on one of the branches of the If, with obj as input.\n+\/\/ If the (LoadKlass .. (AddP obj ..)) is not cloned down, then split if transforms this to: (If .. (Bool(CmpP phi1 ..)))\n+\/\/ and the CheckCastPP to (CheckCastPP phi2). It's possible then that phi2 is transformed to a CheckCastPP\n+\/\/ (through PhiNode::Ideal) and that that CheckCastPP is replaced by another narrower CheckCastPP at the same control\n+\/\/ (through ConstraintCastNode::Identity). That could cause the CheckCastPP at the If to become top while (CmpP phi1)\n+\/\/ wouldn't constant fold because it's using a different data path. Cloning the whole subgraph down guarantees both the\n+\/\/ AddP and CheckCastPP have the same obj input after split if.\n+bool PhaseIdealLoop::process_cmp_loadklass(Node* n, const Node* blk1, const Node* blk2) {\n+  if (n->Opcode() == Op_AddP && at_relevant_ctrl(n, blk1, blk2)) {\n+    Node_List cmp_nodes;\n+    uint old = C->unique();\n+    for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+      Node* u1 = n->fast_out(i);\n+      if (u1->Opcode() == Op_LoadNKlass && at_relevant_ctrl(u1, blk1, blk2)) {\n+        for (DUIterator_Fast jmax, j = u1->fast_outs(jmax); j < jmax; j++) {\n+          Node* u2 = u1->fast_out(j);\n+          if (u2->Opcode() == Op_DecodeNKlass && at_relevant_ctrl(u2, blk1, blk2)) {\n+            for (DUIterator k = u2->outs(); u2->has_out(k); k++) {\n+              Node* u3 = u2->out(k);\n+              if (at_relevant_ctrl(u3, blk1, blk2) && clone_cmp_down(u3, blk1, blk2)) {\n+                --k;\n+              }\n+            }\n+            for (DUIterator_Fast kmax, k = u2->fast_outs(kmax); k < kmax; k++) {\n+              Node* u3 = u2->fast_out(k);\n+              if (u3->_idx >= old) {\n+                cmp_nodes.push(u3);\n+              }\n+            }\n+          }\n+        }\n+      } else if (u1->Opcode() == Op_LoadKlass && at_relevant_ctrl(u1, blk1, blk2)) {\n+        for (DUIterator j = u1->outs(); u1->has_out(j); j++) {\n+          Node* u2 = u1->out(j);\n+          if (at_relevant_ctrl(u2, blk1, blk2) && clone_cmp_down(u2, blk1, blk2)) {\n+            --j;\n+\n+          }\n+        }\n+        for (DUIterator_Fast kmax, k = u1->fast_outs(kmax); k < kmax; k++) {\n+          Node* u2 = u1->fast_out(k);\n+          if (u2->_idx >= old) {\n+            cmp_nodes.push(u2);\n+          }\n+        }\n+      }\n+    }\n+\n+    for (uint i = 0; i < cmp_nodes.size(); ++i) {\n+      Node* cmp = cmp_nodes.at(i);\n+      process_load_klass_helper(n, cmp, 1);\n+      process_load_klass_helper(n, cmp, 2);\n+    }\n+    if (n->outcnt() == 0) {\n+      assert(n->is_dead(), \"\");\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+bool PhaseIdealLoop::at_relevant_ctrl(Node* n, const Node* blk1, const Node* blk2) {\n+  return ctrl_or_self(n) == blk1 || ctrl_or_self(n) == blk2;\n+}\n+\n+void PhaseIdealLoop::process_load_klass_helper(const Node* n, Node* cmp, int i) {\n+  Node* decode = cmp->in(i);\n+  if (decode->Opcode() == Op_DecodeNKlass) {\n+    Node* loadklass = decode->in(1);\n+    if (loadklass->Opcode() == Op_LoadNKlass) {\n+      Node* addp = loadklass->in(MemNode::Address);\n+      if (addp == n) {\n+        Node* ctrl = get_ctrl(cmp);\n+        Node* decode_clone = decode->clone();\n+        Node* loadklass_clone = loadklass->clone();\n+        Node* addp_clone = addp->clone();\n+        register_new_node(decode_clone, ctrl);\n+        register_new_node(loadklass_clone, ctrl);\n+        register_new_node(addp_clone, ctrl);\n+        _igvn.replace_input_of(cmp, i, decode_clone);\n+        _igvn.replace_input_of(decode_clone, 1, loadklass_clone);\n+        _igvn.replace_input_of(loadklass_clone, MemNode::Address, addp_clone);\n+        if (decode->outcnt() == 0) {\n+          _igvn.remove_dead_node(decode);\n+        }\n+      }\n+    }\n+  } else {\n+    Node* loadklass = cmp->in(i);\n+    if (loadklass->Opcode() == Op_LoadKlass) {\n+      Node* addp = loadklass->in(MemNode::Address);\n+      if (addp == n) {\n+        Node* ctrl = get_ctrl(cmp);\n+        Node* loadklass_clone = loadklass->clone();\n+        Node* addp_clone = addp->clone();\n+        register_new_node(loadklass_clone, ctrl);\n+        register_new_node(addp_clone, ctrl);\n+        _igvn.replace_input_of(cmp, i, loadklass_clone);\n+        _igvn.replace_input_of(loadklass_clone, MemNode::Address, addp_clone);\n+        if (loadklass->outcnt() == 0) {\n+          _igvn.remove_dead_node(loadklass);\n+        }\n+      }\n+    }\n+\n+  }\n+}\n+\n+bool PhaseIdealLoop::clone_cmp_down(Node* n, const Node* blk1, const Node* blk2) {\n@@ -97,1 +322,1 @@\n-    if( !(n->outcnt() == 1 && n->unique_out()->is_Bool() &&\n+    if (!(n->outcnt() == 1 && n->unique_out()->is_Bool() &&\n@@ -99,7 +324,5 @@\n-          (get_ctrl(bol) == blk1 ||\n-           get_ctrl(bol) == blk2) &&\n-          bol->outcnt() == 1 &&\n-          bol->unique_out()->is_CMove() &&\n-          (cmov = bol->unique_out()->as_CMove()) &&\n-          (get_ctrl(cmov) == blk1 ||\n-           get_ctrl(cmov) == blk2) ) ) {\n+          (at_relevant_ctrl(bol, blk1, blk2) &&\n+           bol->outcnt() == 1 &&\n+           bol->unique_out()->is_CMove() &&\n+           (cmov = bol->unique_out()->as_CMove()) &&\n+           at_relevant_ctrl(cmov, blk1, blk2)))) {\n@@ -140,1 +363,1 @@\n-          if (get_ctrl(bol) == blk1 || get_ctrl(bol) == blk2) {\n+          if (at_relevant_ctrl(bol, blk1, blk2)) {\n@@ -200,1 +423,1 @@\n-      _igvn.remove_dead_node( n );\n+      _igvn.remove_dead_node(n );\n@@ -205,103 +428,1 @@\n-  if (subgraph_has_opaque(n)) {\n-    Unique_Node_List wq;\n-    wq.push(n);\n-    for (uint i = 0; i < wq.size(); i++) {\n-      Node* m = wq.at(i);\n-      if (m->is_If()) {\n-        assert(skeleton_predicate_has_opaque(m->as_If()), \"opaque node not reachable from if?\");\n-        Node* bol = clone_skeleton_predicate_bool(m, NULL, NULL, m->in(0));\n-        _igvn.replace_input_of(m, 1, bol);\n-      } else {\n-        assert(!m->is_CFG(), \"not CFG expected\");\n-        for (DUIterator_Fast jmax, j = m->fast_outs(jmax); j < jmax; j++) {\n-          Node* u = m->fast_out(j);\n-          wq.push(u);\n-        }\n-      }\n-    }\n-  }\n-\n-  if (n->Opcode() == Op_OpaqueZeroTripGuard) {\n-    \/\/ If this Opaque1 is part of the zero trip guard for a loop:\n-    \/\/ 1- it can't be shared\n-    \/\/ 2- the zero trip guard can't be the if that's being split\n-    \/\/ As a consequence, this node could be assigned control anywhere between its current control and the zero trip guard.\n-    \/\/ Move it down to get it out of the way of split if and avoid breaking the zero trip guard shape.\n-    Node* cmp = n->unique_out();\n-    assert(cmp->Opcode() == Op_CmpI, \"bad zero trip guard shape\");\n-    Node* bol = cmp->unique_out();\n-    assert(bol->Opcode() == Op_Bool, \"bad zero trip guard shape\");\n-    Node* iff = bol->unique_out();\n-    assert(iff->Opcode() == Op_If, \"bad zero trip guard shape\");\n-    set_ctrl(n, iff->in(0));\n-    set_ctrl(cmp, iff->in(0));\n-    set_ctrl(bol, iff->in(0));\n-    return true;\n-  }\n-\n-  \/\/ See if splitting-up a Store.  Any anti-dep loads must go up as\n-  \/\/ well.  An anti-dep load might be in the wrong block, because in\n-  \/\/ this particular layout\/schedule we ignored anti-deps and allow\n-  \/\/ memory to be alive twice.  This only works if we do the same\n-  \/\/ operations on anti-dep loads as we do their killing stores.\n-  if( n->is_Store() && n->in(MemNode::Memory)->in(0) == n->in(0) ) {\n-    \/\/ Get store's memory slice\n-    int alias_idx = C->get_alias_index(_igvn.type(n->in(MemNode::Address))->is_ptr());\n-\n-    \/\/ Get memory-phi anti-dep loads will be using\n-    Node *memphi = n->in(MemNode::Memory);\n-    assert( memphi->is_Phi(), \"\" );\n-    \/\/ Hoist any anti-dep load to the splitting block;\n-    \/\/ it will then \"split-up\".\n-    for (DUIterator_Fast imax,i = memphi->fast_outs(imax); i < imax; i++) {\n-      Node *load = memphi->fast_out(i);\n-      if( load->is_Load() && alias_idx == C->get_alias_index(_igvn.type(load->in(MemNode::Address))->is_ptr()) )\n-        set_ctrl(load,blk1);\n-    }\n-  }\n-\n-  \/\/ Found some other Node; must clone it up\n-#ifndef PRODUCT\n-  if( PrintOpto && VerifyLoopOptimizations ) {\n-    tty->print(\"Cloning up: \");\n-    n->dump();\n-  }\n-#endif\n-\n-  \/\/ ConvI2L may have type information on it which becomes invalid if\n-  \/\/ it moves up in the graph so change any clones so widen the type\n-  \/\/ to TypeLong::INT when pushing it up.\n-  const Type* rtype = NULL;\n-  if (n->Opcode() == Op_ConvI2L && n->bottom_type() != TypeLong::INT) {\n-    rtype = TypeLong::INT;\n-  }\n-\n-  \/\/ Now actually split-up this guy.  One copy per control path merging.\n-  Node *phi = PhiNode::make_blank(blk1, n);\n-  for( uint j = 1; j < blk1->req(); j++ ) {\n-    Node *x = n->clone();\n-    \/\/ Widen the type of the ConvI2L when pushing up.\n-    if (rtype != NULL) x->as_Type()->set_type(rtype);\n-    if( n->in(0) && n->in(0) == blk1 )\n-      x->set_req( 0, blk1->in(j) );\n-    for( uint i = 1; i < n->req(); i++ ) {\n-      Node *m = n->in(i);\n-      if( get_ctrl(m) == blk1 ) {\n-        assert( m->in(0) == blk1, \"\" );\n-        x->set_req( i, m->in(j) );\n-      }\n-    }\n-    register_new_node( x, blk1->in(j) );\n-    phi->init_req( j, x );\n-  }\n-  \/\/ Announce phi to optimizer\n-  register_new_node(phi, blk1);\n-\n-  \/\/ Remove cloned-up value from optimizer; use phi instead\n-  _igvn.replace_node( n, phi );\n-\n-  \/\/ (There used to be a self-recursive call to split_up() here,\n-  \/\/ but it is not needed.  All necessary forward walking is done\n-  \/\/ by do_split_if() below.)\n-\n-  return true;\n+  return false;\n","filename":"src\/hotspot\/share\/opto\/split_if.cpp","additions":235,"deletions":114,"binary":false,"changes":349,"status":"modified"},{"patch":"@@ -0,0 +1,209 @@\n+\/*\n+ * Copyright (c) 2022, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/**\n+ * @test\n+ * @bug 8297345\n+ * @summary C2: SIGSEGV in PhaseIdealLoop::push_pinned_nodes_thru_region\n+ * @requires vm.gc.Parallel\n+ *\n+ * @run main\/othervm -XX:-TieredCompilation -XX:-UseOnStackReplacement -XX:-BackgroundCompilation\n+ *                   -XX:CompileOnly=TestCheckCastPPBecomesTOP::test1 -XX:LoopMaxUnroll=0\n+ *                   -XX:CompileCommand=dontinline,TestCheckCastPPBecomesTOP::notInlined -XX:+UseParallelGC TestCheckCastPPBecomesTOP\n+ * @run main\/othervm -XX:-TieredCompilation -XX:-UseOnStackReplacement -XX:-BackgroundCompilation\n+ *                   -XX:CompileOnly=TestCheckCastPPBecomesTOP::test1 -XX:LoopMaxUnroll=0\n+ *                   -XX:CompileCommand=dontinline,TestCheckCastPPBecomesTOP::notInlined -XX:+UseParallelGC -XX:-UseCompressedClassPointers TestCheckCastPPBecomesTOP\n+ *\n+ *\/\n+\n+public class TestCheckCastPPBecomesTOP {\n+    private static I field;\n+    private static I field2;\n+    private static I field3;\n+    private static volatile int barrier;\n+\n+    public static void main(String[] args) {\n+        A a = new A();\n+        B b = new B();\n+        for (int i = 0; i < 100_000; i++) {\n+            test1Helper3(5);\n+            field2 = field = a;\n+            test1Helper1(b, 100, 100);\n+            test1Helper1(b, 100, 100);\n+            test1Helper1(b, 100, 100);\n+            field2 = field = b;\n+            test1Helper1(b, 100, 100);\n+            test1Helper1(b, 100, 100);\n+\n+            field2 = field = a;\n+            test1Helper1(b, 10, 100);\n+            test1Helper1(b, 10, 100);\n+            test1Helper1(b, 10, 100);\n+            field2 = field = b;\n+            test1Helper1(b, 10, 100);\n+            test1Helper1(b, 10, 100);\n+\n+            field2 = field = a;\n+            test1Helper1(b, 10, 10);\n+            test1Helper1(b, 10, 10);\n+            test1Helper1(b, 10, 10);\n+            field2 = field = b;\n+            test1Helper1(b, 10, 10);\n+            test1Helper1(b, 10, 10);\n+\n+            field2 = field = a;\n+            test1Helper2(b, true);\n+            field2 = field = b;\n+            test1Helper2(b, true);\n+\n+            test1(false);\n+        }\n+   }\n+\n+\n+    private static void test1(boolean flag1) {\n+        I f = field;\n+        if (f == null) {\n+        }\n+        test1Helper3(10);\n+        test1Helper2(f, flag1);\n+\n+            for (int j = 0; j < 10; j++) {\n+                for (int k = 0; k < 10; k++) {\n+                    for (int l = 0; l < 10; l++) {\n+\n+                    }\n+                }\n+            }\n+    }\n+\n+    private static void test1Helper3(int stop) {\n+        int i;\n+        for (i = 0; i < stop; i++) {\n+\n+        }\n+        if (i != 10) {\n+            barrier = 0x42;\n+        }\n+    }\n+\n+\n+    private static void test1Helper2(I f2, boolean flag1) {\n+        if (flag1) {\n+            if (f2 == null) {\n+\n+            }\n+            int i;\n+            for (i = 0; i < 10; i++) {\n+            }\n+            int j;\n+            for (j = 0; j < 10; j++) {\n+                for (int k = 0; k < 10; k++) {\n+\n+                }\n+            }\n+            test1Helper1(f2, i, j);\n+        }\n+    }\n+\n+    private static void test1Helper1(I f2, int i, int j) {\n+        I f1 = field;\n+        if (f1 == null) {\n+\n+        }\n+        I f3 = field2;\n+        if (f3 == null) {\n+        }\n+        field2 = f3;\n+        field = f1;\n+        if (i == 10) {\n+            if (j == 10) {\n+                f1.m1();\n+            } else {\n+                f1 = f3;\n+            }\n+            f3.m2(f1);\n+        } else {\n+            f1 = f3;\n+        }\n+        I f4 = field2;\n+        field = f1;\n+        f4.m3(f1, f2);\n+        I f5 = field;\n+        barrier = 0x42;\n+        f5.m4(f2);\n+    }\n+\n+    private static void notInlined(Object o1, Object o2) {\n+\n+    }\n+\n+    interface I {\n+        void m1();\n+        void m2(I f);\n+        void m3(I f1, I f2);\n+\n+        void m4(I f2);\n+    }\n+\n+    static class A implements I {\n+        public void m1() {\n+\n+        }\n+\n+        public void m2(I f) {\n+            f.m1();\n+        }\n+\n+        public void m3(I f1, I f2) {\n+            f1.m1();\n+            f2.m1();\n+        }\n+\n+        public void m4(I f2) {\n+            notInlined(this, f2);\n+            field3 = this;\n+        }\n+    }\n+\n+    static class B implements I {\n+        public void m1() {\n+\n+        }\n+\n+        public void m2(I f) {\n+            f.m1();\n+        }\n+\n+        public void m3(I f1, I f2) {\n+            f1.m1();\n+            f2.m1();\n+        }\n+\n+        public void m4(I f2) {\n+            notInlined(this, f2);\n+            field3 = this;\n+        }\n+\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/types\/TestCheckCastPPBecomesTOP.java","additions":209,"deletions":0,"binary":false,"changes":209,"status":"added"}]}