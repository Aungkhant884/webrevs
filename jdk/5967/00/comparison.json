{"files":[{"patch":"@@ -5210,0 +5210,9 @@\n+#ifdef COMPILER2\n+#ifdef _LP64\n+  if(UseAVX > 2 && MaxVectorSize >=32 && VM_Version::supports_avx512vlbw()) {\n+    generate_fill_avx3(t, aligned, to, value, count, rtmp, xtmp);\n+    return;\n+  }\n+#endif\n+#endif\n+\n@@ -5309,1 +5318,1 @@\n-      if (UseAVX >= 2 && UseUnalignedLoadStores) {\n+      if (UseAVX == 2 && UseUnalignedLoadStores) {\n@@ -5311,23 +5320,0 @@\n-        if (UseAVX > 2) {\n-          \/\/ Fill 64-byte chunks\n-          Label L_fill_64_bytes_loop_avx3, L_check_fill_64_bytes_avx2;\n-\n-          \/\/ If number of bytes to fill < AVX3Threshold, perform fill using AVX2\n-          cmpl(count, AVX3Threshold);\n-          jccb(Assembler::below, L_check_fill_64_bytes_avx2);\n-\n-          vpbroadcastd(xtmp, xtmp, Assembler::AVX_512bit);\n-\n-          subl(count, 16 << shift);\n-          jccb(Assembler::less, L_check_fill_32_bytes);\n-          align(16);\n-\n-          BIND(L_fill_64_bytes_loop_avx3);\n-          evmovdqul(Address(to, 0), xtmp, Assembler::AVX_512bit);\n-          addptr(to, 64);\n-          subl(count, 16 << shift);\n-          jcc(Assembler::greaterEqual, L_fill_64_bytes_loop_avx3);\n-          jmpb(L_check_fill_32_bytes);\n-\n-          BIND(L_check_fill_64_bytes_avx2);\n-        }\n@@ -5430,0 +5416,24 @@\n+void MacroAssembler::evpbroadcast(BasicType type, XMMRegister dst, Register src, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+      evpbroadcastb(dst, src, vector_len);\n+      break;\n+    case T_SHORT:\n+    case T_CHAR:\n+      evpbroadcastw(dst, src, vector_len);\n+      break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evpbroadcastd(dst, src, vector_len);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evpbroadcastq(dst, src, vector_len);\n+      break;\n+    default:\n+      fatal(\"Unhandled type : %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n@@ -8245,1 +8255,0 @@\n-  assert(shift != 0, \"shift value should be 1 (short),2(int) or 3(long)\");\n@@ -8253,4 +8262,3 @@\n-    movl(temp, 1);\n-    shlxl(temp, temp, length);\n-    subptr(temp, 1);\n-    kmovwl(mask, temp);\n+    LP64_ONLY(mov64(temp, -1L)) NOT_LP64(movl(temp, -1));\n+    bzhiq(temp, temp, length);\n+    kmov(mask, temp);\n@@ -8266,1 +8274,0 @@\n-  assert(shift != 0, \"shift value should be 1 (short), 2(int) or 3(long)\");\n@@ -8268,4 +8275,3 @@\n-  movl(temp, 1);\n-  shlxl(temp, temp, length);\n-  subptr(temp, 1);\n-  kmovwl(mask, temp);\n+  LP64_ONLY(mov64(temp, -1L)) NOT_LP64(movl(temp, -1));\n+  bzhiq(temp, temp, length);\n+  kmov(mask, temp);\n@@ -8292,0 +8298,174 @@\n+#ifdef _LP64\n+void MacroAssembler::generate_fill_avx3(BasicType type, bool aligned,\n+                                        Register to, Register value, Register count,\n+                                        Register rtmp, XMMRegister xtmp) {\n+  Label L_exit;\n+  Label L_fill_start;\n+  Label L_fill_64_bytes;\n+  Label L_fill_96_bytes;\n+  Label L_fill_128_bytes;\n+  Label L_fill_128_bytes_loop;\n+  Label L_fill_128_loop_header;\n+  Label L_fill_128_bytes_loop_header;\n+  Label L_fill_128_bytes_loop_pre_header;\n+  Label L_fill_zmm_sequence;\n+\n+  int shift = -1;\n+  switch(type) {\n+    case T_BYTE:  shift = 0;\n+      break;\n+    case T_SHORT: shift = 1;\n+      break;\n+    case T_INT:   shift = 2;\n+      break;\n+    case T_LONG:  shift = 3;\n+      break;\n+    default:\n+      fatal(\"Unhandled type: %s\\n\", type2name(type));\n+  }\n+\n+  if (AVX3Threshold != 0  || MaxVectorSize == 32) {\n+\n+    if (MaxVectorSize == 64) {\n+      cmpq(count, AVX3Threshold >> shift);\n+      jcc(Assembler::greater, L_fill_zmm_sequence);\n+    }\n+\n+    evpbroadcast(type, xtmp, value, Assembler::AVX_256bit);\n+\n+    bind(L_fill_start);\n+\n+    cmpq(count, 32 >> shift);\n+    jccb(Assembler::greater, L_fill_64_bytes);\n+    fill32_masked_avx(shift, to, 0, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_64_bytes);\n+    cmpq(count, 64 >> shift);\n+    jccb(Assembler::greater, L_fill_96_bytes);\n+    fill64_masked_avx(shift, to, 0, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_96_bytes);\n+    cmpq(count, 96 >> shift);\n+    jccb(Assembler::greater, L_fill_128_bytes);\n+    fill64_avx(to, 0, xtmp);\n+    subq(count, 64 >> shift);\n+    fill32_masked_avx(shift, to, 64, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_128_bytes);\n+    cmpq(count, 128 >> shift);\n+    jcc(Assembler::greater, L_fill_128_bytes_loop_pre_header);\n+    fill64_avx(to, 0, xtmp);\n+    fill32_avx(to, 64, xtmp);\n+    subq(count, 96 >> shift);\n+    fill32_masked_avx(shift, to, 96, xtmp, k2, count, rtmp);\n+    jmp(L_exit);\n+\n+    bind(L_fill_128_bytes_loop_pre_header);\n+    {\n+      mov(rtmp, to);\n+      andq(rtmp, 31);\n+      jccb(Assembler::zero, L_fill_128_bytes_loop_header);\n+      negq(rtmp);\n+      addq(rtmp, 32);\n+      mov64(r8, -1L);\n+      bzhiq(r8, r8, rtmp);\n+      kmovql(k2, r8);\n+      evmovdqu(T_BYTE, k2, Address(to, 0), xtmp, Assembler::AVX_256bit);\n+      addq(to, rtmp);\n+      shrq(rtmp, shift);\n+      subq(count, rtmp);\n+    }\n+\n+    cmpq(count, 128 >> shift);\n+    jcc(Assembler::less, L_fill_start);\n+\n+    bind(L_fill_128_bytes_loop_header);\n+    subq(count, 128 >> shift);\n+\n+    bind(L_fill_128_bytes_loop);\n+      fill64_avx(to, 0, xtmp);\n+      fill64_avx(to, 64, xtmp);\n+      addq(to, 128);\n+      subq(count, 128 >> shift);\n+      jccb(Assembler::greaterEqual, L_fill_128_bytes_loop);\n+\n+    addq(count, 128 >> shift);\n+    jcc(Assembler::zero, L_exit);\n+    jmp(L_fill_start);\n+  }\n+\n+  if (MaxVectorSize == 64) {\n+    \/\/ Sequence using 64 byte ZMM register.\n+    Label L_fill_128_bytes_zmm;\n+    Label L_fill_192_bytes_zmm;\n+    Label L_fill_192_bytes_loop_zmm;\n+    Label L_fill_192_bytes_loop_header_zmm;\n+    Label L_fill_192_bytes_loop_pre_header_zmm;\n+    Label L_fill_start_zmm_sequence;\n+\n+    bind(L_fill_zmm_sequence);\n+    evpbroadcast(type, xtmp, value, Assembler::AVX_512bit);\n+\n+    bind(L_fill_start_zmm_sequence);\n+    cmpq(count, 64 >> shift);\n+    jccb(Assembler::greater, L_fill_128_bytes_zmm);\n+    fill64_masked_avx(shift, to, 0, xtmp, k2, count, rtmp, true);\n+    jmp(L_exit);\n+\n+    bind(L_fill_128_bytes_zmm);\n+    cmpq(count, 128 >> shift);\n+    jccb(Assembler::greater, L_fill_192_bytes_zmm);\n+    fill64_avx(to, 0, xtmp, true);\n+    subq(count, 64 >> shift);\n+    fill64_masked_avx(shift, to, 64, xtmp, k2, count, rtmp, true);\n+    jmp(L_exit);\n+\n+    bind(L_fill_192_bytes_zmm);\n+    cmpq(count, 192 >> shift);\n+    jcc(Assembler::greater, L_fill_192_bytes_loop_pre_header_zmm);\n+    fill64_avx(to, 0, xtmp, true);\n+    fill64_avx(to, 64, xtmp, true);\n+    subq(count, 128 >> shift);\n+    fill64_masked_avx(shift, to, 128, xtmp, k2, count, rtmp, true);\n+    jmp(L_exit);\n+\n+    bind(L_fill_192_bytes_loop_pre_header_zmm);\n+    {\n+      movq(rtmp, to);\n+      andq(rtmp, 63);\n+      jccb(Assembler::zero, L_fill_192_bytes_loop_header_zmm);\n+      negq(rtmp);\n+      addq(rtmp, 64);\n+      mov64(r8, -1L);\n+      bzhiq(r8, r8, rtmp);\n+      kmovql(k2, r8);\n+      evmovdqu(T_BYTE, k2, Address(to, 0), xtmp, Assembler::AVX_512bit);\n+      addq(to, rtmp);\n+      shrq(rtmp, shift);\n+      subq(count, rtmp);\n+    }\n+\n+    cmpq(count, 192 >> shift);\n+    jcc(Assembler::less, L_fill_start_zmm_sequence);\n+\n+    bind(L_fill_192_bytes_loop_header_zmm);\n+    subq(count, 192 >> shift);\n+\n+    bind(L_fill_192_bytes_loop_zmm);\n+      fill64_avx(to, 0, xtmp, true);\n+      fill64_avx(to, 64, xtmp, true);\n+      fill64_avx(to, 128, xtmp, true);\n+      addq(to, 192);\n+      subq(count, 192 >> shift);\n+      jccb(Assembler::greaterEqual, L_fill_192_bytes_loop_zmm);\n+\n+    addq(count, 192 >> shift);\n+    jcc(Assembler::zero, L_exit);\n+    jmp(L_fill_start_zmm_sequence);\n+  }\n+  bind(L_exit);\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":214,"deletions":34,"binary":false,"changes":248,"status":"modified"},{"patch":"@@ -1308,0 +1308,1 @@\n+  void evpbroadcast(BasicType type, XMMRegister dst, Register src, int vector_len);\n@@ -1888,0 +1889,5 @@\n+\n+  void generate_fill_avx3(BasicType type, bool aligned,\n+                          Register to, Register value, Register count,\n+                          Register rtmp, XMMRegister xtmp);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2116,1 +2116,1 @@\n-    const Register to       = c_rarg0;  \/\/ source array address\n+    const Register to       = c_rarg0;  \/\/ destination array address\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1472,0 +1472,8 @@\n+#ifdef COMPILER2\n+  if (FLAG_IS_DEFAULT(OptimizeFill)) {\n+    if (MaxVectorSize < 32 || !VM_Version::supports_avx512vlbw()) {\n+      OptimizeFill = false;\n+    }\n+  }\n+#endif\n+\n@@ -1588,6 +1596,0 @@\n-  if (FLAG_IS_DEFAULT(OptimizeFill)) {\n-    \/\/ 8247307: On x86, the auto-vectorized loop array fill code shows\n-    \/\/ better performance than the array fill stubs. We should reenable\n-    \/\/ this after the x86 stubs get improved.\n-    OptimizeFill = false;\n-  }\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":8,"deletions":6,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,2 +39,2 @@\n-@BenchmarkMode(Mode.AverageTime)\n-@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@BenchmarkMode(Mode.Throughput)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n@@ -44,1 +44,1 @@\n-    @Param({\"10\", \"266\", \"2048\"})\n+    @Param({\"16\", \"31\", \"59\", \"89\", \"126\", \"250\", \"511\", \"1021\", \"2047\", \"4095\", \"8195\", \"65536\"})\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/util\/ArraysFill.java","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"}]}