{"files":[{"patch":"@@ -314,0 +314,1 @@\n+                                                       size_t& actual_plab_size,\n@@ -327,1 +328,0 @@\n-    size_t actual_plab_size = 0;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -187,0 +187,1 @@\n+                                        size_t& actual_plab_size,\n@@ -198,0 +199,1 @@\n+                            size_t& actual_plab_size,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -127,0 +127,1 @@\n+                                           size_t& actual_plab_size,\n@@ -133,1 +134,1 @@\n-  return allocate_direct_or_new_plab(dest, word_sz, refill_failed, node_index);\n+  return allocate_direct_or_new_plab(dest, word_sz, actual_plab_size, refill_failed, node_index);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.inline.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -185,0 +185,2 @@\n+  void update(HeapWord* addr);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1BlockOffsetTable.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,0 +34,6 @@\n+inline void G1BlockOffsetTablePart::update(HeapWord* addr) {\n+  assert(_hr->bottom() <= addr && addr < _hr->top(), \"Invalid address\");\n+  \/\/ We use the function's side effect (to update BOT), but not the function's result.\n+  block_start(addr);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1BlockOffsetTable.inline.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"gc\/g1\/g1ConcurrentBOTUpdate.hpp\"\n@@ -1449,0 +1450,1 @@\n+  _concurrent_bot_update(NULL),\n@@ -1698,0 +1700,3 @@\n+  if (G1UseConcurrentBOTUpdate) {\n+    _concurrent_bot_update = new G1ConcurrentBOTUpdate(this);\n+  }\n@@ -3557,0 +3562,4 @@\n+    if (G1UseConcurrentBOTUpdate) {\n+      _concurrent_bot_update->pre_record_plab_allocation();\n+    }\n+\n@@ -3820,0 +3829,4 @@\n+  if (G1UseConcurrentBOTUpdate) {\n+    _concurrent_bot_update->post_record_plab_allocation();\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -93,0 +93,1 @@\n+class G1ConcurrentBOTUpdate;\n@@ -196,0 +197,2 @@\n+  G1ConcurrentBOTUpdate* _concurrent_bot_update;\n+\n@@ -1060,0 +1063,3 @@\n+  \/\/ Concurrently refine block offset table entries.\n+  G1ConcurrentBOTUpdate* concurrent_bot_update() const { return _concurrent_bot_update; }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,74 @@\n+#include \"gc\/g1\/g1BarrierSet.hpp\"\n+#include \"gc\/g1\/g1BlockOffsetTable.hpp\"\n+#include \"gc\/g1\/g1CardTable.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1ConcurrentBOTUpdate.hpp\"\n+#include \"gc\/g1\/heapRegion.inline.hpp\"\n+\n+#include \"logging\/log.hpp\"\n+\n+G1ConcurrentBOTUpdate::G1ConcurrentBOTUpdate(G1CollectedHeap* g1h) :\n+  _g1h(g1h),\n+  _plab_word_size(0),\n+  _plab_recording_in_progress(false) {}\n+\n+void G1ConcurrentBOTUpdate::update_bot_for_plab(HeapWord* card_boundary) {\n+  HeapRegion* r = _g1h->heap_region_containing(card_boundary);\n+\n+  assert(r->is_old(), \"Only do this for heap regions with BOT\");\n+  assert(_g1h->card_table()->is_card_aligned(card_boundary), \"Need plab card boundary\");\n+\n+  Ticks start = Ticks::now();\n+  r->update_bot(card_boundary);\n+  log_info(gc, bot)(\"Concurrent BOT Update: cr updated 1 plab, took %8.2lf ms\",\n+                    (Ticks::now() - start).seconds() * MILLIUNITS);\n+}\n+\n+bool G1ConcurrentBOTUpdate::update_bot_for_plab_part(HeapWord* card_boundary) {\n+  \/\/ TODO\n+  return false;\n+}\n+\n+void G1ConcurrentBOTUpdate::pre_record_plab_allocation() {\n+  assert_at_safepoint_on_vm_thread();\n+  _plab_word_size = _g1h->desired_plab_sz(G1HeapRegionAttr::Old);\n+  \/\/ A threshold to control the cost of managing the plabs. If plab size is too small,\n+  \/\/ it costs a lot to store them, yet the benefit of updating them becomes unnoticeable.\n+  \/\/ The threshold is chosen based on the BOT mechanics: when a plab is smaller than this value,\n+  \/\/ BOT entries only make skipping one card at a time. So partial updates to the BOT are not\n+  \/\/ likely to incur duplicated work. On the other hand, if a plab is larger than this value,\n+  \/\/ BOT makes large skips (e.g., 16 cards at a time), which might induce duplicated work for\n+  \/\/ partial BOT updates. This is when concurrent (non-partial) BOT update becomes very beneficial.\n+  if (_plab_word_size > (BOTConstants::Base * BOTConstants::N_words)) {\n+    _plab_recording_in_progress = true;\n+  }\n+}\n+\n+void G1ConcurrentBOTUpdate::record_plab_allocation_work(G1PLABCardQueue* plab_card_queue,\n+                                                        HeapWord* plab_allocation,\n+                                                        size_t word_size) {\n+  HeapRegion* r = _g1h->heap_region_containing(plab_allocation);\n+  assert(r->is_old(), \"Only old regions need this\");\n+  assert(word_size > 0, \"Sanity\");\n+  \/\/ Only when a region is full can a plab be smaller than its desired size.\n+  assert(word_size == _plab_word_size ||\n+         (word_size < _plab_word_size && plab_allocation + word_size == r->end()),\n+         \"Invalid plab size\");\n+\n+  HeapWord* first_card_boundary = align_down(plab_allocation, BOTConstants::N_bytes);\n+  HeapWord* last_card_boundary = align_down(plab_allocation + word_size - 1, BOTConstants::N_bytes);\n+  if (first_card_boundary == last_card_boundary) {\n+    \/\/ PLABs not crossing boundary could not have changed BOT. No need to update them.\n+    return;\n+  }\n+\n+  size_t batch_size = HeapRegion::GrainWords \/ _plab_word_size; \/\/ TODO\n+  assert(batch_size > 1, \"At least 2 plabs per region\");\n+  G1BarrierSet::dirty_card_queue_set().enqueue_plab_card(*plab_card_queue,\n+                                                         last_card_boundary, batch_size);\n+}\n+\n+void G1ConcurrentBOTUpdate::post_record_plab_allocation() {\n+  assert_at_safepoint_on_vm_thread();\n+  _plab_recording_in_progress = false;\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentBOTUpdate.cpp","additions":74,"deletions":0,"binary":false,"changes":74,"status":"added"},{"patch":"@@ -0,0 +1,42 @@\n+#ifndef SHARE_GC_G1_G1CONCURRENTBOTUPDATE_HPP\n+#define SHARE_GC_G1_G1CONCURRENTBOTUPDATE_HPP\n+\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+class G1CollectedHeap;\n+class G1PLABCardQueue;\n+\n+class G1ConcurrentBOTUpdate: public CHeapObj<mtGC> {\n+  G1CollectedHeap* _g1h;\n+\n+  \/\/ The plab size recorded before evacuation.\n+  size_t _plab_word_size;\n+\n+  \/\/ A flag to turn recording on\/off. Mainly to disable recording for full gcs.\n+  bool _plab_recording_in_progress;\n+\n+  void record_plab_allocation_work(G1PLABCardQueue* q, HeapWord* plab_allocation, size_t word_size);\n+\n+public:\n+  G1ConcurrentBOTUpdate(G1CollectedHeap* g1h);\n+\n+  \/\/ Prepare BOT update with necessary information, e.g., plab size. Called before recording plabs.\n+  void pre_record_plab_allocation();\n+\n+  \/\/ Record each plab allocation.\n+  void record_plab_allocation(G1PLABCardQueue* q, HeapWord* plab_allocation, size_t word_size) {\n+    if (_plab_recording_in_progress) {\n+      record_plab_allocation_work(q, plab_allocation, word_size);\n+    }\n+  }\n+\n+  \/\/ Called after recording plabs.\n+  void post_record_plab_allocation();\n+\n+  void update_bot_for_plab(HeapWord* card_boundary);\n+  \/\/ This version will update BOT for part of the plab, allowing for more prompt pause (for gc).\n+  \/\/ Return true if the plab has more parts to update; otherwise return false.\n+  bool update_bot_for_plab_part(HeapWord* card_boundary);\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1CONCURRENTBOTUPDATE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentBOTUpdate.hpp","additions":42,"deletions":0,"binary":false,"changes":42,"status":"added"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/g1\/g1ConcurrentBOTUpdate.hpp\"\n@@ -64,0 +65,8 @@\n+G1PLABCardQueue::G1PLABCardQueue(G1DirtyCardQueueSet* qset) :\n+  PtrQueue(qset)\n+{ }\n+\n+G1PLABCardQueue::~G1PLABCardQueue() {\n+  G1BarrierSet::dirty_card_queue_set().flush_queue(*this);\n+}\n+\n@@ -97,0 +106,16 @@\n+void G1DirtyCardQueueSet::flush_queue(G1PLABCardQueue& queue) {\n+  void** buffer = queue.buffer();\n+  if (buffer != nullptr) {\n+    size_t index = queue.index();\n+    queue.set_buffer(nullptr);\n+    queue.set_index(0);\n+    BufferNode* node = BufferNode::make_node_from_buffer(buffer, index);\n+    if (index == buffer_size()) {\n+      deallocate_buffer(node);\n+    } else {\n+      Atomic::add(&_num_cards, buffer_size() - node->index());\n+      _completed.push(*node);\n+    }\n+  }\n+}\n+\n@@ -106,0 +131,17 @@\n+void G1DirtyCardQueueSet::enqueue_plab_card(G1PLABCardQueue& queue, HeapWord* card_boundary,\n+                                            size_t batch_size) {\n+  CardValue* value = (CardValue*)card_boundary; \/\/ Pretend to be a card pointer\n+  if (buffer_size() - queue.index() < batch_size + 1 && try_enqueue(queue, value)) {\n+    return;\n+  }\n+  \/\/ Either we have a full batch or the buffer is full.\n+  BufferNode* old_node = exchange_buffer_with_new(queue);\n+  if (old_node != nullptr) {\n+    Atomic::add(&_num_cards, buffer_size() - old_node->index());\n+    _completed.push(*old_node);\n+  }\n+  \/\/ We enqueue a special card to indicate this is a plab card buffer.\n+  retry_enqueue(queue, nullptr);\n+  retry_enqueue(queue, value);\n+}\n+\n@@ -356,0 +398,1 @@\n+  G1ConcurrentBOTUpdate* const _concurrent_bot_update;\n@@ -431,0 +474,19 @@\n+  bool process_plab_card_buffer() {\n+    \/\/ Check if the first enqueued is a nullptr.\n+    if (_node->index() == _node_buffer_size || _node_buffer[_node_buffer_size - 1] != nullptr) {\n+      \/\/ Not a plab card buffer.\n+      return false;\n+    }\n+    assert(G1UseConcurrentBOTUpdate, \"Otherwise there shouldn't be plab card buffers\");\n+\n+    for (size_t i = _node->index(); i < _node_buffer_size - 1; ++i) {\n+      if (SuspendibleThreadSet::should_yield()) {\n+        \/\/ Abandon the unprocessed cards.\n+        break;\n+      }\n+      _concurrent_bot_update->update_bot_for_plab((HeapWord*)_node_buffer[i]); \/\/ TODO part\n+    }\n+    \/\/ Return \"fully processed\" no matter what. This buffer will always be abandon.\n+    return true;\n+  }\n+\n@@ -441,1 +503,2 @@\n-    _g1rs(G1CollectedHeap::heap()->rem_set()) {}\n+    _g1rs(G1CollectedHeap::heap()->rem_set()),\n+    _concurrent_bot_update(G1CollectedHeap::heap()->concurrent_bot_update()) {}\n@@ -444,0 +507,2 @@\n+    if (process_plab_card_buffer()) return true;\n+\n@@ -479,1 +544,2 @@\n-    assert(node->index() == buffer_size(),\n+    assert(node->index() == buffer_size() ||\n+           BufferNode::make_buffer_from_node(node)[buffer_size() - 1] == nullptr,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.cpp","additions":68,"deletions":2,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -70,0 +70,6 @@\n+class G1PLABCardQueue: public PtrQueue, public CHeapObj<mtGC> {\n+public:\n+  G1PLABCardQueue(G1DirtyCardQueueSet* qset);\n+  ~G1PLABCardQueue();\n+};\n+\n@@ -282,0 +288,2 @@\n+  void flush_queue(G1PLABCardQueue& queue);\n+\n@@ -285,0 +293,2 @@\n+  void enqueue_plab_card(G1PLABCardQueue& queue, HeapWord* card_boundary, size_t batch_size);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1ConcurrentBOTUpdate.hpp\"\n@@ -65,0 +66,1 @@\n+    _plab_card_queue(NULL),\n@@ -96,0 +98,3 @@\n+  if (G1UseConcurrentBOTUpdate) {\n+    _plab_card_queue = new G1PLABCardQueue(&G1BarrierSet::dirty_card_queue_set());\n+  }\n@@ -114,0 +119,2 @@\n+  if (_plab_card_queue != NULL)\n+    G1BarrierSet::dirty_card_queue_set().flush_queue(*_plab_card_queue);\n@@ -126,0 +133,1 @@\n+  delete _plab_card_queue;\n@@ -320,0 +328,1 @@\n+                                                      size_t& actual_plab_size,\n@@ -331,0 +340,1 @@\n+                                                        actual_plab_size,\n@@ -390,0 +400,1 @@\n+  size_t actual_plab_size = 0;\n@@ -395,0 +406,1 @@\n+                                                           actual_plab_size,\n@@ -400,0 +412,1 @@\n+                                      actual_plab_size,\n@@ -405,0 +418,7 @@\n+    if (actual_plab_size != 0) {\n+      \/\/ A new plab has been allocated to accomodate the allocation. Record it.\n+      if (G1UseConcurrentBOTUpdate && dest_attr->is_old()) {\n+        _g1h->concurrent_bot_update()->record_plab_allocation(_plab_card_queue,\n+                                                              obj_ptr, actual_plab_size);\n+      }\n+    }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -56,0 +56,1 @@\n+  G1PLABCardQueue* _plab_card_queue;\n@@ -196,0 +197,1 @@\n+                                  size_t& actual_plab_size,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/g1\/g1ConcurrentBOTUpdate.hpp\"\n@@ -1368,1 +1369,7 @@\n-      cl->apply_to_buffer(node, buffer_size, worker_id);\n+      if (node->index() < buffer_size &&\n+          BufferNode::make_buffer_from_node(node)[buffer_size - 1] != nullptr) {\n+        cl->apply_to_buffer(node, buffer_size, worker_id);\n+      } else {\n+        \/\/ The first card is a nullptr. This buffer must be a plab card buffer.\n+        assert(G1UseConcurrentBOTUpdate, \"Must be\");\n+      }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSet.cpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -346,1 +346,4 @@\n-           section of the heap.\")\n+           section of the heap.\")                                           \\\n+                                                                            \\\n+  product(bool, G1UseConcurrentBOTUpdate, true,                             \\\n+          \"Concurrently refine block offset table entries.\")\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -203,0 +203,2 @@\n+  void update_bot(HeapWord* addr);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -111,0 +111,4 @@\n+inline void HeapRegion::update_bot(HeapWord* addr) {\n+  _bot_part.update(addr);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}