{"files":[{"patch":"@@ -39,0 +39,1 @@\n+#include \"oops\/resolvedFieldEntry.hpp\"\n@@ -352,1 +353,1 @@\n-  \/\/ Get index out of bytecode pointer, get_cache_entry_pointer_at_bcp\n+  \/\/ Get index out of bytecode pointer.\n@@ -354,1 +355,2 @@\n-  \/\/ Get address of invokedynamic array\n+\n+  \/\/ Get the address of the ResolvedIndyEntry array\n@@ -357,2 +359,10 @@\n-  \/\/ Scale the index to be the entry index * sizeof(ResolvedInvokeDynamicInfo)\n-  z_sllg(index, index, exact_log2(sizeof(ResolvedIndyEntry)));\n+\n+  \/\/ Scale the index to form a byte offset into the ResolvedIndyEntry array\n+  size_t entry_size = sizeof(ResolvedIndyEntry);\n+  if (is_power_of_2(entry_size)) {\n+    z_sllg(index, index, exact_log2(entry_size));\n+  } else {\n+    z_mghi(index, entry_size);\n+  }\n+\n+  \/\/ Calculate the final field address.\n@@ -362,0 +372,20 @@\n+void InterpreterMacroAssembler::load_field_entry(Register cache, Register index, int bcp_offset) {\n+  \/\/ Get field index out of bytecode pointer.\n+  get_cache_index_at_bcp(index, bcp_offset, sizeof(u2));\n+\n+  \/\/ Get the address of the ResolvedFieldEntry array.\n+  get_constant_pool_cache(cache);\n+  z_lg(cache, Address(cache, in_bytes(ConstantPoolCache::field_entries_offset())));\n+\n+  \/\/ Scale the index to form a byte offset into the ResolvedFieldEntry array\n+  size_t entry_size = sizeof(ResolvedFieldEntry);\n+  if (is_power_of_2(entry_size)) {\n+    z_sllg(index, index, exact_log2(entry_size));\n+  } else {\n+    z_mghi(index, entry_size);\n+  }\n+\n+  \/\/ Calculate the final field address.\n+  z_la(cache, Array<ResolvedFieldEntry>::base_offset_in_bytes(), index, cache);\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.cpp","additions":34,"deletions":4,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -116,0 +116,1 @@\n+  void load_field_entry(Register cache, Register index, int bcp_offset = 1);\n","filename":"src\/hotspot\/cpu\/s390\/interp_masm_s390.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/resolvedFieldEntry.hpp\"\n@@ -79,4 +80,3 @@\n-    __ z_larl(Z_R0, (int64_t)0);     \/* Check current address alignment. *\/    \\\n-    __ z_slgr(Z_R0, br_tab);         \/* Current Address must be equal    *\/    \\\n-    __ z_slgr(Z_R0, flags);          \/* to calculated branch target.     *\/    \\\n-    __ z_brc(Assembler::bcondLogZero, 3); \/* skip trap if ok. *\/               \\\n+    __ z_larl(br_tab_temp, (int64_t)0);  \/* Check current address alignment. *\/\\\n+    __ z_slgr(br_tab_temp, br_tab);      \/* Current Address must be equal    *\/\\\n+    __ z_brc(Assembler::bcondLogZero, 3);\/* skip trap if ok. *\/                \\\n@@ -254,2 +254,6 @@\n-        __ get_cache_and_index_and_bytecode_at_bcp(Z_R1_scratch, bc_reg,\n-                                                   temp_reg, byte_no, 1);\n+\n+        \/\/ Both registers are block-local temp regs. Their contents before and after is not used.\n+        Register index = bc_reg;\n+        Register cache = temp_reg;\n+\n+        __ load_field_entry(cache, index);\n@@ -257,2 +261,7 @@\n-        __ compareU32_and_branch(temp_reg, (intptr_t)0,\n-                                 Assembler::bcondZero, L_patch_done);\n+\n+        if (byte_no == f1_byte) {\n+          __ z_cli(Address(cache, in_bytes(ResolvedFieldEntry::get_code_offset())), 0);\n+        } else {\n+          __ z_cli(Address(cache, in_bytes(ResolvedFieldEntry::put_code_offset())), 0);\n+        }\n+        __ z_bre(L_patch_done);\n@@ -263,1 +272,1 @@\n-      \/\/ The pair bytecodes have already done the load.\n+      \/\/ The bytecode pair may have already performed the load.\n@@ -271,2 +280,1 @@\n-\n-    Label   L_fast_patch;\n+    NearLabel L_fast_patch;\n@@ -277,0 +285,1 @@\n+\n@@ -281,1 +290,1 @@\n-                      temp_reg, Z_R13, bc_reg);\n+                      temp_reg, Z_bcp, bc_reg);\n@@ -2345,1 +2354,1 @@\n-\/\/ NOTE: Cpe_offset is already computed as byte offset, so we must not\n+\/\/ NOTE: index is already computed as byte offset, so we must not\n@@ -2349,1 +2358,1 @@\n-                                            Register cpe_offset,\n+                                            Register index,\n@@ -2351,5 +2360,0 @@\n-  BLOCK_COMMENT(\"resolve_cache_and_index {\");\n-  NearLabel      resolved, clinit_barrier_slow;\n-  const Register bytecode_in_cpcache = Z_R1_scratch;\n-  const int      total_f1_offset = in_bytes(ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f1_offset());\n-  assert_different_registers(cache, cpe_offset, bytecode_in_cpcache);\n@@ -2357,0 +2361,5 @@\n+  assert_different_registers(cache, index, Z_R1_scratch);\n+  assert(byte_no == f1_byte || byte_no == f2_byte, \"byte_no out of range\");\n+\n+  const Register  bytecode_in_cpcache = Z_R1_scratch;\n+  NearLabel       resolved, clinit_barrier_slow;\n@@ -2358,6 +2367,0 @@\n-  switch (code) {\n-    case Bytecodes::_nofast_getfield: code = Bytecodes::_getfield; break;\n-    case Bytecodes::_nofast_putfield: code = Bytecodes::_putfield; break;\n-    default:\n-      break;\n-  }\n@@ -2365,6 +2368,5 @@\n-  {\n-    assert(byte_no == f1_byte || byte_no == f2_byte, \"byte_no out of range\");\n-    __ get_cache_and_index_and_bytecode_at_bcp(cache, cpe_offset, bytecode_in_cpcache, byte_no, 1, index_size);\n-    \/\/ Have we resolved this bytecode?\n-    __ compare32_and_branch(bytecode_in_cpcache, (int)code, Assembler::bcondEqual, resolved);\n-  }\n+  BLOCK_COMMENT(\"resolve_cache_and_index {\");\n+\n+  __ get_cache_and_index_and_bytecode_at_bcp(cache, index, bytecode_in_cpcache, byte_no, 1, index_size);\n+  \/\/ Have we resolved this bytecode?\n+  __ compare32_and_branch(bytecode_in_cpcache, (int)code, Assembler::bcondEqual, resolved);\n@@ -2372,1 +2374,1 @@\n-  \/\/ Resolve first time through.\n+  \/\/ Resolve first time through via runtime call.\n@@ -2376,1 +2378,1 @@\n-  __ load_const_optimized(Z_ARG2, (int) code);\n+  __ load_const_optimized(Z_ARG2, (int)code);\n@@ -2378,1 +2380,0 @@\n-\n@@ -2380,1 +2381,2 @@\n-  __ get_cache_and_index_at_bcp(cache, cpe_offset, 1, index_size);\n+  __ get_cache_and_index_at_bcp(cache, index, 1, index_size);\n+\n@@ -2388,1 +2390,1 @@\n-    __ load_resolved_method_at_index(byte_no, cache, cpe_offset, method);\n+    __ load_resolved_method_at_index(byte_no, cache, index, method);\n@@ -2396,0 +2398,63 @@\n+void TemplateTable::resolve_cache_and_index_for_field(int byte_no,\n+                                                      Register cache,\n+                                                      Register index) {\n+\n+  assert_different_registers(cache, index);\n+  assert(byte_no == f1_byte || byte_no == f2_byte, \"byte_no out of range\");\n+\n+  NearLabel resolved;\n+\n+  Bytecodes::Code code = bytecode();\n+  switch (code) {\n+    case Bytecodes::_nofast_getfield: code = Bytecodes::_getfield; break;\n+    case Bytecodes::_nofast_putfield: code = Bytecodes::_putfield; break;\n+    default: break;\n+  }\n+\n+  __ load_field_entry(cache, index);\n+  if (byte_no == f1_byte) {\n+    __ z_cli(Address(cache, in_bytes(ResolvedFieldEntry::get_code_offset())), code);\n+  } else {\n+    __ z_cli(Address(cache, in_bytes(ResolvedFieldEntry::put_code_offset())), code);\n+  }\n+  __ z_bre(resolved);\n+\n+  \/\/ resolve first time through\n+  address entry = CAST_FROM_FN_PTR(address, InterpreterRuntime::resolve_from_cache);\n+  __ load_const_optimized(Z_ARG2, (int)code);\n+  __ call_VM(noreg, entry, Z_ARG2);\n+\n+  \/\/ Update registers with resolved info.\n+  __ load_field_entry(cache, index);\n+\n+  __ bind(resolved);\n+}\n+\n+\/\/ The cache register (the only input reg) must be set before call.\n+void TemplateTable::load_resolved_field_entry(Register obj,\n+                                              Register cache,\n+                                              Register tos_state,\n+                                              Register offset,\n+                                              Register flags,\n+                                              bool is_static = false) {\n+  assert_different_registers(cache, tos_state, flags, offset);\n+\n+  \/\/ Field offset\n+  __ load_sized_value(offset, Address(cache, in_bytes(ResolvedFieldEntry::field_offset_offset())), sizeof(int), true \/*is_signed*\/);\n+\n+  \/\/ Flags\n+  __ load_sized_value(flags, Address(cache, in_bytes(ResolvedFieldEntry::flags_offset())), sizeof(u1), false);\n+\n+  \/\/ TOS state\n+  if (tos_state != noreg) {\n+    __ load_sized_value(tos_state, Address(cache, in_bytes(ResolvedFieldEntry::type_offset())), sizeof(u1), false);\n+  }\n+\n+  \/\/ Klass overwrite register\n+  if (is_static) {\n+    __ load_sized_value(obj, Address(cache, ResolvedFieldEntry::field_holder_offset()), sizeof(void*), false);\n+    __ load_sized_value(obj, Address(obj, in_bytes(Klass::java_mirror_offset())), sizeof(void*), false);\n+    __ resolve_oop_handle(obj);\n+  }\n+}\n+\n@@ -2523,2 +2588,4 @@\n-\/\/ The registers cache and index expected to be set before call.\n-\/\/ Correct values of the cache and index registers are preserved.\n+\/\/ The registers cache and index are set up if needed.\n+\/\/ However, the field entry must have been resolved before.\n+\/\/ If no jvmti post operation is performed, their contents remains unchanged.\n+\/\/ After a jvmti post operation, the registers are re-calculated by load_field_entry().\n@@ -2537,1 +2604,1 @@\n-  Label exit;\n+  Label dontPost;\n@@ -2540,5 +2607,2 @@\n-  __ load_and_test_int(Z_R0, Address(Z_tos));\n-  __ z_brz(exit);\n-\n-  \/\/ Index is returned as byte offset, do not shift!\n-  __ get_cache_and_index_at_bcp(Z_ARG3, Z_R1_scratch, 1);\n+  __ z_chsi(0, Z_tos, 0); \/\/ avoid loading data into a scratch register\n+  __ z_bre(dontPost);\n@@ -2547,3 +2611,1 @@\n-  __ add2reg_with_index(Z_ARG3,\n-                        in_bytes(ConstantPoolCache::base_offset()),\n-                        Z_ARG3, Z_R1_scratch);\n+  \/\/ __ load_field_entry(cache, index); \/\/ not required as already set by resolve_cache_and_index_for_field()\n@@ -2554,1 +2616,1 @@\n-    __ mem2reg_opt(Z_ARG2, at_tos());  \/\/ Get object pointer without popping it.\n+    __ load_ptr(0, Z_ARG2);  \/\/ Get object pointer without popping it.\n@@ -2557,0 +2619,1 @@\n+\n@@ -2558,1 +2621,1 @@\n-  \/\/ Z_ARG3: cache entry pointer\n+  \/\/ cache:  cache entry pointer\n@@ -2561,2 +2624,1 @@\n-             Z_ARG2, Z_ARG3);\n-  __ get_cache_and_index_at_bcp(cache, index, 1);\n+             Z_ARG2, cache);\n@@ -2564,1 +2626,4 @@\n-  __ bind(exit);\n+  \/\/ restore registers after runtime call.\n+  __ load_field_entry(cache, index);\n+\n+  __ bind(dontPost);\n@@ -2576,6 +2641,15 @@\n-  const Register cache = Z_tmp_1;\n-  const Register index = Z_tmp_2;\n-  const Register obj   = Z_tmp_1;\n-  const Register off   = Z_ARG2;\n-  const Register flags = Z_ARG1;\n-  const Register bc    = Z_tmp_1;  \/\/ Uses same reg as obj, so don't mix them.\n+  const Register obj           = Z_tmp_1;\n+  const Register off           = Z_tmp_2;\n+  const Register cache         = Z_tmp_1;\n+  const Register index         = Z_tmp_2;\n+  const Register flags         = Z_R1_scratch; \/\/ flags are not used in getfield\n+  const Register br_tab        = Z_R1_scratch;\n+  const Register tos_state     = Z_ARG4;\n+  const Register bc_reg        = Z_tmp_1;\n+  const Register patch_tmp     = Z_ARG4;\n+  const Register oopLoad_tmp1  = Z_R1_scratch;\n+  const Register oopLoad_tmp2  = Z_ARG5;\n+#ifdef ASSERT\n+  const Register br_tab_temp   = Z_R0_scratch;  \/\/ for branch table verification code only\n+#endif\n+\n@@ -2583,1 +2657,11 @@\n-  resolve_cache_and_index(byte_no, cache, index, sizeof(u2));\n+  \/\/ Register usage and life range\n+  \/\/\n+  \/\/  cache, index          : short-lived. Their life ends after load_resolved_field_entry.\n+  \/\/  obj (overwrites cache): long-lived. Used in branch table entries.\n+  \/\/  off (overwrites index): long-lived. Used in branch table entries.\n+  \/\/  flags                 : unused in getfield.\n+  \/\/  br_tab                : short-lived. Only used to address branch table, and for verification in BTB_BEGIN macro.\n+  \/\/  tos_state             : short-lived. Only used to index the branch table entry.\n+  \/\/  bc_reg                : short-lived. Used as work register in patch_bytecode.\n+  \/\/\n+  resolve_cache_and_index_for_field(byte_no, cache, index);\n@@ -2585,1 +2669,1 @@\n-  load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);\n+  load_resolved_field_entry(obj, cache, tos_state, off, flags, is_static);\n@@ -2592,1 +2676,1 @@\n-  \/\/ Displacement is 0, so any store instruction will be fine on any CPU.\n+  \/\/ Displacement is 0. No need to care about limited displacement range.\n@@ -2595,1 +2679,1 @@\n-  Label    is_Byte, is_Bool, is_Int, is_Short, is_Char,\n+  Label    is_Byte, is_Bool,  is_Int,    is_Short, is_Char,\n@@ -2597,3 +2681,2 @@\n-  Label    is_badState8, is_badState9, is_badStateA, is_badStateB,\n-           is_badStateC, is_badStateD, is_badStateE, is_badStateF,\n-           is_badState;\n+  Label    is_badState,  is_badState9, is_badStateA, is_badStateB,\n+           is_badStateC, is_badStateD, is_badStateE, is_badStateF;\n@@ -2601,1 +2684,0 @@\n-  Register br_tab       = Z_R1_scratch;\n@@ -2606,1 +2688,1 @@\n-  assert(btos == 0, \"change code, btos != 0\");\n+  assert((btos == 0) && (atos == 8), \"change branch table! ByteCodes may have changed\");\n@@ -2612,0 +2694,1 @@\n+  \/\/ Calculate branch table size.\n@@ -2618,3 +2701,0 @@\n-    const int r_bitpos  = 63 - bit_shift;\n-    const int l_bitpos  = r_bitpos - ConstantPoolCacheEntry::tos_state_bits + 1;\n-    const int n_rotate  = (bit_shift-ConstantPoolCacheEntry::tos_state_shift);\n@@ -2622,1 +2702,4 @@\n-    __ rotate_then_insert(flags, flags, l_bitpos, r_bitpos, n_rotate, true);\n+    __ z_sllg(tos_state, tos_state, bit_shift);\n+    assert(tos_state != Z_R0_scratch, \"shouldn't be\");\n+    __ z_agr(br_tab, tos_state);\n+    __ z_bcr(Assembler::bcondAlways, br_tab);\n@@ -2624,1 +2707,0 @@\n-  __ z_bc(Assembler::bcondAlways, 0, flags, br_tab);\n@@ -2635,1 +2717,1 @@\n-    patch_bytecode(Bytecodes::_fast_bgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_bgetfield, bc_reg, patch_tmp);\n@@ -2647,1 +2729,1 @@\n-    patch_bytecode(Bytecodes::_fast_bgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_bgetfield, bc_reg, patch_tmp);\n@@ -2659,1 +2741,1 @@\n-    patch_bytecode(Bytecodes::_fast_cgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_cgetfield, bc_reg, patch_tmp);\n@@ -2670,1 +2752,1 @@\n-    patch_bytecode(Bytecodes::_fast_sgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_sgetfield, bc_reg, patch_tmp);\n@@ -2681,1 +2763,1 @@\n-    patch_bytecode(Bytecodes::_fast_igetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_igetfield, bc_reg, patch_tmp);\n@@ -2692,1 +2774,1 @@\n-    patch_bytecode(Bytecodes::_fast_lgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_lgetfield, bc_reg, patch_tmp);\n@@ -2703,1 +2785,1 @@\n-    patch_bytecode(Bytecodes::_fast_fgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_fgetfield, bc_reg, patch_tmp);\n@@ -2714,1 +2796,1 @@\n-    patch_bytecode(Bytecodes::_fast_dgetfield, bc, Z_ARG5);\n+    patch_bytecode(Bytecodes::_fast_dgetfield, bc_reg, patch_tmp);\n@@ -2725,4 +2807,0 @@\n-  BTB_BEGIN(is_badState8, bsize, \"getfield_or_static:is_badState8\");\n-  __ z_illtrap();\n-  __ z_bru(is_badState);\n-  BTB_END( is_badState8, bsize, \"getfield_or_static:is_badState8\");\n@@ -2732,1 +2810,1 @@\n-  BTB_END( is_badState9, bsize, \"getfield_or_static:is_badState9\");\n+  BTB_END(is_badState9, bsize, \"getfield_or_static:is_badState9\");\n@@ -2736,1 +2814,1 @@\n-  BTB_END( is_badStateA, bsize, \"getfield_or_static:is_badStateA\");\n+  BTB_END(is_badStateA, bsize, \"getfield_or_static:is_badStateA\");\n@@ -2740,1 +2818,1 @@\n-  BTB_END( is_badStateB, bsize, \"getfield_or_static:is_badStateB\");\n+  BTB_END(is_badStateB, bsize, \"getfield_or_static:is_badStateB\");\n@@ -2744,1 +2822,1 @@\n-  BTB_END( is_badStateC, bsize, \"getfield_or_static:is_badStateC\");\n+  BTB_END(is_badStateC, bsize, \"getfield_or_static:is_badStateC\");\n@@ -2748,1 +2826,1 @@\n-  BTB_END( is_badStateD, bsize, \"getfield_or_static:is_badStateD\");\n+  BTB_END(is_badStateD, bsize, \"getfield_or_static:is_badStateD\");\n@@ -2752,1 +2830,1 @@\n-  BTB_END( is_badStateE, bsize, \"getfield_or_static:is_badStateE\");\n+  BTB_END(is_badStateE, bsize, \"getfield_or_static:is_badStateE\");\n@@ -2756,1 +2834,1 @@\n-  BTB_END( is_badStateF, bsize, \"getfield_or_static:is_badStateF\");\n+  BTB_END(is_badStateF, bsize, \"getfield_or_static:is_badStateF\");\n@@ -2778,1 +2856,1 @@\n-    do_oop_load(_masm, field, Z_tos, Z_tmp_2, Z_tmp_3, IN_HEAP);\n+    do_oop_load(_masm, field, Z_tos, oopLoad_tmp1, oopLoad_tmp2, IN_HEAP);\n@@ -2782,1 +2860,1 @@\n-      patch_bytecode(Bytecodes::_fast_agetfield, bc, Z_ARG5);\n+      patch_bytecode(Bytecodes::_fast_agetfield, bc_reg, patch_tmp);\n@@ -2806,3 +2884,3 @@\n-\/\/ The registers cache and index expected to be set before call.  The\n-\/\/ function may destroy various registers, just not the cache and\n-\/\/ index registers.\n+\/\/ Register cache is expected to be set before the call.\n+\/\/ This function may destroy various registers.\n+\/\/ Only the contents of register cache is preserved\/restored.\n@@ -2819,6 +2897,4 @@\n-  \/\/ Check to see if a field modification watch has been set before\n-  \/\/ we take the time to call into the VM.\n-  Label    L1;\n-  ByteSize cp_base_offset = ConstantPoolCache::base_offset();\n-  assert_different_registers(cache, index, Z_tos);\n-\n+  \/\/ Check to see if a field modification watch has been set\n+  \/\/ before we take the time to call into the VM.\n+  Label    dontPost;\n+  assert_different_registers(cache, index, Z_tos, Z_ARG2, Z_ARG3, Z_ARG4);\n@@ -2826,2 +2902,2 @@\n-  __ load_and_test_int(Z_R0, Address(Z_tos));\n-  __ z_brz(L1);\n+  __ z_chsi(0, Z_tos, 0); \/\/ avoid loading data into a scratch register\n+  __ z_bre(dontPost);\n@@ -2829,2 +2905,6 @@\n-  \/\/ Index is returned as byte offset, do not shift!\n-  __ get_cache_and_index_at_bcp(Z_ARG3, Z_R1_scratch, 1);\n+  Register obj        = Z_ARG2;\n+  Register fieldEntry = Z_ARG3;\n+  Register value      = Z_ARG4;\n+\n+  \/\/ Take a copy of cache entry pointer\n+  __ z_lgr(fieldEntry, cache);\n@@ -2833,2 +2913,2 @@\n-    \/\/ Life is simple. Null out the object pointer.\n-    __ clear_reg(Z_ARG2, true, false);   \/\/ Don't set CC.\n+    \/\/ Life is simple. NULL the object pointer.\n+    __ clear_reg(obj, true, false); \/\/ Don't set CC.\n@@ -2840,9 +2920,1 @@\n-    __ mem2reg_opt(Z_ARG4,\n-                   Address(Z_ARG3, Z_R1_scratch,\n-                           in_bytes(cp_base_offset + ConstantPoolCacheEntry::flags_offset()) +\n-                           (BytesPerLong - BytesPerInt)),\n-                   false);\n-    __ z_srl(Z_ARG4, ConstantPoolCacheEntry::tos_state_shift);\n-    \/\/ Make sure we don't need to mask Z_ARG4 for tos_state after the above shift.\n-    ConstantPoolCacheEntry::verify_tos_state_shift();\n-    __ mem2reg_opt(Z_ARG2, at_tos(1));  \/\/ Initially assume a one word jvalue.\n+    __ load_sized_value(value, Address(fieldEntry, in_bytes(ResolvedFieldEntry::type_offset())), sizeof(u1), false);\n@@ -2850,1 +2922,1 @@\n-    NearLabel   load_dtos, cont;\n+    __ mem2reg_opt(obj, at_tos(1)); \/\/ Initially assume a one word jvalue.\n@@ -2852,4 +2924,7 @@\n-    __ compareU32_and_branch(Z_ARG4, (intptr_t) ltos,\n-                              Assembler::bcondNotEqual, load_dtos);\n-    __ mem2reg_opt(Z_ARG2, at_tos(2)); \/\/ ltos (two word jvalue)\n-    __ z_bru(cont);\n+    if (VM_Version::has_LoadStoreConditional()) {\n+      __ z_chi(value, ltos);\n+      __ z_locg(obj, at_tos(2), Assembler::bcondEqual);\n+      __ z_chi(value, dtos);\n+      __ z_locg(obj, at_tos(2), Assembler::bcondEqual);\n+    } else {\n+      NearLabel load_dtos, cont;\n@@ -2857,3 +2932,4 @@\n-    __ bind(load_dtos);\n-    __ compareU32_and_branch(Z_ARG4, (intptr_t)dtos, Assembler::bcondNotEqual, cont);\n-    __ mem2reg_opt(Z_ARG2, at_tos(2)); \/\/ dtos (two word jvalue)\n+      __ z_chi(value, ltos);\n+      __ z_brne(load_dtos);\n+      __ mem2reg_opt(obj, at_tos(2)); \/\/ ltos (two word jvalue)\n+      __ z_bru(cont);\n@@ -2861,3 +2937,4 @@\n-    __ bind(cont);\n-  }\n-  \/\/ cache entry pointer\n+      __ bind(load_dtos);\n+      __ z_chi(value, dtos);\n+      __ z_brne(cont);\n+      __ mem2reg_opt(obj, at_tos(2)); \/\/ dtos (two word jvalue)\n@@ -2865,1 +2942,3 @@\n-  __ add2reg_with_index(Z_ARG3, in_bytes(cp_base_offset), Z_ARG3, Z_R1_scratch);\n+      __ bind(cont);\n+    }\n+  }\n@@ -2868,4 +2947,4 @@\n-  __ load_address(Z_ARG4, Address(Z_esp, Interpreter::stackElementSize));\n-  \/\/ Z_ARG2: object pointer set up above (null if static)\n-  \/\/ Z_ARG3: cache entry pointer\n-  \/\/ Z_ARG4: jvalue object on the stack\n+  __ load_address(value, Address(Z_esp, Interpreter::expr_offset_in_bytes(0)));\n+  \/\/ obj:        object pointer set up above (null if static)\n+  \/\/ fieldEntry: field entry pointer\n+  \/\/ value:      jvalue object on the stack\n@@ -2874,2 +2953,4 @@\n-             Z_ARG2, Z_ARG3, Z_ARG4);\n-  __ get_cache_and_index_at_bcp(cache, index, 1);\n+             obj, fieldEntry, value);\n+\n+  \/\/ Reload field entry\n+  __ load_field_entry(cache, index);\n@@ -2877,1 +2958,1 @@\n-  __ bind(L1);\n+  __ bind(dontPost);\n@@ -2885,3 +2966,1 @@\n-  const Register cache         = Z_tmp_1;\n-  const Register index         = Z_ARG5;\n-  const Register obj           = Z_tmp_1;\n+  const Register obj           = Z_ARG5;\n@@ -2889,3 +2968,8 @@\n-  const Register flags         = Z_R1_scratch;\n-  const Register br_tab        = Z_ARG5;\n-  const Register bc            = Z_tmp_1;\n+  const Register cache         = Z_ARG5;\n+  const Register index         = Z_tmp_2;\n+  const Register fieldAddr     = Z_tmp_2;      \/\/ contains obj and off combined. Could be any address register.\n+  const Register flags         = Z_tmp_1;      \/\/ preserves flag value till the end, for volatility check\n+  const Register br_tab        = Z_R1_scratch;\n+  const Register tos_state     = Z_ARG4;\n+  const Register bc_reg        = Z_tmp_2;\n+  const Register patch_tmp     = Z_ARG4;\n@@ -2893,1 +2977,1 @@\n-  const Register oopStore_tmp2 = Z_ARG5;\n+  const Register oopStore_tmp2 = Z_ARG5;       \/\/ tmp2 must be non-volatile reg\n@@ -2895,0 +2979,3 @@\n+#ifdef ASSERT\n+  const Register br_tab_temp   = Z_R0_scratch; \/\/ for branch table verification code only\n+#endif\n@@ -2896,1 +2983,12 @@\n-  resolve_cache_and_index(byte_no, cache, index, sizeof(u2));\n+\/*\n+ *  Register usage and life range\n+ *\n+ *  cache, index          : short-lived. Their life ends after load_resolved_field_entry.\n+ *  obj (overwrites cache): very short-lived, Combined with off immediately.\n+ *  off (overwrites index): long-lived, Used in branch table entries.\n+ *  flags                 : long-lived, Has to survive until the end to determine volatility.\n+ *  br_tab                : short-lived, Only used to address branch table, and for verification in BTB_BEGIN macro.\n+ *  tos_state             : short-live, Only used to index the branch table entry.\n+ *  bc_reg                : short-lived, Used as work register in patch_bytecode.\n+*\/\n+  resolve_cache_and_index_for_field(byte_no, cache, index);\n@@ -2898,6 +2996,16 @@\n-  load_field_cp_cache_entry(obj, cache, index, off, flags, is_static);\n-  \/\/ begin of life for:\n-  \/\/   obj, off   long life range\n-  \/\/   flags      short life range, up to branch into branch table\n-  \/\/ end of life for:\n-  \/\/   cache, index\n+  load_resolved_field_entry(obj, cache, tos_state, off, flags, is_static);\n+\n+  const Address field(fieldAddr);\n+  __ lgr_if_needed(fieldAddr, off);\n+\n+  \/*\n+   * In the static case, we can calculate the final field address easily.\n+   * Do so to occupy only one non-volatile register\n+   * ---------------------\n+   * In the non-static case, we preset fieldAddr with the field offset.\n+   * The object address is available only later. It is popped from stack.\n+   * see pop_and_check_object(obj);\n+   *\/\n+  if (is_static) {\n+    __ z_agr(fieldAddr, obj);\n+  }\n@@ -2905,2 +3013,1 @@\n-  const Address field(obj, off);\n-  Label is_Byte, is_Bool, is_Int, is_Short, is_Char,\n+  Label is_Byte, is_Bool,  is_Int,    is_Short, is_Char,\n@@ -2908,3 +3015,2 @@\n-  Label is_badState8, is_badState9, is_badStateA, is_badStateB,\n-        is_badStateC, is_badStateD, is_badStateE, is_badStateF,\n-        is_badState;\n+  Label is_badState,  is_badState9, is_badStateA, is_badStateB,\n+        is_badStateC, is_badStateD, is_badStateE, is_badStateF;\n@@ -2916,2 +3022,1 @@\n-\n-  assert(btos == 0, \"change code, btos != 0\");\n+  assert((btos == 0) && (atos == 8), \"change branch table! ByteCodes may have changed\");\n@@ -2920,1 +3025,1 @@\n-  const unsigned int bsize = is_static ? BTB_MINSIZE*1 : BTB_MINSIZE*4;\n+  const unsigned int bsize = is_static ? BTB_MINSIZE*1 : BTB_MINSIZE*8;\n@@ -2928,3 +3033,0 @@\n-    const int r_bitpos  = 63 - bit_shift;\n-    const int l_bitpos  = r_bitpos - ConstantPoolCacheEntry::tos_state_bits + 1;\n-    const int n_rotate  = (bit_shift-ConstantPoolCacheEntry::tos_state_shift);\n@@ -2932,2 +3034,4 @@\n-    __ rotate_then_insert(flags, flags, l_bitpos, r_bitpos, n_rotate, true);\n-    __ z_bc(Assembler::bcondAlways, 0, flags, br_tab);\n+    __ z_sllg(tos_state, tos_state, bit_shift);\n+    assert(tos_state != Z_R0_scratch, \"shouldn't be\");\n+    __ z_agr(br_tab, tos_state);\n+    __ z_bcr(Assembler::bcondAlways, br_tab);\n@@ -2935,2 +3039,0 @@\n-  \/\/ end of life for:\n-  \/\/   flags, br_tab\n@@ -2946,0 +3048,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -2949,1 +3052,1 @@\n-    patch_bytecode(Bytecodes::_fast_bputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_bputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -2952,1 +3055,1 @@\n-  BTB_END( is_Byte, bsize, \"putfield_or_static:is_Byte\");\n+  BTB_END(is_Byte, bsize, \"putfield_or_static:is_Byte\");\n@@ -2959,0 +3062,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -2963,1 +3067,1 @@\n-    patch_bytecode(Bytecodes::_fast_zputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_zputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -2973,0 +3077,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -2976,1 +3081,1 @@\n-    patch_bytecode(Bytecodes::_fast_cputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_cputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -2979,1 +3084,1 @@\n-  BTB_END( is_Char, bsize, \"putfield_or_static:is_Char\");\n+  BTB_END(is_Char, bsize, \"putfield_or_static:is_Char\");\n@@ -2986,0 +3091,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -2989,1 +3095,1 @@\n-    patch_bytecode(Bytecodes::_fast_sputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_sputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -2992,1 +3098,1 @@\n-  BTB_END( is_Short, bsize, \"putfield_or_static:is_Short\");\n+  BTB_END(is_Short, bsize, \"putfield_or_static:is_Short\");\n@@ -2999,0 +3105,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -3002,1 +3109,1 @@\n-    patch_bytecode(Bytecodes::_fast_iputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_iputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -3005,1 +3112,1 @@\n-  BTB_END( is_Int, bsize, \"putfield_or_static:is_Int\");\n+  BTB_END(is_Int, bsize, \"putfield_or_static:is_Int\");\n@@ -3012,0 +3119,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -3015,1 +3123,1 @@\n-    patch_bytecode(Bytecodes::_fast_lputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_lputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -3018,1 +3126,1 @@\n-  BTB_END( is_Long, bsize, \"putfield_or_static:is_Long\");\n+  BTB_END(is_Long, bsize, \"putfield_or_static:is_Long\");\n@@ -3025,0 +3133,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -3028,1 +3137,1 @@\n-    patch_bytecode(Bytecodes::_fast_fputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_fputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -3031,1 +3140,1 @@\n-  BTB_END( is_Float, bsize, \"putfield_or_static:is_Float\");\n+  BTB_END(is_Float, bsize, \"putfield_or_static:is_Float\");\n@@ -3038,0 +3147,1 @@\n+    __ z_agr(fieldAddr, obj);\n@@ -3041,1 +3151,1 @@\n-    patch_bytecode(Bytecodes::_fast_dputfield, bc, Z_ARG5, true, byte_no);\n+    patch_bytecode(Bytecodes::_fast_dputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -3044,1 +3154,1 @@\n-  BTB_END( is_Double, bsize, \"putfield_or_static:is_Double\");\n+  BTB_END(is_Double, bsize, \"putfield_or_static:is_Double\");\n@@ -3049,1 +3159,1 @@\n-  BTB_END( is_Object, bsize, \"putfield_or_static:is_Object\");\n+  BTB_END(is_Object, bsize, \"putfield_or_static:is_Object\");\n@@ -3052,4 +3162,0 @@\n-  BTB_BEGIN(is_badState8, bsize, \"putfield_or_static:is_badState8\");\n-  __ z_illtrap();\n-  __ z_bru(is_badState);\n-  BTB_END( is_badState8, bsize, \"putfield_or_static:is_badState8\");\n@@ -3059,1 +3165,1 @@\n-  BTB_END( is_badState9, bsize, \"putfield_or_static:is_badState9\");\n+  BTB_END(is_badState9, bsize, \"putfield_or_static:is_badState9\");\n@@ -3063,1 +3169,1 @@\n-  BTB_END( is_badStateA, bsize, \"putfield_or_static:is_badStateA\");\n+  BTB_END(is_badStateA, bsize, \"putfield_or_static:is_badStateA\");\n@@ -3067,1 +3173,1 @@\n-  BTB_END( is_badStateB, bsize, \"putfield_or_static:is_badStateB\");\n+  BTB_END(is_badStateB, bsize, \"putfield_or_static:is_badStateB\");\n@@ -3071,1 +3177,1 @@\n-  BTB_END( is_badStateC, bsize, \"putfield_or_static:is_badStateC\");\n+  BTB_END(is_badStateC, bsize, \"putfield_or_static:is_badStateC\");\n@@ -3075,1 +3181,1 @@\n-  BTB_END( is_badStateD, bsize, \"putfield_or_static:is_badStateD\");\n+  BTB_END(is_badStateD, bsize, \"putfield_or_static:is_badStateD\");\n@@ -3079,1 +3185,1 @@\n-  BTB_END( is_badStateE, bsize, \"putfield_or_static:is_badStateE\");\n+  BTB_END(is_badStateE, bsize, \"putfield_or_static:is_badStateE\");\n@@ -3083,1 +3189,1 @@\n-  BTB_END( is_badStateF, bsize, \"putfield_or_static:is_badStateF\");\n+  BTB_END(is_badStateF, bsize, \"putfield_or_static:is_badStateF\");\n@@ -3090,1 +3196,1 @@\n-    else            __ stop_static(\"Bad state in putfield\");\n+    else           __ stop_static(\"Bad state in putfield\");\n@@ -3105,0 +3211,1 @@\n+      __ z_agr(fieldAddr, obj);\n@@ -3107,1 +3214,1 @@\n-    do_oop_store(_masm, Address(obj, off), Z_tos,\n+    do_oop_store(_masm, field, Z_tos,\n@@ -3110,1 +3217,1 @@\n-      patch_bytecode(Bytecodes::_fast_aputfield, bc, Z_ARG5, true, byte_no);\n+      patch_bytecode(Bytecodes::_fast_aputfield, bc_reg, patch_tmp, true, byte_no);\n@@ -3119,1 +3226,2 @@\n-  Label notVolatile;\n+  \/\/ only if flags register is non-volatile\n+  NearLabel notVolatile;\n@@ -3121,2 +3229,4 @@\n-  __ testbit(Z_ARG4, ConstantPoolCacheEntry::is_volatile_shift);\n-  __ z_brz(notVolatile);\n+  if (!flags.is_volatile()) {\n+    __ testbit(flags, ResolvedFieldEntry::is_volatile_shift);\n+    __ z_brz(notVolatile);\n+  }\n@@ -3152,4 +3262,0 @@\n-  \/\/ Check to see if a field modification watch has been set before\n-  \/\/ we take the time to call into the VM.\n-  Label   exit;\n-\n@@ -3158,4 +3264,6 @@\n-  __ load_absolute_address(Z_R1_scratch,\n-                           (address) JvmtiExport::get_field_modification_count_addr());\n-  __ load_and_test_int(Z_R0_scratch, Address(Z_R1_scratch));\n-  __ z_brz(exit);\n+  \/\/ Check to see if a field modification watch has been set\n+  \/\/ before we take the time to call into the VM.\n+  Label dontPost;\n+  __ load_absolute_address(Z_R1_scratch, (address)JvmtiExport::get_field_modification_count_addr());\n+  __ z_chsi(0, Z_R1_scratch, 0); \/\/ avoid loading data into a scratch register\n+  __ z_bre(dontPost);\n@@ -3163,1 +3271,3 @@\n-  Register obj = Z_tmp_1;\n+  Register obj        = Z_ARG2;\n+  Register fieldEntry = Z_ARG3;\n+  Register value      = Z_ARG4;\n@@ -3165,3 +3275,2 @@\n-  __ pop_ptr(obj);                  \/\/ Copy the object pointer from tos.\n-  __ verify_oop(obj);\n-  __ push_ptr(obj);                 \/\/ Put the object pointer back on tos.\n+  __ load_ptr(0, obj);              \/\/ Copy the object pointer from tos.\n+  __ verify_oop(obj);               \/\/ and verify it\n@@ -3198,1 +3307,1 @@\n-  __ load_address(Z_ARG4, Address(Z_esp, Interpreter::stackElementSize));\n+  __ load_address(value, Address(Z_esp, Interpreter::expr_offset_in_bytes(0)));\n@@ -3200,1 +3309,1 @@\n-  __ get_cache_entry_pointer_at_bcp(Z_ARG3, Z_tos, 1);\n+  __ load_field_entry(fieldEntry, Z_tos, 1);\n@@ -3203,3 +3312,3 @@\n-  \/\/ obj   : object pointer copied above\n-  \/\/ Z_ARG3: cache entry pointer\n-  \/\/ Z_ARG4: jvalue object on the stack\n+  \/\/ obj        : object pointer copied above\n+  \/\/ fieldEntry : cache entry pointer\n+  \/\/ value      : jvalue object on the stack\n@@ -3208,1 +3317,1 @@\n-             obj, Z_ARG3, Z_ARG4);\n+             obj, fieldEntry, value);\n@@ -3234,1 +3343,1 @@\n-  __ bind(exit);\n+  __ bind(dontPost);\n@@ -3241,1 +3350,0 @@\n-  ByteSize base = ConstantPoolCache::base_offset();\n@@ -3245,3 +3353,5 @@\n-  Register cache = Z_tmp_1;\n-  Register index = Z_tmp_2;\n-  Register flags = Z_ARG5;\n+  Register obj       = Z_tmp_1;\n+  Register cache     = Z_tmp_1;\n+  Register index     = Z_tmp_2;\n+  Register off       = Z_tmp_2;\n+  Register flags     = Z_ARG5;\n@@ -3250,9 +3360,3 @@\n-  __ get_cache_and_index_at_bcp(cache, index, 1);\n-\n-  \/\/ Test for volatile.\n-  assert(!flags->is_volatile(), \"do_oop_store could perform leaf RT call\");\n-  __ z_lg(flags, Address(cache, index, base + ConstantPoolCacheEntry::flags_offset()));\n-\n-  \/\/ Replace index with field offset from cache entry.\n-  Register field_offset = index;\n-  __ z_lg(field_offset, Address(cache, index, base + ConstantPoolCacheEntry::f2_offset()));\n+  __ load_field_entry(cache, index);\n+  \/\/ this call is for nonstatic. obj remains unchanged.\n+  load_resolved_field_entry(obj, cache, noreg, off, flags, false);\n@@ -3261,2 +3365,0 @@\n-  Register   obj = cache;\n-\n@@ -3266,1 +3368,1 @@\n-  const Address   field(obj, field_offset);\n+  const Address field(obj, off);\n@@ -3271,1 +3373,1 @@\n-      do_oop_store(_masm, Address(obj, field_offset), Z_tos,\n+      do_oop_store(_masm, field, Z_tos,\n@@ -3304,1 +3406,1 @@\n-  __ testbit(flags, ConstantPoolCacheEntry::is_volatile_shift);\n+  __ testbit(flags, ResolvedFieldEntry::is_volatile_shift);\n@@ -3314,1 +3416,1 @@\n-  Register obj = Z_tos;\n+  Register obj = Z_tos;  \/\/ Object ptr is in TOS\n@@ -3316,1 +3418,1 @@\n-  \/\/ Do the JVMTI work here to avoid disturbing the register state below\n+  \/\/ Do the JVMTI work here. There is no specific jvmti_post_fast_access() emitter.\n@@ -3318,3 +3420,6 @@\n-    \/\/ Check to see if a field access watch has been set before we\n-    \/\/ take the time to call into the VM.\n-    Label cont;\n+    \/\/ Check to see if a field modification watch has been set\n+    \/\/ before we take the time to call into the VM.\n+    BLOCK_COMMENT(\"jvmti_post_fast_field_access {\");\n+    Label    dontPost;\n+    Register cache = Z_ARG3;\n+    Register index = Z_tmp_2;\n@@ -3322,4 +3427,3 @@\n-    __ load_absolute_address(Z_R1_scratch,\n-                             (address)JvmtiExport::get_field_access_count_addr());\n-    __ load_and_test_int(Z_R0_scratch, Address(Z_R1_scratch));\n-    __ z_brz(cont);\n+    __ load_absolute_address(Z_R1_scratch, (address)JvmtiExport::get_field_access_count_addr());\n+    __ z_chsi(0, Z_R1_scratch, 0); \/\/ avoid loading data into a scratch register\n+    __ z_bre(dontPost);\n@@ -3328,0 +3432,1 @@\n+    __ load_field_entry(cache, index);\n@@ -3329,1 +3434,0 @@\n-    __ get_cache_entry_pointer_at_bcp(Z_ARG3, Z_tmp_1, 1);\n@@ -3335,1 +3439,1 @@\n-    \/\/ Z_ARG3: cache entry pointer\n+    \/\/ cache: cache entry pointer\n@@ -3338,1 +3442,1 @@\n-               Z_ARG2, Z_ARG3);\n+               Z_ARG2, cache);\n@@ -3341,1 +3445,2 @@\n-    __ bind(cont);\n+    __ bind(dontPost);\n+    BLOCK_COMMENT(\"} jvmti_post_fast_field_access\");\n@@ -3345,2 +3450,3 @@\n-  Register   cache = Z_tmp_1;\n-  Register   index = Z_tmp_2;\n+  Register cache = Z_tmp_1;\n+  Register index = Z_tmp_2;\n+  Register off   = Z_tmp_2;\n@@ -3349,1 +3455,1 @@\n-  __ get_cache_and_index_at_bcp(cache, index, 1);\n+  __ load_field_entry(cache, index);\n@@ -3351,3 +3457,1 @@\n-  __ mem2reg_opt(index,\n-                 Address(cache, index,\n-                         ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f2_offset()));\n+  __ load_sized_value(off, Address(cache, in_bytes(ResolvedFieldEntry::field_offset_offset())), sizeof(jint), true);\n@@ -3358,1 +3462,1 @@\n-  Address field(obj, index);\n+  Address field(obj, off);\n@@ -3402,0 +3506,1 @@\n+  Register off   = Z_tmp_2;\n@@ -3404,1 +3509,1 @@\n-  __ get_cache_and_index_at_bcp(cache, index, 2);\n+  __ load_field_entry(cache, index, 2);\n@@ -3406,3 +3511,1 @@\n-  __ mem2reg_opt(index,\n-                 Address(cache, index,\n-                         ConstantPoolCache::base_offset() + ConstantPoolCacheEntry::f2_offset()));\n+  __ load_sized_value(off, Address(cache, in_bytes(ResolvedFieldEntry::field_offset_offset())), sizeof(jint), true);\n@@ -3414,0 +3517,3 @@\n+\n+  Address field(receiver, off);\n+\n@@ -3416,1 +3522,1 @@\n-      __ mem2reg_opt(Z_tos, Address(receiver, index), false);\n+      __ mem2reg_opt(Z_tos, field, false);\n@@ -3419,1 +3525,1 @@\n-      do_oop_load(_masm, Address(receiver, index), Z_tos, Z_tmp_1, Z_tmp_2, IN_HEAP);\n+      do_oop_load(_masm, field, Z_tos, Z_tmp_1, Z_tmp_2, IN_HEAP);\n@@ -3423,1 +3529,1 @@\n-      __ mem2freg_opt(Z_ftos, Address(receiver, index));\n+      __ mem2freg_opt(Z_ftos, field);\n","filename":"src\/hotspot\/cpu\/s390\/templateTable_s390.cpp","additions":368,"deletions":262,"binary":false,"changes":630,"status":"modified"}]}