{"files":[{"patch":"@@ -1929,1 +1929,1 @@\n-  if (C->max_vector_size() >= 16) {\n+  if (C->max_vector_size() > 0) {\n@@ -2415,1 +2415,1 @@\n-  if (!match_rule_supported(opcode) || !vector_size_supported(bt, vlen)) {\n+  if (!match_rule_supported(opcode)) {\n@@ -2423,1 +2423,1 @@\n-    return op_sve_supported(opcode);\n+    return op_sve_supported(opcode, vlen, bt);\n@@ -2465,0 +2465,3 @@\n+    case Op_LoadVectorGather:\n+    case Op_StoreVectorScatter:\n+      return false;\n@@ -2469,1 +2472,1 @@\n-  return true; \/\/ Per default match rules are supported.\n+  return vector_size_supported(bt, vlen);\n@@ -2515,0 +2518,1 @@\n+\n@@ -2517,15 +2521,8 @@\n-  if ((UseSVE > 0) && (MaxVectorSize >= 16)) {\n-    \/\/ Currently vector length less than SVE vector register size is not supported.\n-    return max_size;\n-  } else { \/\/ NEON\n-    \/\/ Limit the vector size to 8 bytes\n-    int size = 8 \/ type2aelembytes(bt);\n-    if (bt == T_BYTE) {\n-      \/\/ To support vector api shuffle\/rearrange.\n-      size = 4;\n-    } else if (bt == T_BOOLEAN) {\n-      \/\/ To support vector api load\/store mask.\n-      size = 2;\n-    }\n-    if (size < 2) size = 2;\n-    return MIN2(size,max_size);\n+  \/\/ Limit the min vector size to 8 bytes.\n+  int size = 8 \/ type2aelembytes(bt);\n+  if (bt == T_BYTE) {\n+    \/\/ To support vector api shuffle\/rearrange.\n+    size = 4;\n+  } else if (bt == T_BOOLEAN) {\n+    \/\/ To support vector api load\/store mask.\n+    size = 2;\n@@ -2533,0 +2530,2 @@\n+  if (size < 2) size = 2;\n+  return MIN2(size, max_size);\n@@ -2542,1 +2541,1 @@\n-  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+  if (UseSVE > 0 && 2 <= len && len <= 256) {\n@@ -3740,1 +3739,1 @@\n-    if (Compile::current()->max_vector_size() >= 16 && uncommon_trap_request() == 0) {\n+    if (Compile::current()->max_vector_size() > 0 && uncommon_trap_request() == 0) {\n@@ -3752,1 +3751,1 @@\n-    } else if (Compile::current()->max_vector_size() >= 16) {\n+    } else if (Compile::current()->max_vector_size() > 0) {\n@@ -3790,1 +3789,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -3803,1 +3802,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -4176,0 +4175,10 @@\n+operand immI_gt_1()\n+%{\n+  predicate(n->get_int() > 1);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":33,"deletions":24,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 2);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 2);\n@@ -47,1 +47,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 4);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 4);\n@@ -58,1 +58,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 8);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 8);\n@@ -2476,3 +2476,4 @@\n-  predicate((n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n-             n->as_Vector()->length() == 8) &&\n-             n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  predicate(UseSVE == 0 &&\n+           (n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n+            n->as_Vector()->length() == 8) &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n@@ -2491,1 +2492,1 @@\n-  predicate(n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n@@ -2948,2 +2949,2 @@\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 8 ||\n+                            n->as_Vector()->length() == 4));\n@@ -2973,2 +2974,2 @@\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 8 ||\n+                            n->as_Vector()->length() == 4));\n@@ -2998,2 +2999,2 @@\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 4 ||\n+                            n->as_Vector()->length() == 2));\n@@ -3023,2 +3024,2 @@\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 4 ||\n+                            n->as_Vector()->length() == 2));\n@@ -3048,1 +3049,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -3072,1 +3073,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -3122,1 +3123,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -4252,2 +4253,2 @@\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length_in_bytes() == 4 ||\n+            n->as_Vector()->length_in_bytes() == 8));\n@@ -4264,1 +4265,1 @@\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length_in_bytes() == 16));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":22,"deletions":21,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -72,3 +72,3 @@\n-VLoadStore(ldrh, H, load,  2,  D, 16,  dst, )\n-VLoadStore(ldrs, S, load,  4,  D, 32,  dst, )\n-VLoadStore(ldrd, D, load,  8,  D, 64,  dst, )\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst, UseSVE == 0 && )\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst, UseSVE == 0 && )\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst, UseSVE == 0 && )\n@@ -1199,4 +1199,5 @@\n-`predicate((n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n-             n->as_Vector()->length() == 8) &&\n-             n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);',\n-`predicate(n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);')')dnl\n+`predicate(UseSVE == 0 &&\n+           (n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n+            n->as_Vector()->length() == 8) &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);',\n+`predicate(UseSVE == 0 && n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);')')dnl\n@@ -1469,3 +1470,4 @@\n-  predicate(ifelse($8, UseSVE == 0 && , $8,\n-                   $8, , , $8`\n-            ')n->as_Vector()->length() == $3);\n+  predicate(UseSVE == 0 && ifelse($8, `',\n+                                  n->as_Vector()->length() == $3,\n+                                  (n->as_Vector()->length() == $3 ||`\n+                            'n->as_Vector()->length() == $8)));\n@@ -1497,18 +1499,18 @@\n-dnl        $1    $2    $3  $4 $5     $6 $7          $8                                $9\n-VREPLICATE(dup,  dup,  8,  B, ,      D, iRegIorL2I, n->as_Vector()->length() == 4 ||, B)\n-VREPLICATE(dup,  dup,  16, B, ,      X, iRegIorL2I, UseSVE == 0 && ,                  B)\n-VREPLICATE(movi, mov,  8,  B, _imm,  D, immI,       n->as_Vector()->length() == 4 ||, B)\n-VREPLICATE(movi, mov,  16, B, _imm,  X, immI,       UseSVE == 0 && ,                  B)\n-VREPLICATE(dup,  dup,  4,  S, ,      D, iRegIorL2I, n->as_Vector()->length() == 2 ||, H)\n-VREPLICATE(dup,  dup,  8,  S, ,      X, iRegIorL2I, UseSVE == 0 && ,                  H)\n-VREPLICATE(movi, mov,  4,  S, _imm,  D, immI,       n->as_Vector()->length() == 2 ||, H)\n-VREPLICATE(movi, mov,  8,  S,  _imm, X, immI,       UseSVE == 0 && ,                  H)\n-VREPLICATE(dup,  dup,  2,  I, ,      D, iRegIorL2I, ,                                 S)\n-VREPLICATE(dup,  dup,  4,  I, ,      X, iRegIorL2I, UseSVE == 0 && ,                  S)\n-VREPLICATE(movi, mov,  2,  I, _imm,  D, immI,       ,                                 S)\n-VREPLICATE(movi, mov,  4,  I,  _imm, X, immI,       UseSVE == 0 && ,                  S)\n-VREPLICATE(dup,  dup,  2,  L, ,      X, iRegL,      UseSVE == 0 && ,                  D)\n-VREPLICATE(movi, eor,  2,  L, _zero, X, immI0,      UseSVE == 0 && ,                  D)\n-VREPLICATE(dup,  dup,  2,  F, ,      D, vRegF,      ,                                 S)\n-VREPLICATE(dup,  dup,  4,  F, ,      X, vRegF,      UseSVE == 0 && ,                  S)\n-VREPLICATE(dup,  dup,  2,  D, ,      X, vRegD,      UseSVE == 0 && ,                  D)\n+dnl        $1    $2    $3  $4 $5     $6 $7          $8 $9\n+VREPLICATE(dup,  dup,  8,  B, ,      D, iRegIorL2I, 4, B)\n+VREPLICATE(dup,  dup,  16, B, ,      X, iRegIorL2I,  , B)\n+VREPLICATE(movi, mov,  8,  B, _imm,  D, immI,       4, B)\n+VREPLICATE(movi, mov,  16, B, _imm,  X, immI,        , B)\n+VREPLICATE(dup,  dup,  4,  S, ,      D, iRegIorL2I, 2, H)\n+VREPLICATE(dup,  dup,  8,  S, ,      X, iRegIorL2I,  , H)\n+VREPLICATE(movi, mov,  4,  S, _imm,  D, immI,       2, H)\n+VREPLICATE(movi, mov,  8,  S,  _imm, X, immI,        , H)\n+VREPLICATE(dup,  dup,  2,  I, ,      D, iRegIorL2I, ,  S)\n+VREPLICATE(dup,  dup,  4,  I, ,      X, iRegIorL2I, ,  S)\n+VREPLICATE(movi, mov,  2,  I, _imm,  D, immI,       ,  S)\n+VREPLICATE(movi, mov,  4,  I,  _imm, X, immI,       ,  S)\n+VREPLICATE(dup,  dup,  2,  L, ,      X, iRegL,      ,  D)\n+VREPLICATE(movi, eor,  2,  L, _zero, X, immI0,      ,  D)\n+VREPLICATE(dup,  dup,  2,  F, ,      D, vRegF,      ,  S)\n+VREPLICATE(dup,  dup,  4,  F, ,      X, vRegF,      ,  S)\n+VREPLICATE(dup,  dup,  2,  D, ,      X, vRegD,      ,  D)\n@@ -1887,2 +1889,2 @@\n-  predicate(ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n-            ')n->as_Vector()->length_in_bytes() == $3);\n+  predicate(UseSVE == 0 && (ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n+            ')n->as_Vector()->length_in_bytes() == $3));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":32,"deletions":30,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -46,0 +47,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -60,1 +62,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -74,1 +76,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -83,0 +85,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -86,1 +90,1 @@\n-  bool op_sve_supported(int opcode);\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -90,15 +94,4 @@\n-  static Assembler::SIMD_RegVariant elemBytes_to_regVariant(int esize) {\n-    switch(esize) {\n-      case 1:\n-        return Assembler::B;\n-      case 2:\n-        return Assembler::H;\n-      case 4:\n-        return Assembler::S;\n-      case 8:\n-        return Assembler::D;\n-      default:\n-        assert(false, \"unsupported\");\n-        ShouldNotReachHere();\n-    }\n-    return Assembler::INVALID;\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n@@ -107,2 +100,5 @@\n-  static Assembler::SIMD_RegVariant elemType_to_regVariant(BasicType bt) {\n-    return elemBytes_to_regVariant(type2aelembytes(bt));\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n@@ -115,3 +111,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n-                                   int opcode, Register base, int index, int size, int disp) {\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n@@ -119,2 +115,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int mesize = type2aelembytes(mem_elem_bt);\n@@ -123,1 +118,1 @@\n-      switch(esize) {\n+      switch(mesize) {\n@@ -126,1 +121,0 @@\n-        type = Assembler::B;\n@@ -130,1 +124,0 @@\n-        type = Assembler::H;\n@@ -134,1 +127,0 @@\n-        type = Assembler::S;\n@@ -138,1 +130,0 @@\n-        type = Assembler::D;\n@@ -144,1 +135,2 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, Assembler::elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n@@ -151,1 +143,2 @@\n-  bool op_sve_supported(int opcode) {\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt) {\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n@@ -154,1 +147,1 @@\n-        \/\/ No multiply reduction instructions\n+      \/\/ No multiply reduction instructions\n@@ -159,3 +152,1 @@\n-        \/\/ Others\n-      case Op_Extract:\n-      case Op_ExtractB:\n+      \/\/ Others\n@@ -163,5 +154,0 @@\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -169,0 +155,1 @@\n+        return false;\n@@ -170,18 +157,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n-      case Op_LoadVectorGather:\n-      case Op_StoreVectorScatter:\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadConst:\n-      case Op_VectorLoadMask:\n@@ -189,1 +158,0 @@\n-      case Op_VectorMaskCmp:\n@@ -191,7 +159,8 @@\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n-      case Op_VectorMaskTrueCount:\n-      case Op_VectorMaskLastTrue:\n-      case Op_VectorMaskFirstTrue:\n-        return false;\n+        if (vlen < 4 || length_in_bytes > MaxVectorSize) {\n+          return false;\n+        } else {\n+          return true;\n+        }\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        return Matcher::vector_size_supported(bt, vlen);\n@@ -199,1 +168,1 @@\n-        return true;\n+        break;\n@@ -201,0 +170,2 @@\n+    \/\/ By default, we only support vector operations with no less than 8 bytes and 2 elements.\n+    return 8 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;\n@@ -213,1 +184,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -215,1 +186,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -217,2 +189,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_ldr $dst, $mem\\t # vector (sve)\" %}\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_ldr $dst, $mem\\t# vector (sve)\" %}\n@@ -221,3 +193,4 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         vector_element_basic_type(this), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    BasicType bt = vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -229,1 +202,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -231,2 +205,131 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_str $mem, $src\\t # vector (sve)\" %}\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_str $mem, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (16 bits)\n+instruct loadV2_vreg(vReg dst, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 2);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrh   $dst,$mem\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvH(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (16 bits)\n+instruct storeV2_vreg(vReg src, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 2);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strh   $mem,$src\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_strvH(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (32 bits)\n+instruct loadV4_vreg(vReg dst, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 4);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (32 bits)\n+instruct storeV4_vreg(vReg src, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 4);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8_vreg(vReg dst, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 8);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8_vreg(vReg src, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 8);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16_vreg(vReg dst, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 16);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(vload_reg_mem128);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16_vreg(vReg src, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 16);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(vstore_reg_mem128);\n+%}\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t# load vector predicated\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ elemType_to_regVariant(bt), vector_length(this));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t# store vector predicated\" %}\n@@ -234,0 +337,2 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ elemType_to_regVariant(bt), vector_length(this, $src));\n@@ -235,3 +340,39 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \"# reinterpret $dst\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"reinterpretResize $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ B, length_in_bytes_resize);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n@@ -245,1 +386,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n+  predicate(UseSVE > 0 &&\n@@ -258,1 +399,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n+  predicate(UseSVE > 0 &&\n@@ -271,1 +412,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+  predicate(UseSVE > 0 &&\n@@ -284,1 +425,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+  predicate(UseSVE > 0 &&\n@@ -297,1 +438,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+  predicate(UseSVE > 0 &&\n@@ -310,1 +451,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+  predicate(UseSVE > 0 &&\n@@ -325,1 +466,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -338,1 +479,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -351,1 +492,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -364,1 +505,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -377,1 +518,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -390,1 +531,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -405,1 +546,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -420,1 +561,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -435,1 +576,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -450,1 +591,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -464,1 +605,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -479,1 +620,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -494,1 +635,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -510,1 +651,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -522,1 +663,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -536,1 +677,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -542,1 +683,1 @@\n-    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n@@ -556,1 +697,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -562,1 +703,1 @@\n-    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n@@ -579,1 +720,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -592,1 +733,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -608,1 +749,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -623,1 +764,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -640,1 +781,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -655,1 +796,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -671,1 +812,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -684,1 +825,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -700,1 +841,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -714,1 +855,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -728,1 +869,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -742,1 +883,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -758,1 +899,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -772,1 +913,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -786,1 +927,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -800,1 +941,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -815,1 +956,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -827,1 +968,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -839,1 +980,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -851,1 +992,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -863,1 +1004,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -876,1 +1017,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -891,1 +1032,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -903,1 +1044,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -917,1 +1058,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -919,1 +1060,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -926,1 +1067,1 @@\n-\/\/ vector add reduction\n+\/\/ vector mask compare\n@@ -928,10 +1069,7 @@\n-instruct reduce_addB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n-  match(Set dst (AddReductionVI src1 src2));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_uaddv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n-            \"smov  $dst, $tmp, B, 0\\n\\t\"\n-            \"addw  $dst, $dst, $src1\\n\\t\"\n-            \"sxtb  $dst, $dst\\t # add reduction B\" %}\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t# vector mask cmp (sve)\" %}\n@@ -939,5 +1077,5 @@\n-    __ sve_uaddv(as_FloatRegister($tmp$$reg), __ B,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    __ sxtb($dst$$Register, $dst$$Register);\n+    BasicType bt = vector_element_basic_type(this);\n+    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n+                   as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n@@ -948,10 +1086,9 @@\n-instruct reduce_addS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n-  match(Set dst (AddReductionVI src1 src2));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_uaddv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n-            \"smov  $dst, $tmp, H, 0\\n\\t\"\n-            \"addw  $dst, $dst, $src1\\n\\t\"\n-            \"sxth  $dst, $dst\\t # add reduction H\" %}\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n@@ -959,5 +1096,6 @@\n-    __ sve_uaddv(as_FloatRegister($tmp$$reg), __ H,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    __ sxth($dst$$Register, $dst$$Register);\n+    Assembler::SIMD_RegVariant size =\n+      __ elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               ptrue, as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n@@ -968,9 +1106,10 @@\n-instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n-  match(Set dst (AddReductionVI src1 src2));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_uaddv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n-            \"umov  $dst, $tmp, S, 0\\n\\t\"\n-            \"addw  $dst, $dst, $src1\\t # add reduction S\" %}\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t# vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n@@ -978,4 +1117,6 @@\n-    __ sve_uaddv(as_FloatRegister($tmp$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    BasicType bt = vector_element_basic_type(this);\n+    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src3$$reg),\n+                   as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n@@ -986,5 +1127,6 @@\n-instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (AddReductionVL src1 src2));\n-  effect(TEMP_DEF dst, TEMP tmp);\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n@@ -992,3 +1134,1 @@\n-  format %{ \"sve_uaddv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n-            \"umov  $dst, $tmp, D, 0\\n\\t\"\n-            \"add  $dst, $dst, $src1\\t # add reduction D\" %}\n+  format %{ \"sve_neg $dst, $src\\t# vector load mask (B)\" %}\n@@ -996,4 +1136,1 @@\n-    __ sve_uaddv(as_FloatRegister($tmp$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n-    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n@@ -1004,5 +1141,7 @@\n-instruct reduce_addF(vRegF src1_dst, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set src1_dst (AddReductionVF src1_dst src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (S)\" %}\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# vector load mask (B to H)\" %}\n@@ -1010,2 +1149,2 @@\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n@@ -1016,5 +1155,9 @@\n-instruct reduce_addD(vRegD src1_dst, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set src1_dst (AddReductionVD src1_dst src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (D)\" %}\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# vector load mask (B to S)\" %}\n@@ -1022,2 +1165,3 @@\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n@@ -1028,10 +1172,10 @@\n-\/\/ vector max reduction\n-\n-instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# vector load mask (B to D)\" %}\n@@ -1039,3 +1183,4 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n@@ -1046,8 +1191,7 @@\n-instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t# vector store mask (B)\" %}\n@@ -1055,3 +1199,2 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n@@ -1062,10 +1205,8 @@\n-\/\/ vector min reduction\n-\n-instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (H to B)\" %}\n@@ -1073,3 +1214,6 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n@@ -1080,8 +1224,9 @@\n-instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (S to B)\" %}\n@@ -1089,3 +1234,7 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n@@ -1096,7 +1245,10 @@\n-\/\/ vector Math.rint, floor, ceil\n-\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n+            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (D to B)\" %}\n@@ -1104,14 +1256,9 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-    }\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n@@ -1122,1 +1269,1 @@\n-\/\/ vector replicate\n+\/\/ load\/store mask vector\n@@ -1124,5 +1271,7 @@\n-instruct replicateB(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB src));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+instruct vloadmask_loadV_byte(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# load vector mask (sve)\" %}\n@@ -1130,1 +1279,7 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n@@ -1135,5 +1290,7 @@\n-instruct replicateS(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS src));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+instruct vloadmask_loadV_non_byte(vReg dst, indirect mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# load vector mask (sve)\" %}\n@@ -1141,1 +1298,7 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n@@ -1146,5 +1309,8 @@\n-instruct replicateI(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI src));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+instruct storeV_vstoremask_byte(vmemA mem, vReg src, vReg tmp, immI_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t# store vector mask (sve)\" %}\n@@ -1152,1 +1318,8 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1157,5 +1330,8 @@\n-instruct replicateL(vReg dst, iRegL src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL src));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n+instruct storeV_vstoremask_non_byte(indirect mem, vReg src, vReg tmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t# store vector mask (sve)\" %}\n@@ -1163,1 +1339,8 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -1168,3 +1351,6 @@\n-instruct replicateB_imm8(vReg dst, immI8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB con));\n+\/\/ vector add reduction\n+\n+instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1172,1 +1358,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addB\/S\/I reduction (sve) (may extend)\" %}\n@@ -1174,1 +1360,12 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1179,3 +1376,5 @@\n-instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS con));\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1183,1 +1382,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n@@ -1185,1 +1384,14 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1190,3 +1402,4 @@\n-instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI con));\n+instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1194,1 +1407,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction (sve)\" %}\n@@ -1196,1 +1409,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1201,3 +1416,5 @@\n-instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL con));\n+instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1205,1 +1422,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n@@ -1207,1 +1424,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1212,3 +1433,4 @@\n-instruct replicateF(vReg dst, vRegF src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateF src));\n+\n+instruct reduce_addF(vRegF src1_dst, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF src1_dst src2));\n@@ -1216,1 +1438,1 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (S)\" %}\n@@ -1218,2 +1440,2 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n@@ -1224,3 +1446,3 @@\n-instruct replicateD(vReg dst, vRegD src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateD src));\n+instruct reduce_addF_partial(vRegF src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF src1_dst src2));\n@@ -1228,1 +1450,2 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_addF $src1_dst, $src1_dst, $src2\\t# addF reduction partial (sve) (S)\" %}\n@@ -1230,2 +1453,3 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S, vector_length(this, $src2));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1236,5 +1460,3 @@\n-\/\/ vector shift\n-\n-instruct vasrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB dst shift));\n+instruct reduce_addD(vRegD src1_dst, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD src1_dst src2));\n@@ -1242,1 +1464,1 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) (D)\" %}\n@@ -1244,2 +1466,2 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n@@ -1250,3 +1472,3 @@\n-instruct vasrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS dst shift));\n+instruct reduce_addD_partial(vRegD src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD src1_dst src2));\n@@ -1254,1 +1476,2 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_addD $src1_dst, $src1_dst, $src2\\t# addD reduction partial (sve) (D)\" %}\n@@ -1256,2 +1479,3 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1262,3 +1486,7 @@\n-instruct vasrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI dst shift));\n+\/\/ vector and reduction\n+\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1266,1 +1494,1 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andB\/S\/I reduction (sve) (may extend)\" %}\n@@ -1268,2 +1496,12 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1274,3 +1512,6 @@\n-instruct vasrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL dst shift));\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1278,1 +1519,1 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n@@ -1280,2 +1521,14 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1286,3 +1539,5 @@\n-instruct vlslB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB dst shift));\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1290,1 +1545,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction (sve)\" %}\n@@ -1292,2 +1547,3 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1298,3 +1554,6 @@\n-instruct vlslS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS dst shift));\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1302,1 +1561,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n@@ -1304,2 +1563,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1310,3 +1572,7 @@\n-instruct vlslI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI dst shift));\n+\/\/ vector or reduction\n+\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1314,1 +1580,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orB\/S\/I reduction (sve) (may extend)\" %}\n@@ -1316,2 +1582,12 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1322,3 +1598,6 @@\n-instruct vlslL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL dst shift));\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1326,1 +1605,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n@@ -1328,2 +1607,14 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1334,3 +1625,5 @@\n-instruct vlsrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB dst shift));\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1338,1 +1631,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction (sve)\" %}\n@@ -1340,2 +1633,3 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1346,3 +1640,6 @@\n-instruct vlsrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS dst shift));\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1350,1 +1647,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n@@ -1352,2 +1649,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1358,3 +1658,7 @@\n-instruct vlsrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI dst shift));\n+\/\/ vector xor reduction\n+\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1362,1 +1666,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorB\/H\/I reduction (sve) (may extend)\" %}\n@@ -1364,2 +1668,12 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1370,3 +1684,6 @@\n-instruct vlsrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL dst shift));\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1374,1 +1691,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n@@ -1376,2 +1693,14 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n@@ -1382,3 +1711,5 @@\n-instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1386,1 +1717,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction (sve)\" %}\n@@ -1388,9 +1719,3 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) con = 7;\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1401,3 +1726,6 @@\n-instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1405,1 +1733,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n@@ -1407,9 +1735,5 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) con = 15;\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1420,3 +1744,10 @@\n-instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+\n+\/\/ vector max reduction\n+\n+instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1424,1 +1755,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# reduce maxB\/S\/I (sve)\" %}\n@@ -1426,8 +1757,6 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1438,3 +1767,8 @@\n-instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+instruct reduce_maxI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1442,1 +1776,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# reduce maxI partial (sve)\" %}\n@@ -1444,8 +1778,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1456,3 +1790,5 @@\n-instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -1460,1 +1796,1 @@\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# reduce maxL partial (sve)\" %}\n@@ -1462,13 +1798,4 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1479,3 +1806,6 @@\n-instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+instruct reduce_maxL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1483,1 +1813,1 @@\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# reduce maxL partial (sve)\" %}\n@@ -1485,13 +1815,1472 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t# max reduction F\" %}\n+  ins_encode %{\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxF_partial(vRegF dst, vRegF src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# reduce max S partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S, vector_length(this, $src2));\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t# max reduction D\" %}\n+  ins_encode %{\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxD_partial(vRegD dst, vRegD src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# reduce max D partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector min reduction\n+\n+instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# reduce minB\/S\/I (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# reduce minI partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# reduce minL partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# reduce minL partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t# min reduction F\" %}\n+  ins_encode %{\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF_partial(vRegF dst, vRegF src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# reduce min S partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ S, vector_length(this, $src2));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t# min reduction D\" %}\n+  ins_encode %{\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD_partial(vRegD dst, vRegD src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# reduce min D partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector replicate\n+\n+instruct replicateB(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateB src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateS src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateI src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL(vReg dst, iRegL src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateL src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateB_imm8(vReg dst, immI8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateB con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateS con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateI con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateL con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateF(vReg dst, vRegF src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateD(vReg dst, vRegD src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift\n+\n+instruct vasrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) con = 7;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) con = 15;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sqrt\n+\n+instruct vsqrtF(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SqrtVF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SqrtVD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sub\n+\n+instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVB src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVS src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVI src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVL src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVF src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVD src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask cast\n+\n+instruct vmaskcast(vReg dst) %{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst (VectorMaskCast dst));\n+  ins_cost(0);\n+  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+\/\/ ------------------------------ Vector cast -------------------------------\n+\n+instruct vcvtBtoS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\t# convert B to S vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\t# convert B to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert B to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert B to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert B to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, B, 0\\n\\t\"\n+            \"sve_uzp1  $dst, B, $src, tmp\\t# convert S to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\t# convert S to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert S to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert S to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert S to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert I to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\t# convert I to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\t# convert I to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, S\\t# convert I to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert I to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert L to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert L to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\t# convert L to I vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert L to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastL2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, D, $src, D\\t# convert L to D vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert F to B vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\t# convert F to S vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\t# convert F to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert F to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_fcvt  $dst, D, $dst, S\\t# convert F to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert D to B vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert D to S vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\t# convert D to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\t# convert D to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvt  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert D to F vector\" %}\n+  ins_encode %{\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+\n+instruct extractB(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractB src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, B, $pTmp, $src, $idx\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 7U\\t# extract from vector(B)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_Register($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 7U);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractS(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractS src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, H, $pTmp, $src, $idx\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 15U\\t# extract from vector(S)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_Register($dst$$reg), __ H, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct extractI(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractI src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, S, $pTmp, $src, $idx\\t# extract from vector(I)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_Register($dst$$reg), __ S, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractL(iRegLNoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractL src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, D, $pTmp, $src, $idx\\t# extract from vector(L)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_Register($dst$$reg), __ D, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractF(vRegF dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractF src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, S, $pTmp, $src, $idx\\t# extract from vector(F)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractD(vRegD dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractD src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, D, $pTmp, $src, $idx\\t# extract from vector(D)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_FloatRegister($dst$$reg), __ D, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n@@ -1502,3 +3291,8 @@\n-instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+\n+instruct vtest_alltrue(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1506,1 +3300,2 @@\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_cmpeq $pTmp, $src1, 0\\n\\t\"\n+            \"csetw $dst, EQ\\t# VectorTest (sve) - alltrue\" %}\n@@ -1508,8 +3303,6 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               ptrue, as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n@@ -1520,3 +3313,6 @@\n-instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+instruct vtest_anytrue(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1524,1 +3320,2 @@\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_cmpeq $pTmp, $src1, -1\\n\\t\"\n+            \"csetw $dst, NE\\t# VectorTest (sve) - anytrue\" %}\n@@ -1526,8 +3323,6 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               ptrue, as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -1538,3 +3333,6 @@\n-instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+instruct vtest_alltrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1542,1 +3340,1 @@\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"vtest_alltrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - alltrue\" %}\n@@ -1544,8 +3342,7 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size, vector_length(this, $src1));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n@@ -1556,3 +3353,6 @@\n-instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+instruct vtest_anytrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1560,1 +3360,1 @@\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"vtest_anytrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - anytrue\" %}\n@@ -1562,8 +3362,7 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size, vector_length(this, $src1));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -1574,5 +3373,38 @@\n-instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+\n+instruct insertI_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, -16, 1\\t# (B\/S\/I)\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B\/S\/I)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index(as_FloatRegister($dst$$reg), size, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertF_small(vReg dst, vReg src, vRegF val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, S, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n@@ -1580,3 +3412,5 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1587,5 +3421,38 @@\n-instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct insertI(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, 0, 1\\t# (B\/S\/I)\\n\\t\"\n+            \"sve_dup $dst, $idx\\t# (B\/S\/I)\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B\/S\/I)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index(as_FloatRegister($tmp1$$reg), size, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), size, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size, ptrue,\n+               as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertL(vReg dst, vReg src, iRegL val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, D, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (L)\" %}\n@@ -1593,3 +3460,5 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ D, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1600,6 +3469,11 @@\n-instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+instruct insertD(vReg dst, vReg src, vRegD val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, D, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (D)\" %}\n@@ -1607,1 +3481,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($dst$$reg), __ D, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ D, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1612,7 +3490,34 @@\n-instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+instruct insertF(vReg dst, vReg src, vRegF val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, S, 0, 1\\n\\t\"\n+            \"sve_dup $dst, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ S, ptrue,\n+               as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+\n+instruct loadshuffleB(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orr $dst, $src, $src\\t# vector load shuffle (B)\" %}\n@@ -1620,1 +3525,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+                 as_FloatRegister($src$$reg),\n+                 as_FloatRegister($src$$reg));\n+    }\n@@ -1625,6 +3534,6 @@\n-instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+instruct loadshuffleS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\t# vector load shuffle (B to H)\" %}\n@@ -1632,1 +3541,1 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n@@ -1637,6 +3546,9 @@\n-instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+instruct loadshuffleI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\t# vector load shuffle (B to S)\" %}\n@@ -1644,1 +3556,2 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n@@ -1649,1 +3562,17 @@\n-\/\/ vector sqrt\n+instruct loadshuffleL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\t# vector load shuffle (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -1651,3 +3580,6 @@\n-instruct vsqrtF(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVF src));\n+\/\/ ------------------------------ Vector rearrange -------------------------------\n+\n+instruct rearrange(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1655,1 +3587,1 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_tbl $dst, $src, $shuffle\\t# vector rearrange\" %}\n@@ -1657,2 +3589,4 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_tbl(as_FloatRegister($dst$$reg), size,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1663,3 +3597,8 @@\n-instruct vsqrtD(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVD src));\n+\/\/ ------------------------------ Vector Load Gather ---------------------------------\n+\n+instruct gatherI(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n@@ -1667,1 +3606,1 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n@@ -1669,2 +3608,1 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1675,1 +3613,15 @@\n-\/\/ vector sub\n+instruct gatherL(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -1677,5 +3629,12 @@\n-instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (SubVB src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+\/\/ ------------------------------ Vector Load Gather Partial-------------------------------\n+\n+instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (I\/F)\" %}\n@@ -1683,3 +3642,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S, vector_length(this));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1690,5 +3648,11 @@\n-instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (SubVS src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (L\/D)\" %}\n@@ -1696,3 +3660,3 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D, vector_length(this));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1703,3 +3667,8 @@\n-instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVI src1 src2));\n+\/\/ ------------------------------ Vector Store Scatter -------------------------------\n+\n+instruct scatterI(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n@@ -1707,1 +3676,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (I\/F)\" %}\n@@ -1709,3 +3678,1 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1716,5 +3683,9 @@\n-instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVL src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+instruct scatterL(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (L\/D)\" %}\n@@ -1722,3 +3693,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1729,5 +3699,12 @@\n-instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVF src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+\/\/ ------------------------------ Vector Store Scatter Partial-------------------------------\n+\n+instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (I\/F)\" %}\n@@ -1735,3 +3712,2 @@\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S, vector_length(this, $src));\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1742,5 +3718,11 @@\n-instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVD src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (L\/D)\" %}\n@@ -1748,3 +3730,3 @@\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D, vector_length(this, $src));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1755,1 +3737,0 @@\n-\/\/ vector mask cast\n@@ -1757,6 +3738,8 @@\n-instruct vmaskcast(vReg dst) %{\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n-            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n-  match(Set dst (VectorMaskCast dst));\n-  ins_cost(0);\n-  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+\/\/ ------------------------------ Vector Load Const -------------------------------\n+\n+instruct loadconB(vReg dst, immI0 src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadConst src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_index $dst, 0, 1\\t# generate iota indices\" %}\n@@ -1764,1 +3747,1 @@\n-    \/\/ empty\n+    __ sve_index(as_FloatRegister($dst$$reg), __ B, 0, 1);\n@@ -1766,1 +3749,1 @@\n-  ins_pipe(pipe_class_empty);\n+  ins_pipe(pipe_slow);\n@@ -1808,0 +3791,195 @@\n+\/\/ ---------------------------- Vector mask reductions ---------------------------\n+\n+instruct vmask_truecount(iRegINoSp dst, vReg src, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (VectorMaskTrueCount src));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"vmask_truecount $dst, $src\\t# vector mask truecount (sve)\" %}\n+  ins_encode %{\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B,\n+                           as_FloatRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue(iRegINoSp dst, vReg src, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (VectorMaskFirstTrue src));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"vmask_firsttrue $dst, $src\\t# vector mask firsttrue (sve)\" %}\n+  ins_encode %{\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B,\n+                           as_FloatRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_lasttrue(iRegINoSp dst, vReg src, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (VectorMaskLastTrue src));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"vmask_lasttrue $dst, $src\\t# vector mask lasttrue (sve)\" %}\n+  ins_encode %{\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B,\n+                           as_FloatRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_truecount_partial(iRegINoSp dst, vReg src, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (VectorMaskTrueCount src));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"vmask_truecount $dst, $src\\t# vector mask truecount partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ B, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B, as_FloatRegister($src$$reg),\n+                           as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_partial(iRegINoSp dst, vReg src, pRegGov pgtmp, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (VectorMaskFirstTrue src));\n+  effect(TEMP pgtmp, TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"vmask_firsttrue $dst, $src\\t# vector mask firsttrue partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($pgtmp$$reg), __ B, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B, as_FloatRegister($src$$reg),\n+                           as_PRegister($pgtmp$$reg), as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_lasttrue_partial(iRegINoSp dst, vReg src, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (VectorMaskLastTrue src));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"vmask_lasttrue $dst, $src\\t# vector mask lasttrue partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ B, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B, as_FloatRegister($src$$reg),\n+                           as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ----------------- Vector mask reductions combined with VectorMaskStore ---------------\n+\n+instruct vstoremask_truecount(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (VectorMaskTrueCount (VectorStoreMask src esize)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"vstoremask_truecount $dst, $src\\t# vector mask truecount (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           ptrue, as_PRegister($ptmp$$reg), vector_length(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_firsttrue(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (VectorMaskFirstTrue (VectorStoreMask src esize)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"vstoremask_firsttrue $dst, $src\\t# vector mask firsttrue (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           ptrue, as_PRegister($ptmp$$reg), vector_length(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_lasttrue(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (VectorMaskLastTrue (VectorStoreMask src esize)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"vstoremask_lasttrue $dst, $src\\t# vector mask lasttrue (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           ptrue, as_PRegister($ptmp$$reg), vector_length(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_truecount_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (VectorMaskTrueCount (VectorStoreMask src esize)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"vstoremask_truecount $dst, $src\\t# vector mask truecount partial (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_firsttrue_partial(iRegINoSp dst, vReg src, immI esize, pRegGov pgtmp, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (VectorMaskFirstTrue (VectorStoreMask src esize)));\n+  effect(TEMP pgtmp, TEMP ptmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"vstoremask_firsttrue $dst, $src\\t# vector mask firsttrue partial (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_whilelo_zr_imm(as_PRegister($pgtmp$$reg), variant, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           as_PRegister($pgtmp$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_lasttrue_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (VectorMaskLastTrue (VectorStoreMask src esize)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"vstoremask_lasttrue $dst, $src\\t# vector mask lasttrue partial (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":2827,"deletions":649,"binary":false,"changes":3476,"status":"modified"},{"patch":"@@ -32,2 +32,0 @@\n-\n-\/\/ 4 bit signed offset -- for predicated load\/store\n@@ -35,2 +33,11 @@\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3     )\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len)\n+define(`TYPE2DATATYPE',\n+`ifelse($1, `B', `BYTE',\n+        $1, `S', `SHORT',\n+        $1, `I', `INT',\n+        $1, `L', `LONG',\n+        $1, `F', `FLOAT',\n+        $1, `D', `DOUBLE',\n+        `error($1)')')dnl\n+dnl\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3       $4   )\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len, scale)\n@@ -40,0 +47,1 @@\n+  \/\/ (esize \/ msize) = $4\n@@ -41,1 +49,1 @@\n-            Matcher::scalable_vector_reg_size(T_BYTE)));\n+            Matcher::scalable_vector_reg_size(T_BYTE)ifelse($4, `1', `', ` \/ $4')));\n@@ -48,2 +56,4 @@\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4)\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4)\n+\n+\/\/ 4 bit signed offset -- for predicated load\/store\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4, 1)\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4, 1)\n@@ -54,1 +64,1 @@\n-operand vmemA_indOff$1$2(iRegP reg, vmemA_imm$1Offset$2 off)\n+operand vmemA_indOff$1$2$3(iRegP reg, vmemA_imm$1Offset$2 off)\n@@ -59,1 +69,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -70,0 +80,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -73,1 +85,1 @@\n-  bool op_sve_supported(int opcode);\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -77,15 +89,4 @@\n-  static Assembler::SIMD_RegVariant elemBytes_to_regVariant(int esize) {\n-    switch(esize) {\n-      case 1:\n-        return Assembler::B;\n-      case 2:\n-        return Assembler::H;\n-      case 4:\n-        return Assembler::S;\n-      case 8:\n-        return Assembler::D;\n-      default:\n-        assert(false, \"unsupported\");\n-        ShouldNotReachHere();\n-    }\n-    return Assembler::INVALID;\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n@@ -94,2 +95,5 @@\n-  static Assembler::SIMD_RegVariant elemType_to_regVariant(BasicType bt) {\n-    return elemBytes_to_regVariant(type2aelembytes(bt));\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n@@ -102,3 +106,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n-                                   int opcode, Register base, int index, int size, int disp) {\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n@@ -106,2 +110,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int mesize = type2aelembytes(mem_elem_bt);\n@@ -110,1 +113,1 @@\n-      switch(esize) {\n+      switch(mesize) {\n@@ -113,1 +116,0 @@\n-        type = Assembler::B;\n@@ -117,1 +119,0 @@\n-        type = Assembler::H;\n@@ -121,1 +122,0 @@\n-        type = Assembler::S;\n@@ -125,1 +125,0 @@\n-        type = Assembler::D;\n@@ -131,1 +130,2 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, Assembler::elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n@@ -138,1 +138,2 @@\n-  bool op_sve_supported(int opcode) {\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt) {\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n@@ -141,1 +142,1 @@\n-        \/\/ No multiply reduction instructions\n+      \/\/ No multiply reduction instructions\n@@ -146,3 +147,1 @@\n-        \/\/ Others\n-      case Op_Extract:\n-      case Op_ExtractB:\n+      \/\/ Others\n@@ -150,5 +149,0 @@\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -156,0 +150,1 @@\n+        return false;\n@@ -157,18 +152,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n-      case Op_LoadVectorGather:\n-      case Op_StoreVectorScatter:\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadConst:\n-      case Op_VectorLoadMask:\n@@ -176,1 +153,0 @@\n-      case Op_VectorMaskCmp:\n@@ -178,7 +154,8 @@\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n-      case Op_VectorMaskTrueCount:\n-      case Op_VectorMaskLastTrue:\n-      case Op_VectorMaskFirstTrue:\n-        return false;\n+        if (vlen < 4 || length_in_bytes > MaxVectorSize) {\n+          return false;\n+        } else {\n+          return true;\n+        }\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        return Matcher::vector_size_supported(bt, vlen);\n@@ -186,1 +163,1 @@\n-        return true;\n+        break;\n@@ -188,0 +165,2 @@\n+    \/\/ By default, we only support vector operations with no less than 8 bytes and 2 elements.\n+    return 8 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;\n@@ -208,1 +187,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -210,1 +189,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -212,2 +192,2 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_ldr $dst, $mem\\t # vector (sve)\" %}\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_ldr $dst, $mem\\t# vector (sve)\" %}\n@@ -216,3 +196,4 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         vector_element_basic_type(this), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    BasicType bt = vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -224,1 +205,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -226,2 +208,65 @@\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_str $mem, $src\\t # vector (sve)\" %}\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_str $mem, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n+\n+dnl\n+define(`VLoadStore', `\n+\/\/ ifelse(load, $3, Load, Store) Vector ($6 bits)\n+instruct $3V$4_vreg`'(vReg $7, vmem$4 mem)\n+%{\n+  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4);\n+  match(Set ifelse(load, $3, dst (LoadVector mem), mem (StoreVector mem src)));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"$1   ifelse(load, $3, `$dst,$mem', `$mem,$src')\\t# vector ($6 bits)\" %}\n+  ins_encode( `aarch64_enc_'ifelse(load, $3, ldr, str)v$2($7, mem) );\n+  ins_pipe(v$3`_reg_mem'ifelse(eval($4 * 8), 128, 128, 64));\n+%}')dnl\n+dnl        $1    $2 $3     $4  $5 $6   $7\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst)\n+VLoadStore(strh, H, store, 2,  D, 16,  src)\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst)\n+VLoadStore(strs, S, store, 4,  D, 32,  src)\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst)\n+VLoadStore(strd, D, store, 8,  D, 64,  src)\n+VLoadStore(ldrq, Q, load, 16,  X, 128, dst)\n+VLoadStore(strq, Q, store, 16, X, 128, src)\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t# load vector predicated\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ elemType_to_regVariant(bt), vector_length(this));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t# store vector predicated\" %}\n@@ -229,0 +274,2 @@\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ elemType_to_regVariant(bt), vector_length(this, $src));\n@@ -230,3 +277,3 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -235,0 +282,15 @@\n+%}dnl\n+\n+\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \"# reinterpret $dst\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n@@ -237,0 +299,21 @@\n+instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"reinterpretResize $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ B, length_in_bytes_resize);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -242,1 +325,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5 &&\n+  predicate(UseSVE > 0 &&\n@@ -254,0 +337,1 @@\n+\n@@ -266,1 +350,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -290,1 +374,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= $3);\n+  predicate(UseSVE > 0);\n@@ -321,1 +405,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -346,1 +430,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -366,1 +450,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -384,1 +468,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -390,1 +474,1 @@\n-    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n@@ -404,1 +488,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -410,1 +494,1 @@\n-    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n@@ -429,1 +513,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -451,1 +535,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -474,1 +558,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -496,1 +580,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -518,1 +602,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -542,1 +626,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -564,1 +648,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -588,1 +672,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= $4);\n+  predicate(UseSVE > 0);\n@@ -606,1 +690,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -608,1 +692,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -613,1 +697,1 @@\n-%}dnl\n+%}\n@@ -615,14 +699,9 @@\n-dnl\n-dnl REDUCE_ADD_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n-dnl REDUCE_ADD_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n-define(`REDUCE_ADD_EXT', `\n-instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n-  match(Set dst ($2 src1 src2));\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_uaddv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n-            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n-            \"addw  $dst, $dst, $src1\\n\\t\"\n-            \"$7  $dst, $dst\\t # add reduction $5\" %}\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t# vector mask cmp (sve)\" %}\n@@ -630,5 +709,5 @@\n-    __ sve_uaddv(as_FloatRegister($tmp$$reg), __ $5,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n-    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n-    __ $7($dst$$Register, $dst$$Register);\n+    BasicType bt = vector_element_basic_type(this);\n+    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n+                   as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n@@ -637,10 +716,49 @@\n-%}')dnl\n-dnl\n-dnl REDUCE_ADD($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n-dnl REDUCE_ADD(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n-define(`REDUCE_ADD', `\n-instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n-  match(Set dst ($2 src1 src2));\n-  effect(TEMP_DEF dst, TEMP tmp);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+      __ elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               ptrue, as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t# vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t# vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ sve_compare(as_PRegister($pTmp$$reg), bt, ptrue, as_FloatRegister($src3$$reg),\n+                   as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n@@ -648,3 +766,1 @@\n-  format %{ \"sve_uaddv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n-            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n-            \"$7  $dst, $dst, $src1\\t # add reduction $5\" %}\n+  format %{ \"sve_neg $dst, $src\\t# vector load mask (B)\" %}\n@@ -652,4 +768,1 @@\n-    __ sve_uaddv(as_FloatRegister($tmp$$reg), __ $5,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n-    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n@@ -658,8 +771,57 @@\n-%}')dnl\n-dnl\n-dnl REDUCE_ADDF($1,        $2,      $3,      $4  )\n-dnl REDUCE_ADDF(insn_name, op_name, reg_dst, size)\n-define(`REDUCE_ADDF', `\n-instruct $1($3 src1_dst, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set src1_dst ($2 src1_dst src2));\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n@@ -667,1 +829,1 @@\n-  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_neg $dst, $src\\t# vector store mask (B)\" %}\n@@ -669,2 +831,2 @@\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src2$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n@@ -673,1 +835,1 @@\n-%}')dnl\n+%}\n@@ -675,7 +837,18 @@\n-\/\/ vector add reduction\n-REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE,  sxtb)\n-REDUCE_ADD_EXT(reduce_addS, AddReductionVI, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n-REDUCE_ADD(reduce_addI, AddReductionVI, iRegINoSp, iRegIorL2I, S, T_INT, addw)\n-REDUCE_ADD(reduce_addL, AddReductionVL, iRegLNoSp, iRegL, D, T_LONG, add)\n-REDUCE_ADDF(reduce_addF, AddReductionVF, vRegF, S)\n-REDUCE_ADDF(reduce_addD, AddReductionVD, vRegD, D)\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -683,0 +856,44 @@\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n+            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t# vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -684,11 +901,11 @@\n-dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )\n-dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)\n-define(`REDUCE_FMINMAX', `\n-instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_f$1v $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"f$1s $dst, $dst, $src1\\t # $1 reduction $2\" %}\n+dnl\n+dnl VLOADMASK_LOADV($1,    $2  )\n+dnl VLOADMASK_LOADV(esize, cond)\n+define(`VLOADMASK_LOADV', `\n+instruct vloadmask_loadV_$1(vReg dst, ifelse($1, `byte', vmemA, indirect) mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) $2);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t# load vector mask (sve)\" %}\n@@ -696,3 +913,7 @@\n-    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = __ elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n@@ -702,3 +923,34 @@\n-\/\/ vector max reduction\n-REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)\n-REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)\n+dnl\n+define(`ARGLIST',\n+`ifelse($1, `byte', vmemA, indirect) mem, vReg src, vReg tmp, ifelse($1, `byte', immI_1, immI_gt_1) esize')\n+dnl\n+dnl STOREV_VSTOREMASK($1,  )\n+dnl STOREV_VSTOREMASK(esize)\n+define(`STOREV_VSTOREMASK', `\n+instruct storeV_vstoremask_$1(ARGLIST($1)) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t# store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+undefine(ARGLIST)dnl\n+dnl\n+\/\/ load\/store mask vector\n+VLOADMASK_LOADV(byte, == 1)\n+VLOADMASK_LOADV(non_byte, > 1)\n+STOREV_VSTOREMASK(byte)\n+STOREV_VSTOREMASK(non_byte)\n@@ -706,3 +958,1 @@\n-\/\/ vector min reduction\n-REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)\n-REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)\n+\/\/ vector add reduction\n@@ -710,1 +960,22 @@\n-\/\/ vector Math.rint, floor, ceil\n+instruct reduce_addI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addB\/S\/I reduction (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -712,5 +983,7 @@\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n@@ -718,13 +991,13 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n@@ -735,7 +1008,5 @@\n-dnl\n-dnl REPLICATE($1,        $2,      $3,      $4,   $5         )\n-dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n-define(`REPLICATE', `\n-instruct $1(vReg dst, $3 src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src));\n+\n+instruct reduce_addL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -743,1 +1014,1 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction (sve)\" %}\n@@ -745,1 +1016,3 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -748,8 +1021,7 @@\n-%}')dnl\n-dnl\n-dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )\n-dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)\n-define(`REPLICATE_IMM8', `\n-instruct $1(vReg dst, $3 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 con));\n+%}\n+\n+instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -757,1 +1029,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n@@ -759,1 +1031,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -762,1 +1038,2 @@\n-%}')dnl\n+%}\n+\n@@ -764,6 +1041,6 @@\n-dnl FREPLICATE($1,        $2,      $3,      $4,   $5         )\n-dnl FREPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n-define(`FREPLICATE', `\n-instruct $1(vReg dst, $3 src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src));\n+dnl REDUCE_ADDF($1,        $2,      $3,      $4  )\n+dnl REDUCE_ADDF(insn_name, op_name, reg_dst, size)\n+define(`REDUCE_ADDF', `\n+instruct $1($3 src1_dst, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set src1_dst (AddReductionV$2 src1_dst src2));\n@@ -771,1 +1048,1 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_fadda $src1_dst, $src1_dst, $src2\\t# vector (sve) ($4)\" %}\n@@ -773,2 +1050,2 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src2$$reg));\n@@ -778,12 +1055,0 @@\n-\n-\/\/ vector replicate\n-REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)\n-REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)\n-REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)\n-REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)\n-REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)\n-REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)\n-REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)\n-REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)\n-FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)\n-FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)\n@@ -791,6 +1056,7 @@\n-dnl VSHIFT_TRUE_PREDICATE($1,        $2,      $3,   $4,          $5  )\n-dnl VSHIFT_TRUE_PREDICATE(insn_name, op_name, size, min_vec_len, insn)\n-define(`VSHIFT_TRUE_PREDICATE', `\n-instruct $1(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n-  match(Set dst ($2 dst shift));\n+dnl\n+dnl REDUCE_ADDF_PARTIAL($1,        $2,     $3,      $4  )\n+dnl REDUCE_ADDF_PARTIAL(insn_name, suffix, reg_dst, size)\n+define(`REDUCE_ADDF_PARTIAL', `\n+instruct $1($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionV$2 src1_dst src2));\n@@ -798,1 +1064,2 @@\n-  format %{ \"$5 $dst, $dst, $shift\\t# vector (sve) ($3)\" %}\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_add$2 $src1_dst, $src1_dst, $src2\\t# add$2 reduction partial (sve) ($4)\" %}\n@@ -800,2 +1067,3 @@\n-    __ $5(as_FloatRegister($dst$$reg), __ $3,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ $4, vector_length(this, $src2));\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -806,6 +1074,12 @@\n-dnl VSHIFT_IMM_UNPREDICATED($1,        $2,      $3,       $4,   $5,          $6  )\n-dnl VSHIFT_IMM_UNPREDICATED(insn_name, op_name, op_name2, size, min_vec_len, insn)\n-define(`VSHIFT_IMM_UNPREDICATED', `\n-instruct $1(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src ($3 shift)));\n+REDUCE_ADDF(reduce_addF, F, vRegF, S)\n+REDUCE_ADDF_PARTIAL(reduce_addF_partial, F, vRegF, S)\n+REDUCE_ADDF(reduce_addD, D, vRegD, D)\n+REDUCE_ADDF_PARTIAL(reduce_addD_partial, D, vRegD, D)\n+\n+\/\/ vector and reduction\n+\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n@@ -813,1 +1087,1 @@\n-  format %{ \"$6 $dst, $src, $shift\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andB\/S\/I reduction (sve) (may extend)\" %}\n@@ -815,3 +1089,507 @@\n-    int con = (int)$shift$$constant;dnl\n-ifelse(eval(index(`$1', `vasr') == 0 || index(`$1', `vlsr') == 0), 1, `\n-    if (con == 0) {\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector or reduction\n+\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orB\/S\/I reduction (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n+               as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector xor reduction\n+\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorB\/H\/I reduction (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    } else {\n+      assert(bt == T_INT, \"unsupported type\");\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction (sve)\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n+                as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_MAXMIN_I($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_I(min_max, op_mame, cmp)\n+define(`REDUCE_MAXMIN_I', `\n+instruct reduce_$1I(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# reduce $1B\/S\/I (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant, ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_L(min_max, op_name, cmp)\n+define(`REDUCE_MAXMIN_L', `\n+instruct reduce_$1L(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# reduce $1L partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D, ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_I_PARTIAL($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_mame, cmp)\n+define(`REDUCE_MAXMIN_I_PARTIAL', `\n+instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# reduce $1I partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), variant, vector_length(this, $src2));\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_PARTIAL($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name, cmp)\n+define(`REDUCE_MAXMIN_L_PARTIAL', `\n+instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# reduce $1L partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ D, vector_length(this, $src2));\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX', `\n+instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_f$1v $dst, $src2 # vector (sve) ($4)\\n\\t\"\n+            \"f$1s $dst, $dst, $src1\\t# $1 reduction $2\" %}\n+  ins_encode %{\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+dnl REDUCE_FMINMAX_PARTIAL($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX_PARTIAL(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX_PARTIAL', `\n+instruct reduce_$1$2_partial($5 dst, $5 src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# reduce $1 $4 partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($ptmp$$reg), __ $4, vector_length(this, $src2));\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector max reduction\n+REDUCE_MAXMIN_I(max, MaxReductionV, GT)\n+REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_MAXMIN_L(max, MaxReductionV, GT)\n+REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PARTIAL(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PARTIAL(max, D, T_DOUBLE, D, vRegD)\n+\n+\/\/ vector min reduction\n+REDUCE_MAXMIN_I(min, MinReductionV, LT)\n+REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV, LT)\n+REDUCE_MAXMIN_L(min, MinReductionV, LT)\n+REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV, LT)\n+REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PARTIAL(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PARTIAL(min, D, T_DOUBLE, D, vRegD)\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl REPLICATE($1,        $2,      $3,      $4,   $5         )\n+dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n+define(`REPLICATE', `\n+instruct $1(vReg dst, $3 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )\n+dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)\n+define(`REPLICATE_IMM8', `\n+instruct $1(vReg dst, $3 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl FREPLICATE($1,        $2,      $3,        $4)\n+dnl FREPLICATE(insn_name, op_name, reg_src, size)\n+define(`FREPLICATE', `\n+instruct $1(vReg dst, $3 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector replicate\n+REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)\n+REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)\n+REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)\n+REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)\n+REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)\n+REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)\n+REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)\n+REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)\n+FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)\n+FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)\n+dnl\n+dnl VSHIFT_TRUE_PREDICATE($1,        $2,      $3,   $4,          $5  )\n+dnl VSHIFT_TRUE_PREDICATE(insn_name, op_name, size, min_vec_len, insn)\n+define(`VSHIFT_TRUE_PREDICATE', `\n+instruct $1(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"$5 $dst, $dst, $shift\\t# vector (sve) ($3)\" %}\n+  ins_encode %{\n+    __ $5(as_FloatRegister($dst$$reg), __ $3,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VSHIFT_IMM_UNPREDICATED($1,        $2,      $3,       $4,   $5,          $6  )\n+dnl VSHIFT_IMM_UNPREDICATED(insn_name, op_name, op_name2, size, min_vec_len, insn)\n+define(`VSHIFT_IMM_UNPREDICATED', `\n+instruct $1(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src ($3 shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"$6 $dst, $src, $shift\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;dnl\n+ifelse(eval(index(`$1', `vasr') == 0 || index(`$1', `vlsr') == 0), 1, `\n+    if (con == 0) {\n@@ -846,1 +1624,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3 &&\n+  predicate(UseSVE > 0 &&\n@@ -913,2 +1691,1 @@\n-\/\/ Intrisics for String.indexOf(char)\n-\n+\/\/ ------------------------------ Vector cast -------------------------------\n@@ -916,4 +1693,3 @@\n-define(`STRING_INDEXOF_CHAR', `\n-instruct string$1_indexof_char_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n-                                  iRegI_R0 result, vReg ztmp1, vReg ztmp2,\n-                                  pRegGov pgtmp, pReg ptmp, rFlagsReg cr)\n+dnl\n+define(`VECTOR_CAST_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n@@ -921,1 +1697,788 @@\n-  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$5  $dst, $7, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$6  $dst, $5, $dst, $5\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$6(as_FloatRegister($dst$$reg), __ $5, ptrue, as_FloatRegister($dst$$reg), __ $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_X2F_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $5\\n\\t\"\n+            \"sve_$6  $tmp, $7, 0\\n\\t\"\n+            \"sve_$8  $dst, $7, $dst, $tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $5);\n+    __ sve_$6(as_FloatRegister($tmp$$reg), __ $7, 0);\n+    __ sve_$8(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_X2X', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_X2F_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$5  $dst, $4, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $9, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $9, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VECTOR_CAST_EXTEND1(B, S, sunpklo, H)\n+VECTOR_CAST_EXTEND2(B, I, sunpklo, H, S)\n+VECTOR_CAST_EXTEND3(B, L, sunpklo, H, S, D)\n+VECTOR_CAST_I2F_EXTEND2(B, F, sunpklo, H, S, scvtf)\n+VECTOR_CAST_I2F_EXTEND3(B, D, sunpklo, H, S, D, scvtf)\n+dnl\n+VECTOR_CAST_NARROW1(S, B, dup, B, uzp1)\n+VECTOR_CAST_EXTEND1(S, I, sunpklo, S)\n+VECTOR_CAST_EXTEND2(S, L, sunpklo, S, D)\n+VECTOR_CAST_X2F_EXTEND1(S, F, sunpklo, S, scvtf, S)\n+VECTOR_CAST_I2F_EXTEND2(S, D, sunpklo, S, D, scvtf)\n+dnl\n+VECTOR_CAST_NARROW2(I, B, dup, H, uzp1, B)\n+VECTOR_CAST_NARROW1(I, S, dup, H, uzp1)\n+VECTOR_CAST_EXTEND1(I, L, sunpklo, D)\n+VECTOR_CAST_X2X(I, F, scvtf, S)\n+VECTOR_CAST_X2F_EXTEND1(I, D, sunpklo, D, scvtf, D)\n+dnl\n+VECTOR_CAST_NARROW3(L, B, dup, S, uzp1, H, B)\n+VECTOR_CAST_NARROW2(L, S, dup, S, uzp1, H)\n+VECTOR_CAST_NARROW1(L, I, dup, S, uzp1)\n+VECTOR_CAST_X2F_NARROW1(L, F, scvtf, S, D, dup, S, uzp1)\n+VECTOR_CAST_X2X(L, D, scvtf, D)\n+dnl\n+VECTOR_CAST_F2X_NARROW2(F, B, fcvtzs, S, dup, H, uzp1, B)\n+VECTOR_CAST_F2X_NARROW1(F, S, fcvtzs, S, dup, H, uzp1)\n+VECTOR_CAST_X2X(F, I, fcvtzs, S)\n+VECTOR_CAST_F2X_EXTEND1(F, L, fcvtzs, S, sunpklo, D)\n+VECTOR_CAST_X2F_EXTEND1(F, D, sunpklo, D, fcvt, S)\n+dnl\n+VECTOR_CAST_F2X_NARROW3(D, B, fcvtzs, D, dup, S, uzp1, H, B)\n+VECTOR_CAST_F2X_NARROW2(D, S, fcvtzs, D, dup, S, uzp1, H)\n+VECTOR_CAST_F2X_NARROW1(D, I, fcvtzs, D, dup, S, uzp1)\n+VECTOR_CAST_X2X(D, L, fcvtzs, D)\n+VECTOR_CAST_X2F_NARROW1(D, F, fcvt, S, D, dup, S, uzp1)\n+dnl\n+dnl\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+define(`VECTOR_EXTRACT_SXT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, $3, $pTmp, $src, $idx\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, $5\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+    __ sbfmw(as_$4($dst$$reg), as_$4($dst$$reg), 0U, $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                $1 $2         $3 $4        $5\n+VECTOR_EXTRACT_SXT(B, iRegINoSp, B, Register, 7U)\n+VECTOR_EXTRACT_SXT(S, iRegINoSp, H, Register, 15U)\n+\n+dnl\n+define(`VECTOR_EXTRACT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_extract $dst, $3, $pTmp, $src, $idx\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ sve_extract(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg),\n+                   as_FloatRegister($src$$reg), (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl            $1 $2         $3 $4\n+VECTOR_EXTRACT(I, iRegINoSp, S, Register)\n+VECTOR_EXTRACT(L, iRegLNoSp, D, Register)\n+VECTOR_EXTRACT(F, vRegF,     S, FloatRegister)\n+VECTOR_EXTRACT(D, vRegD,     D, FloatRegister)\n+\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+dnl\n+dnl VTEST($1,      $2,   $3,  $4  )\n+dnl VTEST(op_name, pred, imm, cond)\n+define(`VTEST', `\n+instruct vtest_$1`'(iRegINoSp dst, vReg src1, vReg src2, pReg pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, $3\\n\\t\"\n+            \"csetw $dst, $4\\t# VectorTest (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               ptrue, as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST(alltrue, overflow, 0, EQ)\n+VTEST(anytrue, ne,      -1, NE)\n+dnl\n+dnl\n+dnl VTEST_PARTIAL($1,      $2,   $3,  $4  )\n+dnl VTEST_PARTIAL(op_name, pred, imm, cond)\n+define(`VTEST_PARTIAL', `\n+instruct vtest_$1_partial`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vtest_$1_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), size, vector_length(this, $src1));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST_PARTIAL(alltrue, overflow, 0, EQ)\n+VTEST_PARTIAL(anytrue, ne,      -1, NE)\n+\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+\n+instruct insertI_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, -16, 1\\t# (B\/S\/I)\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B\/S\/I)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index(as_FloatRegister($dst$$reg), size, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertF_small(vReg dst, vReg src, vRegF val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, S, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ S, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertI(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, 0, 1\\t# (B\/S\/I)\\n\\t\"\n+            \"sve_dup $dst, $idx\\t# (B\/S\/I)\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B\/S\/I)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index(as_FloatRegister($tmp1$$reg), size, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), size, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), size, ptrue,\n+               as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg), as_Register($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl\n+define(`VECTOR_INSERT_D', `\n+instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, $3, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ $3, -16, 1);\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ $3, ptrue,\n+               as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg), as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl             $1 $2     $3 $4\n+VECTOR_INSERT_D(L, iRegL, D, Register)\n+VECTOR_INSERT_D(D, vRegD, D, FloatRegister)\n+\n+instruct insertF(vReg dst, vReg src, vRegF val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, S, 0, 1\\n\\t\"\n+            \"sve_dup $dst, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, as_PRegister($pTmp$$reg), __ S, ptrue,\n+               as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+\n+instruct loadshuffleB(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orr $dst, $src, $src\\t# vector load shuffle (B)\" %}\n+  ins_encode %{\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+                 as_FloatRegister($src$$reg),\n+                 as_FloatRegister($src$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\t# vector load shuffle (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\t# vector load shuffle (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\t# vector load shuffle (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector rearrange -------------------------------\n+\n+instruct rearrange(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorRearrange src shuffle));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_tbl $dst, $src, $shuffle\\t# vector rearrange\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_tbl(as_FloatRegister($dst$$reg), size,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather ---------------------------------\n+\n+instruct gatherI(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(SVE_COST);\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather Partial-------------------------------\n+\n+instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S, vector_length(this));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL_partial(vReg dst, indirect mem, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $pTmp, $mem, $idx\\t# vector load gather partial (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D, vector_length(this));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter -------------------------------\n+\n+instruct scatterI(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatterL(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter Partial-------------------------------\n+\n+instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ S, vector_length(this, $src));\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatterL_partial(indirect mem, vReg src, vReg idx, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n+            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST + INSN_COST);\n+  format %{ \"sve_whilelo_zr_imm $pTmp, vector_length\\n\\t\"\n+            \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"store_vector_scatter $mem, $pTmp, $idx, $src\\t# vector store scatter partial (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister($pTmp$$reg), __ D, vector_length(this, $src));\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($pTmp$$reg), as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+\/\/ ------------------------------ Vector Load Const -------------------------------\n+\n+instruct loadconB(vReg dst, immI0 src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadConst src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_index $dst, 0, 1\\t# generate iota indices\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ B, 0, 1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Intrisics for String.indexOf(char)\n+\n+dnl\n+define(`STRING_INDEXOF_CHAR', `\n+instruct string$1_indexof_char_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+                                  iRegI_R0 result, vReg ztmp1, vReg ztmp2,\n+                                  pRegGov pgtmp, pReg ptmp, rFlagsReg cr)\n+%{\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n@@ -937,0 +2500,18 @@\n+\n+dnl\n+dnl VMASK_REDUCTION($1,     $2,      $3  )\n+dnl VMASK_REDUCTION(suffix, op_name, cost)\n+define(`VMASK_REDUCTION', `\n+instruct vmask_$1(iRegINoSp dst, vReg src, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost($3 * SVE_COST);\n+  format %{ \"vmask_$1 $dst, $src\\t# vector mask $1 (sve)\" %}\n+  ins_encode %{\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B,\n+                           as_FloatRegister($src$$reg), ptrue, as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n@@ -938,0 +2519,26 @@\n+\/\/ ---------------------------- Vector mask reductions ---------------------------\n+VMASK_REDUCTION(truecount, VectorMaskTrueCount, 2)\n+VMASK_REDUCTION(firsttrue, VectorMaskFirstTrue, 3)\n+VMASK_REDUCTION(lasttrue,  VectorMaskLastTrue, 4)\n+dnl\n+dnl VMASK_REDUCTION_PARTIAL($1,     $2,      $3  )\n+dnl VMASK_REDUCTION_PARTIAL(suffix, op_name, cost)\n+define(`VMASK_REDUCTION_PARTIAL', `\n+instruct vmask_$1_partial(iRegINoSp dst, vReg src, pRegGov ifelse($1, `firsttrue', `pgtmp, pReg ptmp', `ptmp'), rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst ($2 src));\n+  effect(TEMP ifelse($1, `firsttrue', `pgtmp, TEMP ptmp', `ptmp'), KILL cr);\n+  ins_cost($3 * SVE_COST);\n+  format %{ \"vmask_$1 $dst, $src\\t# vector mask $1 partial (sve)\" %}\n+  ins_encode %{\n+    __ sve_whilelo_zr_imm(as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), __ B, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, __ B, as_FloatRegister($src$$reg),\n+                           as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VMASK_REDUCTION_PARTIAL(truecount, VectorMaskTrueCount, 3)\n+VMASK_REDUCTION_PARTIAL(firsttrue, VectorMaskFirstTrue, 4)\n+VMASK_REDUCTION_PARTIAL(lasttrue,  VectorMaskLastTrue, 5)\n@@ -939,0 +2546,50 @@\n+dnl\n+dnl VSTOREMASK_REDUCTION($1,     $2,      $3  )\n+dnl VSTOREMASK_REDUCTION(suffix, op_name, cost)\n+define(`VSTOREMASK_REDUCTION', `\n+instruct vstoremask_$1(iRegINoSp dst, vReg src, immI esize, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 (VectorStoreMask src esize)));\n+  effect(TEMP ptmp, KILL cr);\n+  ins_cost($3 * SVE_COST);\n+  format %{ \"vstoremask_$1 $dst, $src\\t# vector mask $1 (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           ptrue, as_PRegister($ptmp$$reg), vector_length(this, $src));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ----------------- Vector mask reductions combined with VectorMaskStore ---------------\n+VSTOREMASK_REDUCTION(truecount, VectorMaskTrueCount, 2)\n+VSTOREMASK_REDUCTION(firsttrue, VectorMaskFirstTrue, 3)\n+VSTOREMASK_REDUCTION(lasttrue,  VectorMaskLastTrue, 4)\n+dnl\n+dnl VSTOREMASK_REDUCTION_PARTIAL($1,     $2,      $3  )\n+dnl VSTOREMASK_REDUCTION_PARTIAL(suffix, op_name, cost)\n+define(`VSTOREMASK_REDUCTION_PARTIAL', `\n+instruct vstoremask_$1_partial(iRegINoSp dst, vReg src, immI esize, pRegGov ifelse($1, `firsttrue', `pgtmp, pReg ptmp', `ptmp'), rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst ($2 (VectorStoreMask src esize)));\n+  effect(TEMP ifelse($1, `firsttrue', `pgtmp, TEMP ptmp', `ptmp'), KILL cr);\n+  ins_cost($3 * SVE_COST);\n+  format %{ \"vstoremask_$1 $dst, $src\\t# vector mask $1 partial (sve)\" %}\n+  ins_encode %{\n+    unsigned size = $esize$$constant;\n+    assert(size == 1 || size == 2 || size == 4 || size == 8, \"unsupported element size\");\n+    Assembler::SIMD_RegVariant variant = __ elemBytes_to_regVariant(size);\n+    __ sve_whilelo_zr_imm(as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), variant, vector_length(this, $src));\n+    __ sve_vmask_reduction(this->ideal_Opcode(), $dst$$Register, variant, as_FloatRegister($src$$reg),\n+                           as_PRegister(ifelse($1, `firsttrue', `$pgtmp', `$ptmp')$$reg), as_PRegister($ptmp$$reg), MaxVectorSize \/ size);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VSTOREMASK_REDUCTION_PARTIAL(truecount, VectorMaskTrueCount, 3)\n+VSTOREMASK_REDUCTION_PARTIAL(firsttrue, VectorMaskFirstTrue, 4)\n+VSTOREMASK_REDUCTION_PARTIAL(lasttrue,  VectorMaskLastTrue, 5)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":1928,"deletions":271,"binary":false,"changes":2199,"status":"modified"},{"patch":"@@ -57,0 +57,23 @@\n+Assembler::SIMD_RegVariant Assembler::_esize2regvariant[9] = {\n+  INVALID,\n+  B,\n+  H,\n+  INVALID,\n+  S,\n+  INVALID,\n+  INVALID,\n+  INVALID,\n+  D,\n+};\n+\n+Assembler::SIMD_Arrangement Assembler::esize2arrangement(unsigned esize, bool isQ) {\n+  guarantee(esize < ARRAY_SIZE(_esize2arrangement_table) &&\n+         _esize2arrangement_table[esize][isQ] != INVALID_ARRANGEMENT, \"unsupported element size\");\n+  return _esize2arrangement_table[esize][isQ];\n+}\n+\n+Assembler::SIMD_RegVariant Assembler::elemBytes_to_regVariant(unsigned esize) {\n+  guarantee(esize < ARRAY_SIZE(_esize2regvariant) && _esize2regvariant[esize] != INVALID,\n+         \"unsupported element size\");\n+  return _esize2regvariant[esize];\n+}\n@@ -58,3 +81,2 @@\n-Assembler::SIMD_Arrangement Assembler::esize2arrangement(int esize, bool isQ) {\n-    guarantee(esize == 1 || esize == 2 || esize == 4 || esize == 8, \"unsupported element size\");\n-    return _esize2arrangement_table[esize][isQ];\n+Assembler::SIMD_RegVariant Assembler::elemType_to_regVariant(BasicType bt) {\n+  return elemBytes_to_regVariant(type2aelembytes(bt));\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.cpp","additions":25,"deletions":3,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -1505,0 +1505,4 @@\n+  enum SIMD_RegVariant {\n+      B, H, S, D, Q, INVALID\n+  };\n+\n@@ -1508,0 +1512,1 @@\n+  static SIMD_RegVariant _esize2regvariant[9];\n@@ -1511,5 +1516,3 @@\n-  static SIMD_Arrangement esize2arrangement(int esize, bool isQ);\n-\n-  enum SIMD_RegVariant {\n-    B, H, S, D, Q, INVALID\n-  };\n+  static SIMD_Arrangement esize2arrangement(unsigned esize, bool isQ);\n+  static SIMD_RegVariant elemType_to_regVariant(BasicType bt);\n+  static SIMD_RegVariant elemBytes_to_regVariant(unsigned esize);\n@@ -2930,1 +2933,1 @@\n-\/\/ SVE arithmetics - unpredicated\n+\/\/ SVE arithmetic - unpredicated\n@@ -2967,1 +2970,1 @@\n-\/\/ SVE integer arithmetics - predicate\n+\/\/ SVE integer arithmetic - predicate\n@@ -2995,1 +2998,1 @@\n-\/\/ SVE floating-point arithmetics - predicate\n+\/\/ SVE floating-point arithmetic - predicate\n@@ -3124,1 +3127,1 @@\n-\/\/ SVE load\/store - predicated\n+\/\/ SVE contiguous load\/store\n@@ -3141,0 +3144,17 @@\n+\/\/ Gather\/scatter load\/store (SVE) - scalar plus vector\n+#define INSN(NAME, op1, type, op2, op3)                                         \\\n+  void NAME(FloatRegister Zt, PRegister Pg, Register Xn, FloatRegister Zm) {    \\\n+    starti;                                                                     \\\n+    f(op1, 31, 25), f(type, 24, 23), f(op2, 22, 21), rf(Zm, 16);                \\\n+    f(op3, 15, 13), pgrf(Pg, 10), srf(Xn, 5), rf(Zt, 0);                        \\\n+  }\n+  \/\/ SVE 32-bit gather load words (scalar plus 32-bit scaled offsets)\n+  INSN(sve_ld1w_gather,  0b1000010, 0b10, 0b01, 0b010);\n+  \/\/ SVE 64-bit gather load (scalar plus 32-bit unpacked scaled offsets)\n+  INSN(sve_ld1d_gather,  0b1100010, 0b11, 0b01, 0b010);\n+  \/\/ SVE 32-bit scatter store (scalar plus 32-bit scaled offsets)\n+  INSN(sve_st1w_scatter, 0b1110010, 0b10, 0b11, 0b100);\n+  \/\/ SVE 64-bit scatter store (scalar plus unpacked 32-bit scaled offsets)\n+  INSN(sve_st1d_scatter, 0b1110010, 0b11, 0b01, 0b100);\n+#undef INSN\n+\n@@ -3154,0 +3174,1 @@\n+\/\/ SVE stack frame adjustment\n@@ -3161,2 +3182,2 @@\n-  INSN(sve_addvl, 0b01);\n-  INSN(sve_addpl, 0b11);\n+  INSN(sve_addvl, 0b01); \/\/ Add multiple of vector register size to scalar register\n+  INSN(sve_addpl, 0b11); \/\/ Add multiple of predicate register size to scalar register\n@@ -3178,2 +3199,2 @@\n-  \/\/ SVE predicate count\n-  void sve_cntp(Register Xd, SIMD_RegVariant T, PRegister Pg, PRegister Pn) {\n+  \/\/ SVE increment register by predicate count\n+  void sve_incp(const Register rd, SIMD_RegVariant T, PRegister pg) {\n@@ -3182,2 +3203,2 @@\n-    f(0b00100101, 31, 24), f(T, 23, 22), f(0b10000010, 21, 14);\n-    prf(Pg, 10), f(0, 9), prf(Pn, 5), rf(Xd, 0);\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(0b1011001000100, 21, 9),\n+    prf(pg, 5), rf(rd, 0);\n@@ -3186,1 +3207,1 @@\n-  \/\/ SVE dup scalar\n+  \/\/ SVE broadcast general-purpose register to vector elements (unpredicated)\n@@ -3194,1 +3215,1 @@\n-  \/\/ SVE dup imm\n+  \/\/ SVE broadcast signed immediate to vector elements (unpredicated)\n@@ -3217,7 +3238,94 @@\n-\/\/ Integer comparisons (SVE)\n-#define INSN(NAME, cond)                                                                          \\\n-  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, FloatRegister Zm)  { \\\n-    starti;                                                                                       \\\n-    assert(T != Q, \"invalid size\");                                                               \\\n-    f(0b00100100, 31, 24), f(T, 23, 22), f(0, 21), rf(Zm, 16), f((cond >> 1) & 7, 15, 13);        \\\n-    pgrf(Pg, 10), rf(Zn, 5), f(cond & 1, 4), prf(Pd, 0);                                          \\\n+  \/\/ SVE copy general-purpose register to vector elements (predicated)\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, Register Rn) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b101000101, 21, 13);\n+    pgrf(Pg, 10), srf(Rn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE copy signed integer immediate to vector elements (predicated)\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm8, bool isMerge) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    int sh = 0;\n+    if (imm8 <= 127 && imm8 >= -128) {\n+      sh = 0;\n+    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n+      sh = 1;\n+      imm8 = (imm8 >> 8);\n+    } else {\n+      guarantee(false, \"invalid immediate\");\n+    }\n+    int m = isMerge ? 1 : 0;\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b01, 21, 20);\n+    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE conditionally select elements from two vectors\n+  void sve_sel(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg,\n+               FloatRegister Zn, FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b11, 15, 14), prf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE Integer\/Floating-Point Compare - Vectors\n+#define INSN(NAME, op1, op2, fp)  \\\n+  void NAME(Condition cond, PRegister Pd, SIMD_RegVariant T, PRegister Pg,             \\\n+            FloatRegister Zn, FloatRegister Zm) {                                      \\\n+    starti;                                                                            \\\n+    if (fp == 0) {                                                                     \\\n+      assert(T != Q, \"invalid size\");                                                  \\\n+    } else {                                                                           \\\n+      assert(T != B && T != Q, \"invalid size\");                                        \\\n+      assert(cond != HI && cond != HS, \"invalid condition for fcm\");                   \\\n+    }                                                                                  \\\n+    int cond_op;                                                                       \\\n+    switch(cond) {                                                                     \\\n+      case EQ: cond_op = (op2 << 2) | 0b10; break;                                     \\\n+      case NE: cond_op = (op2 << 2) | 0b11; break;                                     \\\n+      case GE: cond_op = (op2 << 2) | 0b00; break;                                     \\\n+      case GT: cond_op = (op2 << 2) | 0b01; break;                                     \\\n+      case HI: cond_op = 0b0001; break;                                                \\\n+      case HS: cond_op = 0b0000; break;                                                \\\n+      default:                                                                         \\\n+        ShouldNotReachHere();                                                          \\\n+    }                                                                                  \\\n+    f(op1, 31, 24), f(T, 23, 22), f(0, 21), rf(Zm, 16), f((cond_op >> 1) & 7, 15, 13); \\\n+    pgrf(Pg, 10), rf(Zn, 5), f(cond_op & 1, 4), prf(Pd, 0);                            \\\n+  }\n+\n+  INSN(sve_cmp, 0b00100100, 0b10, 0);\n+  INSN(sve_fcm, 0b01100101, 0b01, 1);\n+#undef INSN\n+\n+\/\/ SVE Integer Compare - Signed Immediate\n+void sve_cmp(Condition cond, PRegister Pd, SIMD_RegVariant T,\n+             PRegister Pg, FloatRegister Zn, int imm5) {\n+  starti;\n+  assert(T != Q, \"invalid size\");\n+  guarantee(-16 <= imm5 && imm5 <= 15, \"invalid immediate\");\n+  int cond_op;\n+  switch(cond) {\n+    case EQ: cond_op = 0b1000; break;\n+    case NE: cond_op = 0b1001; break;\n+    case GE: cond_op = 0b0000; break;\n+    case GT: cond_op = 0b0001; break;\n+    case LE: cond_op = 0b0011; break;\n+    case LT: cond_op = 0b0010; break;\n+    default:\n+      ShouldNotReachHere();\n+  }\n+  f(0b00100101, 31, 24), f(T, 23, 22), f(0b0, 21), sf(imm5, 20, 16),\n+  f((cond_op >> 1) & 0x7, 15, 13), pgrf(Pg, 10), rf(Zn, 5);\n+  f(cond_op & 0x1, 4), prf(Pd, 0);\n+}\n+\n+\/\/ SVE unpack vector elements\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn) { \\\n+    starti;                                                          \\\n+    assert(T != B && T != Q, \"invalid size\");                        \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1100, 21, 18);          \\\n+    f(op, 17, 16), f(0b001110, 15, 10), rf(Zn, 5), rf(Zd, 0);        \\\n@@ -3226,4 +3334,17 @@\n-  INSN(sve_cmpeq, 0b1010);  \/\/ Compare signed equal to vector\n-  INSN(sve_cmpne, 0b1011);  \/\/ Compare not equal to vector\n-  INSN(sve_cmpge, 0b1000);  \/\/ Compare signed greater than or equal to vector\n-  INSN(sve_cmpgt, 0b1001);  \/\/ Compare signed greater than vector\n+  INSN(sve_uunpkhi, 0b11); \/\/ Signed unpack and extend half of vector - high half\n+  INSN(sve_uunpklo, 0b10); \/\/ Signed unpack and extend half of vector - low half\n+  INSN(sve_sunpkhi, 0b01); \/\/ Unsigned unpack and extend half of vector - high half\n+  INSN(sve_sunpklo, 0b00); \/\/ Unsigned unpack and extend half of vector - low half\n+#undef INSN\n+\n+\/\/ SVE permute vector elements\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) { \\\n+    starti;                                                                            \\\n+    assert(T != Q, \"invalid size\");                                                    \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);                       \\\n+    f(0b01101, 15, 11), f(op, 10), rf(Zn, 5), rf(Zd, 0);                               \\\n+  }\n+\n+  INSN(sve_uzp1, 0b0); \/\/ Concatenate even elements from two vectors\n+  INSN(sve_uzp2, 0b1); \/\/ Concatenate odd elements from two vectors\n@@ -3248,4 +3369,2 @@\n-  \/\/ Predicate scan (SVE)\n-\n-  \/\/ Break after the first true condition\n-  void sve_brka(PRegister pd, PRegister pg, PRegister pn, bool isMerge) {\n+  \/\/ SVE predicate reverse\n+  void sve_rev(PRegister Pd, SIMD_RegVariant T, PRegister Pn) {\n@@ -3253,2 +3372,11 @@\n-    f(0b00100101, 31, 24), f(0b00, 23, 22), f(0b01000001, 21, 14),\n-    prf(pg, 10), f(0b0, 9), prf(pn, 5), f(isMerge ? 1 : 0, 4), prf(pd, 0);\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1101000100000, 21, 9);\n+    prf(Pn, 5), f(0, 4), prf(Pd, 0);\n+  }\n+\n+\/\/ SVE partition break condition\n+#define INSN(NAME, op) \\\n+  void NAME(PRegister Pd, PRegister Pg, PRegister Pn, bool isMerge) {      \\\n+    starti;                                                                \\\n+    f(0b00100101, 31, 24), f(op, 23, 22), f(0b01000001, 21, 14);           \\\n+    prf(Pg, 10), f(0b0, 9), prf(Pn, 5), f(isMerge ? 1 : 0, 4), prf(Pd, 0); \\\n@@ -3257,0 +3385,4 @@\n+  INSN(sve_brka, 0b00); \/\/ Break after first true condition\n+  INSN(sve_brkb, 0b10); \/\/ Break before first true condition\n+#undef INSN\n+\n@@ -3271,1 +3403,7 @@\n-  \/\/ Predicate count and increment scalar (SVE)\n+  \/\/ Set scalar to active predicate element count\n+  void sve_cntp(Register Xd, SIMD_RegVariant T, PRegister Pg, PRegister Pn) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(0b10000010, 21, 14);\n+    prf(Pg, 10), f(0, 9), prf(Pn, 5), rf(Xd, 0);\n+  }\n@@ -3273,2 +3411,104 @@\n-  \/\/ Set scalar to the number of Active predicate elements that are TRUE\n-  void sve_incp(const Register rd, SIMD_RegVariant T, PRegister pg) {\n+  \/\/ SVE convert signed integer to floating-point (predicated)\n+  void sve_scvtf(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                 FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           (T_src != H || T_dst == T_src), \"invalid register variant\");\n+    int opc = T_dst;\n+    int opc2 = T_src;\n+    \/\/ In most cases we can treat T_dst, T_src as opc, opc2,\n+    \/\/ except for the following two combinations.\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ | opc | opc2 | U |        Instruction Details         |\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ |  11 |   00 | 0 | SCVTF - 32-bit to double-precision |\n+    \/\/ |  11 |   10 | 0 | SCVTF - 64-bit to single-precision |\n+    \/\/ +-----+------+---+------------------------------------+\n+    if (T_src == S && T_dst == D) {\n+      opc = 0b11;\n+      opc2 = 0b00;\n+    } else if (T_src == D && T_dst == S) {\n+      opc = 0b11;\n+      opc2 = 0b10;\n+    }\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b010, 21, 19);\n+    f(opc2, 18, 17), f(0b0101, 16, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE floating-point convert to signed integer, rounding toward zero (predicated)\n+  void sve_fcvtzs(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                  FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           (T_dst != H || T_src == H), \"invalid register variant\");\n+    int opc = T_src;\n+    int opc2 = T_dst;\n+    \/\/ In most cases we can treat T_src, T_dst as opc, opc2,\n+    \/\/ except for the following two combinations.\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ | opc | opc2 | U |         Instruction Details         |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ |  11 |  10  | 0 | FCVTZS - single-precision to 64-bit |\n+    \/\/ |  11 |  00  | 0 | FCVTZS - double-precision to 32-bit |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    if (T_src == S && T_dst == D) {\n+      opc = 0b11;\n+      opc2 = 0b10;\n+    } else if (T_src == D && T_dst == S) {\n+      opc = 0b11;\n+      opc2 = 0b00;\n+    }\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b011, 21, 19);\n+    f(opc2, 18, 17), f(0b0101, 16, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE floating-point convert precision (predicated)\n+  void sve_fcvt(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           T_src != T_dst, \"invalid register variant\");\n+    guarantee(T_src != H && T_dst != H, \"half-precision unsupported\");\n+    f(0b01100101, 31, 24), f(0b11, 23, 22), f(0b0010, 21, 18);\n+    f(T_dst, 17, 16), f(0b101, 15, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE extract element to general-purpose register\n+#define INSN(NAME, before)                                                      \\\n+  void NAME(Register Rd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                     \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10000, 21, 17);                    \\\n+    f(before, 16), f(0b101, 15, 13);                                            \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Rd, 0);                                         \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+\/\/ SVE extract element to SIMD&FP scalar register\n+#define INSN(NAME, before)                                                           \\\n+  void NAME(FloatRegister Vd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                          \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10001, 21, 17);                         \\\n+    f(before, 16), f(0b100, 15, 13);                                                 \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Vd, 0);                                              \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+  \/\/ SVE create index starting from and incremented by immediate\n+  void sve_index(FloatRegister Zd, SIMD_RegVariant T, int imm1, int imm2) {\n+    starti;\n+    f(0b00000100, 31, 24), f(T, 23, 22), f(0b1, 21);\n+    sf(imm2, 20, 16), f(0b010000, 15, 10);\n+    sf(imm1, 9, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE programmable table lookup\/permute using vector of element indices\n+  void sve_tbl(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) {\n@@ -3277,2 +3517,2 @@\n-    f(0b00100101, 31, 24), f(T, 23, 22), f(0b1011001000100, 21, 9),\n-    prf(pg, 5), rf(rd, 0);\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b001100, 15, 10), rf(Zn, 5), rf(Zd, 0);\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":279,"deletions":39,"binary":false,"changes":318,"status":"modified"},{"patch":"@@ -587,1 +587,1 @@\n-    sve_cmpeq(tmp_pdn, T, tmp_pg, ztmp1, ztmp2);\n+    sve_cmp(Assembler::EQ, tmp_pdn, T, tmp_pg, ztmp1, ztmp2);\n@@ -908,1 +908,1 @@\n-  SIMD_Arrangement size = esize2arrangement(type2aelembytes(bt), isQ);\n+  SIMD_Arrangement size = esize2arrangement((unsigned)type2aelembytes(bt), isQ);\n@@ -947,0 +947,53 @@\n+\n+void C2_MacroAssembler::sve_compare(PRegister pd, BasicType bt, PRegister pg,\n+                                    FloatRegister zn, FloatRegister zm, int cond) {\n+  assert(pg->is_governing(), \"This register has to be a governing predicate register\");\n+  FloatRegister z1 = zn, z2 = zm;\n+  \/\/ Convert the original BoolTest condition to Assembler::condition.\n+  Condition condition;\n+  switch (cond) {\n+    case BoolTest::eq: condition = Assembler::EQ; break;\n+    case BoolTest::ne: condition = Assembler::NE; break;\n+    case BoolTest::le: z1 = zm; z2 = zn; condition = Assembler::GE; break;\n+    case BoolTest::ge: condition = Assembler::GE; break;\n+    case BoolTest::lt: z1 = zm; z2 = zn; condition = Assembler::GT; break;\n+    case BoolTest::gt: condition = Assembler::GT; break;\n+    default:\n+      assert(false, \"unsupported compare condition\");\n+      ShouldNotReachHere();\n+  }\n+\n+  SIMD_RegVariant size = elemType_to_regVariant(bt);\n+  if (bt == T_FLOAT || bt == T_DOUBLE) {\n+    sve_fcm(condition, pd, size, pg, z1, z2);\n+  } else {\n+    assert(is_integral_type(bt), \"unsupported element type\");\n+    sve_cmp(condition, pd, size, pg, z1, z2);\n+  }\n+}\n+\n+void C2_MacroAssembler::sve_vmask_reduction(int opc, Register dst, SIMD_RegVariant size, FloatRegister src,\n+                                            PRegister pg, PRegister pn, int length) {\n+  assert(pg->is_governing(), \"This register has to be a governing predicate register\");\n+  \/\/ The conditional flags will be clobbered by this function\n+  sve_cmp(Assembler::NE, pn, size, pg, src, 0);\n+  switch (opc) {\n+    case Op_VectorMaskTrueCount:\n+      sve_cntp(dst, size, ptrue, pn);\n+      break;\n+    case Op_VectorMaskFirstTrue:\n+      sve_brkb(pn, pg, pn, false);\n+      sve_cntp(dst, size, ptrue, pn);\n+      break;\n+    case Op_VectorMaskLastTrue:\n+      sve_rev(pn, size, pn);\n+      sve_brkb(pn, ptrue, pn, false);\n+      sve_cntp(dst, size, ptrue, pn);\n+      movw(rscratch1, length - 1);\n+      subw(dst, rscratch1, dst);\n+      break;\n+    default:\n+      assert(false, \"unsupported\");\n+      ShouldNotReachHere();\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":55,"deletions":2,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -61,0 +61,26 @@\n+  void sve_compare(PRegister pd, BasicType bt, PRegister pg,\n+                   FloatRegister zn, FloatRegister zm, int cond);\n+\n+  void sve_vmask_reduction(int opc, Register dst, SIMD_RegVariant size, FloatRegister src,\n+                           PRegister pg, PRegister pn, int length = MaxVectorSize);\n+\n+  \/\/ Generate predicate through whilelo, by comparing ZR with an unsigned\n+  \/\/ immediate. rscratch1 will be clobbered.\n+  inline void sve_whilelo_zr_imm(PRegister pd, SIMD_RegVariant size, uint imm) {\n+    assert(UseSVE > 0, \"not supported\");\n+    mov(rscratch1, imm);\n+    sve_whilelo(pd, size, zr, rscratch1);\n+  }\n+\n+  \/\/ Extract a scalar element from an sve vector at position 'idx'.\n+  \/\/ rscratch1 will be clobbered.\n+  \/\/ T could be FloatRegister or Register.\n+  template<class T>\n+  inline void sve_extract(T dst, SIMD_RegVariant size, PRegister pg, FloatRegister src, int idx) {\n+    assert(UseSVE > 0, \"not supported\");\n+    assert(pg->is_governing(), \"This register has to be a governing predicate register\");\n+    mov(rscratch1, idx);\n+    sve_whilele(pg, size, zr, rscratch1);\n+    sve_lastb(dst, size, pg, src);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2539,1 +2539,3 @@\n-  if (restore_vectors) {\n+  \/\/ We may use predicate registers and rely on ptrue with SVE,\n+  \/\/ regardless of wide vector (> 8 bytes) used or not.\n+  if (use_sve) {\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2111,1 +2111,4 @@\n-  if (C->max_vector_size() > 8)\n+  \/\/ And when the scalable vector register is used, we may spill\/unspill\n+  \/\/ the whole reg regardless of the max vector size.\n+  if (C->max_vector_size() > 8 ||\n+      (C->max_vector_size() > 0 && Matcher::supports_scalable_vector())) {\n@@ -2113,0 +2116,1 @@\n+  }\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1539,46 +1539,111 @@\n-                        [\"cpy\",    \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n-                        [\"inc\",    \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n-                        [\"dec\",    \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n-                        [\"lsl\",    \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n-                        [\"lsr\",    \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n-                        [\"lsr\",    \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n-                        [\"addvl\",  \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n-                        [\"addpl\",  \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n-                        [\"cntp\",   \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n-                        [\"dup\",    \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n-                        [\"dup\",    \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n-                        [\"dup\",    \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n-                        [\"dup\",    \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n-                        [\"dup\",    \"__ sve_dup(z4, __ B, r3);\",                          \"dup\\tz4.b, w3\"],\n-                        [\"dup\",    \"__ sve_dup(z14, __ H, r22);\",                        \"dup\\tz14.h, w22\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n-                        [\"ld1h\",   \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n-                        [\"ld1d\",   \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n-                        [\"st1w\",   \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n-                        [\"st1h\",   \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n-                        [\"st1d\",   \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n-                        [\"str\",    \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n-                        [\"cntb\",   \"__ sve_cntb(r9);\",                                   \"cntb\\tx9\"],\n-                        [\"cnth\",   \"__ sve_cnth(r10);\",                                  \"cnth\\tx10\"],\n-                        [\"cntw\",   \"__ sve_cntw(r11);\",                                  \"cntw\\tx11\"],\n-                        [\"cntd\",   \"__ sve_cntd(r12);\",                                  \"cntd\\tx12\"],\n-                        [\"brka\",   \"__ sve_brka(p2, p0, p2, false);\",                    \"brka\\tp2.b, p0\/z, p2.b\"],\n-                        [\"brka\",   \"__ sve_brka(p1, p2, p3, true);\",                     \"brka\\tp1.b, p2\/m, p3.b\"],\n-                        [\"incp\",   \"__ sve_incp(r0, __ B, p2);\",                         \"incp\\tx0, p2.b\"],\n-                        [\"whilelt\",   \"__ sve_whilelt(p0, __ B, r1, r28);\",              \"whilelt\\tp0.b, x1, x28\"],\n-                        [\"whilele\",   \"__ sve_whilele(p2, __ H, r11, r8);\",              \"whilele\\tp2.h, x11, x8\"],\n-                        [\"whilelo\",   \"__ sve_whilelo(p3, __ S, r7, r2);\",               \"whilelo\\tp3.s, x7, x2\"],\n-                        [\"whilels\",   \"__ sve_whilels(p4, __ D, r17, r10);\",             \"whilels\\tp4.d, x17, x10\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n+                        [\"cpy\",     \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n+                        [\"cpy\",     \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n+                        [\"cpy\",     \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n+                        [\"cpy\",     \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n+                        [\"inc\",     \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n+                        [\"dec\",     \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n+                        [\"lsl\",     \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n+                        [\"lsr\",     \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n+                        [\"addvl\",   \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n+                        [\"addpl\",   \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n+                        [\"cntp\",    \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n+                        [\"dup\",     \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n+                        [\"dup\",     \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n+                        [\"dup\",     \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n+                        [\"dup\",     \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n+                        [\"dup\",     \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n+                        [\"dup\",     \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n+                        [\"ld1h\",    \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n+                        [\"st1w\",    \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n+                        [\"st1h\",    \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n+                        [\"st1d\",    \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n+                        [\"str\",     \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"cntb\",    \"__ sve_cntb(r9);\",                                   \"cntb\\tx9\"],\n+                        [\"cnth\",    \"__ sve_cnth(r10);\",                                  \"cnth\\tx10\"],\n+                        [\"cntw\",    \"__ sve_cntw(r11);\",                                  \"cntw\\tx11\"],\n+                        [\"cntd\",    \"__ sve_cntd(r12);\",                                  \"cntd\\tx12\"],\n+                        [\"brka\",    \"__ sve_brka(p2, p0, p2, false);\",                    \"brka\\tp2.b, p0\/z, p2.b\"],\n+                        [\"brka\",    \"__ sve_brka(p1, p2, p3, true);\",                     \"brka\\tp1.b, p2\/m, p3.b\"],\n+                        [\"brkb\",    \"__ sve_brkb(p1, p2, p3, false);\",                    \"brkb\\tp1.b, p2\/z, p3.b\"],\n+                        [\"brkb\",    \"__ sve_brkb(p2, p3, p4, true);\",                     \"brkb\\tp2.b, p3\/m, p4.b\"],\n+                        [\"rev\",     \"__ sve_rev(p0, __ B, p1);\",                          \"rev\\tp0.b, p1.b\"],\n+                        [\"rev\",     \"__ sve_rev(p1, __ H, p2);\",                          \"rev\\tp1.h, p2.h\"],\n+                        [\"rev\",     \"__ sve_rev(p2, __ S, p3);\",                          \"rev\\tp2.s, p3.s\"],\n+                        [\"rev\",     \"__ sve_rev(p3, __ D, p4);\",                          \"rev\\tp3.d, p4.d\"],\n+                        [\"incp\",    \"__ sve_incp(r0, __ B, p2);\",                         \"incp\\tx0, p2.b\"],\n+                        [\"whilelt\", \"__ sve_whilelt(p0, __ B, r1, r28);\",                 \"whilelt\\tp0.b, x1, x28\"],\n+                        [\"whilele\", \"__ sve_whilele(p2, __ H, r11, r8);\",                 \"whilele\\tp2.h, x11, x8\"],\n+                        [\"whilelo\", \"__ sve_whilelo(p3, __ S, r7, r2);\",                  \"whilelo\\tp3.s, x7, x2\"],\n+                        [\"whilels\", \"__ sve_whilels(p4, __ D, r17, r10);\",                \"whilels\\tp4.d, x17, x10\"],\n+                        [\"sel\",     \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n+                        [\"sel\",     \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n+                        [\"cmpeq\",   \"__ sve_cmp(Assembler::EQ, p1, __ B, p0, z0, z1);\",   \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n+                        [\"cmpne\",   \"__ sve_cmp(Assembler::NE, p1, __ H, p0, z2, z3);\",   \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n+                        [\"cmpge\",   \"__ sve_cmp(Assembler::GE, p1, __ S, p2, z4, z5);\",   \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmpgt\",   \"__ sve_cmp(Assembler::GT, p1, __ D, p3, z6, z7);\",   \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmphi\",   \"__ sve_cmp(Assembler::HI, p1, __ S, p2, z4, z5);\",   \"cmphi\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmphs\",   \"__ sve_cmp(Assembler::HS, p1, __ D, p3, z6, z7);\",   \"cmphs\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmpeq\",   \"__ sve_cmp(Assembler::EQ, p1, __ B, p4, z0, 15);\",   \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n+                        [\"cmpne\",   \"__ sve_cmp(Assembler::NE, p1, __ H, p0, z2, -16);\",  \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n+                        [\"cmple\",   \"__ sve_cmp(Assembler::LE, p1, __ S, p1, z4, 0);\",    \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n+                        [\"cmplt\",   \"__ sve_cmp(Assembler::LT, p1, __ D, p2, z6, -1);\",   \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n+                        [\"cmpge\",   \"__ sve_cmp(Assembler::GE, p1, __ S, p3, z4, 5);\",    \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n+                        [\"cmpgt\",   \"__ sve_cmp(Assembler::GT, p1, __ B, p4, z6, -2);\",   \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n+                        [\"fcmeq\",   \"__ sve_fcm(Assembler::EQ, p1, __ S, p0, z0, z1);\",   \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n+                        [\"fcmne\",   \"__ sve_fcm(Assembler::NE, p1, __ D, p0, z2, z3);\",   \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n+                        [\"fcmgt\",   \"__ sve_fcm(Assembler::GT, p1, __ S, p2, z4, z5);\",   \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"fcmge\",   \"__ sve_fcm(Assembler::GE, p1, __ D, p3, z6, z7);\",   \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"uunpkhi\", \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n+                        [\"uunpklo\", \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n+                        [\"sunpkhi\", \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n+                        [\"sunpklo\", \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z1, __ D, p0, z0, __ S);\",              \"scvtf\\tz1.d, p0\/m, z0.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z3, __ D, p1, z2, __ D);\",              \"scvtf\\tz3.d, p1\/m, z2.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p2, z1, __ D);\",              \"scvtf\\tz6.s, p2\/m, z1.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p3, z1, __ S);\",              \"scvtf\\tz6.s, p3\/m, z1.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ S);\",              \"scvtf\\tz6.h, p3\/m, z1.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ D);\",              \"scvtf\\tz6.h, p3\/m, z1.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ H);\",              \"scvtf\\tz6.h, p3\/m, z1.h\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z5, __ D, p3, z4, __ S);\",               \"fcvt\\tz5.d, p3\/m, z4.s\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z1, __ S, p3, z0, __ D);\",               \"fcvt\\tz1.s, p3\/m, z0.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z1, __ D);\",            \"fcvtzs\\tz19.d, p2\/m, z1.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z9, __ S, p1, z8, __ S);\",             \"fcvtzs\\tz9.s, p1\/m, z8.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p2, z0, __ D);\",             \"fcvtzs\\tz1.s, p2\/m, z0.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ D, p3, z0, __ S);\",             \"fcvtzs\\tz1.d, p3\/m, z0.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p4, z18, __ H);\",            \"fcvtzs\\tz1.s, p4\/m, z18.h\"],\n+                        [\"lasta\",   \"__ sve_lasta(r0, __ B, p0, z15);\",                   \"lasta\\tw0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(r1, __ B, p1, z16);\",                   \"lastb\\tw1, p1, z16.b\"],\n+                        [\"lasta\",   \"__ sve_lasta(v0, __ B, p0, z15);\",                   \"lasta\\tb0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(v1, __ B, p1, z16);\",                   \"lastb\\tb1, p1, z16.b\"],\n+                        [\"index\",   \"__ sve_index(z6, __ S, 1, 1);\",                      \"index\\tz6.s, #1, #1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z7, __ H, p3, r5);\",                      \"cpy\\tz7.h, p3\/m, w5\"],\n+                        [\"tbl\",     \"__ sve_tbl(z16, __ S, z17, z18);\",                   \"tbl\\tz16.s, {z17.s}, z18.s\"],\n+                        [\"ld1w\",    \"__ sve_ld1w_gather(z15, p0, r5, z16);\",              \"ld1w\\t{z15.s}, p0\/z, [x5, z16.s, uxtw #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d_gather(z15, p0, r5, z16);\",              \"ld1d\\t{z15.d}, p0\/z, [x5, z16.d, uxtw #3]\"],\n+                        [\"st1w\",    \"__ sve_st1w_scatter(z15, p0, r5, z16);\",             \"st1w\\t{z15.s}, p0, [x5, z16.s, uxtw #2]\"],\n+                        [\"st1d\",    \"__ sve_st1d_scatter(z15, p0, r5, z16);\",             \"st1d\\t{z15.d}, p0, [x5, z16.d, uxtw #3]\"],\n@@ -1654,4 +1719,2 @@\n-                       [\"cmpeq\", \"PPZZ\", \"z\"],\n-                       [\"cmpge\", \"PPZZ\", \"z\"],\n-                       [\"cmpgt\", \"PPZZ\", \"z\"],\n-                       [\"cmpne\", \"PPZZ\", \"z\"],\n+                       [\"uzp1\", \"ZZZ\"],\n+                       [\"uzp2\", \"ZZZ\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":113,"deletions":50,"binary":false,"changes":163,"status":"modified"},{"patch":"@@ -729,0 +729,6 @@\n+    __ sve_cpy(z0, __ B, p0, 127, true);               \/\/       mov     z0.b, p0\/m, 127\n+    __ sve_cpy(z1, __ H, p0, -128, true);              \/\/       mov     z1.h, p0\/m, -128\n+    __ sve_cpy(z2, __ S, p0, 32512, true);             \/\/       mov     z2.s, p0\/m, 32512\n+    __ sve_cpy(z5, __ D, p0, -32768, false);           \/\/       mov     z5.d, p0\/z, -32768\n+    __ sve_cpy(z10, __ B, p0, -1, false);              \/\/       mov     z10.b, p0\/z, -1\n+    __ sve_cpy(z11, __ S, p0, -1, false);              \/\/       mov     z11.s, p0\/z, -1\n@@ -746,2 +752,2 @@\n-    __ sve_dup(z4, __ B, r3);                          \/\/       dup     z4.b, w3\n-    __ sve_dup(z14, __ H, r22);                        \/\/       dup     z14.h, w22\n+    __ sve_dup(z10, __ B, -1);                         \/\/       dup     z10.b, -1\n+    __ sve_dup(z11, __ S, -1);                         \/\/       dup     z11.s, -1\n@@ -749,0 +755,3 @@\n+    __ sve_ld1b(z0, __ H, p1, Address(sp));            \/\/       ld1b    {z0.h}, p1\/z, [sp]\n+    __ sve_ld1b(z0, __ S, p2, Address(sp, r8));        \/\/       ld1b    {z0.s}, p2\/z, [sp, x8]\n+    __ sve_ld1b(z0, __ D, p3, Address(sp, 7));         \/\/       ld1b    {z0.d}, p3\/z, [sp, #7, MUL VL]\n@@ -756,0 +765,3 @@\n+    __ sve_st1b(z0, __ H, p1, Address(sp));            \/\/       st1b    {z0.h}, p1, [sp]\n+    __ sve_st1b(z0, __ S, p2, Address(sp, r8));        \/\/       st1b    {z0.s}, p2, [sp, x8]\n+    __ sve_st1b(z0, __ D, p3, Address(sp));            \/\/       st1b    {z0.d}, p3, [sp]\n@@ -769,0 +781,6 @@\n+    __ sve_brkb(p1, p2, p3, false);                    \/\/       brkb    p1.b, p2\/z, p3.b\n+    __ sve_brkb(p2, p3, p4, true);                     \/\/       brkb    p2.b, p3\/m, p4.b\n+    __ sve_rev(p0, __ B, p1);                          \/\/       rev     p0.b, p1.b\n+    __ sve_rev(p1, __ H, p2);                          \/\/       rev     p1.h, p2.h\n+    __ sve_rev(p2, __ S, p3);                          \/\/       rev     p2.s, p3.s\n+    __ sve_rev(p3, __ D, p4);                          \/\/       rev     p3.d, p4.d\n@@ -774,0 +792,47 @@\n+    __ sve_sel(z0, __ B, p0, z1, z2);                  \/\/       sel     z0.b, p0, z1.b, z2.b\n+    __ sve_sel(z4, __ D, p0, z5, z6);                  \/\/       sel     z4.d, p0, z5.d, z6.d\n+    __ sve_cmp(Assembler::EQ, p1, __ B, p0, z0, z1);   \/\/       cmpeq   p1.b, p0\/z, z0.b, z1.b\n+    __ sve_cmp(Assembler::NE, p1, __ H, p0, z2, z3);   \/\/       cmpne   p1.h, p0\/z, z2.h, z3.h\n+    __ sve_cmp(Assembler::GE, p1, __ S, p2, z4, z5);   \/\/       cmpge   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_cmp(Assembler::GT, p1, __ D, p3, z6, z7);   \/\/       cmpgt   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_cmp(Assembler::HI, p1, __ S, p2, z4, z5);   \/\/       cmphi   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_cmp(Assembler::HS, p1, __ D, p3, z6, z7);   \/\/       cmphs   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_cmp(Assembler::EQ, p1, __ B, p4, z0, 15);   \/\/       cmpeq   p1.b, p4\/z, z0.b, #15\n+    __ sve_cmp(Assembler::NE, p1, __ H, p0, z2, -16);  \/\/       cmpne   p1.h, p0\/z, z2.h, #-16\n+    __ sve_cmp(Assembler::LE, p1, __ S, p1, z4, 0);    \/\/       cmple   p1.s, p1\/z, z4.s, #0\n+    __ sve_cmp(Assembler::LT, p1, __ D, p2, z6, -1);   \/\/       cmplt   p1.d, p2\/z, z6.d, #-1\n+    __ sve_cmp(Assembler::GE, p1, __ S, p3, z4, 5);    \/\/       cmpge   p1.s, p3\/z, z4.s, #5\n+    __ sve_cmp(Assembler::GT, p1, __ B, p4, z6, -2);   \/\/       cmpgt   p1.b, p4\/z, z6.b, #-2\n+    __ sve_fcm(Assembler::EQ, p1, __ S, p0, z0, z1);   \/\/       fcmeq   p1.s, p0\/z, z0.s, z1.s\n+    __ sve_fcm(Assembler::NE, p1, __ D, p0, z2, z3);   \/\/       fcmne   p1.d, p0\/z, z2.d, z3.d\n+    __ sve_fcm(Assembler::GT, p1, __ S, p2, z4, z5);   \/\/       fcmgt   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_fcm(Assembler::GE, p1, __ D, p3, z6, z7);   \/\/       fcmge   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_uunpkhi(z0, __ H, z1);                      \/\/       uunpkhi z0.h, z1.b\n+    __ sve_uunpklo(z4, __ S, z5);                      \/\/       uunpklo z4.s, z5.h\n+    __ sve_sunpkhi(z6, __ D, z7);                      \/\/       sunpkhi z6.d, z7.s\n+    __ sve_sunpklo(z10, __ H, z11);                    \/\/       sunpklo z10.h, z11.b\n+    __ sve_scvtf(z1, __ D, p0, z0, __ S);              \/\/       scvtf   z1.d, p0\/m, z0.s\n+    __ sve_scvtf(z3, __ D, p1, z2, __ D);              \/\/       scvtf   z3.d, p1\/m, z2.d\n+    __ sve_scvtf(z6, __ S, p2, z1, __ D);              \/\/       scvtf   z6.s, p2\/m, z1.d\n+    __ sve_scvtf(z6, __ S, p3, z1, __ S);              \/\/       scvtf   z6.s, p3\/m, z1.s\n+    __ sve_scvtf(z6, __ H, p3, z1, __ S);              \/\/       scvtf   z6.h, p3\/m, z1.s\n+    __ sve_scvtf(z6, __ H, p3, z1, __ D);              \/\/       scvtf   z6.h, p3\/m, z1.d\n+    __ sve_scvtf(z6, __ H, p3, z1, __ H);              \/\/       scvtf   z6.h, p3\/m, z1.h\n+    __ sve_fcvt(z5, __ D, p3, z4, __ S);               \/\/       fcvt    z5.d, p3\/m, z4.s\n+    __ sve_fcvt(z1, __ S, p3, z0, __ D);               \/\/       fcvt    z1.s, p3\/m, z0.d\n+    __ sve_fcvtzs(z19, __ D, p2, z1, __ D);            \/\/       fcvtzs  z19.d, p2\/m, z1.d\n+    __ sve_fcvtzs(z9, __ S, p1, z8, __ S);             \/\/       fcvtzs  z9.s, p1\/m, z8.s\n+    __ sve_fcvtzs(z1, __ S, p2, z0, __ D);             \/\/       fcvtzs  z1.s, p2\/m, z0.d\n+    __ sve_fcvtzs(z1, __ D, p3, z0, __ S);             \/\/       fcvtzs  z1.d, p3\/m, z0.s\n+    __ sve_fcvtzs(z1, __ S, p4, z18, __ H);            \/\/       fcvtzs  z1.s, p4\/m, z18.h\n+    __ sve_lasta(r0, __ B, p0, z15);                   \/\/       lasta   w0, p0, z15.b\n+    __ sve_lastb(r1, __ B, p1, z16);                   \/\/       lastb   w1, p1, z16.b\n+    __ sve_lasta(v0, __ B, p0, z15);                   \/\/       lasta   b0, p0, z15.b\n+    __ sve_lastb(v1, __ B, p1, z16);                   \/\/       lastb   b1, p1, z16.b\n+    __ sve_index(z6, __ S, 1, 1);                      \/\/       index   z6.s, #1, #1\n+    __ sve_cpy(z7, __ H, p3, r5);                      \/\/       cpy     z7.h, p3\/m, w5\n+    __ sve_tbl(z16, __ S, z17, z18);                   \/\/       tbl     z16.s, {z17.s}, z18.s\n+    __ sve_ld1w_gather(z15, p0, r5, z16);              \/\/       ld1w    {z15.s}, p0\/z, [x5, z16.s, uxtw #2]\n+    __ sve_ld1d_gather(z15, p0, r5, z16);              \/\/       ld1d    {z15.d}, p0\/z, [x5, z16.d, uxtw #3]\n+    __ sve_st1w_scatter(z15, p0, r5, z16);             \/\/       st1w    {z15.s}, p0, [x5, z16.s, uxtw #2]\n+    __ sve_st1d_scatter(z15, p0, r5, z16);             \/\/       st1d    {z15.d}, p0, [x5, z16.d, uxtw #3]\n@@ -949,4 +1014,2 @@\n-    __ sve_cmpeq(p5, __ S, p6, z5, z19);               \/\/       cmpeq   p5.s, p6\/z, z5.s, z19.s\n-    __ sve_cmpge(p4, __ S, p5, z16, z29);              \/\/       cmpge   p4.s, p5\/z, z16.s, z29.s\n-    __ sve_cmpgt(p5, __ D, p0, z4, z17);               \/\/       cmpgt   p5.d, p0\/z, z4.d, z17.d\n-    __ sve_cmpne(p1, __ D, p5, z4, z23);               \/\/       cmpne   p1.d, p5\/z, z4.d, z23.d\n+    __ sve_uzp1(z21, __ S, z24, z5);                   \/\/       uzp1    z21.s, z24.s, z5.s\n+    __ sve_uzp2(z21, __ S, z17, z22);                  \/\/       uzp2    z21.s, z17.s, z22.s\n@@ -955,9 +1018,9 @@\n-    __ sve_andv(v19, __ H, p0, z8);                    \/\/       andv h19, p0, z8.h\n-    __ sve_orv(v14, __ D, p6, z17);                    \/\/       orv d14, p6, z17.d\n-    __ sve_eorv(v21, __ B, p1, z30);                   \/\/       eorv b21, p1, z30.b\n-    __ sve_smaxv(v10, __ B, p5, z12);                  \/\/       smaxv b10, p5, z12.b\n-    __ sve_sminv(v9, __ S, p1, z24);                   \/\/       sminv s9, p1, z24.s\n-    __ sve_fminv(v4, __ S, p6, z6);                    \/\/       fminv s4, p6, z6.s\n-    __ sve_fmaxv(v27, __ D, p6, z13);                  \/\/       fmaxv d27, p6, z13.d\n-    __ sve_fadda(v30, __ D, p5, z22);                  \/\/       fadda d30, p5, d30, z22.d\n-    __ sve_uaddv(v30, __ H, p7, z9);                   \/\/       uaddv d30, p7, z9.h\n+    __ sve_andv(v29, __ B, p5, z19);                   \/\/       andv b29, p5, z19.b\n+    __ sve_orv(v4, __ B, p4, z23);                     \/\/       orv b4, p4, z23.b\n+    __ sve_eorv(v19, __ D, p1, z23);                   \/\/       eorv d19, p1, z23.d\n+    __ sve_smaxv(v19, __ H, p0, z8);                   \/\/       smaxv h19, p0, z8.h\n+    __ sve_sminv(v14, __ D, p6, z17);                  \/\/       sminv d14, p6, z17.d\n+    __ sve_fminv(v21, __ S, p1, z30);                  \/\/       fminv s21, p1, z30.s\n+    __ sve_fmaxv(v10, __ S, p5, z12);                  \/\/       fmaxv s10, p5, z12.s\n+    __ sve_fadda(v9, __ D, p1, z24);                   \/\/       fadda d9, p1, d9, z24.d\n+    __ sve_uaddv(v4, __ H, p6, z6);                    \/\/       uaddv d4, p6, z6.h\n@@ -982,7 +1045,7 @@\n-    0x14000000,     0x17ffffd7,     0x1400030d,     0x94000000,\n-    0x97ffffd4,     0x9400030a,     0x3400000a,     0x34fffa2a,\n-    0x340060ea,     0x35000008,     0x35fff9c8,     0x35006088,\n-    0xb400000b,     0xb4fff96b,     0xb400602b,     0xb500001d,\n-    0xb5fff91d,     0xb5005fdd,     0x10000013,     0x10fff8b3,\n-    0x10005f73,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36305ef6,     0x3758000c,     0x375ff7cc,     0x37585e8c,\n+    0x14000000,     0x17ffffd7,     0x1400034c,     0x94000000,\n+    0x97ffffd4,     0x94000349,     0x3400000a,     0x34fffa2a,\n+    0x340068ca,     0x35000008,     0x35fff9c8,     0x35006868,\n+    0xb400000b,     0xb4fff96b,     0xb400680b,     0xb500001d,\n+    0xb5fff91d,     0xb50067bd,     0x10000013,     0x10fff8b3,\n+    0x10006753,     0x90000013,     0x36300016,     0x3637f836,\n+    0x363066d6,     0x3758000c,     0x375ff7cc,     0x3758666c,\n@@ -993,13 +1056,13 @@\n-    0x54005c60,     0x54000001,     0x54fff541,     0x54005c01,\n-    0x54000002,     0x54fff4e2,     0x54005ba2,     0x54000002,\n-    0x54fff482,     0x54005b42,     0x54000003,     0x54fff423,\n-    0x54005ae3,     0x54000003,     0x54fff3c3,     0x54005a83,\n-    0x54000004,     0x54fff364,     0x54005a24,     0x54000005,\n-    0x54fff305,     0x540059c5,     0x54000006,     0x54fff2a6,\n-    0x54005966,     0x54000007,     0x54fff247,     0x54005907,\n-    0x54000008,     0x54fff1e8,     0x540058a8,     0x54000009,\n-    0x54fff189,     0x54005849,     0x5400000a,     0x54fff12a,\n-    0x540057ea,     0x5400000b,     0x54fff0cb,     0x5400578b,\n-    0x5400000c,     0x54fff06c,     0x5400572c,     0x5400000d,\n-    0x54fff00d,     0x540056cd,     0x5400000e,     0x54ffefae,\n-    0x5400566e,     0x5400000f,     0x54ffef4f,     0x5400560f,\n+    0x54006440,     0x54000001,     0x54fff541,     0x540063e1,\n+    0x54000002,     0x54fff4e2,     0x54006382,     0x54000002,\n+    0x54fff482,     0x54006322,     0x54000003,     0x54fff423,\n+    0x540062c3,     0x54000003,     0x54fff3c3,     0x54006263,\n+    0x54000004,     0x54fff364,     0x54006204,     0x54000005,\n+    0x54fff305,     0x540061a5,     0x54000006,     0x54fff2a6,\n+    0x54006146,     0x54000007,     0x54fff247,     0x540060e7,\n+    0x54000008,     0x54fff1e8,     0x54006088,     0x54000009,\n+    0x54fff189,     0x54006029,     0x5400000a,     0x54fff12a,\n+    0x54005fca,     0x5400000b,     0x54fff0cb,     0x54005f6b,\n+    0x5400000c,     0x54fff06c,     0x54005f0c,     0x5400000d,\n+    0x54fff00d,     0x54005ead,     0x5400000e,     0x54ffefae,\n+    0x54005e4e,     0x5400000f,     0x54ffef4f,     0x54005def,\n@@ -1037,1 +1100,1 @@\n-    0xbd1b1869,     0x5800465b,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x58004e3b,     0x1800000b,     0xf8945060,\n@@ -1125,8 +1188,11 @@\n-    0x4cc0ac3f,     0x05a08020,     0x04b0e3e0,     0x0470e7e1,\n-    0x042f9c20,     0x043f9c35,     0x047f9c20,     0x04ff9c20,\n-    0x04299420,     0x04319160,     0x0461943e,     0x04a19020,\n-    0x042053ff,     0x047f5401,     0x25208028,     0x2538cfe0,\n-    0x2578d001,     0x25b8efe2,     0x25f8f007,     0x05203864,\n-    0x05603ace,     0xa400a3e0,     0xa4a8a7ea,     0xa547a814,\n-    0xa4084ffe,     0xa55c53e0,     0xa5e1540b,     0xe400fbf6,\n-    0xe408ffff,     0xe547e400,     0xe4014be0,     0xe4a84fe0,\n+    0x4cc0ac3f,     0x05a08020,     0x05104fe0,     0x05505001,\n+    0x05906fe2,     0x05d03005,     0x05101fea,     0x05901feb,\n+    0x04b0e3e0,     0x0470e7e1,     0x042f9c20,     0x043f9c35,\n+    0x047f9c20,     0x04ff9c20,     0x04299420,     0x04319160,\n+    0x0461943e,     0x04a19020,     0x042053ff,     0x047f5401,\n+    0x25208028,     0x2538cfe0,     0x2578d001,     0x25b8efe2,\n+    0x25f8f007,     0x2538dfea,     0x25b8dfeb,     0xa400a3e0,\n+    0xa420a7e0,     0xa4484be0,     0xa467afe0,     0xa4a8a7ea,\n+    0xa547a814,     0xa4084ffe,     0xa55c53e0,     0xa5e1540b,\n+    0xe400fbf6,     0xe408ffff,     0xe420e7e0,     0xe4484be0,\n+    0xe460efe0,     0xe547e400,     0xe4014be0,     0xe4a84fe0,\n@@ -1135,43 +1201,56 @@\n-    0x25104042,     0x25104871,     0x252c8840,     0x253c1420,\n-    0x25681572,     0x25a21ce3,     0x25ea1e34,     0x1e601000,\n-    0x1e603000,     0x1e621000,     0x1e623000,     0x1e641000,\n-    0x1e643000,     0x1e661000,     0x1e663000,     0x1e681000,\n-    0x1e683000,     0x1e6a1000,     0x1e6a3000,     0x1e6c1000,\n-    0x1e6c3000,     0x1e6e1000,     0x1e6e3000,     0x1e701000,\n-    0x1e703000,     0x1e721000,     0x1e723000,     0x1e741000,\n-    0x1e743000,     0x1e761000,     0x1e763000,     0x1e781000,\n-    0x1e783000,     0x1e7a1000,     0x1e7a3000,     0x1e7c1000,\n-    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8208193,\n-    0xf83101b6,     0xf83c13fe,     0xf821239a,     0xf824309e,\n-    0xf826535e,     0xf8304109,     0xf82c7280,     0xf8216058,\n-    0xf8a08309,     0xf8ba03d0,     0xf8a312ea,     0xf8aa21e4,\n-    0xf8a2310b,     0xf8aa522f,     0xf8a2418a,     0xf8ac71af,\n-    0xf8a26287,     0xf8fa8090,     0xf8e20184,     0xf8f01215,\n-    0xf8f022ab,     0xf8f7334c,     0xf8f751dc,     0xf8eb4038,\n-    0xf8ec715f,     0xf8f06047,     0xf863826d,     0xf8710070,\n-    0xf86113cb,     0xf86521e8,     0xf87d301e,     0xf8745287,\n-    0xf87742bc,     0xf87b70b9,     0xf8616217,     0xb83f8185,\n-    0xb82901fc,     0xb83d13f6,     0xb83320bf,     0xb82e33f0,\n-    0xb830529b,     0xb830416c,     0xb82973c6,     0xb831639b,\n-    0xb8be8147,     0xb8b4008a,     0xb8b81231,     0xb8b623a3,\n-    0xb8af3276,     0xb8b35056,     0xb8af4186,     0xb8b071ab,\n-    0xb8b763c1,     0xb8f38225,     0xb8e202d0,     0xb8ed12aa,\n-    0xb8fd219b,     0xb8fb3023,     0xb8ff5278,     0xb8f14389,\n-    0xb8fb70ef,     0xb8f563f7,     0xb87983e2,     0xb87b0150,\n-    0xb8771073,     0xb8702320,     0xb87a3057,     0xb870508c,\n-    0xb87c43be,     0xb87070db,     0xb86961fd,     0xce273c87,\n-    0xce080ac9,     0xce7e8e9b,     0xce808b45,     0xce79806e,\n-    0xce758768,     0xcec0835a,     0xce608ad8,     0x043100c4,\n-    0x046105e3,     0x65c900a6,     0x65d60a87,     0x65c80545,\n-    0x0416a63e,     0x04001f8b,     0x0450979a,     0x04dabe0d,\n-    0x045381a5,     0x04918b4f,     0x049006cb,     0x0497a264,\n-    0x045eadd1,     0x04881062,     0x040a04d7,     0x04810f71,\n-    0x04dca450,     0x65c084c3,     0x65cd8d93,     0x65c69a68,\n-    0x65878ae0,     0x65c29db3,     0x049da0e6,     0x6582b911,\n-    0x65c0b6d6,     0x65c1a1e2,     0x65cda494,     0x65c18107,\n-    0x65af1493,     0x65e52b36,     0x65ab4ed0,     0x65f06a8d,\n-    0x0451448f,     0x049c7c86,     0x0429335d,     0x04bc3162,\n-    0x047a3027,     0x04e831d1,     0x2493b8a5,     0x249d9604,\n-    0x24d18095,     0x24d7b491,     0x045a2113,     0x04d83a2e,\n-    0x041927d5,     0x0408358a,     0x048a2709,     0x658738c4,\n-    0x65c639bb,     0x65d836de,     0x04413d3e,\n+    0x25104042,     0x25104871,     0x25904861,     0x25904c92,\n+    0x05344020,     0x05744041,     0x05b44062,     0x05f44083,\n+    0x252c8840,     0x253c1420,     0x25681572,     0x25a21ce3,\n+    0x25ea1e34,     0x0522c020,     0x05e6c0a4,     0x2401a001,\n+    0x2443a051,     0x24858881,     0x24c78cd1,     0x24850891,\n+    0x24c70cc1,     0x250f9001,     0x25508051,     0x25802491,\n+    0x25df28c1,     0x25850c81,     0x251e10d1,     0x65816001,\n+    0x65c36051,     0x65854891,     0x65c74cc1,     0x05733820,\n+    0x05b238a4,     0x05f138e6,     0x0570396a,     0x65d0a001,\n+    0x65d6a443,     0x65d4a826,     0x6594ac26,     0x6554ac26,\n+    0x6556ac26,     0x6552ac26,     0x65cbac85,     0x65caac01,\n+    0x65dea833,     0x659ca509,     0x65d8a801,     0x65dcac01,\n+    0x655cb241,     0x0520a1e0,     0x0521a601,     0x052281e0,\n+    0x05238601,     0x04a14026,     0x0568aca7,     0x05b23230,\n+    0x853040af,     0xc5b040af,     0xe57080af,     0xe5b080af,\n+    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,\n+    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,\n+    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,\n+    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,\n+    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,\n+    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,\n+    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,\n+    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,\n+    0xf8208193,     0xf83101b6,     0xf83c13fe,     0xf821239a,\n+    0xf824309e,     0xf826535e,     0xf8304109,     0xf82c7280,\n+    0xf8216058,     0xf8a08309,     0xf8ba03d0,     0xf8a312ea,\n+    0xf8aa21e4,     0xf8a2310b,     0xf8aa522f,     0xf8a2418a,\n+    0xf8ac71af,     0xf8a26287,     0xf8fa8090,     0xf8e20184,\n+    0xf8f01215,     0xf8f022ab,     0xf8f7334c,     0xf8f751dc,\n+    0xf8eb4038,     0xf8ec715f,     0xf8f06047,     0xf863826d,\n+    0xf8710070,     0xf86113cb,     0xf86521e8,     0xf87d301e,\n+    0xf8745287,     0xf87742bc,     0xf87b70b9,     0xf8616217,\n+    0xb83f8185,     0xb82901fc,     0xb83d13f6,     0xb83320bf,\n+    0xb82e33f0,     0xb830529b,     0xb830416c,     0xb82973c6,\n+    0xb831639b,     0xb8be8147,     0xb8b4008a,     0xb8b81231,\n+    0xb8b623a3,     0xb8af3276,     0xb8b35056,     0xb8af4186,\n+    0xb8b071ab,     0xb8b763c1,     0xb8f38225,     0xb8e202d0,\n+    0xb8ed12aa,     0xb8fd219b,     0xb8fb3023,     0xb8ff5278,\n+    0xb8f14389,     0xb8fb70ef,     0xb8f563f7,     0xb87983e2,\n+    0xb87b0150,     0xb8771073,     0xb8702320,     0xb87a3057,\n+    0xb870508c,     0xb87c43be,     0xb87070db,     0xb86961fd,\n+    0xce273c87,     0xce080ac9,     0xce7e8e9b,     0xce808b45,\n+    0xce79806e,     0xce758768,     0xcec0835a,     0xce608ad8,\n+    0x043100c4,     0x046105e3,     0x65c900a6,     0x65d60a87,\n+    0x65c80545,     0x0416a63e,     0x04001f8b,     0x0450979a,\n+    0x04dabe0d,     0x045381a5,     0x04918b4f,     0x049006cb,\n+    0x0497a264,     0x045eadd1,     0x04881062,     0x040a04d7,\n+    0x04810f71,     0x04dca450,     0x65c084c3,     0x65cd8d93,\n+    0x65c69a68,     0x65878ae0,     0x65c29db3,     0x049da0e6,\n+    0x6582b911,     0x65c0b6d6,     0x65c1a1e2,     0x65cda494,\n+    0x65c18107,     0x65af1493,     0x65e52b36,     0x65ab4ed0,\n+    0x65f06a8d,     0x0451448f,     0x049c7c86,     0x0429335d,\n+    0x04bc3162,     0x047a3027,     0x04e831d1,     0x05a56b15,\n+    0x05b66e35,     0x041a367d,     0x041832e4,     0x04d926f3,\n+    0x04482113,     0x04ca3a2e,     0x658727d5,     0x6586358a,\n+    0x65d82709,     0x044138c4,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":166,"deletions":87,"binary":false,"changes":253,"status":"modified"}]}