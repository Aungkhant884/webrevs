{"files":[{"patch":"@@ -1905,1 +1905,1 @@\n-  if (C->max_vector_size() >= 16) {\n+  if (C->max_vector_size() > 0) {\n@@ -2391,1 +2391,1 @@\n-  if (!match_rule_supported(opcode) || !vector_size_supported(bt, vlen)) {\n+  if (!match_rule_supported(opcode)) {\n@@ -2399,1 +2399,1 @@\n-    return op_sve_supported(opcode);\n+    return op_sve_supported(opcode, vlen, bt);\n@@ -2416,0 +2416,3 @@\n+    case Op_LoadVectorGather:\n+    case Op_StoreVectorScatter:\n+      return false;\n@@ -2420,1 +2423,1 @@\n-  return true; \/\/ Per default match rules are supported.\n+  return vector_size_supported(bt, vlen);\n@@ -2460,0 +2463,1 @@\n+\n@@ -2462,15 +2466,8 @@\n-  if ((UseSVE > 0) && (MaxVectorSize >= 16)) {\n-    \/\/ Currently vector length less than SVE vector register size is not supported.\n-    return max_size;\n-  } else { \/\/ NEON\n-    \/\/ Limit the vector size to 8 bytes\n-    int size = 8 \/ type2aelembytes(bt);\n-    if (bt == T_BYTE) {\n-      \/\/ To support vector api shuffle\/rearrange.\n-      size = 4;\n-    } else if (bt == T_BOOLEAN) {\n-      \/\/ To support vector api load\/store mask.\n-      size = 2;\n-    }\n-    if (size < 2) size = 2;\n-    return MIN2(size,max_size);\n+  \/\/ Limit the min vector size to 8 bytes.\n+  int size = 8 \/ type2aelembytes(bt);\n+  if (bt == T_BYTE) {\n+    \/\/ To support vector api shuffle\/rearrange.\n+    size = 4;\n+  } else if (bt == T_BOOLEAN) {\n+    \/\/ To support vector api load\/store mask.\n+    size = 2;\n@@ -2478,0 +2475,2 @@\n+  if (size < 2) size = 2;\n+  return MIN2(size, max_size);\n@@ -2487,1 +2486,1 @@\n-  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+  if (UseSVE > 0 && 2 <= len && len <= 256) {\n@@ -3652,1 +3651,1 @@\n-    if (Compile::current()->max_vector_size() >= 16 && uncommon_trap_request() == 0) {\n+    if (Compile::current()->max_vector_size() > 0 && uncommon_trap_request() == 0) {\n@@ -3664,1 +3663,1 @@\n-    } else if (Compile::current()->max_vector_size() >= 16) {\n+    } else if (Compile::current()->max_vector_size() > 0) {\n@@ -3702,1 +3701,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -3715,1 +3714,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -4096,0 +4095,10 @@\n+operand immI_gt_1()\n+%{\n+  predicate(n->get_int() > 1);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":33,"deletions":24,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 2);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 2);\n@@ -47,1 +47,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 4);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 4);\n@@ -58,1 +58,1 @@\n-  predicate(n->as_LoadVector()->memory_size() == 8);\n+  predicate(UseSVE == 0 && n->as_LoadVector()->memory_size() == 8);\n@@ -3371,3 +3371,4 @@\n-  predicate((n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n-             n->as_Vector()->length() == 8) &&\n-             n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  predicate(UseSVE == 0 &&\n+           (n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n+            n->as_Vector()->length() == 8) &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n@@ -3386,1 +3387,1 @@\n-  predicate(n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n@@ -3843,2 +3844,2 @@\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 8 ||\n+                            n->as_Vector()->length() == 4));\n@@ -3868,2 +3869,2 @@\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 8 ||\n+                            n->as_Vector()->length() == 4));\n@@ -3893,2 +3894,2 @@\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 4 ||\n+                            n->as_Vector()->length() == 2));\n@@ -3918,2 +3919,2 @@\n-  predicate(n->as_Vector()->length() == 2 ||\n-            n->as_Vector()->length() == 4);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length() == 4 ||\n+                            n->as_Vector()->length() == 2));\n@@ -3943,1 +3944,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -3967,1 +3968,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -4017,1 +4018,1 @@\n-  predicate(n->as_Vector()->length() == 2);\n+  predicate(UseSVE == 0 && n->as_Vector()->length() == 2);\n@@ -5148,2 +5149,2 @@\n-  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n-            n->as_Vector()->length_in_bytes() == 8);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length_in_bytes() == 4 ||\n+            n->as_Vector()->length_in_bytes() == 8));\n@@ -5160,1 +5161,1 @@\n-  predicate(n->as_Vector()->length_in_bytes() == 16);\n+  predicate(UseSVE == 0 && (n->as_Vector()->length_in_bytes() == 16));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":22,"deletions":21,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -72,3 +72,3 @@\n-VLoadStore(ldrh, H, load,  2,  D, 16,  dst, )\n-VLoadStore(ldrs, S, load,  4,  D, 32,  dst, )\n-VLoadStore(ldrd, D, load,  8,  D, 64,  dst, )\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst, UseSVE == 0 && )\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst, UseSVE == 0 && )\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst, UseSVE == 0 && )\n@@ -1285,4 +1285,5 @@\n-`predicate((n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n-             n->as_Vector()->length() == 8) &&\n-             n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);',\n-`predicate(n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);')')dnl\n+`predicate(UseSVE == 0 &&\n+           (n->as_Vector()->length() == 2 || n->as_Vector()->length() == 4 ||\n+            n->as_Vector()->length() == 8) &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);',\n+`predicate(UseSVE == 0 && n->as_Vector()->length() == 16 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);')')dnl\n@@ -1555,3 +1556,4 @@\n-  predicate(ifelse($8, UseSVE == 0 && , $8,\n-                   $8, , , $8`\n-            ')n->as_Vector()->length() == $3);\n+  predicate(UseSVE == 0 && ifelse($8, `',\n+                                  n->as_Vector()->length() == $3,\n+                                  (n->as_Vector()->length() == $3 ||`\n+                            'n->as_Vector()->length() == $8)));\n@@ -1583,18 +1585,18 @@\n-dnl        $1    $2    $3  $4 $5     $6 $7          $8                                $9\n-VREPLICATE(dup,  dup,  8,  B, ,      D, iRegIorL2I, n->as_Vector()->length() == 4 ||, B)\n-VREPLICATE(dup,  dup,  16, B, ,      X, iRegIorL2I, UseSVE == 0 && ,                  B)\n-VREPLICATE(movi, mov,  8,  B, _imm,  D, immI,       n->as_Vector()->length() == 4 ||, B)\n-VREPLICATE(movi, mov,  16, B, _imm,  X, immI,       UseSVE == 0 && ,                  B)\n-VREPLICATE(dup,  dup,  4,  S, ,      D, iRegIorL2I, n->as_Vector()->length() == 2 ||, H)\n-VREPLICATE(dup,  dup,  8,  S, ,      X, iRegIorL2I, UseSVE == 0 && ,                  H)\n-VREPLICATE(movi, mov,  4,  S, _imm,  D, immI,       n->as_Vector()->length() == 2 ||, H)\n-VREPLICATE(movi, mov,  8,  S,  _imm, X, immI,       UseSVE == 0 && ,                  H)\n-VREPLICATE(dup,  dup,  2,  I, ,      D, iRegIorL2I, ,                                 S)\n-VREPLICATE(dup,  dup,  4,  I, ,      X, iRegIorL2I, UseSVE == 0 && ,                  S)\n-VREPLICATE(movi, mov,  2,  I, _imm,  D, immI,       ,                                 S)\n-VREPLICATE(movi, mov,  4,  I,  _imm, X, immI,       UseSVE == 0 && ,                  S)\n-VREPLICATE(dup,  dup,  2,  L, ,      X, iRegL,      UseSVE == 0 && ,                  D)\n-VREPLICATE(movi, eor,  2,  L, _zero, X, immI0,      UseSVE == 0 && ,                  D)\n-VREPLICATE(dup,  dup,  2,  F, ,      D, vRegF,      ,                                 S)\n-VREPLICATE(dup,  dup,  4,  F, ,      X, vRegF,      UseSVE == 0 && ,                  S)\n-VREPLICATE(dup,  dup,  2,  D, ,      X, vRegD,      UseSVE == 0 && ,                  D)\n+dnl        $1    $2    $3  $4 $5     $6 $7          $8 $9\n+VREPLICATE(dup,  dup,  8,  B, ,      D, iRegIorL2I, 4, B)\n+VREPLICATE(dup,  dup,  16, B, ,      X, iRegIorL2I,  , B)\n+VREPLICATE(movi, mov,  8,  B, _imm,  D, immI,       4, B)\n+VREPLICATE(movi, mov,  16, B, _imm,  X, immI,        , B)\n+VREPLICATE(dup,  dup,  4,  S, ,      D, iRegIorL2I, 2, H)\n+VREPLICATE(dup,  dup,  8,  S, ,      X, iRegIorL2I,  , H)\n+VREPLICATE(movi, mov,  4,  S, _imm,  D, immI,       2, H)\n+VREPLICATE(movi, mov,  8,  S,  _imm, X, immI,        , H)\n+VREPLICATE(dup,  dup,  2,  I, ,      D, iRegIorL2I, ,  S)\n+VREPLICATE(dup,  dup,  4,  I, ,      X, iRegIorL2I, ,  S)\n+VREPLICATE(movi, mov,  2,  I, _imm,  D, immI,       ,  S)\n+VREPLICATE(movi, mov,  4,  I,  _imm, X, immI,       ,  S)\n+VREPLICATE(dup,  dup,  2,  L, ,      X, iRegL,      ,  D)\n+VREPLICATE(movi, eor,  2,  L, _zero, X, immI0,      ,  D)\n+VREPLICATE(dup,  dup,  2,  F, ,      D, vRegF,      ,  S)\n+VREPLICATE(dup,  dup,  4,  F, ,      X, vRegF,      ,  S)\n+VREPLICATE(dup,  dup,  2,  D, ,      X, vRegD,      ,  D)\n@@ -1978,2 +1980,2 @@\n-  predicate(ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n-            ')n->as_Vector()->length_in_bytes() == $3);\n+  predicate(UseSVE == 0 && (ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n+            ')n->as_Vector()->length_in_bytes() == $3));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":32,"deletions":30,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -46,0 +47,1 @@\n+  \/\/ (esize \/ msize) = 1\n@@ -60,1 +62,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -74,1 +76,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -83,0 +85,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -86,1 +90,1 @@\n-  bool op_sve_supported(int opcode);\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -102,0 +106,24 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n@@ -127,3 +155,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n-                                   int opcode, Register base, int index, int size, int disp) {\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n@@ -131,2 +159,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int mesize = type2aelembytes(mem_elem_bt);\n@@ -135,1 +162,1 @@\n-      switch(esize) {\n+      switch(mesize) {\n@@ -138,1 +165,0 @@\n-        type = Assembler::B;\n@@ -142,1 +168,0 @@\n-        type = Assembler::H;\n@@ -146,1 +171,0 @@\n-        type = Assembler::S;\n@@ -150,1 +174,0 @@\n-        type = Assembler::D;\n@@ -156,1 +179,2 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n@@ -163,1 +187,32 @@\n-  bool op_sve_supported(int opcode) {\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt) {\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n@@ -166,1 +221,1 @@\n-        \/\/ No multiply reduction instructions\n+      \/\/ No multiply reduction instructions\n@@ -171,3 +226,1 @@\n-        \/\/ Others\n-      case Op_Extract:\n-      case Op_ExtractB:\n+      \/\/ Others\n@@ -175,5 +228,0 @@\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -181,0 +229,1 @@\n+        return false;\n@@ -182,5 +231,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n@@ -189,11 +233,2 @@\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadConst:\n-      case Op_VectorLoadMask:\n+        \/\/ Partial size of gather\/scatter are not supported for now.\n+        return length_in_bytes == MaxVectorSize;\n@@ -201,1 +236,0 @@\n-      case Op_VectorMaskCmp:\n@@ -203,4 +237,8 @@\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n-        return false;\n+        if (vlen < 4 || length_in_bytes > MaxVectorSize) {\n+          return false;\n+        } else {\n+          return true;\n+        }\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        return Matcher::vector_size_supported(bt, vlen);\n@@ -208,1 +246,1 @@\n-        return true;\n+        break;\n@@ -210,0 +248,2 @@\n+    \/\/ By default, we only support vector operations with no less than 8 bytes and 2 elements.\n+    return 8 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;\n@@ -222,1 +262,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -224,1 +264,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -226,1 +267,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -230,3 +271,4 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         vector_element_basic_type(this), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    BasicType bt = vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -238,1 +280,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -240,1 +283,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -244,3 +287,177 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (16 bits)\n+instruct loadV2_vreg(vReg dst, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 2);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrh   $dst,$mem\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvH(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (16 bits)\n+instruct storeV2_vreg(vReg src, vmem2 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 2);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strh   $mem,$src\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_strvH(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (32 bits)\n+instruct loadV4_vreg(vReg dst, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 4);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrs   $dst,$mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (32 bits)\n+instruct storeV4_vreg(vReg src, vmem4 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 4);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strs   $mem,$src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8_vreg(vReg dst, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 8);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrd   $dst,$mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(vload_reg_mem64);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8_vreg(vReg src, vmem8 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 8);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strd   $mem,$src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(vstore_reg_mem64);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16_vreg(vReg dst, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() == 16);\n+  match(Set dst (LoadVector mem));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"ldrq   $dst,$mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(vload_reg_mem128);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16_vreg(vReg src, vmem16 mem)\n+%{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() == 16);\n+  match(Set mem (StoreVector mem src));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"strq   $mem,$src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(vstore_reg_mem128);\n+%}\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector predicated\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ mov(rscratch1, vector_length(this));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector predicated\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    __ mov(rscratch1, vector_length(this, $src));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \"# reinterpret $dst\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"reinterpretResize $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ mov(rscratch1, length_in_bytes_resize);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n@@ -254,1 +471,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n+  predicate(UseSVE > 0 &&\n@@ -267,1 +484,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n+  predicate(UseSVE > 0 &&\n@@ -280,1 +497,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+  predicate(UseSVE > 0 &&\n@@ -293,1 +510,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+  predicate(UseSVE > 0 &&\n@@ -306,1 +523,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n+  predicate(UseSVE > 0 &&\n@@ -319,1 +536,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n+  predicate(UseSVE > 0 &&\n@@ -334,1 +551,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -347,1 +564,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -360,1 +577,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -373,1 +590,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -386,1 +603,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -399,1 +616,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -414,1 +631,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -429,1 +646,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -444,1 +661,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -459,1 +676,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -473,1 +690,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -488,1 +705,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -503,1 +720,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -519,1 +736,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -531,1 +748,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -545,1 +762,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -565,1 +782,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -588,1 +805,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -601,1 +818,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -617,1 +834,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -632,1 +849,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -649,1 +866,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -664,1 +881,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -680,1 +897,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -693,1 +910,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -709,1 +926,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -723,1 +940,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -737,1 +954,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -751,1 +968,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -767,1 +984,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -781,1 +998,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -795,1 +1012,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -809,1 +1026,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -824,1 +1041,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n+  predicate(UseSVE > 0);\n@@ -836,1 +1053,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n+  predicate(UseSVE > 0);\n@@ -848,1 +1065,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -860,1 +1077,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -872,1 +1089,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -885,1 +1102,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n+  predicate(UseSVE > 0);\n@@ -900,1 +1117,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -912,1 +1129,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -926,1 +1143,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -928,1 +1145,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -935,0 +1152,287 @@\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n+            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ load\/store mask vector\n+\n+instruct vloadmask_loadV_byte(vReg dst, vmemA mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_loadV_non_byte(vReg dst, indirect mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask_byte(vmemA mem, vReg src, vReg tmp, immI_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_vstoremask_non_byte(indirect mem, vReg src, vReg tmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n@@ -938,2 +1442,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -958,2 +1462,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -978,2 +1482,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -996,2 +1500,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1014,1 +1517,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1026,1 +1529,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -1037,10 +1540,7 @@\n-\/\/ vector max reduction\n-\n-instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n@@ -1048,3 +1548,13 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1055,8 +1565,7 @@\n-instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n+instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n@@ -1064,3 +1573,6 @@\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1071,10 +1583,6 @@\n-\/\/ vector min reduction\n-\n-instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n+instruct reduce_addF_partial(vRegF src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVF src1_dst src2));\n+  ins_cost(SVE_COST);\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_addF $src1_dst, $src1_dst, $src2\\t# addF reduction partial (sve) (S)\" %}\n@@ -1082,3 +1590,4 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ S, zr, rscratch1);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1089,8 +1598,6 @@\n-instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n+instruct reduce_addD_partial(vRegD src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionVD src1_dst src2));\n+  ins_cost(SVE_COST);\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_addD $src1_dst, $src1_dst, $src2\\t# addD reduction partial (sve) (D)\" %}\n@@ -1098,3 +1605,4 @@\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -1105,1 +1613,1 @@\n-\/\/ vector Math.rint, floor, ceil\n+\/\/ vector and reduction\n@@ -1107,5 +1615,10 @@\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct reduce_andB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # and reduction B\" %}\n@@ -1113,14 +1626,5 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-    }\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1131,5 +1635,5 @@\n-\/\/ vector replicate\n-\n-instruct replicateB(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB src));\n+instruct reduce_andS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1137,1 +1641,4 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # and reduction H\" %}\n@@ -1139,1 +1646,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1144,3 +1655,5 @@\n-instruct replicateS(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS src));\n+instruct reduce_andI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1148,1 +1661,3 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\t # and reduction S\" %}\n@@ -1150,1 +1665,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1155,3 +1673,5 @@\n-instruct replicateI(vReg dst, iRegIorL2I src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI src));\n+instruct reduce_andL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1159,1 +1679,3 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"andr  $dst, $dst, $src1\\t # and reduction D\" %}\n@@ -1161,1 +1683,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1166,3 +1691,6 @@\n-instruct replicateL(vReg dst, iRegL src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL src));\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1170,1 +1698,1 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n@@ -1172,1 +1700,13 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1177,3 +1717,6 @@\n-instruct replicateB_imm8(vReg dst, immI8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (ReplicateB con));\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1181,1 +1724,1 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n@@ -1183,1 +1726,6 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1188,3 +1736,8 @@\n-instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (ReplicateS con));\n+\n+\/\/ vector or reduction\n+\n+instruct reduce_orB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1192,1 +1745,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # or reduction B\" %}\n@@ -1194,1 +1750,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1199,3 +1759,5 @@\n-instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateI con));\n+instruct reduce_orS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1203,1 +1765,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # or reduction H\" %}\n@@ -1205,1 +1770,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1210,3 +1779,5 @@\n-instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateL con));\n+instruct reduce_orI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1214,1 +1785,3 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\t # or reduction S\" %}\n@@ -1216,1 +1789,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1221,3 +1797,5 @@\n-instruct replicateF(vReg dst, vRegF src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (ReplicateF src));\n+instruct reduce_orL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1225,1 +1803,3 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"orr  $dst, $dst, $src1\\t # or reduction D\" %}\n@@ -1227,2 +1807,4 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1233,3 +1815,6 @@\n-instruct replicateD(vReg dst, vRegD src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (ReplicateD src));\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1237,1 +1822,1 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n@@ -1239,2 +1824,13 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1245,5 +1841,6 @@\n-\/\/ vector shift\n-\n-instruct vasrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB dst shift));\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1251,1 +1848,1 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n@@ -1253,2 +1850,6 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1259,3 +1860,9 @@\n-instruct vasrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS dst shift));\n+\n+\/\/ vector xor reduction\n+\n+instruct reduce_eorB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1263,1 +1870,4 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxtb  $dst, $dst\\t # eor reduction B\" %}\n@@ -1265,2 +1875,5 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxtb($dst$$Register, $dst$$Register);\n@@ -1271,3 +1884,6 @@\n-instruct vasrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI dst shift));\n+instruct reduce_eorS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1275,1 +1891,4 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"sxth  $dst, $dst\\t # eor reduction H\" %}\n@@ -1277,2 +1896,5 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ sxth($dst$$Register, $dst$$Register);\n@@ -1283,3 +1905,6 @@\n-instruct vasrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL dst shift));\n+instruct reduce_eorI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1287,1 +1912,3 @@\n-  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"umov  $dst, $tmp, S, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\t # eor reduction S\" %}\n@@ -1289,2 +1916,4 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1295,3 +1924,6 @@\n-instruct vlslB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB dst shift));\n+instruct reduce_eorL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -1299,1 +1931,3 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"umov  $dst, $tmp, D, 0\\n\\t\"\n+            \"eor  $dst, $dst, $src1\\t # eor reduction D\" %}\n@@ -1301,2 +1935,4 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1307,3 +1943,6 @@\n-instruct vlslS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS dst shift));\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1311,1 +1950,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n@@ -1313,2 +1952,13 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -1319,3 +1969,6 @@\n-instruct vlslI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI dst shift));\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1323,1 +1976,1 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n@@ -1325,2 +1978,6 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -1331,3 +1988,8 @@\n-instruct vlslL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL dst shift));\n+\n+\/\/ vector max reduction\n+\n+instruct reduce_maxB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1335,1 +1997,4 @@\n-  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction B\" %}\n@@ -1337,2 +2002,5 @@\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1343,3 +2011,5 @@\n-instruct vlsrB(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB dst shift));\n+instruct reduce_maxS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1347,1 +2017,4 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction H\" %}\n@@ -1349,2 +2022,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1355,3 +2031,5 @@\n-instruct vlsrS(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS dst shift));\n+instruct reduce_maxI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1359,1 +2037,4 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"smov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 GT\\t# max reduction S\" %}\n@@ -1361,2 +2042,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1367,3 +2051,5 @@\n-instruct vlsrI(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI dst shift));\n+instruct reduce_maxL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n@@ -1371,1 +2057,4 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_smaxv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"smov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 GT\\t# max reduction D\" %}\n@@ -1373,2 +2062,5 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    __ sve_smaxv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1379,3 +2071,8 @@\n-instruct vlsrL(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL dst shift));\n+instruct reduce_maxI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1383,1 +2080,1 @@\n-  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# reduce maxI partial (sve)\" %}\n@@ -1385,2 +2082,9 @@\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($shift$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1391,3 +2095,6 @@\n-instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+instruct reduce_maxL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MaxReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -1395,1 +2102,1 @@\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# reduce maxL partial (sve)\" %}\n@@ -1397,9 +2104,7 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) con = 7;\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_smaxv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::GT);\n@@ -1410,5 +2115,8 @@\n-instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (RShiftVS src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+instruct reduce_maxF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t # max reduction F\" %}\n@@ -1416,9 +2124,3 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) con = 15;\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1429,5 +2131,8 @@\n-instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (RShiftVI src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+instruct reduce_maxD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fmaxv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmaxs $dst, $dst, $src1\\t # max reduction D\" %}\n@@ -1435,8 +2140,3 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n@@ -1447,5 +2147,8 @@\n-instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (RShiftVL src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct reduce_maxF_partial(vRegF dst, vRegF src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# reduce max S partial (sve)\" %}\n@@ -1453,5 +2156,242 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ S, zr, rscratch1);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxD_partial(vRegD dst, vRegD src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MaxReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# reduce max D partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector min reduction\n+\n+instruct reduce_minB(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (B)\\n\\t\"\n+            \"smov  $dst, $tmp, B, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction B\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ B,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minS(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (H)\\n\\t\"\n+            \"smov  $dst, $tmp, H, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction H\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ H,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (S)\\n\\t\"\n+            \"smov  $dst, $tmp, S, 0\\n\\t\"\n+            \"cmpw  $dst, $src1\\n\\t\"\n+            \"cselw $dst, $dst, $src1 LT\\t# min reduction S\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL(iRegLNoSp dst, iRegL src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sminv $tmp, $src2\\t# vector (sve) (D)\\n\\t\"\n+            \"smov  $dst, $tmp, D, 0\\n\\t\"\n+            \"cmp  $dst, $src1\\n\\t\"\n+            \"csel $dst, $dst, $src1 LT\\t# min reduction D\" %}\n+  ins_encode %{\n+    __ sve_sminv(as_FloatRegister($tmp$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# reduce minI partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (MinReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# reduce minL partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_sminv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::LT);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF(vRegF dst, vRegF src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (S)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t # min reduction F\" %}\n+  ins_encode %{\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD(vRegD dst, vRegD src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_fminv $dst, $src2 # vector (sve) (D)\\n\\t\"\n+            \"fmins $dst, $dst, $src1\\t # min reduction D\" %}\n+  ins_encode %{\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF_partial(vRegF dst, vRegF src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# reduce min S partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ S, zr, rscratch1);\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ S,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD_partial(vRegD dst, vRegD src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (MinReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# reduce min D partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_fminv(as_FloatRegister($dst$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n@@ -1459,2 +2399,0 @@\n-    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n@@ -1465,3 +2403,1295 @@\n-instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+\/\/ vector replicate\n+\n+instruct replicateB(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateB src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateS src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI(vReg dst, iRegIorL2I src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateI src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL(vReg dst, iRegL src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateL src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateB_imm8(vReg dst, immI8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateB con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateS con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI_imm8(vReg dst, immI8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateI con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL_imm8(vReg dst, immL8_shift8 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateL con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateF(vReg dst, vRegF src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateD(vReg dst, vRegD src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ReplicateD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift\n+\n+instruct vasrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVB dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVS dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVI dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVL dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $dst, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($shift$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) con = 7;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) con = 15;\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_asr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_asr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con == 0) {\n+      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 8) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    if (con >= 16) {\n+      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n+           as_FloatRegister($src$$reg));\n+      return;\n+    }\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    int con = (int)$shift$$constant;\n+    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src$$reg), con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sqrt\n+\n+instruct vsqrtF(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SqrtVF src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SqrtVD src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sub\n+\n+instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVB src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVS src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVI src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVL src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVF src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (SubVD src1 src2));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  ins_encode %{\n+    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n+         as_FloatRegister($src1$$reg),\n+         as_FloatRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask cast\n+\n+instruct vmaskcast(vReg dst) %{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n+            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n+  match(Set dst (VectorMaskCast dst));\n+  ins_cost(0);\n+  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+\/\/ ------------------------------ Vector cast -------------------------------\n+\n+instruct vcvtBtoS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\t# convert B to S vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\t# convert S to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\t# convert I to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\t# convert B to I vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert S to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert B to L vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, B, 0\\n\\t\"\n+            \"sve_uzp1  $dst, B, $src, tmp\\t# convert S to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ B, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\t# convert I to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\t# convert L to I vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert I to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert L to S vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $src, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert L to B vector\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert B to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert S to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtBtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastB2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, H, $src\\n\\t\"\n+            \"sve_sunpklo  $dst, S, $dst\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert B to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert L to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvt  $dst, S, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, $tmp\\t# convert D to F vector\" %}\n+  ins_encode %{\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, S, $src, S\\t# convert I to F vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastL2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_scvtf  $dst, D, $src, D\\t# convert L to D vector\" %}\n+  ins_encode %{\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\t# convert F to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\t# convert D to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastI2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_scvtf  $dst, D, $dst, D\\t# convert I to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoF(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorCastS2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, S, $src\\n\\t\"\n+            \"sve_scvtf  $dst, S, $dst, S\\t# convert S to F vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($src$$reg));\n+    __ sve_scvtf(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoD(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_sunpklo  $dst, D, $src\\n\\t\"\n+            \"sve_fcvt  $dst, D, $dst, S\\t# convert F to D vector\" %}\n+  ins_encode %{\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($src$$reg));\n+    __ sve_fcvt(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg), __ S);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\t# convert F to S vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoI(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\t# convert D to I vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_dup  $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert F to B vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoS(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t# convert D to S vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorCastF2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, S, $src, S\\n\\t\"\n+            \"sve_sunpklo  $dst, D, $dst\\t# convert F to L vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($src$$reg), __ S);\n+    __ sve_sunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoB(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_fcvtzs  $dst, D, $src, D\\n\\t\"\n+            \"sve_dup  $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1  $dst, S, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, H, $dst, tmp\\n\\t\"\n+            \"sve_uzp1  $dst, B, $dst, tmp\\n\\t# convert D to B vector\" %}\n+  ins_encode %{\n+    __ sve_fcvtzs(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($src$$reg), __ D);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+\n+instruct extractB(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractB src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, B, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, B, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 7U\\t# extract from vector(B)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ B, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 7U);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractS(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractS src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, H, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, H, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, 15U\\t# extract from vector(S)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ H, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ H, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_Register($dst$$reg), as_Register($dst$$reg), 0U, 15U);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\n+instruct extractI(iRegINoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractI src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, S, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, S, $pTmp, $src\\t# extract from vector(I)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ S, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractL(iRegLNoSp dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractL src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, D, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, D, $pTmp, $src\\t# extract from vector(L)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ D, zr, rscratch1);\n+    __ sve_lastb(as_Register($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractF(vRegF dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractF src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, S, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, S, $pTmp, $src\\t# extract from vector(F)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ S, zr, rscratch1);\n+    __ sve_lastb(as_FloatRegister($dst$$reg), __ S, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractD(vRegD dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (ExtractD src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, D, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, D, $pTmp, $src\\t# extract from vector(D)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ D, zr, rscratch1);\n+    __ sve_lastb(as_FloatRegister($dst$$reg), __ D, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+\n+instruct vtest_alltrue(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, 0\\n\\t\"\n+            \"csetw $dst, EQ\\t# VectorTest (sve) - alltrue\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_anytrue(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, -1\\n\\t\"\n+            \"csetw $dst, NE\\t# VectorTest (sve) - anytrue\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_alltrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1469,1 +3699,1 @@\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+  format %{ \"vtest_alltrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - alltrue\" %}\n@@ -1471,13 +3701,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), 0);\n+    __ csetw(as_Register($dst$$reg), Assembler::EQ);\n@@ -1488,3 +3713,6 @@\n-instruct vlsrS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+instruct vtest_anytrue_partial(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n@@ -1492,1 +3720,1 @@\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+  format %{ \"vtest_anytrue_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - anytrue\" %}\n@@ -1494,13 +3722,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), -1);\n+    __ csetw(as_Register($dst$$reg), Assembler::NE);\n@@ -1511,5 +3734,13 @@\n-instruct vlsrI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (URShiftVI src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+\n+instruct insertB_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, B, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B)\" %}\n@@ -1517,8 +3748,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ B, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ B, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1529,5 +3760,11 @@\n-instruct vlsrL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (URShiftVL src (RShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsr $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct insertS_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, H, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (S)\" %}\n@@ -1535,8 +3772,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con == 0) {\n-      __ sve_orr(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsr(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ H, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ H, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1547,5 +3784,11 @@\n-instruct vlslB_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (LShiftVB src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (B)\" %}\n+instruct insertI_small(vReg dst, vReg src, iRegIorL2I val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, S, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (I)\" %}\n@@ -1553,8 +3796,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 8) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1565,5 +3808,11 @@\n-instruct vlslS_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (LShiftVS src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (H)\" %}\n+instruct insertF_small(vReg dst, vReg src, vRegF val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, S, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n@@ -1571,8 +3820,8 @@\n-    int con = (int)$shift$$constant;\n-    if (con >= 16) {\n-      __ sve_eor(as_FloatRegister($dst$$reg), as_FloatRegister($src$$reg),\n-           as_FloatRegister($src$$reg));\n-      return;\n-    }\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ S, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1583,5 +3832,12 @@\n-instruct vlslI_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (LShiftVI src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (S)\" %}\n+\n+instruct insertL(vReg dst, vReg src, iRegL val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, D, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (L)\" %}\n@@ -1589,3 +3845,8 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ D, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ D, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1596,5 +3857,11 @@\n-instruct vlslL_imm(vReg dst, vReg src, immI shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (LShiftVL src (LShiftCntV shift)));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_lsl $dst, $src, $shift\\t# vector (sve) (D)\" %}\n+instruct insertD(vReg dst, vReg src, vRegD val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, D, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (D)\" %}\n@@ -1602,3 +3869,8 @@\n-    int con = (int)$shift$$constant;\n-    __ sve_lsl(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src$$reg), con);\n+    __ sve_index(as_FloatRegister($dst$$reg), __ D, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ D, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ D,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1609,6 +3881,13 @@\n-instruct vshiftcntB(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_BYTE));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (B)\" %}\n+\n+instruct insertB(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, B, 0, 1\\n\\t\"\n+            \"sve_dup $dst, B, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (B)\" %}\n@@ -1616,1 +3895,9 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ B, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ B, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ B, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ B,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1621,7 +3908,12 @@\n-instruct vshiftcntS(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_CHAR)));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (H)\" %}\n+instruct insertS(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, H, 0, 1\\n\\t\"\n+            \"sve_dup $dst, H, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (S)\" %}\n@@ -1629,1 +3921,9 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ H, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ H, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ H, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ H, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ H,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1634,6 +3934,12 @@\n-instruct vshiftcntI(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (S)\" %}\n+instruct insertI(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_INT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, S, 0, 1\\n\\t\"\n+            \"sve_dup $dst, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (I)\" %}\n@@ -1641,1 +3947,9 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ S, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_Register($val$$reg));\n@@ -1646,6 +3960,12 @@\n-instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG));\n-  match(Set dst (LShiftCntV cnt));\n-  match(Set dst (RShiftCntV cnt));\n-  format %{ \"sve_dup $dst, $cnt\\t# vector shift count (sve) (D)\" %}\n+instruct insertF(vReg dst, vReg src, vRegF val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, S, 0, 1\\n\\t\"\n+            \"sve_dup $dst, S, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector (F)\" %}\n@@ -1653,1 +3973,9 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ D, as_Register($cnt$$reg));\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ S, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ S, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ S, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ S,\n+               as_PRegister($pTmp$$reg), as_FloatRegister($val$$reg));\n@@ -1658,1 +3986,1 @@\n-\/\/ vector sqrt\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n@@ -1660,3 +3988,4 @@\n-instruct vsqrtF(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVF src));\n+instruct loadshuffleB(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadShuffle src));\n@@ -1664,1 +3993,1 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (S)\" %}\n+  format %{ \"sve_orr $dst, $src, $src\\t# vector load shuffle (B)\" %}\n@@ -1666,2 +3995,5 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ S,\n-         ptrue, as_FloatRegister($src$$reg));\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+                 as_FloatRegister($src$$reg),\n+                 as_FloatRegister($src$$reg));\n+    }\n@@ -1672,3 +4004,4 @@\n-instruct vsqrtD(vReg dst, vReg src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n-  match(Set dst (SqrtVD src));\n+instruct loadshuffleS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadShuffle src));\n@@ -1676,1 +4009,1 @@\n-  format %{ \"sve_fsqrt $dst, $src\\t# vector (sve) (D)\" %}\n+  format %{ \"sve_uunpklo $dst, $src\\t# vector load shuffle (B to H)\" %}\n@@ -1678,2 +4011,1 @@\n-    __ sve_fsqrt(as_FloatRegister($dst$$reg), __ D,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n@@ -1684,1 +4016,15 @@\n-\/\/ vector sub\n+instruct loadshuffleI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\t# vector load shuffle (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -1686,5 +4032,10 @@\n-instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 16);\n-  match(Set dst (SubVB src1 src2));\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (B)\" %}\n+instruct loadshuffleL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\t# vector load shuffle (B to D)\" %}\n@@ -1692,3 +4043,3 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ B,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n@@ -1699,3 +4050,7 @@\n-instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 8);\n-  match(Set dst (SubVS src1 src2));\n+\/\/ ------------------------------ Vector rearrange -------------------------------\n+\n+instruct rearrangeB(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 1);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1703,1 +4058,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (H)\" %}\n+  format %{ \"sve_tbl $dst, B, $src, $shuffle\\t# vector rearrange (B)\" %}\n@@ -1705,3 +4060,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ H,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ B,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1712,3 +4066,5 @@\n-instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVI src1 src2));\n+instruct rearrangeS(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 2);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1716,1 +4072,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  format %{ \"sve_tbl $dst, H, $src, $shuffle\\t# vector rearrange (H)\" %}\n@@ -1718,3 +4074,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ H,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1725,3 +4080,5 @@\n-instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVL src1 src2));\n+instruct rearrangeI(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 4);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1729,1 +4086,1 @@\n-  format %{ \"sve_sub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  format %{ \"sve_tbl $dst, S, $src, $shuffle\\t# vector rearrange (S)\" %}\n@@ -1731,3 +4088,2 @@\n-    __ sve_sub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ S,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1738,3 +4094,5 @@\n-instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n-  match(Set dst (SubVF src1 src2));\n+instruct rearrangeL(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == 8);\n+  match(Set dst (VectorRearrange src shuffle));\n@@ -1742,1 +4100,1 @@\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (S)\" %}\n+  format %{ \"sve_tbl $dst, D, $src, $shuffle\\t# vector rearrange (D)\" %}\n@@ -1744,3 +4102,2 @@\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ S,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ D,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n@@ -1751,3 +4108,7 @@\n-instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2);\n-  match(Set dst (SubVD src1 src2));\n+\/\/ ------------------------------ Vector Load Gather ---------------------------------\n+\n+instruct gatherI(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n@@ -1755,1 +4116,1 @@\n-  format %{ \"sve_fsub $dst, $src1, $src2\\t # vector (sve) (D)\" %}\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n@@ -1757,3 +4118,1 @@\n-    __ sve_fsub(as_FloatRegister($dst$$reg), __ D,\n-         as_FloatRegister($src1$$reg),\n-         as_FloatRegister($src2$$reg));\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1764,1 +4123,14 @@\n-\/\/ vector mask cast\n+instruct gatherL(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -1766,6 +4138,9 @@\n-instruct vmaskcast(vReg dst) %{\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->length() == n->in(1)->bottom_type()->is_vect()->length() &&\n-            n->bottom_type()->is_vect()->length_in_bytes() == n->in(1)->bottom_type()->is_vect()->length_in_bytes());\n-  match(Set dst (VectorMaskCast dst));\n-  ins_cost(0);\n-  format %{ \"vmaskcast $dst\\t# empty (sve)\" %}\n+\/\/ ------------------------------ Vector Store Scatter -------------------------------\n+\n+instruct scatterI(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (I\/F)\" %}\n@@ -1773,1 +4148,1 @@\n-    \/\/ empty\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n@@ -1775,1 +4150,16 @@\n-  ins_pipe(pipe_class_empty);\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatterL(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n@@ -1778,0 +4168,13 @@\n+\/\/ ------------------------------ Vector Load Const -------------------------------\n+\n+instruct loadconB(vReg dst, immI0 src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadConst src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_index $dst, 0, 1\\t# generate iota indices\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ B, 0, 1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":2964,"deletions":561,"binary":false,"changes":3525,"status":"modified"},{"patch":"@@ -32,2 +32,0 @@\n-\n-\/\/ 4 bit signed offset -- for predicated load\/store\n@@ -35,2 +33,11 @@\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3     )\n-dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len)\n+define(`TYPE2DATATYPE',\n+`ifelse($1, `B', `BYTE',\n+        $1, `S', `SHORT',\n+        $1, `I', `INT',\n+        $1, `L', `LONG',\n+        $1, `F', `FLOAT',\n+        $1, `D', `DOUBLE',\n+        `error($1)')')dnl\n+dnl\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2,       $3       $4   )\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type, imm_len, scale)\n@@ -40,0 +47,1 @@\n+  \/\/ (esize \/ msize) = $4\n@@ -41,1 +49,1 @@\n-            Matcher::scalable_vector_reg_size(T_BYTE)));\n+            Matcher::scalable_vector_reg_size(T_BYTE)ifelse($4, `1', `', ` \/ $4')));\n@@ -48,2 +56,4 @@\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4)\n-OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4)\n+\n+\/\/ 4 bit signed offset -- for predicated load\/store\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int,  4, 1)\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long, 4, 1)\n@@ -54,1 +64,1 @@\n-operand vmemA_indOff$1$2(iRegP reg, vmemA_imm$1Offset$2 off)\n+operand vmemA_indOff$1$2$3(iRegP reg, vmemA_imm$1Offset$2 off)\n@@ -59,1 +69,1 @@\n-  format %{ \"[$reg, $off, MUL VL]\" %}\n+  format %{ \"[$reg, $off]\" %}\n@@ -70,0 +80,2 @@\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n@@ -73,1 +85,1 @@\n-  bool op_sve_supported(int opcode);\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt);\n@@ -89,0 +101,24 @@\n+  static inline uint vector_length(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length(const MachNode* use, const MachOper* opnd) {\n+    int def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* n) {\n+    const TypeVect* vt = n->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n+  static inline uint vector_length_in_bytes(const MachNode* use, MachOper* opnd) {\n+    uint def_idx = use->operand_index(opnd);\n+    Node* def = use->in(def_idx);\n+    const TypeVect* vt = def->bottom_type()->is_vect();\n+    return vt->length_in_bytes();\n+  }\n+\n@@ -114,3 +150,3 @@\n-  static void loadStoreA_predicate(C2_MacroAssembler masm, bool is_store,\n-                                   FloatRegister reg, PRegister pg, BasicType bt,\n-                                   int opcode, Register base, int index, int size, int disp) {\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n@@ -118,2 +154,1 @@\n-    Assembler::SIMD_RegVariant type;\n-    int esize = type2aelembytes(bt);\n+    int mesize = type2aelembytes(mem_elem_bt);\n@@ -122,1 +157,1 @@\n-      switch(esize) {\n+      switch(mesize) {\n@@ -125,1 +160,0 @@\n-        type = Assembler::B;\n@@ -129,1 +163,0 @@\n-        type = Assembler::H;\n@@ -133,1 +166,0 @@\n-        type = Assembler::S;\n@@ -137,1 +169,0 @@\n-        type = Assembler::D;\n@@ -143,1 +174,2 @@\n-      (masm.*insn)(reg, type, pg, Address(base, disp \/ Matcher::scalable_vector_reg_size(T_BYTE)));\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n@@ -150,1 +182,32 @@\n-  bool op_sve_supported(int opcode) {\n+  static void sve_compare(C2_MacroAssembler masm, PRegister pd, BasicType bt,\n+                          PRegister pg, FloatRegister zn, FloatRegister zm, int cond) {\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    if (bt == T_FLOAT || bt == T_DOUBLE) {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_fcmeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_fcmne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_fcmge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_fcmgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_fcmge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_fcmgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      switch (cond) {\n+        case BoolTest::eq: masm.sve_cmpeq(pd, size, pg, zn, zm); break;\n+        case BoolTest::ne: masm.sve_cmpne(pd, size, pg, zn, zm); break;\n+        case BoolTest::ge: masm.sve_cmpge(pd, size, pg, zn, zm); break;\n+        case BoolTest::gt: masm.sve_cmpgt(pd, size, pg, zn, zm); break;\n+        case BoolTest::le: masm.sve_cmpge(pd, size, pg, zm, zn); break;\n+        case BoolTest::lt: masm.sve_cmpgt(pd, size, pg, zm, zn); break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  }\n+\n+  bool op_sve_supported(int opcode, int vlen, BasicType bt) {\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n@@ -153,1 +216,1 @@\n-        \/\/ No multiply reduction instructions\n+      \/\/ No multiply reduction instructions\n@@ -158,3 +221,1 @@\n-        \/\/ Others\n-      case Op_Extract:\n-      case Op_ExtractB:\n+      \/\/ Others\n@@ -162,5 +223,0 @@\n-      case Op_ExtractD:\n-      case Op_ExtractF:\n-      case Op_ExtractI:\n-      case Op_ExtractL:\n-      case Op_ExtractS:\n@@ -168,0 +224,1 @@\n+        return false;\n@@ -169,5 +226,0 @@\n-      case Op_AndReductionV:\n-      case Op_OrReductionV:\n-      case Op_XorReductionV:\n-      case Op_MaxReductionV:\n-      case Op_MinReductionV:\n@@ -176,11 +228,2 @@\n-      case Op_VectorBlend:\n-      case Op_VectorCast:\n-      case Op_VectorCastB2X:\n-      case Op_VectorCastD2X:\n-      case Op_VectorCastF2X:\n-      case Op_VectorCastI2X:\n-      case Op_VectorCastL2X:\n-      case Op_VectorCastS2X:\n-      case Op_VectorInsert:\n-      case Op_VectorLoadConst:\n-      case Op_VectorLoadMask:\n+        \/\/ Partial size of gather\/scatter are not supported for now.\n+        return length_in_bytes == MaxVectorSize;\n@@ -188,1 +231,0 @@\n-      case Op_VectorMaskCmp:\n@@ -190,4 +232,8 @@\n-      case Op_VectorReinterpret:\n-      case Op_VectorStoreMask:\n-      case Op_VectorTest:\n-        return false;\n+        if (vlen < 4 || length_in_bytes > MaxVectorSize) {\n+          return false;\n+        } else {\n+          return true;\n+        }\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        return Matcher::vector_size_supported(bt, vlen);\n@@ -195,1 +241,1 @@\n-        return true;\n+        break;\n@@ -197,0 +243,2 @@\n+    \/\/ By default, we only support vector operations with no less than 8 bytes and 2 elements.\n+    return 8 <= length_in_bytes && length_in_bytes <= MaxVectorSize && vlen >= 2;\n@@ -217,1 +265,1 @@\n-\/\/ Use predicated vector load\/store\n+\/\/ Unpredicated vector load\/store\n@@ -219,1 +267,2 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n+            n->as_LoadVector()->memory_size() == MaxVectorSize);\n@@ -221,1 +270,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -225,3 +274,4 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n-                         vector_element_basic_type(this), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    BasicType bt = vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -233,1 +283,2 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n+            n->as_StoreVector()->memory_size() == MaxVectorSize);\n@@ -235,1 +286,1 @@\n-  ins_cost(SVE_COST);\n+  ins_cost(4 * SVE_COST);\n@@ -239,3 +290,74 @@\n-    loadStoreA_predicate(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n-                         vector_element_basic_type(this, $src), $mem->opcode(),\n-                         as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg, ptrue,\n+                          bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n+\n+dnl\n+define(`VLoadStore', `\n+\/\/ ifelse(load, $3, Load, Store) Vector ($6 bits)\n+instruct $3V$4_vreg`'(vReg $7, vmem$4 mem)\n+%{\n+  predicate(UseSVE > 0 && `n->as_'ifelse(load, $3, Load, Store)Vector()->memory_size() == $4);\n+  match(Set ifelse(load, $3, dst (LoadVector mem), mem (StoreVector mem src)));\n+  ins_cost(4 * INSN_COST);\n+  format %{ \"$1   ifelse(load, $3, `$dst,$mem', `$mem,$src')\\t# vector ($6 bits)\" %}\n+  ins_encode( `aarch64_enc_'ifelse(load, $3, ldr, str)v$2($7, mem) );\n+  ins_pipe(v$3`_reg_mem'ifelse(eval($4 * 8), 128, 128, 64));\n+%}')dnl\n+dnl        $1    $2 $3     $4  $5 $6   $7\n+VLoadStore(ldrh, H, load,  2,  D, 16,  dst)\n+VLoadStore(strh, H, store, 2,  D, 16,  src)\n+VLoadStore(ldrs, S, load,  4,  D, 32,  dst)\n+VLoadStore(strs, S, store, 4,  D, 32,  src)\n+VLoadStore(ldrd, D, load,  8,  D, 64,  dst)\n+VLoadStore(strd, D, store, 8,  D, 64,  src)\n+VLoadStore(ldrq, Q, load, 16,  X, 128, dst)\n+VLoadStore(strq, Q, store, 16, X, 128, src)\n+\n+\/\/ Predicated vector load\/store, based on the vector length of the node.\n+\/\/ Only load\/store values in the range of the memory_size. This is needed\n+\/\/ when the memory_size is lower than the hardware supported max vector size.\n+\/\/ And this might happen for Vector API mask vector load\/store.\n+instruct loadV_partial(vReg dst, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n+            n->as_LoadVector()->memory_size() < MaxVectorSize);\n+  match(Set dst (LoadVector mem));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(6 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_ldr $dst, $pTmp, $mem\\t # load vector predicated\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    __ mov(rscratch1, vector_length(this));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_partial(vReg src, vmemA mem, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n+            n->as_StoreVector()->memory_size() < MaxVectorSize);\n+  match(Set mem (StoreVector mem src));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"mov rscratch1, vector_length\\n\\t\"\n+            \"sve_whilelo $pTmp, zr, rscratch1\\n\\t\"\n+            \"sve_str $src, $pTmp, $mem\\t # store vector predicated\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src);\n+    __ mov(rscratch1, vector_length(this, $src));\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    FloatRegister src_reg = as_FloatRegister($src$$reg);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n+                          as_PRegister($pTmp$$reg), bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n@@ -244,0 +366,15 @@\n+%}dnl\n+\n+\n+\/\/ vector reinterpret\n+\n+instruct reinterpret(vReg dst) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() ==\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src == dst\n+  match(Set dst (VectorReinterpret dst));\n+  ins_cost(0);\n+  format %{ \"# reinterpret $dst\\t# do nothing\" %}\n+  ins_encode %{\n+    \/\/ empty\n+  %}\n+  ins_pipe(pipe_class_empty);\n@@ -246,0 +383,22 @@\n+instruct reinterpretResize(vReg dst, vReg src, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() !=\n+                          n->in(1)->bottom_type()->is_vect()->length_in_bytes());  \/\/ src != dst\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"reinterpretResize $dst, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ mov(rscratch1, length_in_bytes_resize);\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), __ B, zr, rscratch1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ B, 0);\n+    __ sve_sel(as_FloatRegister($dst$$reg), __ B, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src$$reg), as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -251,1 +410,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5 &&\n+  predicate(UseSVE > 0 &&\n@@ -263,0 +422,1 @@\n+\n@@ -275,1 +435,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -299,1 +459,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= $3);\n+  predicate(UseSVE > 0);\n@@ -330,1 +490,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -355,1 +515,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -375,1 +535,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -393,1 +553,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -413,1 +573,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0);\n@@ -438,1 +598,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -460,1 +620,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -483,1 +643,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -505,1 +665,1 @@\n-  predicate(UseFMA && UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseFMA && UseSVE > 0);\n@@ -527,1 +687,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -551,1 +711,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3);\n+  predicate(UseSVE > 0);\n@@ -573,1 +733,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n+  predicate(UseSVE > 0);\n@@ -597,1 +757,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() >= $4);\n+  predicate(UseSVE > 0);\n@@ -615,1 +775,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 4);\n+  predicate(UseSVE > 0);\n@@ -617,1 +777,1 @@\n-  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\"  %}\n+  format %{ \"sve_cnt $dst, $src\\t# vector (sve) (S)\\n\\t\" %}\n@@ -622,1 +782,262 @@\n-%}dnl\n+%}\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vReg dst, vReg src1, vReg src2, immI cond, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src1, $src2\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, -1\\t # vector mask cmp (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src1$$reg),\n+                as_FloatRegister($src2$$reg), (int)$cond$$constant);\n+    __ sve_cpy(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), -1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vReg src3, pRegGov pTmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) src3));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src3, -1\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size =\n+              elemType_to_regVariant(vector_element_basic_type(this));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src3$$reg), -1);\n+    __ sve_sel(as_FloatRegister($dst$$reg), size, as_PRegister($pTmp$$reg),\n+               as_FloatRegister($src2$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector blend with compare\n+\n+instruct vblend_maskcmp(vReg dst, vReg src1, vReg src2, vReg src3,\n+                        vReg src4, pRegGov pTmp, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) (VectorMaskCmp (Binary src3 src4) cond)));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_cmp $pTmp, $src3, $src4\\t # vector cmp (sve)\\n\\t\"\n+            \"sve_sel $dst, $pTmp, $src2, $src1\\t # vector blend (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this);\n+    sve_compare(C2_MacroAssembler(&cbuf), as_PRegister($pTmp$$reg), bt,\n+                ptrue, as_FloatRegister($src3$$reg),\n+                as_FloatRegister($src4$$reg), (int)$cond$$constant);\n+    __ sve_sel(as_FloatRegister($dst$$reg), elemType_to_regVariant(bt),\n+               as_PRegister($pTmp$$reg), as_FloatRegister($src2$$reg),\n+               as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load mask\n+\n+instruct vloadmaskB(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector load mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskS(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ H, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskI(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ S, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskL(vReg dst, vReg src) %{\n+  predicate(UseSVE > 0 &&\n+            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadMask src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # vector load mask (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ D, ptrue, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremaskB(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_neg $dst, $src\\t # vector store mask (B)\" %}\n+  ins_encode %{\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskS(vReg dst, vReg src, vReg tmp, immI_2 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_dup $tmp, H, 0\\n\\t\"\n+            \"sve_uzp1 $dst, B, $src, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (H to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ H, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskI(vReg dst, vReg src, vReg tmp, immI_4 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_dup $tmp, S, 0\\n\\t\"\n+            \"sve_uzp1 $dst, H, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (S to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ S, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremaskL(vReg dst, vReg src, vReg tmp, immI_8 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_dup $tmp, D, 0\\n\\t\"\n+            \"sve_uzp1 $dst, S, $src, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, H, $dst, $tmp\\n\\t\"\n+            \"sve_uzp1 $dst, B, $dst, $tmp\\n\\t\"\n+            \"sve_neg $dst, B, $dst\\t # vector store mask (sve) (D to B)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($tmp$$reg), __ D, 0);\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ S,\n+                as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ H,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_uzp1(as_FloatRegister($dst$$reg), __ B,\n+                as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_neg(as_FloatRegister($dst$$reg), __ B, ptrue,\n+               as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl\n+dnl VLOADMASK_LOADV($1,    $2  )\n+dnl VLOADMASK_LOADV(esize, cond)\n+define(`VLOADMASK_LOADV', `\n+instruct vloadmask_loadV_$1(vReg dst, ifelse($1, `byte', vmemA, indirect) mem) %{\n+  predicate(UseSVE > 0 && n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) $2);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_ld1b $dst, $mem\\n\\t\"\n+            \"sve_neg $dst, $dst\\t # load vector mask (sve)\" %}\n+  ins_encode %{\n+    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n+    BasicType to_vect_bt = vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_vect_variant = elemType_to_regVariant(to_vect_bt);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg, ptrue,\n+                          T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_neg(dst_reg, to_vect_variant, ptrue, dst_reg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+define(`ARGLIST',\n+`ifelse($1, `byte', vmemA, indirect) mem, vReg src, vReg tmp, ifelse($1, `byte', immI_1, immI_gt_1) esize')\n+dnl\n+dnl STOREV_VSTOREMASK($1,  )\n+dnl STOREV_VSTOREMASK(esize)\n+define(`STOREV_VSTOREMASK', `\n+instruct storeV_vstoremask_$1(ARGLIST($1)) %{\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() *\n+                          n->as_StoreVector()->in(MemNode::ValueIn)->in(2)->get_int() == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_neg $tmp, $src\\n\\t\"\n+            \"sve_st1b $tmp, $mem\\t # store vector mask (sve)\" %}\n+  ins_encode %{\n+    BasicType from_vect_bt = vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant from_vect_variant = elemBytes_to_regVariant($esize$$constant);\n+    __ sve_neg(as_FloatRegister($tmp$$reg), from_vect_variant, ptrue,\n+               as_FloatRegister($src$$reg));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+undefine(ARGLIST)dnl\n+dnl\n+\/\/ load\/store mask vector\n+VLOADMASK_LOADV(byte, == 1)\n+VLOADMASK_LOADV(non_byte, > 1)\n+STOREV_VSTOREMASK(byte)\n+STOREV_VSTOREMASK(non_byte)\n@@ -629,2 +1050,2 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -648,0 +1069,5 @@\n+define(`PREDICATE', `ifelse($1, AddReductionVL,\n+       `predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n+       `predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')')dnl\n+dnl\n@@ -652,2 +1078,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6);\n+  PREDICATE($2)\n@@ -668,0 +1093,1 @@\n+undefine(PREDICATE)dnl\n@@ -673,1 +1099,1 @@\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n@@ -685,1 +1111,1 @@\n-REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE,  sxtb)\n+REDUCE_ADD_EXT(reduce_addB, AddReductionVI, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n@@ -692,12 +1118,7 @@\n-dnl\n-dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )\n-dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)\n-define(`REDUCE_FMINMAX', `\n-instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{\n-  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() >= 16);\n-  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"sve_f$1v $dst, $src2 # vector (sve) (S)\\n\\t\"\n-            \"f$1s $dst, $dst, $src1\\t # $1 reduction $2\" %}\n+instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVI src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n@@ -705,3 +1126,13 @@\n-    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src2$$reg));\n-    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ addw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n@@ -710,10 +1141,1 @@\n-%}')dnl\n-\/\/ vector max reduction\n-REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)\n-REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)\n-\n-\/\/ vector min reduction\n-REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)\n-REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)\n-\n-\/\/ vector Math.rint, floor, ceil\n+%}\n@@ -721,5 +1143,7 @@\n-instruct vroundD(vReg dst, vReg src, immI rmode) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= 2 &&\n-            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (RoundDoubleModeV src rmode));\n-  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AddReductionVL src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n@@ -727,14 +1151,6 @@\n-    switch ($rmode$$constant) {\n-      case RoundDoubleModeNode::rmode_rint:\n-        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_floor:\n-        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-      case RoundDoubleModeNode::rmode_ceil:\n-        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n-             ptrue, as_FloatRegister($src$$reg));\n-        break;\n-    }\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_uaddv(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ add($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -745,6 +1161,7 @@\n-dnl REPLICATE($1,        $2,      $3,      $4,   $5         )\n-dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n-define(`REPLICATE', `\n-instruct $1(vReg dst, $3 src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src));\n+dnl\n+dnl REDUCE_ADDF_PARTIAL($1,        $2,     $3,      $4  )\n+dnl REDUCE_ADDF_PARTIAL(insn_name, suffix, reg_dst, size)\n+define(`REDUCE_ADDF_PARTIAL', `\n+instruct $1($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set src1_dst (AddReductionV$2 src1_dst src2));\n@@ -752,1 +1169,2 @@\n-  format %{ \"sve_dup  $dst, $src\\t# vector (sve) ($4)\" %}\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_add$2 $src1_dst, $src1_dst, $src2\\t# add$2 reduction partial (sve) ($4)\" %}\n@@ -754,1 +1172,4 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ $4, zr, rscratch1);\n+    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n@@ -759,6 +1180,11 @@\n-dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )\n-dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)\n-define(`REPLICATE_IMM8', `\n-instruct $1(vReg dst, $3 con) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 con));\n+REDUCE_ADDF_PARTIAL(reduce_addF_partial, F, vRegF, S)\n+REDUCE_ADDF_PARTIAL(reduce_addD_partial, D, vRegD, D)\n+dnl\n+dnl REDUCE_AND_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -766,1 +1192,4 @@\n-  format %{ \"sve_dup  $dst, $con\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"andw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # and reduction $5\" %}\n@@ -768,1 +1197,5 @@\n-    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n@@ -773,6 +1206,8 @@\n-dnl FREPLICATE($1,        $2,      $3,      $4,   $5         )\n-dnl FREPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n-define(`FREPLICATE', `\n-instruct $1(vReg dst, $3 src) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n-  match(Set dst ($2 src));\n+dnl REDUCE_AND($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_AND(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_AND', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n@@ -780,1 +1215,3 @@\n-  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) ($4)\" %}\n+  format %{ \"sve_andv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # and reduction $5\" %}\n@@ -782,2 +1219,4 @@\n-    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,\n-         ptrue, as_FloatRegister($src$$reg));\n+    __ sve_andv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n@@ -788,18 +1227,12 @@\n-\/\/ vector replicate\n-REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)\n-REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)\n-REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)\n-REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)\n-REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)\n-REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)\n-REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)\n-REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)\n-FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)\n-FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)\n-dnl\n-dnl VSHIFT_TRUE_PREDICATE($1,        $2,      $3,   $4,          $5  )\n-dnl VSHIFT_TRUE_PREDICATE(insn_name, op_name, size, min_vec_len, insn)\n-define(`VSHIFT_TRUE_PREDICATE', `\n-instruct $1(vReg dst, vReg shift) %{\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $4);\n-  match(Set dst ($2 dst shift));\n+\/\/ vector and reduction\n+REDUCE_AND_EXT(reduce_andB, AndReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_AND_EXT(reduce_andS, AndReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_AND(reduce_andI, AndReductionV, iRegINoSp, iRegIorL2I, S, T_INT, andw)\n+REDUCE_AND(reduce_andL, AndReductionV, iRegLNoSp, iRegL, D, T_LONG, andr)\n+\n+instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n@@ -807,1 +1240,1 @@\n-  format %{ \"$5 $dst, $dst, $shift\\t# vector (sve) ($3)\" %}\n+  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n@@ -809,1 +1242,460 @@\n-    __ $5(as_FloatRegister($dst$$reg), __ $3,\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ andw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (AndReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_andv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ andr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_OR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"orrw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_OR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_OR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_OR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # or reduction $5\" %}\n+  ins_encode %{\n+    __ sve_orv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector or reduction\n+REDUCE_OR_EXT(reduce_orB, OrReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_OR_EXT(reduce_orS, OrReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_OR(reduce_orI, OrReductionV, iRegINoSp, iRegIorL2I, S, T_INT, orrw)\n+REDUCE_OR(reduce_orL, OrReductionV, iRegLNoSp, iRegL, D, T_LONG, orr)\n+\n+instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ orrw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (OrReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_orv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ orr($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_XOR_EXT($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR_EXT(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR_EXT', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"eorw  $dst, $dst, $src1\\n\\t\"\n+            \"$7  $dst, $dst\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    __ $7($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_XOR($1,        $2,      $3,      $4,      $5,   $6,        $7   )\n+dnl REDUCE_XOR(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1)\n+define(`REDUCE_XOR', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_eorv $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"umov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $dst, $src1\\t # eor reduction $5\" %}\n+  ins_encode %{\n+    __ sve_eorv(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector xor reduction\n+REDUCE_XOR_EXT(reduce_eorB, XorReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE, sxtb)\n+REDUCE_XOR_EXT(reduce_eorS, XorReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, sxth)\n+REDUCE_XOR(reduce_eorI, XorReductionV, iRegINoSp, iRegIorL2I, S, T_INT, eorw)\n+REDUCE_XOR(reduce_eorL, XorReductionV, iRegLNoSp, iRegL, D, T_LONG, eor)\n+\n+instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# xorI reduction partial (sve) (may extend)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), variant,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ eorw($dst$$Register, $dst$$Register, $src1$$Register);\n+    if (bt == T_BYTE) {\n+      __ sxtb($dst$$Register, $dst$$Register);\n+    } else if (bt == T_SHORT) {\n+      __ sxth($dst$$Register, $dst$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (XorReductionV src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# xorL reduction partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_eorv(as_FloatRegister($vtmp$$reg), __ D,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ eor($dst$$Register, $dst$$Register, $src1$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_MAXMIN($1,        $2,      $3,      $4,      $5,   $6,        $7,    $8,    $9 , $10    )\n+dnl REDUCE_MAXMIN(insn_name, op_name, reg_dst, reg_src, size, elem_type, insn1, insn2, cmp, min_max)\n+define(`REDUCE_MAXMIN', `\n+instruct $1($3 dst, $4 src1, vReg src2, vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $6 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_s$10v $tmp, $src2\\t# vector (sve) ($5)\\n\\t\"\n+            \"smov  $dst, $tmp, $5, 0\\n\\t\"\n+            \"$7  $dst, $src1\\n\\t\"\n+            \"$8 $dst, $dst, $src1 $9\\t# $10 reduction $5\" %}\n+  ins_encode %{\n+    __ sve_s$10v(as_FloatRegister($tmp$$reg), __ $5,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ ifelse($5,D,u,s)mov($dst$$Register, as_FloatRegister($tmp$$reg), __ $5, 0);\n+    __ $7($dst$$Register, $src1$$Register);\n+    __ $8(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$9);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_I_PARTIAL($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_mame, cmp)\n+define(`REDUCE_MAXMIN_I_PARTIAL', `\n+instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            (n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_BYTE ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_SHORT ||\n+             n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_INT));\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# reduce $1I partial (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = vector_element_basic_type(this, $src2);\n+    Assembler::SIMD_RegVariant variant = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), variant, zr, rscratch1);\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), variant,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ smov($dst$$Register, as_FloatRegister($vtmp$$reg), variant, 0);\n+    __ cmpw($dst$$Register, $src1$$Register);\n+    __ cselw(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_PARTIAL($1,      $2,      $3 )\n+dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name, cmp)\n+define(`REDUCE_MAXMIN_L_PARTIAL', `\n+instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# reduce $1L partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ D, zr, rscratch1);\n+    __ sve_s$1v(as_FloatRegister($vtmp$$reg), __ D,\n+                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ umov($dst$$Register, as_FloatRegister($vtmp$$reg), __ D, 0);\n+    __ cmp($dst$$Register, $src1$$Register);\n+    __ csel(as_Register($dst$$reg), as_Register($dst$$reg), as_Register($src1$$reg), Assembler::$3);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_FMINMAX($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX', `\n+instruct reduce_$1$2($5 dst, $5 src1, vReg src2) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"sve_f$1v $dst, $src2 # vector (sve) ($4)\\n\\t\"\n+            \"f$1s $dst, $dst, $src1\\t # $1 reduction $2\" %}\n+  ins_encode %{\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+dnl REDUCE_FMINMAX_PARTIAL($1,      $2,          $3,           $4,   $5         )\n+dnl REDUCE_FMINMAX_PARTIAL(min_max, name_suffix, element_type, size, reg_src_dst)\n+define(`REDUCE_FMINMAX_PARTIAL', `\n+instruct reduce_$1$2_partial($5 dst, $5 src1, vReg src2,\n+                             pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n+            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n+  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# reduce $1 $4 partial (sve)\" %}\n+  ins_encode %{\n+    __ mov(rscratch1, vector_length(this, $src2));\n+    __ sve_whilelo(as_PRegister($ptmp$$reg), __ $4, zr, rscratch1);\n+    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4,\n+         as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n+    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector max reduction\n+REDUCE_MAXMIN(reduce_maxB, MaxReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE,  cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxS, MaxReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxI, MaxReductionV, iRegINoSp, iRegIorL2I, S, T_INT,   cmpw, cselw, GT, max)\n+REDUCE_MAXMIN(reduce_maxL, MaxReductionV, iRegLNoSp, iRegL,      D, T_LONG,  cmp,  csel,  GT, max)\n+REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV, GT)\n+REDUCE_FMINMAX(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX(max, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PARTIAL(max, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PARTIAL(max, D, T_DOUBLE, D, vRegD)\n+\n+\/\/ vector min reduction\n+REDUCE_MAXMIN(reduce_minB, MinReductionV, iRegINoSp, iRegIorL2I, B, T_BYTE,  cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minS, MinReductionV, iRegINoSp, iRegIorL2I, H, T_SHORT, cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minI, MinReductionV, iRegINoSp, iRegIorL2I, S, T_INT,   cmpw, cselw, LT, min)\n+REDUCE_MAXMIN(reduce_minL, MinReductionV, iRegLNoSp, iRegL,      D, T_LONG,  cmp,  csel,  LT, min)\n+REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV, LT)\n+REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV, LT)\n+REDUCE_FMINMAX(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX(min, D, T_DOUBLE, D, vRegD)\n+REDUCE_FMINMAX_PARTIAL(min, F, T_FLOAT,  S, vRegF)\n+REDUCE_FMINMAX_PARTIAL(min, D, T_DOUBLE, D, vRegD)\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"sve_frint $dst, $src, $rmode\\t# vector (sve) (D)\" %}\n+  ins_encode %{\n+    switch ($rmode$$constant) {\n+      case RoundDoubleModeNode::rmode_rint:\n+        __ sve_frintn(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_floor:\n+        __ sve_frintm(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+      case RoundDoubleModeNode::rmode_ceil:\n+        __ sve_frintp(as_FloatRegister($dst$$reg), __ D,\n+             ptrue, as_FloatRegister($src$$reg));\n+        break;\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl REPLICATE($1,        $2,      $3,      $4,   $5         )\n+dnl REPLICATE(insn_name, op_name, reg_src, size, min_vec_len)\n+define(`REPLICATE', `\n+instruct $1(vReg dst, $3 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $src\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REPLICATE_IMM8($1,        $2,      $3,       $4,   $5         )\n+dnl REPLICATE_IMM8(insn_name, op_name, imm_type, size, min_vec_len)\n+define(`REPLICATE_IMM8', `\n+instruct $1(vReg dst, $3 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 con));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_dup  $dst, $con\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $4, $con$$constant);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl FREPLICATE($1,        $2,      $3,        $4)\n+dnl FREPLICATE(insn_name, op_name, reg_src, size)\n+define(`FREPLICATE', `\n+instruct $1(vReg dst, $3 src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cpy  $dst, $src\\t# vector (sve) ($4)\" %}\n+  ins_encode %{\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $4,\n+         ptrue, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+\n+\/\/ vector replicate\n+REPLICATE(replicateB, ReplicateB, iRegIorL2I, B, 16)\n+REPLICATE(replicateS, ReplicateS, iRegIorL2I, H, 8)\n+REPLICATE(replicateI, ReplicateI, iRegIorL2I, S, 4)\n+REPLICATE(replicateL, ReplicateL, iRegL,      D, 2)\n+REPLICATE_IMM8(replicateB_imm8, ReplicateB, immI8,        B, 16)\n+REPLICATE_IMM8(replicateS_imm8, ReplicateS, immI8_shift8, H, 8)\n+REPLICATE_IMM8(replicateI_imm8, ReplicateI, immI8_shift8, S, 4)\n+REPLICATE_IMM8(replicateL_imm8, ReplicateL, immL8_shift8, D, 2)\n+FREPLICATE(replicateF, ReplicateF, vRegF, S, 4)\n+FREPLICATE(replicateD, ReplicateD, vRegD, D, 2)\n+dnl\n+dnl VSHIFT_TRUE_PREDICATE($1,        $2,      $3,   $4,          $5  )\n+dnl VSHIFT_TRUE_PREDICATE(insn_name, op_name, size, min_vec_len, insn)\n+define(`VSHIFT_TRUE_PREDICATE', `\n+instruct $1(vReg dst, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst ($2 dst shift));\n+  ins_cost(SVE_COST);\n+  format %{ \"$5 $dst, $dst, $shift\\t# vector (sve) ($3)\" %}\n+  ins_encode %{\n+    __ $5(as_FloatRegister($dst$$reg), __ $3,\n@@ -819,1 +1711,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $5);\n+  predicate(UseSVE > 0);\n@@ -855,1 +1747,1 @@\n-  predicate(UseSVE > 0 && n->as_Vector()->length() >= $3 &&\n+  predicate(UseSVE > 0 &&\n@@ -922,0 +1814,686 @@\n+\/\/ ------------------------------ Vector cast -------------------------------\n+dnl\n+define(`VECTOR_CAST_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4\n+VECTOR_CAST_EXTEND1(B, S, sunpklo, H)\n+VECTOR_CAST_EXTEND1(S, I, sunpklo, S)\n+VECTOR_CAST_EXTEND1(I, L, sunpklo, D)\n+dnl\n+dnl\n+define(`VECTOR_CAST_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4 $5\n+VECTOR_CAST_EXTEND2(B, I, sunpklo, H, S)\n+VECTOR_CAST_EXTEND2(S, L, sunpklo, S, D)\n+dnl\n+dnl\n+define(`VECTOR_CAST_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3       $4 $5 $6\n+VECTOR_CAST_EXTEND3(B, L, sunpklo, H, S, D)\n+dnl\n+dnl\n+define(`VECTOR_CAST_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5\n+VECTOR_CAST_NARROW1(S, B, dup, B, uzp1)\n+VECTOR_CAST_NARROW1(I, S, dup, H, uzp1)\n+VECTOR_CAST_NARROW1(L, I, dup, S, uzp1)\n+dnl\n+dnl\n+define(`VECTOR_CAST_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5    $6\n+VECTOR_CAST_NARROW2(I, B, dup, H, uzp1, B)\n+VECTOR_CAST_NARROW2(L, S, dup, S, uzp1, H)\n+dnl\n+dnl\n+define(`VECTOR_CAST_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $tmp, $4, 0\\n\\t\"\n+            \"sve_$5  $dst, $4, $src, tmp\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$5  $dst, $7, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($tmp$$reg), __ $4, 0);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2 $3   $4 $5    $6 $7\n+VECTOR_CAST_NARROW3(L, B, dup, S, uzp1, H, B)\n+dnl\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$6  $dst, $5, $dst, $5\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$6(as_FloatRegister($dst$$reg), __ $5, ptrue, as_FloatRegister($dst$$reg), __ $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5 $6\n+VECTOR_CAST_I2F_EXTEND2(B, F, sunpklo, H, S, scvtf)\n+VECTOR_CAST_I2F_EXTEND2(S, D, sunpklo, S, D, scvtf)\n+dnl\n+dnl\n+define(`VECTOR_CAST_I2F_EXTEND3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$3  $dst, $5, $dst\\n\\t\"\n+            \"sve_$3  $dst, $6, $dst\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $5, as_FloatRegister($dst$$reg));\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5 $6 $7\n+VECTOR_CAST_I2F_EXTEND3(B, D, sunpklo, H, S, D, scvtf)\n+dnl\n+dnl\n+define(`VECTOR_CAST_X2F_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $5\\n\\t\"\n+            \"sve_$6  $tmp, $7, 0\\n\\t\"\n+            \"sve_$8  $dst, $7, $dst, $tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $5);\n+    __ sve_$6(as_FloatRegister($tmp$$reg), __ $7, 0);\n+    __ sve_$8(as_FloatRegister($dst$$reg), __ $7, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3     $4 $5 $6   $7 $8\n+VECTOR_CAST_X2F_NARROW1(L, F, scvtf, S, D, dup, S, uzp1)\n+VECTOR_CAST_X2F_NARROW1(D, F, fcvt,  S, D, dup, S, uzp1)\n+dnl\n+dnl\n+define(`VECTOR_CAST_X2X', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl             $1 $2 $3      $4\n+VECTOR_CAST_X2X(I, F, scvtf,  S)\n+VECTOR_CAST_X2X(L, D, scvtf,  D)\n+VECTOR_CAST_X2X(F, I, fcvtzs, S)\n+VECTOR_CAST_X2X(D, L, fcvtzs, D)\n+dnl\n+dnl\n+define(`VECTOR_CAST_X2F_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src\\n\\t\"\n+            \"sve_$5  $dst, $4, $dst, $6\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, as_FloatRegister($src$$reg));\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($dst$$reg), __ $6);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3       $4 $5     $6\n+VECTOR_CAST_X2F_EXTEND1(I, D, sunpklo, D, scvtf, D)\n+VECTOR_CAST_X2F_EXTEND1(S, F, sunpklo, S, scvtf, S)\n+VECTOR_CAST_X2F_EXTEND1(F, D, sunpklo, D, fcvt,  S)\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7\n+VECTOR_CAST_F2X_NARROW1(F, S, fcvtzs, S, dup, H, uzp1)\n+VECTOR_CAST_F2X_NARROW1(D, I, fcvtzs, D, dup, S, uzp1)\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW2', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7    $8\n+VECTOR_CAST_F2X_NARROW2(F, B, fcvtzs, S, dup, H, uzp1, B)\n+VECTOR_CAST_F2X_NARROW2(D, S, fcvtzs, D, dup, S, uzp1, H)\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_EXTEND1', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $dst, $6, $dst\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5       $6\n+VECTOR_CAST_F2X_EXTEND1(F, L, fcvtzs, S, sunpklo, D)\n+dnl\n+dnl\n+define(`VECTOR_CAST_F2X_NARROW3', `\n+instruct vcvt$1to$2`'(vReg dst, vReg src, vReg tmp)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($2));\n+  match(Set dst (VectorCast$1`'2X src));\n+  effect(TEMP tmp);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_$3  $dst, $4, $src, $4\\n\\t\"\n+            \"sve_$5  $tmp, $6, 0\\n\\t\"\n+            \"sve_$7  $dst, $6, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $8, $dst, tmp\\n\\t\"\n+            \"sve_$7  $dst, $9, $dst, tmp\\n\\t# convert $1 to $2 vector\" %}\n+  ins_encode %{\n+    __ sve_$3(as_FloatRegister($dst$$reg), __ $4, ptrue, as_FloatRegister($src$$reg), __ $4);\n+    __ sve_$5(as_FloatRegister($tmp$$reg), __ $6, 0);\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $6, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $8, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+    __ sve_$7(as_FloatRegister($dst$$reg), __ $9, as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                     $1 $2 $3      $4 $5   $6 $7    $8 $9\n+VECTOR_CAST_F2X_NARROW3(D, B, fcvtzs, D, dup, S, uzp1, H, B)\n+\n+\/\/ ------------------------------ Vector extract ---------------------------------\n+define(`VECTOR_EXTRACT_SXT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, $3, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, $3, $pTmp, $src\\n\\t\"\n+            \"sbfmw $dst, $dst, 0U, $5\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ $3, zr, rscratch1);\n+    __ sve_lastb(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+    __ sbfmw(as_$4($dst$$reg), as_$4($dst$$reg), 0U, $5);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                $1 $2         $3 $4        $5\n+VECTOR_EXTRACT_SXT(B, iRegINoSp, B, Register, 7U)\n+VECTOR_EXTRACT_SXT(S, iRegINoSp, H, Register, 15U)\n+\n+dnl\n+define(`VECTOR_EXTRACT', `\n+instruct extract$1`'($2 dst, vReg src, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"movzw rscratch1, $idx\\n\\t\"\n+            \"sve_whilele $pTmp, $3, zr, rscratch1\\n\\t\"\n+            \"sve_lastb $dst, $3, $pTmp, $src\\t# extract from vector($1)\" %}\n+  ins_encode %{\n+    __ movzw(rscratch1, (int)($idx$$constant));\n+    __ sve_whilele(as_PRegister($pTmp$$reg), __ $3, zr, rscratch1);\n+    __ sve_lastb(as_$4($dst$$reg), __ $3, as_PRegister($pTmp$$reg), as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl            $1 $2         $3 $4\n+VECTOR_EXTRACT(I, iRegINoSp, S, Register)\n+VECTOR_EXTRACT(L, iRegLNoSp, D, Register)\n+VECTOR_EXTRACT(F, vRegF,     S, FloatRegister)\n+VECTOR_EXTRACT(D, vRegD,     D, FloatRegister)\n+\n+\/\/ ------------------------------- VectorTest ----------------------------------\n+dnl\n+dnl VTEST($1,      $2,   $3,  $4  )\n+dnl VTEST(op_name, pred, imm, cond)\n+define(`VTEST', `\n+instruct vtest_$1`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_cmpeq $pTmp, $src1, $3\\n\\t\"\n+            \"csetw $dst, $4\\t# VectorTest (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, ptrue,\n+                 as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST(alltrue, overflow, 0, EQ)\n+VTEST(anytrue, ne,      -1, NE)\n+dnl\n+dnl\n+dnl VTEST_PARTIAL($1,      $2,   $3,  $4  )\n+dnl VTEST_PARTIAL(op_name, pred, imm, cond)\n+define(`VTEST_PARTIAL', `\n+instruct vtest_$1_partial`'(iRegINoSp dst, vReg src1, vReg src2, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->in(1)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::$2);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP pTmp, KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vtest_$1_partial $dst, $src1, $src2\\t# VectorTest partial (sve) - $1\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    BasicType bt = vector_element_basic_type(this, $src1);\n+    Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+    __ mov(rscratch1, vector_length(this, $src1));\n+    __ sve_whilelo(as_PRegister($pTmp$$reg), size, zr, rscratch1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), size, as_PRegister($pTmp$$reg),\n+                 as_FloatRegister($src1$$reg), $3);\n+    __ csetw(as_Register($dst$$reg), Assembler::$4);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VTEST_PARTIAL(alltrue, overflow, 0, EQ)\n+VTEST_PARTIAL(anytrue, ne,      -1, NE)\n+\n+\/\/ ------------------------------ Vector insert ---------------------------------\n+define(`VECTOR_INSERT_SMALL', `\n+instruct insert$1_small`'(vReg dst, vReg src, $2 val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() <= 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, $3, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ $3, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl                 $1 $2          $3 $4\n+VECTOR_INSERT_SMALL(B, iRegIorL2I, B, Register)\n+VECTOR_INSERT_SMALL(S, iRegIorL2I, H, Register)\n+VECTOR_INSERT_SMALL(I, iRegIorL2I, S, Register)\n+VECTOR_INSERT_SMALL(F, vRegF,      S, FloatRegister)\n+\n+define(`VECTOR_INSERT_D', `\n+instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pTmp, KILL cr);\n+  ins_cost(4 * SVE_COST);\n+  format %{ \"sve_index $dst, $3, -16, 1\\n\\t\"\n+            \"sve_cmpeq $pTmp, $dst, ($idx-#16) # shift from [0, 31] to [-16, 15]\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ $3, -16, 1);\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,\n+                 as_FloatRegister($dst$$reg), (int)($idx$$constant) - 16);\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl             $1 $2     $3 $4\n+VECTOR_INSERT_D(L, iRegL, D, Register)\n+VECTOR_INSERT_D(D, vRegD, D, FloatRegister)\n+\n+define(`VECTOR_INSERT', `\n+instruct insert$1`'(vReg dst, vReg src, $2 val, immI idx, vReg tmp1, pRegGov pTmp, rFlagsReg cr)\n+%{\n+  predicate(UseSVE > 0 && n->as_Vector()->length() > 32 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_`'TYPE2DATATYPE($1));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP pTmp, KILL cr);\n+  ins_cost(5 * SVE_COST);\n+  format %{ \"sve_index $tmp1, $3, 0, 1\\n\\t\"\n+            \"sve_dup $dst, $3, $idx\\n\\t\"\n+            \"sve_cmpeq $pTmp, $tmp1, $dst\\n\\t\"\n+            \"sve_orr $dst, $src, $src\\n\\t\"\n+            \"sve_cpy $dst, $pTmp, $val\\t# insert into vector ($1)\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($tmp1$$reg), __ $3, 0, 1);\n+    __ sve_dup(as_FloatRegister($dst$$reg), __ $3, (int)($idx$$constant));\n+    __ sve_cmpeq(as_PRegister($pTmp$$reg), __ $3, ptrue,\n+                 as_FloatRegister($tmp1$$reg), as_FloatRegister($dst$$reg));\n+    __ sve_orr(as_FloatRegister($dst$$reg),\n+               as_FloatRegister($src$$reg),\n+               as_FloatRegister($src$$reg));\n+    __ sve_cpy(as_FloatRegister($dst$$reg), __ $3,\n+               as_PRegister($pTmp$$reg), as_$4($val$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl           $1 $2          $3 $4\n+VECTOR_INSERT(B, iRegIorL2I, B, Register)\n+VECTOR_INSERT(S, iRegIorL2I, H, Register)\n+VECTOR_INSERT(I, iRegIorL2I, S, Register)\n+VECTOR_INSERT(F, vRegF,      S, FloatRegister)\n+\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+\n+instruct loadshuffleB(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_orr $dst, $src, $src\\t# vector load shuffle (B)\" %}\n+  ins_encode %{\n+    if (as_FloatRegister($dst$$reg) != as_FloatRegister($src$$reg)) {\n+      __ sve_orr(as_FloatRegister($dst$$reg),\n+                 as_FloatRegister($src$$reg),\n+                 as_FloatRegister($src$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleS(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() == T_SHORT);\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_uunpklo $dst, $src\\t# vector load shuffle (B to H)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleI(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\t# vector load shuffle (B to S)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct loadshuffleL(vReg dst, vReg src)\n+%{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (VectorLoadShuffle src));\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_uunpklo $dst, H, $src\\n\\t\"\n+            \"sve_uunpklo $dst, S, $dst\\n\\t\"\n+            \"sve_uunpklo $dst, D, $dst\\t# vector load shuffle (B to D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ H, as_FloatRegister($src$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ S, as_FloatRegister($dst$$reg));\n+    __ sve_uunpklo(as_FloatRegister($dst$$reg), __ D, as_FloatRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector rearrange -------------------------------\n+dnl\n+define(`VECTOR_REARRANGE', `\n+instruct rearrange$1`'(vReg dst, vReg src, vReg shuffle)\n+%{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) == $2);\n+  match(Set dst (VectorRearrange src shuffle));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_tbl $dst, $3, $src, $shuffle\\t# vector rearrange ($3)\" %}\n+  ins_encode %{\n+    __ sve_tbl(as_FloatRegister($dst$$reg), __ $3,\n+               as_FloatRegister($src$$reg), as_FloatRegister($shuffle$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl              $1 $2 $3\n+VECTOR_REARRANGE(B, 1, B)\n+VECTOR_REARRANGE(S, 2, H)\n+VECTOR_REARRANGE(I, 4, S)\n+VECTOR_REARRANGE(L, 8, D)\n+\n+\/\/ ------------------------------ Vector Load Gather ---------------------------------\n+\n+instruct gatherI(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(SVE_COST);\n+  format %{ \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gatherL(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set dst (LoadVectorGather mem idx));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"load_vector_gather $dst, $mem, $idx\\t# vector load gather (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter -------------------------------\n+\n+instruct scatterI(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n+            n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(SVE_COST);\n+  format %{ \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (I\/F)\" %}\n+  ins_encode %{\n+    __ sve_st1w_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatterL(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+           (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n+            n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_uunpklo $idx, $idx\\n\\t\"\n+            \"store_vector_scatter $mem, $idx, $src\\t# vector store scatter (L\/D)\" %}\n+  ins_encode %{\n+    __ sve_uunpklo(as_FloatRegister($idx$$reg), __ D, as_FloatRegister($idx$$reg));\n+    __ sve_st1d_scatter(as_FloatRegister($src$$reg), ptrue, as_Register($mem$$base), as_FloatRegister($idx$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Const -------------------------------\n+\n+instruct loadconB(vReg dst, immI0 src) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadConst src));\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_index $dst, 0, 1\\t# generate iota indices\" %}\n+  ins_encode %{\n+    __ sve_index(as_FloatRegister($dst$$reg), __ B, 0, 1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":1758,"deletions":180,"binary":false,"changes":1938,"status":"modified"},{"patch":"@@ -3161,0 +3161,14 @@\n+\/\/ SVE load gather, store scatter (scalar plus vector) - 32-bit scaled offset\n+#define INSN(NAME, op1, type, op2, op3)                                         \\\n+  void NAME(FloatRegister Zt, PRegister Pg, Register Xn, FloatRegister Zm) {    \\\n+    starti;                                                                     \\\n+    f(op1, 31, 25), f(type, 24, 23), f(op2, 22, 21), rf(Zm, 16);                \\\n+    f(op3, 15, 13), pgrf(Pg, 10), srf(Xn, 5), rf(Zt, 0);                        \\\n+  }\n+\n+  INSN(sve_ld1w_gather,  0b1000010, 0b10, 0b01, 0b010);\n+  INSN(sve_ld1d_gather,  0b1100010, 0b11, 0b01, 0b010);\n+  INSN(sve_st1w_scatter, 0b1110010, 0b10, 0b11, 0b100);\n+  INSN(sve_st1d_scatter, 0b1110010, 0b11, 0b01, 0b100);\n+#undef INSN\n+\n@@ -3237,0 +3251,234 @@\n+  \/\/ SVE cpy general-purpose register\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, Register Rn) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b101000101, 21, 13);\n+    pgrf(Pg, 10), srf(Rn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE cpy immediate\n+  void sve_cpy(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg, int imm8, bool isMerge) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    int sh = 0;\n+    if (imm8 <= 127 && imm8 >= -128) {\n+      sh = 0;\n+    } else if (T != B && imm8 <= 32512 && imm8 >= -32768 && (imm8 & 0xff) == 0) {\n+      sh = 1;\n+      imm8 = (imm8 >> 8);\n+    } else {\n+      guarantee(false, \"invalid immediate\");\n+    }\n+    int m = isMerge ? 1 : 0;\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b01, 21, 20);\n+    prf(Pg, 16), f(0b0, 15), f(m, 14), f(sh, 13), sf(imm8, 12, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE sel (vectors)\n+  void sve_sel(FloatRegister Zd, SIMD_RegVariant T, PRegister Pg,\n+               FloatRegister Zn, FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b11, 15, 14), prf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE compare vectors\n+#define INSN(NAME, op, cond, fp)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, FloatRegister Zm)  { \\\n+    starti;                                                                                       \\\n+    if (fp == 0) {                                                                                \\\n+      assert(T != Q, \"invalid size\");                                                             \\\n+    } else {                                                                                      \\\n+      assert(T != B && T != Q, \"invalid size\");                                                   \\\n+    }                                                                                             \\\n+    f(op, 31, 24), f(T, 23, 22), f(0b0, 21), rf(Zm, 16), f((cond >> 1) & 0x7, 15, 13);            \\\n+    pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0);                                        \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b00100100, 0b1010, 0);\n+  INSN(sve_cmpne, 0b00100100, 0b1011, 0);\n+  INSN(sve_cmpge, 0b00100100, 0b1000, 0);\n+  INSN(sve_cmpgt, 0b00100100, 0b1001, 0);\n+  INSN(sve_fcmeq, 0b01100101, 0b0110, 1);\n+  INSN(sve_fcmne, 0b01100101, 0b0111, 1);\n+  INSN(sve_fcmgt, 0b01100101, 0b0101, 1);\n+  INSN(sve_fcmge, 0b01100101, 0b0100, 1);\n+#undef INSN\n+\n+\/\/ SVE compare vector with immediate\n+#define INSN(NAME, cond)  \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, PRegister Pg, FloatRegister Zn, int imm5) { \\\n+    starti;                                                                              \\\n+    assert(T != Q, \"invalid size\");                                                      \\\n+    guarantee(-16 <= imm5 && imm5 <= 15, \"invalid immediate\");                           \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(0b0, 21), sf(imm5, 20, 16),                   \\\n+    f((cond >> 1) & 0x7, 15, 13), pgrf(Pg, 10), rf(Zn, 5), f(cond & 0x1, 4), prf(Pd, 0); \\\n+  }\n+\n+  INSN(sve_cmpeq, 0b1000);\n+  INSN(sve_cmpne, 0b1001);\n+  INSN(sve_cmpgt, 0b0001);\n+  INSN(sve_cmpge, 0b0000);\n+  INSN(sve_cmplt, 0b0010);\n+  INSN(sve_cmple, 0b0011);\n+#undef INSN\n+\n+\/\/ SVE unpack and extend\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn) { \\\n+    starti;                                                          \\\n+    assert(T != B && T != Q, \"invalid size\");                        \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1100, 21, 18);          \\\n+    f(op, 17, 16), f(0b001110, 15, 10), rf(Zn, 5), rf(Zd, 0);        \\\n+  }\n+\n+  INSN(sve_uunpkhi, 0b11);\n+  INSN(sve_uunpklo, 0b10);\n+  INSN(sve_sunpkhi, 0b01);\n+  INSN(sve_sunpklo, 0b00);\n+#undef INSN\n+\n+\/\/ SVE uzp1\/uzp2 (vectors)\n+#define INSN(NAME, op) \\\n+  void NAME(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) { \\\n+    starti;                                                                            \\\n+    assert(T != Q, \"invalid size\");                                                    \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);                       \\\n+    f(0b01101, 15, 11), f(op, 10), rf(Zn, 5), rf(Zd, 0);                               \\\n+  }\n+\n+  INSN(sve_uzp1, 0b0);\n+  INSN(sve_uzp2, 0b1);\n+#undef INSN\n+\n+\/\/ SVE while[cond]\n+#define INSN(NAME, decode, sf)                                            \\\n+  void NAME(PRegister Pd, SIMD_RegVariant T, Register Rn, Register Rm) {  \\\n+    starti;                                                               \\\n+    assert(T != Q, \"invalid register variant\");                           \\\n+    f(0b00100101, 31, 24), f(T, 23, 22), f(1, 21),                        \\\n+    zrf(Rm, 16), f(0, 15, 13), f(sf, 12), f(decode >> 1, 11, 10),         \\\n+    zrf(Rn, 5), f(decode & 0b1, 4), prf(Pd, 0);                           \\\n+  }\n+\n+  INSN(sve_whilelt,  0b010, 1);\n+  INSN(sve_whileltw, 0b010, 0);\n+  INSN(sve_whilele,  0b011, 1);\n+  INSN(sve_whilelew, 0b011, 0);\n+  INSN(sve_whilelo,  0b110, 1);\n+  INSN(sve_whilelow, 0b110, 0);\n+  INSN(sve_whilels,  0b111, 1);\n+  INSN(sve_whilelsw, 0b111, 0);\n+#undef INSN\n+\n+  \/\/ SVE convert signed integer to floating-point (predicated)\n+  void sve_scvtf(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                 FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           (T_src != H || T_dst == T_src), \"invalid register variant\");\n+    int opc = T_dst;\n+    int opc2 = T_src;\n+    \/\/ In most cases we can treat T_dst, T_src as opc, opc2,\n+    \/\/ except for the following two combinations.\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ | opc | opc2 | U |        Instruction Details         |\n+    \/\/ +-----+------+---+------------------------------------+\n+    \/\/ |  11 |   00 | 0 | SCVTF - 32-bit to double-precision |\n+    \/\/ |  11 |   10 | 0 | SCVTF - 64-bit to single-precision |\n+    \/\/ +-----+------+---+------------------------------------+\n+    if (T_src == S && T_dst == D) {\n+      opc = 0b11;\n+      opc2 = 0b00;\n+    } else if (T_src == D && T_dst == S) {\n+      opc = 0b11;\n+      opc2 = 0b10;\n+    }\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b010, 21, 19);\n+    f(opc2, 18, 17), f(0b0101, 16, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE floating-point convert to signed integer, rounding toward zero (predicated)\n+  void sve_fcvtzs(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                  FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           (T_dst != H || T_src == H), \"invalid register variant\");\n+    int opc = T_src;\n+    int opc2 = T_dst;\n+    \/\/ In most cases we can treat T_src, T_dst as opc, opc2,\n+    \/\/ except for the following two combinations.\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ | opc | opc2 | U |         Instruction Details         |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    \/\/ |  11 |  10  | 0 | FCVTZS - single-precision to 64-bit |\n+    \/\/ |  11 |  00  | 0 | FCVTZS - double-precision to 32-bit |\n+    \/\/ +-----+------+---+-------------------------------------+\n+    if (T_src == S && T_dst == D) {\n+      opc = 0b11;\n+      opc2 = 0b10;\n+    } else if (T_src == D && T_dst == S) {\n+      opc = 0b11;\n+      opc2 = 0b00;\n+    }\n+    f(0b01100101, 31, 24), f(opc, 23, 22), f(0b011, 21, 19);\n+    f(opc2, 18, 17), f(0b0101, 16, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE floating-point convert precision (predicated)\n+  void sve_fcvt(FloatRegister Zd, SIMD_RegVariant T_dst, PRegister Pg,\n+                FloatRegister Zn, SIMD_RegVariant T_src) {\n+    starti;\n+    assert(T_src != B && T_dst != B && T_src != Q && T_dst != Q &&\n+           T_src != T_dst, \"invalid register variant\");\n+    guarantee(T_src != H && T_dst != H, \"half-precision unsupported\");\n+    f(0b01100101, 31, 24), f(0b11, 23, 22), f(0b0010, 21, 18);\n+    f(T_dst, 17, 16), f(0b101, 15, 13);\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n+\/\/ SVE extract element to general-purpose register\n+#define INSN(NAME, before)                                                      \\\n+  void NAME(Register Rd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                     \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10000, 21, 17);                    \\\n+    f(before, 16), f(0b101, 15, 13);                                            \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Rd, 0);                                         \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+\/\/ SVE extract element to SIMD&FP scalar register\n+#define INSN(NAME, before)                                                           \\\n+  void NAME(FloatRegister Vd, SIMD_RegVariant T, PRegister Pg,  FloatRegister Zn) {  \\\n+    starti;                                                                          \\\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b10001, 21, 17);                         \\\n+    f(before, 16), f(0b100, 15, 13);                                                 \\\n+    pgrf(Pg, 10), rf(Zn, 5), rf(Vd, 0);                                              \\\n+  }\n+\n+  INSN(sve_lasta, 0b0);\n+  INSN(sve_lastb, 0b1);\n+#undef INSN\n+\n+  \/\/ SVE INDEX (immediates)\n+  void sve_index(FloatRegister Zd, SIMD_RegVariant T, int imm1, int imm2) {\n+    starti;\n+    f(0b00000100, 31, 24), f(T, 23, 22), f(0b1, 21);\n+    sf(imm2, 20, 16), f(0b010000, 15, 10);\n+    sf(imm1, 9, 5), rf(Zd, 0);\n+  }\n+\n+  \/\/ SVE programmable table lookup in single vector table\n+  void sve_tbl(FloatRegister Zd, SIMD_RegVariant T, FloatRegister Zn, FloatRegister Zm) {\n+    starti;\n+    assert(T != Q, \"invalid size\");\n+    f(0b00000101, 31, 24), f(T, 23, 22), f(0b1, 21), rf(Zm, 16);\n+    f(0b001100, 15, 10), rf(Zn, 5), rf(Zd, 0);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":248,"deletions":0,"binary":false,"changes":248,"status":"modified"},{"patch":"@@ -2707,1 +2707,3 @@\n-  if (restore_vectors) {\n+  \/\/ We may use predicate registers and rely on ptrue with SVE,\n+  \/\/ regardless of wide vector (> 8 bytes) used or not.\n+  if (use_sve) {\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2111,1 +2111,4 @@\n-  if (C->max_vector_size() > 8)\n+  \/\/ And when the scalable vector register is used, we may spill\/unspill\n+  \/\/ the whole reg regardless of the max vector size.\n+  if (C->max_vector_size() > 8 ||\n+      (C->max_vector_size() > 0 && Matcher::supports_scalable_vector())) {\n@@ -2113,0 +2116,1 @@\n+  }\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1514,33 +1514,104 @@\n-                        [\"cpy\",    \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n-                        [\"inc\",    \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n-                        [\"dec\",    \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n-                        [\"lsl\",    \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n-                        [\"lsl\",    \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n-                        [\"lsr\",    \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n-                        [\"lsr\",    \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n-                        [\"asr\",    \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n-                        [\"addvl\",  \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n-                        [\"addpl\",  \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n-                        [\"cntp\",   \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n-                        [\"dup\",    \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n-                        [\"dup\",    \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n-                        [\"dup\",    \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n-                        [\"dup\",    \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n-                        [\"ld1h\",   \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n-                        [\"ld1b\",   \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n-                        [\"ld1w\",   \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n-                        [\"ld1d\",   \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n-                        [\"st1w\",   \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n-                        [\"st1b\",   \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n-                        [\"st1h\",   \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n-                        [\"st1d\",   \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n-                        [\"ldr\",    \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n-                        [\"str\",    \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n+                        [\"cpy\",     \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n+                        [\"cpy\",     \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n+                        [\"cpy\",     \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n+                        [\"cpy\",     \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n+                        [\"inc\",     \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n+                        [\"dec\",     \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n+                        [\"lsl\",     \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n+                        [\"lsl\",     \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n+                        [\"lsr\",     \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n+                        [\"lsr\",     \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n+                        [\"asr\",     \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n+                        [\"addvl\",   \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n+                        [\"addpl\",   \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n+                        [\"cntp\",    \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n+                        [\"dup\",     \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n+                        [\"dup\",     \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n+                        [\"dup\",     \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n+                        [\"dup\",     \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n+                        [\"dup\",     \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n+                        [\"dup\",     \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n+                        [\"ld1h\",    \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n+                        [\"ld1b\",    \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n+                        [\"ld1w\",    \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n+                        [\"st1w\",    \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n+                        [\"st1b\",    \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n+                        [\"st1h\",    \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n+                        [\"st1d\",    \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n+                        [\"ldr\",     \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n+                        [\"str\",     \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"sel\",     \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n+                        [\"sel\",     \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p0, z0, z1);\",                \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, z3);\",                \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p2, z4, z5);\",                \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ D, p3, z6, z7);\",                \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmple\",   \"__ sve_cmpge(p2, __ B, p0, z10, z11);\",              \"cmple\\tp2.b, p0\/z, z11.b, z10.b\"],\n+                        [\"cmplt\",   \"__ sve_cmpgt(p3, __ S, p0, z16, z17);\",              \"cmplt\\tp3.s, p0\/z, z17.s, z16.s\"],\n+                        [\"cmpeq\",   \"__ sve_cmpeq(p1, __ B, p4, z0, 15);\",                \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n+                        [\"cmpne\",   \"__ sve_cmpne(p1, __ H, p0, z2, -16);\",               \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n+                        [\"cmple\",   \"__ sve_cmple(p1, __ S, p1, z4, 0);\",                 \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n+                        [\"cmplt\",   \"__ sve_cmplt(p1, __ D, p2, z6, -1);\",                \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n+                        [\"cmpge\",   \"__ sve_cmpge(p1, __ S, p3, z4, 5);\",                 \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n+                        [\"cmpgt\",   \"__ sve_cmpgt(p1, __ B, p4, z6, -2);\",                \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n+                        [\"fcmeq\",   \"__ sve_fcmeq(p1, __ S, p0, z0, z1);\",                \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n+                        [\"fcmne\",   \"__ sve_fcmne(p1, __ D, p0, z2, z3);\",                \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n+                        [\"fcmgt\",   \"__ sve_fcmgt(p1, __ S, p2, z4, z5);\",                \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"fcmge\",   \"__ sve_fcmge(p1, __ D, p3, z6, z7);\",                \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"fcmlt\",   \"__ sve_fcmgt(p2, __ S, p0, z10, z11);\",              \"fcmlt\\tp2.s, p0\/z, z11.s, z10.s\"],\n+                        [\"fcmle\",   \"__ sve_fcmge(p3, __ D, p0, z16, z17);\",              \"fcmle\\tp3.d, p0\/z, z17.d, z16.d\"],\n+                        [\"uunpkhi\", \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n+                        [\"uunpklo\", \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n+                        [\"sunpkhi\", \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n+                        [\"sunpklo\", \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n+                        [\"whilelt\", \"__ sve_whilelt(p0, __ B, r1, r2);\",                  \"whilelt\\tp0.b, x1, x2\"],\n+                        [\"whilelt\", \"__ sve_whileltw(p1, __ H, r3, r4);\",                 \"whilelt\\tp1.h, w3, w4\"],\n+                        [\"whilele\", \"__ sve_whilele(p2, __ S, r5, r6);\",                  \"whilele\\tp2.s, x5, x6\"],\n+                        [\"whilele\", \"__ sve_whilelew(p3, __ D, r10, r11);\",               \"whilele\\tp3.d, w10, w11\"],\n+                        [\"whilelo\", \"__ sve_whilelo(p4, __ B, r1, r2);\",                  \"whilelo\\tp4.b, x1, x2\"],\n+                        [\"whilelo\", \"__ sve_whilelow(p0, __ H, r3, r4);\",                 \"whilelo\\tp0.h, w3, w4\"],\n+                        [\"whilels\", \"__ sve_whilels(p1, __ S, r5, r6);\",                  \"whilels\\tp1.s, x5, x6\"],\n+                        [\"whilels\", \"__ sve_whilelsw(p2, __ D, r10, r11);\",               \"whilels\\tp2.d, w10, w11\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z1, __ D, p0, z0, __ S);\",              \"scvtf\\tz1.d, p0\/m, z0.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z3, __ D, p1, z2, __ D);\",              \"scvtf\\tz3.d, p1\/m, z2.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p2, z1, __ D);\",              \"scvtf\\tz6.s, p2\/m, z1.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p3, z1, __ S);\",              \"scvtf\\tz6.s, p3\/m, z1.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ S);\",              \"scvtf\\tz6.h, p3\/m, z1.s\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ D);\",              \"scvtf\\tz6.h, p3\/m, z1.d\"],\n+                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ H);\",              \"scvtf\\tz6.h, p3\/m, z1.h\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z5, __ D, p3, z4, __ S);\",               \"fcvt\\tz5.d, p3\/m, z4.s\"],\n+                        [\"fcvt\",    \"__ sve_fcvt(z1, __ S, p3, z0, __ D);\",               \"fcvt\\tz1.s, p3\/m, z0.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z1, __ D);\",            \"fcvtzs\\tz19.d, p2\/m, z1.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z9, __ S, p1, z8, __ S);\",             \"fcvtzs\\tz9.s, p1\/m, z8.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p2, z0, __ D);\",             \"fcvtzs\\tz1.s, p2\/m, z0.d\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ D, p3, z0, __ S);\",             \"fcvtzs\\tz1.d, p3\/m, z0.s\"],\n+                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p4, z18, __ H);\",            \"fcvtzs\\tz1.s, p4\/m, z18.h\"],\n+                        [\"lasta\",   \"__ sve_lasta(r0, __ B, p0, z15);\",                   \"lasta\\tw0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(r1, __ B, p1, z16);\",                   \"lastb\\tw1, p1, z16.b\"],\n+                        [\"lasta\",   \"__ sve_lasta(v0, __ B, p0, z15);\",                   \"lasta\\tb0, p0, z15.b\"],\n+                        [\"lastb\",   \"__ sve_lastb(v1, __ B, p1, z16);\",                   \"lastb\\tb1, p1, z16.b\"],\n+                        [\"index\",   \"__ sve_index(z6, __ S, 1, 1);\",                      \"index\\tz6.s, #1, #1\"],\n+                        [\"cpy\",     \"__ sve_cpy(z7, __ H, p3, r5);\",                      \"cpy\\tz7.h, p3\/m, w5\"],\n+                        [\"tbl\",     \"__ sve_tbl(z16, __ S, z17, z18);\",                   \"tbl\\tz16.s, {z17.s}, z18.s\"],\n+                        [\"ld1w\",    \"__ sve_ld1w_gather(z15, p0, r5, z16);\",              \"ld1w\\t{z15.s}, p0\/z, [x5, z16.s, uxtw #2]\"],\n+                        [\"ld1d\",    \"__ sve_ld1d_gather(z15, p0, r5, z16);\",              \"ld1d\\t{z15.d}, p0\/z, [x5, z16.d, uxtw #3]\"],\n+                        [\"st1w\",    \"__ sve_st1w_scatter(z15, p0, r5, z16);\",             \"st1w\\t{z15.s}, p0, [x5, z16.s, uxtw #2]\"],\n+                        [\"st1d\",    \"__ sve_st1d_scatter(z15, p0, r5, z16);\",             \"st1d\\t{z15.d}, p0, [x5, z16.d, uxtw #3]\"],\n@@ -1616,0 +1687,2 @@\n+                       [\"uzp1\", \"ZZZ\"],\n+                       [\"uzp2\", \"ZZZ\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":106,"deletions":33,"binary":false,"changes":139,"status":"modified"},{"patch":"@@ -702,0 +702,6 @@\n+    __ sve_cpy(z0, __ B, p0, 127, true);               \/\/       mov     z0.b, p0\/m, 127\n+    __ sve_cpy(z1, __ H, p0, -128, true);              \/\/       mov     z1.h, p0\/m, -128\n+    __ sve_cpy(z2, __ S, p0, 32512, true);             \/\/       mov     z2.s, p0\/m, 32512\n+    __ sve_cpy(z5, __ D, p0, -32768, false);           \/\/       mov     z5.d, p0\/z, -32768\n+    __ sve_cpy(z10, __ B, p0, -1, false);              \/\/       mov     z10.b, p0\/z, -1\n+    __ sve_cpy(z11, __ S, p0, -1, false);              \/\/       mov     z11.s, p0\/z, -1\n@@ -719,0 +725,2 @@\n+    __ sve_dup(z10, __ B, -1);                         \/\/       dup     z10.b, -1\n+    __ sve_dup(z11, __ S, -1);                         \/\/       dup     z11.s, -1\n@@ -720,0 +728,3 @@\n+    __ sve_ld1b(z0, __ H, p1, Address(sp));            \/\/       ld1b    {z0.h}, p1\/z, [sp]\n+    __ sve_ld1b(z0, __ S, p2, Address(sp, r8));        \/\/       ld1b    {z0.s}, p2\/z, [sp, x8]\n+    __ sve_ld1b(z0, __ D, p3, Address(sp, 7));         \/\/       ld1b    {z0.d}, p3\/z, [sp, #7, MUL VL]\n@@ -727,0 +738,3 @@\n+    __ sve_st1b(z0, __ H, p1, Address(sp));            \/\/       st1b    {z0.h}, p1, [sp]\n+    __ sve_st1b(z0, __ S, p2, Address(sp, r8));        \/\/       st1b    {z0.s}, p2, [sp, x8]\n+    __ sve_st1b(z0, __ D, p3, Address(sp));            \/\/       st1b    {z0.d}, p3, [sp]\n@@ -734,0 +748,57 @@\n+    __ sve_sel(z0, __ B, p0, z1, z2);                  \/\/       sel     z0.b, p0, z1.b, z2.b\n+    __ sve_sel(z4, __ D, p0, z5, z6);                  \/\/       sel     z4.d, p0, z5.d, z6.d\n+    __ sve_cmpeq(p1, __ B, p0, z0, z1);                \/\/       cmpeq   p1.b, p0\/z, z0.b, z1.b\n+    __ sve_cmpne(p1, __ H, p0, z2, z3);                \/\/       cmpne   p1.h, p0\/z, z2.h, z3.h\n+    __ sve_cmpge(p1, __ S, p2, z4, z5);                \/\/       cmpge   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_cmpgt(p1, __ D, p3, z6, z7);                \/\/       cmpgt   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_cmpge(p2, __ B, p0, z10, z11);              \/\/       cmple   p2.b, p0\/z, z11.b, z10.b\n+    __ sve_cmpgt(p3, __ S, p0, z16, z17);              \/\/       cmplt   p3.s, p0\/z, z17.s, z16.s\n+    __ sve_cmpeq(p1, __ B, p4, z0, 15);                \/\/       cmpeq   p1.b, p4\/z, z0.b, #15\n+    __ sve_cmpne(p1, __ H, p0, z2, -16);               \/\/       cmpne   p1.h, p0\/z, z2.h, #-16\n+    __ sve_cmple(p1, __ S, p1, z4, 0);                 \/\/       cmple   p1.s, p1\/z, z4.s, #0\n+    __ sve_cmplt(p1, __ D, p2, z6, -1);                \/\/       cmplt   p1.d, p2\/z, z6.d, #-1\n+    __ sve_cmpge(p1, __ S, p3, z4, 5);                 \/\/       cmpge   p1.s, p3\/z, z4.s, #5\n+    __ sve_cmpgt(p1, __ B, p4, z6, -2);                \/\/       cmpgt   p1.b, p4\/z, z6.b, #-2\n+    __ sve_fcmeq(p1, __ S, p0, z0, z1);                \/\/       fcmeq   p1.s, p0\/z, z0.s, z1.s\n+    __ sve_fcmne(p1, __ D, p0, z2, z3);                \/\/       fcmne   p1.d, p0\/z, z2.d, z3.d\n+    __ sve_fcmgt(p1, __ S, p2, z4, z5);                \/\/       fcmgt   p1.s, p2\/z, z4.s, z5.s\n+    __ sve_fcmge(p1, __ D, p3, z6, z7);                \/\/       fcmge   p1.d, p3\/z, z6.d, z7.d\n+    __ sve_fcmgt(p2, __ S, p0, z10, z11);              \/\/       fcmlt   p2.s, p0\/z, z11.s, z10.s\n+    __ sve_fcmge(p3, __ D, p0, z16, z17);              \/\/       fcmle   p3.d, p0\/z, z17.d, z16.d\n+    __ sve_uunpkhi(z0, __ H, z1);                      \/\/       uunpkhi z0.h, z1.b\n+    __ sve_uunpklo(z4, __ S, z5);                      \/\/       uunpklo z4.s, z5.h\n+    __ sve_sunpkhi(z6, __ D, z7);                      \/\/       sunpkhi z6.d, z7.s\n+    __ sve_sunpklo(z10, __ H, z11);                    \/\/       sunpklo z10.h, z11.b\n+    __ sve_whilelt(p0, __ B, r1, r2);                  \/\/       whilelt p0.b, x1, x2\n+    __ sve_whileltw(p1, __ H, r3, r4);                 \/\/       whilelt p1.h, w3, w4\n+    __ sve_whilele(p2, __ S, r5, r6);                  \/\/       whilele p2.s, x5, x6\n+    __ sve_whilelew(p3, __ D, r10, r11);               \/\/       whilele p3.d, w10, w11\n+    __ sve_whilelo(p4, __ B, r1, r2);                  \/\/       whilelo p4.b, x1, x2\n+    __ sve_whilelow(p0, __ H, r3, r4);                 \/\/       whilelo p0.h, w3, w4\n+    __ sve_whilels(p1, __ S, r5, r6);                  \/\/       whilels p1.s, x5, x6\n+    __ sve_whilelsw(p2, __ D, r10, r11);               \/\/       whilels p2.d, w10, w11\n+    __ sve_scvtf(z1, __ D, p0, z0, __ S);              \/\/       scvtf   z1.d, p0\/m, z0.s\n+    __ sve_scvtf(z3, __ D, p1, z2, __ D);              \/\/       scvtf   z3.d, p1\/m, z2.d\n+    __ sve_scvtf(z6, __ S, p2, z1, __ D);              \/\/       scvtf   z6.s, p2\/m, z1.d\n+    __ sve_scvtf(z6, __ S, p3, z1, __ S);              \/\/       scvtf   z6.s, p3\/m, z1.s\n+    __ sve_scvtf(z6, __ H, p3, z1, __ S);              \/\/       scvtf   z6.h, p3\/m, z1.s\n+    __ sve_scvtf(z6, __ H, p3, z1, __ D);              \/\/       scvtf   z6.h, p3\/m, z1.d\n+    __ sve_scvtf(z6, __ H, p3, z1, __ H);              \/\/       scvtf   z6.h, p3\/m, z1.h\n+    __ sve_fcvt(z5, __ D, p3, z4, __ S);               \/\/       fcvt    z5.d, p3\/m, z4.s\n+    __ sve_fcvt(z1, __ S, p3, z0, __ D);               \/\/       fcvt    z1.s, p3\/m, z0.d\n+    __ sve_fcvtzs(z19, __ D, p2, z1, __ D);            \/\/       fcvtzs  z19.d, p2\/m, z1.d\n+    __ sve_fcvtzs(z9, __ S, p1, z8, __ S);             \/\/       fcvtzs  z9.s, p1\/m, z8.s\n+    __ sve_fcvtzs(z1, __ S, p2, z0, __ D);             \/\/       fcvtzs  z1.s, p2\/m, z0.d\n+    __ sve_fcvtzs(z1, __ D, p3, z0, __ S);             \/\/       fcvtzs  z1.d, p3\/m, z0.s\n+    __ sve_fcvtzs(z1, __ S, p4, z18, __ H);            \/\/       fcvtzs  z1.s, p4\/m, z18.h\n+    __ sve_lasta(r0, __ B, p0, z15);                   \/\/       lasta   w0, p0, z15.b\n+    __ sve_lastb(r1, __ B, p1, z16);                   \/\/       lastb   w1, p1, z16.b\n+    __ sve_lasta(v0, __ B, p0, z15);                   \/\/       lasta   b0, p0, z15.b\n+    __ sve_lastb(v1, __ B, p1, z16);                   \/\/       lastb   b1, p1, z16.b\n+    __ sve_index(z6, __ S, 1, 1);                      \/\/       index   z6.s, #1, #1\n+    __ sve_cpy(z7, __ H, p3, r5);                      \/\/       cpy     z7.h, p3\/m, w5\n+    __ sve_tbl(z16, __ S, z17, z18);                   \/\/       tbl     z16.s, {z17.s}, z18.s\n+    __ sve_ld1w_gather(z15, p0, r5, z16);              \/\/       ld1w    {z15.s}, p0\/z, [x5, z16.s, uxtw #2]\n+    __ sve_ld1d_gather(z15, p0, r5, z16);              \/\/       ld1d    {z15.d}, p0\/z, [x5, z16.d, uxtw #3]\n+    __ sve_st1w_scatter(z15, p0, r5, z16);             \/\/       st1w    {z15.s}, p0, [x5, z16.s, uxtw #2]\n+    __ sve_st1d_scatter(z15, p0, r5, z16);             \/\/       st1d    {z15.d}, p0, [x5, z16.d, uxtw #3]\n@@ -909,0 +980,2 @@\n+    __ sve_uzp1(z15, __ S, z4, z4);                    \/\/       uzp1    z15.s, z4.s, z4.s\n+    __ sve_uzp2(z8, __ B, z6, z29);                    \/\/       uzp2    z8.b, z6.b, z29.b\n@@ -911,9 +984,9 @@\n-    __ sve_andv(v15, __ S, p1, z4);                    \/\/       andv s15, p1, z4.s\n-    __ sve_orv(v8, __ B, p1, z29);                     \/\/       orv b8, p1, z29.b\n-    __ sve_eorv(v28, __ D, p4, z29);                   \/\/       eorv d28, p4, z29.d\n-    __ sve_smaxv(v9, __ H, p3, z2);                    \/\/       smaxv h9, p3, z2.h\n-    __ sve_sminv(v28, __ B, p0, z7);                   \/\/       sminv b28, p0, z7.b\n-    __ sve_fminv(v26, __ S, p5, z17);                  \/\/       fminv s26, p5, z17.s\n-    __ sve_fmaxv(v8, __ D, p4, z21);                   \/\/       fmaxv d8, p4, z21.d\n-    __ sve_fadda(v5, __ D, p5, z21);                   \/\/       fadda d5, p5, d5, z21.d\n-    __ sve_uaddv(v22, __ S, p4, z29);                  \/\/       uaddv d22, p4, z29.s\n+    __ sve_andv(v28, __ D, p4, z29);                   \/\/       andv d28, p4, z29.d\n+    __ sve_orv(v9, __ H, p3, z2);                      \/\/       orv h9, p3, z2.h\n+    __ sve_eorv(v28, __ B, p0, z7);                    \/\/       eorv b28, p0, z7.b\n+    __ sve_smaxv(v26, __ H, p5, z17);                  \/\/       smaxv h26, p5, z17.h\n+    __ sve_sminv(v8, __ D, p4, z21);                   \/\/       sminv d8, p4, z21.d\n+    __ sve_fminv(v5, __ D, p5, z21);                   \/\/       fminv d5, p5, z21.d\n+    __ sve_fmaxv(v22, __ D, p4, z29);                  \/\/       fmaxv d22, p4, z29.d\n+    __ sve_fadda(v19, __ D, p0, z4);                   \/\/       fadda d19, p0, d19, z4.d\n+    __ sve_uaddv(v23, __ B, p1, z19);                  \/\/       uaddv d23, p1, z19.b\n@@ -938,7 +1011,7 @@\n-    0x14000000,     0x17ffffd7,     0x140002e1,     0x94000000,\n-    0x97ffffd4,     0x940002de,     0x3400000a,     0x34fffa2a,\n-    0x34005b6a,     0x35000008,     0x35fff9c8,     0x35005b08,\n-    0xb400000b,     0xb4fff96b,     0xb4005aab,     0xb500001d,\n-    0xb5fff91d,     0xb5005a5d,     0x10000013,     0x10fff8b3,\n-    0x100059f3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36305976,     0x3758000c,     0x375ff7cc,     0x3758590c,\n+    0x14000000,     0x17ffffd7,     0x1400032a,     0x94000000,\n+    0x97ffffd4,     0x94000327,     0x3400000a,     0x34fffa2a,\n+    0x3400648a,     0x35000008,     0x35fff9c8,     0x35006428,\n+    0xb400000b,     0xb4fff96b,     0xb40063cb,     0xb500001d,\n+    0xb5fff91d,     0xb500637d,     0x10000013,     0x10fff8b3,\n+    0x10006313,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36306296,     0x3758000c,     0x375ff7cc,     0x3758622c,\n@@ -949,13 +1022,13 @@\n-    0x540056e0,     0x54000001,     0x54fff541,     0x54005681,\n-    0x54000002,     0x54fff4e2,     0x54005622,     0x54000002,\n-    0x54fff482,     0x540055c2,     0x54000003,     0x54fff423,\n-    0x54005563,     0x54000003,     0x54fff3c3,     0x54005503,\n-    0x54000004,     0x54fff364,     0x540054a4,     0x54000005,\n-    0x54fff305,     0x54005445,     0x54000006,     0x54fff2a6,\n-    0x540053e6,     0x54000007,     0x54fff247,     0x54005387,\n-    0x54000008,     0x54fff1e8,     0x54005328,     0x54000009,\n-    0x54fff189,     0x540052c9,     0x5400000a,     0x54fff12a,\n-    0x5400526a,     0x5400000b,     0x54fff0cb,     0x5400520b,\n-    0x5400000c,     0x54fff06c,     0x540051ac,     0x5400000d,\n-    0x54fff00d,     0x5400514d,     0x5400000e,     0x54ffefae,\n-    0x540050ee,     0x5400000f,     0x54ffef4f,     0x5400508f,\n+    0x54006000,     0x54000001,     0x54fff541,     0x54005fa1,\n+    0x54000002,     0x54fff4e2,     0x54005f42,     0x54000002,\n+    0x54fff482,     0x54005ee2,     0x54000003,     0x54fff423,\n+    0x54005e83,     0x54000003,     0x54fff3c3,     0x54005e23,\n+    0x54000004,     0x54fff364,     0x54005dc4,     0x54000005,\n+    0x54fff305,     0x54005d65,     0x54000006,     0x54fff2a6,\n+    0x54005d06,     0x54000007,     0x54fff247,     0x54005ca7,\n+    0x54000008,     0x54fff1e8,     0x54005c48,     0x54000009,\n+    0x54fff189,     0x54005be9,     0x5400000a,     0x54fff12a,\n+    0x54005b8a,     0x5400000b,     0x54fff0cb,     0x54005b2b,\n+    0x5400000c,     0x54fff06c,     0x54005acc,     0x5400000d,\n+    0x54fff00d,     0x54005a6d,     0x5400000e,     0x54ffefae,\n+    0x54005a0e,     0x5400000f,     0x54ffef4f,     0x540059af,\n@@ -993,1 +1066,1 @@\n-    0xbd1b1869,     0x580040db,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x580049fb,     0x1800000b,     0xf8945060,\n@@ -1074,49 +1147,68 @@\n-    0x0e073c20,     0x4cc0ac3f,     0x05a08020,     0x04b0e3e0,\n-    0x0470e7e1,     0x042f9c20,     0x043f9c35,     0x047f9c20,\n-    0x04ff9c20,     0x04299420,     0x04319160,     0x0461943e,\n-    0x04a19020,     0x042053ff,     0x047f5401,     0x25208028,\n-    0x2538cfe0,     0x2578d001,     0x25b8efe2,     0x25f8f007,\n-    0xa400a3e0,     0xa4a8a7ea,     0xa547a814,     0xa4084ffe,\n-    0xa55c53e0,     0xa5e1540b,     0xe400fbf6,     0xe408ffff,\n-    0xe547e400,     0xe4014be0,     0xe4a84fe0,     0xe5f15000,\n-    0x858043e0,     0x85a043ff,     0xe59f5d08,     0x1e601000,\n-    0x1e603000,     0x1e621000,     0x1e623000,     0x1e641000,\n-    0x1e643000,     0x1e661000,     0x1e663000,     0x1e681000,\n-    0x1e683000,     0x1e6a1000,     0x1e6a3000,     0x1e6c1000,\n-    0x1e6c3000,     0x1e6e1000,     0x1e6e3000,     0x1e701000,\n-    0x1e703000,     0x1e721000,     0x1e723000,     0x1e741000,\n-    0x1e743000,     0x1e761000,     0x1e763000,     0x1e781000,\n-    0x1e783000,     0x1e7a1000,     0x1e7a3000,     0x1e7c1000,\n-    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8358303,\n-    0xf8280299,     0xf8301051,     0xf8212300,     0xf8243183,\n-    0xf83f515c,     0xf83a4182,     0xf830703f,     0xf82d601d,\n-    0xf8b3822c,     0xf8b6038d,     0xf8be103f,     0xf8ba209c,\n-    0xf8be30c4,     0xf8be51fa,     0xf8a94188,     0xf8a07034,\n-    0xf8b86002,     0xf8e98358,     0xf8f0007e,     0xf8ea1157,\n-    0xf8e42050,     0xf8eb3148,     0xf8ef5051,     0xf8ea418c,\n-    0xf8ef704d,     0xf8e76354,     0xf8708044,     0xf86401ec,\n-    0xf87511f0,     0xf86b22f5,     0xf86c32fa,     0xf87c516e,\n-    0xf8784181,     0xf87f720a,     0xf8676062,     0xb82d8233,\n-    0xb8300023,     0xb82b10be,     0xb82823af,     0xb83e3280,\n-    0xb82752f4,     0xb83c4375,     0xb8397025,     0xb83763f0,\n-    0xb8a5812c,     0xb8bc03af,     0xb8b6127f,     0xb8bf21c5,\n-    0xb8b031ff,     0xb8bb5214,     0xb8ac412b,     0xb8a6723e,\n-    0xb8bb63dc,     0xb8e7828a,     0xb8ea0304,     0xb8f112d1,\n-    0xb8e321fd,     0xb8f63273,     0xb8f651e2,     0xb8e6420c,\n-    0xb8eb72ed,     0xb8e1627e,     0xb8658051,     0xb87001b6,\n-    0xb86a13b5,     0xb87b236c,     0xb86333e1,     0xb8785233,\n-    0xb869437c,     0xb86f72a7,     0xb877633f,     0xce3a47c2,\n-    0xce110aca,     0xce788c11,     0xce8296d9,     0xce7b806c,\n-    0xce70879d,     0xcec080da,     0xce718b89,     0x04670087,\n-    0x042806c9,     0x659e029b,     0x6590081a,     0x65c80723,\n-    0x04d6bb55,     0x04000096,     0x04508071,     0x041aa8c1,\n-    0x04939ce9,     0x045194b6,     0x041013c8,     0x04d7a171,\n-    0x049ea35c,     0x04c80dbc,     0x040a18b0,     0x044109ed,\n-    0x049cb57a,     0x65809096,     0x658d9233,     0x65c68c4e,\n-    0x658796e3,     0x65828626,     0x049db21b,     0x6582bc62,\n-    0x6580b266,     0x65c1b50c,     0x658db013,     0x65c18677,\n-    0x65a010cd,     0x65a8332e,     0x65bb56d6,     0x65b46e23,\n-    0x04405ce4,     0x048476d0,     0x042b32c9,     0x04b033c5,\n-    0x04613176,     0x04f03288,     0x049a248f,     0x041827a8,\n-    0x04d933bc,     0x04482c49,     0x040a20fc,     0x6587363a,\n-    0x65c632a8,     0x65d836a5,     0x048133b6,\n+    0x0e073c20,     0x4cc0ac3f,     0x05a08020,     0x05104fe0,\n+    0x05505001,     0x05906fe2,     0x05d03005,     0x05101fea,\n+    0x05901feb,     0x04b0e3e0,     0x0470e7e1,     0x042f9c20,\n+    0x043f9c35,     0x047f9c20,     0x04ff9c20,     0x04299420,\n+    0x04319160,     0x0461943e,     0x04a19020,     0x042053ff,\n+    0x047f5401,     0x25208028,     0x2538cfe0,     0x2578d001,\n+    0x25b8efe2,     0x25f8f007,     0x2538dfea,     0x25b8dfeb,\n+    0xa400a3e0,     0xa420a7e0,     0xa4484be0,     0xa467afe0,\n+    0xa4a8a7ea,     0xa547a814,     0xa4084ffe,     0xa55c53e0,\n+    0xa5e1540b,     0xe400fbf6,     0xe408ffff,     0xe420e7e0,\n+    0xe4484be0,     0xe460efe0,     0xe547e400,     0xe4014be0,\n+    0xe4a84fe0,     0xe5f15000,     0x858043e0,     0x85a043ff,\n+    0xe59f5d08,     0x0522c020,     0x05e6c0a4,     0x2401a001,\n+    0x2443a051,     0x24858881,     0x24c78cd1,     0x240b8142,\n+    0x24918213,     0x250f9001,     0x25508051,     0x25802491,\n+    0x25df28c1,     0x25850c81,     0x251e10d1,     0x65816001,\n+    0x65c36051,     0x65854891,     0x65c74cc1,     0x658b4152,\n+    0x65d14203,     0x05733820,     0x05b238a4,     0x05f138e6,\n+    0x0570396a,     0x25221420,     0x25640461,     0x25a614b2,\n+    0x25eb0553,     0x25221c24,     0x25640c60,     0x25a61cb1,\n+    0x25eb0d52,     0x65d0a001,     0x65d6a443,     0x65d4a826,\n+    0x6594ac26,     0x6554ac26,     0x6556ac26,     0x6552ac26,\n+    0x65cbac85,     0x65caac01,     0x65dea833,     0x659ca509,\n+    0x65d8a801,     0x65dcac01,     0x655cb241,     0x0520a1e0,\n+    0x0521a601,     0x052281e0,     0x05238601,     0x04a14026,\n+    0x0568aca7,     0x05b23230,     0x853040af,     0xc5b040af,\n+    0xe57080af,     0xe5b080af,     0x1e601000,     0x1e603000,\n+    0x1e621000,     0x1e623000,     0x1e641000,     0x1e643000,\n+    0x1e661000,     0x1e663000,     0x1e681000,     0x1e683000,\n+    0x1e6a1000,     0x1e6a3000,     0x1e6c1000,     0x1e6c3000,\n+    0x1e6e1000,     0x1e6e3000,     0x1e701000,     0x1e703000,\n+    0x1e721000,     0x1e723000,     0x1e741000,     0x1e743000,\n+    0x1e761000,     0x1e763000,     0x1e781000,     0x1e783000,\n+    0x1e7a1000,     0x1e7a3000,     0x1e7c1000,     0x1e7c3000,\n+    0x1e7e1000,     0x1e7e3000,     0xf8358303,     0xf8280299,\n+    0xf8301051,     0xf8212300,     0xf8243183,     0xf83f515c,\n+    0xf83a4182,     0xf830703f,     0xf82d601d,     0xf8b3822c,\n+    0xf8b6038d,     0xf8be103f,     0xf8ba209c,     0xf8be30c4,\n+    0xf8be51fa,     0xf8a94188,     0xf8a07034,     0xf8b86002,\n+    0xf8e98358,     0xf8f0007e,     0xf8ea1157,     0xf8e42050,\n+    0xf8eb3148,     0xf8ef5051,     0xf8ea418c,     0xf8ef704d,\n+    0xf8e76354,     0xf8708044,     0xf86401ec,     0xf87511f0,\n+    0xf86b22f5,     0xf86c32fa,     0xf87c516e,     0xf8784181,\n+    0xf87f720a,     0xf8676062,     0xb82d8233,     0xb8300023,\n+    0xb82b10be,     0xb82823af,     0xb83e3280,     0xb82752f4,\n+    0xb83c4375,     0xb8397025,     0xb83763f0,     0xb8a5812c,\n+    0xb8bc03af,     0xb8b6127f,     0xb8bf21c5,     0xb8b031ff,\n+    0xb8bb5214,     0xb8ac412b,     0xb8a6723e,     0xb8bb63dc,\n+    0xb8e7828a,     0xb8ea0304,     0xb8f112d1,     0xb8e321fd,\n+    0xb8f63273,     0xb8f651e2,     0xb8e6420c,     0xb8eb72ed,\n+    0xb8e1627e,     0xb8658051,     0xb87001b6,     0xb86a13b5,\n+    0xb87b236c,     0xb86333e1,     0xb8785233,     0xb869437c,\n+    0xb86f72a7,     0xb877633f,     0xce3a47c2,     0xce110aca,\n+    0xce788c11,     0xce8296d9,     0xce7b806c,     0xce70879d,\n+    0xcec080da,     0xce718b89,     0x04670087,     0x042806c9,\n+    0x659e029b,     0x6590081a,     0x65c80723,     0x04d6bb55,\n+    0x04000096,     0x04508071,     0x041aa8c1,     0x04939ce9,\n+    0x045194b6,     0x041013c8,     0x04d7a171,     0x049ea35c,\n+    0x04c80dbc,     0x040a18b0,     0x044109ed,     0x049cb57a,\n+    0x65809096,     0x658d9233,     0x65c68c4e,     0x658796e3,\n+    0x65828626,     0x049db21b,     0x6582bc62,     0x6580b266,\n+    0x65c1b50c,     0x658db013,     0x65c18677,     0x65a010cd,\n+    0x65a8332e,     0x65bb56d6,     0x65b46e23,     0x04405ce4,\n+    0x048476d0,     0x042b32c9,     0x04b033c5,     0x04613176,\n+    0x04f03288,     0x05a4688f,     0x053d6cc8,     0x04da33bc,\n+    0x04582c49,     0x041920fc,     0x0448363a,     0x04ca32a8,\n+    0x65c736a5,     0x65c633b6,     0x65d82093,     0x04012677,\n+\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":171,"deletions":79,"binary":false,"changes":250,"status":"modified"}]}