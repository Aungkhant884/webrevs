{"files":[{"patch":"@@ -2853,0 +2853,106 @@\n+void G1CollectedHeap::prepare_tlabs_for_mutator() {\n+  Ticks start = Ticks::now();\n+\n+  _survivor_evac_stats.adjust_desired_plab_sz();\n+  _old_evac_stats.adjust_desired_plab_sz();\n+\n+  allocate_dummy_regions();\n+\n+  _allocator->init_mutator_alloc_regions();\n+\n+  resize_all_tlabs();\n+\n+  phase_times()->record_resize_tlab_time_ms((Ticks::now() - start).seconds() * 1000.0);\n+}\n+\n+void G1CollectedHeap::retire_tlabs() {\n+  ensure_parsability(true);\n+}\n+\n+void G1CollectedHeap::do_collection_pause_at_safepoint_helper(double target_pause_time_ms) {\n+  ResourceMark rm;\n+\n+  IsGCActiveMark active_gc_mark;\n+  GCIdMark gc_id_mark;\n+  SvcGCMarker sgcm(SvcGCMarker::MINOR);\n+\n+  GCTraceCPUTime tcpu;\n+\n+  _bytes_used_during_gc = 0;\n+\n+  policy()->decide_on_concurrent_start_pause();\n+  \/\/ Record whether this pause may need to trigger a concurrent operation. Later,\n+  \/\/ when we signal the G1ConcurrentMarkThread, the collector state has already\n+  \/\/ been reset for the next pause.\n+  bool should_start_concurrent_mark_operation = collector_state()->in_concurrent_start_gc();\n+\n+  \/\/ Perform the collection.\n+  G1YoungCollector collector(gc_cause(), target_pause_time_ms, &_evac_failure_regions);\n+  collector.collect();\n+\n+  \/\/ It should now be safe to tell the concurrent mark thread to start\n+  \/\/ without its logging output interfering with the logging output\n+  \/\/ that came from the pause.\n+  if (should_start_concurrent_mark_operation) {\n+    \/\/ CAUTION: after the start_concurrent_cycle() call below, the concurrent marking\n+    \/\/ thread(s) could be running concurrently with us. Make sure that anything\n+    \/\/ after this point does not assume that we are the only GC thread running.\n+    \/\/ Note: of course, the actual marking work will not start until the safepoint\n+    \/\/ itself is released in SuspendibleThreadSet::desynchronize().\n+    start_concurrent_cycle(collector.concurrent_operation_is_full_mark());\n+    ConcurrentGCBreakpoints::notify_idle_to_active();\n+  }\n+}\n+\n+void G1CollectedHeap::complete_cleaning(BoolObjectClosure* is_alive,\n+                                        bool class_unloading_occurred) {\n+  uint num_workers = workers()->active_workers();\n+  G1ParallelCleaningTask unlink_task(is_alive, num_workers, class_unloading_occurred);\n+  workers()->run_task(&unlink_task);\n+}\n+\n+bool G1STWSubjectToDiscoveryClosure::do_object_b(oop obj) {\n+  assert(obj != NULL, \"must not be NULL\");\n+  assert(_g1h->is_in_reserved(obj), \"Trying to discover obj \" PTR_FORMAT \" not in heap\", p2i(obj));\n+  \/\/ The areas the CM and STW ref processor manage must be disjoint. The is_in_cset() below\n+  \/\/ may falsely indicate that this is not the case here: however the collection set only\n+  \/\/ contains old regions when concurrent mark is not running.\n+  return _g1h->is_in_cset(obj) || _g1h->heap_region_containing(obj)->is_survivor();\n+}\n+\n+void G1CollectedHeap::make_pending_list_reachable() {\n+  if (collector_state()->in_concurrent_start_gc()) {\n+    oop pll_head = Universe::reference_pending_list();\n+    if (pll_head != NULL) {\n+      \/\/ Any valid worker id is fine here as we are in the VM thread and single-threaded.\n+      _cm->mark_in_next_bitmap(0 \/* worker_id *\/, pll_head);\n+    }\n+  }\n+}\n+\n+static bool do_humongous_object_logging() {\n+  return log_is_enabled(Debug, gc, humongous);\n+}\n+\n+bool G1CollectedHeap::should_do_eager_reclaim() const {\n+  \/\/ As eager reclaim logging also gives information about humongous objects in\n+  \/\/ the heap in general, always do the eager reclaim pass even without known\n+  \/\/ candidates.\n+  return (G1EagerReclaimHumongousObjects &&\n+          (has_humongous_reclaim_candidates() || do_humongous_object_logging()));\n+}\n+\n+void G1CollectedHeap::set_humongous_stats(uint num_humongous_total, uint num_humongous_candidates) {\n+  _num_humongous_objects = num_humongous_total;\n+  _num_humongous_reclaim_candidates = num_humongous_candidates;\n+}\n+\n+bool G1CollectedHeap::should_sample_collection_set_candidates() const {\n+  G1CollectionSetCandidates* candidates = G1CollectedHeap::heap()->collection_set()->candidates();\n+  return candidates != NULL && candidates->num_remaining() > 0;\n+}\n+\n+void G1CollectedHeap::set_collection_set_candidates_stats(G1CardSetMemoryStats& stats) {\n+  _collection_set_candidates_card_set_stats = stats;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":106,"deletions":0,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"gc\/g1\/g1EvacuationInfo.hpp\"\n+#include \"gc\/g1\/g1EvacInfo.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}