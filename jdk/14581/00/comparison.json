{"files":[{"patch":"@@ -168,0 +168,1 @@\n+      case Op_LoopVectorMask:\n@@ -5910,0 +5911,30 @@\n+instruct loop_vmask_gen(pRegGov pg, iRegIorL2I from, iRegIorL2I to, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pg (LoopVectorMask from to));\n+  effect(KILL cr);\n+  format %{ \"loop_vmask_gen $pg, $from, $to\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whileltw($pg$$PRegister, __ elemType_to_regVariant(bt), $from$$Register, $to$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ -------------------------- Vector mask extraction --------------------------\n+\n+instruct extract_high_mask(pRegGov pd, pRegGov pn) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (ExtractHighMask pn));\n+  format %{ \"extract_high_mask $pd, $pn\" %}\n+  ins_encode %{ __ sve_punpkhi($pd$$PRegister, $pn$$PRegister); %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extract_low_mask(pRegGov pd, pRegGov pn) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (ExtractLowMask pn));\n+  format %{ \"extract_low_mask $pd, $pn\" %}\n+  ins_encode %{ __ sve_punpklo($pd$$PRegister, $pn$$PRegister); %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -158,0 +158,1 @@\n+      case Op_LoopVectorMask:\n@@ -4187,0 +4188,30 @@\n+instruct loop_vmask_gen(pRegGov pg, iRegIorL2I from, iRegIorL2I to, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pg (LoopVectorMask from to));\n+  effect(KILL cr);\n+  format %{ \"loop_vmask_gen $pg, $from, $to\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whileltw($pg$$PRegister, __ elemType_to_regVariant(bt), $from$$Register, $to$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ -------------------------- Vector mask extraction --------------------------\n+\n+instruct extract_high_mask(pRegGov pd, pRegGov pn) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (ExtractHighMask pn));\n+  format %{ \"extract_high_mask $pd, $pn\" %}\n+  ins_encode %{ __ sve_punpkhi($pd$$PRegister, $pn$$PRegister); %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extract_low_mask(pRegGov pd, pRegGov pn) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (ExtractLowMask pn));\n+  format %{ \"extract_low_mask $pd, $pn\" %}\n+  ins_encode %{ __ sve_punpklo($pd$$PRegister, $pn$$PRegister); %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -1749,0 +1749,1 @@\n+    case Op_LoopVectorMask:\n@@ -8968,0 +8969,57 @@\n+instruct loop_vmask_gen_small_trip(kReg dst, rRegI from, rRegI to, rRegI tmp1, rRegL tmp2) %{\n+  predicate(n->as_LoopVectorMask()->max_trips() > 0 &&\n+            n->as_LoopVectorMask()->max_trips() < 256);\n+  match(Set dst (LoopVectorMask from to));\n+  format %{ \"loop_vmask_gen_small_trip $dst, $from, $to\\t! loop vector mask generator\" %}\n+  effect(TEMP tmp1, TEMP tmp2);\n+  ins_encode %{\n+    int vlen = Matcher::vector_length(this);\n+    jlong all_true_mask = (vlen < 64) ? ((1L << vlen) - 1) : -1L;\n+    __ movl($tmp1$$Register, $to$$Register);\n+    __ subl($tmp1$$Register, $from$$Register);\n+    __ mov64($tmp2$$Register, all_true_mask);\n+    __ bzhiq($tmp2$$Register, $tmp2$$Register, $tmp1$$Register);\n+    __ kmovql($dst$$KRegister, $tmp2$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct loop_vmask_gen(kReg dst, rRegI from, rRegI to, rRegI tmp1, rRegL tmp2) %{\n+  predicate(n->as_LoopVectorMask()->max_trips() <= 0 ||\n+            n->as_LoopVectorMask()->max_trips() >= 256);\n+  match(Set dst (LoopVectorMask from to));\n+  format %{ \"loop_vmask_gen $dst, $from, $to\\t! loop vector mask generator\" %}\n+  effect(TEMP tmp1, TEMP tmp2);\n+  ins_encode %{\n+    int vlen = Matcher::vector_length(this);\n+    jlong all_true_mask = (vlen < 64) ? ((1L << vlen) - 1) : -1L;\n+    Label SATURATED;\n+    __ movl($tmp1$$Register, $to$$Register);\n+    __ subl($tmp1$$Register, $from$$Register);\n+    __ mov64($tmp2$$Register, all_true_mask);\n+    __ cmpl($tmp1$$Register, 255);\n+    __ jccb(Assembler::greaterEqual, SATURATED);\n+    __ bzhiq($tmp2$$Register, $tmp2$$Register, $tmp1$$Register);\n+    __ bind(SATURATED);\n+    __ kmovql($dst$$KRegister, $tmp2$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct extract_high_mask(kReg dst, kReg src) %{\n+  match(Set dst (ExtractHighMask src));\n+  format %{ \"extract_high_mask $dst, $src\" %}\n+  ins_encode %{\n+    int vlen = Matcher::vector_length(this);\n+    __ kshiftrql($dst$$KRegister, $src$$KRegister, vlen);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct extract_low_mask(kReg dst_src) %{\n+  match(Set dst_src (ExtractLowMask dst_src));\n+  format %{ \"extract_low_mask $dst_src, $dst_src\\t# do nothing\" %}\n+  ins_encode %{ \/* empty encoding *\/ %}\n+  ins_pipe( empty );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":58,"deletions":0,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -4237,0 +4237,1 @@\n+    \"LoopVectorMask\", \"ExtractLowMask\", \"ExtractHighMask\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -515,9 +515,0 @@\n-#ifdef COMPILER2\n-  if (PostLoopMultiversioning && !RangeCheckElimination) {\n-    if (!FLAG_IS_DEFAULT(PostLoopMultiversioning)) {\n-      warning(\"PostLoopMultiversioning disabled because RangeCheckElimination is disabled.\");\n-    }\n-    FLAG_SET_CMDLINE(PostLoopMultiversioning, false);\n-  }\n-#endif \/\/ COMPILER2\n-\n","filename":"src\/hotspot\/share\/compiler\/compilerDefinitions.cpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -185,3 +185,0 @@\n-  product(bool, PostLoopMultiversioning, false, EXPERIMENTAL,               \\\n-           \"Multi versioned post loops to eliminate range checks\")          \\\n-                                                                            \\\n@@ -573,0 +570,6 @@\n+  product(bool, UseMaskedLoop, false, EXPERIMENTAL,                         \\\n+          \"Use fully predicated loop auto-vectorization\")                   \\\n+                                                                            \\\n+  notproduct(bool, TraceMaskedLoop, false,                                  \\\n+          \"Trace masked loop transformations\")                              \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -218,0 +218,1 @@\n+macro(LoopVectorMask)\n@@ -485,0 +486,2 @@\n+macro(ExtractHighMask)\n+macro(ExtractLowMask)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1891,49 +1891,0 @@\n-\n-\/\/-------------------------insert_scalar_rced_post_loop------------------------\n-\/\/ Insert a copy of the rce'd main loop as a post loop,\n-\/\/ We have not unrolled the main loop, so this is the right time to inject this.\n-\/\/ Later we will examine the partner of this post loop pair which still has range checks\n-\/\/ to see inject code which tests at runtime if the range checks are applicable.\n-void PhaseIdealLoop::insert_scalar_rced_post_loop(IdealLoopTree *loop, Node_List &old_new) {\n-  if (!loop->_head->is_CountedLoop()) return;\n-\n-  CountedLoopNode *cl = loop->_head->as_CountedLoop();\n-\n-  \/\/ only process RCE'd main loops\n-  if (!cl->is_main_loop() || loop->range_checks_present()) return;\n-\n-#ifndef PRODUCT\n-  if (TraceLoopOpts) {\n-    tty->print(\"PostScalarRce  \");\n-    loop->dump_head();\n-  }\n-#endif\n-  C->set_major_progress();\n-\n-  \/\/ Find common pieces of the loop being guarded with pre & post loops\n-  CountedLoopNode *main_head = loop->_head->as_CountedLoop();\n-  CountedLoopEndNode *main_end = main_head->loopexit();\n-  \/\/ diagnostic to show loop end is not properly formed\n-  assert(main_end->outcnt() == 2, \"1 true, 1 false path only\");\n-\n-  Node *incr = main_end->incr();\n-  Node *limit = main_end->limit();\n-\n-  \/\/ In this case we throw away the result as we are not using it to connect anything else.\n-  CountedLoopNode *post_head = nullptr;\n-  insert_post_loop(loop, old_new, main_head, main_end, incr, limit, post_head);\n-  copy_assertion_predicates_to_post_loop(main_head->skip_strip_mined(), post_head, incr, main_head->stride());\n-\n-  \/\/ It's difficult to be precise about the trip-counts\n-  \/\/ for post loops.  They are usually very short,\n-  \/\/ so guess that unit vector trips is a reasonable value.\n-  post_head->set_profile_trip_cnt(4.0);\n-  post_head->set_is_rce_post_loop();\n-\n-  \/\/ Now force out all loop-invariant dominating tests.  The optimizer\n-  \/\/ finds some, but we _know_ they are all useless.\n-  peeled_dom_test_elim(loop, old_new);\n-  loop->record_for_igvn();\n-}\n-\n-\n@@ -3207,137 +3158,0 @@\n-\/\/-------------------------multi_version_post_loops----------------------------\n-\/\/ Check the range checks that remain, if simple, use the bounds to guard\n-\/\/ which version to a post loop we execute, one with range checks or one without\n-bool PhaseIdealLoop::multi_version_post_loops(IdealLoopTree *rce_loop, IdealLoopTree *legacy_loop) {\n-  bool multi_version_succeeded = false;\n-  assert(RangeCheckElimination, \"\");\n-  CountedLoopNode *legacy_cl = legacy_loop->_head->as_CountedLoop();\n-  assert(legacy_cl->is_post_loop(), \"\");\n-\n-  \/\/ Check for existence of range checks using the unique instance to make a guard with\n-  Unique_Node_List worklist;\n-  for (uint i = 0; i < legacy_loop->_body.size(); i++) {\n-    Node *iff = legacy_loop->_body[i];\n-    int iff_opc = iff->Opcode();\n-    if (iff_opc == Op_If || iff_opc == Op_RangeCheck) {\n-      worklist.push(iff);\n-    }\n-  }\n-\n-  \/\/ Find RCE'd post loop so that we can stage its guard.\n-  if (legacy_cl->is_canonical_loop_entry() == nullptr) {\n-    return multi_version_succeeded;\n-  }\n-  Node* ctrl = legacy_cl->in(LoopNode::EntryControl);\n-  Node* iffm = ctrl->in(0);\n-\n-  \/\/ Now we test that both the post loops are connected\n-  Node* post_loop_region = iffm->in(0);\n-  if (post_loop_region == nullptr) return multi_version_succeeded;\n-  if (!post_loop_region->is_Region()) return multi_version_succeeded;\n-  Node* covering_region = post_loop_region->in(RegionNode::Control+1);\n-  if (covering_region == nullptr) return multi_version_succeeded;\n-  if (!covering_region->is_Region()) return multi_version_succeeded;\n-  Node* p_f = covering_region->in(RegionNode::Control);\n-  if (p_f == nullptr) return multi_version_succeeded;\n-  if (!p_f->is_IfFalse()) return multi_version_succeeded;\n-  if (!p_f->in(0)->is_CountedLoopEnd()) return multi_version_succeeded;\n-  CountedLoopEndNode* rce_loop_end = p_f->in(0)->as_CountedLoopEnd();\n-  if (rce_loop_end == nullptr) return multi_version_succeeded;\n-  CountedLoopNode* rce_cl = rce_loop_end->loopnode();\n-  if (rce_cl == nullptr || !rce_cl->is_post_loop()) return multi_version_succeeded;\n-  CountedLoopNode *known_rce_cl = rce_loop->_head->as_CountedLoop();\n-  if (rce_cl != known_rce_cl) return multi_version_succeeded;\n-\n-  \/\/ Then we fetch the cover entry test\n-  ctrl = rce_cl->in(LoopNode::EntryControl);\n-  if (!ctrl->is_IfTrue() && !ctrl->is_IfFalse()) return multi_version_succeeded;\n-\n-#ifndef PRODUCT\n-  if (TraceLoopOpts) {\n-    tty->print(\"PostMultiVersion\\n\");\n-    rce_loop->dump_head();\n-    legacy_loop->dump_head();\n-  }\n-#endif\n-\n-  \/\/ Now fetch the limit we want to compare against\n-  Node *limit = rce_cl->limit();\n-  bool first_time = true;\n-\n-  \/\/ If we got this far, we identified the post loop which has been RCE'd and\n-  \/\/ we have a work list.  Now we will try to transform the if guard to cause\n-  \/\/ the loop pair to be multi version executed with the determination left to runtime\n-  \/\/ or the optimizer if full information is known about the given arrays at compile time.\n-  Node *last_min = nullptr;\n-  multi_version_succeeded = true;\n-  while (worklist.size()) {\n-    Node* rc_iffm = worklist.pop();\n-    if (rc_iffm->is_If()) {\n-      Node *rc_bolzm = rc_iffm->in(1);\n-      if (rc_bolzm->is_Bool()) {\n-        Node *rc_cmpzm = rc_bolzm->in(1);\n-        if (rc_cmpzm->is_Cmp()) {\n-          Node *rc_left = rc_cmpzm->in(2);\n-          if (rc_left->Opcode() != Op_LoadRange) {\n-            multi_version_succeeded = false;\n-            break;\n-          }\n-          if (first_time) {\n-            last_min = rc_left;\n-            first_time = false;\n-          } else {\n-            Node *cur_min = new MinINode(last_min, rc_left);\n-            last_min = cur_min;\n-            _igvn.register_new_node_with_optimizer(last_min);\n-          }\n-        }\n-      }\n-    }\n-  }\n-\n-  \/\/ All we have to do is update the limit of the rce loop\n-  \/\/ with the min of our expression and the current limit.\n-  \/\/ We will use this expression to replace the current limit.\n-  if (last_min && multi_version_succeeded) {\n-    Node *cur_min = new MinINode(last_min, limit);\n-    _igvn.register_new_node_with_optimizer(cur_min);\n-    Node *cmp_node = rce_loop_end->cmp_node();\n-    _igvn.replace_input_of(cmp_node, 2, cur_min);\n-    set_ctrl(cur_min, ctrl);\n-    set_loop(cur_min, rce_loop->_parent);\n-\n-    legacy_cl->mark_is_multiversioned();\n-    rce_cl->mark_is_multiversioned();\n-    multi_version_succeeded = true;\n-\n-    C->set_major_progress();\n-  }\n-\n-  return multi_version_succeeded;\n-}\n-\n-\/\/-------------------------poison_rce_post_loop--------------------------------\n-\/\/ Causes the rce'd post loop to be optimized away if multiversioning fails\n-void PhaseIdealLoop::poison_rce_post_loop(IdealLoopTree *rce_loop) {\n-  CountedLoopNode *rce_cl = rce_loop->_head->as_CountedLoop();\n-  Node* ctrl = rce_cl->in(LoopNode::EntryControl);\n-  if (ctrl->is_IfTrue() || ctrl->is_IfFalse()) {\n-    Node* iffm = ctrl->in(0);\n-    if (iffm->is_If()) {\n-      Node* cur_bool = iffm->in(1);\n-      if (cur_bool->is_Bool()) {\n-        Node* cur_cmp = cur_bool->in(1);\n-        if (cur_cmp->is_Cmp()) {\n-          BoolTest::mask new_test = BoolTest::gt;\n-          BoolNode *new_bool = new BoolNode(cur_cmp, new_test);\n-          _igvn.replace_node(cur_bool, new_bool);\n-          _igvn._worklist.push(new_bool);\n-          Node* left_op = cur_cmp->in(1);\n-          _igvn.replace_input_of(cur_cmp, 2, left_op);\n-          C->set_major_progress();\n-        }\n-      }\n-    }\n-  }\n-}\n-\n@@ -3873,8 +3687,0 @@\n-    if (should_unroll && !should_peel && PostLoopMultiversioning &&\n-        Matcher::has_predicated_vectors()) {\n-      \/\/ Try to setup multiversioning on main loops before they are unrolled\n-      if (cl->is_main_loop() && (cl->unrolled_count() == 1)) {\n-        phase->insert_scalar_rced_post_loop(this, old_new);\n-      }\n-    }\n-\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":0,"deletions":194,"binary":false,"changes":194,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+#include \"opto\/vmaskloop.hpp\"\n@@ -2277,0 +2278,4 @@\n+  if (!stride_is_con()) {\n+    \/\/ Stride could be non-constant if a loop is vector masked\n+    return 0;\n+  }\n@@ -4012,0 +4017,1 @@\n+    if (cl->is_vector_masked()) tty->print(\" masked\");\n@@ -4013,1 +4019,0 @@\n-    if (cl->is_multiversioned()) tty->print(\" multi \");\n@@ -4653,23 +4658,1 @@\n-\n-        if (cl->is_rce_post_loop() && !cl->is_vectorized_loop()) {\n-          assert(PostLoopMultiversioning, \"multiversioning must be enabled\");\n-          \/\/ Check that the rce'd post loop is encountered first, multiversion after all\n-          \/\/ major main loop optimization are concluded\n-          if (!C->major_progress()) {\n-            IdealLoopTree *lpt_next = lpt->_next;\n-            if (lpt_next && lpt_next->is_counted()) {\n-              CountedLoopNode *cl = lpt_next->_head->as_CountedLoop();\n-              if (cl->is_post_loop() && lpt_next->range_checks_present()) {\n-                if (!cl->is_multiversioned()) {\n-                  if (multi_version_post_loops(lpt, lpt_next) == false) {\n-                    \/\/ Cause the rce loop to be optimized away if we fail\n-                    cl->mark_is_multiversioned();\n-                    cl->set_slp_max_unroll(0);\n-                    poison_rce_post_loop(lpt);\n-                  }\n-                }\n-              }\n-            }\n-            sw.transform_loop(lpt, true);\n-          }\n-        } else if (cl->is_main_loop()) {\n+        if (cl->is_main_loop()) {\n@@ -4698,0 +4681,12 @@\n+\n+  \/\/ Perform loop vectorization with vector masks\n+  if (UseMaskedLoop && Matcher::has_predicated_vectors() &&\n+      C->has_loops() && !C->major_progress()) {\n+    VectorMaskedLoop vml(this);\n+    for (LoopTreeIterator iter(_ltree_root); !iter.done(); iter.next()) {\n+      IdealLoopTree* lpt = iter.current();\n+      if (lpt->is_counted() && lpt->is_innermost()) {\n+        vml.try_vectorize_loop(lpt);\n+      }\n+    }\n+  }\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":19,"deletions":24,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -75,1 +75,1 @@\n-         IsMultiversioned      = 1<<12,\n+         VectorMasked          = 1<<12,\n@@ -83,2 +83,0 @@\n-  char _postloop_flags;\n-  enum { RCEPostLoop = 1 };\n@@ -96,1 +94,0 @@\n-  bool is_multiversioned() const { return _loop_flags & IsMultiversioned; }\n@@ -98,0 +95,1 @@\n+  bool is_vector_masked() const { return _loop_flags & VectorMasked; }\n@@ -113,1 +111,1 @@\n-  void mark_is_multiversioned() { _loop_flags |= IsMultiversioned; }\n+  void mark_vector_masked() { _loop_flags |= VectorMasked; }\n@@ -124,3 +122,0 @@\n-  int is_rce_post_loop() const { return _postloop_flags & RCEPostLoop; }\n-  void set_is_rce_post_loop() { _postloop_flags |= RCEPostLoop; }\n-\n@@ -137,1 +132,1 @@\n-      _postloop_flags(0), _profile_trip_cnt(COUNT_UNKNOWN)  {\n+      _profile_trip_cnt(COUNT_UNKNOWN)  {\n@@ -146,0 +141,3 @@\n+    if (is_vector_masked()) {\n+      return false;\n+    }\n@@ -325,2 +323,0 @@\n-  void set_slp_pack_count(int pack_count)    { _slp_vector_pack_count = pack_count; }\n-  int  slp_pack_count() const                { return _slp_vector_pack_count; }\n@@ -778,0 +774,2 @@\n+  void collect_loop_core_nodes(PhaseIdealLoop* phase, Unique_Node_List& wq) const;\n+\n@@ -811,2 +809,0 @@\n-  void collect_loop_core_nodes(PhaseIdealLoop* phase, Unique_Node_List& wq) const;\n-\n@@ -832,0 +828,1 @@\n+  friend class VectorMaskedLoop;\n@@ -1308,3 +1305,0 @@\n-  \/\/ Add an RCE'd post loop which we will multi-version adapt for run time test path usage\n-  void insert_scalar_rced_post_loop( IdealLoopTree *loop, Node_List &old_new );\n-\n@@ -1405,7 +1399,0 @@\n-  \/\/ Process post loops which have range checks and try to build a multi-version\n-  \/\/ guard to safely determine if we can execute the post loop which was RCE'd.\n-  bool multi_version_post_loops(IdealLoopTree *rce_loop, IdealLoopTree *legacy_loop);\n-\n-  \/\/ Cause the rce'd post loop to optimized away, this happens if we cannot complete multiverioning\n-  void poison_rce_post_loop(IdealLoopTree *rce_loop);\n-\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":10,"deletions":23,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -101,0 +101,1 @@\n+class LoopVectorMaskNode;\n@@ -123,0 +124,2 @@\n+class ExtractHighMaskNode;\n+class ExtractLowMaskNode;\n@@ -729,0 +732,1 @@\n+      DEFINE_CLASS_ID(LoopVectorMask, Type, 9)\n@@ -912,0 +916,1 @@\n+  DEFINE_CLASS_QUERY(LoopVectorMask)\n@@ -1740,1 +1745,1 @@\n-class Node_Stack {\n+class Node_Stack : public ResourceObj {\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -57,1 +57,0 @@\n-  _post_block(arena(), 8, 0, nullptr),                      \/\/ nodes common to current block which are marked as post loop vectorizable\n@@ -119,5 +118,0 @@\n-  if (cl->is_rce_post_loop() && is_marked_reduction_loop()) {\n-    \/\/ Post loop vectorization doesn't support reductions\n-    return false;\n-  }\n-\n@@ -179,18 +173,0 @@\n-    if (PostLoopMultiversioning) {\n-      if (cl->is_vectorized_loop() && cl->is_main_loop() && !is_marked_reduction_loop()) {\n-        IdealLoopTree *lpt_next = cl->is_strip_mined() ? lpt->_parent->_next : lpt->_next;\n-        CountedLoopNode *cl_next = lpt_next->_head->as_CountedLoop();\n-        \/\/ Main loop SLP works well for manually unrolled loops. But post loop\n-        \/\/ vectorization doesn't work for these. To bail out the optimization\n-        \/\/ earlier, we have range check and loop stride conditions below.\n-        if (cl_next->is_post_loop() && !lpt_next->range_checks_present() &&\n-            cl_next->stride_is_con() && abs(cl_next->stride_con()) == 1) {\n-          if (!cl_next->is_vectorized_loop()) {\n-            \/\/ Propagate some main loop attributes to its corresponding scalar\n-            \/\/ rce'd post loop for vectorization with vector masks\n-            cl_next->set_slp_max_unroll(cl->slp_max_unroll());\n-            cl_next->set_slp_pack_count(cl->slp_pack_count());\n-          }\n-        }\n-      }\n-    }\n@@ -209,3 +185,0 @@\n-  int rpo_idx = _post_block.length();\n-\n-  assert(rpo_idx == 0, \"post loop block is empty\");\n@@ -316,21 +289,0 @@\n-    \/\/ In the main loop, SLP works well if parts of the operations in the loop body\n-    \/\/ are not vectorizable and those non-vectorizable parts will be unrolled only.\n-    \/\/ But in post loops with vector masks, we create singleton packs directly from\n-    \/\/ scalars so all operations should be vectorized together. This compares the\n-    \/\/ number of packs in the post loop with the main loop and bail out if the post\n-    \/\/ loop potentially has more packs.\n-    if (cl->is_rce_post_loop()) {\n-      for (uint i = 0; i < lpt()->_body.size(); i++) {\n-        if (ignored_loop_nodes[i] == -1) {\n-          _post_block.at_put_grow(rpo_idx++, lpt()->_body.at(i));\n-        }\n-      }\n-      if (_post_block.length() > cl->slp_pack_count()) {\n-        \/\/ Clear local_loop_unroll_factor and bail out directly from here\n-        local_loop_unroll_factor = 0;\n-        cl->mark_was_slp();\n-        cl->set_slp_max_unroll(0);\n-        return;\n-      }\n-    }\n-\n@@ -407,1 +359,1 @@\n-    if (cl->is_main_loop() || cl->is_rce_post_loop()) {\n+    if (cl->is_main_loop()) {\n@@ -627,38 +579,0 @@\n-\n-    \/\/ Record eventual count of vector packs for checks in post loop vectorization\n-    if (PostLoopMultiversioning) {\n-      cl->set_slp_pack_count(_packset.length());\n-    }\n-  } else {\n-    assert(cl->is_rce_post_loop(), \"Must be an rce'd post loop\");\n-    int saved_mapped_unroll_factor = cl->slp_max_unroll();\n-    if (saved_mapped_unroll_factor) {\n-      int vector_mapped_unroll_factor = saved_mapped_unroll_factor;\n-\n-      \/\/ now reset the slp_unroll_factor so that we can check the analysis mapped\n-      \/\/ what the vector loop was mapped to\n-      cl->set_slp_max_unroll(0);\n-\n-      \/\/ do the analysis on the post loop\n-      unrolling_analysis(vector_mapped_unroll_factor);\n-\n-      \/\/ if our analyzed loop is a canonical fit, start processing it\n-      if (vector_mapped_unroll_factor == saved_mapped_unroll_factor) {\n-        \/\/ now add the vector nodes to packsets\n-        for (int i = 0; i < _post_block.length(); i++) {\n-          Node* n = _post_block.at(i);\n-          Node_List* singleton = new Node_List();\n-          singleton->push(n);\n-          _packset.append(singleton);\n-          set_my_pack(n, singleton);\n-        }\n-\n-        \/\/ map base types for vector usage\n-        compute_vector_element_type();\n-      } else {\n-        return false;\n-      }\n-    } else {\n-      \/\/ for some reason we could not map the slp analysis state of the vectorized loop\n-      return false;\n-    }\n@@ -2632,10 +2546,0 @@\n-  Node* vmask = nullptr;\n-  if (cl->is_rce_post_loop() && do_reserve_copy()) {\n-    \/\/ Create a vector mask node for post loop, bail out if not created\n-    vmask = create_post_loop_vmask();\n-    if (vmask == nullptr) {\n-      \/\/ create_post_loop_vmask checks many conditions, any of them could fail\n-      return false; \/\/ and reverse to backup IG\n-    }\n-  }\n-\n@@ -2653,4 +2557,0 @@\n-      if (cl->is_rce_post_loop()) {\n-        \/\/ override vlen with the main loops vector length\n-        vlen = cl->slp_max_unroll();\n-      }\n@@ -2678,7 +2578,1 @@\n-        if (cl->is_rce_post_loop()) {\n-          assert(vmask != nullptr, \"vector mask should be generated\");\n-          const TypeVect* vt = TypeVect::make(velt_basic_type(n), vlen);\n-          vn = new LoadVectorMaskedNode(ctl, mem, adr, atyp, vt, vmask);\n-        } else {\n-          vn = LoadVectorNode::make(opc, ctl, mem, adr, atyp, vlen, velt_basic_type(n), control_dependency(p));\n-        }\n+        vn = LoadVectorNode::make(opc, ctl, mem, adr, atyp, vlen, velt_basic_type(n), control_dependency(p));\n@@ -2702,7 +2596,1 @@\n-        if (cl->is_rce_post_loop()) {\n-          assert(vmask != nullptr, \"vector mask should be generated\");\n-          const TypeVect* vt = TypeVect::make(velt_basic_type(n), vlen);\n-          vn = new StoreVectorMaskedNode(ctl, mem, adr, val, atyp, vmask);\n-        } else {\n-          vn = StoreVectorNode::make(opc, ctl, mem, adr, atyp, val, vlen);\n-        }\n+        vn = StoreVectorNode::make(opc, ctl, mem, adr, atyp, val, vlen);\n@@ -2976,3 +2864,0 @@\n-        if (cl->is_rce_post_loop() && do_reserve_copy()) {\n-          cl->mark_is_multiversioned();\n-        }\n@@ -2991,101 +2876,0 @@\n-\/\/-------------------------create_post_loop_vmask-------------------------\n-\/\/ Check the post loop vectorizability and create a vector mask if yes.\n-\/\/ Return null to bail out if post loop is not vectorizable.\n-Node* SuperWord::create_post_loop_vmask() {\n-  CountedLoopNode *cl = lpt()->_head->as_CountedLoop();\n-  assert(cl->is_rce_post_loop(), \"Must be an rce post loop\");\n-  assert(!is_marked_reduction_loop(), \"no vector reduction in post loop\");\n-  assert(abs(cl->stride_con()) == 1, \"post loop stride can only be +\/-1\");\n-\n-  \/\/ Collect vector element types of all post loop packs. Also collect\n-  \/\/ superword pointers of each memory access operation if the address\n-  \/\/ expression is supported. (Note that vectorizable post loop should\n-  \/\/ only have positive scale in counting-up loop and negative scale in\n-  \/\/ counting-down loop.) Collected SWPointer(s) are also used for data\n-  \/\/ dependence check next.\n-  VectorElementSizeStats stats(_arena);\n-  GrowableArray<SWPointer*> swptrs(_arena, _packset.length(), 0, nullptr);\n-  for (int i = 0; i < _packset.length(); i++) {\n-    Node_List* p = _packset.at(i);\n-    assert(p->size() == 1, \"all post loop packs should be singleton\");\n-    Node* n = p->at(0);\n-    BasicType bt = velt_basic_type(n);\n-    if (!is_java_primitive(bt)) {\n-      return nullptr;\n-    }\n-    if (n->is_Mem()) {\n-      SWPointer* mem_p = new (_arena) SWPointer(n->as_Mem(), this, nullptr, false);\n-      \/\/ For each memory access, we check if the scale (in bytes) in its\n-      \/\/ address expression is equal to the data size times loop stride.\n-      \/\/ With this, Only positive scales exist in counting-up loops and\n-      \/\/ negative scales exist in counting-down loops.\n-      if (mem_p->scale_in_bytes() != type2aelembytes(bt) * cl->stride_con()) {\n-        return nullptr;\n-      }\n-      swptrs.append(mem_p);\n-    }\n-    stats.record_size(type2aelembytes(bt));\n-  }\n-\n-  \/\/ Find the vector data type for generating vector masks. Currently we\n-  \/\/ don't support post loops with mixed vector data sizes\n-  int unique_size = stats.unique_size();\n-  BasicType vmask_bt;\n-  switch (unique_size) {\n-    case 1:  vmask_bt = T_BYTE; break;\n-    case 2:  vmask_bt = T_SHORT; break;\n-    case 4:  vmask_bt = T_INT; break;\n-    case 8:  vmask_bt = T_LONG; break;\n-    default: return nullptr;\n-  }\n-\n-  \/\/ Currently we can't remove this MaxVectorSize constraint. Without it,\n-  \/\/ it's not guaranteed that the RCE'd post loop runs at most \"vlen - 1\"\n-  \/\/ iterations, because the vector drain loop may not be cloned from the\n-  \/\/ vectorized main loop. We should re-engineer PostLoopMultiversioning\n-  \/\/ to fix this problem.\n-  int vlen = cl->slp_max_unroll();\n-  if (unique_size * vlen != MaxVectorSize) {\n-    return nullptr;\n-  }\n-\n-  \/\/ Bail out if target doesn't support mask generator or masked load\/store\n-  if (!Matcher::match_rule_supported_vector(Op_LoadVectorMasked, vlen, vmask_bt)  ||\n-      !Matcher::match_rule_supported_vector(Op_StoreVectorMasked, vlen, vmask_bt) ||\n-      !Matcher::match_rule_supported_vector(Op_VectorMaskGen, vlen, vmask_bt)) {\n-    return nullptr;\n-  }\n-\n-  \/\/ Bail out if potential data dependence exists between memory accesses\n-  if (SWPointer::has_potential_dependence(swptrs)) {\n-    return nullptr;\n-  }\n-\n-  \/\/ Create vector mask with the post loop trip count. Note there's another\n-  \/\/ vector drain loop which is cloned from main loop before super-unrolling\n-  \/\/ so the scalar post loop runs at most vlen-1 trips. Hence, this version\n-  \/\/ only runs at most 1 iteration after vector mask transformation.\n-  Node* trip_cnt;\n-  Node* new_incr;\n-  if (cl->stride_con() > 0) {\n-    trip_cnt = new SubINode(cl->limit(), cl->init_trip());\n-    new_incr = new AddINode(cl->phi(), trip_cnt);\n-  } else {\n-    trip_cnt = new SubINode(cl->init_trip(), cl->limit());\n-    new_incr = new SubINode(cl->phi(), trip_cnt);\n-  }\n-  _igvn.register_new_node_with_optimizer(trip_cnt);\n-  _igvn.register_new_node_with_optimizer(new_incr);\n-  _igvn.replace_node(cl->incr(), new_incr);\n-  Node* length = new ConvI2LNode(trip_cnt);\n-  _igvn.register_new_node_with_optimizer(length);\n-  Node* vmask = VectorMaskGenNode::make(length, vmask_bt);\n-  _igvn.register_new_node_with_optimizer(vmask);\n-\n-  \/\/ Remove exit test to transform 1-iteration loop to straight-line code.\n-  \/\/ This results in redundant cmp+branch instructions been eliminated.\n-  Node *cl_exit = cl->loopexit();\n-  _igvn.replace_input_of(cl_exit, 1, _igvn.intcon(0));\n-  return vmask;\n-}\n-\n@@ -3101,6 +2885,0 @@\n-  if (cl->is_rce_post_loop()) {\n-    \/\/ override vlen with the main loops vector length\n-    assert(p->size() == 1, \"Packs in post loop should have only one node\");\n-    vlen = cl->slp_max_unroll();\n-  }\n-\n@@ -3110,4 +2888,2 @@\n-  \/\/ all inputs are the same iv, so we do a same inputs check here. But\n-  \/\/ in post loops, \"have_same_inputs\" is always true because all packs\n-  \/\/ are singleton. That's why a pack size check is also required.\n-  if (opd == iv() && (!have_same_inputs || p->size() == 1)) {\n+  \/\/ all inputs are the same iv, so we do a same inputs check here.\n+  if (opd == iv() && !have_same_inputs) {\n@@ -4029,1 +3805,0 @@\n-  _post_block.clear();\n@@ -4098,1 +3873,1 @@\n-  _stack_idx(0)\n+  _stack_idx(0), _phase(slp->phase()), _lpt(slp->lpt())\n@@ -4103,1 +3878,2 @@\n-  NOT_PRODUCT(_tracer.ctor_1(mem);)\n+  init();\n+}\n@@ -4105,1 +3881,21 @@\n-  Node* adr = mem->in(MemNode::Address);\n+\/\/ Following is used outside superword optimization\n+SWPointer::SWPointer(MemNode* mem, PhaseIdealLoop* phase, IdealLoopTree* lpt,\n+                     Node_Stack* nstack, bool analyze_only) :\n+  _mem(mem), _slp(nullptr), _base(nullptr), _adr(nullptr),\n+  _scale(0), _offset(0), _invar(nullptr),\n+#ifdef ASSERT\n+  _debug_invar(nullptr), _debug_negate_invar(false), _debug_invar_scale(nullptr),\n+#endif\n+  _nstack(nstack), _analyze_only(analyze_only),\n+  _stack_idx(nstack->size()), _phase(phase), _lpt(lpt)\n+#ifndef PRODUCT\n+  , _tracer(nullptr)\n+#endif\n+{\n+  init();\n+}\n+\n+void SWPointer::init() {\n+  NOT_PRODUCT(_tracer.ctor_1(_mem);)\n+\n+  Node* adr = _mem->in(MemNode::Address);\n@@ -4123,1 +3919,1 @@\n-  NOT_PRODUCT(if(_slp->is_trace_alignment()) _tracer.store_depth();)\n+  NOT_PRODUCT(if(_slp && _slp->is_trace_alignment()) _tracer.store_depth();)\n@@ -4152,2 +3948,2 @@\n-  NOT_PRODUCT(if(_slp->is_trace_alignment()) _tracer.restore_depth();)\n-  NOT_PRODUCT(_tracer.ctor_6(mem);)\n+  NOT_PRODUCT(if(_slp && _slp->is_trace_alignment()) _tracer.restore_depth();)\n+  NOT_PRODUCT(_tracer.ctor_6(_mem);)\n@@ -4169,1 +3965,1 @@\n-  _stack_idx(p->_stack_idx)\n+  _stack_idx(p->_stack_idx), _phase(p->_phase), _lpt(p->_lpt)\n@@ -4185,1 +3981,1 @@\n-  if (is_not_member && _slp->lp()->is_main_loop()) {\n+  if (is_not_member && _slp && _slp->lp()->is_main_loop()) {\n@@ -4500,0 +4296,4 @@\n+bool SWPointer::Tracer::slp_trace_alignment() {\n+  return _slp && _slp->is_trace_alignment();\n+}\n+\n@@ -4501,1 +4301,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4507,1 +4307,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4517,1 +4317,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4525,1 +4325,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4532,1 +4332,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4543,1 +4343,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4550,1 +4350,1 @@\n-  if (_slp->do_vector_loop() && _slp->is_debug() && _slp->_lpt->is_member(_slp->_phase->get_loop(n_c)) != (int)_slp->in_bb(n)) {\n+  if (_slp && _slp->do_vector_loop() && _slp->is_debug() && _slp->_lpt->is_member(_slp->_phase->get_loop(n_c)) != (int)_slp->in_bb(n)) {\n@@ -4561,1 +4361,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4568,1 +4368,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4574,1 +4374,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4580,1 +4380,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4588,1 +4388,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4596,1 +4396,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4604,1 +4404,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4612,1 +4412,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4618,1 +4418,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4624,1 +4424,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4631,1 +4431,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4637,1 +4437,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4645,1 +4445,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4653,1 +4453,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4661,1 +4461,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4671,1 +4471,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4677,1 +4477,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4695,1 +4495,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4701,1 +4501,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4707,1 +4507,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4713,1 +4513,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4719,1 +4519,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4726,1 +4526,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4733,1 +4533,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4742,1 +4542,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4751,1 +4551,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4760,1 +4560,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4768,1 +4568,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n@@ -4775,1 +4575,1 @@\n-  if(_slp->is_trace_alignment()) {\n+  if (slp_trace_alignment()) {\n","filename":"src\/hotspot\/share\/opto\/superword.cpp","additions":74,"deletions":274,"binary":false,"changes":348,"status":"modified"},{"patch":"@@ -241,3 +241,2 @@\n-  VectorElementSizeStats(Arena* a) : _stats(NEW_ARENA_ARRAY(a, int, 4)) {\n-    memset(_stats, 0, sizeof(int) * 4);\n-  }\n+  VectorElementSizeStats(Arena* a) : _stats(NEW_ARENA_ARRAY(a, int, 4)) { clear(); }\n+  void clear() { memset(_stats, 0, sizeof(int) * 4); }\n@@ -250,0 +249,4 @@\n+  int count_size(int size) {\n+    return _stats[exact_log2(size)];\n+  }\n+\n@@ -288,1 +291,0 @@\n-  GrowableArray<Node*> _post_block;      \/\/ Nodes in post loop block\n@@ -582,2 +584,0 @@\n-  \/\/ Create vector mask for post loop vectorization\n-  Node* create_post_loop_vmask();\n@@ -660,3 +660,10 @@\n-  PhaseIdealLoop* phase() const { return _slp->phase(); }\n-  IdealLoopTree*  lpt() const   { return _slp->lpt(); }\n-  PhiNode*        iv() const    { return _slp->iv();  } \/\/ Induction var\n+  PhaseIdealLoop* _phase;    \/\/ PhaseIdealLoop handle\n+  IdealLoopTree*  _lpt;      \/\/ Current IdealLoopTree\n+\n+  PhaseIdealLoop* phase() const { return _phase; }\n+  IdealLoopTree*  lpt() const   { return _lpt; }\n+  PhiNode* iv() const {\n+    return _slp ? _slp->iv() : _lpt->_head->as_CountedLoop()->phi()->as_Phi();\n+  }\n+\n+  void init();\n@@ -684,0 +691,3 @@\n+  \/\/ Following is used outside superword optimization\n+  SWPointer(MemNode* mem, PhaseIdealLoop* phase, IdealLoopTree* lpt,\n+            Node_Stack* nstack, bool analyze_only);\n@@ -758,0 +768,2 @@\n+    bool slp_trace_alignment();\n+\n","filename":"src\/hotspot\/share\/opto\/superword.hpp","additions":21,"deletions":9,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -1822,0 +1822,45 @@\n+\/\/------------------------------LoopVectorMaskNode------------------------------\n+\/\/ Node for generating a loop vector mask from an integer range\n+class LoopVectorMaskNode : public TypeNode {\n+ private:\n+  int _max_trips;\n+ public:\n+  LoopVectorMaskNode(Node* from, Node* to, const Type* ty, int max_trips) :\n+      TypeNode(ty, 3), _max_trips(max_trips) {\n+    init_class_id(Class_LoopVectorMask);\n+    init_req(1, from);\n+    init_req(2, to);\n+  }\n+\n+  virtual int Opcode() const;\n+  virtual uint hash() const { return TypeNode::hash() + _max_trips; }\n+  virtual bool cmp(const Node& n) const {\n+    return TypeNode::cmp(n) &&\n+           _max_trips == ((LoopVectorMaskNode&)n)._max_trips;\n+  }\n+  virtual uint size_of() const { return sizeof(LoopVectorMaskNode); }\n+  virtual uint ideal_reg() const { return Op_RegVectMask; }\n+  int max_trips() const { return _max_trips; }\n+};\n+\n+\/\/--------------------------Extract[High|Low]MaskNode--------------------------\n+class ExtractHighMaskNode : public TypeNode {\n+ public:\n+  ExtractHighMaskNode(Node* in, const Type* ty) : TypeNode(ty, 2) {\n+    init_req(1, in);\n+  }\n+\n+  virtual int Opcode() const;\n+  virtual uint ideal_reg() const { return Op_RegVectMask; }\n+};\n+\n+class ExtractLowMaskNode : public TypeNode {\n+ public:\n+  ExtractLowMaskNode(Node* in, const Type* ty) : TypeNode(ty, 2) {\n+    init_req(1, in);\n+  }\n+\n+  virtual int Opcode() const;\n+  virtual uint ideal_reg() const { return Op_RegVectMask; }\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -0,0 +1,975 @@\n+\/*\n+ * Copyright (c) 2023, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"opto\/addnode.hpp\"\n+#include \"opto\/convertnode.hpp\"\n+#include \"opto\/vmaskloop.hpp\"\n+\n+\/\/        L O O P   V E C T O R   M A S K   T R A N S F O R M A T I O N\n+\/\/ ============================================================================\n+\n+\/\/ -------------------------------- Constructor -------------------------------\n+VectorMaskedLoop::VectorMaskedLoop(PhaseIdealLoop* phase) :\n+  _phase(phase),\n+  _igvn(&(phase->_igvn)),\n+  _arena(phase->C->comp_arena()),\n+\n+  _lpt(nullptr),\n+  _cl(nullptr),\n+  _cle(nullptr),\n+  _iv(nullptr),\n+\n+  _core_set(_arena),\n+  _body_set(_arena),\n+  _body_nodes(_arena, 32, 0, nullptr),\n+  _rpo_idx(_arena, 32, 0, 0),\n+  _elem_bt(_arena, 32, 0, T_ILLEGAL),\n+  _stmts(_arena, 2, 0, nullptr),\n+  _swptrs(_arena, 8, 0, nullptr),\n+  _size_stats(_arena)\n+{}\n+\n+\/\/ ------------------- Entry function of vector masked loop -------------------\n+void VectorMaskedLoop::try_vectorize_loop(IdealLoopTree* lpt) {\n+  assert(UseMaskedLoop, \"Option should be enabled\");\n+  assert(lpt->is_counted(), \"Loop must be counted\");\n+  assert(lpt->is_innermost(), \"Loop must be innermost\");\n+\n+  CountedLoopNode *cl = lpt->_head->as_CountedLoop();\n+  \/\/ Skip if loop is already vector masked\n+  if (cl->is_vector_masked()) return;\n+  \/\/ Skip non-post loop\n+  if (!cl->is_post_loop()) return;\n+  \/\/ Skip malformed counted loop\n+  if (!cl->is_valid_counted_loop(T_INT)) return;\n+  \/\/ Skip loop if stride is unsupported\n+  if (abs(cl->stride_con()) != 1) return;\n+  \/\/ Skip loop with control flow\n+  if (cl->loopexit()->in(0) != cl) return;\n+  \/\/ Skip if some loop operations are pinned to the backedge\n+  if (cl->back_control()->outcnt() != 1) return;\n+\n+  \/\/ Init data structures and collect loop nodes\n+  init(lpt);\n+  if (!collect_loop_nodes()) return;\n+\n+  \/\/ Collect loop statements and analyze vectorizability\n+  if (!collect_statements()) return;\n+  if (!analyze_vectorizability()) return;\n+\n+  \/\/ Try creating a vector mask with the smallest vector element size\n+  const TypeVectMask* t_vmask = create_vector_mask_type();\n+  if (t_vmask == nullptr || !t_vmask->isa_vectmask()) return;\n+\n+  \/\/ Transform the loop and set flags\n+  transform_loop(t_vmask);\n+  cl->mark_loop_vectorized();\n+  cl->mark_vector_masked();\n+  _phase->C->set_max_vector_size(MaxVectorSize);\n+  trace_msg(nullptr, \"Loop is vector masked\");\n+}\n+\n+\/\/ ----------------------------------- Init -----------------------------------\n+void VectorMaskedLoop::init(IdealLoopTree* lpt) {\n+  \/\/ Set current loop info\n+  _lpt = lpt;\n+  _cl = lpt->_head->as_CountedLoop();\n+  _cle = _cl->loopexit();\n+  _iv = _cle->phi();\n+\n+  \/\/ Reset data structures\n+  _core_set.clear();\n+  _body_set.clear();\n+  _body_nodes.clear();\n+  _rpo_idx.clear();\n+  _elem_bt.clear();\n+  _stmts.clear();\n+  _swptrs.clear();\n+  _size_stats.clear();\n+}\n+\n+\/\/ ------------------- Loop vectorizable analysis functions -------------------\n+\/\/ Collect loop nodes into an array with reverse postorder for convenience of\n+\/\/ future traversal. Do early bail out if unsupported node is found.\n+bool VectorMaskedLoop::collect_loop_nodes() {\n+  \/\/ Collect 7 (see EMPTY_LOOP_SIZE) core nodes of the loop\n+  _lpt->collect_loop_core_nodes(_phase, _core_set);\n+\n+  \/\/ Push loop nodes into a node set for fast membership check, also create a\n+  \/\/ temporary index map for RPO visit\n+  int node_cnt = _lpt->_body.size();\n+  for (int i = 0; i < node_cnt; i++) {\n+    Node* n = _lpt->_body.at(i);\n+    if (n->is_LoadStore() || n->is_RangeCheck() || n->is_Call()) {\n+      trace_msg(n, \"Found unsupported node in the loop\");\n+      return false;\n+    }\n+    _body_set.push(n);\n+    set_rpo_idx(n, i);\n+  }\n+\n+  \/\/ Visit all loop nodes from the head to create reverse postorder\n+  VectorSet visited(_arena);\n+  VectorSet post_visited(_arena);\n+  GrowableArray<Node*> stack(_arena, node_cnt, 0, nullptr);\n+  stack.push(_cl);\n+  int idx = node_cnt - 1;\n+  while (stack.length() > 0) {\n+    Node* n = stack.top();\n+    if (!visited.test(rpo_idx(n))) {\n+      \/\/ Forward arc in graph\n+      visited.set(rpo_idx(n));\n+    } else if (!post_visited.test(rpo_idx(n))) {\n+      \/\/ Cross or backward arc in graph\n+      if (!is_memory_phi(n)) {\n+        \/\/ Push all users in loop for non-mem-phi nodes\n+        for (DUIterator_Fast imax, i = n->fast_outs(imax); i < imax; i++) {\n+          Node* use = n->fast_out(i);\n+          if (in_body(use) && !visited.test(rpo_idx(use))) {\n+            stack.push(use);\n+          }\n+        }\n+      }\n+      if (n == stack.top()) {\n+        \/\/ Node is still at the top - no additional use is pushed, visit it.\n+        \/\/ Also initialize node info at this time.\n+        stack.pop();\n+        assert(idx >= 0, \"Is some node visited more than once?\");\n+        _body_nodes.at_put_grow(idx, n);\n+        _elem_bt.at_put_grow(idx, T_ILLEGAL);\n+        idx--;\n+        post_visited.set(rpo_idx(n));\n+      }\n+    } else {\n+      stack.pop();\n+    }\n+  }\n+\n+  \/\/ Bail out if loop has unreachable node while traversing from head\n+  if (idx != -1) {\n+    trace_msg(nullptr, \"Loop has unreachable node while traversing from head\");\n+    return false;\n+  }\n+  \/\/ Create a real index map for future use\n+  for (int i = 0; i < _body_nodes.length(); i++) {\n+    set_rpo_idx(_body_nodes.at(i), i);\n+  }\n+\n+#ifndef PRODUCT\n+  if (TraceMaskedLoop) {\n+    tty->print_cr(\"Collected loop nodes in reverse postorder\");\n+    for (int i = 0; i < _body_nodes.length(); i++) {\n+      tty->print(\" rpo=%d\\t\", i);\n+      _body_nodes.at(i)->dump();\n+    }\n+    tty->cr();\n+  }\n+#endif\n+\n+  return true;\n+}\n+\n+\/\/ Try including a node's input at specified index into current statement\n+bool VectorMaskedLoop::collect_statements_helper(\n+          Node* node, uint idx, Node_List* stmt, Node_List* worklist) {\n+  Node* in = node->in(idx);\n+  if (stmt->contains(in) || !in_body(in)) {\n+    \/\/ Input is already included in current statement or out of loop\n+    return true;\n+  }\n+\n+  \/\/ Check support for special inputs first and then general ones\n+  if (is_loop_iv_or_incr(in)) {\n+    \/\/ 1) Check the support of loop iv or increment node input\n+    BasicType bt = statement_bottom_type(stmt);\n+    bt = is_subword_type(bt) ? bt : T_INT;\n+    if (VectorNode::is_populate_index_supported(bt)) {\n+      return true;\n+    } else {\n+      trace_msg(in, \"Populate index operation is not supported\");\n+      return false;\n+    }\n+  } else if (in->is_Phi()) {\n+    \/\/ 2) We don't support phi nodes except the iv phi of the loop\n+    trace_msg(in, \"Found unsupported phi input\");\n+    return false;\n+  } else if (in->is_Load()) {\n+    \/\/ 3) Ok to include a load node if it's supported memory access\n+    if (supported_mem_access(in->as_Load())) {\n+      stmt->push(in);\n+      return true;\n+    } else {\n+      trace_msg(in, \"Found unsupported memory load input\");\n+      return false;\n+    }\n+  } else if (VectorNode::is_shift(in) && in_body(in->in(2))) {\n+    \/\/ 4) We don't support shift operations with variant shift count\n+    trace_msg(in, \"Variant shift count is not supported\");\n+    return false;\n+  } else {\n+    \/\/ 5) For other general inputs, include it and also push it into the\n+    \/\/    worklist to collect inputs recursively\n+    worklist->push(in);\n+    stmt->push(in);\n+    return true;\n+  }\n+}\n+\n+\/\/ Collect lists of nodes that make up loop statements\n+bool VectorMaskedLoop::collect_statements() {\n+  \/\/ First, initialize each statement from a store node.\n+  for (int idx = 0; idx < _body_nodes.length(); idx++) {\n+    Node* node = _body_nodes.at(idx);\n+    if (node->is_Store() && supported_mem_access(node->as_Store())) {\n+      \/\/ Create a new statement and add the store into its node list\n+      Node_List* stmt = new Node_List(_arena);\n+      stmt->push(node);\n+      _stmts.append(stmt);\n+    }\n+  }\n+\n+  \/\/ Do early bail out if no statement is created\n+  int num_stmts = _stmts.length();\n+  if (num_stmts == 0) {\n+    trace_msg(nullptr, \"No vectorizable statement is found\");\n+    return false;\n+  }\n+\n+  \/\/ Then, extend each statement by recursively including input nodes. Bail out\n+  \/\/ if unsupported node is found.\n+  for (int idx = 0; idx < num_stmts; idx++) {\n+    Node_List* stmt = _stmts.at(idx);\n+    assert(stmt->size() == 1, \"Each statement should have exactly one node\");\n+    Node* store = stmt->at(0);\n+    \/\/ Add value input of the store node into a worklist to include more nodes\n+    \/\/ into current statement\n+    Node_List* worklist = new Node_List(_arena);\n+    if (!collect_statements_helper(store, MemNode::ValueIn, stmt, worklist)) {\n+      return false;\n+    }\n+    \/\/ Continue adding nodes until the worklist is empty\n+    while (worklist->size() > 0) {\n+      Node* node = worklist->pop();\n+      uint start, end;\n+      VectorNode::vector_operands(node, &start, &end);\n+      for (uint idx = start; idx < end; idx++) {\n+        if (!collect_statements_helper(node, idx, stmt, worklist)) {\n+          return false;\n+        }\n+      }\n+    }\n+#ifndef PRODUCT\n+    if (TraceMaskedLoop) {\n+      tty->print_cr(\"Nodes in statement [%d] with element type '%s'\",\n+                    idx, type2name(statement_bottom_type(stmt)));\n+      for (uint i = 0; i < stmt->size(); i++) {\n+        stmt->at(i)->dump();\n+      }\n+      tty->cr();\n+    }\n+#endif\n+  }\n+\n+  return true;\n+}\n+\n+\/\/ Analyze loop statements and bail out if any of them is not vectorizable\n+bool VectorMaskedLoop::analyze_vectorizability() {\n+  if (!find_vector_element_types()) {\n+    return false;\n+  }\n+  if (!vector_nodes_implemented()) {\n+    return false;\n+  }\n+  \/\/ Delegate data dependence check to SWPointer utility\n+  if (SWPointer::has_potential_dependence(_swptrs)) {\n+    trace_msg(nullptr, \"Potential data dependence is found in the loop\");\n+    return false;\n+  }\n+  if (!analyze_loop_body_nodes()) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+\/\/ Find element basic type for each vectorization candidate node\n+bool VectorMaskedLoop::find_vector_element_types() {\n+  for (int idx = 0; idx < _stmts.length(); idx++) {\n+    Node_List* stmt = _stmts.at(idx);\n+    BasicType stmt_bottom_type = statement_bottom_type(stmt);\n+    bool subword_stmt = is_subword_type(stmt_bottom_type);\n+\n+    \/\/ Record vector lane size\n+    _size_stats.record_size(type2aelembytes(stmt_bottom_type));\n+\n+    \/\/ Set element type for each statement node from bottom to top. Bail out if\n+    \/\/ the pattern is unsupported\n+    for (int i = stmt->size() - 1; i >= 0; i--) {\n+      Node* node = stmt->at(i);\n+      if (node->is_Mem()) {\n+        \/\/ Use memory type as its element basic type for memory node\n+        BasicType mem_type = node->as_Mem()->memory_type();\n+        set_elem_bt(node, mem_type);\n+        if (node->is_Load()) {\n+          \/\/ For load node, check if it has the same vector element size with\n+          \/\/ the bottom type of the statement\n+          if (!same_element_size(mem_type, stmt_bottom_type)) {\n+            trace_msg(node, \"Vector element size does not match\");\n+            return false;\n+          }\n+        }\n+      } else {\n+        int opc = node->Opcode();\n+        if (subword_stmt &&\n+            (opc == Op_RShiftI || opc == Op_URShiftI ||\n+             opc == Op_AbsI || opc == Op_ReverseBytesI)) {\n+          \/\/ In any Java arithmetic operation, operands of small integer types\n+          \/\/ (boolean, byte, char & short) should be promoted to int first. For\n+          \/\/ some operations, the compiler has to know the operand's higher\n+          \/\/ order bits, which will be lost in narrowed type. These operations\n+          \/\/ shouldn't be vectorized if the higher order bits info is unknown.\n+          Node* in1 = node->in(1);\n+          if (in1->is_Load()) {\n+            BasicType mem_type = in1->as_Mem()->memory_type();\n+            set_elem_bt(node, mem_type);\n+          } else {\n+            trace_msg(node, \"Subword operand does not have precise type\");\n+            return false;\n+          }\n+        } else {\n+          \/\/ Otherwise, use signed subword type or the statement's bottom type\n+          if (subword_stmt) {\n+            set_elem_bt(node, get_signed_subword_bt(stmt_bottom_type));\n+          } else {\n+            BasicType self_type = node->bottom_type()->array_element_basic_type();\n+            if (!same_element_size(self_type, stmt_bottom_type)) {\n+              trace_msg(node, \"Vector element size does not match\");\n+              return false;\n+            }\n+            set_elem_bt(node, self_type);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (TraceMaskedLoop) {\n+    tty->print_cr(\"Element basic types of nodes in the loop\");\n+    for (int idx = 0; idx < _body_nodes.length(); idx++) {\n+      Node* node = _body_nodes.at(idx);\n+      if (has_valid_elem_bt(node)) {\n+        tty->print(\" %s\\t\", type2name(elem_bt(node)));\n+        node->dump();\n+      }\n+    }\n+    tty->cr();\n+  }\n+#endif\n+\n+  return true;\n+}\n+\n+\/\/ Check if all vector operations required are implemented in current backend.\n+\/\/ Bail out if any of the vector op is not implemented.\n+bool VectorMaskedLoop::vector_nodes_implemented() {\n+  for (int idx = 0; idx < _stmts.length(); idx++) {\n+    Node_List* stmt = _stmts.at(idx);\n+    for (int i = stmt->size() - 1; i >= 0; i--) {\n+      Node* node = stmt->at(i);\n+      int opc = node->Opcode();\n+      BasicType bt = elem_bt(node);\n+      int vlen = Matcher::max_vector_size(bt);\n+      if (vlen == 0) {\n+        \/\/ Bail out if vector cannot hold such elements\n+        return false;\n+      }\n+      \/\/ We check special convert and min\/max ops first and then general ops\n+      if (VectorNode::is_convert_opcode(opc)) {\n+        Node* in = node->in(1);\n+        BasicType in_bt = is_loop_iv_or_incr(in) ? T_INT : elem_bt(in);\n+        if (in_bt == T_ILLEGAL || !same_element_size(in_bt, bt) ||\n+            !VectorCastNode::implemented(opc, vlen, in_bt, bt)) {\n+          trace_msg(node, \"Found unimplemented vector cast node\");\n+          return false;\n+        }\n+      } else if (VectorNode::is_minmax_opcode(opc) && is_subword_type(bt)) {\n+        \/\/ Java API for Math.min\/max operations supports only int, long, float\n+        \/\/ and double types. Bail out for subword min\/max operations.\n+        return false;\n+      } else {\n+        int vopc = 0;\n+        if (node->is_Mem()) {\n+          vopc = node->is_Store() ? Op_StoreVectorMasked : Op_LoadVectorMasked;\n+        } else {\n+          vopc = VectorNode::opcode(opc, bt);\n+        }\n+        if (vopc == 0 ||\n+            !Matcher::match_rule_supported_vector_masked(vopc, vlen, bt)) {\n+          trace_msg(node, \"Vector replacement node is not implemented\");\n+          return false;\n+        }\n+      }\n+    }\n+  }\n+  return true;\n+}\n+\n+\/\/ Find unhandled out-of-loop use of loop body nodes and untracked loop body\n+\/\/ nodes to bail out for complex loops\n+bool VectorMaskedLoop::analyze_loop_body_nodes() {\n+  VectorSet tracked(_arena);\n+  int n_nodes = _body_nodes.length();\n+  \/\/ 1) Track all vectorization candidates and loop iv phi nodes\n+  for (int idx = 0; idx < n_nodes; idx++) {\n+    Node* node = _body_nodes.at(idx);\n+    if (has_valid_elem_bt(node) || is_loop_iv(node)) {\n+      tracked.set(idx);\n+    }\n+  }\n+  \/\/ 2) Track memory address computing nodes in SWPointer node stacks\n+  for (int ptridx = 0; ptridx < _swptrs.length(); ptridx++) {\n+    Node_Stack* nstack = _swptrs.at(ptridx)->node_stack();\n+    while (nstack->is_nonempty()) {\n+      Node* node = nstack->node();\n+      if (in_body(node)) {\n+        tracked.set(rpo_idx(node));\n+      }\n+      nstack->pop();\n+    }\n+  }\n+  \/\/ 3) Up to this point, all tracked nodes shouldn't have out-of-loop users\n+  for (int idx = 0; idx < n_nodes; idx++) {\n+    Node* node = _body_nodes.at(idx);\n+    if ((node->is_Mem() && node->as_Mem()->is_Store())) {\n+      \/\/ Only store nodes are exceptions\n+      continue;\n+    }\n+    if (tracked.test(idx)) {\n+      for (DUIterator_Fast imax, i = node->fast_outs(imax); i < imax; i++) {\n+        Node* out = node->fast_out(i);\n+        if (!in_body(out)) {\n+          trace_msg(node, \"Node has out-of-loop user found\");\n+          return false;\n+        }\n+      }\n+    }\n+  }\n+  \/\/ 4) Bail out if the loop body has extra node\n+  for (int idx = 0; idx < n_nodes; idx++) {\n+    Node* node = _body_nodes.at(idx);\n+    if (!tracked.test(idx) && !in_core(node) && !is_memory_phi(node)) {\n+      trace_msg(node, \"Found extra loop node in loop body\");\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n+\/\/ Try creating a vector mask with the smallest vector element size\n+const TypeVectMask* VectorMaskedLoop::create_vector_mask_type() {\n+  BasicType vmask_bt = size_to_basic_type(_size_stats.smallest_size());\n+  int vlen = Matcher::max_vector_size(vmask_bt);\n+  if (!Matcher::match_rule_supported_vector(Op_LoopVectorMask, vlen, vmask_bt)) {\n+    \/\/ Unable to create vector mask with the vlen & bt on this platform\n+    return nullptr;\n+  }\n+  return (TypeVectMask*) TypeVect::makemask(vmask_bt, vlen);\n+}\n+\n+\/\/ This checks if memory access node is our supported pattern\n+bool VectorMaskedLoop::supported_mem_access(MemNode* mem) {\n+  \/\/ First do a quick check by searching existing SWPointer(s)\n+  for (int idx = 0; idx < _swptrs.length(); idx++) {\n+    if (_swptrs.at(idx)->mem() == mem) {\n+      return true;\n+    }\n+  }\n+  \/\/ If not found, try creating a new SWPointer and insert it\n+  SWPointer* ptr = mem_access_to_swpointer(mem);\n+  if (ptr != nullptr) {\n+    _swptrs.push(ptr);\n+    return true;\n+  }\n+  return false;\n+}\n+\n+\/\/ This tries creating an SWPointer object associated to the memory access.\n+\/\/ Return nullptr if it fails or the SWPointer is not valid.\n+SWPointer* VectorMaskedLoop::mem_access_to_swpointer(MemNode* mem) {\n+  \/\/ Should access memory of a Java primitive value\n+  BasicType mem_type = mem->memory_type();\n+  if (!is_java_primitive(mem_type)) {\n+    return nullptr;\n+  }\n+  \/\/ addp: memory address for loading\/storing an array element. It should be an\n+  \/\/ AddP node operating on an array of specific type\n+  Node* addp = mem->in(MemNode::Address);\n+  if (!addp->is_AddP() || !operates_on_array_of_type(addp, mem_type)) {\n+    return nullptr;\n+  }\n+  \/\/ Create a Node_Stack for SWPointer's initial stack\n+  Node_Stack* nstack = new Node_Stack(_arena, 5);\n+  nstack->push(addp, 0);\n+  \/\/ addp2: another possible AddP node for array element addressing. It should\n+  \/\/ operate on the same memory type and have the same base with previous AddP.\n+  Node* addp2 = addp->in(AddPNode::Address);\n+  if (addp2->is_AddP()) {\n+    if (!operates_on_array_of_type(addp2, mem_type) ||\n+        addp->in(AddPNode::Base) != addp2->in(AddPNode::Base)) {\n+      return nullptr;\n+    }\n+    nstack->push(addp2, 1);\n+  }\n+\n+  \/\/ Check supported memory access via SWPointer. It's not supported if\n+  \/\/  1) The constructed SWPointer is invalid\n+  \/\/  2) Address is growing down (index scale * loop stride < 0)\n+  \/\/  3) Memory access scale is different from data size\n+  \/\/  4) The loop increment node is on the SWPointer's node stack\n+  SWPointer* ptr = new (_arena) SWPointer(mem, _phase, _lpt, nstack, true);\n+  if (!ptr->valid()) {\n+    return nullptr;\n+  }\n+  int scale_in_bytes = ptr->scale_in_bytes();\n+  int element_size = type2aelembytes(mem_type);\n+  if (scale_in_bytes * _cl->stride_con() < 0 ||\n+      abs(scale_in_bytes) != element_size) {\n+    return nullptr;\n+  }\n+  for (uint i = 0; i < nstack->size(); i++) {\n+    if (nstack->node_at(i) == _cl->incr()) {\n+      return nullptr;\n+    }\n+  }\n+\n+  return ptr;\n+}\n+\n+\/\/ Check if node operates on an array of specific type\n+bool VectorMaskedLoop::operates_on_array_of_type(Node* node, BasicType bt) {\n+  const TypeAryPtr* aryptr = node->bottom_type()->isa_aryptr();\n+  if (aryptr == nullptr) {\n+    return false;\n+  }\n+  BasicType elem_bt = aryptr->elem()->array_element_basic_type();\n+  return same_type_or_subword_size(elem_bt, bt);\n+}\n+\n+\/\/ ------------------- Actual loop transformation functions -------------------\n+\/\/ Create a tree of vector masks for use of vectorized operations in the loop\n+Node_List* VectorMaskedLoop::create_vmask_tree(const TypeVectMask* t_vmask) {\n+  \/\/ Create the root vector mask node from given vector type\n+  int max_trip_cnt = _cl->trip_count();\n+  Node* root_vmask = _cl->stride_con() > 0 ?\n+      new LoopVectorMaskNode(_iv, _cl->limit(), t_vmask, max_trip_cnt) :\n+      new LoopVectorMaskNode(_cl->limit(), _iv, t_vmask, max_trip_cnt);\n+  _igvn->register_new_node_with_optimizer(root_vmask);\n+\n+  \/\/ Compute the depth of vector mask tree\n+  uint small = _size_stats.smallest_size();\n+  uint large = _size_stats.largest_size();\n+  uint tree_depth = exact_log2(large) - exact_log2(small) + 1;\n+  \/\/ All vector masks construct a perfect binary tree of \"2 ^ depth - 1\" nodes\n+  \/\/ We create a list of \"2 ^ depth\" nodes for easier computation.\n+  Node_List* vmask_tree = new Node_List(_arena, 1 << tree_depth);\n+  \/\/ The root vector mask is always placed at index 1\n+  vmask_tree->insert(1, root_vmask);\n+\n+  \/\/ Place extracted vector masks from the root mask\n+  for (uint lev = 0; lev < tree_depth - 1; lev++) {\n+    uint idx_start = 1 << lev;\n+    uint idx_end = 1 << (lev + 1);\n+    for (uint idx = idx_start; idx < idx_end; idx++) {\n+      \/\/ Calculate children's vector mask type from the parent's type\n+      Node* parent = vmask_tree->at(idx);\n+      int parent_size = type2aelembytes(Matcher::vector_element_basic_type(parent));\n+      BasicType child_bt = size_to_basic_type(parent_size * 2);\n+      int child_vlen = Matcher::max_vector_size(child_bt);\n+      const TypeVectMask* t_vmask = (TypeVectMask*) TypeVect::makemask(child_bt, child_vlen);\n+      \/\/ Create left and right child of the parent\n+      Node* left = new ExtractLowMaskNode(parent, t_vmask);\n+      _igvn->register_new_node_with_optimizer(left);\n+      vmask_tree->insert(2 * idx, left);\n+      Node* right = new ExtractHighMaskNode(parent, t_vmask);\n+      _igvn->register_new_node_with_optimizer(right);\n+      vmask_tree->insert(2 * idx + 1, right);\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (TraceMaskedLoop) {\n+    tty->print_cr(\"Generated vector masks in vmask tree\");\n+    for (uint lev = 0; lev < tree_depth; lev++) {\n+      uint lane_size = 1 << (exact_log2(small) + lev);\n+      tty->print_cr(\"Lane_size = %d\", lane_size);\n+      uint idx_start = 1 << lev;\n+      uint idx_end = 1 << (lev + 1);\n+      for (uint idx = idx_start; idx < idx_end; idx++) {\n+        Node* node = vmask_tree->at(idx);\n+        node->dump();\n+      }\n+    }\n+    tty->cr();\n+  }\n+#endif\n+\n+  return vmask_tree;\n+}\n+\n+\/\/ Helper method for finding or creating a vector input at specified index\n+Node* VectorMaskedLoop::get_vector_input(Node* node, uint idx) {\n+  assert(node != nullptr, \"Given node shouldn't be nullptr\");\n+  BasicType bt = elem_bt(node);\n+  Node* in = node->in(idx);\n+  assert(in != nullptr, \"Input node shouldn't be nullptr\");\n+\n+  \/\/ If input is already a vector node, just use it\n+  if (in->is_Vector() || in->is_LoadVector()) {\n+    return in;\n+  }\n+\n+  \/\/ Create a vector input for different scalar input cases\n+  int vlen = Matcher::max_vector_size(bt);\n+  if (is_loop_iv_or_incr(in)) {\n+    \/\/ Input is the loop iv or increment node\n+    BasicType pop_index_bt = is_subword_type(bt) ?\n+                             get_signed_subword_bt(bt) : T_INT;\n+    const TypeVect* vt = TypeVect::make(pop_index_bt, vlen);\n+    Node* n_stride = _igvn->intcon(_cl->stride_con());\n+    Node* start_index = _iv;\n+    if (is_loop_incr(in)) {\n+      start_index = new AddINode(_iv, n_stride);\n+      _igvn->register_new_node_with_optimizer(start_index);\n+    }\n+    Node* popindex = new PopulateIndexNode(start_index, n_stride, vt);\n+    _igvn->register_new_node_with_optimizer(popindex);\n+    VectorNode::trace_new_vector(popindex, \"VectorMasked\");\n+    return popindex;\n+  } else {\n+    \/\/ Input is a scalar value not in this loop\n+    assert(!in_body(in), \"Node shouldn't be in this loop\");\n+    if (VectorNode::is_roundopD(node) && idx == 2) {\n+      \/\/ 1) Just return the scalar input\n+      return in;\n+    } else {\n+      \/\/ 2) Need replicate the scalar input\n+      Node* vrep = nullptr;\n+      if (VectorNode::is_shift(node) && idx == 2) {\n+        \/\/ 2.1) Input is the 2nd (shift count) of left\/right shift\n+        assert(is_integral_type(bt), \"Shift operation should work on integers\");\n+        Node* mask_con = _igvn->intcon((bt == T_LONG) ?\n+                                       (BitsPerLong - 1) : (BitsPerInt - 1));\n+        Node* mask_op = new AndINode(in, mask_con);\n+        _igvn->register_new_node_with_optimizer(mask_op);\n+        vrep = VectorNode::shift_count(node->Opcode(), mask_op, vlen, bt);\n+      } else if (VectorNode::is_scalar_rotate(node) && idx == 2) {\n+        \/\/ 2.2) Input is the 2nd (rotate shift count) of rotate shift\n+        Node* conv = in;\n+        if (bt == T_LONG) {\n+          conv = new ConvI2LNode(in);\n+          _igvn->register_new_node_with_optimizer(conv);\n+        }\n+        vrep = VectorNode::scalar2vector(conv, vlen, Type::get_const_basic_type(bt));\n+      } else {\n+        \/\/ 2.3) Other general scalar inputs\n+        const Type* type = Type::get_const_basic_type(get_signed_subword_bt(bt));\n+        vrep = VectorNode::scalar2vector(in, vlen, type);\n+      }\n+      _igvn->register_new_node_with_optimizer(vrep);\n+      VectorNode::trace_new_vector(vrep, \"VectorMasked\");\n+      return vrep;\n+    }\n+  }\n+}\n+\n+\/\/ Replace scalar nodes in the loop by vector nodes from top to bottom and\n+\/\/ return the node map of scalar to vector replacement\n+Node_List* VectorMaskedLoop::replace_scalar_ops(Node* mask) {\n+  \/\/ Create a node map of scalar to vector replacement\n+  int n_nodes = _body_nodes.length();\n+  Node_List* s2v_map = new Node_List(_arena, n_nodes);\n+\n+  \/\/ Replace each node with valid element basic type set\n+  for (int idx = 0; idx < n_nodes; idx++) {\n+    Node* snode = _body_nodes.at(idx);\n+    if (has_valid_elem_bt(snode)) {\n+      Node* vnode;\n+      int opc = snode->Opcode();\n+      BasicType bt = elem_bt(snode);\n+      int vlen = Matcher::max_vector_size(bt);\n+      if (snode->is_Mem()) {\n+        Node* ctrl = snode->in(MemNode::Control);\n+        Node* mem = snode->in(MemNode::Memory);\n+        Node* addr = snode->in(MemNode::Address);\n+        const TypePtr* at = snode->as_Mem()->adr_type();\n+        const TypeVect* vt = TypeVect::make(Type::get_const_basic_type(bt), vlen);\n+        if (snode->is_Load()) {\n+          vnode = new LoadVectorMaskedNode(ctrl, mem, addr, at, vt, mask);\n+        } else {\n+          assert(snode->is_Store(), \"Unexpected memory op\");\n+          Node* val = get_vector_input(snode, MemNode::ValueIn);\n+          vnode = new StoreVectorMaskedNode(ctrl, mem, addr, val, at, mask);\n+        }\n+      } else if (VectorNode::is_convert_opcode(opc)) {\n+        Node* in = get_vector_input(snode, 1);\n+        int vopc = VectorCastNode::opcode(opc, in->bottom_type()->is_vect()->element_basic_type());\n+        vnode = VectorCastNode::make(vopc, in, bt, vlen);\n+      } else {\n+        uint start, end;\n+        VectorNode::vector_operands(snode, &start, &end);\n+        assert(start == 1, \"Start should be 1 for all currently supported ops\");\n+        \/\/ The 1st operand is always there\n+        Node* in1 = get_vector_input(snode, 1);\n+        \/\/ The 2nd operand is optional and may be vector shift count\n+        Node* in2 = nullptr;\n+        if (end > 2 || VectorNode::is_shift(snode) || VectorNode::is_roundopD(snode)) {\n+          in2 = get_vector_input(snode, 2);\n+        }\n+        \/\/ The 3rd operand is optional\n+        if (end > 3) {\n+          Node* in3 = get_vector_input(snode, 3);\n+          vnode = VectorNode::make(opc, in1, in2, in3, vlen, bt);\n+        } else {\n+          vnode = VectorNode::make(opc, in1, in2, vlen, bt);\n+        }\n+      }\n+      VectorNode::trace_new_vector(vnode, \"VectorMasked\");\n+      _phase->set_ctrl(vnode, _phase->get_ctrl(snode));\n+      _igvn->replace_node(snode, _igvn->register_new_node_with_optimizer(vnode, snode));\n+      s2v_map->map(rpo_idx(snode), vnode);\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (TraceMaskedLoop) {\n+    tty->print_cr(\"Node scalar to vector replacements\");\n+    for (int idx = 0; idx < _body_nodes.length(); idx++) {\n+      Node* snode = _body_nodes.at(idx);\n+      if (has_valid_elem_bt(snode)) {\n+        Node* vnode = s2v_map->at(rpo_idx(snode));\n+        tty->print(\" Scalar:\\t\");\n+        snode->dump();\n+        tty->print(\"  Vector:\\t\");\n+        vnode->dump();\n+      }\n+    }\n+    tty->cr();\n+  }\n+#endif\n+\n+  return s2v_map;\n+}\n+\n+\/\/ Duplicate vectorized operations with given vector element size\n+void VectorMaskedLoop::duplicate_vector_ops(\n+                Node_List* vmask_tree, Node_List* s2v_map, int lane_size) {\n+  \/\/ Compute vector duplication count and the vmask tree level\n+  int dup_cnt = lane_size \/ _size_stats.smallest_size();\n+  int level = exact_log2(dup_cnt);\n+\n+  \/\/ Collect and clone all vector nodes with given vector element size\n+  Node_List* clone_list = new Node_List(_arena);\n+  for (int idx = 0; idx < _stmts.length(); idx++) {\n+    Node_List* stmt = _stmts.at(idx);\n+    if (type2aelembytes(statement_bottom_type(stmt)) != lane_size) {\n+      continue;\n+    }\n+\n+    \/\/ Collect all nodes to be cloned\n+    for (uint i = 0; i < stmt->size(); i++) {\n+      Node* vnode = s2v_map->at(rpo_idx(stmt->at(i)));\n+      if (!clone_list->contains(vnode)) {\n+        clone_list->push(vnode);\n+      }\n+      \/\/ Also include vector operands of populate index nodes, because those\n+      \/\/ nodes also need to be cloned and adjusted\n+      uint start, end;\n+      VectorNode::vector_operands(vnode, &start, &end);\n+      for (uint i = start; i < end; i++) {\n+        Node* vopd = vnode->in(i);\n+        if (vopd->Opcode() == Op_PopulateIndex) {\n+          Node* init_idx = vopd->in(1);\n+          if (is_loop_iv(init_idx) || is_loop_iv_plus_stride(init_idx)) {\n+            if (!clone_list->contains(vopd)) {\n+              clone_list->push(vopd);\n+            }\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  \/\/ Clone \"dup_cnt - 1\" copies of collected vector nodes and insert the lists\n+  \/\/ of cloned nodes into an array. Also insert the list of the original vector\n+  \/\/ nodes at the array end.\n+  GrowableArray<Node_List*> vector_copies(_arena, dup_cnt, 0, nullptr);\n+  for (int i = 0; i < dup_cnt - 1; i++) {\n+    Node_List* cloned = clone_node_list(clone_list);\n+    vector_copies.push(cloned);\n+  }\n+  vector_copies.push(clone_list);\n+\n+  \/\/ As vector store nodes have phi output, to make adjustment simpler, we use\n+  \/\/ the original list to handle operations at max mask offset \"dup_cnt - 1\".\n+  \/\/ The cloned lists are for small mask offset from \"0\" to \"dup_cnt - 2\".\n+  Node* prev_store = nullptr;\n+  for (int mask_off = 0; mask_off < dup_cnt; mask_off++) {\n+    Node_List* vnodes = vector_copies.at(mask_off);\n+    for (uint i = 0; i < vnodes->size(); i++) {\n+      Node* vn = vnodes->at(i);\n+      \/\/ Do general vector node adjustment for the vector nodes\n+      adjust_vector_node(vn, vmask_tree, level, mask_off);\n+      \/\/ Do cross-node adjustment for vector store nodes.\n+      if (vn->is_StoreVector()) {\n+        \/\/ For vector store nodes, we re-connect memory edges to the previous\n+        \/\/ vector store we just iterated\n+        if (prev_store != nullptr) {\n+          vn->set_req(MemNode::Memory, prev_store);\n+        }\n+        prev_store = vn;\n+      }\n+    }\n+  }\n+\n+#ifndef PRODUCT\n+  if (TraceMaskedLoop) {\n+    tty->print_cr(\"Duplicated vector nodes with lane size = %d\", lane_size);\n+    for (int mask_off = 0; mask_off < dup_cnt; mask_off++) {\n+      Node_List* vp = vector_copies.at(mask_off);\n+      tty->print_cr(\"Offset = %d\", mask_off);\n+      for (uint i = 0; i < vp->size(); i++) {\n+        vp->at(i)->dump();\n+      }\n+    }\n+    tty->cr();\n+  }\n+#endif\n+}\n+\n+\/\/ Helper function for general vector node adjustment after duplication\n+void VectorMaskedLoop::adjust_vector_node(Node* vn, Node_List* vmask_tree,\n+                                          int level, int mask_off) {\n+  Node* vmask = vmask_tree->at((1 << level) + mask_off);\n+  int lane_size = type2aelembytes(Matcher::vector_element_basic_type(vmask));\n+  uint vector_size_in_bytes = Matcher::max_vector_size(T_BYTE);\n+  if (vn->is_Mem()) {\n+    \/\/ 1) For mem accesses, update the mask input, and add additional address\n+    \/\/    offset if mask offset is non-zero\n+    vn->set_req(vn->req() - 1, vmask);\n+    if (mask_off != 0) {\n+      Node* ptr = vn->in(MemNode::Address);\n+      Node* base = ptr->in(AddPNode::Base);\n+      int mem_scale = Matcher::max_vector_size(T_BYTE);\n+      Node* off = _igvn->MakeConX(mem_scale * mask_off);\n+      Node* new_ptr = new AddPNode(base, ptr, off);\n+      _igvn->register_new_node_with_optimizer(new_ptr, ptr);\n+      vn->set_req(MemNode::Address, new_ptr);\n+    }\n+  } else if (vn->Opcode() == Op_PopulateIndex) {\n+    \/\/ 2) For populate index, update start index for non-zero mask offset\n+    if (mask_off != 0) {\n+      int v_stride = vector_size_in_bytes \/ lane_size * _cl->stride_con();\n+      Node* idx_off = _igvn->intcon(v_stride * mask_off);\n+      Node* new_base = new AddINode(vn->in(1), idx_off);\n+      _igvn->register_new_node_with_optimizer(new_base, vn->in(1));\n+      vn->set_req(1, new_base);\n+    }\n+  }\n+}\n+\n+\/\/ Helper function for duplicating a subgraph of nodes\n+Node_List* VectorMaskedLoop::clone_node_list(Node_List* list) {\n+  assert(list != nullptr && list->size() > 0, \"Should not be empty\");\n+  uint size = list->size();\n+  Node_List* new_list = new Node_List(_arena, size);\n+  Node_List* clone_map = new Node_List(_arena, size);\n+  \/\/ Clone each node in the list\n+  for (uint i = 0; i < size; i++) {\n+    Node* old = list->at(i);\n+    Node* new_node = old->clone();\n+    clone_map->map(old->_idx, new_node);\n+    _igvn->register_new_node_with_optimizer(new_node, old);\n+    VectorNode::trace_new_vector(new_node, \"VectorMasked\");\n+    new_list->push(new_node);\n+  }\n+  \/\/ Re-connect input edges to the cloned node\n+  for (uint i = 0; i < size; i++) {\n+    Node* new_node = new_list->at(i);\n+    for (uint j = 0; j < new_node->req(); j++) {\n+      Node* in = new_node->in(j);\n+      if (in != nullptr && in->_idx < clone_map->max()) {\n+        Node* new_in = clone_map->at(in->_idx);\n+        if (new_in != nullptr) {\n+          new_node->set_req(j, new_in);\n+        }\n+      }\n+    }\n+  }\n+  return new_list;\n+}\n+\n+\/\/ Entry function of actual vector mask transformation\n+void VectorMaskedLoop::transform_loop(const TypeVectMask* t_vmask) {\n+  \/\/ Create a tree of vector masks for different vector lane sizes\n+  Node_List* vmask_tree = create_vmask_tree(t_vmask);\n+  Node* root_vmask = vmask_tree->at(1);\n+\n+  \/\/ Replace vectorization candidate nodes to vector nodes\n+  Node_List* s2v_map = replace_scalar_ops(root_vmask);\n+\n+  \/\/ Duplicate and adjust vector nodes with larger vector lane sizes\n+  int small = _size_stats.smallest_size();\n+  int large = _size_stats.largest_size();\n+  for (int lane_size = small * 2; lane_size <= large; lane_size *= 2) {\n+    if (_size_stats.count_size(lane_size) > 0) {\n+      duplicate_vector_ops(vmask_tree, s2v_map, lane_size);\n+    }\n+  }\n+\n+  \/\/ Update loop increment\/decrement to the vector mask true count\n+  Node* true_cnt = new VectorMaskTrueCountNode(root_vmask, TypeInt::INT);\n+  _igvn->register_new_node_with_optimizer(true_cnt);\n+  Node* new_incr;\n+  if (_cl->stride_con() > 0) {\n+    new_incr = new AddINode(_iv, true_cnt);\n+  } else {\n+    new_incr = new SubINode(_iv, true_cnt);\n+  }\n+  _igvn->register_new_node_with_optimizer(new_incr);\n+  _igvn->replace_node(_cl->incr(), new_incr);\n+}\n+\n+\/\/ ------------------------------ Debug printing ------------------------------\n+void VectorMaskedLoop::trace_msg(Node* n, const char* format, ...) {\n+#ifndef PRODUCT\n+  if (TraceMaskedLoop) {\n+    va_list ap;\n+    va_start(ap, format);\n+    tty->vprint_cr(format, ap);\n+    va_end(ap);\n+    if (n != nullptr) n->dump();\n+  }\n+#endif\n+}\n","filename":"src\/hotspot\/share\/opto\/vmaskloop.cpp","additions":975,"deletions":0,"binary":false,"changes":975,"status":"added"},{"patch":"@@ -0,0 +1,136 @@\n+\/*\n+ * Copyright (c) 2023, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#ifndef SHARE_OPTO_VMASKLOOP_HPP\n+#define SHARE_OPTO_VMASKLOOP_HPP\n+\n+#include \"opto\/loopnode.hpp\"\n+#include \"opto\/superword.hpp\"\n+#include \"opto\/vectornode.hpp\"\n+\n+\/\/ ----------------------------- VectorMaskedLoop -----------------------------\n+class VectorMaskedLoop : public ResourceObj {\n+ private:\n+  \/\/ Useful handles\n+  PhaseIdealLoop*            _phase;\n+  PhaseIterGVN*              _igvn;\n+  Arena*                     _arena;\n+\n+  \/\/ Loop information\n+  IdealLoopTree*             _lpt;          \/\/ Idealloop tree\n+  CountedLoopNode*           _cl;           \/\/ CountedLoop node\n+  CountedLoopEndNode*        _cle;          \/\/ CountedLoopEnd node\n+  PhiNode*                   _iv;           \/\/ Loop induction variable PhiNode\n+\n+  \/\/ Data structures for loop analysis\n+  Unique_Node_List           _core_set;     \/\/ Loop core nodes set for fast membership check\n+  Unique_Node_List           _body_set;     \/\/ Loop body nodes set for fast membership check\n+  GrowableArray<Node*>       _body_nodes;   \/\/ Loop body nodes with reverse postorder\n+  GrowableArray<int>         _rpo_idx;      \/\/ Map from node index to RPO traversal index\n+  GrowableArray<BasicType>   _elem_bt;      \/\/ Per node vector element basic type\n+  GrowableArray<Node_List*>  _stmts;        \/\/ Lists of nodes that make up loop statements\n+  GrowableArray<SWPointer*>  _swptrs;       \/\/ SWPointer array for memory access nodes\n+  VectorElementSizeStats     _size_stats;   \/\/ Statistics of data sizes in vectors\n+\n+  \/\/ Basic utilities\n+  bool in_core(Node* n)            { return n != nullptr && _core_set.member(n); }\n+  bool in_body(Node* n)            { return n != nullptr && _body_set.member(n); }\n+  int  rpo_idx(Node* n)            { assert(in_body(n), \"What?\"); return _rpo_idx.at(n->_idx); }\n+  void set_rpo_idx(Node* n, int i) { assert(in_body(n), \"What?\"); _rpo_idx.at_put_grow(n->_idx, i); }\n+\n+  BasicType statement_bottom_type(Node_List* stmt) {\n+    assert(stmt != nullptr && stmt->size() > 0, \"should not be empty\");\n+    assert(stmt->at(0)->is_Store(), \"Must be a store node\");\n+    return stmt->at(0)->as_Store()->memory_type();\n+  }\n+\n+  BasicType size_to_basic_type(int size) {\n+    BasicType bt = T_ILLEGAL;\n+    switch (size) {\n+      case 1: bt = T_BYTE;  break;\n+      case 2: bt = T_SHORT; break;\n+      case 4: bt = T_INT;   break;\n+      case 8: bt = T_LONG;  break;\n+      default: ShouldNotReachHere();\n+    }\n+    return bt;\n+  }\n+\n+  \/\/ Node vector element type accessors\n+  BasicType elem_bt(Node* n) { return _elem_bt.at(rpo_idx(n)); }\n+  void set_elem_bt(Node* n, BasicType bt) { _elem_bt.at_put(rpo_idx(n), bt); }\n+  bool has_valid_elem_bt(Node* n) { return elem_bt(n) != T_ILLEGAL; }\n+\n+  \/\/ Some node check utilities\n+  bool is_loop_iv(Node* n) { return n == _iv; }\n+  bool is_loop_incr(Node* n) { return n == _cl->incr(); }\n+  bool is_loop_iv_or_incr(Node* n) { return n == _iv || n == _cl->incr(); }\n+\n+  bool is_loop_iv_plus_stride(Node* n) {\n+    if (n != nullptr && n->is_Add() && n->in(1) == _iv && n->in(2)->is_Con()) {\n+      const Type* t = n->in(2)->bottom_type();\n+      return t->is_int()->get_con() == _cl->stride_con();\n+    }\n+    return false;\n+  }\n+\n+  bool is_memory_phi(Node* n) {\n+    return n != nullptr && n->is_Phi() && n->bottom_type() == Type::MEMORY;\n+  }\n+\n+  \/\/ Methods for loop vectorizable analysis\n+  void init(IdealLoopTree* lpt);\n+  bool collect_loop_nodes();\n+\n+  bool collect_statements_helper(Node* node, uint idx, Node_List* stmt, Node_List* worklist);\n+  bool collect_statements();\n+\n+  bool analyze_vectorizability();\n+  bool find_vector_element_types();\n+  bool vector_nodes_implemented();\n+  bool analyze_loop_body_nodes();\n+\n+  const TypeVectMask* create_vector_mask_type();\n+\n+  bool supported_mem_access(MemNode* mem);\n+  SWPointer* mem_access_to_swpointer(MemNode* mem);\n+  bool operates_on_array_of_type(Node* node, BasicType bt);\n+\n+  \/\/ Methods for vector masked loop transformation\n+  Node_List* create_vmask_tree(const TypeVectMask* t_vmask);\n+  Node* get_vector_input(Node* node, uint idx);\n+  Node_List* replace_scalar_ops(Node* mask);\n+  void duplicate_vector_ops(Node_List* vmask_tree, Node_List* s2v_map, int lane_size);\n+  void adjust_vector_node(Node* vn, Node_List* vmask_tree, int level, int mask_off);\n+  Node_List* clone_node_list(Node_List* list);\n+  void transform_loop(const TypeVectMask* t_vmask);\n+\n+  \/\/ Debug printing\n+  void trace_msg(Node* n, const char* format, ...);\n+\n+ public:\n+  VectorMaskedLoop(PhaseIdealLoop* phase);\n+  void try_vectorize_loop(IdealLoopTree* lpt);\n+};\n+\n+#endif \/\/ SHARE_OPTO_VMASKLOOP_HPP\n","filename":"src\/hotspot\/share\/opto\/vmaskloop.hpp","additions":136,"deletions":0,"binary":false,"changes":136,"status":"added"},{"patch":"@@ -1532,0 +1532,1 @@\n+  declare_c2_type(LoopVectorMaskNode, TypeNode)                           \\\n@@ -1783,0 +1784,2 @@\n+  declare_c2_type(LoadVectorMaskedNode, LoadVectorNode)                   \\\n+  declare_c2_type(StoreVectorMaskedNode, StoreVectorNode)                 \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -890,0 +890,4 @@\n+inline bool same_element_size(BasicType t1, BasicType t2) {\n+  return type2aelembytes(t1) == type2aelembytes(t2);\n+}\n+\n@@ -891,1 +895,7 @@\n-  return (t1 == t2) || (is_subword_type(t1) && type2aelembytes(t1) == type2aelembytes(t2));\n+  return (t1 == t2) || (is_subword_type(t1) && same_element_size(t1, t2));\n+}\n+\n+inline BasicType get_signed_subword_bt(BasicType bt) {\n+  if (bt == T_BOOLEAN) return T_BYTE;\n+  if (bt == T_CHAR) return T_SHORT;\n+  return bt;\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":11,"deletions":1,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -612,0 +612,5 @@\n+    public static final String LOOP_VECTOR_MASK = PREFIX + \"LOOP_VECTOR_MASK\" + POSTFIX;\n+    static {\n+        beforeMatchingNameRegex(LOOP_VECTOR_MASK, \"LoopVectorMask\");\n+    }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/lib\/ir_framework\/IRNode.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1,41 +0,0 @@\n-\/*\n- * Copyright (c) 2016, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-\/**\n- * @test TestRangeCheckEliminationDisabled\n- * @bug 8154763\n- * @summary Tests PostLoopMultiversioning with RangeCheckElimination disabled.\n- * @run main\/othervm -XX:+IgnoreUnrecognizedVMOptions -XX:+UnlockDiagnosticVMOptions\n- *                   -XX:+UnlockExperimentalVMOptions -XX:+PostLoopMultiversioning -XX:-RangeCheckElimination\n- *                   compiler.rangechecks.TestRangeCheckEliminationDisabled\n- *\/\n-\n-package compiler.rangechecks;\n-\n-public class TestRangeCheckEliminationDisabled {\n-\n-    public static void main(String[] args) {\n-      System.out.println(\"Passed\");\n-    }\n-}\n-\n","filename":"test\/hotspot\/jtreg\/compiler\/rangechecks\/TestRangeCheckEliminationDisabled.java","additions":0,"deletions":41,"binary":false,"changes":41,"status":"deleted"},{"patch":"@@ -80,0 +80,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +94,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +108,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -113,0 +122,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +136,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -135,0 +150,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -146,0 +164,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -158,0 +179,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -170,0 +194,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -183,0 +210,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -197,0 +227,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -208,0 +241,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayCopyTest.java","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -62,0 +62,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -73,0 +76,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -84,0 +90,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -95,0 +104,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -115,0 +127,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -126,0 +141,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -139,0 +157,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayIndexFillTest.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -69,0 +69,1 @@\n+        applyIf = {\"OptimizeFill\", \"false\"},\n@@ -70,0 +71,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIfAnd = {\"UseMaskedLoop\", \"true\", \"OptimizeFill\", \"false\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -80,0 +84,1 @@\n+        applyIf = {\"OptimizeFill\", \"false\"},\n@@ -81,0 +86,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIfAnd = {\"UseMaskedLoop\", \"true\", \"OptimizeFill\", \"false\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +99,1 @@\n+        applyIf = {\"OptimizeFill\", \"false\"},\n@@ -92,0 +101,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIfAnd = {\"UseMaskedLoop\", \"true\", \"OptimizeFill\", \"false\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +114,1 @@\n+        applyIf = {\"OptimizeFill\", \"false\"},\n@@ -103,0 +116,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIfAnd = {\"UseMaskedLoop\", \"true\", \"OptimizeFill\", \"false\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -114,0 +130,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +143,1 @@\n+        applyIf = {\"OptimizeFill\", \"false\"},\n@@ -125,0 +145,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIfAnd = {\"UseMaskedLoop\", \"true\", \"OptimizeFill\", \"false\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -136,0 +159,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -148,0 +174,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -159,0 +188,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -170,0 +202,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -180,0 +215,1 @@\n+        applyIf = {\"OptimizeFill\", \"false\"},\n@@ -181,0 +217,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIfAnd = {\"UseMaskedLoop\", \"true\", \"OptimizeFill\", \"false\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayInvariantFillTest.java","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -102,0 +102,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -113,0 +116,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +130,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -135,0 +144,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -146,0 +158,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -157,0 +172,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayShiftOpTest.java","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -136,0 +136,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -172,0 +175,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -226,0 +232,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -262,0 +271,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayTypeConvertTest.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -63,0 +63,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -72,0 +75,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/ArrayUnsafeOpTest.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -80,0 +80,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +94,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +108,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicBooleanOpTest.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -69,0 +69,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -80,0 +83,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +97,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +111,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -113,0 +125,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +139,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -135,0 +153,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -147,0 +168,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -158,0 +182,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -169,0 +196,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -180,0 +210,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -192,0 +225,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -203,0 +239,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicByteOpTest.java","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -71,0 +71,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -82,0 +85,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -94,0 +100,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -105,0 +114,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -116,0 +128,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -127,0 +142,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -138,0 +156,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -150,0 +171,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -161,0 +185,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -172,0 +199,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -183,0 +213,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -195,0 +228,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -206,0 +242,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -217,0 +256,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -229,0 +271,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicCharOpTest.java","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -69,0 +69,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -80,0 +83,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +97,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +111,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -113,0 +125,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +139,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -135,0 +153,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -146,0 +167,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -157,0 +181,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -168,0 +195,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -179,0 +209,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -190,0 +223,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -203,0 +239,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -216,0 +255,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -229,0 +271,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -242,0 +287,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -255,0 +303,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -268,0 +319,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicDoubleOpTest.java","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -69,0 +69,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -80,0 +83,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +97,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +111,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -113,0 +125,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +139,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -135,0 +153,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -146,0 +167,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -157,0 +181,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -170,0 +197,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -183,0 +213,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -196,0 +229,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -209,0 +245,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -222,0 +261,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -235,0 +277,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicFloatOpTest.java","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -69,0 +69,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -80,0 +83,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -91,0 +97,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -102,0 +111,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -113,0 +125,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -124,0 +139,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -135,0 +153,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -146,0 +167,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -158,0 +182,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -169,0 +196,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -180,0 +210,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -191,0 +224,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -203,0 +239,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -214,0 +253,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -225,0 +267,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicIntOpTest.java","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -70,0 +70,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -81,0 +84,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -92,0 +98,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -103,0 +112,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -114,0 +126,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -127,0 +142,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -138,0 +156,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -150,0 +171,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -161,0 +185,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -172,0 +199,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -183,0 +213,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -195,0 +228,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -206,0 +242,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -217,0 +256,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicLongOpTest.java","additions":42,"deletions":0,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -71,0 +71,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -82,0 +85,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -93,0 +99,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -104,0 +113,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -115,0 +127,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -126,0 +141,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -137,0 +155,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -149,0 +170,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -160,0 +184,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -171,0 +198,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -182,0 +212,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -194,0 +227,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -205,0 +241,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -253,0 +292,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/BasicShortOpTest.java","additions":42,"deletions":0,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -86,0 +86,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -99,0 +102,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -112,0 +118,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -126,0 +135,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -140,0 +152,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -154,0 +169,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -372,0 +390,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/LoopArrayIndexComputeTest.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -88,0 +88,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -99,0 +102,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -110,0 +116,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -121,0 +130,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -132,0 +144,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -143,0 +158,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -158,0 +176,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -173,0 +194,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -186,0 +210,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -201,0 +228,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -214,0 +244,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -227,0 +260,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -240,0 +276,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -253,0 +292,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -265,0 +307,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -274,0 +319,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -292,0 +340,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/LoopCombinedOpTest.java","additions":51,"deletions":0,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -69,0 +69,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/LoopControlFlowTest.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -73,0 +73,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -85,0 +88,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -97,0 +103,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -109,0 +118,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -121,0 +133,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/LoopLiveOutNodesTest.java","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -84,0 +84,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -95,0 +98,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -106,0 +112,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -117,0 +126,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -128,0 +140,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -141,0 +156,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -214,0 +232,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/LoopRangeStrideTest.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -68,0 +68,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -87,0 +90,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n@@ -103,0 +109,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/MultipleLoopsTest.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -65,0 +65,3 @@\n+    @IR(applyIfCPUFeature = {\"sve\", \"true\"},\n+        applyIf = {\"UseMaskedLoop\", \"true\"},\n+        counts = {IRNode.LOOP_VECTOR_MASK, \">0\"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/StripMinedLoopTest.java","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-        WB.setBooleanVMFlag(\"PostLoopMultiversioning\", true);\n+        WB.setBooleanVMFlag(\"UseMaskedLoop\", true);\n@@ -83,2 +83,0 @@\n-        \/\/ Add extra VM options to enable more auto-vectorization chances\n-        irTest.addFlags(\"-XX:-OptimizeFill\");\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/runner\/VectorizationTestRunner.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"}]}