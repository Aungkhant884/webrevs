{"files":[{"patch":"@@ -1873,0 +1873,4 @@\n+void G1ConcurrentMark::par_clear_range_in_prev_bitmap(MemRegion mr) {\n+  _prev_mark_bitmap->par_clear_range(mr);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -567,0 +567,1 @@\n+  inline void par_mark_in_prev_bitmap(oop p);\n@@ -572,0 +573,1 @@\n+  void par_clear_range_in_prev_bitmap(MemRegion mr);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -276,0 +276,5 @@\n+inline void G1ConcurrentMark::par_mark_in_prev_bitmap(oop p) {\n+  assert(!_prev_mark_bitmap->is_marked(p), \"sanity\");\n+  _prev_mark_bitmap->par_mark(p);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.inline.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1,214 +0,0 @@\n-\/*\n- * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n-#include \"gc\/g1\/g1CollectorState.hpp\"\n-#include \"gc\/g1\/g1ConcurrentMark.inline.hpp\"\n-#include \"gc\/g1\/g1EvacFailure.hpp\"\n-#include \"gc\/g1\/g1EvacFailureRegions.hpp\"\n-#include \"gc\/g1\/g1HeapVerifier.hpp\"\n-#include \"gc\/g1\/g1OopClosures.inline.hpp\"\n-#include \"gc\/g1\/heapRegion.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n-#include \"gc\/shared\/preservedMarks.inline.hpp\"\n-#include \"oops\/access.inline.hpp\"\n-#include \"oops\/compressedOops.inline.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-\n-class RemoveSelfForwardPtrObjClosure: public ObjectClosure {\n-  G1CollectedHeap* _g1h;\n-  G1ConcurrentMark* _cm;\n-  HeapRegion* _hr;\n-  size_t _marked_words;\n-  bool _during_concurrent_start;\n-  uint _worker_id;\n-  HeapWord* _last_forwarded_object_end;\n-\n-public:\n-  RemoveSelfForwardPtrObjClosure(HeapRegion* hr,\n-                                 bool during_concurrent_start,\n-                                 uint worker_id) :\n-    _g1h(G1CollectedHeap::heap()),\n-    _cm(_g1h->concurrent_mark()),\n-    _hr(hr),\n-    _marked_words(0),\n-    _during_concurrent_start(during_concurrent_start),\n-    _worker_id(worker_id),\n-    _last_forwarded_object_end(hr->bottom()) { }\n-\n-  size_t marked_bytes() { return _marked_words * HeapWordSize; }\n-\n-  \/\/ Iterate over the live objects in the region to find self-forwarded objects\n-  \/\/ that need to be kept live. We need to update the remembered sets of these\n-  \/\/ objects. Further update the BOT and marks.\n-  \/\/ We can coalesce and overwrite the remaining heap contents with dummy objects\n-  \/\/ as they have either been dead or evacuated (which are unreferenced now, i.e.\n-  \/\/ dead too) already.\n-  void do_object(oop obj) {\n-    HeapWord* obj_addr = cast_from_oop<HeapWord*>(obj);\n-    assert(_last_forwarded_object_end <= obj_addr, \"should iterate in ascending address order\");\n-    assert(_hr->is_in(obj_addr), \"sanity\");\n-\n-    \/\/ The object failed to move.\n-    assert(obj->is_forwarded() && obj->forwardee() == obj, \"sanity\");\n-\n-    zap_dead_objects(_last_forwarded_object_end, obj_addr);\n-    \/\/ We consider all objects that we find self-forwarded to be\n-    \/\/ live. What we'll do is that we'll update the prev marking\n-    \/\/ info so that they are all under PTAMS and explicitly marked.\n-    if (!_cm->is_marked_in_prev_bitmap(obj)) {\n-      _cm->mark_in_prev_bitmap(obj);\n-    }\n-    if (_during_concurrent_start) {\n-      \/\/ For the next marking info we'll only mark the\n-      \/\/ self-forwarded objects explicitly if we are during\n-      \/\/ concurrent start (since, normally, we only mark objects pointed\n-      \/\/ to by roots if we succeed in copying them). By marking all\n-      \/\/ self-forwarded objects we ensure that we mark any that are\n-      \/\/ still pointed to be roots. During concurrent marking, and\n-      \/\/ after concurrent start, we don't need to mark any objects\n-      \/\/ explicitly and all objects in the CSet are considered\n-      \/\/ (implicitly) live. So, we won't mark them explicitly and\n-      \/\/ we'll leave them over NTAMS.\n-      _cm->mark_in_next_bitmap(_worker_id, _hr, obj);\n-    }\n-    size_t obj_size = obj->size();\n-\n-    _marked_words += obj_size;\n-    PreservedMarks::init_forwarded_mark(obj);\n-\n-    HeapWord* obj_end = obj_addr + obj_size;\n-    _last_forwarded_object_end = obj_end;\n-    _hr->alloc_block_in_bot(obj_addr, obj_end);\n-  }\n-\n-  \/\/ Fill the memory area from start to end with filler objects, and update the BOT\n-  \/\/ and the mark bitmap accordingly.\n-  void zap_dead_objects(HeapWord* start, HeapWord* end) {\n-    if (start == end) {\n-      return;\n-    }\n-\n-    size_t gap_size = pointer_delta(end, start);\n-    MemRegion mr(start, gap_size);\n-    if (gap_size >= CollectedHeap::min_fill_size()) {\n-      CollectedHeap::fill_with_objects(start, gap_size);\n-\n-      HeapWord* end_first_obj = start + cast_to_oop(start)->size();\n-      _hr->alloc_block_in_bot(start, end_first_obj);\n-      \/\/ Fill_with_objects() may have created multiple (i.e. two)\n-      \/\/ objects, as the max_fill_size() is half a region.\n-      \/\/ After updating the BOT for the first object, also update the\n-      \/\/ BOT for the second object to make the BOT complete.\n-      if (end_first_obj != end) {\n-        _hr->alloc_block_in_bot(end_first_obj, end);\n-#ifdef ASSERT\n-        size_t size_second_obj = cast_to_oop(end_first_obj)->size();\n-        HeapWord* end_of_second_obj = end_first_obj + size_second_obj;\n-        assert(end == end_of_second_obj,\n-               \"More than two objects were used to fill the area from \" PTR_FORMAT \" to \" PTR_FORMAT \", \"\n-               \"second objects size \" SIZE_FORMAT \" ends at \" PTR_FORMAT,\n-               p2i(start), p2i(end), size_second_obj, p2i(end_of_second_obj));\n-#endif\n-      }\n-    }\n-    _cm->clear_range_in_prev_bitmap(mr);\n-  }\n-\n-  void zap_remainder() {\n-    zap_dead_objects(_last_forwarded_object_end, _hr->top());\n-  }\n-};\n-\n-class RemoveSelfForwardPtrHRClosure: public HeapRegionClosure {\n-  G1CollectedHeap* _g1h;\n-  uint _worker_id;\n-\n-  G1EvacFailureRegions* _evac_failure_regions;\n-\n-public:\n-  RemoveSelfForwardPtrHRClosure(uint worker_id,\n-                                G1EvacFailureRegions* evac_failure_regions) :\n-    _g1h(G1CollectedHeap::heap()),\n-    _worker_id(worker_id),\n-    _evac_failure_regions(evac_failure_regions) {\n-  }\n-\n-  size_t remove_self_forward_ptr_by_walking_hr(HeapRegion* hr,\n-                                               bool during_concurrent_start) {\n-    RemoveSelfForwardPtrObjClosure rspc(hr,\n-                                        during_concurrent_start,\n-                                        _worker_id);\n-    \/\/ Iterates evac failure objs which are recorded during evacuation.\n-    hr->process_and_drop_evac_failure_objs(&rspc);\n-    \/\/ Need to zap the remainder area of the processed region.\n-    rspc.zap_remainder();\n-\n-    return rspc.marked_bytes();\n-  }\n-\n-  bool do_heap_region(HeapRegion *hr) {\n-    assert(!hr->is_pinned(), \"Unexpected pinned region at index %u\", hr->hrm_index());\n-    assert(hr->in_collection_set(), \"bad CS\");\n-\n-    if (_evac_failure_regions->contains(hr->hrm_index())) {\n-      hr->clear_index_in_opt_cset();\n-\n-      bool during_concurrent_start = _g1h->collector_state()->in_concurrent_start_gc();\n-      bool during_concurrent_mark = _g1h->collector_state()->mark_or_rebuild_in_progress();\n-\n-      hr->note_self_forwarding_removal_start(during_concurrent_start,\n-                                             during_concurrent_mark);\n-      _g1h->verifier()->check_bitmaps(\"Self-Forwarding Ptr Removal\", hr);\n-\n-      hr->reset_bot();\n-\n-      size_t live_bytes = remove_self_forward_ptr_by_walking_hr(hr, during_concurrent_start);\n-\n-      hr->rem_set()->clean_strong_code_roots(hr);\n-      hr->rem_set()->clear_locked(true);\n-\n-      hr->note_self_forwarding_removal_end(live_bytes);\n-    }\n-    return false;\n-  }\n-};\n-\n-G1ParRemoveSelfForwardPtrsTask::G1ParRemoveSelfForwardPtrsTask(G1EvacFailureRegions* evac_failure_regions) :\n-  WorkerTask(\"G1 Remove Self-forwarding Pointers\"),\n-  _g1h(G1CollectedHeap::heap()),\n-  _hrclaimer(_g1h->workers()->active_workers()),\n-  _evac_failure_regions(evac_failure_regions) { }\n-\n-void G1ParRemoveSelfForwardPtrsTask::work(uint worker_id) {\n-  RemoveSelfForwardPtrHRClosure rsfp_cl(worker_id, _evac_failure_regions);\n-\n-  \/\/ Iterate through all regions that failed evacuation during the entire collection.\n-  _evac_failure_regions->par_iterate(&rsfp_cl, &_hrclaimer, worker_id);\n-}\n-\n-uint G1ParRemoveSelfForwardPtrsTask::num_failed_regions() const {\n-  return _evac_failure_regions->num_regions_failed_evacuation();\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":0,"deletions":214,"binary":false,"changes":214,"status":"deleted"},{"patch":"@@ -1,54 +0,0 @@\n-\/*\n- * Copyright (c) 2012, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_G1EVACFAILURE_HPP\n-#define SHARE_GC_G1_G1EVACFAILURE_HPP\n-\n-#include \"gc\/g1\/g1OopClosures.hpp\"\n-#include \"gc\/g1\/heapRegionManager.hpp\"\n-#include \"gc\/shared\/workerThread.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-class G1CollectedHeap;\n-class G1EvacFailureRegions;\n-\n-\/\/ Task to fixup self-forwarding pointers\n-\/\/ installed as a result of an evacuation failure.\n-class G1ParRemoveSelfForwardPtrsTask: public WorkerTask {\n-protected:\n-  G1CollectedHeap* _g1h;\n-  HeapRegionClaimer _hrclaimer;\n-\n-  G1EvacFailureRegions* _evac_failure_regions;\n-  uint volatile _num_failed_regions;\n-\n-public:\n-  G1ParRemoveSelfForwardPtrsTask(G1EvacFailureRegions* evac_failure_regions);\n-\n-  void work(uint worker_id);\n-\n-  uint num_failed_regions() const;\n-};\n-\n-#endif \/\/ SHARE_GC_G1_G1EVACFAILURE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.hpp","additions":0,"deletions":54,"binary":false,"changes":54,"status":"deleted"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -29,1 +29,3 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/shared\/taskqueue.inline.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -32,1 +34,0 @@\n-\n@@ -58,1 +59,1 @@\n-  DEBUG_ONLY(_region_idx(region_idx) COMMA)\n+  _region_idx(region_idx),\n@@ -60,1 +61,3 @@\n-  _offsets(&_alloc_options, &_free_segment_list)  {\n+  _offsets(&_alloc_options, &_free_segment_list),\n+  _helper(this, _region_idx),\n+  _word_size(0) {\n@@ -64,4 +67,3 @@\n-\/\/ Helper class to join, sort and iterate over the previously collected segmented\n-\/\/ array of objects that failed evacuation.\n-class G1EvacFailureObjectsIterationHelper {\n-  typedef G1EvacFailureObjectsSet::OffsetInRegion OffsetInRegion;\n+int G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::order_oop(OffsetInRegion a, OffsetInRegion b) {\n+  return static_cast<int>(a-b);\n+}\n@@ -69,4 +71,2 @@\n-  G1EvacFailureObjectsSet* _objects_set;\n-  const G1SegmentedArray<OffsetInRegion, mtGC>* _segments;\n-  OffsetInRegion* _offset_array;\n-  uint _array_length;\n+void G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::join_and_sort() {\n+  _segments->iterate_segments(*this);\n@@ -74,6 +74,2 @@\n-  static int order_oop(OffsetInRegion a, OffsetInRegion b) {\n-    return static_cast<int>(a-b);\n-  }\n-\n-  void join_and_sort() {\n-    _segments->iterate_segments(*this);\n+  QuickSort::sort(_offset_array, _array_length, order_oop, true);\n+}\n@@ -81,1 +77,3 @@\n-    QuickSort::sort(_offset_array, _array_length, order_oop, true);\n+HeapWord* G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::previous_object_end(HeapRegion* region, uint start_idx) {\n+  if (start_idx == 0) {\n+    return region->bottom();\n@@ -83,0 +81,6 @@\n+  oop obj = _objects_set->from_offset(_offset_array[start_idx - 1]);\n+  HeapWord* obj_addr = cast_from_oop<HeapWord*>(obj);\n+  size_t obj_size = obj->size();\n+  HeapWord* obj_end = obj_addr + obj_size;\n+  return obj_end;\n+}\n@@ -84,5 +88,10 @@\n-  void iterate(ObjectClosure* closure) {\n-    for (uint i = 0; i < _array_length; i++) {\n-      oop cur = _objects_set->from_offset(_offset_array[i]);\n-      closure->do_object(cur);\n-    }\n+void G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::insert_queue(G1EvacFailureParScanTasksQueue* queue) {\n+  assert(_array_length > 0, \"must be\");\n+  uint i = 1;\n+  uint start_idx = (uint)-1;\n+  HeapWord* prev_end = nullptr;\n+  HeapRegion* region = G1CollectedHeap::heap()->region_at(_region_idx);\n+  for (; i*TASK_LIMIT < _array_length; i++) {\n+    start_idx = (i-1)*TASK_LIMIT;\n+    prev_end = previous_object_end(region, start_idx);\n+    queue->push(G1EvacFailureParScanTask(region, prev_end, start_idx, i * TASK_LIMIT));\n@@ -90,0 +99,4 @@\n+  start_idx = (i-1)*TASK_LIMIT;\n+  prev_end = previous_object_end(region, start_idx);\n+  queue->push(G1EvacFailureParScanTask(region, prev_end, start_idx, _array_length, true));\n+}\n@@ -91,6 +104,6 @@\n-public:\n-  G1EvacFailureObjectsIterationHelper(G1EvacFailureObjectsSet* collector) :\n-    _objects_set(collector),\n-    _segments(&_objects_set->_offsets),\n-    _offset_array(nullptr),\n-    _array_length(0) { }\n+G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::G1EvacFailureObjectsIterationHelper(G1EvacFailureObjectsSet* collector, uint region_idx) :\n+  _objects_set(collector),\n+  _segments(&_objects_set->_offsets),\n+  _offset_array(nullptr),\n+  _array_length(0),\n+  _region_idx(region_idx) { }\n@@ -98,3 +111,3 @@\n-  void process_and_drop(ObjectClosure* closure) {\n-    uint num = _segments->num_allocated_slots();\n-    _offset_array = NEW_C_HEAP_ARRAY(OffsetInRegion, num, mtGC);\n+void G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::prepare(G1EvacFailureParScanTasksQueue* queue) {\n+  uint num = _segments->num_allocated_slots();\n+  _offset_array = NEW_C_HEAP_ARRAY(OffsetInRegion, num, mtGC);\n@@ -102,3 +115,2 @@\n-    join_and_sort();\n-    assert(_array_length == num, \"must be %u, %u\", _array_length, num);\n-    iterate(closure);\n+  join_and_sort();\n+  assert(_array_length == num, \"must be %u, %u\", _array_length, num);\n@@ -106,2 +118,2 @@\n-    FREE_C_HEAP_ARRAY(OffsetInRegion, _offset_array);\n-  }\n+  insert_queue(queue);\n+}\n@@ -109,4 +121,5 @@\n-  \/\/ Callback of G1SegmentedArray::iterate_segments\n-  void do_segment(G1SegmentedArraySegment<mtGC>* segment, uint length) {\n-    segment->copy_to(&_offset_array[_array_length]);\n-    _array_length += length;\n+void G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::iterate(ObjectClosure* closure, G1EvacFailureParScanTask& task) {\n+  assert(_region_idx == task.region()->hrm_index(), \"must be\");\n+  for (uint i = task.start(); i < task.end(); i++) {\n+    oop cur = _objects_set->from_offset(_offset_array[i]);\n+    closure->do_object(cur);\n@@ -114,1 +127,13 @@\n-};\n+}\n+\n+void G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::reset() {\n+  FREE_C_HEAP_ARRAY(OffsetInRegion, _offset_array);\n+  _offset_array = nullptr;\n+  _array_length = 0;\n+}\n+\n+\/\/ Callback of G1SegmentedArray::iterate_segments\n+void G1EvacFailureObjectsSet::G1EvacFailureObjectsIterationHelper::do_segment(G1SegmentedArraySegment<mtGC>* segment, uint length) {\n+  segment->copy_to(&_offset_array[_array_length]);\n+  _array_length += length;\n+}\n@@ -116,1 +141,1 @@\n-void G1EvacFailureObjectsSet::process_and_drop(ObjectClosure* closure) {\n+size_t G1EvacFailureObjectsSet::pre_iteration(G1EvacFailureParScanTasksQueue* queue) {\n@@ -119,2 +144,8 @@\n-  G1EvacFailureObjectsIterationHelper helper(this);\n-  helper.process_and_drop(closure);\n+  _helper.prepare(queue);\n+\n+  return Atomic::load(&_word_size) * HeapWordSize;\n+}\n+\n+void G1EvacFailureObjectsSet::iterate(ObjectClosure* closure, G1EvacFailureParScanTask& task) {\n+  _helper.iterate(closure, task);\n+}\n@@ -122,0 +153,2 @@\n+void G1EvacFailureObjectsSet::post_iteration() {\n+  _helper.reset();\n@@ -123,0 +156,1 @@\n+  Atomic::store(&_word_size, size_t(0));\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureObjectsSet.cpp","additions":81,"deletions":47,"binary":false,"changes":128,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/g1\/g1EvacFailureParScanTask.hpp\"\n@@ -31,0 +32,1 @@\n+#include \"runtime\/atomic.hpp\"\n@@ -32,1 +34,1 @@\n-class G1EvacFailureObjectsIterationHelper;\n+class HeapRegion;\n@@ -39,3 +41,0 @@\n-  friend class G1EvacFailureObjectsIterationHelper;\n-\n-public:\n@@ -47,1 +46,32 @@\n-private:\n+  \/\/ Helper class to join, sort and iterate over the previously collected segmented\n+  \/\/ array of objects that failed evacuation.\n+  class G1EvacFailureObjectsIterationHelper {\n+    typedef G1EvacFailureObjectsSet::OffsetInRegion OffsetInRegion;\n+\n+    static const uint TASK_LIMIT = 1000;\n+\n+    G1EvacFailureObjectsSet* _objects_set;\n+    const G1SegmentedArray<OffsetInRegion, mtGC>* _segments;\n+    OffsetInRegion* _offset_array;\n+    uint _array_length;\n+    uint _region_idx;\n+\n+    static int order_oop(OffsetInRegion a, OffsetInRegion b);\n+\n+    void join_and_sort();\n+\n+    HeapWord* previous_object_end(HeapRegion* region, uint start_idx);\n+\n+    void insert_queue(G1EvacFailureParScanTasksQueue* queue);\n+\n+  public:\n+    G1EvacFailureObjectsIterationHelper(G1EvacFailureObjectsSet* collector, uint region_idx);\n+\n+    void prepare(G1EvacFailureParScanTasksQueue* queue);\n+    void iterate(ObjectClosure* closure, G1EvacFailureParScanTask& task);\n+    void reset();\n+\n+    \/\/ Callback of G1SegmentedArray::iterate_segments\n+    void do_segment(G1SegmentedArraySegment<mtGC>* segment, uint length);\n+  };\n+\n@@ -49,0 +79,1 @@\n+\n@@ -56,1 +87,1 @@\n-  DEBUG_ONLY(const uint _region_idx;)\n+  const uint _region_idx;\n@@ -64,0 +95,5 @@\n+  G1EvacFailureObjectsIterationHelper _helper;\n+\n+  \/\/ Live words in the evacuation failure region.\n+  volatile size_t _word_size;\n+\n@@ -73,6 +109,12 @@\n-  inline void record(oop obj);\n-\n-  \/\/ Apply the given ObjectClosure to all objects that failed evacuation and\n-  \/\/ empties the list after processing.\n-  \/\/ Objects are passed in increasing address order.\n-  void process_and_drop(ObjectClosure* closure);\n+  inline void record(oop obj, size_t word_size);\n+\n+  \/\/ Prepare parallel iteration by building and sorting list of evacuation\n+  \/\/ failure objects, and constructing parallelizable tasks.\n+  \/\/ Return live bytes in the evacuation failure region.\n+  size_t pre_iteration(G1EvacFailureParScanTasksQueue* queue);\n+  \/\/ Apply the given ObjectClosure to all previously recorded objects in the task\n+  \/\/ that failed evacuation in ascending address order.\n+  void iterate(ObjectClosure* closure, G1EvacFailureParScanTask& task);\n+  \/\/ Empty the list of evacuation failure objects.\n+  \/\/ Reset live words in the evacuation failure region.\n+  void post_iteration();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureObjectsSet.hpp","additions":54,"deletions":12,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -31,1 +31,1 @@\n-#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n@@ -33,1 +33,1 @@\n-void G1EvacFailureObjectsSet::record(oop obj) {\n+inline void G1EvacFailureObjectsSet::record(oop obj, size_t word_size) {\n@@ -38,0 +38,1 @@\n+  Atomic::add(&_word_size, word_size);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureObjectsSet.inline.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -0,0 +1,292 @@\n+\/*\n+ * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1EvacFailureParScanState.hpp\"\n+\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n+#include \"gc\/g1\/g1ConcurrentMark.inline.hpp\"\n+#include \"gc\/g1\/g1EvacFailureRegions.inline.hpp\"\n+#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"gc\/g1\/heapRegionManager.hpp\"\n+#include \"gc\/shared\/preservedMarks.inline.hpp\"\n+#include \"gc\/shared\/taskqueue.inline.hpp\"\n+#include \"memory\/iterator.inline.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+\n+class G1PreRemoveSelfForwardClosure: public HeapRegionClosure {\n+  G1CollectedHeap* _g1h;\n+  uint _worker_id;\n+\n+  G1EvacFailureRegions* _evac_failure_regions;\n+\n+  G1EvacFailureParScanTasksQueue* _task_queue;\n+\n+public:\n+  G1PreRemoveSelfForwardClosure(uint worker_id,\n+                                G1EvacFailureRegions* evac_failure_regions,\n+                                G1EvacFailureParScanTasksQueue* task_queue) :\n+    _g1h(G1CollectedHeap::heap()),\n+    _worker_id(worker_id),\n+    _evac_failure_regions(evac_failure_regions),\n+    _task_queue(task_queue) {\n+  }\n+\n+  size_t prepare_evac_failure_objs(HeapRegion* hr) {\n+    return hr->prepare_evac_failure_objs(_task_queue);\n+  }\n+\n+  bool do_heap_region(HeapRegion *hr) {\n+    assert(!hr->is_pinned(), \"Unexpected pinned region at index %u\", hr->hrm_index());\n+    assert(hr->in_collection_set(), \"bad CS\");\n+\n+    if (_evac_failure_regions->contains(hr->hrm_index())) {\n+      hr->clear_index_in_opt_cset();\n+\n+      bool during_concurrent_start = _g1h->collector_state()->in_concurrent_start_gc();\n+      bool during_concurrent_mark = _g1h->collector_state()->mark_or_rebuild_in_progress();\n+\n+      hr->note_self_forwarding_removal_start(during_concurrent_start,\n+                                             during_concurrent_mark);\n+      _g1h->verifier()->check_bitmaps(\"Self-Forwarding Ptr Removal\", hr);\n+\n+      hr->reset_bot();\n+\n+      size_t live_bytes = prepare_evac_failure_objs(hr);\n+\n+      hr->rem_set()->clean_strong_code_roots(hr);\n+      hr->rem_set()->clear_locked(true);\n+\n+      hr->note_self_forwarding_removal_end(live_bytes);\n+    }\n+    return false;\n+  }\n+};\n+\n+class G1RemoveSelfForwardClosure: public ObjectClosure {\n+  G1CollectedHeap* _g1h;\n+  G1ConcurrentMark* _cm;\n+  HeapRegion* _hr;\n+  size_t _marked_words;\n+  bool _during_concurrent_start;\n+  uint _worker_id;\n+  HeapWord* _last_forwarded_object_end;\n+\n+  \/\/ Fill the memory area from start to end with filler objects, and update the BOT\n+  \/\/ and the mark bitmap accordingly.\n+  void zap_dead_objects(HeapWord* start, HeapWord* end) {\n+    if (start == end) {\n+      return;\n+    }\n+\n+    size_t gap_size = pointer_delta(end, start);\n+    MemRegion mr(start, gap_size);\n+    if (gap_size >= CollectedHeap::min_fill_size()) {\n+      CollectedHeap::fill_with_objects(start, gap_size);\n+\n+      size_t dummy_size = cast_to_oop(start)->size();\n+      HeapWord* end_first_obj = start + dummy_size;\n+      _hr->update_bot_at(start, dummy_size, false);\n+      \/\/ Fill_with_objects() may have created multiple (i.e. two)\n+      \/\/ objects, as the max_fill_size() is half a region.\n+      \/\/ After updating the BOT for the first object, also update the\n+      \/\/ BOT for the second object to make the BOT complete.\n+      if (end_first_obj != end) {\n+        _hr->update_bot_at(end_first_obj, cast_to_oop(end_first_obj)->size(), false);\n+#ifdef ASSERT\n+        size_t size_second_obj = cast_to_oop(end_first_obj)->size();\n+        HeapWord* end_of_second_obj = end_first_obj + size_second_obj;\n+        assert(end == end_of_second_obj,\n+               \"More than two objects were used to fill the area from \" PTR_FORMAT \" to \" PTR_FORMAT \", \"\n+                                                                                                     \"second objects size \" SIZE_FORMAT \" ends at \" PTR_FORMAT,\n+               p2i(start), p2i(end), size_second_obj, p2i(end_of_second_obj));\n+#endif\n+      }\n+    }\n+    _cm->par_clear_range_in_prev_bitmap(mr);\n+  }\n+\n+  void zap_remainder() {\n+    zap_dead_objects(_last_forwarded_object_end, _hr->top());\n+  }\n+\n+public:\n+  G1RemoveSelfForwardClosure(bool during_concurrent_start, uint worker_id) :\n+    _g1h(G1CollectedHeap::heap()),\n+    _cm(_g1h->concurrent_mark()),\n+    _marked_words(0),\n+    _during_concurrent_start(during_concurrent_start),\n+    _worker_id(worker_id),\n+    _last_forwarded_object_end(nullptr) { }\n+\n+  void set_state(HeapRegion* region, G1EvacFailureParScanTask& task) {\n+    _hr = region;\n+    _last_forwarded_object_end = const_cast<HeapWord*>(task.previous_object_end());\n+  }\n+\n+  \/\/ Iterate over the live objects in the region to find self-forwarded objects\n+  \/\/ that need to be kept live. We need to update the remembered sets of these\n+  \/\/ objects. Further update the BOT and marks.\n+  \/\/ We can coalesce and overwrite the remaining heap contents with dummy objects\n+  \/\/ as they have either been dead or evacuated (which are unreferenced now, i.e.\n+  \/\/ dead too) already.\n+  void do_object(oop obj) {\n+\n+    HeapWord* obj_addr = cast_from_oop<HeapWord*>(obj);\n+    assert(_last_forwarded_object_end <= obj_addr, \"should iterate in ascending address order\");\n+    assert(_hr->is_in(obj_addr), \"sanity\");\n+\n+    \/\/ The object failed to move.\n+    assert(obj->is_forwarded() && obj->forwardee() == obj, \"sanity\");\n+\n+    zap_dead_objects(_last_forwarded_object_end, obj_addr);\n+    \/\/ We consider all objects that we find self-forwarded to be\n+    \/\/ live. What we'll do is that we'll update the prev marking\n+    \/\/ info so that they are all under PTAMS and explicitly marked.\n+    if (!_cm->is_marked_in_prev_bitmap(obj)) {\n+      _cm->par_mark_in_prev_bitmap(obj);\n+    }\n+    if (_during_concurrent_start) {\n+      \/\/ For the next marking info we'll only mark the\n+      \/\/ self-forwarded objects explicitly if we are during\n+      \/\/ concurrent start (since, normally, we only mark objects pointed\n+      \/\/ to by roots if we succeed in copying them). By marking all\n+      \/\/ self-forwarded objects we ensure that we mark any that are\n+      \/\/ still pointed to be roots. During concurrent marking, and\n+      \/\/ after concurrent start, we don't need to mark any objects\n+      \/\/ explicitly and all objects in the CSet are considered\n+      \/\/ (implicitly) live. So, we won't mark them explicitly and\n+      \/\/ we'll leave them over NTAMS.\n+      _cm->mark_in_next_bitmap(_worker_id, _hr, obj);\n+    }\n+    size_t obj_size = obj->size();\n+\n+    _marked_words += obj_size;\n+    PreservedMarks::init_forwarded_mark(obj);\n+\n+    HeapWord* obj_end = obj_addr + obj_size;\n+    _last_forwarded_object_end = obj_end;\n+    _hr->update_bot_at(obj_addr, obj_size, false);\n+  }\n+\n+  void process_last() {\n+    zap_remainder();\n+    \/\/ As we have process the self forwardee in parallel,\n+    \/\/ it's necessary to update the bot threshold explicitly.\n+    _hr->update_bot_threshold();\n+  }\n+};\n+\n+class G1PostRemoveSelfForwardClosure: public HeapRegionClosure {\n+\n+  bool do_heap_region(HeapRegion *hr) {\n+    hr->reset_evac_failure_objs();\n+    return false;\n+  }\n+};\n+\n+void G1EvacFailureParScanState::dispatch_task(G1EvacFailureParScanTask& task, G1RemoveSelfForwardClosure& closure) {\n+  DEBUG_ONLY(task.verify();)\n+  HeapRegion* region = G1CollectedHeap::heap()->region_at(task._region->hrm_index());\n+  closure.set_state(region, task);\n+  region->iterate_evac_failure_objs(&closure, task);\n+  if (task.last()) {\n+    closure.process_last();\n+  }\n+}\n+\n+void G1EvacFailureParScanState::trim_queue_to_threshold(uint threshold, G1RemoveSelfForwardClosure& closure) {\n+  G1EvacFailureParScanTask task;\n+  do {\n+    while (_task_queue->pop_overflow(task)) {\n+      if (!_task_queue->try_push_to_taskqueue(task)) {\n+        dispatch_task(task, closure);\n+      }\n+    }\n+    while (_task_queue->pop_local(task, threshold)) {\n+      dispatch_task(task, closure);\n+    }\n+  } while (!_task_queue->overflow_empty());\n+}\n+\n+void G1EvacFailureParScanState::trim_queue(G1RemoveSelfForwardClosure& closure) {\n+  trim_queue_to_threshold(0, closure);\n+  assert(_task_queue->overflow_empty(), \"invariant\");\n+  assert(_task_queue->taskqueue_empty(), \"invariant\");\n+}\n+\n+void G1EvacFailureParScanState::steal_and_trim_queue(G1RemoveSelfForwardClosure& closure) {\n+  G1EvacFailureParScanTask stolen_task;\n+  while (_task_queues->steal(_worker_id, stolen_task)) {\n+    dispatch_task(stolen_task, closure);\n+    \/\/ Processing stolen task may have added tasks to our queue.\n+    trim_queue(closure);\n+  }\n+}\n+\n+void G1EvacFailureParScanState::prev_scan() {\n+  assert(_worker_id < _task_queues->size(), \"must be\");\n+  G1PreRemoveSelfForwardClosure closure(_worker_id, _evac_failure_regions, _task_queues->queue(_worker_id));\n+\n+  \/\/ Iterate through all regions that failed evacuation during the entire collection.\n+  _evac_failure_regions->par_iterate(&closure, _prev_claimer, _worker_id);\n+}\n+\n+void G1EvacFailureParScanState::scan() {\n+  bool during_concurrent_start = G1CollectedHeap::heap()->collector_state()->in_concurrent_start_gc();\n+  G1RemoveSelfForwardClosure closure(during_concurrent_start, _worker_id);\n+\n+  trim_queue(closure);\n+  do {\n+    steal_and_trim_queue(closure);\n+  } while (!offer_termination());\n+}\n+\n+void G1EvacFailureParScanState::post_scan() {\n+  G1PostRemoveSelfForwardClosure closure;\n+\n+  \/\/ Iterate through all regions that failed evacuation during the entire collection.\n+  _evac_failure_regions->par_iterate(&closure, _post_claimer, _worker_id);\n+}\n+\n+G1EvacFailureParScanState::G1EvacFailureParScanState(G1EvacFailureRegions* evac_failure_regions,\n+                                                     G1EvacFailureParScanTasksQueueSet* queues,\n+                                                     TaskTerminator* terminator,\n+                                                     uint worker_id,\n+                                                     HeapRegionClaimer* pre_claimer,\n+                                                     HeapRegionClaimer* post_claimer) :\n+  _evac_failure_regions(evac_failure_regions),\n+  _task_queues(queues),\n+  _worker_id(worker_id),\n+  _task_queue(queues->queue(_worker_id)),\n+  _terminator(terminator),\n+  _prev_claimer(pre_claimer),\n+  _post_claimer(post_claimer) { }\n+\n+void G1EvacFailureParScanState::do_void() {\n+  prev_scan();\n+  scan();\n+  post_scan();\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureParScanState.cpp","additions":292,"deletions":0,"binary":false,"changes":292,"status":"added"},{"patch":"@@ -0,0 +1,78 @@\n+\/*\n+ * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1EVACFAILUREPARSCANSTATE_HPP\n+#define SHARE_GC_G1_G1EVACFAILUREPARSCANSTATE_HPP\n+\n+#include \"gc\/g1\/g1EvacFailureParScanTask.hpp\"\n+#include \"gc\/shared\/taskTerminator.hpp\"\n+#include \"gc\/shared\/workerThread.hpp\"\n+#include \"memory\/allocation.hpp\"\n+\n+class G1EvacFailureRegions;\n+class G1RemoveSelfForwardClosure;\n+class HeapRegionClaimer;\n+class TaskTerminator;\n+\n+class G1EvacFailureParScanState {\n+  G1EvacFailureRegions* _evac_failure_regions;\n+\n+  G1EvacFailureParScanTasksQueueSet* _task_queues;\n+  uint _worker_id;\n+  G1EvacFailureParScanTasksQueue* _task_queue;\n+\n+  TaskTerminator* _terminator;\n+\n+  HeapRegionClaimer* _prev_claimer;\n+  HeapRegionClaimer* _post_claimer;\n+\n+  void dispatch_task(G1EvacFailureParScanTask& task, G1RemoveSelfForwardClosure& closure);\n+\n+  void trim_queue(G1RemoveSelfForwardClosure& closure);\n+\n+  void trim_queue_to_threshold(uint threshold, G1RemoveSelfForwardClosure& closure);\n+\n+  void steal_and_trim_queue(G1RemoveSelfForwardClosure& closure);\n+\n+  inline bool offer_termination() {\n+    return (_terminator == nullptr) ? true : _terminator->offer_termination();\n+  }\n+\n+  void prev_scan();\n+  void scan();\n+  void post_scan();\n+\n+public:\n+  G1EvacFailureParScanState(G1EvacFailureRegions* evac_failure_regions,\n+                            G1EvacFailureParScanTasksQueueSet* queues,\n+                            TaskTerminator* terminator,\n+                            uint worker_id,\n+                            HeapRegionClaimer* pre_claimer,\n+                            HeapRegionClaimer* post_claimer);\n+\n+  void do_void();\n+};\n+\n+#endif \/\/SHARE_GC_G1_G1EVACFAILUREPARSCANSTATE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureParScanState.hpp","additions":78,"deletions":0,"binary":false,"changes":78,"status":"added"},{"patch":"@@ -0,0 +1,63 @@\n+\/*\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1EvacFailureParScanTask.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+\n+G1EvacFailureParScanTask::G1EvacFailureParScanTask(HeapRegion* region,\n+                                                   HeapWord* previous_obj,\n+                                                   uint start,\n+                                                   uint end,\n+                                                   bool last) :\n+  _region(region),\n+  _previous_object_end(previous_obj),\n+  _start(start),\n+  _end(end),\n+  _last(last) { }\n+\n+G1EvacFailureParScanTask::G1EvacFailureParScanTask(const G1EvacFailureParScanTask& o) {\n+  this->_region = o._region;\n+  this->_previous_object_end = o._previous_object_end;\n+  this->_start = o._start;\n+  this->_end = o._end;\n+  this->_last = o._last;\n+}\n+\n+G1EvacFailureParScanTask& G1EvacFailureParScanTask::operator=(const G1EvacFailureParScanTask& o) {\n+  this->_region = o._region;\n+  this->_previous_object_end = o._previous_object_end;\n+  this->_start = o._start;\n+  this->_end = o._end;\n+  this->_last = o._last;\n+  return *this;\n+}\n+\n+#ifdef ASSERT\n+void G1EvacFailureParScanTask::verify() {\n+    assert(_region != nullptr, \"must be\");\n+    assert(_start < _end, \"must be\");\n+    assert(_previous_object_end != nullptr, \"must be\");\n+  }\n+#endif \/\/ ASSERT\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureParScanTask.cpp","additions":63,"deletions":0,"binary":false,"changes":63,"status":"added"},{"patch":"@@ -0,0 +1,70 @@\n+\/*\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1EVACFAILUREPARSCANTASK_HPP\n+#define SHARE_GC_G1_G1EVACFAILUREPARSCANTASK_HPP\n+\n+#include \"gc\/shared\/taskqueue.hpp\"\n+#include \"memory\/allocation.hpp\"\n+\n+class HeapRegion;\n+\n+class G1EvacFailureParScanTask {\n+  friend class G1EvacFailureParScanState;\n+\n+  HeapRegion* _region;\n+  \/\/ The previous live object end before this task.\n+  \/\/ It could be bottom of the region if this task is the first part of an region.\n+  HeapWord* _previous_object_end;\n+  \/\/ Inclusive\n+  uint _start;\n+  \/\/ Exclusive\n+  uint _end;\n+  \/\/ If this is the task including the last part of an region.\n+  bool _last;\n+\n+public:\n+  G1EvacFailureParScanTask(HeapRegion* region = nullptr,\n+                           HeapWord* previous_obj = nullptr,\n+                           uint start = -1,\n+                           uint end = -1,\n+                           bool last = false);\n+\n+  G1EvacFailureParScanTask(const G1EvacFailureParScanTask& o);\n+\n+  G1EvacFailureParScanTask& operator=(const G1EvacFailureParScanTask& o);\n+\n+  HeapRegion* region() { return _region; }\n+  HeapWord* previous_object_end() { return _previous_object_end; }\n+  uint start() { return _start; }\n+  uint end() { return _end; }\n+  bool last() { return _last; }\n+\n+  DEBUG_ONLY(void verify();)\n+};\n+\n+typedef OverflowTaskQueue<G1EvacFailureParScanTask, mtGC> G1EvacFailureParScanTasksQueue;\n+typedef GenericTaskQueueSet<G1EvacFailureParScanTasksQueue, mtGC> G1EvacFailureParScanTasksQueueSet;\n+\n+#endif \/\/ SHARE_GC_G1_G1EVACFAILUREPARSCANTASK_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureParScanTask.hpp","additions":70,"deletions":0,"binary":false,"changes":70,"status":"added"},{"patch":"@@ -621,1 +621,1 @@\n-    r->record_evac_failure_obj(old);\n+    r->record_evac_failure_obj(old, word_sz);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -33,0 +33,3 @@\n+#include \"gc\/g1\/g1EvacFailureParScanState.hpp\"\n+#include \"gc\/g1\/g1EvacFailureParScanTask.hpp\"\n+#include \"gc\/g1\/g1EvacFailureRegions.hpp\"\n@@ -38,0 +41,1 @@\n+#include \"gc\/g1\/heapRegionManager.hpp\"\n@@ -39,0 +43,2 @@\n+#include \"gc\/shared\/taskqueue.inline.hpp\"\n+#include \"gc\/shared\/taskTerminator.hpp\"\n@@ -40,0 +46,1 @@\n+#include \"utilities\/stack.inline.hpp\"\n@@ -101,1 +108,2 @@\n-  G1ParRemoveSelfForwardPtrsTask _task;\n+  static const uint WORKER_COST_FACTOR = 5;\n+\n@@ -104,0 +112,17 @@\n+  HeapRegionClaimer _pre_hrclaimer;\n+  HeapRegionClaimer _post_hrclaimer;\n+\n+  const uint _worker_cost;\n+  uint _threads;\n+\n+  G1EvacFailureParScanTasksQueueSet* _task_queues;\n+  TaskTerminator _terminator;\n+\n+  void init_task_queues(uint length) {\n+    _task_queues = new G1EvacFailureParScanTasksQueueSet(length);\n+    for (uint i = 0; i < _task_queues->size(); i++) {\n+      G1EvacFailureParScanTasksQueue* q = new G1EvacFailureParScanTasksQueue();\n+      _task_queues->register_queue(i, q);\n+    }\n+  }\n+\n@@ -107,2 +132,22 @@\n-    _task(evac_failure_regions),\n-    _evac_failure_regions(evac_failure_regions) { }\n+    _evac_failure_regions(evac_failure_regions),\n+    _pre_hrclaimer(G1CollectedHeap::heap()->workers()->active_workers()),\n+    _post_hrclaimer(G1CollectedHeap::heap()->workers()->active_workers()),\n+    _worker_cost(_evac_failure_regions->num_regions_failed_evacuation() * WORKER_COST_FACTOR),\n+    _threads(0),\n+    _task_queues(nullptr),\n+    _terminator(_threads, _task_queues) {\n+  }\n+\n+  ~RemoveSelfForwardPtrsTask() {\n+    if (_task_queues == nullptr) return;\n+    for (uint i = 0; i < _task_queues->size(); i++) {\n+      delete _task_queues->queue(i);\n+    }\n+    delete _task_queues;\n+  }\n+\n+  void set_threads(uint threads) {\n+    _threads = threads;\n+    init_task_queues(_threads);\n+    _terminator.reset_for_reuse(_threads, _task_queues);\n+  }\n@@ -112,1 +157,1 @@\n-    return _evac_failure_regions->num_regions_failed_evacuation();\n+    return _worker_cost;\n@@ -116,1 +161,7 @@\n-    _task.work(worker_id);\n+    assert(G1CollectedHeap::heap()->workers()->active_workers() == _threads,\n+           \"must be, \" UINT32_FORMAT \", \" UINT32_FORMAT,\n+           G1CollectedHeap::heap()->workers()->active_workers(), _threads);\n+    assert(worker_id < _threads, \"must be\");\n+    assert(_threads == _task_queues->size(), \"must be\");\n+    G1EvacFailureParScanState scan_state(_evac_failure_regions, _task_queues, &_terminator, worker_id, &_pre_hrclaimer, &_post_hrclaimer);\n+    scan_state.do_void();\n@@ -131,0 +182,1 @@\n+  RemoveSelfForwardPtrsTask* remove_self_task = nullptr;\n@@ -132,1 +184,2 @@\n-    add_parallel_task(new RemoveSelfForwardPtrsTask(evac_failure_regions));\n+    remove_self_task = new RemoveSelfForwardPtrsTask(evac_failure_regions);\n+    add_parallel_task(remove_self_task);\n@@ -135,0 +188,4 @@\n+  if (evacuation_failed) {\n+    uint workers = MIN2(num_workers_estimate(), G1CollectedHeap::heap()->workers()->active_workers());\n+    remove_self_task->set_threads(workers);\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":63,"deletions":6,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"gc\/g1\/g1EvacFailure.hpp\"\n+#include \"gc\/g1\/g1EvacFailureParScanTask.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -110,2 +110,10 @@\n-void HeapRegion::process_and_drop_evac_failure_objs(ObjectClosure* closure) {\n-  _evac_failure_objs.process_and_drop(closure);\n+size_t HeapRegion::prepare_evac_failure_objs(G1EvacFailureParScanTasksQueue* queue) {\n+  return _evac_failure_objs.pre_iteration(queue);\n+}\n+\n+void HeapRegion::iterate_evac_failure_objs(ObjectClosure* closure, G1EvacFailureParScanTask& task) {\n+  _evac_failure_objs.iterate(closure, task);\n+}\n+\n+void HeapRegion::reset_evac_failure_objs() {\n+  _evac_failure_objs.post_iteration();\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/g1\/g1EvacFailureParScanTask.hpp\"\n@@ -168,1 +169,1 @@\n-  inline void update_bot_at(HeapWord* obj_start, size_t obj_size);\n+  inline void update_bot_at(HeapWord* obj_start, size_t obj_size, bool assert_old = true);\n@@ -171,2 +172,2 @@\n-  inline void update_bot_crossing_threshold(HeapWord** threshold, HeapWord* obj_start, HeapWord* obj_end);\n-  inline HeapWord* bot_threshold_for_addr(const void* addr);\n+  inline void update_bot_crossing_threshold(HeapWord** threshold, HeapWord* obj_start, HeapWord* obj_end, bool assert_old = true);\n+  inline HeapWord* bot_threshold_for_addr(const void* addr, bool assert_old = true);\n@@ -570,2 +571,6 @@\n-  void record_evac_failure_obj(oop obj);\n-  \/\/ Applies the given closure to all previously recorded objects\n+  void record_evac_failure_obj(oop obj, size_t word_size);\n+  \/\/ Prepare parallel iteration of all previously recorded objects\n+  \/\/ that failed evacuation.\n+  \/\/ Return live bytes in the evacuation failure region.\n+  size_t prepare_evac_failure_objs(G1EvacFailureParScanTasksQueue* queue);\n+  \/\/ Apply the given ObjectClosure to all previously recorded objects in the task\n@@ -573,1 +578,4 @@\n-  void process_and_drop_evac_failure_objs(ObjectClosure* closure);\n+  void iterate_evac_failure_objs(ObjectClosure* closure, G1EvacFailureParScanTask& task);\n+  \/\/ Release resources used in previous iteration of objects\n+  \/\/ that failed evacuation.\n+  void reset_evac_failure_objs();\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":14,"deletions":6,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -239,1 +239,1 @@\n-inline HeapWord* HeapRegion::bot_threshold_for_addr(const void* addr) {\n+inline HeapWord* HeapRegion::bot_threshold_for_addr(const void* addr, bool assert_old) {\n@@ -244,1 +244,1 @@\n-  assert(is_old(),\n+  assert(!assert_old || is_old(),\n@@ -250,2 +250,2 @@\n-inline void HeapRegion::update_bot_crossing_threshold(HeapWord** threshold, HeapWord* obj_start, HeapWord* obj_end) {\n-  assert(is_old(), \"should only do BOT updates for old regions\");\n+inline void HeapRegion::update_bot_crossing_threshold(HeapWord** threshold, HeapWord* obj_start, HeapWord* obj_end, bool assert_old) {\n+  assert(!assert_old || is_old(), \"should only do BOT updates for old regions\");\n@@ -259,2 +259,2 @@\n-inline void HeapRegion::update_bot_at(HeapWord* obj_start, size_t obj_size) {\n-  HeapWord* threshold = bot_threshold_for_addr(obj_start);\n+inline void HeapRegion::update_bot_at(HeapWord* obj_start, size_t obj_size, bool assert_old) {\n+  HeapWord* threshold = bot_threshold_for_addr(obj_start, assert_old);\n@@ -264,1 +264,1 @@\n-    update_bot_crossing_threshold(&threshold, obj_start, obj_end);\n+    update_bot_crossing_threshold(&threshold, obj_start, obj_end, assert_old);\n@@ -446,2 +446,2 @@\n-inline void HeapRegion::record_evac_failure_obj(oop obj) {\n-  _evac_failure_objs.record(obj);\n+inline void HeapRegion::record_evac_failure_obj(oop obj, size_t word_size) {\n+  _evac_failure_objs.record(obj, word_size);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":9,"deletions":9,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -63,0 +63,15 @@\n+void MarkBitMap::do_par_clear(MemRegion mr, bool large) {\n+  MemRegion intersection = mr.intersection(_covered);\n+  assert(!intersection.is_empty(),\n+         \"Given range from \" PTR_FORMAT \" to \" PTR_FORMAT \" is completely outside the heap\",\n+         p2i(mr.start()), p2i(mr.end()));\n+  \/\/ convert address range into offset range\n+  size_t beg = addr_to_offset(intersection.start());\n+  size_t end = addr_to_offset(intersection.end());\n+  if (large) {\n+    _bm.par_clear_range(beg, end, BitMap::large_range);\n+  } else {\n+    _bm.par_clear_range(beg, end, BitMap::small_range);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+  void do_par_clear(MemRegion mr, bool large);\n@@ -100,0 +101,3 @@\n+\n+  void par_clear_range(MemRegion mr)   { do_par_clear(mr, false);      }\n+  void par_clear_range_large(MemRegion mr) { do_par_clear(mr, true);       }\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -101,1 +101,1 @@\n-void TaskTerminator::reset_for_reuse(uint n_threads) {\n+void TaskTerminator::reset_for_reuse(uint n_threads, TaskQueueSetSuper* queue_set) {\n@@ -104,0 +104,3 @@\n+  if (queue_set != nullptr) {\n+    _queue_set = queue_set;\n+  }\n","filename":"src\/hotspot\/share\/gc\/shared\/taskTerminator.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -123,1 +123,1 @@\n-  void reset_for_reuse(uint n_threads);\n+  void reset_for_reuse(uint n_threads, TaskQueueSetSuper* queue_set = nullptr);\n","filename":"src\/hotspot\/share\/gc\/shared\/taskTerminator.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}