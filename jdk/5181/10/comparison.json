{"files":[{"patch":"@@ -73,24 +73,24 @@\n-    if (obj->is_forwarded() && obj->forwardee() == obj) {\n-      \/\/ The object failed to move.\n-\n-      zap_dead_objects(_last_forwarded_object_end, obj_addr);\n-      \/\/ We consider all objects that we find self-forwarded to be\n-      \/\/ live. What we'll do is that we'll update the prev marking\n-      \/\/ info so that they are all under PTAMS and explicitly marked.\n-      if (!_cm->is_marked_in_prev_bitmap(obj)) {\n-        _cm->mark_in_prev_bitmap(obj);\n-      }\n-      if (_during_concurrent_start) {\n-        \/\/ For the next marking info we'll only mark the\n-        \/\/ self-forwarded objects explicitly if we are during\n-        \/\/ concurrent start (since, normally, we only mark objects pointed\n-        \/\/ to by roots if we succeed in copying them). By marking all\n-        \/\/ self-forwarded objects we ensure that we mark any that are\n-        \/\/ still pointed to be roots. During concurrent marking, and\n-        \/\/ after concurrent start, we don't need to mark any objects\n-        \/\/ explicitly and all objects in the CSet are considered\n-        \/\/ (implicitly) live. So, we won't mark them explicitly and\n-        \/\/ we'll leave them over NTAMS.\n-        _cm->mark_in_next_bitmap(_worker_id, _hr, obj);\n-      }\n-      size_t obj_size = obj->size();\n+    \/\/ The object failed to move.\n+    assert(obj->is_forwarded() && obj->forwardee() == obj, \"sanity\");\n+\n+    zap_dead_objects(_last_forwarded_object_end, obj_addr);\n+    \/\/ We consider all objects that we find self-forwarded to be\n+    \/\/ live. What we'll do is that we'll update the prev marking\n+    \/\/ info so that they are all under PTAMS and explicitly marked.\n+    if (!_cm->is_marked_in_prev_bitmap(obj)) {\n+      _cm->mark_in_prev_bitmap(obj);\n+    }\n+    if (_during_concurrent_start) {\n+      \/\/ For the next marking info we'll only mark the\n+      \/\/ self-forwarded objects explicitly if we are during\n+      \/\/ concurrent start (since, normally, we only mark objects pointed\n+      \/\/ to by roots if we succeed in copying them). By marking all\n+      \/\/ self-forwarded objects we ensure that we mark any that are\n+      \/\/ still pointed to be roots. During concurrent marking, and\n+      \/\/ after concurrent start, we don't need to mark any objects\n+      \/\/ explicitly and all objects in the CSet are considered\n+      \/\/ (implicitly) live. So, we won't mark them explicitly and\n+      \/\/ we'll leave them over NTAMS.\n+      _cm->mark_in_next_bitmap(_worker_id, _hr, obj);\n+    }\n+    size_t obj_size = obj->size();\n@@ -98,2 +98,2 @@\n-      _marked_bytes += (obj_size * HeapWordSize);\n-      PreservedMarks::init_forwarded_mark(obj);\n+    _marked_bytes += (obj_size * HeapWordSize);\n+    PreservedMarks::init_forwarded_mark(obj);\n@@ -101,4 +101,3 @@\n-      HeapWord* obj_end = obj_addr + obj_size;\n-      _last_forwarded_object_end = obj_end;\n-      _hr->alloc_block_in_bot(obj_addr, obj_end);\n-    }\n+    HeapWord* obj_end = obj_addr + obj_size;\n+    _last_forwarded_object_end = obj_end;\n+    _hr->alloc_block_in_bot(obj_addr, obj_end);\n@@ -167,1 +166,2 @@\n-    hr->object_iterate(&rspc);\n+    \/\/ Iterates evac failure objs which are recorded during evacuation.\n+    hr->iterate_evac_failure_objs(&rspc);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":31,"deletions":31,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -0,0 +1,119 @@\n+\/*\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1EvacuationFailureObjsInHR.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"utilities\/quickSort.hpp\"\n+\n+\n+const uint G1EvacuationFailureObjsInHR::MaxBufferLength =\n+  static_cast<uint>(1u << (HeapRegion::LogOfHRGrainBytes-LogHeapWordSize));\n+\n+const G1SegmentedArrayAllocOptions G1EvacuationFailureObjsInHR::_alloc_options =\n+  G1SegmentedArrayAllocOptions(uint(sizeof (Elem)), BufferLength, UINT_MAX, Alignment);\n+G1SegmentedArrayBufferList<mtGC> G1EvacuationFailureObjsInHR::_free_buffer_list;\n+\n+void G1EvacuationFailureObjsInHR::visit_buffer(G1SegmentedArrayBuffer<mtGC>* node, uint limit) {\n+  node->copy_to(&_offset_array[_objs_num]);\n+  _objs_num += limit;\n+  \/\/ Verify elements in the buffer\n+  DEBUG_ONLY(node->iterate_elems(*this));\n+}\n+\n+void G1EvacuationFailureObjsInHR::visit_elem(void* elem) {\n+  uint* ptr = (uint*)elem;\n+  assert(*ptr < _max_offset, \"must be, %u\", *ptr);\n+}\n+\n+void G1EvacuationFailureObjsInHR::compact() {\n+  assert_at_safepoint();\n+  assert(_offset_array == NULL, \"must be\");\n+  uint num = _nodes_array.num_allocated_nodes();\n+  _offset_array = NEW_C_HEAP_ARRAY(Elem, num, mtGC);\n+  \/\/ Copy buffers' data to local array\n+  _nodes_array.iterate_nodes(*this);\n+  assert(_objs_num == num, \"must be %u, %u\", _objs_num, num);\n+  \/\/ We're at safepoint, no need to sync by GlobalCounter\n+  _nodes_array.drop_all();\n+}\n+\n+static int order_oop(G1EvacuationFailureObjsInHR::Elem a,\n+                     G1EvacuationFailureObjsInHR::Elem b) {\n+  return static_cast<int>(a-b);\n+}\n+\n+void G1EvacuationFailureObjsInHR::sort() {\n+  QuickSort::sort(_offset_array, _objs_num, order_oop, true);\n+}\n+\n+void G1EvacuationFailureObjsInHR::clear_array() {\n+  FREE_C_HEAP_ARRAY(Elem, _offset_array);\n+  _offset_array = NULL;\n+  _objs_num = 0;\n+}\n+\n+void G1EvacuationFailureObjsInHR::iterate_internal(ObjectClosure* closure) {\n+  Elem prev = 0;\n+  for (uint i = 0; i < _objs_num; i++) {\n+    assert(i == 0 ? (prev <= _offset_array[i]) : (prev < _offset_array[i]),\n+           \"must be, %u, %u, %u\", i, prev, _offset_array[i]);\n+    assert(prev < _max_offset, \"must be, %u\", prev);\n+    closure->do_object(cast_from_offset(prev = _offset_array[i]));\n+  }\n+  clear_array();\n+}\n+\n+G1EvacuationFailureObjsInHR::G1EvacuationFailureObjsInHR(uint region_idx, HeapWord* bottom) :\n+  _max_offset(static_cast<Elem>(1u << (HeapRegion::LogOfHRGrainBytes-LogHeapWordSize))),\n+  _region_idx(region_idx),\n+  _bottom(bottom),\n+  _nodes_array(\"\", &_alloc_options, &_free_buffer_list),\n+  _offset_array(NULL),\n+  _objs_num(0) {\n+  assert(HeapRegion::LogOfHRGrainBytes < 32, \"must be\");\n+}\n+\n+G1EvacuationFailureObjsInHR::~G1EvacuationFailureObjsInHR() {\n+  assert(_offset_array == NULL, \"must be\");\n+}\n+\n+void G1EvacuationFailureObjsInHR::record(oop obj) {\n+  assert(obj != NULL, \"must be\");\n+  assert(_region_idx == G1CollectedHeap::heap()->heap_region_containing(obj)->hrm_index(), \"must be\");\n+  Elem offset = cast_from_oop_addr(obj);\n+  assert(obj == cast_from_offset(offset), \"must be\");\n+  assert(offset < _max_offset, \"must be, %u\", offset);\n+  Elem* e = _nodes_array.allocate();\n+  *e = offset;\n+}\n+\n+void G1EvacuationFailureObjsInHR::iterate(ObjectClosure* closure) {\n+  compact();\n+  sort();\n+  iterate_internal(closure);\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacuationFailureObjsInHR.cpp","additions":119,"deletions":0,"binary":false,"changes":119,"status":"added"},{"patch":"@@ -0,0 +1,94 @@\n+\/*\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1EVACUATIONFAILUREOBJSINHR_HPP\n+#define SHARE_GC_G1_G1EVACUATIONFAILUREOBJSINHR_HPP\n+\n+#include \"gc\/g1\/g1SegmentedArray.hpp\"\n+#include \"memory\/iterator.hpp\"\n+#include \"oops\/oop.hpp\"\n+\n+\/\/ This class\n+\/\/   1. records the objects per region which have failed to evacuate.\n+\/\/   2. speeds up removing self forwarded ptrs in post evacuation phase.\n+\/\/\n+class G1EvacuationFailureObjsInHR {\n+\n+public:\n+  typedef uint Elem;\n+\n+private:\n+  static const uint BufferLength = 256;\n+  static const uint MaxBufferLength;\n+  static const uint Alignment = 4;\n+\n+  static const G1SegmentedArrayAllocOptions _alloc_options;\n+  \/\/ This free list is shared among evacuation failure process in all regions.\n+  static G1SegmentedArrayBufferList<mtGC> _free_buffer_list;\n+\n+  const Elem _max_offset;\n+  const uint _region_idx;\n+  const HeapWord* _bottom;\n+\n+  \/\/ To improve space efficiency, elements are offset rather than raw addr\n+  G1SegmentedArray<Elem, mtGC> _nodes_array;\n+  \/\/ Local array contains the _nodes_array data in flat layout\n+  Elem* _offset_array;\n+  uint _objs_num;\n+\n+private:\n+  oop cast_from_offset(Elem offset) {\n+    return cast_to_oop(_bottom + offset);\n+  }\n+  Elem cast_from_oop_addr(oop obj) {\n+    const HeapWord* o = cast_from_oop<const HeapWord*>(obj);\n+    size_t offset = pointer_delta(o, _bottom);\n+    return static_cast<Elem>(offset);\n+  }\n+\n+  \/\/ Copy buffers' data to local array, must be called at safepoint\n+  void compact();\n+  void sort();\n+  void clear_array();\n+  \/\/ Iterate through evac failure objects in local array\n+  void iterate_internal(ObjectClosure* closure);\n+\n+public:\n+  G1EvacuationFailureObjsInHR(uint region_idx, HeapWord* bottom);\n+  ~G1EvacuationFailureObjsInHR();\n+\n+  \/\/ Record an evac failure object\n+  void record(oop obj);\n+  \/\/ Iterate through evac failure objects\n+  void iterate(ObjectClosure* closure);\n+\n+  \/\/ Copy a buffer data to local array\n+  void visit_buffer(G1SegmentedArrayBuffer<mtGC>* node, uint limit);\n+\n+  \/\/ Verify elements in the buffer\n+  void visit_elem(void* elem);\n+};\n+\n+\n+#endif \/\/SHARE_GC_G1_G1EVACUATIONFAILUREOBJSINHR_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacuationFailureObjsInHR.hpp","additions":94,"deletions":0,"binary":false,"changes":94,"status":"added"},{"patch":"@@ -610,0 +610,3 @@\n+    \/\/ Records evac failure objs, this will help speed up iteration\n+    \/\/ of these objs later in *remove self forward* phase of post evacuation.\n+    r->record_evac_failure_obj(old);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -76,0 +76,13 @@\n+  uint length() const {\n+    \/\/ _next_allocate might grow greater than _num_elems in multi-thread env,\n+    \/\/ so, here we need to return the adjusted real length value.\n+    return _next_allocate > _num_elems ? _num_elems : _next_allocate;\n+  }\n+\n+  void copy_to(void* dest) const {\n+    ::memcpy(dest, _buffer, length() * _elem_size);\n+  }\n+\n+  template<typename Visitor>\n+  void iterate_elems(Visitor& v) const;\n+\n@@ -193,0 +206,2 @@\n+  DEBUG_ONLY(uint calculate_length() const;)\n+\n@@ -197,1 +212,5 @@\n-  uint num_allocated_nodes() const { return Atomic::load(&_num_allocated_nodes); }\n+  uint num_allocated_nodes() const {\n+    uint allocated = Atomic::load(&_num_allocated_nodes);\n+    assert(calculate_length() == allocated, \"Must be\");\n+    return allocated;\n+  }\n@@ -215,0 +234,3 @@\n+\n+  template<typename Visitor>\n+  void iterate_nodes(Visitor& v) const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.hpp","additions":23,"deletions":1,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -58,0 +58,9 @@\n+template<MEMFLAGS flag>\n+template<typename Visitor>\n+void G1SegmentedArrayBuffer<flag>::iterate_elems(Visitor& v) const {\n+  for (uint i = 0; i < length(); i++) {\n+    void* ptr = _buffer + i * _elem_size;\n+    v.visit_elem(ptr);\n+  }\n+}\n+\n@@ -236,0 +245,39 @@\n+#ifdef ASSERT\n+template <MEMFLAGS flag>\n+class LengthVisitor {\n+  uint _total;\n+public:\n+  LengthVisitor() : _total(0) {}\n+  void visit_buffer(G1SegmentedArrayBuffer<flag>* node, uint limit) {\n+    _total += limit;\n+  }\n+  uint length() const {\n+    return _total;\n+  }\n+};\n+\n+template <class Elem, MEMFLAGS flag>\n+uint G1SegmentedArray<Elem, flag>::calculate_length() const {\n+  LengthVisitor<flag> v;\n+  iterate_nodes(v);\n+  return v.length();\n+}\n+#endif\n+\n+template <class Elem, MEMFLAGS flag>\n+template <typename Visitor>\n+void G1SegmentedArray<Elem, flag>::iterate_nodes(Visitor& v) const {\n+  G1SegmentedArrayBuffer<flag>* cur = Atomic::load_acquire(&_first);\n+\n+  if (cur != nullptr) {\n+    assert(_last != nullptr, \"If there is at least one element, there must be a last one.\");\n+\n+    while (cur != nullptr) {\n+      uint limit = cur->length();\n+      v.visit_buffer(cur, limit);\n+\n+      cur = cur->next();\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.inline.hpp","additions":48,"deletions":0,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -111,0 +111,8 @@\n+void HeapRegion::record_evac_failure_obj(oop obj) {\n+  _evac_failure_objs.record(obj);\n+}\n+\n+void HeapRegion::iterate_evac_failure_objs(ObjectClosure* closure) {\n+  _evac_failure_objs.iterate(closure);\n+}\n+\n@@ -251,1 +259,2 @@\n-  _node_index(G1NUMA::UnknownNodeIndex)\n+  _node_index(G1NUMA::UnknownNodeIndex),\n+  _evac_failure_objs(hrm_index, _bottom)\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1EvacuationFailureObjsInHR.hpp\"\n@@ -261,0 +262,2 @@\n+  G1EvacuationFailureObjsInHR _evac_failure_objs;\n+\n@@ -557,0 +560,5 @@\n+  \/\/ Records evac failure objs during evaucation, this will help speed up iteration\n+  \/\/ of these objs later in *remove self forward* phase of post evacuation.\n+  void record_evac_failure_obj(oop obj);\n+  \/\/ Iterates evac failure objs which are recorded during evcauation.\n+  void iterate_evac_failure_objs(ObjectClosure* closure);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"}]}