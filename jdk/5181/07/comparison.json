{"files":[{"patch":"@@ -73,24 +73,24 @@\n-    if (obj->is_forwarded() && obj->forwardee() == obj) {\n-      \/\/ The object failed to move.\n-\n-      zap_dead_objects(_last_forwarded_object_end, obj_addr);\n-      \/\/ We consider all objects that we find self-forwarded to be\n-      \/\/ live. What we'll do is that we'll update the prev marking\n-      \/\/ info so that they are all under PTAMS and explicitly marked.\n-      if (!_cm->is_marked_in_prev_bitmap(obj)) {\n-        _cm->mark_in_prev_bitmap(obj);\n-      }\n-      if (_during_concurrent_start) {\n-        \/\/ For the next marking info we'll only mark the\n-        \/\/ self-forwarded objects explicitly if we are during\n-        \/\/ concurrent start (since, normally, we only mark objects pointed\n-        \/\/ to by roots if we succeed in copying them). By marking all\n-        \/\/ self-forwarded objects we ensure that we mark any that are\n-        \/\/ still pointed to be roots. During concurrent marking, and\n-        \/\/ after concurrent start, we don't need to mark any objects\n-        \/\/ explicitly and all objects in the CSet are considered\n-        \/\/ (implicitly) live. So, we won't mark them explicitly and\n-        \/\/ we'll leave them over NTAMS.\n-        _cm->mark_in_next_bitmap(_worker_id, _hr, obj);\n-      }\n-      size_t obj_size = obj->size();\n+    \/\/ The object failed to move.\n+    assert(obj->is_forwarded() && obj->forwardee() == obj, \"sanity\");\n+\n+    zap_dead_objects(_last_forwarded_object_end, obj_addr);\n+    \/\/ We consider all objects that we find self-forwarded to be\n+    \/\/ live. What we'll do is that we'll update the prev marking\n+    \/\/ info so that they are all under PTAMS and explicitly marked.\n+    if (!_cm->is_marked_in_prev_bitmap(obj)) {\n+      _cm->mark_in_prev_bitmap(obj);\n+    }\n+    if (_during_concurrent_start) {\n+      \/\/ For the next marking info we'll only mark the\n+      \/\/ self-forwarded objects explicitly if we are during\n+      \/\/ concurrent start (since, normally, we only mark objects pointed\n+      \/\/ to by roots if we succeed in copying them). By marking all\n+      \/\/ self-forwarded objects we ensure that we mark any that are\n+      \/\/ still pointed to be roots. During concurrent marking, and\n+      \/\/ after concurrent start, we don't need to mark any objects\n+      \/\/ explicitly and all objects in the CSet are considered\n+      \/\/ (implicitly) live. So, we won't mark them explicitly and\n+      \/\/ we'll leave them over NTAMS.\n+      _cm->mark_in_next_bitmap(_worker_id, _hr, obj);\n+    }\n+    size_t obj_size = obj->size();\n@@ -98,2 +98,2 @@\n-      _marked_bytes += (obj_size * HeapWordSize);\n-      PreservedMarks::init_forwarded_mark(obj);\n+    _marked_bytes += (obj_size * HeapWordSize);\n+    PreservedMarks::init_forwarded_mark(obj);\n@@ -101,4 +101,3 @@\n-      HeapWord* obj_end = obj_addr + obj_size;\n-      _last_forwarded_object_end = obj_end;\n-      _hr->alloc_block_in_bot(obj_addr, obj_end);\n-    }\n+    HeapWord* obj_end = obj_addr + obj_size;\n+    _last_forwarded_object_end = obj_end;\n+    _hr->cross_threshold(obj_addr, obj_end);\n@@ -167,1 +166,2 @@\n-    hr->object_iterate(&rspc);\n+    \/\/ Iterates evac failure objs which are recorded during evacuation.\n+    hr->iterate_evac_failure_objs(&rspc);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":31,"deletions":31,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -0,0 +1,109 @@\n+\/*\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"g1EvacuationFailureObjsInHR.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"utilities\/quickSort.hpp\"\n+\n+\n+\n+\/\/ === G1EvacuationFailureObjsInHR ===\n+\n+void G1EvacuationFailureObjsInHR::visit(Elem elem) {\n+  uint32_t offset = elem;\n+  _offset_array[_objs_num++] = offset;\n+}\n+\n+void G1EvacuationFailureObjsInHR::visit(Array<NODE_LENGTH, Elem>::NODE_XXX* node, uint32_t limit) {\n+  ::memcpy(&_offset_array[_objs_num], node->_oop_offsets, limit * sizeof(Elem));\n+  _objs_num += limit;\n+}\n+\n+void G1EvacuationFailureObjsInHR::compact() {\n+  assert(_offset_array == NULL, \"must be\");\n+  _offset_array = NEW_C_HEAP_ARRAY(Elem, _nodes_array.objs_num(), mtGC);\n+  \/\/ _nodes_array.iterate_elements(this);\n+  _nodes_array.iterate_nodes(this);\n+  uint expected = _nodes_array.objs_num();\n+  assert(_objs_num == expected, \"must be %u, %u\", _objs_num, expected);\n+  _nodes_array.reset();\n+}\n+\n+static int order_oop(G1EvacuationFailureObjsInHR::Elem a,\n+                     G1EvacuationFailureObjsInHR::Elem b) {\n+  return static_cast<int>(a-b);\n+}\n+\n+void G1EvacuationFailureObjsInHR::sort() {\n+  QuickSort::sort(_offset_array, _objs_num, order_oop, true);\n+}\n+\n+void G1EvacuationFailureObjsInHR::clear_array() {\n+  FREE_C_HEAP_ARRAY(Elem, _offset_array);\n+  _offset_array = NULL;\n+  _objs_num = 0;\n+}\n+\n+void G1EvacuationFailureObjsInHR::iterate_internal(ObjectClosure* closure) {\n+  Elem prev = 0;\n+  for (uint i = 0; i < _objs_num; i++) {\n+    assert(i == 0 ? (prev <= _offset_array[i]) : (prev < _offset_array[i]),\n+           \"must be, %u, %u, %u\", i, prev, _offset_array[i]);\n+    assert(prev < _max_offset, \"must be, %u\", prev);\n+    closure->do_object(cast_from_offset(prev = _offset_array[i]));\n+  }\n+  clear_array();\n+}\n+\n+G1EvacuationFailureObjsInHR::G1EvacuationFailureObjsInHR(uint region_idx, HeapWord* bottom) :\n+  _max_offset(static_cast<Elem>(1u << (HeapRegion::LogOfHRGrainBytes-LogHeapWordSize))),\n+  _region_idx(region_idx),\n+  _bottom(bottom),\n+  _nodes_array(static_cast<uint32_t>(HeapRegion::GrainWords) \/ NODE_LENGTH + 2u),\n+  _offset_array(NULL),\n+  _objs_num(0) {\n+  assert(HeapRegion::LogOfHRGrainBytes < 32, \"must be\");\n+}\n+\n+G1EvacuationFailureObjsInHR::~G1EvacuationFailureObjsInHR() {\n+  assert(_offset_array == NULL, \"must be\");\n+}\n+\n+void G1EvacuationFailureObjsInHR::record(oop obj) {\n+  assert(obj != NULL, \"must be\");\n+  assert(_region_idx == G1CollectedHeap::heap()->heap_region_containing(obj)->hrm_index(), \"must be\");\n+  Elem offset = cast_from_oop_addr(obj);\n+  assert(obj == cast_from_offset(offset), \"must be\");\n+  assert(offset < _max_offset, \"must be, %u\", offset);\n+  _nodes_array.add(offset);\n+}\n+\n+void G1EvacuationFailureObjsInHR::iterate(ObjectClosure* closure) {\n+  compact();\n+  sort();\n+  iterate_internal(closure);\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacuationFailureObjsInHR.cpp","additions":109,"deletions":0,"binary":false,"changes":109,"status":"added"},{"patch":"@@ -0,0 +1,254 @@\n+\/*\n+ * Copyright (c) 2021, Huawei and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1EVACUATIONFAILUREOBJSINHR_HPP\n+#define SHARE_GC_G1_G1EVACUATIONFAILUREOBJSINHR_HPP\n+\n+#include \"memory\/iterator.hpp\"\n+#include \"oops\/oop.hpp\"\n+\n+\/\/ This class\n+\/\/   1. records the objects per region which have failed to evacuate.\n+\/\/   2. speeds up removing self forwarded ptrs in post evacuation phase.\n+\/\/\n+class G1EvacuationFailureObjsInHR {\n+  template<uint32_t LEN, typename Elem>\n+  class Array;\n+\n+\n+  \/\/ === Node ===\n+\n+  template<uint32_t LEN, typename Elem>\n+  class Node : public CHeapObj<mtGC>{\n+    friend G1EvacuationFailureObjsInHR;\n+    friend Array<LEN, Elem>;\n+\n+  private:\n+    static const uint32_t LENGTH = LEN;\n+    static const size_t SIZE = LENGTH * sizeof(Elem);\n+    Elem* _oop_offsets;\n+\n+  public:\n+    Node() {\n+      _oop_offsets = (Elem*)AllocateHeap(SIZE, mtGC);\n+    }\n+    Elem& operator[] (size_t idx) {\n+      return _oop_offsets[idx];\n+    }\n+    static Node<LEN, Elem>* create_node() {\n+      return new Node<LEN, Elem>();\n+    }\n+    static void free_node(Node<LEN, Elem>* node) {\n+      assert(node != NULL, \"must be\");\n+      FreeHeap(node->_oop_offsets);\n+      delete node;\n+    }\n+  };\n+\n+\n+  \/\/ === Array ===\n+\n+  template<uint32_t NODE_SIZE, typename Elem>\n+  class Array : public CHeapObj<mtGC> {\n+  public:\n+    typedef Node<NODE_SIZE, Elem> NODE_XXX;\n+\n+  private:\n+    const uint64_t low_mask;\n+    const uint64_t high_mask;\n+    const uint32_t _max_nodes_length;\n+\n+    volatile uint64_t _cur_pos;\n+    NODE_XXX* volatile * _nodes;\n+    volatile uint _elements_num;\n+\n+  private:\n+    uint64_t low(uint64_t n) {\n+      return (n & low_mask);\n+    }\n+    uint64_t high(uint64_t n) {\n+      return (n & high_mask);\n+    }\n+    uint32_t elem_index(uint64_t n) {\n+      assert(low(n) < NODE_XXX::LENGTH, \"must be\");\n+      return low(n);\n+    }\n+    uint32_t node_index(uint64_t n) {\n+      uint32_t hi = high(n) >> 32;\n+      assert(hi < _max_nodes_length, \"must be\");\n+      return hi;\n+    }\n+\n+    uint64_t next(uint64_t n) {\n+      uint64_t lo = low(n);\n+      uint64_t hi = high(n);\n+      assert((lo < NODE_XXX::LENGTH) && (NODE_XXX::LENGTH <= low_mask), \"must be\");\n+      assert(hi < high_mask, \"must be\");\n+      if ((lo+1) == NODE_XXX::LENGTH) {\n+        lo = 0;\n+        hi += ((uint64_t)1 << 32);\n+      } else {\n+        lo++;\n+      }\n+      assert(hi <= high_mask, \"must be\");\n+      return hi | lo;\n+    }\n+\n+  public:\n+    Array(uint32_t max_nodes_length) :\n+      low_mask(((uint64_t)1 << 32) - 1),\n+      high_mask(low_mask << 32),\n+      _max_nodes_length(max_nodes_length) {\n+\n+      _nodes = (NODE_XXX**)AllocateHeap(_max_nodes_length * sizeof(NODE_XXX*), mtGC);\n+      for (uint32_t i = 0; i < _max_nodes_length; i++) {\n+        Atomic::store(&_nodes[i], (NODE_XXX *)NULL);\n+      }\n+\n+      Atomic::store(&_elements_num, 0u);\n+      Atomic::store(&_cur_pos, (uint64_t)0);\n+    }\n+\n+    ~Array() {\n+      assert(_nodes != NULL, \"must be\");\n+      reset();\n+      FreeHeap((NODE_XXX**)_nodes);\n+    }\n+\n+    uint objs_num() {\n+      return Atomic::load(&_elements_num);\n+    }\n+\n+    void add(Elem elem) {\n+      while (true) {\n+        uint64_t pos = Atomic::load(&_cur_pos);\n+        uint64_t next_pos = next(pos);\n+        uint64_t res = Atomic::cmpxchg(&_cur_pos, pos, next_pos);\n+        if (res == pos) {\n+          uint32_t hi = node_index(pos);\n+          uint32_t lo = elem_index(pos);\n+          if (lo == 0) {\n+            Atomic::store(&_nodes[hi], NODE_XXX::create_node());\n+          }\n+          NODE_XXX* node = NULL;\n+          while ((node = Atomic::load(&_nodes[hi])) == NULL);\n+\n+          node->operator[](lo) = elem;\n+          Atomic::inc(&_elements_num);\n+          break;\n+        }\n+      }\n+    }\n+\n+    template<typename VISITOR>\n+    void iterate_elements(VISITOR v) {\n+      int64_t pos = Atomic::load(&_cur_pos);\n+      DEBUG_ONLY(uint total = 0);\n+      uint32_t hi = node_index(pos);\n+      uint32_t lo = elem_index(pos);\n+      for (uint32_t i = 0; i <= hi; i++) {\n+        uint32_t limit = (i == hi) ? lo : NODE_XXX::LENGTH;\n+        NODE_XXX* node = Atomic::load(&_nodes[i]);\n+        for (uint32_t j = 0; j < limit; j++) {\n+          v->visit(node->operator[](j));\n+          DEBUG_ONLY(total++);\n+        }\n+      }\n+      assert(total == Atomic::load(&_elements_num), \"must be\");\n+    }\n+\n+    template<typename VISITOR>\n+    void iterate_nodes(VISITOR v) {\n+      int64_t pos = Atomic::load(&_cur_pos);\n+      uint32_t hi = node_index(pos);\n+      uint32_t lo = elem_index(pos);\n+      for (uint32_t i = 0; i <= hi; i++) {\n+        NODE_XXX* node = Atomic::load(&_nodes[i]);\n+        uint32_t limit = (i == hi) ? lo : NODE_XXX::LENGTH;\n+        if (limit == 0) {\n+          break;\n+        }\n+        v->visit(node, limit);\n+      }\n+    }\n+\n+    void reset() {\n+      int64_t pos = Atomic::load(&_cur_pos);\n+      uint32_t hi = node_index(pos);\n+      uint32_t lo = elem_index(pos);\n+      for (uint32_t i = 0; i <= hi; i++) {\n+        NODE_XXX* node = Atomic::load(&_nodes[i]);\n+        assert(node != NULL || ((i == hi) && (lo == 0)), \"must be\");\n+        if (node == NULL) {\n+          break;\n+        }\n+        NODE_XXX::free_node(node);\n+        Atomic::store(&_nodes[i], (NODE_XXX *)NULL);\n+      }\n+      Atomic::store(&_elements_num, 0u);\n+      Atomic::store(&_cur_pos, (uint64_t)0);\n+    }\n+  };\n+\n+\n+  \/\/ === G1EvacuationFailureObjsInHR ===\n+\n+public:\n+  typedef uint32_t Elem;\n+\n+private:\n+  static const uint32_t NODE_LENGTH = 256;\n+  const Elem _max_offset;\n+  const uint _region_idx;\n+  const HeapWord* _bottom;\n+  Array<NODE_LENGTH, Elem> _nodes_array;\n+  Elem* _offset_array;\n+  uint _objs_num;\n+\n+private:\n+  oop cast_from_offset(Elem offset) {\n+    return cast_to_oop(_bottom + offset);\n+  }\n+  Elem cast_from_oop_addr(oop obj) {\n+    const HeapWord* o = cast_from_oop<const HeapWord*>(obj);\n+    size_t offset = pointer_delta(o, _bottom);\n+    return static_cast<Elem>(offset);\n+  }\n+  void visit(Elem);\n+  void visit(Array<NODE_LENGTH, Elem>::NODE_XXX* node, uint32_t limit);\n+  void compact();\n+  void sort();\n+  void clear_array();\n+  void iterate_internal(ObjectClosure* closure);\n+\n+public:\n+  G1EvacuationFailureObjsInHR(uint region_idx, HeapWord* bottom);\n+  ~G1EvacuationFailureObjsInHR();\n+\n+  void record(oop obj);\n+  void iterate(ObjectClosure* closure);\n+};\n+\n+\n+#endif \/\/SHARE_GC_G1_G1EVACUATIONFAILUREOBJSINHR_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacuationFailureObjsInHR.hpp","additions":254,"deletions":0,"binary":false,"changes":254,"status":"added"},{"patch":"@@ -610,0 +610,3 @@\n+    \/\/ Records evac failure objs, this will help speed up iteration\n+    \/\/ of these objs later in *remove self forward* phase of post evacuation.\n+    r->record_evac_failure_obj(old);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -111,0 +111,8 @@\n+void HeapRegion::record_evac_failure_obj(oop obj) {\n+  _evac_failure_objs.record(obj);\n+}\n+\n+void HeapRegion::iterate_evac_failure_objs(ObjectClosure* closure) {\n+  _evac_failure_objs.iterate(closure);\n+}\n+\n@@ -251,1 +259,2 @@\n-  _node_index(G1NUMA::UnknownNodeIndex)\n+  _node_index(G1NUMA::UnknownNodeIndex),\n+  _evac_failure_objs(hrm_index, _bottom)\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1EvacuationFailureObjsInHR.hpp\"\n@@ -261,0 +262,2 @@\n+  G1EvacuationFailureObjsInHR _evac_failure_objs;\n+\n@@ -557,0 +560,5 @@\n+  \/\/ Records evac failure objs during evaucation, this will help speed up iteration\n+  \/\/ of these objs later in *remove self forward* phase of post evacuation.\n+  void record_evac_failure_obj(oop obj);\n+  \/\/ Iterates evac failure objs which are recorded during evcauation.\n+  void iterate_evac_failure_objs(ObjectClosure* closure);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"}]}