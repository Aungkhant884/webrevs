{"files":[{"patch":"@@ -17111,92 +17111,0 @@\n-%}\n-\n-instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MaxReductionV fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"fmaxs $dst, $fsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 1\\n\\t\"\n-            \"fmaxs $dst, $dst, $tmp\\t# max reduction2F\" %}\n-  ins_encode %{\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MaxReductionV fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"fmaxv $dst, T4S, $vsrc\\n\\t\"\n-            \"fmaxs $dst, $dst, $fsrc\\t# max reduction4F\" %}\n-  ins_encode %{\n-    __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (MaxReductionV dsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"fmaxd $dst, $dsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, D, $vsrc, 0, 1\\n\\t\"\n-            \"fmaxd $dst, $dst, $tmp\\t# max reduction2D\" %}\n-  ins_encode %{\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc, vecD tmp) %{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MinReductionV fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"fmins $dst, $fsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, S, $vsrc, 0, 1\\n\\t\"\n-            \"fmins $dst, $dst, $tmp\\t# min reduction2F\" %}\n-  ins_encode %{\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ S, as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n-  match(Set dst (MinReductionV fsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst);\n-  format %{ \"fminv $dst, T4S, $vsrc\\n\\t\"\n-            \"fmins $dst, $dst, $fsrc\\t# min reduction4F\" %}\n-  ins_encode %{\n-    __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n-%}\n-\n-instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc, vecX tmp) %{\n-  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n-  match(Set dst (MinReductionV dsrc vsrc));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP tmp);\n-  format %{ \"fmind $dst, $dsrc, $vsrc\\n\\t\"\n-            \"ins   $tmp, D, $vsrc, 0, 1\\n\\t\"\n-            \"fmind $dst, $dst, $tmp\\t# min reduction2D\" %}\n-  ins_encode %{\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg), as_FloatRegister($vsrc$$reg));\n-    __ ins(as_FloatRegister($tmp$$reg), __ D, as_FloatRegister($vsrc$$reg), 0, 1);\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($tmp$$reg));\n-  %}\n-  ins_pipe(pipe_class_default);\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":0,"deletions":92,"binary":false,"changes":92,"status":"modified"},{"patch":"@@ -902,0 +902,84 @@\n+instruct reduce_max2F(vRegF dst, vRegF fsrc, vecD vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (MaxReductionV fsrc vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"fmaxp $dst, $vsrc, S\\n\\t\"\n+            \"fmaxs $dst, $dst, $fsrc\\t# max reduction2F\" %}\n+  ins_encode %{\n+    __ fmaxp(as_FloatRegister($dst$$reg), as_FloatRegister($vsrc$$reg), __ S);\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct reduce_max4F(vRegF dst, vRegF fsrc, vecX vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (MaxReductionV fsrc vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"fmaxv $dst,  T4S, $vsrc\\n\\t\"\n+            \"fmaxs $dst, $dst, $fsrc\\t# max reduction4F\" %}\n+  ins_encode %{\n+    __ fmaxv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));\n+    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct reduce_max2D(vRegD dst, vRegD dsrc, vecX vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (MaxReductionV dsrc vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"fmaxp $dst, $vsrc, D\\n\\t\"\n+            \"fmaxd $dst, $dst, $dsrc\\t# max reduction2D\" %}\n+  ins_encode %{\n+    __ fmaxp(as_FloatRegister($dst$$reg), as_FloatRegister($vsrc$$reg), __ D);\n+    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct reduce_min2F(vRegF dst, vRegF fsrc, vecD vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (MinReductionV fsrc vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"fminp $dst, $vsrc, S\\n\\t\"\n+            \"fmins $dst, $dst, $fsrc\\t# min reduction2F\" %}\n+  ins_encode %{\n+    __ fminp(as_FloatRegister($dst$$reg), as_FloatRegister($vsrc$$reg), __ S);\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct reduce_min4F(vRegF dst, vRegF fsrc, vecX vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n+  match(Set dst (MinReductionV fsrc vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"fminv $dst,  T4S, $vsrc\\n\\t\"\n+            \"fmins $dst, $dst, $fsrc\\t# min reduction4F\" %}\n+  ins_encode %{\n+    __ fminv(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($vsrc$$reg));\n+    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($fsrc$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct reduce_min2D(vRegD dst, vRegD dsrc, vecX vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n+  match(Set dst (MinReductionV dsrc vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"fminp $dst, $vsrc, D\\n\\t\"\n+            \"fmind $dst, $dst, $dsrc\\t# min reduction2D\" %}\n+  ins_encode %{\n+    __ fminp(as_FloatRegister($dst$$reg), as_FloatRegister($vsrc$$reg), __ D);\n+    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($dsrc$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":84,"deletions":0,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -539,0 +539,24 @@\n+define(`REDUCE_MINMAX_FORD', `\n+instruct reduce_$1$4$5(vReg$5 dst, vReg$5 $6src, vec$7 vsrc) %{\n+  predicate(n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_`'ifelse($5, F, FLOAT, DOUBLE));\n+  match(Set dst (ifelse($1, max, Max, Min)ReductionV $6src vsrc));\n+  ins_cost(INSN_COST);\n+  effect(TEMP_DEF dst);\n+  format %{ \"$2 $dst, ifelse($4, 2, $vsrc`, 'ifelse($5, F, S, D), ` T4S, $vsrc')\\n\\t\"\n+            \"$3 $dst, $dst, $$6src\\t# $1 reduction$4$5\" %}\n+  ins_encode %{\n+    __ $2(as_FloatRegister($dst$$reg), ifelse($4, 4, `__ T4S, as_FloatRegister($vsrc$$reg))',\n+                                              $4$5, 2F, `as_FloatRegister($vsrc$$reg), __ S)',\n+                                              $4$5, 2D, `as_FloatRegister($vsrc$$reg), __ D)');\n+    __ $3(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($$6src$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}')dnl\n+dnl                $1   $2     $3     $4 $5 $6 $7\n+REDUCE_MINMAX_FORD(max, fmaxp, fmaxs, 2, F, f, D)\n+REDUCE_MINMAX_FORD(max, fmaxv, fmaxs, 4, F, f, X)\n+REDUCE_MINMAX_FORD(max, fmaxp, fmaxd, 2, D, d, X)\n+REDUCE_MINMAX_FORD(min, fminp, fmins, 2, F, f, D)\n+REDUCE_MINMAX_FORD(min, fminv, fmins, 4, F, f, X)\n+REDUCE_MINMAX_FORD(min, fminp, fmind, 2, D, d, X)\n+dnl\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -2638,8 +2638,7 @@\n-  \/\/ (Floating-point) {a, b} -> (a + b)\n-  void faddp(FloatRegister Vd, FloatRegister Vn, SIMD_RegVariant type) {\n-    assert(type == D || type == S, \"Wrong type for faddp\");\n-    starti;\n-    f(0b011111100, 31, 23);\n-    f(type == D ? 1 : 0, 22);\n-    f(0b110000110110, 21, 10);\n-    rf(Vn, 5), rf(Vd, 0);\n+  \/\/ Floating-point AdvSIMD scalar pairwise\n+#define INSN(NAME, op1, op2) \\\n+  void NAME(FloatRegister Vd, FloatRegister Vn, SIMD_RegVariant type) {                 \\\n+    starti;                                                                             \\\n+    assert(type == D || type == S, \"Wrong type for faddp\/fmaxp\/fminp\");                 \\\n+    f(0b0111111, 31, 25), f(op1, 24, 23),                                               \\\n+    f(type == S ? 0 : 1, 22), f(0b11000, 21, 17), f(op2, 16, 10), rf(Vn, 5), rf(Vd, 0); \\\n@@ -2648,0 +2647,6 @@\n+  INSN(faddp, 0b00, 0b0110110);\n+  INSN(fmaxp, 0b00, 0b0111110);\n+  INSN(fminp, 0b01, 0b0111110);\n+\n+#undef INSN\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":13,"deletions":8,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -1404,0 +1404,2 @@\n+          [\"fmaxp\", \"fmaxp\", \"2S\"], [\"fmaxp\", \"fmaxp\", \"2D\"],\n+          [\"fminp\", \"fminp\", \"2S\"], [\"fminp\", \"fminp\", \"2D\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -543,0 +543,4 @@\n+    __ fmaxp(v4, __ T2S, v5);                          \/\/       fmaxp   s4, v5.2S\n+    __ fmaxp(v20, __ T2D, v21);                        \/\/       fmaxp   d20, v21.2D\n+    __ fminp(v11, __ T2S, v12);                        \/\/       fminp   s11, v12.2S\n+    __ fminp(v29, __ T2D, v30);                        \/\/       fminp   d29, v30.2D\n@@ -545,18 +549,18 @@\n-    __ absr(v4, __ T8B, v5);                           \/\/       abs     v4.8B, v5.8B\n-    __ absr(v20, __ T16B, v21);                        \/\/       abs     v20.16B, v21.16B\n-    __ absr(v11, __ T4H, v12);                         \/\/       abs     v11.4H, v12.4H\n-    __ absr(v29, __ T8H, v30);                         \/\/       abs     v29.8H, v30.8H\n-    __ absr(v15, __ T2S, v16);                         \/\/       abs     v15.2S, v16.2S\n-    __ absr(v21, __ T4S, v22);                         \/\/       abs     v21.4S, v22.4S\n-    __ absr(v4, __ T2D, v5);                           \/\/       abs     v4.2D, v5.2D\n-    __ fabs(v14, __ T2S, v15);                         \/\/       fabs    v14.2S, v15.2S\n-    __ fabs(v22, __ T4S, v23);                         \/\/       fabs    v22.4S, v23.4S\n-    __ fabs(v25, __ T2D, v26);                         \/\/       fabs    v25.2D, v26.2D\n-    __ fneg(v6, __ T2S, v7);                           \/\/       fneg    v6.2S, v7.2S\n-    __ fneg(v12, __ T4S, v13);                         \/\/       fneg    v12.4S, v13.4S\n-    __ fneg(v14, __ T2D, v15);                         \/\/       fneg    v14.2D, v15.2D\n-    __ fsqrt(v13, __ T2S, v14);                        \/\/       fsqrt   v13.2S, v14.2S\n-    __ fsqrt(v14, __ T4S, v15);                        \/\/       fsqrt   v14.4S, v15.4S\n-    __ fsqrt(v9, __ T2D, v10);                         \/\/       fsqrt   v9.2D, v10.2D\n-    __ notr(v25, __ T8B, v26);                         \/\/       not     v25.8B, v26.8B\n-    __ notr(v28, __ T16B, v29);                        \/\/       not     v28.16B, v29.16B\n+    __ absr(v15, __ T8B, v16);                         \/\/       abs     v15.8B, v16.8B\n+    __ absr(v21, __ T16B, v22);                        \/\/       abs     v21.16B, v22.16B\n+    __ absr(v4, __ T4H, v5);                           \/\/       abs     v4.4H, v5.4H\n+    __ absr(v14, __ T8H, v15);                         \/\/       abs     v14.8H, v15.8H\n+    __ absr(v22, __ T2S, v23);                         \/\/       abs     v22.2S, v23.2S\n+    __ absr(v25, __ T4S, v26);                         \/\/       abs     v25.4S, v26.4S\n+    __ absr(v6, __ T2D, v7);                           \/\/       abs     v6.2D, v7.2D\n+    __ fabs(v12, __ T2S, v13);                         \/\/       fabs    v12.2S, v13.2S\n+    __ fabs(v14, __ T4S, v15);                         \/\/       fabs    v14.4S, v15.4S\n+    __ fabs(v13, __ T2D, v14);                         \/\/       fabs    v13.2D, v14.2D\n+    __ fneg(v14, __ T2S, v15);                         \/\/       fneg    v14.2S, v15.2S\n+    __ fneg(v9, __ T4S, v10);                          \/\/       fneg    v9.4S, v10.4S\n+    __ fneg(v25, __ T2D, v26);                         \/\/       fneg    v25.2D, v26.2D\n+    __ fsqrt(v28, __ T2S, v29);                        \/\/       fsqrt   v28.2S, v29.2S\n+    __ fsqrt(v10, __ T4S, v11);                        \/\/       fsqrt   v10.4S, v11.4S\n+    __ fsqrt(v19, __ T2D, v20);                        \/\/       fsqrt   v19.2D, v20.2D\n+    __ notr(v11, __ T8B, v12);                         \/\/       not     v11.8B, v12.8B\n+    __ notr(v17, __ T16B, v18);                        \/\/       not     v17.16B, v18.16B\n@@ -565,76 +569,76 @@\n-    __ andr(v10, __ T8B, v11, v12);                    \/\/       and     v10.8B, v11.8B, v12.8B\n-    __ andr(v19, __ T16B, v20, v21);                   \/\/       and     v19.16B, v20.16B, v21.16B\n-    __ orr(v11, __ T8B, v12, v13);                     \/\/       orr     v11.8B, v12.8B, v13.8B\n-    __ orr(v17, __ T16B, v18, v19);                    \/\/       orr     v17.16B, v18.16B, v19.16B\n-    __ eor(v21, __ T8B, v22, v23);                     \/\/       eor     v21.8B, v22.8B, v23.8B\n-    __ eor(v15, __ T16B, v16, v17);                    \/\/       eor     v15.16B, v16.16B, v17.16B\n-    __ addv(v20, __ T8B, v21, v22);                    \/\/       add     v20.8B, v21.8B, v22.8B\n-    __ addv(v23, __ T16B, v24, v25);                   \/\/       add     v23.16B, v24.16B, v25.16B\n-    __ addv(v26, __ T4H, v27, v28);                    \/\/       add     v26.4H, v27.4H, v28.4H\n-    __ addv(v5, __ T8H, v6, v7);                       \/\/       add     v5.8H, v6.8H, v7.8H\n-    __ addv(v6, __ T2S, v7, v8);                       \/\/       add     v6.2S, v7.2S, v8.2S\n-    __ addv(v15, __ T4S, v16, v17);                    \/\/       add     v15.4S, v16.4S, v17.4S\n-    __ addv(v15, __ T2D, v16, v17);                    \/\/       add     v15.2D, v16.2D, v17.2D\n-    __ fadd(v25, __ T2S, v26, v27);                    \/\/       fadd    v25.2S, v26.2S, v27.2S\n-    __ fadd(v16, __ T4S, v17, v18);                    \/\/       fadd    v16.4S, v17.4S, v18.4S\n-    __ fadd(v27, __ T2D, v28, v29);                    \/\/       fadd    v27.2D, v28.2D, v29.2D\n-    __ subv(v24, __ T8B, v25, v26);                    \/\/       sub     v24.8B, v25.8B, v26.8B\n-    __ subv(v15, __ T16B, v16, v17);                   \/\/       sub     v15.16B, v16.16B, v17.16B\n-    __ subv(v25, __ T4H, v26, v27);                    \/\/       sub     v25.4H, v26.4H, v27.4H\n-    __ subv(v14, __ T8H, v15, v16);                    \/\/       sub     v14.8H, v15.8H, v16.8H\n-    __ subv(v10, __ T2S, v11, v12);                    \/\/       sub     v10.2S, v11.2S, v12.2S\n-    __ subv(v13, __ T4S, v14, v15);                    \/\/       sub     v13.4S, v14.4S, v15.4S\n-    __ subv(v14, __ T2D, v15, v16);                    \/\/       sub     v14.2D, v15.2D, v16.2D\n-    __ fsub(v20, __ T2S, v21, v22);                    \/\/       fsub    v20.2S, v21.2S, v22.2S\n-    __ fsub(v1, __ T4S, v2, v3);                       \/\/       fsub    v1.4S, v2.4S, v3.4S\n-    __ fsub(v22, __ T2D, v23, v24);                    \/\/       fsub    v22.2D, v23.2D, v24.2D\n-    __ mulv(v30, __ T8B, v31, v0);                     \/\/       mul     v30.8B, v31.8B, v0.8B\n-    __ mulv(v14, __ T16B, v15, v16);                   \/\/       mul     v14.16B, v15.16B, v16.16B\n-    __ mulv(v2, __ T4H, v3, v4);                       \/\/       mul     v2.4H, v3.4H, v4.4H\n-    __ mulv(v6, __ T8H, v7, v8);                       \/\/       mul     v6.8H, v7.8H, v8.8H\n-    __ mulv(v3, __ T2S, v4, v5);                       \/\/       mul     v3.2S, v4.2S, v5.2S\n-    __ mulv(v7, __ T4S, v8, v9);                       \/\/       mul     v7.4S, v8.4S, v9.4S\n-    __ fabd(v24, __ T2S, v25, v26);                    \/\/       fabd    v24.2S, v25.2S, v26.2S\n-    __ fabd(v0, __ T4S, v1, v2);                       \/\/       fabd    v0.4S, v1.4S, v2.4S\n-    __ fabd(v27, __ T2D, v28, v29);                    \/\/       fabd    v27.2D, v28.2D, v29.2D\n-    __ fmul(v29, __ T2S, v30, v31);                    \/\/       fmul    v29.2S, v30.2S, v31.2S\n-    __ fmul(v5, __ T4S, v6, v7);                       \/\/       fmul    v5.4S, v6.4S, v7.4S\n-    __ fmul(v5, __ T2D, v6, v7);                       \/\/       fmul    v5.2D, v6.2D, v7.2D\n-    __ mlav(v29, __ T4H, v30, v31);                    \/\/       mla     v29.4H, v30.4H, v31.4H\n-    __ mlav(v11, __ T8H, v12, v13);                    \/\/       mla     v11.8H, v12.8H, v13.8H\n-    __ mlav(v25, __ T2S, v26, v27);                    \/\/       mla     v25.2S, v26.2S, v27.2S\n-    __ mlav(v0, __ T4S, v1, v2);                       \/\/       mla     v0.4S, v1.4S, v2.4S\n-    __ fmla(v30, __ T2S, v31, v0);                     \/\/       fmla    v30.2S, v31.2S, v0.2S\n-    __ fmla(v0, __ T4S, v1, v2);                       \/\/       fmla    v0.4S, v1.4S, v2.4S\n-    __ fmla(v17, __ T2D, v18, v19);                    \/\/       fmla    v17.2D, v18.2D, v19.2D\n-    __ mlsv(v28, __ T4H, v29, v30);                    \/\/       mls     v28.4H, v29.4H, v30.4H\n-    __ mlsv(v25, __ T8H, v26, v27);                    \/\/       mls     v25.8H, v26.8H, v27.8H\n-    __ mlsv(v9, __ T2S, v10, v11);                     \/\/       mls     v9.2S, v10.2S, v11.2S\n-    __ mlsv(v25, __ T4S, v26, v27);                    \/\/       mls     v25.4S, v26.4S, v27.4S\n-    __ fmls(v12, __ T2S, v13, v14);                    \/\/       fmls    v12.2S, v13.2S, v14.2S\n-    __ fmls(v15, __ T4S, v16, v17);                    \/\/       fmls    v15.4S, v16.4S, v17.4S\n-    __ fmls(v11, __ T2D, v12, v13);                    \/\/       fmls    v11.2D, v12.2D, v13.2D\n-    __ fdiv(v10, __ T2S, v11, v12);                    \/\/       fdiv    v10.2S, v11.2S, v12.2S\n-    __ fdiv(v17, __ T4S, v18, v19);                    \/\/       fdiv    v17.4S, v18.4S, v19.4S\n-    __ fdiv(v24, __ T2D, v25, v26);                    \/\/       fdiv    v24.2D, v25.2D, v26.2D\n-    __ maxv(v21, __ T8B, v22, v23);                    \/\/       smax    v21.8B, v22.8B, v23.8B\n-    __ maxv(v23, __ T16B, v24, v25);                   \/\/       smax    v23.16B, v24.16B, v25.16B\n-    __ maxv(v0, __ T4H, v1, v2);                       \/\/       smax    v0.4H, v1.4H, v2.4H\n-    __ maxv(v16, __ T8H, v17, v18);                    \/\/       smax    v16.8H, v17.8H, v18.8H\n-    __ maxv(v10, __ T2S, v11, v12);                    \/\/       smax    v10.2S, v11.2S, v12.2S\n-    __ maxv(v6, __ T4S, v7, v8);                       \/\/       smax    v6.4S, v7.4S, v8.4S\n-    __ fmax(v28, __ T2S, v29, v30);                    \/\/       fmax    v28.2S, v29.2S, v30.2S\n-    __ fmax(v6, __ T4S, v7, v8);                       \/\/       fmax    v6.4S, v7.4S, v8.4S\n-    __ fmax(v5, __ T2D, v6, v7);                       \/\/       fmax    v5.2D, v6.2D, v7.2D\n-    __ minv(v5, __ T8B, v6, v7);                       \/\/       smin    v5.8B, v6.8B, v7.8B\n-    __ minv(v20, __ T16B, v21, v22);                   \/\/       smin    v20.16B, v21.16B, v22.16B\n-    __ minv(v17, __ T4H, v18, v19);                    \/\/       smin    v17.4H, v18.4H, v19.4H\n-    __ minv(v15, __ T8H, v16, v17);                    \/\/       smin    v15.8H, v16.8H, v17.8H\n-    __ minv(v17, __ T2S, v18, v19);                    \/\/       smin    v17.2S, v18.2S, v19.2S\n-    __ minv(v29, __ T4S, v30, v31);                    \/\/       smin    v29.4S, v30.4S, v31.4S\n-    __ fmin(v26, __ T2S, v27, v28);                    \/\/       fmin    v26.2S, v27.2S, v28.2S\n-    __ fmin(v28, __ T4S, v29, v30);                    \/\/       fmin    v28.4S, v29.4S, v30.4S\n-    __ fmin(v1, __ T2D, v2, v3);                       \/\/       fmin    v1.2D, v2.2D, v3.2D\n-    __ cmeq(v27, __ T8B, v28, v29);                    \/\/       cmeq    v27.8B, v28.8B, v29.8B\n-    __ cmeq(v0, __ T16B, v1, v2);                      \/\/       cmeq    v0.16B, v1.16B, v2.16B\n-    __ cmeq(v20, __ T4H, v21, v22);                    \/\/       cmeq    v20.4H, v21.4H, v22.4H\n+    __ andr(v21, __ T8B, v22, v23);                    \/\/       and     v21.8B, v22.8B, v23.8B\n+    __ andr(v15, __ T16B, v16, v17);                   \/\/       and     v15.16B, v16.16B, v17.16B\n+    __ orr(v20, __ T8B, v21, v22);                     \/\/       orr     v20.8B, v21.8B, v22.8B\n+    __ orr(v23, __ T16B, v24, v25);                    \/\/       orr     v23.16B, v24.16B, v25.16B\n+    __ eor(v26, __ T8B, v27, v28);                     \/\/       eor     v26.8B, v27.8B, v28.8B\n+    __ eor(v5, __ T16B, v6, v7);                       \/\/       eor     v5.16B, v6.16B, v7.16B\n+    __ addv(v6, __ T8B, v7, v8);                       \/\/       add     v6.8B, v7.8B, v8.8B\n+    __ addv(v15, __ T16B, v16, v17);                   \/\/       add     v15.16B, v16.16B, v17.16B\n+    __ addv(v15, __ T4H, v16, v17);                    \/\/       add     v15.4H, v16.4H, v17.4H\n+    __ addv(v25, __ T8H, v26, v27);                    \/\/       add     v25.8H, v26.8H, v27.8H\n+    __ addv(v16, __ T2S, v17, v18);                    \/\/       add     v16.2S, v17.2S, v18.2S\n+    __ addv(v27, __ T4S, v28, v29);                    \/\/       add     v27.4S, v28.4S, v29.4S\n+    __ addv(v24, __ T2D, v25, v26);                    \/\/       add     v24.2D, v25.2D, v26.2D\n+    __ fadd(v15, __ T2S, v16, v17);                    \/\/       fadd    v15.2S, v16.2S, v17.2S\n+    __ fadd(v25, __ T4S, v26, v27);                    \/\/       fadd    v25.4S, v26.4S, v27.4S\n+    __ fadd(v14, __ T2D, v15, v16);                    \/\/       fadd    v14.2D, v15.2D, v16.2D\n+    __ subv(v10, __ T8B, v11, v12);                    \/\/       sub     v10.8B, v11.8B, v12.8B\n+    __ subv(v13, __ T16B, v14, v15);                   \/\/       sub     v13.16B, v14.16B, v15.16B\n+    __ subv(v14, __ T4H, v15, v16);                    \/\/       sub     v14.4H, v15.4H, v16.4H\n+    __ subv(v20, __ T8H, v21, v22);                    \/\/       sub     v20.8H, v21.8H, v22.8H\n+    __ subv(v1, __ T2S, v2, v3);                       \/\/       sub     v1.2S, v2.2S, v3.2S\n+    __ subv(v22, __ T4S, v23, v24);                    \/\/       sub     v22.4S, v23.4S, v24.4S\n+    __ subv(v30, __ T2D, v31, v0);                     \/\/       sub     v30.2D, v31.2D, v0.2D\n+    __ fsub(v14, __ T2S, v15, v16);                    \/\/       fsub    v14.2S, v15.2S, v16.2S\n+    __ fsub(v2, __ T4S, v3, v4);                       \/\/       fsub    v2.4S, v3.4S, v4.4S\n+    __ fsub(v6, __ T2D, v7, v8);                       \/\/       fsub    v6.2D, v7.2D, v8.2D\n+    __ mulv(v3, __ T8B, v4, v5);                       \/\/       mul     v3.8B, v4.8B, v5.8B\n+    __ mulv(v7, __ T16B, v8, v9);                      \/\/       mul     v7.16B, v8.16B, v9.16B\n+    __ mulv(v24, __ T4H, v25, v26);                    \/\/       mul     v24.4H, v25.4H, v26.4H\n+    __ mulv(v0, __ T8H, v1, v2);                       \/\/       mul     v0.8H, v1.8H, v2.8H\n+    __ mulv(v27, __ T2S, v28, v29);                    \/\/       mul     v27.2S, v28.2S, v29.2S\n+    __ mulv(v29, __ T4S, v30, v31);                    \/\/       mul     v29.4S, v30.4S, v31.4S\n+    __ fabd(v5, __ T2S, v6, v7);                       \/\/       fabd    v5.2S, v6.2S, v7.2S\n+    __ fabd(v5, __ T4S, v6, v7);                       \/\/       fabd    v5.4S, v6.4S, v7.4S\n+    __ fabd(v29, __ T2D, v30, v31);                    \/\/       fabd    v29.2D, v30.2D, v31.2D\n+    __ fmul(v11, __ T2S, v12, v13);                    \/\/       fmul    v11.2S, v12.2S, v13.2S\n+    __ fmul(v25, __ T4S, v26, v27);                    \/\/       fmul    v25.4S, v26.4S, v27.4S\n+    __ fmul(v0, __ T2D, v1, v2);                       \/\/       fmul    v0.2D, v1.2D, v2.2D\n+    __ mlav(v30, __ T4H, v31, v0);                     \/\/       mla     v30.4H, v31.4H, v0.4H\n+    __ mlav(v0, __ T8H, v1, v2);                       \/\/       mla     v0.8H, v1.8H, v2.8H\n+    __ mlav(v17, __ T2S, v18, v19);                    \/\/       mla     v17.2S, v18.2S, v19.2S\n+    __ mlav(v28, __ T4S, v29, v30);                    \/\/       mla     v28.4S, v29.4S, v30.4S\n+    __ fmla(v25, __ T2S, v26, v27);                    \/\/       fmla    v25.2S, v26.2S, v27.2S\n+    __ fmla(v9, __ T4S, v10, v11);                     \/\/       fmla    v9.4S, v10.4S, v11.4S\n+    __ fmla(v25, __ T2D, v26, v27);                    \/\/       fmla    v25.2D, v26.2D, v27.2D\n+    __ mlsv(v12, __ T4H, v13, v14);                    \/\/       mls     v12.4H, v13.4H, v14.4H\n+    __ mlsv(v15, __ T8H, v16, v17);                    \/\/       mls     v15.8H, v16.8H, v17.8H\n+    __ mlsv(v11, __ T2S, v12, v13);                    \/\/       mls     v11.2S, v12.2S, v13.2S\n+    __ mlsv(v10, __ T4S, v11, v12);                    \/\/       mls     v10.4S, v11.4S, v12.4S\n+    __ fmls(v17, __ T2S, v18, v19);                    \/\/       fmls    v17.2S, v18.2S, v19.2S\n+    __ fmls(v24, __ T4S, v25, v26);                    \/\/       fmls    v24.4S, v25.4S, v26.4S\n+    __ fmls(v21, __ T2D, v22, v23);                    \/\/       fmls    v21.2D, v22.2D, v23.2D\n+    __ fdiv(v23, __ T2S, v24, v25);                    \/\/       fdiv    v23.2S, v24.2S, v25.2S\n+    __ fdiv(v0, __ T4S, v1, v2);                       \/\/       fdiv    v0.4S, v1.4S, v2.4S\n+    __ fdiv(v16, __ T2D, v17, v18);                    \/\/       fdiv    v16.2D, v17.2D, v18.2D\n+    __ maxv(v10, __ T8B, v11, v12);                    \/\/       smax    v10.8B, v11.8B, v12.8B\n+    __ maxv(v6, __ T16B, v7, v8);                      \/\/       smax    v6.16B, v7.16B, v8.16B\n+    __ maxv(v28, __ T4H, v29, v30);                    \/\/       smax    v28.4H, v29.4H, v30.4H\n+    __ maxv(v6, __ T8H, v7, v8);                       \/\/       smax    v6.8H, v7.8H, v8.8H\n+    __ maxv(v5, __ T2S, v6, v7);                       \/\/       smax    v5.2S, v6.2S, v7.2S\n+    __ maxv(v5, __ T4S, v6, v7);                       \/\/       smax    v5.4S, v6.4S, v7.4S\n+    __ fmax(v20, __ T2S, v21, v22);                    \/\/       fmax    v20.2S, v21.2S, v22.2S\n+    __ fmax(v17, __ T4S, v18, v19);                    \/\/       fmax    v17.4S, v18.4S, v19.4S\n+    __ fmax(v15, __ T2D, v16, v17);                    \/\/       fmax    v15.2D, v16.2D, v17.2D\n+    __ minv(v17, __ T8B, v18, v19);                    \/\/       smin    v17.8B, v18.8B, v19.8B\n+    __ minv(v29, __ T16B, v30, v31);                   \/\/       smin    v29.16B, v30.16B, v31.16B\n+    __ minv(v26, __ T4H, v27, v28);                    \/\/       smin    v26.4H, v27.4H, v28.4H\n+    __ minv(v28, __ T8H, v29, v30);                    \/\/       smin    v28.8H, v29.8H, v30.8H\n+    __ minv(v1, __ T2S, v2, v3);                       \/\/       smin    v1.2S, v2.2S, v3.2S\n+    __ minv(v27, __ T4S, v28, v29);                    \/\/       smin    v27.4S, v28.4S, v29.4S\n+    __ fmin(v0, __ T2S, v1, v2);                       \/\/       fmin    v0.2S, v1.2S, v2.2S\n+    __ fmin(v20, __ T4S, v21, v22);                    \/\/       fmin    v20.4S, v21.4S, v22.4S\n+    __ fmin(v28, __ T2D, v29, v30);                    \/\/       fmin    v28.2D, v29.2D, v30.2D\n+    __ cmeq(v15, __ T8B, v16, v17);                    \/\/       cmeq    v15.8B, v16.8B, v17.8B\n+    __ cmeq(v12, __ T16B, v13, v14);                   \/\/       cmeq    v12.16B, v13.16B, v14.16B\n+    __ cmeq(v10, __ T4H, v11, v12);                    \/\/       cmeq    v10.4H, v11.4H, v12.4H\n@@ -642,26 +646,26 @@\n-    __ cmeq(v15, __ T2S, v16, v17);                    \/\/       cmeq    v15.2S, v16.2S, v17.2S\n-    __ cmeq(v12, __ T4S, v13, v14);                    \/\/       cmeq    v12.4S, v13.4S, v14.4S\n-    __ cmeq(v10, __ T2D, v11, v12);                    \/\/       cmeq    v10.2D, v11.2D, v12.2D\n-    __ fcmeq(v28, __ T2S, v29, v30);                   \/\/       fcmeq   v28.2S, v29.2S, v30.2S\n-    __ fcmeq(v28, __ T4S, v29, v30);                   \/\/       fcmeq   v28.4S, v29.4S, v30.4S\n-    __ fcmeq(v19, __ T2D, v20, v21);                   \/\/       fcmeq   v19.2D, v20.2D, v21.2D\n-    __ cmgt(v22, __ T8B, v23, v24);                    \/\/       cmgt    v22.8B, v23.8B, v24.8B\n-    __ cmgt(v10, __ T16B, v11, v12);                   \/\/       cmgt    v10.16B, v11.16B, v12.16B\n-    __ cmgt(v4, __ T4H, v5, v6);                       \/\/       cmgt    v4.4H, v5.4H, v6.4H\n-    __ cmgt(v30, __ T8H, v31, v0);                     \/\/       cmgt    v30.8H, v31.8H, v0.8H\n-    __ cmgt(v20, __ T2S, v21, v22);                    \/\/       cmgt    v20.2S, v21.2S, v22.2S\n-    __ cmgt(v8, __ T4S, v9, v10);                      \/\/       cmgt    v8.4S, v9.4S, v10.4S\n-    __ cmgt(v30, __ T2D, v31, v0);                     \/\/       cmgt    v30.2D, v31.2D, v0.2D\n-    __ fcmgt(v17, __ T2S, v18, v19);                   \/\/       fcmgt   v17.2S, v18.2S, v19.2S\n-    __ fcmgt(v10, __ T4S, v11, v12);                   \/\/       fcmgt   v10.4S, v11.4S, v12.4S\n-    __ fcmgt(v27, __ T2D, v28, v29);                   \/\/       fcmgt   v27.2D, v28.2D, v29.2D\n-    __ cmge(v2, __ T8B, v3, v4);                       \/\/       cmge    v2.8B, v3.8B, v4.8B\n-    __ cmge(v24, __ T16B, v25, v26);                   \/\/       cmge    v24.16B, v25.16B, v26.16B\n-    __ cmge(v4, __ T4H, v5, v6);                       \/\/       cmge    v4.4H, v5.4H, v6.4H\n-    __ cmge(v3, __ T8H, v4, v5);                       \/\/       cmge    v3.8H, v4.8H, v5.8H\n-    __ cmge(v8, __ T2S, v9, v10);                      \/\/       cmge    v8.2S, v9.2S, v10.2S\n-    __ cmge(v22, __ T4S, v23, v24);                    \/\/       cmge    v22.4S, v23.4S, v24.4S\n-    __ cmge(v17, __ T2D, v18, v19);                    \/\/       cmge    v17.2D, v18.2D, v19.2D\n-    __ fcmge(v13, __ T2S, v14, v15);                   \/\/       fcmge   v13.2S, v14.2S, v15.2S\n-    __ fcmge(v4, __ T4S, v5, v6);                      \/\/       fcmge   v4.4S, v5.4S, v6.4S\n-    __ fcmge(v28, __ T2D, v29, v30);                   \/\/       fcmge   v28.2D, v29.2D, v30.2D\n+    __ cmeq(v28, __ T2S, v29, v30);                    \/\/       cmeq    v28.2S, v29.2S, v30.2S\n+    __ cmeq(v19, __ T4S, v20, v21);                    \/\/       cmeq    v19.4S, v20.4S, v21.4S\n+    __ cmeq(v22, __ T2D, v23, v24);                    \/\/       cmeq    v22.2D, v23.2D, v24.2D\n+    __ fcmeq(v10, __ T2S, v11, v12);                   \/\/       fcmeq   v10.2S, v11.2S, v12.2S\n+    __ fcmeq(v4, __ T4S, v5, v6);                      \/\/       fcmeq   v4.4S, v5.4S, v6.4S\n+    __ fcmeq(v30, __ T2D, v31, v0);                    \/\/       fcmeq   v30.2D, v31.2D, v0.2D\n+    __ cmgt(v20, __ T8B, v21, v22);                    \/\/       cmgt    v20.8B, v21.8B, v22.8B\n+    __ cmgt(v8, __ T16B, v9, v10);                     \/\/       cmgt    v8.16B, v9.16B, v10.16B\n+    __ cmgt(v30, __ T4H, v31, v0);                     \/\/       cmgt    v30.4H, v31.4H, v0.4H\n+    __ cmgt(v17, __ T8H, v18, v19);                    \/\/       cmgt    v17.8H, v18.8H, v19.8H\n+    __ cmgt(v10, __ T2S, v11, v12);                    \/\/       cmgt    v10.2S, v11.2S, v12.2S\n+    __ cmgt(v27, __ T4S, v28, v29);                    \/\/       cmgt    v27.4S, v28.4S, v29.4S\n+    __ cmgt(v2, __ T2D, v3, v4);                       \/\/       cmgt    v2.2D, v3.2D, v4.2D\n+    __ fcmgt(v24, __ T2S, v25, v26);                   \/\/       fcmgt   v24.2S, v25.2S, v26.2S\n+    __ fcmgt(v4, __ T4S, v5, v6);                      \/\/       fcmgt   v4.4S, v5.4S, v6.4S\n+    __ fcmgt(v3, __ T2D, v4, v5);                      \/\/       fcmgt   v3.2D, v4.2D, v5.2D\n+    __ cmge(v8, __ T8B, v9, v10);                      \/\/       cmge    v8.8B, v9.8B, v10.8B\n+    __ cmge(v22, __ T16B, v23, v24);                   \/\/       cmge    v22.16B, v23.16B, v24.16B\n+    __ cmge(v17, __ T4H, v18, v19);                    \/\/       cmge    v17.4H, v18.4H, v19.4H\n+    __ cmge(v13, __ T8H, v14, v15);                    \/\/       cmge    v13.8H, v14.8H, v15.8H\n+    __ cmge(v4, __ T2S, v5, v6);                       \/\/       cmge    v4.2S, v5.2S, v6.2S\n+    __ cmge(v28, __ T4S, v29, v30);                    \/\/       cmge    v28.4S, v29.4S, v30.4S\n+    __ cmge(v23, __ T2D, v24, v25);                    \/\/       cmge    v23.2D, v24.2D, v25.2D\n+    __ fcmge(v21, __ T2S, v22, v23);                   \/\/       fcmge   v21.2S, v22.2S, v23.2S\n+    __ fcmge(v25, __ T4S, v26, v27);                   \/\/       fcmge   v25.4S, v26.4S, v27.4S\n+    __ fcmge(v24, __ T2D, v25, v26);                   \/\/       fcmge   v24.2D, v25.2D, v26.2D\n@@ -754,9 +758,9 @@\n-    __ swp(Assembler::xword, r24, r21, r26);           \/\/       swp     x24, x21, [x26]\n-    __ ldadd(Assembler::xword, r24, r3, r24);          \/\/       ldadd   x24, x3, [x24]\n-    __ ldbic(Assembler::xword, r26, r23, r15);         \/\/       ldclr   x26, x23, [x15]\n-    __ ldeor(Assembler::xword, r21, r3, r24);          \/\/       ldeor   x21, x3, [x24]\n-    __ ldorr(Assembler::xword, r8, r25, r20);          \/\/       ldset   x8, x25, [x20]\n-    __ ldsmin(Assembler::xword, r16, r17, r2);         \/\/       ldsmin  x16, x17, [x2]\n-    __ ldsmax(Assembler::xword, r1, r0, r24);          \/\/       ldsmax  x1, x0, [x24]\n-    __ ldumin(Assembler::xword, r4, r3, r12);          \/\/       ldumin  x4, x3, [x12]\n-    __ ldumax(Assembler::xword, zr, r28, r10);         \/\/       ldumax  xzr, x28, [x10]\n+    __ swp(Assembler::xword, r3, r24, r26);            \/\/       swp     x3, x24, [x26]\n+    __ ldadd(Assembler::xword, r23, r15, r21);         \/\/       ldadd   x23, x15, [x21]\n+    __ ldbic(Assembler::xword, r3, r24, r8);           \/\/       ldclr   x3, x24, [x8]\n+    __ ldeor(Assembler::xword, r25, r20, r16);         \/\/       ldeor   x25, x20, [x16]\n+    __ ldorr(Assembler::xword, r17, r2, r1);           \/\/       ldset   x17, x2, [x1]\n+    __ ldsmin(Assembler::xword, r0, r24, r4);          \/\/       ldsmin  x0, x24, [x4]\n+    __ ldsmax(Assembler::xword, r3, r12, sp);          \/\/       ldsmax  x3, x12, [sp]\n+    __ ldumin(Assembler::xword, r28, r10, r26);        \/\/       ldumin  x28, x10, [x26]\n+    __ ldumax(Assembler::xword, r2, r12, r15);         \/\/       ldumax  x2, x12, [x15]\n@@ -765,9 +769,9 @@\n-    __ swpa(Assembler::xword, r26, r2, r12);           \/\/       swpa    x26, x2, [x12]\n-    __ ldadda(Assembler::xword, r16, zr, r1);          \/\/       ldadda  x16, xzr, [x1]\n-    __ ldbica(Assembler::xword, r13, r29, r0);         \/\/       ldclra  x13, x29, [x0]\n-    __ ldeora(Assembler::xword, r19, r12, r17);        \/\/       ldeora  x19, x12, [x17]\n-    __ ldorra(Assembler::xword, r22, r13, r28);        \/\/       ldseta  x22, x13, [x28]\n-    __ ldsmina(Assembler::xword, r30, zr, r1);         \/\/       ldsmina x30, xzr, [x1]\n-    __ ldsmaxa(Assembler::xword, r26, r28, r4);        \/\/       ldsmaxa x26, x28, [x4]\n-    __ ldumina(Assembler::xword, r30, r4, r6);         \/\/       ldumina x30, x4, [x6]\n-    __ ldumaxa(Assembler::xword, r30, r26, r15);       \/\/       ldumaxa x30, x26, [x15]\n+    __ swpa(Assembler::xword, zr, r1, r13);            \/\/       swpa    xzr, x1, [x13]\n+    __ ldadda(Assembler::xword, r29, r0, r19);         \/\/       ldadda  x29, x0, [x19]\n+    __ ldbica(Assembler::xword, r12, r17, r22);        \/\/       ldclra  x12, x17, [x22]\n+    __ ldeora(Assembler::xword, r13, r28, r30);        \/\/       ldeora  x13, x28, [x30]\n+    __ ldorra(Assembler::xword, zr, r1, r26);          \/\/       ldseta  xzr, x1, [x26]\n+    __ ldsmina(Assembler::xword, r28, r4, r30);        \/\/       ldsmina x28, x4, [x30]\n+    __ ldsmaxa(Assembler::xword, r4, r6, r30);         \/\/       ldsmaxa x4, x6, [x30]\n+    __ ldumina(Assembler::xword, r26, r16, r9);        \/\/       ldumina x26, x16, [x9]\n+    __ ldumaxa(Assembler::xword, r8, r12, r0);         \/\/       ldumaxa x8, x12, [x0]\n@@ -776,9 +780,9 @@\n-    __ swpal(Assembler::xword, r9, r8, r12);           \/\/       swpal   x9, x8, [x12]\n-    __ ldaddal(Assembler::xword, r0, r20, r1);         \/\/       ldaddal x0, x20, [x1]\n-    __ ldbical(Assembler::xword, r24, r2, r0);         \/\/       ldclral x24, x2, [x0]\n-    __ ldeoral(Assembler::xword, r9, r24, r26);        \/\/       ldeoral x9, x24, [x26]\n-    __ ldorral(Assembler::xword, r16, r30, r3);        \/\/       ldsetal x16, x30, [x3]\n-    __ ldsminal(Assembler::xword, r10, r23, r10);      \/\/       ldsminal        x10, x23, [x10]\n-    __ ldsmaxal(Assembler::xword, r4, r16, r2);        \/\/       ldsmaxal        x4, x16, [x2]\n-    __ lduminal(Assembler::xword, r11, r8, r10);       \/\/       lduminal        x11, x8, [x10]\n-    __ ldumaxal(Assembler::xword, r15, r17, r2);       \/\/       ldumaxal        x15, x17, [x2]\n+    __ swpal(Assembler::xword, r20, r1, r24);          \/\/       swpal   x20, x1, [x24]\n+    __ ldaddal(Assembler::xword, r2, r0, r9);          \/\/       ldaddal x2, x0, [x9]\n+    __ ldbical(Assembler::xword, r24, r26, r16);       \/\/       ldclral x24, x26, [x16]\n+    __ ldeoral(Assembler::xword, r30, r3, r10);        \/\/       ldeoral x30, x3, [x10]\n+    __ ldorral(Assembler::xword, r23, r10, r4);        \/\/       ldsetal x23, x10, [x4]\n+    __ ldsminal(Assembler::xword, r16, r2, r11);       \/\/       ldsminal        x16, x2, [x11]\n+    __ ldsmaxal(Assembler::xword, r8, r10, r15);       \/\/       ldsmaxal        x8, x10, [x15]\n+    __ lduminal(Assembler::xword, r17, r2, r10);       \/\/       lduminal        x17, x2, [x10]\n+    __ ldumaxal(Assembler::xword, r12, r12, r15);      \/\/       ldumaxal        x12, x12, [x15]\n@@ -787,9 +791,9 @@\n-    __ swpl(Assembler::xword, r10, r12, r12);          \/\/       swpl    x10, x12, [x12]\n-    __ ldaddl(Assembler::xword, r15, r13, r2);         \/\/       ldaddl  x15, x13, [x2]\n-    __ ldbicl(Assembler::xword, r7, r20, r26);         \/\/       ldclrl  x7, x20, [x26]\n-    __ ldeorl(Assembler::xword, r16, r4, r2);          \/\/       ldeorl  x16, x4, [x2]\n-    __ ldorrl(Assembler::xword, r4, r12, r15);         \/\/       ldsetl  x4, x12, [x15]\n-    __ ldsminl(Assembler::xword, r21, r16, r15);       \/\/       ldsminl x21, x16, [x15]\n-    __ ldsmaxl(Assembler::xword, r11, r21, r23);       \/\/       ldsmaxl x11, x21, [x23]\n-    __ lduminl(Assembler::xword, r12, r26, r23);       \/\/       lduminl x12, x26, [x23]\n-    __ ldumaxl(Assembler::xword, r28, r14, r11);       \/\/       ldumaxl x28, x14, [x11]\n+    __ swpl(Assembler::xword, r13, r2, r7);            \/\/       swpl    x13, x2, [x7]\n+    __ ldaddl(Assembler::xword, r20, r26, r16);        \/\/       ldaddl  x20, x26, [x16]\n+    __ ldbicl(Assembler::xword, r4, r2, r4);           \/\/       ldclrl  x4, x2, [x4]\n+    __ ldeorl(Assembler::xword, r12, r16, r21);        \/\/       ldeorl  x12, x16, [x21]\n+    __ ldorrl(Assembler::xword, r16, r16, r11);        \/\/       ldsetl  x16, x16, [x11]\n+    __ ldsminl(Assembler::xword, r21, r23, r12);       \/\/       ldsminl x21, x23, [x12]\n+    __ ldsmaxl(Assembler::xword, r26, r23, r28);       \/\/       ldsmaxl x26, x23, [x28]\n+    __ lduminl(Assembler::xword, r14, r11, r24);       \/\/       lduminl x14, x11, [x24]\n+    __ ldumaxl(Assembler::xword, r1, r12, sp);         \/\/       ldumaxl x1, x12, [sp]\n@@ -798,9 +802,9 @@\n-    __ swp(Assembler::word, r24, r1, r12);             \/\/       swp     w24, w1, [x12]\n-    __ ldadd(Assembler::word, zr, r10, r16);           \/\/       ldadd   wzr, w10, [x16]\n-    __ ldbic(Assembler::word, r7, r2, r3);             \/\/       ldclr   w7, w2, [x3]\n-    __ ldeor(Assembler::word, r13, r19, r17);          \/\/       ldeor   w13, w19, [x17]\n-    __ ldorr(Assembler::word, r16, r3, r1);            \/\/       ldset   w16, w3, [x1]\n-    __ ldsmin(Assembler::word, r11, r30, r5);          \/\/       ldsmin  w11, w30, [x5]\n-    __ ldsmax(Assembler::word, r8, r15, r29);          \/\/       ldsmax  w8, w15, [x29]\n-    __ ldumin(Assembler::word, r30, r0, r20);          \/\/       ldumin  w30, w0, [x20]\n-    __ ldumax(Assembler::word, r7, r20, r23);          \/\/       ldumax  w7, w20, [x23]\n+    __ swp(Assembler::word, r10, r16, r7);             \/\/       swp     w10, w16, [x7]\n+    __ ldadd(Assembler::word, r2, r3, r13);            \/\/       ldadd   w2, w3, [x13]\n+    __ ldbic(Assembler::word, r19, r17, r16);          \/\/       ldclr   w19, w17, [x16]\n+    __ ldeor(Assembler::word, r3, r1, r11);            \/\/       ldeor   w3, w1, [x11]\n+    __ ldorr(Assembler::word, r30, r5, r8);            \/\/       ldset   w30, w5, [x8]\n+    __ ldsmin(Assembler::word, r15, r29, r30);         \/\/       ldsmin  w15, w29, [x30]\n+    __ ldsmax(Assembler::word, r0, r20, r7);           \/\/       ldsmax  w0, w20, [x7]\n+    __ ldumin(Assembler::word, r20, r23, r28);         \/\/       ldumin  w20, w23, [x28]\n+    __ ldumax(Assembler::word, r21, r27, r25);         \/\/       ldumax  w21, w27, [x25]\n@@ -809,9 +813,9 @@\n-    __ swpa(Assembler::word, r28, r21, r27);           \/\/       swpa    w28, w21, [x27]\n-    __ ldadda(Assembler::word, r25, r5, r1);           \/\/       ldadda  w25, w5, [x1]\n-    __ ldbica(Assembler::word, r23, r16, sp);          \/\/       ldclra  w23, w16, [sp]\n-    __ ldeora(Assembler::word, r5, r12, r9);           \/\/       ldeora  w5, w12, [x9]\n-    __ ldorra(Assembler::word, r28, r15, r29);         \/\/       ldseta  w28, w15, [x29]\n-    __ ldsmina(Assembler::word, r22, zr, r19);         \/\/       ldsmina w22, wzr, [x19]\n-    __ ldsmaxa(Assembler::word, zr, r5, r14);          \/\/       ldsmaxa wzr, w5, [x14]\n-    __ ldumina(Assembler::word, r16, zr, r15);         \/\/       ldumina w16, wzr, [x15]\n-    __ ldumaxa(Assembler::word, r27, r20, r16);        \/\/       ldumaxa w27, w20, [x16]\n+    __ swpa(Assembler::word, r5, r1, r23);             \/\/       swpa    w5, w1, [x23]\n+    __ ldadda(Assembler::word, r16, zr, r5);           \/\/       ldadda  w16, wzr, [x5]\n+    __ ldbica(Assembler::word, r12, r9, r28);          \/\/       ldclra  w12, w9, [x28]\n+    __ ldeora(Assembler::word, r15, r29, r22);         \/\/       ldeora  w15, w29, [x22]\n+    __ ldorra(Assembler::word, zr, r19, sp);           \/\/       ldseta  wzr, w19, [sp]\n+    __ ldsmina(Assembler::word, r5, r14, r15);         \/\/       ldsmina w5, w14, [x15]\n+    __ ldsmaxa(Assembler::word, zr, r16, r27);         \/\/       ldsmaxa wzr, w16, [x27]\n+    __ ldumina(Assembler::word, r20, r16, r12);        \/\/       ldumina w20, w16, [x12]\n+    __ ldumaxa(Assembler::word, r11, r9, r6);          \/\/       ldumaxa w11, w9, [x6]\n@@ -820,9 +824,9 @@\n-    __ swpal(Assembler::word, r12, r11, r9);           \/\/       swpal   w12, w11, [x9]\n-    __ ldaddal(Assembler::word, r6, r30, r17);         \/\/       ldaddal w6, w30, [x17]\n-    __ ldbical(Assembler::word, r27, r28, r30);        \/\/       ldclral w27, w28, [x30]\n-    __ ldeoral(Assembler::word, r7, r10, r20);         \/\/       ldeoral w7, w10, [x20]\n-    __ ldorral(Assembler::word, r10, r4, r24);         \/\/       ldsetal w10, w4, [x24]\n-    __ ldsminal(Assembler::word, r17, r17, r22);       \/\/       ldsminal        w17, w17, [x22]\n-    __ ldsmaxal(Assembler::word, r3, r29, r15);        \/\/       ldsmaxal        w3, w29, [x15]\n-    __ lduminal(Assembler::word, r22, r19, r19);       \/\/       lduminal        w22, w19, [x19]\n-    __ ldumaxal(Assembler::word, r22, r2, r15);        \/\/       ldumaxal        w22, w2, [x15]\n+    __ swpal(Assembler::word, r30, r17, r27);          \/\/       swpal   w30, w17, [x27]\n+    __ ldaddal(Assembler::word, r28, r30, r7);         \/\/       ldaddal w28, w30, [x7]\n+    __ ldbical(Assembler::word, r10, r20, r10);        \/\/       ldclral w10, w20, [x10]\n+    __ ldeoral(Assembler::word, r4, r24, r17);         \/\/       ldeoral w4, w24, [x17]\n+    __ ldorral(Assembler::word, r17, r22, r3);         \/\/       ldsetal w17, w22, [x3]\n+    __ ldsminal(Assembler::word, r29, r15, r22);       \/\/       ldsminal        w29, w15, [x22]\n+    __ ldsmaxal(Assembler::word, r19, r19, r22);       \/\/       ldsmaxal        w19, w19, [x22]\n+    __ lduminal(Assembler::word, r2, r15, r6);         \/\/       lduminal        w2, w15, [x6]\n+    __ ldumaxal(Assembler::word, r12, r16, r11);       \/\/       ldumaxal        w12, w16, [x11]\n@@ -831,9 +835,9 @@\n-    __ swpl(Assembler::word, r6, r12, r16);            \/\/       swpl    w6, w12, [x16]\n-    __ ldaddl(Assembler::word, r11, r13, r23);         \/\/       ldaddl  w11, w13, [x23]\n-    __ ldbicl(Assembler::word, r1, r30, r19);          \/\/       ldclrl  w1, w30, [x19]\n-    __ ldeorl(Assembler::word, r5, r17, r2);           \/\/       ldeorl  w5, w17, [x2]\n-    __ ldorrl(Assembler::word, r16, r22, r13);         \/\/       ldsetl  w16, w22, [x13]\n-    __ ldsminl(Assembler::word, r10, r21, r29);        \/\/       ldsminl w10, w21, [x29]\n-    __ ldsmaxl(Assembler::word, r27, r12, r27);        \/\/       ldsmaxl w27, w12, [x27]\n-    __ lduminl(Assembler::word, r3, r1, sp);           \/\/       lduminl w3, w1, [sp]\n-    __ ldumaxl(Assembler::word, r24, r19, r17);        \/\/       ldumaxl w24, w19, [x17]\n+    __ swpl(Assembler::word, r13, r23, r1);            \/\/       swpl    w13, w23, [x1]\n+    __ ldaddl(Assembler::word, r30, r19, r5);          \/\/       ldaddl  w30, w19, [x5]\n+    __ ldbicl(Assembler::word, r17, r2, r16);          \/\/       ldclrl  w17, w2, [x16]\n+    __ ldeorl(Assembler::word, r22, r13, r10);         \/\/       ldeorl  w22, w13, [x10]\n+    __ ldorrl(Assembler::word, r21, r29, r27);         \/\/       ldsetl  w21, w29, [x27]\n+    __ ldsminl(Assembler::word, r12, r27, r3);         \/\/       ldsminl w12, w27, [x3]\n+    __ ldsmaxl(Assembler::word, r1, zr, r24);          \/\/       ldsmaxl w1, wzr, [x24]\n+    __ lduminl(Assembler::word, r19, r17, r9);         \/\/       lduminl w19, w17, [x9]\n+    __ ldumaxl(Assembler::word, r28, r27, r15);        \/\/       ldumaxl w28, w27, [x15]\n@@ -842,4 +846,4 @@\n-    __ bcax(v9, __ T16B, v27, v26, v14);               \/\/       bcax            v9.16B, v27.16B, v26.16B, v14.16B\n-    __ eor3(v6, __ T16B, v20, v22, v30);               \/\/       eor3            v6.16B, v20.16B, v22.16B, v30.16B\n-    __ rax1(v24, __ T2D, v2, v30);                     \/\/       rax1            v24.2D, v2.2D, v30.2D\n-    __ xar(v26, __ T2D, v17, v10, 46);                 \/\/       xar             v26.2D, v17.2D, v10.2D, #46\n+    __ bcax(v6, __ T16B, v20, v22, v30);               \/\/       bcax            v6.16B, v20.16B, v22.16B, v30.16B\n+    __ eor3(v24, __ T16B, v2, v30, v26);               \/\/       eor3            v24.16B, v2.16B, v30.16B, v26.16B\n+    __ rax1(v17, __ T2D, v10, v22);                    \/\/       rax1            v17.2D, v10.2D, v22.2D\n+    __ xar(v17, __ T2D, v2, v17, 1);                   \/\/       xar             v17.2D, v2.2D, v17.2D, #1\n@@ -848,4 +852,4 @@\n-    __ sha512h(v17, __ T2D, v2, v17);                  \/\/       sha512h         q17, q2, v17.2D\n-    __ sha512h2(v0, __ T2D, v24, v25);                 \/\/       sha512h2                q0, q24, v25.2D\n-    __ sha512su0(v22, __ T2D, v2);                     \/\/       sha512su0               v22.2D, v2.2D\n-    __ sha512su1(v17, __ T2D, v12, v3);                \/\/       sha512su1               v17.2D, v12.2D, v3.2D\n+    __ sha512h(v24, __ T2D, v25, v22);                 \/\/       sha512h         q24, q25, v22.2D\n+    __ sha512h2(v2, __ T2D, v17, v12);                 \/\/       sha512h2                q2, q17, v12.2D\n+    __ sha512su0(v3, __ T2D, v27);                     \/\/       sha512su0               v3.2D, v27.2D\n+    __ sha512su1(v29, __ T2D, v28, v16);               \/\/       sha512su1               v29.2D, v28.2D, v16.2D\n@@ -854,38 +858,38 @@\n-    __ sve_add(z27, __ S, z29, z28);                   \/\/       add     z27.s, z29.s, z28.s\n-    __ sve_sub(z26, __ D, z6, z9);                     \/\/       sub     z26.d, z6.d, z9.d\n-    __ sve_fadd(z17, __ S, z7, z4);                    \/\/       fadd    z17.s, z7.s, z4.s\n-    __ sve_fmul(z15, __ S, z9, z22);                   \/\/       fmul    z15.s, z9.s, z22.s\n-    __ sve_fsub(z2, __ D, z27, z20);                   \/\/       fsub    z2.d, z27.d, z20.d\n-    __ sve_abs(z5, __ S, p6, z0);                      \/\/       abs     z5.s, p6\/m, z0.s\n-    __ sve_add(z14, __ H, p1, z25);                    \/\/       add     z14.h, p1\/m, z14.h, z25.h\n-    __ sve_asr(z27, __ D, p5, z26);                    \/\/       asr     z27.d, p5\/m, z27.d, z26.d\n-    __ sve_cnt(z24, __ B, p5, z0);                     \/\/       cnt     z24.b, p5\/m, z0.b\n-    __ sve_lsl(z6, __ B, p4, z0);                      \/\/       lsl     z6.b, p4\/m, z6.b, z0.b\n-    __ sve_lsr(z15, __ B, p0, z9);                     \/\/       lsr     z15.b, p0\/m, z15.b, z9.b\n-    __ sve_mul(z5, __ B, p2, z27);                     \/\/       mul     z5.b, p2\/m, z5.b, z27.b\n-    __ sve_neg(z20, __ B, p5, z20);                    \/\/       neg     z20.b, p5\/m, z20.b\n-    __ sve_not(z10, __ D, p2, z16);                    \/\/       not     z10.d, p2\/m, z16.d\n-    __ sve_smax(z6, __ H, p4, z2);                     \/\/       smax    z6.h, p4\/m, z6.h, z2.h\n-    __ sve_smin(z29, __ D, p7, z2);                    \/\/       smin    z29.d, p7\/m, z29.d, z2.d\n-    __ sve_sub(z22, __ H, p7, z14);                    \/\/       sub     z22.h, p7\/m, z22.h, z14.h\n-    __ sve_fabs(z27, __ S, p4, z23);                   \/\/       fabs    z27.s, p4\/m, z23.s\n-    __ sve_fadd(z2, __ D, p3, z10);                    \/\/       fadd    z2.d, p3\/m, z2.d, z10.d\n-    __ sve_fdiv(z10, __ S, p6, z22);                   \/\/       fdiv    z10.s, p6\/m, z10.s, z22.s\n-    __ sve_fmax(z3, __ S, p5, z16);                    \/\/       fmax    z3.s, p5\/m, z3.s, z16.s\n-    __ sve_fmin(z1, __ D, p4, z16);                    \/\/       fmin    z1.d, p4\/m, z1.d, z16.d\n-    __ sve_fmul(z12, __ S, p3, z12);                   \/\/       fmul    z12.s, p3\/m, z12.s, z12.s\n-    __ sve_fneg(z16, __ D, p0, z20);                   \/\/       fneg    z16.d, p0\/m, z20.d\n-    __ sve_frintm(z5, __ D, p1, z7);                   \/\/       frintm  z5.d, p1\/m, z7.d\n-    __ sve_frintn(z12, __ D, p7, z16);                 \/\/       frintn  z12.d, p7\/m, z16.d\n-    __ sve_frintp(z6, __ S, p0, z28);                  \/\/       frintp  z6.s, p0\/m, z28.s\n-    __ sve_fsqrt(z4, __ D, p1, z17);                   \/\/       fsqrt   z4.d, p1\/m, z17.d\n-    __ sve_fsub(z13, __ S, p3, z19);                   \/\/       fsub    z13.s, p3\/m, z13.s, z19.s\n-    __ sve_fmla(z24, __ S, p5, z17, z0);               \/\/       fmla    z24.s, p5\/m, z17.s, z0.s\n-    __ sve_fmls(z23, __ S, p1, z19, z30);              \/\/       fmls    z23.s, p1\/m, z19.s, z30.s\n-    __ sve_fnmla(z16, __ S, p1, z0, z7);               \/\/       fnmla   z16.s, p1\/m, z0.s, z7.s\n-    __ sve_fnmls(z17, __ D, p6, z8, z10);              \/\/       fnmls   z17.d, p6\/m, z8.d, z10.d\n-    __ sve_mla(z20, __ B, p5, z27, z2);                \/\/       mla     z20.b, p5\/m, z27.b, z2.b\n-    __ sve_mls(z15, __ B, p4, z20, z7);                \/\/       mls     z15.b, p4\/m, z20.b, z7.b\n-    __ sve_and(z28, z7, z0);                           \/\/       and     z28.d, z7.d, z0.d\n-    __ sve_eor(z16, z19, z22);                         \/\/       eor     z16.d, z19.d, z22.d\n-    __ sve_orr(z15, z9, z22);                          \/\/       orr     z15.d, z9.d, z22.d\n+    __ sve_add(z26, __ D, z6, z9);                     \/\/       add     z26.d, z6.d, z9.d\n+    __ sve_sub(z17, __ B, z7, z4);                     \/\/       sub     z17.b, z7.b, z4.b\n+    __ sve_fadd(z15, __ S, z9, z22);                   \/\/       fadd    z15.s, z9.s, z22.s\n+    __ sve_fmul(z2, __ D, z27, z20);                   \/\/       fmul    z2.d, z27.d, z20.d\n+    __ sve_fsub(z5, __ D, z26, z0);                    \/\/       fsub    z5.d, z26.d, z0.d\n+    __ sve_abs(z14, __ H, p1, z25);                    \/\/       abs     z14.h, p1\/m, z25.h\n+    __ sve_add(z27, __ D, p5, z26);                    \/\/       add     z27.d, p5\/m, z27.d, z26.d\n+    __ sve_asr(z24, __ B, p5, z0);                     \/\/       asr     z24.b, p5\/m, z24.b, z0.b\n+    __ sve_cnt(z6, __ B, p4, z0);                      \/\/       cnt     z6.b, p4\/m, z0.b\n+    __ sve_lsl(z15, __ B, p0, z9);                     \/\/       lsl     z15.b, p0\/m, z15.b, z9.b\n+    __ sve_lsr(z5, __ B, p2, z27);                     \/\/       lsr     z5.b, p2\/m, z5.b, z27.b\n+    __ sve_mul(z20, __ B, p5, z20);                    \/\/       mul     z20.b, p5\/m, z20.b, z20.b\n+    __ sve_neg(z10, __ D, p2, z16);                    \/\/       neg     z10.d, p2\/m, z16.d\n+    __ sve_not(z6, __ H, p4, z2);                      \/\/       not     z6.h, p4\/m, z2.h\n+    __ sve_smax(z29, __ D, p7, z2);                    \/\/       smax    z29.d, p7\/m, z29.d, z2.d\n+    __ sve_smin(z22, __ H, p7, z14);                   \/\/       smin    z22.h, p7\/m, z22.h, z14.h\n+    __ sve_sub(z27, __ B, p4, z23);                    \/\/       sub     z27.b, p4\/m, z27.b, z23.b\n+    __ sve_fabs(z2, __ D, p3, z10);                    \/\/       fabs    z2.d, p3\/m, z10.d\n+    __ sve_fadd(z10, __ S, p6, z22);                   \/\/       fadd    z10.s, p6\/m, z10.s, z22.s\n+    __ sve_fdiv(z3, __ S, p5, z16);                    \/\/       fdiv    z3.s, p5\/m, z3.s, z16.s\n+    __ sve_fmax(z1, __ D, p4, z16);                    \/\/       fmax    z1.d, p4\/m, z1.d, z16.d\n+    __ sve_fmin(z12, __ S, p3, z12);                   \/\/       fmin    z12.s, p3\/m, z12.s, z12.s\n+    __ sve_fmul(z16, __ D, p0, z20);                   \/\/       fmul    z16.d, p0\/m, z16.d, z20.d\n+    __ sve_fneg(z5, __ D, p1, z7);                     \/\/       fneg    z5.d, p1\/m, z7.d\n+    __ sve_frintm(z12, __ D, p7, z16);                 \/\/       frintm  z12.d, p7\/m, z16.d\n+    __ sve_frintn(z6, __ S, p0, z28);                  \/\/       frintn  z6.s, p0\/m, z28.s\n+    __ sve_frintp(z4, __ D, p1, z17);                  \/\/       frintp  z4.d, p1\/m, z17.d\n+    __ sve_fsqrt(z13, __ S, p3, z19);                  \/\/       fsqrt   z13.s, p3\/m, z19.s\n+    __ sve_fsub(z24, __ S, p5, z17);                   \/\/       fsub    z24.s, p5\/m, z24.s, z17.s\n+    __ sve_fmla(z10, __ D, p6, z6, z19);               \/\/       fmla    z10.d, p6\/m, z6.d, z19.d\n+    __ sve_fmls(z13, __ S, p4, z6, z0);                \/\/       fmls    z13.s, p4\/m, z6.s, z0.s\n+    __ sve_fnmla(z14, __ S, p4, z25, z8);              \/\/       fnmla   z14.s, p4\/m, z25.s, z8.s\n+    __ sve_fnmls(z22, __ S, p5, z22, z27);             \/\/       fnmls   z22.s, p5\/m, z22.s, z27.s\n+    __ sve_mla(z3, __ B, p3, z17, z20);                \/\/       mla     z3.b, p3\/m, z17.b, z20.b\n+    __ sve_mls(z4, __ H, p7, z7, z0);                  \/\/       mls     z4.h, p7\/m, z7.h, z0.h\n+    __ sve_and(z16, z19, z22);                         \/\/       and     z16.d, z19.d, z22.d\n+    __ sve_eor(z15, z9, z22);                          \/\/       eor     z15.d, z9.d, z22.d\n+    __ sve_orr(z25, z5, z30);                          \/\/       orr     z25.d, z5.d, z30.d\n@@ -894,9 +898,9 @@\n-    __ sve_andv(v25, __ S, p1, z30);                   \/\/       andv s25, p1, z30.s\n-    __ sve_orv(v13, __ B, p5, z11);                    \/\/       orv b13, p5, z11.b\n-    __ sve_eorv(v13, __ S, p2, z20);                   \/\/       eorv s13, p2, z20.s\n-    __ sve_smaxv(v25, __ B, p3, z4);                   \/\/       smaxv b25, p3, z4.b\n-    __ sve_sminv(v17, __ D, p2, z6);                   \/\/       sminv d17, p2, z6.d\n-    __ sve_fminv(v4, __ D, p7, z16);                   \/\/       fminv d4, p7, z16.d\n-    __ sve_fmaxv(v26, __ S, p2, z14);                  \/\/       fmaxv s26, p2, z14.s\n-    __ sve_fadda(v11, __ S, p7, z3);                   \/\/       fadda s11, p7, s11, z3.s\n-    __ sve_uaddv(v1, __ S, p6, z21);                   \/\/       uaddv d1, p6, z21.s\n+    __ sve_andv(v13, __ B, p5, z11);                   \/\/       andv b13, p5, z11.b\n+    __ sve_orv(v13, __ S, p2, z20);                    \/\/       orv s13, p2, z20.s\n+    __ sve_eorv(v25, __ B, p3, z4);                    \/\/       eorv b25, p3, z4.b\n+    __ sve_smaxv(v17, __ D, p2, z6);                   \/\/       smaxv d17, p2, z6.d\n+    __ sve_sminv(v4, __ D, p7, z16);                   \/\/       sminv d4, p7, z16.d\n+    __ sve_fminv(v26, __ S, p2, z14);                  \/\/       fminv s26, p2, z14.s\n+    __ sve_fmaxv(v11, __ S, p7, z3);                   \/\/       fmaxv s11, p7, z3.s\n+    __ sve_fadda(v1, __ D, p6, z21);                   \/\/       fadda d1, p6, d1, z21.d\n+    __ sve_uaddv(v14, __ S, p2, z17);                  \/\/       uaddv d14, p2, z17.s\n@@ -921,7 +925,7 @@\n-    0x14000000,     0x17ffffd7,     0x140002d0,     0x94000000,\n-    0x97ffffd4,     0x940002cd,     0x3400000a,     0x34fffa2a,\n-    0x3400594a,     0x35000008,     0x35fff9c8,     0x350058e8,\n-    0xb400000b,     0xb4fff96b,     0xb400588b,     0xb500001d,\n-    0xb5fff91d,     0xb500583d,     0x10000013,     0x10fff8b3,\n-    0x100057d3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36305756,     0x3758000c,     0x375ff7cc,     0x375856ec,\n+    0x14000000,     0x17ffffd7,     0x140002d4,     0x94000000,\n+    0x97ffffd4,     0x940002d1,     0x3400000a,     0x34fffa2a,\n+    0x340059ca,     0x35000008,     0x35fff9c8,     0x35005968,\n+    0xb400000b,     0xb4fff96b,     0xb400590b,     0xb500001d,\n+    0xb5fff91d,     0xb50058bd,     0x10000013,     0x10fff8b3,\n+    0x10005853,     0x90000013,     0x36300016,     0x3637f836,\n+    0x363057d6,     0x3758000c,     0x375ff7cc,     0x3758576c,\n@@ -932,13 +936,13 @@\n-    0x540054c0,     0x54000001,     0x54fff541,     0x54005461,\n-    0x54000002,     0x54fff4e2,     0x54005402,     0x54000002,\n-    0x54fff482,     0x540053a2,     0x54000003,     0x54fff423,\n-    0x54005343,     0x54000003,     0x54fff3c3,     0x540052e3,\n-    0x54000004,     0x54fff364,     0x54005284,     0x54000005,\n-    0x54fff305,     0x54005225,     0x54000006,     0x54fff2a6,\n-    0x540051c6,     0x54000007,     0x54fff247,     0x54005167,\n-    0x54000008,     0x54fff1e8,     0x54005108,     0x54000009,\n-    0x54fff189,     0x540050a9,     0x5400000a,     0x54fff12a,\n-    0x5400504a,     0x5400000b,     0x54fff0cb,     0x54004feb,\n-    0x5400000c,     0x54fff06c,     0x54004f8c,     0x5400000d,\n-    0x54fff00d,     0x54004f2d,     0x5400000e,     0x54ffefae,\n-    0x54004ece,     0x5400000f,     0x54ffef4f,     0x54004e6f,\n+    0x54005540,     0x54000001,     0x54fff541,     0x540054e1,\n+    0x54000002,     0x54fff4e2,     0x54005482,     0x54000002,\n+    0x54fff482,     0x54005422,     0x54000003,     0x54fff423,\n+    0x540053c3,     0x54000003,     0x54fff3c3,     0x54005363,\n+    0x54000004,     0x54fff364,     0x54005304,     0x54000005,\n+    0x54fff305,     0x540052a5,     0x54000006,     0x54fff2a6,\n+    0x54005246,     0x54000007,     0x54fff247,     0x540051e7,\n+    0x54000008,     0x54fff1e8,     0x54005188,     0x54000009,\n+    0x54fff189,     0x54005129,     0x5400000a,     0x54fff12a,\n+    0x540050ca,     0x5400000b,     0x54fff0cb,     0x5400506b,\n+    0x5400000c,     0x54fff06c,     0x5400500c,     0x5400000d,\n+    0x54fff00d,     0x54004fad,     0x5400000e,     0x54ffefae,\n+    0x54004f4e,     0x5400000f,     0x54ffef4f,     0x54004eef,\n@@ -976,1 +980,1 @@\n-    0xbd1b1869,     0x58003ebb,     0x1800000b,     0xf8945060,\n+    0xbd1b1869,     0x58003f3b,     0x1800000b,     0xf8945060,\n@@ -1019,31 +1023,32 @@\n-    0x4eb1aa0f,     0x6eb0f820,     0x0e20b8a4,     0x4e20bab4,\n-    0x0e60b98b,     0x4e60bbdd,     0x0ea0ba0f,     0x4ea0bad5,\n-    0x4ee0b8a4,     0x0ea0f9ee,     0x4ea0faf6,     0x4ee0fb59,\n-    0x2ea0f8e6,     0x6ea0f9ac,     0x6ee0f9ee,     0x2ea1f9cd,\n-    0x6ea1f9ee,     0x6ee1f949,     0x2e205b59,     0x6e205bbc,\n-    0x0e2c1d6a,     0x4e351e93,     0x0ead1d8b,     0x4eb31e51,\n-    0x2e371ed5,     0x6e311e0f,     0x0e3686b4,     0x4e398717,\n-    0x0e7c877a,     0x4e6784c5,     0x0ea884e6,     0x4eb1860f,\n-    0x4ef1860f,     0x0e3bd759,     0x4e32d630,     0x4e7dd79b,\n-    0x2e3a8738,     0x6e31860f,     0x2e7b8759,     0x6e7085ee,\n-    0x2eac856a,     0x6eaf85cd,     0x6ef085ee,     0x0eb6d6b4,\n-    0x4ea3d441,     0x4ef8d6f6,     0x0e209ffe,     0x4e309dee,\n-    0x0e649c62,     0x4e689ce6,     0x0ea59c83,     0x4ea99d07,\n-    0x2ebad738,     0x6ea2d420,     0x6efdd79b,     0x2e3fdfdd,\n-    0x6e27dcc5,     0x6e67dcc5,     0x0e7f97dd,     0x4e6d958b,\n-    0x0ebb9759,     0x4ea29420,     0x0e20cffe,     0x4e22cc20,\n-    0x4e73ce51,     0x2e7e97bc,     0x6e7b9759,     0x2eab9549,\n-    0x6ebb9759,     0x0eaecdac,     0x4eb1ce0f,     0x4eedcd8b,\n-    0x2e2cfd6a,     0x6e33fe51,     0x6e7aff38,     0x0e3766d5,\n-    0x4e396717,     0x0e626420,     0x4e726630,     0x0eac656a,\n-    0x4ea864e6,     0x0e3ef7bc,     0x4e28f4e6,     0x4e67f4c5,\n-    0x0e276cc5,     0x4e366eb4,     0x0e736e51,     0x4e716e0f,\n-    0x0eb36e51,     0x4ebf6fdd,     0x0ebcf77a,     0x4ebef7bc,\n-    0x4ee3f441,     0x2e3d8f9b,     0x6e228c20,     0x2e768eb4,\n-    0x6e7e8fbc,     0x2eb18e0f,     0x6eae8dac,     0x6eec8d6a,\n-    0x0e3ee7bc,     0x4e3ee7bc,     0x4e75e693,     0x0e3836f6,\n-    0x4e2c356a,     0x0e6634a4,     0x4e6037fe,     0x0eb636b4,\n-    0x4eaa3528,     0x4ee037fe,     0x2eb3e651,     0x6eace56a,\n-    0x6efde79b,     0x0e243c62,     0x4e3a3f38,     0x0e663ca4,\n-    0x4e653c83,     0x0eaa3d28,     0x4eb83ef6,     0x4ef33e51,\n-    0x2e2fe5cd,     0x6e26e4a4,     0x6e7ee7bc,     0xba5fd3e3,\n+    0x4eb1aa0f,     0x6eb0f820,     0x7e30f8a4,     0x7e70fab4,\n+    0x7eb0f98b,     0x7ef0fbdd,     0x0e20ba0f,     0x4e20bad5,\n+    0x0e60b8a4,     0x4e60b9ee,     0x0ea0baf6,     0x4ea0bb59,\n+    0x4ee0b8e6,     0x0ea0f9ac,     0x4ea0f9ee,     0x4ee0f9cd,\n+    0x2ea0f9ee,     0x6ea0f949,     0x6ee0fb59,     0x2ea1fbbc,\n+    0x6ea1f96a,     0x6ee1fa93,     0x2e20598b,     0x6e205a51,\n+    0x0e371ed5,     0x4e311e0f,     0x0eb61eb4,     0x4eb91f17,\n+    0x2e3c1f7a,     0x6e271cc5,     0x0e2884e6,     0x4e31860f,\n+    0x0e71860f,     0x4e7b8759,     0x0eb28630,     0x4ebd879b,\n+    0x4efa8738,     0x0e31d60f,     0x4e3bd759,     0x4e70d5ee,\n+    0x2e2c856a,     0x6e2f85cd,     0x2e7085ee,     0x6e7686b4,\n+    0x2ea38441,     0x6eb886f6,     0x6ee087fe,     0x0eb0d5ee,\n+    0x4ea4d462,     0x4ee8d4e6,     0x0e259c83,     0x4e299d07,\n+    0x0e7a9f38,     0x4e629c20,     0x0ebd9f9b,     0x4ebf9fdd,\n+    0x2ea7d4c5,     0x6ea7d4c5,     0x6effd7dd,     0x2e2ddd8b,\n+    0x6e3bdf59,     0x6e62dc20,     0x0e6097fe,     0x4e629420,\n+    0x0eb39651,     0x4ebe97bc,     0x0e3bcf59,     0x4e2bcd49,\n+    0x4e7bcf59,     0x2e6e95ac,     0x6e71960f,     0x2ead958b,\n+    0x6eac956a,     0x0eb3ce51,     0x4ebacf38,     0x4ef7ced5,\n+    0x2e39ff17,     0x6e22fc20,     0x6e72fe30,     0x0e2c656a,\n+    0x4e2864e6,     0x0e7e67bc,     0x4e6864e6,     0x0ea764c5,\n+    0x4ea764c5,     0x0e36f6b4,     0x4e33f651,     0x4e71f60f,\n+    0x0e336e51,     0x4e3f6fdd,     0x0e7c6f7a,     0x4e7e6fbc,\n+    0x0ea36c41,     0x4ebd6f9b,     0x0ea2f420,     0x4eb6f6b4,\n+    0x4efef7bc,     0x2e318e0f,     0x6e2e8dac,     0x2e6c8d6a,\n+    0x6e7e8fbc,     0x2ebe8fbc,     0x6eb58e93,     0x6ef88ef6,\n+    0x0e2ce56a,     0x4e26e4a4,     0x4e60e7fe,     0x0e3636b4,\n+    0x4e2a3528,     0x0e6037fe,     0x4e733651,     0x0eac356a,\n+    0x4ebd379b,     0x4ee43462,     0x2ebae738,     0x6ea6e4a4,\n+    0x6ee5e483,     0x0e2a3d28,     0x4e383ef6,     0x0e733e51,\n+    0x4e6f3dcd,     0x0ea63ca4,     0x4ebe3fbc,     0x4ef93f17,\n+    0x2e37e6d5,     0x6e3be759,     0x6e7ae738,     0xba5fd3e3,\n@@ -1069,33 +1074,33 @@\n-    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8388355,\n-    0xf8380303,     0xf83a11f7,     0xf8352303,     0xf8283299,\n-    0xf8305051,     0xf8214300,     0xf8247183,     0xf83f615c,\n-    0xf8ba8182,     0xf8b0003f,     0xf8ad101d,     0xf8b3222c,\n-    0xf8b6338d,     0xf8be503f,     0xf8ba409c,     0xf8be70c4,\n-    0xf8be61fa,     0xf8e98188,     0xf8e00034,     0xf8f81002,\n-    0xf8e92358,     0xf8f0307e,     0xf8ea5157,     0xf8e44050,\n-    0xf8eb7148,     0xf8ef6051,     0xf86a818c,     0xf86f004d,\n-    0xf8671354,     0xf8702044,     0xf86431ec,     0xf87551f0,\n-    0xf86b42f5,     0xf86c72fa,     0xf87c616e,     0xb8388181,\n-    0xb83f020a,     0xb8271062,     0xb82d2233,     0xb8303023,\n-    0xb82b50be,     0xb82843af,     0xb83e7280,     0xb82762f4,\n-    0xb8bc8375,     0xb8b90025,     0xb8b713f0,     0xb8a5212c,\n-    0xb8bc33af,     0xb8b6527f,     0xb8bf41c5,     0xb8b071ff,\n-    0xb8bb6214,     0xb8ec812b,     0xb8e6023e,     0xb8fb13dc,\n-    0xb8e7228a,     0xb8ea3304,     0xb8f152d1,     0xb8e341fd,\n-    0xb8f67273,     0xb8f661e2,     0xb866820c,     0xb86b02ed,\n-    0xb861127e,     0xb8652051,     0xb87031b6,     0xb86a53b5,\n-    0xb87b436c,     0xb86373e1,     0xb8786233,     0xce3a3b69,\n-    0xce167a86,     0xce7e8c58,     0xce8aba3a,     0xce718051,\n-    0xce798700,     0xcec08056,     0xce638991,     0x04bc03bb,\n-    0x04e904da,     0x658400f1,     0x6596092f,     0x65d40762,\n-    0x0496b805,     0x0440072e,     0x04d0975b,     0x041ab418,\n-    0x04139006,     0x0411812f,     0x04100b65,     0x0417b694,\n-    0x04deaa0a,     0x04481046,     0x04ca1c5d,     0x04411dd6,\n-    0x049cb2fb,     0x65c08d42,     0x658d9aca,     0x65869603,\n-    0x65c79201,     0x65828d8c,     0x04dda290,     0x65c2a4e5,\n-    0x65c0be0c,     0x6581a386,     0x65cda624,     0x65818e6d,\n-    0x65a01638,     0x65be2677,     0x65a74410,     0x65ea7911,\n-    0x04025774,     0x0407728f,     0x042030fc,     0x04b63270,\n-    0x0476312f,     0x049a27d9,     0x0418356d,     0x04992a8d,\n-    0x04082c99,     0x04ca28d1,     0x65c73e04,     0x658629da,\n-    0x65983c6b,     0x04813aa1,\n+    0x1e7c3000,     0x1e7e1000,     0x1e7e3000,     0xf8238358,\n+    0xf83702af,     0xf8231118,     0xf8392214,     0xf8313022,\n+    0xf8205098,     0xf82343ec,     0xf83c734a,     0xf82261ec,\n+    0xf8bf81a1,     0xf8bd0260,     0xf8ac12d1,     0xf8ad23dc,\n+    0xf8bf3341,     0xf8bc53c4,     0xf8a443c6,     0xf8ba7130,\n+    0xf8a8600c,     0xf8f48301,     0xf8e20120,     0xf8f8121a,\n+    0xf8fe2143,     0xf8f7308a,     0xf8f05162,     0xf8e841ea,\n+    0xf8f17142,     0xf8ec61ec,     0xf86d80e2,     0xf874021a,\n+    0xf8641082,     0xf86c22b0,     0xf8703170,     0xf8755197,\n+    0xf87a4397,     0xf86e730b,     0xf86163ec,     0xb82a80f0,\n+    0xb82201a3,     0xb8331211,     0xb8232161,     0xb83e3105,\n+    0xb82f53dd,     0xb82040f4,     0xb8347397,     0xb835633b,\n+    0xb8a582e1,     0xb8b000bf,     0xb8ac1389,     0xb8af22dd,\n+    0xb8bf33f3,     0xb8a551ee,     0xb8bf4370,     0xb8b47190,\n+    0xb8ab60c9,     0xb8fe8371,     0xb8fc00fe,     0xb8ea1154,\n+    0xb8e42238,     0xb8f13076,     0xb8fd52cf,     0xb8f342d3,\n+    0xb8e270cf,     0xb8ec6170,     0xb86d8037,     0xb87e00b3,\n+    0xb8711202,     0xb876214d,     0xb875337d,     0xb86c507b,\n+    0xb861431f,     0xb8737131,     0xb87c61fb,     0xce367a86,\n+    0xce1e6858,     0xce768d51,     0xce910451,     0xce768338,\n+    0xce6c8622,     0xcec08363,     0xce708b9d,     0x04e900da,\n+    0x042404f1,     0x6596012f,     0x65d40b62,     0x65c00745,\n+    0x0456a72e,     0x04c0175b,     0x04109418,     0x041ab006,\n+    0x0413812f,     0x04118b65,     0x04101694,     0x04d7aa0a,\n+    0x045eb046,     0x04c81c5d,     0x044a1dd6,     0x040112fb,\n+    0x04dcad42,     0x65809aca,     0x658d9603,     0x65c69201,\n+    0x65878d8c,     0x65c28290,     0x04dda4e5,     0x65c2be0c,\n+    0x6580a386,     0x65c1a624,     0x658dae6d,     0x65819638,\n+    0x65f318ca,     0x65a030cd,     0x65a8532e,     0x65bb76d6,\n+    0x04144e23,     0x04407ce4,     0x04363270,     0x04b6312f,\n+    0x047e30b9,     0x041a356d,     0x04982a8d,     0x04192c99,\n+    0x04c828d1,     0x04ca3e04,     0x658729da,     0x65863c6b,\n+    0x65d83aa1,     0x04812a2e,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":337,"deletions":332,"binary":false,"changes":669,"status":"modified"},{"patch":"@@ -0,0 +1,98 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, Huawei Technologies Co., Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+package org.openjdk.bench.vm.compiler;\n+\n+import org.openjdk.jmh.annotations.*;\n+import org.openjdk.jmh.infra.*;\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.Random;\n+\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Thread)\n+public class VectorReduction {\n+    @Param({\"512\"})\n+    public int COUNT;\n+\n+    private float[]  floatsA;\n+    private float[]  floatsB;\n+    private double[] doublesA;\n+    private double[] doublesB;\n+\n+    @Param(\"0\")\n+    private int seed;\n+    private Random r = new Random(seed);\n+\n+    @Setup\n+    public void init() {\n+        floatsA = new float[COUNT];\n+        floatsB = new float[COUNT];\n+        doublesA = new double[COUNT];\n+        doublesB = new double[COUNT];\n+\n+        for (int i = 0; i < COUNT; i++) {\n+            floatsA[i] = r.nextFloat();\n+            floatsB[i] = r.nextFloat();\n+            doublesA[i] = r.nextDouble();\n+            doublesB[i] = r.nextDouble();\n+        }\n+    }\n+\n+    @Benchmark\n+    public void maxRedF(Blackhole bh) {\n+        float max = 0.0f;\n+        for (int i = 0; i < COUNT; i++) {\n+            max = Math.max(max, floatsA[i] - floatsB[i]);\n+        }\n+        bh.consume(max);\n+    }\n+\n+    @Benchmark\n+    public void minRedF(Blackhole bh) {\n+        float min = 0.0f;\n+        for (int i = 0; i < COUNT; i++) {\n+            min = Math.min(min, floatsA[i] - floatsB[i]);\n+        }\n+        bh.consume(min);\n+    }\n+\n+    @Benchmark\n+    public void maxRedD(Blackhole bh) {\n+        double max = 0.0d;\n+        for (int i = 0; i < COUNT; i++) {\n+            max = Math.max(max, doublesA[i] - doublesB[i]);\n+        }\n+        bh.consume(max);\n+    }\n+\n+    @Benchmark\n+    public void minRedD(Blackhole bh) {\n+        double min = 0.0d;\n+        for (int i = 0; i < COUNT; i++) {\n+            min = Math.min(min, doublesA[i] - doublesB[i]);\n+        }\n+        bh.consume(min);\n+    }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/vm\/compiler\/VectorReductionFloatingMinMax.java","additions":98,"deletions":0,"binary":false,"changes":98,"status":"added"}]}