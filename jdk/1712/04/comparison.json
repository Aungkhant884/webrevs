{"files":[{"patch":"@@ -1776,1 +1776,1 @@\n-        new Command(\"dumpheap\", \"dumpheap [filename]\", false) {\n+        new Command(\"dumpheap\", \"dumpheap [gz=<1-9>] [filename]\", false) {\n@@ -1778,1 +1778,1 @@\n-                if (t.countTokens() > 1) {\n+                if (t.countTokens() > 2) {\n@@ -1782,3 +1782,20 @@\n-                    String filename;\n-                    if (t.countTokens() == 1) {\n-                        filename = t.nextToken();\n+                    String filename = \"heap.bin\";\n+                    int gzlevel = 0;\n+                    \/* Parse \"gz=\" option. *\/\n+                    String option = t.nextToken();\n+                    String[] keyValue = option.split(\"=\");\n+                    if (keyValue[0].equals(\"gz\")) {\n+                        String level = keyValue[1];\n+                        try {\n+                            gzlevel = Integer.parseInt(level);\n+                        } catch (NumberFormatException e) {\n+                            err.println(\"gz option value not an integer (\"+level+\")\");\n+                            usage();\n+                            return;\n+                        }\n+                        if (gzlevel < 1 || gzlevel > 9) {\n+                            err.println(\"Compression level out of range (1-9): \" + level);\n+                            usage();\n+                            return;\n+                        }\n+                        filename = \"heap.bin.gz\";\n@@ -1786,1 +1803,8 @@\n-                        filename = \"heap.bin\";;\n+                      usage();\n+                      return;\n+                    }\n+                    \/* Parse filename. *\/\n+                    if (t.countTokens() == 2) {\n+                       filename = t.nextToken();\n+                    } else if (t.countTokens() == 1) {\n+                       filename = option;\n@@ -1789,1 +1813,1 @@\n-                        jmap.writeHeapHprofBin(filename);\n+                        jmap.writeHeapHprofBin(filename, gzlevel);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/CommandProcessor.java","additions":31,"deletions":7,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -130,0 +130,1 @@\n+        System.out.println(\"    --gz <1-9>              The compression level for gzipped dump file.\");\n@@ -304,10 +305,12 @@\n-        Map<String, String> longOptsMap = Map.of(\"exe=\", \"exe\",\n-                                                 \"core=\", \"core\",\n-                                                 \"pid=\", \"pid\",\n-                                                 \"connect=\", \"connect\",\n-                                                 \"heap\", \"-heap\",\n-                                                 \"binaryheap\", \"binaryheap\",\n-                                                 \"dumpfile=\", \"dumpfile\",\n-                                                 \"histo\", \"-histo\",\n-                                                 \"clstats\", \"-clstats\",\n-                                                 \"finalizerinfo\", \"-finalizerinfo\");\n+        Map<String, String> longOptsMap = Map.ofEntries(\n+                Map.entry(\"exe=\", \"exe\"),\n+                Map.entry(\"core=\", \"core\"),\n+                Map.entry(\"pid=\", \"pid\"),\n+                Map.entry(\"connect=\", \"connect\"),\n+                Map.entry(\"heap\", \"-heap\"),\n+                Map.entry(\"binaryheap\", \"binaryheap\"),\n+                Map.entry(\"dumpfile=\", \"dumpfile\"),\n+                Map.entry(\"gz=\", \"gz\"),\n+                Map.entry(\"histo\", \"-histo\"),\n+                Map.entry(\"clstats\", \"-clstats\"),\n+                Map.entry(\"finalizerinfo\", \"-finalizerinfo\"));\n@@ -318,0 +321,2 @@\n+        String gzLevel = newArgMap.get(\"gz\");\n+        String command = \"-heap:format=b\";\n@@ -322,4 +327,5 @@\n-            if (dumpfile == null) {\n-                newArgMap.put(\"-heap:format=b\", null);\n-            } else {\n-                newArgMap.put(\"-heap:format=b,file=\" + dumpfile, null);\n+            if (gzLevel != null) {\n+                command += \",gz=\" + gzLevel;\n+            }\n+            if (dumpfile != null) {\n+                command += \",file=\" + dumpfile;\n@@ -327,0 +333,1 @@\n+            newArgMap.put(command, null);\n@@ -331,0 +338,1 @@\n+        newArgMap.remove(\"gz\");\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/SALauncher.java","additions":22,"deletions":14,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-        return \"-heap|-heap:format=b|-histo|-clstats|-finalizerinfo\";\n+        return \"-heap|-heap:format=b[,gz=<1-9>]|-histo|-clstats|-finalizerinfo\";\n@@ -57,6 +57,11 @@\n-        System.out.println(\"    <no option>\\tto print same info as Solaris pmap\");\n-        System.out.println(\"    -heap\\tto print java heap summary\");\n-        System.out.println(\"    -heap:format=b\\tto dump java heap in hprof binary format\");\n-        System.out.println(\"    -histo\\tto print histogram of java object heap\");\n-        System.out.println(\"    -clstats\\tto print class loader statistics\");\n-        System.out.println(\"    -finalizerinfo\\tto print information on objects awaiting finalization\");\n+        System.out.println(\"    <no option>\\tTo print same info as Solaris pmap.\");\n+        System.out.println(\"    -heap\\tTo print java heap summary.\");\n+        System.out.println(\"    -heap:format=b[,gz=<1-9>]\\tTo dump java heap in hprof binary format.\");\n+        System.out.println(\"                             \\tIf gz specified, the heap dump is written\");\n+        System.out.println(\"                             \\tin gzipped format using the given compression level.\");\n+        System.err.println(\"                             \\t1 (recommended) is the fastest, 9 the strongest compression.\");\n+        System.out.println(\"    -heap:format=x           \\tTo dump java heap in GXL format.\");\n+        System.out.println(\"                             \\tPlease be aware that \\\"gz\\\" option is not valid for heap dump in GXL format.\");\n+        System.out.println(\"    -histo\\tTo print histogram of java object heap.\");\n+        System.out.println(\"    -clstats\\tTo print class loader statistics.\");\n+        System.out.println(\"    -finalizerinfo\\tTo print information on objects awaiting finalization.\");\n@@ -75,0 +80,1 @@\n+    private static int gzLevel = 0;\n@@ -97,1 +103,1 @@\n-            writeHeapHprofBin(dumpfile);\n+            writeHeapHprofBin(dumpfile, gzLevel);\n@@ -154,0 +160,16 @@\n+                        } else if (keyValue[0].equals(\"gz\")) {\n+                            String level = keyValue[1];\n+                            if (mode == MODE_HEAP_GRAPH_GXL) {\n+                                System.err.println(\"The \\\"gz\\\" option is not compatible with heap dump in GXL format.\");\n+                                System.exit(1);\n+                            }\n+                            try {\n+                                gzLevel = Integer.parseInt(level);\n+                            } catch (NumberFormatException e) {\n+                                System.err.println(\"gz option value not an integer (\"+level+\")\");\n+                                System.exit(1);\n+                            }\n+                            if (gzLevel < 1 || gzLevel > 9) {\n+                                System.err.println(\"Compression level out of range (1-9): \" + level);\n+                                System.exit(1);\n+                            }\n@@ -179,1 +201,1 @@\n-    public boolean writeHeapHprofBin(String fileName) {\n+    public boolean writeHeapHprofBin(String fileName, int gzLevel) {\n@@ -181,1 +203,9 @@\n-            HeapGraphWriter hgw = new HeapHprofBinWriter();\n+            HeapGraphWriter hgw;\n+            if (gzLevel == 0) {\n+                hgw = new HeapHprofBinWriter();\n+            } else if (gzLevel >=1 && gzLevel <= 9) {\n+                hgw = new HeapHprofBinWriter(gzLevel);\n+            } else {\n+                System.err.println(\"Illegal compression level: \" + gzLevel);\n+                return false;\n+            }\n@@ -191,1 +221,1 @@\n-        return writeHeapHprofBin(\"heap.bin\");\n+        return writeHeapHprofBin(\"heap.bin\", 0);\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/tools\/JMap.java","additions":41,"deletions":11,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+import java.util.zip.*;\n@@ -389,0 +390,7 @@\n+        this.gzLevel = 0;\n+    }\n+\n+    public HeapHprofBinWriter(int gzLevel) {\n+        this.KlassMap = new ArrayList<Klass>();\n+        this.names = new HashSet<Symbol>();\n+        this.gzLevel = gzLevel;\n@@ -392,0 +400,1 @@\n+        GZIPOutputStream gzipOut = null;\n@@ -394,0 +403,4 @@\n+        \/\/ Check weather we should dump the heap as segments\n+        useSegmentedHeapDump = isCompression() ||\n+                (vm.getUniverse().heap().used() > HPROF_SEGMENTED_HEAP_DUMP_THRESHOLD);\n+\n@@ -396,2 +409,15 @@\n-        out = new DataOutputStream(new BufferedOutputStream(fos));\n-\n+        hprofBufferedOut = null;\n+        OutputStream dataOut = fos;\n+        if (useSegmentedHeapDump) {\n+            if (isCompression()) {\n+                dataOut = new GZIPOutputStream(fos) {\n+                    {\n+                        this.def.setLevel(gzLevel);\n+                    }\n+                };\n+            }\n+            hprofBufferedOut = new SegmentedOutputStream(dataOut);\n+        } else {\n+            hprofBufferedOut = new SegmentedOutputStream(fos, false);\n+        }\n+        out = new DataOutputStream(hprofBufferedOut);\n@@ -422,3 +448,0 @@\n-        \/\/ Check weather we should dump the heap as segments\n-        useSegmentedHeapDump = vm.getUniverse().heap().used() > HPROF_SEGMENTED_HEAP_DUMP_THRESHOLD;\n-\n@@ -450,4 +473,5 @@\n-        \/\/ Fill in final length\n-        fillInHeapRecordLength();\n-\n-        if (useSegmentedHeapDump) {\n+        if (!useSegmentedHeapDump) {\n+            \/\/ Fill in final length\n+            fillInHeapRecordLength();\n+        } else {\n+            hprofBufferedOut.exitSegmentMode();\n@@ -462,0 +486,1 @@\n+        out.close();\n@@ -463,3 +488,1 @@\n-\n-        \/\/ close the file stream\n-        fos.close();\n+        hprofBufferedOut = null;\n@@ -470,5 +493,5 @@\n-        if (currentSegmentStart == 0) {\n-            \/\/ write heap data header, depending on heap size use segmented heap\n-            \/\/ format\n-            out.writeByte((byte) (useSegmentedHeapDump ? HPROF_HEAP_DUMP_SEGMENT\n-                    : HPROF_HEAP_DUMP));\n+        if (useSegmentedHeapDump) {\n+            hprofBufferedOut.enterSegmentMode();\n+        } else if (currentSegmentStart == 0) {\n+            \/\/ write heap data header\n+            out.writeByte((byte) (HPROF_HEAP_DUMP));\n@@ -489,5 +512,1 @@\n-            out.flush();\n-            if ((fos.getChannel().position() - currentSegmentStart - 4L) >= HPROF_SEGMENTED_HEAP_DUMP_SEGMENT_SIZE) {\n-                fillInHeapRecordLength();\n-                currentSegmentStart = 0;\n-            }\n+            hprofBufferedOut.exitSegmentMode();\n@@ -498,0 +517,2 @@\n+        \/\/ For compression, the length is written by SegmentedOutputStream\n+        if (useSegmentedHeapDump) return;\n@@ -572,0 +593,2 @@\n+        \/\/ only process when segmented heap dump is not used, since SegmentedOutputStream\n+        \/\/ could create segment automatically.\n@@ -573,1 +596,1 @@\n-        if (currentRecordLength > 0 &&\n+        if ((!useSegmentedHeapDump) && currentRecordLength > 0 &&\n@@ -1229,0 +1252,4 @@\n+    private boolean isCompression() {\n+      return (gzLevel >= 1 && gzLevel <= 9);\n+    }\n+\n@@ -1236,0 +1263,1 @@\n+    private SegmentedOutputStream hprofBufferedOut;\n@@ -1239,0 +1267,1 @@\n+    private int gzLevel;\n@@ -1277,0 +1306,193 @@\n+\n+    \/**\n+     * The class implements a buffered output stream for segment data.\n+     * It is used inside HeapHprofBinWritter only for heap dump.\n+     * Because the current implementation of segment heap dump needs to update\n+     * the segment size at segment header, and because it is hard to modify the\n+     * compressed data after they are written to file, this class first saves the\n+     * uncompressed data into an internal buffer, and then writes through to the\n+     * GZIPOutputStream when the whole segment data are ready and the size is updated.\n+     * When the data to written is larger than internal buffer, or the internal buffer\n+     * is full, the internal buffer will be extend to a larger one.\n+     * This class defines a switch to turn on\/off the segment mode. if turned off,\n+     * it behaves same as BufferedOutputStream.\n+     * *\/\n+    private class SegmentedOutputStream extends BufferedOutputStream {\n+        \/**\n+         * Creates a new buffered output stream to support segment heap dump data.\n+         *\n+         * @param   out                 the underlying output stream.\n+         * @param   allowSegmental      whether allow segmental dump.\n+         *\/\n+        public SegmentedOutputStream(OutputStream out, boolean allowSegmental) {\n+            super(out, 8192);\n+            segmentMode = false;\n+            this.allowSegmental = allowSegmental;\n+            segmentBuffer = new byte[SEGMENT_BUFFER_SIZE];\n+            segmentWritten = 0;\n+        }\n+\n+        \/**\n+         * Creates a new buffered output stream to support segment heap dump data.\n+         *\n+         * @param   out                 the underlying output stream.\n+         *\/\n+        public SegmentedOutputStream(OutputStream out) {\n+            this(out, true);\n+        }\n+\n+        \/**\n+         * Writes the specified byte to this buffered output stream.\n+         *\n+         * @param      b   the byte to be written.\n+         * @throws     IOException  if an I\/O error occurs.\n+         *\/\n+        @Override\n+        public synchronized void write(int b) throws IOException {\n+           if (segmentMode) {\n+               if (segmentWritten == 0) {\n+                   \/\/ At the begining of the segment.\n+                   writeSegmentHeader();\n+               } else if (segmentWritten == segmentBuffer.length) {\n+                   int newSize = segmentBuffer.length + SEGMENT_BUFFER_INC_SIZE;\n+                   byte newBuf[] = new byte[newSize];\n+                   System.arraycopy(segmentBuffer, 0, newBuf, 0, segmentWritten);\n+                   segmentBuffer = newBuf;\n+               }\n+               segmentBuffer[segmentWritten++] = (byte)b;\n+               return;\n+           }\n+           super.write(b);\n+        }\n+\n+        \/**\n+         * Writes {@code len} bytes from the specified byte array\n+         * starting at offset {@code off} to this output stream.\n+         *\n+         * @param      b     the data.\n+         * @param      off   the start offset in the data.\n+         * @param      len   the number of bytes to write.\n+         * @throws     IOException  if an I\/O error occurs.\n+         *\/\n+        @Override\n+        public synchronized void write(byte b[], int off, int len) throws IOException {\n+            if (segmentMode) {\n+                if (segmentWritten == 0) {\n+                    writeSegmentHeader();\n+                }\n+                \/\/ Data size is larger than segment buffer length, extend segment buffer.\n+                if (segmentWritten + len > segmentBuffer.length) {\n+                    int newSize = segmentBuffer.length + Math.max(SEGMENT_BUFFER_INC_SIZE, len);\n+                    byte newBuf[] = new byte[newSize];\n+                    System.arraycopy(segmentBuffer, 0, newBuf, 0, segmentWritten);\n+                    segmentBuffer = newBuf;\n+                }\n+                System.arraycopy(b, off, segmentBuffer, segmentWritten, len);\n+                segmentWritten += len;\n+                return;\n+            }\n+            super.write(b, off, len);\n+        }\n+\n+        \/**\n+         * Flushes this buffered output stream. This forces any buffered\n+         * output bytes to be written out to the underlying output stream.\n+         *\n+         * @throws     IOException  if an I\/O error occurs.\n+         * @see        java.io.FilterOutputStream#out\n+         *\/\n+        @Override\n+        public synchronized void flush() throws IOException {\n+            if (segmentMode) {\n+                assert segmentWritten > SEGMENT_HEADER_SIZE\n+                        : \"invalid header in segment mode\";\n+\n+                if (segmentWritten > (segmentBuffer.length)) {\n+                    throw new RuntimeException(\"Heap segment size overflow.\");\n+                }\n+\n+                if (segmentWritten > SEGMENT_HEADER_SIZE) {\n+                    fillSegmentSize(segmentWritten - SEGMENT_HEADER_SIZE);\n+                    super.write(segmentBuffer, 0, segmentWritten);\n+                    super.flush();\n+                    segmentWritten = 0;\n+                }\n+                return;\n+            }\n+            super.flush();\n+        }\n+\n+        \/**\n+         * Enters segment mode, flush buffered data and set flag.\n+         *\/\n+        public void enterSegmentMode() throws IOException {\n+            if (!allowSegmental) return;\n+            if (!segmentMode) {\n+                super.flush();\n+                segmentMode = true;\n+                segmentWritten = 0;\n+            }\n+        }\n+\n+        \/**\n+         * Exits segment mode, flush segment data.\n+         *\/\n+        public void exitSegmentMode() throws IOException {\n+            if (!allowSegmental) return;\n+            if (segmentMode) {\n+                flush();\n+                assert segmentWritten == 0;\n+                segmentMode = false;\n+            }\n+        }\n+\n+        \/**\n+         * Writes the write segment header into internal buffer.\n+         *\/\n+        private void writeSegmentHeader() {\n+            assert segmentWritten == 0;\n+            segmentBuffer[segmentWritten++] = (byte)HPROF_HEAP_DUMP_SEGMENT;\n+            writeInteger(0);\n+            \/\/ segment size, write dummy length of 0 and we'll fix it later.\n+            writeInteger(0);\n+        }\n+\n+        \/**\n+         * Fills the segment data size into the header.\n+         *\/\n+        private void fillSegmentSize(int size) {\n+            segmentBuffer[5] = (byte)(size >>> 24);\n+            segmentBuffer[6] = (byte)(size >>> 16);\n+            segmentBuffer[7] = (byte)(size >>>  8);\n+            segmentBuffer[8] = (byte)(size >>>  0);\n+        }\n+\n+        \/**\n+         * Writes an {@code int} to the internal segment buffer\n+         * {@code written} is incremented by {@code 4}.\n+         *\/\n+        private final void writeInteger(int v) {\n+            segmentBuffer[segmentWritten++] = (byte)(v >>> 24);\n+            segmentBuffer[segmentWritten++] = (byte)(v >>> 16);\n+            segmentBuffer[segmentWritten++] = (byte)(v >>>  8);\n+            segmentBuffer[segmentWritten++] = (byte)(v >>>  0);\n+        }\n+\n+        \/\/ The buffer size for segmentBuffer.\n+        \/\/ Since it is hard to calculate and fill the data size of an segment in compressed\n+        \/\/ data, making the segment data stored in this buffer could help rewrite the data\n+        \/\/ size before the segment data are written to GZIPOutputStream.\n+        private static final int SEGMENT_BUFFER_SIZE = 1 << 20;\n+        \/\/ Buffer size used for resize the segment buffer.\n+        private static final int SEGMENT_BUFFER_INC_SIZE = 1 << 10;\n+        \/\/ Headers:\n+        \/\/    1 byte for HPROF_HEAP_DUMP_SEGMENT\n+        \/\/    4 bytes for timestamp\n+        \/\/    4 bytes for size\n+        private static final int SEGMENT_HEADER_SIZE = 9;\n+        \/\/ Segment support.\n+        private boolean segmentMode;\n+        private boolean allowSegmental;\n+        private byte segmentBuffer[];\n+        private int segmentWritten;\n+    }\n","filename":"src\/jdk.hotspot.agent\/share\/classes\/sun\/jvm\/hotspot\/utilities\/HeapHprofBinWriter.java","additions":245,"deletions":23,"binary":false,"changes":268,"status":"modified"}]}