{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -682,0 +682,4 @@\n+    \/**\n+     * Read and discard urgent data (MSG_OOB) on the socket.\n+     *\/\n+    static native boolean discardOOB(FileDescriptor fd) throws IOException;\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/Net.java","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,1 @@\n+import java.io.FileDescriptor;\n@@ -77,0 +78,4 @@\n+    FileDescriptor getFD() {\n+        return channel.getFD();\n+    }\n+\n","filename":"src\/java.base\/share\/classes\/sun\/nio\/ch\/SelectionKeyImpl.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,1 +38,1 @@\n-        PrivilegedAction<SelectorProviderImpl> pa = WindowsSelectorProvider::new;\n+        PrivilegedAction<SelectorProviderImpl> pa = WEPollSelectorProvider::new;\n","filename":"src\/java.base\/windows\/classes\/sun\/nio\/ch\/DefaultSelectorProvider.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -64,2 +64,2 @@\n-    private final SourceChannel source;\n-    private final SinkChannel sink;\n+    private final SourceChannelImpl source;\n+    private final SinkChannelImpl sink;\n@@ -67,1 +67,1 @@\n-    private class Initializer\n+    private static class Initializer\n@@ -206,1 +206,1 @@\n-    public SourceChannel source() {\n+    public SourceChannelImpl source() {\n@@ -210,1 +210,1 @@\n-    public SinkChannel sink() {\n+    public SinkChannelImpl sink() {\n","filename":"src\/java.base\/windows\/classes\/sun\/nio\/ch\/PipeImpl.java","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -0,0 +1,128 @@\n+\/*\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package sun.nio.ch;\n+\n+import java.io.IOException;\n+import jdk.internal.misc.Unsafe;\n+\n+\/**\n+ * Provides access to wepoll.\n+ *\/\n+class WEPoll {\n+    private static final Unsafe UNSAFE = Unsafe.getUnsafe();\n+\n+    private WEPoll() { }\n+\n+    \/**\n+     * typedef union epoll_data {\n+     *     void *ptr;\n+     *     int fd;\n+     *     uint32_t u32;\n+     *     uint64_t u64;\n+     *     SOCKET sock;   \/\/ Windows specific\n+     *     HANDLE hnd;    \/\/ Windows specific\n+     *  } epoll_data_t;\n+     *\n+     * struct epoll_event {\n+     *     uint32_t events;\n+     *     epoll_data_t data;\n+     * }\n+     *\/\n+    private static final int SIZEOF_EPOLLEVENT   = eventSize();\n+    private static final int OFFSETOF_EVENTS     = eventsOffset();\n+    private static final int OFFSETOF_SOCK       = dataOffset();\n+\n+    \/\/ opcodes\n+    static final int EPOLL_CTL_ADD  = 1;\n+    static final int EPOLL_CTL_MOD  = 2;\n+    static final int EPOLL_CTL_DEL  = 3;\n+\n+    \/\/ events\n+    static final int EPOLLIN   = (1 << 0);\n+    static final int EPOLLPRI  = (1 << 1);\n+    static final int EPOLLOUT  = (1 << 2);\n+    static final int EPOLLERR  = (1 << 3);\n+    static final int EPOLLHUP  = (1 << 4);\n+\n+    \/\/ flags\n+    static final int EPOLLONESHOT   = (1 << 31);\n+\n+    \/**\n+     * Allocates a poll array to handle up to {@code count} events.\n+     *\/\n+    static long allocatePollArray(int count) {\n+        return UNSAFE.allocateMemory(count * SIZEOF_EPOLLEVENT);\n+    }\n+\n+    \/**\n+     * Free a poll array\n+     *\/\n+    static void freePollArray(long address) {\n+        UNSAFE.freeMemory(address);\n+    }\n+\n+    \/**\n+     * Returns event[i];\n+     *\/\n+    static long getEvent(long address, int i) {\n+        return address + (SIZEOF_EPOLLEVENT*i);\n+    }\n+\n+    \/**\n+     * Returns event->data.socket\n+     *\/\n+    static long getSocket(long eventAddress) {\n+        return UNSAFE.getLong(eventAddress + OFFSETOF_SOCK);\n+    }\n+\n+    \/**\n+     * Returns event->events\n+     *\/\n+    static int getEvents(long eventAddress) {\n+        return UNSAFE.getInt(eventAddress + OFFSETOF_EVENTS);\n+    }\n+\n+    \/\/ -- Native methods --\n+\n+    private static native int eventSize();\n+\n+    private static native int eventsOffset();\n+\n+    private static native int dataOffset();\n+\n+    static native long create() throws IOException;\n+\n+    static native int ctl(long h, int opcode, long s, int events);\n+\n+    static native int wait(long h, long pollAddress, int numfds, int timeout)\n+        throws IOException;\n+\n+    static native void close(long h);\n+\n+    static {\n+        IOUtil.load();\n+    }\n+}\n","filename":"src\/java.base\/windows\/classes\/sun\/nio\/ch\/WEPoll.java","additions":128,"deletions":0,"binary":false,"changes":128,"status":"added"},{"patch":"@@ -0,0 +1,276 @@\n+\/*\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package sun.nio.ch;\n+\n+import java.io.FileDescriptor;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ClosedSelectorException;\n+import java.nio.channels.Pipe;\n+import java.nio.channels.SelectionKey;\n+import java.nio.channels.Selector;\n+import java.nio.channels.spi.SelectorProvider;\n+import java.util.ArrayDeque;\n+import java.util.Deque;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.function.Consumer;\n+\n+import static sun.nio.ch.WEPoll.*;\n+\n+\/**\n+ * Windows wepoll based Selector implementation\n+ *\/\n+class WEPollSelectorImpl extends SelectorImpl {\n+    \/\/ maximum number of events to poll in one call to epoll_wait\n+    private static final int NUM_EPOLLEVENTS = 256;\n+\n+    \/\/ wepoll handle\n+    private final long eph;\n+\n+    \/\/ address of epoll_event array when polling with epoll_wait\n+    private final long pollArrayAddress;\n+\n+    \/\/ maps SOCKET to selection key, synchronize on selector\n+    private final Map<Integer, SelectionKeyImpl> fdToKey = new HashMap<>();\n+\n+    \/\/ pending new registrations\/updates, queued by setEventOps\n+    private final Object updateLock = new Object();\n+    private final Deque<SelectionKeyImpl> updateKeys = new ArrayDeque<>();\n+\n+    \/\/ interrupt\/wakeup\n+    private final Object interruptLock = new Object();\n+    private boolean interruptTriggered;\n+    private final PipeImpl pipe;\n+    private final int fd0Val, fd1Val;\n+\n+    WEPollSelectorImpl(SelectorProvider sp) throws IOException {\n+        super(sp);\n+\n+        this.eph = WEPoll.create();\n+        this.pollArrayAddress = WEPoll.allocatePollArray(NUM_EPOLLEVENTS);\n+\n+        \/\/ wakeup support\n+        try {\n+            this.pipe = new PipeImpl(sp, \/*buffering*\/ false);\n+        } catch (IOException ioe) {\n+            WEPoll.freePollArray(pollArrayAddress);\n+            WEPoll.close(eph);\n+            throw ioe;\n+        }\n+        this.fd0Val = pipe.source().getFDVal();\n+        this.fd1Val = pipe.sink().getFDVal();\n+\n+        \/\/ register one end of the pipe for wakeups\n+        WEPoll.ctl(eph, EPOLL_CTL_ADD, fd0Val, WEPoll.EPOLLIN);\n+    }\n+\n+    private void ensureOpen() {\n+        if (!isOpen())\n+            throw new ClosedSelectorException();\n+    }\n+\n+    @Override\n+    protected int doSelect(Consumer<SelectionKey> action, long timeout)\n+        throws IOException\n+    {\n+        assert Thread.holdsLock(this);\n+\n+        \/\/ epoll_wait timeout is int\n+        int to = (int) Math.min(timeout, Integer.MAX_VALUE);\n+        boolean blocking = (to != 0);\n+\n+        int numEntries;\n+        processUpdateQueue();\n+        processDeregisterQueue();\n+        try {\n+            begin(blocking);\n+            numEntries = WEPoll.wait(eph, pollArrayAddress, NUM_EPOLLEVENTS, to);\n+        } finally {\n+            end(blocking);\n+        }\n+        processDeregisterQueue();\n+        return processEvents(numEntries, action);\n+    }\n+\n+    \/**\n+     * Process changes to the interest ops.\n+     *\/\n+    private void processUpdateQueue() {\n+        assert Thread.holdsLock(this);\n+\n+        synchronized (updateLock) {\n+            SelectionKeyImpl ski;\n+            while ((ski = updateKeys.pollFirst()) != null) {\n+                if (ski.isValid()) {\n+                    int fd = ski.getFDVal();\n+                    \/\/ add to fdToKey if needed\n+                    SelectionKeyImpl previous = fdToKey.putIfAbsent(fd, ski);\n+                    assert (previous == null) || (previous == ski);\n+                    int newOps = ski.translateInterestOps();\n+                    int registeredOps = ski.registeredEvents();\n+                    if (newOps != registeredOps) {\n+                        if (newOps == 0) {\n+                            \/\/ remove from epoll\n+                            WEPoll.ctl(eph, EPOLL_CTL_DEL, fd, 0);\n+                        } else {\n+                            int events = toEPollEvents(newOps);\n+                            if (registeredOps == 0) {\n+                                \/\/ add to epoll\n+                                WEPoll.ctl(eph, EPOLL_CTL_ADD, fd, events);\n+                            } else {\n+                                \/\/ modify events\n+                                WEPoll.ctl(eph, EPOLL_CTL_MOD, fd, events);\n+                            }\n+                        }\n+                        ski.registeredEvents(newOps);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    \/**\n+     * Process the polled events.\n+     * If the interrupt fd has been selected, drain it and clear the interrupt.\n+     *\/\n+    private int processEvents(int numEntries, Consumer<SelectionKey> action)\n+        throws IOException\n+    {\n+        assert Thread.holdsLock(this);\n+\n+        boolean interrupted = false;\n+        int numKeysUpdated = 0;\n+        for (int i = 0; i < numEntries; i++) {\n+            long event = WEPoll.getEvent(pollArrayAddress, i);\n+            int fd = (int) WEPoll.getSocket(event);\n+            if (fd == fd0Val) {\n+                interrupted = true;\n+            } else {\n+                SelectionKeyImpl ski = fdToKey.get(fd);\n+                if (ski != null) {\n+                    int events = WEPoll.getEvents(event);\n+                    if ((events & WEPoll.EPOLLPRI) != 0) {\n+                        Net.discardOOB(ski.getFD());\n+                    }\n+                    int rOps = toReadyOps(events);\n+                    numKeysUpdated += processReadyEvents(rOps, ski, action);\n+                }\n+            }\n+        }\n+\n+        if (interrupted) {\n+            clearInterrupt();\n+        }\n+\n+        return numKeysUpdated;\n+    }\n+\n+    @Override\n+    protected void implClose() throws IOException {\n+        assert !isOpen() && Thread.holdsLock(this);\n+\n+        \/\/ prevent further wakeup\n+        synchronized (interruptLock) {\n+            interruptTriggered = true;\n+        }\n+\n+        \/\/ close the epoll port and free resources\n+        WEPoll.close(eph);\n+        WEPoll.freePollArray(pollArrayAddress);\n+        pipe.sink().close();\n+        pipe.source().close();\n+    }\n+\n+    @Override\n+    protected void implDereg(SelectionKeyImpl ski) throws IOException {\n+        assert !ski.isValid() && Thread.holdsLock(this);\n+\n+        int fd = ski.getFDVal();\n+        if (fdToKey.remove(fd) != null) {\n+            if (ski.registeredEvents() != 0) {\n+                WEPoll.ctl(eph, EPOLL_CTL_DEL, fd, 0);\n+                ski.registeredEvents(0);\n+            }\n+        } else {\n+            assert ski.registeredEvents() == 0;\n+        }\n+    }\n+\n+    @Override\n+    public void setEventOps(SelectionKeyImpl ski) {\n+        ensureOpen();\n+        synchronized (updateLock) {\n+            updateKeys.addLast(ski);\n+        }\n+    }\n+\n+    @Override\n+    public Selector wakeup() {\n+        synchronized (interruptLock) {\n+            if (!interruptTriggered) {\n+                try {\n+                    IOUtil.write1(fd1Val, (byte) 0);\n+                } catch (IOException ioe) {\n+                    throw new InternalError(ioe);\n+                }\n+                interruptTriggered = true;\n+            }\n+        }\n+        return this;\n+    }\n+\n+    private void clearInterrupt() throws IOException {\n+        synchronized (interruptLock) {\n+            IOUtil.drain(fd0Val);\n+            interruptTriggered = false;\n+        }\n+    }\n+\n+    \/**\n+     * Maps interest ops to epoll events\n+     *\/\n+    private static int toEPollEvents(int ops) {\n+        int events = EPOLLPRI;\n+        if ((ops & Net.POLLIN) != 0)\n+            events |= EPOLLIN;\n+        if ((ops & (Net.POLLOUT | Net.POLLCONN)) != 0)\n+            events |= EPOLLOUT;\n+        return events;\n+    }\n+\n+    \/**\n+     * Map epoll events to ready ops\n+     *\/\n+    private static int toReadyOps(int events) {\n+        int ops = 0;\n+        if ((events & WEPoll.EPOLLIN) != 0) ops |= Net.POLLIN;\n+        if ((events & WEPoll.EPOLLOUT) != 0) ops |= (Net.POLLOUT | Net.POLLCONN);\n+        if ((events & WEPoll.EPOLLHUP) != 0) ops |= Net.POLLHUP;\n+        if ((events & WEPoll.EPOLLERR) != 0) ops |= Net.POLLERR;\n+        return ops;\n+    }\n+}\n","filename":"src\/java.base\/windows\/classes\/sun\/nio\/ch\/WEPollSelectorImpl.java","additions":276,"deletions":0,"binary":false,"changes":276,"status":"added"},{"patch":"@@ -0,0 +1,35 @@\n+\/*\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package sun.nio.ch;\n+\n+import java.io.IOException;\n+import java.nio.channels.spi.AbstractSelector;\n+\n+public class WEPollSelectorProvider extends SelectorProviderImpl {\n+    public AbstractSelector openSelector() throws IOException {\n+        return new WEPollSelectorImpl(this);\n+    }\n+}\n","filename":"src\/java.base\/windows\/classes\/sun\/nio\/ch\/WEPollSelectorProvider.java","additions":35,"deletions":0,"binary":false,"changes":35,"status":"added"},{"patch":"@@ -368,1 +368,3 @@\n-        private int processSelectedKeys(long updateCount, Consumer<SelectionKey> action) {\n+        private int processSelectedKeys(long updateCount, Consumer<SelectionKey> action)\n+            throws IOException\n+        {\n@@ -395,0 +397,1 @@\n+            throws IOException\n@@ -418,1 +421,1 @@\n-                        && discardUrgentData(desc)) {\n+                        && Net.discardOOB(ski.getFD())) {\n@@ -514,2 +517,0 @@\n-    private native boolean discardUrgentData(int fd);\n-\n@@ -526,1 +527,1 @@\n-    private int updateSelectedKeys(Consumer<SelectionKey> action) {\n+    private int updateSelectedKeys(Consumer<SelectionKey> action) throws IOException {\n","filename":"src\/java.base\/windows\/classes\/sun\/nio\/ch\/WindowsSelectorImpl.java","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -0,0 +1,34 @@\n+## Bert Belder: wepoll v 1.5.8\n+\n+### wepoll License\n+```\n+wepoll - epoll for Windows\n+https:\/\/github.com\/piscisaureus\/wepoll\n+\n+Copyright 2012-2020, Bert Belder <bertbelder@gmail.com>\n+All rights reserved.\n+\n+Redistribution and use in source and binary forms, with or without\n+modification, are permitted provided that the following conditions are\n+met:\n+\n+  * Redistributions of source code must retain the above copyright\n+    notice, this list of conditions and the following disclaimer.\n+\n+  * Redistributions in binary form must reproduce the above copyright\n+    notice, this list of conditions and the following disclaimer in the\n+    documentation and\/or other materials provided with the distribution.\n+\n+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+\n+```\n","filename":"src\/java.base\/windows\/legal\/wepoll.md","additions":34,"deletions":0,"binary":false,"changes":34,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -151,3 +151,0 @@\n-\/* Note: Drain uses the int fd value. It is currently not called\n-   on windows.\n-*\/\n@@ -157,11 +154,2 @@\n-    DWORD read = 0;\n-    int totalRead = 0;\n-    BOOL result = 0;\n-    HANDLE h = (HANDLE)_get_osfhandle(fd);\n-    char buf[128];\n-\n-    if (h == INVALID_HANDLE_VALUE) {\n-        JNU_ThrowIOExceptionWithLastError(env, \"Read failed\");\n-        return JNI_FALSE;\n-    }\n-\n+    char buf[16];\n+    jboolean readBytes = JNI_FALSE;\n@@ -169,10 +157,4 @@\n-        result = ReadFile(h,          \/* File handle to read *\/\n-                          (LPVOID)&buf,    \/* address to put data *\/\n-                          128,        \/* number of bytes to read *\/\n-                          &read,      \/* number of bytes read *\/\n-                          NULL);      \/* no overlapped struct *\/\n-\n-        if (result == 0) {\n-            int error = GetLastError();\n-            if (error == ERROR_NO_DATA) {\n-                return (totalRead > 0) ? JNI_TRUE : JNI_FALSE;\n+        int n = recv((SOCKET) fd, buf, sizeof(buf), 0);\n+        if (n == SOCKET_ERROR) {\n+            if (WSAGetLastError() != WSAEWOULDBLOCK) {\n+                JNU_ThrowIOExceptionWithLastError(env, \"recv failed\");\n@@ -180,7 +162,1 @@\n-            JNU_ThrowIOExceptionWithLastError(env, \"Drain\");\n-            return JNI_FALSE;\n-        }\n-        if (read > 0) {\n-            totalRead += read;\n-        } else {\n-            break;\n+            return readBytes;\n@@ -188,0 +164,15 @@\n+        if (n <= 0)\n+            return readBytes;\n+        if (n < (int)sizeof(buf))\n+            return JNI_TRUE;\n+        readBytes = JNI_TRUE;\n+    }\n+}\n+\n+JNIEXPORT jint JNICALL\n+Java_sun_nio_ch_IOUtil_write1(JNIEnv *env, jclass cl, jint fd, jbyte b)\n+{\n+    int n = send((SOCKET) fd, &b, 1, 0);\n+    if (n == SOCKET_ERROR && WSAGetLastError() != WSAEWOULDBLOCK) {\n+        JNU_ThrowIOExceptionWithLastError(env, \"send failed\");\n+        return IOS_THROWN;\n@@ -189,1 +180,1 @@\n-    return (totalRead > 0) ? JNI_TRUE : JNI_FALSE;\n+    return (n == 1) ? 1 : 0;\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/IOUtil.c","additions":24,"deletions":33,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -657,2 +657,1 @@\n-    if (events & POLLOUT ||\n-        events & POLLCONN) {\n+    if (events & POLLOUT) {\n@@ -771,1 +770,1 @@\n-    return (jshort)POLLCONN;\n+    return (jshort)POLLOUT;\n@@ -789,0 +788,21 @@\n+\n+JNIEXPORT jboolean JNICALL\n+Java_sun_nio_ch_Net_discardOOB(JNIEnv* env, jclass clazz, jobject fdo)\n+{\n+    char buf[8];\n+    jboolean discarded = JNI_FALSE;\n+    for (;;) {\n+        int n = recv(fdval(env, fdo), (char*)&buf, sizeof(buf), MSG_OOB);\n+        if (n == SOCKET_ERROR) {\n+            if (WSAGetLastError() != WSAEWOULDBLOCK) {\n+                JNU_ThrowIOExceptionWithLastError(env, \"recv failed\");\n+            }\n+            return discarded;\n+        }\n+        if (n <= 0)\n+            return discarded;\n+        if (n < (int)sizeof(buf))\n+            return JNI_TRUE;\n+        discarded = JNI_TRUE;\n+    }\n+}\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/Net.c","additions":24,"deletions":4,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -0,0 +1,93 @@\n+\/*\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"jni.h\"\n+#include \"jni_util.h\"\n+#include \"jvm.h\"\n+#include \"jlong.h\"\n+#include \"nio.h\"\n+#include \"nio_util.h\"\n+#include \"wepoll.h\"\n+#include \"sun_nio_ch_WEPoll.h\"\n+\n+JNIEXPORT jint JNICALL\n+Java_sun_nio_ch_WEPoll_eventSize(JNIEnv* env, jclass clazz)\n+{\n+    return sizeof(struct epoll_event);\n+}\n+\n+JNIEXPORT jint JNICALL\n+Java_sun_nio_ch_WEPoll_eventsOffset(JNIEnv* env, jclass clazz)\n+{\n+    return offsetof(struct epoll_event, events);\n+}\n+\n+JNIEXPORT jint JNICALL\n+Java_sun_nio_ch_WEPoll_dataOffset(JNIEnv* env, jclass clazz)\n+{\n+    return offsetof(struct epoll_event, data);\n+}\n+\n+JNIEXPORT jlong JNICALL\n+Java_sun_nio_ch_WEPoll_create(JNIEnv *env, jclass clazz) {\n+    HANDLE h = epoll_create1(0);\n+    if (h < 0) {\n+        JNU_ThrowIOExceptionWithLastError(env, \"epoll_create1 failed\");\n+    }\n+    return ptr_to_jlong(h);\n+}\n+\n+JNIEXPORT jint JNICALL\n+Java_sun_nio_ch_WEPoll_ctl(JNIEnv *env, jclass clazz, jlong h,\n+                           jint opcode, jlong s, jint events)\n+{\n+    struct epoll_event event;\n+    int res;\n+    SOCKET socket = (SOCKET) jlong_to_ptr(s);\n+\n+    event.events = (uint32_t) events;\n+    event.data.sock = socket;\n+\n+    res = epoll_ctl(jlong_to_ptr(h), opcode, socket, &event);\n+    return (res == 0) ? 0 : errno;\n+}\n+\n+JNIEXPORT jint JNICALL\n+Java_sun_nio_ch_WEPoll_wait(JNIEnv *env, jclass clazz, jlong h,\n+                            jlong address, jint numfds, jint timeout)\n+{\n+    struct epoll_event *events = jlong_to_ptr(address);\n+    int res = epoll_wait(jlong_to_ptr(h), events, numfds, timeout);\n+    if (res < 0) {\n+        JNU_ThrowIOExceptionWithLastError(env, \"epoll_wait failed\");\n+        return IOS_THROWN;\n+    }\n+    return res;\n+}\n+\n+JNIEXPORT void JNICALL\n+Java_sun_nio_ch_WEPoll_close(JNIEnv *env, jclass clazz, jlong h) {\n+    epoll_close(jlong_to_ptr(h));\n+}\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/WEPollNatives.c","additions":93,"deletions":0,"binary":false,"changes":93,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -102,2 +102,1 @@\n-        if (fds[i].events & (POLLOUT | POLLCONN))\n-        {\n+        if (fds[i].events & POLLOUT) {\n@@ -193,16 +192,0 @@\n-\n-JNIEXPORT jboolean JNICALL\n-Java_sun_nio_ch_WindowsSelectorImpl_discardUrgentData(JNIEnv* env, jobject this,\n-                                                      jint s)\n-{\n-    char data[8];\n-    jboolean discarded = JNI_FALSE;\n-    int n;\n-    do {\n-        n = recv(s, (char*)&data, sizeof(data), MSG_OOB);\n-        if (n > 0) {\n-            discarded = JNI_TRUE;\n-        }\n-    } while (n > 0);\n-    return discarded;\n-}\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/WindowsSelectorImpl.c","additions":2,"deletions":19,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -67,16 +67,0 @@\n-#ifndef POLLIN\n-    \/* WSAPoll()\/WSAPOLLFD and the corresponding constants are only defined   *\/\n-    \/* in Windows Vista \/ Windows Server 2008 and later. If we are on an      *\/\n-    \/* older release we just use the Solaris constants as this was previously *\/\n-    \/* done in PollArrayWrapper.java.                                         *\/\n-    #define POLLIN       0x0001\n-    #define POLLOUT      0x0004\n-    #define POLLERR      0x0008\n-    #define POLLHUP      0x0010\n-    #define POLLNVAL     0x0020\n-    #define POLLCONN     0x0002\n-#else\n-    \/* POLLCONN must not equal any of the other constants (see winsock2.h).   *\/\n-    #define POLLCONN     0x2000\n-#endif\n-\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/nio_util.h","additions":1,"deletions":17,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -0,0 +1,2283 @@\n+\/*\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * This file is available under and governed by the GNU General Public\n+ * License version 2 only, as published by the Free Software Foundation.\n+ * However, the following notice accompanied the original version of this\n+ * file and, per its terms, should not be removed:\n+ *\n+ * wepoll - epoll for Windows\n+ * https:\/\/github.com\/piscisaureus\/wepoll\n+ *\n+ * Copyright 2012-2020, Bert Belder <bertbelder@gmail.com>\n+ * All rights reserved.\n+ *\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions are\n+ * met:\n+ *\n+ *   * Redistributions of source code must retain the above copyright\n+ *     notice, this list of conditions and the following disclaimer.\n+ *\n+ *   * Redistributions in binary form must reproduce the above copyright\n+ *     notice, this list of conditions and the following disclaimer in the\n+ *     documentation and\/or other materials provided with the distribution.\n+ *\n+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+ * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+ *\/\n+\n+#ifndef WEPOLL_EXPORT\n+#define WEPOLL_EXPORT\n+#endif\n+\n+#include <stdint.h>\n+\n+enum EPOLL_EVENTS {\n+  EPOLLIN      = (int) (1U <<  0),\n+  EPOLLPRI     = (int) (1U <<  1),\n+  EPOLLOUT     = (int) (1U <<  2),\n+  EPOLLERR     = (int) (1U <<  3),\n+  EPOLLHUP     = (int) (1U <<  4),\n+  EPOLLRDNORM  = (int) (1U <<  6),\n+  EPOLLRDBAND  = (int) (1U <<  7),\n+  EPOLLWRNORM  = (int) (1U <<  8),\n+  EPOLLWRBAND  = (int) (1U <<  9),\n+  EPOLLMSG     = (int) (1U << 10), \/* Never reported. *\/\n+  EPOLLRDHUP   = (int) (1U << 13),\n+  EPOLLONESHOT = (int) (1U << 31)\n+};\n+\n+#define EPOLLIN      (1U <<  0)\n+#define EPOLLPRI     (1U <<  1)\n+#define EPOLLOUT     (1U <<  2)\n+#define EPOLLERR     (1U <<  3)\n+#define EPOLLHUP     (1U <<  4)\n+#define EPOLLRDNORM  (1U <<  6)\n+#define EPOLLRDBAND  (1U <<  7)\n+#define EPOLLWRNORM  (1U <<  8)\n+#define EPOLLWRBAND  (1U <<  9)\n+#define EPOLLMSG     (1U << 10)\n+#define EPOLLRDHUP   (1U << 13)\n+#define EPOLLONESHOT (1U << 31)\n+\n+#define EPOLL_CTL_ADD 1\n+#define EPOLL_CTL_MOD 2\n+#define EPOLL_CTL_DEL 3\n+\n+typedef void* HANDLE;\n+typedef uintptr_t SOCKET;\n+\n+typedef union epoll_data {\n+  void* ptr;\n+  int fd;\n+  uint32_t u32;\n+  uint64_t u64;\n+  SOCKET sock; \/* Windows specific *\/\n+  HANDLE hnd;  \/* Windows specific *\/\n+} epoll_data_t;\n+\n+struct epoll_event {\n+  uint32_t events;   \/* Epoll events and flags *\/\n+  epoll_data_t data; \/* User data variable *\/\n+};\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+WEPOLL_EXPORT HANDLE epoll_create(int size);\n+WEPOLL_EXPORT HANDLE epoll_create1(int flags);\n+\n+WEPOLL_EXPORT int epoll_close(HANDLE ephnd);\n+\n+WEPOLL_EXPORT int epoll_ctl(HANDLE ephnd,\n+                            int op,\n+                            SOCKET sock,\n+                            struct epoll_event* event);\n+\n+WEPOLL_EXPORT int epoll_wait(HANDLE ephnd,\n+                             struct epoll_event* events,\n+                             int maxevents,\n+                             int timeout);\n+\n+#ifdef __cplusplus\n+} \/* extern \"C\" *\/\n+#endif\n+\n+#include <assert.h>\n+\n+#include <stdlib.h>\n+\n+#define WEPOLL_INTERNAL static\n+#define WEPOLL_INTERNAL_EXTERN static\n+\n+#if defined(__clang__)\n+#pragma clang diagnostic push\n+#pragma clang diagnostic ignored \"-Wnonportable-system-include-path\"\n+#pragma clang diagnostic ignored \"-Wreserved-id-macro\"\n+#elif defined(_MSC_VER)\n+#pragma warning(push, 1)\n+#endif\n+\n+#undef WIN32_LEAN_AND_MEAN\n+#define WIN32_LEAN_AND_MEAN\n+\n+#undef _WIN32_WINNT\n+#define _WIN32_WINNT 0x0600\n+\n+#include <winsock2.h>\n+#include <ws2tcpip.h>\n+#include <windows.h>\n+\n+#if defined(__clang__)\n+#pragma clang diagnostic pop\n+#elif defined(_MSC_VER)\n+#pragma warning(pop)\n+#endif\n+\n+WEPOLL_INTERNAL int nt_global_init(void);\n+\n+typedef LONG NTSTATUS;\n+typedef NTSTATUS* PNTSTATUS;\n+\n+#ifndef NT_SUCCESS\n+#define NT_SUCCESS(status) (((NTSTATUS)(status)) >= 0)\n+#endif\n+\n+#ifndef STATUS_SUCCESS\n+#define STATUS_SUCCESS ((NTSTATUS) 0x00000000L)\n+#endif\n+\n+#ifndef STATUS_PENDING\n+#define STATUS_PENDING ((NTSTATUS) 0x00000103L)\n+#endif\n+\n+#ifndef STATUS_CANCELLED\n+#define STATUS_CANCELLED ((NTSTATUS) 0xC0000120L)\n+#endif\n+\n+#ifndef STATUS_NOT_FOUND\n+#define STATUS_NOT_FOUND ((NTSTATUS) 0xC0000225L)\n+#endif\n+\n+typedef struct _IO_STATUS_BLOCK {\n+  NTSTATUS Status;\n+  ULONG_PTR Information;\n+} IO_STATUS_BLOCK, *PIO_STATUS_BLOCK;\n+\n+typedef VOID(NTAPI* PIO_APC_ROUTINE)(PVOID ApcContext,\n+                                     PIO_STATUS_BLOCK IoStatusBlock,\n+                                     ULONG Reserved);\n+\n+typedef struct _UNICODE_STRING {\n+  USHORT Length;\n+  USHORT MaximumLength;\n+  PWSTR Buffer;\n+} UNICODE_STRING, *PUNICODE_STRING;\n+\n+#define RTL_CONSTANT_STRING(s) \\\n+  { sizeof(s) - sizeof((s)[0]), sizeof(s), s }\n+\n+typedef struct _OBJECT_ATTRIBUTES {\n+  ULONG Length;\n+  HANDLE RootDirectory;\n+  PUNICODE_STRING ObjectName;\n+  ULONG Attributes;\n+  PVOID SecurityDescriptor;\n+  PVOID SecurityQualityOfService;\n+} OBJECT_ATTRIBUTES, *POBJECT_ATTRIBUTES;\n+\n+#define RTL_CONSTANT_OBJECT_ATTRIBUTES(ObjectName, Attributes) \\\n+  { sizeof(OBJECT_ATTRIBUTES), NULL, ObjectName, Attributes, NULL, NULL }\n+\n+#ifndef FILE_OPEN\n+#define FILE_OPEN 0x00000001UL\n+#endif\n+\n+#define KEYEDEVENT_WAIT 0x00000001UL\n+#define KEYEDEVENT_WAKE 0x00000002UL\n+#define KEYEDEVENT_ALL_ACCESS \\\n+  (STANDARD_RIGHTS_REQUIRED | KEYEDEVENT_WAIT | KEYEDEVENT_WAKE)\n+\n+#define NT_NTDLL_IMPORT_LIST(X)           \\\n+  X(NTSTATUS,                             \\\n+    NTAPI,                                \\\n+    NtCancelIoFileEx,                     \\\n+    (HANDLE FileHandle,                   \\\n+     PIO_STATUS_BLOCK IoRequestToCancel,  \\\n+     PIO_STATUS_BLOCK IoStatusBlock))     \\\n+                                          \\\n+  X(NTSTATUS,                             \\\n+    NTAPI,                                \\\n+    NtCreateFile,                         \\\n+    (PHANDLE FileHandle,                  \\\n+     ACCESS_MASK DesiredAccess,           \\\n+     POBJECT_ATTRIBUTES ObjectAttributes, \\\n+     PIO_STATUS_BLOCK IoStatusBlock,      \\\n+     PLARGE_INTEGER AllocationSize,       \\\n+     ULONG FileAttributes,                \\\n+     ULONG ShareAccess,                   \\\n+     ULONG CreateDisposition,             \\\n+     ULONG CreateOptions,                 \\\n+     PVOID EaBuffer,                      \\\n+     ULONG EaLength))                     \\\n+                                          \\\n+  X(NTSTATUS,                             \\\n+    NTAPI,                                \\\n+    NtCreateKeyedEvent,                   \\\n+    (PHANDLE KeyedEventHandle,            \\\n+     ACCESS_MASK DesiredAccess,           \\\n+     POBJECT_ATTRIBUTES ObjectAttributes, \\\n+     ULONG Flags))                        \\\n+                                          \\\n+  X(NTSTATUS,                             \\\n+    NTAPI,                                \\\n+    NtDeviceIoControlFile,                \\\n+    (HANDLE FileHandle,                   \\\n+     HANDLE Event,                        \\\n+     PIO_APC_ROUTINE ApcRoutine,          \\\n+     PVOID ApcContext,                    \\\n+     PIO_STATUS_BLOCK IoStatusBlock,      \\\n+     ULONG IoControlCode,                 \\\n+     PVOID InputBuffer,                   \\\n+     ULONG InputBufferLength,             \\\n+     PVOID OutputBuffer,                  \\\n+     ULONG OutputBufferLength))           \\\n+                                          \\\n+  X(NTSTATUS,                             \\\n+    NTAPI,                                \\\n+    NtReleaseKeyedEvent,                  \\\n+    (HANDLE KeyedEventHandle,             \\\n+     PVOID KeyValue,                      \\\n+     BOOLEAN Alertable,                   \\\n+     PLARGE_INTEGER Timeout))             \\\n+                                          \\\n+  X(NTSTATUS,                             \\\n+    NTAPI,                                \\\n+    NtWaitForKeyedEvent,                  \\\n+    (HANDLE KeyedEventHandle,             \\\n+     PVOID KeyValue,                      \\\n+     BOOLEAN Alertable,                   \\\n+     PLARGE_INTEGER Timeout))             \\\n+                                          \\\n+  X(ULONG, WINAPI, RtlNtStatusToDosError, (NTSTATUS Status))\n+\n+#define X(return_type, attributes, name, parameters) \\\n+  WEPOLL_INTERNAL_EXTERN return_type(attributes* name) parameters;\n+NT_NTDLL_IMPORT_LIST(X)\n+#undef X\n+\n+#define AFD_POLL_RECEIVE           0x0001\n+#define AFD_POLL_RECEIVE_EXPEDITED 0x0002\n+#define AFD_POLL_SEND              0x0004\n+#define AFD_POLL_DISCONNECT        0x0008\n+#define AFD_POLL_ABORT             0x0010\n+#define AFD_POLL_LOCAL_CLOSE       0x0020\n+#define AFD_POLL_ACCEPT            0x0080\n+#define AFD_POLL_CONNECT_FAIL      0x0100\n+\n+typedef struct _AFD_POLL_HANDLE_INFO {\n+  HANDLE Handle;\n+  ULONG Events;\n+  NTSTATUS Status;\n+} AFD_POLL_HANDLE_INFO, *PAFD_POLL_HANDLE_INFO;\n+\n+typedef struct _AFD_POLL_INFO {\n+  LARGE_INTEGER Timeout;\n+  ULONG NumberOfHandles;\n+  ULONG Exclusive;\n+  AFD_POLL_HANDLE_INFO Handles[1];\n+} AFD_POLL_INFO, *PAFD_POLL_INFO;\n+\n+WEPOLL_INTERNAL int afd_create_device_handle(HANDLE iocp_handle,\n+                                             HANDLE* afd_device_handle_out);\n+\n+WEPOLL_INTERNAL int afd_poll(HANDLE afd_device_handle,\n+                             AFD_POLL_INFO* poll_info,\n+                             IO_STATUS_BLOCK* io_status_block);\n+WEPOLL_INTERNAL int afd_cancel_poll(HANDLE afd_device_handle,\n+                                    IO_STATUS_BLOCK* io_status_block);\n+\n+#define return_map_error(value) \\\n+  do {                          \\\n+    err_map_win_error();        \\\n+    return (value);             \\\n+  } while (0)\n+\n+#define return_set_error(value, error) \\\n+  do {                                 \\\n+    err_set_win_error(error);          \\\n+    return (value);                    \\\n+  } while (0)\n+\n+WEPOLL_INTERNAL void err_map_win_error(void);\n+WEPOLL_INTERNAL void err_set_win_error(DWORD error);\n+WEPOLL_INTERNAL int err_check_handle(HANDLE handle);\n+\n+#define IOCTL_AFD_POLL 0x00012024\n+\n+static UNICODE_STRING afd__device_name =\n+    RTL_CONSTANT_STRING(L\"\\\\Device\\\\Afd\\\\Wepoll\");\n+\n+static OBJECT_ATTRIBUTES afd__device_attributes =\n+    RTL_CONSTANT_OBJECT_ATTRIBUTES(&afd__device_name, 0);\n+\n+int afd_create_device_handle(HANDLE iocp_handle,\n+                             HANDLE* afd_device_handle_out) {\n+  HANDLE afd_device_handle;\n+  IO_STATUS_BLOCK iosb;\n+  NTSTATUS status;\n+\n+  \/* By opening \\Device\\Afd without specifying any extended attributes, we'll\n+   * get a handle that lets us talk to the AFD driver, but that doesn't have an\n+   * associated endpoint (so it's not a socket). *\/\n+  status = NtCreateFile(&afd_device_handle,\n+                        SYNCHRONIZE,\n+                        &afd__device_attributes,\n+                        &iosb,\n+                        NULL,\n+                        0,\n+                        FILE_SHARE_READ | FILE_SHARE_WRITE,\n+                        FILE_OPEN,\n+                        0,\n+                        NULL,\n+                        0);\n+  if (status != STATUS_SUCCESS)\n+    return_set_error(-1, RtlNtStatusToDosError(status));\n+\n+  if (CreateIoCompletionPort(afd_device_handle, iocp_handle, 0, 0) == NULL)\n+    goto error;\n+\n+  if (!SetFileCompletionNotificationModes(afd_device_handle,\n+                                          FILE_SKIP_SET_EVENT_ON_HANDLE))\n+    goto error;\n+\n+  *afd_device_handle_out = afd_device_handle;\n+  return 0;\n+\n+error:\n+  CloseHandle(afd_device_handle);\n+  return_map_error(-1);\n+}\n+\n+int afd_poll(HANDLE afd_device_handle,\n+             AFD_POLL_INFO* poll_info,\n+             IO_STATUS_BLOCK* io_status_block) {\n+  NTSTATUS status;\n+\n+  \/* Blocking operation is not supported. *\/\n+  assert(io_status_block != NULL);\n+\n+  io_status_block->Status = STATUS_PENDING;\n+  status = NtDeviceIoControlFile(afd_device_handle,\n+                                 NULL,\n+                                 NULL,\n+                                 io_status_block,\n+                                 io_status_block,\n+                                 IOCTL_AFD_POLL,\n+                                 poll_info,\n+                                 sizeof *poll_info,\n+                                 poll_info,\n+                                 sizeof *poll_info);\n+\n+  if (status == STATUS_SUCCESS)\n+    return 0;\n+  else if (status == STATUS_PENDING)\n+    return_set_error(-1, ERROR_IO_PENDING);\n+  else\n+    return_set_error(-1, RtlNtStatusToDosError(status));\n+}\n+\n+int afd_cancel_poll(HANDLE afd_device_handle,\n+                    IO_STATUS_BLOCK* io_status_block) {\n+  NTSTATUS cancel_status;\n+  IO_STATUS_BLOCK cancel_iosb;\n+\n+  \/* If the poll operation has already completed or has been cancelled earlier,\n+   * there's nothing left for us to do. *\/\n+  if (io_status_block->Status != STATUS_PENDING)\n+    return 0;\n+\n+  cancel_status =\n+      NtCancelIoFileEx(afd_device_handle, io_status_block, &cancel_iosb);\n+\n+  \/* NtCancelIoFileEx() may return STATUS_NOT_FOUND if the operation completed\n+   * just before calling NtCancelIoFileEx(). This is not an error. *\/\n+  if (cancel_status == STATUS_SUCCESS || cancel_status == STATUS_NOT_FOUND)\n+    return 0;\n+  else\n+    return_set_error(-1, RtlNtStatusToDosError(cancel_status));\n+}\n+\n+WEPOLL_INTERNAL int epoll_global_init(void);\n+\n+WEPOLL_INTERNAL int init(void);\n+\n+typedef struct port_state port_state_t;\n+typedef struct queue queue_t;\n+typedef struct sock_state sock_state_t;\n+typedef struct ts_tree_node ts_tree_node_t;\n+\n+WEPOLL_INTERNAL port_state_t* port_new(HANDLE* iocp_handle_out);\n+WEPOLL_INTERNAL int port_close(port_state_t* port_state);\n+WEPOLL_INTERNAL int port_delete(port_state_t* port_state);\n+\n+WEPOLL_INTERNAL int port_wait(port_state_t* port_state,\n+                              struct epoll_event* events,\n+                              int maxevents,\n+                              int timeout);\n+\n+WEPOLL_INTERNAL int port_ctl(port_state_t* port_state,\n+                             int op,\n+                             SOCKET sock,\n+                             struct epoll_event* ev);\n+\n+WEPOLL_INTERNAL int port_register_socket(port_state_t* port_state,\n+                                         sock_state_t* sock_state,\n+                                         SOCKET socket);\n+WEPOLL_INTERNAL void port_unregister_socket(port_state_t* port_state,\n+                                            sock_state_t* sock_state);\n+WEPOLL_INTERNAL sock_state_t* port_find_socket(port_state_t* port_state,\n+                                               SOCKET socket);\n+\n+WEPOLL_INTERNAL void port_request_socket_update(port_state_t* port_state,\n+                                                sock_state_t* sock_state);\n+WEPOLL_INTERNAL void port_cancel_socket_update(port_state_t* port_state,\n+                                               sock_state_t* sock_state);\n+\n+WEPOLL_INTERNAL void port_add_deleted_socket(port_state_t* port_state,\n+                                             sock_state_t* sock_state);\n+WEPOLL_INTERNAL void port_remove_deleted_socket(port_state_t* port_state,\n+                                                sock_state_t* sock_state);\n+\n+WEPOLL_INTERNAL HANDLE port_get_iocp_handle(port_state_t* port_state);\n+WEPOLL_INTERNAL queue_t* port_get_poll_group_queue(port_state_t* port_state);\n+\n+WEPOLL_INTERNAL port_state_t* port_state_from_handle_tree_node(\n+    ts_tree_node_t* tree_node);\n+WEPOLL_INTERNAL ts_tree_node_t* port_state_to_handle_tree_node(\n+    port_state_t* port_state);\n+\n+\/* The reflock is a special kind of lock that normally prevents a chunk of\n+ * memory from being freed, but does allow the chunk of memory to eventually be\n+ * released in a coordinated fashion.\n+ *\n+ * Under normal operation, threads increase and decrease the reference count,\n+ * which are wait-free operations.\n+ *\n+ * Exactly once during the reflock's lifecycle, a thread holding a reference to\n+ * the lock may \"destroy\" the lock; this operation blocks until all other\n+ * threads holding a reference to the lock have dereferenced it. After\n+ * \"destroy\" returns, the calling thread may assume that no other threads have\n+ * a reference to the lock.\n+ *\n+ * Attemmpting to lock or destroy a lock after reflock_unref_and_destroy() has\n+ * been called is invalid and results in undefined behavior. Therefore the user\n+ * should use another lock to guarantee that this can't happen.\n+ *\/\n+\n+typedef struct reflock {\n+  volatile long state; \/* 32-bit Interlocked APIs operate on `long` values. *\/\n+} reflock_t;\n+\n+WEPOLL_INTERNAL int reflock_global_init(void);\n+\n+WEPOLL_INTERNAL void reflock_init(reflock_t* reflock);\n+WEPOLL_INTERNAL void reflock_ref(reflock_t* reflock);\n+WEPOLL_INTERNAL void reflock_unref(reflock_t* reflock);\n+WEPOLL_INTERNAL void reflock_unref_and_destroy(reflock_t* reflock);\n+\n+#include <stdbool.h>\n+\n+\/* N.b.: the tree functions do not set errno or LastError when they fail. Each\n+ * of the API functions has at most one failure mode. It is up to the caller to\n+ * set an appropriate error code when necessary. *\/\n+\n+typedef struct tree tree_t;\n+typedef struct tree_node tree_node_t;\n+\n+typedef struct tree {\n+  tree_node_t* root;\n+} tree_t;\n+\n+typedef struct tree_node {\n+  tree_node_t* left;\n+  tree_node_t* right;\n+  tree_node_t* parent;\n+  uintptr_t key;\n+  bool red;\n+} tree_node_t;\n+\n+WEPOLL_INTERNAL void tree_init(tree_t* tree);\n+WEPOLL_INTERNAL void tree_node_init(tree_node_t* node);\n+\n+WEPOLL_INTERNAL int tree_add(tree_t* tree, tree_node_t* node, uintptr_t key);\n+WEPOLL_INTERNAL void tree_del(tree_t* tree, tree_node_t* node);\n+\n+WEPOLL_INTERNAL tree_node_t* tree_find(const tree_t* tree, uintptr_t key);\n+WEPOLL_INTERNAL tree_node_t* tree_root(const tree_t* tree);\n+\n+typedef struct ts_tree {\n+  tree_t tree;\n+  SRWLOCK lock;\n+} ts_tree_t;\n+\n+typedef struct ts_tree_node {\n+  tree_node_t tree_node;\n+  reflock_t reflock;\n+} ts_tree_node_t;\n+\n+WEPOLL_INTERNAL void ts_tree_init(ts_tree_t* rtl);\n+WEPOLL_INTERNAL void ts_tree_node_init(ts_tree_node_t* node);\n+\n+WEPOLL_INTERNAL int ts_tree_add(ts_tree_t* ts_tree,\n+                                ts_tree_node_t* node,\n+                                uintptr_t key);\n+\n+WEPOLL_INTERNAL ts_tree_node_t* ts_tree_del_and_ref(ts_tree_t* ts_tree,\n+                                                    uintptr_t key);\n+WEPOLL_INTERNAL ts_tree_node_t* ts_tree_find_and_ref(ts_tree_t* ts_tree,\n+                                                     uintptr_t key);\n+\n+WEPOLL_INTERNAL void ts_tree_node_unref(ts_tree_node_t* node);\n+WEPOLL_INTERNAL void ts_tree_node_unref_and_destroy(ts_tree_node_t* node);\n+\n+static ts_tree_t epoll__handle_tree;\n+\n+int epoll_global_init(void) {\n+  ts_tree_init(&epoll__handle_tree);\n+  return 0;\n+}\n+\n+static HANDLE epoll__create(void) {\n+  port_state_t* port_state;\n+  HANDLE ephnd;\n+  ts_tree_node_t* tree_node;\n+\n+  if (init() < 0)\n+    return NULL;\n+\n+  port_state = port_new(&ephnd);\n+  if (port_state == NULL)\n+    return NULL;\n+\n+  tree_node = port_state_to_handle_tree_node(port_state);\n+  if (ts_tree_add(&epoll__handle_tree, tree_node, (uintptr_t) ephnd) < 0) {\n+    \/* This should never happen. *\/\n+    port_delete(port_state);\n+    return_set_error(NULL, ERROR_ALREADY_EXISTS);\n+  }\n+\n+  return ephnd;\n+}\n+\n+HANDLE epoll_create(int size) {\n+  if (size <= 0)\n+    return_set_error(NULL, ERROR_INVALID_PARAMETER);\n+\n+  return epoll__create();\n+}\n+\n+HANDLE epoll_create1(int flags) {\n+  if (flags != 0)\n+    return_set_error(NULL, ERROR_INVALID_PARAMETER);\n+\n+  return epoll__create();\n+}\n+\n+int epoll_close(HANDLE ephnd) {\n+  ts_tree_node_t* tree_node;\n+  port_state_t* port_state;\n+\n+  if (init() < 0)\n+    return -1;\n+\n+  tree_node = ts_tree_del_and_ref(&epoll__handle_tree, (uintptr_t) ephnd);\n+  if (tree_node == NULL) {\n+    err_set_win_error(ERROR_INVALID_PARAMETER);\n+    goto err;\n+  }\n+\n+  port_state = port_state_from_handle_tree_node(tree_node);\n+  port_close(port_state);\n+\n+  ts_tree_node_unref_and_destroy(tree_node);\n+\n+  return port_delete(port_state);\n+\n+err:\n+  err_check_handle(ephnd);\n+  return -1;\n+}\n+\n+int epoll_ctl(HANDLE ephnd, int op, SOCKET sock, struct epoll_event* ev) {\n+  ts_tree_node_t* tree_node;\n+  port_state_t* port_state;\n+  int r;\n+\n+  if (init() < 0)\n+    return -1;\n+\n+  tree_node = ts_tree_find_and_ref(&epoll__handle_tree, (uintptr_t) ephnd);\n+  if (tree_node == NULL) {\n+    err_set_win_error(ERROR_INVALID_PARAMETER);\n+    goto err;\n+  }\n+\n+  port_state = port_state_from_handle_tree_node(tree_node);\n+  r = port_ctl(port_state, op, sock, ev);\n+\n+  ts_tree_node_unref(tree_node);\n+\n+  if (r < 0)\n+    goto err;\n+\n+  return 0;\n+\n+err:\n+  \/* On Linux, in the case of epoll_ctl(), EBADF takes priority over other\n+   * errors. Wepoll mimics this behavior. *\/\n+  err_check_handle(ephnd);\n+  err_check_handle((HANDLE) sock);\n+  return -1;\n+}\n+\n+int epoll_wait(HANDLE ephnd,\n+               struct epoll_event* events,\n+               int maxevents,\n+               int timeout) {\n+  ts_tree_node_t* tree_node;\n+  port_state_t* port_state;\n+  int num_events;\n+\n+  if (maxevents <= 0)\n+    return_set_error(-1, ERROR_INVALID_PARAMETER);\n+\n+  if (init() < 0)\n+    return -1;\n+\n+  tree_node = ts_tree_find_and_ref(&epoll__handle_tree, (uintptr_t) ephnd);\n+  if (tree_node == NULL) {\n+    err_set_win_error(ERROR_INVALID_PARAMETER);\n+    goto err;\n+  }\n+\n+  port_state = port_state_from_handle_tree_node(tree_node);\n+  num_events = port_wait(port_state, events, maxevents, timeout);\n+\n+  ts_tree_node_unref(tree_node);\n+\n+  if (num_events < 0)\n+    goto err;\n+\n+  return num_events;\n+\n+err:\n+  err_check_handle(ephnd);\n+  return -1;\n+}\n+\n+#include <errno.h>\n+\n+#define ERR__ERRNO_MAPPINGS(X)               \\\n+  X(ERROR_ACCESS_DENIED, EACCES)             \\\n+  X(ERROR_ALREADY_EXISTS, EEXIST)            \\\n+  X(ERROR_BAD_COMMAND, EACCES)               \\\n+  X(ERROR_BAD_EXE_FORMAT, ENOEXEC)           \\\n+  X(ERROR_BAD_LENGTH, EACCES)                \\\n+  X(ERROR_BAD_NETPATH, ENOENT)               \\\n+  X(ERROR_BAD_NET_NAME, ENOENT)              \\\n+  X(ERROR_BAD_NET_RESP, ENETDOWN)            \\\n+  X(ERROR_BAD_PATHNAME, ENOENT)              \\\n+  X(ERROR_BROKEN_PIPE, EPIPE)                \\\n+  X(ERROR_CANNOT_MAKE, EACCES)               \\\n+  X(ERROR_COMMITMENT_LIMIT, ENOMEM)          \\\n+  X(ERROR_CONNECTION_ABORTED, ECONNABORTED)  \\\n+  X(ERROR_CONNECTION_ACTIVE, EISCONN)        \\\n+  X(ERROR_CONNECTION_REFUSED, ECONNREFUSED)  \\\n+  X(ERROR_CRC, EACCES)                       \\\n+  X(ERROR_DIR_NOT_EMPTY, ENOTEMPTY)          \\\n+  X(ERROR_DISK_FULL, ENOSPC)                 \\\n+  X(ERROR_DUP_NAME, EADDRINUSE)              \\\n+  X(ERROR_FILENAME_EXCED_RANGE, ENOENT)      \\\n+  X(ERROR_FILE_NOT_FOUND, ENOENT)            \\\n+  X(ERROR_GEN_FAILURE, EACCES)               \\\n+  X(ERROR_GRACEFUL_DISCONNECT, EPIPE)        \\\n+  X(ERROR_HOST_DOWN, EHOSTUNREACH)           \\\n+  X(ERROR_HOST_UNREACHABLE, EHOSTUNREACH)    \\\n+  X(ERROR_INSUFFICIENT_BUFFER, EFAULT)       \\\n+  X(ERROR_INVALID_ADDRESS, EADDRNOTAVAIL)    \\\n+  X(ERROR_INVALID_FUNCTION, EINVAL)          \\\n+  X(ERROR_INVALID_HANDLE, EBADF)             \\\n+  X(ERROR_INVALID_NETNAME, EADDRNOTAVAIL)    \\\n+  X(ERROR_INVALID_PARAMETER, EINVAL)         \\\n+  X(ERROR_INVALID_USER_BUFFER, EMSGSIZE)     \\\n+  X(ERROR_IO_PENDING, EINPROGRESS)           \\\n+  X(ERROR_LOCK_VIOLATION, EACCES)            \\\n+  X(ERROR_MORE_DATA, EMSGSIZE)               \\\n+  X(ERROR_NETNAME_DELETED, ECONNABORTED)     \\\n+  X(ERROR_NETWORK_ACCESS_DENIED, EACCES)     \\\n+  X(ERROR_NETWORK_BUSY, ENETDOWN)            \\\n+  X(ERROR_NETWORK_UNREACHABLE, ENETUNREACH)  \\\n+  X(ERROR_NOACCESS, EFAULT)                  \\\n+  X(ERROR_NONPAGED_SYSTEM_RESOURCES, ENOMEM) \\\n+  X(ERROR_NOT_ENOUGH_MEMORY, ENOMEM)         \\\n+  X(ERROR_NOT_ENOUGH_QUOTA, ENOMEM)          \\\n+  X(ERROR_NOT_FOUND, ENOENT)                 \\\n+  X(ERROR_NOT_LOCKED, EACCES)                \\\n+  X(ERROR_NOT_READY, EACCES)                 \\\n+  X(ERROR_NOT_SAME_DEVICE, EXDEV)            \\\n+  X(ERROR_NOT_SUPPORTED, ENOTSUP)            \\\n+  X(ERROR_NO_MORE_FILES, ENOENT)             \\\n+  X(ERROR_NO_SYSTEM_RESOURCES, ENOMEM)       \\\n+  X(ERROR_OPERATION_ABORTED, EINTR)          \\\n+  X(ERROR_OUT_OF_PAPER, EACCES)              \\\n+  X(ERROR_PAGED_SYSTEM_RESOURCES, ENOMEM)    \\\n+  X(ERROR_PAGEFILE_QUOTA, ENOMEM)            \\\n+  X(ERROR_PATH_NOT_FOUND, ENOENT)            \\\n+  X(ERROR_PIPE_NOT_CONNECTED, EPIPE)         \\\n+  X(ERROR_PORT_UNREACHABLE, ECONNRESET)      \\\n+  X(ERROR_PROTOCOL_UNREACHABLE, ENETUNREACH) \\\n+  X(ERROR_REM_NOT_LIST, ECONNREFUSED)        \\\n+  X(ERROR_REQUEST_ABORTED, EINTR)            \\\n+  X(ERROR_REQ_NOT_ACCEP, EWOULDBLOCK)        \\\n+  X(ERROR_SECTOR_NOT_FOUND, EACCES)          \\\n+  X(ERROR_SEM_TIMEOUT, ETIMEDOUT)            \\\n+  X(ERROR_SHARING_VIOLATION, EACCES)         \\\n+  X(ERROR_TOO_MANY_NAMES, ENOMEM)            \\\n+  X(ERROR_TOO_MANY_OPEN_FILES, EMFILE)       \\\n+  X(ERROR_UNEXP_NET_ERR, ECONNABORTED)       \\\n+  X(ERROR_WAIT_NO_CHILDREN, ECHILD)          \\\n+  X(ERROR_WORKING_SET_QUOTA, ENOMEM)         \\\n+  X(ERROR_WRITE_PROTECT, EACCES)             \\\n+  X(ERROR_WRONG_DISK, EACCES)                \\\n+  X(WSAEACCES, EACCES)                       \\\n+  X(WSAEADDRINUSE, EADDRINUSE)               \\\n+  X(WSAEADDRNOTAVAIL, EADDRNOTAVAIL)         \\\n+  X(WSAEAFNOSUPPORT, EAFNOSUPPORT)           \\\n+  X(WSAECONNABORTED, ECONNABORTED)           \\\n+  X(WSAECONNREFUSED, ECONNREFUSED)           \\\n+  X(WSAECONNRESET, ECONNRESET)               \\\n+  X(WSAEDISCON, EPIPE)                       \\\n+  X(WSAEFAULT, EFAULT)                       \\\n+  X(WSAEHOSTDOWN, EHOSTUNREACH)              \\\n+  X(WSAEHOSTUNREACH, EHOSTUNREACH)           \\\n+  X(WSAEINPROGRESS, EBUSY)                   \\\n+  X(WSAEINTR, EINTR)                         \\\n+  X(WSAEINVAL, EINVAL)                       \\\n+  X(WSAEISCONN, EISCONN)                     \\\n+  X(WSAEMSGSIZE, EMSGSIZE)                   \\\n+  X(WSAENETDOWN, ENETDOWN)                   \\\n+  X(WSAENETRESET, EHOSTUNREACH)              \\\n+  X(WSAENETUNREACH, ENETUNREACH)             \\\n+  X(WSAENOBUFS, ENOMEM)                      \\\n+  X(WSAENOTCONN, ENOTCONN)                   \\\n+  X(WSAENOTSOCK, ENOTSOCK)                   \\\n+  X(WSAEOPNOTSUPP, EOPNOTSUPP)               \\\n+  X(WSAEPROCLIM, ENOMEM)                     \\\n+  X(WSAESHUTDOWN, EPIPE)                     \\\n+  X(WSAETIMEDOUT, ETIMEDOUT)                 \\\n+  X(WSAEWOULDBLOCK, EWOULDBLOCK)             \\\n+  X(WSANOTINITIALISED, ENETDOWN)             \\\n+  X(WSASYSNOTREADY, ENETDOWN)                \\\n+  X(WSAVERNOTSUPPORTED, ENOSYS)\n+\n+static errno_t err__map_win_error_to_errno(DWORD error) {\n+  switch (error) {\n+#define X(error_sym, errno_sym) \\\n+  case error_sym:               \\\n+    return errno_sym;\n+    ERR__ERRNO_MAPPINGS(X)\n+#undef X\n+  }\n+  return EINVAL;\n+}\n+\n+void err_map_win_error(void) {\n+  errno = err__map_win_error_to_errno(GetLastError());\n+}\n+\n+void err_set_win_error(DWORD error) {\n+  SetLastError(error);\n+  errno = err__map_win_error_to_errno(error);\n+}\n+\n+int err_check_handle(HANDLE handle) {\n+  DWORD flags;\n+\n+  \/* GetHandleInformation() succeeds when passed INVALID_HANDLE_VALUE, so check\n+   * for this condition explicitly. *\/\n+  if (handle == INVALID_HANDLE_VALUE)\n+    return_set_error(-1, ERROR_INVALID_HANDLE);\n+\n+  if (!GetHandleInformation(handle, &flags))\n+    return_map_error(-1);\n+\n+  return 0;\n+}\n+\n+#include <stddef.h>\n+\n+#define array_count(a) (sizeof(a) \/ (sizeof((a)[0])))\n+\n+#define container_of(ptr, type, member) \\\n+  ((type*) ((uintptr_t) (ptr) - offsetof(type, member)))\n+\n+#define unused_var(v) ((void) (v))\n+\n+\/* Polyfill `inline` for older versions of msvc (up to Visual Studio 2013) *\/\n+#if defined(_MSC_VER) && _MSC_VER < 1900\n+#define inline __inline\n+#endif\n+\n+WEPOLL_INTERNAL int ws_global_init(void);\n+WEPOLL_INTERNAL SOCKET ws_get_base_socket(SOCKET socket);\n+\n+static bool init__done = false;\n+static INIT_ONCE init__once = INIT_ONCE_STATIC_INIT;\n+\n+static BOOL CALLBACK init__once_callback(INIT_ONCE* once,\n+                                         void* parameter,\n+                                         void** context) {\n+  unused_var(once);\n+  unused_var(parameter);\n+  unused_var(context);\n+\n+  \/* N.b. that initialization order matters here. *\/\n+  if (ws_global_init() < 0 || nt_global_init() < 0 ||\n+      reflock_global_init() < 0 || epoll_global_init() < 0)\n+    return FALSE;\n+\n+  init__done = true;\n+  return TRUE;\n+}\n+\n+int init(void) {\n+  if (!init__done &&\n+      !InitOnceExecuteOnce(&init__once, init__once_callback, NULL, NULL))\n+    \/* `InitOnceExecuteOnce()` itself is infallible, and it doesn't set any\n+     * error code when the once-callback returns FALSE. We return -1 here to\n+     * indicate that global initialization failed; the failing init function is\n+     * resposible for setting `errno` and calling `SetLastError()`. *\/\n+    return -1;\n+\n+  return 0;\n+}\n+\n+\/* Set up a workaround for the following problem:\n+ *   FARPROC addr = GetProcAddress(...);\n+ *   MY_FUNC func = (MY_FUNC) addr;          <-- GCC 8 warning\/error.\n+ *   MY_FUNC func = (MY_FUNC) (void*) addr;  <-- MSVC  warning\/error.\n+ * To compile cleanly with either compiler, do casts with this \"bridge\" type:\n+ *   MY_FUNC func = (MY_FUNC) (nt__fn_ptr_cast_t) addr; *\/\n+#ifdef __GNUC__\n+typedef void* nt__fn_ptr_cast_t;\n+#else\n+typedef FARPROC nt__fn_ptr_cast_t;\n+#endif\n+\n+#define X(return_type, attributes, name, parameters) \\\n+  WEPOLL_INTERNAL return_type(attributes* name) parameters = NULL;\n+NT_NTDLL_IMPORT_LIST(X)\n+#undef X\n+\n+int nt_global_init(void) {\n+  HMODULE ntdll;\n+  FARPROC fn_ptr;\n+\n+  ntdll = GetModuleHandleW(L\"ntdll.dll\");\n+  if (ntdll == NULL)\n+    return -1;\n+\n+#define X(return_type, attributes, name, parameters) \\\n+  fn_ptr = GetProcAddress(ntdll, #name);             \\\n+  if (fn_ptr == NULL)                                \\\n+    return -1;                                       \\\n+  name = (return_type(attributes*) parameters)(nt__fn_ptr_cast_t) fn_ptr;\n+  NT_NTDLL_IMPORT_LIST(X)\n+#undef X\n+\n+  return 0;\n+}\n+\n+#include <string.h>\n+\n+typedef struct poll_group poll_group_t;\n+\n+typedef struct queue_node queue_node_t;\n+\n+WEPOLL_INTERNAL poll_group_t* poll_group_acquire(port_state_t* port);\n+WEPOLL_INTERNAL void poll_group_release(poll_group_t* poll_group);\n+\n+WEPOLL_INTERNAL void poll_group_delete(poll_group_t* poll_group);\n+\n+WEPOLL_INTERNAL poll_group_t* poll_group_from_queue_node(\n+    queue_node_t* queue_node);\n+WEPOLL_INTERNAL HANDLE\n+    poll_group_get_afd_device_handle(poll_group_t* poll_group);\n+\n+typedef struct queue_node {\n+  queue_node_t* prev;\n+  queue_node_t* next;\n+} queue_node_t;\n+\n+typedef struct queue {\n+  queue_node_t head;\n+} queue_t;\n+\n+WEPOLL_INTERNAL void queue_init(queue_t* queue);\n+WEPOLL_INTERNAL void queue_node_init(queue_node_t* node);\n+\n+WEPOLL_INTERNAL queue_node_t* queue_first(const queue_t* queue);\n+WEPOLL_INTERNAL queue_node_t* queue_last(const queue_t* queue);\n+\n+WEPOLL_INTERNAL void queue_prepend(queue_t* queue, queue_node_t* node);\n+WEPOLL_INTERNAL void queue_append(queue_t* queue, queue_node_t* node);\n+WEPOLL_INTERNAL void queue_move_to_start(queue_t* queue, queue_node_t* node);\n+WEPOLL_INTERNAL void queue_move_to_end(queue_t* queue, queue_node_t* node);\n+WEPOLL_INTERNAL void queue_remove(queue_node_t* node);\n+\n+WEPOLL_INTERNAL bool queue_is_empty(const queue_t* queue);\n+WEPOLL_INTERNAL bool queue_is_enqueued(const queue_node_t* node);\n+\n+#define POLL_GROUP__MAX_GROUP_SIZE 32\n+\n+typedef struct poll_group {\n+  port_state_t* port_state;\n+  queue_node_t queue_node;\n+  HANDLE afd_device_handle;\n+  size_t group_size;\n+} poll_group_t;\n+\n+static poll_group_t* poll_group__new(port_state_t* port_state) {\n+  HANDLE iocp_handle = port_get_iocp_handle(port_state);\n+  queue_t* poll_group_queue = port_get_poll_group_queue(port_state);\n+\n+  poll_group_t* poll_group = malloc(sizeof *poll_group);\n+  if (poll_group == NULL)\n+    return_set_error(NULL, ERROR_NOT_ENOUGH_MEMORY);\n+\n+  memset(poll_group, 0, sizeof *poll_group);\n+\n+  queue_node_init(&poll_group->queue_node);\n+  poll_group->port_state = port_state;\n+\n+  if (afd_create_device_handle(iocp_handle, &poll_group->afd_device_handle) <\n+      0) {\n+    free(poll_group);\n+    return NULL;\n+  }\n+\n+  queue_append(poll_group_queue, &poll_group->queue_node);\n+\n+  return poll_group;\n+}\n+\n+void poll_group_delete(poll_group_t* poll_group) {\n+  assert(poll_group->group_size == 0);\n+  CloseHandle(poll_group->afd_device_handle);\n+  queue_remove(&poll_group->queue_node);\n+  free(poll_group);\n+}\n+\n+poll_group_t* poll_group_from_queue_node(queue_node_t* queue_node) {\n+  return container_of(queue_node, poll_group_t, queue_node);\n+}\n+\n+HANDLE poll_group_get_afd_device_handle(poll_group_t* poll_group) {\n+  return poll_group->afd_device_handle;\n+}\n+\n+poll_group_t* poll_group_acquire(port_state_t* port_state) {\n+  queue_t* poll_group_queue = port_get_poll_group_queue(port_state);\n+  poll_group_t* poll_group =\n+      !queue_is_empty(poll_group_queue)\n+          ? container_of(\n+                queue_last(poll_group_queue), poll_group_t, queue_node)\n+          : NULL;\n+\n+  if (poll_group == NULL ||\n+      poll_group->group_size >= POLL_GROUP__MAX_GROUP_SIZE)\n+    poll_group = poll_group__new(port_state);\n+  if (poll_group == NULL)\n+    return NULL;\n+\n+  if (++poll_group->group_size == POLL_GROUP__MAX_GROUP_SIZE)\n+    queue_move_to_start(poll_group_queue, &poll_group->queue_node);\n+\n+  return poll_group;\n+}\n+\n+void poll_group_release(poll_group_t* poll_group) {\n+  port_state_t* port_state = poll_group->port_state;\n+  queue_t* poll_group_queue = port_get_poll_group_queue(port_state);\n+\n+  poll_group->group_size--;\n+  assert(poll_group->group_size < POLL_GROUP__MAX_GROUP_SIZE);\n+\n+  queue_move_to_end(poll_group_queue, &poll_group->queue_node);\n+\n+  \/* Poll groups are currently only freed when the epoll port is closed. *\/\n+}\n+\n+WEPOLL_INTERNAL sock_state_t* sock_new(port_state_t* port_state,\n+                                       SOCKET socket);\n+WEPOLL_INTERNAL void sock_delete(port_state_t* port_state,\n+                                 sock_state_t* sock_state);\n+WEPOLL_INTERNAL void sock_force_delete(port_state_t* port_state,\n+                                       sock_state_t* sock_state);\n+\n+WEPOLL_INTERNAL int sock_set_event(port_state_t* port_state,\n+                                   sock_state_t* sock_state,\n+                                   const struct epoll_event* ev);\n+\n+WEPOLL_INTERNAL int sock_update(port_state_t* port_state,\n+                                sock_state_t* sock_state);\n+WEPOLL_INTERNAL int sock_feed_event(port_state_t* port_state,\n+                                    IO_STATUS_BLOCK* io_status_block,\n+                                    struct epoll_event* ev);\n+\n+WEPOLL_INTERNAL sock_state_t* sock_state_from_queue_node(\n+    queue_node_t* queue_node);\n+WEPOLL_INTERNAL queue_node_t* sock_state_to_queue_node(\n+    sock_state_t* sock_state);\n+WEPOLL_INTERNAL sock_state_t* sock_state_from_tree_node(\n+    tree_node_t* tree_node);\n+WEPOLL_INTERNAL tree_node_t* sock_state_to_tree_node(sock_state_t* sock_state);\n+\n+#define PORT__MAX_ON_STACK_COMPLETIONS 256\n+\n+typedef struct port_state {\n+  HANDLE iocp_handle;\n+  tree_t sock_tree;\n+  queue_t sock_update_queue;\n+  queue_t sock_deleted_queue;\n+  queue_t poll_group_queue;\n+  ts_tree_node_t handle_tree_node;\n+  CRITICAL_SECTION lock;\n+  size_t active_poll_count;\n+} port_state_t;\n+\n+static inline port_state_t* port__alloc(void) {\n+  port_state_t* port_state = malloc(sizeof *port_state);\n+  if (port_state == NULL)\n+    return_set_error(NULL, ERROR_NOT_ENOUGH_MEMORY);\n+\n+  return port_state;\n+}\n+\n+static inline void port__free(port_state_t* port) {\n+  assert(port != NULL);\n+  free(port);\n+}\n+\n+static inline HANDLE port__create_iocp(void) {\n+  HANDLE iocp_handle =\n+      CreateIoCompletionPort(INVALID_HANDLE_VALUE, NULL, 0, 0);\n+  if (iocp_handle == NULL)\n+    return_map_error(NULL);\n+\n+  return iocp_handle;\n+}\n+\n+port_state_t* port_new(HANDLE* iocp_handle_out) {\n+  port_state_t* port_state;\n+  HANDLE iocp_handle;\n+\n+  port_state = port__alloc();\n+  if (port_state == NULL)\n+    goto err1;\n+\n+  iocp_handle = port__create_iocp();\n+  if (iocp_handle == NULL)\n+    goto err2;\n+\n+  memset(port_state, 0, sizeof *port_state);\n+\n+  port_state->iocp_handle = iocp_handle;\n+  tree_init(&port_state->sock_tree);\n+  queue_init(&port_state->sock_update_queue);\n+  queue_init(&port_state->sock_deleted_queue);\n+  queue_init(&port_state->poll_group_queue);\n+  ts_tree_node_init(&port_state->handle_tree_node);\n+  InitializeCriticalSection(&port_state->lock);\n+\n+  *iocp_handle_out = iocp_handle;\n+  return port_state;\n+\n+err2:\n+  port__free(port_state);\n+err1:\n+  return NULL;\n+}\n+\n+static inline int port__close_iocp(port_state_t* port_state) {\n+  HANDLE iocp_handle = port_state->iocp_handle;\n+  port_state->iocp_handle = NULL;\n+\n+  if (!CloseHandle(iocp_handle))\n+    return_map_error(-1);\n+\n+  return 0;\n+}\n+\n+int port_close(port_state_t* port_state) {\n+  int result;\n+\n+  EnterCriticalSection(&port_state->lock);\n+  result = port__close_iocp(port_state);\n+  LeaveCriticalSection(&port_state->lock);\n+\n+  return result;\n+}\n+\n+int port_delete(port_state_t* port_state) {\n+  tree_node_t* tree_node;\n+  queue_node_t* queue_node;\n+\n+  \/* At this point the IOCP port should have been closed. *\/\n+  assert(port_state->iocp_handle == NULL);\n+\n+  while ((tree_node = tree_root(&port_state->sock_tree)) != NULL) {\n+    sock_state_t* sock_state = sock_state_from_tree_node(tree_node);\n+    sock_force_delete(port_state, sock_state);\n+  }\n+\n+  while ((queue_node = queue_first(&port_state->sock_deleted_queue)) != NULL) {\n+    sock_state_t* sock_state = sock_state_from_queue_node(queue_node);\n+    sock_force_delete(port_state, sock_state);\n+  }\n+\n+  while ((queue_node = queue_first(&port_state->poll_group_queue)) != NULL) {\n+    poll_group_t* poll_group = poll_group_from_queue_node(queue_node);\n+    poll_group_delete(poll_group);\n+  }\n+\n+  assert(queue_is_empty(&port_state->sock_update_queue));\n+\n+  DeleteCriticalSection(&port_state->lock);\n+\n+  port__free(port_state);\n+\n+  return 0;\n+}\n+\n+static int port__update_events(port_state_t* port_state) {\n+  queue_t* sock_update_queue = &port_state->sock_update_queue;\n+\n+  \/* Walk the queue, submitting new poll requests for every socket that needs\n+   * it. *\/\n+  while (!queue_is_empty(sock_update_queue)) {\n+    queue_node_t* queue_node = queue_first(sock_update_queue);\n+    sock_state_t* sock_state = sock_state_from_queue_node(queue_node);\n+\n+    if (sock_update(port_state, sock_state) < 0)\n+      return -1;\n+\n+    \/* sock_update() removes the socket from the update queue. *\/\n+  }\n+\n+  return 0;\n+}\n+\n+static inline void port__update_events_if_polling(port_state_t* port_state) {\n+  if (port_state->active_poll_count > 0)\n+    port__update_events(port_state);\n+}\n+\n+static inline int port__feed_events(port_state_t* port_state,\n+                                    struct epoll_event* epoll_events,\n+                                    OVERLAPPED_ENTRY* iocp_events,\n+                                    DWORD iocp_event_count) {\n+  int epoll_event_count = 0;\n+  DWORD i;\n+\n+  for (i = 0; i < iocp_event_count; i++) {\n+    IO_STATUS_BLOCK* io_status_block =\n+        (IO_STATUS_BLOCK*) iocp_events[i].lpOverlapped;\n+    struct epoll_event* ev = &epoll_events[epoll_event_count];\n+\n+    epoll_event_count += sock_feed_event(port_state, io_status_block, ev);\n+  }\n+\n+  return epoll_event_count;\n+}\n+\n+static inline int port__poll(port_state_t* port_state,\n+                             struct epoll_event* epoll_events,\n+                             OVERLAPPED_ENTRY* iocp_events,\n+                             DWORD maxevents,\n+                             DWORD timeout) {\n+  DWORD completion_count;\n+\n+  if (port__update_events(port_state) < 0)\n+    return -1;\n+\n+  port_state->active_poll_count++;\n+\n+  LeaveCriticalSection(&port_state->lock);\n+\n+  BOOL r = GetQueuedCompletionStatusEx(port_state->iocp_handle,\n+                                       iocp_events,\n+                                       maxevents,\n+                                       &completion_count,\n+                                       timeout,\n+                                       FALSE);\n+\n+  EnterCriticalSection(&port_state->lock);\n+\n+  port_state->active_poll_count--;\n+\n+  if (!r)\n+    return_map_error(-1);\n+\n+  return port__feed_events(\n+      port_state, epoll_events, iocp_events, completion_count);\n+}\n+\n+int port_wait(port_state_t* port_state,\n+              struct epoll_event* events,\n+              int maxevents,\n+              int timeout) {\n+  OVERLAPPED_ENTRY stack_iocp_events[PORT__MAX_ON_STACK_COMPLETIONS];\n+  OVERLAPPED_ENTRY* iocp_events;\n+  uint64_t due = 0;\n+  DWORD gqcs_timeout;\n+  int result;\n+\n+  \/* Check whether `maxevents` is in range. *\/\n+  if (maxevents <= 0)\n+    return_set_error(-1, ERROR_INVALID_PARAMETER);\n+\n+  \/* Decide whether the IOCP completion list can live on the stack, or allocate\n+   * memory for it on the heap. *\/\n+  if ((size_t) maxevents <= array_count(stack_iocp_events)) {\n+    iocp_events = stack_iocp_events;\n+  } else if ((iocp_events =\n+                  malloc((size_t) maxevents * sizeof *iocp_events)) == NULL) {\n+    iocp_events = stack_iocp_events;\n+    maxevents = array_count(stack_iocp_events);\n+  }\n+\n+  \/* Compute the timeout for GetQueuedCompletionStatus, and the wait end\n+   * time, if the user specified a timeout other than zero or infinite. *\/\n+  if (timeout > 0) {\n+    due = GetTickCount64() + (uint64_t) timeout;\n+    gqcs_timeout = (DWORD) timeout;\n+  } else if (timeout == 0) {\n+    gqcs_timeout = 0;\n+  } else {\n+    gqcs_timeout = INFINITE;\n+  }\n+\n+  EnterCriticalSection(&port_state->lock);\n+\n+  \/* Dequeue completion packets until either at least one interesting event\n+   * has been discovered, or the timeout is reached. *\/\n+  for (;;) {\n+    uint64_t now;\n+\n+    result = port__poll(\n+        port_state, events, iocp_events, (DWORD) maxevents, gqcs_timeout);\n+    if (result < 0 || result > 0)\n+      break; \/* Result, error, or time-out. *\/\n+\n+    if (timeout < 0)\n+      continue; \/* When timeout is negative, never time out. *\/\n+\n+    \/* Update time. *\/\n+    now = GetTickCount64();\n+\n+    \/* Do not allow the due time to be in the past. *\/\n+    if (now >= due) {\n+      SetLastError(WAIT_TIMEOUT);\n+      break;\n+    }\n+\n+    \/* Recompute time-out argument for GetQueuedCompletionStatus. *\/\n+    gqcs_timeout = (DWORD)(due - now);\n+  }\n+\n+  port__update_events_if_polling(port_state);\n+\n+  LeaveCriticalSection(&port_state->lock);\n+\n+  if (iocp_events != stack_iocp_events)\n+    free(iocp_events);\n+\n+  if (result >= 0)\n+    return result;\n+  else if (GetLastError() == WAIT_TIMEOUT)\n+    return 0;\n+  else\n+    return -1;\n+}\n+\n+static inline int port__ctl_add(port_state_t* port_state,\n+                                SOCKET sock,\n+                                struct epoll_event* ev) {\n+  sock_state_t* sock_state = sock_new(port_state, sock);\n+  if (sock_state == NULL)\n+    return -1;\n+\n+  if (sock_set_event(port_state, sock_state, ev) < 0) {\n+    sock_delete(port_state, sock_state);\n+    return -1;\n+  }\n+\n+  port__update_events_if_polling(port_state);\n+\n+  return 0;\n+}\n+\n+static inline int port__ctl_mod(port_state_t* port_state,\n+                                SOCKET sock,\n+                                struct epoll_event* ev) {\n+  sock_state_t* sock_state = port_find_socket(port_state, sock);\n+  if (sock_state == NULL)\n+    return -1;\n+\n+  if (sock_set_event(port_state, sock_state, ev) < 0)\n+    return -1;\n+\n+  port__update_events_if_polling(port_state);\n+\n+  return 0;\n+}\n+\n+static inline int port__ctl_del(port_state_t* port_state, SOCKET sock) {\n+  sock_state_t* sock_state = port_find_socket(port_state, sock);\n+  if (sock_state == NULL)\n+    return -1;\n+\n+  sock_delete(port_state, sock_state);\n+\n+  return 0;\n+}\n+\n+static inline int port__ctl_op(port_state_t* port_state,\n+                               int op,\n+                               SOCKET sock,\n+                               struct epoll_event* ev) {\n+  switch (op) {\n+    case EPOLL_CTL_ADD:\n+      return port__ctl_add(port_state, sock, ev);\n+    case EPOLL_CTL_MOD:\n+      return port__ctl_mod(port_state, sock, ev);\n+    case EPOLL_CTL_DEL:\n+      return port__ctl_del(port_state, sock);\n+    default:\n+      return_set_error(-1, ERROR_INVALID_PARAMETER);\n+  }\n+}\n+\n+int port_ctl(port_state_t* port_state,\n+             int op,\n+             SOCKET sock,\n+             struct epoll_event* ev) {\n+  int result;\n+\n+  EnterCriticalSection(&port_state->lock);\n+  result = port__ctl_op(port_state, op, sock, ev);\n+  LeaveCriticalSection(&port_state->lock);\n+\n+  return result;\n+}\n+\n+int port_register_socket(port_state_t* port_state,\n+                         sock_state_t* sock_state,\n+                         SOCKET socket) {\n+  if (tree_add(&port_state->sock_tree,\n+               sock_state_to_tree_node(sock_state),\n+               socket) < 0)\n+    return_set_error(-1, ERROR_ALREADY_EXISTS);\n+  return 0;\n+}\n+\n+void port_unregister_socket(port_state_t* port_state,\n+                            sock_state_t* sock_state) {\n+  tree_del(&port_state->sock_tree, sock_state_to_tree_node(sock_state));\n+}\n+\n+sock_state_t* port_find_socket(port_state_t* port_state, SOCKET socket) {\n+  tree_node_t* tree_node = tree_find(&port_state->sock_tree, socket);\n+  if (tree_node == NULL)\n+    return_set_error(NULL, ERROR_NOT_FOUND);\n+  return sock_state_from_tree_node(tree_node);\n+}\n+\n+void port_request_socket_update(port_state_t* port_state,\n+                                sock_state_t* sock_state) {\n+  if (queue_is_enqueued(sock_state_to_queue_node(sock_state)))\n+    return;\n+  queue_append(&port_state->sock_update_queue,\n+               sock_state_to_queue_node(sock_state));\n+}\n+\n+void port_cancel_socket_update(port_state_t* port_state,\n+                               sock_state_t* sock_state) {\n+  unused_var(port_state);\n+  if (!queue_is_enqueued(sock_state_to_queue_node(sock_state)))\n+    return;\n+  queue_remove(sock_state_to_queue_node(sock_state));\n+}\n+\n+void port_add_deleted_socket(port_state_t* port_state,\n+                             sock_state_t* sock_state) {\n+  if (queue_is_enqueued(sock_state_to_queue_node(sock_state)))\n+    return;\n+  queue_append(&port_state->sock_deleted_queue,\n+               sock_state_to_queue_node(sock_state));\n+}\n+\n+void port_remove_deleted_socket(port_state_t* port_state,\n+                                sock_state_t* sock_state) {\n+  unused_var(port_state);\n+  if (!queue_is_enqueued(sock_state_to_queue_node(sock_state)))\n+    return;\n+  queue_remove(sock_state_to_queue_node(sock_state));\n+}\n+\n+HANDLE port_get_iocp_handle(port_state_t* port_state) {\n+  assert(port_state->iocp_handle != NULL);\n+  return port_state->iocp_handle;\n+}\n+\n+queue_t* port_get_poll_group_queue(port_state_t* port_state) {\n+  return &port_state->poll_group_queue;\n+}\n+\n+port_state_t* port_state_from_handle_tree_node(ts_tree_node_t* tree_node) {\n+  return container_of(tree_node, port_state_t, handle_tree_node);\n+}\n+\n+ts_tree_node_t* port_state_to_handle_tree_node(port_state_t* port_state) {\n+  return &port_state->handle_tree_node;\n+}\n+\n+void queue_init(queue_t* queue) {\n+  queue_node_init(&queue->head);\n+}\n+\n+void queue_node_init(queue_node_t* node) {\n+  node->prev = node;\n+  node->next = node;\n+}\n+\n+static inline void queue__detach_node(queue_node_t* node) {\n+  node->prev->next = node->next;\n+  node->next->prev = node->prev;\n+}\n+\n+queue_node_t* queue_first(const queue_t* queue) {\n+  return !queue_is_empty(queue) ? queue->head.next : NULL;\n+}\n+\n+queue_node_t* queue_last(const queue_t* queue) {\n+  return !queue_is_empty(queue) ? queue->head.prev : NULL;\n+}\n+\n+void queue_prepend(queue_t* queue, queue_node_t* node) {\n+  node->next = queue->head.next;\n+  node->prev = &queue->head;\n+  node->next->prev = node;\n+  queue->head.next = node;\n+}\n+\n+void queue_append(queue_t* queue, queue_node_t* node) {\n+  node->next = &queue->head;\n+  node->prev = queue->head.prev;\n+  node->prev->next = node;\n+  queue->head.prev = node;\n+}\n+\n+void queue_move_to_start(queue_t* queue, queue_node_t* node) {\n+  queue__detach_node(node);\n+  queue_prepend(queue, node);\n+}\n+\n+void queue_move_to_end(queue_t* queue, queue_node_t* node) {\n+  queue__detach_node(node);\n+  queue_append(queue, node);\n+}\n+\n+void queue_remove(queue_node_t* node) {\n+  queue__detach_node(node);\n+  queue_node_init(node);\n+}\n+\n+bool queue_is_empty(const queue_t* queue) {\n+  return !queue_is_enqueued(&queue->head);\n+}\n+\n+bool queue_is_enqueued(const queue_node_t* node) {\n+  return node->prev != node;\n+}\n+\n+#define REFLOCK__REF          ((long) 0x00000001UL)\n+#define REFLOCK__REF_MASK     ((long) 0x0fffffffUL)\n+#define REFLOCK__DESTROY      ((long) 0x10000000UL)\n+#define REFLOCK__DESTROY_MASK ((long) 0xf0000000UL)\n+#define REFLOCK__POISON       ((long) 0x300dead0UL)\n+\n+static HANDLE reflock__keyed_event = NULL;\n+\n+int reflock_global_init(void) {\n+  NTSTATUS status = NtCreateKeyedEvent(\n+      &reflock__keyed_event, KEYEDEVENT_ALL_ACCESS, NULL, 0);\n+  if (status != STATUS_SUCCESS)\n+    return_set_error(-1, RtlNtStatusToDosError(status));\n+  return 0;\n+}\n+\n+void reflock_init(reflock_t* reflock) {\n+  reflock->state = 0;\n+}\n+\n+static void reflock__signal_event(void* address) {\n+  NTSTATUS status =\n+      NtReleaseKeyedEvent(reflock__keyed_event, address, FALSE, NULL);\n+  if (status != STATUS_SUCCESS)\n+    abort();\n+}\n+\n+static void reflock__await_event(void* address) {\n+  NTSTATUS status =\n+      NtWaitForKeyedEvent(reflock__keyed_event, address, FALSE, NULL);\n+  if (status != STATUS_SUCCESS)\n+    abort();\n+}\n+\n+void reflock_ref(reflock_t* reflock) {\n+  long state = InterlockedAdd(&reflock->state, REFLOCK__REF);\n+\n+  \/* Verify that the counter didn't overflow and the lock isn't destroyed. *\/\n+  assert((state & REFLOCK__DESTROY_MASK) == 0);\n+  unused_var(state);\n+}\n+\n+void reflock_unref(reflock_t* reflock) {\n+  long state = InterlockedAdd(&reflock->state, -REFLOCK__REF);\n+\n+  \/* Verify that the lock was referenced and not already destroyed. *\/\n+  assert((state & REFLOCK__DESTROY_MASK & ~REFLOCK__DESTROY) == 0);\n+\n+  if (state == REFLOCK__DESTROY)\n+    reflock__signal_event(reflock);\n+}\n+\n+void reflock_unref_and_destroy(reflock_t* reflock) {\n+  long state =\n+      InterlockedAdd(&reflock->state, REFLOCK__DESTROY - REFLOCK__REF);\n+  long ref_count = state & REFLOCK__REF_MASK;\n+\n+  \/* Verify that the lock was referenced and not already destroyed. *\/\n+  assert((state & REFLOCK__DESTROY_MASK) == REFLOCK__DESTROY);\n+\n+  if (ref_count != 0)\n+    reflock__await_event(reflock);\n+\n+  state = InterlockedExchange(&reflock->state, REFLOCK__POISON);\n+  assert(state == REFLOCK__DESTROY);\n+}\n+\n+#define SOCK__KNOWN_EPOLL_EVENTS                                       \\\n+  (EPOLLIN | EPOLLPRI | EPOLLOUT | EPOLLERR | EPOLLHUP | EPOLLRDNORM | \\\n+   EPOLLRDBAND | EPOLLWRNORM | EPOLLWRBAND | EPOLLMSG | EPOLLRDHUP)\n+\n+typedef enum sock__poll_status {\n+  SOCK__POLL_IDLE = 0,\n+  SOCK__POLL_PENDING,\n+  SOCK__POLL_CANCELLED\n+} sock__poll_status_t;\n+\n+typedef struct sock_state {\n+  IO_STATUS_BLOCK io_status_block;\n+  AFD_POLL_INFO poll_info;\n+  queue_node_t queue_node;\n+  tree_node_t tree_node;\n+  poll_group_t* poll_group;\n+  SOCKET base_socket;\n+  epoll_data_t user_data;\n+  uint32_t user_events;\n+  uint32_t pending_events;\n+  sock__poll_status_t poll_status;\n+  bool delete_pending;\n+} sock_state_t;\n+\n+static inline sock_state_t* sock__alloc(void) {\n+  sock_state_t* sock_state = malloc(sizeof *sock_state);\n+  if (sock_state == NULL)\n+    return_set_error(NULL, ERROR_NOT_ENOUGH_MEMORY);\n+  return sock_state;\n+}\n+\n+static inline void sock__free(sock_state_t* sock_state) {\n+  assert(sock_state != NULL);\n+  free(sock_state);\n+}\n+\n+static inline int sock__cancel_poll(sock_state_t* sock_state) {\n+  assert(sock_state->poll_status == SOCK__POLL_PENDING);\n+\n+  if (afd_cancel_poll(poll_group_get_afd_device_handle(sock_state->poll_group),\n+                      &sock_state->io_status_block) < 0)\n+    return -1;\n+\n+  sock_state->poll_status = SOCK__POLL_CANCELLED;\n+  sock_state->pending_events = 0;\n+  return 0;\n+}\n+\n+sock_state_t* sock_new(port_state_t* port_state, SOCKET socket) {\n+  SOCKET base_socket;\n+  poll_group_t* poll_group;\n+  sock_state_t* sock_state;\n+\n+  if (socket == 0 || socket == INVALID_SOCKET)\n+    return_set_error(NULL, ERROR_INVALID_HANDLE);\n+\n+  base_socket = ws_get_base_socket(socket);\n+  if (base_socket == INVALID_SOCKET)\n+    return NULL;\n+\n+  poll_group = poll_group_acquire(port_state);\n+  if (poll_group == NULL)\n+    return NULL;\n+\n+  sock_state = sock__alloc();\n+  if (sock_state == NULL)\n+    goto err1;\n+\n+  memset(sock_state, 0, sizeof *sock_state);\n+\n+  sock_state->base_socket = base_socket;\n+  sock_state->poll_group = poll_group;\n+\n+  tree_node_init(&sock_state->tree_node);\n+  queue_node_init(&sock_state->queue_node);\n+\n+  if (port_register_socket(port_state, sock_state, socket) < 0)\n+    goto err2;\n+\n+  return sock_state;\n+\n+err2:\n+  sock__free(sock_state);\n+err1:\n+  poll_group_release(poll_group);\n+\n+  return NULL;\n+}\n+\n+static int sock__delete(port_state_t* port_state,\n+                        sock_state_t* sock_state,\n+                        bool force) {\n+  if (!sock_state->delete_pending) {\n+    if (sock_state->poll_status == SOCK__POLL_PENDING)\n+      sock__cancel_poll(sock_state);\n+\n+    port_cancel_socket_update(port_state, sock_state);\n+    port_unregister_socket(port_state, sock_state);\n+\n+    sock_state->delete_pending = true;\n+  }\n+\n+  \/* If the poll request still needs to complete, the sock_state object can't\n+   * be free()d yet. `sock_feed_event()` or `port_close()` will take care\n+   * of this later. *\/\n+  if (force || sock_state->poll_status == SOCK__POLL_IDLE) {\n+    \/* Free the sock_state now. *\/\n+    port_remove_deleted_socket(port_state, sock_state);\n+    poll_group_release(sock_state->poll_group);\n+    sock__free(sock_state);\n+  } else {\n+    \/* Free the socket later. *\/\n+    port_add_deleted_socket(port_state, sock_state);\n+  }\n+\n+  return 0;\n+}\n+\n+void sock_delete(port_state_t* port_state, sock_state_t* sock_state) {\n+  sock__delete(port_state, sock_state, false);\n+}\n+\n+void sock_force_delete(port_state_t* port_state, sock_state_t* sock_state) {\n+  sock__delete(port_state, sock_state, true);\n+}\n+\n+int sock_set_event(port_state_t* port_state,\n+                   sock_state_t* sock_state,\n+                   const struct epoll_event* ev) {\n+  \/* EPOLLERR and EPOLLHUP are always reported, even when not requested by the\n+   * caller. However they are disabled after a event has been reported for a\n+   * socket for which the EPOLLONESHOT flag was set. *\/\n+  uint32_t events = ev->events | EPOLLERR | EPOLLHUP;\n+\n+  sock_state->user_events = events;\n+  sock_state->user_data = ev->data;\n+\n+  if ((events & SOCK__KNOWN_EPOLL_EVENTS & ~sock_state->pending_events) != 0)\n+    port_request_socket_update(port_state, sock_state);\n+\n+  return 0;\n+}\n+\n+static inline DWORD sock__epoll_events_to_afd_events(uint32_t epoll_events) {\n+  \/* Always monitor for AFD_POLL_LOCAL_CLOSE, which is triggered when the\n+   * socket is closed with closesocket() or CloseHandle(). *\/\n+  DWORD afd_events = AFD_POLL_LOCAL_CLOSE;\n+\n+  if (epoll_events & (EPOLLIN | EPOLLRDNORM))\n+    afd_events |= AFD_POLL_RECEIVE | AFD_POLL_ACCEPT;\n+  if (epoll_events & (EPOLLPRI | EPOLLRDBAND))\n+    afd_events |= AFD_POLL_RECEIVE_EXPEDITED;\n+  if (epoll_events & (EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND))\n+    afd_events |= AFD_POLL_SEND;\n+  if (epoll_events & (EPOLLIN | EPOLLRDNORM | EPOLLRDHUP))\n+    afd_events |= AFD_POLL_DISCONNECT;\n+  if (epoll_events & EPOLLHUP)\n+    afd_events |= AFD_POLL_ABORT;\n+  if (epoll_events & EPOLLERR)\n+    afd_events |= AFD_POLL_CONNECT_FAIL;\n+\n+  return afd_events;\n+}\n+\n+static inline uint32_t sock__afd_events_to_epoll_events(DWORD afd_events) {\n+  uint32_t epoll_events = 0;\n+\n+  if (afd_events & (AFD_POLL_RECEIVE | AFD_POLL_ACCEPT))\n+    epoll_events |= EPOLLIN | EPOLLRDNORM;\n+  if (afd_events & AFD_POLL_RECEIVE_EXPEDITED)\n+    epoll_events |= EPOLLPRI | EPOLLRDBAND;\n+  if (afd_events & AFD_POLL_SEND)\n+    epoll_events |= EPOLLOUT | EPOLLWRNORM | EPOLLWRBAND;\n+  if (afd_events & AFD_POLL_DISCONNECT)\n+    epoll_events |= EPOLLIN | EPOLLRDNORM | EPOLLRDHUP;\n+  if (afd_events & AFD_POLL_ABORT)\n+    epoll_events |= EPOLLHUP;\n+  if (afd_events & AFD_POLL_CONNECT_FAIL)\n+    \/* Linux reports all these events after connect() has failed. *\/\n+    epoll_events |=\n+        EPOLLIN | EPOLLOUT | EPOLLERR | EPOLLRDNORM | EPOLLWRNORM | EPOLLRDHUP;\n+\n+  return epoll_events;\n+}\n+\n+int sock_update(port_state_t* port_state, sock_state_t* sock_state) {\n+  assert(!sock_state->delete_pending);\n+\n+  if ((sock_state->poll_status == SOCK__POLL_PENDING) &&\n+      (sock_state->user_events & SOCK__KNOWN_EPOLL_EVENTS &\n+       ~sock_state->pending_events) == 0) {\n+    \/* All the events the user is interested in are already being monitored by\n+     * the pending poll operation. It might spuriously complete because of an\n+     * event that we're no longer interested in; when that happens we'll submit\n+     * a new poll operation with the updated event mask. *\/\n+\n+  } else if (sock_state->poll_status == SOCK__POLL_PENDING) {\n+    \/* A poll operation is already pending, but it's not monitoring for all the\n+     * events that the user is interested in. Therefore, cancel the pending\n+     * poll operation; when we receive it's completion package, a new poll\n+     * operation will be submitted with the correct event mask. *\/\n+    if (sock__cancel_poll(sock_state) < 0)\n+      return -1;\n+\n+  } else if (sock_state->poll_status == SOCK__POLL_CANCELLED) {\n+    \/* The poll operation has already been cancelled, we're still waiting for\n+     * it to return. For now, there's nothing that needs to be done. *\/\n+\n+  } else if (sock_state->poll_status == SOCK__POLL_IDLE) {\n+    \/* No poll operation is pending; start one. *\/\n+    sock_state->poll_info.Exclusive = FALSE;\n+    sock_state->poll_info.NumberOfHandles = 1;\n+    sock_state->poll_info.Timeout.QuadPart = INT64_MAX;\n+    sock_state->poll_info.Handles[0].Handle = (HANDLE) sock_state->base_socket;\n+    sock_state->poll_info.Handles[0].Status = 0;\n+    sock_state->poll_info.Handles[0].Events =\n+        sock__epoll_events_to_afd_events(sock_state->user_events);\n+\n+    if (afd_poll(poll_group_get_afd_device_handle(sock_state->poll_group),\n+                 &sock_state->poll_info,\n+                 &sock_state->io_status_block) < 0) {\n+      switch (GetLastError()) {\n+        case ERROR_IO_PENDING:\n+          \/* Overlapped poll operation in progress; this is expected. *\/\n+          break;\n+        case ERROR_INVALID_HANDLE:\n+          \/* Socket closed; it'll be dropped from the epoll set. *\/\n+          return sock__delete(port_state, sock_state, false);\n+        default:\n+          \/* Other errors are propagated to the caller. *\/\n+          return_map_error(-1);\n+      }\n+    }\n+\n+    \/* The poll request was successfully submitted. *\/\n+    sock_state->poll_status = SOCK__POLL_PENDING;\n+    sock_state->pending_events = sock_state->user_events;\n+\n+  } else {\n+    \/* Unreachable. *\/\n+    assert(false);\n+  }\n+\n+  port_cancel_socket_update(port_state, sock_state);\n+  return 0;\n+}\n+\n+int sock_feed_event(port_state_t* port_state,\n+                    IO_STATUS_BLOCK* io_status_block,\n+                    struct epoll_event* ev) {\n+  sock_state_t* sock_state =\n+      container_of(io_status_block, sock_state_t, io_status_block);\n+  AFD_POLL_INFO* poll_info = &sock_state->poll_info;\n+  uint32_t epoll_events = 0;\n+\n+  sock_state->poll_status = SOCK__POLL_IDLE;\n+  sock_state->pending_events = 0;\n+\n+  if (sock_state->delete_pending) {\n+    \/* Socket has been deleted earlier and can now be freed. *\/\n+    return sock__delete(port_state, sock_state, false);\n+\n+  } else if (io_status_block->Status == STATUS_CANCELLED) {\n+    \/* The poll request was cancelled by CancelIoEx. *\/\n+\n+  } else if (!NT_SUCCESS(io_status_block->Status)) {\n+    \/* The overlapped request itself failed in an unexpected way. *\/\n+    epoll_events = EPOLLERR;\n+\n+  } else if (poll_info->NumberOfHandles < 1) {\n+    \/* This poll operation succeeded but didn't report any socket events. *\/\n+\n+  } else if (poll_info->Handles[0].Events & AFD_POLL_LOCAL_CLOSE) {\n+    \/* The poll operation reported that the socket was closed. *\/\n+    return sock__delete(port_state, sock_state, false);\n+\n+  } else {\n+    \/* Events related to our socket were reported. *\/\n+    epoll_events =\n+        sock__afd_events_to_epoll_events(poll_info->Handles[0].Events);\n+  }\n+\n+  \/* Requeue the socket so a new poll request will be submitted. *\/\n+  port_request_socket_update(port_state, sock_state);\n+\n+  \/* Filter out events that the user didn't ask for. *\/\n+  epoll_events &= sock_state->user_events;\n+\n+  \/* Return if there are no epoll events to report. *\/\n+  if (epoll_events == 0)\n+    return 0;\n+\n+  \/* If the the socket has the EPOLLONESHOT flag set, unmonitor all events,\n+   * even EPOLLERR and EPOLLHUP. But always keep looking for closed sockets. *\/\n+  if (sock_state->user_events & EPOLLONESHOT)\n+    sock_state->user_events = 0;\n+\n+  ev->data = sock_state->user_data;\n+  ev->events = epoll_events;\n+  return 1;\n+}\n+\n+sock_state_t* sock_state_from_queue_node(queue_node_t* queue_node) {\n+  return container_of(queue_node, sock_state_t, queue_node);\n+}\n+\n+queue_node_t* sock_state_to_queue_node(sock_state_t* sock_state) {\n+  return &sock_state->queue_node;\n+}\n+\n+sock_state_t* sock_state_from_tree_node(tree_node_t* tree_node) {\n+  return container_of(tree_node, sock_state_t, tree_node);\n+}\n+\n+tree_node_t* sock_state_to_tree_node(sock_state_t* sock_state) {\n+  return &sock_state->tree_node;\n+}\n+\n+void ts_tree_init(ts_tree_t* ts_tree) {\n+  tree_init(&ts_tree->tree);\n+  InitializeSRWLock(&ts_tree->lock);\n+}\n+\n+void ts_tree_node_init(ts_tree_node_t* node) {\n+  tree_node_init(&node->tree_node);\n+  reflock_init(&node->reflock);\n+}\n+\n+int ts_tree_add(ts_tree_t* ts_tree, ts_tree_node_t* node, uintptr_t key) {\n+  int r;\n+\n+  AcquireSRWLockExclusive(&ts_tree->lock);\n+  r = tree_add(&ts_tree->tree, &node->tree_node, key);\n+  ReleaseSRWLockExclusive(&ts_tree->lock);\n+\n+  return r;\n+}\n+\n+static inline ts_tree_node_t* ts_tree__find_node(ts_tree_t* ts_tree,\n+                                                 uintptr_t key) {\n+  tree_node_t* tree_node = tree_find(&ts_tree->tree, key);\n+  if (tree_node == NULL)\n+    return NULL;\n+\n+  return container_of(tree_node, ts_tree_node_t, tree_node);\n+}\n+\n+ts_tree_node_t* ts_tree_del_and_ref(ts_tree_t* ts_tree, uintptr_t key) {\n+  ts_tree_node_t* ts_tree_node;\n+\n+  AcquireSRWLockExclusive(&ts_tree->lock);\n+\n+  ts_tree_node = ts_tree__find_node(ts_tree, key);\n+  if (ts_tree_node != NULL) {\n+    tree_del(&ts_tree->tree, &ts_tree_node->tree_node);\n+    reflock_ref(&ts_tree_node->reflock);\n+  }\n+\n+  ReleaseSRWLockExclusive(&ts_tree->lock);\n+\n+  return ts_tree_node;\n+}\n+\n+ts_tree_node_t* ts_tree_find_and_ref(ts_tree_t* ts_tree, uintptr_t key) {\n+  ts_tree_node_t* ts_tree_node;\n+\n+  AcquireSRWLockShared(&ts_tree->lock);\n+\n+  ts_tree_node = ts_tree__find_node(ts_tree, key);\n+  if (ts_tree_node != NULL)\n+    reflock_ref(&ts_tree_node->reflock);\n+\n+  ReleaseSRWLockShared(&ts_tree->lock);\n+\n+  return ts_tree_node;\n+}\n+\n+void ts_tree_node_unref(ts_tree_node_t* node) {\n+  reflock_unref(&node->reflock);\n+}\n+\n+void ts_tree_node_unref_and_destroy(ts_tree_node_t* node) {\n+  reflock_unref_and_destroy(&node->reflock);\n+}\n+\n+void tree_init(tree_t* tree) {\n+  memset(tree, 0, sizeof *tree);\n+}\n+\n+void tree_node_init(tree_node_t* node) {\n+  memset(node, 0, sizeof *node);\n+}\n+\n+#define TREE__ROTATE(cis, trans)   \\\n+  tree_node_t* p = node;           \\\n+  tree_node_t* q = node->trans;    \\\n+  tree_node_t* parent = p->parent; \\\n+                                   \\\n+  if (parent) {                    \\\n+    if (parent->left == p)         \\\n+      parent->left = q;            \\\n+    else                           \\\n+      parent->right = q;           \\\n+  } else {                         \\\n+    tree->root = q;                \\\n+  }                                \\\n+                                   \\\n+  q->parent = parent;              \\\n+  p->parent = q;                   \\\n+  p->trans = q->cis;               \\\n+  if (p->trans)                    \\\n+    p->trans->parent = p;          \\\n+  q->cis = p;\n+\n+static inline void tree__rotate_left(tree_t* tree, tree_node_t* node) {\n+  TREE__ROTATE(left, right)\n+}\n+\n+static inline void tree__rotate_right(tree_t* tree, tree_node_t* node) {\n+  TREE__ROTATE(right, left)\n+}\n+\n+#define TREE__INSERT_OR_DESCEND(side) \\\n+  if (parent->side) {                 \\\n+    parent = parent->side;            \\\n+  } else {                            \\\n+    parent->side = node;              \\\n+    break;                            \\\n+  }\n+\n+#define TREE__REBALANCE_AFTER_INSERT(cis, trans) \\\n+  tree_node_t* grandparent = parent->parent;     \\\n+  tree_node_t* uncle = grandparent->trans;       \\\n+                                                 \\\n+  if (uncle && uncle->red) {                     \\\n+    parent->red = uncle->red = false;            \\\n+    grandparent->red = true;                     \\\n+    node = grandparent;                          \\\n+  } else {                                       \\\n+    if (node == parent->trans) {                 \\\n+      tree__rotate_##cis(tree, parent);          \\\n+      node = parent;                             \\\n+      parent = node->parent;                     \\\n+    }                                            \\\n+    parent->red = false;                         \\\n+    grandparent->red = true;                     \\\n+    tree__rotate_##trans(tree, grandparent);     \\\n+  }\n+\n+int tree_add(tree_t* tree, tree_node_t* node, uintptr_t key) {\n+  tree_node_t* parent;\n+\n+  parent = tree->root;\n+  if (parent) {\n+    for (;;) {\n+      if (key < parent->key) {\n+        TREE__INSERT_OR_DESCEND(left)\n+      } else if (key > parent->key) {\n+        TREE__INSERT_OR_DESCEND(right)\n+      } else {\n+        return -1;\n+      }\n+    }\n+  } else {\n+    tree->root = node;\n+  }\n+\n+  node->key = key;\n+  node->left = node->right = NULL;\n+  node->parent = parent;\n+  node->red = true;\n+\n+  for (; parent && parent->red; parent = node->parent) {\n+    if (parent == parent->parent->left) {\n+      TREE__REBALANCE_AFTER_INSERT(left, right)\n+    } else {\n+      TREE__REBALANCE_AFTER_INSERT(right, left)\n+    }\n+  }\n+  tree->root->red = false;\n+\n+  return 0;\n+}\n+\n+#define TREE__REBALANCE_AFTER_REMOVE(cis, trans)   \\\n+  tree_node_t* sibling = parent->trans;            \\\n+                                                   \\\n+  if (sibling->red) {                              \\\n+    sibling->red = false;                          \\\n+    parent->red = true;                            \\\n+    tree__rotate_##cis(tree, parent);              \\\n+    sibling = parent->trans;                       \\\n+  }                                                \\\n+  if ((sibling->left && sibling->left->red) ||     \\\n+      (sibling->right && sibling->right->red)) {   \\\n+    if (!sibling->trans || !sibling->trans->red) { \\\n+      sibling->cis->red = false;                   \\\n+      sibling->red = true;                         \\\n+      tree__rotate_##trans(tree, sibling);         \\\n+      sibling = parent->trans;                     \\\n+    }                                              \\\n+    sibling->red = parent->red;                    \\\n+    parent->red = sibling->trans->red = false;     \\\n+    tree__rotate_##cis(tree, parent);              \\\n+    node = tree->root;                             \\\n+    break;                                         \\\n+  }                                                \\\n+  sibling->red = true;\n+\n+void tree_del(tree_t* tree, tree_node_t* node) {\n+  tree_node_t* parent = node->parent;\n+  tree_node_t* left = node->left;\n+  tree_node_t* right = node->right;\n+  tree_node_t* next;\n+  bool red;\n+\n+  if (!left) {\n+    next = right;\n+  } else if (!right) {\n+    next = left;\n+  } else {\n+    next = right;\n+    while (next->left)\n+      next = next->left;\n+  }\n+\n+  if (parent) {\n+    if (parent->left == node)\n+      parent->left = next;\n+    else\n+      parent->right = next;\n+  } else {\n+    tree->root = next;\n+  }\n+\n+  if (left && right) {\n+    red = next->red;\n+    next->red = node->red;\n+    next->left = left;\n+    left->parent = next;\n+    if (next != right) {\n+      parent = next->parent;\n+      next->parent = node->parent;\n+      node = next->right;\n+      parent->left = node;\n+      next->right = right;\n+      right->parent = next;\n+    } else {\n+      next->parent = parent;\n+      parent = next;\n+      node = next->right;\n+    }\n+  } else {\n+    red = node->red;\n+    node = next;\n+  }\n+\n+  if (node)\n+    node->parent = parent;\n+  if (red)\n+    return;\n+  if (node && node->red) {\n+    node->red = false;\n+    return;\n+  }\n+\n+  do {\n+    if (node == tree->root)\n+      break;\n+    if (node == parent->left) {\n+      TREE__REBALANCE_AFTER_REMOVE(left, right)\n+    } else {\n+      TREE__REBALANCE_AFTER_REMOVE(right, left)\n+    }\n+    node = parent;\n+    parent = parent->parent;\n+  } while (!node->red);\n+\n+  if (node)\n+    node->red = false;\n+}\n+\n+tree_node_t* tree_find(const tree_t* tree, uintptr_t key) {\n+  tree_node_t* node = tree->root;\n+  while (node) {\n+    if (key < node->key)\n+      node = node->left;\n+    else if (key > node->key)\n+      node = node->right;\n+    else\n+      return node;\n+  }\n+  return NULL;\n+}\n+\n+tree_node_t* tree_root(const tree_t* tree) {\n+  return tree->root;\n+}\n+\n+#ifndef SIO_BSP_HANDLE_POLL\n+#define SIO_BSP_HANDLE_POLL 0x4800001D\n+#endif\n+\n+#ifndef SIO_BASE_HANDLE\n+#define SIO_BASE_HANDLE 0x48000022\n+#endif\n+\n+int ws_global_init(void) {\n+  int r;\n+  WSADATA wsa_data;\n+\n+  r = WSAStartup(MAKEWORD(2, 2), &wsa_data);\n+  if (r != 0)\n+    return_set_error(-1, (DWORD) r);\n+\n+  return 0;\n+}\n+\n+static inline SOCKET ws__ioctl_get_bsp_socket(SOCKET socket, DWORD ioctl) {\n+  SOCKET bsp_socket;\n+  DWORD bytes;\n+\n+  if (WSAIoctl(socket,\n+               ioctl,\n+               NULL,\n+               0,\n+               &bsp_socket,\n+               sizeof bsp_socket,\n+               &bytes,\n+               NULL,\n+               NULL) != SOCKET_ERROR)\n+    return bsp_socket;\n+  else\n+    return INVALID_SOCKET;\n+}\n+\n+SOCKET ws_get_base_socket(SOCKET socket) {\n+  SOCKET base_socket;\n+  DWORD error;\n+\n+  for (;;) {\n+    base_socket = ws__ioctl_get_bsp_socket(socket, SIO_BASE_HANDLE);\n+    if (base_socket != INVALID_SOCKET)\n+      return base_socket;\n+\n+    error = GetLastError();\n+    if (error == WSAENOTSOCK)\n+      return_set_error(INVALID_SOCKET, error);\n+\n+    \/* Even though Microsoft documentation clearly states that LSPs should\n+     * never intercept the `SIO_BASE_HANDLE` ioctl [1], Komodia based LSPs do\n+     * so anyway, breaking it, with the apparent intention of preventing LSP\n+     * bypass [2]. Fortunately they don't handle `SIO_BSP_HANDLE_POLL`, which\n+     * will at least let us obtain the socket associated with the next winsock\n+     * protocol chain entry. If this succeeds, loop around and call\n+     * `SIO_BASE_HANDLE` again with the returned BSP socket, to make sure that\n+     * we unwrap all layers and retrieve the actual base socket.\n+     *  [1] https:\/\/docs.microsoft.com\/en-us\/windows\/win32\/winsock\/winsock-ioctls\n+     *  [2] https:\/\/www.komodia.com\/newwiki\/index.php?title=Komodia%27s_Redirector_bug_fixes#Version_2.2.2.6\n+     *\/\n+    base_socket = ws__ioctl_get_bsp_socket(socket, SIO_BSP_HANDLE_POLL);\n+    if (base_socket != INVALID_SOCKET && base_socket != socket)\n+      socket = base_socket;\n+    else\n+      return_set_error(INVALID_SOCKET, error);\n+  }\n+}\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/wepoll.c","additions":2283,"deletions":0,"binary":false,"changes":2283,"status":"added"},{"patch":"@@ -0,0 +1,143 @@\n+\/*\n+ * Copyright (c) 2020, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.  Oracle designates this\n+ * particular file as subject to the \"Classpath\" exception as provided\n+ * by Oracle in the LICENSE file that accompanied this code.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/*\n+ * This file is available under and governed by the GNU General Public\n+ * License version 2 only, as published by the Free Software Foundation.\n+ * However, the following notice accompanied the original version of this\n+ * file and, per its terms, should not be removed:\n+ *\n+ * wepoll - epoll for Windows\n+ * https:\/\/github.com\/piscisaureus\/wepoll\n+ *\n+ * Copyright 2012-2020, Bert Belder <bertbelder@gmail.com>\n+ * All rights reserved.\n+ *\n+ * Redistribution and use in source and binary forms, with or without\n+ * modification, are permitted provided that the following conditions are\n+ * met:\n+ *\n+ *   * Redistributions of source code must retain the above copyright\n+ *     notice, this list of conditions and the following disclaimer.\n+ *\n+ *   * Redistributions in binary form must reproduce the above copyright\n+ *     notice, this list of conditions and the following disclaimer in the\n+ *     documentation and\/or other materials provided with the distribution.\n+ *\n+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n+ * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n+ *\/\n+\n+#ifndef WEPOLL_H_\n+#define WEPOLL_H_\n+\n+#ifndef WEPOLL_EXPORT\n+#define WEPOLL_EXPORT\n+#endif\n+\n+#include <stdint.h>\n+\n+enum EPOLL_EVENTS {\n+  EPOLLIN      = (int) (1U <<  0),\n+  EPOLLPRI     = (int) (1U <<  1),\n+  EPOLLOUT     = (int) (1U <<  2),\n+  EPOLLERR     = (int) (1U <<  3),\n+  EPOLLHUP     = (int) (1U <<  4),\n+  EPOLLRDNORM  = (int) (1U <<  6),\n+  EPOLLRDBAND  = (int) (1U <<  7),\n+  EPOLLWRNORM  = (int) (1U <<  8),\n+  EPOLLWRBAND  = (int) (1U <<  9),\n+  EPOLLMSG     = (int) (1U << 10), \/* Never reported. *\/\n+  EPOLLRDHUP   = (int) (1U << 13),\n+  EPOLLONESHOT = (int) (1U << 31)\n+};\n+\n+#define EPOLLIN      (1U <<  0)\n+#define EPOLLPRI     (1U <<  1)\n+#define EPOLLOUT     (1U <<  2)\n+#define EPOLLERR     (1U <<  3)\n+#define EPOLLHUP     (1U <<  4)\n+#define EPOLLRDNORM  (1U <<  6)\n+#define EPOLLRDBAND  (1U <<  7)\n+#define EPOLLWRNORM  (1U <<  8)\n+#define EPOLLWRBAND  (1U <<  9)\n+#define EPOLLMSG     (1U << 10)\n+#define EPOLLRDHUP   (1U << 13)\n+#define EPOLLONESHOT (1U << 31)\n+\n+#define EPOLL_CTL_ADD 1\n+#define EPOLL_CTL_MOD 2\n+#define EPOLL_CTL_DEL 3\n+\n+typedef void* HANDLE;\n+typedef uintptr_t SOCKET;\n+\n+typedef union epoll_data {\n+  void* ptr;\n+  int fd;\n+  uint32_t u32;\n+  uint64_t u64;\n+  SOCKET sock; \/* Windows specific *\/\n+  HANDLE hnd;  \/* Windows specific *\/\n+} epoll_data_t;\n+\n+struct epoll_event {\n+  uint32_t events;   \/* Epoll events and flags *\/\n+  epoll_data_t data; \/* User data variable *\/\n+};\n+\n+#ifdef __cplusplus\n+extern \"C\" {\n+#endif\n+\n+WEPOLL_EXPORT HANDLE epoll_create(int size);\n+WEPOLL_EXPORT HANDLE epoll_create1(int flags);\n+\n+WEPOLL_EXPORT int epoll_close(HANDLE ephnd);\n+\n+WEPOLL_EXPORT int epoll_ctl(HANDLE ephnd,\n+                            int op,\n+                            SOCKET sock,\n+                            struct epoll_event* event);\n+\n+WEPOLL_EXPORT int epoll_wait(HANDLE ephnd,\n+                             struct epoll_event* events,\n+                             int maxevents,\n+                             int timeout);\n+\n+#ifdef __cplusplus\n+} \/* extern \"C\" *\/\n+#endif\n+\n+#endif \/* WEPOLL_H_ *\/\n","filename":"src\/java.base\/windows\/native\/libnio\/ch\/wepoll.h","additions":143,"deletions":0,"binary":false,"changes":143,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2017, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,5 @@\n+\/* @test\n+ * @requires (os.family == \"windows\")\n+ * @run main\/othervm -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.WindowsSelectorProvider ChangingInterests\n+ *\/\n+\n","filename":"test\/jdk\/java\/nio\/channels\/Selector\/ChangingInterests.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2013, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -32,0 +32,5 @@\n+\/* @test\n+ * @requires (os.family == \"windows\")\n+ * @run main\/othervm -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.WindowsSelectorProvider LotsOfChannels\n+ *\/\n+\n","filename":"test\/jdk\/java\/nio\/channels\/Selector\/LotsOfChannels.java","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2010, 2017, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2010, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,5 +26,6 @@\n- * @requires (os.family != \"mac\") | (os.version == \"10.10.5\")\n- *    | (os.simpleVersion != \"10.8\" & os.simpleVersion != \"10.9\"\n- *        & os.simpleVersion != \"10.10\")\n- * @summary OOB data causes a SocketChannel, with OOBINLINE disabled, to be\n- *    selected\n+ * @summary OOB data causes a SocketChannel, with OOBINLINE disabled, to be selected\n+ *\/\n+\n+\/* @test\n+ * @requires (os.family == \"windows\")\n+ * @run main\/othervm -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.WindowsSelectorProvider OutOfBand\n","filename":"test\/jdk\/java\/nio\/channels\/Selector\/OutOfBand.java","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,6 @@\n+\n+\/* @test\n+ * @requires (os.family == \"windows\")\n+ * @run main\/othervm\/timeout=1200 -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.WindowsSelectorProvider RacyDeregister\n+ *\/\n+\n","filename":"test\/jdk\/java\/nio\/channels\/Selector\/RacyDeregister.java","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -25,0 +25,1 @@\n+ * @summary Unit test for Selector.select\/selectNow(Consumer)\n@@ -27,2 +28,5 @@\n- * @summary Unit test for Selector select(Consumer), select(Consumer,long) and\n- *          selectNow(Consumer)\n+ *\/\n+\n+\/* @test\n+ * @requires (os.family == \"windows\")\n+ * @run testng\/othervm -Djava.nio.channels.spi.SelectorProvider=sun.nio.ch.WindowsSelectorProvider SelectWithConsumer\n","filename":"test\/jdk\/java\/nio\/channels\/Selector\/SelectWithConsumer.java","additions":7,"deletions":3,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,111 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package org.openjdk.bench.java.nio.channels;\n+\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.net.SocketAddress;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.Selector;\n+import java.nio.channels.SelectionKey;\n+import java.nio.channels.ServerSocketChannel;\n+import java.nio.channels.SocketChannel;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+\/**\n+ * Benchmark for Selector.select(Consumer) when there is one channel ready.\n+ *\/\n+@BenchmarkMode(Mode.AverageTime)\n+@OutputTimeUnit(TimeUnit.NANOSECONDS)\n+@State(Scope.Thread)\n+public class SelectOne {\n+    private Selector sel;\n+    private List<SocketChannel> clients;\n+    private List<SocketChannel> peers;\n+\n+    private final int nready = 1;  \/\/ one channel ready for reading\n+\n+    @Param({\"1\", \"10\", \"100\", \"1000\", \"10000\"})\n+    private int nchannels;  \/\/ number of registered channels\n+\n+    @Setup\n+    public void setup() throws IOException {\n+        sel = Selector.open();\n+        clients = new ArrayList<SocketChannel>();\n+        peers = new ArrayList<SocketChannel>();\n+\n+        try (ServerSocketChannel listener = ServerSocketChannel.open()) {\n+            listener.bind(new InetSocketAddress(0));\n+            SocketAddress remote = listener.getLocalAddress();\n+\n+            for (int i = 0; i < nchannels; i++) {\n+                SocketChannel sc = SocketChannel.open(remote);\n+                sc.configureBlocking(false);\n+                sc.register(sel, SelectionKey.OP_READ);\n+                clients.add(sc);\n+\n+                SocketChannel peer = listener.accept();\n+                peers.add(peer);\n+            }\n+\n+            for (int i = nready - 1; i >= 0; i--) {\n+                SocketChannel peer = peers.get(i);\n+                peer.write(ByteBuffer.allocate(1));\n+            }\n+        }\n+    }\n+\n+    @TearDown\n+    public void teardown() throws IOException {\n+        for (SocketChannel sc: clients) {\n+            sc.close();\n+        }\n+        for (SocketChannel sc: peers) {\n+            sc.close();\n+        }\n+        if (sel != null) {\n+            sel.close();\n+        }\n+    }\n+\n+    @Benchmark\n+    public void testSelectOne() throws IOException {\n+        int nselected = sel.select(k -> { });\n+        if (nselected != 1) {\n+            throw new RuntimeException();\n+        }\n+    }\n+}\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/nio\/channels\/SelectOne.java","additions":111,"deletions":0,"binary":false,"changes":111,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, Oracle America, Inc.\n+ * Copyright (c) 2021, Oracle America, Inc.\n@@ -32,1 +32,1 @@\n-package org.openjdk.bench.java.nio;\n+package org.openjdk.bench.java.nio.channels;\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/nio\/channels\/SelectorWakeup.java","additions":2,"deletions":2,"binary":false,"changes":4,"previous_filename":"test\/micro\/org\/openjdk\/bench\/java\/nio\/SelectorWakeup.java","status":"renamed"}]}