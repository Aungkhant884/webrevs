{"files":[{"patch":"@@ -28,0 +28,2 @@\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.inline.hpp\"\n@@ -52,1 +54,0 @@\n-  HeapRegionRemSet::setup_remset_size();\n@@ -56,0 +57,4 @@\n+\n+  \/\/ We need to initialize card set configuration as soon as heap region size is\n+  \/\/ known as it depends on it and is used really early.\n+  initialize_card_set_configuration();\n@@ -115,0 +120,34 @@\n+\n+void G1Arguments::initialize_card_set_configuration() {\n+  assert(HeapRegion::LogOfHRGrainBytes != 0, \"not initialized\");\n+  \/\/ Array of Cards card set container globals.\n+  const int LOG_M = 20;\n+  uint region_size_log_mb = (uint)MAX2(HeapRegion::LogOfHRGrainBytes - LOG_M, 0);\n+\n+  if (FLAG_IS_DEFAULT(G1RemSetArrayOfCardsEntries)) {\n+    uint num_cards_in_inline_ptr = G1CardSetConfiguration::num_cards_in_inline_ptr(HeapRegion::LogOfHRGrainBytes - CardTable::card_shift);\n+    FLAG_SET_ERGO(G1RemSetArrayOfCardsEntries, MAX2(num_cards_in_inline_ptr * 2,\n+                                                    G1RemSetArrayOfCardsEntriesBase * (1u << (region_size_log_mb + 1))));\n+  }\n+\n+  \/\/ Round to next 8 byte boundary for array to maximize space usage.\n+  size_t const cur_size = G1CardSetArray::size_in_bytes(G1RemSetArrayOfCardsEntries);\n+  FLAG_SET_ERGO(G1RemSetArrayOfCardsEntries,\n+                G1RemSetArrayOfCardsEntries + (uint)(align_up(cur_size, G1CardSetAllocOptions::BufferAlignment) - cur_size) \/ sizeof(G1CardSetArray::EntryDataType));\n+\n+  \/\/ Howl card set container globals.\n+  if (FLAG_IS_DEFAULT(G1RemSetHowlNumBuckets)) {\n+    FLAG_SET_ERGO(G1RemSetHowlNumBuckets, G1CardSetHowl::num_buckets(HeapRegion::CardsPerRegion,\n+                                                                     G1RemSetArrayOfCardsEntries,\n+                                                                     G1RemSetHowlMaxNumBuckets));\n+  }\n+\n+  if (FLAG_IS_DEFAULT(G1RemSetHowlMaxNumBuckets)) {\n+    FLAG_SET_ERGO(G1RemSetHowlMaxNumBuckets, MAX2(G1RemSetHowlMaxNumBuckets, G1RemSetHowlNumBuckets));\n+  } else if (G1RemSetHowlMaxNumBuckets < G1RemSetHowlNumBuckets) {\n+    FormatBuffer<> buf(\"Maximum Howl card set container bucket size %u smaller than requested bucket size %u\",\n+                       G1RemSetHowlMaxNumBuckets, G1RemSetHowlNumBuckets);\n+    vm_exit_during_initialization(buf);\n+  }\n+}\n+\n@@ -192,0 +231,8 @@\n+\n+  \/\/ Verify that the maximum parallelism isn't too high to eventually overflow\n+  \/\/ the refcount in G1CardSetContainer.\n+  uint max_parallel_refinement_threads = G1ConcRefinementThreads + G1DirtyCardQueueSet::num_par_ids();\n+  uint const divisor = 3;  \/\/ Safe divisor; we increment by 2 for each claim, but there is a small initial value.\n+  if (max_parallel_refinement_threads > UINTPTR_MAX \/ divisor) {\n+    vm_exit_during_initialization(\"Too large parallelism for remembered sets.\");\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Arguments.cpp","additions":48,"deletions":1,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+  static void initialize_card_set_configuration();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Arguments.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -0,0 +1,899 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1CardSet.inline.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.inline.hpp\"\n+#include \"gc\/g1\/g1CardSetMemory.inline.hpp\"\n+#include \"gc\/g1\/g1FromCardCache.hpp\"\n+#include \"gc\/g1\/heapRegion.inline.hpp\"\n+#include \"memory\/allocation.inline.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/globals_extension.hpp\"\n+#include \"runtime\/mutex.hpp\"\n+#include \"utilities\/bitMap.inline.hpp\"\n+#include \"utilities\/concurrentHashTable.inline.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/lockFreeStack.hpp\"\n+#include \"utilities\/spinYield.hpp\"\n+\n+#include \"gc\/shared\/gcLogPrecious.hpp\"\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+#include \"runtime\/java.hpp\"\n+\n+G1CardSet::CardSetPtr G1CardSet::FullCardSet = (G1CardSet::CardSetPtr)-1;\n+\n+G1CardSetConfiguration::G1CardSetConfiguration() :\n+  _inline_ptr_bits_per_card(HeapRegion::LogOfHRGrainBytes - CardTable::card_shift) {\n+\n+  \/\/ Array of Cards card set container size calculation\n+  _num_cards_in_array = G1RemSetArrayOfCardsEntries;\n+\n+  \/\/ Full card set container size calculation\n+  _max_cards_in_card_set = (uint)HeapRegion::CardsPerRegion;\n+  assert(is_power_of_2(_max_cards_in_card_set),\n+        \"max_cards_in_card_set must be a power of 2: %u\", _max_cards_in_card_set);\n+  _cards_in_howl_threshold = _max_cards_in_card_set * (double)G1RemSetCoarsenHowlToFullPercent \/ 100;\n+\n+  \/\/ Howl card set container size calculation.\n+  _num_buckets_in_howl = G1RemSetHowlNumBuckets;\n+\n+  \/\/ Howl Bitmap card set container size calculation.\n+  _num_cards_in_howl_bitmap = G1CardSetHowl::bitmap_size(_max_cards_in_card_set, _num_buckets_in_howl);\n+  _log2_num_cards_in_howl_bitmap = log2i_exact(_num_cards_in_howl_bitmap);\n+  _cards_in_howl_bitmap_threshold = _num_cards_in_howl_bitmap * (double)G1RemSetCoarsenHowlBitmapToHowlFullPercent \/ 100;\n+  _bitmap_hash_mask = ~(~(0) << _log2_num_cards_in_howl_bitmap);\n+\n+  log_configuration();\n+}\n+\n+G1CardSetConfiguration::G1CardSetConfiguration(uint inline_ptr_bits_per_card,\n+                                               uint num_cards_in_array,\n+                                               double cards_in_bitmap_threshold,\n+                                               uint max_buckets_in_howl,\n+                                               double cards_in_howl_threshold,\n+                                               uint max_cards_in_cardset) :\n+  _inline_ptr_bits_per_card(inline_ptr_bits_per_card),\n+  _num_cards_in_array(num_cards_in_array),\n+  _max_cards_in_card_set(max_cards_in_cardset),\n+  _cards_in_howl_threshold(max_cards_in_cardset * cards_in_howl_threshold) {\n+\n+  assert(is_power_of_2(_max_cards_in_card_set),\n+        \"max_cards_in_card_set must be a power of 2: %u\", _max_cards_in_card_set);\n+\n+  _num_buckets_in_howl = G1CardSetHowl::num_buckets(_max_cards_in_card_set, _num_cards_in_array, max_buckets_in_howl);\n+\n+  _num_cards_in_howl_bitmap = G1CardSetHowl::bitmap_size(_max_cards_in_card_set, _num_buckets_in_howl);\n+  _cards_in_howl_bitmap_threshold = _num_cards_in_howl_bitmap * cards_in_bitmap_threshold;\n+  _log2_num_cards_in_howl_bitmap = log2i_exact(_num_cards_in_howl_bitmap);\n+  _bitmap_hash_mask = ~(~(0) << _log2_num_cards_in_howl_bitmap);\n+\n+  log_configuration();\n+}\n+\n+void G1CardSetConfiguration::log_configuration() {\n+  log_debug_p(gc, remset)(\"Card Set container configuration: \"\n+                          \"InlinePtr #elems %u size %zu \"\n+                          \"Array Of Cards #elems %u size %zu \"\n+                          \"Howl #buckets %u coarsen threshold %u \"\n+                          \"Howl Bitmap #elems %u size %zu coarsen threshold %u\",\n+                          num_cards_in_inline_ptr(), sizeof(void*),\n+                          num_cards_in_array(), G1CardSetArray::size_in_bytes(num_cards_in_array()),\n+                          num_buckets_in_howl(), cards_in_howl_threshold(),\n+                          num_cards_in_howl_bitmap(), G1CardSetBitMap::size_in_bytes(num_cards_in_howl_bitmap()), cards_in_howl_bitmap_threshold());\n+}\n+\n+uint G1CardSetConfiguration::num_cards_in_inline_ptr() const {\n+  return num_cards_in_inline_ptr(_inline_ptr_bits_per_card);\n+}\n+\n+uint G1CardSetConfiguration::num_cards_in_inline_ptr(uint bits_per_card) {\n+  return G1CardSetInlinePtr::max_cards_in_inline_ptr(bits_per_card);\n+}\n+\n+G1CardSetAllocOptions* G1CardSetConfiguration::mem_object_alloc_options() {\n+  G1CardSetAllocOptions* result = NEW_C_HEAP_ARRAY(G1CardSetAllocOptions, num_mem_object_types(), mtGC);\n+\n+  result[0] = { (uint)CardSetHash::get_node_size() };\n+  result[1] = { (uint)G1CardSetArray::size_in_bytes(num_cards_in_array()), 2, 256 };\n+  result[2] = { (uint)G1CardSetBitMap::size_in_bytes(num_cards_in_howl_bitmap()), 2, 256 };\n+  result[3] = { (uint)G1CardSetHowl::size_in_bytes(num_buckets_in_howl()), 2, 256 };\n+\n+  return result;\n+}\n+\n+const char* G1CardSetConfiguration::mem_object_type_name_str(uint index) {\n+  const char* names[] = { \"Node\", \"Array\", \"Bitmap\", \"Howl\" };\n+  return names[index];\n+}\n+\n+void G1CardSetCoarsenStats::reset() {\n+  STATIC_ASSERT(ARRAY_SIZE(_coarsen_from) == ARRAY_SIZE(_coarsen_collision));\n+  for (uint i = 0; i < ARRAY_SIZE(_coarsen_from); i++) {\n+    _coarsen_from[i] = 0;\n+    _coarsen_collision[i] = 0;\n+  }\n+}\n+\n+void G1CardSetCoarsenStats::add(G1CardSetCoarsenStats& other) {\n+  STATIC_ASSERT(ARRAY_SIZE(_coarsen_from) == ARRAY_SIZE(_coarsen_collision));\n+  for (uint i = 0; i < ARRAY_SIZE(_coarsen_from); i++) {\n+    _coarsen_from[i] += other._coarsen_from[i];\n+    _coarsen_collision[i] += other._coarsen_collision[i];\n+  }\n+}\n+\n+void G1CardSetCoarsenStats::subtract_from(G1CardSetCoarsenStats& other) {\n+  STATIC_ASSERT(ARRAY_SIZE(_coarsen_from) == ARRAY_SIZE(_coarsen_collision));\n+  for (uint i = 0; i < ARRAY_SIZE(_coarsen_from); i++) {\n+    _coarsen_from[i] = other._coarsen_from[i] - _coarsen_from[i];\n+    _coarsen_collision[i] = other._coarsen_collision[i] - _coarsen_collision[i];\n+  }\n+}\n+\n+void G1CardSetCoarsenStats::record_coarsening(uint tag, bool collision) {\n+  assert(tag < ARRAY_SIZE(_coarsen_from), \"tag %u out of bounds\", tag);\n+  Atomic::inc(&_coarsen_from[tag], memory_order_relaxed);\n+  if (collision) {\n+    Atomic::inc(&_coarsen_collision[tag], memory_order_relaxed);\n+  }\n+}\n+\n+void G1CardSetCoarsenStats::print_on(outputStream* out) {\n+  out->print_cr(\"Inline->AoC %zu (%zu) \"\n+                \"AoC->Howl %zu (%zu) \"\n+                \"Howl->Full %zu (%zu) \"\n+                \"Inline->AoC %zu (%zu) \"\n+                \"AoC->BitMap %zu (%zu) \"\n+                \"BitMap->Full %zu (%zu) \",\n+                _coarsen_from[0], _coarsen_collision[0],\n+                _coarsen_from[1], _coarsen_collision[1],\n+                \/\/ There is no BitMap at the first level so we can't .\n+                _coarsen_from[3], _coarsen_collision[3],\n+                _coarsen_from[4], _coarsen_collision[4],\n+                _coarsen_from[5], _coarsen_collision[5],\n+                _coarsen_from[6], _coarsen_collision[6]\n+               );\n+}\n+\n+class G1CardSetHashTable : public CHeapObj<mtGCCardSet> {\n+  using CardSetPtr = G1CardSet::CardSetPtr;\n+\n+  \/\/ Did we insert at least one element in the table?\n+  bool volatile _inserted_elem;\n+\n+  G1CardSetMemoryManager* _mm;\n+  CardSetHash _table;\n+\n+  class G1CardSetHashTableLookUp : public StackObj {\n+    uint _region_idx;\n+  public:\n+    explicit G1CardSetHashTableLookUp(uint region_idx) : _region_idx(region_idx) { }\n+\n+    uintx get_hash() const { return _region_idx; }\n+\n+    bool equals(G1CardSetHashTableValue* value, bool* is_dead) {\n+      *is_dead = false;\n+      return value->_region_idx == _region_idx;\n+    }\n+  };\n+\n+  class G1CardSetHashTableFound : public StackObj {\n+    G1CardSetHashTableValue* _value;\n+  public:\n+    void operator()(G1CardSetHashTableValue* value) {\n+      _value = value;\n+    }\n+\n+    G1CardSetHashTableValue* value() const { return _value; }\n+  };\n+\n+  class G1CardSetHashTableScan : public StackObj {\n+    G1CardSet::G1CardSetPtrIterator* _scan_f;\n+  public:\n+    explicit G1CardSetHashTableScan(G1CardSet::G1CardSetPtrIterator* f) : _scan_f(f) { }\n+\n+    bool operator()(G1CardSetHashTableValue* value) {\n+      _scan_f->do_cardsetptr(value->_region_idx, value->_num_occupied, value->_card_set);\n+      return true;\n+    }\n+  };\n+\n+\n+public:\n+  static const size_t InitialLogTableSize = 2;\n+\n+  G1CardSetHashTable(G1CardSetMemoryManager* mm,\n+                     size_t initial_log_table_size = InitialLogTableSize) :\n+    _inserted_elem(false),\n+    _mm(mm),\n+    _table(mm, initial_log_table_size) {\n+  }\n+\n+  ~G1CardSetHashTable() {\n+    reset();\n+  }\n+\n+  G1CardSetHashTableValue* get_or_add(uint region_idx, bool* should_grow) {\n+    G1CardSetHashTableLookUp lookup(region_idx);\n+    G1CardSetHashTableFound found;\n+\n+    if (_table.get(Thread::current(), lookup, found)) {\n+      return found.value();\n+    }\n+\n+    G1CardSetHashTableValue value(region_idx, G1CardSetInlinePtr());\n+    bool inserted = _table.insert_get(Thread::current(), lookup, value, found, should_grow);\n+\n+    if (!_inserted_elem && inserted) {\n+      \/\/ It does not matter to us who is setting the flag so a regular atomic store\n+      \/\/ is sufficient.\n+      Atomic::store(&_inserted_elem, true);\n+    }\n+\n+    return found.value();\n+  }\n+\n+  CardSetPtr get(uint region_idx) {\n+    G1CardSetHashTableLookUp lookup(region_idx);\n+    G1CardSetHashTableFound found;\n+\n+    if (_table.get(Thread::current(), lookup, found)) {\n+      return found.value()->_card_set;\n+    }\n+    return nullptr;\n+  }\n+\n+  void iterate_safepoint(G1CardSet::G1CardSetPtrIterator* cl2) {\n+    G1CardSetHashTableScan cl(cl2);\n+    _table.do_safepoint_scan(cl);\n+  }\n+\n+  void iterate(G1CardSet::G1CardSetPtrIterator* cl2) {\n+    G1CardSetHashTableScan cl(cl2);\n+    _table.do_scan(Thread::current(), cl);\n+  }\n+\n+  void reset() {\n+    if (Atomic::load(&_inserted_elem)) {\n+       _table.unsafe_reset(InitialLogTableSize);\n+      Atomic::store(&_inserted_elem, false);\n+    }\n+  }\n+\n+  void print(outputStream* os) {\n+    os->print(\"TBL \" PTR_FORMAT \" size %zu mem %zu \", p2i(&_table), _table.get_size_log2(Thread::current()), _table.get_mem_size(Thread::current()));\n+  }\n+\n+  void grow() {\n+    \/\/ Just double for now.\n+    size_t new_limit = _table.get_size_log2(Thread::current()) + 1;\n+    _table.grow(Thread::current(), new_limit);\n+  }\n+\n+  size_t mem_size() {\n+    return sizeof(*this) +\n+      _table.get_mem_size(Thread::current()) - sizeof(_table);\n+  }\n+\n+  size_t log_table_size() { return _table.get_size_log2(Thread::current()); }\n+};\n+\n+void* G1CardSetHashTableConfig::allocate_node(void* context, size_t size, Value const& value) {\n+  G1CardSetMemoryManager* mm = (G1CardSetMemoryManager*)context;\n+  return mm->allocate_node();\n+}\n+\n+void G1CardSetHashTableConfig::free_node(void* context, void* memory, Value const& value) {\n+  G1CardSetMemoryManager* mm = (G1CardSetMemoryManager*)context;\n+  mm->free_node(memory);\n+}\n+\n+G1CardSetCoarsenStats G1CardSet::_coarsen_stats;\n+G1CardSetCoarsenStats G1CardSet::_last_coarsen_stats;\n+\n+G1CardSet::G1CardSet(G1CardSetConfiguration* config, G1CardSetMemoryManager* mm) :\n+  _mm(mm),\n+  _config(config),\n+  _table(new G1CardSetHashTable(mm)),\n+  _num_occupied(0) {\n+}\n+\n+G1CardSet::~G1CardSet() {\n+  delete _table;\n+  _mm->flush();\n+}\n+\n+uint G1CardSet::card_set_type_to_mem_object_type(uintptr_t type) const {\n+  assert(type == G1CardSet::CardSetArrayOfCards ||\n+         type == G1CardSet::CardSetBitMap ||\n+         type == G1CardSet::CardSetHowl, \"should not allocate card set type %zu\", type);\n+\n+  return (uint)type;\n+}\n+\n+uint8_t* G1CardSet::allocate_mem_object(uintptr_t type) {\n+  return _mm->allocate(card_set_type_to_mem_object_type(type));\n+}\n+\n+void G1CardSet::free_mem_object(CardSetPtr card_set) {\n+  assert(card_set != G1CardSet::FreeCardSet, \"should not free Free card set\");\n+  assert(card_set != G1CardSet::FullCardSet, \"should not free Full card set\");\n+\n+  uintptr_t type = card_set_type(card_set);\n+  void* value = strip_card_set_type(card_set);\n+\n+  assert(type == G1CardSet::CardSetArrayOfCards ||\n+         type == G1CardSet::CardSetBitMap ||\n+         type == G1CardSet::CardSetHowl, \"should not free card set type %zu\", type);\n+\n+#ifdef ASSERT\n+  if (type == G1CardSet::CardSetArrayOfCards ||\n+      type == G1CardSet::CardSetBitMap ||\n+      type == G1CardSet::CardSetHowl) {\n+    G1CardSetContainer* card_set = (G1CardSetContainer*)value;\n+    assert((card_set->refcount() == 1), \"must be\");\n+  }\n+#endif\n+\n+  _mm->free(card_set_type_to_mem_object_type(type), value);\n+}\n+\n+G1CardSet::CardSetPtr G1CardSet::acquire_card_set(CardSetPtr volatile* card_set_addr) {\n+  \/\/ Update reference counts under RCU critical section to avoid a\n+  \/\/ use-after-cleapup bug where we increment a reference count for\n+  \/\/ an object whose memory has already been cleaned up and reused.\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+  while (true) {\n+    \/\/ Get cardsetptr and increment refcount atomically wrt to memory reuse.\n+    CardSetPtr card_set = Atomic::load_acquire(card_set_addr);\n+    uint cs_type = card_set_type(card_set);\n+    if (card_set == FullCardSet || cs_type == CardSetInlinePtr) {\n+      return card_set;\n+    }\n+\n+    G1CardSetContainer* card_set_on_heap = (G1CardSetContainer*)strip_card_set_type(card_set);\n+\n+    if (card_set_on_heap->try_increment_refcount()) {\n+      assert(card_set_on_heap->refcount() >= 3, \"Smallest value is 3\");\n+      return card_set;\n+    }\n+  }\n+}\n+\n+bool G1CardSet::release_card_set(CardSetPtr card_set) {\n+  uint cs_type = card_set_type(card_set);\n+  if (card_set == FullCardSet || cs_type == CardSetInlinePtr) {\n+    return false;\n+  }\n+\n+  G1CardSetContainer* card_set_on_heap = (G1CardSetContainer*)strip_card_set_type(card_set);\n+  return card_set_on_heap->decrement_refcount() == 1;\n+}\n+\n+void G1CardSet::release_and_maybe_free_card_set(CardSetPtr card_set) {\n+  if (release_card_set(card_set)) {\n+    free_mem_object(card_set);\n+  }\n+}\n+\n+void G1CardSet::release_and_must_free_card_set(CardSetPtr card_set) {\n+  bool should_free = release_card_set(card_set);\n+  assert(should_free, \"should have been the only one having a reference\");\n+  free_mem_object(card_set);\n+}\n+\n+class G1ReleaseCardsets : public StackObj {\n+  G1CardSet* _card_set;\n+  using CardSetPtr = G1CardSet::CardSetPtr;\n+\n+  void coarsen_to_full(CardSetPtr* card_set_addr) {\n+    while (true) {\n+      CardSetPtr cur_card_set = Atomic::load_acquire(card_set_addr);\n+      uint cs_type = G1CardSet::card_set_type(cur_card_set);\n+      if (cur_card_set == G1CardSet::FullCardSet) {\n+        return;\n+      }\n+\n+      CardSetPtr old_value = Atomic::cmpxchg(card_set_addr, cur_card_set, G1CardSet::FullCardSet);\n+\n+      if (old_value == cur_card_set) {\n+        _card_set->release_and_maybe_free_card_set(cur_card_set);\n+        return;\n+      }\n+    }\n+  }\n+\n+public:\n+  explicit G1ReleaseCardsets(G1CardSet* card_set) : _card_set(card_set) { }\n+\n+  void operator ()(CardSetPtr* card_set_addr) {\n+    coarsen_to_full(card_set_addr);\n+  }\n+};\n+\n+G1AddCardResult G1CardSet::add_to_array(CardSetPtr card_set, uint card_in_region) {\n+  G1CardSetArray* array = card_set_ptr<G1CardSetArray>(card_set);\n+  return array->add(card_in_region);\n+}\n+\n+G1AddCardResult G1CardSet::add_to_howl(CardSetPtr parent_card_set,\n+                                                uint card_region,\n+                                                uint card_in_region,\n+                                                bool increment_total) {\n+  G1CardSetHowl* howl = card_set_ptr<G1CardSetHowl>(parent_card_set);\n+\n+  G1AddCardResult add_result;\n+  CardSetPtr to_transfer = nullptr;\n+  CardSetPtr card_set;\n+\n+  uint bucket = _config->howl_bucket_index(card_in_region);\n+  volatile CardSetPtr* bucket_entry = howl->get_card_set_addr(bucket);\n+\n+  while (true) {\n+    if (Atomic::load(&howl->_num_entries) >= _config->cards_in_howl_threshold()) {\n+      return Overflow;\n+    }\n+\n+    card_set = acquire_card_set(bucket_entry);\n+    add_result = add_to_card_set(bucket_entry, card_set, card_region, card_in_region);\n+\n+    if (add_result != Overflow) {\n+      break;\n+    }\n+    \/\/ Card set has overflown. Coarsen and retry.\n+    bool coarsened = coarsen_card_set(bucket_entry, card_set, card_in_region, true \/* within_howl *\/);\n+    _coarsen_stats.record_coarsening(card_set_type(card_set) + G1CardSetCoarsenStats::CoarsenHowlOffset, !coarsened);\n+    if (coarsened) {\n+      \/\/ We have been the one coarsening this card set (and in the process added that card).\n+      add_result = Added;\n+      to_transfer = card_set;\n+      break;\n+    }\n+    \/\/ Somebody else beat us to coarsening. Retry.\n+    release_and_maybe_free_card_set(card_set);\n+  }\n+\n+  if (increment_total && add_result == Added) {\n+    Atomic::inc(&howl->_num_entries, memory_order_relaxed);\n+  }\n+\n+  if (to_transfer != nullptr) {\n+    transfer_cards_in_howl(parent_card_set, to_transfer, card_region);\n+  }\n+\n+  release_and_maybe_free_card_set(card_set);\n+  return add_result;\n+}\n+\n+G1AddCardResult G1CardSet::add_to_bitmap(CardSetPtr card_set, uint card_in_region) {\n+  G1CardSetBitMap* bitmap = card_set_ptr<G1CardSetBitMap>(card_set);\n+  uint card_offset = _config->howl_bitmap_offset(card_in_region);\n+  return bitmap->add(card_offset, _config->cards_in_howl_bitmap_threshold(), _config->num_cards_in_howl_bitmap());\n+}\n+\n+G1AddCardResult G1CardSet::add_to_inline_ptr(CardSetPtr volatile* card_set_addr, CardSetPtr card_set, uint card_in_region) {\n+  G1CardSetInlinePtr value(card_set_addr, card_set);\n+  return value.add(card_in_region, _config->inline_ptr_bits_per_card(), _config->num_cards_in_inline_ptr());\n+}\n+\n+G1CardSet::CardSetPtr G1CardSet::create_coarsened_array_of_cards(uint card_in_region, bool within_howl) {\n+  uint8_t* data = nullptr;\n+  CardSetPtr new_card_set;\n+  if (within_howl) {\n+    uint const size_in_bits = _config->num_cards_in_howl_bitmap();\n+    uint card_offset = _config->howl_bitmap_offset(card_in_region);\n+    data = allocate_mem_object(CardSetBitMap);\n+    new (data) G1CardSetBitMap(card_offset, size_in_bits);\n+    new_card_set = make_card_set_ptr(data, CardSetBitMap);\n+  } else {\n+    data = allocate_mem_object(CardSetHowl);\n+    new (data) G1CardSetHowl(card_in_region, _config);\n+    new_card_set = make_card_set_ptr(data, CardSetHowl);\n+  }\n+  return new_card_set;\n+}\n+\n+bool G1CardSet::coarsen_card_set(volatile CardSetPtr* card_set_addr,\n+                                 CardSetPtr cur_card_set,\n+                                 uint card_in_region,\n+                                 bool within_howl) {\n+  CardSetPtr new_card_set = nullptr;\n+\n+  switch (card_set_type(cur_card_set)) {\n+    case CardSetArrayOfCards : {\n+      new_card_set = create_coarsened_array_of_cards(card_in_region, within_howl);\n+      break;\n+    }\n+    case CardSetBitMap: {\n+      new_card_set = FullCardSet;\n+      break;\n+    }\n+    case CardSetInlinePtr: {\n+      uint const size = _config->num_cards_in_array();\n+      uint8_t* data = allocate_mem_object(CardSetArrayOfCards);\n+      new (data) G1CardSetArray(card_in_region, size);\n+      new_card_set = make_card_set_ptr(data, CardSetArrayOfCards);\n+      break;\n+    }\n+    case CardSetHowl: {\n+      new_card_set = FullCardSet; \/\/ anything will do at this point.\n+      break;\n+    }\n+    default:\n+      ShouldNotReachHere();\n+  }\n+\n+  CardSetPtr old_value = Atomic::cmpxchg(card_set_addr, cur_card_set, new_card_set); \/\/ Memory order?\n+  if (old_value == cur_card_set) {\n+    \/\/ Success. Indicate that the cards from the current card set must be transferred\n+    \/\/ by this caller.\n+    \/\/ Release the hash table reference to the card. The caller still holds the\n+    \/\/ reference to this card set, so it can never be released (and we do not need to\n+    \/\/ check its result).\n+    bool should_free = release_card_set(cur_card_set);\n+    assert(!should_free, \"must have had more than one reference\");\n+    \/\/ Free containers if cur_card_set is CardSetHowl\n+    if (card_set_type(cur_card_set) == CardSetHowl) {\n+      G1ReleaseCardsets rel(this);\n+      card_set_ptr<G1CardSetHowl>(cur_card_set)->iterate(rel, _config->num_buckets_in_howl());\n+    }\n+    return true;\n+  } else {\n+    \/\/ Somebody else beat us to coarsening that card set. Exit, but clean up first.\n+    if (new_card_set != FullCardSet) {\n+      assert(new_card_set != nullptr, \"must not be\");\n+      release_and_must_free_card_set(new_card_set);\n+    }\n+    return false;\n+  }\n+}\n+\n+class G1TransferCard : public StackObj {\n+  G1CardSet* _card_set;\n+  uint _region_idx;\n+public:\n+  G1TransferCard(G1CardSet* card_set, uint region_idx) : _card_set(card_set), _region_idx(region_idx) { }\n+\n+  void operator ()(uint card_idx) {\n+    _card_set->add_card(_region_idx, card_idx, false);\n+  }\n+};\n+\n+void G1CardSet::transfer_cards(G1CardSetHashTableValue* table_entry, CardSetPtr source_card_set, uint card_region) {\n+  assert(source_card_set != FullCardSet, \"Should not need to transfer from full\");\n+  \/\/ Need to transfer old entries unless there is a Full card set in place now, i.e.\n+  \/\/ the old type has been CardSetBitMap.\n+\n+  \/\/ We only need to transfer from anything below CardSetHowl. \"Full\" contains\n+  \/\/ all elements anyway.\n+  if (card_set_type(source_card_set) != CardSetHowl) {\n+    G1TransferCard iter(this, card_region);\n+    iterate_cards_during_transfer(source_card_set, iter);\n+  } else {\n+    assert(card_set_type(source_card_set) == CardSetHowl, \"must be\");\n+    \/\/ Need to correct for that the Full remembered set occupies more cards than the\n+    \/\/ AoCS before.\n+    Atomic::add(&_num_occupied, _config->max_cards_in_region() - table_entry->_num_occupied, memory_order_relaxed);\n+  }\n+}\n+\n+void G1CardSet::transfer_cards_in_howl(CardSetPtr parent_card_set,\n+                                                     CardSetPtr source_card_set,\n+                                                     uint card_region) {\n+  assert(card_set_type(parent_card_set) == CardSetHowl, \"must be\");\n+  assert(source_card_set != FullCardSet, \"Should not need to transfer from full\");\n+  \/\/ Need to transfer old entries unless there is a Full card set in place now, i.e.\n+  \/\/ the old type has been CardSetBitMap.\n+  if (card_set_type(source_card_set) != CardSetBitMap) {\n+    \/\/ We only need to transfer from anything below CardSetBitMap.\n+    G1TransferCard iter(this, card_region);\n+    iterate_cards_during_transfer(source_card_set, iter);\n+  } else {\n+    uint diff = _config->num_cards_in_howl_bitmap() - card_set_ptr<G1CardSetBitMap>(source_card_set)->num_bits_set();\n+\n+    \/\/ Need to correct for that the Full remembered set occupies more cards than the\n+    \/\/ bitmap before.\n+    \/\/ We add 1 element less because the values will be incremented\n+    \/\/ in G1CardSet::add_card for the current addition or where already incremented in\n+    \/\/ G1CardSet::add_to_howl after coarsening.\n+    diff -= 1;\n+\n+    G1CardSetHowl* howling_array = card_set_ptr<G1CardSetHowl>(parent_card_set);\n+    Atomic::add(&howling_array->_num_entries, diff, memory_order_relaxed);\n+\n+    bool should_grow_table = false;\n+    G1CardSetHashTableValue* table_entry = get_or_add_card_set(card_region, &should_grow_table);\n+    Atomic::add(&table_entry->_num_occupied, diff, memory_order_relaxed);\n+\n+    Atomic::add(&_num_occupied, diff, memory_order_relaxed);\n+  }\n+}\n+\n+G1AddCardResult G1CardSet::add_to_card_set(volatile CardSetPtr* card_set_addr, CardSetPtr card_set,  uint card_region, uint card_in_region, bool increment_total) {\n+  assert(card_set_addr != nullptr, \"Cannot add to empty cardset\");\n+\n+  G1AddCardResult add_result;\n+\n+  switch (card_set_type(card_set)) {\n+    case CardSetInlinePtr: {\n+      add_result = add_to_inline_ptr(card_set_addr, card_set, card_in_region);\n+      break;\n+    }\n+    case CardSetArrayOfCards : {\n+      add_result = add_to_array(card_set, card_in_region);\n+      break;\n+    }\n+    case CardSetBitMap: {\n+      add_result = add_to_bitmap(card_set, card_in_region);\n+      break;\n+    }\n+    case CardSetHowl: {\n+      assert(CardSetHowl == card_set_type(FullCardSet), \"must be\");\n+      if (card_set == FullCardSet) {\n+        return Found;\n+      }\n+      add_result = add_to_howl(card_set, card_region, card_in_region, increment_total);\n+      break;\n+    }\n+    default:\n+      ShouldNotReachHere();\n+  }\n+\n+  return add_result;\n+}\n+\n+G1CardSetHashTableValue* G1CardSet::get_or_add_card_set(uint card_region, bool* should_grow_table) {\n+  return _table->get_or_add(card_region, should_grow_table);\n+}\n+\n+G1CardSet::CardSetPtr G1CardSet::get_card_set(uint card_region) {\n+  return _table->get(card_region);\n+}\n+\n+G1AddCardResult G1CardSet::add_card(uint card_region, uint card_in_region, bool increment_total) {\n+  G1AddCardResult add_result;\n+  CardSetPtr to_transfer = nullptr;\n+  CardSetPtr card_set;\n+\n+  bool should_grow_table = false;\n+  G1CardSetHashTableValue* table_entry = get_or_add_card_set(card_region, &should_grow_table);\n+  while (true) {\n+    card_set = acquire_card_set(&table_entry->_card_set);\n+    add_result = add_to_card_set(&table_entry->_card_set, card_set, card_region, card_in_region, increment_total);\n+\n+    if (add_result != Overflow) {\n+      break;\n+    }\n+    \/\/ Card set has overflown. Coarsen and retry.\n+    bool coarsened = coarsen_card_set(&table_entry->_card_set, card_set, card_in_region);\n+    _coarsen_stats.record_coarsening(card_set_type(card_set), !coarsened);\n+    if (coarsened) {\n+      \/\/ We have been the one coarsening this card set (and in the process added that card).\n+      add_result = Added;\n+      to_transfer = card_set;\n+      break;\n+    }\n+    \/\/ Somebody else beat us to coarsening. Retry.\n+    release_and_maybe_free_card_set(card_set);\n+  }\n+\n+  if (increment_total && add_result == Added) {\n+    Atomic::inc(&table_entry->_num_occupied, memory_order_relaxed);\n+    Atomic::inc(&_num_occupied, memory_order_relaxed);\n+  }\n+  if (should_grow_table) {\n+    _table->grow();\n+  }\n+  if (to_transfer != nullptr) {\n+    transfer_cards(table_entry, to_transfer, card_region);\n+  }\n+\n+  release_and_maybe_free_card_set(card_set);\n+\n+  return add_result;\n+}\n+\n+bool G1CardSet::contains_card(uint card_region, uint card_in_region) {\n+  assert(card_in_region < _config->max_cards_in_region(),\n+         \"Card %u is beyond max %u\", card_in_region, _config->max_cards_in_region());\n+\n+  \/\/ Protect the card set from reclamation.\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+  CardSetPtr card_set = get_card_set(card_region);\n+  if (card_set == nullptr) {\n+    return false;\n+  } else if (card_set == FullCardSet) {\n+    \/\/ contains_card() is not a performance critical method so we do not hide that\n+    \/\/ case in the switch below.\n+    return true;\n+  }\n+\n+  switch (card_set_type(card_set)) {\n+    case CardSetInlinePtr: {\n+      G1CardSetInlinePtr ptr(card_set);\n+      return ptr.contains(card_in_region, _config->inline_ptr_bits_per_card());\n+    }\n+    case CardSetArrayOfCards :  return card_set_ptr<G1CardSetArray>(card_set)->contains(card_in_region);\n+    case CardSetBitMap: return card_set_ptr<G1CardSetBitMap>(card_set)->contains(card_in_region, _config->num_cards_in_howl_bitmap());\n+    case CardSetHowl: {\n+      G1CardSetHowl* howling_array = card_set_ptr<G1CardSetHowl>(card_set);\n+\n+      return howling_array->contains(card_in_region, _config);\n+    }\n+  }\n+  ShouldNotReachHere();\n+  return false;\n+}\n+\n+void G1CardSet::print_info(outputStream* st, uint card_region, uint card_in_region) {\n+  CardSetPtr card_set = get_card_set(card_region);\n+  if (card_set == nullptr) {\n+    st->print(\"NULL card set\");\n+    return;\n+  } else if (card_set == FullCardSet) {\n+    st->print(\"FULL card set)\");\n+    return;\n+  }\n+  switch (card_set_type(card_set)) {\n+    case CardSetInlinePtr: {\n+      st->print(\"InlinePtr not containing %u\", card_in_region);\n+      break;\n+    }\n+    case CardSetArrayOfCards :  {\n+      st->print(\"AoC not containing %u\", card_in_region);\n+      break;\n+    }\n+    case CardSetBitMap: {\n+      st->print(\"BitMap not containing %u\", card_in_region);\n+      break;\n+    }\n+    case CardSetHowl: {\n+      st->print(\"CardSetHowl not containing %u\", card_in_region);\n+      break;\n+    }\n+    default: st->print(\"Unknown card set type %u\", card_set_type(card_set)); ShouldNotReachHere(); break;\n+  }\n+}\n+\n+template <class CardVisitor>\n+void G1CardSet::iterate_cards_during_transfer(CardSetPtr const card_set, CardVisitor& found) {\n+  uint type = card_set_type(card_set);\n+  assert(type == CardSetInlinePtr || type == CardSetArrayOfCards,\n+         \"invalid card set type %d to transfer from\",\n+         card_set_type(card_set));\n+\n+  switch (type) {\n+    case CardSetInlinePtr: {\n+      G1CardSetInlinePtr ptr(card_set);\n+      ptr.iterate(found, _config->inline_ptr_bits_per_card());\n+      return;\n+    }\n+    case CardSetArrayOfCards : {\n+      card_set_ptr<G1CardSetArray>(card_set)->iterate(found);\n+      return;\n+    }\n+    default:\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void G1CardSet::iterate_containers(G1CardSetPtrIterator* found, bool at_safepoint) {\n+  if (at_safepoint) {\n+    _table->iterate_safepoint(found);\n+  } else {\n+    _table->iterate(found);\n+  }\n+}\n+\n+template <typename Closure>\n+class G1ContainerCards {\n+  Closure& _iter;\n+  uint _region_idx;\n+\n+public:\n+  G1ContainerCards(Closure& iter, uint region_idx) : _iter(iter), _region_idx(region_idx) { }\n+\n+  bool start_iterate(uint tag) { return true; }\n+\n+  void operator()(uint card_idx) {\n+    _iter.do_card(_region_idx, card_idx);\n+  }\n+\n+  void operator()(uint card_idx, uint length) {\n+    for (uint i = 0; i < length; i++) {\n+      _iter.do_card(_region_idx, card_idx);\n+    }\n+  }\n+};\n+\n+void G1CardSet::iterate_cards(G1CardSetCardIterator& iter) {\n+  G1CardSetMergeCardIterator<G1CardSetCardIterator, G1ContainerCards> cl(this, iter);\n+  iterate_containers(&cl);\n+}\n+\n+bool G1CardSet::occupancy_less_or_equal_to(size_t limit) const {\n+  return occupied() <= limit;\n+}\n+\n+bool G1CardSet::is_empty() const {\n+  return _num_occupied == 0;\n+}\n+\n+size_t G1CardSet::occupied() const {\n+  return _num_occupied;\n+}\n+\n+size_t G1CardSet::num_containers() {\n+  class GetNumberOfContainers : public G1CardSetPtrIterator {\n+  public:\n+    size_t _count;\n+\n+    GetNumberOfContainers() : G1CardSetPtrIterator(), _count(0) { }\n+\n+    void do_cardsetptr(uint region_idx, size_t num_occupied, CardSetPtr card_set) override {\n+      _count++;\n+    }\n+  } cl;\n+\n+  iterate_containers(&cl);\n+  return cl._count;\n+}\n+\n+G1CardSetCoarsenStats G1CardSet::coarsen_stats() {\n+  return _coarsen_stats;\n+}\n+\n+void G1CardSet::print_coarsen_stats(outputStream* out) {\n+  _last_coarsen_stats.subtract_from(_coarsen_stats);\n+  out->print(\"Coarsening (recent): \");\n+  _last_coarsen_stats.print_on(out);\n+  out->print(\"Coarsening (all): \");\n+  _coarsen_stats.print_on(out);\n+}\n+\n+size_t G1CardSet::mem_size() const {\n+  return sizeof(*this) +\n+         _table->mem_size() +\n+         _mm->mem_size();\n+}\n+\n+size_t G1CardSet::wasted_mem_size() const {\n+  return _mm->wasted_mem_size();\n+}\n+\n+size_t G1CardSet::static_mem_size() {\n+  return sizeof(FullCardSet) + sizeof(_coarsen_stats);\n+}\n+\n+void G1CardSet::clear() {\n+  _table->reset();\n+  _num_occupied = 0;\n+  _mm->flush();\n+}\n+\n+void G1CardSet::print(outputStream* os) {\n+  _table->print(os);\n+  _mm->print(os);\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSet.cpp","additions":899,"deletions":0,"binary":false,"changes":899,"status":"added"},{"patch":"@@ -0,0 +1,367 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSET_HPP\n+#define SHARE_GC_G1_G1CARDSET_HPP\n+\n+#include \"memory\/allocation.hpp\"\n+#include \"memory\/padded.hpp\"\n+#include \"oops\/oopsHierarchy.hpp\"\n+#include \"utilities\/concurrentHashTable.hpp\"\n+#include \"utilities\/lockFreeStack.hpp\"\n+\n+class G1CardSetAllocOptions;\n+class G1CardSetBufferList;\n+class G1CardSetHashTable;\n+class G1CardSetHashTableValue;\n+class G1CardSetMemoryManager;\n+class Mutex;\n+\n+\/\/ The result of an attempt to add a card to that card set.\n+enum G1AddCardResult {\n+  Overflow,  \/\/ The card set is more than full. The entry may have been added. Need\n+             \/\/ Coarsen and retry.\n+  Found,     \/\/ The card is already in the set.\n+  Added      \/\/ The card has been added to the set by this attempt.\n+};\n+\n+class G1CardSetConfiguration {\n+  uint _inline_ptr_bits_per_card;\n+  uint _num_cards_in_array;\n+  uint _num_cards_in_howl_bitmap;\n+  uint _num_buckets_in_howl;\n+  uint _max_cards_in_card_set;\n+  uint _cards_in_howl_threshold;\n+  uint _cards_in_howl_bitmap_threshold;\n+  uint _log2_num_cards_in_howl_bitmap;\n+  size_t _bitmap_hash_mask;\n+\n+  void log_configuration();\n+public:\n+\n+  \/\/ Initialize card set configuration from globals.\n+  G1CardSetConfiguration();\n+  \/\/ Initialize card set configuration from parameters.\n+  G1CardSetConfiguration(uint inline_ptr_bits_per_card,\n+                         uint num_cards_in_array,\n+                         double cards_in_bitmap_threshold,\n+                         uint max_buckets_in_howl,\n+                         double cards_in_howl_threshold,\n+                         uint max_cards_in_cardset);\n+\n+  \/\/ Inline pointer configuration\n+  uint inline_ptr_bits_per_card() const { return _inline_ptr_bits_per_card; }\n+  uint num_cards_in_inline_ptr() const;\n+  static uint num_cards_in_inline_ptr(uint bits_per_card);\n+\n+  \/\/ Array of Cards configuration\n+  bool use_cards_in_array() const { return _num_cards_in_array != 0; } \/\/ Unused for now\n+  \/\/ Number of cards in \"Array of Cards\" set; 0 to disable.\n+  \/\/ Always coarsen to next level if full, so no specific threshold.\n+  uint num_cards_in_array() const { return _num_cards_in_array; }\n+\n+  \/\/ Bitmap within Howl card set container configuration\n+  bool use_cards_in_howl_bitmap() const { return _num_cards_in_howl_bitmap != 0; } \/\/ Unused for now\n+  uint num_cards_in_howl_bitmap() const { return _num_cards_in_howl_bitmap; }\n+  \/\/ (Approximate) Number of cards in bitmap to coarsen Howl Bitmap to Howl Full.\n+  uint cards_in_howl_bitmap_threshold() const { return _cards_in_howl_bitmap_threshold; }\n+  uint log2_num_cards_in_howl_bitmap() const {return _log2_num_cards_in_howl_bitmap;}\n+\n+  \/\/ Howl card set container configuration\n+  uint num_buckets_in_howl() const { return _num_buckets_in_howl; }\n+  \/\/ Threshold at which to turn howling arrays into Full.\n+  uint cards_in_howl_threshold() const { return _cards_in_howl_threshold; }\n+  uint howl_bitmap_offset(uint card_idx) const { return card_idx & _bitmap_hash_mask; }\n+  \/\/ Given a card index, return the bucket in the array of card sets.\n+  uint howl_bucket_index(uint card_idx) { return card_idx >> _log2_num_cards_in_howl_bitmap; }\n+\n+  \/\/ Full card configuration\n+  \/\/ Maximum number of cards in a non-full card set for a single region. Card sets\n+  \/\/ with more entries per region are coarsened to Full.\n+  uint max_cards_in_region() const { return _max_cards_in_card_set; }\n+\n+  \/\/ Memory object types configuration\n+  \/\/ Number of distinctly sized memory objects on the card set heap.\n+  \/\/ Currently contains CHT-Nodes, ArrayOfCards, BitMaps, Howl\n+  static constexpr uint num_mem_object_types() { return 4; }\n+  \/\/ Returns the memory allocation options for the memory objects on the card set heap. The returned\n+  \/\/ array must be freed by the caller.\n+  G1CardSetAllocOptions* mem_object_alloc_options();\n+\n+  \/\/ For a given memory object, get a descriptive name.\n+  static const char* mem_object_type_name_str(uint index);\n+};\n+\n+\/\/ Collects coarsening statistics: how many attempts of each kind and how many\n+\/\/ failed due to a competing thread doing the coarsening first.\n+class G1CardSetCoarsenStats {\n+public:\n+  \/\/ Number of entries in the statistics tables: since we index with the source\n+  \/\/ cardset of the coarsening, this is the total number of combinations of\n+  \/\/ card sets - 1.\n+  static constexpr size_t NumCoarsenCategories = 7;\n+  \/\/ Coarsening statistics for the possible CardSetPtr in the Howl card set\n+  \/\/ start from this offset.\n+  static constexpr size_t CoarsenHowlOffset = 4;\n+\n+private:\n+  \/\/ Indices are \"from\" indices.\n+  size_t _coarsen_from[NumCoarsenCategories];\n+  size_t _coarsen_collision[NumCoarsenCategories];\n+\n+public:\n+  G1CardSetCoarsenStats() { reset(); }\n+\n+  void reset();\n+\n+  void add(G1CardSetCoarsenStats& other);\n+  void subtract_from(G1CardSetCoarsenStats& other);\n+\n+  \/\/ Record a coarsening for the given tag\/category. Collision should be true if\n+  \/\/ this coarsening lost the race to do the coarsening of that category.\n+  void record_coarsening(uint tag, bool collision);\n+\n+  size_t num_coarsening(uint tag) const { return Atomic::load(&_coarsen_from[tag]); }\n+\n+  void print_on(outputStream* out);\n+};\n+\n+class G1CardSet : public CHeapObj<mtGCCardSet> {\n+  friend class G1CardSetTest;\n+  friend class G1CardSetMtTestTask;\n+\n+  template <typename Closure, template <typename> class CardorRanges>\n+  friend class G1CardSetMergeCardIterator;\n+\n+  friend class G1TransferCard;\n+\n+  friend class G1ReleaseCardsets;\n+\n+  static G1CardSetCoarsenStats _coarsen_stats; \/\/ Coarsening statistics since VM start.\n+  static G1CardSetCoarsenStats _last_coarsen_stats; \/\/ Coarsening statistics at last GC.\n+public:\n+  \/\/ Two lower bits are used to encode the card storage types\n+  static const uintptr_t CardSetPtrHeaderSize = 2;\n+\n+  \/\/ CardSetPtr represents the card storage type of a given region. It encodes\n+  \/\/ a type in the LSBs, in addition to having a few significant values.\n+  \/\/\n+  \/\/ Possible encodings:\n+  \/\/\n+  \/\/ 0...00000 free               (should never happen)\n+  \/\/ 1...11111 full\n+  \/\/ X...XXX00 inline-ptr-cards   (64 bit)\n+  \/\/ X...XXX01 array of cards\n+  \/\/ X...XXX10 bitmap\n+  \/\/ X...XXX11 howl (64 bit)\n+  typedef void* CardSetPtr;\n+  \/\/ Coarsening happens in the order below:\n+  \/\/ CardSetInlinePtr -> CardSetArrayOfCards -> CardSetHowl -> Full\n+  \/\/ Corsening of containers inside the CardSetHowl happens in the order:\n+  \/\/ CardSetInlinePtr -> CardSetArrayOfCards -> CardSetBitMap -> Full\n+  static const uintptr_t CardSetInlinePtr      = 0x0;\n+  static const uintptr_t CardSetArrayOfCards   = 0x1;\n+  static const uintptr_t CardSetBitMap         = 0x2;\n+  static const uintptr_t CardSetHowl           = 0x3;\n+\n+  \/\/ The special sentinel values\n+  static constexpr CardSetPtr FreeCardSet = nullptr;\n+  \/\/ Unfortunately we can't make (G1CardSet::CardSetPtr)-1 constexpr because\n+  \/\/ reinterpret_casts are forbidden in constexprs. Use a regular static instead.\n+  static CardSetPtr FullCardSet;\n+\n+  static const uintptr_t CardSetPtrTypeMask    = ((uintptr_t)1 << CardSetPtrHeaderSize) - 1;\n+\n+  static CardSetPtr strip_card_set_type(CardSetPtr ptr) { return (CardSetPtr)((uintptr_t)ptr & ~CardSetPtrTypeMask); }\n+\n+  static uint card_set_type(CardSetPtr ptr) { return (uintptr_t)ptr & CardSetPtrTypeMask; }\n+\n+  template <class T>\n+  static T* card_set_ptr(CardSetPtr ptr);\n+\n+private:\n+  G1CardSetMemoryManager* _mm;\n+  G1CardSetConfiguration* _config;\n+\n+  G1CardSetHashTable* _table;\n+\n+  \/\/ Total number of cards in this card set. This is a best-effort value, i.e. there may\n+  \/\/ be (slightly) more cards in the card set than this value in reality.\n+  size_t _num_occupied;\n+\n+  CardSetPtr make_card_set_ptr(void* value, uintptr_t type);\n+\n+  CardSetPtr acquire_card_set(CardSetPtr volatile* card_set_addr);\n+  \/\/ Returns true if the card set should be released\n+  bool release_card_set(CardSetPtr card_set);\n+  \/\/ Release card set and free if needed.\n+  void release_and_maybe_free_card_set(CardSetPtr card_set);\n+  \/\/ Release card set and free (and it must be freeable).\n+  void release_and_must_free_card_set(CardSetPtr card_set);\n+\n+  \/\/ Coarsens the CardSet cur_card_set to the next level; tries to replace the\n+  \/\/ previous CardSet with a new one which includes the given card_in_region.\n+  \/\/ coarsen_card_set does not transfer cards from cur_card_set\n+  \/\/ to the new card_set. Transfer is achieved by transfer_cards.\n+  \/\/ Returns true if this was the thread that coarsened the CardSet (and added the card).\n+  bool coarsen_card_set(CardSetPtr volatile* card_set_addr,\n+                        CardSetPtr cur_card_set,\n+                        uint card_in_region, bool within_howl = false);\n+\n+  CardSetPtr create_coarsened_array_of_cards(uint card_in_region, bool within_howl);\n+\n+  \/\/ Transfer entries from source_card_set to a recently installed coarser storage type\n+  \/\/ We only need to transfer anything finer than CardSetBitMap. \"Full\" contains\n+  \/\/ all elements anyway.\n+  void transfer_cards(G1CardSetHashTableValue* table_entry, CardSetPtr source_card_set, uint card_region);\n+  void transfer_cards_in_howl(CardSetPtr parent_card_set, CardSetPtr source_card_set, uint card_region);\n+\n+  G1AddCardResult add_to_card_set(CardSetPtr volatile* card_set_addr, CardSetPtr card_set, uint card_region, uint card, bool increment_total = true);\n+\n+  G1AddCardResult add_to_inline_ptr(CardSetPtr volatile* card_set_addr, CardSetPtr card_set, uint card_in_region);\n+  G1AddCardResult add_to_array(CardSetPtr card_set, uint card_in_region);\n+  G1AddCardResult add_to_bitmap(CardSetPtr card_set, uint card_in_region);\n+  G1AddCardResult add_to_howl(CardSetPtr parent_card_set, uint card_region, uint card_in_region, bool increment_total = true);\n+\n+  G1CardSetHashTableValue* get_or_add_card_set(uint card_region, bool* should_grow_table);\n+  CardSetPtr get_card_set(uint card_region);\n+\n+  \/\/ Iterate over cards of a card set container during transfer of the cards from\n+  \/\/ one container to another. Executes\n+  \/\/\n+  \/\/     void operator ()(uint card_idx)\n+  \/\/\n+  \/\/ on the given class.\n+  template <class CardVisitor>\n+  void iterate_cards_during_transfer(CardSetPtr const card_set, CardVisitor& found);\n+\n+  \/\/ Iterate over the container, calling a method on every card or card range contained\n+  \/\/ in the card container.\n+  \/\/ For every container, first calls\n+  \/\/\n+  \/\/   void start_iterate(uint tag, uint region_idx);\n+  \/\/\n+  \/\/ Then for every card or card range it calls\n+  \/\/\n+  \/\/   void do_card(uint card_idx);\n+  \/\/   void do_card_range(uint card_idx, uint length);\n+  \/\/\n+  \/\/ where card_idx is the card index within that region_idx passed before in\n+  \/\/ start_iterate().\n+  \/\/\n+  template <class CardOrRangeVisitor>\n+  void iterate_cards_or_ranges_in_container(CardSetPtr const card_set, CardOrRangeVisitor& found);\n+\n+  uint card_set_type_to_mem_object_type(uintptr_t type) const;\n+  uint8_t* allocate_mem_object(uintptr_t type);\n+  void free_mem_object(CardSetPtr card_set);\n+\n+public:\n+  G1CardSetConfiguration* config() const { return _config; }\n+\n+  \/\/ Create a new remembered set for a particular heap region.\n+  G1CardSet(G1CardSetConfiguration* config, G1CardSetMemoryManager* mm);\n+  virtual ~G1CardSet();\n+\n+  \/\/ Adds the given card to this set, returning an appropriate result. If added,\n+  \/\/ updates the total count.\n+  G1AddCardResult add_card(uint card_region, uint card_in_region, bool increment_total = true);\n+\n+  bool contains_card(uint card_region, uint card_in_region);\n+\n+  void print_info(outputStream* st, uint card_region, uint card_in_region);\n+\n+  \/\/ Returns whether this remembered set (and all sub-sets) have an occupancy\n+  \/\/ that is less or equal to the given occupancy.\n+  bool occupancy_less_or_equal_to(size_t limit) const;\n+\n+  \/\/ Returns whether this remembered set (and all sub-sets) does not contain any entry.\n+  bool is_empty() const;\n+\n+  \/\/ Returns the number of cards contained in this remembered set.\n+  size_t occupied() const;\n+\n+  size_t num_containers();\n+\n+  static G1CardSetCoarsenStats coarsen_stats();\n+  static void print_coarsen_stats(outputStream* out);\n+\n+  \/\/ Returns size of the actual remembered set containers in bytes.\n+  size_t mem_size() const;\n+  size_t wasted_mem_size() const;\n+  \/\/ Returns the size of static data in bytes.\n+  static size_t static_mem_size();\n+\n+  \/\/ Clear the entire contents of this remembered set.\n+  void clear();\n+\n+  void print(outputStream* os);\n+\n+  \/\/ Various iterators - should be made inlineable somehow.\n+  class G1CardSetPtrIterator {\n+  public:\n+    virtual void do_cardsetptr(uint region_idx, size_t num_occupied, CardSetPtr card_set) = 0;\n+  };\n+\n+  void iterate_containers(G1CardSetPtrIterator* iter, bool safepoint = false);\n+\n+  class G1CardSetCardIterator {\n+  public:\n+    virtual void do_card(uint region_idx, uint card_idx) = 0;\n+  };\n+\n+  void iterate_cards(G1CardSetCardIterator& iter);\n+\n+  \/\/ Iterate all cards for card set merging. Must be a CardOrRangeVisitor as\n+  \/\/ explained above.\n+  template <class CardOrRangeVisitor>\n+  void iterate_for_merge(CardOrRangeVisitor& cl);\n+};\n+\n+class G1CardSetHashTableValue {\n+public:\n+  using CardSetPtr = G1CardSet::CardSetPtr;\n+\n+  const uint _region_idx;\n+  uint volatile _num_occupied;\n+  CardSetPtr volatile _card_set;\n+\n+  G1CardSetHashTableValue(uint region_idx, CardSetPtr card_set) : _region_idx(region_idx), _num_occupied(0), _card_set(card_set) { }\n+};\n+\n+class G1CardSetHashTableConfig : public StackObj {\n+public:\n+  using Value = G1CardSetHashTableValue;\n+\n+  static uintx get_hash(Value const& value, bool* is_dead) {\n+    *is_dead = false;\n+    return value._region_idx;\n+  }\n+  static void* allocate_node(void* context, size_t size, Value const& value);\n+  static void free_node(void* context, void* memory, Value const& value);\n+};\n+\n+typedef ConcurrentHashTable<G1CardSetHashTableConfig, mtGCCardSet> CardSetHash;\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSET_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSet.hpp","additions":367,"deletions":0,"binary":false,"changes":367,"status":"added"},{"patch":"@@ -0,0 +1,125 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSET_INLINE_HPP\n+#define SHARE_GC_G1_G1CARDSET_INLINE_HPP\n+\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.inline.hpp\"\n+#include \"gc\/g1\/g1GCPhaseTimes.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"logging\/log.hpp\"\n+\n+template <class T>\n+inline T* G1CardSet::card_set_ptr(CardSetPtr ptr) {\n+  return (T*)strip_card_set_type(ptr);\n+}\n+\n+inline G1CardSet::CardSetPtr G1CardSet::make_card_set_ptr(void* value, uintptr_t type) {\n+  assert(card_set_type(value) == 0, \"Given ptr \" PTR_FORMAT \" already has type bits set\", p2i(value));\n+  return (CardSetPtr)((uintptr_t)value | type);\n+}\n+\n+template <class CardOrRangeVisitor>\n+inline void G1CardSet::iterate_cards_or_ranges_in_container(CardSetPtr const card_set, CardOrRangeVisitor& found) {\n+  switch (card_set_type(card_set)) {\n+    case CardSetInlinePtr: {\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSMergedInline)) {\n+        G1CardSetInlinePtr ptr(card_set);\n+        ptr.iterate(found, _config->inline_ptr_bits_per_card());\n+      }\n+      return;\n+    }\n+    case CardSetArrayOfCards : {\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSMergedArrayOfCards)) {\n+        card_set_ptr<G1CardSetArray>(card_set)->iterate(found);\n+      }\n+      return;\n+    }\n+    case CardSetBitMap: {\n+      \/\/ There is no first-level bitmap spanning the whole area.\n+      ShouldNotReachHere();\n+      return;\n+    }\n+    case CardSetHowl: {\n+      assert(card_set_type(FullCardSet) == CardSetHowl, \"Must be\");\n+      if (card_set == FullCardSet) {\n+        if (found.start_iterate(G1GCPhaseTimes::MergeRSMergedFull)) {\n+          found(0, _config->max_cards_in_region());\n+        }\n+        return;\n+      }\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSMergedHowl)) {\n+        card_set_ptr<G1CardSetHowl>(card_set)->iterate(found, _config);\n+      }\n+      return;\n+    }\n+  }\n+  log_error(gc)(\"Unkown card set type %u\", card_set_type(card_set));\n+  ShouldNotReachHere();\n+}\n+\n+template <typename Closure>\n+class G1ContainerCardsOrRanges {\n+  Closure& _iter;\n+  uint _region_idx;\n+\n+public:\n+  G1ContainerCardsOrRanges(Closure& iter, uint region_idx) : _iter(iter), _region_idx(region_idx) { }\n+\n+  bool start_iterate(uint tag) {\n+    return _iter.start_iterate(tag, _region_idx);\n+  }\n+\n+  void operator()(uint card_idx) {\n+    _iter.do_card(card_idx);\n+  }\n+\n+  void operator()(uint card_idx, uint length) {\n+    _iter.do_card_range(card_idx, length);\n+  }\n+};\n+\n+template <typename Closure, template <typename> class CardOrRanges>\n+class G1CardSetMergeCardIterator : public G1CardSet::G1CardSetPtrIterator {\n+  G1CardSet* _card_set;\n+  Closure& _iter;\n+\n+public:\n+\n+  G1CardSetMergeCardIterator(G1CardSet* card_set, Closure& iter) : _card_set(card_set), _iter(iter) { }\n+\n+  void do_cardsetptr(uint region_idx, size_t num_occupied, G1CardSet::CardSetPtr card_set) override {\n+    CardOrRanges<Closure> cl(_iter, region_idx);\n+    _card_set->iterate_cards_or_ranges_in_container(card_set, cl);\n+  }\n+};\n+\n+template <class CardOrRangeVisitor>\n+inline void G1CardSet::iterate_for_merge(CardOrRangeVisitor& cl) {\n+  G1CardSetMergeCardIterator<CardOrRangeVisitor, G1ContainerCardsOrRanges> cl2(this, cl);\n+  iterate_containers(&cl2, true \/* at_safepoint *\/);\n+}\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSET_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSet.inline.hpp","additions":125,"deletions":0,"binary":false,"changes":125,"status":"added"},{"patch":"@@ -0,0 +1,290 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSETCONTAINERS_HPP\n+#define SHARE_GC_G1_G1CARDSETCONTAINERS_HPP\n+\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/bitMap.inline.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/spinYield.hpp\"\n+\n+#include \"logging\/log.hpp\"\n+\n+#include \"runtime\/thread.inline.hpp\"\n+\n+class G1CardSetInlinePtr : public StackObj {\n+  friend class G1CardSetContainersTest;\n+\n+  typedef G1CardSet::CardSetPtr CardSetPtr;\n+\n+  CardSetPtr volatile * _value_addr;\n+  CardSetPtr _value;\n+\n+  static const uint SizeFieldLen = 3;\n+  static const uint SizeFieldPos = 2;\n+  static const uint HeaderSize = G1CardSet::CardSetPtrHeaderSize + SizeFieldLen;\n+\n+  static const uint BitsInValue = sizeof(CardSetPtr) * BitsPerByte;\n+\n+  static const uintptr_t SizeFieldMask = (((uint)1 << SizeFieldLen) - 1) << SizeFieldPos;\n+\n+  static uint8_t card_pos_for(uint const idx, uint const bits_per_card) {\n+    return (idx * bits_per_card + HeaderSize);\n+  }\n+\n+  static CardSetPtr merge(CardSetPtr orig_value, uint card_in_region, uint idx, uint bits_per_card);\n+\n+  static uint card_at(CardSetPtr value, uint const idx, uint const bits_per_card) {\n+    uint8_t card_pos = card_pos_for(idx, bits_per_card);\n+    uint result = ((uintptr_t)value >> card_pos) & (((uintptr_t)1 << bits_per_card) - 1);\n+    return result;\n+  }\n+public:\n+  G1CardSetInlinePtr() : _value_addr(nullptr), _value((CardSetPtr)G1CardSet::CardSetInlinePtr) { }\n+\n+  G1CardSetInlinePtr(CardSetPtr value) : _value_addr(nullptr), _value(value) {\n+    assert(((uintptr_t)_value & G1CardSet::CardSetInlinePtr) == G1CardSet::CardSetInlinePtr, \"Value \" PTR_FORMAT \" is not a valid G1CardSetInPtr.\", p2i(_value));\n+  }\n+\n+  G1CardSetInlinePtr(CardSetPtr volatile* value_addr, CardSetPtr value) : _value_addr(value_addr), _value(value) {\n+    assert(((uintptr_t)_value & G1CardSet::CardSetInlinePtr) == G1CardSet::CardSetInlinePtr, \"Value \" PTR_FORMAT \" is not a valid G1CardSetInPtr.\", p2i(_value));\n+  }\n+\n+  G1AddCardResult add(uint const card_idx, uint const bits_per_card, uint const max_cards_in_inline_ptr);\n+\n+  bool contains(uint const card_idx, uint const bits_per_card);\n+\n+  template <class CardVisitor>\n+  void iterate(CardVisitor& found, uint const bits_per_card);\n+\n+  operator CardSetPtr () { return _value; }\n+\n+  static uint max_cards_in_inline_ptr(uint bits_per_card) {\n+    return (BitsInValue - HeaderSize) \/ bits_per_card;\n+  }\n+\n+  static uint num_cards_in(CardSetPtr value) {\n+    return ((uintptr_t)value & SizeFieldMask) >> SizeFieldPos;\n+  }\n+};\n+\n+\n+\/\/ Common base class for card set container related objects managed on the heap. Depending\n+\/\/ on the current use, one of the two overlapping elements are used:\n+\/\/\n+\/\/ While such an object is assigned to a card set container, we utilize the\n+\/\/ reference count for memory management.\n+\/\/\n+\/\/ In this case the object is one of three states:\n+\/\/ 1: Live: The object is visible to other threads, thus can\n+\/\/    safely be accessed by other threads (_ref_count >= 3).\n+\/\/ 2: Dead: The object is visible to only a single thread and may be\n+\/\/    safely reclaimed (_ref_count == 1).\n+\/\/ 3: Reclaimed: The object's memory has been reclaimed ((_ref_count & 0x1) == 0).\n+\/\/ To maintain these constraints, live objects should have ((_ref_count & 0x1) == 1),\n+\/\/ which requires that we increment the reference counts by 2 starting at _ref_count = 3.\n+\/\/\n+\/\/ When such an object is on a free list, we reuse the same field for linking\n+\/\/ together those free objects.\n+class G1CardSetContainer {\n+private:\n+  union {\n+    G1CardSetContainer* _next;\n+    uintptr_t _ref_count;\n+  };\n+\n+public:\n+  G1CardSetContainer() : _ref_count(3) { }\n+\n+  uintptr_t refcount() const { return Atomic::load_acquire(&_ref_count); }\n+\n+  bool try_increment_refcount();\n+\n+  \/\/ Decrement refcount potentially while racing increment, so we need\n+  \/\/ to check the value after attempting to decrement.\n+  uintptr_t decrement_refcount();\n+\n+  G1CardSetContainer* next() {\n+    return _next;\n+  }\n+\n+  G1CardSetContainer** next_addr() {\n+    return &_next;\n+  }\n+\n+  void set_next(G1CardSetContainer* next) {\n+    _next = next;\n+  }\n+};\n+\n+class G1CardSetArray : public G1CardSetContainer {\n+public:\n+  typedef uint16_t EntryDataType;\n+  typedef uint EntryCountType;\n+  using CardSetPtr = G1CardSet::CardSetPtr;\n+private:\n+  EntryCountType _size;\n+  EntryCountType volatile _num_entries;\n+  EntryDataType _data[2];\n+\n+  static const EntryCountType LockBitMask = (EntryCountType)1 << (sizeof(EntryCountType) * BitsPerByte - 1);\n+  static const EntryCountType EntryMask = LockBitMask - 1;\n+\n+  class G1CardSetArrayLocker : public StackObj {\n+    EntryCountType volatile* _value;\n+    EntryCountType volatile _original_value;\n+    bool _success;\n+  public:\n+    G1CardSetArrayLocker(EntryCountType volatile* value);\n+\n+    EntryCountType num_entries() const { return _original_value; }\n+    void inc_num_entries() { _success = true; }\n+\n+    ~G1CardSetArrayLocker() {\n+      assert(((_original_value + _success) & EntryMask) == (EntryCountType)(_original_value + _success), \"precondition!\" );\n+\n+      Atomic::release_store(_value, (EntryCountType)(_original_value + _success));\n+    }\n+  };\n+\n+  template<typename Derived>\n+  static size_t header_size_in_bytes_internal() {\n+    return offset_of(Derived, _data);\n+  }\n+\n+public:\n+  G1CardSetArray(uint const card_in_region, EntryCountType num_elems);\n+\n+  G1AddCardResult add(uint card_idx);\n+\n+  bool contains(uint card_idx);\n+\n+  template <class CardVisitor>\n+  void iterate(CardVisitor& found);\n+\n+  size_t num_entries() const { return _num_entries & EntryMask; }\n+  size_t max_entries() const { return _size; }\n+\n+  static size_t header_size_in_bytes() { return header_size_in_bytes_internal<G1CardSetArray>(); }\n+\n+  static size_t size_in_bytes(size_t num_cards) {\n+    return header_size_in_bytes() + sizeof(EntryDataType) * num_cards;\n+  }\n+};\n+\n+class G1CardSetBitMap : public G1CardSetContainer {\n+  size_t _num_bits_set;\n+  BitMap::bm_word_t _bits[1];\n+\n+  using CardSetPtr = G1CardSet::CardSetPtr;\n+\n+  template<typename Derived>\n+  static size_t header_size_in_bytes_internal() {\n+    return offset_of(Derived, _bits);\n+  }\n+\n+public:\n+  G1CardSetBitMap(uint const card_in_region, uint const size_in_bits);\n+\n+  G1AddCardResult add(uint card_idx, size_t threshold, size_t size_in_bits);\n+\n+  bool contains(uint card_idx, size_t size_in_bits) {\n+    BitMapView bm(_bits, size_in_bits);\n+    return bm.at(card_idx);\n+  }\n+\n+  uint num_bits_set() const { return (uint)_num_bits_set; }\n+\n+  template <class CardVisitor>\n+  void iterate(CardVisitor& found, size_t const size_in_bits, uint offset);\n+\n+  uint next(uint const idx, size_t const size_in_bits) {\n+    BitMapView bm(_bits, size_in_bits);\n+    return static_cast<uint>(bm.get_next_one_offset(idx));\n+  }\n+\n+  static size_t header_size_in_bytes() { return header_size_in_bytes_internal<G1CardSetBitMap>(); }\n+\n+  static size_t size_in_bytes(size_t size_in_bits) { return header_size_in_bytes() + BitMap::calc_size_in_words(size_in_bits) * BytesPerWord; }\n+};\n+\n+class G1CardSetHowl : public G1CardSetContainer {\n+public:\n+  typedef uint EntryCountType;\n+  using CardSetPtr = G1CardSet::CardSetPtr;\n+  EntryCountType volatile _num_entries;\n+private:\n+  CardSetPtr _buckets[2];\n+  \/\/ Do not add class member variables beyond this point\n+\n+  template<typename Derived>\n+  static size_t header_size_in_bytes_internal() {\n+    return offset_of(Derived, _buckets);\n+  }\n+\n+  \/\/ Iterates over the given CardSetPtr with at index in this Howl card set,\n+  \/\/ applying a CardOrRangeVisitor on it.\n+  template <class CardOrRangeVisitor>\n+  void iterate_cardset(CardSetPtr const card_set, uint index, CardOrRangeVisitor& found, G1CardSetConfiguration* config);\n+\n+public:\n+  G1CardSetHowl(EntryCountType card_in_region, G1CardSetConfiguration* config);\n+\n+  CardSetPtr* get_card_set_addr(EntryCountType index) {\n+    return &_buckets[index];\n+  }\n+\n+  bool contains(uint card_idx, G1CardSetConfiguration* config);\n+\n+  \/\/ Iterates over all CardSetPtrs in this Howl card set, applying a CardOrRangeVisitor\n+  \/\/ on it.\n+  template <class CardOrRangeVisitor>\n+  void iterate(CardOrRangeVisitor& found, G1CardSetConfiguration* config);\n+\n+  \/\/ Iterates over all CardSetPtrs in this Howl card set. Calls\n+  \/\/\n+  \/\/   void operator ()(CardSetPtr* card_set_addr);\n+  \/\/\n+  \/\/ on all of them.\n+  template <class CardSetPtrVisitor>\n+  void iterate(CardSetPtrVisitor& found, uint num_card_sets);\n+\n+  static EntryCountType num_buckets(size_t size_in_bits, size_t num_cards_in_array, size_t max_buckets);\n+\n+  static EntryCountType bitmap_size(size_t size_in_bits, uint num_buckets) {\n+    EntryCountType num_cards = (EntryCountType)size_in_bits \/ num_buckets;\n+    return round_up_power_of_2(num_cards);\n+  }\n+\n+  static size_t header_size_in_bytes() { return header_size_in_bytes_internal<G1CardSetHowl>(); }\n+\n+  static size_t size_in_bytes(size_t num_arrays) {\n+    return header_size_in_bytes() + sizeof(CardSetPtr) * num_arrays;\n+  }\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSETCONTAINERS_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetContainers.hpp","additions":290,"deletions":0,"binary":false,"changes":290,"status":"added"},{"patch":"@@ -0,0 +1,339 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSETCONTAINERS_INLINE_HPP\n+#define SHARE_GC_G1_G1CARDSETCONTAINERS_INLINE_HPP\n+\n+#include \"gc\/g1\/g1CardSetContainers.hpp\"\n+#include \"gc\/g1\/g1GCPhaseTimes.hpp\"\n+\n+inline G1CardSetInlinePtr::CardSetPtr G1CardSetInlinePtr::merge(CardSetPtr orig_value, uint card_in_region, uint idx, uint bits_per_card) {\n+  assert((idx & (SizeFieldMask >> SizeFieldPos)) == idx, \"Index %u too large to fit into size field\", idx);\n+  assert(card_in_region < ((uint)1 << bits_per_card), \"Card %u too large to fit into card value field\", card_in_region);\n+\n+  uint8_t card_pos = card_pos_for(idx, bits_per_card);\n+  assert(card_pos + bits_per_card < BitsInValue, \"Putting card at pos %u with %u bits would extend beyond pointer\", card_pos, bits_per_card);\n+\n+  \/\/ Check that we do not touch any fields we do not own.\n+  uintptr_t mask = ((((uintptr_t)1 << bits_per_card) - 1) << card_pos);\n+  assert(((uintptr_t)orig_value & mask) == 0, \"The bits in the new range should be empty; orig_value \" PTR_FORMAT \" mask \" PTR_FORMAT, p2i(orig_value), mask);\n+\n+  uintptr_t value = ((uintptr_t)(idx + 1) << SizeFieldPos) | ((uintptr_t)card_in_region << card_pos);\n+  uintptr_t res = (((uintptr_t)orig_value & ~SizeFieldMask) | value);\n+  return (CardSetPtr)res;\n+}\n+\n+inline G1AddCardResult G1CardSetInlinePtr::add(uint card_idx, uint bits_per_card, uint max_cards_in_inline_ptr) {\n+  assert(_value_addr != nullptr, \"No value address available, cannot add to set.\");\n+\n+  while (true) {\n+    uint num_elems = num_cards_in(_value);\n+    \/\/ Check if the card is already stored in the pointer.\n+    if (contains(card_idx, bits_per_card)) {\n+      return Found;\n+    }\n+    \/\/ Check if there is actually enough space.\n+    if (num_elems >= max_cards_in_inline_ptr) {\n+      return Overflow;\n+    }\n+    CardSetPtr new_value = merge(_value, card_idx, num_elems, bits_per_card);\n+    CardSetPtr old_value = Atomic::cmpxchg(_value_addr, _value, new_value, memory_order_relaxed);\n+    if (_value == old_value) {\n+      return Added;\n+    }\n+    \/\/ Update values and retry.\n+    _value = old_value;\n+    \/\/ The value of the pointer may have changed to something different than\n+    \/\/ an inline card set. Exit then instead of overwriting.\n+    if (G1CardSet::card_set_type(_value) != G1CardSet::CardSetInlinePtr) {\n+      return Overflow;\n+    }\n+  }\n+}\n+\n+inline bool G1CardSetInlinePtr::contains(uint card_idx, uint bits_per_card) {\n+  uint num_elems = num_cards_in(_value);\n+  uintptr_t const card_mask = (1 << bits_per_card) - 1;\n+\n+  uintptr_t value = ((uintptr_t)_value) >> card_pos_for(0, bits_per_card);\n+  \/\/ Check if the card is already stored in the pointer.\n+  for (uint cur_idx = 0; cur_idx < num_elems; cur_idx++) {\n+    if ((value & card_mask) == card_idx) {\n+      return true;\n+    }\n+    value >>= bits_per_card;\n+  }\n+  return false;\n+}\n+\n+template <class CardVisitor>\n+inline void G1CardSetInlinePtr::iterate(CardVisitor& found, uint bits_per_card) {\n+  uint const num_elems = num_cards_in(_value);\n+  uintptr_t const card_mask = (1 << bits_per_card) - 1;\n+\n+  uintptr_t value = ((uintptr_t)_value) >> card_pos_for(0, bits_per_card);\n+  for (uint cur_idx = 0; cur_idx < num_elems; cur_idx++) {\n+    found(value & card_mask);\n+    value >>= bits_per_card;\n+  }\n+}\n+\n+inline bool G1CardSetContainer::try_increment_refcount() {\n+  uintptr_t old_value = refcount();\n+  while (true) {\n+    if (old_value < 3 || (old_value & 0x1) == 0) {  \/\/ reclaimed,  reference counts are odd numbers starting at 3\n+      return false; \/\/ dead, can't revive.\n+    }\n+\n+    uintptr_t new_value = old_value + 2;\n+    uintptr_t ref_count = Atomic::cmpxchg(&_ref_count, old_value, new_value);\n+    if (ref_count == old_value) {\n+      return true;\n+    }\n+    old_value = ref_count;\n+  }\n+}\n+\n+inline uintptr_t G1CardSetContainer::decrement_refcount() {\n+  uintptr_t old_value = refcount();\n+  assert((old_value & 0x1) != 0 && old_value >= 3, \"precondition\");\n+  return Atomic::sub(&_ref_count, 2u);\n+}\n+\n+inline G1CardSetArray::G1CardSetArray(uint card_in_region, EntryCountType num_elems) :\n+  G1CardSetContainer(),\n+  _size(num_elems),\n+  _num_entries(1) {\n+  assert(_size > 0, \"CardSetArray of size 0 not supported.\");\n+  assert(_size < LockBitMask, \"Only support CardSetArray of size %u or smaller.\", LockBitMask - 1);\n+  _data[0] = card_in_region;\n+}\n+\n+inline G1CardSetArray::G1CardSetArrayLocker::G1CardSetArrayLocker(EntryCountType volatile* value) :\n+  _value(value),\n+  _success(false) {\n+  SpinYield s;\n+  EntryCountType original_value = (*_value) & EntryMask;\n+  while (true) {\n+    EntryCountType old_value = Atomic::cmpxchg(_value,\n+                                               original_value,\n+                                               (EntryCountType)(original_value | LockBitMask));\n+    if (old_value == original_value) {\n+      \/\/ Succeeded locking the array.\n+      _original_value = original_value;\n+      break;\n+    }\n+    \/\/ Failed. Retry (with the lock bit stripped again).\n+    original_value = old_value & EntryMask;\n+    s.wait();\n+  }\n+}\n+\n+inline G1AddCardResult G1CardSetArray::add(uint card_idx) {\n+  assert(card_idx < (1u << (sizeof(_data[0]) * BitsPerByte)),\n+         \"Card index %u does not fit card element.\", card_idx);\n+  EntryCountType num_entries = Atomic::load_acquire(&_num_entries) & EntryMask;\n+  EntryCountType idx = 0;\n+  for (; idx < num_entries; idx++) {\n+    if (_data[idx] == card_idx) {\n+      return Found;\n+    }\n+  }\n+\n+  \/\/ Since we did not find the card, lock.\n+  G1CardSetArrayLocker x(&_num_entries);\n+\n+  \/\/ Reload number of entries from the G1CardSetArrayLocker as it might have changed.\n+  \/\/ It already read the actual value with the necessary synchronization.\n+  num_entries = x.num_entries();\n+  \/\/ Look if the elements added while waiting for the lock are the same as our card.\n+  for (; idx < num_entries; idx++) {\n+    if (_data[idx] == card_idx) {\n+      return Found;\n+    }\n+  }\n+\n+  \/\/ Check if there is space left.\n+  if (num_entries == _size) {\n+    return Overflow;\n+  }\n+\n+  _data[num_entries] = card_idx;\n+\n+  x.inc_num_entries();\n+\n+  return Added;\n+}\n+\n+inline bool G1CardSetArray::contains(uint card_idx) {\n+  EntryCountType num_entries = Atomic::load_acquire(&_num_entries) & EntryMask;\n+\n+  for (EntryCountType idx = 0; idx < num_entries; idx++) {\n+    if (_data[idx] == card_idx) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+template <class CardVisitor>\n+void G1CardSetArray::iterate(CardVisitor& found) {\n+  EntryCountType num_entries = Atomic::load_acquire(&_num_entries) & EntryMask;\n+  for (EntryCountType idx = 0; idx < num_entries; idx++) {\n+    found(_data[idx]);\n+  }\n+}\n+\n+inline G1CardSetBitMap::G1CardSetBitMap(uint card_in_region, uint size_in_bits) :\n+  G1CardSetContainer(), _num_bits_set(1) {\n+  assert(size_in_bits % (sizeof(_bits[0]) * BitsPerByte) == 0,\n+         \"Size %u should be aligned to bitmap word size.\", size_in_bits);\n+  BitMapView bm(_bits, size_in_bits);\n+  bm.clear();\n+  bm.set_bit(card_in_region);\n+}\n+\n+inline G1AddCardResult G1CardSetBitMap::add(uint card_idx, size_t threshold, size_t size_in_bits) {\n+  BitMapView bm(_bits, size_in_bits);\n+  if (_num_bits_set >= threshold) {\n+    return bm.at(card_idx) ? Found : Overflow;\n+  }\n+  if (bm.par_set_bit(card_idx)) {\n+    Atomic::inc(&_num_bits_set, memory_order_relaxed);\n+    return Added;\n+  }\n+  return Found;\n+}\n+\n+template <class CardVisitor>\n+inline void G1CardSetBitMap::iterate(CardVisitor& found, size_t size_in_bits, uint offset) {\n+  BitMapView bm(_bits, size_in_bits);\n+  BitMap::idx_t idx = bm.get_next_one_offset(0);\n+  while (idx != size_in_bits) {\n+    found((offset | (uint)idx));\n+    idx = bm.get_next_one_offset(idx + 1);\n+  }\n+}\n+\n+inline G1CardSetHowl::G1CardSetHowl(EntryCountType card_in_region, G1CardSetConfiguration* config) :\n+  G1CardSetContainer(),\n+  _num_entries((config->num_cards_in_array() + 1)) \/* Card Transfer will not increment _num_entries *\/ {\n+  EntryCountType num_buckets = config->num_buckets_in_howl();\n+  EntryCountType bucket = config->howl_bucket_index(card_in_region);\n+  for (uint i = 0; i < num_buckets; ++i) {\n+    _buckets[i] = G1CardSetInlinePtr();\n+    if (i == bucket) {\n+      G1CardSetInlinePtr value(&_buckets[i], _buckets[i]);\n+      value.add(card_in_region, config->inline_ptr_bits_per_card(), config->num_cards_in_inline_ptr());\n+    }\n+  }\n+}\n+\n+inline bool G1CardSetHowl::contains(uint card_idx, G1CardSetConfiguration* config) {\n+  EntryCountType bucket = config->howl_bucket_index(card_idx);\n+  CardSetPtr* array_entry = get_card_set_addr(bucket);\n+  CardSetPtr card_set = Atomic::load_acquire(array_entry);\n+\n+  switch (G1CardSet::card_set_type(card_set)) {\n+    case G1CardSet::CardSetArrayOfCards : {\n+      return G1CardSet::card_set_ptr<G1CardSetArray>(card_set)->contains(card_idx);\n+    }\n+    case G1CardSet::CardSetBitMap: {\n+      uint card_offset = config->howl_bitmap_offset(card_idx);\n+      return G1CardSet::card_set_ptr<G1CardSetBitMap>(card_set)->contains(card_offset, config->num_cards_in_howl_bitmap());\n+    }\n+    case G1CardSet::CardSetInlinePtr: {\n+      G1CardSetInlinePtr ptr(card_set);\n+      return ptr.contains(card_idx, config->inline_ptr_bits_per_card());\n+    }\n+    case G1CardSet::CardSetHowl: {\/\/ Fullcard set entry\n+      assert(card_set == G1CardSet::FullCardSet, \"Must be\");\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+template <class CardOrRangeVisitor>\n+inline void G1CardSetHowl::iterate(CardOrRangeVisitor& found, G1CardSetConfiguration* config) {\n+  for (uint i = 0; i < config->num_buckets_in_howl(); ++i) {\n+    iterate_cardset(_buckets[i], i, found, config);\n+  }\n+}\n+\n+template <class CardSetPtrVisitor>\n+inline void G1CardSetHowl::iterate(CardSetPtrVisitor& found, uint num_card_sets) {\n+  for (uint i = 0; i < num_card_sets; ++i) {\n+    found(&_buckets[i]);\n+  }\n+}\n+\n+template <class CardOrRangeVisitor>\n+inline void G1CardSetHowl::iterate_cardset(CardSetPtr const card_set, uint index, CardOrRangeVisitor& found, G1CardSetConfiguration* config) {\n+  switch (G1CardSet::card_set_type(card_set)) {\n+    case G1CardSet::CardSetInlinePtr: {\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSHowlInline)) {\n+        G1CardSetInlinePtr ptr(card_set);\n+        ptr.iterate(found, config->inline_ptr_bits_per_card());\n+      }\n+      return;\n+    }\n+    case G1CardSet::CardSetArrayOfCards : {\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSHowlArrayOfCards)) {\n+        G1CardSet::card_set_ptr<G1CardSetArray>(card_set)->iterate(found);\n+      }\n+      return;\n+    }\n+    case G1CardSet::CardSetBitMap: {\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSHowlBitmap)) {\n+        uint offset = index << config->log2_num_cards_in_howl_bitmap();\n+        G1CardSet::card_set_ptr<G1CardSetBitMap>(card_set)->iterate(found, config->num_cards_in_howl_bitmap(), offset);\n+      }\n+      return;\n+    }\n+    case G1CardSet::CardSetHowl: { \/\/ actually FullCardSet\n+      if (found.start_iterate(G1GCPhaseTimes::MergeRSHowlFull)) {\n+        assert(card_set == G1CardSet::FullCardSet, \"Must be\");\n+        uint offset = index << config->log2_num_cards_in_howl_bitmap();\n+        for (uint i = 0; i < config->max_cards_in_region(); i++) {\n+          found((offset | (uint)i));\n+        }\n+      }\n+      return;\n+    }\n+  }\n+}\n+\n+inline G1CardSetHowl::EntryCountType G1CardSetHowl::num_buckets(size_t size_in_bits, size_t num_cards_in_array, size_t max_num_buckets) {\n+  size_t size_bitmap_bytes = BitMap::calc_size_in_words(size_in_bits) * BytesPerWord;\n+  \/\/ Ensure that in the worst case arrays consume half the memory size\n+  \/\/ of storing the entire bitmap\n+  size_t max_size_arrays_bytes = size_bitmap_bytes \/ 2;\n+  size_t size_array_bytes = num_cards_in_array * sizeof(G1CardSetArray::EntryDataType);\n+  size_t num_arrays = max_size_arrays_bytes \/ size_array_bytes;\n+  num_arrays = MAX2((size_t)1, MIN2(num_arrays, max_num_buckets));\n+  return (EntryCountType)num_arrays;\n+}\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSETCONTAINERS_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetContainers.inline.hpp","additions":339,"deletions":0,"binary":false,"changes":339,"status":"added"},{"patch":"@@ -0,0 +1,203 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1CardSetFreeMemoryTask.hpp\"\n+#include \"gc\/g1\/g1CardSetMemory.inline.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1_globals.hpp\"\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+#include \"gc\/shared\/suspendibleThreadSet.hpp\"\n+#include \"heapRegionRemSet.hpp\"\n+#include \"ci\/ciUtilities.hpp\"\n+\n+constexpr const char* G1CardSetFreeMemoryTask::_state_names[];\n+\n+const char* G1CardSetFreeMemoryTask::get_state_name(State value) const {\n+  return _state_names[static_cast<std::underlying_type_t<State>>(value)];\n+}\n+\n+bool G1CardSetFreeMemoryTask::deadline_exceeded(jlong deadline) {\n+  return os::elapsed_counter() >= deadline;\n+}\n+\n+static size_t keep_size(size_t free, size_t used, double percent) {\n+  size_t to_keep = used * percent;\n+  return MIN2(free, to_keep);\n+}\n+\n+bool G1CardSetFreeMemoryTask::calculate_return_infos(jlong deadline) {\n+  \/\/ Ignore the deadline in this step as it is very short.\n+\n+  G1CardSetMemoryStats used = _total_used;\n+  G1CardSetMemoryStats free = G1CardSetFreePool::free_list_sizes();\n+\n+  _return_info = new G1ReturnMemoryProcessorSet(used.num_pools());\n+  for (uint i = 0; i < used.num_pools(); i++) {\n+    size_t return_to_vm_size = keep_size(free._num_mem_sizes[i],\n+                                         used._num_mem_sizes[i],\n+                                         G1RemSetFreeMemoryKeepExcessRatio);\n+    log_trace(gc, task)(\"Card Set Free Memory: Type %s: Free: %zu (%zu) \"\n+                        \"Used: %zu Keep: %zu\",\n+                        G1CardSetConfiguration::mem_object_type_name_str(i),\n+                        free._num_mem_sizes[i], free._num_buffers[i],\n+                        used._num_mem_sizes[i], return_to_vm_size);\n+\n+    _return_info->append(new G1ReturnMemoryProcessor(return_to_vm_size));\n+  }\n+\n+  G1CardSetFreePool::update_unlink_processors(_return_info);\n+  return false;\n+}\n+\n+bool G1CardSetFreeMemoryTask::return_memory_to_vm(jlong deadline) {\n+  for (int i = 0; i < _return_info->length(); i++) {\n+    G1ReturnMemoryProcessor* info = _return_info->at(i);\n+    if (!info->finished_return_to_vm()) {\n+      if (info->return_to_vm(deadline)) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n+bool G1CardSetFreeMemoryTask::return_memory_to_os(jlong deadline) {\n+  for (int i = 0; i < _return_info->length(); i++) {\n+    G1ReturnMemoryProcessor* info = _return_info->at(i);\n+    if (!info->finished_return_to_os()) {\n+      if (info->return_to_os(deadline)) {\n+        return true;\n+      }\n+    }\n+  }\n+  return false;\n+}\n+\n+bool G1CardSetFreeMemoryTask::cleanup_return_infos() {\n+  for (int i = 0; i < _return_info->length(); i++) {\n+     G1ReturnMemoryProcessor* info = _return_info->at(i);\n+     delete info;\n+  }\n+  delete _return_info;\n+\n+  _return_info = nullptr;\n+  return false;\n+}\n+\n+bool G1CardSetFreeMemoryTask::free_excess_card_set_memory() {\n+  jlong start = os::elapsed_counter();\n+  jlong end = start +\n+              (os::elapsed_frequency() \/ 1000) * G1RemSetFreeMemoryStepDurationMillis;\n+\n+  log_trace(gc, task)(\"Card Set Free Memory: Step start %1.3f end %1.3f\",\n+                      TimeHelper::counter_to_millis(start), TimeHelper::counter_to_millis(end));\n+\n+  State next_state;\n+\n+  do {\n+    switch (_state) {\n+      case State::CalculateUsed: {\n+        if (calculate_return_infos(end)) {\n+          next_state = _state;\n+          return true;\n+        }\n+        next_state = State::ReturnToVM;\n+        break;\n+      }\n+      case State::ReturnToVM: {\n+        if (return_memory_to_vm(end)) {\n+          next_state = _state;\n+          return true;\n+        }\n+        next_state = State::ReturnToOS;\n+        break;\n+      }\n+      case State::ReturnToOS: {\n+        if (return_memory_to_os(end)) {\n+          next_state = _state;\n+          return true;\n+        }\n+        next_state = State::Cleanup;\n+        break;\n+      }\n+      case State::Cleanup: {\n+        cleanup_return_infos();\n+        next_state = State::Inactive;\n+        break;\n+      }\n+      default:\n+        log_error(gc, task)(\"Should not try to free excess card set memory in %s state\", get_state_name(_state));\n+        ShouldNotReachHere();\n+        break;\n+    }\n+\n+    set_state(next_state);\n+  } while (_state != State::Inactive && !deadline_exceeded(end));\n+\n+  log_trace(gc, task)(\"Card Set Free Memory: Step took %1.3fms, done %s\",\n+                      TimeHelper::counter_to_millis(os::elapsed_counter() - start),\n+                      bool_to_str(_state == State::CalculateUsed));\n+\n+  return is_active();\n+}\n+\n+void G1CardSetFreeMemoryTask::set_state(State new_state) {\n+  log_trace(gc, task)(\"Card Set Free Memory: State change from %s to %s\",\n+                      get_state_name(_state),\n+                      get_state_name(new_state));\n+  _state = new_state;\n+}\n+\n+bool G1CardSetFreeMemoryTask::is_active() const {\n+  return _state != State::Inactive;\n+}\n+\n+jlong G1CardSetFreeMemoryTask::reschedule_delay_ms() const {\n+  return G1RemSetFreeMemoryRescheduleDelayMillis;\n+}\n+\n+G1CardSetFreeMemoryTask::G1CardSetFreeMemoryTask(const char* name) :\n+  G1ServiceTask(name), _state(State::CalculateUsed), _return_info(nullptr) { }\n+\n+void G1CardSetFreeMemoryTask::execute() {\n+  SuspendibleThreadSetJoiner sts;\n+\n+  if (free_excess_card_set_memory()) {\n+    schedule(reschedule_delay_ms());\n+  }\n+}\n+\n+void G1CardSetFreeMemoryTask::notify_new_stats(G1CardSetMemoryStats* young_gen_stats,\n+                                               G1CardSetMemoryStats* collection_set_candidate_stats) {\n+  assert_at_safepoint_on_vm_thread();\n+\n+  _total_used = *young_gen_stats;\n+  _total_used.add(*collection_set_candidate_stats);\n+\n+  if (!is_active()) {\n+    set_state(State::CalculateUsed);\n+    G1CollectedHeap::heap()->service_thread()->schedule_task(this, 0);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetFreeMemoryTask.cpp","additions":203,"deletions":0,"binary":false,"changes":203,"status":"added"},{"patch":"@@ -0,0 +1,97 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSETFREEMEMORYTASK_HPP\n+#define SHARE_GC_G1_G1CARDSETFREEMEMORYTASK_HPP\n+\n+#include \"gc\/g1\/g1ServiceThread.hpp\"\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"utilities\/growableArray.hpp\"\n+#include \"utilities\/ticks.hpp\"\n+\n+class G1CardSetBuffer;\n+\n+\/\/ Task handling deallocation of free card set memory.\n+class G1CardSetFreeMemoryTask : public G1ServiceTask {\n+\n+  enum class State : uint {\n+    Inactive,\n+    CalculateUsed,\n+    ReturnToVM,\n+    ReturnToOS,\n+    Cleanup\n+  };\n+\n+  static constexpr const char* _state_names[] = { \"Invalid\",\n+                                                  \"CalculateUsed\",\n+                                                  \"ReturnToVM\",\n+                                                  \"ReturnToOS\",\n+                                                  \"Cleanup\" };\n+\n+  const char* get_state_name(State value) const;\n+\n+  State _state;\n+\n+  \/\/ Current total card set memory usage.\n+  G1CardSetMemoryStats _total_used;\n+\n+  typedef G1CardSetFreePool::G1ReturnMemoryProcessor G1ReturnMemoryProcessor;\n+  typedef G1CardSetFreePool::G1ReturnMemoryProcessorSet G1ReturnMemoryProcessorSet;\n+\n+  G1ReturnMemoryProcessorSet* _return_info;\n+\n+  \/\/ Returns whether the given deadline has passed.\n+  bool deadline_exceeded(jlong deadline);\n+\n+  \/\/ Methods for the tasks to be done. They all return true if that step has\n+  \/\/ completed.\n+  bool calculate_return_infos(jlong deadline);\n+  bool return_memory_to_vm(jlong deadline);\n+  bool return_memory_to_os(jlong deadline);\n+  bool cleanup_return_infos();\n+\n+  \/\/ Free excess card set memory, main method. Returns true if there is more work\n+  \/\/ to do.\n+  bool free_excess_card_set_memory();\n+\n+  void set_state(State new_state);\n+  \/\/ Returns whether we are currently processing a recent request.\n+  bool is_active() const;\n+\n+  \/\/ The delay used to reschedule this task if not all work has been completed.\n+  jlong reschedule_delay_ms() const;\n+\n+public:\n+  explicit G1CardSetFreeMemoryTask(const char* name);\n+\n+  void execute() override;\n+\n+  \/\/ Notify the task of new used remembered set memory statistics for the young\n+  \/\/ generation and the collection set candidate sets.\n+  void notify_new_stats(G1CardSetMemoryStats* young_gen_stats,\n+                        G1CardSetMemoryStats* collection_set_candidate_stats);\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSETFREEMEMORYTASK_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetFreeMemoryTask.hpp","additions":97,"deletions":0,"binary":false,"changes":97,"status":"added"},{"patch":"@@ -0,0 +1,478 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1CardSetMemory.inline.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/formatBuffer.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+\n+G1CardSetBuffer::G1CardSetBuffer(uint elem_size, uint num_instances, G1CardSetBuffer* next) :\n+    _elem_size(elem_size), _num_elems(num_instances), _next(next), _next_allocate(0) {\n+\n+  _buffer = NEW_C_HEAP_ARRAY(char, (size_t)_num_elems * elem_size, mtGCCardSet);\n+}\n+\n+G1CardSetBuffer::~G1CardSetBuffer() {\n+  FREE_C_HEAP_ARRAY(mtGCCardSet, _buffer);\n+}\n+\n+void* G1CardSetBuffer::get_new_buffer_elem() {\n+  if (_next_allocate >= _num_elems) {\n+    return nullptr;\n+  }\n+  uint result = Atomic::fetch_and_add(&_next_allocate, 1u, memory_order_relaxed);\n+  if (result >= _num_elems) {\n+    return nullptr;\n+  }\n+  void* r = _buffer + (uint)result * _elem_size;\n+  return r;\n+}\n+\n+void G1CardSetBufferList::bulk_add(G1CardSetBuffer& first, G1CardSetBuffer& last, size_t num, size_t mem_size) {\n+  _list.prepend(first, last);\n+  Atomic::add(&_num_buffers, num, memory_order_relaxed);\n+  Atomic::add(&_mem_size, mem_size, memory_order_relaxed);\n+}\n+\n+void G1CardSetBufferList::print_on(outputStream* out, const char* prefix) {\n+  out->print_cr(\"%s: buffers %zu size %zu\", prefix, Atomic::load(&_num_buffers), Atomic::load(&_mem_size));\n+}\n+\n+G1CardSetBuffer* G1CardSetBufferList::get() {\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+\n+  G1CardSetBuffer* result = _list.pop();\n+  if (result != nullptr) {\n+    Atomic::dec(&_num_buffers, memory_order_relaxed);\n+    Atomic::sub(&_mem_size, result->mem_size(), memory_order_relaxed);\n+  }\n+  return result;\n+}\n+\n+G1CardSetBuffer* G1CardSetBufferList::get_all(size_t& num_buffers, size_t& mem_size) {\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+\n+  G1CardSetBuffer* result = _list.pop_all();\n+  num_buffers = Atomic::load(&_num_buffers);\n+  mem_size = Atomic::load(&_mem_size);\n+\n+  if (result != nullptr) {\n+    Atomic::sub(&_num_buffers, num_buffers, memory_order_relaxed);\n+    Atomic::sub(&_mem_size, mem_size, memory_order_relaxed);\n+  }\n+  return result;\n+}\n+\n+void G1CardSetBufferList::free_all() {\n+  size_t num_freed = 0;\n+  size_t mem_size_freed = 0;\n+  G1CardSetBuffer* cur;\n+\n+  while ((cur = _list.pop()) != nullptr) {\n+    mem_size_freed += cur->mem_size();\n+    num_freed++;\n+    delete cur;\n+  }\n+\n+  Atomic::sub(&_num_buffers, num_freed, memory_order_relaxed);\n+  Atomic::sub(&_mem_size, mem_size_freed, memory_order_relaxed);\n+}\n+\n+template <class Elem>\n+G1CardSetAllocator<Elem>::G1CardSetAllocator(const char* name,\n+                                             const G1CardSetAllocOptions& buffer_options,\n+                                             G1CardSetBufferList* free_buffer_list) :\n+  _alloc_options(buffer_options),\n+  _first(nullptr),\n+  _last(nullptr),\n+  _num_buffers(0),\n+  _mem_size(0),\n+  _free_buffer_list(free_buffer_list),\n+  _transfer_lock(false),\n+  _free_nodes_list(),\n+  _pending_nodes_list(),\n+  _num_pending_nodes(0),\n+  _num_free_nodes(0),\n+  _num_allocated_nodes(0),\n+  _num_available_nodes(0)\n+{\n+  assert(elem_size() >= sizeof(G1CardSetContainer), \"Element instance size %u for allocator %s too small\",\n+         elem_size(), name);\n+  assert(_free_buffer_list != nullptr, \"precondition!\");\n+}\n+\n+template <class Elem>\n+bool G1CardSetAllocator<Elem>::try_transfer_pending() {\n+  \/\/ Attempt to claim the lock.\n+  if (Atomic::load_acquire(&_transfer_lock) || \/\/ Skip CAS if likely to fail.\n+      Atomic::cmpxchg(&_transfer_lock, false, true)) {\n+    return false;\n+  }\n+  \/\/ Have the lock; perform the transfer.\n+\n+  \/\/ Claim all the pending nodes.\n+  G1CardSetContainer* first = _pending_nodes_list.pop_all();\n+\n+  if (first != nullptr) {\n+    \/\/ Prepare to add the claimed nodes, and update _num_pending_nodes.\n+    G1CardSetContainer* last = first;\n+    Atomic::load_acquire(&_num_pending_nodes);\n+\n+    uint count = 1;\n+    for (G1CardSetContainer* next = first->next(); next != nullptr; next = next->next()) {\n+      last = next;\n+      ++count;\n+    }\n+\n+    Atomic::sub(&_num_pending_nodes, count);\n+\n+    \/\/ Wait for any in-progress pops to avoid ABA for them.\n+    GlobalCounter::write_synchronize();\n+    \/\/ Add synchronized nodes to _free_node_list.\n+    \/\/ Update count first so there can be no underflow in allocate().\n+    Atomic::add(&_num_free_nodes, count);\n+    _free_nodes_list.prepend(*first, *last);\n+  }\n+  Atomic::release_store(&_transfer_lock, false);\n+  return true;\n+}\n+\n+template <class Elem>\n+void G1CardSetAllocator<Elem>::free(Elem* elem) {\n+  assert(elem != nullptr, \"precondition\");\n+  assert(elem_size() >= sizeof(G1CardSetContainer), \"size mismatch\");\n+  \/\/ Desired minimum transfer batch size.  There is relatively little\n+  \/\/ importance to the specific number.  It shouldn't be too big, else\n+  \/\/ we're wasting space when the release rate is low.  If the release\n+  \/\/ rate is high, we might accumulate more than this before being\n+  \/\/ able to start a new transfer, but that's okay.  Also note that\n+  \/\/ the allocation rate and the release rate are going to be fairly\n+  \/\/ similar, due to how the buffers are used. - kbarret\n+  uint const trigger_transfer = 10;\n+\n+  uint pending_count = Atomic::add(&_num_pending_nodes, 1u, memory_order_relaxed);\n+\n+  G1CardSetContainer* node =  reinterpret_cast<G1CardSetContainer*>(reinterpret_cast<char*>(elem));\n+\n+  node->set_next(nullptr);\n+  assert(node->next() == nullptr, \"precondition\");\n+\n+  _pending_nodes_list.push(*node);\n+\n+  if (pending_count > trigger_transfer) {\n+    try_transfer_pending();\n+  }\n+}\n+\n+template <class Elem>\n+void G1CardSetAllocator<Elem>::drop_all() {\n+  _free_nodes_list.pop_all();\n+  _pending_nodes_list.pop_all();\n+  G1CardSetBuffer* cur = Atomic::load_acquire(&_first);\n+\n+  if (cur != nullptr) {\n+    assert(_last != nullptr, \"If there is at least one element, there must be a last one.\");\n+\n+    G1CardSetBuffer* first = cur;\n+#ifdef ASSERT\n+    \/\/ Check list consistency.\n+    G1CardSetBuffer* last = cur;\n+    uint num_buffers = 0;\n+    size_t mem_size = 0;\n+    while (cur != nullptr) {\n+      mem_size += cur->mem_size();\n+      num_buffers++;\n+\n+      G1CardSetBuffer* next = cur->next();\n+      last = cur;\n+      cur = next;\n+    }\n+#endif\n+    assert(num_buffers == _num_buffers, \"Buffer count inconsistent %u %u\", num_buffers, _num_buffers);\n+    assert(mem_size == _mem_size, \"Memory size inconsistent\");\n+    assert(last == _last, \"Inconsistent last element\");\n+\n+    _free_buffer_list->bulk_add(*first, *_last, _num_buffers, _mem_size);\n+  }\n+\n+  _first = nullptr;\n+  _last = nullptr;\n+  _num_available_nodes = 0;\n+  _num_allocated_nodes = 0;\n+  _num_pending_nodes = 0;\n+  _num_buffers = 0;\n+  _mem_size = 0;\n+  _num_free_nodes = 0;\n+}\n+\n+template <class Elem>\n+void G1CardSetAllocator<Elem>::print(outputStream* os) {\n+  os->print(\"MA \" PTR_FORMAT \": %u elems pending (allocated %u available %u) used %.3f highest %u buffers %u size %zu \",\n+                p2i(this), _num_pending_nodes, _num_allocated_nodes, _num_available_nodes, percent_of(_num_allocated_nodes - _num_pending_nodes, _num_available_nodes), _first != nullptr ? _first->num_elems() : 0, _num_buffers, mem_size());\n+}\n+\n+G1CardSetMemoryStats::G1CardSetMemoryStats() {\n+  clear();\n+}\n+\n+G1CardSetMemoryStats::G1CardSetMemoryStats(void(*fn)(const void*,uint,size_t&,size_t&), const void* context) {\n+  clear();\n+  for (uint i = 0; i < num_pools(); i++) {\n+    fn(context, i, _num_mem_sizes[i], _num_buffers[i]);\n+  }\n+}\n+\n+void G1CardSetMemoryStats::clear() {\n+  for (uint i = 0; i < num_pools(); i++) {\n+    _num_mem_sizes[i] = 0;\n+    _num_buffers[i] = 0;\n+  }\n+}\n+\n+void G1CardSetFreePool::update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processor) {\n+  uint num_free_lists = _freelist_pool.num_free_lists();\n+\n+  for (uint i = 0; i < num_free_lists; i++) {\n+    unlink_processor->at(i)->visit_free_list(_freelist_pool.free_list(i));\n+  }\n+}\n+\n+void G1CardSetFreePool::G1ReturnMemoryProcessor::visit_free_list(G1CardSetBufferList* source) {\n+  assert(_source == nullptr, \"already visited\");\n+  if (_return_to_vm_size > 0) {\n+    _source = source;\n+  } else {\n+    assert(_source == nullptr, \"must be\");\n+  }\n+  if (source->mem_size() > _return_to_vm_size) {\n+    _first = source->get_all(_num_unlinked, _unlinked_bytes);\n+  } else {\n+    assert(_first == nullptr, \"must be\");\n+  }\n+  \/\/ Above we were racing with other threads getting the contents of the free list,\n+  \/\/ so while we might have been asked to return something to the OS initially,\n+  \/\/ the free list might be empty anyway. In this case just reset internal values\n+  \/\/ used for checking whether there is work available.\n+  if (_first == nullptr) {\n+    _source = nullptr;\n+    _return_to_vm_size = 0;\n+  }\n+}\n+\n+bool G1CardSetFreePool::G1ReturnMemoryProcessor::return_to_vm(jlong deadline) {\n+  assert(!finished_return_to_vm(), \"already returned everything to the VM\");\n+  assert(_first != nullptr, \"must have element to return\");\n+\n+  size_t keep_size = 0;\n+  size_t keep_num = 0;\n+\n+  G1CardSetBuffer* cur = _first;\n+  G1CardSetBuffer* last = nullptr;\n+\n+  while (cur != nullptr && _return_to_vm_size > 0) {\n+    size_t cur_size = cur->mem_size();\n+    _return_to_vm_size -= MIN2(_return_to_vm_size, cur_size);\n+\n+    keep_size += cur_size;\n+    keep_num++;\n+\n+    last = cur;\n+    cur = cur->next();\n+    \/\/ To ensure progress, perform the deadline check here.\n+    if (os::elapsed_counter() > deadline) {\n+      break;\n+    }\n+  }\n+\n+  assert(_first != nullptr, \"must be\");\n+  assert(last != nullptr, \"must be\");\n+\n+  last->set_next(nullptr);\n+\n+  \/\/ Wait for any in-progress pops to avoid ABA for them.\n+  GlobalCounter::write_synchronize();\n+  _source->bulk_add(*_first, *last, keep_num, keep_size);\n+  _first = cur;\n+\n+  log_trace(gc, task)(\"Card Set Free Memory: Returned to VM %zu buffers size %zu\", keep_num, keep_size);\n+\n+  \/\/ _return_to_vm_size may be larger than what is available in the list at the\n+  \/\/ time we actually get the list. I.e. the list and _return_to_vm_size may be\n+  \/\/ inconsistent.\n+  \/\/ So also check if we actually already at the end of the list for the exit\n+  \/\/ condition.\n+  if (_return_to_vm_size == 0 || _first == nullptr) {\n+    _source = nullptr;\n+    _return_to_vm_size = 0;\n+  }\n+  return _source != nullptr;\n+}\n+\n+bool G1CardSetFreePool::G1ReturnMemoryProcessor::return_to_os(jlong deadline) {\n+  assert(finished_return_to_vm(), \"not finished returning to VM\");\n+  assert(!finished_return_to_os(), \"already returned everything to the OS\");\n+\n+  \/\/ Now delete the rest.\n+  size_t num_delete = 0;\n+  size_t mem_size_deleted = 0;\n+\n+  while (_first != nullptr) {\n+    G1CardSetBuffer* next = _first->next();\n+    num_delete++;\n+    mem_size_deleted += _first->mem_size();\n+    delete _first;\n+    _first = next;\n+\n+    \/\/ To ensure progress, perform the deadline check here.\n+    if (os::elapsed_counter() > deadline) {\n+      break;\n+    }\n+  }\n+\n+  log_trace(gc, task)(\"Card Set Free Memory: Return to OS %zu buffers size %zu\", num_delete, mem_size_deleted);\n+\n+  return _first != nullptr;\n+}\n+\n+G1CardSetFreePool G1CardSetFreePool::_freelist_pool(G1CardSetConfiguration::num_mem_object_types());\n+\n+G1CardSetFreePool::G1CardSetFreePool(uint num_free_lists) :\n+  _num_free_lists(num_free_lists) {\n+\n+  _free_lists = NEW_C_HEAP_ARRAY(G1CardSetBufferList, _num_free_lists, mtGC);\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    new (&_free_lists[i]) G1CardSetBufferList();\n+  }\n+}\n+\n+G1CardSetFreePool::~G1CardSetFreePool() {\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    _free_lists[i].~G1CardSetBufferList();\n+  }\n+  FREE_C_HEAP_ARRAY(mtGC, _free_lists);\n+}\n+\n+static void collect_mem_sizes(const void* context, uint i, size_t& mem_size, size_t& num_buffers) {\n+  ((G1CardSetFreePool*)context)->get_size(i, mem_size, num_buffers);\n+}\n+\n+void G1CardSetFreePool::get_size(uint i, size_t& mem_size, size_t& num_buffers) const {\n+  mem_size = _free_lists[i].mem_size();\n+  num_buffers = _free_lists[i].num_buffers();\n+}\n+\n+G1CardSetMemoryStats G1CardSetFreePool::memory_sizes() const {\n+  return G1CardSetMemoryStats(collect_mem_sizes, this);\n+}\n+\n+size_t G1CardSetFreePool::mem_size() const {\n+  size_t result = 0;\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    result += _free_lists[i].mem_size();\n+  }\n+  return result;\n+}\n+\n+void G1CardSetFreePool::print_on(outputStream* out) {\n+  out->print_cr(\"  Free Pool: size %zu\", free_list_pool()->mem_size());\n+  for (uint i = 0; i < _num_free_lists; i++) {\n+    FormatBuffer<> fmt(\"    %s\", G1CardSetConfiguration::mem_object_type_name_str(i));\n+    _free_lists[i].print_on(out, fmt);\n+  }\n+}\n+\n+G1CardSetMemoryManager::G1CardSetMemoryManager(G1CardSetConfiguration* config,\n+                                               G1CardSetFreePool* free_list_pool) : _config(config) {\n+\n+  _allocators = NEW_C_HEAP_ARRAY(G1CardSetAllocator<G1CardSetContainer>,\n+                                 _config->num_mem_object_types(),\n+                                 mtGC);\n+  G1CardSetAllocOptions* alloc_options = _config->mem_object_alloc_options();\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    new (&_allocators[i]) G1CardSetAllocator<G1CardSetContainer>(_config->mem_object_type_name_str(i),\n+                                                                 alloc_options[i],\n+                                                                 free_list_pool->free_list(i));\n+  }\n+  FREE_C_HEAP_ARRAY(size_t, alloc_options);\n+}\n+\n+uint G1CardSetMemoryManager::num_mem_object_types() const {\n+  return _config->num_mem_object_types();\n+}\n+\n+\n+G1CardSetMemoryManager::~G1CardSetMemoryManager() {\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    _allocators[i].~G1CardSetAllocator();\n+  }\n+  FREE_C_HEAP_ARRAY(G1CardSetAllocator<G1CardSetContainer>, _allocators);\n+}\n+\n+void G1CardSetMemoryManager::free(uint type, void* value) {\n+  assert(type < num_mem_object_types(), \"must be\");\n+  _allocators[type].free((G1CardSetContainer*)value);\n+}\n+\n+void G1CardSetMemoryManager::flush() {\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    _allocators[i].drop_all();\n+  }\n+}\n+\n+void G1CardSetMemoryManager::print(outputStream* os) {\n+  os->print_cr(\"MM \" PTR_FORMAT \" size %zu\", p2i(this), sizeof(*this));\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    _allocators[i].print(os);\n+  }\n+}\n+\n+size_t G1CardSetMemoryManager::mem_size() const {\n+  size_t result = 0;\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    result += _allocators[i].mem_size();\n+  }\n+  return sizeof(*this) -\n+    (sizeof(G1CardSetAllocator<G1CardSetContainer>) * num_mem_object_types()) +\n+    result;\n+}\n+\n+size_t G1CardSetMemoryManager::wasted_mem_size() const {\n+  size_t result = 0;\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    result += _allocators[i].wasted_mem_size();\n+  }\n+  return result;\n+}\n+\n+G1CardSetMemoryStats G1CardSetMemoryManager::memory_stats() const {\n+  G1CardSetMemoryStats result;\n+  for (uint i = 0; i < num_mem_object_types(); i++) {\n+    result._num_mem_sizes[i] += _allocators[i].mem_size();\n+    result._num_buffers[i] += _allocators[i].num_buffers();\n+  }\n+  return result;\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.cpp","additions":478,"deletions":0,"binary":false,"changes":478,"status":"added"},{"patch":"@@ -0,0 +1,384 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSETMEMORY_HPP\n+#define SHARE_GC_G1_G1CARDSETMEMORY_HPP\n+\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"utilities\/growableArray.hpp\"\n+#include \"utilities\/lockFreeStack.hpp\"\n+\n+class G1CardSetConfiguration;\n+class outputStream;\n+\n+\/\/ Collects G1CardSetAllocator options\/heuristics. Called by G1CardSetAllocator\n+\/\/ to determine the next size of the allocated G1CardSetBuffer.\n+class G1CardSetAllocOptions {\n+  uint _elem_size;\n+  uint _initial_num_elems;\n+  \/\/ Defines a limit to the number of elements in the buffer\n+  uint _max_num_elems;\n+\n+  uint exponential_expand(uint prev_num_elems) {\n+    return clamp(prev_num_elems * 2, _initial_num_elems, _max_num_elems);\n+  }\n+\n+public:\n+  static const uint BufferAlignment = 8;\n+  static const uint MinimumBufferSize = 8;\n+  static const uint MaximumBufferSize =  UINT_MAX \/ 2;\n+\n+  G1CardSetAllocOptions(uint elem_size, uint initial_num_elems = MinimumBufferSize, uint max_num_elems = MaximumBufferSize) :\n+    _elem_size(align_up(elem_size, BufferAlignment)),\n+    _initial_num_elems(initial_num_elems),\n+    _max_num_elems(max_num_elems) {\n+  }\n+\n+  uint next_num_elems(uint prev_num_elems) {\n+    return exponential_expand(prev_num_elems);\n+  }\n+\n+  uint elem_size () const {return _elem_size;}\n+};\n+\n+\/\/ A single buffer\/arena containing _num_elems blocks of memory of _elem_size.\n+\/\/ G1CardSetBuffers can be linked together using a singly linked list.\n+class G1CardSetBuffer : public CHeapObj<mtGCCardSet> {\n+  uint _elem_size;\n+  uint _num_elems;\n+\n+  G1CardSetBuffer* volatile _next;\n+\n+  char* _buffer;  \/\/ Actual data.\n+\n+  \/\/ Index into the next free block to allocate into. Full if equal (or larger)\n+  \/\/ to _num_elems (can be larger because we atomically increment this value and\n+  \/\/ check only afterwards if the allocation has been successful).\n+  uint volatile _next_allocate;\n+\n+public:\n+  G1CardSetBuffer(uint elem_size, uint num_elems, G1CardSetBuffer* next);\n+  ~G1CardSetBuffer();\n+\n+  G1CardSetBuffer* volatile* next_addr() { return &_next; }\n+\n+  void* get_new_buffer_elem();\n+\n+  uint num_elems() const { return _num_elems; }\n+\n+  G1CardSetBuffer* next() const { return _next; }\n+\n+  void set_next(G1CardSetBuffer* next) {\n+    assert(next != this, \" loop condition\");\n+    _next = next;\n+  }\n+\n+  void reset(G1CardSetBuffer* next) {\n+    _next_allocate = 0;\n+    assert(next != this, \" loop condition\");\n+    set_next(next);\n+    memset((void*)_buffer, 0, (size_t)_num_elems * _elem_size);\n+  }\n+\n+  uint elem_size() const { return _elem_size; }\n+\n+  size_t mem_size() const { return sizeof(*this) + (size_t)_num_elems * _elem_size; }\n+\n+  bool is_full() const { return _next_allocate >= _num_elems; }\n+};\n+\n+\/\/ Set of (free) G1CardSetBuffers. The assumed usage is that allocation\n+\/\/ to it and removal of elements is strictly separate, but every action may be\n+\/\/ performed by multiple threads at the same time.\n+\/\/ Counts and memory usage are current on a best-effort basis if accessed concurrently.\n+class G1CardSetBufferList {\n+  static G1CardSetBuffer* volatile* next_ptr(G1CardSetBuffer& node) {\n+    return node.next_addr();\n+  }\n+  typedef LockFreeStack<G1CardSetBuffer, &next_ptr> NodeStack;\n+\n+  NodeStack _list;\n+\n+  volatile size_t _num_buffers;\n+  volatile size_t _mem_size;\n+\n+public:\n+  G1CardSetBufferList() : _list(), _num_buffers(0), _mem_size(0) { }\n+  ~G1CardSetBufferList() { free_all(); }\n+\n+  void bulk_add(G1CardSetBuffer& first, G1CardSetBuffer& last, size_t num, size_t mem_size);\n+  void add(G1CardSetBuffer& elem) { _list.prepend(elem); }\n+\n+  G1CardSetBuffer* get();\n+  G1CardSetBuffer* get_all(size_t& num_buffers, size_t& mem_size);\n+\n+  \/\/ Give back all memory to the OS.\n+  void free_all();\n+\n+  void print_on(outputStream* out, const char* prefix = \"\");\n+\n+  size_t num_buffers() const { return Atomic::load(&_num_buffers); }\n+  size_t mem_size() const { return Atomic::load(&_mem_size); }\n+};\n+\n+\/\/ Arena-like allocator for (card set) heap memory objects (Elem elements).\n+\/\/\n+\/\/ Actual allocation from the C heap occurs on G1CardSetBuffer basis, i.e. sets\n+\/\/ of elements. The assumed allocation pattern for these G1CardSetBuffer elements\n+\/\/ is assumed to be strictly two-phased:\n+\/\/\n+\/\/ - in the first phase, G1CardSetBuffers are allocated from the C heap (or a free\n+\/\/ list given at initialization time). This allocation may occur in parallel. This\n+\/\/ typically corresponds to a single mutator phase, but may extend over multiple.\n+\/\/\n+\/\/ - in the second phase, G1CardSetBuffers are given back in bulk to the free list.\n+\/\/ This is typically done during a GC pause.\n+\/\/\n+\/\/ Some third party is responsible for giving back memory from the free list to\n+\/\/ the operating system.\n+\/\/\n+\/\/ Allocation and deallocation in the first phase on G1CardSetContainer basis\n+\/\/ may occur by multiple threads at once.\n+\/\/\n+\/\/ Allocation occurs from an internal free list of G1CardSetContainers first,\n+\/\/ only then trying to bump-allocate from the current G1CardSetBuffer. If there is\n+\/\/ none, this class allocates a new G1CardSetBuffer (allocated from the C heap,\n+\/\/ asking the G1CardSetAllocOptions instance about sizes etc) and uses that one.\n+\/\/\n+\/\/ The G1CardSetContainerOnHeaps free list is a linked list of G1CardSetContainers\n+\/\/ within all G1CardSetBuffer instances allocated so far. It uses a separate\n+\/\/ pending list and global synchronization to avoid the ABA problem when the\n+\/\/ user frees a memory object.\n+\/\/\n+\/\/ The class also manages a few counters for statistics using atomic operations.\n+\/\/ Their values are only consistent within each other with extra global\n+\/\/ synchronization.\n+\/\/\n+\/\/ Since it is expected that every CardSet (and in extension each region) has its\n+\/\/ own set of allocators, there is intentionally no padding between them to save\n+\/\/ memory.\n+template <class Elem>\n+class G1CardSetAllocator {\n+  \/\/ G1CardSetBuffer management.\n+\n+  \/\/ G1CardSetAllocOptions provides parameters for allocation buffer\n+  \/\/ sizing and expansion.\n+  G1CardSetAllocOptions _alloc_options;\n+\n+  G1CardSetBuffer* volatile _first;       \/\/ The (start of the) list of all buffers.\n+  G1CardSetBuffer* _last;                 \/\/ The last element of the list of all buffers.\n+  volatile uint _num_buffers;             \/\/ Number of assigned buffers to this allocator.\n+  volatile size_t _mem_size;              \/\/ Memory used by all buffers.\n+\n+  G1CardSetBufferList* _free_buffer_list; \/\/ The global free buffer list to\n+                                          \/\/ preferentially get new buffers from.\n+\n+  \/\/ G1CardSetContainer node management within the G1CardSetBuffers allocated\n+  \/\/ by this allocator.\n+\n+  static G1CardSetContainer* volatile* next_ptr(G1CardSetContainer& node);\n+  typedef LockFreeStack<G1CardSetContainer, &next_ptr> NodeStack;\n+\n+  volatile bool _transfer_lock;\n+  NodeStack _free_nodes_list;\n+  NodeStack _pending_nodes_list;\n+\n+  volatile uint _num_pending_nodes;   \/\/ Number of nodes in the pending list.\n+  volatile uint _num_free_nodes;      \/\/ Number of nodes in the free list.\n+\n+  volatile uint _num_allocated_nodes; \/\/ Number of total nodes allocated and in use.\n+  volatile uint _num_available_nodes; \/\/ Number of nodes available in all buffers (allocated + free + pending + not yet used).\n+\n+  \/\/ Try to transfer nodes from _pending_nodes_list to _free_nodes_list, with a\n+  \/\/ synchronization delay for any in-progress pops from the _free_nodes_list\n+  \/\/ to solve ABA here.\n+  bool try_transfer_pending();\n+\n+  uint num_free_elems() const;\n+\n+  G1CardSetBuffer* create_new_buffer(G1CardSetBuffer* const prev);\n+\n+  uint elem_size() const { return _alloc_options.elem_size(); }\n+\n+public:\n+  G1CardSetAllocator(const char* name,\n+                     const G1CardSetAllocOptions& buffer_options,\n+                     G1CardSetBufferList* free_buffer_list);\n+  ~G1CardSetAllocator() {\n+    drop_all();\n+  }\n+\n+  Elem* allocate();\n+  void free(Elem* elem);\n+\n+  \/\/ Deallocate all buffers to the free buffer list and reset this allocator. Must\n+  \/\/ be called in a globally synchronized area.\n+  void drop_all();\n+\n+  uint num_buffers() const;\n+\n+  size_t mem_size() const {\n+    return sizeof(*this) +\n+      num_buffers() * sizeof(G1CardSetBuffer) + (size_t)_num_available_nodes * elem_size();\n+  }\n+\n+  size_t wasted_mem_size() const {\n+    return ((size_t)_num_available_nodes - (_num_allocated_nodes - _num_pending_nodes)) * elem_size();\n+  }\n+\n+  void print(outputStream* os);\n+};\n+\n+\/\/ Statistics for a fixed set of buffer lists. Contains the number of buffers and memory\n+\/\/ used for each. Note that statistics are typically not taken atomically so there\n+\/\/ can be inconsistencies. The user must be prepared for them.\n+class G1CardSetMemoryStats {\n+public:\n+\n+  size_t _num_mem_sizes[G1CardSetConfiguration::num_mem_object_types()];\n+  size_t _num_buffers[G1CardSetConfiguration::num_mem_object_types()];\n+\n+  \/\/ Returns all-zero statistics.\n+  G1CardSetMemoryStats();\n+  \/\/ For every element in the set (indicated by i), call fn to provide the\n+  \/\/ memory size and number of buffers for that i'th buffer list.\n+  G1CardSetMemoryStats(void (*fn)(const void* context, uint i, size_t& mem_size, size_t& num_buffers), const void* context);\n+\n+  void add(G1CardSetMemoryStats const other) {\n+    STATIC_ASSERT(ARRAY_SIZE(_num_buffers) == ARRAY_SIZE(_num_mem_sizes));\n+    for (uint i = 0; i < ARRAY_SIZE(_num_mem_sizes); i++) {\n+      _num_mem_sizes[i] += other._num_mem_sizes[i];\n+      _num_buffers[i] += other._num_buffers[i];\n+    }\n+  }\n+\n+  void clear();\n+\n+  uint num_pools() const { return G1CardSetConfiguration::num_mem_object_types(); }\n+};\n+\n+\/\/ A set of free lists holding memory buffers for use by G1CardSetAllocators.\n+class G1CardSetFreePool {\n+  \/\/ The global free pool.\n+  static G1CardSetFreePool _freelist_pool;\n+\n+  uint _num_free_lists;\n+  G1CardSetBufferList* _free_lists;\n+\n+public:\n+  static G1CardSetFreePool* free_list_pool() { return &_freelist_pool; }\n+  static G1CardSetMemoryStats free_list_sizes() { return _freelist_pool.memory_sizes(); }\n+\n+  class G1ReturnMemoryProcessor;\n+  typedef GrowableArrayCHeap<G1ReturnMemoryProcessor*, mtGC> G1ReturnMemoryProcessorSet;\n+\n+  static void update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processors);\n+\n+  explicit G1CardSetFreePool(uint num_free_lists);\n+  ~G1CardSetFreePool();\n+\n+  G1CardSetBufferList* free_list(uint i) {\n+    assert(i < _num_free_lists, \"must be\");\n+    return &_free_lists[i];\n+  }\n+\n+  uint num_free_lists() const { return _num_free_lists; }\n+\n+  \/\/ Return sizes for free list i in this free list pool.\n+  void get_size(uint i, size_t& mem_size, size_t& num_buffers) const;\n+\n+  G1CardSetMemoryStats memory_sizes() const;\n+  size_t mem_size() const;\n+\n+  void print_on(outputStream* out);\n+};\n+\n+\/\/ Data structure containing current in-progress state for returning memory to the\n+\/\/ operating system for a single G1CardSetBufferList.\n+class G1CardSetFreePool::G1ReturnMemoryProcessor : public CHeapObj<mtGC> {\n+  G1CardSetBufferList* _source;\n+  size_t _return_to_vm_size;\n+\n+  G1CardSetBuffer* _first;\n+  size_t _unlinked_bytes;\n+  size_t _num_unlinked;\n+\n+public:\n+  explicit G1ReturnMemoryProcessor(size_t return_to_vm) :\n+    _source(nullptr), _return_to_vm_size(return_to_vm), _first(nullptr), _unlinked_bytes(0), _num_unlinked(0) {\n+  }\n+\n+  \/\/ Updates the instance members about the given card set buffer list for the purpose\n+  \/\/ of giving back memory. Only necessary members are updated, e.g. if there is\n+  \/\/ nothing to return to the VM, do not set the source list.\n+  void visit_free_list(G1CardSetBufferList* source);\n+\n+  bool finished_return_to_vm() const { return _return_to_vm_size == 0; }\n+  bool finished_return_to_os() const { return _first == nullptr; }\n+\n+  \/\/ Returns memory to the VM until the given deadline expires. Returns true if\n+  \/\/ there is no more work. Guarantees forward progress, i.e. at least one buffer\n+  \/\/ has been processed after returning.\n+  \/\/ return_to_vm() re-adds buffers to the respective free list.\n+  bool return_to_vm(jlong deadline);\n+  \/\/ Returns memory to the VM until the given deadline expires. Returns true if\n+  \/\/ there is no more work. Guarantees forward progress, i.e. at least one buffer\n+  \/\/ has been processed after returning.\n+  \/\/ return_to_os() gives back buffers to the OS.\n+  bool return_to_os(jlong deadline);\n+};\n+\n+class G1CardSetMemoryManager : public CHeapObj<mtGCCardSet> {\n+  G1CardSetConfiguration* _config;\n+\n+  G1CardSetAllocator<G1CardSetContainer>* _allocators;\n+\n+  uint num_mem_object_types() const;\n+public:\n+  G1CardSetMemoryManager(G1CardSetConfiguration* config,\n+                         G1CardSetFreePool* free_list_pool);\n+\n+  virtual ~G1CardSetMemoryManager();\n+\n+  \/\/ Allocate and free a memory object of given type.\n+  inline uint8_t* allocate(uint type);\n+  void free(uint type, void* value);\n+\n+  \/\/ Allocate and free a hash table node.\n+  inline uint8_t* allocate_node();\n+  inline void free_node(void* value);\n+\n+  void flush();\n+\n+  void print(outputStream* os);\n+\n+  size_t mem_size() const;\n+  size_t wasted_mem_size() const;\n+\n+  G1CardSetMemoryStats memory_stats() const;\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSETMEMORY_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.hpp","additions":384,"deletions":0,"binary":false,"changes":384,"status":"added"},{"patch":"@@ -0,0 +1,132 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1CARDSETMEMORY_INLINE_HPP\n+#define SHARE_GC_G1_G1CARDSETMEMORY_INLINE_HPP\n+\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.hpp\"\n+#include \"utilities\/ostream.hpp\"\n+\n+#include \"gc\/g1\/g1CardSetContainers.inline.hpp\"\n+#include \"utilities\/globalCounter.inline.hpp\"\n+\n+template <class Elem>\n+G1CardSetContainer* volatile* G1CardSetAllocator<Elem>::next_ptr(G1CardSetContainer& node) {\n+  return node.next_addr();\n+}\n+\n+template <class Elem>\n+G1CardSetBuffer* G1CardSetAllocator<Elem>::create_new_buffer(G1CardSetBuffer* const prev) {\n+\n+  \/\/ Take an existing buffer if available.\n+  G1CardSetBuffer* next = _free_buffer_list->get();\n+  if (next == nullptr) {\n+    uint prev_num_elems = (prev != nullptr) ? prev->num_elems() : 0;\n+    uint num_elems = _alloc_options.next_num_elems(prev_num_elems);\n+    next = new G1CardSetBuffer(elem_size(), num_elems, prev);\n+  } else {\n+    assert(elem_size() == next->elem_size() , \"Mismatch %d != %d Elem %zu\", elem_size(), next->elem_size(), sizeof(Elem));\n+    next->reset(prev);\n+  }\n+\n+  \/\/ Install it as current allocation buffer.\n+  G1CardSetBuffer* old = Atomic::cmpxchg(&_first, prev, next);\n+  if (old != prev) {\n+    \/\/ Somebody else installed the buffer, use that one.\n+    delete next;\n+    return old;\n+  } else {\n+    \/\/ Did we install the first element in the list? If so, this is also the last.\n+    if (prev == nullptr) {\n+      _last = next;\n+    }\n+    \/\/ Successfully installed the buffer into the list.\n+    Atomic::inc(&_num_buffers, memory_order_relaxed);\n+    Atomic::add(&_mem_size, next->mem_size(), memory_order_relaxed);\n+    Atomic::add(&_num_available_nodes, next->num_elems(), memory_order_relaxed);\n+    return next;\n+  }\n+}\n+\n+template <class Elem>\n+Elem* G1CardSetAllocator<Elem>::allocate() {\n+  assert(elem_size() > 0, \"instance size not set.\");\n+\n+  if (num_free_elems() > 0) {\n+    \/\/ Pop under critical section to deal with ABA problem\n+    \/\/ Other solutions to the same problem are more complicated (ref counting, HP)\n+    GlobalCounter::CriticalSection cs(Thread::current());\n+\n+    G1CardSetContainer* node = _free_nodes_list.pop();\n+    if (node != nullptr) {\n+      Elem* elem = reinterpret_cast<Elem*>(reinterpret_cast<char*>(node));\n+      Atomic::sub(&_num_free_nodes, 1u);\n+      guarantee(is_aligned(elem, 8), \"result \" PTR_FORMAT \" not aligned\", p2i(elem));\n+      return elem;\n+    }\n+  }\n+\n+  G1CardSetBuffer* cur = Atomic::load_acquire(&_first);\n+  if (cur == nullptr) {\n+    cur = create_new_buffer(cur);\n+  }\n+\n+  while (true) {\n+    Elem* elem = (Elem*)cur->get_new_buffer_elem();\n+    if (elem != nullptr) {\n+      Atomic::inc(&_num_allocated_nodes, memory_order_relaxed);\n+      guarantee(is_aligned(elem, 8), \"result \" PTR_FORMAT \" not aligned\", p2i(elem));\n+      return elem;\n+    }\n+    \/\/ The buffer is full. Next round.\n+    assert(cur->is_full(), \"must be\");\n+    cur = create_new_buffer(cur);\n+  }\n+}\n+\n+inline uint8_t* G1CardSetMemoryManager::allocate(uint type) {\n+  assert(type < num_mem_object_types(), \"must be\");\n+  return (uint8_t*)_allocators[type].allocate();\n+}\n+\n+inline uint8_t* G1CardSetMemoryManager::allocate_node() {\n+  return allocate(0);\n+}\n+\n+inline void G1CardSetMemoryManager::free_node(void* value) {\n+  free(0, value);\n+}\n+\n+template <class Elem>\n+inline uint G1CardSetAllocator<Elem>::num_buffers() const {\n+  return Atomic::load(&_num_buffers);\n+}\n+\n+template <class Elem>\n+inline uint G1CardSetAllocator<Elem>::num_free_elems() const {\n+  return Atomic::load(&_num_free_nodes);\n+}\n+\n+#endif \/\/ SHARE_GC_G1_G1CARDSETMEMORY_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.inline.hpp","additions":132,"deletions":0,"binary":false,"changes":132,"status":"added"},{"patch":"@@ -105,1 +105,1 @@\n-  inline size_t mark_region_dirty(size_t start_card_index, size_t num_cards);\n+  inline size_t mark_range_dirty(size_t start_card_index, size_t num_cards);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardTable.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -46,1 +46,1 @@\n-inline size_t G1CardTable::mark_region_dirty(size_t start_card_index, size_t num_cards) {\n+inline size_t G1CardTable::mark_range_dirty(size_t start_card_index, size_t num_cards) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardTable.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CodeBlobClosure.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"gc\/g1\/g1CollectionSetCandidates.hpp\"\n@@ -71,1 +72,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n@@ -150,1 +151,1 @@\n-  return new HeapRegion(hrs_index, bot(), mr);\n+  return new HeapRegion(hrs_index, bot(), mr, &_card_set_config);\n@@ -1379,0 +1380,1 @@\n+  _free_card_set_memory_task(NULL),\n@@ -1415,0 +1417,1 @@\n+  _card_set_config(),\n@@ -1683,0 +1686,3 @@\n+  _free_card_set_memory_task = new G1CardSetFreeMemoryTask(\"Card Set Free Memory Task\");\n+  _service_thread->register_task(_free_card_set_memory_task);\n+\n@@ -2573,0 +2579,3 @@\n+\n+  _free_card_set_memory_task->notify_new_stats(&_young_gen_card_set_stats,\n+                                               &_collection_set_candidates_card_set_stats);\n@@ -2641,1 +2650,1 @@\n-         rem_set->occupancy_less_or_equal_than(G1RSetSparseRegionEntries) :\n+         rem_set->occupancy_less_or_equal_than(G1RemSetArrayOfCardsEntries) :\n@@ -2919,1 +2928,0 @@\n-\n@@ -2928,1 +2936,0 @@\n-\n@@ -2933,1 +2940,0 @@\n-\n@@ -3280,0 +3286,9 @@\n+bool G1CollectedHeap::should_sample_collection_set_candidates() const {\n+  G1CollectionSetCandidates* candidates = G1CollectedHeap::heap()->collection_set()->candidates();\n+  return candidates != NULL && candidates->num_remaining() > 0;\n+}\n+\n+void G1CollectedHeap::set_collection_set_candidates_stats(G1CardSetMemoryStats& stats) {\n+  _collection_set_candidates_card_set_stats = stats;\n+}\n+\n@@ -3287,0 +3302,11 @@\n+    G1CardSetMemoryStats _card_set_stats;\n+\n+    void sample_card_set_size(HeapRegion* hr) {\n+      \/\/ Sample card set sizes for young gen and humongous before GC: this makes\n+      \/\/ the policy to give back memory to the OS keep the most recent amount of\n+      \/\/ memory for these regions.\n+      if (hr->is_young() || hr->is_starts_humongous()) {\n+        _card_set_stats.add(hr->rem_set()->card_set_memory_stats());\n+      }\n+    }\n+\n@@ -3359,0 +3385,2 @@\n+      sample_card_set_size(hr);\n+\n@@ -3379,0 +3407,4 @@\n+\n+    G1CardSetMemoryStats card_set_stats() const {\n+      return _card_set_stats;\n+    }\n@@ -3385,0 +3417,3 @@\n+\n+  G1CardSetMemoryStats _all_card_set_stats;\n+\n@@ -3396,0 +3431,3 @@\n+\n+    MutexLocker x(ParGCRareEvent_lock, Mutex::_no_safepoint_check_flag);\n+    _all_card_set_stats.add(cl.card_set_stats());\n@@ -3413,0 +3451,4 @@\n+\n+  G1CardSetMemoryStats all_card_set_stats() const {\n+    return _all_card_set_stats;\n+  }\n@@ -3438,0 +3480,2 @@\n+    _young_gen_card_set_stats = g1_prep_task.all_card_set_stats();\n+\n@@ -3712,0 +3756,1 @@\n+  rem_set()->print_coarsen_stats();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":51,"deletions":6,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"gc\/g1\/g1CardSetFreeMemoryTask.hpp\"\n@@ -68,0 +70,1 @@\n+class G1CardSetFreeMemoryTask;\n@@ -160,0 +163,1 @@\n+  G1CardSetFreeMemoryTask* _free_card_set_memory_task;\n@@ -175,0 +179,5 @@\n+  \/\/ Young gen memory statistics before GC.\n+  G1CardSetMemoryStats _young_gen_card_set_stats;\n+  \/\/ Collection set candidates memory statistics after GC.\n+  G1CardSetMemoryStats _collection_set_candidates_card_set_stats;\n+\n@@ -269,0 +278,3 @@\n+  bool should_sample_collection_set_candidates() const;\n+  void set_collection_set_candidates_stats(G1CardSetMemoryStats& stats);\n+\n@@ -838,0 +850,2 @@\n+  \/\/ Global card set configuration\n+  G1CardSetConfiguration _card_set_config;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSet.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectionSetChooser.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n@@ -42,1 +43,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n@@ -2945,1 +2946,1 @@\n-  _total_remset_bytes += HeapRegionRemSet::fl_mem_size() + HeapRegionRemSet::static_mem_size();\n+  _total_remset_bytes += G1CardSetFreePool::free_list_pool()->mem_size() + HeapRegionRemSet::static_mem_size();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCOopClosures.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+constexpr const char* G1GCPhaseTimes::GCMergeRSWorkItemsStrings[];\n+\n@@ -74,4 +76,3 @@\n-  _gc_par_phases[MergeRS]->create_thread_work_items(\"Merged Sparse:\", MergeRSMergedSparse);\n-  _gc_par_phases[MergeRS]->create_thread_work_items(\"Merged Fine:\", MergeRSMergedFine);\n-  _gc_par_phases[MergeRS]->create_thread_work_items(\"Merged Coarse:\", MergeRSMergedCoarse);\n-  _gc_par_phases[MergeRS]->create_thread_work_items(\"Dirty Cards:\", MergeRSDirtyCards);\n+  for (uint i = 0; i < MergeRSContainersSentinel; i++) {\n+    _gc_par_phases[MergeRS]->create_thread_work_items(GCMergeRSWorkItemsStrings[i], i);\n+  }\n@@ -80,4 +81,3 @@\n-  _gc_par_phases[OptMergeRS]->create_thread_work_items(\"Merged Sparse:\", MergeRSMergedSparse);\n-  _gc_par_phases[OptMergeRS]->create_thread_work_items(\"Merged Fine:\", MergeRSMergedFine);\n-  _gc_par_phases[OptMergeRS]->create_thread_work_items(\"Merged Coarse:\", MergeRSMergedCoarse);\n-  _gc_par_phases[OptMergeRS]->create_thread_work_items(\"Dirty Cards:\", MergeRSDirtyCards);\n+  for (uint i = 0; i < MergeRSContainersSentinel; i++) {\n+    _gc_par_phases[OptMergeRS]->create_thread_work_items(GCMergeRSWorkItemsStrings[i], i);\n+  }\n@@ -137,0 +137,2 @@\n+  _gc_par_phases[SampleCollectionSetCandidates] = new WorkerDataArray<double>(\"SampleCandidates\", \"Sample CSet Candidates (ms):\", max_gc_threads);\n+\n@@ -173,0 +175,1 @@\n+  _recorded_sample_collection_set_candidates_time_ms = 0.0;\n@@ -452,0 +455,1 @@\n+                        _recorded_sample_collection_set_candidates_time_ms +\n@@ -475,0 +479,2 @@\n+  debug_time(\"Sample Collection Set Candidates\", _recorded_sample_collection_set_candidates_time_ms);\n+  trace_phase(_gc_par_phases[RedirtyCards]);\n@@ -488,0 +494,3 @@\n+  if (G1CollectedHeap::heap()->should_sample_collection_set_candidates()) {\n+    debug_phase(_gc_par_phases[SampleCollectionSetCandidates], 1);\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.cpp","additions":17,"deletions":8,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+    SampleCollectionSetCandidates,\n@@ -100,5 +101,11 @@\n-  enum GCMergeRSWorkTimes {\n-    MergeRSMergedSparse,\n-    MergeRSMergedFine,\n-    MergeRSMergedCoarse,\n-    MergeRSDirtyCards\n+  enum GCMergeRSWorkItems : uint {\n+    MergeRSMergedInline = 0,\n+    MergeRSMergedArrayOfCards,\n+    MergeRSMergedHowl,\n+    MergeRSMergedFull,\n+    MergeRSHowlInline,\n+    MergeRSHowlArrayOfCards,\n+    MergeRSHowlBitmap,\n+    MergeRSHowlFull,\n+    MergeRSDirtyCards,\n+    MergeRSContainersSentinel\n@@ -107,0 +114,5 @@\n+  static constexpr const char* GCMergeRSWorkItemsStrings[MergeRSContainersSentinel] =\n+    { \"Merged Inline\", \"Merged ArrayOfCards\", \"Merged Howl\", \"Merged Full\",\n+      \"Merged Howl Inline\", \"Merged Howl ArrayOfCards\", \"Merged Howl BitMap\", \"Merged Howl Full\",\n+      \"Dirty Cards\" };\n+\n@@ -176,0 +188,2 @@\n+  double _recorded_sample_collection_set_candidates_time_ms;\n+\n@@ -332,0 +346,4 @@\n+  void record_sample_collection_set_candidates_time_ms(double time_ms) {\n+    _recorded_sample_collection_set_candidates_time_ms = time_ms;\n+  }\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.hpp","additions":23,"deletions":5,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1OopClosures.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -33,1 +33,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n@@ -53,0 +53,2 @@\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1CardSet.inline.hpp\"\n@@ -48,1 +49,0 @@\n-#include \"gc\/g1\/sparsePRT.hpp\"\n@@ -384,3 +384,1 @@\n-    if (!_region_scan_chunks[chunk_idx]) {\n-      _region_scan_chunks[chunk_idx] = true;\n-    }\n+    _region_scan_chunks[chunk_idx] = true;\n@@ -1064,1 +1062,1 @@\n-\/\/ Small ring buffer used for prefetching cards for read\/write from the card\n+\/\/ Small ring buffer used for prefetching cards for write from the card\n@@ -1066,1 +1064,1 @@\n-template <class T, bool for_write>\n+template <class T>\n@@ -1099,5 +1097,1 @@\n-    if (for_write) {\n-      Prefetch::write(elem, 0);\n-    } else {\n-      Prefetch::read(elem, 0);\n-    }\n+    Prefetch::write(elem, 0);\n@@ -1114,1 +1108,27 @@\n-  \/\/ Visitor for remembered sets, dropping entries onto the card table.\n+  class G1MergeCardSetStats {\n+    size_t _merged[G1GCPhaseTimes::MergeRSContainersSentinel];\n+\n+  public:\n+    G1MergeCardSetStats() {\n+      for (uint i = 0; i < ARRAY_SIZE(_merged); i++) {\n+        _merged[i] = 0;\n+      }\n+    }\n+\n+    void inc_card_set_merged(uint tag) {\n+      assert(tag < ARRAY_SIZE(_merged), \"tag out of bounds %u\", tag);\n+      _merged[tag]++;\n+    }\n+\n+    void inc_cards_dirty(size_t increment = 1) {\n+      _merged[G1GCPhaseTimes::MergeRSDirtyCards] += increment;\n+    }\n+\n+    size_t merged(uint i) const { return _merged[i]; }\n+  };\n+\n+  \/\/ Visitor for remembered sets. Several methods of it are called by a region's\n+  \/\/ card set iterator to drop card set remembered set entries onto the card.\n+  \/\/ table. This is in addition to being the HeapRegionClosure to iterate over\n+  \/\/ all region's remembered sets.\n+  \/\/\n@@ -1124,5 +1144,1 @@\n-    uint _merged_sparse;\n-    uint _merged_fine;\n-    uint _merged_coarse;\n-\n-    size_t _cards_dirty;\n+    G1MergeCardSetStats _stats;\n@@ -1134,1 +1150,1 @@\n-    class G1MergeCardSetCache : public G1MergeHeapRootsPrefetchCache<G1CardTable::CardValue, true> {\n+    class G1MergeCardSetCache : public G1MergeHeapRootsPrefetchCache<G1CardTable::CardValue> {\n@@ -1141,1 +1157,1 @@\n-        G1MergeHeapRootsPrefetchCache<G1CardTable::CardValue, true>(G1CardTable::dirty_card_val()),\n+        G1MergeHeapRootsPrefetchCache<G1CardTable::CardValue>(G1CardTable::dirty_card_val()),\n@@ -1163,1 +1179,1 @@\n-        _cards_dirty++;\n+        _stats.inc_cards_dirty();\n@@ -1168,4 +1184,0 @@\n-    void start_iterate(uint const region_idx) {\n-      _region_base_idx = (size_t)region_idx << HeapRegion::LogCardsPerRegion;\n-    }\n-\n@@ -1173,0 +1185,1 @@\n+\n@@ -1176,4 +1189,1 @@\n-      _merged_sparse(0),\n-      _merged_fine(0),\n-      _merged_coarse(0),\n-      _cards_dirty(0),\n+      _stats(),\n@@ -1181,2 +1191,1 @@\n-      _merge_card_set_cache(this) {\n-    }\n+      _merge_card_set_cache(this) { }\n@@ -1191,24 +1200,7 @@\n-    void next_coarse_prt(uint const region_idx) {\n-      if (!remember_if_interesting(region_idx)) {\n-        return;\n-      }\n-\n-      _merged_coarse++;\n-\n-      start_iterate(region_idx);\n-      _cards_dirty += _ct->mark_region_dirty(_region_base_idx, HeapRegion::CardsPerRegion);\n-      _scan_state->set_chunk_region_dirty(_region_base_idx);\n-    }\n-\n-    void next_fine_prt(uint const region_idx, BitMap* bm) {\n-      if (!remember_if_interesting(region_idx)) {\n-        return;\n-      }\n-\n-      _merged_fine++;\n-\n-      start_iterate(region_idx);\n-      BitMap::idx_t cur = bm->get_next_one_offset(0);\n-      while (cur != bm->size()) {\n-        do_card((uint)cur);\n-        cur = bm->get_next_one_offset(cur + 1);\n+    \/\/ Returns whether the given region actually needs iteration.\n+    bool start_iterate(uint const tag, uint const region_idx) {\n+      assert(tag < G1GCPhaseTimes::MergeRSDirtyCards, \"invalid tag %u\", tag);\n+      if (remember_if_interesting(region_idx)) {\n+        _region_base_idx = (size_t)region_idx << HeapRegion::LogCardsPerRegion;\n+        _stats.inc_card_set_merged(tag);\n+        return true;\n@@ -1216,0 +1208,1 @@\n+      return false;\n@@ -1218,11 +1211,6 @@\n-    void next_sparse_prt(uint const region_idx, SparsePRTEntry::card_elem_t* cards, uint const num_cards) {\n-      if (!remember_if_interesting(region_idx)) {\n-        return;\n-      }\n-\n-      _merged_sparse++;\n-\n-      start_iterate(region_idx);\n-      for (uint i = 0; i < num_cards; i++) {\n-        do_card(cards[i]);\n-      }\n+    void do_card_range(uint const start_card_idx, uint const length) {\n+      assert(start_card_idx == 0, \"must be\");\n+      assert(length == HeapRegion::CardsPerRegion, \"must be\");\n+      size_t num_dirtied = _ct->mark_range_dirty(_region_base_idx, HeapRegion::CardsPerRegion);\n+      _stats.inc_cards_dirty(num_dirtied);\n+      _scan_state->set_chunk_region_dirty(_region_base_idx);\n@@ -1231,1 +1219,1 @@\n-    \/\/ Helper to put the remembered set cards for these regions onto the card\n+    \/\/ Helper to merge the cards in the card set for the given region onto the card\n@@ -1245,1 +1233,1 @@\n-    void dump_rem_set_for_region(HeapRegion* r) {\n+    void merge_card_set_for_region(HeapRegion* r) {\n@@ -1250,1 +1238,1 @@\n-        rem_set->iterate_prts(*this);\n+        rem_set->iterate_for_merge(*this);\n@@ -1258,1 +1246,1 @@\n-      dump_rem_set_for_region(r);\n+      merge_card_set_for_region(r);\n@@ -1263,5 +1251,1 @@\n-    size_t merged_sparse() const { return _merged_sparse; }\n-    size_t merged_fine() const { return _merged_fine; }\n-    size_t merged_coarse() const { return _merged_coarse; }\n-\n-    size_t cards_dirty() const { return _cards_dirty; }\n+    G1MergeCardSetStats stats() const { return _stats; }\n@@ -1273,1 +1257,2 @@\n-    G1MergeCardSetClosure _cl;\n+    G1RemSetScanState* _scan_state;\n+    G1MergeCardSetStats _merge_stats;\n@@ -1276,1 +1261,1 @@\n-    G1FlushHumongousCandidateRemSets(G1RemSetScanState* scan_state) : _cl(scan_state) { }\n+    G1FlushHumongousCandidateRemSets(G1RemSetScanState* scan_state) : _scan_state(scan_state), _merge_stats() { }\n@@ -1287,1 +1272,1 @@\n-      guarantee(r->rem_set()->occupancy_less_or_equal_than(G1RSetSparseRegionEntries),\n+      guarantee(r->rem_set()->occupancy_less_or_equal_than(G1RemSetArrayOfCardsEntries),\n@@ -1290,1 +1275,6 @@\n-      _cl.dump_rem_set_for_region(r);\n+      G1MergeCardSetStats stats;\n+      {\n+        G1MergeCardSetClosure cl(_scan_state);\n+        cl.merge_card_set_for_region(r);\n+        stats = cl.stats();\n+      }\n@@ -1310,5 +1300,1 @@\n-    size_t merged_sparse() const { return _cl.merged_sparse(); }\n-    size_t merged_fine() const { return _cl.merged_fine(); }\n-    size_t merged_coarse() const { return _cl.merged_coarse(); }\n-\n-    size_t cards_dirty() const { return _cl.cards_dirty(); }\n+    size_t merged(uint i) const { return _merge_stats.merged(i); }\n@@ -1319,1 +1305,0 @@\n-    friend class G1MergeLogBufferCardsCache;\n@@ -1327,17 +1312,0 @@\n-    class G1MergeLogBufferCardsCache : public G1MergeHeapRootsPrefetchCache<G1CardTable::CardValue, false> {\n-      G1MergeLogBufferCardsClosure* const _merge_log_buffer_cl;\n-\n-    public:\n-      G1MergeLogBufferCardsCache(G1MergeLogBufferCardsClosure* const merge_log_buffer_cl) :\n-        \/\/ Initially set dummy card value to Clean to avoid any actual work if we\n-        \/\/ try to process it.\n-        G1MergeHeapRootsPrefetchCache<G1CardTable::CardValue, false>(G1CardTable::clean_card_val()),\n-        _merge_log_buffer_cl(merge_log_buffer_cl) { }\n-\n-      ~G1MergeLogBufferCardsCache() {\n-        for (uint i = 0; i < CacheSize; i++) {\n-          _merge_log_buffer_cl->process_card(push(&_dummy_card));\n-        }\n-      }\n-    } _merge_log_buffer_cache;\n-\n@@ -1358,2 +1326,1 @@\n-      _cards_skipped(0),\n-      _merge_log_buffer_cache(this)\n+      _cards_skipped(0)\n@@ -1376,2 +1343,1 @@\n-        CardValue* to_process = _merge_log_buffer_cache.push(card_ptr);\n-        process_card(to_process);\n+        process_card(card_ptr);\n@@ -1445,4 +1411,3 @@\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged_sparse(), G1GCPhaseTimes::MergeRSMergedSparse);\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged_fine(), G1GCPhaseTimes::MergeRSMergedFine);\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged_coarse(), G1GCPhaseTimes::MergeRSMergedCoarse);\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.cards_dirty(), G1GCPhaseTimes::MergeRSDirtyCards);\n+      for (uint i = 0; i < G1GCPhaseTimes::MergeRSContainersSentinel; i++) {\n+        p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged(i), i);\n+      }\n@@ -1454,2 +1419,6 @@\n-      G1MergeCardSetClosure cl(_scan_state);\n-      g1h->collection_set_iterate_increment_from(&cl, &_hr_claimer, worker_id);\n+      G1MergeCardSetStats stats;\n+      {\n+        G1MergeCardSetClosure cl(_scan_state);\n+        g1h->collection_set_iterate_increment_from(&cl, &_hr_claimer, worker_id);\n+        stats = cl.stats();\n+      }\n@@ -1457,4 +1426,3 @@\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged_sparse(), G1GCPhaseTimes::MergeRSMergedSparse);\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged_fine(), G1GCPhaseTimes::MergeRSMergedFine);\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.merged_coarse(), G1GCPhaseTimes::MergeRSMergedCoarse);\n-      p->record_or_add_thread_work_item(merge_remset_phase, worker_id, cl.cards_dirty(), G1GCPhaseTimes::MergeRSDirtyCards);\n+      for (uint i = 0; i < G1GCPhaseTimes::MergeRSContainersSentinel; i++) {\n+        p->record_or_add_thread_work_item(merge_remset_phase, worker_id, stats.merged(i), i);\n+      }\n@@ -1489,1 +1457,3 @@\n-  size_t num_visited_cards = _scan_state->num_visited_cards();\n+  LogTarget(Debug, gc, remset) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n@@ -1491,1 +1461,1 @@\n-  size_t total_dirty_region_cards = _scan_state->num_cards_in_dirty_regions();\n+    size_t num_visited_cards = _scan_state->num_visited_cards();\n@@ -1493,10 +1463,13 @@\n-  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-  size_t total_old_region_cards =\n-    (g1h->num_regions() - (g1h->num_free_regions() - g1h->collection_set()->cur_length())) * HeapRegion::CardsPerRegion;\n-\n-  log_debug(gc,remset)(\"Visited cards \" SIZE_FORMAT \" Total dirty \" SIZE_FORMAT \" (%.2lf%%) Total old \" SIZE_FORMAT \" (%.2lf%%)\",\n-                       num_visited_cards,\n-                       total_dirty_region_cards,\n-                       percent_of(num_visited_cards, total_dirty_region_cards),\n-                       total_old_region_cards,\n-                       percent_of(num_visited_cards, total_old_region_cards));\n+    size_t total_dirty_region_cards = _scan_state->num_cards_in_dirty_regions();\n+\n+    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+    size_t total_old_region_cards =\n+      (g1h->num_regions() - (g1h->num_free_regions() - g1h->collection_set()->cur_length())) * HeapRegion::CardsPerRegion;\n+\n+    ls.print_cr(\"Visited cards \" SIZE_FORMAT \" Total dirty \" SIZE_FORMAT \" (%.2lf%%) Total old \" SIZE_FORMAT \" (%.2lf%%)\",\n+                num_visited_cards,\n+                total_dirty_region_cards,\n+                percent_of(num_visited_cards, total_dirty_region_cards),\n+                total_old_region_cards,\n+                percent_of(num_visited_cards, total_old_region_cards));\n+  }\n@@ -1534,3 +1507,1 @@\n-  if (log_is_enabled(Debug, gc, remset)) {\n-    print_merge_heap_roots_stats();\n-  }\n+  print_merge_heap_roots_stats();\n@@ -1551,0 +1522,9 @@\n+void G1RemSet::print_coarsen_stats() {\n+  LogTarget(Debug, gc, remset) lt;\n+  if (lt.is_enabled()) {\n+    LogStream ls(lt);\n+\n+    G1CardSet::print_coarsen_stats(&ls);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSet.cpp","additions":110,"deletions":130,"binary":false,"changes":240,"status":"modified"},{"patch":"@@ -110,0 +110,4 @@\n+  \/\/ Cleans the card table from temporary duplicate detection information.\n+  void cleanup_after_scan_heap_roots();\n+  \/\/ Print coarsening stats.\n+  void print_coarsen_stats();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSet.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n@@ -34,1 +35,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n@@ -51,0 +52,1 @@\n+\n@@ -53,1 +55,1 @@\n-  _num_coarsenings = HeapRegionRemSet::n_coarsenings();\n+  _coarsenings = HeapRegionRemSet::coarsen_stats();\n@@ -71,1 +73,1 @@\n-  _num_coarsenings(0),\n+  _coarsenings(),\n@@ -91,1 +93,1 @@\n-  _num_coarsenings = other->num_coarsenings();\n+  _coarsenings = other->_coarsenings;\n@@ -102,1 +104,1 @@\n-  _num_coarsenings = other->num_coarsenings() - _num_coarsenings;\n+  _coarsenings.subtract_from(other->_coarsenings);\n@@ -115,0 +117,1 @@\n+  size_t _rs_wasted_mem_size;\n@@ -118,0 +121,1 @@\n+  size_t _amount_tracked;\n@@ -139,0 +143,1 @@\n+  size_t amount_tracked() const { return _amount_tracked; }\n@@ -142,2 +147,2 @@\n-  RegionTypeCounter(const char* name) : _name(name), _rs_mem_size(0), _cards_occupied(0),\n-    _amount(0), _code_root_mem_size(0), _code_root_elems(0) { }\n+  RegionTypeCounter(const char* name) : _name(name), _rs_wasted_mem_size(0), _rs_mem_size(0), _cards_occupied(0),\n+    _amount(0), _amount_tracked(0), _code_root_mem_size(0), _code_root_elems(0) { }\n@@ -145,2 +150,3 @@\n-  void add(size_t rs_mem_size, size_t cards_occupied, size_t code_root_mem_size,\n-    size_t code_root_elems) {\n+  void add(size_t rs_wasted_mem_size, size_t rs_mem_size, size_t cards_occupied,\n+           size_t code_root_mem_size, size_t code_root_elems, bool tracked) {\n+    _rs_wasted_mem_size += rs_wasted_mem_size;\n@@ -152,0 +158,1 @@\n+    _amount_tracked += tracked ? 1 : 0;\n@@ -154,0 +161,1 @@\n+  size_t rs_wasted_mem_size() const { return _rs_wasted_mem_size; }\n@@ -161,4 +169,5 @@\n-    out->print_cr(\"    \" SIZE_FORMAT_W(8) \"%s (%5.1f%%) by \" SIZE_FORMAT \" %s regions\",\n-        byte_size_in_proper_unit(rs_mem_size()),\n-        proper_unit_for_byte_size(rs_mem_size()),\n-        rs_mem_size_percent_of(total), amount(), _name);\n+    out->print_cr(\"    \" SIZE_FORMAT_W(8) \" (%5.1f%%) by \" SIZE_FORMAT \" \"\n+                  \"(\" SIZE_FORMAT \") %s regions wasted \" SIZE_FORMAT,\n+                  rs_mem_size(), rs_mem_size_percent_of(total),\n+                  amount_tracked(), amount(),\n+                  _name, rs_wasted_mem_size());\n@@ -168,2 +177,4 @@\n-    out->print_cr(\"     \" SIZE_FORMAT_W(8) \" (%5.1f%%) entries by \" SIZE_FORMAT \" %s regions\",\n-        cards_occupied(), cards_occupied_percent_of(total), amount(), _name);\n+    out->print_cr(\"     \" SIZE_FORMAT_W(8) \" (%5.1f%%) entries by \" SIZE_FORMAT \" \"\n+                  \"(\" SIZE_FORMAT \") %s regions\",\n+                  cards_occupied(), cards_occupied_percent_of(total),\n+                  amount_tracked(), amount(), _name);\n@@ -198,0 +209,1 @@\n+  size_t total_rs_wasted_mem_sz() const     { return _all.rs_wasted_mem_size(); }\n@@ -225,0 +237,1 @@\n+    size_t rs_wasted_mem_sz = hrrs->wasted_mem_size();\n@@ -252,2 +265,4 @@\n-    current->add(rs_mem_sz, occupied_cards, code_root_mem_sz, code_root_elems);\n-    _all.add(rs_mem_sz, occupied_cards, code_root_mem_sz, code_root_elems);\n+    current->add(rs_wasted_mem_sz, rs_mem_sz, occupied_cards,\n+                 code_root_mem_sz, code_root_elems, r->rem_set()->is_tracked());\n+    _all.add(rs_wasted_mem_sz, rs_mem_sz, occupied_cards,\n+             code_root_mem_sz, code_root_elems, r->rem_set()->is_tracked());\n@@ -262,6 +277,5 @@\n-    out->print_cr(\"  Total per region rem sets sizes = \" SIZE_FORMAT \"%s.\"\n-                  \" Max = \" SIZE_FORMAT \"%s.\",\n-                  byte_size_in_proper_unit(total_rs_mem_sz()),\n-                  proper_unit_for_byte_size(total_rs_mem_sz()),\n-                  byte_size_in_proper_unit(max_rs_mem_sz()),\n-                  proper_unit_for_byte_size(max_rs_mem_sz()));\n+    out->print_cr(\"  Total per region rem sets sizes = \" SIZE_FORMAT\n+                  \" Max = \" SIZE_FORMAT \" wasted = \" SIZE_FORMAT,\n+                  total_rs_mem_sz(),\n+                  max_rs_mem_sz(),\n+                  total_rs_wasted_mem_sz());\n@@ -272,7 +286,0 @@\n-    out->print_cr(\"   Static structures = \" SIZE_FORMAT \"%s,\"\n-                  \" free_lists = \" SIZE_FORMAT \"%s.\",\n-                  byte_size_in_proper_unit(HeapRegionRemSet::static_mem_size()),\n-                  proper_unit_for_byte_size(HeapRegionRemSet::static_mem_size()),\n-                  byte_size_in_proper_unit(HeapRegionRemSet::fl_mem_size()),\n-                  proper_unit_for_byte_size(HeapRegionRemSet::fl_mem_size()));\n-\n@@ -288,1 +295,1 @@\n-                  \"size = \" SIZE_FORMAT \"%s, occupied = \" SIZE_FORMAT \"%s.\",\n+                  \"size = \" SIZE_FORMAT \" occupied = \" SIZE_FORMAT,\n@@ -290,4 +297,6 @@\n-                  byte_size_in_proper_unit(rem_set->mem_size()),\n-                  proper_unit_for_byte_size(rem_set->mem_size()),\n-                  byte_size_in_proper_unit(rem_set->occupied()),\n-                  proper_unit_for_byte_size(rem_set->occupied()));\n+                  rem_set->mem_size(),\n+                  rem_set->occupied());\n+\n+    HeapRegionRemSet::print_static_mem_size(out);\n+    G1CardSetFreePool::free_list_pool()->print_on(out);\n+\n@@ -322,1 +331,2 @@\n-  out->print_cr(\"  Did \" SIZE_FORMAT \" coarsenings.\", num_coarsenings());\n+  out->print(\"Coarsening: \");\n+  _coarsenings.print_on(out);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSetSummary.cpp","additions":46,"deletions":36,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/g1\/g1CardSet.hpp\"\n@@ -36,1 +37,1 @@\n-  size_t _num_coarsenings;\n+  G1CardSetCoarsenStats _coarsenings;\n@@ -68,4 +69,0 @@\n-\n-  size_t num_coarsenings() const {\n-    return _num_coarsenings;\n-  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSetSummary.hpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -29,1 +29,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSetTrackingPolicy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n@@ -30,0 +31,1 @@\n+#include \"gc\/g1\/g1CollectionSetCandidates.hpp\"\n@@ -44,0 +46,3 @@\n+  if (SampleCollectionSetCandidatesTask::should_execute()) {\n+    add_serial_task(new SampleCollectionSetCandidatesTask());\n+  }\n@@ -67,0 +72,26 @@\n+bool G1PostEvacuateCollectionSetCleanupTask1::SampleCollectionSetCandidatesTask::should_execute() {\n+  return G1CollectedHeap::heap()->should_sample_collection_set_candidates();\n+}\n+\n+double G1PostEvacuateCollectionSetCleanupTask1::SampleCollectionSetCandidatesTask::worker_cost() const {\n+  return should_execute() ? 1.0 : AlmostNoWork;\n+}\n+\n+class G1SampleCollectionSetCandidatesClosure : public HeapRegionClosure {\n+public:\n+  G1CardSetMemoryStats _total;\n+\n+  bool do_heap_region(HeapRegion* r) override {\n+    _total.add(r->rem_set()->card_set_memory_stats());\n+    return false;\n+  }\n+};\n+\n+void G1PostEvacuateCollectionSetCleanupTask1::SampleCollectionSetCandidatesTask::do_work(uint worker_id) {\n+  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+\n+  G1SampleCollectionSetCandidatesClosure cl;\n+  g1h->collection_set()->candidates()->iterate(&cl);\n+  g1h->set_collection_set_candidates_stats(cl._total);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":31,"deletions":0,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+\/\/ - Sample Collection Set Candidates (s)\n@@ -46,0 +47,1 @@\n+  class SampleCollectionSetCandidatesTask;\n@@ -71,0 +73,10 @@\n+class G1PostEvacuateCollectionSetCleanupTask1::SampleCollectionSetCandidatesTask : public G1AbstractSubTask {\n+public:\n+  SampleCollectionSetCandidatesTask() : G1AbstractSubTask(G1GCPhaseTimes::SampleCollectionSetCandidates) { }\n+\n+  static bool should_execute();\n+\n+  double worker_cost() const override;\n+  void do_work(uint worker_id) override;\n+};\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -133,2 +133,2 @@\n-          \"Each time the rset update queue increases by this amount \"       \\\n-          \"activate the next refinement thread if available. \"              \\\n+          \"Each time the remembered set update queue increases by this \"    \\\n+          \"amount activate the next refinement thread if available. \"       \\\n@@ -141,1 +141,2 @@\n-          \"process RS update buffers during the collection pause.\")         \\\n+          \"processing remembered set update buffers during the collection \" \\\n+          \"pause.\")                                                         \\\n@@ -156,20 +157,34 @@\n-  develop(intx, G1RSetRegionEntriesBase, 256,                               \\\n-          \"Max number of regions in a fine-grain table per MB.\")            \\\n-          range(1, max_jint\/wordSize)                                       \\\n-                                                                            \\\n-  product(intx, G1RSetRegionEntries, 0,                                     \\\n-          \"Max number of regions for which we keep bitmaps.\"                \\\n-          \"Will be set ergonomically by default\")                           \\\n-          range(0, max_jint\/wordSize)                                       \\\n-          constraint(G1RSetRegionEntriesConstraintFunc,AfterErgo)           \\\n-                                                                            \\\n-  develop(intx, G1RSetSparseRegionEntriesBase, 4,                           \\\n-          \"Max number of entries per region in a sparse table \"             \\\n-          \"per MB.\")                                                        \\\n-          range(1, max_jint\/wordSize)                                       \\\n-                                                                            \\\n-  product(intx, G1RSetSparseRegionEntries, 0,                               \\\n-          \"Max number of entries per region in a sparse table.\"             \\\n-          \"Will be set ergonomically by default.\")                          \\\n-          range(0, max_jint\/wordSize)                                       \\\n-          constraint(G1RSetSparseRegionEntriesConstraintFunc,AfterErgo)     \\\n+  develop(uint, G1RemSetArrayOfCardsEntriesBase, 4,                         \\\n+          \"Maximum number of entries per region in the Array of Cards \"     \\\n+          \"card set container per MB of a heap region.\")                    \\\n+          range(1, 65536)                                                   \\\n+                                                                            \\\n+  product(uint, G1RemSetArrayOfCardsEntries, 0,  EXPERIMENTAL,              \\\n+          \"Maximum number of entries per Array of Cards card set \"          \\\n+          \"container. Will be set ergonomically by default.\")               \\\n+          range(0, 65536)                                                   \\\n+          constraint(G1RemSetArrayOfCardsEntriesConstraintFunc,AfterErgo)   \\\n+                                                                            \\\n+  product(uint, G1RemSetHowlMaxNumBuckets, 8, EXPERIMENTAL,                 \\\n+          \"Maximum number of buckets per Howl card set container. The \"     \\\n+          \"default gives at worst bitmaps of size 8k. This showed to be a \" \\\n+          \"good tradeoff between bitmap size (waste) and cacheability of \"  \\\n+          \"the bucket array. Must be a power of two.\")                      \\\n+          range(1, 1024)                                                    \\\n+          constraint(G1RemSetHowlMaxNumBucketsConstraintFunc,AfterErgo)     \\\n+                                                                            \\\n+  product(uint, G1RemSetHowlNumBuckets, 0, EXPERIMENTAL,                    \\\n+          \"Number of buckets per Howl card set container. Must be a power \" \\\n+          \"of two. Will be set ergonomically by default.\")                  \\\n+          range(0, 1024)                                                    \\\n+          constraint(G1RemSetHowlNumBucketsConstraintFunc,AfterErgo)        \\\n+                                                                            \\\n+  product(uint, G1RemSetCoarsenHowlBitmapToHowlFullPercent, 90, EXPERIMENTAL, \\\n+          \"Percentage at which to coarsen a Howl bitmap to Howl full card \" \\\n+          \"set container.\")                                                 \\\n+          range(1, 100)                                                     \\\n+                                                                            \\\n+  product(uint, G1RemSetCoarsenHowlToFullPercent, 90, EXPERIMENTAL,         \\\n+          \"Percentage at which to coarsen a Howl card set to Full card \"    \\\n+          \"set container.\")                                                 \\\n+          range(1, 100)                                                     \\\n@@ -193,1 +208,1 @@\n-          \"The number of parallel rem set update threads. \"                 \\\n+          \"The number of parallel remembered set update threads. \"          \\\n@@ -305,2 +320,17 @@\n-          range(0.0, (double)max_uintx)\n-\n+          range(0.0, (double)max_uintx)                                     \\\n+                                                                            \\\n+  product(uint, G1RemSetFreeMemoryRescheduleDelayMillis, 10, EXPERIMENTAL,  \\\n+          \"Time after which the card set free memory task reschedules \"     \\\n+          \"itself if there is work remaining.\")                             \\\n+          range(1, UINT_MAX)                                                \\\n+                                                                            \\\n+  product(double, G1RemSetFreeMemoryStepDurationMillis, 1, EXPERIMENTAL,    \\\n+          \"The amount of time that the free memory task should spend \"      \\\n+          \"before a pause of G1RemSetFreeMemoryRescheduleDelayMillis \"      \\\n+          \"length.\")                                                        \\\n+          range(1e-3, 1e+6)                                                 \\\n+                                                                            \\\n+  product(double, G1RemSetFreeMemoryKeepExcessRatio, 0.1, EXPERIMENTAL,     \\\n+          \"The percentage of free card set memory that G1 should keep as \"  \\\n+          \"percentage of the currently used memory.\")                       \\\n+          range(0.0, 1.0)\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":57,"deletions":27,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n@@ -233,1 +233,2 @@\n-                       MemRegion mr) :\n+                       MemRegion mr,\n+                       G1CardSetConfiguration* config) :\n@@ -260,1 +261,1 @@\n-  _rem_set = new HeapRegionRemSet(bot, this);\n+  _rem_set = new HeapRegionRemSet(this, config);\n@@ -618,0 +619,2 @@\n+          LogStream ls(log.error());\n+          to->rem_set()->print_info(&ls, p);\n@@ -622,1 +625,0 @@\n-          LogStream ls(log.error());\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+class G1CardSetConfiguration;\n+class G1CardSetMemoryManager;\n@@ -283,1 +285,4 @@\n-  HeapRegion(uint hrm_index, G1BlockOffsetTable* bot, MemRegion mr);\n+  HeapRegion(uint hrm_index,\n+             G1BlockOffsetTable* bot,\n+             MemRegion mr,\n+             G1CardSetConfiguration* config);\n@@ -447,0 +452,1 @@\n+  void set_rem_set(HeapRegionRemSet* rem_set) { _rem_set = rem_set; }\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -25,0 +25,2 @@\n+#include <cstdio>\n+\n@@ -31,1 +33,0 @@\n-#include \"gc\/g1\/sparsePRT.inline.hpp\"\n@@ -47,346 +48,8 @@\n-PerRegionTable* PerRegionTable::alloc(HeapRegion* hr) {\n-  PerRegionTable* fl = _free_list;\n-  while (fl != NULL) {\n-    PerRegionTable* nxt = fl->next();\n-    PerRegionTable* res = Atomic::cmpxchg(&_free_list, fl, nxt);\n-    if (res == fl) {\n-      fl->init(hr, true);\n-      return fl;\n-    } else {\n-      fl = _free_list;\n-    }\n-  }\n-  assert(fl == NULL, \"Loop condition.\");\n-  return new PerRegionTable(hr);\n-}\n-\n-PerRegionTable* volatile PerRegionTable::_free_list = NULL;\n-\n-size_t OtherRegionsTable::_max_fine_entries = 0;\n-size_t OtherRegionsTable::_mod_max_fine_entries_mask = 0;\n-size_t OtherRegionsTable::_fine_eviction_stride = 0;\n-size_t OtherRegionsTable::_fine_eviction_sample_size = 0;\n-\n-OtherRegionsTable::OtherRegionsTable(Mutex* m) :\n-  _g1h(G1CollectedHeap::heap()),\n-  _m(m),\n-  _num_occupied(0),\n-  _coarse_map(mtGC),\n-  _has_coarse_entries(false),\n-  _fine_grain_regions(NULL),\n-  _n_fine_entries(0),\n-  _first_all_fine_prts(NULL),\n-  _last_all_fine_prts(NULL),\n-  _fine_eviction_start(0),\n-  _sparse_table()\n-{\n-  typedef PerRegionTable* PerRegionTablePtr;\n-\n-  if (_max_fine_entries == 0) {\n-    assert(_mod_max_fine_entries_mask == 0, \"Both or none.\");\n-    size_t max_entries_log = (size_t)log2i(G1RSetRegionEntries);\n-    _max_fine_entries = (size_t)1 << max_entries_log;\n-    _mod_max_fine_entries_mask = _max_fine_entries - 1;\n-\n-    assert(_fine_eviction_sample_size == 0\n-           && _fine_eviction_stride == 0, \"All init at same time.\");\n-    _fine_eviction_sample_size = MAX2((size_t)4, max_entries_log);\n-    _fine_eviction_stride = _max_fine_entries \/ _fine_eviction_sample_size;\n-  }\n-\n-  _fine_grain_regions = NEW_C_HEAP_ARRAY(PerRegionTablePtr, _max_fine_entries, mtGC);\n-  for (size_t i = 0; i < _max_fine_entries; i++) {\n-    _fine_grain_regions[i] = NULL;\n-  }\n-}\n-\n-void OtherRegionsTable::link_to_all(PerRegionTable* prt) {\n-  \/\/ We always append to the beginning of the list for convenience;\n-  \/\/ the order of entries in this list does not matter.\n-  if (_first_all_fine_prts != NULL) {\n-    prt->set_next(_first_all_fine_prts);\n-  } else {\n-    \/\/ this is the first element we insert. Adjust the \"last\" pointer\n-    _last_all_fine_prts = prt;\n-    assert(prt->next() == NULL, \"just checking\");\n-  }\n-  _first_all_fine_prts = prt;\n-\n-  assert(_first_all_fine_prts == prt, \"just checking\");\n-  assert((_first_all_fine_prts == NULL && _last_all_fine_prts == NULL) ||\n-         (_first_all_fine_prts != NULL && _last_all_fine_prts != NULL),\n-         \"just checking\");\n-  assert(_last_all_fine_prts == NULL || _last_all_fine_prts->next() == NULL,\n-         \"just checking\");\n-}\n-\n-CardIdx_t OtherRegionsTable::card_within_region(OopOrNarrowOopStar within_region, HeapRegion* hr) {\n-  assert(hr->is_in_reserved(within_region),\n-         \"HeapWord \" PTR_FORMAT \" is outside of region %u [\" PTR_FORMAT \", \" PTR_FORMAT \")\",\n-         p2i(within_region), hr->hrm_index(), p2i(hr->bottom()), p2i(hr->end()));\n-  CardIdx_t result = (CardIdx_t)(pointer_delta((HeapWord*)within_region, hr->bottom()) >> (CardTable::card_shift - LogHeapWordSize));\n-  return result;\n-}\n-\n-void OtherRegionsTable::add_reference(OopOrNarrowOopStar from, uint tid) {\n-  \/\/ Note that this may be a continued H region.\n-  HeapRegion* from_hr = _g1h->heap_region_containing(from);\n-  RegionIdx_t from_hrm_ind = (RegionIdx_t) from_hr->hrm_index();\n-\n-  \/\/ If the region is already coarsened, return.\n-  if (is_region_coarsened(from_hrm_ind)) {\n-    assert(contains_reference(from), \"We just found \" PTR_FORMAT \" in the Coarse table\", p2i(from));\n-    return;\n-  }\n-\n-  size_t num_added_by_coarsening = 0;\n-  \/\/ Otherwise find a per-region table to add it to.\n-  size_t ind = from_hrm_ind & _mod_max_fine_entries_mask;\n-  PerRegionTable* prt = find_region_table(ind, from_hr);\n-  if (prt == NULL) {\n-    MutexLocker x(_m, Mutex::_no_safepoint_check_flag);\n-\n-    \/\/ Rechecking if the region is coarsened, while holding the lock.\n-    if (is_region_coarsened(from_hrm_ind)) {\n-      assert(contains_reference_locked(from), \"We just found \" PTR_FORMAT \" in the Coarse table\", p2i(from));\n-      return;\n-    }\n-\n-    \/\/ Confirm that it's really not there...\n-    prt = find_region_table(ind, from_hr);\n-    if (prt == NULL) {\n-\n-      CardIdx_t card_index = card_within_region(from, from_hr);\n-\n-      SparsePRT::AddCardResult result = _sparse_table.add_card(from_hrm_ind, card_index);\n-      if (result != SparsePRT::overflow) {\n-        if (result == SparsePRT::added) {\n-          Atomic::inc(&_num_occupied, memory_order_relaxed);\n-        }\n-        assert(contains_reference_locked(from), \"We just added \" PTR_FORMAT \" to the Sparse table\", p2i(from));\n-        return;\n-      }\n-\n-      \/\/ Sparse PRT returned overflow (sparse table is full)\n-\n-      if (_n_fine_entries == _max_fine_entries) {\n-        prt = delete_region_table(num_added_by_coarsening);\n-        \/\/ There is no need to clear the links to the 'all' list here:\n-        \/\/ prt will be reused immediately, i.e. remain in the 'all' list.\n-        prt->init(from_hr, false \/* clear_links_to_all_list *\/);\n-      } else {\n-        prt = PerRegionTable::alloc(from_hr);\n-        link_to_all(prt);\n-      }\n-\n-      PerRegionTable* first_prt = _fine_grain_regions[ind];\n-      prt->set_collision_list_next(first_prt);\n-      \/\/ The assignment into _fine_grain_regions allows the prt to\n-      \/\/ start being used concurrently. In addition to\n-      \/\/ collision_list_next which must be visible (else concurrent\n-      \/\/ parsing of the list, if any, may fail to see other entries),\n-      \/\/ the content of the prt must be visible (else for instance\n-      \/\/ some mark bits may not yet seem cleared or a 'later' update\n-      \/\/ performed by a concurrent thread could be undone when the\n-      \/\/ zeroing becomes visible). This requires store ordering.\n-      Atomic::release_store(&_fine_grain_regions[ind], prt);\n-      _n_fine_entries++;\n-\n-      \/\/ Transfer from sparse to fine-grain. The cards from the sparse table\n-      \/\/ were already added to the total in _num_occupied.\n-      SparsePRTEntry *sprt_entry = _sparse_table.get_entry(from_hrm_ind);\n-      assert(sprt_entry != NULL, \"There should have been an entry\");\n-      for (int i = 0; i < sprt_entry->num_valid_cards(); i++) {\n-        CardIdx_t c = sprt_entry->card(i);\n-        prt->add_card(c);\n-      }\n-      \/\/ Now we can delete the sparse entry.\n-      bool res = _sparse_table.delete_entry(from_hrm_ind);\n-      assert(res, \"It should have been there.\");\n-    }\n-    assert(prt != NULL && prt->hr() == from_hr, \"consequence\");\n-  }\n-  \/\/ Note that we can't assert \"prt->hr() == from_hr\", because of the\n-  \/\/ possibility of concurrent reuse.  But see head comment of\n-  \/\/ OtherRegionsTable for why this is OK.\n-  assert(prt != NULL, \"Inv\");\n-\n-  if (prt->add_reference(from)) {\n-    num_added_by_coarsening++;\n-  }\n-  Atomic::add(&_num_occupied, num_added_by_coarsening, memory_order_relaxed);\n-  assert(contains_reference(from), \"We just added \" PTR_FORMAT \" to the PRT (%d)\", p2i(from), prt->contains_reference(from));\n-}\n-\n-PerRegionTable*\n-OtherRegionsTable::find_region_table(size_t ind, HeapRegion* hr) const {\n-  assert(ind < _max_fine_entries, \"Preconditions.\");\n-  PerRegionTable* prt = _fine_grain_regions[ind];\n-  while (prt != NULL && prt->hr() != hr) {\n-    prt = prt->collision_list_next();\n-  }\n-  \/\/ Loop postcondition is the method postcondition.\n-  return prt;\n-}\n-\n-jint OtherRegionsTable::_n_coarsenings = 0;\n-\n-PerRegionTable* OtherRegionsTable::delete_region_table(size_t& added_by_deleted) {\n-  assert(_m->owned_by_self(), \"Precondition\");\n-  assert(_n_fine_entries == _max_fine_entries, \"Precondition\");\n-  PerRegionTable* max = NULL;\n-  jint max_occ = 0;\n-  PerRegionTable** max_prev = NULL;\n-\n-  size_t i = _fine_eviction_start;\n-  for (size_t k = 0; k < _fine_eviction_sample_size; k++) {\n-    size_t ii = i;\n-    \/\/ Make sure we get a non-NULL sample.\n-    while (_fine_grain_regions[ii] == NULL) {\n-      ii++;\n-      if (ii == _max_fine_entries) ii = 0;\n-      guarantee(ii != i, \"We must find one.\");\n-    }\n-    PerRegionTable** prev = &_fine_grain_regions[ii];\n-    PerRegionTable* cur = *prev;\n-    while (cur != NULL) {\n-      jint cur_occ = cur->occupied();\n-      if (max == NULL || cur_occ > max_occ) {\n-        max = cur;\n-        max_prev = prev;\n-        max_occ = cur_occ;\n-      }\n-      prev = cur->collision_list_next_addr();\n-      cur = cur->collision_list_next();\n-    }\n-    i = i + _fine_eviction_stride;\n-    if (i >= _n_fine_entries) i = i - _n_fine_entries;\n-  }\n-\n-  _fine_eviction_start++;\n-\n-  if (_fine_eviction_start >= _n_fine_entries) {\n-    _fine_eviction_start -= _n_fine_entries;\n-  }\n-\n-  guarantee(max != NULL, \"Since _n_fine_entries > 0\");\n-  guarantee(max_prev != NULL, \"Since max != NULL.\");\n-\n-  \/\/ Ensure the corresponding coarse bit is set.\n-  size_t max_hrm_index = (size_t) max->hr()->hrm_index();\n-  if (Atomic::load(&_has_coarse_entries)) {\n-    _coarse_map.at_put(max_hrm_index, true);\n-  } else {\n-    \/\/ This will lazily initialize an uninitialized bitmap\n-    _coarse_map.reinitialize(G1CollectedHeap::heap()->max_reserved_regions());\n-    assert(!_coarse_map.at(max_hrm_index), \"No coarse entries\");\n-    _coarse_map.at_put(max_hrm_index, true);\n-    \/\/ Release store guarantees that the bitmap has initialized before any\n-    \/\/ concurrent reader will ever see _has_coarse_entries is true\n-    \/\/ (when read with load_acquire)\n-    Atomic::release_store(&_has_coarse_entries, true);\n-  }\n-\n-  added_by_deleted = HeapRegion::CardsPerRegion - max_occ;\n-  \/\/ Unsplice.\n-  *max_prev = max->collision_list_next();\n-  Atomic::inc(&_n_coarsenings);\n-  _n_fine_entries--;\n-  return max;\n-}\n-\n-bool OtherRegionsTable::occupancy_less_or_equal_than(size_t limit) const {\n-  return occupied() <= limit;\n-}\n-\n-bool OtherRegionsTable::is_empty() const {\n-  return occupied() == 0;\n-}\n-\n-size_t OtherRegionsTable::occupied() const {\n-  return _num_occupied;\n-}\n-\n-size_t OtherRegionsTable::mem_size() const {\n-  size_t sum = 0;\n-  \/\/ all PRTs are of the same size so it is sufficient to query only one of them.\n-  if (_first_all_fine_prts != NULL) {\n-    assert(_last_all_fine_prts != NULL &&\n-      _first_all_fine_prts->mem_size() == _last_all_fine_prts->mem_size(), \"check that mem_size() is constant\");\n-    sum += _first_all_fine_prts->mem_size() * _n_fine_entries;\n-  }\n-  sum += (sizeof(PerRegionTable*) * _max_fine_entries);\n-  sum += (_coarse_map.size_in_words() * HeapWordSize);\n-  sum += (_sparse_table.mem_size());\n-  sum += sizeof(OtherRegionsTable) - sizeof(_sparse_table); \/\/ Avoid double counting above.\n-  return sum;\n-}\n-\n-size_t OtherRegionsTable::static_mem_size() {\n-  return G1FromCardCache::static_mem_size();\n-}\n-\n-size_t OtherRegionsTable::fl_mem_size() {\n-  return PerRegionTable::fl_mem_size();\n-}\n-\n-void OtherRegionsTable::clear() {\n-  \/\/ if there are no entries, skip this step\n-  if (_first_all_fine_prts != NULL) {\n-    guarantee(_first_all_fine_prts != NULL && _last_all_fine_prts != NULL, \"just checking\");\n-    PerRegionTable::bulk_free(_first_all_fine_prts, _last_all_fine_prts);\n-    memset(_fine_grain_regions, 0, _max_fine_entries * sizeof(_fine_grain_regions[0]));\n-  } else {\n-    guarantee(_first_all_fine_prts == NULL && _last_all_fine_prts == NULL, \"just checking\");\n-  }\n-\n-  _first_all_fine_prts = _last_all_fine_prts = NULL;\n-  _sparse_table.clear();\n-  if (Atomic::load(&_has_coarse_entries)) {\n-    _coarse_map.clear();\n-  }\n-  _n_fine_entries = 0;\n-  Atomic::store(&_has_coarse_entries, false);\n-\n-  _num_occupied = 0;\n-}\n-\n-bool OtherRegionsTable::contains_reference(OopOrNarrowOopStar from) const {\n-  \/\/ Cast away const in this case.\n-  MutexLocker x((Mutex*)_m, Mutex::_no_safepoint_check_flag);\n-  return contains_reference_locked(from);\n-}\n-\n-bool OtherRegionsTable::contains_reference_locked(OopOrNarrowOopStar from) const {\n-  HeapRegion* hr = _g1h->heap_region_containing(from);\n-  RegionIdx_t hr_ind = (RegionIdx_t) hr->hrm_index();\n-  \/\/ Is this region in the coarse map?\n-  if (is_region_coarsened(hr_ind)) return true;\n-\n-  PerRegionTable* prt = find_region_table(hr_ind & _mod_max_fine_entries_mask,\n-                                          hr);\n-  if (prt != NULL) {\n-    return prt->contains_reference(from);\n-  } else {\n-    CardIdx_t card_index = card_within_region(from, hr);\n-    return _sparse_table.contains_card(hr_ind, card_index);\n-  }\n-}\n-\n-\/\/ A load_acquire on _has_coarse_entries - coupled with the release_store in\n-\/\/ delete_region_table - guarantees we don't access _coarse_map before\n-\/\/ it's been properly initialized.\n-bool OtherRegionsTable::is_region_coarsened(RegionIdx_t from_hrm_ind) const {\n-  return Atomic::load_acquire(&_has_coarse_entries) && _coarse_map.at(from_hrm_ind);\n-}\n-\n-HeapRegionRemSet::HeapRegionRemSet(G1BlockOffsetTable* bot,\n-                                   HeapRegion* hr)\n-  : _bot(bot),\n-    _code_roots(),\n-    _m(Mutex::leaf, FormatBuffer<128>(\"HeapRegionRemSet lock #%u\", hr->hrm_index()), true, Mutex::_safepoint_check_never),\n-    _other_regions(&_m),\n-    _hr(hr),\n-    _state(Untracked)\n-{\n-}\n+HeapRegionRemSet::HeapRegionRemSet(HeapRegion* hr,\n+                                   G1CardSetConfiguration* config) :\n+  _m(Mutex::leaf + 1, FormatBuffer<128>(\"HeapRegionRemSet lock #%u\", hr->hrm_index()), true, Monitor::_safepoint_check_never),\n+  _code_roots(),\n+  _card_set_mm(config, G1CardSetFreePool::free_list_pool()),\n+  _card_set(config, &_card_set_mm),\n+  _hr(hr),\n+  _state(Untracked) { }\n@@ -398,14 +61,0 @@\n-void HeapRegionRemSet::setup_remset_size() {\n-  const int LOG_M = 20;\n-  guarantee(HeapRegion::LogOfHRGrainBytes >= LOG_M, \"Code assumes the region size >= 1M, but is \" SIZE_FORMAT \"B\", HeapRegion::GrainBytes);\n-\n-  int region_size_log_mb = HeapRegion::LogOfHRGrainBytes - LOG_M;\n-  if (FLAG_IS_DEFAULT(G1RSetSparseRegionEntries)) {\n-    G1RSetSparseRegionEntries = G1RSetSparseRegionEntriesBase * ((size_t)1 << (region_size_log_mb + 1));\n-  }\n-  if (FLAG_IS_DEFAULT(G1RSetRegionEntries)) {\n-    G1RSetRegionEntries = G1RSetRegionEntriesBase * (region_size_log_mb + 1);\n-  }\n-  guarantee(G1RSetSparseRegionEntries > 0 && G1RSetRegionEntries > 0 , \"Sanity\");\n-}\n-\n@@ -422,1 +71,1 @@\n-  _other_regions.clear();\n+  _card_set.clear();\n@@ -427,0 +76,4 @@\n+void HeapRegionRemSet::print_static_mem_size(outputStream* out) {\n+  out->print_cr(\"  Static structures = \" SIZE_FORMAT, HeapRegionRemSet::static_mem_size());\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.cpp","additions":15,"deletions":362,"binary":false,"changes":377,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,2 @@\n+#include \"gc\/g1\/g1CardSet.hpp\"\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n@@ -30,1 +32,0 @@\n-#include \"gc\/g1\/sparsePRT.hpp\"\n@@ -32,0 +33,1 @@\n+#include \"runtime\/safepoint.hpp\"\n@@ -34,240 +36,1 @@\n-\/\/ Remembered set for a heap region.  Represent a set of \"cards\" that\n-\/\/ contain pointers into the owner heap region.  Cards are defined somewhat\n-\/\/ abstractly, in terms of what the \"BlockOffsetTable\" in use can parse.\n-\n-class G1CollectedHeap;\n-class G1BlockOffsetTable;\n-class G1CardLiveData;\n-class HeapRegion;\n-class PerRegionTable;\n-class SparsePRT;\n-class nmethod;\n-\n-\/\/ The \"_coarse_map\" is a bitmap with one bit for each region, where set\n-\/\/ bits indicate that the corresponding region may contain some pointer\n-\/\/ into the owning region.\n-\n-\/\/ The \"_fine_grain_entries\" array is an open hash table of PerRegionTables\n-\/\/ (PRTs), indicating regions for which we're keeping the RS as a set of\n-\/\/ cards.  The strategy is to cap the size of the fine-grain table,\n-\/\/ deleting an entry and setting the corresponding coarse-grained bit when\n-\/\/ we would overflow this cap.\n-\n-\/\/ We use a mixture of locking and lock-free techniques here.  We allow\n-\/\/ threads to locate PRTs without locking, but threads attempting to alter\n-\/\/ a bucket list obtain a lock.  This means that any failing attempt to\n-\/\/ find a PRT must be retried with the lock.  It might seem dangerous that\n-\/\/ a read can find a PRT that is concurrently deleted.  This is all right,\n-\/\/ because:\n-\/\/\n-\/\/   1) We only actually free PRT's at safe points (though we reuse them at\n-\/\/      other times).\n-\/\/   2) We find PRT's in an attempt to add entries.  If a PRT is deleted,\n-\/\/      it's _coarse_map bit is set, so the that we were attempting to add\n-\/\/      is represented.  If a deleted PRT is re-used, a thread adding a bit,\n-\/\/      thinking the PRT is for a different region, does no harm.\n-\n-class OtherRegionsTable {\n-  G1CollectedHeap* _g1h;\n-  Mutex*           _m;\n-\n-  size_t volatile _num_occupied;\n-\n-  \/\/ These are protected by \"_m\".\n-  CHeapBitMap   _coarse_map;\n-  bool volatile _has_coarse_entries;\n-  static jint   _n_coarsenings;\n-\n-  PerRegionTable** _fine_grain_regions;\n-  size_t           _n_fine_entries;\n-\n-  \/\/ The fine grain remembered sets are linked together using\n-  \/\/ their 'next' fields.\n-  \/\/ This allows fast bulk freeing of all the fine grain remembered\n-  \/\/ set entries, and fast finding of all of them without iterating\n-  \/\/ over the _fine_grain_regions table.\n-  PerRegionTable * _first_all_fine_prts;\n-  PerRegionTable * _last_all_fine_prts;\n-\n-  \/\/ Used to sample a subset of the fine grain PRTs to determine which\n-  \/\/ PRT to evict and coarsen.\n-  size_t        _fine_eviction_start;\n-  static size_t _fine_eviction_stride;\n-  static size_t _fine_eviction_sample_size;\n-\n-  SparsePRT   _sparse_table;\n-\n-  \/\/ These are static after init.\n-  static size_t _max_fine_entries;\n-  static size_t _mod_max_fine_entries_mask;\n-\n-  \/\/ Requires \"prt\" to be the first element of the bucket list appropriate\n-  \/\/ for \"hr\".  If this list contains an entry for \"hr\", return it,\n-  \/\/ otherwise return \"NULL\".\n-  PerRegionTable* find_region_table(size_t ind, HeapRegion* hr) const;\n-\n-  \/\/ Find, delete, and return a candidate PerRegionTable, if any exists,\n-  \/\/ adding the deleted region to the coarse bitmap.  Requires the caller\n-  \/\/ to hold _m, and the fine-grain table to be full.\n-  PerRegionTable* delete_region_table(size_t& added_by_deleted);\n-\n-  \/\/ link\/add the given fine grain remembered set into the \"all\" list\n-  void link_to_all(PerRegionTable * prt);\n-\n-  bool contains_reference_locked(OopOrNarrowOopStar from) const;\n-\n-public:\n-  \/\/ Create a new remembered set. The given mutex is used to ensure consistency.\n-  OtherRegionsTable(Mutex* m);\n-\n-  template <class Closure>\n-  void iterate(Closure& v);\n-\n-  \/\/ Returns the card index of the given within_region pointer relative to the bottom\n-  \/\/ of the given heap region.\n-  static CardIdx_t card_within_region(OopOrNarrowOopStar within_region, HeapRegion* hr);\n-  \/\/ Adds the reference from \"from to this remembered set.\n-  void add_reference(OopOrNarrowOopStar from, uint tid);\n-\n-  \/\/ Returns whether the remembered set contains the given reference.\n-  bool contains_reference(OopOrNarrowOopStar from) const;\n-\n-  \/\/ Returns whether this remembered set (and all sub-sets) have an occupancy\n-  \/\/ that is less or equal than the given occupancy.\n-  bool occupancy_less_or_equal_than(size_t limit) const;\n-\n-  \/\/ Returns whether this remembered set (and all sub-sets) does not contain any entry.\n-  bool is_empty() const;\n-\n-  \/\/ Returns the number of cards contained in this remembered set.\n-  size_t occupied() const;\n-\n-  static jint n_coarsenings() { return _n_coarsenings; }\n-\n-  \/\/ Returns size of the actual remembered set containers in bytes.\n-  size_t mem_size() const;\n-  \/\/ Returns the size of static data in bytes.\n-  static size_t static_mem_size();\n-  \/\/ Returns the size of the free list content in bytes.\n-  static size_t fl_mem_size();\n-\n-  \/\/ Clear the entire contents of this remembered set.\n-  void clear();\n-\n-  \/\/ Safe for use by concurrent readers outside _m\n-  bool is_region_coarsened(RegionIdx_t from_hrm_ind) const;\n-};\n-\n-class PerRegionTable: public CHeapObj<mtGC> {\n-  friend class OtherRegionsTable;\n-\n-  HeapRegion*     _hr;\n-  CHeapBitMap     _bm;\n-  jint            _occupied;\n-\n-  \/\/ next pointer for free\/allocated 'all' list\n-  PerRegionTable* _next;\n-\n-  \/\/ next pointer in collision list\n-  PerRegionTable * _collision_list_next;\n-\n-  \/\/ Global free list of PRTs\n-  static PerRegionTable* volatile _free_list;\n-\n-protected:\n-  PerRegionTable(HeapRegion* hr) :\n-    _hr(hr),\n-    _bm(HeapRegion::CardsPerRegion, mtGC),\n-    _occupied(0),\n-    _next(NULL),\n-    _collision_list_next(NULL)\n-  {}\n-\n-public:\n-  \/\/ We need access in order to union things into the base table.\n-  BitMap* bm() { return &_bm; }\n-\n-  HeapRegion* hr() const { return Atomic::load_acquire(&_hr); }\n-\n-  jint occupied() const {\n-    return _occupied;\n-  }\n-\n-  void init(HeapRegion* hr, bool clear_links_to_all_list);\n-\n-  inline bool add_reference(OopOrNarrowOopStar from);\n-\n-  inline bool add_card(CardIdx_t from_card_index);\n-\n-  \/\/ (Destructively) union the bitmap of the current table into the given\n-  \/\/ bitmap (which is assumed to be of the same size.)\n-  void union_bitmap_into(BitMap* bm) {\n-    bm->set_union(_bm);\n-  }\n-\n-  \/\/ Mem size in bytes.\n-  size_t mem_size() const {\n-    return sizeof(PerRegionTable) + _bm.size_in_words() * HeapWordSize;\n-  }\n-\n-  \/\/ Requires \"from\" to be in \"hr()\".\n-  bool contains_reference(OopOrNarrowOopStar from) const {\n-    assert(hr()->is_in_reserved(from), \"Precondition.\");\n-    size_t card_ind = pointer_delta(from, hr()->bottom(),\n-                                    G1CardTable::card_size);\n-    return _bm.at(card_ind);\n-  }\n-\n-  \/\/ Bulk-free the PRTs from prt to last, assumes that they are\n-  \/\/ linked together using their _next field.\n-  static void bulk_free(PerRegionTable* prt, PerRegionTable* last) {\n-    while (true) {\n-      PerRegionTable* fl = _free_list;\n-      last->set_next(fl);\n-      PerRegionTable* res = Atomic::cmpxchg(&_free_list, fl, prt);\n-      if (res == fl) {\n-        return;\n-      }\n-    }\n-    ShouldNotReachHere();\n-  }\n-\n-  static void free(PerRegionTable* prt) {\n-    bulk_free(prt, prt);\n-  }\n-\n-  \/\/ Returns an initialized PerRegionTable instance.\n-  static PerRegionTable* alloc(HeapRegion* hr);\n-\n-  PerRegionTable* next() const { return _next; }\n-  void set_next(PerRegionTable* next) { _next = next; }\n-\n-  \/\/ Accessor and Modification routines for the pointer for the\n-  \/\/ singly linked collision list that links the PRTs within the\n-  \/\/ OtherRegionsTable::_fine_grain_regions hash table.\n-  \/\/\n-\n-  PerRegionTable* collision_list_next() const {\n-    return _collision_list_next;\n-  }\n-\n-  void set_collision_list_next(PerRegionTable* next) {\n-    _collision_list_next = next;\n-  }\n-\n-  PerRegionTable** collision_list_next_addr() {\n-    return &_collision_list_next;\n-  }\n-\n-  static size_t fl_mem_size() {\n-    PerRegionTable* cur = _free_list;\n-    size_t res = 0;\n-    while (cur != NULL) {\n-      res += cur->mem_size();\n-      cur = cur->next();\n-    }\n-    return res;\n-  }\n-\n-  static void test_fl_mem_size();\n-};\n+class outputStream;\n@@ -278,3 +41,1 @@\n-private:\n-  G1BlockOffsetTable* _bot;\n-\n+  Mutex _m;\n@@ -285,1 +46,1 @@\n-  Mutex _m;\n+  G1CardSetMemoryManager _card_set_mm;\n@@ -287,1 +48,2 @@\n-  OtherRegionsTable _other_regions;\n+  \/\/ The set of cards in the Java heap\n+  G1CardSet _card_set;\n@@ -291,0 +53,1 @@\n+  inline void split_card(OopOrNarrowOopStar from, uint& card_region, uint& card_within_region) const;\n@@ -294,1 +57,1 @@\n-  HeapRegionRemSet(G1BlockOffsetTable* bot, HeapRegion* hr);\n+  HeapRegionRemSet(HeapRegion* hr, G1CardSetConfiguration* config);\n@@ -297,1 +60,3 @@\n-  static void setup_remset_size();\n+  bool cardset_is_empty() const {\n+    return _card_set.is_empty();\n+  }\n@@ -300,1 +65,1 @@\n-    return (strong_code_roots_list_length() == 0) && _other_regions.is_empty();\n+    return (strong_code_roots_list_length() == 0) && cardset_is_empty();\n@@ -304,1 +69,1 @@\n-    return (strong_code_roots_list_length() == 0) && _other_regions.occupancy_less_or_equal_than(occ);\n+    return (strong_code_roots_list_length() == 0) && _card_set.occupied() <= occ;\n@@ -307,8 +72,5 @@\n-  \/\/ For each PRT in the card (remembered) set call one of the following methods\n-  \/\/ of the given closure:\n-  \/\/\n-  \/\/ set_full_region_dirty(uint region_idx) - pass the region index for coarse PRTs\n-  \/\/ set_bitmap_dirty(uint region_idx, BitMap* bitmap) - pass the region index and bitmap for fine PRTs\n-  \/\/ set_cards_dirty(uint region_idx, elem_t* cards, uint num_cards) - pass region index and cards for sparse PRTs\n-  template <class Closure>\n-  inline void iterate_prts(Closure& cl);\n+  \/\/ Iterate the card based remembered set for merging them into the card table.\n+  \/\/ The passed closure must be a CardOrRangeVisitor; we use a template parameter\n+  \/\/ to pass it in to facilitate inlining as much as possible.\n+  template <class CardOrRangeVisitor>\n+  inline void iterate_for_merge(CardOrRangeVisitor& cl);\n@@ -317,1 +79,1 @@\n-    return _other_regions.occupied();\n+    return _card_set.occupied();\n@@ -320,1 +82,4 @@\n-  static jint n_coarsenings() { return OtherRegionsTable::n_coarsenings(); }\n+  \/\/ Coarsening statistics since VM start.\n+  static G1CardSetCoarsenStats coarsen_stats() { return G1CardSet::coarsen_stats(); }\n+\n+  G1CardSetConfiguration* config() const { return _card_set.config(); }\n@@ -342,8 +107,3 @@\n-  void set_state_empty() {\n-    guarantee(SafepointSynchronize::is_at_safepoint() || !is_tracked(), \"Should only set to Untracked during safepoint but is %s.\", get_state_str());\n-    if (_state == Untracked) {\n-      return;\n-    }\n-    clear_fcc();\n-    _state = Untracked;\n-  }\n+  inline void set_state_empty();\n+  inline void set_state_updating();\n+  inline void set_state_complete();\n@@ -351,27 +111,1 @@\n-  void set_state_updating() {\n-    guarantee(SafepointSynchronize::is_at_safepoint() && !is_tracked(), \"Should only set to Updating from Untracked during safepoint but is %s\", get_state_str());\n-    clear_fcc();\n-    _state = Updating;\n-  }\n-\n-  void set_state_complete() {\n-    clear_fcc();\n-    _state = Complete;\n-  }\n-\n-  void add_reference(OopOrNarrowOopStar from, uint tid) {\n-    RemSetState state = _state;\n-    if (state == Untracked) {\n-      return;\n-    }\n-\n-    uint cur_idx = _hr->hrm_index();\n-    uintptr_t from_card = uintptr_t(from) >> CardTable::card_shift;\n-\n-    if (G1FromCardCache::contains_or_replace(tid, cur_idx, from_card)) {\n-      assert(contains_reference(from), \"We just found \" PTR_FORMAT \" in the FromCardCache\", p2i(from));\n-      return;\n-    }\n-\n-    _other_regions.add_reference(from, tid);\n-  }\n+  inline void add_reference(OopOrNarrowOopStar from, uint tid);\n@@ -384,2 +118,4 @@\n-  \/\/ The actual # of bytes this hr_remset takes up.\n-  \/\/ Note also includes the strong code root set.\n+  G1CardSetMemoryStats card_set_memory_stats() const { return _card_set_mm.memory_stats(); }\n+\n+  \/\/ The actual # of bytes this hr_remset takes up. Also includes the strong code\n+  \/\/ root set.\n@@ -387,2 +123,1 @@\n-    MutexLocker x(&_m, Mutex::_no_safepoint_check_flag);\n-    return _other_regions.mem_size()\n+    return _card_set.mem_size()\n@@ -391,1 +126,1 @@\n-      + (sizeof(HeapRegionRemSet) - sizeof(OtherRegionsTable))\n+      + (sizeof(HeapRegionRemSet) - sizeof(G1CardSet))\n@@ -395,0 +130,4 @@\n+  size_t wasted_mem_size() {\n+    return _card_set.wasted_mem_size();\n+  }\n+\n@@ -398,1 +137,1 @@\n-    return OtherRegionsTable::static_mem_size() + G1CodeRootSet::static_mem_size();\n+    return G1CardSet::static_mem_size() + G1CodeRootSet::static_mem_size() + sizeof(G1CardSetFreePool);\n@@ -403,3 +142,1 @@\n-  static size_t fl_mem_size() {\n-    return OtherRegionsTable::fl_mem_size();\n-  }\n+  static size_t free_list_mem_size();\n@@ -407,3 +144,5 @@\n-  bool contains_reference(OopOrNarrowOopStar from) const {\n-    return _other_regions.contains_reference(from);\n-  }\n+  static void print_static_mem_size(outputStream* out);\n+\n+  inline bool contains_reference(OopOrNarrowOopStar from);\n+\n+  inline void print_info(outputStream* st, OopOrNarrowOopStar from);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.hpp","additions":47,"deletions":308,"binary":false,"changes":355,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,2 @@\n+#include \"gc\/g1\/g1CardSet.inline.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -31,1 +33,0 @@\n-#include \"gc\/g1\/sparsePRT.hpp\"\n@@ -35,3 +36,8 @@\n-template <class Closure>\n-inline void HeapRegionRemSet::iterate_prts(Closure& cl) {\n-  _other_regions.iterate(cl);\n+void HeapRegionRemSet::set_state_empty() {\n+  guarantee(SafepointSynchronize::is_at_safepoint() || !is_tracked(),\n+            \"Should only set to Untracked during safepoint but is %s.\", get_state_str());\n+  if (_state == Untracked) {\n+    return;\n+  }\n+  clear_fcc();\n+  _state = Untracked;\n@@ -40,6 +46,5 @@\n-inline bool PerRegionTable::add_card(CardIdx_t from_card_index) {\n-  if (_bm.par_set_bit(from_card_index)) {\n-    Atomic::inc(&_occupied, memory_order_relaxed);\n-    return true;\n-  }\n-  return false;\n+void HeapRegionRemSet::set_state_updating() {\n+  guarantee(SafepointSynchronize::is_at_safepoint() && !is_tracked(),\n+            \"Should only set to Updating from Untracked during safepoint but is %s\", get_state_str());\n+  clear_fcc();\n+  _state = Updating;\n@@ -48,13 +53,3 @@\n-inline bool PerRegionTable::add_reference(OopOrNarrowOopStar from) {\n-  \/\/ Must make this robust in case \"from\" is not in \"_hr\", because of\n-  \/\/ concurrency.\n-\n-  HeapRegion* loc_hr = hr();\n-  \/\/ If the test below fails, then this table was reused concurrently\n-  \/\/ with this operation.  This is OK, since the old table was coarsened,\n-  \/\/ and adding a bit to the new table is never incorrect.\n-  if (loc_hr->is_in_reserved(from)) {\n-    CardIdx_t from_card = OtherRegionsTable::card_within_region(from, loc_hr);\n-    return add_card(from_card);\n-  }\n-  return false;\n+void HeapRegionRemSet::set_state_complete() {\n+  clear_fcc();\n+  _state = Complete;\n@@ -63,10 +58,4 @@\n-inline void PerRegionTable::init(HeapRegion* hr, bool clear_links_to_all_list) {\n-  if (clear_links_to_all_list) {\n-    set_next(NULL);\n-  }\n-  _collision_list_next = NULL;\n-  _occupied = 0;\n-  _bm.clear();\n-  \/\/ Make sure that the bitmap clearing above has been finished before publishing\n-  \/\/ this PRT to concurrent threads.\n-  Atomic::release_store(&_hr, hr);\n+\n+template <class CardOrRangeVisitor>\n+inline void HeapRegionRemSet::iterate_for_merge(CardOrRangeVisitor& cl) {\n+  _card_set.iterate_for_merge(cl);\n@@ -75,15 +64,10 @@\n-template <class Closure>\n-void OtherRegionsTable::iterate(Closure& cl) {\n-  if (Atomic::load(&_has_coarse_entries)) {\n-    BitMap::idx_t cur = _coarse_map.get_next_one_offset(0);\n-    while (cur != _coarse_map.size()) {\n-      cl.next_coarse_prt((uint)cur);\n-      cur = _coarse_map.get_next_one_offset(cur + 1);\n-    }\n-  }\n-  {\n-    PerRegionTable* cur = _first_all_fine_prts;\n-    while (cur != NULL) {\n-      cl.next_fine_prt(cur->hr()->hrm_index(), cur->bm());\n-      cur = cur->next();\n-    }\n+void HeapRegionRemSet::split_card(OopOrNarrowOopStar from, uint& card_region, uint& card_within_region) const {\n+  HeapRegion* hr = G1CollectedHeap::heap()->heap_region_containing(from);\n+  card_region = hr->hrm_index();\n+  card_within_region = (uint)(pointer_delta((HeapWord*)from, hr->bottom()) >> (CardTable::card_shift - LogHeapWordSize));\n+}\n+\n+void HeapRegionRemSet::add_reference(OopOrNarrowOopStar from, uint tid) {\n+  RemSetState state = _state;\n+  if (state == Untracked) {\n+    return;\n@@ -91,6 +75,9 @@\n-  {\n-    SparsePRTBucketIter iter(&_sparse_table);\n-    SparsePRTEntry* cur;\n-    while (iter.has_next(cur)) {\n-      cl.next_sparse_prt(cur->r_ind(), cur->cards(), cur->num_valid_cards());\n-    }\n+\n+  uint cur_idx = _hr->hrm_index();\n+  uintptr_t from_card = uintptr_t(from) >> CardTable::card_shift;\n+\n+  if (G1FromCardCache::contains_or_replace(tid, cur_idx, from_card)) {\n+    \/\/ We can't check whether the card is in the remembered set - the card container\n+    \/\/ may be coarsened just now.\n+    \/\/assert(contains_reference(from), \"We just found \" PTR_FORMAT \" in the FromCardCache\", p2i(from));\n+   return;\n@@ -98,0 +85,25 @@\n+\n+  uint card_region;\n+  uint card_within_region;\n+\n+  split_card(from, card_region, card_within_region);\n+\n+  _card_set.add_card(card_region, card_within_region);\n+}\n+\n+bool HeapRegionRemSet::contains_reference(OopOrNarrowOopStar from) {\n+  uint card_region;\n+  uint card_within_region;\n+\n+  split_card(from, card_region, card_within_region);\n+\n+  return _card_set.contains_card(card_region, card_within_region);\n+}\n+\n+void HeapRegionRemSet::print_info(outputStream* st, OopOrNarrowOopStar from) {\n+  uint card_region;\n+  uint card_within_region;\n+\n+  split_card(from, card_region, card_within_region);\n+\n+  _card_set.print_info(st, card_region, card_within_region);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.inline.hpp","additions":67,"deletions":55,"binary":false,"changes":122,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionSet.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-JVMFlag::Error G1RSetRegionEntriesConstraintFunc(intx value, bool verbose) {\n+JVMFlag::Error G1RemSetArrayOfCardsEntriesConstraintFunc(uint value, bool verbose) {\n@@ -34,1 +34,1 @@\n-  \/\/ Default value of G1RSetRegionEntries=0 means will be set ergonomically.\n+  \/\/ Default value of G1RemSetArrayOfCardsEntries=0 means will be set ergonomically.\n@@ -36,1 +36,1 @@\n-  if (FLAG_IS_CMDLINE(G1RSetRegionEntries) && (value < 1)) {\n+  if (FLAG_IS_CMDLINE(G1RemSetArrayOfCardsEntries) && (value < 1)) {\n@@ -38,2 +38,2 @@\n-                        \"G1RSetRegionEntries (\" INTX_FORMAT \") must be \"\n-                        \"greater than or equal to 1\\n\",\n+                        \"G1RemSetArrayOfCardsEntries (%u) must be \"\n+                        \"greater than or equal to 1.\\n\",\n@@ -47,1 +47,1 @@\n-JVMFlag::Error G1RSetSparseRegionEntriesConstraintFunc(intx value, bool verbose) {\n+JVMFlag::Error G1RemSetHowlNumBucketsConstraintFunc(uint value, bool verbose) {\n@@ -50,3 +50,4 @@\n-  \/\/ Default value of G1RSetSparseRegionEntries=0 means will be set ergonomically.\n-  \/\/ Minimum value is 1.\n-  if (FLAG_IS_CMDLINE(G1RSetSparseRegionEntries) && (value < 1)) {\n+  if (!FLAG_IS_CMDLINE(G1RemSetHowlNumBuckets)) {\n+    return JVMFlag::SUCCESS;\n+  }\n+  if (value == 0 || !is_power_of_2(G1RemSetHowlNumBuckets)) {\n@@ -54,2 +55,2 @@\n-                        \"G1RSetSparseRegionEntries (\" INTX_FORMAT \") must be \"\n-                        \"greater than or equal to 1\\n\",\n+                        \"G1RemSetHowlNumBuckets (%u) must be a power of two \"\n+                        \"and greater than or equal to 1.\\n\",\n@@ -58,1 +59,8 @@\n-  } else {\n+  }\n+  return JVMFlag::SUCCESS;\n+}\n+\n+JVMFlag::Error G1RemSetHowlMaxNumBucketsConstraintFunc(uint value, bool verbose) {\n+  if (!UseG1GC) return JVMFlag::SUCCESS;\n+\n+  if (!FLAG_IS_CMDLINE(G1RemSetHowlMaxNumBuckets)) {\n@@ -61,0 +69,7 @@\n+  if (!is_power_of_2(G1RemSetHowlMaxNumBuckets)) {\n+    JVMFlag::printError(verbose,\n+                        \"G1RemSetMaxHowlNumBuckets (%u) must be a power of two.\\n\",\n+                        value);\n+    return JVMFlag::VIOLATES_CONSTRAINT;\n+  }\n+  return JVMFlag::SUCCESS;\n","filename":"src\/hotspot\/share\/gc\/g1\/jvmFlagConstraintsG1.cpp","additions":27,"deletions":12,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -33,3 +33,6 @@\n-  \/* G1 Flag Constraints *\/                           \\\n-  f(intx,   G1RSetRegionEntriesConstraintFunc)        \\\n-  f(intx,   G1RSetSparseRegionEntriesConstraintFunc)  \\\n+  \/* G1 Remembered Sets Constraints *\/                \\\n+  f(uint,   G1RemSetArrayOfCardsEntriesConstraintFunc)\\\n+  f(uint,   G1RemSetHowlMaxNumBucketsConstraintFunc)  \\\n+  f(uint,   G1RemSetHowlNumBucketsConstraintFunc)     \\\n+                                                      \\\n+  \/* G1 Heap Size Constraints *\/                      \\\n","filename":"src\/hotspot\/share\/gc\/g1\/jvmFlagConstraintsG1.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1,311 +0,0 @@\n-\/*\n- * Copyright (c) 2001, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"gc\/g1\/heapRegion.hpp\"\n-#include \"gc\/g1\/heapRegionBounds.inline.hpp\"\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n-#include \"gc\/g1\/sparsePRT.hpp\"\n-#include \"gc\/shared\/cardTableBarrierSet.hpp\"\n-#include \"gc\/shared\/space.inline.hpp\"\n-#include \"memory\/allocation.inline.hpp\"\n-\n-\/\/ Check that the size of the SparsePRTEntry is evenly divisible by the maximum\n-\/\/ member type to avoid SIGBUS when accessing them.\n-STATIC_ASSERT(sizeof(SparsePRTEntry) % sizeof(int) == 0);\n-\n-void SparsePRTEntry::init(RegionIdx_t region_ind) {\n-  \/\/ Check that the card array element type can represent all cards in the region.\n-  \/\/ Choose a large SparsePRTEntry::card_elem_t (e.g. CardIdx_t) if required.\n-  assert(((size_t)1 << (sizeof(SparsePRTEntry::card_elem_t) * BitsPerByte)) *\n-         G1CardTable::card_size >= HeapRegionBounds::max_size(), \"precondition\");\n-  assert(G1RSetSparseRegionEntries > 0, \"precondition\");\n-  _region_ind = region_ind;\n-  _next_index = RSHashTable::NullEntry;\n-  _next_null = 0;\n-}\n-\n-bool SparsePRTEntry::contains_card(CardIdx_t card_index) const {\n-  for (int i = 0; i < num_valid_cards(); i++) {\n-    if (card(i) == card_index) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n-SparsePRT::AddCardResult SparsePRTEntry::add_card(CardIdx_t card_index) {\n-  for (int i = 0; i < num_valid_cards(); i++) {\n-    if (card(i) == card_index) {\n-      return SparsePRT::found;\n-    }\n-  }\n-  if (num_valid_cards() < cards_num() - 1) {\n-    _cards[_next_null] = (card_elem_t)card_index;\n-    _next_null++;\n-    return SparsePRT::added;\n-   }\n-  \/\/ Otherwise, we're full.\n-  return SparsePRT::overflow;\n-}\n-\n-void SparsePRTEntry::copy_cards(card_elem_t* cards) const {\n-  memcpy(cards, _cards, cards_num() * sizeof(card_elem_t));\n-}\n-\n-void SparsePRTEntry::copy_cards(SparsePRTEntry* e) const {\n-  copy_cards(e->_cards);\n-  assert(_next_null >= 0, \"invariant\");\n-  assert(_next_null <= cards_num(), \"invariant\");\n-  e->_next_null = _next_null;\n-}\n-\n-\/\/ ----------------------------------------------------------------------\n-\n-float RSHashTable::TableOccupancyFactor = 0.5f;\n-\n-\/\/ The empty table can't hold any entries and is effectively immutable\n-\/\/ This means it can be used as an initial sentinel value\n-static int empty_buckets[] = { RSHashTable::NullEntry };\n-RSHashTable RSHashTable::empty_table;\n-\n-RSHashTable::RSHashTable() :\n-  _num_entries(0),\n-  _capacity(0),\n-  _capacity_mask(0),\n-  _occupied_entries(0),\n-  _entries(NULL),\n-  _buckets(empty_buckets),\n-  _free_region(0),\n-  _free_list(NullEntry) { }\n-\n-RSHashTable::RSHashTable(size_t capacity) :\n-  _num_entries((capacity * TableOccupancyFactor) + 1),\n-  _capacity(capacity),\n-  _capacity_mask(capacity - 1),\n-  _occupied_entries(0),\n-  _entries((SparsePRTEntry*)NEW_C_HEAP_ARRAY(char, _num_entries * SparsePRTEntry::size(), mtGC)),\n-  _buckets(NEW_C_HEAP_ARRAY(int, capacity, mtGC)),\n-  _free_region(0),\n-  _free_list(NullEntry)\n-{\n-  clear();\n-}\n-\n-RSHashTable::~RSHashTable() {\n-  \/\/ Nothing to free for empty RSHashTable\n-  if (_buckets != empty_buckets) {\n-    assert(_entries != NULL, \"invariant\");\n-    FREE_C_HEAP_ARRAY(SparsePRTEntry, _entries);\n-    FREE_C_HEAP_ARRAY(int, _buckets);\n-  }\n-}\n-\n-void RSHashTable::clear() {\n-  assert(_buckets != empty_buckets, \"Shouldn't call this for the empty_table\");\n-  _occupied_entries = 0;\n-  guarantee(_entries != NULL, \"invariant\");\n-  guarantee(_buckets != NULL, \"invariant\");\n-\n-  guarantee(_capacity <= ((size_t)1 << (sizeof(int)*BitsPerByte-1)) - 1,\n-                \"_capacity too large\");\n-\n-  \/\/ This will put -1 == NullEntry in the key field of all entries.\n-  memset((void*)_entries, NullEntry, _num_entries * SparsePRTEntry::size());\n-  memset((void*)_buckets, NullEntry, _capacity * sizeof(int));\n-  _free_list = NullEntry;\n-  _free_region = 0;\n-}\n-\n-SparsePRT::AddCardResult RSHashTable::add_card(RegionIdx_t region_ind, CardIdx_t card_index) {\n-  assert(this != &empty_table, \"can't add a card to the empty table\");\n-  SparsePRTEntry* e = entry_for_region_ind_create(region_ind);\n-  assert(e != NULL && e->r_ind() == region_ind,\n-         \"Postcondition of call above.\");\n-  SparsePRT::AddCardResult res = e->add_card(card_index);\n-  assert(e->num_valid_cards() > 0, \"Postcondition\");\n-  return res;\n-}\n-\n-SparsePRTEntry* RSHashTable::get_entry(RegionIdx_t region_ind) const {\n-  int ind = (int) (region_ind & capacity_mask());\n-  int cur_ind = _buckets[ind];\n-  SparsePRTEntry* cur;\n-  while (cur_ind != NullEntry &&\n-         (cur = entry(cur_ind))->r_ind() != region_ind) {\n-    cur_ind = cur->next_index();\n-  }\n-\n-  if (cur_ind == NullEntry) return NULL;\n-  \/\/ Otherwise...\n-  assert(cur->r_ind() == region_ind, \"Postcondition of loop + test above.\");\n-  assert(cur->num_valid_cards() > 0, \"Inv\");\n-  return cur;\n-}\n-\n-bool RSHashTable::delete_entry(RegionIdx_t region_ind) {\n-  int ind = (int) (region_ind & capacity_mask());\n-  int* prev_loc = &_buckets[ind];\n-  int cur_ind = *prev_loc;\n-  SparsePRTEntry* cur;\n-  while (cur_ind != NullEntry &&\n-         (cur = entry(cur_ind))->r_ind() != region_ind) {\n-    prev_loc = cur->next_index_addr();\n-    cur_ind = *prev_loc;\n-  }\n-\n-  if (cur_ind == NullEntry) return false;\n-  \/\/ Otherwise, splice out \"cur\".\n-  *prev_loc = cur->next_index();\n-  free_entry(cur_ind);\n-  _occupied_entries--;\n-  return true;\n-}\n-\n-SparsePRTEntry*\n-RSHashTable::entry_for_region_ind_create(RegionIdx_t region_ind) {\n-  SparsePRTEntry* res = get_entry(region_ind);\n-  if (res == NULL) {\n-    int new_ind = alloc_entry();\n-    res = entry(new_ind);\n-    res->init(region_ind);\n-    \/\/ Insert at front.\n-    int ind = (int) (region_ind & capacity_mask());\n-    res->set_next_index(_buckets[ind]);\n-    _buckets[ind] = new_ind;\n-    _occupied_entries++;\n-  }\n-  return res;\n-}\n-\n-int RSHashTable::alloc_entry() {\n-  int res;\n-  if (_free_list != NullEntry) {\n-    res = _free_list;\n-    _free_list = entry(res)->next_index();\n-    return res;\n-  } else if ((size_t)_free_region < _num_entries) {\n-    res = _free_region;\n-    _free_region++;\n-    return res;\n-  } else {\n-    return NullEntry;\n-  }\n-}\n-\n-void RSHashTable::free_entry(int fi) {\n-  entry(fi)->set_next_index(_free_list);\n-  _free_list = fi;\n-}\n-\n-void RSHashTable::add_entry(SparsePRTEntry* e) {\n-  assert(e->num_valid_cards() > 0, \"Precondition.\");\n-  SparsePRTEntry* e2 = entry_for_region_ind_create(e->r_ind());\n-  e->copy_cards(e2);\n-  assert(e2->num_valid_cards() > 0, \"Postcondition.\");\n-}\n-\n-bool RSHashTableBucketIter::has_next(SparsePRTEntry*& entry) {\n-  while (_bl_ind == RSHashTable::NullEntry)  {\n-    if (_tbl_ind + 1 >= _rsht->capacity()) {\n-      return false;\n-    }\n-    _tbl_ind++;\n-    _bl_ind = _rsht->_buckets[_tbl_ind];\n-  }\n-  entry = _rsht->entry(_bl_ind);\n-  _bl_ind = entry->next_index();\n-  return true;\n-}\n-\n-bool RSHashTable::contains_card(RegionIdx_t region_index, CardIdx_t card_index) const {\n-  SparsePRTEntry* e = get_entry(region_index);\n-  return (e != NULL && e->contains_card(card_index));\n-}\n-\n-size_t RSHashTable::mem_size() const {\n-  return sizeof(RSHashTable) +\n-    _num_entries * (SparsePRTEntry::size() + sizeof(int));\n-}\n-\n-\/\/ ----------------------------------------------------------------------\n-\n-SparsePRT::SparsePRT() :\n-  _table(&RSHashTable::empty_table) {\n-}\n-\n-\n-SparsePRT::~SparsePRT() {\n-  if (_table != &RSHashTable::empty_table) {\n-    delete _table;\n-  }\n-}\n-\n-\n-size_t SparsePRT::mem_size() const {\n-  \/\/ We ignore \"_cur\" here, because it either = _next, or else it is\n-  \/\/ on the deleted list.\n-  return sizeof(SparsePRT) + _table->mem_size();\n-}\n-\n-SparsePRT::AddCardResult SparsePRT::add_card(RegionIdx_t region_id, CardIdx_t card_index) {\n-  if (_table->should_expand()) {\n-    expand();\n-  }\n-  return _table->add_card(region_id, card_index);\n-}\n-\n-SparsePRTEntry* SparsePRT::get_entry(RegionIdx_t region_id) {\n-  return _table->get_entry(region_id);\n-}\n-\n-bool SparsePRT::delete_entry(RegionIdx_t region_id) {\n-  return _table->delete_entry(region_id);\n-}\n-\n-void SparsePRT::clear() {\n-  \/\/ If the entry table not at initial capacity, just reset to the empty table.\n-  if (_table->capacity() == InitialCapacity) {\n-    _table->clear();\n-  } else if (_table != &RSHashTable::empty_table) {\n-    delete _table;\n-    _table = &RSHashTable::empty_table;\n-  }\n-}\n-\n-void SparsePRT::expand() {\n-  RSHashTable* last = _table;\n-  if (last != &RSHashTable::empty_table) {\n-    _table = new RSHashTable(last->capacity() * 2);\n-    for (size_t i = 0; i < last->num_entries(); i++) {\n-      SparsePRTEntry* e = last->entry((int)i);\n-      if (e->valid_entry()) {\n-        _table->add_entry(e);\n-      }\n-    }\n-    delete last;\n-  } else {\n-    _table = new RSHashTable(InitialCapacity);\n-  }\n-}\n","filename":"src\/hotspot\/share\/gc\/g1\/sparsePRT.cpp","additions":0,"deletions":311,"binary":false,"changes":311,"status":"deleted"},{"patch":"@@ -1,246 +0,0 @@\n-\/*\n- * Copyright (c) 2001, 2019, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_G1_SPARSEPRT_HPP\n-#define SHARE_GC_G1_SPARSEPRT_HPP\n-\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n-#include \"gc\/g1\/heapRegion.hpp\"\n-#include \"gc\/shared\/cardTableBarrierSet.hpp\"\n-#include \"memory\/allocation.hpp\"\n-#include \"runtime\/mutex.hpp\"\n-#include \"utilities\/align.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-\n-class RSHashTable;\n-class SparsePRTEntry;\n-\n-\/\/ Sparse remembered set for a heap region (the \"owning\" region).  Maps\n-\/\/ indices of other regions to short sequences of cards in the other region\n-\/\/ that might contain pointers into the owner region.\n-\/\/ Concurrent access to a SparsePRT must be serialized by some external mutex.\n-class SparsePRT {\n-  friend class SparsePRTBucketIter;\n-\n-  RSHashTable* _table;\n-\n-  static const size_t InitialCapacity = 8;\n-\n-  void expand();\n-\n-public:\n-  SparsePRT();\n-  ~SparsePRT();\n-\n-  size_t mem_size() const;\n-\n-  enum AddCardResult {\n-    overflow, \/\/ The table is full, could not add the card to the table.\n-    found,    \/\/ The card is already in the PRT.\n-    added     \/\/ The card has been added.\n-  };\n-\n-  \/\/ Attempts to ensure that the given card_index in the given region is in\n-  \/\/ the sparse table.  If successful (because the card was already\n-  \/\/ present, or because it was successfully added) returns \"true\".\n-  \/\/ Otherwise, returns \"false\" to indicate that the addition would\n-  \/\/ overflow the entry for the region.  The caller must transfer these\n-  \/\/ entries to a larger-capacity representation.\n-  AddCardResult add_card(RegionIdx_t region_id, CardIdx_t card_index);\n-\n-  \/\/ Return the pointer to the entry associated with the given region.\n-  SparsePRTEntry* get_entry(RegionIdx_t region_ind);\n-\n-  \/\/ If there is an entry for \"region_ind\", removes it and return \"true\";\n-  \/\/ otherwise returns \"false.\"\n-  bool delete_entry(RegionIdx_t region_ind);\n-\n-  \/\/ Clear the table, and reinitialize to initial capacity.\n-  void clear();\n-\n-  bool contains_card(RegionIdx_t region_id, CardIdx_t card_index) const;\n-};\n-\n-class SparsePRTEntry: public CHeapObj<mtGC> {\n-public:\n-  \/\/ The type of a card entry.\n-  typedef uint16_t card_elem_t;\n-\n-private:\n-  \/\/ We need to make sizeof(SparsePRTEntry) an even multiple of maximum member size,\n-  \/\/ in order to force correct alignment that could otherwise cause SIGBUS errors\n-  \/\/ when reading the member variables. This calculates the minimum number of card\n-  \/\/ array elements required to get that alignment.\n-  static const size_t card_array_alignment = sizeof(int) \/ sizeof(card_elem_t);\n-\n-  RegionIdx_t _region_ind;\n-  int         _next_index;\n-  int         _next_null;\n-  \/\/ The actual cards stored in this array.\n-  \/\/ WARNING: Don't put any data members beyond this line. Card array has, in fact, variable length.\n-  \/\/ It should always be the last data member.\n-  card_elem_t _cards[card_array_alignment];\n-\n-  \/\/ Copy the current entry's cards into \"cards\".\n-  inline void copy_cards(card_elem_t* cards) const;\n-public:\n-  \/\/ Returns the size of the entry, used for entry allocation.\n-  static size_t size() { return sizeof(SparsePRTEntry) + sizeof(card_elem_t) * (cards_num() - card_array_alignment); }\n-  \/\/ Returns the size of the card array.\n-  static int cards_num() {\n-    return align_up((int)G1RSetSparseRegionEntries, (int)card_array_alignment);\n-  }\n-\n-  \/\/ Set the region_ind to the given value, and delete all cards.\n-  inline void init(RegionIdx_t region_ind);\n-\n-  RegionIdx_t r_ind() const { return _region_ind; }\n-  bool valid_entry() const { return r_ind() >= 0; }\n-\n-  int next_index() const { return _next_index; }\n-  int* next_index_addr() { return &_next_index; }\n-  void set_next_index(int ni) { _next_index = ni; }\n-\n-  \/\/ Returns \"true\" iff the entry contains the given card index.\n-  inline bool contains_card(CardIdx_t card_index) const;\n-\n-  \/\/ Returns the number of non-NULL card entries.\n-  inline int num_valid_cards() const { return _next_null; }\n-\n-  inline SparsePRT::AddCardResult add_card(CardIdx_t card_index);\n-\n-  \/\/ Copy the current entry's cards into the \"_card\" array of \"e.\"\n-  inline void copy_cards(SparsePRTEntry* e) const;\n-\n-  card_elem_t* cards() { return _cards; }\n-\n-  inline CardIdx_t card(int i) const {\n-    assert(i >= 0, \"must be nonnegative\");\n-    assert(i < cards_num(), \"range checking\");\n-    return (CardIdx_t)_cards[i];\n-  }\n-};\n-\n-class RSHashTable : public CHeapObj<mtGC> {\n-\n-  friend class RSHashTableBucketIter;\n-\n-  \/\/ Inverse maximum hash table occupancy used.\n-  static float TableOccupancyFactor;\n-\n-  size_t _num_entries;\n-\n-  size_t _capacity;\n-  size_t _capacity_mask;\n-  size_t _occupied_entries;\n-\n-  SparsePRTEntry* _entries;\n-  int* _buckets;\n-  int  _free_region;\n-  int  _free_list;\n-\n-  \/\/ Requires that the caller hold a lock preventing parallel modifying\n-  \/\/ operations, and that the the table be less than completely full.  If\n-  \/\/ an entry for \"region_ind\" is already in the table, finds it and\n-  \/\/ returns its address; otherwise allocates, initializes, inserts and\n-  \/\/ returns a new entry for \"region_ind\".\n-  SparsePRTEntry* entry_for_region_ind_create(RegionIdx_t region_ind);\n-\n-  \/\/ Returns the index of the next free entry in \"_entries\".\n-  int alloc_entry();\n-  \/\/ Declares the entry \"fi\" to be free.  (It must have already been\n-  \/\/ deleted from any bucket lists.\n-  void free_entry(int fi);\n-\n-  \/\/ For the empty sentinel created at static initialization time\n-  RSHashTable();\n-\n-public:\n-  RSHashTable(size_t capacity);\n-  ~RSHashTable();\n-\n-  static const int NullEntry = -1;\n-  static RSHashTable empty_table;\n-\n-  bool should_expand() const { return _occupied_entries == _num_entries; }\n-\n-  \/\/ Attempts to ensure that the given card_index in the given region is in\n-  \/\/ the sparse table.  If successful (because the card was already\n-  \/\/ present, or because it was successfully added) returns \"true\".\n-  \/\/ Otherwise, returns \"false\" to indicate that the addition would\n-  \/\/ overflow the entry for the region.  The caller must transfer these\n-  \/\/ entries to a larger-capacity representation.\n-  SparsePRT::AddCardResult add_card(RegionIdx_t region_id, CardIdx_t card_index);\n-\n-  bool delete_entry(RegionIdx_t region_id);\n-\n-  bool contains_card(RegionIdx_t region_id, CardIdx_t card_index) const;\n-\n-  void add_entry(SparsePRTEntry* e);\n-\n-  SparsePRTEntry* get_entry(RegionIdx_t region_id) const;\n-\n-  void clear();\n-\n-  size_t capacity() const      { return _capacity; }\n-  size_t capacity_mask() const { return _capacity_mask;  }\n-  size_t mem_size() const;\n-  \/\/ The number of SparsePRTEntry instances available.\n-  size_t num_entries() const { return _num_entries; }\n-\n-  SparsePRTEntry* entry(int i) const {\n-    assert(i >= 0 && (size_t)i < _num_entries, \"precondition\");\n-    return (SparsePRTEntry*)((char*)_entries + SparsePRTEntry::size() * i);\n-  }\n-\n-  void print();\n-};\n-\n-\/\/ This is embedded in HRRS iterator.\n-class RSHashTableBucketIter {\n-  uint _tbl_ind;        \/\/ [0.._rsht->_capacity)\n-  int  _bl_ind;         \/\/ [-1, 0.._rsht->_capacity)\n-\n-  RSHashTable* _rsht;\n-\n-public:\n-  RSHashTableBucketIter(RSHashTable* rsht) :\n-    _tbl_ind(0),\n-    _bl_ind(rsht->_buckets[_tbl_ind]),\n-    _rsht(rsht) { }\n-\n-  bool has_next(SparsePRTEntry*& entry);\n-};\n-\n-class SparsePRTBucketIter: public RSHashTableBucketIter {\n-public:\n-  SparsePRTBucketIter(const SparsePRT* sprt) :\n-    RSHashTableBucketIter(sprt->_table) {}\n-\n-  bool has_next(SparsePRTEntry*& entry) {\n-    return RSHashTableBucketIter::has_next(entry);\n-  }\n-};\n-\n-#endif \/\/ SHARE_GC_G1_SPARSEPRT_HPP\n","filename":"src\/hotspot\/share\/gc\/g1\/sparsePRT.hpp","additions":0,"deletions":246,"binary":false,"changes":246,"status":"deleted"},{"patch":"@@ -238,2 +238,2 @@\n-  static CardValue clean_card_val()          { return clean_card; }\n-  static CardValue dirty_card_val()          { return dirty_card; }\n+  static constexpr CardValue clean_card_val()          { return clean_card; }\n+  static constexpr CardValue dirty_card_val()          { return dirty_card; }\n","filename":"src\/hotspot\/share\/gc\/shared\/cardTable.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n-  static const uint MaxThreadWorkItems = 6;\n+  static const uint MaxThreadWorkItems = 9;\n","filename":"src\/hotspot\/share\/gc\/shared\/workerDataArray.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -127,0 +127,1 @@\n+  f(mtGCCardSet,      \"GCCardSet\")   \/* G1 card set remembered set                *\/ \\\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -102,1 +102,1 @@\n-#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.inline.hpp\"\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -528,0 +528,2 @@\n+  { \"G1RSetRegionEntries\",          JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+  { \"G1RSetSparseRegionEntries\",    JDK_Version::undefined(), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -192,0 +192,4 @@\n+\n+    size_t get_mem_size() {\n+      return sizeof(*this) + _size * sizeof(Bucket);\n+    }\n@@ -387,0 +391,2 @@\n+  size_t get_mem_size(Thread* thread);\n+\n@@ -388,1 +394,1 @@\n-  size_t get_node_size() const { return sizeof(Node); }\n+  static size_t get_node_size() { return sizeof(Node); }\n","filename":"src\/hotspot\/share\/utilities\/concurrentHashTable.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -40,2 +40,2 @@\n-\/\/ 2^5  = 32 buckets\n-#define SIZE_SMALL_LOG2 5\n+\/\/ 2^2  = 4 buckets\n+#define SIZE_SMALL_LOG2 2\n@@ -820,4 +820,1 @@\n-\n-  if (_new_table->_log2_size == _log2_size_limit) {\n-    _size_limit_reached = true;\n-  }\n+  _size_limit_reached = _new_table->_log2_size == _log2_size_limit;\n@@ -957,0 +954,1 @@\n+    Prefetch::read(current_node->next(), 0);\n@@ -1035,0 +1033,8 @@\n+template <typename CONFIG, MEMFLAGS F>\n+inline size_t ConcurrentHashTable<CONFIG, F>::\n+  get_mem_size(Thread* thread)\n+{\n+  ScopedCS cs(thread, this);\n+  return sizeof(*this) + _table->get_mem_size();\n+}\n+\n@@ -1138,2 +1144,0 @@\n-  assert(Thread::current()->is_VM_thread(),\n-         \"should be in vm thread\");\n","filename":"src\/hotspot\/share\/utilities\/concurrentHashTable.inline.hpp","additions":12,"deletions":8,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -63,5 +63,8 @@\n-  HeapRegion hr0(0, &bot, mr0);\n-  HeapRegion hr1(1, &bot, mr1);\n-  HeapRegion hr2(2, &bot, mr2);\n-  HeapRegion hr3(3, &bot, mr3);\n-  HeapRegion hr4(4, &bot, mr4);\n+  G1CardSetConfiguration config;\n+\n+  HeapRegion hr0(0, &bot, mr0, &config);\n+  HeapRegion hr1(1, &bot, mr1, &config);\n+  HeapRegion hr2(2, &bot, mr2, &config);\n+  HeapRegion hr3(3, &bot, mr3, &config);\n+  HeapRegion hr4(4, &bot, mr4, &config);\n+\n","filename":"test\/hotspot\/gtest\/gc\/g1\/test_freeRegionList.cpp","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -0,0 +1,480 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1CardSet.inline.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.hpp\"\n+#include \"gc\/g1\/g1CardSetMemory.hpp\"\n+#include \"gc\/g1\/heapRegionRemSet.hpp\"\n+#include \"gc\/shared\/gcTraceTime.inline.hpp\"\n+#include \"gc\/shared\/workgroup.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"unittest.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+\n+class G1CardSetTest : public ::testing::Test {\n+\n+  class G1CountCardsClosure : public G1CardSet::G1CardSetCardIterator {\n+  public:\n+    size_t _num_cards;\n+\n+    G1CountCardsClosure() : _num_cards(0) { }\n+    void do_card(uint region_idx, uint card_idx) override {\n+      _num_cards++;\n+    }\n+  };\n+\n+  static WorkGang* _workers;\n+  static uint _max_workers;\n+\n+  static WorkGang* workers() {\n+    if (_workers == NULL) {\n+      _max_workers = os::processor_count();\n+      _workers = new WorkGang(\"G1CardSetTest Work Gang\", _max_workers, false, false);\n+      _workers->initialize_workers();\n+      _workers->update_active_workers(_max_workers);\n+    }\n+    return _workers;\n+  }\n+\n+  \/\/ Check whether iteration agrees with the expected number of entries. If the\n+  \/\/ add has been single-threaded, we can also check whether the occupied()\n+  \/\/ (which is an estimate in that case) agrees.\n+  static void check_iteration(G1CardSet* card_set,\n+                              const size_t expected,\n+                              const bool add_was_single_threaded = true);\n+\n+public:\n+  G1CardSetTest() { }\n+  ~G1CardSetTest() { }\n+\n+  static uint next_random(uint& seed, uint i) {\n+    \/\/ Park–Miller random number generator\n+    seed = (seed * 279470273u) % 0xfffffffb;\n+    return (seed % i);\n+  }\n+\n+  static void cardset_basic_test();\n+  static void cardset_mt_test();\n+\n+  static void add_cards(G1CardSet* card_set, uint cards_per_region, uint* cards, uint num_cards, G1AddCardResult* results);\n+  static void contains_cards(G1CardSet* card_set, uint cards_per_region, uint* cards, uint num_cards);\n+\n+  static void translate_cards(uint cards_per_region, uint region_idx, uint* cards, uint num_cards);\n+\n+  static void iterate_cards(G1CardSet* card_set, G1CardSet::G1CardSetCardIterator* cl);\n+};\n+\n+WorkGang* G1CardSetTest::_workers = NULL;\n+uint G1CardSetTest::_max_workers = 0;\n+\n+void G1CardSetTest::add_cards(G1CardSet* card_set, uint cards_per_region, uint* cards, uint num_cards, G1AddCardResult* results) {\n+  for (uint i = 0; i < num_cards; i++) {\n+\n+    uint region_idx = cards[i] \/ cards_per_region;\n+    uint card_idx = cards[i] % cards_per_region;\n+\n+    G1AddCardResult res = card_set->add_card(region_idx, card_idx);\n+    if (results != NULL) {\n+      ASSERT_TRUE(res == results[i]);\n+    }\n+  }\n+}\n+\n+class G1CheckCardClosure : public G1CardSet::G1CardSetCardIterator {\n+  G1CardSet* _card_set;\n+\n+  uint _cards_per_region;\n+  uint* _cards_to_expect;\n+  uint _num_cards;\n+\n+  bool _wrong_region_idx;\n+\n+public:\n+  G1CheckCardClosure(G1CardSet* card_set, uint cards_per_region, uint* cards_to_expect, uint num_cards) :\n+    _card_set(card_set),\n+    _cards_per_region(cards_per_region),\n+    _cards_to_expect(cards_to_expect),\n+    _num_cards(num_cards),\n+    _wrong_region_idx(false) {\n+  }\n+\n+  void do_card(uint region_idx, uint card_idx) override {\n+    uint card = _cards_per_region * region_idx + card_idx;\n+    for (uint i = 0; i < _num_cards; i++) {\n+      if (_cards_to_expect[i] == card) {\n+        _cards_to_expect[i] = (uint)-1;\n+      }\n+    }\n+  }\n+\n+  bool all_found() const {\n+    bool all_good = true;\n+    for (uint i = 0; i < _num_cards; i++) {\n+      if (_cards_to_expect[i] != (uint)-1) {\n+        log_error(gc)(\"Could not find card %u in region %u\",\n+                      _cards_to_expect[i] % _cards_per_region,\n+                      _cards_to_expect[i] \/ _cards_per_region);\n+        all_good = false;\n+      }\n+    }\n+    return all_good;\n+  }\n+};\n+\n+void G1CardSetTest::contains_cards(G1CardSet* card_set, uint cards_per_region, uint* cards, uint num_cards) {\n+  for (uint i = 0; i < num_cards; i++) {\n+    uint region_idx = cards[i] \/ cards_per_region;\n+    uint card_idx = cards[i] % cards_per_region;\n+\n+    ASSERT_TRUE(card_set->contains_card(region_idx, card_idx));\n+  }\n+\n+  G1CheckCardClosure cl(card_set, cards_per_region, cards, num_cards);\n+  card_set->iterate_cards(cl);\n+\n+  ASSERT_TRUE(cl.all_found());\n+}\n+\n+\/\/ Offsets the card indexes in the cards array by the region_idx.\n+void G1CardSetTest::translate_cards(uint cards_per_region, uint region_idx, uint* cards, uint num_cards) {\n+  for (uint i = 0; i < num_cards; i++) {\n+    cards[i] = cards_per_region * region_idx + cards[i];\n+  }\n+}\n+\n+class G1CountCardsOccupied : public G1CardSet::G1CardSetPtrIterator {\n+  size_t _num_occupied;\n+\n+public:\n+  G1CountCardsOccupied() : _num_occupied(0) { }\n+\n+  void do_cardsetptr(uint region_idx, size_t num_occupied, G1CardSet::CardSetPtr card_set) override {\n+    _num_occupied += num_occupied;\n+  }\n+\n+  size_t num_occupied() const { return _num_occupied; }\n+};\n+\n+void G1CardSetTest::check_iteration(G1CardSet* card_set, const size_t expected, const bool single_threaded) {\n+\n+  class CheckIterator : public G1CardSet::G1CardSetCardIterator {\n+  public:\n+    G1CardSet* _card_set;\n+    size_t _num_found;\n+\n+    CheckIterator(G1CardSet* card_set) : _card_set(card_set), _num_found(0) { }\n+\n+    void do_card(uint region_idx, uint card_idx) override {\n+      ASSERT_TRUE(_card_set->contains_card(region_idx, card_idx));\n+      _num_found++;\n+    }\n+  } cl(card_set);\n+\n+  card_set->iterate_cards(cl);\n+\n+  ASSERT_TRUE(expected == cl._num_found);\n+  \/\/ We can assert this only if we are single-threaded.\n+  if (single_threaded) {\n+    ASSERT_EQ(card_set->occupied(), cl._num_found);\n+  }\n+}\n+\n+void G1CardSetTest::cardset_basic_test() {\n+\n+  const uint CardsPerRegion = 2048;\n+  const double FullCardSetThreshold = 0.8;\n+  const double BitmapCoarsenThreshold = 0.9;\n+\n+  G1CardSetConfiguration config(log2i_exact(CardsPerRegion), 28, BitmapCoarsenThreshold, 8, FullCardSetThreshold, CardsPerRegion);\n+  G1CardSetFreePool free_pool(config.num_mem_object_types());\n+  G1CardSetMemoryManager mm(&config, &free_pool);\n+\n+  {\n+    G1CardSet card_set(&config, &mm);\n+\n+    uint cards1[] = { 1, 2, 3 };\n+    G1AddCardResult results1[] = { Added, Added, Added };\n+    translate_cards(CardsPerRegion, 99, cards1, ARRAY_SIZE(cards1));\n+    add_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1), results1);\n+    contains_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1));\n+    ASSERT_TRUE(card_set.occupied() == ARRAY_SIZE(cards1));\n+\n+    G1CountCardsClosure count_cards;\n+    card_set.iterate_cards(count_cards);\n+    ASSERT_TRUE(count_cards._num_cards == ARRAY_SIZE(cards1));\n+\n+    check_iteration(&card_set, card_set.occupied());\n+\n+    card_set.clear();\n+    ASSERT_TRUE(card_set.occupied() == 0);\n+\n+    check_iteration(&card_set, 0);\n+  }\n+\n+  {\n+    G1CardSet card_set(&config, &mm);\n+\n+    uint cards1[] = { 0, 2047, 17, 17 };\n+    G1AddCardResult results1[] = { Added, Added, Added, Found };\n+    translate_cards(CardsPerRegion, 100, cards1, ARRAY_SIZE(cards1));\n+    add_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1), results1);\n+    \/\/ -1 because of the duplicate at the end.\n+    contains_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1) - 1);\n+    ASSERT_TRUE(card_set.occupied() == ARRAY_SIZE(cards1) - 1);\n+\n+    G1CountCardsClosure count_cards;\n+    card_set.iterate_cards(count_cards);\n+    ASSERT_TRUE(count_cards._num_cards == ARRAY_SIZE(cards1) - 1);\n+\n+    check_iteration(&card_set, card_set.occupied());\n+\n+    card_set.clear();\n+    ASSERT_TRUE(card_set.occupied() == 0);\n+  }\n+\n+  {\n+    G1CardSet card_set(&config, &mm);\n+\n+    uint cards1[] = { 0, 2047, 17, 18 \/* for region 100 *\/,\n+                      1,  128, 35, 17 \/* for region 990 *\/\n+                    };\n+    translate_cards(CardsPerRegion, 100, &cards1[0], 4);\n+    translate_cards(CardsPerRegion, 990, &cards1[4], 4);\n+\n+    add_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1), NULL);\n+    contains_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1));\n+    ASSERT_TRUE(card_set.occupied() == ARRAY_SIZE(cards1));\n+\n+    G1CountCardsClosure count_cards;\n+    card_set.iterate_cards(count_cards);\n+    ASSERT_TRUE(count_cards._num_cards == ARRAY_SIZE(cards1));\n+\n+    check_iteration(&card_set, card_set.occupied());\n+\n+    card_set.clear();\n+    ASSERT_TRUE(card_set.occupied() == 0);\n+  }\n+\n+  {\n+    G1CardSet card_set(&config, &mm);\n+\n+    uint cards1[100];\n+    for (uint i = 0; i < ARRAY_SIZE(cards1); i++) {\n+      cards1[i] = i + 3;\n+      translate_cards(CardsPerRegion, i, &cards1[i], 1);\n+    }\n+    add_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1), NULL);\n+    contains_cards(&card_set, CardsPerRegion, cards1, ARRAY_SIZE(cards1));\n+\n+    ASSERT_TRUE(card_set.num_containers() == ARRAY_SIZE(cards1));\n+    ASSERT_TRUE(card_set.occupied() == ARRAY_SIZE(cards1));\n+\n+    G1CountCardsClosure count_cards;\n+    card_set.iterate_cards(count_cards);\n+    ASSERT_TRUE(count_cards._num_cards == ARRAY_SIZE(cards1));\n+\n+    check_iteration(&card_set, card_set.occupied());\n+\n+    card_set.clear();\n+    ASSERT_TRUE(card_set.occupied() == 0);\n+  }\n+\n+  {\n+    G1CardSet card_set(&config, &mm);\n+\n+    \/\/ Generate non-prime numbers from 1 to 1000\n+    uint count = 0;\n+    for (uint i = 2; i < 33; i++) {\n+      if (!card_set.contains_card(100, i)) {\n+        for (uint j = i * i; j < 1000; j += i) {\n+          G1AddCardResult res = card_set.add_card(100, j);\n+          count += (res == Added);\n+        }\n+      }\n+    }\n+\n+    G1CountCardsOccupied cl;\n+    card_set.iterate_containers(&cl);\n+\n+    ASSERT_TRUE(count == card_set.occupied());\n+    ASSERT_TRUE(card_set.occupied() == cl.num_occupied());\n+\n+    check_iteration(&card_set, card_set.occupied());\n+\n+    card_set.clear();\n+    ASSERT_TRUE(card_set.occupied() == 0);\n+  }\n+  { \/\/ Test coarsening to full\n+    G1CardSet card_set(&config, &mm);\n+\n+    uint count = 0;\n+    uint i = 10;\n+    uint bitmap_threshold = config.cards_in_howl_bitmap_threshold();\n+    for (; i <  bitmap_threshold + 10; i++) {\n+      G1AddCardResult res = card_set.add_card(99, i);\n+      ASSERT_TRUE(res == Added);\n+      count++;\n+      ASSERT_TRUE(count == card_set.occupied());\n+    }\n+\n+    G1AddCardResult res = card_set.add_card(99, config.num_cards_in_howl_bitmap() - 1);\n+    \/\/ Adding above card should have coarsened Bitmap -> Full.\n+    ASSERT_TRUE(res == Added);\n+    ASSERT_TRUE(config.num_cards_in_howl_bitmap() == card_set.occupied());\n+\n+    res = card_set.add_card(99, config.num_cards_in_howl_bitmap() - 2);\n+    ASSERT_TRUE(res == Found);\n+\n+    uint threshold = config.cards_in_howl_threshold();\n+    uint adjusted_threshold = config.cards_in_howl_bitmap_threshold() * config.num_buckets_in_howl();\n+    i = config.num_cards_in_howl_bitmap();\n+    count = i;\n+    for (; i <  threshold; i++) {\n+      G1AddCardResult res = card_set.add_card(99, i);\n+      ASSERT_TRUE(res == Added);\n+      count++;\n+      ASSERT_TRUE(count == card_set.occupied());\n+    }\n+\n+    res = card_set.add_card(99, CardsPerRegion - 1);\n+    \/\/ Adding above card should have coarsened Howl -> Full.\n+    ASSERT_TRUE(res == Added);\n+    ASSERT_TRUE(CardsPerRegion == card_set.occupied());\n+\n+    check_iteration(&card_set, card_set.occupied());\n+\n+    res = card_set.add_card(99, CardsPerRegion - 2);\n+    ASSERT_TRUE(res == Found);\n+\n+    G1CountCardsClosure count_cards;\n+    card_set.iterate_cards(count_cards);\n+    ASSERT_TRUE(count_cards._num_cards == config.max_cards_in_region());\n+\n+    card_set.clear();\n+    ASSERT_TRUE(card_set.occupied() == 0);\n+  }\n+}\n+\n+class G1CardSetMtTestTask : public AbstractGangTask {\n+  G1CardSet* _card_set;\n+\n+  size_t _added;\n+  size_t _found;\n+\n+public:\n+  G1CardSetMtTestTask(G1CardSet* card_set) :\n+    AbstractGangTask(\"\"),\n+    _card_set(card_set),\n+    _added(0),\n+    _found(0) { }\n+\n+  void work(uint worker_id) {\n+    uint seed = worker_id;\n+    size_t added = 0;\n+    size_t found = 0;\n+\n+    for (uint i = 0; i < 100000; i++) {\n+      uint region = G1CardSetTest::next_random(seed, 1000);\n+      uint card = G1CardSetTest::next_random(seed, 10000);\n+\n+      G1AddCardResult res = _card_set->add_card(region, card);\n+\n+      ASSERT_TRUE(res == Added || res == Found);\n+      if (res == Added) {\n+        added++;\n+      } else if (res == Found) {\n+        found++;\n+      }\n+    }\n+    Atomic::add(&_added, added);\n+    Atomic::add(&_found, found);\n+  }\n+\n+  size_t added() const { return _added; }\n+  size_t found() const { return _found; }\n+};\n+\n+void G1CardSetTest::cardset_mt_test() {\n+  const uint CardsPerRegion = 16384;\n+  const double FullCardSetThreshold = 1.0;\n+  const uint BitmapCoarsenThreshold = 1.0;\n+\n+  G1CardSetConfiguration config(log2i_exact(CardsPerRegion), 120, BitmapCoarsenThreshold, 8, FullCardSetThreshold, CardsPerRegion);\n+  G1CardSetFreePool free_pool(config.num_mem_object_types());\n+  G1CardSetMemoryManager mm(&config, &free_pool);\n+\n+  G1CardSet card_set(&config, &mm);\n+\n+  log_error(gc)(\"MT parallel part start\");\n+\n+  const uint num_workers = workers()->active_workers();\n+\n+  G1CardSetMtTestTask cl(&card_set);\n+\n+  {\n+    GCTraceTime(Error, gc) x(\"Cardset test\");\n+    _workers->run_task(&cl, num_workers);\n+  }\n+\n+  log_error(gc)(\"MT parallel part, added \" SIZE_FORMAT \" duplicate \" SIZE_FORMAT, cl.added(), cl.found());\n+\n+  size_t num_found = 0;\n+  \/\/ Now check the contents of the card set.\n+  for (uint i = 0; i < num_workers; i++) {\n+    uint seed = i;\n+\n+    for (uint j = 0; j < 100000; j++) {\n+      uint region = G1CardSetTest::next_random(seed, 1000);\n+      uint card = G1CardSetTest::next_random(seed, 10000);\n+\n+      bool contains = card_set.contains_card(region, card);\n+      ASSERT_TRUE(contains);\n+\n+      num_found += contains;\n+    }\n+  }\n+\n+  ASSERT_TRUE(num_found == cl.added() + cl.found());\n+\n+  G1CountCardsClosure count_cards;\n+  card_set.iterate_cards(count_cards);\n+\n+  check_iteration(&card_set, count_cards._num_cards, false \/* add_was_single_threaded *\/);\n+\n+  \/\/ During coarsening we try to unblock concurrent threads as soon as possible,\n+  \/\/ so we do not add the cards from the smaller CardSetContainer to the larger\n+  \/\/ one immediately, allowing addition by concurrent threads after allocating\n+  \/\/ the space immediately. So the amount of \"successfully added\" results may be\n+  \/\/ (and in case of many threads typically is) higher than the number of unique\n+  \/\/ cards.\n+  ASSERT_TRUE(count_cards._num_cards <= cl.added());\n+}\n+\n+TEST_VM(G1CardSetTest, basic_cardset_test) {\n+  G1CardSetTest::cardset_basic_test();\n+}\n+\n+TEST_VM(G1CardSetTest, mt_cardset_test) {\n+  G1CardSetTest::cardset_mt_test();\n+}\n","filename":"test\/hotspot\/gtest\/gc\/g1\/test_g1CardSet.cpp","additions":480,"deletions":0,"binary":false,"changes":480,"status":"added"},{"patch":"@@ -0,0 +1,263 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"gc\/g1\/g1CardSetContainers.inline.hpp\"\n+#include \"gc\/g1\/heapRegionBounds.inline.hpp\"\n+#include \"gc\/shared\/cardTable.hpp\"\n+#include \"memory\/allocation.inline.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/powerOfTwo.hpp\"\n+#include \"unittest.hpp\"\n+\n+class G1CardSetContainersTest : public ::testing::Test {\n+public:\n+  G1CardSetContainersTest() { }\n+  ~G1CardSetContainersTest() { }\n+\n+  static uint cards_per_inlineptr_set(uint bits_per_card) {\n+    return G1CardSetInlinePtr::max_cards_in_inline_ptr(bits_per_card);\n+  }\n+\n+  static void cardset_inlineptr_test(uint bits_per_card);\n+  static void cardset_array_test(uint cards_per_array);\n+  static void cardset_bitmap_test(uint threshold, uint size_in_bits);\n+};\n+\n+class G1FindCardsInRange : public StackObj {\n+  uint _num_cards;\n+  uint _range_min;\n+  bool* _cards_found;\n+public:\n+  G1FindCardsInRange(uint range_min, uint range_max) :\n+    _num_cards(range_max - range_min + 1),\n+    _range_min(range_min),\n+    _cards_found(NEW_C_HEAP_ARRAY(bool, _num_cards, mtGC)) {\n+    for (uint i = 0; i < _num_cards; i++) {\n+      _cards_found[i] = false;\n+    }\n+  }\n+\n+  void verify_all_found() {\n+    verify_part_found(_num_cards);\n+  }\n+\n+  void verify_part_found(uint num) {\n+    for (uint i = 0; i < num; i++) {\n+      ASSERT_TRUE(_cards_found[i]);\n+    }\n+  }\n+\n+  ~G1FindCardsInRange() {\n+    FREE_C_HEAP_ARRAY(mtGC, _cards_found);\n+  }\n+  void operator()(uint card) {\n+    ASSERT_TRUE((card - _range_min) < _num_cards);\n+    ASSERT_FALSE(_cards_found[card - _range_min]); \/\/ Must not have been found yet.\n+    _cards_found[card - _range_min] = true;\n+  }\n+};\n+\n+void G1CardSetContainersTest::cardset_inlineptr_test(uint bits_per_card) {\n+  const uint CardsPerSet = cards_per_inlineptr_set(bits_per_card);\n+\n+  G1AddCardResult res;\n+\n+  G1CardSet::CardSetPtr value = G1CardSetInlinePtr();\n+\n+  for (uint i = 0; i < CardsPerSet; i++) {\n+    {\n+      G1CardSetInlinePtr cards(&value, value);\n+      res = cards.add(i + 1, bits_per_card, CardsPerSet);\n+      ASSERT_TRUE(res == Added);\n+    }\n+    {\n+      G1CardSetInlinePtr cards(&value, value);\n+      ASSERT_TRUE(cards.contains(i + 1, bits_per_card));\n+    }\n+  }\n+\n+  for (uint i = 0; i < CardsPerSet; i++) {\n+    G1CardSetInlinePtr cards(value);\n+    ASSERT_TRUE(cards.contains(i + 1, bits_per_card));\n+  }\n+\n+  \/\/ Try to add again, should all return that the card had been added.\n+  for (uint i = 0; i < CardsPerSet; i++) {\n+    G1CardSetInlinePtr cards(&value, value);\n+    res = cards.add(i + 1, bits_per_card, CardsPerSet);\n+    ASSERT_TRUE(res == Found);\n+  }\n+\n+  \/\/ Should be no more space in set.\n+  {\n+    G1CardSetInlinePtr cards(&value, value);\n+    res = cards.add(CardsPerSet + 1, bits_per_card, CardsPerSet);\n+    ASSERT_TRUE(res == Overflow);\n+  }\n+\n+  \/\/ Cards should still be in the set.\n+  for (uint i = 0; i < CardsPerSet; i++) {\n+    G1CardSetInlinePtr cards(value);\n+    ASSERT_TRUE(cards.contains(i + 1, bits_per_card));\n+  }\n+\n+  \/\/ Boundary cards should not be in the set.\n+  {\n+    G1CardSetInlinePtr cards(value);\n+    ASSERT_TRUE(!cards.contains(0, bits_per_card));\n+    ASSERT_TRUE(!cards.contains(CardsPerSet + 1, bits_per_card));\n+  }\n+\n+  \/\/ Verify iteration finds all cards too and only those.\n+  {\n+    G1FindCardsInRange found(1, CardsPerSet);\n+    G1CardSetInlinePtr cards(value);\n+    cards.iterate(found, bits_per_card);\n+    found.verify_all_found();\n+  }\n+}\n+\n+void G1CardSetContainersTest::cardset_array_test(uint cards_per_array) {\n+  uint8_t* cardset_data = NEW_C_HEAP_ARRAY(uint8_t, G1CardSetArray::size_in_bytes(cards_per_array), mtGC);\n+  G1CardSetArray* cards = new (cardset_data) G1CardSetArray(1, cards_per_array);\n+\n+  ASSERT_TRUE(cards->contains(1)); \/\/ Added during initialization\n+  ASSERT_TRUE(cards->num_entries() == 1); \/\/ Check it's the only one.\n+\n+  G1AddCardResult res;\n+\n+  \/\/ Add some elements\n+  for (uint i = 1; i < cards_per_array; i++) {\n+    res = cards->add(i + 1);\n+    ASSERT_TRUE(res == Added);\n+  }\n+\n+  \/\/ Check they are in the container.\n+  for (uint i = 0; i < cards_per_array; i++) {\n+    ASSERT_TRUE(cards->contains(i + 1));\n+  }\n+\n+  \/\/ Try to add again, should all return that the card had been added.\n+  for (uint i = 0; i < cards_per_array; i++) {\n+    res = cards->add(i + 1);\n+    ASSERT_TRUE(res == Found);\n+  }\n+\n+  \/\/ Should be no more space in set.\n+  {\n+    res = cards->add(cards_per_array + 1);\n+    ASSERT_TRUE(res == Overflow);\n+  }\n+\n+  \/\/ Cards should still be in the set.\n+  for (uint i = 0; i < cards_per_array; i++) {\n+    ASSERT_TRUE(cards->contains(i + 1));\n+  }\n+\n+  ASSERT_TRUE(!cards->contains(0));\n+  ASSERT_TRUE(!cards->contains(cards_per_array + 1));\n+\n+  \/\/ Verify iteration finds all cards too.\n+  {\n+    G1FindCardsInRange found(1, cards_per_array);\n+    cards->iterate(found);\n+    found.verify_all_found();\n+  }\n+\n+  FREE_C_HEAP_ARRAY(mtGC, cardset_data);\n+}\n+\n+void G1CardSetContainersTest::cardset_bitmap_test(uint threshold, uint size_in_bits) {\n+  uint8_t* cardset_data = NEW_C_HEAP_ARRAY(uint8_t, G1CardSetBitMap::size_in_bytes(size_in_bits), mtGC);\n+  G1CardSetBitMap* cards = new (cardset_data) G1CardSetBitMap(1, size_in_bits);\n+\n+  ASSERT_TRUE(cards->contains(1, size_in_bits)); \/\/ Added during initialization\n+  ASSERT_TRUE(cards->num_bits_set() == 1); \/\/ Should be the only one.\n+\n+  G1AddCardResult res;\n+\n+  for (uint i = 1; i < threshold; i++) {\n+    res = cards->add(i + 1, threshold, size_in_bits);\n+    ASSERT_TRUE(res == Added);\n+  }\n+\n+  for (uint i = 0; i < threshold; i++) {\n+    ASSERT_TRUE(cards->contains(i + 1, size_in_bits));\n+  }\n+\n+  \/\/ Try to add again, should all return that the card had been added.\n+  for (uint i = 0; i < threshold; i++) {\n+    res = cards->add(i + 1, threshold, size_in_bits);\n+    ASSERT_TRUE(res == Found);\n+  }\n+\n+  \/\/ Should be no more space in set.\n+  {\n+    res = cards->add(threshold + 1, threshold, size_in_bits);\n+    ASSERT_TRUE(res == Overflow);\n+  }\n+\n+  \/\/ Cards should still be in the set.\n+  for (uint i = 0; i < threshold; i++) {\n+    ASSERT_TRUE(cards->contains(i + 1, size_in_bits));\n+  }\n+\n+  ASSERT_TRUE(!cards->contains(0, size_in_bits));\n+\n+  \/\/ Verify iteration finds all cards too.\n+  {\n+    G1FindCardsInRange found(1, threshold + 1);\n+    cards->iterate(found, size_in_bits, 0);\n+    found.verify_part_found(threshold);\n+  }\n+\n+  FREE_C_HEAP_ARRAY(mtGC, cardset_data);\n+}\n+\n+TEST_VM_F(G1CardSetContainersTest, basic_cardset_inptr_test) {\n+  uint const min = (uint)log2i(HeapRegionBounds::min_size());\n+  uint const max = (uint)log2i(HeapRegionBounds::max_size());\n+\n+  for (uint i = min; i <= max; i++) {\n+    G1CardSetContainersTest::cardset_inlineptr_test(i - CardTable::card_shift);\n+  }\n+}\n+\n+TEST_VM_F(G1CardSetContainersTest, basic_cardset_array_test) {\n+  uint array_sizes[] = { 5, 9, 63, 77, 127 };\n+\n+  for (uint i = 0; i < ARRAY_SIZE(array_sizes); i++) {\n+    size_t const max_cards_in_set = ARRAY_SIZE(array_sizes);\n+    G1CardSetContainersTest::cardset_array_test(max_cards_in_set);\n+  }\n+}\n+\n+TEST_VM_F(G1CardSetContainersTest, basic_cardset_bitmap_test) {\n+  uint bit_sizes[] = { 64, 2048 };\n+  uint threshold_sizes[] = { 17, 330 };\n+\n+  for (uint i = 0; i < ARRAY_SIZE(bit_sizes); i++) {\n+    G1CardSetContainersTest::cardset_bitmap_test(threshold_sizes[i], bit_sizes[i]);\n+  }\n+}\n","filename":"test\/hotspot\/gtest\/gc\/g1\/test_g1CardSetContainers.cpp","additions":263,"deletions":0,"binary":false,"changes":263,"status":"added"},{"patch":"@@ -0,0 +1,67 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package gc.arguments;\n+\n+\/*\n+ * @test TestG1RemSetFlags\n+ * @requires vm.gc.G1\n+ * @summary Verify that the remembered set flags are updated as expected\n+ * @modules java.base\/jdk.internal.misc\n+ * @modules java.management\/sun.management\n+ * @library \/test\/lib\n+ * @library \/\n+ * @run driver gc.arguments.TestG1RemSetFlags\n+ *\/\n+\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+\n+public class TestG1RemSetFlags {\n+\n+  private static void checkG1RemSetFlags(String[] flags, int exitValue) throws Exception {\n+    ArrayList<String> flagList = new ArrayList<String>();\n+    flagList.addAll(Arrays.asList(flags));\n+    flagList.add(\"-XX:+UseG1GC\");\n+    flagList.add(\"-XX:+PrintFlagsFinal\");\n+    flagList.add(\"-version\");\n+\n+    ProcessBuilder pb = GCArguments.createJavaProcessBuilder(flagList);\n+    OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+    output.shouldHaveExitValue(exitValue);\n+  }\n+\n+  public static void main(String args[]) throws Exception {\n+    checkG1RemSetFlags(new String[] { \"-XX:+UnlockExperimentalVMOptions\", \"-XX:G1RemSetHowlNumBuckets=8\", \"-XX:G1RemSetHowlMaxNumBuckets=8\"  },  0);\n+    checkG1RemSetFlags(new String[] { \"-XX:+UnlockExperimentalVMOptions\", \"-XX:G1RemSetHowlNumBuckets=8\", \"-XX:G1RemSetHowlMaxNumBuckets=16\"  },  0);\n+    checkG1RemSetFlags(new String[] { \"-XX:+UnlockExperimentalVMOptions\", \"-XX:G1RemSetHowlNumBuckets=16\", \"-XX:G1RemSetHowlMaxNumBuckets=8\"  },  1);\n+    checkG1RemSetFlags(new String[] { \"-XX:+UnlockExperimentalVMOptions\", \"-XX:G1RemSetHowlNumBuckets=7\"  },  1);\n+    checkG1RemSetFlags(new String[] { \"-XX:+UnlockExperimentalVMOptions\", \"-XX:G1RemSetHowlMaxNumBuckets=7\"  },  1);\n+  }\n+}\n","filename":"test\/hotspot\/jtreg\/gc\/arguments\/TestG1RemSetFlags.java","additions":67,"deletions":0,"binary":false,"changes":67,"status":"added"},{"patch":"@@ -104,3 +104,8 @@\n-        new LogMessageWithLevel(\"Merged Sparse\", Level.DEBUG),\n-        new LogMessageWithLevel(\"Merged Fine\", Level.DEBUG),\n-        new LogMessageWithLevel(\"Merged Coarse\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Inline\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged ArrayOfCards\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Howl\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Full\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Howl Inline\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Howl ArrayOfCards\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Howl BitMap\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Merged Howl Full\", Level.DEBUG),\n@@ -138,0 +143,1 @@\n+        new LogMessageWithLevel(\"Sample Collection Set Candidates\", Level.DEBUG),\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestGCLogMessages.java","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -37,1 +37,1 @@\n- * @run main\/othervm -Xbootclasspath\/a:. -Xlog:gc,gc+humongous=debug -XX:+UseG1GC -XX:MaxTenuringThreshold=0 -XX:G1RSetSparseRegionEntries=32 -XX:G1HeapRegionSize=1m -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI gc.g1.TestNoEagerReclaimOfHumongousRegions\n+ * @run main\/othervm -Xbootclasspath\/a:. -Xlog:gc,gc+humongous=debug -XX:+UseG1GC -XX:MaxTenuringThreshold=0 -XX:+UnlockExperimentalVMOptions -XX:G1RemSetArrayOfCardsEntries=32 -XX:G1HeapRegionSize=1m -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI gc.g1.TestNoEagerReclaimOfHumongousRegions\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestNoEagerReclaimOfHumongousRegions.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -105,0 +105,2 @@\n+    private static final int CARDSIZE = 512; \/\/ Card size in bytes.\n+\n@@ -232,2 +234,2 @@\n-        \/\/ threshold for sparce -> fine\n-        final int FINE = WB.getIntxVMFlag(\"G1RSetSparseRegionEntries\").intValue();\n+        \/\/ Threshold for Array of Cards -> Howl\n+        final int ARRAY_TO_HOWL_THRESHOLD = WB.getUintVMFlag(\"G1RemSetArrayOfCardsEntries\").intValue();\n@@ -235,2 +237,4 @@\n-        \/\/ threshold for fine -> coarse\n-        final int COARSE = WB.getIntxVMFlag(\"G1RSetRegionEntries\").intValue();\n+        \/\/ Threshold for Howl -> Full\n+        int coarsenHowlToFullPercent = WB.getUintVMFlag(\"G1RemSetCoarsenHowlToFullPercent\").intValue();\n+        int cardsPerRegion = WB.getSizeTVMFlag(\"G1HeapRegionSize\").intValue() \/ CARDSIZE;\n+        final int HOWL_TO_FULL_THRESHOLD = (cardsPerRegion * coarsenHowlToFullPercent) \/ 100;\n@@ -244,2 +248,7 @@\n-        int[] regToRegRefCounts = {0, FINE \/ 2, 0, FINE, (FINE + COARSE) \/ 2, 0,\n-            COARSE, COARSE + 10, FINE + 1, FINE \/ 2, 0};\n+        int[] regToRegRefCounts = {\n+            0, ARRAY_TO_HOWL_THRESHOLD \/ 2,\n+            0, ARRAY_TO_HOWL_THRESHOLD,\n+            (ARRAY_TO_HOWL_THRESHOLD + HOWL_TO_FULL_THRESHOLD) \/ 2, 0,\n+            HOWL_TO_FULL_THRESHOLD, HOWL_TO_FULL_THRESHOLD + 10,\n+            ARRAY_TO_HOWL_THRESHOLD + 1, ARRAY_TO_HOWL_THRESHOLD \/ 2,\n+            0};\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/TestStressRSetCoarsening.java","additions":15,"deletions":6,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -233,2 +233,0 @@\n-        excludeTestMaxRange(\"G1RSetRegionEntries\");\n-        excludeTestMaxRange(\"G1RSetSparseRegionEntries\");\n","filename":"test\/hotspot\/jtreg\/runtime\/CommandLine\/OptionsValidation\/TestOptionsWithRanges.java","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -53,1 +53,1 @@\n-        pb.command(new String[] { JDKToolFinder.getJDKTool(\"jcmd\"), pid, \"VM.native_memory\", \"summary\"});\n+        pb.command(new String[] { JDKToolFinder.getJDKTool(\"jcmd\"), pid, \"VM.native_memory\", \"detail\"});\n@@ -62,1 +62,1 @@\n-        addr = wb.NMTMallocWithPseudoStackAndType(2 * 1024, pc, 8 \/* mtInternal *\/ );\n+        addr = wb.NMTMallocWithPseudoStackAndType(2 * 1024, pc, 9 \/* mtInternal *\/ );\n","filename":"test\/hotspot\/jtreg\/runtime\/NMT\/MallocSiteTypeChange.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -118,1 +118,2 @@\n-            \"RebuildFreeList\"\n+            \"RebuildFreeList\",\n+            \"SampleCandidates\"\n","filename":"test\/jdk\/jdk\/jfr\/event\/gc\/collection\/TestG1ParallelPhases.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"}]}