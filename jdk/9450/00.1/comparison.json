{"files":[{"patch":"@@ -0,0 +1,109 @@\n+\/*\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2014 SAP SE. All rights reserved.\n+ * Copyright (c) 2022, IBM Corp.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/metaspace.hpp\"\n+#include \"runtime\/frame.inline.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n+\n+frame JavaThread::pd_last_frame() {\n+  assert(has_last_Java_frame(), \"must have last_Java_sp() when suspended\");\n+\n+  intptr_t* sp = Atomic::load_acquire(&_anchor._last_Java_sp);\n+  address pc = _anchor.last_Java_pc();\n+\n+  return frame(sp, pc);\n+}\n+\n+bool JavaThread::pd_get_top_frame_for_profiling(frame* fr_addr, void* ucontext, bool isInJava) {\n+\n+  \/\/ If we have a last_Java_frame, then we should use it even if\n+  \/\/ isInJava == true.  It should be more reliable than ucontext info.\n+  if (has_last_Java_frame() && frame_anchor()->walkable()) {\n+    *fr_addr = pd_last_frame();\n+    return true;\n+  }\n+\n+  \/\/ At this point, we don't have a last_Java_frame, so\n+  \/\/ we try to glean some information out of the ucontext\n+  \/\/ if we were running Java code when SIGPROF came in.\n+  if (isInJava) {\n+    ucontext_t* uc = (ucontext_t*) ucontext;\n+    address pc = (address)uc->uc_mcontext.jmp_context.iar;\n+\n+    if (pc == NULL) {\n+      \/\/ ucontext wasn't useful\n+      return false;\n+    }\n+\n+    frame ret_frame((intptr_t*)uc->uc_mcontext.jmp_context.gpr[1\/*REG_SP*\/], pc);\n+\n+    if (ret_frame.fp() == NULL) {\n+      \/\/ The found frame does not have a valid frame pointer.\n+      \/\/ Bail out because this will create big trouble later on, either\n+      \/\/  - when using istate, calculated as (NULL - ijava_state_size) or\n+      \/\/  - when using fp() directly in safe_for_sender()\n+      \/\/\n+      \/\/ There is no conclusive description (yet) how this could happen, but it does.\n+      \/\/ For more details on what was observed, see thread_linux_s390.cpp\n+      return false;\n+    }\n+\n+    if (ret_frame.is_interpreted_frame()) {\n+      frame::ijava_state *istate = ret_frame.get_ijava_state();\n+      const Method *m = (const Method*)(istate->method);\n+      if (!Method::is_valid_method(m)) return false;\n+      if (!Metaspace::contains(m->constMethod())) return false;\n+\n+      uint64_t reg_bcp = uc->uc_mcontext.jmp_context.gpr[14\/*R14_bcp*\/];\n+      uint64_t istate_bcp = istate->bcp;\n+      uint64_t code_start = (uint64_t)(m->code_base());\n+      uint64_t code_end = (uint64_t)(m->code_base() + m->code_size());\n+      if (istate_bcp >= code_start && istate_bcp < code_end) {\n+        \/\/ we have a valid bcp, don't touch it, do nothing\n+      } else if (reg_bcp >= code_start && reg_bcp < code_end) {\n+        istate->bcp = reg_bcp;\n+      } else {\n+        return false;\n+      }\n+    }\n+    if (!ret_frame.safe_for_sender(this)) {\n+      \/\/ nothing else to try if the frame isn't good\n+      return false;\n+    }\n+    *fr_addr = ret_frame;\n+    return true;\n+  }\n+  \/\/ nothing else to try\n+  return false;\n+}\n+\n+\/\/ Forte Analyzer AsyncGetCallTrace profiling support.\n+bool JavaThread::pd_get_top_frame_for_signal_handler(frame* fr_addr, void* ucontext, bool isInJava) {\n+  return pd_get_top_frame_for_profiling(fr_addr, ucontext, isInJava);\n+}\n+\n+void JavaThread::cache_global_variables() { }\n","filename":"src\/hotspot\/os_cpu\/aix_ppc\/javaThread_aix_ppc.cpp","additions":109,"deletions":0,"binary":false,"changes":109,"status":"added"},{"patch":"@@ -0,0 +1,108 @@\n+\/*\n+ * Copyright (c) 1997, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2022 SAP SE. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/metaspace.hpp\"\n+#include \"runtime\/frame.inline.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n+\n+frame JavaThread::pd_last_frame() {\n+  assert(has_last_Java_frame(), \"must have last_Java_sp() when suspended\");\n+\n+  intptr_t* sp = Atomic::load_acquire(&_anchor._last_Java_sp);\n+  address pc = _anchor.last_Java_pc();\n+\n+  return frame(sp, pc);\n+}\n+\n+bool JavaThread::pd_get_top_frame_for_profiling(frame* fr_addr, void* ucontext, bool isInJava) {\n+\n+  \/\/ If we have a last_Java_frame, then we should use it even if\n+  \/\/ isInJava == true.  It should be more reliable than ucontext info.\n+  if (has_last_Java_frame() && frame_anchor()->walkable()) {\n+    *fr_addr = pd_last_frame();\n+    return true;\n+  }\n+\n+  \/\/ At this point, we don't have a last_Java_frame, so\n+  \/\/ we try to glean some information out of the ucontext\n+  \/\/ if we were running Java code when SIGPROF came in.\n+  if (isInJava) {\n+    ucontext_t* uc = (ucontext_t*) ucontext;\n+    address pc = (address)uc->uc_mcontext.regs->nip;\n+\n+    if (pc == NULL) {\n+      \/\/ ucontext wasn't useful\n+      return false;\n+    }\n+\n+    frame ret_frame((intptr_t*)uc->uc_mcontext.regs->gpr[1\/*REG_SP*\/], pc);\n+\n+    if (ret_frame.fp() == NULL) {\n+      \/\/ The found frame does not have a valid frame pointer.\n+      \/\/ Bail out because this will create big trouble later on, either\n+      \/\/  - when using istate, calculated as (NULL - ijava_state_size) or\n+      \/\/  - when using fp() directly in safe_for_sender()\n+      \/\/\n+      \/\/ There is no conclusive description (yet) how this could happen, but it does.\n+      \/\/ For more details on what was observed, see thread_linux_s390.cpp\n+      return false;\n+    }\n+\n+    if (ret_frame.is_interpreted_frame()) {\n+      frame::ijava_state *istate = ret_frame.get_ijava_state();\n+      const Method *m = (const Method*)(istate->method);\n+      if (!Method::is_valid_method(m)) return false;\n+      if (!Metaspace::contains(m->constMethod())) return false;\n+\n+      uint64_t reg_bcp = uc->uc_mcontext.regs->gpr[14\/*R14_bcp*\/];\n+      uint64_t istate_bcp = istate->bcp;\n+      uint64_t code_start = (uint64_t)(m->code_base());\n+      uint64_t code_end = (uint64_t)(m->code_base() + m->code_size());\n+      if (istate_bcp >= code_start && istate_bcp < code_end) {\n+        \/\/ we have a valid bcp, don't touch it, do nothing\n+      } else if (reg_bcp >= code_start && reg_bcp < code_end) {\n+        istate->bcp = reg_bcp;\n+      } else {\n+        return false;\n+      }\n+    }\n+    if (!ret_frame.safe_for_sender(this)) {\n+      \/\/ nothing else to try if the frame isn't good\n+      return false;\n+    }\n+    *fr_addr = ret_frame;\n+    return true;\n+  }\n+  \/\/ nothing else to try\n+  return false;\n+}\n+\n+\/\/ Forte Analyzer AsyncGetCallTrace profiling support.\n+bool JavaThread::pd_get_top_frame_for_signal_handler(frame* fr_addr, void* ucontext, bool isInJava) {\n+  return pd_get_top_frame_for_profiling(fr_addr, ucontext, isInJava);\n+}\n+\n+void JavaThread::cache_global_variables() { }\n","filename":"src\/hotspot\/os_cpu\/linux_ppc\/javaThread_linux_ppc.cpp","additions":108,"deletions":0,"binary":false,"changes":108,"status":"added"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"gc\/g1\/g1ConcurrentRebuildAndScrub.hpp\"\n@@ -75,0 +76,1 @@\n+#include \"runtime\/threads.hpp\"\n@@ -364,2 +366,1 @@\n-                                   G1RegionToSpaceMapper* prev_bitmap_storage,\n-                                   G1RegionToSpaceMapper* next_bitmap_storage) :\n+                                   G1RegionToSpaceMapper* bitmap_storage) :\n@@ -369,4 +370,1 @@\n-  _mark_bitmap_1(),\n-  _mark_bitmap_2(),\n-  _prev_mark_bitmap(&_mark_bitmap_1),\n-  _next_mark_bitmap(&_mark_bitmap_2),\n+  _mark_bitmap(),\n@@ -421,2 +419,1 @@\n-  _mark_bitmap_1.initialize(g1h->reserved(), prev_bitmap_storage);\n-  _mark_bitmap_2.initialize(g1h->reserved(), next_bitmap_storage);\n+  _mark_bitmap.initialize(g1h->reserved(), bitmap_storage);\n@@ -469,1 +466,1 @@\n-    _tasks[i]->reset(_next_mark_bitmap);\n+    _tasks[i]->reset(mark_bitmap());\n@@ -502,6 +499,0 @@\n-static void clear_mark_if_set(G1CMBitMap* bitmap, HeapWord* addr) {\n-  if (bitmap->is_marked(addr)) {\n-    bitmap->clear(addr);\n-  }\n-}\n-\n@@ -511,3 +502,2 @@\n-  \/\/ Need to clear all mark bits of the humongous object.\n-  clear_mark_if_set(_prev_mark_bitmap, r->bottom());\n-  clear_mark_if_set(_next_mark_bitmap, r->bottom());\n+  \/\/ Need to clear mark bit of the humongous object. Doing this unconditionally is fine.\n+  mark_bitmap()->clear(r->bottom());\n@@ -589,1 +579,1 @@\n-  \/\/ Heap region closure used for clearing the _next_mark_bitmap.\n+  \/\/ Heap region closure used for clearing the _mark_bitmap.\n@@ -613,5 +603,3 @@\n-      \/\/ During a Concurrent Undo Mark cycle, the _next_mark_bitmap is  cleared\n-      \/\/ without swapping with the _prev_mark_bitmap. Therefore, the per region\n-      \/\/ next_top_at_mark_start and live_words data are current wrt\n-      \/\/ _next_mark_bitmap. We use this information to only clear ranges of the\n-      \/\/ bitmap that require clearing.\n+      \/\/ During a Concurrent Undo Mark cycle, the per region top_at_mark_start and\n+      \/\/ live_words data are current wrt to the _mark_bitmap. We use this information\n+      \/\/ to only clear ranges of the bitmap that require clearing.\n@@ -624,1 +612,1 @@\n-        assert(_bitmap->get_next_marked_addr(r->next_top_at_mark_start(), r->end()) == r->end(), \"Should not have marked bits above ntams\");\n+        assert(_bitmap->get_next_marked_addr(r->top_at_mark_start(), r->end()) == r->end(), \"Should not have marked bits above tams\");\n@@ -633,1 +621,1 @@\n-      _bitmap(cm->next_mark_bitmap()),\n+      _bitmap(cm->mark_bitmap()),\n@@ -668,0 +656,2 @@\n+      r->note_end_of_clearing();\n+\n@@ -694,1 +684,1 @@\n-void G1ConcurrentMark::clear_next_bitmap(WorkerThreads* workers, bool may_yield) {\n+void G1ConcurrentMark::clear_bitmap(WorkerThreads* workers, bool may_yield) {\n@@ -720,1 +710,1 @@\n-  clear_next_bitmap(_concurrent_workers, true);\n+  clear_bitmap(_concurrent_workers, true);\n@@ -727,1 +717,1 @@\n-void G1ConcurrentMark::clear_next_bitmap(WorkerThreads* workers) {\n+void G1ConcurrentMark::clear_bitmap(WorkerThreads* workers) {\n@@ -734,1 +724,1 @@\n-  clear_next_bitmap(workers, false);\n+  clear_bitmap(workers, false);\n@@ -957,1 +947,1 @@\n-  assert(hr->is_old() || hr->next_top_at_mark_start() == hr->bottom(),\n+  assert(hr->is_old() || hr->top_at_mark_start() == hr->bottom(),\n@@ -959,2 +949,2 @@\n-  assert(hr->next_top_at_mark_start() == region->start(),\n-         \"MemRegion start should be equal to nTAMS\");\n+  assert(hr->top_at_mark_start() == region->start(),\n+         \"MemRegion start should be equal to TAMS\");\n@@ -1028,1 +1018,1 @@\n-  _g1h->collector_state()->set_clearing_next_bitmap(false);\n+  _g1h->collector_state()->set_clearing_bitmap(false);\n@@ -1063,1 +1053,11 @@\n-void G1ConcurrentMark::verify_during_pause(G1HeapVerifier::G1VerifyType type, VerifyOption vo, const char* caller) {\n+const char* G1ConcurrentMark::verify_location_string(VerifyLocation location) {\n+  static const char* location_strings[] = { \"Remark Before\",\n+                                            \"Remark After\",\n+                                            \"Remark Overflow\",\n+                                            \"Cleanup Before\",\n+                                            \"Cleanup After\" };\n+  return location_strings[static_cast<std::underlying_type_t<VerifyLocation>>(location)];\n+}\n+\n+void G1ConcurrentMark::verify_during_pause(G1HeapVerifier::G1VerifyType type,\n+                                           VerifyLocation location) {\n@@ -1068,0 +1068,2 @@\n+  const char* caller = verify_location_string(location);\n+\n@@ -1075,2 +1077,1 @@\n-    verifier->verify(type, vo, buffer);\n-  }\n+    verifier->verify(type, VerifyOption::G1UseConcMarking, buffer);\n@@ -1078,1 +1079,6 @@\n-  verifier->check_bitmaps(caller);\n+    \/\/ Only check bitmap in Remark, and not at After-Verification because the regions\n+    \/\/ already have their TAMS'es reset.\n+    if (location != VerifyLocation::RemarkAfter) {\n+      verifier->verify_bitmap_clear(true \/* above_tams_only *\/);\n+    }\n+  }\n@@ -1118,1 +1124,1 @@\n-      size_t const obj_size_in_words = (size_t)cast_to_oop(hr->bottom())->size();\n+      size_t const obj_size_in_words = cast_to_oop(hr->bottom())->size();\n@@ -1161,1 +1167,1 @@\n-      hr->add_to_marked_bytes(marked_bytes);\n+      hr->note_end_of_marking(marked_bytes);\n@@ -1163,1 +1169,0 @@\n-      hr->note_end_of_marking();\n@@ -1197,1 +1202,1 @@\n-class G1UpdateRemSetTrackingAfterRebuild : public HeapRegionClosure {\n+class G1UpdateRegionsAfterRebuild : public HeapRegionClosure {\n@@ -1199,0 +1204,1 @@\n+\n@@ -1200,1 +1206,3 @@\n-  G1UpdateRemSetTrackingAfterRebuild(G1CollectedHeap* g1h) : _g1h(g1h) { }\n+  G1UpdateRegionsAfterRebuild(G1CollectedHeap* g1h) :\n+    _g1h(g1h) {\n+  }\n@@ -1203,0 +1211,2 @@\n+    \/\/ Update the remset tracking state from updating to complete\n+    \/\/ if remembered sets have been rebuilt.\n@@ -1222,1 +1232,1 @@\n-  verify_during_pause(G1HeapVerifier::G1VerifyRemark, VerifyOption::G1UsePrevMarking, \"Remark before\");\n+  verify_during_pause(G1HeapVerifier::G1VerifyRemark, VerifyLocation::RemarkBefore);\n@@ -1247,2 +1257,3 @@\n-    \/\/ Install newly created mark bitmap as \"prev\".\n-    swap_mark_bitmaps();\n+    \/\/ All marking completed. Check bitmap now as we will start to reset TAMSes\n+    \/\/ in parallel below so that we can not do this in the After-Remark verification.\n+    _g1h->verifier()->verify_bitmap_clear(true \/* above_tams_only *\/);\n@@ -1250,1 +1261,0 @@\n-    _g1h->collector_state()->set_clearing_next_bitmap(true);\n@@ -1283,1 +1293,1 @@\n-    verify_during_pause(G1HeapVerifier::G1VerifyRemark, VerifyOption::G1UsePrevMarking, \"Remark after\");\n+    verify_during_pause(G1HeapVerifier::G1VerifyRemark, VerifyLocation::RemarkAfter);\n@@ -1286,1 +1296,1 @@\n-    \/\/ Completely reset the marking state since marking completed\n+    \/\/ Completely reset the marking state (except bitmaps) since marking completed.\n@@ -1292,1 +1302,1 @@\n-    verify_during_pause(G1HeapVerifier::G1VerifyRemark, VerifyOption::G1UsePrevMarking, \"Remark overflow\");\n+    verify_during_pause(G1HeapVerifier::G1VerifyRemark, VerifyLocation::RemarkOverflow);\n@@ -1342,1 +1352,1 @@\n-      if (hr->used() > 0 && hr->max_live_bytes() == 0 && !hr->is_young() && !hr->is_closed_archive()) {\n+      if (hr->used() > 0 && hr->live_bytes() == 0 && !hr->is_young() && !hr->is_closed_archive()) {\n@@ -1438,1 +1448,1 @@\n-  verify_during_pause(G1HeapVerifier::G1VerifyCleanup, VerifyOption::G1UsePrevMarking, \"Cleanup before\");\n+  verify_during_pause(G1HeapVerifier::G1VerifyCleanup, VerifyLocation::CleanupBefore);\n@@ -1441,0 +1451,2 @@\n+    \/\/ Update the remset tracking information as well as marking all regions\n+    \/\/ as fully parsable.\n@@ -1442,1 +1454,1 @@\n-    G1UpdateRemSetTrackingAfterRebuild cl(_g1h);\n+    G1UpdateRegionsAfterRebuild cl(_g1h);\n@@ -1448,1 +1460,1 @@\n-  verify_during_pause(G1HeapVerifier::G1VerifyCleanup, VerifyOption::G1UsePrevMarking, \"Cleanup after\");\n+  verify_during_pause(G1HeapVerifier::G1VerifyCleanup, VerifyLocation::CleanupAfter);\n@@ -1713,2 +1725,0 @@\n-\/\/ When sampling object counts, we already swapped the mark bitmaps, so we need to use\n-\/\/ the prev bitmap determining liveness.\n@@ -1728,1 +1738,1 @@\n-  \/\/ using either the next or prev bitmap.\n+  \/\/ using either the bitmap or after the cycle using the scrubbing information.\n@@ -1738,7 +1748,0 @@\n-\n-void G1ConcurrentMark::swap_mark_bitmaps() {\n-  G1CMBitMap* temp = _prev_mark_bitmap;\n-  _prev_mark_bitmap = _next_mark_bitmap;\n-  _next_mark_bitmap = temp;\n-}\n-\n@@ -1876,2 +1879,4 @@\n-void G1ConcurrentMark::clear_range_in_prev_bitmap(MemRegion mr) {\n-  _prev_mark_bitmap->clear_range(mr);\n+void G1ConcurrentMark::clear_bitmap_for_region(HeapRegion* hr) {\n+  assert_at_safepoint();\n+  _mark_bitmap.clear_range(MemRegion(hr->bottom(), hr->end()));\n+  hr->note_end_of_clearing();\n@@ -1880,2 +1885,1 @@\n-HeapRegion*\n-G1ConcurrentMark::claim_region(uint worker_id) {\n+HeapRegion* G1ConcurrentMark::claim_region(uint worker_id) {\n@@ -1899,2 +1903,2 @@\n-      HeapWord*   bottom        = curr_region->bottom();\n-      HeapWord*   limit         = curr_region->next_top_at_mark_start();\n+      HeapWord* bottom = curr_region->bottom();\n+      HeapWord* limit = curr_region->top_at_mark_start();\n@@ -1997,3 +2001,1 @@\n-void G1ConcurrentMark::rebuild_rem_set_concurrently() {\n-  \/\/ If Remark did not select any regions for RemSet rebuild,\n-  \/\/ skip the rebuild remembered set phase\n+void G1ConcurrentMark::rebuild_and_scrub() {\n@@ -2001,2 +2003,1 @@\n-    log_debug(gc, marking)(\"Skipping Remembered Set Rebuild. No regions selected for rebuild\");\n-    return;\n+    log_debug(gc, marking)(\"Skipping Remembered Set Rebuild. No regions selected for rebuild, will only scrub\");\n@@ -2004,1 +2005,2 @@\n-  _g1h->rem_set()->rebuild_rem_set(this, _concurrent_workers, _worker_id_offset);\n+\n+  G1ConcurrentRebuildAndScrub::rebuild_and_scrub(this, needs_remembered_set_rebuild(), _concurrent_workers);\n@@ -2018,1 +2020,1 @@\n-void G1ConcurrentMark::concurrent_cycle_abort() {\n+bool G1ConcurrentMark::concurrent_cycle_abort() {\n@@ -2029,8 +2031,1 @@\n-    return;\n-  }\n-\n-  \/\/ Clear all marks in the next bitmap for this full gc as it has been used by the\n-  \/\/ marking that is interrupted by this full gc.\n-  {\n-    GCTraceTime(Debug, gc) debug(\"Clear Next Bitmap\");\n-    clear_next_bitmap(_g1h->workers());\n+    return false;\n@@ -2038,3 +2033,0 @@\n-  \/\/ Note we cannot clear the previous marking bitmap here\n-  \/\/ since VerifyDuringGC verifies the objects marked during\n-  \/\/ a full GC against the previous bitmap.\n@@ -2054,3 +2046,3 @@\n-  satb_mq_set.set_active_all_threads(\n-                                 false, \/* new active value *\/\n-                                 satb_mq_set.is_active() \/* expected_active *\/);\n+  satb_mq_set.set_active_all_threads(false, \/* new active value *\/\n+                                     satb_mq_set.is_active() \/* expected_active *\/);\n+  return true;\n@@ -2104,4 +2096,2 @@\n-  st->print_cr(\"Marking Bits (Prev, Next): (CMBitMap*) \" PTR_FORMAT \", (CMBitMap*) \" PTR_FORMAT,\n-               p2i(_prev_mark_bitmap), p2i(_next_mark_bitmap));\n-  _prev_mark_bitmap->print_on_error(st, \" Prev Bits: \");\n-  _next_mark_bitmap->print_on_error(st, \" Next Bits: \");\n+  st->print_cr(\"Marking Bits: (CMBitMap*) \" PTR_FORMAT, p2i(mark_bitmap()));\n+  _mark_bitmap.print_on_error(st, \" Bits: \");\n@@ -2131,3 +2121,3 @@\n-  HeapRegion* hr            = _curr_region;\n-  HeapWord* bottom          = hr->bottom();\n-  HeapWord* limit           = hr->next_top_at_mark_start();\n+  HeapRegion* hr = _curr_region;\n+  HeapWord* bottom = hr->bottom();\n+  HeapWord* limit = hr->top_at_mark_start();\n@@ -2147,2 +2137,2 @@\n-    \/\/ evacuation pause empties the region underneath our feet (NTAMS\n-    \/\/ at bottom). We then do some allocation in the region (NTAMS\n+    \/\/ evacuation pause empties the region underneath our feet (TAMS\n+    \/\/ at bottom). We then do some allocation in the region (TAMS\n@@ -2150,1 +2140,1 @@\n-    \/\/ alloc region (NTAMS will move to top() and the objects\n+    \/\/ alloc region (TAMS will move to top() and the objects\n@@ -2184,3 +2174,3 @@\n-void G1CMTask::reset(G1CMBitMap* next_mark_bitmap) {\n-  guarantee(next_mark_bitmap != NULL, \"invariant\");\n-  _next_mark_bitmap              = next_mark_bitmap;\n+void G1CMTask::reset(G1CMBitMap* mark_bitmap) {\n+  guarantee(mark_bitmap != NULL, \"invariant\");\n+  _mark_bitmap              = mark_bitmap;\n@@ -2670,1 +2660,1 @@\n-        if (_next_mark_bitmap->is_marked(mr.start())) {\n+        if (_mark_bitmap->is_marked(mr.start())) {\n@@ -2678,1 +2668,1 @@\n-      } else if (_next_mark_bitmap->iterate(&bitmap_closure, mr)) {\n+      } else if (_mark_bitmap->iterate(&bitmap_closure, mr)) {\n@@ -2896,1 +2886,1 @@\n-  _next_mark_bitmap(NULL),\n+  _mark_bitmap(NULL),\n@@ -2962,3 +2952,5 @@\n-  _total_used_bytes(0), _total_capacity_bytes(0),\n-  _total_prev_live_bytes(0), _total_next_live_bytes(0),\n-  _total_remset_bytes(0), _total_code_roots_bytes(0)\n+  _total_used_bytes(0),\n+  _total_capacity_bytes(0),\n+  _total_live_bytes(0),\n+  _total_remset_bytes(0),\n+  _total_code_roots_bytes(0)\n@@ -2987,1 +2979,0 @@\n-                          G1PPRL_BYTE_H_FORMAT\n@@ -2993,1 +2984,1 @@\n-                          \"used\", \"prev-live\", \"next-live\", \"gc-eff\",\n+                          \"used\", \"live\", \"gc-eff\",\n@@ -3000,1 +2991,0 @@\n-                          G1PPRL_BYTE_H_FORMAT\n@@ -3006,1 +2996,1 @@\n-                          \"(bytes)\", \"(bytes)\", \"(bytes)\", \"(bytes\/ms)\",\n+                          \"(bytes)\", \"(bytes)\", \"(bytes\/ms)\",\n@@ -3020,2 +3010,1 @@\n-  size_t prev_live_bytes = r->live_bytes();\n-  size_t next_live_bytes = r->next_live_bytes();\n+  size_t live_bytes      = r->live_bytes();\n@@ -3030,2 +3019,1 @@\n-  _total_prev_live_bytes += prev_live_bytes;\n-  _total_next_live_bytes += next_live_bytes;\n+  _total_live_bytes      += live_bytes;\n@@ -3047,1 +3035,0 @@\n-                        G1PPRL_BYTE_FORMAT\n@@ -3053,1 +3040,1 @@\n-                        used_bytes, prev_live_bytes, next_live_bytes, gc_efficiency.buffer(),\n+                        used_bytes, live_bytes, gc_efficiency.buffer(),\n@@ -3072,2 +3059,1 @@\n-                         G1PPRL_SUM_MB_PERC_FORMAT(\"prev-live\")\n-                         G1PPRL_SUM_MB_PERC_FORMAT(\"next-live\")\n+                         G1PPRL_SUM_MB_PERC_FORMAT(\"live\")\n@@ -3079,4 +3065,2 @@\n-                         bytes_to_mb(_total_prev_live_bytes),\n-                         percent_of(_total_prev_live_bytes, _total_capacity_bytes),\n-                         bytes_to_mb(_total_next_live_bytes),\n-                         percent_of(_total_next_live_bytes, _total_capacity_bytes),\n+                         bytes_to_mb(_total_live_bytes),\n+                         percent_of(_total_live_bytes, _total_capacity_bytes),\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":110,"deletions":126,"binary":false,"changes":236,"status":"modified"},{"patch":"@@ -32,1 +32,1 @@\n-#include \"runtime\/thread.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n","filename":"src\/hotspot\/share\/jfr\/recorder\/storage\/jfrStorageUtils.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"runtime\/thread.inline.hpp\"\n+#include \"runtime\/javaThread.hpp\"\n","filename":"src\/hotspot\/share\/jfr\/recorder\/storage\/jfrStorageUtils.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2963,0 +2963,3 @@\n+        \/** NOTE: if annotation processors are present, annotation processing rounds can happen after this method,\n+         *  this can impact in particular records for which annotations are forcibly propagated.\n+         *\/\n@@ -3603,1 +3606,1 @@\n-        if ((s.flags() & PREVIEW_API) != 0 && !preview.participatesInPreview(other, s)) {\n+        if ((s.flags() & PREVIEW_API) != 0 && !preview.participatesInPreview(syms, other, s)) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -31,4 +31,0 @@\n-\n-\n-serviceability\/sa\/TestJhsdbJstackMixed.java 8248675 linux-aarch64\n-\n@@ -40,0 +36,3 @@\n+serviceability\/sa\/TestJhsdbJstackMixed.java 8248675 linux-aarch64\n+\n+serviceability\/jvmti\/VMObjectAlloc\/VMObjectAllocTest.java 8288430 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList-Xcomp.txt","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -604,2 +604,0 @@\n-security\/infra\/java\/security\/cert\/CertPathValidator\/certification\/ActalisCA.java  8224768 generic-all\n-\n@@ -664,1 +662,0 @@\n-javax\/swing\/JPopupMenu\/6580930\/bug6580930.java 7124313 macosx-all\n@@ -674,1 +671,0 @@\n-javax\/swing\/Popup\/TaskbarPositionTest.java 8065097 macosx-all,linux-all\n@@ -684,1 +680,0 @@\n-javax\/swing\/JTable\/8236907\/LastVisibleRow.java 8284619 macosx-all\n","filename":"test\/jdk\/ProblemList.txt","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"}]}