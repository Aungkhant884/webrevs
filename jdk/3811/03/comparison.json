{"files":[{"patch":"@@ -60,0 +60,3 @@\n+  \/\/ Worker cost for \"almost no work\" to be done.\n+  static constexpr double AlmostNoWork = 0.01;\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1BatchedGangTask.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-#include \"gc\/g1\/g1CardTableEntryClosure.hpp\"\n@@ -71,0 +70,1 @@\n+#include \"gc\/g1\/g1YoungGCPostEvacuateTasks.hpp\"\n@@ -127,34 +127,0 @@\n-class RedirtyLoggedCardTableEntryClosure : public G1CardTableEntryClosure {\n- private:\n-  size_t _num_dirtied;\n-  G1CollectedHeap* _g1h;\n-  G1CardTable* _g1_ct;\n-\n-  HeapRegion* region_for_card(CardValue* card_ptr) const {\n-    return _g1h->heap_region_containing(_g1_ct->addr_for(card_ptr));\n-  }\n-\n-  bool will_become_free(HeapRegion* hr) const {\n-    \/\/ A region will be freed by free_collection_set if the region is in the\n-    \/\/ collection set and has not had an evacuation failure.\n-    return _g1h->is_in_cset(hr) && !hr->evacuation_failed();\n-  }\n-\n- public:\n-  RedirtyLoggedCardTableEntryClosure(G1CollectedHeap* g1h) : G1CardTableEntryClosure(),\n-    _num_dirtied(0), _g1h(g1h), _g1_ct(g1h->card_table()) { }\n-\n-  void do_card_ptr(CardValue* card_ptr, uint worker_id) {\n-    HeapRegion* hr = region_for_card(card_ptr);\n-\n-    \/\/ Should only dirty cards in regions that won't be freed.\n-    if (!will_become_free(hr)) {\n-      *card_ptr = G1CardTable::dirty_card_val();\n-      _num_dirtied++;\n-    }\n-  }\n-\n-  size_t num_dirtied()   const { return _num_dirtied; }\n-};\n-\n-\n@@ -177,0 +143,6 @@\n+void G1CollectedHeap::run_batch_task(G1BatchedGangTask* cl) {\n+  uint num_workers = MAX2(1u, MIN2(cl->num_workers_estimate(), workers()->active_workers()));\n+  cl->set_max_workers(num_workers);\n+  workers()->run_task(cl, num_workers);\n+}\n+\n@@ -1429,1 +1401,2 @@\n-  _has_humongous_reclaim_candidates(false),\n+  _num_humongous_reclaim_total_objects(0),\n+  _num_humongous_reclaim_candidate_objects(0),\n@@ -3089,22 +3062,0 @@\n-void G1CollectedHeap::remove_self_forwarding_pointers(G1RedirtyCardsQueueSet* rdcqs) {\n-  uint num_workers = MIN2(workers()->active_workers(), num_regions_failed_evacuation());\n-\n-  G1ParRemoveSelfForwardPtrsTask cl(rdcqs);\n-  log_debug(gc, ergo)(\"Running %s using %u workers for %u failed regions\",\n-                      cl.name(), num_workers, num_regions_failed_evacuation());\n-  workers()->run_task(&cl, num_workers);\n-\n-  assert(cl.num_failed_regions() == num_regions_failed_evacuation(),\n-         \"Removed regions %u inconsistent with expected %u\",\n-         cl.num_failed_regions(), num_regions_failed_evacuation());\n-}\n-\n-void G1CollectedHeap::restore_after_evac_failure(G1RedirtyCardsQueueSet* rdcqs) {\n-  double remove_self_forwards_start = os::elapsedTime();\n-\n-  remove_self_forwarding_pointers(rdcqs);\n-  _preserved_marks_set.restore(workers());\n-\n-  phase_times()->record_evac_fail_remove_self_forwards((os::elapsedTime() - remove_self_forwards_start) * 1000.0);\n-}\n-\n@@ -3190,47 +3141,0 @@\n-class G1RedirtyLoggedCardsTask : public AbstractGangTask {\n- private:\n-  G1RedirtyCardsQueueSet* _qset;\n-  G1CollectedHeap* _g1h;\n-  BufferNode* volatile _nodes;\n-\n-  void par_apply(RedirtyLoggedCardTableEntryClosure* cl, uint worker_id) {\n-    size_t buffer_size = _qset->buffer_size();\n-    BufferNode* next = Atomic::load(&_nodes);\n-    while (next != NULL) {\n-      BufferNode* node = next;\n-      next = Atomic::cmpxchg(&_nodes, node, node->next());\n-      if (next == node) {\n-        cl->apply_to_buffer(node, buffer_size, worker_id);\n-        next = node->next();\n-      }\n-    }\n-  }\n-\n- public:\n-  G1RedirtyLoggedCardsTask(G1RedirtyCardsQueueSet* qset, G1CollectedHeap* g1h) :\n-    AbstractGangTask(\"Redirty Cards\"),\n-    _qset(qset), _g1h(g1h), _nodes(qset->all_completed_buffers()) { }\n-\n-  virtual void work(uint worker_id) {\n-    G1GCPhaseTimes* p = _g1h->phase_times();\n-    G1GCParPhaseTimesTracker x(p, G1GCPhaseTimes::RedirtyCards, worker_id);\n-\n-    RedirtyLoggedCardTableEntryClosure cl(_g1h);\n-    par_apply(&cl, worker_id);\n-\n-    p->record_thread_work_item(G1GCPhaseTimes::RedirtyCards, worker_id, cl.num_dirtied());\n-  }\n-};\n-\n-void G1CollectedHeap::redirty_logged_cards(G1RedirtyCardsQueueSet* rdcqs) {\n-  double redirty_logged_cards_start = os::elapsedTime();\n-\n-  G1RedirtyLoggedCardsTask redirty_task(rdcqs, this);\n-  workers()->run_task(&redirty_task);\n-\n-  G1DirtyCardQueueSet& dcq = G1BarrierSet::dirty_card_queue_set();\n-  dcq.merge_bufferlists(rdcqs);\n-\n-  phase_times()->record_redirty_logged_cards_time_ms((os::elapsedTime() - redirty_logged_cards_start) * 1000.0);\n-}\n-\n@@ -3516,4 +3420,3 @@\n-void G1CollectedHeap::merge_per_thread_state_info(G1ParScanThreadStateSet* per_thread_states) {\n-  Ticks start = Ticks::now();\n-  per_thread_states->flush();\n-  phase_times()->record_or_add_time_secs(G1GCPhaseTimes::MergePSS, 0 \/* worker_id *\/, (Ticks::now() - start).seconds());\n+bool G1CollectedHeap::eagerly_reclaim_enabled() const {\n+  return (G1EagerReclaimHumongousObjects &&\n+          (G1CollectedHeap::heap()->has_humongous_reclaim_candidate_objects() || log_is_enabled(Debug, gc, humongous)));\n@@ -3526,2 +3429,2 @@\n-    size_t _worker_humongous_total;\n-    size_t _worker_humongous_candidates;\n+    uint _worker_humongous_total;\n+    uint _worker_humongous_candidates;\n@@ -3625,2 +3528,2 @@\n-  volatile size_t _humongous_total;\n-  volatile size_t _humongous_candidates;\n+  volatile uint _humongous_total;\n+  volatile uint _humongous_candidates;\n@@ -3635,4 +3538,0 @@\n-  ~G1PrepareEvacuationTask() {\n-    _g1h->set_has_humongous_reclaim_candidate(_humongous_candidates > 0);\n-  }\n-\n@@ -3644,1 +3543,1 @@\n-  void add_humongous_candidates(size_t candidates) {\n+  void add_humongous_candidates(uint candidates) {\n@@ -3648,1 +3547,1 @@\n-  void add_humongous_total(size_t total) {\n+  void add_humongous_total(uint total) {\n@@ -3652,1 +3551,1 @@\n-  size_t humongous_candidates() {\n+  uint humongous_candidates() {\n@@ -3656,1 +3555,1 @@\n-  size_t humongous_total() {\n+  uint humongous_total() {\n@@ -3684,3 +3583,3 @@\n-    phase_times()->record_register_regions(task_time.seconds() * 1000.0,\n-                                           g1_prep_task.humongous_total(),\n-                                           g1_prep_task.humongous_candidates());\n+    phase_times()->record_register_regions(task_time.seconds() * 1000.0);\n+    _num_humongous_reclaim_total_objects = g1_prep_task.humongous_total();\n+    _num_humongous_reclaim_candidate_objects = g1_prep_task.humongous_candidates();\n@@ -3930,2 +3829,0 @@\n-  rem_set()->cleanup_after_scan_heap_roots();\n-\n@@ -3955,27 +3852,1 @@\n-  if (evacuation_failed()) {\n-    restore_after_evac_failure(rdcqs);\n-\n-    \/\/ Reset the G1EvacuationFailureALot counters and flags\n-    NOT_PRODUCT(reset_evacuation_should_fail();)\n-\n-    double recalculate_used_start = os::elapsedTime();\n-    set_used(recalculate_used());\n-    p->record_evac_fail_recalc_used_time((os::elapsedTime() - recalculate_used_start) * 1000.0);\n-\n-    if (_archive_allocator != NULL) {\n-      _archive_allocator->clear_used();\n-    }\n-    for (uint i = 0; i < ParallelGCThreads; i++) {\n-      if (_evacuation_failed_info_array[i].has_failed()) {\n-        _gc_tracer_stw->report_evacuation_failed(_evacuation_failed_info_array[i]);\n-      }\n-    }\n-  } else {\n-    \/\/ The \"used\" of the the collection set have already been subtracted\n-    \/\/ when they were freed.  Add in the bytes used.\n-    increase_used(_bytes_used_during_gc);\n-  }\n-\n-  _preserved_marks_set.assert_empty();\n-\n-  merge_per_thread_state_info(per_thread_states);\n+  post_evacuate_cleanup_1(per_thread_states, rdcqs);\n@@ -3983,7 +3854,1 @@\n-  \/\/ Reset and re-enable the hot card cache.\n-  \/\/ Note the counts for the cards in the regions in the\n-  \/\/ collection set are reset when the collection set is freed.\n-  _hot_card_cache->reset_hot_cache();\n-  _hot_card_cache->set_use_cache(true);\n-\n-  purge_code_root_memory();\n+  post_evacuate_cleanup_2(&_preserved_marks_set, rdcqs, &evacuation_info, per_thread_states->surviving_young_words());\n@@ -3991,5 +3856,1 @@\n-  redirty_logged_cards(rdcqs);\n-\n-  free_collection_set(&_collection_set, evacuation_info, per_thread_states->surviving_young_words());\n-\n-  eagerly_reclaim_humongous_regions();\n+  assert_used_and_recalculate_used_equal(this);\n@@ -4004,5 +3865,0 @@\n-#if COMPILER2_OR_JVMCI\n-  double start = os::elapsedTime();\n-  DerivedPointerTable::update_pointers();\n-  phase_times()->record_derived_pointer_table_update_time((os::elapsedTime() - start) * 1000.0);\n-#endif\n@@ -4077,260 +3933,3 @@\n-class G1FreeCollectionSetTask : public AbstractGangTask {\n-  \/\/ Helper class to keep statistics for the collection set freeing\n-  class FreeCSetStats {\n-    size_t _before_used_bytes;   \/\/ Usage in regions successfully evacutate\n-    size_t _after_used_bytes;    \/\/ Usage in regions failing evacuation\n-    size_t _bytes_allocated_in_old_since_last_gc; \/\/ Size of young regions turned into old\n-    size_t _failure_used_words;  \/\/ Live size in failed regions\n-    size_t _failure_waste_words; \/\/ Wasted size in failed regions\n-    size_t _rs_length;           \/\/ Remembered set size\n-    uint _regions_freed;         \/\/ Number of regions freed\n-  public:\n-    FreeCSetStats() :\n-        _before_used_bytes(0),\n-        _after_used_bytes(0),\n-        _bytes_allocated_in_old_since_last_gc(0),\n-        _failure_used_words(0),\n-        _failure_waste_words(0),\n-        _rs_length(0),\n-        _regions_freed(0) { }\n-\n-    void merge_stats(FreeCSetStats* other) {\n-      assert(other != NULL, \"invariant\");\n-      _before_used_bytes += other->_before_used_bytes;\n-      _after_used_bytes += other->_after_used_bytes;\n-      _bytes_allocated_in_old_since_last_gc += other->_bytes_allocated_in_old_since_last_gc;\n-      _failure_used_words += other->_failure_used_words;\n-      _failure_waste_words += other->_failure_waste_words;\n-      _rs_length += other->_rs_length;\n-      _regions_freed += other->_regions_freed;\n-    }\n-\n-    void report(G1CollectedHeap* g1h, G1EvacuationInfo* evacuation_info) {\n-      evacuation_info->set_regions_freed(_regions_freed);\n-      evacuation_info->increment_collectionset_used_after(_after_used_bytes);\n-\n-      g1h->decrement_summary_bytes(_before_used_bytes);\n-      g1h->alloc_buffer_stats(G1HeapRegionAttr::Old)->add_failure_used_and_waste(_failure_used_words, _failure_waste_words);\n-\n-      G1Policy *policy = g1h->policy();\n-      policy->old_gen_alloc_tracker()->add_allocated_bytes_since_last_gc(_bytes_allocated_in_old_since_last_gc);\n-      policy->record_rs_length(_rs_length);\n-      policy->cset_regions_freed();\n-    }\n-\n-    void account_failed_region(HeapRegion* r) {\n-      size_t used_words = r->marked_bytes() \/ HeapWordSize;\n-      _failure_used_words += used_words;\n-      _failure_waste_words += HeapRegion::GrainWords - used_words;\n-      _after_used_bytes += r->used();\n-\n-      \/\/ When moving a young gen region to old gen, we \"allocate\" that whole\n-      \/\/ region there. This is in addition to any already evacuated objects.\n-      \/\/ Notify the policy about that. Old gen regions do not cause an\n-      \/\/ additional allocation: both the objects still in the region and the\n-      \/\/ ones already moved are accounted for elsewhere.\n-      if (r->is_young()) {\n-        _bytes_allocated_in_old_since_last_gc += HeapRegion::GrainBytes;\n-      }\n-    }\n-\n-    void account_evacuated_region(HeapRegion* r) {\n-      _before_used_bytes += r->used();\n-      _regions_freed += 1;\n-    }\n-\n-    void account_rs_length(HeapRegion* r) {\n-      _rs_length += r->rem_set()->occupied();\n-    }\n-  };\n-\n-  \/\/ Closure applied to all regions in the collection set.\n-  class FreeCSetClosure : public HeapRegionClosure {\n-    \/\/ Helper to send JFR events for regions.\n-    class JFREventForRegion {\n-      EventGCPhaseParallel _event;\n-    public:\n-      JFREventForRegion(HeapRegion* region, uint worker_id) : _event() {\n-        _event.set_gcId(GCId::current());\n-        _event.set_gcWorkerId(worker_id);\n-        if (region->is_young()) {\n-          _event.set_name(G1GCPhaseTimes::phase_name(G1GCPhaseTimes::YoungFreeCSet));\n-        } else {\n-          _event.set_name(G1GCPhaseTimes::phase_name(G1GCPhaseTimes::NonYoungFreeCSet));\n-        }\n-      }\n-\n-      ~JFREventForRegion() {\n-        _event.commit();\n-      }\n-    };\n-\n-    \/\/ Helper to do timing for region work.\n-    class TimerForRegion {\n-      Tickspan& _time;\n-      Ticks     _start_time;\n-    public:\n-      TimerForRegion(Tickspan& time) : _time(time), _start_time(Ticks::now()) { }\n-      ~TimerForRegion() {\n-        _time += Ticks::now() - _start_time;\n-      }\n-    };\n-\n-    \/\/ FreeCSetClosure members\n-    G1CollectedHeap* _g1h;\n-    const size_t*    _surviving_young_words;\n-    uint             _worker_id;\n-    Tickspan         _young_time;\n-    Tickspan         _non_young_time;\n-    FreeCSetStats*   _stats;\n-\n-    void assert_in_cset(HeapRegion* r) {\n-      assert(r->young_index_in_cset() != 0 &&\n-             (uint)r->young_index_in_cset() <= _g1h->collection_set()->young_region_length(),\n-             \"Young index %u is wrong for region %u of type %s with %u young regions\",\n-             r->young_index_in_cset(), r->hrm_index(), r->get_type_str(), _g1h->collection_set()->young_region_length());\n-    }\n-\n-    void handle_evacuated_region(HeapRegion* r) {\n-      assert(!r->is_empty(), \"Region %u is an empty region in the collection set.\", r->hrm_index());\n-      stats()->account_evacuated_region(r);\n-\n-      \/\/ Free the region and and its remembered set.\n-      _g1h->free_region(r, NULL);\n-      _g1h->hr_printer()->cleanup(r);\n-    }\n-\n-    void handle_failed_region(HeapRegion* r) {\n-      \/\/ Do some allocation statistics accounting. Regions that failed evacuation\n-      \/\/ are always made old, so there is no need to update anything in the young\n-      \/\/ gen statistics, but we need to update old gen statistics.\n-      stats()->account_failed_region(r);\n-\n-      \/\/ Update the region state due to the failed evacuation.\n-      r->handle_evacuation_failure();\n-\n-      \/\/ Add region to old set, need to hold lock.\n-      MutexLocker x(OldSets_lock, Mutex::_no_safepoint_check_flag);\n-      _g1h->old_set_add(r);\n-    }\n-\n-    Tickspan& timer_for_region(HeapRegion* r) {\n-      return r->is_young() ? _young_time : _non_young_time;\n-    }\n-\n-    FreeCSetStats* stats() {\n-      return _stats;\n-    }\n-  public:\n-    FreeCSetClosure(const size_t* surviving_young_words,\n-                    uint worker_id,\n-                    FreeCSetStats* stats) :\n-        HeapRegionClosure(),\n-        _g1h(G1CollectedHeap::heap()),\n-        _surviving_young_words(surviving_young_words),\n-        _worker_id(worker_id),\n-        _young_time(),\n-        _non_young_time(),\n-        _stats(stats) { }\n-\n-    virtual bool do_heap_region(HeapRegion* r) {\n-      assert(r->in_collection_set(), \"Invariant: %u missing from CSet\", r->hrm_index());\n-      JFREventForRegion event(r, _worker_id);\n-      TimerForRegion timer(timer_for_region(r));\n-\n-      _g1h->clear_region_attr(r);\n-      stats()->account_rs_length(r);\n-\n-      if (r->is_young()) {\n-        assert_in_cset(r);\n-        r->record_surv_words_in_group(_surviving_young_words[r->young_index_in_cset()]);\n-      }\n-\n-      if (r->evacuation_failed()) {\n-        handle_failed_region(r);\n-      } else {\n-        handle_evacuated_region(r);\n-      }\n-      assert(!_g1h->is_on_master_free_list(r), \"sanity\");\n-\n-      return false;\n-    }\n-\n-    void report_timing(Tickspan parallel_time) {\n-      G1GCPhaseTimes* pt = _g1h->phase_times();\n-      pt->record_time_secs(G1GCPhaseTimes::ParFreeCSet, _worker_id, parallel_time.seconds());\n-      if (_young_time.value() > 0) {\n-        pt->record_time_secs(G1GCPhaseTimes::YoungFreeCSet, _worker_id, _young_time.seconds());\n-      }\n-      if (_non_young_time.value() > 0) {\n-        pt->record_time_secs(G1GCPhaseTimes::NonYoungFreeCSet, _worker_id, _non_young_time.seconds());\n-      }\n-    }\n-  };\n-\n-  \/\/ G1FreeCollectionSetTask members\n-  G1CollectedHeap*  _g1h;\n-  G1EvacuationInfo* _evacuation_info;\n-  FreeCSetStats*    _worker_stats;\n-  HeapRegionClaimer _claimer;\n-  const size_t*     _surviving_young_words;\n-  uint              _active_workers;\n-\n-  FreeCSetStats* worker_stats(uint worker) {\n-    return &_worker_stats[worker];\n-  }\n-\n-  void report_statistics() {\n-    \/\/ Merge the accounting\n-    FreeCSetStats total_stats;\n-    for (uint worker = 0; worker < _active_workers; worker++) {\n-      total_stats.merge_stats(worker_stats(worker));\n-    }\n-    total_stats.report(_g1h, _evacuation_info);\n-  }\n-\n-public:\n-  G1FreeCollectionSetTask(G1EvacuationInfo* evacuation_info, const size_t* surviving_young_words, uint active_workers) :\n-      AbstractGangTask(\"G1 Free Collection Set\"),\n-      _g1h(G1CollectedHeap::heap()),\n-      _evacuation_info(evacuation_info),\n-      _worker_stats(NEW_C_HEAP_ARRAY(FreeCSetStats, active_workers, mtGC)),\n-      _claimer(active_workers),\n-      _surviving_young_words(surviving_young_words),\n-      _active_workers(active_workers) {\n-    for (uint worker = 0; worker < active_workers; worker++) {\n-      ::new (&_worker_stats[worker]) FreeCSetStats();\n-    }\n-  }\n-\n-  ~G1FreeCollectionSetTask() {\n-    Ticks serial_time = Ticks::now();\n-    report_statistics();\n-    for (uint worker = 0; worker < _active_workers; worker++) {\n-      _worker_stats[worker].~FreeCSetStats();\n-    }\n-    FREE_C_HEAP_ARRAY(FreeCSetStats, _worker_stats);\n-    _g1h->phase_times()->record_serial_free_cset_time_ms((Ticks::now() - serial_time).seconds() * 1000.0);\n-  }\n-\n-  virtual void work(uint worker_id) {\n-    EventGCPhaseParallel event;\n-    Ticks start = Ticks::now();\n-    FreeCSetClosure cl(_surviving_young_words, worker_id, worker_stats(worker_id));\n-    _g1h->collection_set_par_iterate_all(&cl, &_claimer, worker_id);\n-\n-    \/\/ Report the total parallel time along with some more detailed metrics.\n-    cl.report_timing(Ticks::now() - start);\n-    event.commit(GCId::current(), worker_id, G1GCPhaseTimes::phase_name(G1GCPhaseTimes::ParFreeCSet));\n-  }\n-};\n-\n-void G1CollectedHeap::free_collection_set(G1CollectionSet* collection_set, G1EvacuationInfo& evacuation_info, const size_t* surviving_young_words) {\n-  _eden.clear();\n-\n-  \/\/ The free collections set is split up in two tasks, the first\n-  \/\/ frees the collection set and records what regions are free,\n-  \/\/ and the second one rebuilds the free list. This proved to be\n-  \/\/ more efficient than adding a sorted list to another.\n-\n-  Ticks free_cset_start_time = Ticks::now();\n+void G1CollectedHeap::post_evacuate_cleanup_1(G1ParScanThreadStateSet* per_thread_states,\n+                                              G1RedirtyCardsQueueSet* rdcqs) {\n+  Ticks start = Ticks::now();\n@@ -4338,7 +3937,2 @@\n-    uint const num_cs_regions = _collection_set.region_length();\n-    uint const num_workers = clamp(num_cs_regions, 1u, workers()->active_workers());\n-    G1FreeCollectionSetTask cl(&evacuation_info, surviving_young_words, num_workers);\n-\n-    log_debug(gc, ergo)(\"Running %s using %u workers for collection set length %u (%u)\",\n-                        cl.name(), num_workers, num_cs_regions, num_regions());\n-    workers()->run_task(&cl, num_workers);\n+    G1PostEvacuateCollectionSetCleanupTask1 cl(per_thread_states, rdcqs);\n+    run_batch_task(&cl);\n@@ -4346,5 +3940,1 @@\n-\n-  Ticks free_cset_end_time = Ticks::now();\n-  phase_times()->record_total_free_cset_time_ms((free_cset_end_time - free_cset_start_time).seconds() * 1000.0);\n-\n-  collection_set->clear();\n+  phase_times()->record_post_evacuate_cleanup_task_1_time((Ticks::now() - start).seconds() * 1000.0);\n@@ -4353,120 +3943,8 @@\n-class G1FreeHumongousRegionClosure : public HeapRegionClosure {\n-  uint _humongous_objects_reclaimed;\n-  uint _humongous_regions_reclaimed;\n-  size_t _freed_bytes;\n-public:\n-\n-  G1FreeHumongousRegionClosure() :\n-    _humongous_objects_reclaimed(0), _humongous_regions_reclaimed(0), _freed_bytes(0) {\n-  }\n-\n-  virtual bool do_heap_region(HeapRegion* r) {\n-    if (!r->is_starts_humongous()) {\n-      return false;\n-    }\n-\n-    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n-\n-    oop obj = cast_to_oop(r->bottom());\n-    G1CMBitMap* next_bitmap = g1h->concurrent_mark()->next_mark_bitmap();\n-\n-    \/\/ The following checks whether the humongous object is live are sufficient.\n-    \/\/ The main additional check (in addition to having a reference from the roots\n-    \/\/ or the young gen) is whether the humongous object has a remembered set entry.\n-    \/\/\n-    \/\/ A humongous object cannot be live if there is no remembered set for it\n-    \/\/ because:\n-    \/\/ - there can be no references from within humongous starts regions referencing\n-    \/\/ the object because we never allocate other objects into them.\n-    \/\/ (I.e. there are no intra-region references that may be missed by the\n-    \/\/ remembered set)\n-    \/\/ - as soon there is a remembered set entry to the humongous starts region\n-    \/\/ (i.e. it has \"escaped\" to an old object) this remembered set entry will stay\n-    \/\/ until the end of a concurrent mark.\n-    \/\/\n-    \/\/ It is not required to check whether the object has been found dead by marking\n-    \/\/ or not, in fact it would prevent reclamation within a concurrent cycle, as\n-    \/\/ all objects allocated during that time are considered live.\n-    \/\/ SATB marking is even more conservative than the remembered set.\n-    \/\/ So if at this point in the collection there is no remembered set entry,\n-    \/\/ nobody has a reference to it.\n-    \/\/ At the start of collection we flush all refinement logs, and remembered sets\n-    \/\/ are completely up-to-date wrt to references to the humongous object.\n-    \/\/\n-    \/\/ Other implementation considerations:\n-    \/\/ - never consider object arrays at this time because they would pose\n-    \/\/ considerable effort for cleaning up the the remembered sets. This is\n-    \/\/ required because stale remembered sets might reference locations that\n-    \/\/ are currently allocated into.\n-    uint region_idx = r->hrm_index();\n-    if (!g1h->is_humongous_reclaim_candidate(region_idx) ||\n-        !r->rem_set()->is_empty()) {\n-      log_debug(gc, humongous)(\"Live humongous region %u object size \" SIZE_FORMAT \" start \" PTR_FORMAT \"  with remset \" SIZE_FORMAT \" code roots \" SIZE_FORMAT \" is marked %d reclaim candidate %d type array %d\",\n-                               region_idx,\n-                               (size_t)obj->size() * HeapWordSize,\n-                               p2i(r->bottom()),\n-                               r->rem_set()->occupied(),\n-                               r->rem_set()->strong_code_roots_list_length(),\n-                               next_bitmap->is_marked(r->bottom()),\n-                               g1h->is_humongous_reclaim_candidate(region_idx),\n-                               obj->is_typeArray()\n-                              );\n-      return false;\n-    }\n-\n-    guarantee(obj->is_typeArray(),\n-              \"Only eagerly reclaiming type arrays is supported, but the object \"\n-              PTR_FORMAT \" is not.\", p2i(r->bottom()));\n-\n-    log_debug(gc, humongous)(\"Dead humongous region %u object size \" SIZE_FORMAT \" start \" PTR_FORMAT \" with remset \" SIZE_FORMAT \" code roots \" SIZE_FORMAT \" is marked %d reclaim candidate %d type array %d\",\n-                             region_idx,\n-                             (size_t)obj->size() * HeapWordSize,\n-                             p2i(r->bottom()),\n-                             r->rem_set()->occupied(),\n-                             r->rem_set()->strong_code_roots_list_length(),\n-                             next_bitmap->is_marked(r->bottom()),\n-                             g1h->is_humongous_reclaim_candidate(region_idx),\n-                             obj->is_typeArray()\n-                            );\n-\n-    G1ConcurrentMark* const cm = g1h->concurrent_mark();\n-    cm->humongous_object_eagerly_reclaimed(r);\n-    assert(!cm->is_marked_in_prev_bitmap(obj) && !cm->is_marked_in_next_bitmap(obj),\n-           \"Eagerly reclaimed humongous region %u should not be marked at all but is in prev %s next %s\",\n-           region_idx,\n-           BOOL_TO_STR(cm->is_marked_in_prev_bitmap(obj)),\n-           BOOL_TO_STR(cm->is_marked_in_next_bitmap(obj)));\n-    _humongous_objects_reclaimed++;\n-    do {\n-      HeapRegion* next = g1h->next_region_in_humongous(r);\n-      _freed_bytes += r->used();\n-      r->set_containing_set(NULL);\n-      _humongous_regions_reclaimed++;\n-      g1h->free_humongous_region(r, NULL);\n-      g1h->hr_printer()->cleanup(r);\n-      r = next;\n-    } while (r != NULL);\n-\n-    return false;\n-  }\n-\n-  uint humongous_objects_reclaimed() {\n-    return _humongous_objects_reclaimed;\n-  }\n-\n-  uint humongous_regions_reclaimed() {\n-    return _humongous_regions_reclaimed;\n-  }\n-\n-  size_t bytes_freed() const {\n-    return _freed_bytes;\n-  }\n-};\n-\n-void G1CollectedHeap::eagerly_reclaim_humongous_regions() {\n-  assert_at_safepoint_on_vm_thread();\n-\n-  if (!G1EagerReclaimHumongousObjects ||\n-      (!_has_humongous_reclaim_candidates && !log_is_enabled(Debug, gc, humongous))) {\n-    phase_times()->record_fast_reclaim_humongous_time_ms(0.0, 0);\n-    return;\n+void G1CollectedHeap::post_evacuate_cleanup_2(PreservedMarksSet* preserved_marks,\n+                                              G1RedirtyCardsQueueSet* rdcqs,\n+                                              G1EvacuationInfo* evacuation_info,\n+                                              const size_t* surviving_young_words) {\n+  Ticks start = Ticks::now();\n+  {\n+    G1PostEvacuateCollectionSetCleanupTask2 cl(preserved_marks, rdcqs, evacuation_info, surviving_young_words);\n+    run_batch_task(&cl);\n@@ -4474,0 +3952,2 @@\n+  phase_times()->record_post_evacuate_cleanup_task_2_time((Ticks::now() - start).seconds() * 1000.0);\n+}\n@@ -4475,8 +3955,3 @@\n-  double start_time = os::elapsedTime();\n-\n-  G1FreeHumongousRegionClosure cl;\n-  heap_region_iterate(&cl);\n-\n-  remove_from_old_gen_sets(0, 0, cl.humongous_regions_reclaimed());\n-\n-  decrement_summary_bytes(cl.bytes_freed());\n+void G1CollectedHeap::clear_eden() {\n+  _eden.clear();\n+}\n@@ -4484,2 +3959,2 @@\n-  phase_times()->record_fast_reclaim_humongous_time_ms((os::elapsedTime() - start_time) * 1000.0,\n-                                                       cl.humongous_objects_reclaimed());\n+void G1CollectedHeap::clear_collection_set() {\n+  collection_set()->clear();\n@@ -4851,0 +4326,27 @@\n+void G1CollectedHeap::update_used_after_gc() {\n+  if (evacuation_failed()) {\n+    \/\/ Reset the G1EvacuationFailureALot counters and flags\n+    NOT_PRODUCT(reset_evacuation_should_fail();)\n+\n+    set_used(recalculate_used());\n+\n+    if (_archive_allocator != NULL) {\n+      _archive_allocator->clear_used();\n+    }\n+    for (uint i = 0; i < ParallelGCThreads; i++) {\n+      if (_evacuation_failed_info_array[i].has_failed()) {\n+        _gc_tracer_stw->report_evacuation_failed(_evacuation_failed_info_array[i]);\n+      }\n+    }\n+  } else {\n+    \/\/ The \"used\" of the the collection set have already been subtracted\n+    \/\/ when they were freed.  Add in the bytes used.\n+    increase_used(_bytes_used_during_gc);\n+  }\n+}\n+\n+void G1CollectedHeap::reset_hot_card_cache() {\n+  _hot_card_cache->reset_hot_cache();\n+  _hot_card_cache->set_use_cache(true);\n+}\n+\n@@ -4852,1 +4354,0 @@\n-  double purge_start = os::elapsedTime();\n@@ -4854,2 +4355,0 @@\n-  double purge_time_ms = (os::elapsedTime() - purge_start) * 1000.0;\n-  phase_times()->record_strong_code_root_purge_time(purge_time_ms);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":74,"deletions":575,"binary":false,"changes":649,"status":"modified"},{"patch":"@@ -77,0 +77,1 @@\n+class G1BatchedGangTask;\n@@ -174,2 +175,0 @@\n-  void eagerly_reclaim_humongous_regions();\n-\n@@ -248,1 +247,1 @@\n-   protected:\n+  protected:\n@@ -250,1 +249,1 @@\n-   public:\n+  public:\n@@ -261,3 +260,10 @@\n-  \/\/ Stores whether during humongous object registration we found candidate regions.\n-  \/\/ If not, we can skip a few steps.\n-  bool _has_humongous_reclaim_candidates;\n+  uint _num_humongous_reclaim_total_objects; \/\/ Current amount of (all) humongous objects found in the heap.\n+  uint _num_humongous_reclaim_candidate_objects; \/\/ Number of humongous object eager reclaim candidates.\n+public:\n+  uint num_humongous_total_objects() const { return _num_humongous_reclaim_total_objects; }\n+  uint num_humongous_reclaim_candidate_objects() const { return _num_humongous_reclaim_candidate_objects; }\n+  bool has_humongous_reclaim_candidate_objects() const { return _num_humongous_reclaim_candidate_objects > 0; }\n+\n+  bool eagerly_reclaim_enabled() const;\n+\n+private:\n@@ -549,4 +555,0 @@\n-  \/\/ Merges the information gathered on a per-thread basis for all worker threads\n-  \/\/ during GC into global variables.\n-  void merge_per_thread_state_info(G1ParScanThreadStateSet* per_thread_states);\n-\n@@ -563,0 +565,2 @@\n+  \/\/ Run the given batch task using the work gang.\n+  void run_batch_task(G1BatchedGangTask* cl);\n@@ -611,1 +615,0 @@\n-  inline void set_has_humongous_reclaim_candidate(bool value);\n@@ -836,3 +839,10 @@\n-  \/\/ After a collection pause, convert the regions in the collection set into free\n-  \/\/ regions.\n-  void free_collection_set(G1CollectionSet* collection_set, G1EvacuationInfo& evacuation_info, const size_t* surviving_young_words);\n+  void post_evacuate_cleanup_1(G1ParScanThreadStateSet* per_thread_states,\n+                               G1RedirtyCardsQueueSet* rdcqs);\n+  void post_evacuate_cleanup_2(PreservedMarksSet* preserved_marks,\n+                               G1RedirtyCardsQueueSet* rdcqs,\n+                               G1EvacuationInfo* evacuation_info,\n+                               const size_t* surviving_young_words);\n+\n+  \/\/ After a collection pause, reset eden and the collection set.\n+  void clear_eden();\n+  void clear_collection_set();\n@@ -859,8 +869,0 @@\n-  \/\/ Failed evacuations cause some logical from-space objects to have\n-  \/\/ forwarding pointers to themselves.  Reset them.\n-  void remove_self_forwarding_pointers(G1RedirtyCardsQueueSet* rdcqs);\n-\n-  \/\/ Restore the objects in the regions in the collection set after an\n-  \/\/ evacuation failure.\n-  void restore_after_evac_failure(G1RedirtyCardsQueueSet* rdcqs);\n-\n@@ -1388,0 +1390,7 @@\n+  \/\/ Recalculate amount of used memory after GC. Must be called after all allocation\n+  \/\/ has finished.\n+  void update_used_after_gc();\n+  \/\/ Reset and re-enable the hot card cache.\n+  \/\/ Note the counts for the cards in the regions in the\n+  \/\/ collection set are reset when the collection set is freed.\n+  void reset_hot_card_cache();\n@@ -1403,3 +1412,0 @@\n-  \/\/ Redirty logged cards in the refinement queue.\n-  void redirty_logged_cards(G1RedirtyCardsQueueSet* rdcqs);\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":32,"deletions":26,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -315,4 +315,0 @@\n-inline void G1CollectedHeap::set_has_humongous_reclaim_candidate(bool value) {\n-  _has_humongous_reclaim_candidates = value;\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.inline.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -505,1 +505,1 @@\n-  assert_at_safepoint_on_vm_thread();\n+  assert_at_safepoint();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -111,0 +111,11 @@\n+  _gc_par_phases[MergePSS] = new WorkerDataArray<double>(\"MergePSS\", \"Merge Per-Thread State (ms):\", max_gc_threads);\n+  _gc_par_phases[RemoveSelfForwardingPtr] = new WorkerDataArray<double>(\"RemoveSelfForwardingPtr\", \"Remove Self Forwards (ms):\", max_gc_threads);\n+  _gc_par_phases[ClearCardTable] = new WorkerDataArray<double>(\"ClearLoggedCards\", \"Clear Logged Cards (ms):\", max_gc_threads);\n+  _gc_par_phases[RecalculateUsed] = new WorkerDataArray<double>(\"RecalculateUsed\", \"Recalculate Used Memory (ms):\", max_gc_threads);\n+  _gc_par_phases[ResetHotCardCache] = new WorkerDataArray<double>(\"ResetHotCardCache\", \"Reset Hot Card Cache (ms):\", max_gc_threads);\n+  _gc_par_phases[PurgeCodeRoots] = new WorkerDataArray<double>(\"PurgeCodeRoots\", \"Purge Code Roots (ms):\", max_gc_threads);\n+#if COMPILER2_OR_JVMCI\n+  _gc_par_phases[UpdateDerivedPointers] = new WorkerDataArray<double>(\"UpdateDerivedPointers\", \"Update Derived Pointers (ms):\", max_gc_threads);\n+#endif\n+  _gc_par_phases[EagerlyReclaimHumongousObjects] = new WorkerDataArray<double>(\"EagerlyReclaimHumongousObjects\", \"Eagerly Reclaim Humongous Objects (ms):\", max_gc_threads);\n+  _gc_par_phases[RestorePreservedMarks] = new WorkerDataArray<double>(\"RestorePreservedMarks\", \"Restore Preserved Marks (ms):\", max_gc_threads);\n@@ -125,1 +136,3 @@\n-  _gc_par_phases[MergePSS] = new WorkerDataArray<double>(\"MergePSS\", \"Merge Per-Thread State\", 1 \/* length *\/, true \/* is_serial *\/);\n+  _gc_par_phases[MergePSS]->create_thread_work_items(\"Copied Bytes\", MergePSSCopiedBytes);\n+  _gc_par_phases[MergePSS]->create_thread_work_items(\"LAB Waste\", MergePSSLABWasteBytes);\n+  _gc_par_phases[MergePSS]->create_thread_work_items(\"LAB Undo Waste\", MergePSSLABUndoWasteBytes);\n@@ -127,3 +140,3 @@\n-  _gc_par_phases[MergePSS]->create_thread_work_items(\"Copied Bytes\", MergePSSCopiedBytes, max_gc_threads);\n-  _gc_par_phases[MergePSS]->create_thread_work_items(\"LAB Waste\", MergePSSLABWasteBytes, max_gc_threads);\n-  _gc_par_phases[MergePSS]->create_thread_work_items(\"LAB Undo Waste\", MergePSSLABUndoWasteBytes, max_gc_threads);\n+  _gc_par_phases[EagerlyReclaimHumongousObjects]->create_thread_work_items(\"Humongous Total\", EagerlyReclaimNumTotal);\n+  _gc_par_phases[EagerlyReclaimHumongousObjects]->create_thread_work_items(\"Humongous Candidates\", EagerlyReclaimNumCandidates);\n+  _gc_par_phases[EagerlyReclaimHumongousObjects]->create_thread_work_items(\"Humongous Reclaimed\", EagerlyReclaimNumReclaimed);\n@@ -143,1 +156,1 @@\n-  _gc_par_phases[RedirtyCards] = new WorkerDataArray<double>(\"RedirtyCards\", \"Parallel Redirty (ms):\", max_gc_threads);\n+  _gc_par_phases[RedirtyCards] = new WorkerDataArray<double>(\"RedirtyCards\", \"Redirty Logged Cards (ms):\", max_gc_threads);\n@@ -146,1 +159,1 @@\n-  _gc_par_phases[ParFreeCSet] = new WorkerDataArray<double>(\"ParFreeCSet\", \"Parallel Free Collection Set (ms):\", max_gc_threads);\n+  _gc_par_phases[FreeCollectionSet] = new WorkerDataArray<double>(\"FreeCSet\", \"Free Collection Set (ms):\", max_gc_threads);\n@@ -158,1 +171,0 @@\n-  _cur_strong_code_root_purge_time_ms = 0.0;\n@@ -163,2 +175,0 @@\n-  _cur_evac_fail_recalc_used = 0.0;\n-  _cur_evac_fail_remove_self_forwards = 0.0;\n@@ -168,3 +178,2 @@\n-  _cur_concatenate_dirty_card_logs_time_ms = 0.0;\n-  _cur_derived_pointer_table_update_time_ms = 0.0;\n-  _cur_clear_ct_time_ms = 0.0;\n+  _cur_post_evacuate_cleanup_1_time_ms = 0.0;\n+  _cur_post_evacuate_cleanup_2_time_ms = 0.0;\n@@ -180,1 +189,0 @@\n-  _recorded_redirty_logged_cards_time_ms = 0.0;\n@@ -183,1 +191,0 @@\n-  _recorded_total_free_cset_time_ms = 0.0;\n@@ -187,1 +194,0 @@\n-  _cur_fast_reclaim_humongous_time_ms = 0.0;\n@@ -189,3 +195,0 @@\n-  _cur_fast_reclaim_humongous_total = 0;\n-  _cur_fast_reclaim_humongous_candidates = 0;\n-  _cur_fast_reclaim_humongous_reclaimed = 0;\n@@ -406,4 +409,0 @@\n-  if (G1EagerReclaimHumongousObjects) {\n-    trace_count(\"Humongous Total\", _cur_fast_reclaim_humongous_total);\n-    trace_count(\"Humongous Candidate\", _cur_fast_reclaim_humongous_candidates);\n-  }\n@@ -465,6 +464,1 @@\n-  const double evac_fail_handling = _cur_evac_fail_recalc_used +\n-                                    _cur_evac_fail_remove_self_forwards;\n-  assert(_gc_par_phases[MergePSS]->get(0) != WorkerDataArray<double>::uninitialized(), \"must be set\");\n-  const double merge_pss = _gc_par_phases[MergePSS]->get(0) * MILLIUNITS;\n-  const double sum_ms = evac_fail_handling +\n-                        _cur_collection_code_root_fixup_time_ms +\n+  const double sum_ms = _cur_collection_code_root_fixup_time_ms +\n@@ -474,5 +468,3 @@\n-                        _cur_clear_ct_time_ms +\n-                        merge_pss +\n-                        _cur_strong_code_root_purge_time_ms +\n-                        _recorded_redirty_logged_cards_time_ms +\n-                        _recorded_total_free_cset_time_ms +\n+                        _cur_string_deduplication_time_ms +\n+                        _cur_post_evacuate_cleanup_1_time_ms +\n+                        _cur_post_evacuate_cleanup_2_time_ms +\n@@ -480,3 +472,2 @@\n-                        _cur_fast_reclaim_humongous_time_ms +\n-                        _cur_expand_heap_time_ms +\n-                        _cur_string_deduplication_time_ms;\n+                        _recorded_start_new_cset_time_ms +\n+                        _cur_expand_heap_time_ms;\n@@ -488,2 +479,0 @@\n-  debug_time(\"Clear Card Table\", _cur_clear_ct_time_ms);\n-\n@@ -501,0 +490,4 @@\n+  debug_time(\"Post Evacuate Cleanup 1\", _cur_post_evacuate_cleanup_1_time_ms);\n+  debug_phase(_gc_par_phases[MergePSS], 1);\n+  debug_phase(_gc_par_phases[ClearCardTable], 1);\n+  debug_phase(_gc_par_phases[RecalculateUsed], 1);\n@@ -502,3 +495,1 @@\n-    debug_time(\"Evacuation Failure\", evac_fail_handling);\n-    trace_time(\"Recalculate Used\", _cur_evac_fail_recalc_used);\n-    trace_time(\"Remove Self Forwards\",_cur_evac_fail_remove_self_forwards);\n+    debug_phase(_gc_par_phases[RemoveSelfForwardingPtr], 1);\n@@ -507,5 +498,7 @@\n-  debug_phase(_gc_par_phases[MergePSS], 0);\n-  debug_time(\"Code Roots Purge\", _cur_strong_code_root_purge_time_ms);\n-\n-  debug_time(\"Redirty Cards\", _recorded_redirty_logged_cards_time_ms);\n-  trace_phase(_gc_par_phases[RedirtyCards]);\n+  debug_time(\"Post Evacuate Cleanup 2\", _cur_post_evacuate_cleanup_2_time_ms);\n+  if (G1CollectedHeap::heap()->evacuation_failed()) {\n+    debug_phase(_gc_par_phases[RecalculateUsed], 1);\n+    debug_phase(_gc_par_phases[RestorePreservedMarks], 1);\n+  }\n+  debug_phase(_gc_par_phases[ResetHotCardCache], 1);\n+  debug_phase(_gc_par_phases[PurgeCodeRoots], 1);\n@@ -513,1 +506,1 @@\n-  debug_time(\"DerivedPointerTable Update\", _cur_derived_pointer_table_update_time_ms);\n+  debug_phase(_gc_par_phases[UpdateDerivedPointers], 1);\n@@ -515,0 +508,7 @@\n+  if (G1CollectedHeap::heap()->eagerly_reclaim_enabled()) {\n+    debug_phase(_gc_par_phases[EagerlyReclaimHumongousObjects], 1);\n+  }\n+  debug_phase(_gc_par_phases[RedirtyCards], 1);\n+  debug_phase(_gc_par_phases[FreeCollectionSet], 1);\n+  trace_phase(_gc_par_phases[YoungFreeCSet], true, 2);\n+  trace_phase(_gc_par_phases[NonYoungFreeCSet], true, 2);\n@@ -516,1 +516,0 @@\n-  debug_time(\"Free Collection Set\", _recorded_total_free_cset_time_ms);\n@@ -518,3 +517,0 @@\n-  trace_phase(_gc_par_phases[ParFreeCSet]);\n-  trace_phase(_gc_par_phases[YoungFreeCSet], true, 1);\n-  trace_phase(_gc_par_phases[NonYoungFreeCSet], true, 1);\n@@ -526,4 +522,0 @@\n-  if (G1EagerReclaimHumongousObjects) {\n-    debug_time(\"Humongous Reclaim\", _cur_fast_reclaim_humongous_time_ms);\n-    trace_count(\"Humongous Reclaimed\", _cur_fast_reclaim_humongous_reclaimed);\n-  }\n@@ -536,1 +528,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.cpp","additions":47,"deletions":56,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -76,1 +76,1 @@\n-    ParFreeCSet,\n+    FreeCollectionSet,\n@@ -81,0 +81,10 @@\n+    RemoveSelfForwardingPtr,\n+    ClearCardTable,\n+    RecalculateUsed,\n+    ResetHotCardCache,\n+    PurgeCodeRoots,\n+#if COMPILER2_OR_JVMCI\n+    UpdateDerivedPointers,\n+#endif\n+    EagerlyReclaimHumongousObjects,\n+    RestorePreservedMarks,\n@@ -123,0 +133,6 @@\n+  enum GCEagerlyReclaimHumongousObjectsItems {\n+    EagerlyReclaimNumTotal,\n+    EagerlyReclaimNumCandidates,\n+    EagerlyReclaimNumReclaimed\n+  };\n+\n@@ -132,4 +148,0 @@\n-  double _cur_strong_code_root_purge_time_ms;\n-\n-  double _cur_evac_fail_recalc_used;\n-  double _cur_evac_fail_remove_self_forwards;\n@@ -150,1 +162,2 @@\n-  double _cur_derived_pointer_table_update_time_ms;\n+  double _cur_post_evacuate_cleanup_1_time_ms;\n+  double _cur_post_evacuate_cleanup_2_time_ms;\n@@ -168,2 +181,0 @@\n-  double _recorded_redirty_logged_cards_time_ms;\n-\n@@ -176,2 +187,0 @@\n-  double _recorded_total_free_cset_time_ms;\n-\n@@ -186,5 +195,0 @@\n-  double _cur_fast_reclaim_humongous_time_ms;\n-  size_t _cur_fast_reclaim_humongous_total;\n-  size_t _cur_fast_reclaim_humongous_candidates;\n-  size_t _cur_fast_reclaim_humongous_reclaimed;\n-\n@@ -263,8 +267,0 @@\n-  void record_derived_pointer_table_update_time(double ms) {\n-    _cur_derived_pointer_table_update_time_ms = ms;\n-  }\n-\n-  void record_clear_ct_time(double ms) {\n-    _cur_clear_ct_time_ms = ms;\n-  }\n-\n@@ -287,4 +283,0 @@\n-  void record_strong_code_root_purge_time(double ms) {\n-    _cur_strong_code_root_purge_time_ms = ms;\n-  }\n-\n@@ -307,8 +299,0 @@\n-  void record_evac_fail_recalc_used_time(double ms) {\n-    _cur_evac_fail_recalc_used = ms;\n-  }\n-\n-  void record_evac_fail_remove_self_forwards(double ms) {\n-    _cur_evac_fail_remove_self_forwards = ms;\n-  }\n-\n@@ -327,4 +311,0 @@\n-  void record_total_free_cset_time_ms(double time_ms) {\n-    _recorded_total_free_cset_time_ms = time_ms;\n-  }\n-\n@@ -343,1 +323,1 @@\n-  void record_register_regions(double time_ms, size_t total, size_t candidates) {\n+  void record_register_regions(double time_ms) {\n@@ -345,2 +325,0 @@\n-    _cur_fast_reclaim_humongous_total = total;\n-    _cur_fast_reclaim_humongous_candidates = candidates;\n@@ -349,3 +327,6 @@\n-  void record_fast_reclaim_humongous_time_ms(double value, size_t reclaimed) {\n-    _cur_fast_reclaim_humongous_time_ms = value;\n-    _cur_fast_reclaim_humongous_reclaimed = reclaimed;\n+  void record_post_evacuate_cleanup_task_1_time(double time_ms) {\n+    _cur_post_evacuate_cleanup_1_time_ms = time_ms;\n+  }\n+\n+  void record_post_evacuate_cleanup_task_2_time(double time_ms) {\n+    _cur_post_evacuate_cleanup_2_time_ms = time_ms;\n@@ -362,4 +343,0 @@\n-  void record_redirty_logged_cards_time_ms(double time_ms) {\n-    _recorded_redirty_logged_cards_time_ms = time_ms;\n-  }\n-\n@@ -406,4 +383,0 @@\n-  double cur_clear_ct_time_ms() {\n-    return _cur_clear_ct_time_ms;\n-  }\n-\n@@ -422,4 +395,0 @@\n-  double total_free_cset_time_ms() {\n-    return _recorded_total_free_cset_time_ms;\n-  }\n-\n@@ -434,8 +403,0 @@\n-  double fast_reclaim_humongous_time_ms() {\n-    return _cur_fast_reclaim_humongous_time_ms;\n-  }\n-\n-  size_t fast_reclaim_humongous_candidates() const {\n-    return _cur_fast_reclaim_humongous_candidates;\n-  }\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.hpp","additions":26,"deletions":65,"binary":false,"changes":91,"status":"modified"},{"patch":"@@ -131,1 +131,0 @@\n-    assert(Thread::current()->is_VM_thread(), \"Current thread should be the VMthread\");\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HotCardCache.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -578,1 +578,1 @@\n-  return other_time_ms(pause_time_ms) - phase_times()->total_free_cset_time_ms() - phase_times()->total_rebuild_freelist_time_ms();\n+  return other_time_ms(pause_time_ms) - phase_times()->total_rebuild_freelist_time_ms();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/g1\/g1BatchedGangTask.hpp\"\n@@ -221,1 +222,1 @@\n-  class G1ClearCardTableTask : public AbstractGangTask {\n+  class G1ClearCardTableTask : public G1AbstractSubTask {\n@@ -235,1 +236,1 @@\n-      AbstractGangTask(\"G1 Clear Card Table Task\"),\n+      G1AbstractSubTask(G1GCPhaseTimes::ClearCardTable),\n@@ -245,0 +246,18 @@\n+    double worker_cost() const override {\n+      uint num_regions = _regions->size();\n+\n+      if (num_regions == 0) {\n+        \/\/ There is no card table clean work, only some cleanup of memory.\n+        return AlmostNoWork;\n+      }\n+      return ((double)align_up((size_t)num_regions << HeapRegion::LogCardsPerRegion, chunk_size()) \/ chunk_size());\n+    }\n+\n+\n+    virtual ~G1ClearCardTableTask() {\n+      _scan_state->cleanup();\n+#ifndef PRODUCT\n+      G1CollectedHeap::heap()->verifier()->verify_card_table_cleanup();\n+#endif\n+    }\n+\n@@ -247,1 +266,1 @@\n-    void work(uint worker_id) {\n+    void do_work(uint worker_id) override {\n@@ -262,25 +281,0 @@\n-  \/\/ Clear the card table of \"dirty\" regions.\n-  void clear_card_table(WorkGang* workers) {\n-    uint num_regions = _all_dirty_regions->size();\n-\n-    if (num_regions == 0) {\n-      return;\n-    }\n-\n-    uint const num_chunks = (uint)(align_up((size_t)num_regions << HeapRegion::LogCardsPerRegion, G1ClearCardTableTask::chunk_size()) \/ G1ClearCardTableTask::chunk_size());\n-    uint const num_workers = MIN2(num_chunks, workers->active_workers());\n-    uint const chunk_length = G1ClearCardTableTask::chunk_size() \/ (uint)HeapRegion::CardsPerRegion;\n-\n-    \/\/ Iterate over the dirty cards region list.\n-    G1ClearCardTableTask cl(G1CollectedHeap::heap(), _all_dirty_regions, chunk_length, this);\n-\n-    log_debug(gc, ergo)(\"Running %s using %u workers for %u \"\n-                        \"units of work for %u regions.\",\n-                        cl.name(), num_workers, num_chunks, num_regions);\n-    workers->run_task(&cl, num_workers);\n-\n-#ifndef PRODUCT\n-    G1CollectedHeap::heap()->verifier()->verify_card_table_cleanup();\n-#endif\n-  }\n-\n@@ -394,2 +388,5 @@\n-  void cleanup(WorkGang* workers) {\n-    clear_card_table(workers);\n+  G1AbstractSubTask* create_cleanup_after_scan_heap_roots_task() {\n+    uint const chunk_length = G1ClearCardTableTask::chunk_size() \/ (uint)HeapRegion::CardsPerRegion;\n+\n+    return new G1ClearCardTableTask(G1CollectedHeap::heap(), _all_dirty_regions, chunk_length, this);\n+  }\n@@ -397,0 +394,1 @@\n+  void cleanup() {\n@@ -1312,1 +1310,1 @@\n-        p->fast_reclaim_humongous_candidates() > 0 &&\n+        g1h->has_humongous_reclaim_candidate_objects() &&\n@@ -1423,7 +1421,2 @@\n-void G1RemSet::cleanup_after_scan_heap_roots() {\n-  G1GCPhaseTimes* phase_times = _g1h->phase_times();\n-\n-  \/\/ Set all cards back to clean.\n-  double start = os::elapsedTime();\n-  _scan_state->cleanup(_g1h->workers());\n-  phase_times->record_clear_ct_time((os::elapsedTime() - start) * 1000.0);\n+G1AbstractSubTask* G1RemSet::create_cleanup_after_scan_heap_roots_task() {\n+  return _scan_state->create_cleanup_after_scan_heap_roots_task();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSet.cpp","additions":31,"deletions":38,"binary":false,"changes":69,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-class G1BlockOffsetTable;\n@@ -44,0 +43,1 @@\n+class G1AbstractSubTask;\n@@ -110,2 +110,3 @@\n-  \/\/ Cleans the card table from temporary duplicate detection information.\n-  void cleanup_after_scan_heap_roots();\n+  \/\/ Creates a gang task for cleaining up temporary data structures and the\n+  \/\/ card table, removing temporary duplicate detection information.\n+  G1AbstractSubTask* create_cleanup_after_scan_heap_roots_task();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1RemSet.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -0,0 +1,606 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"compiler\/oopMap.hpp\"\n+#include \"gc\/g1\/g1CardTableEntryClosure.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n+#include \"gc\/g1\/g1ConcurrentMark.inline.hpp\"\n+#include \"gc\/g1\/g1EvacStats.inline.hpp\"\n+#include \"gc\/g1\/g1ParScanThreadState.hpp\"\n+#include \"gc\/g1\/g1RemSet.hpp\"\n+#include \"gc\/g1\/g1YoungGCPostEvacuateTasks.hpp\"\n+#include \"jfr\/jfrEvents.hpp\"\n+#include \"utilities\/ticks.hpp\"\n+\n+G1PostEvacuateCollectionSetCleanupTask1::G1PostEvacuateCollectionSetCleanupTask1(G1ParScanThreadStateSet* per_thread_states,\n+                                                                                 G1RedirtyCardsQueueSet* rdcqs) :\n+  G1BatchedGangTask(\"Post Evacuate Cleanup 1\", G1CollectedHeap::heap()->phase_times())\n+{\n+  add_serial_task(new MergePssTask(per_thread_states));\n+  add_serial_task(new RecalculateUsedTask());\n+  if (RemoveSelfForwardPtrsTask::should_execute()) {\n+    add_parallel_task(new RemoveSelfForwardPtrsTask(rdcqs));\n+  }\n+  add_parallel_task(G1CollectedHeap::heap()->rem_set()->create_cleanup_after_scan_heap_roots_task());\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask1::MergePssTask::MergePssTask(G1ParScanThreadStateSet* per_thread_states) :\n+  G1AbstractSubTask(G1GCPhaseTimes::MergePSS),\n+  _per_thread_states(per_thread_states) { }\n+\n+void G1PostEvacuateCollectionSetCleanupTask1::MergePssTask::do_work(uint worker_id) {\n+  _per_thread_states->flush();\n+}\n+\n+double G1PostEvacuateCollectionSetCleanupTask1::RecalculateUsedTask::worker_cost() const {\n+  \/\/ If there is no evacuation failure, the work to perform is minimal.\n+  return G1CollectedHeap::heap()->evacuation_failed() ? 1.0 : AlmostNoWork;\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask1::RecalculateUsedTask::do_work(uint worker_id) {\n+  G1CollectedHeap::heap()->update_used_after_gc();\n+}\n+\n+bool G1PostEvacuateCollectionSetCleanupTask1::RemoveSelfForwardPtrsTask::should_execute() {\n+  return G1CollectedHeap::heap()->evacuation_failed();\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask1::RemoveSelfForwardPtrsTask::RemoveSelfForwardPtrsTask(G1RedirtyCardsQueueSet* rdcqs) :\n+  G1AbstractSubTask(G1GCPhaseTimes::RemoveSelfForwardingPtr), _cl(rdcqs) { }\n+\n+G1PostEvacuateCollectionSetCleanupTask1::RemoveSelfForwardPtrsTask::~RemoveSelfForwardPtrsTask() {\n+  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+  assert(_cl.num_failed_regions() == g1h->num_regions_failed_evacuation(),\n+         \"Removed regions %u inconsistent with expected %u\",\n+         _cl.num_failed_regions(), g1h->num_regions_failed_evacuation());\n+}\n+\n+double G1PostEvacuateCollectionSetCleanupTask1::RemoveSelfForwardPtrsTask::worker_cost() const {\n+  assert(should_execute(), \"Should not call this if not executed\");\n+  return G1CollectedHeap::heap()->num_regions_failed_evacuation();\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask1::RemoveSelfForwardPtrsTask::do_work(uint worker_id) {\n+  _cl.work(worker_id);\n+}\n+\n+class G1FreeHumongousRegionClosure : public HeapRegionClosure {\n+  uint _humongous_objects_reclaimed;\n+  uint _humongous_regions_reclaimed;\n+  size_t _freed_bytes;\n+public:\n+\n+  G1FreeHumongousRegionClosure() :\n+    _humongous_objects_reclaimed(0),\n+    _humongous_regions_reclaimed(0),\n+    _freed_bytes(0) {\n+  }\n+\n+  virtual bool do_heap_region(HeapRegion* r) {\n+    if (!r->is_starts_humongous()) {\n+      return false;\n+    }\n+\n+    G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+\n+    oop obj = cast_to_oop(r->bottom());\n+    G1CMBitMap* next_bitmap = g1h->concurrent_mark()->next_mark_bitmap();\n+\n+    \/\/ The following checks whether the humongous object is live are sufficient.\n+    \/\/ The main additional check (in addition to having a reference from the roots\n+    \/\/ or the young gen) is whether the humongous object has a remembered set entry.\n+    \/\/\n+    \/\/ A humongous object cannot be live if there is no remembered set for it\n+    \/\/ because:\n+    \/\/ - there can be no references from within humongous starts regions referencing\n+    \/\/ the object because we never allocate other objects into them.\n+    \/\/ (I.e. there are no intra-region references that may be missed by the\n+    \/\/ remembered set)\n+    \/\/ - as soon there is a remembered set entry to the humongous starts region\n+    \/\/ (i.e. it has \"escaped\" to an old object) this remembered set entry will stay\n+    \/\/ until the end of a concurrent mark.\n+    \/\/\n+    \/\/ It is not required to check whether the object has been found dead by marking\n+    \/\/ or not, in fact it would prevent reclamation within a concurrent cycle, as\n+    \/\/ all objects allocated during that time are considered live.\n+    \/\/ SATB marking is even more conservative than the remembered set.\n+    \/\/ So if at this point in the collection there is no remembered set entry,\n+    \/\/ nobody has a reference to it.\n+    \/\/ At the start of collection we flush all refinement logs, and remembered sets\n+    \/\/ are completely up-to-date wrt to references to the humongous object.\n+    \/\/\n+    \/\/ Other implementation considerations:\n+    \/\/ - never consider object arrays at this time because they would pose\n+    \/\/ considerable effort for cleaning up the the remembered sets. This is\n+    \/\/ required because stale remembered sets might reference locations that\n+    \/\/ are currently allocated into.\n+    uint region_idx = r->hrm_index();\n+    if (!g1h->is_humongous_reclaim_candidate(region_idx) ||\n+        !r->rem_set()->is_empty()) {\n+      log_debug(gc, humongous)(\"Live humongous region %u object size \" SIZE_FORMAT \" start \" PTR_FORMAT \"  with remset \" SIZE_FORMAT \" code roots \" SIZE_FORMAT \" is marked %d reclaim candidate %d type array %d\",\n+                               region_idx,\n+                               (size_t)obj->size() * HeapWordSize,\n+                               p2i(r->bottom()),\n+                               r->rem_set()->occupied(),\n+                               r->rem_set()->strong_code_roots_list_length(),\n+                               next_bitmap->is_marked(r->bottom()),\n+                               g1h->is_humongous_reclaim_candidate(region_idx),\n+                               obj->is_typeArray()\n+                              );\n+      return false;\n+    }\n+\n+    guarantee(obj->is_typeArray(),\n+              \"Only eagerly reclaiming type arrays is supported, but the object \"\n+              PTR_FORMAT \" is not.\", p2i(r->bottom()));\n+\n+    log_debug(gc, humongous)(\"Dead humongous region %u object size \" SIZE_FORMAT \" start \" PTR_FORMAT \" with remset \" SIZE_FORMAT \" code roots \" SIZE_FORMAT \" is marked %d reclaim candidate %d type array %d\",\n+                             region_idx,\n+                             (size_t)obj->size() * HeapWordSize,\n+                             p2i(r->bottom()),\n+                             r->rem_set()->occupied(),\n+                             r->rem_set()->strong_code_roots_list_length(),\n+                             next_bitmap->is_marked(r->bottom()),\n+                             g1h->is_humongous_reclaim_candidate(region_idx),\n+                             obj->is_typeArray()\n+                            );\n+\n+    G1ConcurrentMark* const cm = g1h->concurrent_mark();\n+    cm->humongous_object_eagerly_reclaimed(r);\n+    assert(!cm->is_marked_in_prev_bitmap(obj) && !cm->is_marked_in_next_bitmap(obj),\n+           \"Eagerly reclaimed humongous region %u should not be marked at all but is in prev %s next %s\",\n+           region_idx,\n+           BOOL_TO_STR(cm->is_marked_in_prev_bitmap(obj)),\n+           BOOL_TO_STR(cm->is_marked_in_next_bitmap(obj)));\n+    _humongous_objects_reclaimed++;\n+    do {\n+      HeapRegion* next = g1h->next_region_in_humongous(r);\n+      _freed_bytes += r->used();\n+      r->set_containing_set(nullptr);\n+      _humongous_regions_reclaimed++;\n+      g1h->free_humongous_region(r, nullptr);\n+      g1h->hr_printer()->cleanup(r);\n+      r = next;\n+    } while (r != nullptr);\n+\n+    return false;\n+  }\n+\n+  uint humongous_objects_reclaimed() {\n+    return _humongous_objects_reclaimed;\n+  }\n+\n+  uint humongous_regions_reclaimed() {\n+    return _humongous_regions_reclaimed;\n+  }\n+\n+  size_t bytes_freed() const {\n+    return _freed_bytes;\n+  }\n+};\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::ResetHotCardCacheTask::do_work(uint worker_id) {\n+  G1CollectedHeap::heap()->reset_hot_card_cache();\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::PurgeCodeRootsTask::do_work(uint worker_id) {\n+  G1CollectedHeap::heap()->purge_code_root_memory();\n+}\n+\n+#if COMPILER2_OR_JVMCI\n+void G1PostEvacuateCollectionSetCleanupTask2::UpdateDerivedPointersTask::do_work(uint worker_id) {\n+  DerivedPointerTable::update_pointers();\n+}\n+#endif\n+\n+bool G1PostEvacuateCollectionSetCleanupTask2::EagerlyReclaimHumongousObjectsTask::should_execute() {\n+  return G1CollectedHeap::heap()->eagerly_reclaim_enabled();\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask2::EagerlyReclaimHumongousObjectsTask::EagerlyReclaimHumongousObjectsTask() :\n+  G1AbstractSubTask(G1GCPhaseTimes::EagerlyReclaimHumongousObjects),\n+  _humongous_regions_reclaimed(0),\n+  _bytes_freed(0) { }\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::EagerlyReclaimHumongousObjectsTask::do_work(uint worker_id) {\n+  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+\n+  G1FreeHumongousRegionClosure cl;\n+  g1h->heap_region_iterate(&cl);\n+\n+  record_work_item(worker_id, G1GCPhaseTimes::EagerlyReclaimNumTotal, g1h->num_humongous_total_objects());\n+  record_work_item(worker_id, G1GCPhaseTimes::EagerlyReclaimNumCandidates, g1h->num_humongous_reclaim_candidate_objects());\n+  record_work_item(worker_id, G1GCPhaseTimes::EagerlyReclaimNumReclaimed, cl.humongous_objects_reclaimed());\n+\n+  _humongous_regions_reclaimed = cl.humongous_regions_reclaimed();\n+  _bytes_freed = cl.bytes_freed();\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask2::EagerlyReclaimHumongousObjectsTask::~EagerlyReclaimHumongousObjectsTask() {\n+  G1CollectedHeap* g1h = G1CollectedHeap::heap();\n+\n+  g1h->remove_from_old_gen_sets(0, 0, _humongous_regions_reclaimed);\n+  g1h->decrement_summary_bytes(_bytes_freed);\n+}\n+\n+bool G1PostEvacuateCollectionSetCleanupTask2::RestorePreservedMarksTask::should_execute() {\n+  return G1CollectedHeap::heap()->evacuation_failed();\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask2::RestorePreservedMarksTask::RestorePreservedMarksTask(PreservedMarksSet* preserved_marks) :\n+  G1AbstractSubTask(G1GCPhaseTimes::RestorePreservedMarks), _preserved_marks(preserved_marks), _cl(preserved_marks->create_task()) { }\n+\n+G1PostEvacuateCollectionSetCleanupTask2::RestorePreservedMarksTask::~RestorePreservedMarksTask() {\n+  delete _cl;\n+}\n+\n+double G1PostEvacuateCollectionSetCleanupTask2::RestorePreservedMarksTask::worker_cost() const {\n+  assert(should_execute(), \"Should not call this if not executed\");\n+  return _preserved_marks->num();\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::RestorePreservedMarksTask::do_work(uint worker_id) {\n+  _cl->work(worker_id);\n+}\n+\n+class RedirtyLoggedCardTableEntryClosure : public G1CardTableEntryClosure {\n+ private:\n+  size_t _num_dirtied;\n+  G1CollectedHeap* _g1h;\n+  G1CardTable* _g1_ct;\n+\n+  HeapRegion* region_for_card(CardValue* card_ptr) const {\n+    return _g1h->heap_region_containing(_g1_ct->addr_for(card_ptr));\n+  }\n+\n+  bool will_become_free(HeapRegion* hr) const {\n+    \/\/ A region will be freed by free_collection_set if the region is in the\n+    \/\/ collection set and has not had an evacuation failure.\n+    return _g1h->is_in_cset(hr) && !hr->evacuation_failed();\n+  }\n+\n+ public:\n+  RedirtyLoggedCardTableEntryClosure(G1CollectedHeap* g1h) : G1CardTableEntryClosure(),\n+    _num_dirtied(0), _g1h(g1h), _g1_ct(g1h->card_table()) { }\n+\n+  void do_card_ptr(CardValue* card_ptr, uint worker_id) {\n+    HeapRegion* hr = region_for_card(card_ptr);\n+\n+    \/\/ Should only dirty cards in regions that won't be freed.\n+    if (!will_become_free(hr)) {\n+      *card_ptr = G1CardTable::dirty_card_val();\n+      _num_dirtied++;\n+    }\n+  }\n+\n+  size_t num_dirtied()   const { return _num_dirtied; }\n+};\n+\n+G1PostEvacuateCollectionSetCleanupTask2::RedirtyLoggedCardsTask::RedirtyLoggedCardsTask(G1RedirtyCardsQueueSet* rdcqs) :\n+  G1AbstractSubTask(G1GCPhaseTimes::RedirtyCards),\n+  _rdcqs(rdcqs),\n+  _nodes(rdcqs->all_completed_buffers()) { }\n+\n+G1PostEvacuateCollectionSetCleanupTask2::RedirtyLoggedCardsTask::~RedirtyLoggedCardsTask() {\n+  G1DirtyCardQueueSet& dcq = G1BarrierSet::dirty_card_queue_set();\n+  dcq.merge_bufferlists(_rdcqs);\n+  _rdcqs->verify_empty();\n+}\n+\n+double G1PostEvacuateCollectionSetCleanupTask2::RedirtyLoggedCardsTask::worker_cost() const {\n+  \/\/ Needs more investigation.\n+  return G1CollectedHeap::heap()->workers()->active_workers();\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::RedirtyLoggedCardsTask::do_work(uint worker_id) {\n+  RedirtyLoggedCardTableEntryClosure cl(G1CollectedHeap::heap());\n+  const size_t buffer_size = _rdcqs->buffer_size();\n+  BufferNode* next = Atomic::load(&_nodes);\n+  while (next != nullptr) {\n+    BufferNode* node = next;\n+    next = Atomic::cmpxchg(&_nodes, node, node->next());\n+    if (next == node) {\n+      cl.apply_to_buffer(node, buffer_size, worker_id);\n+      next = node->next();\n+    }\n+  }\n+  record_work_item(worker_id, 0, cl.num_dirtied());\n+}\n+\n+\/\/ Helper class to keep statistics for the collection set freeing\n+class FreeCSetStats {\n+  size_t _before_used_bytes;   \/\/ Usage in regions successfully evacutate\n+  size_t _after_used_bytes;    \/\/ Usage in regions failing evacuation\n+  size_t _bytes_allocated_in_old_since_last_gc; \/\/ Size of young regions turned into old\n+  size_t _failure_used_words;  \/\/ Live size in failed regions\n+  size_t _failure_waste_words; \/\/ Wasted size in failed regions\n+  size_t _rs_length;           \/\/ Remembered set size\n+  uint _regions_freed;         \/\/ Number of regions freed\n+\n+public:\n+  FreeCSetStats() :\n+      _before_used_bytes(0),\n+      _after_used_bytes(0),\n+      _bytes_allocated_in_old_since_last_gc(0),\n+      _failure_used_words(0),\n+      _failure_waste_words(0),\n+      _rs_length(0),\n+      _regions_freed(0) { }\n+\n+  void merge_stats(FreeCSetStats* other) {\n+    assert(other != nullptr, \"invariant\");\n+    _before_used_bytes += other->_before_used_bytes;\n+    _after_used_bytes += other->_after_used_bytes;\n+    _bytes_allocated_in_old_since_last_gc += other->_bytes_allocated_in_old_since_last_gc;\n+    _failure_used_words += other->_failure_used_words;\n+    _failure_waste_words += other->_failure_waste_words;\n+    _rs_length += other->_rs_length;\n+    _regions_freed += other->_regions_freed;\n+  }\n+\n+  void report(G1CollectedHeap* g1h, G1EvacuationInfo* evacuation_info) {\n+    evacuation_info->set_regions_freed(_regions_freed);\n+    evacuation_info->increment_collectionset_used_after(_after_used_bytes);\n+\n+    g1h->decrement_summary_bytes(_before_used_bytes);\n+    g1h->alloc_buffer_stats(G1HeapRegionAttr::Old)->add_failure_used_and_waste(_failure_used_words, _failure_waste_words);\n+\n+    G1Policy *policy = g1h->policy();\n+    policy->old_gen_alloc_tracker()->add_allocated_bytes_since_last_gc(_bytes_allocated_in_old_since_last_gc);\n+    policy->record_rs_length(_rs_length);\n+    policy->cset_regions_freed();\n+  }\n+\n+  void account_failed_region(HeapRegion* r) {\n+    size_t used_words = r->marked_bytes() \/ HeapWordSize;\n+    _failure_used_words += used_words;\n+    _failure_waste_words += HeapRegion::GrainWords - used_words;\n+    _after_used_bytes += r->used();\n+\n+    \/\/ When moving a young gen region to old gen, we \"allocate\" that whole\n+    \/\/ region there. This is in addition to any already evacuated objects.\n+    \/\/ Notify the policy about that. Old gen regions do not cause an\n+    \/\/ additional allocation: both the objects still in the region and the\n+    \/\/ ones already moved are accounted for elsewhere.\n+    if (r->is_young()) {\n+      _bytes_allocated_in_old_since_last_gc += HeapRegion::GrainBytes;\n+    }\n+  }\n+\n+  void account_evacuated_region(HeapRegion* r) {\n+      size_t used = r->used();\n+      assert(used > 0, \"region %u %s zero used\", r->hrm_index(), r->get_short_type_str());\n+    _before_used_bytes += used;\n+    _regions_freed += 1;\n+  }\n+\n+  void account_rs_length(HeapRegion* r) {\n+    _rs_length += r->rem_set()->occupied();\n+  }\n+};\n+\n+\/\/ Closure applied to all regions in the collection set.\n+class FreeCSetClosure : public HeapRegionClosure {\n+  \/\/ Helper to send JFR events for regions.\n+  class JFREventForRegion {\n+    EventGCPhaseParallel _event;\n+\n+  public:\n+    JFREventForRegion(HeapRegion* region, uint worker_id) : _event() {\n+      _event.set_gcId(GCId::current());\n+      _event.set_gcWorkerId(worker_id);\n+      if (region->is_young()) {\n+        _event.set_name(G1GCPhaseTimes::phase_name(G1GCPhaseTimes::YoungFreeCSet));\n+      } else {\n+        _event.set_name(G1GCPhaseTimes::phase_name(G1GCPhaseTimes::NonYoungFreeCSet));\n+      }\n+    }\n+\n+    ~JFREventForRegion() {\n+      _event.commit();\n+    }\n+  };\n+\n+  \/\/ Helper to do timing for region work.\n+  class TimerForRegion {\n+    Tickspan& _time;\n+    Ticks     _start_time;\n+  public:\n+    TimerForRegion(Tickspan& time) : _time(time), _start_time(Ticks::now()) { }\n+    ~TimerForRegion() {\n+      _time += Ticks::now() - _start_time;\n+    }\n+  };\n+\n+  \/\/ FreeCSetClosure members\n+  G1CollectedHeap* _g1h;\n+  const size_t*    _surviving_young_words;\n+  uint             _worker_id;\n+  Tickspan         _young_time;\n+  Tickspan         _non_young_time;\n+  FreeCSetStats*   _stats;\n+\n+  void assert_in_cset(HeapRegion* r) {\n+    assert(r->young_index_in_cset() != 0 &&\n+           (uint)r->young_index_in_cset() <= _g1h->collection_set()->young_region_length(),\n+           \"Young index %u is wrong for region %u of type %s with %u young regions\",\n+           r->young_index_in_cset(), r->hrm_index(), r->get_type_str(), _g1h->collection_set()->young_region_length());\n+  }\n+\n+  void handle_evacuated_region(HeapRegion* r) {\n+    assert(!r->is_empty(), \"Region %u is an empty region in the collection set.\", r->hrm_index());\n+    stats()->account_evacuated_region(r);\n+\n+    \/\/ Free the region and and its remembered set.\n+    _g1h->free_region(r, nullptr);\n+    _g1h->hr_printer()->cleanup(r);\n+  }\n+\n+  void handle_failed_region(HeapRegion* r) {\n+    \/\/ Do some allocation statistics accounting. Regions that failed evacuation\n+    \/\/ are always made old, so there is no need to update anything in the young\n+    \/\/ gen statistics, but we need to update old gen statistics.\n+    stats()->account_failed_region(r);\n+\n+    \/\/ Update the region state due to the failed evacuation.\n+    r->handle_evacuation_failure();\n+\n+    \/\/ Add region to old set, need to hold lock.\n+    MutexLocker x(OldSets_lock, Mutex::_no_safepoint_check_flag);\n+    _g1h->old_set_add(r);\n+  }\n+\n+  Tickspan& timer_for_region(HeapRegion* r) {\n+    return r->is_young() ? _young_time : _non_young_time;\n+  }\n+\n+  FreeCSetStats* stats() {\n+    return _stats;\n+  }\n+\n+public:\n+  FreeCSetClosure(const size_t* surviving_young_words,\n+                  uint worker_id,\n+                  FreeCSetStats* stats) :\n+      HeapRegionClosure(),\n+      _g1h(G1CollectedHeap::heap()),\n+      _surviving_young_words(surviving_young_words),\n+      _worker_id(worker_id),\n+      _young_time(),\n+      _non_young_time(),\n+      _stats(stats) { }\n+\n+  virtual bool do_heap_region(HeapRegion* r) {\n+    assert(r->in_collection_set(), \"Invariant: %u missing from CSet\", r->hrm_index());\n+    JFREventForRegion event(r, _worker_id);\n+    TimerForRegion timer(timer_for_region(r));\n+\n+    _g1h->clear_region_attr(r);\n+    stats()->account_rs_length(r);\n+\n+    if (r->is_young()) {\n+      assert_in_cset(r);\n+      r->record_surv_words_in_group(_surviving_young_words[r->young_index_in_cset()]);\n+    }\n+\n+    if (r->evacuation_failed()) {\n+      handle_failed_region(r);\n+    } else {\n+      handle_evacuated_region(r);\n+    }\n+    assert(!_g1h->is_on_master_free_list(r), \"sanity\");\n+\n+    return false;\n+  }\n+\n+  void report_timing() {\n+    G1GCPhaseTimes* pt = _g1h->phase_times();\n+    if (_young_time.value() > 0) {\n+      pt->record_time_secs(G1GCPhaseTimes::YoungFreeCSet, _worker_id, _young_time.seconds());\n+    }\n+    if (_non_young_time.value() > 0) {\n+      pt->record_time_secs(G1GCPhaseTimes::NonYoungFreeCSet, _worker_id, _non_young_time.seconds());\n+    }\n+  }\n+};\n+\n+FreeCSetStats* G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::worker_stats(uint worker) {\n+  return &_worker_stats[worker];\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::report_statistics() {\n+  \/\/ Merge the accounting\n+  FreeCSetStats total_stats;\n+  for (uint worker = 0; worker < _active_workers; worker++) {\n+    total_stats.merge_stats(worker_stats(worker));\n+  }\n+  total_stats.report(_g1h, _evacuation_info);\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::FreeCollectionSetTask(G1EvacuationInfo* evacuation_info,\n+                                                                                      const size_t* surviving_young_words) :\n+    G1AbstractSubTask(G1GCPhaseTimes::FreeCollectionSet),\n+    _g1h(G1CollectedHeap::heap()),\n+    _evacuation_info(evacuation_info),\n+    _worker_stats(nullptr),\n+    _claimer(0),\n+    _surviving_young_words(surviving_young_words),\n+    _active_workers(0) {\n+  _g1h->clear_eden();\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::~FreeCollectionSetTask() {\n+  Ticks serial_time = Ticks::now();\n+  report_statistics();\n+  for (uint worker = 0; worker < _active_workers; worker++) {\n+    _worker_stats[worker].~FreeCSetStats();\n+  }\n+  FREE_C_HEAP_ARRAY(FreeCSetStats, _worker_stats);\n+  _g1h->phase_times()->record_serial_free_cset_time_ms((Ticks::now() - serial_time).seconds() * 1000.0);\n+  _g1h->clear_collection_set();\n+}\n+\n+double G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::worker_cost() const {\n+  return G1CollectedHeap::heap()->collection_set()->region_length();\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::set_max_workers(uint max_workers) {\n+  _active_workers = max_workers;\n+  _worker_stats = NEW_C_HEAP_ARRAY(FreeCSetStats, max_workers, mtGC);\n+  for (uint worker = 0; worker < _active_workers; worker++) {\n+    ::new (&_worker_stats[worker]) FreeCSetStats();\n+  }\n+  _claimer.set_n_workers(_active_workers);\n+}\n+\n+void G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask::do_work(uint worker_id) {\n+  FreeCSetClosure cl(_surviving_young_words, worker_id, worker_stats(worker_id));\n+  _g1h->collection_set_par_iterate_all(&cl, &_claimer, worker_id);\n+  \/\/ Report per-region type timings.\n+  cl.report_timing();\n+}\n+\n+G1PostEvacuateCollectionSetCleanupTask2::G1PostEvacuateCollectionSetCleanupTask2(PreservedMarksSet* preserved_marks_set,\n+                                                                                 G1RedirtyCardsQueueSet* rdcqs,\n+                                                                                 G1EvacuationInfo* evacuation_info,\n+                                                                                 const size_t* surviving_young_words) :\n+  G1BatchedGangTask(\"Post Evacuate Cleanup 2\", G1CollectedHeap::heap()->phase_times())\n+{\n+  add_serial_task(new ResetHotCardCacheTask());\n+  add_serial_task(new PurgeCodeRootsTask());\n+#if COMPILER2_OR_JVMCI\n+  add_serial_task(new UpdateDerivedPointersTask());\n+#endif\n+  if (EagerlyReclaimHumongousObjectsTask::should_execute()) {\n+    add_serial_task(new EagerlyReclaimHumongousObjectsTask());\n+  }\n+\n+  if (RestorePreservedMarksTask::should_execute()) {\n+    add_parallel_task(new RestorePreservedMarksTask(preserved_marks_set));\n+  }\n+  add_parallel_task(new RedirtyLoggedCardsTask(rdcqs));\n+  add_parallel_task(new FreeCollectionSetTask(evacuation_info, surviving_young_words));\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":606,"deletions":0,"binary":false,"changes":606,"status":"added"},{"patch":"@@ -0,0 +1,199 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1YOUNGGCPOSTEVACUATETASKS_HPP\n+#define SHARE_GC_G1_G1YOUNGGCPOSTEVACUATETASKS_HPP\n+\n+#include \"gc\/g1\/g1BatchedGangTask.hpp\"\n+#include \"gc\/g1\/g1EvacFailure.hpp\"\n+\n+class FreeCSetStats;\n+\n+class G1CollectedHeap;\n+class G1EvacuationInfo;\n+class G1ParScanThreadStateSet;\n+class G1RedirtyCardsQueueSet;\n+\n+\/\/ First set of post evacuate collection set tasks containing (\"s\" means serial):\n+\/\/ - Merge PSS (s)\n+\/\/ - Recalculate Used (s)\n+\/\/ - Remove Self Forwards (on evacuation failure)\n+\/\/ - Clear Card Table\n+class G1PostEvacuateCollectionSetCleanupTask1 : public G1BatchedGangTask {\n+  class MergePssTask;\n+  class RecalculateUsedTask;\n+  class RemoveSelfForwardPtrsTask;\n+\n+public:\n+  G1PostEvacuateCollectionSetCleanupTask1(G1ParScanThreadStateSet* per_thread_states,\n+                                          G1RedirtyCardsQueueSet* rdcqs);\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask1::MergePssTask : public G1AbstractSubTask {\n+  G1ParScanThreadStateSet* _per_thread_states;\n+\n+public:\n+  MergePssTask(G1ParScanThreadStateSet* per_thread_states);\n+\n+  double worker_cost() const override { return 1.0; }\n+  void do_work(uint worker_id) override;\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask1::RecalculateUsedTask : public G1AbstractSubTask {\n+public:\n+  RecalculateUsedTask() : G1AbstractSubTask(G1GCPhaseTimes::RecalculateUsed) { }\n+\n+  double worker_cost() const override;\n+  void do_work(uint worker_id) override;\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask1::RemoveSelfForwardPtrsTask : public G1AbstractSubTask {\n+  G1ParRemoveSelfForwardPtrsTask _cl;\n+\n+public:\n+  RemoveSelfForwardPtrsTask(G1RedirtyCardsQueueSet* rdcqs);\n+  ~RemoveSelfForwardPtrsTask();\n+\n+  static bool should_execute();\n+\n+  double worker_cost() const override;\n+  void do_work(uint worker_id) override;\n+};\n+\n+\/\/ Second set of post evacuate collection set tasks containing (s means serial):\n+\/\/ - Eagerly Reclaim Humongous Objects (s)\n+\/\/ - Purge Code Roots (s)\n+\/\/ - Reset Hot Card Cache (s)\n+\/\/ - Update Derived Pointers (s)\n+\/\/ - Redirty Logged Cards\n+\/\/ - Restore Preserved Marks (on evacuation failure)\n+\/\/ - Free Collection Set\n+class G1PostEvacuateCollectionSetCleanupTask2 : public G1BatchedGangTask {\n+  class EagerlyReclaimHumongousObjectsTask;\n+  class PurgeCodeRootsTask;\n+  class ResetHotCardCacheTask;\n+#if COMPILER2_OR_JVMCI\n+  class UpdateDerivedPointersTask;\n+#endif\n+\n+  class RedirtyLoggedCardsTask;\n+  class RestorePreservedMarksTask;\n+  class FreeCollectionSetTask;\n+\n+public:\n+  G1PostEvacuateCollectionSetCleanupTask2(PreservedMarksSet* preserved_marks_set,\n+                                          G1RedirtyCardsQueueSet* rdcqs,\n+                                          G1EvacuationInfo* evacuation_info,\n+                                          const size_t* surviving_young_words);\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask2::ResetHotCardCacheTask : public G1AbstractSubTask {\n+public:\n+  ResetHotCardCacheTask() : G1AbstractSubTask(G1GCPhaseTimes::ResetHotCardCache) { }\n+\n+  double worker_cost() const override { return 0.5; }\n+  void do_work(uint worker_id) override;\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask2::PurgeCodeRootsTask : public G1AbstractSubTask {\n+public:\n+  PurgeCodeRootsTask() : G1AbstractSubTask(G1GCPhaseTimes::PurgeCodeRoots) { }\n+\n+  double worker_cost() const override { return 1.0; }\n+  void do_work(uint worker_id) override;\n+};\n+\n+#if COMPILER2_OR_JVMCI\n+class G1PostEvacuateCollectionSetCleanupTask2::UpdateDerivedPointersTask : public G1AbstractSubTask {\n+public:\n+  UpdateDerivedPointersTask() : G1AbstractSubTask(G1GCPhaseTimes::UpdateDerivedPointers) { }\n+\n+  double worker_cost() const override { return 1.0; }\n+  void do_work(uint worker_id) override;\n+};\n+#endif\n+\n+class G1PostEvacuateCollectionSetCleanupTask2::EagerlyReclaimHumongousObjectsTask : public G1AbstractSubTask {\n+  uint _humongous_regions_reclaimed;\n+  size_t _bytes_freed;\n+\n+public:\n+  EagerlyReclaimHumongousObjectsTask();\n+  virtual ~EagerlyReclaimHumongousObjectsTask();\n+\n+  static bool should_execute();\n+\n+  double worker_cost() const override { return 1.0; }\n+  void do_work(uint worker_id) override;\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask2::RestorePreservedMarksTask : public G1AbstractSubTask {\n+  PreservedMarksSet* _preserved_marks;\n+  AbstractGangTask* _cl;\n+\n+public:\n+  RestorePreservedMarksTask(PreservedMarksSet* preserved_marks);\n+  virtual ~RestorePreservedMarksTask();\n+\n+  static bool should_execute();\n+\n+  double worker_cost() const override;\n+  void do_work(uint worker_id) override;\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask2::RedirtyLoggedCardsTask : public G1AbstractSubTask {\n+  G1RedirtyCardsQueueSet* _rdcqs;\n+  BufferNode* volatile _nodes;\n+\n+public:\n+  RedirtyLoggedCardsTask(G1RedirtyCardsQueueSet* rdcqs);\n+  virtual ~RedirtyLoggedCardsTask();\n+\n+  double worker_cost() const override;\n+  void do_work(uint worker_id) override;\n+};\n+\n+class G1PostEvacuateCollectionSetCleanupTask2::FreeCollectionSetTask : public G1AbstractSubTask {\n+  G1CollectedHeap*  _g1h;\n+  G1EvacuationInfo* _evacuation_info;\n+  FreeCSetStats*    _worker_stats;\n+  HeapRegionClaimer _claimer;\n+  const size_t*     _surviving_young_words;\n+  uint              _active_workers;\n+\n+  FreeCSetStats* worker_stats(uint worker);\n+  void report_statistics();\n+\n+public:\n+  FreeCollectionSetTask(G1EvacuationInfo* evacuation_info, const size_t* surviving_young_words);\n+  virtual ~FreeCollectionSetTask();\n+\n+  double worker_cost() const override;\n+  void set_max_workers(uint max_workers) override;\n+\n+  void do_work(uint worker_id) override;\n+};\n+\n+#endif \/\/ SHARE_GC_G1_G1YOUNGGCPOSTEVACUATETASKS_HPP\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.hpp","additions":199,"deletions":0,"binary":false,"changes":199,"status":"added"},{"patch":"@@ -737,1 +737,0 @@\n-  assert(n_workers > 0, \"Need at least one worker.\");\n@@ -748,0 +747,1 @@\n+  assert(_n_workers > 0, \"must be set\");\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionManager.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -318,0 +318,5 @@\n+  void set_n_workers(uint n_workers) {\n+    assert(_n_workers == 0, \"already set\");\n+    assert(n_workers > 0, \"must be\");\n+    _n_workers = n_workers;\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionManager.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -145,0 +145,4 @@\n+AbstractGangTask* PreservedMarksSet::create_task() {\n+  return new RestorePreservedMarksTask(this);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+class AbstractGangTask;\n@@ -116,0 +117,2 @@\n+  AbstractGangTask* create_task();\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/preservedMarks.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-  out->print(\"%-25s\", \"\");\n+  out->print(\"%-30s\", \"\");\n@@ -81,1 +81,1 @@\n-  out->print(\"%-25s\", \"\");\n+  out->print(\"%-30s\", \"\");\n","filename":"src\/hotspot\/share\/gc\/shared\/workerDataArray.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -153,1 +153,1 @@\n-    out->print(\"%-25s\", title());\n+    out->print(\"%-30s\", title());\n","filename":"src\/hotspot\/share\/gc\/shared\/workerDataArray.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-class AbstractGangTask {\n+class AbstractGangTask : public CHeapObj<mtInternal> {\n","filename":"src\/hotspot\/share\/gc\/shared\/workgroup.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -79,1 +79,1 @@\n-    out.print(\"%-25s\", str);\n+    out.print(\"%-30s\", str);\n","filename":"test\/hotspot\/gtest\/gc\/shared\/test_workerDataArray.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -50,0 +50,6 @@\n+    static final String SumSeparator = \"Sum: \";\n+\n+    private static String getSumValue(String s) {\n+        return s.substring(s.indexOf(SumSeparator) + SumSeparator.length(), s.indexOf(\", Workers\"));\n+    }\n+\n@@ -71,4 +77,4 @@\n-        \/\/   Humongous Total: b\n-        \/\/   Humongous Candidate: c\n-        \/\/   Humongous Reclaim: d.dms\n-        \/\/   Humongous Reclaimed: e\n+        \/\/   Eagerly Reclaim Humonguous Objects b.cms\n+        \/\/   Humongous Total: Min: 1, Avg:  1.0, Max: 1, Diff: 0, Sum: c, Workers: 1\n+        \/\/   Humongous Candidate: Min: 1, Avg:  1.0, Max: 1, Diff: 0, Sum: d, Workers: 1\n+        \/\/   Humongous Reclaimed: Min: 1, Avg:  1.0, Max: 1, Diff: 0, Sum: e, Workers: 1\n@@ -84,3 +90,3 @@\n-            int total = Integer.parseInt(lines[i + 1]);\n-            int candidate = Integer.parseInt(lines[i + 2]);\n-            int reclaimed = Integer.parseInt(lines[i + 4]);\n+            int total = Integer.parseInt(getSumValue(lines[i + 2]));\n+            int candidate = Integer.parseInt(getSumValue(lines[i + 3]));\n+            int reclaimed = Integer.parseInt(getSumValue(lines[i + 4]));\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestEagerReclaimHumongousRegionsLog.java","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -130,3 +130,2 @@\n-        new LogMessageWithLevel(\"Redirty Cards\", Level.DEBUG),\n-        new LogMessageWithLevel(\"Parallel Redirty\", Level.TRACE),\n-        new LogMessageWithLevel(\"Redirtied Cards\", Level.TRACE),\n+        new LogMessageWithLevel(\"Redirty Logged Cards\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Redirtied Cards\", Level.DEBUG),\n@@ -134,1 +133,1 @@\n-        new LogMessageWithLevel(\"Code Roots Purge\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Purge Code Roots\", Level.DEBUG),\n@@ -145,1 +144,0 @@\n-        new LogMessageWithLevel(\"Parallel Free Collection Set\", Level.TRACE),\n@@ -153,2 +151,0 @@\n-        \/\/ Humongous Eager Reclaim\n-        new LogMessageWithLevel(\"Humongous Reclaim\", Level.DEBUG),\n@@ -169,1 +165,1 @@\n-        new LogMessageWithLevelC2OrJVMCIOnly(\"DerivedPointerTable Update\", Level.DEBUG),\n+        new LogMessageWithLevelC2OrJVMCIOnly(\"Update Derived Pointers\", Level.DEBUG),\n@@ -241,3 +237,3 @@\n-        new LogMessageWithLevel(\"Evacuation Failure\", Level.DEBUG),\n-        new LogMessageWithLevel(\"Recalculate Used\", Level.TRACE),\n-        new LogMessageWithLevel(\"Remove Self Forwards\", Level.TRACE),\n+        new LogMessageWithLevel(\"Recalculate Used Memory\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Restore Preserved Marks\", Level.DEBUG),\n+        new LogMessageWithLevel(\"Remove Self Forwards\", Level.DEBUG),\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestGCLogMessages.java","additions":7,"deletions":11,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -66,1 +66,1 @@\n-        \"-Xlog:gc+ihop+ergo=debug,gc*=debug\"\n+        \"-Xlog:gc+ihop+ergo=debug\"\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/ihop\/TestIHOPStatic.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -71,1 +71,1 @@\n-        \"-Xlog:gc=debug,gc+plab=debug,gc+phases=trace\",\n+        \"-Xlog:gc=debug,gc+phases=trace\",\n@@ -118,0 +118,1 @@\n+\n@@ -198,1 +199,1 @@\n-                .filter(line -> line.contains(\"Evacuation Failure\"))\n+                .filter(line -> line.contains(\"space exhausted\"))\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/plab\/TestPLABEvacuationFailure.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -110,1 +110,8 @@\n-            \"ParFreeCSet\",\n+            \"RecalculateUsed\",\n+            \"ResetHotCardCache\",\n+            \"FreeCSet\",\n+            \"PurgeCodeRoots\",\n+            \"UpdateDerivedPointers\",\n+            \"EagerlyReclaimHumongousObjects\",\n+            \"ClearLoggedCards\",\n+            \"MergePSS\",\n","filename":"test\/jdk\/jdk\/jfr\/event\/gc\/collection\/TestG1ParallelPhases.java","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"}]}