{"files":[{"patch":"@@ -42,0 +42,4 @@\n+extern aarch64_atomic_stub_t aarch64_atomic_fetch_or_4_impl;\n+extern aarch64_atomic_stub_t aarch64_atomic_fetch_or_8_impl;\n+extern aarch64_atomic_stub_t aarch64_atomic_fetch_or_4_relaxed_impl;\n+extern aarch64_atomic_stub_t aarch64_atomic_fetch_or_8_relaxed_impl;\n","filename":"src\/hotspot\/cpu\/aarch64\/atomic_aarch64.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -8003,0 +8003,4 @@\n+DEFAULT_ATOMIC_OP(fetch_or, 4, )\n+DEFAULT_ATOMIC_OP(fetch_or, 8, )\n+DEFAULT_ATOMIC_OP(fetch_or, 4, _relaxed)\n+DEFAULT_ATOMIC_OP(fetch_or, 8, _relaxed)\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -157,0 +157,54 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const;\n+};\n+\n+template<>\n+template<typename D>\n+inline D Atomic::PlatformBitOp<4>::fetch_and_or(D volatile* dest, D set_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(4 == sizeof(D));\n+\n+  D result, temp;\n+\n+  pre_membar(order);\n+\n+  __asm__ __volatile__ (\n+    \"1: lwarx   %0,  0, %3    \\n\"\n+    \"   or      %1, %0, %2    \\n\"\n+    \"   stwcx.  %1,  0, %3    \\n\"\n+    \"   bne-    1b            \\n\"\n+    : \/*%0*\/\"=&r\" (result), \/*%1*\/\"=&r\" (temp)\n+    : \/*%2*\/\"r\" (set_value), \/*%3*\/\"r\" (dest)\n+    : \"cc\", \"memory\" );\n+\n+  post_membar(order);\n+\n+  return result;\n+}\n+\n+template<>\n+template<typename D>\n+inline D Atomic::PlatformBitOp<8>::fetch_and_or(D volatile* dest, D set_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(8 == sizeof(D));\n+\n+  D result, temp;\n+\n+  pre_membar(order);\n+\n+  __asm__ __volatile__ (\n+    \"1: ldarx   %0,  0, %3    \\n\"\n+    \"   or      %1, %0, %2    \\n\"\n+    \"   stdcx.  %1,  0, %3    \\n\"\n+    \"   bne-    1b            \\n\"\n+    : \/*%0*\/\"=&r\" (result), \/*%1*\/\"=&r\" (temp)\n+    : \/*%2*\/\"r\" (set_value), \/*%3*\/\"r\" (dest)\n+    : \"cc\", \"memory\" );\n+\n+  post_membar(order);\n+\n+  return result;\n+}\n+\n","filename":"src\/hotspot\/os_cpu\/aix_ppc\/atomic_aix_ppc.hpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -51,0 +51,10 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D res = __atomic_fetch_or(dest, set_value, __ATOMIC_RELEASE);\n+    FULL_MEM_BARRIER;\n+    return res;\n+  }\n+};\n+\n","filename":"src\/hotspot\/os_cpu\/bsd_aarch64\/atomic_bsd_aarch64.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -55,0 +55,20 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D old_val = *dest;\n+\n+    do {\n+      const D new_val = old_val | set_value;\n+      const D cur_val = Atomic::cmpxchg(dest, old_val, new_val, order);\n+      if (cur_val == old_val) {\n+        \/\/ Success\n+        return old_val;\n+      }\n+\n+      \/\/ The value changed, retry\n+      old_val = cur_val;\n+    } while (true);\n+  }\n+};\n+\n","filename":"src\/hotspot\/os_cpu\/bsd_x86\/atomic_bsd_x86.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -206,0 +206,20 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D old_val = *dest;\n+\n+    do {\n+      const D new_val = old_val | set_value;\n+      const D cur_val = Atomic::cmpxchg(dest, old_val, new_val, order);\n+      if (cur_val == old_val) {\n+        \/\/ Success\n+        return old_val;\n+      }\n+\n+      \/\/ The value changed, retry\n+      old_val = cur_val;\n+    } while (true);\n+  }\n+};\n+\n","filename":"src\/hotspot\/os_cpu\/bsd_zero\/atomic_bsd_zero.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -88,0 +88,62 @@\n+        .globl aarch64_atomic_fetch_or_8_default_impl\n+        .align 5\n+aarch64_atomic_fetch_or_8_default_impl:\n+#ifdef __ARM_FEATURE_ATOMICS\n+        ldsetal x1, x2, [x0]\n+#else\n+        prfm    pstl1strm, [x0]\n+0:      ldaxr   x2, [x0]\n+        orr     x8, x2, x1\n+        stlxr   w9, x8, [x0]\n+        cbnz    w9, 0b\n+#endif\n+        dmb     ish\n+        mov     x0, x2\n+        ret\n+\n+        .globl aarch64_atomic_fetch_or_4_default_impl\n+        .align 5\n+aarch64_atomic_fetch_or_4_default_impl:\n+#ifdef __ARM_FEATURE_ATOMICS\n+        ldsetal w1, w2, [x0]\n+#else\n+        prfm    pstl1strm, [x0]\n+0:      ldaxr   w2, [x0]\n+        orr     w8, w2, w1\n+        stlxr   w9, w8, [x0]\n+        cbnz    w9, 0b\n+#endif\n+        dmb     ish\n+        mov     w0, w2\n+        ret\n+\n+        .global aarch64_atomic_fetch_or_8_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_fetch_or_8_relaxed_default_impl:\n+#ifdef __ARM_FEATURE_ATOMICS\n+        ldset x1, x2, [x0]\n+#else\n+        prfm    pstl1strm, [x0]\n+0:      ldxr    x2, [x0]\n+        orr     x8, x2, x1\n+        stxr    w9, x8, [x0]\n+        cbnz    w9, 0b\n+#endif\n+        mov     x0, x2\n+        ret\n+\n+        .global aarch64_atomic_fetch_or_4_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_fetch_or_4_relaxed_default_impl:\n+#ifdef __ARM_FEATURE_ATOMICS\n+        ldset w1, w2, [x0]\n+#else\n+        prfm    pstl1strm, [x0]\n+0:      ldxr    w2, [x0]\n+        orr     w8, w2, w1\n+        stxr    w9, w8, [x0]\n+        cbnz    w9, 0b\n+#endif\n+        mov     w0, w2\n+        ret\n+\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/atomic_linux_aarch64.S","additions":62,"deletions":0,"binary":false,"changes":62,"status":"modified"},{"patch":"@@ -116,0 +116,36 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const;\n+};\n+\n+template<>\n+template<typename D>\n+inline D Atomic::PlatformBitOp<4>::fetch_and_or(D volatile* dest, D set_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(4 == sizeof(D));\n+  aarch64_atomic_stub_t stub;\n+  switch (order) {\n+  case memory_order_relaxed:\n+    stub = aarch64_atomic_fetch_or_4_relaxed_impl; break;\n+  default:\n+    stub = aarch64_atomic_fetch_or_4_impl; break;\n+  }\n+  return atomic_fastcall(stub, dest, set_value);\n+}\n+\n+template<>\n+template<typename D>\n+inline D Atomic::PlatformBitOp<8>::fetch_and_or(D volatile* dest, D set_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(8 == sizeof(D));\n+  aarch64_atomic_stub_t stub;\n+  switch (order) {\n+  case memory_order_relaxed:\n+    stub = aarch64_atomic_fetch_or_8_relaxed_impl; break;\n+  default:\n+    stub = aarch64_atomic_fetch_or_8_impl; break;\n+  }\n+  return atomic_fastcall(stub, dest, set_value);\n+}\n+\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/atomic_linux_aarch64.hpp","additions":36,"deletions":0,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -121,0 +121,19 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D old_val = *dest;\n+\n+    do {\n+      const D new_val = old_val | set_value;\n+      const D cur_val = Atomic::cmpxchg(dest, old_val, new_val, order);\n+      if (cur_val == old_val) {\n+        \/\/ Success\n+        return old_val;\n+      }\n+\n+      \/\/ The value changed, retry\n+      old_val = cur_val;\n+    } while (true);\n+  }\n+};\n","filename":"src\/hotspot\/os_cpu\/linux_arm\/atomic_linux_arm.hpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -157,0 +157,54 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const;\n+};\n+\n+template<>\n+template<typename D>\n+inline D Atomic::PlatformBitOp<4>::fetch_and_or(D volatile* dest, D set_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(4 == sizeof(D));\n+\n+  D result, temp;\n+\n+  pre_membar(order);\n+\n+  __asm__ __volatile__ (\n+    \"1: lwarx   %0,  0, %3    \\n\"\n+    \"   or      %1, %0, %2    \\n\"\n+    \"   stwcx.  %1,  0, %3    \\n\"\n+    \"   bne-    1b            \\n\"\n+    : \/*%0*\/\"=&r\" (result), \/*%1*\/\"=&r\" (temp)\n+    : \/*%2*\/\"r\" (set_value), \/*%3*\/\"r\" (dest)\n+    : \"cc\", \"memory\" );\n+\n+  post_membar(order);\n+\n+  return result;\n+}\n+\n+template<>\n+template<typename D>\n+inline D Atomic::PlatformBitOp<8>::fetch_and_or(D volatile* dest, D set_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(8 == sizeof(D));\n+\n+  D result, temp;\n+\n+  pre_membar(order);\n+\n+  __asm__ __volatile__ (\n+    \"1: ldarx   %0,  0, %3    \\n\"\n+    \"   or      %1, %0, %2    \\n\"\n+    \"   stdcx.  %1,  0, %3    \\n\"\n+    \"   bne-    1b            \\n\"\n+    : \/*%0*\/\"=&r\" (result), \/*%1*\/\"=&r\" (temp)\n+    : \/*%2*\/\"r\" (set_value), \/*%3*\/\"r\" (dest)\n+    : \"cc\", \"memory\" );\n+\n+  post_membar(order);\n+\n+  return result;\n+}\n+\n","filename":"src\/hotspot\/os_cpu\/linux_ppc\/atomic_linux_ppc.hpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -51,0 +51,10 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D res = __atomic_fetch_or(dest, set_value, __ATOMIC_RELEASE);\n+    FULL_MEM_BARRIER;\n+    return res;\n+  }\n+};\n+\n","filename":"src\/hotspot\/os_cpu\/linux_riscv\/atomic_linux_riscv.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -195,0 +195,19 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D old_val = *dest;\n+\n+    do {\n+      const D new_val = old_val | set_value;\n+      const D cur_val = Atomic::cmpxchg(dest, old_val, new_val, order);\n+      if (cur_val == old_val) {\n+        \/\/ Success\n+        return old_val;\n+      }\n+\n+      \/\/ The value changed, retry\n+      old_val = cur_val;\n+    } while (true);\n+  }\n+};\n","filename":"src\/hotspot\/os_cpu\/linux_s390\/atomic_linux_s390.hpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -55,0 +55,20 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D old_val = *dest;\n+\n+    do {\n+      const D new_val = old_val | set_value;\n+      const D cur_val = Atomic::cmpxchg(dest, old_val, new_val, order);\n+      if (cur_val == old_val) {\n+        \/\/ Success\n+        return old_val;\n+      }\n+\n+      \/\/ The value changed, retry\n+      old_val = cur_val;\n+    } while (true);\n+  }\n+};\n+\n","filename":"src\/hotspot\/os_cpu\/linux_x86\/atomic_linux_x86.hpp","additions":20,"deletions":0,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -68,0 +68,10 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const {\n+    D res = __atomic_fetch_or(dest, set_value, __ATOMIC_RELEASE);\n+    FULL_MEM_BARRIER;\n+    return res;\n+  }\n+};\n+\n","filename":"src\/hotspot\/os_cpu\/linux_zero\/atomic_linux_zero.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -70,0 +70,26 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const;\n+};\n+\n+\/\/ The Interlocked* APIs only take long and will not accept __int32. That is\n+\/\/ acceptable on Windows, since long is a 32-bits integer type.\n+\n+#define DEFINE_INTRINSIC_OR(IntrinsicName, IntrinsicType)                 \\\n+  template<>                                                              \\\n+  template<typename D>                                                    \\\n+  inline D Atomic::PlatformBitOp<sizeof(IntrinsicType)>::fetch_and_or(D volatile* dest, \\\n+                                                                      D set_value, \\\n+                                                                      atomic_memory_order order) const { \\\n+    STATIC_ASSERT(sizeof(IntrinsicType) == sizeof(D));                    \\\n+    return PrimitiveConversions::cast<D>(                                 \\\n+      IntrinsicName(reinterpret_cast<IntrinsicType volatile *>(dest),     \\\n+                    PrimitiveConversions::cast<IntrinsicType>(set_value))); \\\n+  }\n+\n+DEFINE_INTRINSIC_OR(InterlockedOr,   long)\n+DEFINE_INTRINSIC_OR(InterlockedOr64, __int64)\n+\n+#undef DEFINE_INTRINSIC_OR\n+\n","filename":"src\/hotspot\/os_cpu\/windows_aarch64\/atomic_windows_aarch64.hpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -73,0 +73,26 @@\n+template<size_t byte_size>\n+struct Atomic::PlatformBitOp {\n+  template<typename D>\n+  D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) const;\n+};\n+\n+\/\/ The Interlocked* APIs only take long and will not accept __int32. That is\n+\/\/ acceptable on Windows, since long is a 32-bits integer type.\n+\n+#define DEFINE_INTRINSIC_OR(IntrinsicName, IntrinsicType)                 \\\n+  template<>                                                              \\\n+  template<typename D>                                                    \\\n+  inline D Atomic::PlatformBitOp<sizeof(IntrinsicType)>::fetch_and_or(D volatile* dest, \\\n+                                                                      D set_value, \\\n+                                                                      atomic_memory_order order) const { \\\n+    STATIC_ASSERT(sizeof(IntrinsicType) == sizeof(D));                    \\\n+    return PrimitiveConversions::cast<D>(                                 \\\n+      IntrinsicName(reinterpret_cast<IntrinsicType volatile *>(dest),     \\\n+                    PrimitiveConversions::cast<IntrinsicType>(set_value))); \\\n+  }\n+\n+DEFINE_INTRINSIC_OR(InterlockedOr,   long)\n+DEFINE_INTRINSIC_OR(InterlockedOr64, __int64)\n+\n+#undef DEFINE_INTRINSIC_OR\n+\n","filename":"src\/hotspot\/os_cpu\/windows_x86\/atomic_windows_x86.hpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -50,1 +50,0 @@\n-  bm_word_t old_val = *addr;\n@@ -52,14 +51,7 @@\n-  do {\n-    const bm_word_t new_val = old_val | pair_mask;\n-    if (new_val == old_val) {\n-      \/\/ Someone else beat us to it\n-      inc_live = false;\n-      return false;\n-    }\n-    const bm_word_t cur_val = Atomic::cmpxchg(addr, old_val, new_val);\n-    if (cur_val == old_val) {\n-      \/\/ Success\n-      const bm_word_t marked_mask = bit_mask(bit);\n-      inc_live = !(old_val & marked_mask);\n-      return true;\n-    }\n+  const bm_word_t old_val = *addr;\n+  const bm_word_t new_val = old_val | pair_mask;\n+  if (new_val == old_val) {\n+    \/\/ Someone else beat us to it\n+    inc_live = false;\n+    return false;\n+  }\n@@ -67,3 +59,4 @@\n-    \/\/ The value changed, retry\n-    old_val = cur_val;\n-  } while (true);\n+  const bm_word_t cur_val = Atomic::fetch_and_or(addr, pair_mask);\n+  const bm_word_t marked_mask = bit_mask(bit);\n+  inc_live = !(cur_val & marked_mask);\n+  return inc_live;\n","filename":"src\/hotspot\/share\/gc\/z\/zBitMap.inline.hpp","additions":11,"deletions":18,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -138,0 +138,8 @@\n+  \/\/ Atomically bit-or to a location. *or*() provide:\n+  \/\/ <fence> bit-or-value-to-dest <membar StoreLoad|StoreStore>\n+\n+  \/\/ Returns previous value.\n+  template<typename D>\n+  inline static D fetch_and_or(D volatile* dest, D set_value,\n+                               atomic_memory_order order = memory_order_conservative);\n+\n@@ -280,0 +288,30 @@\n+  \/\/ Dispatch handler for bitop.  Provides type-based validity checking\n+  \/\/ and limited conversions around calls to the platform-specific\n+  \/\/ implementation layer provided by PlatformBitOp.\n+  template<typename D, typename Enable = void>\n+  struct BitOpImpl;\n+\n+  \/\/ Platform-specific implementation of bitop.  Support for sizes of 4\n+  \/\/ bytes and (if different) pointer size bytes are required.  The\n+  \/\/ class must be default constructable, with these requirements:\n+  \/\/\n+  \/\/ - dest is of type D*, an integral or pointer type.\n+  \/\/ - set_value is of type D, an integral type.\n+  \/\/ - order is of type atomic_memory_order.\n+  \/\/ - platform_bitop is an object of type PlatformBitOp<sizeof(D)>.\n+  \/\/\n+  \/\/ Then\n+  \/\/   platform_bitop.fetch_and_or(dest, set_value, order)\n+  \/\/ must be valid expressions returning a result convertible to D.\n+  \/\/\n+  \/\/ fetch_and_or atomically bit-or set_value to the value of dest,\n+  \/\/ returning the old value.\n+  \/\/\n+  \/\/ When D is a pointer type P*, the fetch_and_or treat it as if it\n+  \/\/ were an uintptr_t; they do not perform any scaling of set_value,\n+  \/\/ as that has already been done by the caller.\n+  \/\/\n+  \/\/ No definition is provided; all platforms must explicitly define\n+  \/\/ this class and any needed specializations.\n+  template<size_t byte_size> struct PlatformBitOp;\n+\n@@ -717,0 +755,16 @@\n+template<typename D>\n+inline D Atomic::fetch_and_or(D volatile* dest, D set_value,\n+                              atomic_memory_order order) {\n+  return BitOpImpl<D>::fetch_and_or(dest, set_value, order);\n+}\n+\n+template<typename D>\n+struct Atomic::BitOpImpl<\n+  D,\n+  typename EnableIf<IsIntegral<D>::value || IsPointer<D>::value>::type>\n+{\n+  static D fetch_and_or(D volatile* dest, D set_value, atomic_memory_order order) {\n+    return PlatformBitOp<sizeof(D)>().fetch_and_or(dest, set_value, order);\n+  }\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/atomic.hpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"}]}