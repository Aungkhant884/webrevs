{"files":[{"patch":"@@ -1177,0 +1177,11 @@\n+void C2_MacroAssembler::vshiftw_imm(int opcode, XMMRegister dst, int shift) {\n+  if (opcode == Op_RShiftVB) {\n+    psraw(dst, shift);\n+  } else if (opcode == Op_LShiftVB) {\n+    psllw(dst, shift);\n+  } else {\n+    assert((opcode == Op_URShiftVB),\"opcode should be Op_URShiftVB\");\n+    psrlw(dst, shift);\n+  }\n+}\n+\n@@ -1192,0 +1203,11 @@\n+void C2_MacroAssembler::vshiftw_imm(int opcode, XMMRegister dst, XMMRegister nds, int shift, int vector_len) {\n+  if (opcode == Op_RShiftVB) {\n+    vpsraw(dst, nds, shift, vector_len);\n+  } else if (opcode == Op_LShiftVB) {\n+    vpsllw(dst, nds, shift, vector_len);\n+  } else {\n+    assert((opcode == Op_URShiftVB),\"opcode should be Op_URShiftVB\");\n+    vpsrlw(dst, nds, shift, vector_len);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -102,0 +102,1 @@\n+  void vshiftw_imm(int opcode, XMMRegister dst, int shift);\n@@ -103,0 +104,1 @@\n+  void vshiftw_imm(int opcode, XMMRegister dst, XMMRegister nds, int shift, int vector_len);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -5860,0 +5860,20 @@\n+instruct vshiftB_imm(vec dst, vec src, immI8 shift, vec tmp, rRegI scratch) %{\n+  predicate(vector_length(n) <= 8);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  effect(TEMP dst, USE src, TEMP tmp, TEMP scratch);\n+  format %{\"vshiftB_imm $dst,$src,$shift\" %}\n+  ins_encode %{\n+    assert(UseSSE > 3, \"required\");\n+    int opcode = this->ideal_Opcode();\n+    bool sign = (opcode != Op_URShiftVB);\n+    __ vextendbw(sign, $tmp$$XMMRegister, $src$$XMMRegister);\n+    __ vshiftw_imm(opcode, $tmp$$XMMRegister, $shift$$constant);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ pand($dst$$XMMRegister, $tmp$$XMMRegister);\n+    __ packuswb($dst$$XMMRegister, $dst$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -5885,0 +5905,24 @@\n+instruct vshift16B_imm(vec dst, vec src, immI8 shift, vec tmp1, vec tmp2, rRegI scratch) %{\n+  predicate(vector_length(n) == 16 && UseAVX <= 1);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  effect(TEMP dst, USE src, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  format %{\"vshift16B_imm $dst,$src,$shift\" %}\n+  ins_encode %{\n+    assert(UseSSE > 3, \"required\");\n+    int opcode = this->ideal_Opcode();\n+    bool sign = (opcode != Op_URShiftVB);\n+    __ vextendbw(sign, $tmp1$$XMMRegister, $src$$XMMRegister);\n+    __ vshiftw_imm(opcode, $tmp1$$XMMRegister, $shift$$constant);\n+    __ pshufd($tmp2$$XMMRegister, $src$$XMMRegister, 0xE);\n+    __ vextendbw(sign, $tmp2$$XMMRegister, $tmp2$$XMMRegister);\n+    __ vshiftw_imm(opcode, $tmp2$$XMMRegister, $shift$$constant);\n+    __ movdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ pand($tmp2$$XMMRegister, $dst$$XMMRegister);\n+    __ pand($dst$$XMMRegister, $tmp1$$XMMRegister);\n+    __ packuswb($dst$$XMMRegister, $tmp2$$XMMRegister);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -5906,0 +5950,20 @@\n+instruct vshift16B_avx_imm(vec dst, vec src, immI8 shift, vec tmp, rRegI scratch) %{\n+  predicate(vector_length(n) == 16 && UseAVX > 1);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  format %{\"vshift16B_avx_imm $dst,$src,$shift\" %}\n+  ins_encode %{\n+    int opcode = this->ideal_Opcode();\n+    bool sign = (opcode != Op_URShiftVB);\n+    int vlen_enc = Assembler::AVX_256bit;\n+    __ vextendbw(sign, $tmp$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ vshiftw_imm(opcode, $tmp$$XMMRegister, $tmp$$XMMRegister, $shift$$constant, vlen_enc);\n+    __ vpand($tmp$$XMMRegister, $tmp$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n+    __ vextracti128_high($dst$$XMMRegister, $tmp$$XMMRegister);\n+    __ vpackuswb($dst$$XMMRegister, $tmp$$XMMRegister, $dst$$XMMRegister, 0);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -5931,0 +5995,25 @@\n+instruct vshift32B_avx_imm(vec dst, vec src, immI8 shift, vec tmp, rRegI scratch) %{\n+  predicate(vector_length(n) == 32);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  effect(TEMP dst, TEMP tmp, TEMP scratch);\n+  format %{\"vshift32B_avx_imm $dst,$src,$shift\" %}\n+  ins_encode %{\n+    assert(UseAVX > 1, \"required\");\n+    int opcode = this->ideal_Opcode();\n+    bool sign = (opcode != Op_URShiftVB);\n+    int vlen_enc = Assembler::AVX_256bit;\n+    __ vextracti128_high($tmp$$XMMRegister, $src$$XMMRegister);\n+    __ vextendbw(sign, $tmp$$XMMRegister, $tmp$$XMMRegister, vlen_enc);\n+    __ vextendbw(sign, $dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ vshiftw_imm(opcode, $tmp$$XMMRegister, $tmp$$XMMRegister, $shift$$constant, vlen_enc);\n+    __ vshiftw_imm(opcode, $dst$$XMMRegister, $dst$$XMMRegister, $shift$$constant, vlen_enc);\n+    __ vpand($tmp$$XMMRegister, $tmp$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n+    __ vpand($dst$$XMMRegister, $dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), vlen_enc, $scratch$$Register);\n+    __ vpackuswb($dst$$XMMRegister, $dst$$XMMRegister, $tmp$$XMMRegister, vlen_enc);\n+    __ vpermq($dst$$XMMRegister, $dst$$XMMRegister, 0xD8, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -5959,0 +6048,28 @@\n+instruct vshift64B_avx_imm(vec dst, vec src, immI8 shift, vec tmp1, vec tmp2, rRegI scratch) %{\n+  predicate(vector_length(n) == 64);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  effect(TEMP dst, TEMP tmp1, TEMP tmp2, TEMP scratch);\n+  format %{\"vshift64B_avx_imm $dst,$src,$shift\" %}\n+  ins_encode %{\n+    assert(UseAVX > 2, \"required\");\n+    int opcode = this->ideal_Opcode();\n+    bool sign = (opcode != Op_URShiftVB);\n+    int vlen_enc = Assembler::AVX_512bit;\n+    __ vextracti64x4($tmp1$$XMMRegister, $src$$XMMRegister, 1);\n+    __ vextendbw(sign, $tmp1$$XMMRegister, $tmp1$$XMMRegister, vlen_enc);\n+    __ vextendbw(sign, $tmp2$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ vshiftw_imm(opcode, $tmp1$$XMMRegister, $tmp1$$XMMRegister, $shift$$constant, vlen_enc);\n+    __ vshiftw_imm(opcode, $tmp2$$XMMRegister, $tmp2$$XMMRegister, $shift$$constant, vlen_enc);\n+    __ vmovdqu($dst$$XMMRegister, ExternalAddress(vector_short_to_byte_mask()), $scratch$$Register);\n+    __ vpbroadcastd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vpand($tmp1$$XMMRegister, $tmp1$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vpand($tmp2$$XMMRegister, $tmp2$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vpackuswb($dst$$XMMRegister, $tmp1$$XMMRegister, $tmp2$$XMMRegister, vlen_enc);\n+    __ evmovdquq($tmp2$$XMMRegister, ExternalAddress(vector_byte_perm_mask()), vlen_enc, $scratch$$Register);\n+    __ vpermq($dst$$XMMRegister, $tmp2$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":117,"deletions":0,"binary":false,"changes":117,"status":"modified"},{"patch":"@@ -372,1 +372,2 @@\n-    res = gvn().transform(VectorNode::make(Op_LShiftVB, res, cnt, vt));\n+    Node* shift_cnt = gvn().transform(new LShiftCntVNode(cnt, vt));\n+    res = gvn().transform(VectorNode::make(Op_LShiftVB, res, shift_cnt, vt));\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -0,0 +1,103 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.vectorapi;\n+\n+import jdk.incubator.vector.ByteVector;\n+import jdk.incubator.vector.VectorSpecies;\n+import jdk.incubator.vector.VectorShuffle;\n+\n+import org.testng.Assert;\n+import org.testng.annotations.Test;\n+\n+\n+\/*\n+ * @test\n+ * @bug 8265956\n+ * @modules jdk.incubator.vector\n+ * @run testng\/othervm compiler.vectorapi.TestVectorShuffleIotaByte\n+ *\/\n+\n+@Test\n+public class TestVectorShuffleIotaByte {\n+    static final VectorSpecies<Byte> SPECIESb_64 = ByteVector.SPECIES_64;\n+    static final VectorSpecies<Byte> SPECIESb_128 = ByteVector.SPECIES_128;\n+    static final VectorSpecies<Byte> SPECIESb_256 = ByteVector.SPECIES_256;\n+    static final VectorSpecies<Byte> SPECIESb_512 = ByteVector.SPECIES_512;\n+\n+    static final int INVOC_COUNT = Integer.getInteger(\"jdk.incubator.vector.test.loop-iterations\", 50000);\n+\n+    static byte[] ab_64 = {41, 45, 59, 46, 115, 101, 103, 97};\n+    static byte[] ab_128 = {112, 32, 116, 117, 111, 104, 116, 105, 119, 32, 107, 111, 111, 98, 32, 97};\n+    static byte[] ab_256 = {32, 101, 107, 105, 108, 32, 115, 105, 32, 117, 111, 121, 32, 116, 117, 111,\n+                            104, 116, 105, 119, 32, 121, 97, 100, 32, 121, 114, 101, 118, 69, 32, 46};\n+    static byte[] ab_512 = {103, 110, 97, 117, 72, 32, 71, 78, 65, 87, 32, 45, 45, 33, 117, 111, 121, 32,\n+                            103, 110, 105, 115, 115, 105, 77, 32, 46, 117, 111, 121, 32, 111, 116, 32, 114,\n+                            101, 116, 116, 101, 108, 32, 100, 114, 105, 104, 116, 32, 121, 109, 32, 115, 105,\n+                            32, 115, 105, 104, 116, 44, 121, 116, 101, 101, 119, 83};\n+\n+    static byte[] expected_64 = {1, 3, 5, 7, -7, -5, -3, -1};\n+    static byte[] expected_128 = {1, 3, 5, 7, 9, 11, 13, 15, -15, -13, -11, -9, -7, -5, -3, -1};\n+    static byte[] expected_256 = {1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31,\n+                                  -31, -29, -27, -25, -23, -21, -19, -17, -15, -13, -11, -9, -7, -5, -3, -1};\n+    static byte[] expected_512 = {1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31,\n+                                  33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63,\n+                                  -63, -61, -59, -57, -55, -53, -51, -49, -47, -45, -43, -41, -39, -37, -35, -33,\n+                                  -31, -29, -27, -25, -23, -21, -19, -17, -15, -13, -11, -9, -7, -5, -3, -1};\n+\n+    @Test\n+    static void testShuffleIota_64() {\n+        for (int ic = 0; ic < INVOC_COUNT; ic++) {\n+            ByteVector bv1 = (ByteVector) VectorShuffle.iota(SPECIESb_64, 1, 2, false).toVector();\n+            bv1.intoArray(ab_64, 0);\n+        }\n+        Assert.assertEquals(ab_64, expected_64);\n+    }\n+\n+    @Test\n+    static void testShuffleIota_128() {\n+        for (int ic = 0; ic < INVOC_COUNT; ic++) {\n+            ByteVector bv2 = (ByteVector) VectorShuffle.iota(SPECIESb_128, 1, 2, false).toVector();\n+            bv2.intoArray(ab_128, 0);\n+        }\n+        Assert.assertEquals(ab_128, expected_128);\n+    }\n+\n+    @Test\n+    static void testShuffleIota_256() {\n+        for (int ic = 0; ic < INVOC_COUNT; ic++) {\n+            ByteVector bv3 = (ByteVector) VectorShuffle.iota(SPECIESb_256, 1, 2, false).toVector();\n+            bv3.intoArray(ab_256, 0);\n+        }\n+        Assert.assertEquals(ab_256, expected_256);\n+    }\n+\n+    @Test\n+    static void testShuffleIota_512() {\n+        for (int ic = 0; ic < INVOC_COUNT; ic++) {\n+            ByteVector bv4 = (ByteVector) VectorShuffle.iota(SPECIESb_512, 1, 2, false).toVector();\n+            bv4.intoArray(ab_512, 0);\n+        }\n+        Assert.assertEquals(ab_512, expected_512);\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/TestVectorShuffleIotaByte.java","additions":103,"deletions":0,"binary":false,"changes":103,"status":"added"}]}