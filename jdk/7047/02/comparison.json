{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.inline.hpp\"\n@@ -45,0 +46,1 @@\n+  G1HeapRegionChunk* _chunk;\n@@ -46,0 +48,1 @@\n+  size_t _marked_objects;\n@@ -52,0 +55,1 @@\n+                                 G1HeapRegionChunk* chunk,\n@@ -57,0 +61,1 @@\n+    _chunk(chunk),\n@@ -58,0 +63,1 @@\n+    _marked_objects(0),\n@@ -59,2 +65,4 @@\n-    _worker_id(worker_id),\n-    _last_forwarded_object_end(hr->bottom()) { }\n+    _worker_id(worker_id) {\n+    _last_forwarded_object_end = _chunk->include_first_obj_in_region() ?\n+                                 _hr->bottom() : _chunk->first_obj_in_chunk();\n+  }\n@@ -62,1 +70,2 @@\n-  size_t marked_bytes() { return _marked_words * HeapWordSize; }\n+  size_t marked_words() const { return _marked_words; }\n+  size_t marked_objects() const { return _marked_objects; }\n@@ -97,0 +106,1 @@\n+    _marked_objects++;\n@@ -102,1 +112,1 @@\n-    _hr->alloc_block_in_bot(obj_addr, obj_end);\n+    _hr->update_bot_if_crossing_boundary(obj_addr, obj_size, false);\n@@ -118,0 +128,1 @@\n+      size_t dummy_size = cast_to_oop(start)->size();\n@@ -119,1 +130,1 @@\n-      _hr->alloc_block_in_bot(start, end_first_obj);\n+      _hr->update_bot_if_crossing_boundary(start, dummy_size, false);\n@@ -125,1 +136,1 @@\n-        _hr->alloc_block_in_bot(end_first_obj, end);\n+        _hr->update_bot_if_crossing_boundary(end_first_obj, cast_to_oop(end_first_obj)->size(), false);\n@@ -140,1 +151,6 @@\n-    zap_dead_objects(_last_forwarded_object_end, _hr->top());\n+    zap_dead_objects(_last_forwarded_object_end, _chunk->next_obj_in_region());\n+    if (_chunk->include_last_obj_in_region()) {\n+      \/\/ As we have process the self forwardee in parallel,\n+      \/\/ it's necessary to update the bot threshold explicitly.\n+      _hr->update_bot_threshold();\n+    }\n@@ -144,1 +160,1 @@\n-class RemoveSelfForwardPtrHRClosure: public HeapRegionClosure {\n+class RemoveSelfForwardPtrHRChunkClosure : public G1HeapRegionChunkClosure {\n@@ -146,0 +162,1 @@\n+  size_t* _marked_words_in_regions;\n@@ -148,16 +165,4 @@\n-  G1EvacFailureRegions* _evac_failure_regions;\n-\n-  G1GCPhaseTimes* _phase_times;\n-\n-public:\n-  RemoveSelfForwardPtrHRClosure(uint worker_id,\n-                                G1EvacFailureRegions* evac_failure_regions) :\n-    _g1h(G1CollectedHeap::heap()),\n-    _worker_id(worker_id),\n-    _evac_failure_regions(evac_failure_regions),\n-    _phase_times(G1CollectedHeap::heap()->phase_times()) {\n-  }\n-\n-  size_t remove_self_forward_ptr_by_walking_hr(HeapRegion* hr,\n-                                               bool during_concurrent_start) {\n-    RemoveSelfForwardPtrObjClosure rspc(hr,\n+  void remove_self_forward_ptr_by_walking_chunk(G1HeapRegionChunk* chunk,\n+                                                bool during_concurrent_start) {\n+    RemoveSelfForwardPtrObjClosure rspc(chunk->heap_region(),\n+                                        chunk,\n@@ -169,2 +174,2 @@\n-    G1CMBitMap* bitmap = const_cast<G1CMBitMap*>(_g1h->concurrent_mark()->prev_mark_bitmap());\n-    hr->apply_to_marked_objects(bitmap, &rspc);\n+    chunk->apply_to_marked_objects(&rspc);\n+    _marked_words_in_regions[chunk->heap_region()->hrm_index()] += rspc.marked_words();\n@@ -172,1 +177,3 @@\n-    rspc.zap_remainder();\n+    if (!chunk->empty()) {\n+      rspc.zap_remainder();\n+    }\n@@ -174,1 +181,3 @@\n-    return rspc.marked_bytes();\n+    G1GCPhaseTimes* p = _g1h->phase_times();\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, rspc.marked_words(), G1GCPhaseTimes::RemoveSelfForwardObjectsBytes);\n+    p->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, rspc.marked_objects(), G1GCPhaseTimes::RemoveSelfForwardObjectsNum);\n@@ -177,6 +186,7 @@\n-  bool do_heap_region(HeapRegion *hr) {\n-    assert(!hr->is_pinned(), \"Unexpected pinned region at index %u\", hr->hrm_index());\n-    assert(hr->in_collection_set(), \"bad CS\");\n-    assert(_evac_failure_regions->contains(hr->hrm_index()), \"precondition\");\n-\n-    hr->clear_index_in_opt_cset();\n+public:\n+  RemoveSelfForwardPtrHRChunkClosure(size_t* marked_words_in_regions,\n+                                     uint worker_id) :\n+    _g1h(G1CollectedHeap::heap()),\n+    _marked_words_in_regions(marked_words_in_regions),\n+    _worker_id(worker_id) {\n+  }\n@@ -184,0 +194,1 @@\n+  void do_heap_region_chunk(G1HeapRegionChunk* chunk) override {\n@@ -185,21 +196,1 @@\n-    bool during_concurrent_mark = _g1h->collector_state()->mark_or_rebuild_in_progress();\n-\n-    hr->note_self_forwarding_removal_start(during_concurrent_start,\n-                                           during_concurrent_mark);\n-\n-    hr->reset_bot();\n-\n-    _phase_times->record_or_add_thread_work_item(G1GCPhaseTimes::RestoreRetainedRegions,\n-                                                   _worker_id,\n-                                                   1,\n-                                                   G1GCPhaseTimes::RestoreRetainedRegionsNum);\n-\n-    size_t live_bytes = remove_self_forward_ptr_by_walking_hr(hr, during_concurrent_start);\n-\n-    hr->rem_set()->clean_strong_code_roots(hr);\n-    hr->rem_set()->clear_locked(true);\n-\n-    hr->note_self_forwarding_removal_end(live_bytes);\n-    _g1h->verifier()->check_bitmaps(\"Self-Forwarding Ptr Removal\", hr);\n-\n-    return false;\n+    remove_self_forward_ptr_by_walking_chunk(chunk, during_concurrent_start);\n@@ -216,1 +207,0 @@\n-  RemoveSelfForwardPtrHRClosure rsfp_cl(worker_id, _evac_failure_regions);\n@@ -218,2 +208,15 @@\n-  \/\/ Iterate through all regions that failed evacuation during the entire collection.\n-  _evac_failure_regions->par_iterate(&rsfp_cl, &_hrclaimer, worker_id);\n+  \/\/ TODO: maybe only allocate and iterate through evacuation failed regions\n+  size_t marked_words_in_regions[_evac_failure_regions->max_regions()];\n+  memset(marked_words_in_regions, 0, sizeof marked_words_in_regions);\n+  RemoveSelfForwardPtrHRChunkClosure chunk_closure(marked_words_in_regions, worker_id);\n+\n+  \/\/ Iterate through all chunks in regions that failed evacuation during the entire collection.\n+  _evac_failure_regions->par_iterate_chunks_in_regions(&chunk_closure, worker_id);\n+\n+  \/\/ Sync marked words of regions to HeapRegion.\n+  for (uint idx = 0; idx < _evac_failure_regions->max_regions(); idx++) {\n+    if (marked_words_in_regions[idx] > 0) {\n+      HeapRegion* region = _g1h->region_at(idx);\n+      region->note_self_forwarding_removal_end_par(marked_words_in_regions[idx] * BytesPerWord);\n+    }\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":61,"deletions":58,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n@@ -36,0 +37,1 @@\n+  _chunk_claimers(nullptr),\n@@ -37,1 +39,4 @@\n-  _max_regions(0) { }\n+  _max_regions(0),\n+  _heap(G1CollectedHeap::heap()),\n+  _phase_times(_heap->phase_times()) {\n+}\n@@ -41,0 +46,1 @@\n+  assert(_chunk_claimers == nullptr, \"not cleaned up\");\n@@ -48,0 +54,1 @@\n+  _chunk_claimers = NEW_C_HEAP_ARRAY(G1HeapRegionChunksClaimer*, _max_regions, mtGC);\n@@ -52,0 +59,7 @@\n+\n+  for (uint i = 0; i < _evac_failure_regions_cur_length; i++) {\n+    FREE_C_HEAP_OBJ(_chunk_claimers[_evac_failure_regions[i]]);\n+  }\n+  FREE_C_HEAP_ARRAY(uint, _chunk_claimers);\n+  _chunk_claimers = nullptr;\n+\n@@ -67,0 +81,11 @@\n+void G1EvacFailureRegions::par_iterate_chunks_in_regions(G1HeapRegionChunkClosure* chunk_closure,\n+                                                         uint worker_id) const {\n+  G1ScanChunksInHeapRegionClosure closure(_chunk_claimers, chunk_closure, worker_id);\n+\n+  G1CollectedHeap::heap()->par_iterate_regions_array(&closure,\n+                                                     nullptr, \/\/ pass null, so every worker thread go through every region.\n+                                                     _evac_failure_regions,\n+                                                     Atomic::load(&_evac_failure_regions_cur_length),\n+                                                     worker_id);\n+}\n+\n@@ -71,0 +96,22 @@\n+\n+void G1EvacFailureRegions::prepare_region(uint region_idx) {\n+  HeapRegion* hr = _heap->region_at(region_idx);\n+  assert(!hr->is_pinned(), \"Unexpected pinned region at index %u\", hr->hrm_index());\n+  assert(hr->in_collection_set(), \"bad CS\");\n+  assert(contains(hr->hrm_index()), \"precondition\");\n+\n+  hr->clear_index_in_opt_cset();\n+\n+  bool during_concurrent_start = _heap->collector_state()->in_concurrent_start_gc();\n+  bool during_concurrent_mark = _heap->collector_state()->mark_or_rebuild_in_progress();\n+\n+  hr->note_self_forwarding_removal_start(during_concurrent_start,\n+                                         during_concurrent_mark);\n+\n+  hr->reset_bot();\n+\n+  _phase_times->record_or_add_thread_work_item(G1GCPhaseTimes::RestoreRetainedRegions,\n+                                               0,\n+                                               1,\n+                                               G1GCPhaseTimes::RestoreRetainedRegionsNum);\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.cpp","additions":49,"deletions":2,"binary":false,"changes":51,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+class G1HeapRegionChunksClaimer;\n+class G1HeapRegionChunkClosure;\n@@ -42,0 +44,2 @@\n+  \/\/ Claims chunks in regions automatically.\n+  G1HeapRegionChunksClaimer** _chunk_claimers;\n@@ -46,0 +50,5 @@\n+  G1CollectedHeap* _heap;\n+  G1GCPhaseTimes* _phase_times;\n+\n+  \/\/ Do necessary preparation for evacuation failure regions\n+  void prepare_region(uint region_idx);\n@@ -60,0 +69,7 @@\n+  \/\/ Iterate through all chunks in regions that failed evacuation during the entire collection.\n+  void par_iterate_chunks_in_regions(G1HeapRegionChunkClosure* chunk_closure,\n+                                     uint worker_id) const;\n+\n+  uint max_regions() {\n+    return _max_regions;\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.hpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"utilities\/bitMap.inline.hpp\"\n@@ -34,0 +34,1 @@\n+\n@@ -39,0 +40,2 @@\n+    _chunk_claimers[region_idx] = new (NEW_C_HEAP_OBJ(G1HeapRegionChunksClaimer, mtGC)) G1HeapRegionChunksClaimer(region_idx);\n+    prepare_region(region_idx);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.inline.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -106,0 +106,2 @@\n+  _gc_par_phases[RemoveSelfForwardsInChunks] = new WorkerDataArray<double>(\"RemoveSelfForwardsInChunks\", \"Remove Self Forwards In Chunks (ms):\", max_gc_threads);\n+  _gc_par_phases[PrepareChunks] = new WorkerDataArray<double>(\"PrepareChunks\", \"Prepare Chunks (ms):\", max_gc_threads);\n@@ -115,0 +117,1 @@\n+  _gc_par_phases[VerifyAfterSelfForwardingPtrRemoval] = new WorkerDataArray<double>(\"VerifyAfterSelfForwardingPtrRemoval\", \"Verify Retained Regions (ms):\", max_gc_threads);\n@@ -137,0 +140,5 @@\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Forward Chunks:\", RemoveSelfForwardChunksNum);\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Empty Forward Chunks:\", RemoveSelfForwardEmptyChunksNum);\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Forward Objects:\", RemoveSelfForwardObjectsNum);\n+  _gc_par_phases[RemoveSelfForwardsInChunks]->create_thread_work_items(\"Forward Bytes:\", RemoveSelfForwardObjectsBytes);\n+\n@@ -486,0 +494,2 @@\n+    debug_phase(_gc_par_phases[PrepareChunks], 2);\n+    debug_phase(_gc_par_phases[RemoveSelfForwardsInChunks], 2);\n@@ -493,0 +503,1 @@\n+    debug_phase(_gc_par_phases[VerifyAfterSelfForwardingPtrRemoval], 1);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.cpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -81,0 +81,2 @@\n+    RemoveSelfForwardsInChunks,\n+    PrepareChunks,\n@@ -90,0 +92,1 @@\n+    VerifyAfterSelfForwardingPtrRemoval,\n@@ -151,0 +154,7 @@\n+  enum RemoveSelfForwardsInChunksWorkItems {\n+    RemoveSelfForwardChunksNum,\n+    RemoveSelfForwardEmptyChunksNum,\n+    RemoveSelfForwardObjectsNum,\n+    RemoveSelfForwardObjectsBytes,\n+  };\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1GCPhaseTimes.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,103 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n+#include \"gc\/g1\/g1ConcurrentMarkBitMap.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+\n+G1HeapRegionChunk::G1HeapRegionChunk(HeapRegion* region, uint chunk_idx, uint chunk_size, const G1CMBitMap* const bitmap) :\n+  _chunk_size(chunk_size),\n+  _region(region),\n+  _chunk_idx(chunk_idx),\n+  _bitmap(bitmap) {\n+\n+  HeapWord* top = _region->top();\n+  HeapWord* bottom = _region->bottom();\n+  _start = MIN2(top, bottom + _chunk_idx * _chunk_size);\n+  _limit = MIN2(top, bottom + (_chunk_idx + 1) * _chunk_size);\n+  _first_obj_in_chunk = _bitmap->get_next_marked_addr(_start, _limit);\n+  _next_obj_in_region = _bitmap->get_next_marked_addr(_limit, top);\n+  \/\/ There is marked obj in this chunk\n+  bool marked_obj_in_this_chunk = _start <= _first_obj_in_chunk && _first_obj_in_chunk < _limit;\n+  _include_first_obj_in_region = marked_obj_in_this_chunk\n+                                 && _bitmap->get_next_marked_addr(bottom, _limit) >= _start;\n+  _include_last_obj_in_region = marked_obj_in_this_chunk\n+                                && _bitmap->get_next_marked_addr(_limit, top) == top;\n+}\n+\n+G1HeapRegionChunksClaimer::G1HeapRegionChunksClaimer(uint region_idx, bool region_ready) :\n+  _chunk_num(G1YoungGCEvacFailureInjector::evacuation_failure_heap_region_chunk_num()),\n+  _chunk_size(static_cast<uint>(G1HeapRegionSize \/ _chunk_num)),\n+  _region_idx(region_idx),\n+  _chunks(mtGC) {\n+  _chunks.resize(_chunk_num);\n+}\n+\n+bool G1HeapRegionChunksClaimer::claim_chunk(uint chunk_idx) {\n+  return _chunks.par_set_bit(chunk_idx);\n+}\n+\n+G1ScanChunksInHeapRegionClosure::G1ScanChunksInHeapRegionClosure(G1HeapRegionChunksClaimer** chunk_claimers,\n+                                                                 G1HeapRegionChunkClosure* closure,\n+                                                                 uint worker_id) :\n+  _chunk_claimers(chunk_claimers),\n+  _closure(closure),\n+  _worker_id(worker_id),\n+  _bitmap(G1CollectedHeap::heap()->concurrent_mark()->prev_mark_bitmap()) {\n+}\n+\n+bool G1ScanChunksInHeapRegionClosure::do_heap_region(HeapRegion* r) {\n+  G1GCPhaseTimes* phase_times = G1CollectedHeap::heap()->phase_times();\n+  G1HeapRegionChunksClaimer* claimer = _chunk_claimers[r->hrm_index()];\n+\n+  uint total_workers = G1CollectedHeap::heap()->workers()->active_workers();\n+  const uint start_pos = _worker_id * claimer->chunk_num() \/ total_workers;\n+  uint chunk_idx = start_pos;\n+\n+  while (true) {\n+    if (claimer->claim_chunk(chunk_idx)) {\n+      Ticks start2 = Ticks::now();\n+      G1HeapRegionChunk chunk(r, chunk_idx, claimer->chunk_size(), _bitmap);\n+      phase_times->record_or_add_time_secs(G1GCPhaseTimes::PrepareChunks, _worker_id, (Ticks::now() - start2).seconds());\n+\n+      if (chunk.empty()) {\n+        phase_times->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, 1, G1GCPhaseTimes::RemoveSelfForwardEmptyChunksNum);\n+        continue;\n+      }\n+      phase_times->record_or_add_thread_work_item(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, 1, G1GCPhaseTimes::RemoveSelfForwardChunksNum);\n+      Ticks start = Ticks::now();\n+      _closure->do_heap_region_chunk(&chunk);\n+      phase_times->record_or_add_time_secs(G1GCPhaseTimes::RemoveSelfForwardsInChunks, _worker_id, (Ticks::now() - start).seconds());\n+    }\n+\n+    if (++chunk_idx == claimer->chunk_num()) {\n+      chunk_idx = 0;\n+    }\n+    if (chunk_idx == start_pos) break;\n+  }\n+  return false;\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.cpp","additions":103,"deletions":0,"binary":false,"changes":103,"status":"added"},{"patch":"@@ -0,0 +1,123 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n+#define SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n+\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/bitMap.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+class G1CMBitMap;\n+class HeapRegion;\n+\n+class G1HeapRegionChunk {\n+  const uint _chunk_size;\n+  HeapRegion* _region;\n+  uint _chunk_idx;\n+  const G1CMBitMap* const _bitmap;\n+\n+  \/\/ _start < _first_obj_in_chunk <= _limit <= _next_obj_in_region\n+  HeapWord * _start;\n+  HeapWord * _limit;\n+  HeapWord * _first_obj_in_chunk;\n+  HeapWord * _next_obj_in_region;\n+\n+  bool _include_first_obj_in_region;\n+  bool _include_last_obj_in_region;\n+\n+public:\n+  G1HeapRegionChunk(HeapRegion* region, uint chunk_idx, uint chunk_size, const G1CMBitMap* const bitmap);\n+\n+  \/\/ All objects that failed evacuation has been marked in the prev bitmap.\n+  \/\/ Use the bitmap to apply the above closure to all failing objects.\n+  template<typename ApplyToMarkedClosure>\n+  void apply_to_marked_objects(ApplyToMarkedClosure* closure);\n+\n+  HeapRegion* heap_region() const {\n+    return _region;\n+  }\n+\n+  HeapWord* first_obj_in_chunk() const {\n+    return _first_obj_in_chunk;\n+  }\n+\n+  HeapWord* next_obj_in_region() const {\n+    return _next_obj_in_region;\n+  }\n+\n+  bool empty() const {\n+    return _first_obj_in_chunk >= _limit;\n+  }\n+\n+  bool include_first_obj_in_region() const {\n+    return _include_first_obj_in_region;\n+  }\n+\n+  bool include_last_obj_in_region() const {\n+    return _include_last_obj_in_region;\n+  }\n+};\n+\n+class G1HeapRegionChunkClosure {\n+public:\n+  \/\/ Typically called on each region until it returns true.\n+  virtual void do_heap_region_chunk(G1HeapRegionChunk* c) = 0;\n+};\n+\n+class G1HeapRegionChunksClaimer {\n+  const uint _chunk_num;\n+  const uint _chunk_size;\n+  const uint _region_idx;\n+  CHeapBitMap _chunks;\n+\n+public:\n+  G1HeapRegionChunksClaimer(uint region_idx, bool region_ready = false);\n+\n+  bool claim_chunk(uint chunk_idx);\n+\n+  uint chunk_size() {\n+    return _chunk_size;\n+  }\n+  uint chunk_num() {\n+    return _chunk_num;\n+  }\n+};\n+\n+\/\/ Iterate through chunks of regions, for each region do single preparation.\n+class G1ScanChunksInHeapRegionClosure : public HeapRegionClosure {\n+  G1HeapRegionChunksClaimer** _chunk_claimers;\n+  G1HeapRegionChunkClosure* _closure;\n+  uint _worker_id;\n+  const G1CMBitMap* const _bitmap;\n+\n+public:\n+  G1ScanChunksInHeapRegionClosure(G1HeapRegionChunksClaimer** chunk_claimers,\n+                                  G1HeapRegionChunkClosure* closure,\n+                                  uint worker_id);\n+\n+  bool do_heap_region(HeapRegion* r) override;\n+};\n+\n+#endif \/\/SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.hpp","additions":123,"deletions":0,"binary":false,"changes":123,"status":"added"},{"patch":"@@ -0,0 +1,52 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n+#define SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n+\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n+#include \"gc\/shared\/markBitMap.inline.hpp\"\n+#include \"runtime\/prefetch.hpp\"\n+\n+template<typename ApplyToMarkedClosure>\n+inline void G1HeapRegionChunk::apply_to_marked_objects(ApplyToMarkedClosure* closure) {\n+  HeapWord* next_addr = _first_obj_in_chunk;\n+\n+  while (next_addr < _limit) {\n+    Prefetch::write(next_addr, PrefetchScanIntervalInBytes);\n+    \/\/ This explicit is_marked check is a way to avoid\n+    \/\/ some extra work done by get_next_marked_addr for\n+    \/\/ the case where next_addr is marked.\n+    if (_bitmap->is_marked(next_addr)) {\n+      oop current = cast_to_oop(next_addr);\n+      next_addr += closure->apply(current);\n+    } else {\n+      next_addr = _bitmap->get_next_marked_addr(next_addr, _limit);\n+    }\n+  }\n+\n+  \/\/ assert(next_addr == _limit, \"Should stop the scan at the limit.\");\n+}\n+\n+#endif \/\/SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.inline.hpp","additions":52,"deletions":0,"binary":false,"changes":52,"status":"added"},{"patch":"@@ -110,0 +110,8 @@\n+uint G1YoungGCEvacFailureInjector::evacuation_failure_worker_cost() {\n+  return G1EvacuationFailureALotWorkerCost;\n+}\n+\n+uint G1YoungGCEvacFailureInjector::evacuation_failure_heap_region_chunk_num() {\n+  return G1EvacuationFailureHeapRegionChunkNum;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCEvacFailureInjector.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -83,0 +83,4 @@\n+\n+  static uint evacuation_failure_worker_cost() EVAC_FAILURE_INJECTOR_RETURN_( return 2; );\n+\n+  static uint evacuation_failure_heap_region_chunk_num() EVAC_FAILURE_INJECTOR_RETURN_( return 256; );\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCEvacFailureInjector.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -70,0 +70,2 @@\n+  G1EvacFailureRegions* _evac_failure_regions;\n+\n@@ -71,1 +73,3 @@\n-  SampleCollectionSetCandidatesTask() : G1AbstractSubTask(G1GCPhaseTimes::SampleCollectionSetCandidates) { }\n+  SampleCollectionSetCandidatesTask(G1EvacFailureRegions* evac_failure_regions) :\n+    G1AbstractSubTask(G1GCPhaseTimes::SampleCollectionSetCandidates),\n+    _evac_failure_regions(evac_failure_regions) { }\n@@ -84,0 +88,1 @@\n+      G1EvacFailureRegions* _evac_failure_regions;\n@@ -87,2 +92,13 @@\n-      bool do_heap_region(HeapRegion* r) override {\n-        _total.add(r->rem_set()->card_set_memory_stats());\n+      G1SampleCollectionSetCandidatesClosure(G1EvacFailureRegions* evac_failure_regions) :\n+        _evac_failure_regions(evac_failure_regions) { }\n+\n+      bool do_heap_region(HeapRegion* hr) override {\n+        _total.add(hr->rem_set()->card_set_memory_stats());\n+\n+        \/\/ Put the clearing code here on purpose to make sure the rem set data\n+        \/\/ is cleared only after syncing.\n+        \/\/ It also avoid race condition by putting the clearing code here.\n+        if (_evac_failure_regions->contains(hr->hrm_index())) {\n+          hr->rem_set()->clean_strong_code_roots(hr);\n+          hr->rem_set()->clear_locked(true);\n+        }\n@@ -91,1 +107,1 @@\n-    } cl;\n+    } cl(_evac_failure_regions);\n@@ -112,1 +128,1 @@\n-    return _evac_failure_regions->num_regions_failed_evacuation();\n+    return _evac_failure_regions->num_regions_failed_evacuation() * G1YoungGCEvacFailureInjector::evacuation_failure_worker_cost();\n@@ -129,1 +145,1 @@\n-    add_serial_task(new SampleCollectionSetCandidatesTask());\n+    add_serial_task(new SampleCollectionSetCandidatesTask(evac_failure_regions));\n@@ -360,0 +376,34 @@\n+class G1PostEvacuateCollectionSetCleanupTask2::VerifyAfterSelfForwardingPtrRemovalTask : public G1AbstractSubTask {\n+  G1EvacFailureRegions* _evac_failure_regions;\n+  HeapRegionClaimer _claimer;\n+\n+  class VerifyRegionClosure : public HeapRegionClosure {\n+  public:\n+    bool do_heap_region(HeapRegion* hr) override {\n+      G1CollectedHeap::heap()->verifier()->check_bitmaps(\"Self-Forwarding Ptr Removal\", hr);\n+      return false;\n+    }\n+  };\n+\n+public:\n+  VerifyAfterSelfForwardingPtrRemovalTask(G1EvacFailureRegions* evac_failure_regions) :\n+    G1AbstractSubTask(G1GCPhaseTimes::VerifyAfterSelfForwardingPtrRemoval),\n+    _evac_failure_regions(evac_failure_regions),\n+    _claimer(0) {\n+    assert(G1VerifyBitmaps && _evac_failure_regions->evacuation_failed(), \"precondition\");\n+  }\n+\n+  void set_max_workers(uint max_workers) override {\n+    _claimer.set_n_workers(max_workers);\n+  }\n+\n+  double worker_cost() const override {\n+    return _evac_failure_regions->num_regions_failed_evacuation();\n+  }\n+\n+  void do_work(uint worker_id) override {\n+    VerifyRegionClosure closure;\n+    _evac_failure_regions->par_iterate(&closure, &_claimer, worker_id);\n+  }\n+};\n+\n@@ -682,0 +732,3 @@\n+    if (G1VerifyBitmaps) {\n+      add_parallel_task(new VerifyAfterSelfForwardingPtrRemovalTask(evac_failure_regions));\n+    }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":59,"deletions":6,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+  class VerifyAfterSelfForwardingPtrRemovalTask;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -82,1 +82,10 @@\n-          range(1, 100)\n+          range(1, 100)                                                     \\\n+  product(uint, G1EvacuationFailureALotWorkerCost, 2,                       \\\n+          \"The percentage of regions in the collection set starting \"       \\\n+          \"from the beginning where the forced evacuation failure \"         \\\n+          \"injection will be applied.\")                                     \\\n+          range(1, 16)                                                      \\\n+  product(uint, G1EvacuationFailureHeapRegionChunkNum, 256,                 \\\n+          \"Chunks num per G1 region when process evacuation failure \"       \\\n+          \"regions in parallel.\")                                           \\\n+          range(1, 1024)\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -282,0 +282,1 @@\n+  _prev_top_at_mark_start = top();\n@@ -298,5 +299,2 @@\n-void HeapRegion::note_self_forwarding_removal_end(size_t marked_bytes) {\n-  assert(marked_bytes <= used(),\n-         \"marked: \" SIZE_FORMAT \" used: \" SIZE_FORMAT, marked_bytes, used());\n-  _prev_top_at_mark_start = top();\n-  _prev_marked_bytes = marked_bytes;\n+void HeapRegion::note_self_forwarding_removal_end_par(size_t marked_bytes) {\n+  Atomic::add(&_prev_marked_bytes, marked_bytes, memory_order_relaxed);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":3,"deletions":5,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -166,1 +166,1 @@\n-  inline void update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size);\n+  inline void update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size, bool assert_old = false);\n@@ -513,3 +513,3 @@\n-  \/\/ Notify the region that we have finished processing self-forwarded\n-  \/\/ objects during evac failure handling.\n-  void note_self_forwarding_removal_end(size_t marked_bytes);\n+  \/\/ Notify the region that we have partially finished processing self-forwarded\n+  \/\/ objects during evacuation failure handling.\n+  void note_self_forwarding_removal_end_par(size_t marked_bytes);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-inline void HeapRegion::update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size) {\n-  assert(is_old(), \"should only do BOT updates for old regions\");\n+inline void HeapRegion::update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size, bool assert_old) {\n+  assert(!assert_old || is_old(), \"should only do BOT updates for old regions\");\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -63,0 +63,15 @@\n+void MarkBitMap::do_par_clear(MemRegion mr, bool large) {\n+  MemRegion intersection = mr.intersection(_covered);\n+  assert(!intersection.is_empty(),\n+         \"Given range from \" PTR_FORMAT \" to \" PTR_FORMAT \" is completely outside the heap\",\n+         p2i(mr.start()), p2i(mr.end()));\n+  \/\/ convert address range into offset range\n+  size_t beg = addr_to_offset(intersection.start());\n+  size_t end = addr_to_offset(intersection.end());\n+  if (large) {\n+    _bm.par_clear_range(beg, end, BitMap::large_range);\n+  } else {\n+    _bm.par_clear_range(beg, end, BitMap::small_range);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+  void do_par_clear(MemRegion mr, bool large);\n@@ -100,0 +101,3 @@\n+\n+  void par_clear_range(MemRegion mr)   { do_par_clear(mr, false); }\n+  void par_clear_range_large(MemRegion mr) { do_par_clear(mr, true); }\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}