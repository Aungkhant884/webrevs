{"files":[{"patch":"@@ -32,0 +32,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.inline.hpp\"\n@@ -45,0 +46,1 @@\n+  G1HeapRegionChunk* _chunk;\n@@ -52,0 +54,1 @@\n+                                 G1HeapRegionChunk* chunk,\n@@ -57,0 +60,1 @@\n+    _chunk(chunk),\n@@ -59,2 +63,4 @@\n-    _worker_id(worker_id),\n-    _last_forwarded_object_end(hr->bottom()) { }\n+    _worker_id(worker_id) {\n+    _last_forwarded_object_end = _chunk->include_first_obj_in_region() ?\n+                                 _hr->bottom() : _chunk->first_obj_in_chunk();\n+  }\n@@ -102,1 +108,1 @@\n-    _hr->alloc_block_in_bot(obj_addr, obj_end);\n+    _hr->update_bot_if_crossing_boundary(obj_addr, obj_size, false);\n@@ -118,0 +124,1 @@\n+      size_t dummy_size = cast_to_oop(start)->size();\n@@ -119,1 +126,1 @@\n-      _hr->alloc_block_in_bot(start, end_first_obj);\n+      _hr->update_bot_if_crossing_boundary(start, dummy_size, false);\n@@ -125,1 +132,1 @@\n-        _hr->alloc_block_in_bot(end_first_obj, end);\n+        _hr->update_bot_if_crossing_boundary(end_first_obj, cast_to_oop(end_first_obj)->size(), false);\n@@ -140,1 +147,38 @@\n-    zap_dead_objects(_last_forwarded_object_end, _hr->top());\n+    zap_dead_objects(_last_forwarded_object_end, _chunk->next_obj_in_region());\n+    if (_chunk->include_last_obj_in_region()) {\n+      \/\/ As we have process the self forwardee in parallel,\n+      \/\/ it's necessary to update the bot threshold explicitly.\n+      _hr->update_bot_threshold();\n+    }\n+  }\n+};\n+\n+class RemoveSelfForwardPtrHRChunkClosure : public G1HeapRegionChunkClosure {\n+  G1CollectedHeap* _g1h;\n+  uint _worker_id;\n+\n+  void remove_self_forward_ptr_by_walking_chunk(G1HeapRegionChunk* chunk,\n+                                                bool during_concurrent_start) {\n+    RemoveSelfForwardPtrObjClosure rspc(chunk->heap_region(),\n+                                        chunk,\n+                                        during_concurrent_start,\n+                                        _worker_id);\n+\n+    \/\/ All objects that failed evacuation has been marked in the prev bitmap.\n+    \/\/ Use the bitmap to apply the above closure to all failing objects.\n+    chunk->apply_to_marked_objects(&rspc);\n+    \/\/ Need to zap the remainder area of the processed region.\n+    if (!chunk->empty()) {\n+      rspc.zap_remainder();\n+    }\n+  }\n+\n+public:\n+  RemoveSelfForwardPtrHRChunkClosure(uint worker_id) :\n+    _g1h(G1CollectedHeap::heap()),\n+    _worker_id(worker_id) {\n+  }\n+\n+  void do_heap_region_chunk(G1HeapRegionChunk* chunk) override {\n+    bool during_concurrent_start = _g1h->collector_state()->in_concurrent_start_gc();\n+    remove_self_forward_ptr_by_walking_chunk(chunk, during_concurrent_start);\n@@ -161,16 +205,0 @@\n-  size_t remove_self_forward_ptr_by_walking_hr(HeapRegion* hr,\n-                                               bool during_concurrent_start) {\n-    RemoveSelfForwardPtrObjClosure rspc(hr,\n-                                        during_concurrent_start,\n-                                        _worker_id);\n-\n-    \/\/ All objects that failed evacuation has been marked in the prev bitmap.\n-    \/\/ Use the bitmap to apply the above closure to all failing objects.\n-    G1CMBitMap* bitmap = const_cast<G1CMBitMap*>(_g1h->concurrent_mark()->prev_mark_bitmap());\n-    hr->apply_to_marked_objects(bitmap, &rspc);\n-    \/\/ Need to zap the remainder area of the processed region.\n-    rspc.zap_remainder();\n-\n-    return rspc.marked_bytes();\n-  }\n-\n@@ -197,1 +225,1 @@\n-    size_t live_bytes = remove_self_forward_ptr_by_walking_hr(hr, during_concurrent_start);\n+    size_t live_bytes = _evac_failure_regions->live_bytes_in_region(hr->hrm_index());\n@@ -216,4 +244,4 @@\n-  RemoveSelfForwardPtrHRClosure rsfp_cl(worker_id, _evac_failure_regions);\n-\n-  \/\/ Iterate through all regions that failed evacuation during the entire collection.\n-  _evac_failure_regions->par_iterate(&rsfp_cl, &_hrclaimer, worker_id);\n+  RemoveSelfForwardPtrHRClosure prepare_region_closure(worker_id, _evac_failure_regions);\n+  RemoveSelfForwardPtrHRChunkClosure chunk_closure(worker_id);\n+  \/\/ Iterate through all chunks in regions that failed evacuation during the entire collection.\n+  _evac_failure_regions->par_iterate_chunks_in_regions(&prepare_region_closure, &chunk_closure, worker_id);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailure.cpp","additions":55,"deletions":27,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"gc\/g1\/g1CollectedHeap.hpp\"\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n@@ -36,0 +37,1 @@\n+  _chunk_claimers(nullptr),\n@@ -37,1 +39,6 @@\n-  _max_regions(0) { }\n+  _max_regions(0) {\n+  _live_stats = NEW_C_HEAP_ARRAY(G1RegionMarkStats, G1CollectedHeap::heap()->max_regions(), mtGC);\n+  for (uint j = 0; j < G1CollectedHeap::heap()->max_regions(); j++) {\n+    _live_stats[j].clear();\n+  }\n+}\n@@ -41,0 +48,3 @@\n+  assert(_chunk_claimers == nullptr, \"not cleaned up\");\n+  FREE_C_HEAP_ARRAY(uint, _live_stats);\n+  _live_stats = nullptr;\n@@ -48,0 +58,1 @@\n+  _chunk_claimers = NEW_C_HEAP_ARRAY(G1HeapRegionChunksClaimer*, _max_regions, mtGC);\n@@ -52,0 +63,7 @@\n+\n+  for (uint i = 0; i < _evac_failure_regions_cur_length; i++) {\n+    FREE_C_HEAP_OBJ(_chunk_claimers[_evac_failure_regions[i]]);\n+  }\n+  FREE_C_HEAP_ARRAY(uint, _chunk_claimers);\n+  _chunk_claimers = nullptr;\n+\n@@ -67,0 +85,12 @@\n+void G1EvacFailureRegions::par_iterate_chunks_in_regions(HeapRegionClosure* prepare_region_closure,\n+                                                         G1HeapRegionChunkClosure* chunk_closure,\n+                                                         uint worker_id) const {\n+  G1ScanChunksInHeapRegionClosure closure(_chunk_claimers, prepare_region_closure, chunk_closure, worker_id);\n+\n+  G1CollectedHeap::heap()->par_iterate_regions_array(&closure,\n+                                                     nullptr, \/\/ pass null, so every worker thread go through every region.\n+                                                     _evac_failure_regions,\n+                                                     Atomic::load(&_evac_failure_regions_cur_length),\n+                                                     worker_id);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.cpp","additions":32,"deletions":2,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -31,0 +31,2 @@\n+class G1HeapRegionChunksClaimer;\n+class G1HeapRegionChunkClosure;\n@@ -42,0 +44,2 @@\n+  \/\/ Claims chunks in regions automatically.\n+  G1HeapRegionChunksClaimer** _chunk_claimers;\n@@ -47,0 +51,3 @@\n+  \/\/ Live bytes in evacuation failed regions\n+  G1RegionMarkStats* _live_stats;\n+\n@@ -60,0 +67,4 @@\n+  \/\/ Iterate through all chunks in regions that failed evacuation during the entire collection.\n+  void par_iterate_chunks_in_regions(HeapRegionClosure* prepare_region_closure,\n+                                     G1HeapRegionChunkClosure* chunk_closure,\n+                                     uint worker_id) const;\n@@ -65,0 +76,8 @@\n+  size_t live_bytes_in_region(uint region_idx) const {\n+    return _live_stats[region_idx]._live_words * BytesPerWord;\n+  }\n+\n+  G1RegionMarkStats* live_stats() const {\n+    return _live_stats;\n+  }\n+\n@@ -72,1 +91,1 @@\n-  inline bool record(uint region_idx);\n+  inline bool record(uint region_idx, size_t word_sz, G1RegionMarkStatsCache* _mark_stats_cache);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.hpp","additions":20,"deletions":1,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n@@ -30,1 +31,0 @@\n-#include \"utilities\/bitMap.inline.hpp\"\n@@ -32,1 +32,1 @@\n-bool G1EvacFailureRegions::record(uint region_idx) {\n+bool G1EvacFailureRegions::record(uint region_idx, size_t word_sz, G1RegionMarkStatsCache* mark_stats_cache) {\n@@ -34,0 +34,2 @@\n+  mark_stats_cache->add_live_words(region_idx, word_sz);\n+\n@@ -39,0 +41,1 @@\n+    _chunk_claimers[region_idx] = new (NEW_C_HEAP_OBJ(G1HeapRegionChunksClaimer, mtGC)) G1HeapRegionChunksClaimer(region_idx);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1EvacFailureRegions.inline.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -0,0 +1,108 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1CollectedHeap.inline.hpp\"\n+#include \"gc\/g1\/g1ConcurrentMarkBitMap.inline.hpp\"\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n+#include \"gc\/g1\/heapRegion.hpp\"\n+\n+G1HeapRegionChunk::G1HeapRegionChunk(HeapRegion* region, uint chunk_idx, uint chunk_size, const G1CMBitMap* const bitmap) :\n+  _chunk_size(chunk_size),\n+  _region(region),\n+  _chunk_idx(chunk_idx),\n+  _bitmap(bitmap) {\n+\n+  HeapWord* top = _region->top();\n+  HeapWord* bottom = _region->bottom();\n+  _start = MIN2(top, bottom + _chunk_idx * _chunk_size);\n+  _limit = MIN2(top, bottom + (_chunk_idx + 1) * _chunk_size);\n+  _first_obj_in_chunk = _bitmap->get_next_marked_addr(_start, _limit);\n+  _next_obj_in_region = _bitmap->get_next_marked_addr(_limit, top);\n+  \/\/ There is marked obj in this chunk\n+  bool marked_obj_in_this_chunk = _start <= _first_obj_in_chunk && _first_obj_in_chunk < _limit;\n+  _include_first_obj_in_region = marked_obj_in_this_chunk\n+                                 && _bitmap->get_next_marked_addr(bottom, _limit) >= _start;\n+  _include_last_obj_in_region = marked_obj_in_this_chunk\n+                                && _bitmap->get_next_marked_addr(_limit, top) == top;\n+}\n+\n+G1HeapRegionChunksClaimer::G1HeapRegionChunksClaimer(uint region_idx, bool region_ready) :\n+  _chunk_num(G1YoungGCEvacFailureInjector::evacuation_failure_heap_region_chunk_num()),\n+  _chunk_size(static_cast<uint>(G1HeapRegionSize \/ _chunk_num)),\n+  _region_idx(region_idx),\n+  _region_claimed(false),\n+  _region_ready(region_ready),\n+  _chunks(mtGC) {\n+  _chunks.resize(_chunk_num);\n+}\n+\n+bool G1HeapRegionChunksClaimer::claim_chunk(uint chunk_idx) {\n+  return _chunks.par_set_bit(chunk_idx);\n+}\n+\n+void G1HeapRegionChunksClaimer::prepare_region(HeapRegionClosure* prepare_region_closure) {\n+  if (claim_prepare_region()) {\n+    prepare_region_closure->do_heap_region(G1CollectedHeap::heap()->region_at(_region_idx));\n+    set_region_ready();\n+    return;\n+  }\n+  while (!region_ready());\n+}\n+\n+G1ScanChunksInHeapRegionClosure::G1ScanChunksInHeapRegionClosure(G1HeapRegionChunksClaimer** chunk_claimers,\n+                                                                 HeapRegionClosure* prepare_region_closure,\n+                                                                 G1HeapRegionChunkClosure* closure,\n+                                                                 uint worker_id) :\n+  _chunk_claimers(chunk_claimers),\n+  _prepare_region_closure(prepare_region_closure),\n+  _closure(closure),\n+  _worker_id(worker_id),\n+  _bitmap(G1CollectedHeap::heap()->concurrent_mark()->prev_mark_bitmap()) {\n+}\n+\n+bool G1ScanChunksInHeapRegionClosure::do_heap_region(HeapRegion* r) {\n+  G1HeapRegionChunksClaimer* claimer = _chunk_claimers[r->hrm_index()];\n+  claimer->prepare_region(_prepare_region_closure);\n+\n+  uint total_workers = G1CollectedHeap::heap()->workers()->active_workers();\n+  const uint start_pos = _worker_id * claimer->chunk_num() \/ total_workers;\n+  uint chunk_idx = start_pos;\n+  while (true) {\n+    if (claimer->claim_chunk(chunk_idx)) {\n+      G1HeapRegionChunk chunk(r, chunk_idx, claimer->chunk_size(), _bitmap);\n+      if (chunk.empty()) {\n+        continue;\n+      }\n+      _closure->do_heap_region_chunk(&chunk);\n+    }\n+\n+    if (++chunk_idx == claimer->chunk_num()) {\n+      chunk_idx = 0;\n+    }\n+    if (chunk_idx == start_pos) break;\n+  }\n+  return false;\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.cpp","additions":108,"deletions":0,"binary":false,"changes":108,"status":"added"},{"patch":"@@ -0,0 +1,140 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n+#define SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n+\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/bitMap.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+\n+class G1CMBitMap;\n+class HeapRegion;\n+\n+class G1HeapRegionChunk {\n+  const uint _chunk_size;\n+  HeapRegion* _region;\n+  uint _chunk_idx;\n+  const G1CMBitMap* const _bitmap;\n+\n+  \/\/ _start < _first_obj_in_chunk <= _limit <= _next_obj_in_region\n+  HeapWord * _start;\n+  HeapWord * _limit;\n+  HeapWord * _first_obj_in_chunk;\n+  HeapWord * _next_obj_in_region;\n+\n+  bool _include_first_obj_in_region;\n+  bool _include_last_obj_in_region;\n+\n+public:\n+  G1HeapRegionChunk(HeapRegion* region, uint chunk_idx, uint chunk_size, const G1CMBitMap* const bitmap);\n+\n+  \/\/ All objects that failed evacuation has been marked in the prev bitmap.\n+  \/\/ Use the bitmap to apply the above closure to all failing objects.\n+  template<typename ApplyToMarkedClosure>\n+  void apply_to_marked_objects(ApplyToMarkedClosure* closure);\n+\n+  HeapRegion* heap_region() const {\n+    return _region;\n+  }\n+\n+  HeapWord* first_obj_in_chunk() const {\n+    return _first_obj_in_chunk;\n+  }\n+\n+  HeapWord* next_obj_in_region() const {\n+    return _next_obj_in_region;\n+  }\n+\n+  bool empty() const {\n+    return _first_obj_in_chunk >= _limit;\n+  }\n+\n+  bool include_first_obj_in_region() const {\n+    return _include_first_obj_in_region;\n+  }\n+\n+  bool include_last_obj_in_region() const {\n+    return _include_last_obj_in_region;\n+  }\n+};\n+\n+class G1HeapRegionChunkClosure {\n+public:\n+  \/\/ Typically called on each region until it returns true.\n+  virtual void do_heap_region_chunk(G1HeapRegionChunk* c) = 0;\n+};\n+\n+class G1HeapRegionChunksClaimer {\n+  const uint _chunk_num;\n+  const uint _chunk_size;\n+  const uint _region_idx;\n+  volatile bool _region_claimed;\n+  volatile bool _region_ready;\n+  CHeapBitMap _chunks;\n+\n+  bool claim_prepare_region() {\n+    return !Atomic::cmpxchg(&_region_claimed, false, true);\n+  }\n+  bool region_ready() {\n+    return Atomic::load(&_region_ready);\n+  }\n+  void set_region_ready() {\n+    Atomic::store(&_region_ready, true);\n+  }\n+\n+public:\n+  G1HeapRegionChunksClaimer(uint region_idx, bool region_ready = false);\n+\n+  bool claim_chunk(uint chunk_idx);\n+\n+  uint chunk_size() {\n+    return _chunk_size;\n+  }\n+  uint chunk_num() {\n+    return _chunk_num;\n+  }\n+\n+  void prepare_region(HeapRegionClosure* prepare_region_closure);\n+};\n+\n+\/\/ Iterate through chunks of regions, for each region do single preparation.\n+class G1ScanChunksInHeapRegionClosure : public HeapRegionClosure {\n+  G1HeapRegionChunksClaimer** _chunk_claimers;\n+  \/\/ Preparation closure for a single region.\n+  HeapRegionClosure* _prepare_region_closure;\n+  G1HeapRegionChunkClosure* _closure;\n+  uint _worker_id;\n+  const G1CMBitMap* const _bitmap;\n+\n+public:\n+  G1ScanChunksInHeapRegionClosure(G1HeapRegionChunksClaimer** chunk_claimers,\n+                                  HeapRegionClosure* prepare_region_closure,\n+                                  G1HeapRegionChunkClosure* closure,\n+                                  uint worker_id);\n+\n+  bool do_heap_region(HeapRegion* r) override;\n+};\n+\n+#endif \/\/SHARE_GC_G1_G1HEAPREGIONCHUNK_HPP\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.hpp","additions":140,"deletions":0,"binary":false,"changes":140,"status":"added"},{"patch":"@@ -0,0 +1,52 @@\n+\/*\n+ * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n+#define SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n+\n+#include \"gc\/g1\/g1HeapRegionChunk.hpp\"\n+#include \"gc\/shared\/markBitMap.inline.hpp\"\n+#include \"runtime\/prefetch.hpp\"\n+\n+template<typename ApplyToMarkedClosure>\n+inline void G1HeapRegionChunk::apply_to_marked_objects(ApplyToMarkedClosure* closure) {\n+  HeapWord* next_addr = _first_obj_in_chunk;\n+\n+  while (next_addr < _limit) {\n+    Prefetch::write(next_addr, PrefetchScanIntervalInBytes);\n+    \/\/ This explicit is_marked check is a way to avoid\n+    \/\/ some extra work done by get_next_marked_addr for\n+    \/\/ the case where next_addr is marked.\n+    if (_bitmap->is_marked(next_addr)) {\n+      oop current = cast_to_oop(next_addr);\n+      next_addr += closure->apply(current);\n+    } else {\n+      next_addr = _bitmap->get_next_marked_addr(next_addr, _limit);\n+    }\n+  }\n+\n+  \/\/ assert(next_addr == _limit, \"Should stop the scan at the limit.\");\n+}\n+\n+#endif \/\/SHARE_GC_G1_G1HEAPREGIONCHUNK_INLINE_HPP\n\\ No newline at end of file\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeapRegionChunk.inline.hpp","additions":52,"deletions":0,"binary":false,"changes":52,"status":"added"},{"patch":"@@ -63,1 +63,2 @@\n-                                           G1EvacFailureRegions* evac_failure_regions)\n+                                           G1EvacFailureRegions* evac_failure_regions,\n+                                           G1RegionMarkStats* evac_failure_mark_stats)\n@@ -91,1 +92,2 @@\n-    _evac_failure_regions(evac_failure_regions)\n+    _evac_failure_regions(evac_failure_regions),\n+    _evac_failure_mark_stats_cache(evac_failure_mark_stats, G1RegionMarkStatsCache::RegionMarkStatsCacheSize)\n@@ -114,0 +116,1 @@\n+  flush_evac_failure_mark_stats_cache();\n@@ -569,1 +572,2 @@\n-                               _evac_failure_regions);\n+                               _evac_failure_regions,\n+                               _evac_failure_live_stats);\n@@ -604,0 +608,9 @@\n+void G1ParScanThreadStateSet::flush_evac_failure_live_data() {\n+  assert(!_flushed, \"thread local state from the per thread states should be flushed once\");\n+\n+  for (uint worker_id = 0; worker_id < _n_workers; ++worker_id) {\n+    G1ParScanThreadState* pss = _states[worker_id];\n+    pss->flush_evac_failure_mark_stats_cache();\n+  }\n+}\n+\n@@ -628,1 +641,1 @@\n-    if (_evac_failure_regions->record(r->hrm_index())) {\n+    if (_evac_failure_regions->record(r->hrm_index(), word_sz, &_evac_failure_mark_stats_cache)) {\n@@ -700,1 +713,2 @@\n-    _evac_failure_regions(evac_failure_regions) {\n+    _evac_failure_regions(evac_failure_regions),\n+    _evac_failure_live_stats(_evac_failure_regions->live_stats()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":19,"deletions":5,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -109,0 +109,1 @@\n+  G1RegionMarkStatsCache _evac_failure_mark_stats_cache;\n@@ -120,1 +121,2 @@\n-                       G1EvacFailureRegions* evac_failure_regions);\n+                       G1EvacFailureRegions* evac_failure_regions,\n+                       G1RegionMarkStats* evac_failure_mark_stats);\n@@ -157,0 +159,2 @@\n+  void flush_evac_failure_mark_stats_cache() { _evac_failure_mark_stats_cache.evict_all(); }\n+\n@@ -241,0 +245,2 @@\n+  \/\/ Records the liveness of regions which failed evacuation.\n+  G1RegionMarkStats* _evac_failure_live_stats;\n@@ -256,0 +262,1 @@\n+  void flush_evac_failure_live_data();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -110,0 +110,8 @@\n+uint G1YoungGCEvacFailureInjector::evacuation_failure_worker_cost() {\n+  return G1EvacuationFailureALotWorkerCost;\n+}\n+\n+uint G1YoungGCEvacFailureInjector::evacuation_failure_heap_region_chunk_num() {\n+  return G1EvacuationFailureHeapRegionChunkNum;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCEvacFailureInjector.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -83,0 +83,4 @@\n+\n+  static uint evacuation_failure_worker_cost() EVAC_FAILURE_INJECTOR_RETURN_( return 2; );\n+\n+  static uint evacuation_failure_heap_region_chunk_num() EVAC_FAILURE_INJECTOR_RETURN_( return 256; );\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCEvacFailureInjector.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -112,1 +112,1 @@\n-    return _evac_failure_regions->num_regions_failed_evacuation();\n+    return _evac_failure_regions->num_regions_failed_evacuation() * G1YoungGCEvacFailureInjector::evacuation_failure_worker_cost();\n@@ -125,0 +125,3 @@\n+  if (evacuation_failed) {\n+    per_thread_states->flush_evac_failure_live_data();\n+  }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1YoungGCPostEvacuateTasks.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -82,1 +82,10 @@\n-          range(1, 100)\n+          range(1, 100)                                                     \\\n+  product(uint, G1EvacuationFailureALotWorkerCost, 2,                       \\\n+          \"The percentage of regions in the collection set starting \"       \\\n+          \"from the beginning where the forced evacuation failure \"         \\\n+          \"injection will be applied.\")                                     \\\n+          range(1, 16)                                                      \\\n+  product(uint, G1EvacuationFailureHeapRegionChunkNum, 256,                 \\\n+          \"Chunks num per G1 region when process evacuation failure \"       \\\n+          \"regions in parallel.\")                                           \\\n+          range(1, 1024)\n","filename":"src\/hotspot\/share\/gc\/g1\/g1_globals.hpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -166,1 +166,1 @@\n-  inline void update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size);\n+  inline void update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size, bool assert_old = false);\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -234,2 +234,2 @@\n-inline void HeapRegion::update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size) {\n-  assert(is_old(), \"should only do BOT updates for old regions\");\n+inline void HeapRegion::update_bot_if_crossing_boundary(HeapWord* obj_start, size_t obj_size, bool assert_old) {\n+  assert(!assert_old || is_old(), \"should only do BOT updates for old regions\");\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -63,0 +63,15 @@\n+void MarkBitMap::do_par_clear(MemRegion mr, bool large) {\n+  MemRegion intersection = mr.intersection(_covered);\n+  assert(!intersection.is_empty(),\n+         \"Given range from \" PTR_FORMAT \" to \" PTR_FORMAT \" is completely outside the heap\",\n+         p2i(mr.start()), p2i(mr.end()));\n+  \/\/ convert address range into offset range\n+  size_t beg = addr_to_offset(intersection.start());\n+  size_t end = addr_to_offset(intersection.end());\n+  if (large) {\n+    _bm.par_clear_range(beg, end, BitMap::large_range);\n+  } else {\n+    _bm.par_clear_range(beg, end, BitMap::small_range);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+  void do_par_clear(MemRegion mr, bool large);\n@@ -100,0 +101,3 @@\n+\n+  void par_clear_range(MemRegion mr)   { do_par_clear(mr, false); }\n+  void par_clear_range_large(MemRegion mr) { do_par_clear(mr, true); }\n","filename":"src\/hotspot\/share\/gc\/shared\/markBitMap.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"}]}