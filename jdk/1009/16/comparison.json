{"files":[{"patch":"@@ -38,2 +38,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahMarkCompact.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -41,0 +40,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -45,0 +45,1 @@\n+#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n@@ -54,59 +55,0 @@\n-template<UpdateRefsMode UPDATE_REFS>\n-class ShenandoahInitMarkRootsClosure : public OopClosure {\n-private:\n-  ShenandoahObjToScanQueue* _queue;\n-  ShenandoahHeap* _heap;\n-  ShenandoahMarkingContext* const _mark_context;\n-\n-  template <class T>\n-  inline void do_oop_work(T* p) {\n-    ShenandoahConcurrentMark::mark_through_ref<T, UPDATE_REFS, NO_DEDUP>(p, _heap, _queue, _mark_context, false);\n-  }\n-\n-public:\n-  ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q) :\n-    _queue(q),\n-    _heap(ShenandoahHeap::heap()),\n-    _mark_context(_heap->marking_context()) {};\n-\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-};\n-\n-ShenandoahMarkRefsSuperClosure::ShenandoahMarkRefsSuperClosure(ShenandoahObjToScanQueue* q, ShenandoahReferenceProcessor* rp) :\n-  MetadataVisitingOopIterateClosure(rp),\n-  _queue(q),\n-  _heap(ShenandoahHeap::heap()),\n-  _mark_context(_heap->marking_context()),\n-  _weak(false)\n-{ }\n-\n-template<UpdateRefsMode UPDATE_REFS>\n-class ShenandoahInitMarkRootsTask : public AbstractGangTask {\n-private:\n-  ShenandoahRootScanner* _rp;\n-public:\n-  ShenandoahInitMarkRootsTask(ShenandoahRootScanner* rp) :\n-    AbstractGangTask(\"Shenandoah Init Mark Roots\"),\n-    _rp(rp) {\n-  }\n-\n-  void work(uint worker_id) {\n-    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n-    ShenandoahParallelWorkerSession worker_session(worker_id);\n-\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-    ShenandoahObjToScanQueueSet* queues = heap->concurrent_mark()->task_queues();\n-    assert(queues->get_reserved() > worker_id, \"Queue has not been reserved for worker id: %d\", worker_id);\n-\n-    ShenandoahObjToScanQueue* q = queues->queue(worker_id);\n-\n-    ShenandoahInitMarkRootsClosure<UPDATE_REFS> mark_cl(q);\n-    do_work(heap, &mark_cl, worker_id);\n-  }\n-\n-private:\n-  void do_work(ShenandoahHeap* heap, OopClosure* oops, uint worker_id) {\n-    _rp->roots_do(worker_id, oops);\n-  }\n-};\n@@ -143,2 +85,2 @@\n-  ShenandoahConcurrentMark* _cm;\n-  TaskTerminator* _terminator;\n+  ShenandoahConcurrentMark* const _cm;\n+  TaskTerminator* const           _terminator;\n@@ -197,33 +139,0 @@\n-\/\/ Process concurrent roots at safepoints\n-template <typename T>\n-class ShenandoahProcessConcurrentRootsTask : public AbstractGangTask {\n-private:\n-  ShenandoahConcurrentRootScanner<false \/* concurrent *\/> _rs;\n-  ShenandoahConcurrentMark* const _cm;\n-  ShenandoahReferenceProcessor*   _rp;\n-public:\n-\n-  ShenandoahProcessConcurrentRootsTask(ShenandoahConcurrentMark* cm,\n-                                       ShenandoahPhaseTimings::Phase phase,\n-                                       uint nworkers);\n-  void work(uint worker_id);\n-};\n-\n-template <typename T>\n-ShenandoahProcessConcurrentRootsTask<T>::ShenandoahProcessConcurrentRootsTask(ShenandoahConcurrentMark* cm,\n-                                                                              ShenandoahPhaseTimings::Phase phase,\n-                                                                              uint nworkers) :\n-  AbstractGangTask(\"Shenandoah Process Concurrent Roots\"),\n-  _rs(nworkers, phase),\n-  _cm(cm),\n-  _rp(ShenandoahHeap::heap()->ref_processor()) {\n-}\n-\n-template <typename T>\n-void ShenandoahProcessConcurrentRootsTask<T>::work(uint worker_id) {\n-  ShenandoahParallelWorkerSession worker_session(worker_id);\n-  ShenandoahObjToScanQueue* q = _cm->task_queues()->queue(worker_id);\n-  T cl(q, _rp);\n-  _rs.oops_do(&cl, worker_id);\n-}\n-\n@@ -284,3 +193,11 @@\n-void ShenandoahConcurrentMark::mark_roots(ShenandoahPhaseTimings::Phase root_phase) {\n-  assert(Thread::current()->is_VM_thread(), \"can only do this in VMThread\");\n-  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+class ShenandoahInitMarkRootsTask : public AbstractGangTask {\n+private:\n+  ShenandoahRootScanner              _root_scanner;\n+  ShenandoahObjToScanQueueSet* const _task_queues;\n+public:\n+  ShenandoahInitMarkRootsTask(uint n_workers, ShenandoahObjToScanQueueSet* task_queues) :\n+    AbstractGangTask(\"Shenandoah Init Mark Roots\"),\n+    _root_scanner(n_workers, ShenandoahPhaseTimings::scan_roots),\n+    _task_queues(task_queues) {\n+    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+  }\n@@ -288,2 +205,3 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  ShenandoahGCPhase phase(root_phase);\n+  void work(uint worker_id) {\n+    ShenandoahParallelWorkerSession worker_session(worker_id);\n+    assert(_task_queues->get_reserved() > worker_id, \"Queue has not been reserved for worker id: %d\", worker_id);\n@@ -291,3 +209,5 @@\n-  ShenandoahReferenceProcessor* ref_processor = heap->ref_processor();\n-  ref_processor->reset_thread_locals();\n-  ref_processor->set_soft_reference_policy(_heap->soft_ref_policy()->should_clear_all_soft_refs());\n+    ShenandoahObjToScanQueue* q = _task_queues->queue(worker_id);\n+    ShenandoahInitMarkRootsClosure mark_cl(q);\n+    _root_scanner.roots_do(worker_id, &mark_cl);\n+  }\n+};\n@@ -295,1 +215,11 @@\n-  WorkGang* workers = heap->workers();\n+ShenandoahConcurrentMark::ShenandoahConcurrentMark() :\n+  ShenandoahMark() {}\n+\n+void ShenandoahConcurrentMark::mark_stw_roots() {\n+  assert(Thread::current()->is_VM_thread(), \"Can only do this in VMThread\");\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+  assert(!_heap->has_forwarded_objects(), \"Not expected\");\n+\n+  ShenandoahGCPhase phase(ShenandoahPhaseTimings::scan_roots);\n+\n+  WorkGang* workers = ShenandoahHeap::heap()->workers();\n@@ -300,1 +230,0 @@\n-  ShenandoahRootScanner root_proc(nworkers, root_phase);\n@@ -304,9 +233,2 @@\n-  if (heap->has_forwarded_objects()) {\n-    ShenandoahInitMarkRootsTask<RESOLVE> mark_roots(&root_proc);\n-    workers->run_task(&mark_roots);\n-  } else {\n-    \/\/ No need to update references, which means the heap is stable.\n-    \/\/ Can save time not walking through forwarding pointers.\n-    ShenandoahInitMarkRootsTask<NONE> mark_roots(&root_proc);\n-    workers->run_task(&mark_roots);\n-  }\n+  ShenandoahInitMarkRootsTask mark_roots(nworkers, task_queues());\n+  workers->run_task(&mark_roots);\n@@ -329,1 +251,3 @@\n-  uint nworkers = _heap->workers()->active_workers();\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  WorkGang* workers = heap->workers();\n+  uint nworkers = workers->active_workers();\n@@ -333,1 +257,1 @@\n-  _heap->workers()->run_task(&update_roots);\n+  workers->run_task(&update_roots);\n@@ -367,2 +291,2 @@\n-\n-  WorkGang* workers = _heap->workers();\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  WorkGang* workers = heap->workers();\n@@ -379,14 +303,0 @@\n-void ShenandoahConcurrentMark::initialize(uint workers) {\n-  _heap = ShenandoahHeap::heap();\n-\n-  uint num_queues = MAX2(workers, 1U);\n-\n-  _task_queues = new ShenandoahObjToScanQueueSet((int) num_queues);\n-\n-  for (uint i = 0; i < num_queues; ++i) {\n-    ShenandoahObjToScanQueue* task_queue = new ShenandoahObjToScanQueue();\n-    task_queue->initialize();\n-    _task_queues->register_queue(i, task_queue);\n-  }\n-}\n-\n@@ -397,1 +307,1 @@\n-  ShenandoahConcurrentRootScanner<true \/* concurrent *\/> _rs;\n+  ShenandoahConcurrentRootScanner     _root_scanner;\n@@ -410,3 +320,3 @@\n-                                                                     ShenandoahReferenceProcessor* rp,\n-                                                                     ShenandoahPhaseTimings::Phase phase,\n-                                                                     uint nworkers) :\n+                                                                    ShenandoahReferenceProcessor* rp,\n+                                                                    ShenandoahPhaseTimings::Phase phase,\n+                                                                    uint nworkers) :\n@@ -414,1 +324,1 @@\n-  _rs(nworkers, phase),\n+  _root_scanner(nworkers, phase),\n@@ -424,1 +334,1 @@\n-  _rs.oops_do(&cl, worker_id);\n+  _root_scanner.roots_do(&cl, worker_id);\n@@ -427,3 +337,2 @@\n-void ShenandoahConcurrentMark::mark_from_roots() {\n-  WorkGang* workers = _heap->workers();\n-  uint nworkers = workers->active_workers();\n+void ShenandoahConcurrentMark::mark_concurrent_roots() {\n+  assert(!heap()->has_forwarded_objects(), \"Not expected\");\n@@ -431,0 +340,1 @@\n+  WorkGang* workers = heap()->workers();\n@@ -432,0 +342,3 @@\n+  task_queues()->reserve(workers->active_workers());\n+\/\/  ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_mark_roots);\n+  ShenandoahMarkConcurrentRootsTask task(task_queues(), rp,  ShenandoahPhaseTimings::conc_mark_roots, workers->active_workers());\n@@ -433,1 +346,2 @@\n-  task_queues()->reserve(nworkers);\n+  workers->run_task(&task);\n+}\n@@ -435,6 +349,5 @@\n-  {\n-    ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_mark_roots);\n-    \/\/ Use separate task to mark concurrent roots, since it may hold ClassLoaderData_lock and CodeCache_lock\n-    ShenandoahMarkConcurrentRootsTask task(task_queues(), rp, ShenandoahPhaseTimings::conc_mark_roots, nworkers);\n-    workers->run_task(&task);\n-  }\n+void ShenandoahConcurrentMark::concurrent_mark() {\n+  WorkGang* workers = heap()->workers();\n+  uint nworkers = workers->active_workers();\n+  task_queues()->reserve(nworkers);\n+  TaskTerminator terminator(nworkers, task_queues());\n@@ -451,1 +364,1 @@\n-void ShenandoahConcurrentMark::finish_mark_from_roots(bool full_gc) {\n+void ShenandoahConcurrentMark::finish_mark() {\n@@ -453,44 +366,2 @@\n-\n-  uint nworkers = _heap->workers()->active_workers();\n-\n-  {\n-    \/\/ Full GC does not execute concurrent cycle. Degenerated cycle may bypass concurrent cycle.\n-    \/\/ In those cases, concurrent roots might not be scanned, scan them here. Ideally, this\n-    \/\/ should piggyback to ShenandoahFinalMarkingTask, but it makes time tracking very hard.\n-    \/\/ Given full GC and degenerated GC are rare, use a separate task.\n-    if (_heap->is_degenerated_gc_in_progress() || _heap->is_full_gc_in_progress()) {\n-      ShenandoahPhaseTimings::Phase phase = _heap->is_full_gc_in_progress() ?\n-                                            ShenandoahPhaseTimings::full_gc_scan_conc_roots :\n-                                            ShenandoahPhaseTimings::degen_gc_scan_conc_roots;\n-      ShenandoahGCPhase gc_phase(phase);\n-      if (_heap->has_forwarded_objects()) {\n-        ShenandoahProcessConcurrentRootsTask<ShenandoahMarkResolveRefsClosure> task(this, phase, nworkers);\n-        _heap->workers()->run_task(&task);\n-      } else {\n-        ShenandoahProcessConcurrentRootsTask<ShenandoahMarkRefsClosure> task(this, phase, nworkers);\n-        _heap->workers()->run_task(&task);\n-      }\n-    }\n-\n-    \/\/ Finally mark everything else we've got in our queues during the previous steps.\n-    \/\/ It does two different things for concurrent vs. mark-compact GC:\n-    \/\/ - For concurrent GC, it starts with empty task queues, drains the remaining\n-    \/\/   SATB buffers, and then completes the marking closure.\n-    \/\/ - For mark-compact GC, it starts out with the task queues seeded by initial\n-    \/\/   root scan, and completes the closure, thus marking through all live objects\n-    \/\/ The implementation is the same, so it's shared here.\n-    {\n-      ShenandoahGCPhase phase(full_gc ?\n-                              ShenandoahPhaseTimings::full_gc_mark_finish_queues :\n-                              ShenandoahPhaseTimings::finish_queues);\n-      task_queues()->reserve(nworkers);\n-\n-      StrongRootsScope scope(nworkers);\n-      TaskTerminator terminator(nworkers, task_queues());\n-      ShenandoahFinalMarkingTask task(this, &terminator, ShenandoahStringDedup::is_enabled());\n-      _heap->workers()->run_task(&task);\n-    }\n-\n-    assert(task_queues()->is_empty(), \"Should be empty\");\n-  }\n-\n+  assert(Thread::current()->is_VM_thread(), \"Must by VM Thread\");\n+  finish_mark_work();\n@@ -502,20 +373,11 @@\n-void ShenandoahConcurrentMark::cancel() {\n-  \/\/ Clean up marking stacks.\n-  ShenandoahObjToScanQueueSet* queues = task_queues();\n-  queues->clear();\n-\n-  \/\/ Cancel SATB buffers.\n-  ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();\n-}\n-\n-ShenandoahObjToScanQueue* ShenandoahConcurrentMark::get_queue(uint worker_id) {\n-  assert(task_queues()->get_reserved() > worker_id, \"No reserved queue for worker id: %d\", worker_id);\n-  return _task_queues->queue(worker_id);\n-}\n-\n-template <bool CANCELLABLE>\n-void ShenandoahConcurrentMark::mark_loop_prework(uint w, TaskTerminator *t, ShenandoahReferenceProcessor* rp,\n-                                                 bool strdedup) {\n-  ShenandoahObjToScanQueue* q = get_queue(w);\n-\n-  ShenandoahLiveData* ld = _heap->get_liveness_cache(w);\n+void ShenandoahConcurrentMark::finish_mark_work() {\n+  \/\/ Finally mark everything else we've got in our queues during the previous steps.\n+  \/\/ It does two different things for concurrent vs. mark-compact GC:\n+  \/\/ - For concurrent GC, it starts with empty task queues, drains the remaining\n+  \/\/   SATB buffers, and then completes the marking closure.\n+  \/\/ - For mark-compact GC, it starts out with the task queues seeded by initial\n+  \/\/   root scan, and completes the closure, thus marking through all live objects\n+  \/\/ The implementation is the same, so it's shared here.\n+  ShenandoahGCPhase phase(ShenandoahPhaseTimings::finish_queues);\n+  uint nworkers = _heap->workers()->active_workers();\n+  task_queues()->reserve(nworkers);\n@@ -523,39 +385,4 @@\n-  \/\/ TODO: We can clean up this if we figure out how to do templated oop closures that\n-  \/\/ play nice with specialized_oop_iterators.\n-  if (_heap->unload_classes()) {\n-    if (_heap->has_forwarded_objects()) {\n-      if (strdedup) {\n-        ShenandoahMarkUpdateRefsMetadataDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkUpdateRefsMetadataClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    } else {\n-      if (strdedup) {\n-        ShenandoahMarkRefsMetadataDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkRefsMetadataClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    }\n-  } else {\n-    if (_heap->has_forwarded_objects()) {\n-      if (strdedup) {\n-        ShenandoahMarkUpdateRefsDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkUpdateRefsClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    } else {\n-      if (strdedup) {\n-        ShenandoahMarkRefsDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkRefsClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    }\n-  }\n+  StrongRootsScope scope(nworkers);\n+  TaskTerminator terminator(nworkers, task_queues());\n+  ShenandoahFinalMarkingTask task(this, &terminator, ShenandoahStringDedup::is_enabled());\n+  heap()->workers()->run_task(&task);\n@@ -563,1 +390,1 @@\n-  _heap->flush_liveness_cache(w);\n+  assert(task_queues()->is_empty(), \"Should be empty\");\n@@ -566,26 +393,0 @@\n-template <class T, bool CANCELLABLE>\n-void ShenandoahConcurrentMark::mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *terminator) {\n-  uintx stride = ShenandoahMarkLoopStride;\n-\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  ShenandoahObjToScanQueueSet* queues = task_queues();\n-  ShenandoahObjToScanQueue* q;\n-  ShenandoahMarkTask t;\n-\n-  _heap->ref_processor()->set_mark_closure(worker_id, cl);\n-\n-  \/*\n-   * Process outstanding queues, if any.\n-   *\n-   * There can be more queues than workers. To deal with the imbalance, we claim\n-   * extra queues first. Since marking can push new tasks into the queue associated\n-   * with this worker id, we come back to process this queue in the normal loop.\n-   *\/\n-  assert(queues->get_reserved() == heap->workers()->active_workers(),\n-         \"Need to reserve proper number of queues: reserved: %u, active: %u\", queues->get_reserved(), heap->workers()->active_workers());\n-\n-  q = queues->claim_next();\n-  while (q != NULL) {\n-    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n-      return;\n-    }\n@@ -593,46 +394,4 @@\n-    for (uint i = 0; i < stride; i++) {\n-      if (q->pop(t)) {\n-        do_task<T>(q, cl, live_data, &t);\n-      } else {\n-        assert(q->is_empty(), \"Must be empty\");\n-        q = queues->claim_next();\n-        break;\n-      }\n-    }\n-  }\n-  q = get_queue(worker_id);\n-\n-  ShenandoahSATBBufferClosure drain_satb(q);\n-  SATBMarkQueueSet& satb_mq_set = ShenandoahBarrierSet::satb_mark_queue_set();\n-\n-  \/*\n-   * Normal marking loop:\n-   *\/\n-  while (true) {\n-    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n-      return;\n-    }\n-\n-    while (satb_mq_set.completed_buffers_num() > 0) {\n-      satb_mq_set.apply_closure_to_completed_buffer(&drain_satb);\n-    }\n-\n-    uint work = 0;\n-    for (uint i = 0; i < stride; i++) {\n-      if (q->pop(t) ||\n-          queues->steal(worker_id, t)) {\n-        do_task<T>(q, cl, live_data, &t);\n-        work++;\n-      } else {\n-        break;\n-      }\n-    }\n-\n-    if (work == 0) {\n-      \/\/ No work encountered in current stride, try to terminate.\n-      \/\/ Need to leave the STS here otherwise it might block safepoints.\n-      ShenandoahSuspendibleThreadSetLeaver stsl(CANCELLABLE && ShenandoahSuspendibleWorkers);\n-      ShenandoahTerminatorTerminator tt(heap);\n-      if (terminator->offer_termination(&tt)) return;\n-    }\n-  }\n+void ShenandoahConcurrentMark::cancel() {\n+  clear();\n+  ShenandoahReferenceProcessor* rp = ShenandoahHeap::heap()->ref_processor();\n+  rp->abandon_partial_discovery();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.cpp","additions":85,"deletions":326,"binary":false,"changes":411,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"gc\/shenandoah\/shenandoahPhaseTimings.hpp\"\n@@ -37,4 +37,3 @@\n-class ShenandoahConcurrentMark: public CHeapObj<mtGC> {\n-private:\n-  ShenandoahHeap* _heap;\n-  ShenandoahObjToScanQueueSet* _task_queues;\n+class ShenandoahConcurrentMark: public ShenandoahMark {\n+  friend class ShenandoahConcurrentMarkingTask;\n+  friend class ShenandoahFinalMarkingTask;\n@@ -43,8 +42,1 @@\n-  void initialize(uint workers);\n-  void cancel();\n-\n-\/\/ ---------- Marking loop and tasks\n-\/\/\n-private:\n-  template <class T>\n-  inline void do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task);\n+  ShenandoahConcurrentMark();\n@@ -52,2 +44,3 @@\n-  template <class T>\n-  inline void do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop array, bool weak);\n+  \/\/ When concurrent stack processing is not supported\n+  void mark_stw_roots();\n+  void mark_concurrent_roots();\n@@ -55,2 +48,4 @@\n-  template <class T>\n-  inline void do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop array, int chunk, int pow, bool weak);\n+  \/\/ Concurrent mark\n+  void concurrent_mark();\n+  \/\/ Finish mark at a safepoint\n+  void finish_mark();\n@@ -58,1 +53,0 @@\n-  inline void count_liveness(ShenandoahLiveData* live_data, oop obj);\n@@ -60,15 +54,1 @@\n-  template <class T, bool CANCELLABLE>\n-  void mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *t);\n-\n-  template <bool CANCELLABLE>\n-  void mark_loop_prework(uint worker_id, TaskTerminator *terminator, ShenandoahReferenceProcessor* rp, bool strdedup);\n-\n-public:\n-  void mark_loop(uint worker_id, TaskTerminator* terminator, ShenandoahReferenceProcessor* rp,\n-                 bool cancellable, bool strdedup) {\n-    if (cancellable) {\n-      mark_loop_prework<true>(worker_id, terminator, rp, strdedup);\n-    } else {\n-      mark_loop_prework<false>(worker_id, terminator, rp, strdedup);\n-    }\n-  }\n+  static void cancel();\n@@ -76,16 +56,3 @@\n-  template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n-  static inline void mark_through_ref(T* p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context, bool weak);\n-\n-  void mark_from_roots();\n-  void finish_mark_from_roots(bool full_gc);\n-\n-  void mark_roots(ShenandoahPhaseTimings::Phase root_phase);\n-  void update_roots(ShenandoahPhaseTimings::Phase root_phase);\n-  void update_thread_roots(ShenandoahPhaseTimings::Phase root_phase);\n-\n-\/\/ ---------- Helpers\n-\/\/ Used from closures, need to be public\n-\/\/\n-public:\n-  ShenandoahObjToScanQueue* get_queue(uint worker_id);\n-  ShenandoahObjToScanQueueSet* task_queues() { return _task_queues; }\n+  \/\/ TODO: where to put them\n+  static void update_roots(ShenandoahPhaseTimings::Phase root_phase);\n+  static void update_thread_roots(ShenandoahPhaseTimings::Phase root_phase);\n@@ -93,0 +60,2 @@\n+private:\n+  void finish_mark_work();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.hpp","additions":18,"deletions":49,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -1,285 +0,0 @@\n-\/*\n- * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP\n-#define SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP\n-\n-#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n-#include \"gc\/shenandoah\/shenandoahBarrierSet.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n-#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahMarkingContext.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahStringDedup.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahTaskqueue.inline.hpp\"\n-#include \"memory\/iterator.inline.hpp\"\n-#include \"oops\/compressedOops.inline.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/prefetch.inline.hpp\"\n-\n-template <class T>\n-void ShenandoahConcurrentMark::do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task) {\n-  oop obj = task->obj();\n-\n-  shenandoah_assert_not_forwarded(NULL, obj);\n-  shenandoah_assert_marked(NULL, obj);\n-  shenandoah_assert_not_in_cset_except(NULL, obj, _heap->cancelled_gc());\n-\n-  \/\/ Are we in weak subgraph scan?\n-  bool weak = task->is_weak();\n-  cl->set_weak(weak);\n-\n-  if (task->is_not_chunked()) {\n-    if (obj->is_instance()) {\n-      \/\/ Case 1: Normal oop, process as usual.\n-      obj->oop_iterate(cl);\n-    } else if (obj->is_objArray()) {\n-      \/\/ Case 2: Object array instance and no chunk is set. Must be the first\n-      \/\/ time we visit it, start the chunked processing.\n-      do_chunked_array_start<T>(q, cl, obj, weak);\n-    } else {\n-      \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n-      \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n-      \/\/ We skip iterating over the klass pointer since we know that\n-      \/\/ Universe::TypeArrayKlass never moves.\n-      assert (obj->is_typeArray(), \"should be type array\");\n-    }\n-    \/\/ Count liveness the last: push the outstanding work to the queues first\n-    \/\/ Avoid double-counting objects that are visited twice due to upgrade\n-    \/\/ from final- to strong mark.\n-    if (task->count_liveness()) {\n-      count_liveness(live_data, obj);\n-    }\n-  } else {\n-    \/\/ Case 4: Array chunk, has sensible chunk id. Process it.\n-    do_chunked_array<T>(q, cl, obj, task->chunk(), task->pow(), weak);\n-  }\n-}\n-\n-inline void ShenandoahConcurrentMark::count_liveness(ShenandoahLiveData* live_data, oop obj) {\n-  size_t region_idx = _heap->heap_region_index_containing(obj);\n-  ShenandoahHeapRegion* region = _heap->get_region(region_idx);\n-  size_t size = obj->size();\n-\n-  if (!region->is_humongous_start()) {\n-    assert(!region->is_humongous(), \"Cannot have continuations here\");\n-    ShenandoahLiveData cur = live_data[region_idx];\n-    size_t new_val = size + cur;\n-    if (new_val >= SHENANDOAH_LIVEDATA_MAX) {\n-      \/\/ overflow, flush to region data\n-      region->increase_live_data_gc_words(new_val);\n-      live_data[region_idx] = 0;\n-    } else {\n-      \/\/ still good, remember in locals\n-      live_data[region_idx] = (ShenandoahLiveData) new_val;\n-    }\n-  } else {\n-    shenandoah_assert_in_correct_region(NULL, obj);\n-    size_t num_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);\n-\n-    for (size_t i = region_idx; i < region_idx + num_regions; i++) {\n-      ShenandoahHeapRegion* chain_reg = _heap->get_region(i);\n-      assert(chain_reg->is_humongous(), \"Expecting a humongous region\");\n-      chain_reg->increase_live_data_gc_words(chain_reg->used() >> LogHeapWordSize);\n-    }\n-  }\n-}\n-\n-template <class T>\n-inline void ShenandoahConcurrentMark::do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop obj, bool weak) {\n-  assert(obj->is_objArray(), \"expect object array\");\n-  objArrayOop array = objArrayOop(obj);\n-  int len = array->length();\n-\n-  if (len <= (int) ObjArrayMarkingStride*2) {\n-    \/\/ A few slices only, process directly\n-    array->oop_iterate_range(cl, 0, len);\n-  } else {\n-    int bits = log2_long((size_t) len);\n-    \/\/ Compensate for non-power-of-two arrays, cover the array in excess:\n-    if (len != (1 << bits)) bits++;\n-\n-    \/\/ Only allow full chunks on the queue. This frees do_chunked_array() from checking from\/to\n-    \/\/ boundaries against array->length(), touching the array header on every chunk.\n-    \/\/\n-    \/\/ To do this, we cut the prefix in full-sized chunks, and submit them on the queue.\n-    \/\/ If the array is not divided in chunk sizes, then there would be an irregular tail,\n-    \/\/ which we will process separately.\n-\n-    int last_idx = 0;\n-\n-    int chunk = 1;\n-    int pow = bits;\n-\n-    \/\/ Handle overflow\n-    if (pow >= 31) {\n-      assert (pow == 31, \"sanity\");\n-      pow--;\n-      chunk = 2;\n-      last_idx = (1 << pow);\n-      bool pushed = q->push(ShenandoahMarkTask(array, true, weak, 1, pow));\n-      assert(pushed, \"overflow queue should always succeed pushing\");\n-    }\n-\n-    \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Record the last\n-    \/\/ successful right boundary to figure out the irregular tail.\n-    while ((1 << pow) > (int)ObjArrayMarkingStride &&\n-           (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n-      pow--;\n-      int left_chunk = chunk*2 - 1;\n-      int right_chunk = chunk*2;\n-      int left_chunk_end = left_chunk * (1 << pow);\n-      if (left_chunk_end < len) {\n-        bool pushed = q->push(ShenandoahMarkTask(array, true, weak, left_chunk, pow));\n-        assert(pushed, \"overflow queue should always succeed pushing\");\n-        chunk = right_chunk;\n-        last_idx = left_chunk_end;\n-      } else {\n-        chunk = left_chunk;\n-      }\n-    }\n-\n-    \/\/ Process the irregular tail, if present\n-    int from = last_idx;\n-    if (from < len) {\n-      array->oop_iterate_range(cl, from, len);\n-    }\n-  }\n-}\n-\n-template <class T>\n-inline void ShenandoahConcurrentMark::do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop obj, int chunk, int pow, bool weak) {\n-  assert(obj->is_objArray(), \"expect object array\");\n-  objArrayOop array = objArrayOop(obj);\n-\n-  assert (ObjArrayMarkingStride > 0, \"sanity\");\n-\n-  \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Avoid pushing tasks that\n-  \/\/ are known to start beyond the array.\n-  while ((1 << pow) > (int)ObjArrayMarkingStride && (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n-    pow--;\n-    chunk *= 2;\n-    bool pushed = q->push(ShenandoahMarkTask(array, true, weak, chunk - 1, pow));\n-    assert(pushed, \"overflow queue should always succeed pushing\");\n-  }\n-\n-  int chunk_size = 1 << pow;\n-\n-  int from = (chunk - 1) * chunk_size;\n-  int to = chunk * chunk_size;\n-\n-#ifdef ASSERT\n-  int len = array->length();\n-  assert (0 <= from && from < len, \"from is sane: %d\/%d\", from, len);\n-  assert (0 < to && to <= len, \"to is sane: %d\/%d\", to, len);\n-#endif\n-\n-  array->oop_iterate_range(cl, from, to);\n-}\n-\n-class ShenandoahSATBBufferClosure : public SATBBufferClosure {\n-private:\n-  ShenandoahObjToScanQueue* _queue;\n-  ShenandoahHeap* _heap;\n-  ShenandoahMarkingContext* const _mark_context;\n-public:\n-  ShenandoahSATBBufferClosure(ShenandoahObjToScanQueue* q) :\n-    _queue(q),\n-    _heap(ShenandoahHeap::heap()),\n-    _mark_context(_heap->marking_context())\n-  {\n-  }\n-\n-  void do_buffer(void **buffer, size_t size) {\n-    assert(size == 0 || !_heap->has_forwarded_objects(), \"Forwarded objects are not expected here\");\n-    if (ShenandoahStringDedup::is_enabled()) {\n-      do_buffer_impl<ENQUEUE_DEDUP>(buffer, size);\n-    } else {\n-      do_buffer_impl<NO_DEDUP>(buffer, size);\n-    }\n-  }\n-\n-  template<StringDedupMode STRING_DEDUP>\n-  void do_buffer_impl(void **buffer, size_t size) {\n-    for (size_t i = 0; i < size; ++i) {\n-      oop *p = (oop *) &buffer[i];\n-      ShenandoahConcurrentMark::mark_through_ref<oop, NONE, STRING_DEDUP>(p, _heap, _queue, _mark_context, false);\n-    }\n-  }\n-};\n-\n-template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n-inline void ShenandoahConcurrentMark::mark_through_ref(T *p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context, bool weak) {\n-  T o = RawAccess<>::oop_load(p);\n-  if (!CompressedOops::is_null(o)) {\n-    oop obj = CompressedOops::decode_not_null(o);\n-    switch (UPDATE_REFS) {\n-    case NONE:\n-      break;\n-    case RESOLVE:\n-      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n-      break;\n-    case SIMPLE:\n-      \/\/ We piggy-back reference updating to the marking tasks.\n-      obj = heap->update_with_forwarded_not_null(p, obj);\n-      break;\n-    case CONCURRENT:\n-      obj = heap->maybe_update_with_forwarded_not_null(p, obj);\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-\n-    \/\/ Note: Only when concurrently updating references can obj be different\n-    \/\/ (that is, really different, not just different from-\/to-space copies of the same)\n-    \/\/ from the one we originally loaded. Mutator thread can beat us by writing something\n-    \/\/ else into the location. In that case, we would mark through that updated value,\n-    \/\/ on the off-chance it is not handled by other means (e.g. via SATB). However,\n-    \/\/ if that write was NULL, we don't need to do anything else.\n-    if (UPDATE_REFS != CONCURRENT || !CompressedOops::is_null(obj)) {\n-      shenandoah_assert_not_forwarded(p, obj);\n-      shenandoah_assert_not_in_cset_except(p, obj, heap->cancelled_gc());\n-\n-      bool skip_live = false;\n-      bool marked;\n-      if (weak) {\n-        marked = mark_context->mark_weak(obj);\n-      } else {\n-        marked = mark_context->mark_strong(obj, \/* was_upgraded = *\/ skip_live);\n-      }\n-      if (marked) {\n-        bool pushed = q->push(ShenandoahMarkTask(obj, skip_live, weak));\n-        assert(pushed, \"overflow queue should always succeed pushing\");\n-\n-        if ((STRING_DEDUP == ENQUEUE_DEDUP) && ShenandoahStringDedup::is_candidate(obj)) {\n-          assert(ShenandoahStringDedup::is_enabled(), \"Must be enabled\");\n-          ShenandoahStringDedup::enqueue_candidate(obj);\n-        }\n-      }\n-\n-      shenandoah_assert_marked(p, obj);\n-    }\n-  }\n-}\n-\n-#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp","additions":0,"deletions":285,"binary":false,"changes":285,"status":"deleted"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -33,0 +33,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -400,0 +401,4 @@\n+  \/\/ Concurrent mark roots\n+  heap->entry_mark_roots();\n+  if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_outside_cycle)) return;\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -61,1 +61,1 @@\n-#include \"gc\/shenandoah\/shenandoahTaskqueue.hpp\"\n+#include \"gc\/shenandoah\/shenandoahSTWMark.hpp\"\n@@ -250,1 +250,1 @@\n-  _marking_context = new ShenandoahMarkingContext(_heap_region, _bitmap_region, _num_regions);\n+  _marking_context = new ShenandoahMarkingContext(_heap_region, _bitmap_region, _num_regions, MAX2(_max_workers, 1U));\n@@ -465,2 +465,0 @@\n-  _scm(new ShenandoahConcurrentMark()),\n-  _full_gc(new ShenandoahMarkCompact()),\n@@ -614,3 +612,0 @@\n-  _scm->initialize(_max_workers);\n-  _full_gc->initialize(_gc_timer);\n-\n@@ -1607,0 +1602,5 @@\n+  \/\/ Weak reference processing\n+  ShenandoahReferenceProcessor* rp = ref_processor();\n+  rp->reset_thread_locals();\n+  rp->set_soft_reference_policy(soft_ref_policy()->should_clear_all_soft_refs());\n+\n@@ -1609,2 +1609,2 @@\n-\n-  concurrent_mark()->mark_roots(ShenandoahPhaseTimings::scan_roots);\n+  ShenandoahConcurrentMark mark;\n+  mark.mark_stw_roots();\n@@ -1624,0 +1624,5 @@\n+void ShenandoahHeap::op_mark_roots() {\n+  ShenandoahConcurrentMark mark;\n+  mark.mark_concurrent_roots();\n+}\n+\n@@ -1625,1 +1630,2 @@\n-  concurrent_mark()->mark_from_roots();\n+  ShenandoahConcurrentMark mark;\n+  mark.concurrent_mark();\n@@ -1679,4 +1685,0 @@\n-  \/\/ It is critical that we\n-  \/\/ evacuate roots right after finishing marking, so that we don't\n-  \/\/ get unmarked objects in the roots.\n-\n@@ -1684,97 +1686,2 @@\n-    concurrent_mark()->finish_mark_from_roots(\/* full_gc = *\/ false);\n-\n-    \/\/ Marking is completed, deactivate SATB barrier\n-    set_concurrent_mark_in_progress(false);\n-    mark_complete_marking_context();\n-\n-    \/\/ Notify JVMTI that the tagmap table will need cleaning.\n-    JvmtiTagMap::set_needs_cleaning();\n-\n-    if (is_degenerated_gc_in_progress()) {\n-      parallel_cleaning(false \/* full gc*\/);\n-    }\n-\n-    if (ShenandoahVerify) {\n-      verifier()->verify_roots_no_forwarded();\n-    }\n-\n-    {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_region_states);\n-      ShenandoahFinalMarkUpdateRegionStateClosure cl;\n-      parallel_heap_region_iterate(&cl);\n-\n-      assert_pinned_region_status();\n-    }\n-\n-    \/\/ Retire the TLABs, which will force threads to reacquire their TLABs after the pause.\n-    \/\/ This is needed for two reasons. Strong one: new allocations would be with new freeset,\n-    \/\/ which would be outside the collection set, so no cset writes would happen there.\n-    \/\/ Weaker one: new allocations would happen past update watermark, and so less work would\n-    \/\/ be needed for reference updates (would update the large filler instead).\n-    if (UseTLAB) {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_manage_labs);\n-      tlabs_retire(false);\n-    }\n-\n-    {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::choose_cset);\n-      ShenandoahHeapLocker locker(lock());\n-      _collection_set->clear();\n-      heuristics()->choose_collection_set(_collection_set);\n-    }\n-\n-    {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_rebuild_freeset);\n-      ShenandoahHeapLocker locker(lock());\n-      _free_set->rebuild();\n-    }\n-\n-    if (!is_degenerated_gc_in_progress()) {\n-      prepare_concurrent_roots();\n-      prepare_concurrent_unloading();\n-    }\n-\n-    \/\/ If collection set has candidates, start evacuation.\n-    \/\/ Otherwise, bypass the rest of the cycle.\n-    if (!collection_set()->is_empty()) {\n-      ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);\n-\n-      if (ShenandoahVerify) {\n-        verifier()->verify_before_evacuation();\n-      }\n-\n-      set_evacuation_in_progress(true);\n-      \/\/ From here on, we need to update references.\n-      set_has_forwarded_objects(true);\n-\n-      if (!is_degenerated_gc_in_progress()) {\n-        \/\/ Arm nmethods for concurrent codecache processing.\n-        ShenandoahCodeRoots::arm_nmethods();\n-        evacuate_and_update_roots();\n-      }\n-\n-      \/\/ Notify JVMTI that oops are changed.\n-      JvmtiTagMap::set_needs_rehashing();\n-\n-      if (ShenandoahPacing) {\n-        pacer()->setup_for_evac();\n-      }\n-\n-      if (ShenandoahVerify) {\n-        \/\/ If OOM while evacuating\/updating of roots, there is no guarantee of their consistencies\n-        if (!cancelled_gc()) {\n-          \/\/ We only evacuate\/update thread roots at this pause\n-          verifier()->verify_roots_no_forwarded(ShenandoahRootVerifier::ThreadRoots);\n-        }\n-        verifier()->verify_during_evacuation();\n-      }\n-    } else {\n-      if (ShenandoahVerify) {\n-        verifier()->verify_after_concmark();\n-      }\n-\n-      if (VerifyAfterGC) {\n-        Universe::verify();\n-      }\n-    }\n-\n+    finish_mark();\n+    prepare_evacuation();\n@@ -1784,1 +1691,1 @@\n-    concurrent_mark()->cancel();\n+    ShenandoahConcurrentMark::cancel();\n@@ -1786,4 +1693,0 @@\n-\n-    \/\/ Abandon reference processing right away: pre-cleaning must have failed.\n-    ShenandoahReferenceProcessor* rp = ref_processor();\n-    rp->abandon_partial_discovery();\n@@ -1840,0 +1743,103 @@\n+\/\/ Helpers\n+void ShenandoahHeap::finish_mark() {\n+  assert(!cancelled_gc(), \"Should not continue\");\n+  ShenandoahConcurrentMark mark;\n+  mark.finish_mark();\n+  \/\/ Marking is completed, deactivate SATB barrier\n+  set_concurrent_mark_in_progress(false);\n+  mark_complete_marking_context();\n+}\n+\n+void ShenandoahHeap::prepare_evacuation() {\n+  \/\/ Notify JVMTI that the tagmap table will need cleaning.\n+  JvmtiTagMap::set_needs_cleaning();\n+\n+  if (is_degenerated_gc_in_progress()) {\n+    parallel_cleaning(false \/* full gc*\/);\n+  }\n+\n+  if (ShenandoahVerify) {\n+    verifier()->verify_roots_no_forwarded();\n+  }\n+\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_region_states);\n+    ShenandoahFinalMarkUpdateRegionStateClosure cl;\n+    parallel_heap_region_iterate(&cl);\n+\n+    assert_pinned_region_status();\n+  }\n+\n+  \/\/ Retire the TLABs, which will force threads to reacquire their TLABs after the pause.\n+  \/\/ This is needed for two reasons. Strong one: new allocations would be with new freeset,\n+  \/\/ which would be outside the collection set, so no cset writes would happen there.\n+  \/\/ Weaker one: new allocations would happen past update watermark, and so less work would\n+  \/\/ be needed for reference updates (would update the large filler instead).\n+  if (UseTLAB) {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_manage_labs);\n+    tlabs_retire(false);\n+  }\n+\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::choose_cset);\n+    ShenandoahHeapLocker locker(lock());\n+    _collection_set->clear();\n+    heuristics()->choose_collection_set(_collection_set);\n+  }\n+\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_rebuild_freeset);\n+    ShenandoahHeapLocker locker(lock());\n+    _free_set->rebuild();\n+  }\n+\n+  if (!is_degenerated_gc_in_progress()) {\n+    prepare_concurrent_roots();\n+    prepare_concurrent_unloading();\n+  }\n+\n+  \/\/ If collection set has candidates, start evacuation.\n+  \/\/ Otherwise, bypass the rest of the cycle.\n+  if (!collection_set()->is_empty()) {\n+    ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);\n+\n+    if (ShenandoahVerify) {\n+      verifier()->verify_before_evacuation();\n+    }\n+\n+    set_evacuation_in_progress(true);\n+    \/\/ From here on, we need to update references.\n+    set_has_forwarded_objects(true);\n+\n+    if (!is_degenerated_gc_in_progress()) {\n+      \/\/ Arm nmethods for concurrent codecache processing.\n+      ShenandoahCodeRoots::arm_nmethods();\n+      evacuate_and_update_roots();\n+    }\n+\n+    \/\/ Notify JVMTI that oops are changed.\n+    JvmtiTagMap::set_needs_rehashing();\n+\n+    if (ShenandoahPacing) {\n+      pacer()->setup_for_evac();\n+    }\n+\n+    if (ShenandoahVerify) {\n+      \/\/ If OOM while evacuating\/updating of roots, there is no guarantee of their consistencies\n+      if (!cancelled_gc()) {\n+        \/\/ We only evacuate\/update thread at this pause\n+        verifier()->verify_roots_no_forwarded(ShenandoahRootVerifier::ThreadRoots);\n+      }\n+      verifier()->verify_during_evacuation();\n+    }\n+  } else {\n+    if (ShenandoahVerify) {\n+      verifier()->verify_after_concmark();\n+    }\n+\n+    if (VerifyAfterGC) {\n+      Universe::verify();\n+    }\n+  }\n+}\n+\n@@ -2135,1 +2141,3 @@\n-  full_gc()->do_it(cause);\n+  ShenandoahMarkCompact full_gc;\n+  full_gc.initialize(_gc_timer);\n+  full_gc.do_it(cause);\n@@ -2172,0 +2180,7 @@\n+\n+      \/\/ Degenerated from concurrent mark roots, reset for STW mark\n+      if (is_concurrent_mark_in_progress()) {\n+        ShenandoahConcurrentMark::cancel();\n+        set_concurrent_mark_in_progress(false);\n+      }\n+\n@@ -2176,4 +2191,6 @@\n-      op_init_mark();\n-      if (cancelled_gc()) {\n-        op_degenerated_fail();\n-        return;\n+      \/\/ STW root scan\n+      {\n+        assert(!has_forwarded_objects(), \"Should not have forwarded heap\");\n+        ShenandoahSTWMark mark(false \/*full_gc*\/);\n+        mark.mark();\n+        assert(!cancelled_gc(), \"STW mark can not OOM\");\n@@ -2181,1 +2198,0 @@\n-\n@@ -2183,1 +2199,5 @@\n-      op_final_mark();\n+      if (point == _degenerated_mark) {\n+        finish_mark();\n+      }\n+      prepare_evacuation();\n+\n@@ -2197,2 +2217,1 @@\n-        ShenandoahTimingsTracker t(ShenandoahPhaseTimings::conc_weak_refs_work);\n-        ShenandoahGCWorkerPhase worker_phase(ShenandoahPhaseTimings::conc_weak_refs_work);\n+        ShenandoahGCPhase phase(ShenandoahPhaseTimings::degen_gc_weakrefs);\n@@ -2785,1 +2804,1 @@\n-    concurrent_mark()->update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);\n+    ShenandoahConcurrentMark::update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);\n@@ -3037,0 +3056,15 @@\n+void ShenandoahHeap::entry_mark_roots() {\n+  TraceCollectorStats tcs(monitoring_support()->concurrent_collection_counters());\n+\n+  const char* msg = \"Concurrent marking roots\";\n+  ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_mark_roots);\n+  EventMark em(\"%s\", msg);\n+\n+  ShenandoahWorkerScope scope(workers(),\n+                              ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),\n+                              \"concurrent marking roots\");\n+\n+  try_inject_alloc_failure();\n+  op_mark_roots();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":161,"deletions":127,"binary":false,"changes":288,"status":"modified"},{"patch":"@@ -51,1 +51,0 @@\n-class ShenandoahMarkCompact;\n@@ -59,2 +58,0 @@\n-class ShenandoahConcurrentMark;\n-class ShenandoahMarkCompact;\n@@ -62,1 +59,0 @@\n-class ShenandoahReferenceProcessor;\n@@ -64,0 +60,1 @@\n+class ShenandoahReferenceProcessor;\n@@ -391,0 +388,1 @@\n+  void entry_mark_roots();\n@@ -416,0 +414,1 @@\n+  void op_mark_roots();\n@@ -439,0 +438,4 @@\n+\/\/ Helpers\n+  void finish_mark();\n+  void prepare_evacuation();\n+\n@@ -441,0 +444,1 @@\n+\/\/ Mark support\n@@ -447,2 +451,0 @@\n-  ShenandoahConcurrentMark*  _scm;\n-  ShenandoahMarkCompact*     _full_gc;\n@@ -455,1 +457,0 @@\n-  ShenandoahMarkCompact*     full_gc()                 { return _full_gc;           }\n@@ -462,1 +463,0 @@\n-  ShenandoahConcurrentMark*  concurrent_mark()         { return _scm;               }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -0,0 +1,201 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shared\/gcTrace.hpp\"\n+#include \"gc\/shared\/referenceProcessorPhaseTimes.hpp\"\n+#include \"gc\/shenandoah\/shenandoahBarrierSet.hpp\"\n+#include \"gc\/shenandoah\/shenandoahClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOopClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahUtils.hpp\"\n+#include \"gc\/shenandoah\/shenandoahVerifier.hpp\"\n+\n+#include \"memory\/iterator.inline.hpp\"\n+\n+ShenandoahMarkRefsSuperClosure::ShenandoahMarkRefsSuperClosure(ShenandoahObjToScanQueue* q,  ShenandoahReferenceProcessor* rp) :\n+  MetadataVisitingOopIterateClosure(rp),\n+  _queue(q),\n+  _heap(ShenandoahHeap::heap()),\n+  _mark_context(_heap->marking_context()),\n+  _weak(false)\n+{ }\n+\n+ShenandoahInitMarkRootsClosure::ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q) :\n+  _queue(q),\n+  _heap(ShenandoahHeap::heap()),\n+  _mark_context(_heap->marking_context()) {\n+}\n+\n+ShenandoahMark::ShenandoahMark() :\n+  _heap(ShenandoahHeap::heap()),\n+  _task_queues(_heap->marking_context()->task_queues()) {\n+}\n+\n+void ShenandoahMark::clear() {\n+  \/\/ Clean up marking stacks.\n+  ShenandoahObjToScanQueueSet* queues = ShenandoahHeap::heap()->marking_context()->task_queues();\n+  queues->clear();\n+\n+  \/\/ Cancel SATB buffers.\n+  ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();\n+}\n+\n+template <bool CANCELLABLE>\n+void ShenandoahMark::mark_loop_prework(uint w, TaskTerminator *t, ShenandoahReferenceProcessor *rp,\n+                                       bool strdedup) {\n+  ShenandoahObjToScanQueue* q = get_queue(w);\n+\n+  ShenandoahLiveData* ld = _heap->get_liveness_cache(w);\n+\n+  \/\/ TODO: We can clean up this if we figure out how to do templated oop closures that\n+  \/\/ play nice with specialized_oop_iterators.\n+  if (_heap->unload_classes()) {\n+    if (_heap->has_forwarded_objects()) {\n+      if (strdedup) {\n+        ShenandoahMarkUpdateRefsMetadataDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkUpdateRefsMetadataClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    } else {\n+      if (strdedup) {\n+        ShenandoahMarkRefsMetadataDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkRefsMetadataClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    }\n+  } else {\n+    if (_heap->has_forwarded_objects()) {\n+      if (strdedup) {\n+        ShenandoahMarkUpdateRefsDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkUpdateRefsClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    } else {\n+      if (strdedup) {\n+        ShenandoahMarkRefsDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkRefsClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    }\n+  }\n+\n+  _heap->flush_liveness_cache(w);\n+}\n+\n+template <class T, bool CANCELLABLE>\n+void ShenandoahMark::mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *terminator) {\n+  uintx stride = ShenandoahMarkLoopStride;\n+\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  ShenandoahObjToScanQueueSet* queues = task_queues();\n+  ShenandoahObjToScanQueue* q;\n+  ShenandoahMarkTask t;\n+\n+  heap->ref_processor()->set_mark_closure(worker_id, cl);\n+\n+  \/*\n+   * Process outstanding queues, if any.\n+   *\n+   * There can be more queues than workers. To deal with the imbalance, we claim\n+   * extra queues first. Since marking can push new tasks into the queue associated\n+   * with this worker id, we come back to process this queue in the normal loop.\n+   *\/\n+  assert(queues->get_reserved() == heap->workers()->active_workers(),\n+         \"Need to reserve proper number of queues: reserved: %u, active: %u\", queues->get_reserved(), heap->workers()->active_workers());\n+\n+  q = queues->claim_next();\n+  while (q != NULL) {\n+    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n+      return;\n+    }\n+\n+    for (uint i = 0; i < stride; i++) {\n+      if (q->pop(t)) {\n+        do_task<T>(q, cl, live_data, &t);\n+      } else {\n+        assert(q->is_empty(), \"Must be empty\");\n+        q = queues->claim_next();\n+        break;\n+      }\n+    }\n+  }\n+  q = get_queue(worker_id);\n+\n+  ShenandoahSATBBufferClosure drain_satb(q);\n+  SATBMarkQueueSet& satb_mq_set = ShenandoahBarrierSet::satb_mark_queue_set();\n+\n+  \/*\n+   * Normal marking loop:\n+   *\/\n+  while (true) {\n+    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n+      return;\n+    }\n+\n+    while (satb_mq_set.completed_buffers_num() > 0) {\n+      satb_mq_set.apply_closure_to_completed_buffer(&drain_satb);\n+    }\n+\n+    uint work = 0;\n+    for (uint i = 0; i < stride; i++) {\n+      if (q->pop(t) ||\n+          queues->steal(worker_id, t)) {\n+        do_task<T>(q, cl, live_data, &t);\n+        work++;\n+      } else {\n+        break;\n+      }\n+    }\n+\n+    if (work == 0) {\n+      \/\/ No work encountered in current stride, try to terminate.\n+      \/\/ Need to leave the STS here otherwise it might block safepoints.\n+      ShenandoahSuspendibleThreadSetLeaver stsl(CANCELLABLE && ShenandoahSuspendibleWorkers);\n+      ShenandoahTerminatorTerminator tt(heap);\n+      if (terminator->offer_termination(&tt)) return;\n+    }\n+  }\n+}\n+\n+void ShenandoahMark::mark_loop(uint worker_id, TaskTerminator* terminator, ShenandoahReferenceProcessor *rp,\n+               bool cancellable, bool strdedup) {\n+  if (cancellable) {\n+    mark_loop_prework<true>(worker_id, terminator, rp, strdedup);\n+  } else {\n+    mark_loop_prework<false>(worker_id, terminator, rp, strdedup);\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.cpp","additions":201,"deletions":0,"binary":false,"changes":201,"status":"added"},{"patch":"@@ -0,0 +1,101 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHMARK_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHMARK_HPP\n+\n+#include \"gc\/shared\/taskTerminator.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOopClosures.hpp\"\n+#include \"gc\/shenandoah\/shenandoahPhaseTimings.hpp\"\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.hpp\"\n+\n+class ShenandoahCMDrainMarkingStackClosure;\n+\n+class ShenandoahInitMarkRootsClosure : public OopClosure {\n+private:\n+  ShenandoahObjToScanQueue* const _queue;\n+  ShenandoahHeap*           const _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+\n+  template <class T>\n+  inline void do_oop_work(T* p);\n+\n+public:\n+  ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q);\n+\n+  void do_oop(narrowOop* p) { do_oop_work(p); }\n+  void do_oop(oop* p)       { do_oop_work(p); }\n+};\n+\n+\/\/ Base class for mark\n+\/\/ Mark class does not maintain states. Instead, mark states are\n+\/\/ maintained by task queues, mark bitmap and SATB buffers (concurrent mark)\n+class ShenandoahMark: public StackObj {\n+  friend class ShenandoahCMDrainMarkingStackClosure;\n+\n+protected:\n+  ShenandoahHeap* const              _heap;\n+  ShenandoahObjToScanQueueSet* const _task_queues;\n+\n+protected:\n+  ShenandoahMark();\n+\n+public:\n+  template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n+  static inline void mark_through_ref(T* p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context, bool weak);\n+\n+  static void clear();\n+\n+  \/\/ Helpers\n+  inline ShenandoahObjToScanQueueSet* task_queues() const;\n+  inline ShenandoahObjToScanQueue* get_queue(uint index) const;\n+\n+\/\/ ---------- Marking loop and tasks\n+private:\n+  template <class T>\n+  inline void do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task);\n+\n+  template <class T>\n+  inline void do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop array, bool weak);\n+\n+  template <class T>\n+  inline void do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop array, int chunk, int pow, bool weak);\n+\n+  inline void count_liveness(ShenandoahLiveData* live_data, oop obj);\n+\n+  template <class T, bool CANCELLABLE>\n+  void mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *t);\n+\n+  template <bool CANCELLABLE>\n+  void mark_loop_prework(uint worker_id, TaskTerminator *terminator, ShenandoahReferenceProcessor *rp, bool strdedup);\n+\n+protected:\n+  void mark_loop(uint worker_id, TaskTerminator* terminator, ShenandoahReferenceProcessor *rp,\n+                 bool cancellable, bool strdedup);\n+\n+  inline ShenandoahHeap* heap() const;\n+};\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHMARK_HPP\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.hpp","additions":101,"deletions":0,"binary":false,"changes":101,"status":"added"},{"patch":"@@ -0,0 +1,302 @@\n+\/*\n+ * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHMARK_INLINE_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHMARK_INLINE_HPP\n+\n+#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n+#include \"gc\/shenandoah\/shenandoahBarrierSet.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMarkingContext.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahStringDedup.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.inline.hpp\"\n+#include \"memory\/iterator.inline.hpp\"\n+#include \"oops\/compressedOops.inline.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/prefetch.inline.hpp\"\n+\n+template <class T>\n+void ShenandoahInitMarkRootsClosure::do_oop_work(T* p) {\n+  ShenandoahMark::mark_through_ref<T, NONE, NO_DEDUP>(p, _heap, _queue, _mark_context, false);\n+}\n+\n+template <class T>\n+void ShenandoahMark::do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task) {\n+  oop obj = task->obj();\n+\n+  shenandoah_assert_not_forwarded(NULL, obj);\n+  shenandoah_assert_marked(NULL, obj);\n+  shenandoah_assert_not_in_cset_except(NULL, obj, _heap->cancelled_gc());\n+\n+  \/\/ Are we in weak subgraph scan?\n+  bool weak = task->is_weak();\n+  cl->set_weak(weak);\n+\n+  if (task->is_not_chunked()) {\n+    if (obj->is_instance()) {\n+      \/\/ Case 1: Normal oop, process as usual.\n+      obj->oop_iterate(cl);\n+    } else if (obj->is_objArray()) {\n+      \/\/ Case 2: Object array instance and no chunk is set. Must be the first\n+      \/\/ time we visit it, start the chunked processing.\n+      do_chunked_array_start<T>(q, cl, obj, weak);\n+    } else {\n+      \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n+      \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n+      \/\/ We skip iterating over the klass pointer since we know that\n+      \/\/ Universe::TypeArrayKlass never moves.\n+      assert (obj->is_typeArray(), \"should be type array\");\n+    }\n+    \/\/ Count liveness the last: push the outstanding work to the queues first\n+    \/\/ Avoid double-counting objects that are visited twice due to upgrade\n+    \/\/ from final- to strong mark.\n+    if (task->count_liveness()) {\n+      count_liveness(live_data, obj);\n+    }\n+  } else {\n+    \/\/ Case 4: Array chunk, has sensible chunk id. Process it.\n+    do_chunked_array<T>(q, cl, obj, task->chunk(), task->pow(), weak);\n+  }\n+}\n+\n+inline void ShenandoahMark::count_liveness(ShenandoahLiveData* live_data, oop obj) {\n+  size_t region_idx = _heap->heap_region_index_containing(obj);\n+  ShenandoahHeapRegion* region = _heap->get_region(region_idx);\n+  size_t size = obj->size();\n+\n+  if (!region->is_humongous_start()) {\n+    assert(!region->is_humongous(), \"Cannot have continuations here\");\n+    ShenandoahLiveData cur = live_data[region_idx];\n+    size_t new_val = size + cur;\n+    if (new_val >= SHENANDOAH_LIVEDATA_MAX) {\n+      \/\/ overflow, flush to region data\n+      region->increase_live_data_gc_words(new_val);\n+      live_data[region_idx] = 0;\n+    } else {\n+      \/\/ still good, remember in locals\n+      live_data[region_idx] = (ShenandoahLiveData) new_val;\n+    }\n+  } else {\n+    shenandoah_assert_in_correct_region(NULL, obj);\n+    size_t num_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);\n+\n+    for (size_t i = region_idx; i < region_idx + num_regions; i++) {\n+      ShenandoahHeapRegion* chain_reg = _heap->get_region(i);\n+      assert(chain_reg->is_humongous(), \"Expecting a humongous region\");\n+      chain_reg->increase_live_data_gc_words(chain_reg->used() >> LogHeapWordSize);\n+    }\n+  }\n+}\n+\n+template <class T>\n+inline void ShenandoahMark::do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop obj, bool weak) {\n+  assert(obj->is_objArray(), \"expect object array\");\n+  objArrayOop array = objArrayOop(obj);\n+  int len = array->length();\n+\n+  if (len <= (int) ObjArrayMarkingStride*2) {\n+    \/\/ A few slices only, process directly\n+    array->oop_iterate_range(cl, 0, len);\n+  } else {\n+    int bits = log2_long((size_t) len);\n+    \/\/ Compensate for non-power-of-two arrays, cover the array in excess:\n+    if (len != (1 << bits)) bits++;\n+\n+    \/\/ Only allow full chunks on the queue. This frees do_chunked_array() from checking from\/to\n+    \/\/ boundaries against array->length(), touching the array header on every chunk.\n+    \/\/\n+    \/\/ To do this, we cut the prefix in full-sized chunks, and submit them on the queue.\n+    \/\/ If the array is not divided in chunk sizes, then there would be an irregular tail,\n+    \/\/ which we will process separately.\n+\n+    int last_idx = 0;\n+\n+    int chunk = 1;\n+    int pow = bits;\n+\n+    \/\/ Handle overflow\n+    if (pow >= 31) {\n+      assert (pow == 31, \"sanity\");\n+      pow--;\n+      chunk = 2;\n+      last_idx = (1 << pow);\n+      bool pushed = q->push(ShenandoahMarkTask(array, true, weak, 1, pow));\n+      assert(pushed, \"overflow queue should always succeed pushing\");\n+    }\n+\n+    \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Record the last\n+    \/\/ successful right boundary to figure out the irregular tail.\n+    while ((1 << pow) > (int)ObjArrayMarkingStride &&\n+           (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n+      pow--;\n+      int left_chunk = chunk*2 - 1;\n+      int right_chunk = chunk*2;\n+      int left_chunk_end = left_chunk * (1 << pow);\n+      if (left_chunk_end < len) {\n+        bool pushed = q->push(ShenandoahMarkTask(array, true, weak, left_chunk, pow));\n+        assert(pushed, \"overflow queue should always succeed pushing\");\n+        chunk = right_chunk;\n+        last_idx = left_chunk_end;\n+      } else {\n+        chunk = left_chunk;\n+      }\n+    }\n+\n+    \/\/ Process the irregular tail, if present\n+    int from = last_idx;\n+    if (from < len) {\n+      array->oop_iterate_range(cl, from, len);\n+    }\n+  }\n+}\n+\n+template <class T>\n+inline void ShenandoahMark::do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop obj, int chunk, int pow, bool weak) {\n+  assert(obj->is_objArray(), \"expect object array\");\n+  objArrayOop array = objArrayOop(obj);\n+\n+  assert (ObjArrayMarkingStride > 0, \"sanity\");\n+\n+  \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Avoid pushing tasks that\n+  \/\/ are known to start beyond the array.\n+  while ((1 << pow) > (int)ObjArrayMarkingStride && (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n+    pow--;\n+    chunk *= 2;\n+    bool pushed = q->push(ShenandoahMarkTask(array, true, weak, chunk - 1, pow));\n+    assert(pushed, \"overflow queue should always succeed pushing\");\n+  }\n+\n+  int chunk_size = 1 << pow;\n+\n+  int from = (chunk - 1) * chunk_size;\n+  int to = chunk * chunk_size;\n+\n+#ifdef ASSERT\n+  int len = array->length();\n+  assert (0 <= from && from < len, \"from is sane: %d\/%d\", from, len);\n+  assert (0 < to && to <= len, \"to is sane: %d\/%d\", to, len);\n+#endif\n+\n+  array->oop_iterate_range(cl, from, to);\n+}\n+\n+class ShenandoahSATBBufferClosure : public SATBBufferClosure {\n+private:\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+public:\n+  ShenandoahSATBBufferClosure(ShenandoahObjToScanQueue* q) :\n+    _queue(q),\n+    _heap(ShenandoahHeap::heap()),\n+    _mark_context(_heap->marking_context())\n+  {\n+  }\n+\n+  void do_buffer(void **buffer, size_t size) {\n+    assert(size == 0 || !_heap->has_forwarded_objects(), \"Forwarded objects are not expected here\");\n+    if (ShenandoahStringDedup::is_enabled()) {\n+      do_buffer_impl<ENQUEUE_DEDUP>(buffer, size);\n+    } else {\n+      do_buffer_impl<NO_DEDUP>(buffer, size);\n+    }\n+  }\n+\n+  template<StringDedupMode STRING_DEDUP>\n+  void do_buffer_impl(void **buffer, size_t size) {\n+    for (size_t i = 0; i < size; ++i) {\n+      oop *p = (oop *) &buffer[i];\n+      ShenandoahMark::mark_through_ref<oop, NONE, STRING_DEDUP>(p, _heap, _queue, _mark_context, false);\n+    }\n+  }\n+};\n+\n+template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n+inline void ShenandoahMark::mark_through_ref(T *p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context, bool weak) {\n+  T o = RawAccess<>::oop_load(p);\n+  if (!CompressedOops::is_null(o)) {\n+    oop obj = CompressedOops::decode_not_null(o);\n+    switch (UPDATE_REFS) {\n+    case NONE:\n+      break;\n+    case RESOLVE:\n+      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n+      break;\n+    case SIMPLE:\n+      \/\/ We piggy-back reference updating to the marking tasks.\n+      obj = heap->update_with_forwarded_not_null(p, obj);\n+      break;\n+    case CONCURRENT:\n+      obj = heap->maybe_update_with_forwarded_not_null(p, obj);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n+    \/\/ Note: Only when concurrently updating references can obj be different\n+    \/\/ (that is, really different, not just different from-\/to-space copies of the same)\n+    \/\/ from the one we originally loaded. Mutator thread can beat us by writing something\n+    \/\/ else into the location. In that case, we would mark through that updated value,\n+    \/\/ on the off-chance it is not handled by other means (e.g. via SATB). However,\n+    \/\/ if that write was NULL, we don't need to do anything else.\n+    if (UPDATE_REFS != CONCURRENT || !CompressedOops::is_null(obj)) {\n+      shenandoah_assert_not_forwarded(p, obj);\n+      shenandoah_assert_not_in_cset_except(p, obj, heap->cancelled_gc());\n+\n+      bool skip_live = false;\n+      bool marked;\n+      if (weak) {\n+        marked = mark_context->mark_weak(obj);\n+      } else {\n+        marked = mark_context->mark_strong(obj, \/* was_upgraded = *\/ skip_live);\n+      }\n+      if (marked) {\n+        bool pushed = q->push(ShenandoahMarkTask(obj, skip_live, weak));\n+        assert(pushed, \"overflow queue should always succeed pushing\");\n+\n+        if ((STRING_DEDUP == ENQUEUE_DEDUP) && ShenandoahStringDedup::is_candidate(obj)) {\n+          assert(ShenandoahStringDedup::is_enabled(), \"Must be enabled\");\n+          ShenandoahStringDedup::enqueue_candidate(obj);\n+        }\n+      }\n+\n+      shenandoah_assert_marked(p, obj);\n+    }\n+  }\n+}\n+\n+ShenandoahObjToScanQueueSet* ShenandoahMark::task_queues() const {\n+  return _task_queues;\n+}\n+\n+ShenandoahObjToScanQueue* ShenandoahMark::get_queue(uint index) const {\n+  return _task_queues->queue(index);\n+}\n+\n+ShenandoahHeap* ShenandoahMark::heap() const {\n+  return _heap;\n+}\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHMARK_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.inline.hpp","additions":302,"deletions":0,"binary":false,"changes":302,"status":"added"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -36,0 +36,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -43,0 +44,1 @@\n+#include \"gc\/shenandoah\/shenandoahSTWMark.hpp\"\n@@ -117,1 +119,1 @@\n-      heap->concurrent_mark()->cancel();\n+      ShenandoahConcurrentMark::cancel();\n@@ -124,1 +126,1 @@\n-      heap->concurrent_mark()->update_roots(ShenandoahPhaseTimings::full_gc_update_roots);\n+      ShenandoahConcurrentMark::update_roots(ShenandoahPhaseTimings::full_gc_update_roots);\n@@ -241,2 +243,0 @@\n-  ShenandoahConcurrentMark* cm = heap->concurrent_mark();\n-\n@@ -249,4 +249,7 @@\n-  cm->mark_roots(ShenandoahPhaseTimings::full_gc_scan_roots);\n-  cm->finish_mark_from_roots(\/* full_gc = *\/ true);\n-  heap->mark_complete_marking_context();\n-  rp->process_references(heap->workers(), false \/* concurrent *\/);\n+\n+  ShenandoahSTWMark mark(true \/*full_gc*\/);\n+  mark.mark();\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::full_gc_weakrefs);\n+    rp->process_references(heap->workers(), false \/* concurrent *\/);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkCompact.cpp","additions":12,"deletions":9,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-class ShenandoahMarkCompact : public CHeapObj<mtGC> {\n+class ShenandoahMarkCompact : public StackObj {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkCompact.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -30,0 +30,2 @@\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.inline.hpp\"\n+#include \"utilities\/stack.inline.hpp\"\n@@ -31,1 +33,1 @@\n-ShenandoahMarkingContext::ShenandoahMarkingContext(MemRegion heap_region, MemRegion bitmap_region, size_t num_regions) :\n+ShenandoahMarkingContext::ShenandoahMarkingContext(MemRegion heap_region, MemRegion bitmap_region, size_t num_regions, uint max_queues) :\n@@ -36,1 +38,15 @@\n-                      ((uintx) heap_region.start() >> ShenandoahHeapRegion::region_size_bytes_shift())) {\n+                      ((uintx) heap_region.start() >> ShenandoahHeapRegion::region_size_bytes_shift())),\n+  _task_queues(new ShenandoahObjToScanQueueSet(max_queues)) {\n+  for (uint i = 0; i < max_queues; ++i) {\n+    ShenandoahObjToScanQueue* task_queue = new ShenandoahObjToScanQueue();\n+    task_queue->initialize();\n+    _task_queues->register_queue(i, task_queue);\n+  }\n+}\n+\n+ShenandoahMarkingContext::~ShenandoahMarkingContext() {\n+  for (uint i = 0; i < _task_queues->size(); ++i) {\n+    ShenandoahObjToScanQueue* q = _task_queues->queue(i);\n+    delete q;\n+  }\n+  delete _task_queues;\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.cpp","additions":18,"deletions":2,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -34,0 +34,2 @@\n+class ShenandoahObjToScanQueueSet;\n+\n@@ -39,0 +41,1 @@\n+  \/\/ Marking bitmap\n@@ -47,0 +50,3 @@\n+  \/\/ Marking task queues\n+  ShenandoahObjToScanQueueSet* _task_queues;\n+\n@@ -48,1 +54,2 @@\n-  ShenandoahMarkingContext(MemRegion heap_region, MemRegion bitmap_region, size_t num_regions);\n+  ShenandoahMarkingContext(MemRegion heap_region, MemRegion bitmap_region, size_t num_regions, uint max_queues);\n+  ~ShenandoahMarkingContext();\n@@ -83,0 +90,2 @@\n+  \/\/ Task queues\n+  ShenandoahObjToScanQueueSet* task_queues() const { return _task_queues; }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkingContext.hpp","additions":10,"deletions":1,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -33,1 +33,1 @@\n-  ShenandoahConcurrentMark::mark_through_ref<T, UPDATE_REFS, STRING_DEDUP>(p, _heap, _queue, _mark_context, _weak);\n+  ShenandoahMark::mark_through_ref<T, UPDATE_REFS, STRING_DEDUP>(p, _heap, _queue, _mark_context, _weak);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOopClosures.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -103,1 +103,1 @@\n-    case full_gc_scan_roots:\n+    case full_gc_mark:\n@@ -106,1 +106,2 @@\n-    case degen_gc_scan_conc_roots:\n+    case degen_gc_stw_mark:\n+    case degen_gc_mark:\n@@ -108,1 +109,0 @@\n-    case full_gc_scan_conc_roots:\n@@ -131,1 +131,1 @@\n-    case full_gc_scan_roots:\n+    case full_gc_mark:\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -46,0 +46,1 @@\n+  f(CNT_PREFIX ## ParallelMark,             DESC_PREFIX \"Parallel Mark\")               \\\n@@ -119,8 +120,12 @@\n-  f(degen_gc_scan_conc_roots,                       \"  Degen Mark Roots\")              \\\n-  SHENANDOAH_PAR_PHASE_DO(degen_gc_conc_mark_,      \"    DM: \", f)                     \\\n-  f(degen_gc_purge,                                  \"   System Purge\")                \\\n-  f(degen_gc_purge_class_unload,                     \"     Unload Classes\")            \\\n-  SHENANDOAH_PAR_PHASE_DO(degen_gc_purge_cu_par_,    \"       DCU: \", f)                \\\n-  f(degen_gc_purge_weak_par,                         \"     Weak Roots\")                \\\n-  SHENANDOAH_PAR_PHASE_DO(degen_gc_purge_weak_p_,    \"       DWR: \", f)                \\\n-  f(degen_gc_purge_cldg,                             \"     CLDG\")                      \\\n+  f(degen_gc_stw_mark,                              \"  Degen STW Mark\")                \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_stw_mark_,       \"    DSM: \", f)                    \\\n+  f(degen_gc_mark,                                  \"  Degen Mark\")                    \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_mark_,           \"    DM: \", f)                     \\\n+  f(degen_gc_purge,                                 \"    System Purge\")                \\\n+  f(degen_gc_purge_class_unload,                    \"      Unload Classes\")            \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_purge_cu_par_,   \"        DCU: \", f)                \\\n+  f(degen_gc_weakrefs,                              \"  Weak References\")               \\\n+  f(degen_gc_weakrefs_process,                      \"   Process\")                      \\\n+  f(degen_gc_purge_weak_par,                        \"     Weak Roots\")                 \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_purge_weak_p_,   \"       DWR: \", f)                \\\n+  f(degen_gc_purge_cldg,                            \"     CLDG\")                      \\\n@@ -136,4 +141,0 @@\n-  f(full_gc_scan_roots,                             \"  Scan Roots\")                    \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_scan_roots_,      \"    FS: \", f)                     \\\n-  f(full_gc_scan_conc_roots,                        \"  Scan Concurrent Roots\")         \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_scan_conc_roots,  \"    FCS: \", f)                    \\\n@@ -141,1 +142,1 @@\n-  f(full_gc_mark_finish_queues,                     \"    Finish Queues\")               \\\n+  SHENANDOAH_PAR_PHASE_DO(full_gc_mark_,            \"    FM: \", f)                     \\\n@@ -143,1 +144,0 @@\n-  f(full_gc_weakrefs_process,                       \"      Process\")                   \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.hpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -134,1 +134,0 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Must at safepoint\");\n@@ -160,0 +159,47 @@\n+ShenandoahSTWRootScanner::ShenandoahSTWRootScanner(ShenandoahPhaseTimings::Phase phase) :\n+   ShenandoahRootProcessor(phase),\n+   _thread_roots(phase, ShenandoahHeap::heap()->workers()->active_workers() > 1),\n+   _code_roots(phase),\n+   _cld_roots(phase, ShenandoahHeap::heap()->workers()->active_workers()),\n+   _vm_roots(phase),\n+   _dedup_roots(phase),\n+   _unload_classes(ShenandoahHeap::heap()->unload_classes()) {\n+}\n+\n+ShenandoahConcurrentRootScanner::ShenandoahConcurrentRootScanner(uint n_workers,\n+                                                                 ShenandoahPhaseTimings::Phase phase) :\n+   ShenandoahRootProcessor(phase),\n+  _vm_roots(phase),\n+  _cld_roots(phase, n_workers),\n+  _codecache_snapshot(NULL),\n+  _phase(phase) {\n+  if (!ShenandoahHeap::heap()->unload_classes()) {\n+    CodeCache_lock->lock_without_safepoint_check();\n+    _codecache_snapshot = ShenandoahCodeRoots::table()->snapshot_for_iteration();\n+  }\n+  assert(!ShenandoahHeap::heap()->has_forwarded_objects(), \"Not expecting forwarded pointers during concurrent marking\");\n+}\n+\n+ShenandoahConcurrentRootScanner::~ShenandoahConcurrentRootScanner() {\n+  if (!ShenandoahHeap::heap()->unload_classes()) {\n+    ShenandoahCodeRoots::table()->finish_iteration(_codecache_snapshot);\n+    CodeCache_lock->unlock();\n+  }\n+}\n+\n+void ShenandoahConcurrentRootScanner::roots_do(OopClosure* oops, uint worker_id) {\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  CLDToOopClosure clds_cl(oops, ClassLoaderData::_claim_strong);\n+  _vm_roots.oops_do(oops, worker_id);\n+\n+  if (!heap->unload_classes()) {\n+    AlwaysTrueClosure always_true;\n+    _cld_roots.cld_do(&clds_cl, worker_id);\n+    ShenandoahWorkerTimingsTracker timer(_phase, ShenandoahPhaseTimings::CodeCacheRoots, worker_id);\n+    CodeBlobToOopClosure blobs(oops, !CodeBlobToOopClosure::FixRelocations);\n+    _codecache_snapshot->parallel_blobs_do(&blobs);\n+  } else {\n+    _cld_roots.always_strong_cld_do(&clds_cl, worker_id);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.cpp","additions":47,"deletions":1,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -166,2 +166,19 @@\n-template <bool CONCURRENT>\n-class ShenandoahConcurrentRootScanner {\n+\/\/ STW root scanner\n+class ShenandoahSTWRootScanner : public ShenandoahRootProcessor {\n+private:\n+  ShenandoahThreadRoots           _thread_roots;\n+  ShenandoahCodeCacheRoots        _code_roots;\n+  ShenandoahClassLoaderDataRoots<false \/*concurrent*\/, false \/* single_thread*\/>\n+                                  _cld_roots;\n+  ShenandoahVMRoots<false \/*concurrent*\/>\n+                                  _vm_roots;\n+  ShenandoahStringDedupRoots      _dedup_roots;\n+  const bool                      _unload_classes;\n+public:\n+  ShenandoahSTWRootScanner(ShenandoahPhaseTimings::Phase phase);\n+\n+  template <typename T>\n+  void roots_do(T* oops, uint worker_id);\n+};\n+\n+class ShenandoahConcurrentRootScanner : public ShenandoahRootProcessor {\n@@ -169,2 +186,2 @@\n-  ShenandoahVMRoots<CONCURRENT>            _vm_roots;\n-  ShenandoahClassLoaderDataRoots<CONCURRENT, false \/* single-threaded*\/>\n+  ShenandoahVMRoots<true \/*concurrent*\/>    _vm_roots;\n+  ShenandoahClassLoaderDataRoots<true \/*concurrent*\/, false \/* single-threaded*\/>\n@@ -179,1 +196,1 @@\n-  void oops_do(OopClosure* oops, uint worker_id);\n+  void roots_do(OopClosure* oops, uint worker_id);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.hpp","additions":22,"deletions":5,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -119,1 +119,0 @@\n-\n@@ -147,39 +146,18 @@\n-template <bool CONCURRENT>\n-ShenandoahConcurrentRootScanner<CONCURRENT>::ShenandoahConcurrentRootScanner(uint n_workers,\n-                                                                             ShenandoahPhaseTimings::Phase phase) :\n-  _vm_roots(phase),\n-  _cld_roots(phase, n_workers),\n-  _codecache_snapshot(NULL),\n-  _phase(phase) {\n-  if (!ShenandoahHeap::heap()->unload_classes()) {\n-    if (CONCURRENT) {\n-      CodeCache_lock->lock_without_safepoint_check();\n-    } else {\n-      assert(SafepointSynchronize::is_at_safepoint(), \"Must be at a safepoint\");\n-    }\n-    _codecache_snapshot = ShenandoahCodeRoots::table()->snapshot_for_iteration();\n-  }\n-  assert(!CONCURRENT || !ShenandoahHeap::heap()->has_forwarded_objects(), \"Not expecting forwarded pointers during concurrent marking\");\n-}\n-\n-template <bool CONCURRENT>\n-ShenandoahConcurrentRootScanner<CONCURRENT>::~ShenandoahConcurrentRootScanner() {\n-  if (!ShenandoahHeap::heap()->unload_classes()) {\n-    ShenandoahCodeRoots::table()->finish_iteration(_codecache_snapshot);\n-    if (CONCURRENT) {\n-      CodeCache_lock->unlock();\n-    }\n-  }\n-}\n-\n-template <bool CONCURRENT>\n-void ShenandoahConcurrentRootScanner<CONCURRENT>::oops_do(OopClosure* oops, uint worker_id) {\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-  CLDToOopClosure clds_cl(oops, CONCURRENT ? ClassLoaderData::_claim_strong : ClassLoaderData::_claim_none);\n-  _vm_roots.oops_do(oops, worker_id);\n-\n-  if (!heap->unload_classes()) {\n-    _cld_roots.cld_do(&clds_cl, worker_id);\n-    ShenandoahWorkerTimingsTracker timer(_phase, ShenandoahPhaseTimings::CodeCacheRoots, worker_id);\n-    CodeBlobToOopClosure blobs(oops, !CodeBlobToOopClosure::FixRelocations);\n-    _codecache_snapshot->parallel_blobs_do(&blobs);\n+\/\/ The rationale for selecting the roots to scan is as follows:\n+\/\/   a. With unload_classes = true, we only want to scan the actual strong roots from the\n+\/\/      code cache. This will allow us to identify the dead classes, unload them, *and*\n+\/\/      invalidate the relevant code cache blobs. This could be only done together with\n+\/\/      class unloading.\n+\/\/   b. With unload_classes = false, we have to nominally retain all the references from code\n+\/\/      cache, because there could be the case of embedded class\/oop in the generated code,\n+\/\/      which we will never visit during mark. Without code cache invalidation, as in (a),\n+\/\/      we risk executing that code cache blob, and crashing.\n+template <typename T>\n+void ShenandoahSTWRootScanner::roots_do(T* oops, uint worker_id) {\n+  MarkingCodeBlobClosure blobs_cl(oops, !CodeBlobToOopClosure::FixRelocations);\n+  CLDToOopClosure clds(oops, ClassLoaderData::_claim_strong);\n+  ResourceMark rm;\n+\n+  if (_unload_classes) {\n+    _thread_roots.oops_do(oops, &blobs_cl, worker_id);\n+    _cld_roots.always_strong_cld_do(&clds, worker_id);\n@@ -187,1 +165,5 @@\n-    _cld_roots.always_strong_cld_do(&clds_cl, worker_id);\n+    AlwaysTrueClosure always_true;\n+    _thread_roots.oops_do(oops, NULL, worker_id);\n+    _code_roots.code_blobs_do(&blobs_cl, worker_id);\n+    _cld_roots.cld_do(&clds, worker_id);\n+    _dedup_roots.oops_do(&always_true, oops, worker_id);\n@@ -189,0 +171,2 @@\n+\n+  _vm_roots.oops_do<T>(oops, worker_id);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.inline.hpp","additions":25,"deletions":41,"binary":false,"changes":66,"status":"modified"},{"patch":"@@ -0,0 +1,113 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shared\/strongRootsScope.hpp\"\n+#include \"gc\/shared\/workgroup.hpp\"\n+#include \"gc\/shenandoah\/shenandoahClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahReferenceProcessor.hpp\"\n+#include \"gc\/shenandoah\/shenandoahRootProcessor.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahSTWMark.hpp\"\n+#include \"gc\/shenandoah\/shenandoahVerifier.hpp\"\n+\n+\n+class ShenandoahSTWMarkTask : public AbstractGangTask {\n+private:\n+  ShenandoahSTWMark* const _mark;\n+\n+public:\n+  ShenandoahSTWMarkTask(ShenandoahSTWMark* mark);\n+  void work(uint worker_id);\n+};\n+\n+ShenandoahSTWMarkTask::ShenandoahSTWMarkTask(ShenandoahSTWMark* mark) :\n+  AbstractGangTask(\"Shenandoah STW mark\"),\n+  _mark(mark) {\n+}\n+\n+void ShenandoahSTWMarkTask::work(uint worker_id) {\n+  ShenandoahParallelWorkerSession worker_session(worker_id);\n+  _mark->mark_roots(worker_id);\n+  _mark->finish_mark(worker_id);\n+}\n+\n+ShenandoahSTWMark::ShenandoahSTWMark(bool full_gc) :\n+  ShenandoahMark(),\n+  _root_scanner(full_gc ? ShenandoahPhaseTimings::full_gc_mark : ShenandoahPhaseTimings::degen_gc_stw_mark),\n+  _terminator(ShenandoahHeap::heap()->workers()->active_workers(), ShenandoahHeap::heap()->marking_context()->task_queues()),\n+  _full_gc(full_gc) {\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a Shenandoah safepoint\");\n+}\n+\n+void ShenandoahSTWMark::mark() {\n+  \/\/ Weak reference processing\n+  ShenandoahReferenceProcessor* rp = heap()->ref_processor();\n+  rp->reset_thread_locals();\n+  rp->set_soft_reference_policy(heap()->soft_ref_policy()->should_clear_all_soft_refs());\n+\n+  \/\/ Init mark, do not expect forwarded pointers in roots\n+  if (ShenandoahVerify) {\n+    assert(Thread::current()->is_VM_thread(), \"Must be\");\n+    heap()->verifier()->verify_roots_no_forwarded();\n+  }\n+\n+  uint nworkers = heap()->workers()->active_workers();\n+  task_queues()->reserve(nworkers);\n+\n+\n+  {\n+    \/\/ Mark\n+    StrongRootsScope scope(nworkers);\n+    ShenandoahSTWMarkTask task(this);\n+    heap()->workers()->run_task(&task);\n+\n+    assert(task_queues()->is_empty(), \"Should be empty\");\n+  }\n+\n+  heap()->mark_complete_marking_context();\n+\n+  assert(task_queues()->is_empty(), \"Should be empty\");\n+  TASKQUEUE_STATS_ONLY(task_queues()->print_taskqueue_stats());\n+  TASKQUEUE_STATS_ONLY(task_queues()->reset_taskqueue_stats());\n+\n+}\n+\n+void ShenandoahSTWMark::mark_roots(uint worker_id) {\n+  ShenandoahInitMarkRootsClosure  init_mark(task_queues()->queue(worker_id));\n+  _root_scanner.roots_do(&init_mark, worker_id);\n+}\n+\n+void ShenandoahSTWMark::finish_mark(uint worker_id) {\n+  ShenandoahPhaseTimings::Phase phase = _full_gc ? ShenandoahPhaseTimings::full_gc_mark : ShenandoahPhaseTimings::degen_gc_stw_mark;\n+  ShenandoahWorkerTimingsTracker timer(phase, ShenandoahPhaseTimings::ParallelMark, worker_id);\n+  ShenandoahReferenceProcessor* rp = heap()->ref_processor();\n+\n+  mark_loop(worker_id, &_terminator, rp,\n+            false, \/\/ not cancellable\n+            ShenandoahStringDedup::is_enabled());\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahSTWMark.cpp","additions":113,"deletions":0,"binary":false,"changes":113,"status":"added"},{"patch":"@@ -0,0 +1,51 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHSTWMARK_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHSTWMARK_HPP\n+\n+#include \"gc\/shared\/taskTerminator.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.hpp\"\n+#include \"gc\/shenandoah\/shenandoahRootProcessor.hpp\"\n+\n+class ShenandoahSTWMarkTask;\n+\n+class ShenandoahSTWMark : public ShenandoahMark {\n+  friend class ShenandoahSTWMarkTask;\n+\n+private:\n+  ShenandoahSTWRootScanner      _root_scanner;\n+  TaskTerminator                _terminator;\n+  bool                          _full_gc;\n+public:\n+ ShenandoahSTWMark(bool full_gc);\n+ void mark();\n+\n+private:\n+  void mark_roots(uint worker_id);\n+  void finish_mark(uint worker_id);\n+};\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHSTWMARK_HPP\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahSTWMark.hpp","additions":51,"deletions":0,"binary":false,"changes":51,"status":"added"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2013, 2020, Red Hat, Inc. All rights reserved.\n@@ -56,1 +56,1 @@\n-  VM_ShenandoahInitMark() : VM_ShenandoahOperation() {};\n+  VM_ShenandoahInitMark() : VM_ShenandoahOperation() {}\n@@ -64,1 +64,1 @@\n-  VM_ShenandoahFinalMarkStartEvac() : VM_ShenandoahOperation() {};\n+  VM_ShenandoahFinalMarkStartEvac() : VM_ShenandoahOperation() {}\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVMOperations.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"}]}