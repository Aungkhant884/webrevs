{"files":[{"patch":"@@ -40,2 +40,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahMarkCompact.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -43,0 +42,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -46,0 +46,1 @@\n+#include \"gc\/shenandoah\/shenandoahStringDedup.hpp\"\n@@ -55,58 +56,0 @@\n-template<UpdateRefsMode UPDATE_REFS>\n-class ShenandoahInitMarkRootsClosure : public OopClosure {\n-private:\n-  ShenandoahObjToScanQueue* _queue;\n-  ShenandoahHeap* _heap;\n-  ShenandoahMarkingContext* const _mark_context;\n-\n-  template <class T>\n-  inline void do_oop_work(T* p) {\n-    ShenandoahConcurrentMark::mark_through_ref<T, UPDATE_REFS, NO_DEDUP>(p, _heap, _queue, _mark_context);\n-  }\n-\n-public:\n-  ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q) :\n-    _queue(q),\n-    _heap(ShenandoahHeap::heap()),\n-    _mark_context(_heap->marking_context()) {};\n-\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-};\n-\n-ShenandoahMarkRefsSuperClosure::ShenandoahMarkRefsSuperClosure(ShenandoahObjToScanQueue* q, ReferenceProcessor* rp) :\n-  MetadataVisitingOopIterateClosure(rp),\n-  _queue(q),\n-  _heap(ShenandoahHeap::heap()),\n-  _mark_context(_heap->marking_context())\n-{ }\n-\n-template<UpdateRefsMode UPDATE_REFS>\n-class ShenandoahInitMarkRootsTask : public AbstractGangTask {\n-private:\n-  ShenandoahRootScanner* _rp;\n-public:\n-  ShenandoahInitMarkRootsTask(ShenandoahRootScanner* rp) :\n-    AbstractGangTask(\"Shenandoah Init Mark Roots\"),\n-    _rp(rp) {\n-  }\n-\n-  void work(uint worker_id) {\n-    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n-    ShenandoahParallelWorkerSession worker_session(worker_id);\n-\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-    ShenandoahObjToScanQueueSet* queues = heap->concurrent_mark()->task_queues();\n-    assert(queues->get_reserved() > worker_id, \"Queue has not been reserved for worker id: %d\", worker_id);\n-\n-    ShenandoahObjToScanQueue* q = queues->queue(worker_id);\n-\n-    ShenandoahInitMarkRootsClosure<UPDATE_REFS> mark_cl(q);\n-    do_work(heap, &mark_cl, worker_id);\n-  }\n-\n-private:\n-  void do_work(ShenandoahHeap* heap, OopClosure* oops, uint worker_id) {\n-    _rp->roots_do(worker_id, oops);\n-  }\n-};\n@@ -143,2 +86,2 @@\n-  ShenandoahConcurrentMark* _cm;\n-  TaskTerminator* _terminator;\n+  ShenandoahConcurrentMark* const _cm;\n+  TaskTerminator* const           _terminator;\n@@ -203,38 +146,0 @@\n-\/\/ Process concurrent roots at safepoints\n-template <typename T>\n-class ShenandoahProcessConcurrentRootsTask : public AbstractGangTask {\n-private:\n-  ShenandoahConcurrentRootScanner<false \/* concurrent *\/> _rs;\n-  ShenandoahConcurrentMark* const _cm;\n-  ReferenceProcessor*             _rp;\n-public:\n-\n-  ShenandoahProcessConcurrentRootsTask(ShenandoahConcurrentMark* cm,\n-                                       ShenandoahPhaseTimings::Phase phase,\n-                                       uint nworkers);\n-  void work(uint worker_id);\n-};\n-\n-template <typename T>\n-ShenandoahProcessConcurrentRootsTask<T>::ShenandoahProcessConcurrentRootsTask(ShenandoahConcurrentMark* cm,\n-                                                                              ShenandoahPhaseTimings::Phase phase,\n-                                                                              uint nworkers) :\n-  AbstractGangTask(\"Shenandoah Process Concurrent Roots\"),\n-  _rs(nworkers, phase),\n-  _cm(cm),\n-  _rp(NULL) {\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  if (heap->process_references()) {\n-    _rp = heap->ref_processor();\n-    shenandoah_assert_rp_isalive_installed();\n-  }\n-}\n-\n-template <typename T>\n-void ShenandoahProcessConcurrentRootsTask<T>::work(uint worker_id) {\n-  ShenandoahParallelWorkerSession worker_session(worker_id);\n-  ShenandoahObjToScanQueue* q = _cm->task_queues()->queue(worker_id);\n-  T cl(q, _rp);\n-  _rs.oops_do(&cl, worker_id);\n-}\n-\n@@ -301,3 +206,11 @@\n-void ShenandoahConcurrentMark::mark_roots(ShenandoahPhaseTimings::Phase root_phase) {\n-  assert(Thread::current()->is_VM_thread(), \"can only do this in VMThread\");\n-  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+class ShenandoahInitMarkRootsTask : public AbstractGangTask {\n+private:\n+  ShenandoahRootScanner              _root_scanner;\n+  ShenandoahObjToScanQueueSet* const _task_queues;\n+public:\n+  ShenandoahInitMarkRootsTask(uint n_workers, ShenandoahObjToScanQueueSet* task_queues) :\n+    AbstractGangTask(\"Shenandoah Init Mark Roots\"),\n+    _root_scanner(n_workers, ShenandoahPhaseTimings::scan_roots),\n+    _task_queues(task_queues) {\n+    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+  }\n@@ -305,1 +218,3 @@\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  void work(uint worker_id) {\n+    ShenandoahParallelWorkerSession worker_session(worker_id);\n+    assert(_task_queues->get_reserved() > worker_id, \"Queue has not been reserved for worker id: %d\", worker_id);\n@@ -307,1 +222,5 @@\n-  ShenandoahGCPhase phase(root_phase);\n+    ShenandoahObjToScanQueue* q = _task_queues->queue(worker_id);\n+    ShenandoahInitMarkRootsClosure mark_cl(q);\n+    _root_scanner.roots_do(worker_id, &mark_cl);\n+  }\n+};\n@@ -309,1 +228,11 @@\n-  WorkGang* workers = heap->workers();\n+ShenandoahConcurrentMark::ShenandoahConcurrentMark() :\n+  ShenandoahMark() {}\n+\n+void ShenandoahConcurrentMark::mark_stw_roots() {\n+  assert(Thread::current()->is_VM_thread(), \"Can only do this in VMThread\");\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+  assert(!_heap->has_forwarded_objects(), \"Not expected\");\n+\n+  ShenandoahGCPhase phase(ShenandoahPhaseTimings::scan_roots);\n+\n+  WorkGang* workers = ShenandoahHeap::heap()->workers();\n@@ -314,1 +243,0 @@\n-  ShenandoahRootScanner root_proc(nworkers, root_phase);\n@@ -318,9 +246,2 @@\n-  if (heap->has_forwarded_objects()) {\n-    ShenandoahInitMarkRootsTask<RESOLVE> mark_roots(&root_proc);\n-    workers->run_task(&mark_roots);\n-  } else {\n-    \/\/ No need to update references, which means the heap is stable.\n-    \/\/ Can save time not walking through forwarding pointers.\n-    ShenandoahInitMarkRootsTask<NONE> mark_roots(&root_proc);\n-    workers->run_task(&mark_roots);\n-  }\n+  ShenandoahInitMarkRootsTask mark_roots(nworkers, task_queues());\n+  workers->run_task(&mark_roots);\n@@ -343,1 +264,3 @@\n-  uint nworkers = _heap->workers()->active_workers();\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  WorkGang* workers = heap->workers();\n+  uint nworkers = workers->active_workers();\n@@ -347,1 +270,1 @@\n-  _heap->workers()->run_task(&update_roots);\n+  workers->run_task(&update_roots);\n@@ -381,2 +304,2 @@\n-\n-  WorkGang* workers = _heap->workers();\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  WorkGang* workers = heap->workers();\n@@ -393,14 +316,0 @@\n-void ShenandoahConcurrentMark::initialize(uint workers) {\n-  _heap = ShenandoahHeap::heap();\n-\n-  uint num_queues = MAX2(workers, 1U);\n-\n-  _task_queues = new ShenandoahObjToScanQueueSet((int) num_queues);\n-\n-  for (uint i = 0; i < num_queues; ++i) {\n-    ShenandoahObjToScanQueue* task_queue = new ShenandoahObjToScanQueue();\n-    task_queue->initialize();\n-    _task_queues->register_queue(i, task_queue);\n-  }\n-}\n-\n@@ -411,1 +320,1 @@\n-  ShenandoahConcurrentRootScanner<true \/* concurrent *\/> _rs;\n+  ShenandoahConcurrentRootScanner    _root_scanner;\n@@ -413,1 +322,0 @@\n-  ReferenceProcessor* const          _rp;\n@@ -417,2 +325,0 @@\n-                                    ReferenceProcessor* rp,\n-                                    ShenandoahPhaseTimings::Phase phase,\n@@ -424,2 +330,0 @@\n-                                                                     ReferenceProcessor* rp,\n-                                                                     ShenandoahPhaseTimings::Phase phase,\n@@ -428,3 +332,2 @@\n-  _rs(nworkers, phase),\n-  _queue_set(qs),\n-  _rp(rp) {\n+  _root_scanner(nworkers, ShenandoahPhaseTimings::conc_mark_roots),\n+  _queue_set(qs) {\n@@ -437,2 +340,2 @@\n-  ShenandoahMarkResolveRefsClosure cl(q, _rp);\n-  _rs.oops_do(&cl, worker_id);\n+  ShenandoahInitMarkRootsClosure cl(q);\n+  _root_scanner.roots_do(&cl, worker_id);\n@@ -441,2 +344,10 @@\n-void ShenandoahConcurrentMark::mark_from_roots() {\n-  WorkGang* workers = _heap->workers();\n+void ShenandoahConcurrentMark::mark_concurrent_roots() {\n+  assert(!_heap->has_forwarded_objects(), \"Not expected\");\n+\n+  WorkGang* workers = heap()->workers();\n+  ShenandoahMarkConcurrentRootsTask task(task_queues(), workers->active_workers());\n+  workers->run_task(&task);\n+}\n+\n+void ShenandoahConcurrentMark::concurrent_mark() {\n+  WorkGang* workers = heap()->workers();\n@@ -444,0 +355,2 @@\n+  task_queues()->reserve(nworkers);\n+  TaskTerminator terminator(nworkers, task_queues());\n@@ -446,2 +359,2 @@\n-  if (_heap->process_references()) {\n-    rp = _heap->ref_processor();\n+  if (heap()->process_references()) {\n+    rp = heap()->ref_processor();\n@@ -453,7 +366,0 @@\n-  }\n-\n-  shenandoah_assert_rp_isalive_not_installed();\n-  ShenandoahIsAliveSelector is_alive;\n-  ReferenceProcessorIsAliveMutator fix_isalive(_heap->ref_processor(), is_alive.is_alive_closure());\n-\n-  task_queues()->reserve(nworkers);\n@@ -461,4 +367,4 @@\n-  {\n-    ShenandoahGCPhase phase(ShenandoahPhaseTimings::conc_mark_roots);\n-    \/\/ Use separate task to mark concurrent roots, since it may hold ClassLoaderData_lock and CodeCache_lock\n-    ShenandoahMarkConcurrentRootsTask task(task_queues(), rp, ShenandoahPhaseTimings::conc_mark_roots, nworkers);\n+    shenandoah_assert_rp_isalive_not_installed();\n+    ShenandoahIsAliveSelector is_alive;\n+    ReferenceProcessorIsAliveMutator fix_isalive(rp, is_alive.is_alive_closure());\n+    ShenandoahConcurrentMarkingTask task(this, &terminator);\n@@ -466,4 +372,1 @@\n-  }\n-\n-  {\n-    TaskTerminator terminator(nworkers, task_queues());\n+  } else {\n@@ -473,2 +376,1 @@\n-\n-  assert(task_queues()->is_empty() || _heap->cancelled_gc(), \"Should be empty when not cancelled\");\n+  assert(task_queues()->is_empty() || heap()->cancelled_gc(), \"Should be empty when not cancelled\");\n@@ -477,1 +379,1 @@\n-void ShenandoahConcurrentMark::finish_mark_from_roots(bool full_gc) {\n+void ShenandoahConcurrentMark::finish_mark() {\n@@ -479,4 +381,2 @@\n-\n-  uint nworkers = _heap->workers()->active_workers();\n-\n-  {\n+  assert(Thread::current()->is_VM_thread(), \"Must by VM Thread\");\n+  if (heap()->process_references()) {\n@@ -486,44 +386,5 @@\n-\n-    \/\/ Full GC does not execute concurrent cycle. Degenerated cycle may bypass concurrent cycle.\n-    \/\/ In those cases, concurrent roots might not be scanned, scan them here. Ideally, this\n-    \/\/ should piggyback to ShenandoahFinalMarkingTask, but it makes time tracking very hard.\n-    \/\/ Given full GC and degenerated GC are rare, use a separate task.\n-    if (_heap->is_degenerated_gc_in_progress() || _heap->is_full_gc_in_progress()) {\n-      ShenandoahPhaseTimings::Phase phase = _heap->is_full_gc_in_progress() ?\n-                                            ShenandoahPhaseTimings::full_gc_scan_conc_roots :\n-                                            ShenandoahPhaseTimings::degen_gc_scan_conc_roots;\n-      ShenandoahGCPhase gc_phase(phase);\n-      if (_heap->has_forwarded_objects()) {\n-        ShenandoahProcessConcurrentRootsTask<ShenandoahMarkResolveRefsClosure> task(this, phase, nworkers);\n-        _heap->workers()->run_task(&task);\n-      } else {\n-        ShenandoahProcessConcurrentRootsTask<ShenandoahMarkRefsClosure> task(this, phase, nworkers);\n-        _heap->workers()->run_task(&task);\n-      }\n-    }\n-\n-    \/\/ Finally mark everything else we've got in our queues during the previous steps.\n-    \/\/ It does two different things for concurrent vs. mark-compact GC:\n-    \/\/ - For concurrent GC, it starts with empty task queues, drains the remaining\n-    \/\/   SATB buffers, and then completes the marking closure.\n-    \/\/ - For mark-compact GC, it starts out with the task queues seeded by initial\n-    \/\/   root scan, and completes the closure, thus marking through all live objects\n-    \/\/ The implementation is the same, so it's shared here.\n-    {\n-      ShenandoahGCPhase phase(full_gc ?\n-                              ShenandoahPhaseTimings::full_gc_mark_finish_queues :\n-                              ShenandoahPhaseTimings::finish_queues);\n-      task_queues()->reserve(nworkers);\n-\n-      StrongRootsScope scope(nworkers);\n-      TaskTerminator terminator(nworkers, task_queues());\n-      ShenandoahFinalMarkingTask task(this, &terminator, ShenandoahStringDedup::is_enabled());\n-      _heap->workers()->run_task(&task);\n-    }\n-\n-    assert(task_queues()->is_empty(), \"Should be empty\");\n-  }\n-\n-  \/\/ When we're done marking everything, we process weak references.\n-  if (_heap->process_references()) {\n-    weak_refs_work(full_gc);\n+    finish_mark_work();\n+    \/\/ When we're done marking everything, we process weak references.\n+    process_weak_refs(false \/*full_gc*\/);\n+  } else {\n+    finish_mark_work();\n@@ -537,187 +398,11 @@\n-\/\/ Weak Reference Closures\n-class ShenandoahCMDrainMarkingStackClosure: public VoidClosure {\n-  uint _worker_id;\n-  TaskTerminator* _terminator;\n-  bool _reset_terminator;\n-\n-public:\n-  ShenandoahCMDrainMarkingStackClosure(uint worker_id, TaskTerminator* t, bool reset_terminator = false):\n-    _worker_id(worker_id),\n-    _terminator(t),\n-    _reset_terminator(reset_terminator) {\n-  }\n-\n-  void do_void() {\n-    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n-\n-    ShenandoahHeap* sh = ShenandoahHeap::heap();\n-    ShenandoahConcurrentMark* scm = sh->concurrent_mark();\n-    assert(sh->process_references(), \"why else would we be here?\");\n-    ReferenceProcessor* rp = sh->ref_processor();\n-\n-    shenandoah_assert_rp_isalive_installed();\n-\n-    scm->mark_loop(_worker_id, _terminator, rp,\n-                   false,   \/\/ not cancellable\n-                   false);  \/\/ do not do strdedup\n-\n-    if (_reset_terminator) {\n-      _terminator->reset_for_reuse();\n-    }\n-  }\n-};\n-\n-class ShenandoahCMKeepAliveClosure : public OopClosure {\n-private:\n-  ShenandoahObjToScanQueue* _queue;\n-  ShenandoahHeap* _heap;\n-  ShenandoahMarkingContext* const _mark_context;\n-\n-  template <class T>\n-  inline void do_oop_work(T* p) {\n-    ShenandoahConcurrentMark::mark_through_ref<T, NONE, NO_DEDUP>(p, _heap, _queue, _mark_context);\n-  }\n-\n-public:\n-  ShenandoahCMKeepAliveClosure(ShenandoahObjToScanQueue* q) :\n-    _queue(q),\n-    _heap(ShenandoahHeap::heap()),\n-    _mark_context(_heap->marking_context()) {}\n-\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-};\n-\n-class ShenandoahCMKeepAliveUpdateClosure : public OopClosure {\n-private:\n-  ShenandoahObjToScanQueue* _queue;\n-  ShenandoahHeap* _heap;\n-  ShenandoahMarkingContext* const _mark_context;\n-\n-  template <class T>\n-  inline void do_oop_work(T* p) {\n-    ShenandoahConcurrentMark::mark_through_ref<T, SIMPLE, NO_DEDUP>(p, _heap, _queue, _mark_context);\n-  }\n-\n-public:\n-  ShenandoahCMKeepAliveUpdateClosure(ShenandoahObjToScanQueue* q) :\n-    _queue(q),\n-    _heap(ShenandoahHeap::heap()),\n-    _mark_context(_heap->marking_context()) {}\n-\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-};\n-\n-class ShenandoahWeakUpdateClosure : public OopClosure {\n-private:\n-  ShenandoahHeap* const _heap;\n-\n-  template <class T>\n-  inline void do_oop_work(T* p) {\n-    oop o = _heap->maybe_update_with_forwarded(p);\n-    shenandoah_assert_marked_except(p, o, o == NULL);\n-  }\n-\n-public:\n-  ShenandoahWeakUpdateClosure() : _heap(ShenandoahHeap::heap()) {}\n-\n-  void do_oop(narrowOop* p) { do_oop_work(p); }\n-  void do_oop(oop* p)       { do_oop_work(p); }\n-};\n-\n-class ShenandoahRefProcTaskProxy : public AbstractGangTask {\n-private:\n-  AbstractRefProcTaskExecutor::ProcessTask& _proc_task;\n-  TaskTerminator* _terminator;\n-\n-public:\n-  ShenandoahRefProcTaskProxy(AbstractRefProcTaskExecutor::ProcessTask& proc_task,\n-                             TaskTerminator* t) :\n-    AbstractGangTask(\"Shenandoah Process Weak References\"),\n-    _proc_task(proc_task),\n-    _terminator(t) {\n-  }\n-\n-  void work(uint worker_id) {\n-    Thread* current_thread = Thread::current();\n-    ResourceMark rm(current_thread);\n-    HandleMark hm(current_thread);\n-    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-    ShenandoahParallelWorkerSession worker_session(worker_id);\n-    ShenandoahCMDrainMarkingStackClosure complete_gc(worker_id, _terminator);\n-    if (heap->has_forwarded_objects()) {\n-      ShenandoahForwardedIsAliveClosure is_alive;\n-      ShenandoahCMKeepAliveUpdateClosure keep_alive(heap->concurrent_mark()->get_queue(worker_id));\n-      _proc_task.work(worker_id, is_alive, keep_alive, complete_gc);\n-    } else {\n-      ShenandoahIsAliveClosure is_alive;\n-      ShenandoahCMKeepAliveClosure keep_alive(heap->concurrent_mark()->get_queue(worker_id));\n-      _proc_task.work(worker_id, is_alive, keep_alive, complete_gc);\n-    }\n-  }\n-};\n-\n-class ShenandoahRefProcTaskExecutor : public AbstractRefProcTaskExecutor {\n-private:\n-  WorkGang* _workers;\n-\n-public:\n-  ShenandoahRefProcTaskExecutor(WorkGang* workers) :\n-    _workers(workers) {\n-  }\n-\n-  \/\/ Executes a task using worker threads.\n-  void execute(ProcessTask& task, uint ergo_workers) {\n-    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n-\n-    ShenandoahHeap* heap = ShenandoahHeap::heap();\n-    ShenandoahConcurrentMark* cm = heap->concurrent_mark();\n-    ShenandoahPushWorkerQueuesScope scope(_workers, cm->task_queues(),\n-                                          ergo_workers,\n-                                          \/* do_check = *\/ false);\n-    uint nworkers = _workers->active_workers();\n-    cm->task_queues()->reserve(nworkers);\n-    TaskTerminator terminator(nworkers, cm->task_queues());\n-    ShenandoahRefProcTaskProxy proc_task_proxy(task, &terminator);\n-    _workers->run_task(&proc_task_proxy);\n-  }\n-};\n-\n-void ShenandoahConcurrentMark::weak_refs_work(bool full_gc) {\n-  assert(_heap->process_references(), \"sanity\");\n-\n-  ShenandoahPhaseTimings::Phase phase_root =\n-          full_gc ?\n-          ShenandoahPhaseTimings::full_gc_weakrefs :\n-          ShenandoahPhaseTimings::weakrefs;\n-\n-  ShenandoahGCPhase phase(phase_root);\n-\n-  ReferenceProcessor* rp = _heap->ref_processor();\n-\n-  \/\/ NOTE: We cannot shortcut on has_discovered_references() here, because\n-  \/\/ we will miss marking JNI Weak refs then, see implementation in\n-  \/\/ ReferenceProcessor::process_discovered_references.\n-  weak_refs_work_doit(full_gc);\n-\n-  rp->verify_no_references_recorded();\n-  assert(!rp->discovery_enabled(), \"Post condition\");\n-\n-}\n-\n-void ShenandoahConcurrentMark::weak_refs_work_doit(bool full_gc) {\n-  ReferenceProcessor* rp = _heap->ref_processor();\n-\n-  ShenandoahPhaseTimings::Phase phase_process =\n-          full_gc ?\n-          ShenandoahPhaseTimings::full_gc_weakrefs_process :\n-          ShenandoahPhaseTimings::weakrefs_process;\n-\n-  shenandoah_assert_rp_isalive_not_installed();\n-  ShenandoahIsAliveSelector is_alive;\n-  ReferenceProcessorIsAliveMutator fix_isalive(rp, is_alive.is_alive_closure());\n-\n-  WorkGang* workers = _heap->workers();\n-  uint nworkers = workers->active_workers();\n+void ShenandoahConcurrentMark::finish_mark_work() {\n+  \/\/ Finally mark everything else we've got in our queues during the previous steps.\n+  \/\/ It does two different things for concurrent vs. mark-compact GC:\n+  \/\/ - For concurrent GC, it starts with empty task queues, drains the remaining\n+  \/\/   SATB buffers, and then completes the marking closure.\n+  \/\/ - For mark-compact GC, it starts out with the task queues seeded by initial\n+  \/\/   root scan, and completes the closure, thus marking through all live objects\n+  \/\/ The implementation is the same, so it's shared here.\n+  ShenandoahGCPhase phase(ShenandoahPhaseTimings::finish_queues);\n+  uint nworkers = _heap->workers()->active_workers();\n+  task_queues()->reserve(nworkers);\n@@ -725,2 +410,4 @@\n-  rp->setup_policy(_heap->soft_ref_policy()->should_clear_all_soft_refs());\n-  rp->set_active_mt_degree(nworkers);\n+  StrongRootsScope scope(nworkers);\n+  TaskTerminator terminator(nworkers, task_queues());\n+  ShenandoahFinalMarkingTask task(this, &terminator, ShenandoahStringDedup::is_enabled());\n+  heap()->workers()->run_task(&task);\n@@ -729,40 +416,0 @@\n-\n-  \/\/ complete_gc and keep_alive closures instantiated here are only needed for\n-  \/\/ single-threaded path in RP. They share the queue 0 for tracking work, which\n-  \/\/ simplifies implementation. Since RP may decide to call complete_gc several\n-  \/\/ times, we need to be able to reuse the terminator.\n-  uint serial_worker_id = 0;\n-  TaskTerminator terminator(1, task_queues());\n-  ShenandoahCMDrainMarkingStackClosure complete_gc(serial_worker_id, &terminator, \/* reset_terminator = *\/ true);\n-\n-  ShenandoahRefProcTaskExecutor executor(workers);\n-\n-  ReferenceProcessorPhaseTimes pt(_heap->gc_timer(), rp->num_queues());\n-\n-  {\n-    \/\/ Note: Don't emit JFR event for this phase, to avoid overflow nesting phase level.\n-    \/\/ Reference Processor emits 2 levels JFR event, that can get us over the JFR\n-    \/\/ event nesting level limits, in case of degenerated GC gets upgraded to\n-    \/\/ full GC.\n-    ShenandoahTimingsTracker phase_timing(phase_process);\n-\n-    if (_heap->has_forwarded_objects()) {\n-      ShenandoahCMKeepAliveUpdateClosure keep_alive(get_queue(serial_worker_id));\n-      const ReferenceProcessorStats& stats =\n-        rp->process_discovered_references(is_alive.is_alive_closure(), &keep_alive,\n-                                          &complete_gc, &executor,\n-                                          &pt);\n-       _heap->tracer()->report_gc_reference_stats(stats);\n-    } else {\n-      ShenandoahCMKeepAliveClosure keep_alive(get_queue(serial_worker_id));\n-      const ReferenceProcessorStats& stats =\n-        rp->process_discovered_references(is_alive.is_alive_closure(), &keep_alive,\n-                                          &complete_gc, &executor,\n-                                          &pt);\n-      _heap->tracer()->report_gc_reference_stats(stats);\n-    }\n-\n-    pt.print_all_references();\n-\n-    assert(task_queues()->is_empty(), \"Should be empty\");\n-  }\n@@ -780,0 +427,2 @@\n+private:\n+  ShenandoahConcurrentMark* const _mark;\n@@ -781,0 +430,3 @@\n+  ShenandoahPrecleanCompleteGCClosure(ShenandoahConcurrentMark* mark) :\n+    _mark(mark) { }\n+\n@@ -782,2 +434,1 @@\n-    ShenandoahHeap* sh = ShenandoahHeap::heap();\n-    ShenandoahConcurrentMark* scm = sh->concurrent_mark();\n+    ShenandoahHeap* const sh = ShenandoahHeap::heap();\n@@ -785,1 +436,1 @@\n-    TaskTerminator terminator(1, scm->task_queues());\n+    TaskTerminator terminator(1, _mark->task_queues());\n@@ -790,1 +441,1 @@\n-    scm->mark_loop(0, &terminator, rp,\n+    _mark->mark_loop(0, &terminator, rp,\n@@ -798,1 +449,2 @@\n-  ReferenceProcessor* _rp;\n+  ShenandoahConcurrentMark* const _mark;\n+  ReferenceProcessor* const       _rp;\n@@ -801,1 +453,1 @@\n-  ShenandoahPrecleanTask(ReferenceProcessor* rp) :\n+  ShenandoahPrecleanTask(ShenandoahConcurrentMark* mark, ReferenceProcessor* rp) :\n@@ -803,0 +455,1 @@\n+          _mark(mark),\n@@ -809,2 +462,1 @@\n-    ShenandoahHeap* sh = ShenandoahHeap::heap();\n-    assert(!sh->has_forwarded_objects(), \"No forwarded objects expected here\");\n+    assert(!ShenandoahHeap::heap()->has_forwarded_objects(), \"No forwarded objects expected here\");\n@@ -812,1 +464,1 @@\n-    ShenandoahObjToScanQueue* q = sh->concurrent_mark()->get_queue(worker_id);\n+    ShenandoahObjToScanQueue* q = _mark->get_queue(worker_id);\n@@ -815,1 +467,1 @@\n-    ShenandoahPrecleanCompleteGCClosure complete_gc;\n+    ShenandoahPrecleanCompleteGCClosure complete_gc(_mark);\n@@ -827,0 +479,3 @@\n+  if (!_heap->process_references()) {\n+    return;\n+  }\n@@ -834,2 +489,0 @@\n-  assert(_heap->process_references(), \"sanity\");\n-\n@@ -858,1 +511,1 @@\n-  ShenandoahPrecleanTask task(rp);\n+  ShenandoahPrecleanTask task(this, rp);\n@@ -865,12 +518,2 @@\n-  \/\/ Clean up marking stacks.\n-  ShenandoahObjToScanQueueSet* queues = task_queues();\n-  queues->clear();\n-\n-  \/\/ Cancel SATB buffers.\n-  ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();\n-}\n-\n-ShenandoahObjToScanQueue* ShenandoahConcurrentMark::get_queue(uint worker_id) {\n-  assert(task_queues()->get_reserved() > worker_id, \"No reserved queue for worker id: %d\", worker_id);\n-  return _task_queues->queue(worker_id);\n-}\n+  clear();\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n@@ -878,120 +521,6 @@\n-template <bool CANCELLABLE>\n-void ShenandoahConcurrentMark::mark_loop_prework(uint w, TaskTerminator *t, ReferenceProcessor *rp,\n-                                                 bool strdedup) {\n-  ShenandoahObjToScanQueue* q = get_queue(w);\n-\n-  ShenandoahLiveData* ld = _heap->get_liveness_cache(w);\n-\n-  \/\/ TODO: We can clean up this if we figure out how to do templated oop closures that\n-  \/\/ play nice with specialized_oop_iterators.\n-  if (_heap->unload_classes()) {\n-    if (_heap->has_forwarded_objects()) {\n-      if (strdedup) {\n-        ShenandoahMarkUpdateRefsMetadataDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkUpdateRefsMetadataClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    } else {\n-      if (strdedup) {\n-        ShenandoahMarkRefsMetadataDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkRefsMetadataClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    }\n-  } else {\n-    if (_heap->has_forwarded_objects()) {\n-      if (strdedup) {\n-        ShenandoahMarkUpdateRefsDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkUpdateRefsClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkUpdateRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    } else {\n-      if (strdedup) {\n-        ShenandoahMarkRefsDedupClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n-      } else {\n-        ShenandoahMarkRefsClosure cl(q, rp);\n-        mark_loop_work<ShenandoahMarkRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n-      }\n-    }\n-  }\n-\n-  _heap->flush_liveness_cache(w);\n-}\n-\n-template <class T, bool CANCELLABLE>\n-void ShenandoahConcurrentMark::mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *terminator) {\n-  uintx stride = ShenandoahMarkLoopStride;\n-\n-  ShenandoahHeap* heap = ShenandoahHeap::heap();\n-  ShenandoahObjToScanQueueSet* queues = task_queues();\n-  ShenandoahObjToScanQueue* q;\n-  ShenandoahMarkTask t;\n-\n-  \/*\n-   * Process outstanding queues, if any.\n-   *\n-   * There can be more queues than workers. To deal with the imbalance, we claim\n-   * extra queues first. Since marking can push new tasks into the queue associated\n-   * with this worker id, we come back to process this queue in the normal loop.\n-   *\/\n-  assert(queues->get_reserved() == heap->workers()->active_workers(),\n-         \"Need to reserve proper number of queues: reserved: %u, active: %u\", queues->get_reserved(), heap->workers()->active_workers());\n-\n-  q = queues->claim_next();\n-  while (q != NULL) {\n-    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n-      return;\n-    }\n-\n-    for (uint i = 0; i < stride; i++) {\n-      if (q->pop(t)) {\n-        do_task<T>(q, cl, live_data, &t);\n-      } else {\n-        assert(q->is_empty(), \"Must be empty\");\n-        q = queues->claim_next();\n-        break;\n-      }\n-    }\n-  }\n-  q = get_queue(worker_id);\n-\n-  ShenandoahSATBBufferClosure drain_satb(q);\n-  SATBMarkQueueSet& satb_mq_set = ShenandoahBarrierSet::satb_mark_queue_set();\n-\n-  \/*\n-   * Normal marking loop:\n-   *\/\n-  while (true) {\n-    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n-      return;\n-    }\n-\n-    while (satb_mq_set.completed_buffers_num() > 0) {\n-      satb_mq_set.apply_closure_to_completed_buffer(&drain_satb);\n-    }\n-\n-    uint work = 0;\n-    for (uint i = 0; i < stride; i++) {\n-      if (q->pop(t) ||\n-          queues->steal(worker_id, t)) {\n-        do_task<T>(q, cl, live_data, &t);\n-        work++;\n-      } else {\n-        break;\n-      }\n-    }\n-\n-    if (work == 0) {\n-      \/\/ No work encountered in current stride, try to terminate.\n-      \/\/ Need to leave the STS here otherwise it might block safepoints.\n-      ShenandoahSuspendibleThreadSetLeaver stsl(CANCELLABLE && ShenandoahSuspendibleWorkers);\n-      ShenandoahTerminatorTerminator tt(heap);\n-      if (terminator->offer_termination(&tt)) return;\n-    }\n+  if (heap->process_references()) {\n+    \/\/ Abandon reference processing right away: pre-cleaning must have failed.\n+    ReferenceProcessor *rp = heap->ref_processor();\n+    rp->disable_discovery();\n+    rp->abandon_partial_discovery();\n+    rp->verify_no_references_recorded();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.cpp","additions":118,"deletions":589,"binary":false,"changes":707,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.hpp\"\n@@ -31,1 +32,0 @@\n-#include \"gc\/shenandoah\/shenandoahPhaseTimings.hpp\"\n@@ -34,1 +34,3 @@\n-class ShenandoahStrDedupQueue;\n+class ShenandoahConcurrentMarkingTask;\n+class ShenandoahFinalMarkingTask;\n+class ShenandoahPrecleanCompleteGCClosure;\n@@ -36,4 +38,4 @@\n-class ShenandoahConcurrentMark: public CHeapObj<mtGC> {\n-private:\n-  ShenandoahHeap* _heap;\n-  ShenandoahObjToScanQueueSet* _task_queues;\n+class ShenandoahConcurrentMark: public ShenandoahMark {\n+  friend class ShenandoahConcurrentMarkingTask;\n+  friend class ShenandoahFinalMarkingTask;\n+  friend class ShenandoahPrecleanCompleteGCClosure;\n@@ -42,11 +44,1 @@\n-  void initialize(uint workers);\n-  void cancel();\n-\n-\/\/ ---------- Marking loop and tasks\n-\/\/\n-private:\n-  template <class T>\n-  inline void do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task);\n-\n-  template <class T>\n-  inline void do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop array);\n+  ShenandoahConcurrentMark();\n@@ -54,2 +46,3 @@\n-  template <class T>\n-  inline void do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop array, int chunk, int pow);\n+  \/\/ When concurrent stack processing is not supported\n+  void mark_stw_roots();\n+  void mark_concurrent_roots();\n@@ -57,17 +50,4 @@\n-  inline void count_liveness(ShenandoahLiveData* live_data, oop obj);\n-\n-  template <class T, bool CANCELLABLE>\n-  void mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *t);\n-\n-  template <bool CANCELLABLE>\n-  void mark_loop_prework(uint worker_id, TaskTerminator *terminator, ReferenceProcessor *rp, bool strdedup);\n-\n-public:\n-  void mark_loop(uint worker_id, TaskTerminator* terminator, ReferenceProcessor *rp,\n-                 bool cancellable, bool strdedup) {\n-    if (cancellable) {\n-      mark_loop_prework<true>(worker_id, terminator, rp, strdedup);\n-    } else {\n-      mark_loop_prework<false>(worker_id, terminator, rp, strdedup);\n-    }\n-  }\n+  \/\/ Concurrent mark\n+  void concurrent_mark();\n+  \/\/ Finish mark at a safepoint\n+  void finish_mark();\n@@ -75,2 +55,2 @@\n-  template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n-  static inline void mark_through_ref(T* p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context);\n+  \/\/ Reference processing\n+  void preclean_weak_refs();\n@@ -78,2 +58,1 @@\n-  void mark_from_roots();\n-  void finish_mark_from_roots(bool full_gc);\n+  static void cancel();\n@@ -81,3 +60,3 @@\n-  void mark_roots(ShenandoahPhaseTimings::Phase root_phase);\n-  void update_roots(ShenandoahPhaseTimings::Phase root_phase);\n-  void update_thread_roots(ShenandoahPhaseTimings::Phase root_phase);\n+  \/\/ TODO: where to put them\n+  static void update_roots(ShenandoahPhaseTimings::Phase root_phase);\n+  static void update_thread_roots(ShenandoahPhaseTimings::Phase root_phase);\n@@ -85,2 +64,0 @@\n-\/\/ ---------- Weak references\n-\/\/\n@@ -88,13 +65,1 @@\n-  void weak_refs_work(bool full_gc);\n-  void weak_refs_work_doit(bool full_gc);\n-\n-public:\n-  void preclean_weak_refs();\n-\n-\/\/ ---------- Helpers\n-\/\/ Used from closures, need to be public\n-\/\/\n-public:\n-  ShenandoahObjToScanQueue* get_queue(uint worker_id);\n-  ShenandoahObjToScanQueueSet* task_queues() { return _task_queues; }\n-\n+  void finish_mark_work();\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.hpp","additions":23,"deletions":58,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -1,270 +0,0 @@\n-\/*\n- * Copyright (c) 2015, 2019, Red Hat, Inc. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP\n-#define SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP\n-\n-#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n-#include \"gc\/shenandoah\/shenandoahBarrierSet.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n-#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahMarkingContext.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahStringDedup.inline.hpp\"\n-#include \"gc\/shenandoah\/shenandoahTaskqueue.inline.hpp\"\n-#include \"memory\/iterator.inline.hpp\"\n-#include \"oops\/compressedOops.inline.hpp\"\n-#include \"oops\/oop.inline.hpp\"\n-#include \"runtime\/prefetch.inline.hpp\"\n-\n-template <class T>\n-void ShenandoahConcurrentMark::do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task) {\n-  oop obj = task->obj();\n-\n-  shenandoah_assert_not_forwarded(NULL, obj);\n-  shenandoah_assert_marked(NULL, obj);\n-  shenandoah_assert_not_in_cset_except(NULL, obj, _heap->cancelled_gc());\n-\n-  if (task->is_not_chunked()) {\n-    if (obj->is_instance()) {\n-      \/\/ Case 1: Normal oop, process as usual.\n-      obj->oop_iterate(cl);\n-    } else if (obj->is_objArray()) {\n-      \/\/ Case 2: Object array instance and no chunk is set. Must be the first\n-      \/\/ time we visit it, start the chunked processing.\n-      do_chunked_array_start<T>(q, cl, obj);\n-    } else {\n-      \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n-      \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n-      \/\/ We skip iterating over the klass pointer since we know that\n-      \/\/ Universe::TypeArrayKlass never moves.\n-      assert (obj->is_typeArray(), \"should be type array\");\n-    }\n-    \/\/ Count liveness the last: push the outstanding work to the queues first\n-    count_liveness(live_data, obj);\n-  } else {\n-    \/\/ Case 4: Array chunk, has sensible chunk id. Process it.\n-    do_chunked_array<T>(q, cl, obj, task->chunk(), task->pow());\n-  }\n-}\n-\n-inline void ShenandoahConcurrentMark::count_liveness(ShenandoahLiveData* live_data, oop obj) {\n-  size_t region_idx = _heap->heap_region_index_containing(obj);\n-  ShenandoahHeapRegion* region = _heap->get_region(region_idx);\n-  size_t size = obj->size();\n-\n-  if (!region->is_humongous_start()) {\n-    assert(!region->is_humongous(), \"Cannot have continuations here\");\n-    ShenandoahLiveData cur = live_data[region_idx];\n-    size_t new_val = size + cur;\n-    if (new_val >= SHENANDOAH_LIVEDATA_MAX) {\n-      \/\/ overflow, flush to region data\n-      region->increase_live_data_gc_words(new_val);\n-      live_data[region_idx] = 0;\n-    } else {\n-      \/\/ still good, remember in locals\n-      live_data[region_idx] = (ShenandoahLiveData) new_val;\n-    }\n-  } else {\n-    shenandoah_assert_in_correct_region(NULL, obj);\n-    size_t num_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);\n-\n-    for (size_t i = region_idx; i < region_idx + num_regions; i++) {\n-      ShenandoahHeapRegion* chain_reg = _heap->get_region(i);\n-      assert(chain_reg->is_humongous(), \"Expecting a humongous region\");\n-      chain_reg->increase_live_data_gc_words(chain_reg->used() >> LogHeapWordSize);\n-    }\n-  }\n-}\n-\n-template <class T>\n-inline void ShenandoahConcurrentMark::do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop obj) {\n-  assert(obj->is_objArray(), \"expect object array\");\n-  objArrayOop array = objArrayOop(obj);\n-  int len = array->length();\n-\n-  if (len <= (int) ObjArrayMarkingStride*2) {\n-    \/\/ A few slices only, process directly\n-    array->oop_iterate_range(cl, 0, len);\n-  } else {\n-    int bits = log2_long((size_t) len);\n-    \/\/ Compensate for non-power-of-two arrays, cover the array in excess:\n-    if (len != (1 << bits)) bits++;\n-\n-    \/\/ Only allow full chunks on the queue. This frees do_chunked_array() from checking from\/to\n-    \/\/ boundaries against array->length(), touching the array header on every chunk.\n-    \/\/\n-    \/\/ To do this, we cut the prefix in full-sized chunks, and submit them on the queue.\n-    \/\/ If the array is not divided in chunk sizes, then there would be an irregular tail,\n-    \/\/ which we will process separately.\n-\n-    int last_idx = 0;\n-\n-    int chunk = 1;\n-    int pow = bits;\n-\n-    \/\/ Handle overflow\n-    if (pow >= 31) {\n-      assert (pow == 31, \"sanity\");\n-      pow--;\n-      chunk = 2;\n-      last_idx = (1 << pow);\n-      bool pushed = q->push(ShenandoahMarkTask(array, 1, pow));\n-      assert(pushed, \"overflow queue should always succeed pushing\");\n-    }\n-\n-    \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Record the last\n-    \/\/ successful right boundary to figure out the irregular tail.\n-    while ((1 << pow) > (int)ObjArrayMarkingStride &&\n-           (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n-      pow--;\n-      int left_chunk = chunk*2 - 1;\n-      int right_chunk = chunk*2;\n-      int left_chunk_end = left_chunk * (1 << pow);\n-      if (left_chunk_end < len) {\n-        bool pushed = q->push(ShenandoahMarkTask(array, left_chunk, pow));\n-        assert(pushed, \"overflow queue should always succeed pushing\");\n-        chunk = right_chunk;\n-        last_idx = left_chunk_end;\n-      } else {\n-        chunk = left_chunk;\n-      }\n-    }\n-\n-    \/\/ Process the irregular tail, if present\n-    int from = last_idx;\n-    if (from < len) {\n-      array->oop_iterate_range(cl, from, len);\n-    }\n-  }\n-}\n-\n-template <class T>\n-inline void ShenandoahConcurrentMark::do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop obj, int chunk, int pow) {\n-  assert(obj->is_objArray(), \"expect object array\");\n-  objArrayOop array = objArrayOop(obj);\n-\n-  assert (ObjArrayMarkingStride > 0, \"sanity\");\n-\n-  \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Avoid pushing tasks that\n-  \/\/ are known to start beyond the array.\n-  while ((1 << pow) > (int)ObjArrayMarkingStride && (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n-    pow--;\n-    chunk *= 2;\n-    bool pushed = q->push(ShenandoahMarkTask(array, chunk - 1, pow));\n-    assert(pushed, \"overflow queue should always succeed pushing\");\n-  }\n-\n-  int chunk_size = 1 << pow;\n-\n-  int from = (chunk - 1) * chunk_size;\n-  int to = chunk * chunk_size;\n-\n-#ifdef ASSERT\n-  int len = array->length();\n-  assert (0 <= from && from < len, \"from is sane: %d\/%d\", from, len);\n-  assert (0 < to && to <= len, \"to is sane: %d\/%d\", to, len);\n-#endif\n-\n-  array->oop_iterate_range(cl, from, to);\n-}\n-\n-class ShenandoahSATBBufferClosure : public SATBBufferClosure {\n-private:\n-  ShenandoahObjToScanQueue* _queue;\n-  ShenandoahHeap* _heap;\n-  ShenandoahMarkingContext* const _mark_context;\n-public:\n-  ShenandoahSATBBufferClosure(ShenandoahObjToScanQueue* q) :\n-    _queue(q),\n-    _heap(ShenandoahHeap::heap()),\n-    _mark_context(_heap->marking_context())\n-  {\n-  }\n-\n-  void do_buffer(void **buffer, size_t size) {\n-    assert(size == 0 || !_heap->has_forwarded_objects(), \"Forwarded objects are not expected here\");\n-    if (ShenandoahStringDedup::is_enabled()) {\n-      do_buffer_impl<ENQUEUE_DEDUP>(buffer, size);\n-    } else {\n-      do_buffer_impl<NO_DEDUP>(buffer, size);\n-    }\n-  }\n-\n-  template<StringDedupMode STRING_DEDUP>\n-  void do_buffer_impl(void **buffer, size_t size) {\n-    for (size_t i = 0; i < size; ++i) {\n-      oop *p = (oop *) &buffer[i];\n-      ShenandoahConcurrentMark::mark_through_ref<oop, NONE, STRING_DEDUP>(p, _heap, _queue, _mark_context);\n-    }\n-  }\n-};\n-\n-template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n-inline void ShenandoahConcurrentMark::mark_through_ref(T *p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context) {\n-  T o = RawAccess<>::oop_load(p);\n-  if (!CompressedOops::is_null(o)) {\n-    oop obj = CompressedOops::decode_not_null(o);\n-    switch (UPDATE_REFS) {\n-    case NONE:\n-      break;\n-    case RESOLVE:\n-      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n-      break;\n-    case SIMPLE:\n-      \/\/ We piggy-back reference updating to the marking tasks.\n-      obj = heap->update_with_forwarded_not_null(p, obj);\n-      break;\n-    case CONCURRENT:\n-      obj = heap->maybe_update_with_forwarded_not_null(p, obj);\n-      break;\n-    default:\n-      ShouldNotReachHere();\n-    }\n-\n-    \/\/ Note: Only when concurrently updating references can obj be different\n-    \/\/ (that is, really different, not just different from-\/to-space copies of the same)\n-    \/\/ from the one we originally loaded. Mutator thread can beat us by writing something\n-    \/\/ else into the location. In that case, we would mark through that updated value,\n-    \/\/ on the off-chance it is not handled by other means (e.g. via SATB). However,\n-    \/\/ if that write was NULL, we don't need to do anything else.\n-    if (UPDATE_REFS != CONCURRENT || !CompressedOops::is_null(obj)) {\n-      shenandoah_assert_not_forwarded(p, obj);\n-      shenandoah_assert_not_in_cset_except(p, obj, heap->cancelled_gc());\n-\n-      if (mark_context->mark(obj)) {\n-        bool pushed = q->push(ShenandoahMarkTask(obj));\n-        assert(pushed, \"overflow queue should always succeed pushing\");\n-\n-        if ((STRING_DEDUP == ENQUEUE_DEDUP) && ShenandoahStringDedup::is_candidate(obj)) {\n-          assert(ShenandoahStringDedup::is_enabled(), \"Must be enabled\");\n-          ShenandoahStringDedup::enqueue_candidate(obj);\n-        }\n-      }\n-\n-      shenandoah_assert_marked(p, obj);\n-    }\n-  }\n-}\n-\n-#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHCONCURRENTMARK_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp","additions":0,"deletions":270,"binary":false,"changes":270,"status":"deleted"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -33,0 +33,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -400,2 +401,6 @@\n-  \/\/ Start initial mark under STW\n-  heap->vmop_entry_init_mark();\n+  \/\/ Mark\n+  {\n+    ShenandoahConcurrentMark mark;\n+\n+    \/\/ Start initial mark under STW\n+    heap->vmop_entry_init_mark(&mark);\n@@ -403,3 +408,3 @@\n-  \/\/ Continue concurrent mark\n-  heap->entry_mark();\n-  if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_mark)) return;\n+    \/\/ Concurrent mark roots\n+    heap->entry_mark_roots(&mark);\n+    if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_outside_cycle)) return;\n@@ -407,2 +412,3 @@\n-  \/\/ If not cancelled, can try to concurrently pre-clean\n-  heap->entry_preclean();\n+    \/\/ Continue concurrent mark\n+    heap->entry_mark(&mark);\n+    if (check_cancellation_or_degen(ShenandoahHeap::_degenerated_mark)) return;\n@@ -410,2 +416,6 @@\n-  \/\/ Complete marking under STW, and start evacuation\n-  heap->vmop_entry_final_mark();\n+    \/\/ If not cancelled, can try to concurrently pre-clean\n+    heap->entry_preclean(&mark);\n+\n+    \/\/ Complete marking under STW, and start evacuation\n+    heap->vmop_entry_final_mark(&mark);\n+  }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahControlThread.cpp","additions":20,"deletions":10,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -60,0 +60,1 @@\n+#include \"gc\/shenandoah\/shenandoahSTWMark.hpp\"\n@@ -462,0 +463,1 @@\n+  _task_queues(NULL),\n@@ -466,2 +468,0 @@\n-  _scm(new ShenandoahConcurrentMark()),\n-  _full_gc(new ShenandoahMarkCompact()),\n@@ -615,2 +615,8 @@\n-  _scm->initialize(_max_workers);\n-  _full_gc->initialize(_gc_timer);\n+  \/\/ Task queues\n+  uint num_queues = MAX2(_max_workers, 1U);\n+  _task_queues = new ShenandoahObjToScanQueueSet((int) num_queues);\n+  for (uint i = 0; i < num_queues; ++i) {\n+    ShenandoahObjToScanQueue* task_queue = new ShenandoahObjToScanQueue();\n+    task_queue->initialize();\n+    _task_queues->register_queue(i, task_queue);\n+  }\n@@ -1580,1 +1586,1 @@\n-void ShenandoahHeap::op_init_mark() {\n+void ShenandoahHeap::op_init_mark(ShenandoahConcurrentMark* mark) {\n@@ -1614,2 +1620,1 @@\n-\n-  concurrent_mark()->mark_roots(ShenandoahPhaseTimings::scan_roots);\n+  mark->mark_stw_roots();\n@@ -1629,2 +1634,6 @@\n-void ShenandoahHeap::op_mark() {\n-  concurrent_mark()->mark_from_roots();\n+void ShenandoahHeap::op_mark_roots(ShenandoahConcurrentMark* mark) {\n+  mark->mark_concurrent_roots();\n+}\n+\n+void ShenandoahHeap::op_mark(ShenandoahConcurrentMark* mark) {\n+  mark->concurrent_mark();\n@@ -1680,1 +1689,1 @@\n-void ShenandoahHeap::op_final_mark() {\n+void ShenandoahHeap::op_final_mark(ShenandoahConcurrentMark* mark) {\n@@ -1684,4 +1693,0 @@\n-  \/\/ It is critical that we\n-  \/\/ evacuate roots right after finishing marking, so that we don't\n-  \/\/ get unmarked objects in the roots.\n-\n@@ -1689,99 +1694,2 @@\n-    concurrent_mark()->finish_mark_from_roots(\/* full_gc = *\/ false);\n-\n-    \/\/ Marking is completed, deactivate SATB barrier\n-    set_concurrent_mark_in_progress(false);\n-    mark_complete_marking_context();\n-\n-    parallel_cleaning(false \/* full gc*\/);\n-\n-    if (ShenandoahVerify) {\n-      verifier()->verify_roots_no_forwarded();\n-    }\n-\n-    {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_region_states);\n-      ShenandoahFinalMarkUpdateRegionStateClosure cl;\n-      parallel_heap_region_iterate(&cl);\n-\n-      assert_pinned_region_status();\n-    }\n-\n-    \/\/ Retire the TLABs, which will force threads to reacquire their TLABs after the pause.\n-    \/\/ This is needed for two reasons. Strong one: new allocations would be with new freeset,\n-    \/\/ which would be outside the collection set, so no cset writes would happen there.\n-    \/\/ Weaker one: new allocations would happen past update watermark, and so less work would\n-    \/\/ be needed for reference updates (would update the large filler instead).\n-    if (UseTLAB) {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_manage_labs);\n-      tlabs_retire(false);\n-    }\n-\n-    {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::choose_cset);\n-      ShenandoahHeapLocker locker(lock());\n-      _collection_set->clear();\n-      heuristics()->choose_collection_set(_collection_set);\n-    }\n-\n-    {\n-      ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_rebuild_freeset);\n-      ShenandoahHeapLocker locker(lock());\n-      _free_set->rebuild();\n-    }\n-\n-    if (!is_degenerated_gc_in_progress()) {\n-      prepare_concurrent_roots();\n-      prepare_concurrent_unloading();\n-    }\n-\n-    \/\/ If collection set has candidates, start evacuation.\n-    \/\/ Otherwise, bypass the rest of the cycle.\n-    if (!collection_set()->is_empty()) {\n-      ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);\n-\n-      if (ShenandoahVerify) {\n-        verifier()->verify_before_evacuation();\n-      }\n-\n-      set_evacuation_in_progress(true);\n-      \/\/ From here on, we need to update references.\n-      set_has_forwarded_objects(true);\n-\n-      if (!is_degenerated_gc_in_progress()) {\n-        if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {\n-          ShenandoahCodeRoots::arm_nmethods();\n-        }\n-        evacuate_and_update_roots();\n-      }\n-\n-      if (ShenandoahPacing) {\n-        pacer()->setup_for_evac();\n-      }\n-\n-      if (ShenandoahVerify) {\n-        \/\/ If OOM while evacuating\/updating of roots, there is no guarantee of their consistencies\n-        if (!cancelled_gc()) {\n-          ShenandoahRootVerifier::RootTypes types = ShenandoahRootVerifier::None;\n-          if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {\n-            types = ShenandoahRootVerifier::combine(ShenandoahRootVerifier::JNIHandleRoots, ShenandoahRootVerifier::WeakRoots);\n-            types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::CLDGRoots);\n-            types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::StringDedupRoots);\n-          }\n-\n-          if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {\n-            types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::CodeRoots);\n-          }\n-          verifier()->verify_roots_no_forwarded_except(types);\n-        }\n-        verifier()->verify_during_evacuation();\n-      }\n-    } else {\n-      if (ShenandoahVerify) {\n-        verifier()->verify_after_concmark();\n-      }\n-\n-      if (VerifyAfterGC) {\n-        Universe::verify();\n-      }\n-    }\n-\n+    finish_mark(mark);\n+    prepare_evacuation();\n@@ -1791,1 +1699,1 @@\n-    concurrent_mark()->cancel();\n+    ShenandoahConcurrentMark::cancel();\n@@ -1793,8 +1701,0 @@\n-\n-    if (process_references()) {\n-      \/\/ Abandon reference processing right away: pre-cleaning must have failed.\n-      ReferenceProcessor *rp = ref_processor();\n-      rp->disable_discovery();\n-      rp->abandon_partial_discovery();\n-      rp->verify_no_references_recorded();\n-    }\n@@ -1851,0 +1751,104 @@\n+\/\/ Helpers\n+void ShenandoahHeap::finish_mark(ShenandoahConcurrentMark* mark) {\n+  assert(!cancelled_gc(), \"Should not continue\");\n+  mark->finish_mark();\n+  \/\/ Marking is completed, deactivate SATB barrier\n+  set_concurrent_mark_in_progress(false);\n+  mark_complete_marking_context();\n+}\n+\n+void ShenandoahHeap::prepare_evacuation() {\n+  if (ShenandoahVerify) {\n+    verifier()->verify_roots_no_forwarded();\n+  }\n+\n+  parallel_cleaning(false \/* full gc*\/);\n+\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_update_region_states);\n+    ShenandoahFinalMarkUpdateRegionStateClosure cl;\n+    parallel_heap_region_iterate(&cl);\n+\n+    assert_pinned_region_status();\n+  }\n+\n+  \/\/ Retire the TLABs, which will force threads to reacquire their TLABs after the pause.\n+  \/\/ This is needed for two reasons. Strong one: new allocations would be with new freeset,\n+  \/\/ which would be outside the collection set, so no cset writes would happen there.\n+  \/\/ Weaker one: new allocations would happen past update watermark, and so less work would\n+  \/\/ be needed for reference updates (would update the large filler instead).\n+  if (UseTLAB) {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_manage_labs);\n+    tlabs_retire(false);\n+  }\n+\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::choose_cset);\n+    ShenandoahHeapLocker locker(lock());\n+    _collection_set->clear();\n+    heuristics()->choose_collection_set(_collection_set);\n+  }\n+\n+  {\n+    ShenandoahGCPhase phase(ShenandoahPhaseTimings::final_rebuild_freeset);\n+    ShenandoahHeapLocker locker(lock());\n+    _free_set->rebuild();\n+  }\n+\n+  if (!is_degenerated_gc_in_progress()) {\n+    prepare_concurrent_roots();\n+    prepare_concurrent_unloading();\n+  }\n+\n+  \/\/ If collection set has candidates, start evacuation.\n+  \/\/ Otherwise, bypass the rest of the cycle.\n+  if (!collection_set()->is_empty()) {\n+    ShenandoahGCPhase init_evac(ShenandoahPhaseTimings::init_evac);\n+\n+    if (ShenandoahVerify) {\n+      verifier()->verify_before_evacuation();\n+    }\n+\n+    set_evacuation_in_progress(true);\n+    \/\/ From here on, we need to update references.\n+    set_has_forwarded_objects(true);\n+\n+    if (!is_degenerated_gc_in_progress()) {\n+      if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {\n+        ShenandoahCodeRoots::arm_nmethods();\n+      }\n+      evacuate_and_update_roots();\n+    }\n+\n+    if (ShenandoahPacing) {\n+      pacer()->setup_for_evac();\n+    }\n+\n+    if (ShenandoahVerify) {\n+      \/\/ If OOM while evacuating\/updating of roots, there is no guarantee of their consistencies\n+      if (!cancelled_gc()) {\n+        ShenandoahRootVerifier::RootTypes types = ShenandoahRootVerifier::None;\n+        if (ShenandoahConcurrentRoots::should_do_concurrent_roots()) {\n+          types = ShenandoahRootVerifier::combine(ShenandoahRootVerifier::JNIHandleRoots, ShenandoahRootVerifier::WeakRoots);\n+          types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::CLDGRoots);\n+          types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::StringDedupRoots);\n+        }\n+\n+        if (ShenandoahConcurrentRoots::should_do_concurrent_class_unloading()) {\n+          types = ShenandoahRootVerifier::combine(types, ShenandoahRootVerifier::CodeRoots);\n+        }\n+        verifier()->verify_roots_no_forwarded_except(types);\n+      }\n+      verifier()->verify_during_evacuation();\n+    }\n+  } else {\n+    if (ShenandoahVerify) {\n+      verifier()->verify_after_concmark();\n+    }\n+\n+    if (VerifyAfterGC) {\n+      Universe::verify();\n+    }\n+  }\n+}\n+\n@@ -2080,1 +2084,1 @@\n-void ShenandoahHeap::op_preclean() {\n+void ShenandoahHeap::op_preclean(ShenandoahConcurrentMark* mark) {\n@@ -2084,1 +2088,1 @@\n-  concurrent_mark()->preclean_weak_refs();\n+  mark->preclean_weak_refs();\n@@ -2091,1 +2095,3 @@\n-  full_gc()->do_it(cause);\n+  ShenandoahMarkCompact full_gc;\n+  full_gc.initialize(_gc_timer);\n+  full_gc.do_it(cause);\n@@ -2131,0 +2137,6 @@\n+      \/\/ Degenerated from concurrent mark roots, reset for STW mark\n+      if (is_concurrent_mark_in_progress()) {\n+        ShenandoahConcurrentMark::cancel();\n+        set_concurrent_mark_in_progress(false);\n+      }\n+\n@@ -2133,4 +2145,7 @@\n-      op_init_mark();\n-      if (cancelled_gc()) {\n-        op_degenerated_fail();\n-        return;\n+      \/\/ STW root scan\n+      {\n+        assert(!has_forwarded_objects(), \"Should not have forwarded heap\");\n+        ShenandoahSTWMark mark(false \/*full_gc*\/);\n+        mark.mark();\n+        mark_complete_marking_context();\n+        assert(!cancelled_gc(), \"STW mark can not OOM\");\n@@ -2138,1 +2153,0 @@\n-\n@@ -2140,1 +2154,6 @@\n-      op_final_mark();\n+      if (point == _degenerated_mark) {\n+        ShenandoahConcurrentMark mark;\n+        finish_mark(&mark);\n+      }\n+      prepare_evacuation();\n+\n@@ -2762,1 +2781,1 @@\n-    concurrent_mark()->update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);\n+    ShenandoahConcurrentMark::update_roots(ShenandoahPhaseTimings::degen_gc_update_roots);\n@@ -2888,1 +2907,1 @@\n-void ShenandoahHeap::vmop_entry_init_mark() {\n+void ShenandoahHeap::vmop_entry_init_mark(ShenandoahConcurrentMark* mark) {\n@@ -2893,1 +2912,1 @@\n-  VM_ShenandoahInitMark op;\n+  VM_ShenandoahInitMark op(mark);\n@@ -2897,1 +2916,1 @@\n-void ShenandoahHeap::vmop_entry_final_mark() {\n+void ShenandoahHeap::vmop_entry_final_mark(ShenandoahConcurrentMark* mark) {\n@@ -2902,1 +2921,1 @@\n-  VM_ShenandoahFinalMarkStartEvac op;\n+  VM_ShenandoahFinalMarkStartEvac op(mark);\n@@ -2941,1 +2960,1 @@\n-void ShenandoahHeap::entry_init_mark() {\n+void ShenandoahHeap::entry_init_mark(ShenandoahConcurrentMark* mark) {\n@@ -2950,1 +2969,1 @@\n-  op_init_mark();\n+  op_init_mark(mark);\n@@ -2953,1 +2972,1 @@\n-void ShenandoahHeap::entry_final_mark() {\n+void ShenandoahHeap::entry_final_mark(ShenandoahConcurrentMark* mark) {\n@@ -2962,1 +2981,1 @@\n-  op_final_mark();\n+  op_final_mark(mark);\n@@ -3014,1 +3033,16 @@\n-void ShenandoahHeap::entry_mark() {\n+void ShenandoahHeap::entry_mark_roots(ShenandoahConcurrentMark* mark) {\n+  TraceCollectorStats tcs(monitoring_support()->concurrent_collection_counters());\n+\n+  const char* msg = \"Concurrent marking roots\";\n+  ShenandoahConcurrentPhase gc_phase(msg, ShenandoahPhaseTimings::conc_mark_roots);\n+  EventMark em(\"%s\", msg);\n+\n+  ShenandoahWorkerScope scope(workers(),\n+                              ShenandoahWorkerPolicy::calc_workers_for_conc_marking(),\n+                              \"concurrent marking roots\");\n+\n+  try_inject_alloc_failure();\n+  op_mark_roots(mark);\n+}\n+\n+void ShenandoahHeap::entry_mark(ShenandoahConcurrentMark* mark) {\n@@ -3026,1 +3060,1 @@\n-  op_mark();\n+  op_mark(mark);\n@@ -3156,1 +3190,1 @@\n-void ShenandoahHeap::entry_preclean() {\n+void ShenandoahHeap::entry_preclean(ShenandoahConcurrentMark* mark) {\n@@ -3168,1 +3202,1 @@\n-    op_preclean();\n+    op_preclean(mark);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":179,"deletions":145,"binary":false,"changes":324,"status":"modified"},{"patch":"@@ -373,2 +373,2 @@\n-  void vmop_entry_init_mark();\n-  void vmop_entry_final_mark();\n+  void vmop_entry_init_mark(ShenandoahConcurrentMark* mark);\n+  void vmop_entry_final_mark(ShenandoahConcurrentMark* mark);\n@@ -382,2 +382,2 @@\n-  void entry_init_mark();\n-  void entry_final_mark();\n+  void entry_init_mark(ShenandoahConcurrentMark* mark);\n+  void entry_final_mark(ShenandoahConcurrentMark* mark);\n@@ -392,2 +392,3 @@\n-  void entry_mark();\n-  void entry_preclean();\n+  void entry_mark_roots(ShenandoahConcurrentMark* mark);\n+  void entry_mark(ShenandoahConcurrentMark* mark);\n+  void entry_preclean(ShenandoahConcurrentMark* mark);\n@@ -407,2 +408,2 @@\n-  void op_init_mark();\n-  void op_final_mark();\n+  void op_init_mark(ShenandoahConcurrentMark* mark);\n+  void op_final_mark(ShenandoahConcurrentMark* mark);\n@@ -417,2 +418,3 @@\n-  void op_mark();\n-  void op_preclean();\n+  void op_mark_roots(ShenandoahConcurrentMark* mark);\n+  void op_mark(ShenandoahConcurrentMark* mark);\n+  void op_preclean(ShenandoahConcurrentMark* mark);\n@@ -440,0 +442,4 @@\n+\/\/ Helpers\n+  void finish_mark(ShenandoahConcurrentMark* mark);\n+  void prepare_evacuation();\n+\n@@ -442,0 +448,7 @@\n+\/\/ Mark support\n+private:\n+  ShenandoahObjToScanQueueSet* _task_queues;\n+\n+public:\n+  ShenandoahObjToScanQueueSet* task_queues() const { return _task_queues; }\n+\n@@ -448,2 +461,0 @@\n-  ShenandoahConcurrentMark*  _scm;\n-  ShenandoahMarkCompact*     _full_gc;\n@@ -456,1 +467,0 @@\n-  ShenandoahMarkCompact*     full_gc()                 { return _full_gc;           }\n@@ -463,1 +473,0 @@\n-  ShenandoahConcurrentMark*  concurrent_mark()         { return _scm;               }\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.hpp","additions":23,"deletions":14,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -0,0 +1,395 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shared\/gcTrace.hpp\"\n+#include \"gc\/shared\/referenceProcessorPhaseTimes.hpp\"\n+\n+#include \"gc\/shenandoah\/shenandoahBarrierSet.hpp\"\n+#include \"gc\/shenandoah\/shenandoahClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOopClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahVerifier.hpp\"\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.hpp\"\n+#include \"gc\/shenandoah\/shenandoahUtils.hpp\"\n+\n+ShenandoahMarkRefsSuperClosure::ShenandoahMarkRefsSuperClosure(ShenandoahObjToScanQueue* q, ReferenceProcessor* rp) :\n+  MetadataVisitingOopIterateClosure(rp),\n+  _queue(q),\n+  _heap(ShenandoahHeap::heap()),\n+  _mark_context(_heap->marking_context())\n+{ }\n+\n+ShenandoahInitMarkRootsClosure::ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q) :\n+  _queue(q),\n+  _heap(ShenandoahHeap::heap()),\n+  _mark_context(_heap->marking_context()) {\n+}\n+\n+ShenandoahMark::ShenandoahMark() :\n+  _heap(ShenandoahHeap::heap()),\n+  _task_queues(_heap->task_queues()) {\n+}\n+\n+void ShenandoahMark::clear() {\n+  \/\/ Clean up marking stacks.\n+  ShenandoahObjToScanQueueSet* queues = ShenandoahHeap::heap()->task_queues();\n+  queues->clear();\n+\n+  \/\/ Cancel SATB buffers.\n+  ShenandoahBarrierSet::satb_mark_queue_set().abandon_partial_marking();\n+}\n+\n+template <bool CANCELLABLE>\n+void ShenandoahMark::mark_loop_prework(uint w, TaskTerminator *t, ReferenceProcessor *rp,\n+                                       bool strdedup) {\n+  ShenandoahObjToScanQueue* q = get_queue(w);\n+\n+  ShenandoahLiveData* ld = _heap->get_liveness_cache(w);\n+\n+  \/\/ TODO: We can clean up this if we figure out how to do templated oop closures that\n+  \/\/ play nice with specialized_oop_iterators.\n+  if (_heap->unload_classes()) {\n+    if (_heap->has_forwarded_objects()) {\n+      if (strdedup) {\n+        ShenandoahMarkUpdateRefsMetadataDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkUpdateRefsMetadataClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    } else {\n+      if (strdedup) {\n+        ShenandoahMarkRefsMetadataDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsMetadataDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkRefsMetadataClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsMetadataClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    }\n+  } else {\n+    if (_heap->has_forwarded_objects()) {\n+      if (strdedup) {\n+        ShenandoahMarkUpdateRefsDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkUpdateRefsClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkUpdateRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    } else {\n+      if (strdedup) {\n+        ShenandoahMarkRefsDedupClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsDedupClosure, CANCELLABLE>(&cl, ld, w, t);\n+      } else {\n+        ShenandoahMarkRefsClosure cl(q, rp);\n+        mark_loop_work<ShenandoahMarkRefsClosure, CANCELLABLE>(&cl, ld, w, t);\n+      }\n+    }\n+  }\n+\n+  _heap->flush_liveness_cache(w);\n+}\n+\n+template <class T, bool CANCELLABLE>\n+void ShenandoahMark::mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *terminator) {\n+  uintx stride = ShenandoahMarkLoopStride;\n+\n+  ShenandoahHeap* heap = ShenandoahHeap::heap();\n+  ShenandoahObjToScanQueueSet* queues = task_queues();\n+  ShenandoahObjToScanQueue* q;\n+  ShenandoahMarkTask t;\n+\n+  \/*\n+   * Process outstanding queues, if any.\n+   *\n+   * There can be more queues than workers. To deal with the imbalance, we claim\n+   * extra queues first. Since marking can push new tasks into the queue associated\n+   * with this worker id, we come back to process this queue in the normal loop.\n+   *\/\n+  assert(queues->get_reserved() == heap->workers()->active_workers(),\n+         \"Need to reserve proper number of queues: reserved: %u, active: %u\", queues->get_reserved(), heap->workers()->active_workers());\n+\n+  q = queues->claim_next();\n+  while (q != NULL) {\n+    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n+      return;\n+    }\n+\n+    for (uint i = 0; i < stride; i++) {\n+      if (q->pop(t)) {\n+        do_task<T>(q, cl, live_data, &t);\n+      } else {\n+        assert(q->is_empty(), \"Must be empty\");\n+        q = queues->claim_next();\n+        break;\n+      }\n+    }\n+  }\n+  q = get_queue(worker_id);\n+\n+  ShenandoahSATBBufferClosure drain_satb(q);\n+  SATBMarkQueueSet& satb_mq_set = ShenandoahBarrierSet::satb_mark_queue_set();\n+\n+  \/*\n+   * Normal marking loop:\n+   *\/\n+  while (true) {\n+    if (CANCELLABLE && heap->check_cancelled_gc_and_yield()) {\n+      return;\n+    }\n+\n+    while (satb_mq_set.completed_buffers_num() > 0) {\n+      satb_mq_set.apply_closure_to_completed_buffer(&drain_satb);\n+    }\n+\n+    uint work = 0;\n+    for (uint i = 0; i < stride; i++) {\n+      if (q->pop(t) ||\n+          queues->steal(worker_id, t)) {\n+        do_task<T>(q, cl, live_data, &t);\n+        work++;\n+      } else {\n+        break;\n+      }\n+    }\n+\n+    if (work == 0) {\n+      \/\/ No work encountered in current stride, try to terminate.\n+      \/\/ Need to leave the STS here otherwise it might block safepoints.\n+      ShenandoahSuspendibleThreadSetLeaver stsl(CANCELLABLE && ShenandoahSuspendibleWorkers);\n+      ShenandoahTerminatorTerminator tt(heap);\n+      if (terminator->offer_termination(&tt)) return;\n+    }\n+  }\n+}\n+\n+void ShenandoahMark::mark_loop(uint worker_id, TaskTerminator* terminator, ReferenceProcessor *rp,\n+               bool cancellable, bool strdedup) {\n+  if (cancellable) {\n+    mark_loop_prework<true>(worker_id, terminator, rp, strdedup);\n+  } else {\n+    mark_loop_prework<false>(worker_id, terminator, rp, strdedup);\n+  }\n+}\n+\n+\/\/ Weak Reference Closures\n+class ShenandoahCMDrainMarkingStackClosure: public VoidClosure {\n+  const uint            _worker_id;\n+  ShenandoahMark* const _mark;\n+  TaskTerminator* const _terminator;\n+  const bool            _reset_terminator;\n+\n+public:\n+  ShenandoahCMDrainMarkingStackClosure(uint worker_id, ShenandoahMark* mark, TaskTerminator* t, bool reset_terminator = false):\n+    _worker_id(worker_id),\n+    _mark(mark),\n+    _terminator(t),\n+    _reset_terminator(reset_terminator) {\n+  }\n+\n+  void do_void() {\n+    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+\n+    ShenandoahHeap* sh = ShenandoahHeap::heap();\n+    assert(sh->process_references(), \"why else would we be here?\");\n+    ReferenceProcessor* rp = sh->ref_processor();\n+    shenandoah_assert_rp_isalive_installed();\n+\n+    _mark->mark_loop(_worker_id, _terminator, rp,\n+                   false,   \/\/ not cancellable\n+                   false);  \/\/ do not do strdedup\n+\n+    if (_reset_terminator) {\n+      _terminator->reset_for_reuse();\n+    }\n+  }\n+};\n+\n+class ShenandoahCMKeepAliveUpdateClosure : public OopClosure {\n+private:\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+\n+  template <class T>\n+  inline void do_oop_work(T* p) {\n+    ShenandoahMark::mark_through_ref<T, SIMPLE, NO_DEDUP>(p, _heap, _queue, _mark_context);\n+  }\n+\n+public:\n+  ShenandoahCMKeepAliveUpdateClosure(ShenandoahObjToScanQueue* q) :\n+    _queue(q),\n+    _heap(ShenandoahHeap::heap()),\n+    _mark_context(_heap->marking_context()) {}\n+\n+  void do_oop(narrowOop* p) { do_oop_work(p); }\n+  void do_oop(oop* p)       { do_oop_work(p); }\n+};\n+\n+class ShenandoahRefProcTaskProxy : public AbstractGangTask {\n+private:\n+  AbstractRefProcTaskExecutor::ProcessTask& _proc_task;\n+  ShenandoahMark* const                     _mark;\n+  TaskTerminator* const                     _terminator;\n+\n+public:\n+  ShenandoahRefProcTaskProxy(AbstractRefProcTaskExecutor::ProcessTask& proc_task,\n+                             ShenandoahMark* mark,\n+                             TaskTerminator* t) :\n+    AbstractGangTask(\"Shenandoah Process Weak References\"),\n+    _proc_task(proc_task),\n+    _mark(mark),\n+    _terminator(t) {\n+  }\n+\n+  void work(uint worker_id) {\n+    Thread* current_thread = Thread::current();\n+    ResourceMark rm(current_thread);\n+    HandleMark hm(current_thread);\n+    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+    ShenandoahHeap* heap = ShenandoahHeap::heap();\n+    ShenandoahParallelWorkerSession worker_session(worker_id);\n+    ShenandoahCMDrainMarkingStackClosure complete_gc(worker_id, _mark, _terminator);\n+    if (heap->has_forwarded_objects()) {\n+      ShenandoahForwardedIsAliveClosure is_alive;\n+      ShenandoahCMKeepAliveUpdateClosure keep_alive(heap->task_queues()->queue(worker_id));\n+      _proc_task.work(worker_id, is_alive, keep_alive, complete_gc);\n+    } else {\n+      ShenandoahIsAliveClosure is_alive;\n+      ShenandoahCMKeepAliveClosure keep_alive(heap->task_queues()->queue(worker_id));\n+      _proc_task.work(worker_id, is_alive, keep_alive, complete_gc);\n+    }\n+  }\n+};\n+\n+class ShenandoahRefProcTaskExecutor : public AbstractRefProcTaskExecutor {\n+private:\n+  ShenandoahMark* const _mark;\n+  WorkGang* const       _workers;\n+\n+public:\n+  ShenandoahRefProcTaskExecutor(ShenandoahMark* mark, WorkGang* workers) :\n+    _mark(mark),\n+    _workers(workers) {\n+  }\n+\n+  \/\/ Executes a task using worker threads.\n+  void execute(ProcessTask& task, uint ergo_workers) {\n+    assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a safepoint\");\n+\n+    ShenandoahHeap* heap = ShenandoahHeap::heap();\n+    ShenandoahObjToScanQueueSet* task_queues = heap->task_queues();\n+    ShenandoahPushWorkerQueuesScope scope(_workers, task_queues,\n+                                          ergo_workers,\n+                                          \/* do_check = *\/ false);\n+    uint nworkers = _workers->active_workers();\n+    task_queues->reserve(nworkers);\n+    TaskTerminator terminator(nworkers, task_queues);\n+    ShenandoahRefProcTaskProxy proc_task_proxy(task, _mark, &terminator);\n+    _workers->run_task(&proc_task_proxy);\n+  }\n+};\n+\n+\n+void ShenandoahMark::process_weak_refs(bool full_gc) {\n+  if (_heap->process_references()) {\n+    ShenandoahPhaseTimings::Phase phase_root =\n+            full_gc ?\n+            ShenandoahPhaseTimings::full_gc_weakrefs :\n+            ShenandoahPhaseTimings::degen_gc_weakrefs;\n+\n+    ShenandoahGCPhase phase(phase_root);\n+\n+    ReferenceProcessor* rp = _heap->ref_processor();\n+\n+    \/\/ NOTE: We cannot shortcut on has_discovered_references() here, because\n+    \/\/ we will miss marking JNI Weak refs then, see implementation in\n+    \/\/ ReferenceProcessor::process_discovered_references.\n+    process_weak_refs_work(full_gc);\n+\n+    rp->verify_no_references_recorded();\n+    assert(!rp->discovery_enabled(), \"Post condition\");\n+  }\n+}\n+\n+void ShenandoahMark::process_weak_refs_work(bool full_gc) {\n+  ReferenceProcessor* rp = _heap->ref_processor();\n+\n+  ShenandoahPhaseTimings::Phase phase_process =\n+          full_gc ?\n+          ShenandoahPhaseTimings::full_gc_weakrefs_process :\n+          ShenandoahPhaseTimings::degen_gc_weakrefs_process;\n+\n+  ShenandoahIsAliveSelector is_alive;\n+  WorkGang* workers = _heap->workers();\n+  uint nworkers = workers->active_workers();\n+\n+  rp->setup_policy(_heap->soft_ref_policy()->should_clear_all_soft_refs());\n+  rp->set_active_mt_degree(nworkers);\n+\n+  assert(task_queues()->is_empty(), \"Should be empty\");\n+\n+  \/\/ complete_gc and keep_alive closures instantiated here are only needed for\n+  \/\/ single-threaded path in RP. They share the queue 0 for tracking work, which\n+  \/\/ simplifies implementation. Since RP may decide to call complete_gc several\n+  \/\/ times, we need to be able to reuse the terminator.\n+  uint serial_worker_id = 0;\n+  TaskTerminator terminator(1, task_queues());\n+  ShenandoahCMDrainMarkingStackClosure complete_gc(serial_worker_id, this, &terminator, \/* reset_terminator = *\/ true);\n+\n+  ShenandoahRefProcTaskExecutor executor(this, workers);\n+\n+  ReferenceProcessorPhaseTimes pt(heap()->gc_timer(), rp->num_queues());\n+\n+  {\n+    \/\/ Note: Don't emit JFR event for this phase, to avoid overflow nesting phase level.\n+    \/\/ Reference Processor emits 2 levels JFR event, that can get us over the JFR\n+    \/\/ event nesting level limits, in case of degenerated GC gets upgraded to\n+    \/\/ full GC.\n+    ShenandoahTimingsTracker phase_timing(phase_process);\n+\n+    if (_heap->has_forwarded_objects()) {\n+      ShenandoahCMKeepAliveUpdateClosure keep_alive(get_queue(serial_worker_id));\n+      const ReferenceProcessorStats& stats =\n+        rp->process_discovered_references(is_alive.is_alive_closure(), &keep_alive,\n+                                          &complete_gc, &executor,\n+                                          &pt);\n+       _heap->tracer()->report_gc_reference_stats(stats);\n+    } else {\n+      ShenandoahCMKeepAliveClosure keep_alive(get_queue(serial_worker_id));\n+      const ReferenceProcessorStats& stats =\n+        rp->process_discovered_references(is_alive.is_alive_closure(), &keep_alive,\n+                                          &complete_gc, &executor,\n+                                          &pt);\n+      _heap->tracer()->report_gc_reference_stats(stats);\n+    }\n+\n+    pt.print_all_references();\n+\n+    assert(task_queues()->is_empty(), \"Should be empty\");\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.cpp","additions":395,"deletions":0,"binary":false,"changes":395,"status":"added"},{"patch":"@@ -0,0 +1,124 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHMARK_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHMARK_HPP\n+\n+#include \"gc\/shared\/taskTerminator.hpp\"\n+#include \"gc\/shenandoah\/shenandoahOopClosures.hpp\"\n+#include \"gc\/shenandoah\/shenandoahPhaseTimings.hpp\"\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.hpp\"\n+\n+class ShenandoahCMDrainMarkingStackClosure;\n+\n+class ShenandoahInitMarkRootsClosure : public OopClosure {\n+private:\n+  ShenandoahObjToScanQueue* const _queue;\n+  ShenandoahHeap*           const _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+\n+  template <class T>\n+  inline void do_oop_work(T* p);\n+\n+public:\n+  ShenandoahInitMarkRootsClosure(ShenandoahObjToScanQueue* q);\n+\n+  void do_oop(narrowOop* p) { do_oop_work(p); }\n+  void do_oop(oop* p)       { do_oop_work(p); }\n+};\n+\n+class ShenandoahCMKeepAliveClosure : public OopClosure {\n+private:\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+\n+  template <class T>\n+  inline void do_oop_work(T* p);\n+\n+public:\n+  ShenandoahCMKeepAliveClosure(ShenandoahObjToScanQueue* q) :\n+    _queue(q),\n+    _heap(ShenandoahHeap::heap()),\n+    _mark_context(_heap->marking_context()) {}\n+\n+  void do_oop(narrowOop* p) { do_oop_work(p); }\n+  void do_oop(oop* p)       { do_oop_work(p); }\n+};\n+\n+\/\/ Base class for mark\n+\/\/ Mark class does not maintain states. Instead, mark states are\n+\/\/ maintained by task queues, mark bitmap and SATB buffers (concurrent mark)\n+class ShenandoahMark: public StackObj {\n+  friend class ShenandoahCMDrainMarkingStackClosure;\n+\n+protected:\n+  ShenandoahHeap* const              _heap;\n+  ShenandoahObjToScanQueueSet* const _task_queues;\n+\n+protected:\n+  ShenandoahMark();\n+\n+public:\n+  template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n+  static inline void mark_through_ref(T* p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context);\n+\n+  static void clear();\n+\n+  \/\/ Helpers\n+  inline ShenandoahObjToScanQueueSet* task_queues() const;\n+  inline ShenandoahObjToScanQueue* get_queue(uint index) const;\n+\n+\/\/ ---------- Marking loop and tasks\n+private:\n+  template <class T>\n+  inline void do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task);\n+\n+  template <class T>\n+  inline void do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop array);\n+\n+  template <class T>\n+  inline void do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop array, int chunk, int pow);\n+\n+  inline void count_liveness(ShenandoahLiveData* live_data, oop obj);\n+\n+  template <class T, bool CANCELLABLE>\n+  void mark_loop_work(T* cl, ShenandoahLiveData* live_data, uint worker_id, TaskTerminator *t);\n+\n+  template <bool CANCELLABLE>\n+  void mark_loop_prework(uint worker_id, TaskTerminator *terminator, ReferenceProcessor *rp, bool strdedup);\n+\n+protected:\n+  void mark_loop(uint worker_id, TaskTerminator* terminator, ReferenceProcessor *rp,\n+                 bool cancellable, bool strdedup);\n+\n+  \/\/ Reference processing\n+  void process_weak_refs(bool full_gc);\n+  void process_weak_refs_work(bool full_gc);\n+\n+  inline ShenandoahHeap* heap() const;\n+};\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHMARK_HPP\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.hpp","additions":124,"deletions":0,"binary":false,"changes":124,"status":"added"},{"patch":"@@ -0,0 +1,292 @@\n+\/*\n+ * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHMARK_INLINE_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHMARK_INLINE_HPP\n+\n+#include \"gc\/shenandoah\/shenandoahAsserts.hpp\"\n+#include \"gc\/shenandoah\/shenandoahBarrierSet.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahHeap.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMarkingContext.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahStringDedup.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahTaskqueue.inline.hpp\"\n+#include \"memory\/iterator.inline.hpp\"\n+#include \"oops\/compressedOops.inline.hpp\"\n+#include \"oops\/oop.inline.hpp\"\n+#include \"runtime\/prefetch.inline.hpp\"\n+\n+template <class T>\n+void ShenandoahInitMarkRootsClosure::do_oop_work(T* p) {\n+  ShenandoahMark::mark_through_ref<T, NONE, NO_DEDUP>(p, _heap, _queue, _mark_context);\n+}\n+\n+template <class T>\n+void ShenandoahCMKeepAliveClosure::do_oop_work(T* p) {\n+  ShenandoahMark::mark_through_ref<T, NONE, NO_DEDUP>(p, _heap, _queue, _mark_context);\n+}\n+\n+template <class T>\n+void ShenandoahMark::do_task(ShenandoahObjToScanQueue* q, T* cl, ShenandoahLiveData* live_data, ShenandoahMarkTask* task) {\n+  oop obj = task->obj();\n+\n+  shenandoah_assert_not_forwarded(NULL, obj);\n+  shenandoah_assert_marked(NULL, obj);\n+  shenandoah_assert_not_in_cset_except(NULL, obj, _heap->cancelled_gc());\n+\n+  if (task->is_not_chunked()) {\n+    if (obj->is_instance()) {\n+      \/\/ Case 1: Normal oop, process as usual.\n+      obj->oop_iterate(cl);\n+    } else if (obj->is_objArray()) {\n+      \/\/ Case 2: Object array instance and no chunk is set. Must be the first\n+      \/\/ time we visit it, start the chunked processing.\n+      do_chunked_array_start<T>(q, cl, obj);\n+    } else {\n+      \/\/ Case 3: Primitive array. Do nothing, no oops there. We use the same\n+      \/\/ performance tweak TypeArrayKlass::oop_oop_iterate_impl is using:\n+      \/\/ We skip iterating over the klass pointer since we know that\n+      \/\/ Universe::TypeArrayKlass never moves.\n+      assert (obj->is_typeArray(), \"should be type array\");\n+    }\n+    \/\/ Count liveness the last: push the outstanding work to the queues first\n+    count_liveness(live_data, obj);\n+  } else {\n+    \/\/ Case 4: Array chunk, has sensible chunk id. Process it.\n+    do_chunked_array<T>(q, cl, obj, task->chunk(), task->pow());\n+  }\n+}\n+\n+inline void ShenandoahMark::count_liveness(ShenandoahLiveData* live_data, oop obj) {\n+  size_t region_idx = _heap->heap_region_index_containing(obj);\n+  ShenandoahHeapRegion* region = _heap->get_region(region_idx);\n+  size_t size = obj->size();\n+\n+  if (!region->is_humongous_start()) {\n+    assert(!region->is_humongous(), \"Cannot have continuations here\");\n+    ShenandoahLiveData cur = live_data[region_idx];\n+    size_t new_val = size + cur;\n+    if (new_val >= SHENANDOAH_LIVEDATA_MAX) {\n+      \/\/ overflow, flush to region data\n+      region->increase_live_data_gc_words(new_val);\n+      live_data[region_idx] = 0;\n+    } else {\n+      \/\/ still good, remember in locals\n+      live_data[region_idx] = (ShenandoahLiveData) new_val;\n+    }\n+  } else {\n+    shenandoah_assert_in_correct_region(NULL, obj);\n+    size_t num_regions = ShenandoahHeapRegion::required_regions(size * HeapWordSize);\n+\n+    for (size_t i = region_idx; i < region_idx + num_regions; i++) {\n+      ShenandoahHeapRegion* chain_reg = _heap->get_region(i);\n+      assert(chain_reg->is_humongous(), \"Expecting a humongous region\");\n+      chain_reg->increase_live_data_gc_words(chain_reg->used() >> LogHeapWordSize);\n+    }\n+  }\n+}\n+\n+template <class T>\n+inline void ShenandoahMark::do_chunked_array_start(ShenandoahObjToScanQueue* q, T* cl, oop obj) {\n+  assert(obj->is_objArray(), \"expect object array\");\n+  objArrayOop array = objArrayOop(obj);\n+  int len = array->length();\n+\n+  if (len <= (int) ObjArrayMarkingStride*2) {\n+    \/\/ A few slices only, process directly\n+    array->oop_iterate_range(cl, 0, len);\n+  } else {\n+    int bits = log2_long((size_t) len);\n+    \/\/ Compensate for non-power-of-two arrays, cover the array in excess:\n+    if (len != (1 << bits)) bits++;\n+\n+    \/\/ Only allow full chunks on the queue. This frees do_chunked_array() from checking from\/to\n+    \/\/ boundaries against array->length(), touching the array header on every chunk.\n+    \/\/\n+    \/\/ To do this, we cut the prefix in full-sized chunks, and submit them on the queue.\n+    \/\/ If the array is not divided in chunk sizes, then there would be an irregular tail,\n+    \/\/ which we will process separately.\n+\n+    int last_idx = 0;\n+\n+    int chunk = 1;\n+    int pow = bits;\n+\n+    \/\/ Handle overflow\n+    if (pow >= 31) {\n+      assert (pow == 31, \"sanity\");\n+      pow--;\n+      chunk = 2;\n+      last_idx = (1 << pow);\n+      bool pushed = q->push(ShenandoahMarkTask(array, 1, pow));\n+      assert(pushed, \"overflow queue should always succeed pushing\");\n+    }\n+\n+    \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Record the last\n+    \/\/ successful right boundary to figure out the irregular tail.\n+    while ((1 << pow) > (int)ObjArrayMarkingStride &&\n+           (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n+      pow--;\n+      int left_chunk = chunk*2 - 1;\n+      int right_chunk = chunk*2;\n+      int left_chunk_end = left_chunk * (1 << pow);\n+      if (left_chunk_end < len) {\n+        bool pushed = q->push(ShenandoahMarkTask(array, left_chunk, pow));\n+        assert(pushed, \"overflow queue should always succeed pushing\");\n+        chunk = right_chunk;\n+        last_idx = left_chunk_end;\n+      } else {\n+        chunk = left_chunk;\n+      }\n+    }\n+\n+    \/\/ Process the irregular tail, if present\n+    int from = last_idx;\n+    if (from < len) {\n+      array->oop_iterate_range(cl, from, len);\n+    }\n+  }\n+}\n+\n+template <class T>\n+inline void ShenandoahMark::do_chunked_array(ShenandoahObjToScanQueue* q, T* cl, oop obj, int chunk, int pow) {\n+  assert(obj->is_objArray(), \"expect object array\");\n+  objArrayOop array = objArrayOop(obj);\n+\n+  assert (ObjArrayMarkingStride > 0, \"sanity\");\n+\n+  \/\/ Split out tasks, as suggested in ShenandoahMarkTask docs. Avoid pushing tasks that\n+  \/\/ are known to start beyond the array.\n+  while ((1 << pow) > (int)ObjArrayMarkingStride && (chunk*2 < ShenandoahMarkTask::chunk_size())) {\n+    pow--;\n+    chunk *= 2;\n+    bool pushed = q->push(ShenandoahMarkTask(array, chunk - 1, pow));\n+    assert(pushed, \"overflow queue should always succeed pushing\");\n+  }\n+\n+  int chunk_size = 1 << pow;\n+\n+  int from = (chunk - 1) * chunk_size;\n+  int to = chunk * chunk_size;\n+\n+#ifdef ASSERT\n+  int len = array->length();\n+  assert (0 <= from && from < len, \"from is sane: %d\/%d\", from, len);\n+  assert (0 < to && to <= len, \"to is sane: %d\/%d\", to, len);\n+#endif\n+\n+  array->oop_iterate_range(cl, from, to);\n+}\n+\n+class ShenandoahSATBBufferClosure : public SATBBufferClosure {\n+private:\n+  ShenandoahObjToScanQueue* _queue;\n+  ShenandoahHeap* _heap;\n+  ShenandoahMarkingContext* const _mark_context;\n+public:\n+  ShenandoahSATBBufferClosure(ShenandoahObjToScanQueue* q) :\n+    _queue(q),\n+    _heap(ShenandoahHeap::heap()),\n+    _mark_context(_heap->marking_context())\n+  {\n+  }\n+\n+  void do_buffer(void **buffer, size_t size) {\n+    assert(size == 0 || !_heap->has_forwarded_objects(), \"Forwarded objects are not expected here\");\n+    if (ShenandoahStringDedup::is_enabled()) {\n+      do_buffer_impl<ENQUEUE_DEDUP>(buffer, size);\n+    } else {\n+      do_buffer_impl<NO_DEDUP>(buffer, size);\n+    }\n+  }\n+\n+  template<StringDedupMode STRING_DEDUP>\n+  void do_buffer_impl(void **buffer, size_t size) {\n+    for (size_t i = 0; i < size; ++i) {\n+      oop *p = (oop *) &buffer[i];\n+      ShenandoahMark::mark_through_ref<oop, NONE, STRING_DEDUP>(p, _heap, _queue, _mark_context);\n+    }\n+  }\n+};\n+\n+template<class T, UpdateRefsMode UPDATE_REFS, StringDedupMode STRING_DEDUP>\n+inline void ShenandoahMark::mark_through_ref(T *p, ShenandoahHeap* heap, ShenandoahObjToScanQueue* q, ShenandoahMarkingContext* const mark_context) {\n+  T o = RawAccess<>::oop_load(p);\n+  if (!CompressedOops::is_null(o)) {\n+    oop obj = CompressedOops::decode_not_null(o);\n+    switch (UPDATE_REFS) {\n+    case NONE:\n+      break;\n+    case RESOLVE:\n+      obj = ShenandoahBarrierSet::resolve_forwarded_not_null(obj);\n+      break;\n+    case SIMPLE:\n+      \/\/ We piggy-back reference updating to the marking tasks.\n+      obj = heap->update_with_forwarded_not_null(p, obj);\n+      break;\n+    case CONCURRENT:\n+      obj = heap->maybe_update_with_forwarded_not_null(p, obj);\n+      break;\n+    default:\n+      ShouldNotReachHere();\n+    }\n+\n+    \/\/ Note: Only when concurrently updating references can obj be different\n+    \/\/ (that is, really different, not just different from-\/to-space copies of the same)\n+    \/\/ from the one we originally loaded. Mutator thread can beat us by writing something\n+    \/\/ else into the location. In that case, we would mark through that updated value,\n+    \/\/ on the off-chance it is not handled by other means (e.g. via SATB). However,\n+    \/\/ if that write was NULL, we don't need to do anything else.\n+    if (UPDATE_REFS != CONCURRENT || !CompressedOops::is_null(obj)) {\n+      shenandoah_assert_not_forwarded(p, obj);\n+      shenandoah_assert_not_in_cset_except(p, obj, heap->cancelled_gc());\n+\n+      if (mark_context->mark(obj)) {\n+        bool pushed = q->push(ShenandoahMarkTask(obj));\n+        assert(pushed, \"overflow queue should always succeed pushing\");\n+\n+        if ((STRING_DEDUP == ENQUEUE_DEDUP) && ShenandoahStringDedup::is_candidate(obj)) {\n+          assert(ShenandoahStringDedup::is_enabled(), \"Must be enabled\");\n+          ShenandoahStringDedup::enqueue_candidate(obj);\n+        }\n+      }\n+\n+      shenandoah_assert_marked(p, obj);\n+    }\n+  }\n+}\n+\n+ShenandoahObjToScanQueueSet* ShenandoahMark::task_queues() const {\n+  return _task_queues;\n+}\n+\n+ShenandoahObjToScanQueue* ShenandoahMark::get_queue(uint index) const {\n+  return _task_queues->queue(index);\n+}\n+\n+ShenandoahHeap* ShenandoahMark::heap() const {\n+  return _heap;\n+}\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHMARK_INLINE_HPP\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMark.inline.hpp","additions":292,"deletions":0,"binary":false,"changes":292,"status":"added"},{"patch":"@@ -31,1 +31,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahConcurrentMark.hpp\"\n@@ -36,0 +36,1 @@\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -42,0 +43,1 @@\n+#include \"gc\/shenandoah\/shenandoahSTWMark.hpp\"\n@@ -116,1 +118,1 @@\n-      heap->concurrent_mark()->cancel();\n+      ShenandoahConcurrentMark::cancel();\n@@ -123,1 +125,1 @@\n-      heap->concurrent_mark()->update_roots(ShenandoahPhaseTimings::full_gc_update_roots);\n+      ShenandoahConcurrentMark::update_roots(ShenandoahPhaseTimings::full_gc_update_roots);\n@@ -131,7 +133,1 @@\n-    \/\/ e. Abandon reference discovery and clear all discovered references.\n-    ReferenceProcessor* rp = heap->ref_processor();\n-    rp->disable_discovery();\n-    rp->abandon_partial_discovery();\n-    rp->verify_no_references_recorded();\n-\n-    \/\/ f. Set back forwarded objects bit back, in case some steps above dropped it.\n+    \/\/ e. Set back forwarded objects bit back, in case some steps above dropped it.\n@@ -140,1 +136,1 @@\n-    \/\/ g. Sync pinned region status from the CP marks\n+    \/\/ f. Sync pinned region status from the CP marks\n@@ -242,2 +238,0 @@\n-  ShenandoahConcurrentMark* cm = heap->concurrent_mark();\n-\n@@ -247,5 +241,2 @@\n-  ReferenceProcessor* rp = heap->ref_processor();\n-  \/\/ enable (\"weak\") refs discovery\n-  rp->enable_discovery(true \/*verify_no_refs*\/);\n-  rp->setup_policy(true); \/\/ forcefully purge all soft references\n-  rp->set_active_mt_degree(heap->workers()->active_workers());\n+  ShenandoahSTWMark mark(true \/*full_gc*\/);\n+  mark.mark();\n@@ -253,2 +244,0 @@\n-  cm->mark_roots(ShenandoahPhaseTimings::full_gc_scan_roots);\n-  cm->finish_mark_from_roots(\/* full_gc = *\/ true);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkCompact.cpp","additions":9,"deletions":20,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-class ShenandoahMarkCompact : public CHeapObj<mtGC> {\n+class ShenandoahMarkCompact : public StackObj {\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahMarkCompact.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2015, 2020, Red Hat, Inc. All rights reserved.\n@@ -29,1 +29,1 @@\n-#include \"gc\/shenandoah\/shenandoahConcurrentMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n@@ -33,1 +33,1 @@\n-  ShenandoahConcurrentMark::mark_through_ref<T, UPDATE_REFS, STRING_DEDUP>(p, _heap, _queue, _mark_context);\n+  ShenandoahMark::mark_through_ref<T, UPDATE_REFS, STRING_DEDUP>(p, _heap, _queue, _mark_context);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahOopClosures.inline.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -103,1 +103,1 @@\n-    case full_gc_scan_roots:\n+    case full_gc_mark:\n@@ -106,1 +106,2 @@\n-    case degen_gc_scan_conc_roots:\n+    case degen_gc_stw_mark:\n+    case degen_gc_mark:\n@@ -108,1 +109,0 @@\n-    case full_gc_scan_conc_roots:\n@@ -130,1 +130,1 @@\n-    case full_gc_scan_roots:\n+    case full_gc_mark:\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -47,0 +47,1 @@\n+  f(CNT_PREFIX ## ParallelMark,             DESC_PREFIX \"Parallel Mark\")               \\\n@@ -125,2 +126,6 @@\n-  f(degen_gc_scan_conc_roots,                       \"  Degen Mark Roots\")              \\\n-  SHENANDOAH_PAR_PHASE_DO(degen_gc_conc_mark_,      \"    DM: \", f)                     \\\n+  f(degen_gc_stw_mark,                              \"  Degen STW Mark\")                \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_stw_mark_,      \"     DSM: \", f)                    \\\n+  f(degen_gc_mark,                                  \"  Degen Mark\")                    \\\n+  SHENANDOAH_PAR_PHASE_DO(degen_gc_mark_,           \"    DM: \", f)                     \\\n+  f(degen_gc_weakrefs,                              \"  Weak References\")               \\\n+  f(degen_gc_weakrefs_process,                      \"   Process\")                      \\\n@@ -136,4 +141,0 @@\n-  f(full_gc_scan_roots,                             \"  Scan Roots\")                    \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_scan_roots_,      \"    FS: \", f)                     \\\n-  f(full_gc_scan_conc_roots,                        \"  Scan Concurrent Roots\")         \\\n-  SHENANDOAH_PAR_PHASE_DO(full_gc_scan_conc_roots,  \"    FCS: \", f)                    \\\n@@ -141,1 +142,1 @@\n-  f(full_gc_mark_finish_queues,                     \"    Finish Queues\")               \\\n+  SHENANDOAH_PAR_PHASE_DO(full_gc_mark_,            \"    FM: \", f)                     \\\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahPhaseTimings.hpp","additions":8,"deletions":7,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -157,1 +157,0 @@\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Must at safepoint\");\n@@ -183,0 +182,49 @@\n+ShenandoahSTWRootScanner::ShenandoahSTWRootScanner(ShenandoahPhaseTimings::Phase phase) :\n+   ShenandoahRootProcessor(phase),\n+   _thread_roots(phase, ShenandoahHeap::heap()->workers()->active_workers() > 1),\n+   _code_roots(phase),\n+   _cld_roots(phase, ShenandoahHeap::heap()->workers()->active_workers()),\n+   _vm_roots(phase),\n+   _dedup_roots(phase),\n+   _unload_classes(ShenandoahHeap::heap()->unload_classes()) {\n+}\n+\n+ShenandoahConcurrentRootScanner::ShenandoahConcurrentRootScanner(uint n_workers,\n+                                                                 ShenandoahPhaseTimings::Phase phase) :\n+   ShenandoahRootProcessor(phase),\n+  _vm_roots(phase),\n+  _cld_roots(phase, n_workers),\n+  _dedup_roots(phase),\n+  _codecache_snapshot(NULL),\n+  _phase(phase) {\n+  if (!ShenandoahHeap::heap()->unload_classes()) {\n+    CodeCache_lock->lock_without_safepoint_check();\n+    _codecache_snapshot = ShenandoahCodeRoots::table()->snapshot_for_iteration();\n+  }\n+  assert(!ShenandoahHeap::heap()->has_forwarded_objects(), \"Not expecting forwarded pointers during concurrent marking\");\n+}\n+\n+ShenandoahConcurrentRootScanner::~ShenandoahConcurrentRootScanner() {\n+  if (!ShenandoahHeap::heap()->unload_classes()) {\n+    ShenandoahCodeRoots::table()->finish_iteration(_codecache_snapshot);\n+    CodeCache_lock->unlock();\n+  }\n+}\n+\n+void ShenandoahConcurrentRootScanner::roots_do(OopClosure* oops, uint worker_id) {\n+  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n+  CLDToOopClosure clds_cl(oops, ClassLoaderData::_claim_strong);\n+  _vm_roots.oops_do(oops, worker_id);\n+\n+  if (!heap->unload_classes()) {\n+    AlwaysTrueClosure always_true;\n+    _cld_roots.cld_do(&clds_cl, worker_id);\n+    _dedup_roots.oops_do(&always_true, oops, worker_id);\n+    ShenandoahWorkerTimingsTracker timer(_phase, ShenandoahPhaseTimings::CodeCacheRoots, worker_id);\n+    CodeBlobToOopClosure blobs(oops, !CodeBlobToOopClosure::FixRelocations);\n+    _codecache_snapshot->parallel_blobs_do(&blobs);\n+  } else {\n+    _cld_roots.always_strong_cld_do(&clds_cl, worker_id);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.cpp","additions":49,"deletions":1,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -197,2 +197,19 @@\n-template <bool CONCURRENT>\n-class ShenandoahConcurrentRootScanner {\n+\/\/ STW root scanner\n+class ShenandoahSTWRootScanner : public ShenandoahRootProcessor {\n+private:\n+  ShenandoahThreadRoots           _thread_roots;\n+  ShenandoahCodeCacheRoots        _code_roots;\n+  ShenandoahClassLoaderDataRoots<false \/*concurrent*\/, false \/* single_thread*\/>\n+                                  _cld_roots;\n+  ShenandoahVMRoots<false \/*concurrent*\/>\n+                                  _vm_roots;\n+  ShenandoahStringDedupRoots      _dedup_roots;\n+  const bool                      _unload_classes;\n+public:\n+  ShenandoahSTWRootScanner(ShenandoahPhaseTimings::Phase phase);\n+\n+  template <typename T>\n+  void roots_do(T* oops, uint worker_id);\n+};\n+\n+class ShenandoahConcurrentRootScanner : public ShenandoahRootProcessor {\n@@ -200,2 +217,2 @@\n-  ShenandoahVMRoots<CONCURRENT>            _vm_roots;\n-  ShenandoahClassLoaderDataRoots<CONCURRENT, false \/* single-threaded*\/>\n+  ShenandoahVMRoots<true \/*concurrent*\/>    _vm_roots;\n+  ShenandoahClassLoaderDataRoots<true \/*concurrent*\/, false \/* single-threaded*\/>\n@@ -211,1 +228,1 @@\n-  void oops_do(OopClosure* oops, uint worker_id);\n+  void roots_do(OopClosure* oops, uint worker_id);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.hpp","additions":22,"deletions":5,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -119,1 +119,0 @@\n-\n@@ -147,36 +146,19 @@\n-template <bool CONCURRENT>\n-ShenandoahConcurrentRootScanner<CONCURRENT>::ShenandoahConcurrentRootScanner(uint n_workers,\n-                                                                             ShenandoahPhaseTimings::Phase phase) :\n-  _vm_roots(phase),\n-  _cld_roots(phase, n_workers),\n-  _dedup_roots(phase),\n-  _codecache_snapshot(NULL),\n-  _phase(phase) {\n-  if (!ShenandoahHeap::heap()->unload_classes()) {\n-    if (CONCURRENT) {\n-      CodeCache_lock->lock_without_safepoint_check();\n-    } else {\n-      assert(SafepointSynchronize::is_at_safepoint(), \"Must be at a safepoint\");\n-    }\n-    _codecache_snapshot = ShenandoahCodeRoots::table()->snapshot_for_iteration();\n-  }\n-  assert(!CONCURRENT || !ShenandoahHeap::heap()->has_forwarded_objects(), \"Not expecting forwarded pointers during concurrent marking\");\n-}\n-\n-template <bool CONCURRENT>\n-ShenandoahConcurrentRootScanner<CONCURRENT>::~ShenandoahConcurrentRootScanner() {\n-  if (!ShenandoahHeap::heap()->unload_classes()) {\n-    ShenandoahCodeRoots::table()->finish_iteration(_codecache_snapshot);\n-    if (CONCURRENT) {\n-      CodeCache_lock->unlock();\n-    }\n-  }\n-}\n-\n-template <bool CONCURRENT>\n-void ShenandoahConcurrentRootScanner<CONCURRENT>::oops_do(OopClosure* oops, uint worker_id) {\n-  ShenandoahHeap* const heap = ShenandoahHeap::heap();\n-  CLDToOopClosure clds_cl(oops, CONCURRENT ? ClassLoaderData::_claim_strong : ClassLoaderData::_claim_none);\n-  _vm_roots.oops_do(oops, worker_id);\n-\n-  if (!heap->unload_classes()) {\n+\/\/ The rationale for selecting the roots to scan is as follows:\n+\/\/   a. With unload_classes = true, we only want to scan the actual strong roots from the\n+\/\/      code cache. This will allow us to identify the dead classes, unload them, *and*\n+\/\/      invalidate the relevant code cache blobs. This could be only done together with\n+\/\/      class unloading.\n+\/\/   b. With unload_classes = false, we have to nominally retain all the references from code\n+\/\/      cache, because there could be the case of embedded class\/oop in the generated code,\n+\/\/      which we will never visit during mark. Without code cache invalidation, as in (a),\n+\/\/      we risk executing that code cache blob, and crashing.\n+template <typename T>\n+void ShenandoahSTWRootScanner::roots_do(T* oops, uint worker_id) {\n+  MarkingCodeBlobClosure blobs_cl(oops, !CodeBlobToOopClosure::FixRelocations);\n+  CLDToOopClosure clds(oops, ClassLoaderData::_claim_strong);\n+  ResourceMark rm;\n+\n+  if (_unload_classes) {\n+    _thread_roots.oops_do(oops, &blobs_cl, worker_id);\n+    _cld_roots.always_strong_cld_do(&clds, worker_id);\n+  } else {\n@@ -184,1 +166,3 @@\n-    _cld_roots.cld_do(&clds_cl, worker_id);\n+    _thread_roots.oops_do(oops, NULL, worker_id);\n+    _code_roots.code_blobs_do(&blobs_cl, worker_id);\n+    _cld_roots.cld_do(&clds, worker_id);\n@@ -186,5 +170,0 @@\n-    ShenandoahWorkerTimingsTracker timer(_phase, ShenandoahPhaseTimings::CodeCacheRoots, worker_id);\n-    CodeBlobToOopClosure blobs(oops, !CodeBlobToOopClosure::FixRelocations);\n-    _codecache_snapshot->parallel_blobs_do(&blobs);\n-  } else {\n-    _cld_roots.always_strong_cld_do(&clds_cl, worker_id);\n@@ -192,0 +171,2 @@\n+\n+  _vm_roots.oops_do<T>(oops, worker_id);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahRootProcessor.inline.hpp","additions":24,"deletions":43,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -0,0 +1,125 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/shared\/strongRootsScope.hpp\"\n+#include \"gc\/shared\/workgroup.hpp\"\n+#include \"gc\/shenandoah\/shenandoahClosures.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahRootProcessor.inline.hpp\"\n+#include \"gc\/shenandoah\/shenandoahSTWMark.hpp\"\n+#include \"gc\/shenandoah\/shenandoahVerifier.hpp\"\n+\n+\n+class ShenandoahSTWMarkTask : public AbstractGangTask {\n+private:\n+  ShenandoahSTWMark* const _mark;\n+\n+public:\n+  ShenandoahSTWMarkTask(ShenandoahSTWMark* mark);\n+  void work(uint worker_id);\n+};\n+\n+ShenandoahSTWMarkTask::ShenandoahSTWMarkTask(ShenandoahSTWMark* mark) :\n+  AbstractGangTask(\"Shenandoah STW mark\"),\n+  _mark(mark) {\n+}\n+\n+void ShenandoahSTWMarkTask::work(uint worker_id) {\n+  ShenandoahParallelWorkerSession worker_session(worker_id);\n+  _mark->mark_roots(worker_id);\n+  _mark->finish_mark(worker_id);\n+}\n+\n+ShenandoahSTWMark::ShenandoahSTWMark(bool full_gc) :\n+  ShenandoahMark(),\n+  _root_scanner(full_gc ? ShenandoahPhaseTimings::full_gc_mark : ShenandoahPhaseTimings::degen_gc_stw_mark),\n+  _terminator(ShenandoahHeap::heap()->workers()->active_workers(), ShenandoahHeap::heap()->task_queues()),\n+  _full_gc(full_gc) {\n+  assert(ShenandoahSafepoint::is_at_shenandoah_safepoint(), \"Must be at a Shenandoah safepoint\");\n+}\n+\n+void ShenandoahSTWMark::mark() {\n+  \/\/ Init mark, do not expect forwarded pointers in roots\n+  if (ShenandoahVerify) {\n+    assert(Thread::current()->is_VM_thread(), \"Must be\");\n+    heap()->verifier()->verify_roots_no_forwarded();\n+  }\n+\n+  uint nworkers = heap()->workers()->active_workers();\n+  task_queues()->reserve(nworkers);\n+\n+  ReferenceProcessor* rp = NULL;\n+  if (heap()->process_references()) {\n+    rp = heap()->ref_processor();\n+    rp->set_active_mt_degree(nworkers);\n+\n+    \/\/ enable (\"weak\") refs discovery\n+    rp->enable_discovery(true \/*verify_no_refs*\/);\n+    rp->setup_policy(_heap->soft_ref_policy()->should_clear_all_soft_refs());\n+  }\n+\n+  shenandoah_assert_rp_isalive_not_installed();\n+  ShenandoahIsAliveSelector is_alive;\n+  ReferenceProcessorIsAliveMutator fix_isalive(rp, is_alive.is_alive_closure());\n+\n+  {\n+    \/\/ Mark\n+    StrongRootsScope scope(nworkers);\n+    ShenandoahSTWMarkTask task(this);\n+    heap()->workers()->run_task(&task);\n+\n+    assert(task_queues()->is_empty(), \"Should be empty\");\n+  }\n+\n+  \/\/ Weak reference processing\n+  process_weak_refs(_full_gc \/*full gc*\/);\n+\n+  assert(task_queues()->is_empty(), \"Should be empty\");\n+  TASKQUEUE_STATS_ONLY(task_queues()->print_taskqueue_stats());\n+  TASKQUEUE_STATS_ONLY(task_queues()->reset_taskqueue_stats());\n+\n+}\n+\n+void ShenandoahSTWMark::mark_roots(uint worker_id) {\n+  ShenandoahInitMarkRootsClosure  init_mark(task_queues()->queue(worker_id));\n+  _root_scanner.roots_do(&init_mark, worker_id);\n+}\n+\n+void ShenandoahSTWMark::finish_mark(uint worker_id) {\n+  ShenandoahPhaseTimings::Phase phase = _full_gc ? ShenandoahPhaseTimings::full_gc_mark : ShenandoahPhaseTimings::degen_gc_stw_mark;\n+  ShenandoahWorkerTimingsTracker timer(phase, ShenandoahPhaseTimings::ParallelMark, worker_id);\n+\n+  ReferenceProcessor* rp = NULL;\n+  if (heap()->process_references()) {\n+    rp = heap()->ref_processor();\n+  }\n+\n+  mark_loop(worker_id, &_terminator, rp,\n+            false, \/\/ not cancellable\n+            ShenandoahStringDedup::is_enabled());\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahSTWMark.cpp","additions":125,"deletions":0,"binary":false,"changes":125,"status":"added"},{"patch":"@@ -0,0 +1,51 @@\n+\/*\n+ * Copyright (c) 2020, Red Hat, Inc. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_GC_SHENANDOAH_SHENANDOAHSTWMARK_HPP\n+#define SHARE_GC_SHENANDOAH_SHENANDOAHSTWMARK_HPP\n+\n+#include \"gc\/shared\/taskTerminator.hpp\"\n+#include \"gc\/shenandoah\/shenandoahMark.hpp\"\n+#include \"gc\/shenandoah\/shenandoahRootProcessor.hpp\"\n+\n+class ShenandoahSTWMarkTask;\n+\n+class ShenandoahSTWMark : public ShenandoahMark {\n+  friend class ShenandoahSTWMarkTask;\n+\n+private:\n+  ShenandoahSTWRootScanner      _root_scanner;\n+  TaskTerminator                _terminator;\n+  bool                          _full_gc;\n+public:\n+ ShenandoahSTWMark(bool full_gc);\n+ void mark();\n+\n+private:\n+  void mark_roots(uint worker_id);\n+  void finish_mark(uint worker_id);\n+};\n+\n+#endif \/\/ SHARE_GC_SHENANDOAH_SHENANDOAHSTWMARK_HPP\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahSTWMark.hpp","additions":51,"deletions":0,"binary":false,"changes":51,"status":"added"},{"patch":"@@ -46,1 +46,1 @@\n-  ShenandoahHeap::heap()->entry_init_mark();\n+  ShenandoahHeap::heap()->entry_init_mark(_mark);\n@@ -51,1 +51,1 @@\n-  ShenandoahHeap::heap()->entry_final_mark();\n+  ShenandoahHeap::heap()->entry_final_mark(_mark);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVMOperations.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2019, Red Hat, Inc. All rights reserved.\n+ * Copyright (c) 2013, 2020, Red Hat, Inc. All rights reserved.\n@@ -30,0 +30,2 @@\n+class ShenandoahConcurrentMark;\n+\n@@ -55,0 +57,2 @@\n+private:\n+  ShenandoahConcurrentMark* const _mark;\n@@ -56,1 +60,3 @@\n-  VM_ShenandoahInitMark() : VM_ShenandoahOperation() {};\n+  VM_ShenandoahInitMark(ShenandoahConcurrentMark* mark) :\n+    VM_ShenandoahOperation(),\n+    _mark(mark) {};\n@@ -63,0 +69,2 @@\n+private:\n+  ShenandoahConcurrentMark* const _mark;\n@@ -64,1 +72,3 @@\n-  VM_ShenandoahFinalMarkStartEvac() : VM_ShenandoahReferenceOperation() {};\n+  VM_ShenandoahFinalMarkStartEvac(ShenandoahConcurrentMark* mark) :\n+    VM_ShenandoahReferenceOperation(),\n+    _mark(mark) {};\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahVMOperations.hpp","additions":13,"deletions":3,"binary":false,"changes":16,"status":"modified"}]}