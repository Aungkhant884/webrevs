{"files":[{"patch":"@@ -34,4 +34,1 @@\n-#if defined(LINUX)\n-#include \"waitBarrier_linux.hpp\"\n-typedef LinuxWaitBarrier WaitBarrierDefault;\n-#else\n+\/\/ FIXME: Replaced for testing on all platforms, revert before integration\n@@ -39,1 +36,0 @@\n-#endif\n","filename":"src\/hotspot\/share\/utilities\/waitBarrier.hpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -32,0 +32,34 @@\n+\/\/ Implements the striped semaphore wait barrier.\n+\/\/\n+\/\/ In addition to the barrier tag, it uses two counters to keep the semaphore\n+\/\/ count correct and not leave any late thread waiting.\n+\/\/\n+\/\/ To guarantee progress and safety, we should make sure that new barrier tag\n+\/\/ starts with the completely empty set of waiters and free semaphore. This\n+\/\/ requires either waiting for all threads to leave wait() for current barrier\n+\/\/ tag on disarm(), or waiting for all threads to leave the previous tag before\n+\/\/ reusing the semaphore in arm().\n+\/\/\n+\/\/ When there are multiple threads, it is normal for some threads to take\n+\/\/ significant time to leave the barrier. Waiting for these threads introduces\n+\/\/ stalls on barrier reuse. If wait on disarm(), this stall is nearly guaranteed\n+\/\/ to happen if some threads are stalled. If we wait on arm(), we can get lucky\n+\/\/ that most threads would be able to catch up, exit wait(), and so we arrive\n+\/\/ to arm() with semaphore ready for reuse.\n+\/\/\n+\/\/ However, that is insufficient in practice. Therefore, this implementation goes\n+\/\/ a step further and implements the _striped_ semaphores. We maintain several\n+\/\/ semaphores (along with aux counters) in cells. The barrier tags are assigned\n+\/\/ to cells in some simple manner. Most of the current uses have sequential barrier\n+\/\/ tags, so simple modulo works well.\n+\/\/\n+\/\/ We then operate on a cell like we would operate on a single semaphore: we wait\n+\/\/ at arm() for all threads to catch up before reusing the cell, and only then use it.\n+\/\/ For the cost of maintaining just a few cells, we have enough window for threads\n+\/\/ to catch up.\n+\/\/\n+\/\/ For extra generality, the implementation uses the strongest barriers for extra safety,\n+\/\/ even when not strictly required to do so for correctness. Extra barrier overhead\n+\/\/ is dominated by the actual wait\/notify latency.\n+\/\/\n+\n@@ -33,4 +67,23 @@\n-  assert(_barrier_tag == 0, \"Already armed\");\n-  assert(_waiters == 0, \"We left a thread hanging\");\n-  _barrier_tag = barrier_tag;\n-  _waiters = 0;\n+  assert(barrier_tag != 0, \"Pre-condition: should be arming with armed value\");\n+  assert(Atomic::load(&_barrier_tag) == 0, \"Pre-condition: should not be already armed\");\n+\n+  Cell& cell = tag_to_cell(barrier_tag);\n+\n+  \/\/ Prepare target cell for arming.\n+  \/\/ New waiters would still return immediately until barrier is fully armed.\n+\n+  assert(Atomic::load(&cell._unsignaled_waits) == 0, \"Pre-condition: no unsignaled waits\");\n+\n+  \/\/ Before we continue to arm, we need to make sure that all threads\n+  \/\/ have left the previous cell. This allows reusing the cell.\n+  SpinYield sp;\n+  while (Atomic::load_acquire(&cell._wait_threads) > 0) {\n+    assert(Atomic::load(&cell._unsignaled_waits) == 0, \"Lifecycle sanity: no new waiters\");\n+    sp.wait();\n+  }\n+\n+  \/\/ Announce the barrier is ready to accept waiters.\n+  \/\/ Make sure accesses to barrier tag are fully ordered.\n+  \/\/ API specifies arm() must provide a trailing fence.\n+  OrderAccess::fence();\n+  Atomic::release_store(&_barrier_tag, barrier_tag);\n@@ -40,12 +93,21 @@\n-int GenericWaitBarrier::wake_if_needed() {\n-  assert(_barrier_tag == 0, \"Not disarmed\");\n-  int w = _waiters;\n-  if (w == 0) {\n-    \/\/ Load of _barrier_threads in caller must not pass the load of _waiters.\n-    OrderAccess::loadload();\n-    return 0;\n-  }\n-  assert(w > 0, \"Bad counting\");\n-  \/\/ We need an exact count which never goes below zero,\n-  \/\/ otherwise the semaphore may be signalled too many times.\n-  if (Atomic::cmpxchg(&_waiters, w, w - 1) == w) {\n+int GenericWaitBarrier::Cell::wake_if_needed(int max) {\n+  \/\/ Match the signal counts with the number of unsignaled waits.\n+  \/\/ This would allow semaphore to be reused after we are done with it in\n+  \/\/ this arm-wait-disarm cycle.\n+\n+  int wakeups = 0;\n+  while (true) {\n+    int cur = Atomic::load_acquire(&_unsignaled_waits);\n+    if (cur == 0) {\n+      \/\/ All done, no more waiters.\n+      return 0;\n+    }\n+    assert(cur > 0, \"Sanity\");\n+\n+    int prev = Atomic::cmpxchg(&_unsignaled_waits, cur, cur - 1);\n+    if (prev != cur) {\n+      \/\/ Contention! Return to caller for early return or backoff.\n+      return prev;\n+    }\n+\n+    \/\/ Signal!\n@@ -53,1 +115,5 @@\n-    return w - 1;\n+\n+    if (wakeups++ > max) {\n+      \/\/ Over the wakeup limit, break out.\n+      return prev;\n+    }\n@@ -55,1 +121,0 @@\n-  return w;\n@@ -59,4 +124,7 @@\n-  assert(_barrier_tag != 0, \"Not armed\");\n-  _barrier_tag = 0;\n-  \/\/ Loads of _barrier_threads\/_waiters must not float above disarm store and\n-  \/\/ disarm store must not sink below.\n+  int tag = Atomic::load_acquire(&_barrier_tag);\n+  assert(tag != 0, \"Pre-condition: should be armed\");\n+\n+  \/\/ Announce the barrier is disarmed. New waiters would start to return immediately.\n+  \/\/ Make sure accesses to barrier tag are fully ordered.\n+  OrderAccess::fence();\n+  Atomic::release_store(&_barrier_tag, 0);\n@@ -64,1 +132,4 @@\n-  int left;\n+\n+  Cell& cell = tag_to_cell(tag);\n+\n+  \/\/ Wake up all current waiters.\n@@ -66,8 +137,4 @@\n-  do {\n-    left = GenericWaitBarrier::wake_if_needed();\n-    if (left == 0 && _barrier_threads > 0) {\n-      \/\/ There is no thread to wake but we still have barrier threads.\n-      sp.wait();\n-    }\n-    \/\/ We must loop here until there are no waiters or potential waiters.\n-  } while (left > 0 || _barrier_threads > 0);\n+  while (cell.wake_if_needed(INT_MAX) > 0) {\n+    sp.wait();\n+  }\n+\n@@ -76,0 +143,2 @@\n+\n+  assert(Atomic::load(&cell._unsignaled_waits) == 0, \"Post-condition: no unsignaled waits\");\n@@ -79,2 +148,5 @@\n-  assert(barrier_tag != 0, \"Trying to wait on disarmed value\");\n-  if (barrier_tag != _barrier_tag) {\n+  assert(barrier_tag != 0, \"Pre-condition: should be waiting on armed value\");\n+\n+  if (Atomic::load_acquire(&_barrier_tag) != barrier_tag) {\n+    \/\/ Not our current barrier at all, return right away without touching\n+    \/\/ anything. Chances are we catching up with disarm() disarming right now.\n@@ -85,7 +157,31 @@\n-  Atomic::add(&_barrier_threads, 1);\n-  if (barrier_tag != 0 && barrier_tag == _barrier_tag) {\n-    Atomic::add(&_waiters, 1);\n-    _sem_barrier.wait();\n-    \/\/ We help out with posting, but we need to do so before we decrement the\n-    \/\/ _barrier_threads otherwise we might wake threads up in next wait.\n-    GenericWaitBarrier::wake_if_needed();\n+\n+  Cell& cell = tag_to_cell(barrier_tag);\n+\n+  Atomic::add(&cell._wait_threads, 1);\n+\n+  \/\/ There is a subtle race against disarming code.\n+  \/\/\n+  \/\/ Disarming first lowers the actual barrier tag, and then proceeds to signal\n+  \/\/ threads. If we resume here after disarm() signaled all current waiters, we\n+  \/\/ might go into the wait without a matching signal, and be stuck indefinitely.\n+  \/\/ To avoid this, we check the expected barrier tag right here.\n+  \/\/\n+  \/\/ Note that we have to do this check *after* incrementing _wait_threads. Otherwise,\n+  \/\/ the disarming code might not notice that we are about to wait, and not deliver\n+  \/\/ additional signal to wake us up. (This is a Dekker-like step in disguise.)\n+\n+  \/\/ Make sure accesses to barrier tag are fully ordered.\n+  OrderAccess::fence();\n+\n+  if (Atomic::load_acquire(&_barrier_tag) == barrier_tag) {\n+    Atomic::add(&cell._unsignaled_waits, 1);\n+\n+    \/\/ Wait for notification.\n+    cell._sem_barrier.wait();\n+\n+    \/\/ Unblocked! We help out with waking up two siblings. This allows to avalanche\n+    \/\/ the wakeups for many threads, even if some threads are lagging behind.\n+    \/\/ Note that we can only do this *before* decrementing _wait_threads, otherwise\n+    \/\/ we might prematurely wake up threads for another barrier tag. Current arm()\n+    \/\/ sequence protects us from this trouble by waiting until all waiters leave.\n+    cell.wake_if_needed(2);\n@@ -93,1 +189,5 @@\n-  Atomic::add(&_barrier_threads, -1);\n+\n+  Atomic::sub(&cell._wait_threads, 1);\n+\n+  \/\/ API specifies wait() must provide a trailing fence.\n+  OrderAccess::fence();\n","filename":"src\/hotspot\/share\/utilities\/waitBarrier_generic.cpp","additions":141,"deletions":41,"binary":false,"changes":182,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"memory\/padded.hpp\"\n@@ -32,2 +33,0 @@\n-\/\/ In addition to the barrier tag, it uses two counters to keep the semaphore\n-\/\/ count correct and not leave any late thread waiting.\n@@ -35,0 +34,29 @@\n+private:\n+  class Cell : public CHeapObj<mtInternal> {\n+    friend GenericWaitBarrier;\n+  private:\n+    DEFINE_PAD_MINUS_SIZE(0, DEFAULT_CACHE_LINE_SIZE, 0);\n+\n+    Semaphore _sem_barrier;\n+\n+    \/\/ The number of threads in the wait path.\n+    volatile int _wait_threads;\n+\n+    \/\/ The number of waits that need to be signalled.\n+    volatile int _unsignaled_waits;\n+\n+    DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, 0);\n+\n+  public:\n+    Cell() : _sem_barrier(0), _wait_threads(0), _unsignaled_waits(0) {}\n+    NONCOPYABLE(Cell);\n+\n+    int wake_if_needed(int max);\n+  };\n+\n+  \/\/ Should be enough for most uses without exploding the footprint.\n+  static constexpr int CELLS_COUNT = 16;\n+\n+  Cell _cells[CELLS_COUNT];\n+  Cell& tag_to_cell(int tag) { return _cells[tag & (CELLS_COUNT - 1)]; }\n+\n@@ -36,6 +64,0 @@\n-  \/\/ The number of threads waiting on or about to wait on the semaphore.\n-  volatile int _waiters;\n-  \/\/ The number of threads in the wait path, before or after the tag check.\n-  \/\/ These threads can become waiters.\n-  volatile int _barrier_threads;\n-  Semaphore _sem_barrier;\n@@ -45,4 +67,2 @@\n-  int wake_if_needed();\n-\n- public:\n-  GenericWaitBarrier() : _barrier_tag(0), _waiters(0), _barrier_threads(0), _sem_barrier(0) {}\n+public:\n+  GenericWaitBarrier() : _cells(), _barrier_tag(0) {}\n@@ -51,1 +71,1 @@\n-  const char* description() { return \"semaphore\"; }\n+  const char* description() { return \"striped semaphore\"; }\n","filename":"src\/hotspot\/share\/utilities\/waitBarrier_generic.hpp","additions":33,"deletions":13,"binary":false,"changes":46,"status":"modified"}]}