{"files":[{"patch":"@@ -1793,0 +1793,5 @@\n+  INSN(vsse8_v,  0b0100111, 0b000, 0b10, 0b0);\n+  INSN(vsse16_v, 0b0100111, 0b101, 0b10, 0b0);\n+  INSN(vsse32_v, 0b0100111, 0b110, 0b10, 0b0);\n+  INSN(vsse64_v, 0b0100111, 0b111, 0b10, 0b0);\n+\n","filename":"src\/hotspot\/cpu\/riscv\/assembler_riscv.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1292,0 +1292,7 @@\n+  \/\/ rotate vector register left with shift bits, 32-bit version\n+  inline void vrole32_vi(VectorRegister vd, uint32_t shift, VectorRegister tmp_vr) {\n+    vsrl_vi(tmp_vr, vd, 32 - shift);\n+    vsll_vi(vd, vd, shift);\n+    vor_vv(vd, vd, tmp_vr);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -4280,0 +4280,136 @@\n+  \/**\n+   * Perform the quarter round calculations on values contained within four vector registers.\n+   *\n+   * @param aVec the SIMD register containing only the \"a\" values\n+   * @param bVec the SIMD register containing only the \"b\" values\n+   * @param cVec the SIMD register containing only the \"c\" values\n+   * @param dVec the SIMD register containing only the \"d\" values\n+   * @param tmp_vr temporary vector register holds intermedia values.\n+   *\/\n+  void chacha20_quarter_round(VectorRegister aVec, VectorRegister bVec,\n+                          VectorRegister cVec, VectorRegister dVec, VectorRegister tmp_vr) {\n+    \/\/ a += b, d ^= a, d <<<= 16\n+    __ vadd_vv(aVec, aVec, bVec);\n+    __ vxor_vv(dVec, dVec, aVec);\n+    __ vrole32_vi(dVec, 16, tmp_vr);\n+\n+    \/\/ c += d, b ^= c, b <<<= 12\n+    __ vadd_vv(cVec, cVec, dVec);\n+    __ vxor_vv(bVec, bVec, cVec);\n+    __ vrole32_vi(bVec, 12, tmp_vr);\n+\n+    \/\/ a += b, d ^= a, d <<<= 8\n+    __ vadd_vv(aVec, aVec, bVec);\n+    __ vxor_vv(dVec, dVec, aVec);\n+    __ vrole32_vi(dVec, 8, tmp_vr);\n+\n+    \/\/ c += d, b ^= c, b <<<= 7\n+    __ vadd_vv(cVec, cVec, dVec);\n+    __ vxor_vv(bVec, bVec, cVec);\n+    __ vrole32_vi(bVec, 7, tmp_vr);\n+  }\n+\n+  \/**\n+   * int com.sun.crypto.provider.ChaCha20Cipher.implChaCha20Block(int[] initState, byte[] result)\n+   *\n+   *  Input arguments:\n+   *  c_rarg0   - state, the starting state\n+   *  c_rarg1   - key_stream, the array that will hold the result of the ChaCha20 block function\n+   *\n+   *  Implementation Note:\n+   *   Parallelization is achieved by loading individual state elements into vectors for N blocks.\n+   *   N depends on single vector register length.\n+   *\/\n+  address generate_chacha20Block() {\n+    Label L_Rounds;\n+\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"chacha20Block\");\n+    address start = __ pc();\n+    __ enter();\n+\n+    const int states_len = 16;\n+    const int step = 4;\n+    const Register state = c_rarg0;\n+    const Register key_stream = c_rarg1;\n+    const Register tmp_addr = t0;\n+    const Register length = t1;\n+\n+    \/\/ Organize vector registers in an array that facilitates\n+    \/\/ putting repetitive opcodes into loop structures below.\n+    const VectorRegister work_vrs[16] = {\n+      v0, v1, v2,  v3,  v4,  v5,  v6,  v7,\n+      v8, v9, v10, v11, v12, v13, v14, v15\n+    };\n+    const VectorRegister tmp_vr = v16;\n+    const VectorRegister counter_vr = v17;\n+\n+    {\n+      \/\/ Put 16 here, as com.sun.crypto.providerChaCha20Cipher.KS_MAX_LEN is 1024\n+      \/\/ in java level.\n+      __ vsetivli(length, 16, Assembler::e32, Assembler::m1);\n+    }\n+\n+    \/\/ Load from source state.\n+    \/\/ Every element in source state is duplicated to all elements in the corresponding vector.\n+    __ mv(tmp_addr, state);\n+    for (int i = 0; i < states_len; i += 1) {\n+      __ vlse32_v(work_vrs[i], tmp_addr, zr);\n+      __ addi(tmp_addr, tmp_addr, step);\n+    }\n+    \/\/ Adjust counter for every individual block.\n+    __ vid_v(counter_vr);\n+    __ vadd_vv(work_vrs[12], work_vrs[12], counter_vr);\n+\n+    \/\/ Perform 10 iterations of the 8 quarter round set\n+    {\n+      const Register loop = t2; \/\/ share t2 with other non-overlapping usages.\n+      __ mv(loop, 10);\n+      __ BIND(L_Rounds);\n+\n+      chacha20_quarter_round(work_vrs[0], work_vrs[4], work_vrs[8],  work_vrs[12], tmp_vr);\n+      chacha20_quarter_round(work_vrs[1], work_vrs[5], work_vrs[9],  work_vrs[13], tmp_vr);\n+      chacha20_quarter_round(work_vrs[2], work_vrs[6], work_vrs[10], work_vrs[14], tmp_vr);\n+      chacha20_quarter_round(work_vrs[3], work_vrs[7], work_vrs[11], work_vrs[15], tmp_vr);\n+\n+      chacha20_quarter_round(work_vrs[0], work_vrs[5], work_vrs[10], work_vrs[15], tmp_vr);\n+      chacha20_quarter_round(work_vrs[1], work_vrs[6], work_vrs[11], work_vrs[12], tmp_vr);\n+      chacha20_quarter_round(work_vrs[2], work_vrs[7], work_vrs[8],  work_vrs[13], tmp_vr);\n+      chacha20_quarter_round(work_vrs[3], work_vrs[4], work_vrs[9],  work_vrs[14], tmp_vr);\n+\n+      __ sub(loop, loop, 1);\n+      __ bnez(loop, L_Rounds);\n+    }\n+\n+    \/\/ Add the original state into the end working state.\n+    \/\/ We do this by first duplicating every element in source state array to the corresponding\n+    \/\/ vector, then adding it to the post-loop working state.\n+    __ mv(tmp_addr, state);\n+    for (int i = 0; i < states_len; i += 1) {\n+      __ vlse32_v(tmp_vr, tmp_addr, zr);\n+      __ addi(tmp_addr, tmp_addr, step);\n+      __ vadd_vv(work_vrs[i], work_vrs[i], tmp_vr);\n+    }\n+    \/\/ Add the counter overlay onto work_vrs[12] at the end.\n+    __ vadd_vv(work_vrs[12], work_vrs[12], counter_vr);\n+\n+    \/\/ Store result to key stream.\n+    {\n+      const Register stride = t2; \/\/ share t2 with other non-overlapping usages.\n+      \/\/ Every block occupies 64 bytes, so we use 64 as stride of the vector store.\n+      __ mv(stride, 64);\n+      for (int i = 0; i < states_len; i += 1) {\n+        __ vsse32_v(work_vrs[i], key_stream, stride);\n+        __ addi(key_stream, key_stream, step);\n+      }\n+    }\n+\n+    \/\/ Return length of output key_stream\n+    __ slli(c_rarg0, length, 6);\n+\n+    __ leave();\n+    __ ret();\n+\n+    return (address) start;\n+  }\n+\n@@ -4499,0 +4635,5 @@\n+\n+    if (UseChaCha20Intrinsics) {\n+      StubRoutines::_chacha20Block = generate_chacha20Block();\n+    }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/stubGenerator_riscv.cpp","additions":141,"deletions":0,"binary":false,"changes":141,"status":"modified"},{"patch":"@@ -251,0 +251,10 @@\n+  if (UseRVV) {\n+    if (FLAG_IS_DEFAULT(UseChaCha20Intrinsics)) {\n+      FLAG_SET_DEFAULT(UseChaCha20Intrinsics, true);\n+    }\n+  } else if (UseChaCha20Intrinsics) {\n+    if (!FLAG_IS_DEFAULT(UseChaCha20Intrinsics)) {\n+      warning(\"Chacha20 intrinsic requires RVV instructions (not available on this CPU)\");\n+    }\n+    FLAG_SET_DEFAULT(UseChaCha20Intrinsics, false);\n+  }\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"}]}