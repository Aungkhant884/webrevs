{"files":[{"patch":"@@ -1840,2 +1840,0 @@\n-    __ mov(rscratch1, _thread_in_native);\n-    __ strw(rscratch1, Address(rthread, JavaThread::thread_state_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2186,0 +2186,2 @@\n+  \/\/ Use that pc we placed in r_return_pc a while back as the current frame anchor.\n+  __ set_last_Java_frame(R1_SP, r_return_pc);\n@@ -2191,3 +2193,0 @@\n-    \/\/ Use that pc we placed in r_return_pc a while back as the current frame anchor.\n-    __ set_last_Java_frame(R1_SP, r_return_pc);\n-\n@@ -2274,4 +2273,0 @@\n-    \/\/ Transition from _thread_in_Java to _thread_in_native.\n-    __ li(R0, _thread_in_native);\n-    __ release();\n-    __ stw(R0, thread_(thread_state));\n","filename":"src\/hotspot\/cpu\/ppc\/sharedRuntime_ppc.cpp","additions":2,"deletions":7,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1993,1 +1993,0 @@\n-    __ set_thread_state(_thread_in_native);\n","filename":"src\/hotspot\/cpu\/s390\/sharedRuntime_s390.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1217,91 +1217,0 @@\n-\/\/ Registers need to be saved for runtime call\n-static Register caller_saved_registers[] = {\n-  rcx, rdx, rsi, rdi\n-};\n-\n-\/\/ Save caller saved registers except r1 and r2\n-static void save_registers_except(MacroAssembler* masm, Register r1, Register r2) {\n-  int reg_len = (int)(sizeof(caller_saved_registers) \/ sizeof(Register));\n-  for (int index = 0; index < reg_len; index ++) {\n-    Register this_reg = caller_saved_registers[index];\n-    if (this_reg != r1 && this_reg != r2) {\n-      __ push(this_reg);\n-    }\n-  }\n-}\n-\n-\/\/ Restore caller saved registers except r1 and r2\n-static void restore_registers_except(MacroAssembler* masm, Register r1, Register r2) {\n-  int reg_len = (int)(sizeof(caller_saved_registers) \/ sizeof(Register));\n-  for (int index = reg_len - 1; index >= 0; index --) {\n-    Register this_reg = caller_saved_registers[index];\n-    if (this_reg != r1 && this_reg != r2) {\n-      __ pop(this_reg);\n-    }\n-  }\n-}\n-\n-\/\/ Pin object, return pinned object or null in rax\n-static void gen_pin_object(MacroAssembler* masm,\n-                           Register thread, VMRegPair reg) {\n-  __ block_comment(\"gen_pin_object {\");\n-\n-  Label is_null;\n-  Register tmp_reg = rax;\n-  VMRegPair tmp(tmp_reg->as_VMReg());\n-  if (reg.first()->is_stack()) {\n-    \/\/ Load the arg up from the stack\n-    simple_move32(masm, reg, tmp);\n-    reg = tmp;\n-  } else {\n-    __ movl(tmp_reg, reg.first()->as_Register());\n-  }\n-  __ testptr(reg.first()->as_Register(), reg.first()->as_Register());\n-  __ jccb(Assembler::equal, is_null);\n-\n-  \/\/ Save registers that may be used by runtime call\n-  Register arg = reg.first()->is_Register() ? reg.first()->as_Register() : noreg;\n-  save_registers_except(masm, arg, thread);\n-\n-  __ call_VM_leaf(\n-    CAST_FROM_FN_PTR(address, SharedRuntime::pin_object),\n-    thread, reg.first()->as_Register());\n-\n-  \/\/ Restore saved registers\n-  restore_registers_except(masm, arg, thread);\n-\n-  __ bind(is_null);\n-  __ block_comment(\"} gen_pin_object\");\n-}\n-\n-\/\/ Unpin object\n-static void gen_unpin_object(MacroAssembler* masm,\n-                             Register thread, VMRegPair reg) {\n-  __ block_comment(\"gen_unpin_object {\");\n-  Label is_null;\n-\n-  \/\/ temp register\n-  __ push(rax);\n-  Register tmp_reg = rax;\n-  VMRegPair tmp(tmp_reg->as_VMReg());\n-\n-  simple_move32(masm, reg, tmp);\n-\n-  __ testptr(rax, rax);\n-  __ jccb(Assembler::equal, is_null);\n-\n-  \/\/ Save registers that may be used by runtime call\n-  Register arg = reg.first()->is_Register() ? reg.first()->as_Register() : noreg;\n-  save_registers_except(masm, arg, thread);\n-\n-  __ call_VM_leaf(\n-    CAST_FROM_FN_PTR(address, SharedRuntime::unpin_object),\n-    thread, rax);\n-\n-  \/\/ Restore saved registers\n-  restore_registers_except(masm, arg, thread);\n-  __ bind(is_null);\n-  __ pop(rax);\n-  __ block_comment(\"} gen_unpin_object\");\n-}\n-\n@@ -1782,5 +1691,0 @@\n-  \/\/ Inbound arguments that need to be pinned for critical natives\n-  GrowableArray<int> pinned_args(total_in_args);\n-  \/\/ Current stack slot for storing register based array argument\n-  int pinned_slot = oop_handle_offset;\n-\n@@ -1799,20 +1703,0 @@\n-          if (Universe::heap()->supports_object_pinning()) {\n-            \/\/ gen_pin_object handles save and restore\n-            \/\/ of any clobbered registers\n-            gen_pin_object(masm, thread, in_arg);\n-            pinned_args.append(i);\n-\n-            \/\/ rax has pinned array\n-            VMRegPair result_reg(rax->as_VMReg());\n-            if (!in_arg.first()->is_stack()) {\n-              assert(pinned_slot <= stack_slots, \"overflow\");\n-              simple_move32(masm, result_reg, VMRegImpl::stack2reg(pinned_slot));\n-              pinned_slot += VMRegImpl::slots_per_word;\n-            } else {\n-              \/\/ Write back pinned value, it will be used to unpin this argument\n-              __ movptr(Address(rbp, reg2offset_in(in_arg.first())), result_reg.first()->as_Register());\n-            }\n-            \/\/ We have the array in register, use it\n-            in_arg = result_reg;\n-          }\n-\n@@ -1973,1 +1857,0 @@\n-\n@@ -1978,1 +1861,0 @@\n-  }\n@@ -1980,2 +1862,3 @@\n-  \/\/ Now set thread in native\n-  __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native);\n+    \/\/ Now set thread in native\n+    __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native);\n+  }\n@@ -2012,20 +1895,0 @@\n-  \/\/ unpin pinned arguments\n-  pinned_slot = oop_handle_offset;\n-  if (pinned_args.length() > 0) {\n-    \/\/ save return value that may be overwritten otherwise.\n-    save_native_result(masm, ret_type, stack_slots);\n-    for (int index = 0; index < pinned_args.length(); index ++) {\n-      int i = pinned_args.at(index);\n-      assert(pinned_slot <= stack_slots, \"overflow\");\n-      if (!in_regs[i].first()->is_stack()) {\n-        int offset = pinned_slot * VMRegImpl::stack_slot_size;\n-        __ movl(in_regs[i].first()->as_Register(), Address(rsp, offset));\n-        pinned_slot += VMRegImpl::slots_per_word;\n-      }\n-      \/\/ gen_pin_object handles save and restore\n-      \/\/ of any other clobbered registers\n-      gen_unpin_object(masm, thread, in_regs[i]);\n-    }\n-    restore_native_result(masm, ret_type, stack_slots);\n-  }\n-\n@@ -2043,1 +1906,0 @@\n-    __ movl(Address(thread, JavaThread::thread_state_offset()), _thread_in_native);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_32.cpp","additions":3,"deletions":141,"binary":false,"changes":144,"status":"modified"},{"patch":"@@ -1381,60 +1381,0 @@\n-\n-\/\/ Pin object, return pinned object or null in rax\n-static void gen_pin_object(MacroAssembler* masm,\n-                           VMRegPair reg) {\n-  __ block_comment(\"gen_pin_object {\");\n-\n-  \/\/ rax always contains oop, either incoming or\n-  \/\/ pinned.\n-  Register tmp_reg = rax;\n-\n-  Label is_null;\n-  VMRegPair tmp;\n-  VMRegPair in_reg = reg;\n-\n-  tmp.set_ptr(tmp_reg->as_VMReg());\n-  if (reg.first()->is_stack()) {\n-    \/\/ Load the arg up from the stack\n-    move_ptr(masm, reg, tmp);\n-    reg = tmp;\n-  } else {\n-    __ movptr(rax, reg.first()->as_Register());\n-  }\n-  __ testptr(reg.first()->as_Register(), reg.first()->as_Register());\n-  __ jccb(Assembler::equal, is_null);\n-\n-  if (reg.first()->as_Register() != c_rarg1) {\n-    __ movptr(c_rarg1, reg.first()->as_Register());\n-  }\n-\n-  __ call_VM_leaf(\n-    CAST_FROM_FN_PTR(address, SharedRuntime::pin_object),\n-    r15_thread, c_rarg1);\n-\n-  __ bind(is_null);\n-  __ block_comment(\"} gen_pin_object\");\n-}\n-\n-\/\/ Unpin object\n-static void gen_unpin_object(MacroAssembler* masm,\n-                             VMRegPair reg) {\n-  __ block_comment(\"gen_unpin_object {\");\n-  Label is_null;\n-\n-  if (reg.first()->is_stack()) {\n-    __ movptr(c_rarg1, Address(rbp, reg2offset_in(reg.first())));\n-  } else if (reg.first()->as_Register() != c_rarg1) {\n-    __ movptr(c_rarg1, reg.first()->as_Register());\n-  }\n-\n-  __ testptr(c_rarg1, c_rarg1);\n-  __ jccb(Assembler::equal, is_null);\n-\n-  __ call_VM_leaf(\n-    CAST_FROM_FN_PTR(address, SharedRuntime::unpin_object),\n-    r15_thread, c_rarg1);\n-\n-  __ bind(is_null);\n-  __ block_comment(\"} gen_unpin_object\");\n-}\n-\n@@ -2103,4 +2043,0 @@\n-  \/\/ Inbound arguments that need to be pinned for critical natives\n-  GrowableArray<int> pinned_args(total_in_args);\n-  \/\/ Current stack slot for storing register based array argument\n-  int pinned_slot = oop_handle_offset;\n@@ -2155,17 +2091,0 @@\n-          \/\/ pin before unpack\n-          if (Universe::heap()->supports_object_pinning()) {\n-            save_args(masm, total_c_args, 0, out_regs);\n-            gen_pin_object(masm, in_regs[i]);\n-            pinned_args.append(i);\n-            restore_args(masm, total_c_args, 0, out_regs);\n-\n-            \/\/ rax has pinned array\n-            VMRegPair result_reg;\n-            result_reg.set_ptr(rax->as_VMReg());\n-            move_ptr(masm, result_reg, in_regs[i]);\n-            if (!in_regs[i].first()->is_stack()) {\n-              assert(pinned_slot <= stack_slots, \"overflow\");\n-              move_ptr(masm, result_reg, VMRegImpl::stack2reg(pinned_slot));\n-              pinned_slot += VMRegImpl::slots_per_word;\n-            }\n-          }\n@@ -2384,18 +2303,0 @@\n-  \/\/ unpin pinned arguments\n-  pinned_slot = oop_handle_offset;\n-  if (pinned_args.length() > 0) {\n-    \/\/ save return value that may be overwritten otherwise.\n-    save_native_result(masm, ret_type, stack_slots);\n-    for (int index = 0; index < pinned_args.length(); index ++) {\n-      int i = pinned_args.at(index);\n-      assert(pinned_slot <= stack_slots, \"overflow\");\n-      if (!in_regs[i].first()->is_stack()) {\n-        int offset = pinned_slot * VMRegImpl::stack_slot_size;\n-        __ movq(in_regs[i].first()->as_Register(), Address(rsp, offset));\n-        pinned_slot += VMRegImpl::slots_per_word;\n-      }\n-      gen_unpin_object(masm, in_regs[i]);\n-    }\n-    restore_native_result(masm, ret_type, stack_slots);\n-  }\n-\n@@ -2413,1 +2314,0 @@\n-    __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":0,"deletions":100,"binary":false,"changes":100,"status":"modified"},{"patch":"@@ -2941,16 +2941,0 @@\n-JRT_LEAF(oopDesc*, SharedRuntime::pin_object(JavaThread* thread, oopDesc* obj))\n-  assert(Universe::heap()->supports_object_pinning(), \"Why we are here?\");\n-  assert(obj != NULL, \"Should not be null\");\n-  oop o(obj);\n-  o = Universe::heap()->pin_object(thread, o);\n-  assert(o != NULL, \"Should not be null\");\n-  return o;\n-JRT_END\n-\n-JRT_LEAF(void, SharedRuntime::unpin_object(JavaThread* thread, oopDesc* obj))\n-  assert(Universe::heap()->supports_object_pinning(), \"Why we are here?\");\n-  assert(obj != NULL, \"Should not be null\");\n-  oop o(obj);\n-  Universe::heap()->unpin_object(thread, o);\n-JRT_END\n-\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -489,4 +489,0 @@\n-  \/\/ Pin\/Unpin object\n-  static oopDesc* pin_object(JavaThread* thread, oopDesc* obj);\n-  static void unpin_object(JavaThread* thread, oopDesc* obj);\n-\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -56,1 +57,1 @@\n- * @bug 8199868\n+ * @bug 8199868 8233343\n@@ -58,1 +59,1 @@\n- * @requires os.arch ==\"x86_64\" | os.arch == \"amd64\" | os.arch==\"x86\" | os.arch==\"i386\"\n+ * @requires os.arch ==\"x86_64\" | os.arch == \"amd64\" | os.arch==\"x86\" | os.arch==\"i386\" | os.arch==\"ppc64\" | os.arch==\"ppc64le\" | os.arch==\"s390x\"\n","filename":"test\/hotspot\/jtreg\/gc\/CriticalNativeArgs.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -3,0 +3,1 @@\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,1 +63,1 @@\n- * @bug 8199868\n+ * @bug 8199868 8233343\n@@ -64,1 +65,1 @@\n- * @requires os.arch ==\"x86_64\" | os.arch == \"amd64\" | os.arch==\"x86\" | os.arch==\"i386\"\n+ * @requires os.arch ==\"x86_64\" | os.arch == \"amd64\" | os.arch==\"x86\" | os.arch==\"i386\" | os.arch==\"ppc64\" | os.arch==\"ppc64le\" | os.arch==\"s390x\"\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/CriticalNativeStress.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"}]}