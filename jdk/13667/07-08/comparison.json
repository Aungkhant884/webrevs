{"files":[{"patch":"@@ -384,0 +384,1 @@\n+\/\/ Supports I\/O operations for a dump\n@@ -420,0 +421,5 @@\n+  \/\/ Total number of bytes written to the disk\n+  virtual julong bytes_written() const = 0;\n+  \/\/ Return non-null if error occurred\n+  virtual char const* error() const = 0;\n+\n@@ -441,4 +447,0 @@\n-  \/\/ Total number of bytes written to the disk\n-  virtual julong bytes_written() const = 0;\n-  \/\/ Return non-null if error occurred\n-  virtual char const* error() const = 0;\n@@ -577,1 +579,0 @@\n-    ResourceMark rm;\n@@ -1519,0 +1520,1 @@\n+\/\/ The VM operation merges separate dump files into a complete one\n@@ -1524,0 +1526,1 @@\n+  int _dump_seq;\n@@ -1528,2 +1531,2 @@\n-  VM_HeapDumpMerge(const char* path, DumpWriter* writer)\n-    : _writer(writer), _path(path), _has_error(_writer->has_error()) {}\n+  VM_HeapDumpMerge(const char* path, DumpWriter* writer, int dump_seq) : \n+    _writer(writer), _path(path), _has_error(_writer->has_error()), _dump_seq(dump_seq) {}\n@@ -1536,0 +1539,62 @@\n+void VM_HeapDumpMerge::merge_done() {\n+  \/\/ Writes the HPROF_HEAP_DUMP_END record.\n+  if (!_has_error) {\n+    DumperSupport::end_of_dump(_writer);\n+    _writer->flush();\n+  }\n+  _dump_seq = 0; \/\/reset\n+}\n+\n+void VM_HeapDumpMerge::merge_file(char* path) {\n+  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n+  TraceTime timer(\"Merge segmented heap file\", TRACETIME_LOG(Info, heapdump));\n+\n+  fileStream part_fs(path, \"r\");\n+  if (!part_fs.is_open()) {\n+    log_error(heapdump)(\"Can not open segmented heap file %s during merging\", path);\n+    _writer->set_error(\"Can not open segmented heap file during merging\");\n+    _has_error = true;\n+    return;\n+  }\n+\n+  jlong total = 0;\n+  int cnt = 0;\n+  char read_buf[4096];\n+  while ((cnt = part_fs.read(read_buf, 1, 4096)) != 0) {\n+    _writer->write_raw(read_buf, cnt);\n+    total += cnt;\n+  }\n+\n+  _writer->flush();\n+  if (part_fs.fileSize() != total) {\n+    log_error(heapdump)(\"Merged heap dump %s is incomplete\", path);\n+    _writer->set_error(\"Merged heap dump is incomplete\");\n+    _has_error = true;\n+  }\n+}\n+\n+void VM_HeapDumpMerge::doit() {\n+  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n+  TraceTime timer(\"Merge heap files complete\", TRACETIME_LOG(Info, heapdump));\n+\n+  \/\/ Since contents in segmented heap file were already zipped, we don't need to zip\n+  \/\/ them again during merging.\n+  AbstractCompressor* saved_compressor = _writer->compressor();\n+  _writer->set_compressor(nullptr);\n+\n+  \/\/ merge segmented heap file and remove it anyway\n+  char path[JVM_MAXPATHLEN];\n+  for (int i = 0; i < _dump_seq; i++) {\n+    memset(path, 0, JVM_MAXPATHLEN);\n+    os::snprintf(path, JVM_MAXPATHLEN, \"%s.p%d\", _path, i);\n+    if (!_has_error) {\n+      merge_file(path);\n+    }\n+    remove(path);\n+  }\n+\n+  \/\/ restore compressor for further use\n+  _writer->set_compressor(saved_compressor);\n+  merge_done();\n+}\n+\n@@ -1548,0 +1613,1 @@\n+  volatile int            _dump_seq;\n@@ -1556,1 +1622,0 @@\n-  static DumpWriter* create_dump_writer();\n@@ -1574,0 +1639,3 @@\n+  \/\/ create dump writer for every parallel dump thread\n+  DumpWriter* create_dump_writer();\n+\n@@ -1603,0 +1671,1 @@\n+    _dump_seq = 0;\n@@ -1633,0 +1702,1 @@\n+  int dump_seq()           { return _dump_seq; }\n@@ -1892,64 +1962,0 @@\n-static int volatile dump_seq = 0;\n-\n-void VM_HeapDumpMerge::merge_done() {\n-  \/\/ Writes the HPROF_HEAP_DUMP_END record.\n-  if (!_has_error) {\n-    DumperSupport::end_of_dump(_writer);\n-    _writer->flush();\n-  }\n-  dump_seq = 0; \/\/reset\n-}\n-\n-void VM_HeapDumpMerge::merge_file(char* path) {\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n-  TraceTime timer(\"Merge segmented heap file\", TRACETIME_LOG(Info, heapdump));\n-\n-  fileStream part_fs(path, \"r\");\n-  if (!part_fs.is_open()) {\n-    log_error(heapdump)(\"Can not open segmented heap file %s during merging\", path);\n-    _writer->set_error(\"Can not open segmented heap file during merging\");\n-    _has_error = true;\n-    return;\n-  }\n-\n-  jlong total = 0;\n-  int cnt = 0;\n-  char read_buf[4096];\n-  while ((cnt = part_fs.read(read_buf, 1, 4096)) != 0) {\n-    _writer->write_raw(read_buf, cnt);\n-    total += cnt;\n-  }\n-\n-  _writer->flush();\n-  if (part_fs.fileSize() != total) {\n-    log_error(heapdump)(\"Merged heap dump %s is incomplete\", path);\n-    _writer->set_error(\"Merged heap dump is incomplete\");\n-    _has_error = true;\n-  }\n-}\n-\n-void VM_HeapDumpMerge::doit() {\n-  assert(!SafepointSynchronize::is_at_safepoint(), \"merging happens outside safepoint\");\n-  TraceTime timer(\"Merge heap files complete\", TRACETIME_LOG(Info, heapdump));\n-\n-  \/\/ Since contents in segmented heap file were already zipped, we don't need to zip\n-  \/\/ them again during merging.\n-  AbstractCompressor* saved_compressor = _writer->compressor();\n-  _writer->set_compressor(nullptr);\n-\n-  \/\/ merge segmented heap file and remove it anyway\n-  char path[JVM_MAXPATHLEN];\n-  for (int i = 0; i < dump_seq; i++) {\n-    memset(path, 0, JVM_MAXPATHLEN);\n-    os::snprintf(path, JVM_MAXPATHLEN, \"%s.p%d\", _path, i);\n-    if (!_has_error) {\n-      merge_file(path);\n-    }\n-    remove(path);\n-  }\n-\n-  \/\/ restore compressor for further use\n-  _writer->set_compressor(saved_compressor);\n-  merge_done();\n-}\n-\n@@ -1960,0 +1966,1 @@\n+  \/\/ generate segmented heap file path\n@@ -1962,1 +1969,1 @@\n-  int seq = Atomic::fetch_and_add(&dump_seq, 1);\n+  int seq = Atomic::fetch_and_add(&_dump_seq, 1);\n@@ -1964,0 +1971,1 @@\n+  \/\/ create corresponding writer for that\n@@ -2168,1 +2176,1 @@\n-    VM_HeapDumpMerge op(path, &writer);\n+    VM_HeapDumpMerge op(path, &writer, dumper.dump_seq());\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":82,"deletions":74,"binary":false,"changes":156,"status":"modified"}]}