{"files":[{"patch":"@@ -81,220 +81,194 @@\n-\/\/ Source used to generate the AVX512 fmod assembly below:\n-\/\/\n-\/\/ #include <ia32intrin.h>\n-\/\/ #include <emmintrin.h>\n-\/\/ #pragma float_control(precise, on)\n-\/\/\n-\/\/ #define UINT32 unsigned int\n-\/\/ #define SINT32 int\n-\/\/ #define UINT64 unsigned __int64\n-\/\/ #define SINT64 __int64\n-\/\/\n-\/\/ #define DP_FMA(a, b, c)    __fence(_mm_cvtsd_f64(_mm_fmadd_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c))))\n-\/\/ #define DP_FMA_RN(a, b, c)    _mm_cvtsd_f64(_mm_fmadd_round_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c), (_MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC)))\n-\/\/ #define DP_FMA_RZ(a, b, c) __fence(_mm_cvtsd_f64(_mm_fmadd_round_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC))))\n-\/\/\n-\/\/ #define DP_ROUND_RZ(a)   _mm_cvtsd_f64(_mm_roundscale_sd(_mm_setzero_pd(), _mm_set_sd(a), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC)))\n-\/\/\n-\/\/ #define DP_CONST(C)    _castu64_f64(0x##C##ull)\n-\/\/ #define DP_AND(X, Y)   _mm_cvtsd_f64(_mm_and_pd(_mm_set_sd(X), _mm_set_sd(Y)))\n-\/\/ #define DP_XOR(X, Y)   _mm_cvtsd_f64(_mm_xor_pd(_mm_set_sd(X), _mm_set_sd(Y)))\n-\/\/ #define DP_OR(X, Y)    _mm_cvtsd_f64(_mm_or_pd(_mm_set_sd(X), _mm_set_sd(Y)))\n-\/\/ #define DP_DIV_RZ(a, b) __fence(_mm_cvtsd_f64(_mm_div_round_sd(_mm_set_sd(a), _mm_set_sd(b), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC))))\n-\/\/ #define DP_FNMA(a, b, c)    __fence(_mm_cvtsd_f64(_mm_fnmadd_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c))))\n-\/\/ #define DP_FNMA_RZ(a, b, c) __fence(_mm_cvtsd_f64(_mm_fnmadd_round_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC))))\n-\/\/\n-\/\/ #define D2L(x)  _mm_castpd_si128(x)\n-\/\/ \/\/ transfer highest 32 bits (of low 64b) to GPR\n-\/\/ #define TRANSFER_HIGH_INT32(X)   _mm_extract_epi32(D2L(_mm_set_sd(X)), 1)\n-\/\/\n-\/\/ double fmod(double x, double y)\n-\/\/ {\n-\/\/ double a, b, sgn_a, q, bs, bs2;\n-\/\/ unsigned eq;\n-\/\/\n-\/\/     \/\/ |x|, |y|\n-\/\/     a = DP_AND(x, DP_CONST(7fffffffffffffff));\n-\/\/     b = DP_AND(y, DP_CONST(7fffffffffffffff));\n-\/\/     \/\/ sign(x)\n-\/\/     sgn_a = DP_XOR(x, a);\n-\/\/     q = DP_DIV_RZ(a, b);\n-\/\/     q = DP_ROUND_RZ(q);\n-\/\/     eq = TRANSFER_HIGH_INT32(q);\n-\/\/     if (!eq)  return x + sgn_a;\n-\/\/     if (eq >= 0x7fefffffu) goto SPECIAL_FMOD;\n-\/\/     a = DP_FNMA_RZ(b, q, a);\n-\/\/\n-\/\/ FMOD_CONT:\n-\/\/     while (b <= a)\n-\/\/     {\n-\/\/         q = DP_DIV_RZ(a, b);\n-\/\/         q = DP_ROUND_RZ(q);\n-\/\/         a = DP_FNMA_RZ(b, q, a);\n-\/\/     }\n-\/\/\n-\/\/     a = DP_XOR(a, sgn_a);\n-\/\/     return a;\n-\/\/\n-\/\/ SPECIAL_FMOD:\n-\/\/\n-\/\/     \/\/ y==0 or x==Inf?\n-\/\/     if ((b == 0.0) || (!(a <= DP_CONST(7fefffffffffffff))))\n-\/\/         return DP_FNMA(b, q, a);    \/\/ NaN\n-\/\/     \/\/ y is NaN?\n-\/\/     if (!(b <= DP_CONST(7ff0000000000000))) return y + y;\n-\/\/     \/\/ b* 2*1023\n-\/\/     bs = b * DP_CONST(7fe0000000000000);\n-\/\/     q = DP_DIV_RZ(a, bs);\n-\/\/     q = DP_ROUND_RZ(q);\n-\/\/     eq = TRANSFER_HIGH_INT32(q);\n-\/\/     if (eq >= 0x7fefffffu)\n-\/\/     {\n-\/\/         \/\/ b* 2*1023 * 2^1023\n-\/\/         bs2 = bs * DP_CONST(7fe0000000000000);\n-\/\/         while (bs2 <= a)\n-\/\/         {\n-\/\/             q = DP_DIV_RZ(a, bs2);\n-\/\/             q = DP_ROUND_RZ(q);\n-\/\/             a = DP_FNMA_RZ(bs2, q, a);\n-\/\/         }\n-\/\/     }\n-\/\/     else\n-\/\/     a = DP_FNMA_RZ(bs, q, a);\n-\/\/\n-\/\/     while (bs <= a)\n-\/\/     {\n-\/\/         q = DP_DIV_RZ(a, bs);\n-\/\/         q = DP_ROUND_RZ(q);\n-\/\/         a = DP_FNMA_RZ(bs, q, a);\n-\/\/     }\n-\/\/\n-\/\/     goto FMOD_CONT;\n-\/\/ }\n-\n-\n-  Label L_5280, L_52a0, L_5256, L_5300, L_5320, L_52c0, L_52d0, L_5360, L_5380, L_53b0, L_5390;\n-  Label L_53c0, L_52a6, L_53d0, L_exit;\n-\n-  __ movdqa(xmm2, xmm0);\n-  __ movq(xmm0, xmm0);\n-  __ mov64(rax, 0x7FFFFFFFFFFFFFFF);\n-  __ evpbroadcastq(xmm3, rax, Assembler::AVX_128bit);\n-\n-  __ vpand(xmm6, xmm0, xmm3, Assembler::AVX_128bit);\n-  __ vpand(xmm4, xmm1, xmm3, Assembler::AVX_128bit);\n-  __ vpxor(xmm3, xmm6, xmm0, Assembler::AVX_128bit);\n-  __ movq(xmm5, xmm4);\n-  __ evdivsd(xmm0, xmm6, xmm5, Assembler::EVEX_RZ);\n-  __ movq(xmm0, xmm0);\n-  __ vxorpd(xmm7, xmm7, xmm7, Assembler::AVX_128bit);\n-  __ vroundsd(xmm0, xmm7, xmm0, 0xb);\n-  __ extractps(rax, xmm0, 1);\n-  __ testl(rax, rax);\n-  __ jcc(Assembler::equal, L_5280);\n-\n-  __ cmpl(rax, 0x7feffffe);\n-  __ jcc(Assembler::belowEqual, L_52a0);\n-  __ vpxor(xmm2, xmm2, xmm2, Assembler::AVX_128bit);\n-  __ ucomisd(xmm4, xmm2);\n-  __ jcc(Assembler::notEqual, L_5256);\n-  __ jcc(Assembler::noParity, L_5300);\n-\n-  __ bind(L_5256);\n-  __ movsd(xmm2, ExternalAddress((address)CONST_MAX), rax);\n-  __ ucomisd(xmm2, xmm6);\n-  __ jcc(Assembler::below, L_5300);\n-  __ movsd(xmm0, ExternalAddress((address)CONST_INF), rax);\n-  __ ucomisd(xmm0, xmm4);\n-  __ jcc(Assembler::aboveEqual, L_5320);\n-\n-  __ vaddsd(xmm0, xmm1, xmm1);\n-  __ jmp(L_exit);\n-\n-  __ align32();\n-  __ bind(L_5280);\n-  __ vaddsd(xmm0, xmm3, xmm2);\n-  __ jmp(L_exit);\n-\n-  __ align(8);\n-  __ bind(L_52a0);\n-  __ evfnmadd213sd(xmm0, xmm4, xmm6, Assembler::EVEX_RZ);\n-  __ bind(L_52a6);\n-  __ ucomisd(xmm0, xmm4);\n-  __ jcc(Assembler::aboveEqual, L_52c0);\n-  __ vpxor(xmm0, xmm3, xmm0, Assembler::AVX_128bit);\n-  __ jmp(L_exit);\n-\n-  __ bind(L_52c0);\n-\n-  __ movq(xmm6, xmm0);\n-  __ vpxor(xmm1, xmm1, xmm1, Assembler::AVX_128bit);\n-  __ align32();\n-  __ bind(L_52d0);\n-\n-  __ evdivsd(xmm2, xmm6, xmm5, Assembler::EVEX_RZ);\n-  __ movq(xmm2, xmm2);\n-  __ vroundsd(xmm2, xmm1, xmm2, 0xb);\n-  __ evfnmadd213sd(xmm2, xmm4, xmm0, Assembler::EVEX_RZ);\n-  __ ucomisd(xmm2, xmm4);\n-  __ movq(xmm6, xmm2);\n-  __ movapd(xmm0, xmm2);\n-  __ jcc(Assembler::aboveEqual, L_52d0);\n-\n-  __ vpxor(xmm0, xmm3, xmm2, Assembler::AVX_128bit);\n-  __ jmp(L_exit);\n-\n-  __ bind(L_5300);\n-  __ vfnmadd213sd(xmm0, xmm4, xmm6);\n-  __ jmp(L_exit);\n-\n-  __ bind(L_5320);\n-  __ vmulsd(xmm1, xmm4, ExternalAddress((address)CONST_e307), rax);\n-  __ movq(xmm2, xmm1);\n-  __ evdivsd(xmm0, xmm6, xmm2, Assembler::EVEX_RZ);\n-  __ movq(xmm0, xmm0);\n-  __ vroundsd(xmm7, xmm7, xmm0, 0xb);\n-  __ extractps(rax, xmm7, 1);\n-  __ cmpl(rax, 0x7fefffff);\n-  __ jcc(Assembler::below, L_5360);\n-  __ vmulsd(xmm0, xmm1, ExternalAddress((address)CONST_e307), rax);\n-  __ ucomisd(xmm6, xmm0);\n-  __ jcc(Assembler::aboveEqual, L_5380);\n-  __ movapd(xmm7, xmm6);\n-  __ jmp(L_53b0);\n-\n-  __ bind(L_5360);\n-  __ evfnmadd213sd(xmm7, xmm1, xmm6, Assembler::EVEX_RZ);\n-  __ jmp(L_53b0);\n-\n-  __ bind(L_5380);\n-  __ vxorpd(xmm8, xmm8, xmm8, Assembler::AVX_128bit);\n-\n-  __ align32();\n-  __ bind(L_5390);\n-  __ evdivsd(xmm7, xmm6, xmm0, Assembler::EVEX_RZ);\n-  __ movq(xmm7, xmm7);\n-  __ vroundsd(xmm7, xmm8, xmm7, 0xb);\n-  __ evfnmadd213sd(xmm7, xmm0, xmm6, Assembler::EVEX_RZ);\n-  __ ucomisd(xmm7, xmm0);\n-  __ movapd(xmm6, xmm7);\n-  __ jcc(Assembler::aboveEqual, L_5390);\n-  __ bind(L_53b0);\n-  __ ucomisd(xmm7, xmm1);\n-  __ jcc(Assembler::aboveEqual, L_53c0);\n-  __ movapd(xmm0, xmm7);\n-  __ jmp(L_52a6);\n-\n-  __ bind(L_53c0);\n-  __ vxorpd(xmm6, xmm6, xmm6, Assembler::AVX_128bit);\n-  __ align32();\n-  __ bind(L_53d0);\n-  __ evdivsd(xmm0, xmm7, xmm2, Assembler::EVEX_RZ);\n-  __ movq(xmm0, xmm0);\n-  __ vroundsd(xmm0, xmm6, xmm0, 0xb);\n-  __ evfnmadd213sd(xmm0, xmm1, xmm7, Assembler::EVEX_RZ);\n-  __ ucomisd(xmm0, xmm1);\n-  __ movapd(xmm7, xmm0);\n-  __ jcc(Assembler::aboveEqual, L_53d0);\n-  __ jmp(L_52a6);\n-\n-  __ bind(L_exit);\n+    \/\/ Source used to generate the AVX512 fmod assembly below:\n+    \/\/\n+    \/\/ #include <ia32intrin.h>\n+    \/\/ #include <emmintrin.h>\n+    \/\/ #pragma float_control(precise, on)\n+    \/\/\n+    \/\/ #define UINT32 unsigned int\n+    \/\/ #define SINT32 int\n+    \/\/ #define UINT64 unsigned __int64\n+    \/\/ #define SINT64 __int64\n+    \/\/\n+    \/\/ #define DP_FMA(a, b, c)    __fence(_mm_cvtsd_f64(_mm_fmadd_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c))))\n+    \/\/ #define DP_FMA_RN(a, b, c)    _mm_cvtsd_f64(_mm_fmadd_round_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c), (_MM_FROUND_TO_NEAREST_INT | _MM_FROUND_NO_EXC)))\n+    \/\/ #define DP_FMA_RZ(a, b, c) __fence(_mm_cvtsd_f64(_mm_fmadd_round_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC))))\n+    \/\/\n+    \/\/ #define DP_ROUND_RZ(a)   _mm_cvtsd_f64(_mm_roundscale_sd(_mm_setzero_pd(), _mm_set_sd(a), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC)))\n+    \/\/\n+    \/\/ #define DP_CONST(C)    _castu64_f64(0x##C##ull)\n+    \/\/ #define DP_AND(X, Y)   _mm_cvtsd_f64(_mm_and_pd(_mm_set_sd(X), _mm_set_sd(Y)))\n+    \/\/ #define DP_XOR(X, Y)   _mm_cvtsd_f64(_mm_xor_pd(_mm_set_sd(X), _mm_set_sd(Y)))\n+    \/\/ #define DP_OR(X, Y)    _mm_cvtsd_f64(_mm_or_pd(_mm_set_sd(X), _mm_set_sd(Y)))\n+    \/\/ #define DP_DIV_RZ(a, b) __fence(_mm_cvtsd_f64(_mm_div_round_sd(_mm_set_sd(a), _mm_set_sd(b), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC))))\n+    \/\/ #define DP_FNMA(a, b, c)    __fence(_mm_cvtsd_f64(_mm_fnmadd_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c))))\n+    \/\/ #define DP_FNMA_RZ(a, b, c) __fence(_mm_cvtsd_f64(_mm_fnmadd_round_sd(_mm_set_sd(a), _mm_set_sd(b), _mm_set_sd(c), (_MM_FROUND_TO_ZERO | _MM_FROUND_NO_EXC))))\n+    \/\/\n+    \/\/ #define D2L(x)  _mm_castpd_si128(x)\n+    \/\/ \/\/ transfer highest 32 bits (of low 64b) to GPR\n+    \/\/ #define TRANSFER_HIGH_INT32(X)   _mm_extract_epi32(D2L(_mm_set_sd(X)), 1)\n+    \/\/\n+    \/\/ double fmod(double x, double y)\n+    \/\/ {\n+    \/\/ double a, b, sgn_a, q, bs, bs2;\n+    \/\/ unsigned eq;\n+\n+    Label L_5280, L_52a0, L_5256, L_5300, L_5320, L_52c0, L_52d0, L_5360, L_5380, L_53b0, L_5390;\n+    Label L_53c0, L_52a6, L_53d0, L_exit;\n+\n+    __ movdqa(xmm2, xmm0);\n+    \/\/     \/\/ |x|, |y|\n+    \/\/     a = DP_AND(x, DP_CONST(7fffffffffffffff));\n+    __ movq(xmm0, xmm0);\n+    __ mov64(rax, 0x7FFFFFFFFFFFFFFF);\n+    __ evpbroadcastq(xmm3, rax, Assembler::AVX_128bit);\n+    __ vpand(xmm6, xmm0, xmm3, Assembler::AVX_128bit);\n+    \/\/     b = DP_AND(y, DP_CONST(7fffffffffffffff));\n+    __ vpand(xmm4, xmm1, xmm3, Assembler::AVX_128bit);\n+    \/\/     \/\/ sign(x)\n+    \/\/     sgn_a = DP_XOR(x, a);\n+    __ vpxor(xmm3, xmm6, xmm0, Assembler::AVX_128bit);\n+    \/\/     q = DP_DIV_RZ(a, b);\n+    __ movq(xmm5, xmm4);\n+    __ evdivsd(xmm0, xmm6, xmm5, Assembler::EVEX_RZ);\n+    \/\/     q = DP_ROUND_RZ(q);\n+    __ movq(xmm0, xmm0);\n+    \/\/     a = DP_AND(x, DP_CONST(7fffffffffffffff));\n+    __ vxorpd(xmm7, xmm7, xmm7, Assembler::AVX_128bit);\n+    \/\/     q = DP_ROUND_RZ(q);\n+    __ vroundsd(xmm0, xmm7, xmm0, 0xb);\n+    \/\/     eq = TRANSFER_HIGH_INT32(q);\n+    __ extractps(rax, xmm0, 1);\n+    \/\/     if (!eq)  return x + sgn_a;\n+    __ testl(rax, rax);\n+    __ jcc(Assembler::equal, L_5280);\n+    \/\/     if (eq >= 0x7fefffffu) goto SPECIAL_FMOD;\n+    __ cmpl(rax, 0x7feffffe);\n+    __ jcc(Assembler::belowEqual, L_52a0);\n+    __ vpxor(xmm2, xmm2, xmm2, Assembler::AVX_128bit);\n+    \/\/ SPECIAL_FMOD:\n+    \/\/\n+    \/\/     \/\/ y==0 or x==Inf?\n+    \/\/     if ((b == 0.0) || (!(a <= DP_CONST(7fefffffffffffff))))\n+    __ ucomisd(xmm4, xmm2);\n+    __ jcc(Assembler::notEqual, L_5256);\n+    __ jcc(Assembler::noParity, L_5300);\n+    __ bind(L_5256);\n+    __ movsd(xmm2, ExternalAddress((address)CONST_MAX), rax);\n+    __ ucomisd(xmm2, xmm6);\n+    __ jcc(Assembler::below, L_5300);\n+    __ movsd(xmm0, ExternalAddress((address)CONST_INF), rax);\n+    \/\/         return DP_FNMA(b, q, a);    \/\/ NaN\n+    \/\/     \/\/ y is NaN?\n+    \/\/     if (!(b <= DP_CONST(7ff0000000000000))) return y + y;\n+    __ ucomisd(xmm0, xmm4);\n+    __ jcc(Assembler::aboveEqual, L_5320);\n+    __ vaddsd(xmm0, xmm1, xmm1);\n+    __ jmp(L_exit);\n+    \/\/     if (!eq)  return x + sgn_a;\n+    __ align32();\n+    __ bind(L_5280);\n+    __ vaddsd(xmm0, xmm3, xmm2);\n+    __ jmp(L_exit);\n+    \/\/     a = DP_FNMA_RZ(b, q, a);\n+    __ align(8);\n+    __ bind(L_52a0);\n+    __ evfnmadd213sd(xmm0, xmm4, xmm6, Assembler::EVEX_RZ);\n+    \/\/     while (b <= a)\n+    __ bind(L_52a6);\n+    __ ucomisd(xmm0, xmm4);\n+    __ jcc(Assembler::aboveEqual, L_52c0);\n+    \/\/     a = DP_XOR(a, sgn_a);\n+    __ vpxor(xmm0, xmm3, xmm0, Assembler::AVX_128bit);\n+    __ jmp(L_exit);\n+    __ bind(L_52c0);\n+    __ movq(xmm6, xmm0);\n+    \/\/         q = DP_ROUND_RZ(q);\n+    __ vpxor(xmm1, xmm1, xmm1, Assembler::AVX_128bit);\n+    __ align32();\n+    __ bind(L_52d0);\n+    \/\/         q = DP_DIV_RZ(a, b);\n+    __ evdivsd(xmm2, xmm6, xmm5, Assembler::EVEX_RZ);\n+    \/\/         q = DP_ROUND_RZ(q);\n+    __ movq(xmm2, xmm2);\n+    __ vroundsd(xmm2, xmm1, xmm2, 0xb);\n+    \/\/     a = DP_FNMA_RZ(b, q, a);\n+    __ evfnmadd213sd(xmm2, xmm4, xmm0, Assembler::EVEX_RZ);\n+    \/\/     while (b <= a)\n+    __ ucomisd(xmm2, xmm4);\n+    __ movq(xmm6, xmm2);\n+    __ movapd(xmm0, xmm2);\n+    __ jcc(Assembler::aboveEqual, L_52d0);\n+    \/\/     a = DP_XOR(a, sgn_a);\n+    __ vpxor(xmm0, xmm3, xmm2, Assembler::AVX_128bit);\n+    __ jmp(L_exit);\n+    \/\/         return DP_FNMA(b, q, a);    \/\/ NaN\n+    __ bind(L_5300);\n+    __ vfnmadd213sd(xmm0, xmm4, xmm6);\n+    __ jmp(L_exit);\n+    \/\/     bs = b * DP_CONST(7fe0000000000000);\n+    __ bind(L_5320);\n+    __ vmulsd(xmm1, xmm4, ExternalAddress((address)CONST_e307), rax);\n+    \/\/     q = DP_DIV_RZ(a, bs);\n+    __ movq(xmm2, xmm1);\n+    __ evdivsd(xmm0, xmm6, xmm2, Assembler::EVEX_RZ);\n+    \/\/     q = DP_ROUND_RZ(q);\n+    __ movq(xmm0, xmm0);\n+    __ vroundsd(xmm7, xmm7, xmm0, 0xb);\n+    \/\/     eq = TRANSFER_HIGH_INT32(q);\n+    __ extractps(rax, xmm7, 1);\n+    \/\/     if (eq >= 0x7fefffffu)\n+    __ cmpl(rax, 0x7fefffff);\n+    __ jcc(Assembler::below, L_5360);\n+    \/\/         \/\/ b* 2*1023 * 2^1023\n+    \/\/         bs2 = bs * DP_CONST(7fe0000000000000);\n+    __ vmulsd(xmm0, xmm1, ExternalAddress((address)CONST_e307), rax);\n+    \/\/         while (bs2 <= a)\n+    __ ucomisd(xmm6, xmm0);\n+    __ jcc(Assembler::aboveEqual, L_5380);\n+    __ movapd(xmm7, xmm6);\n+    __ jmp(L_53b0);\n+    \/\/         a = DP_FNMA_RZ(b, q, a);\n+    __ bind(L_5360);\n+    __ evfnmadd213sd(xmm7, xmm1, xmm6, Assembler::EVEX_RZ);\n+    __ jmp(L_53b0);\n+    \/\/             q = DP_ROUND_RZ(q);\n+    __ bind(L_5380);\n+    __ vxorpd(xmm8, xmm8, xmm8, Assembler::AVX_128bit);\n+    \/\/             q = DP_DIV_RZ(qa, bs2);\n+    __ align32();\n+    __ bind(L_5390);\n+    __ evdivsd(xmm7, xmm6, xmm0, Assembler::EVEX_RZ);\n+    \/\/             q = DP_ROUND_RZ(q);\n+    __ movq(xmm7, xmm7);\n+    __ vroundsd(xmm7, xmm8, xmm7, 0xb);\n+    \/\/             a = DP_FNMA_RZ(bs2, q, a);\n+    __ evfnmadd213sd(xmm7, xmm0, xmm6, Assembler::EVEX_RZ);\n+    \/\/         while (bs2 <= a)\n+    __ ucomisd(xmm7, xmm0);\n+    __ movapd(xmm6, xmm7);\n+    __ jcc(Assembler::aboveEqual, L_5390);\n+    \/\/     while (bs <= a)\n+    __ bind(L_53b0);\n+    __ ucomisd(xmm7, xmm1);\n+    __ jcc(Assembler::aboveEqual, L_53c0);\n+    __ movapd(xmm0, xmm7);\n+    __ jmp(L_52a6);\n+    \/\/         q = DP_ROUND_RZ(q);\n+    __ bind(L_53c0);\n+    __ vxorpd(xmm6, xmm6, xmm6, Assembler::AVX_128bit);\n+    \/\/         q = DP_DIV_RZ(a, bs);\n+    __ align32();\n+    __ bind(L_53d0);\n+    __ evdivsd(xmm0, xmm7, xmm2, Assembler::EVEX_RZ);\n+    \/\/         q = DP_ROUND_RZ(q);\n+    __ movq(xmm0, xmm0);\n+    __ vroundsd(xmm0, xmm6, xmm0, 0xb);\n+    \/\/         a = DP_FNMA_RZ(bs, q, a);\n+    __ evfnmadd213sd(xmm0, xmm1, xmm7, Assembler::EVEX_RZ);\n+    \/\/     while (bs <= a)\n+    __ ucomisd(xmm0, xmm1);\n+    __ movapd(xmm7, xmm0);\n+    __ jcc(Assembler::aboveEqual, L_53d0);\n+    __ jmp(L_52a6);\n+\n+    __ bind(L_exit);\n@@ -307,227 +281,227 @@\n-\/\/   double fmod(double x, double y)\n-\/\/ {\n-\/\/ double a, b, sgn_a, q, bs, bs2, corr, res;\n-\/\/ unsigned eq;\n-\/\/ unsigned mxcsr, mxcsr_rz;\n-\n-\/\/   __asm { stmxcsr DWORD PTR[mxcsr] }\n-\/\/   mxcsr_rz = 0x7f80 | mxcsr;\n-  __ push(rax);\n-  __ stmxcsr(Address(rsp, 0));\n-  __ movl(rax, Address(rsp, 0));\n-  __ movl(rcx, rax);\n-  __ orl(rcx, 0x7f80);\n-  __ movl(Address(rsp, 0x04), rcx);\n-\n-\/\/     \/\/ |x|, |y|\n-\/\/     a = DP_AND(x, DP_CONST(7fffffffffffffff));\n-  __ movq(xmm2, xmm0);\n-  __ vmovdqu(xmm3, ExternalAddress((address)CONST_NaN), rcx);\n-  __ vpand(xmm4, xmm2, xmm3, Assembler::AVX_128bit);\n-\/\/     b = DP_AND(y, DP_CONST(7fffffffffffffff));\n-  __ vpand(xmm3, xmm1, xmm3, Assembler::AVX_128bit);\n-\/\/   \/\/ sign(x)\n-\/\/   sgn_a = DP_XOR(x, a);\n-  __ mov64(rcx, 0x8000000000000000);\n-  __ movq(xmm5, rcx);\n-  __ vpand(xmm2, xmm2, xmm5, Assembler::AVX_128bit);\n-\n-\/\/   if (a < b)  return x + sgn_a;\n-  __ ucomisd(xmm3, xmm4);\n-  __ jcc(Assembler::belowEqual, L_104a);\n-  __ vaddsd(xmm0, xmm2, xmm0);\n-  __ jmp(L_11bd);\n-\n-\/\/   if (((mxcsr & 0x6000)!=0x2000) && (a < b * 0x1p+260))\n-  __ bind(L_104a);\n-  __ andl(rax, 0x6000);\n-  __ cmpl(rax, 0x2000);\n-  __ jcc(Assembler::equal, L_10c1);\n-  __ vmulsd(xmm0, xmm3, ExternalAddress((address)CONST_1p260), rax);\n-  __ ucomisd(xmm0, xmm4);\n-  __ jcc(Assembler::belowEqual, L_10c1);\n-\/\/   {\n-\/\/     q = DP_DIV(a, b);\n-  __ vdivpd(xmm0, xmm4, xmm3, Assembler::AVX_128bit);\n-\/\/     corr = DP_SHR(DP_FNMA(b, q, a), 63);\n-  __ movapd(xmm1, xmm0);\n-  __ vfnmadd213sd(xmm1, xmm3, xmm4);\n-  __ movq(xmm5, xmm1);\n-  __ vpxor(xmm1, xmm1, xmm1, Assembler::AVX_128bit);\n-  __ vpcmpgtq(xmm5, xmm1, xmm5, Assembler::AVX_128bit);\n-\/\/     q = DP_PSUBQ(q, corr);\n-  __ vpaddq(xmm0, xmm5, xmm0, Assembler::AVX_128bit);\n-\/\/     q = DP_TRUNC(q);\n-  __ vroundsd(xmm0, xmm0, xmm0, 3);\n-\/\/     a = DP_FNMA(b, q, a);\n-  __ vfnmadd213sd(xmm0, xmm3, xmm4);\n-  __ align32();\n-\/\/     while (b <= a)\n-  __ bind(L_1090);\n-  __ ucomisd(xmm0, xmm3);\n-  __ jcc(Assembler::below, L_11b9);\n-\/\/     {\n-\/\/       q = DP_DIV(a, b);\n-  __ vdivsd(xmm4, xmm0, xmm3);\n-\/\/       corr = DP_SHR(DP_FNMA(b, q, a), 63);\n-  __ movapd(xmm5, xmm4);\n-  __ vfnmadd213sd(xmm5, xmm3, xmm0);\n-  __ movq(xmm5, xmm5);\n-  __ vpcmpgtq(xmm5, xmm1, xmm5, Assembler::AVX_128bit);\n-\/\/       q = DP_PSUBQ(q, corr);\n-  __ vpaddq(xmm4, xmm5, xmm4, Assembler::AVX_128bit);\n-\/\/       q = DP_TRUNC(q);\n-  __ vroundsd(xmm4, xmm4, xmm4, 3);\n-\/\/       a = DP_FNMA(b, q, a);\n-  __ vfnmadd231sd(xmm0, xmm3, xmm4);\n-  __ jmp(L_1090);\n-\/\/     }\n-\/\/     return DP_XOR(a, sgn_a);\n-\/\/   }\n-\n-\/\/   __asm { ldmxcsr DWORD PTR [mxcsr_rz] }\n-  __ bind(L_10c1);\n-  __ ldmxcsr(Address(rsp, 0x04));\n-\n-\/\/   q = DP_DIV(a, b);\n-  __ vdivpd(xmm0, xmm4, xmm3, Assembler::AVX_128bit);\n-\/\/   q = DP_TRUNC(q);\n-  __ vroundsd(xmm0, xmm0, xmm0, 3);\n-\n-\/\/   eq = TRANSFER_HIGH_INT32(q);\n-  __ extractps(rax, xmm0, 1);\n-\n-\/\/   if (__builtin_expect((eq >= 0x7fefffffu), (0==1))) goto SPECIAL_FMOD;\n-  __ cmpl(rax, 0x7feffffe);\n-  __ jcc(Assembler::above, L_10e7);\n-\n-\/\/   a = DP_FNMA(b, q, a);\n-  __ vfnmadd213sd(xmm0, xmm3, xmm4);\n-  __ jmp(L_11af);\n-\n-\/\/ SPECIAL_FMOD:\n-\n-\/\/   \/\/ y==0 or x==Inf?\n-\/\/   if ((b == 0.0) || (!(a <= DP_CONST(7fefffffffffffff))))\n-  __ bind(L_10e7);\n-  __ vpxor(xmm5, xmm5, xmm5, Assembler::AVX_128bit);\n-  __ ucomisd(xmm3, xmm5);\n-  __ jcc(Assembler::notEqual, L_10f3);\n-  __ jcc(Assembler::noParity, L_111c);\n-\n-  __ bind(L_10f3);\n-  __ movsd(xmm5, ExternalAddress((address)CONST_MAX), rax);\n-  __ ucomisd(xmm5, xmm4);\n-  __ jcc(Assembler::below, L_111c);\n-\/\/     return res;\n-\/\/   }\n-\/\/   \/\/ y is NaN?\n-\/\/   if (!(b <= DP_CONST(7ff0000000000000))) {\n-  __ movsd(xmm0, ExternalAddress((address)CONST_INF), rax);\n-  __ ucomisd(xmm0, xmm3);\n-  __ jcc(Assembler::aboveEqual, L_112a);\n-\/\/     res = y + y;\n-  __ vaddsd(xmm0, xmm1, xmm1);\n-\/\/     __asm { ldmxcsr DWORD PTR[mxcsr] }\n-  __ ldmxcsr(Address(rsp, 0));\n-  __ jmp(L_11bd);\n-\/\/   {\n-\/\/     res = DP_FNMA(b, q, a);    \/\/ NaN\n-  __ bind(L_111c);\n-  __ vfnmadd213sd(xmm0, xmm3, xmm4);\n-\/\/     __asm { ldmxcsr DWORD PTR[mxcsr] }\n-  __ ldmxcsr(Address(rsp, 0));\n-  __ jmp(L_11bd);\n-\/\/     return res;\n-\/\/   }\n-\n-\/\/   \/\/ b* 2*1023\n-\/\/   bs = b * DP_CONST(7fe0000000000000);\n-  __ bind(L_112a);\n-  __ vmulsd(xmm1, xmm3, ExternalAddress((address)CONST_e307), rax);\n-\n-\/\/   q = DP_DIV(a, bs);\n-  __ vdivsd(xmm0, xmm4, xmm1);\n-\/\/   q = DP_TRUNC(q);\n-  __ vroundsd(xmm0, xmm0, xmm0, 3);\n-\n-\/\/   eq = TRANSFER_HIGH_INT32(q);\n-  __ extractps(rax, xmm0, 1);\n-\n-\/\/   if (eq >= 0x7fefffffu)\n-  __ cmpl(rax, 0x7fefffff);\n-  __ jcc(Assembler::below, L_116e);\n-\/\/   {\n-\/\/     \/\/ b* 2*1023 * 2^1023\n-\/\/     bs2 = bs * DP_CONST(7fe0000000000000);\n-  __ vmulsd(xmm0, xmm1, ExternalAddress((address)CONST_e307), rax);\n-\/\/     while (bs2 <= a)\n-  __ ucomisd(xmm4, xmm0);\n-  __ jcc(Assembler::below, L_1173);\n-\/\/     {\n-\/\/       q = DP_DIV(a, bs2);\n-  __ bind(L_1157);\n-  __ vdivsd(xmm5, xmm4, xmm0);\n-\/\/       q = DP_TRUNC(q);\n-  __ vroundsd(xmm5, xmm5, xmm5, 3);\n-\/\/       a = DP_FNMA(bs2, q, a);\n-  __ vfnmadd231sd(xmm4, xmm0, xmm5);\n-\/\/     while (bs2 <= a)\n-  __ ucomisd(xmm4, xmm0);\n-  __ jcc(Assembler::aboveEqual, L_1157);\n-  __ jmp(L_1173);\n-\/\/     }\n-\/\/   }\n-\/\/   else\n-\/\/   a = DP_FNMA(bs, q, a);\n-  __ bind(L_116e);\n-  __ vfnmadd231sd(xmm4, xmm1, xmm0);\n-\n-\/\/   while (bs <= a)\n-  __ bind(L_1173);\n-  __ ucomisd(xmm4, xmm1);\n-  __ jcc(Assembler::aboveEqual, L_117f);\n-  __ movapd(xmm0, xmm4);\n-  __ jmp(L_11af);\n-\/\/   {\n-\/\/     q = DP_DIV(a, bs);\n-  __ bind(L_117f);\n-  __ vdivsd(xmm0, xmm4, xmm1);\n-\/\/     q = DP_TRUNC(q);\n-  __ vroundsd(xmm0, xmm0, xmm0, 3);\n-\/\/     a = DP_FNMA(bs, q, a);\n-  __ vfnmadd213sd(xmm0, xmm1, xmm4);\n-\n-\/\/   while (bs <= a)\n-  __ ucomisd(xmm0, xmm1);\n-  __ movapd(xmm4, xmm0);\n-  __ jcc(Assembler::aboveEqual, L_117f);\n-  __ jmp(L_11af);\n-  __ align32();\n-\/\/   {\n-\/\/     q = DP_DIV(a, b);\n-  __ bind(L_11a0);\n-  __ vdivsd(xmm1, xmm0, xmm3);\n-\/\/     q = DP_TRUNC(q);\n-  __ vroundsd(xmm1, xmm1, xmm1, 3);\n-\/\/     a = DP_FNMA(b, q, a);\n-  __ vfnmadd231sd(xmm0, xmm3, xmm1);\n-\n-\/\/ FMOD_CONT:\n-\/\/   while (b <= a)\n-  __ bind(L_11af);\n-  __ ucomisd(xmm0, xmm3);\n-  __ jcc(Assembler::aboveEqual, L_11a0);\n-\/\/   }\n-\n-\/\/   __asm { ldmxcsr DWORD PTR[mxcsr] }\n-  __ ldmxcsr(Address(rsp, 0));\n-  __ bind(L_11b9);\n-  __ vpxor(xmm0, xmm2, xmm0, Assembler::AVX_128bit);\n-\/\/   }\n-\n-\/\/   goto FMOD_CONT;\n-\n-\/\/ }\n-  __ bind(L_11bd);\n-  __ pop(rax);\n+    \/\/   double fmod(double x, double y)\n+    \/\/ {\n+    \/\/ double a, b, sgn_a, q, bs, bs2, corr, res;\n+    \/\/ unsigned eq;\n+    \/\/ unsigned mxcsr, mxcsr_rz;\n+\n+    \/\/   __asm { stmxcsr DWORD PTR[mxcsr] }\n+    \/\/   mxcsr_rz = 0x7f80 | mxcsr;\n+    __ push(rax);\n+    __ stmxcsr(Address(rsp, 0));\n+    __ movl(rax, Address(rsp, 0));\n+    __ movl(rcx, rax);\n+    __ orl(rcx, 0x7f80);\n+    __ movl(Address(rsp, 0x04), rcx);\n+\n+    \/\/     \/\/ |x|, |y|\n+    \/\/     a = DP_AND(x, DP_CONST(7fffffffffffffff));\n+    __ movq(xmm2, xmm0);\n+    __ vmovdqu(xmm3, ExternalAddress((address)CONST_NaN), rcx);\n+    __ vpand(xmm4, xmm2, xmm3, Assembler::AVX_128bit);\n+    \/\/     b = DP_AND(y, DP_CONST(7fffffffffffffff));\n+    __ vpand(xmm3, xmm1, xmm3, Assembler::AVX_128bit);\n+    \/\/   \/\/ sign(x)\n+    \/\/   sgn_a = DP_XOR(x, a);\n+    __ mov64(rcx, 0x8000000000000000);\n+    __ movq(xmm5, rcx);\n+    __ vpand(xmm2, xmm2, xmm5, Assembler::AVX_128bit);\n+\n+    \/\/   if (a < b)  return x + sgn_a;\n+    __ ucomisd(xmm3, xmm4);\n+    __ jcc(Assembler::belowEqual, L_104a);\n+    __ vaddsd(xmm0, xmm2, xmm0);\n+    __ jmp(L_11bd);\n+\n+    \/\/   if (((mxcsr & 0x6000)!=0x2000) && (a < b * 0x1p+260))\n+    __ bind(L_104a);\n+    __ andl(rax, 0x6000);\n+    __ cmpl(rax, 0x2000);\n+    __ jcc(Assembler::equal, L_10c1);\n+    __ vmulsd(xmm0, xmm3, ExternalAddress((address)CONST_1p260), rax);\n+    __ ucomisd(xmm0, xmm4);\n+    __ jcc(Assembler::belowEqual, L_10c1);\n+    \/\/   {\n+    \/\/     q = DP_DIV(a, b);\n+    __ vdivpd(xmm0, xmm4, xmm3, Assembler::AVX_128bit);\n+    \/\/     corr = DP_SHR(DP_FNMA(b, q, a), 63);\n+    __ movapd(xmm1, xmm0);\n+    __ vfnmadd213sd(xmm1, xmm3, xmm4);\n+    __ movq(xmm5, xmm1);\n+    __ vpxor(xmm1, xmm1, xmm1, Assembler::AVX_128bit);\n+    __ vpcmpgtq(xmm5, xmm1, xmm5, Assembler::AVX_128bit);\n+    \/\/     q = DP_PSUBQ(q, corr);\n+    __ vpaddq(xmm0, xmm5, xmm0, Assembler::AVX_128bit);\n+    \/\/     q = DP_TRUNC(q);\n+    __ vroundsd(xmm0, xmm0, xmm0, 3);\n+    \/\/     a = DP_FNMA(b, q, a);\n+    __ vfnmadd213sd(xmm0, xmm3, xmm4);\n+    __ align32();\n+    \/\/     while (b <= a)\n+    __ bind(L_1090);\n+    __ ucomisd(xmm0, xmm3);\n+    __ jcc(Assembler::below, L_11b9);\n+    \/\/     {\n+    \/\/       q = DP_DIV(a, b);\n+    __ vdivsd(xmm4, xmm0, xmm3);\n+    \/\/       corr = DP_SHR(DP_FNMA(b, q, a), 63);\n+    __ movapd(xmm5, xmm4);\n+    __ vfnmadd213sd(xmm5, xmm3, xmm0);\n+    __ movq(xmm5, xmm5);\n+    __ vpcmpgtq(xmm5, xmm1, xmm5, Assembler::AVX_128bit);\n+    \/\/       q = DP_PSUBQ(q, corr);\n+    __ vpaddq(xmm4, xmm5, xmm4, Assembler::AVX_128bit);\n+    \/\/       q = DP_TRUNC(q);\n+    __ vroundsd(xmm4, xmm4, xmm4, 3);\n+    \/\/       a = DP_FNMA(b, q, a);\n+    __ vfnmadd231sd(xmm0, xmm3, xmm4);\n+    __ jmp(L_1090);\n+    \/\/     }\n+    \/\/     return DP_XOR(a, sgn_a);\n+    \/\/   }\n+\n+    \/\/   __asm { ldmxcsr DWORD PTR [mxcsr_rz] }\n+    __ bind(L_10c1);\n+    __ ldmxcsr(Address(rsp, 0x04));\n+\n+    \/\/   q = DP_DIV(a, b);\n+    __ vdivpd(xmm0, xmm4, xmm3, Assembler::AVX_128bit);\n+    \/\/   q = DP_TRUNC(q);\n+    __ vroundsd(xmm0, xmm0, xmm0, 3);\n+\n+    \/\/   eq = TRANSFER_HIGH_INT32(q);\n+    __ extractps(rax, xmm0, 1);\n+\n+    \/\/   if (__builtin_expect((eq >= 0x7fefffffu), (0==1))) goto SPECIAL_FMOD;\n+    __ cmpl(rax, 0x7feffffe);\n+    __ jcc(Assembler::above, L_10e7);\n+\n+    \/\/   a = DP_FNMA(b, q, a);\n+    __ vfnmadd213sd(xmm0, xmm3, xmm4);\n+    __ jmp(L_11af);\n+\n+    \/\/ SPECIAL_FMOD:\n+\n+    \/\/   \/\/ y==0 or x==Inf?\n+    \/\/   if ((b == 0.0) || (!(a <= DP_CONST(7fefffffffffffff))))\n+    __ bind(L_10e7);\n+    __ vpxor(xmm5, xmm5, xmm5, Assembler::AVX_128bit);\n+    __ ucomisd(xmm3, xmm5);\n+    __ jcc(Assembler::notEqual, L_10f3);\n+    __ jcc(Assembler::noParity, L_111c);\n+\n+    __ bind(L_10f3);\n+    __ movsd(xmm5, ExternalAddress((address)CONST_MAX), rax);\n+    __ ucomisd(xmm5, xmm4);\n+    __ jcc(Assembler::below, L_111c);\n+    \/\/     return res;\n+    \/\/   }\n+    \/\/   \/\/ y is NaN?\n+    \/\/   if (!(b <= DP_CONST(7ff0000000000000))) {\n+    __ movsd(xmm0, ExternalAddress((address)CONST_INF), rax);\n+    __ ucomisd(xmm0, xmm3);\n+    __ jcc(Assembler::aboveEqual, L_112a);\n+    \/\/     res = y + y;\n+    __ vaddsd(xmm0, xmm1, xmm1);\n+    \/\/     __asm { ldmxcsr DWORD PTR[mxcsr] }\n+    __ ldmxcsr(Address(rsp, 0));\n+    __ jmp(L_11bd);\n+    \/\/   {\n+    \/\/     res = DP_FNMA(b, q, a);    \/\/ NaN\n+    __ bind(L_111c);\n+    __ vfnmadd213sd(xmm0, xmm3, xmm4);\n+    \/\/     __asm { ldmxcsr DWORD PTR[mxcsr] }\n+    __ ldmxcsr(Address(rsp, 0));\n+    __ jmp(L_11bd);\n+    \/\/     return res;\n+    \/\/   }\n+\n+    \/\/   \/\/ b* 2*1023\n+    \/\/   bs = b * DP_CONST(7fe0000000000000);\n+    __ bind(L_112a);\n+    __ vmulsd(xmm1, xmm3, ExternalAddress((address)CONST_e307), rax);\n+\n+    \/\/   q = DP_DIV(a, bs);\n+    __ vdivsd(xmm0, xmm4, xmm1);\n+    \/\/   q = DP_TRUNC(q);\n+    __ vroundsd(xmm0, xmm0, xmm0, 3);\n+\n+    \/\/   eq = TRANSFER_HIGH_INT32(q);\n+    __ extractps(rax, xmm0, 1);\n+\n+    \/\/   if (eq >= 0x7fefffffu)\n+    __ cmpl(rax, 0x7fefffff);\n+    __ jcc(Assembler::below, L_116e);\n+    \/\/   {\n+    \/\/     \/\/ b* 2*1023 * 2^1023\n+    \/\/     bs2 = bs * DP_CONST(7fe0000000000000);\n+    __ vmulsd(xmm0, xmm1, ExternalAddress((address)CONST_e307), rax);\n+    \/\/     while (bs2 <= a)\n+    __ ucomisd(xmm4, xmm0);\n+    __ jcc(Assembler::below, L_1173);\n+    \/\/     {\n+    \/\/       q = DP_DIV(a, bs2);\n+    __ bind(L_1157);\n+    __ vdivsd(xmm5, xmm4, xmm0);\n+    \/\/       q = DP_TRUNC(q);\n+    __ vroundsd(xmm5, xmm5, xmm5, 3);\n+    \/\/       a = DP_FNMA(bs2, q, a);\n+    __ vfnmadd231sd(xmm4, xmm0, xmm5);\n+    \/\/     while (bs2 <= a)\n+    __ ucomisd(xmm4, xmm0);\n+    __ jcc(Assembler::aboveEqual, L_1157);\n+    __ jmp(L_1173);\n+    \/\/     }\n+    \/\/   }\n+    \/\/   else\n+    \/\/   a = DP_FNMA(bs, q, a);\n+    __ bind(L_116e);\n+    __ vfnmadd231sd(xmm4, xmm1, xmm0);\n+\n+    \/\/   while (bs <= a)\n+    __ bind(L_1173);\n+    __ ucomisd(xmm4, xmm1);\n+    __ jcc(Assembler::aboveEqual, L_117f);\n+    __ movapd(xmm0, xmm4);\n+    __ jmp(L_11af);\n+    \/\/   {\n+    \/\/     q = DP_DIV(a, bs);\n+    __ bind(L_117f);\n+    __ vdivsd(xmm0, xmm4, xmm1);\n+    \/\/     q = DP_TRUNC(q);\n+    __ vroundsd(xmm0, xmm0, xmm0, 3);\n+    \/\/     a = DP_FNMA(bs, q, a);\n+    __ vfnmadd213sd(xmm0, xmm1, xmm4);\n+\n+    \/\/   while (bs <= a)\n+    __ ucomisd(xmm0, xmm1);\n+    __ movapd(xmm4, xmm0);\n+    __ jcc(Assembler::aboveEqual, L_117f);\n+    __ jmp(L_11af);\n+    __ align32();\n+    \/\/   {\n+    \/\/     q = DP_DIV(a, b);\n+    __ bind(L_11a0);\n+    __ vdivsd(xmm1, xmm0, xmm3);\n+    \/\/     q = DP_TRUNC(q);\n+    __ vroundsd(xmm1, xmm1, xmm1, 3);\n+    \/\/     a = DP_FNMA(b, q, a);\n+    __ vfnmadd231sd(xmm0, xmm3, xmm1);\n+\n+    \/\/ FMOD_CONT:\n+    \/\/   while (b <= a)\n+    __ bind(L_11af);\n+    __ ucomisd(xmm0, xmm3);\n+    __ jcc(Assembler::aboveEqual, L_11a0);\n+    \/\/   }\n+\n+    \/\/   __asm { ldmxcsr DWORD PTR[mxcsr] }\n+    __ ldmxcsr(Address(rsp, 0));\n+    __ bind(L_11b9);\n+    __ vpxor(xmm0, xmm2, xmm0, Assembler::AVX_128bit);\n+    \/\/   }\n+\n+    \/\/   goto FMOD_CONT;\n+\n+    \/\/ }\n+    __ bind(L_11bd);\n+    __ pop(rax);\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64_fmod.cpp","additions":421,"deletions":447,"binary":false,"changes":868,"status":"modified"}]}