{"files":[{"patch":"@@ -542,0 +542,46 @@\n+void ParallelScavengeHeap::object_iterate_parallel(ObjectClosure* cl,\n+                                                   uint worker_id,\n+                                                   uint thread_num) {\n+  \/\/ It is hard to divide space in youngGen for parallel processing because it is\n+  \/\/ hard to get valid object for any given address.\n+  \/\/ So use 1 thread to process 1 space in Young Generation (eden, from\/to).\n+  assert(worker_id < thread_num,\n+         \"worker (%d) must not exceed total thread number (%d)\", worker_id, thread_num);\n+  if (thread_num <= 1) {\n+    \/\/ Work serially as less than 1 workers\n+    this->object_iterate(cl);\n+  } else if (thread_num == 2) {\n+    \/\/ 2 workers, all workers for all generations\n+    \/\/ YoungGen internally handle the logic of assigning worker to seperate space\n+    young_gen()->object_iterate_parallel(cl, worker_id, thread_num);\n+    old_gen()->object_iterate_parallel(cl, worker_id, thread_num);\n+  } else {\n+    \/\/ More than 2 workers.\n+    \/\/ The first 2 threads (worker 0 and worker 1) for youngGen and others for oldGen\n+    if (worker_id <= 1) {\n+      young_gen()->object_iterate_parallel(cl, worker_id, thread_num);\n+    } else {\n+      old_gen()->object_iterate_parallel(cl, worker_id, thread_num);\n+    }\n+  }\n+}\n+\n+class PSScavengeParallelObjectIterator : public ParallelObjectIterator {\n+private:\n+  uint _thread_num;\n+  ParallelScavengeHeap*  _heap;\n+\n+public:\n+  PSScavengeParallelObjectIterator(uint thread_num) :\n+      _thread_num(thread_num),\n+      _heap(ParallelScavengeHeap::heap()) {}\n+\n+  virtual void object_iterate(ObjectClosure* cl, uint worker_id) {\n+    _heap->object_iterate_parallel(cl, worker_id, _thread_num);\n+  }\n+};\n+\n+ParallelObjectIterator* ParallelScavengeHeap::parallel_object_iterator(uint thread_num) {\n+  return new PSScavengeParallelObjectIterator(thread_num);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":46,"deletions":0,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -212,0 +212,2 @@\n+  void object_iterate_parallel(ObjectClosure* cl, uint worker_id, uint thread_num);\n+  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num);\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -174,0 +174,90 @@\n+void PSOldGen::object_iterate_parallel(ObjectClosure* cl,\n+                                       uint worker_id,\n+                                       uint thread_num) {\n+  if (thread_num <= 1) {\n+    \/\/ Only 1 thread, work serially for whole space\n+    object_space()->object_iterate(cl);\n+  } else if (thread_num == 2) {\n+    \/\/ if there are 2 workers, all workers process youngGen and oldGen.\n+    blocks_iterate_parallel(cl, worker_id, thread_num);\n+  } else if (worker_id >=2) {\n+    \/\/ If there are more than 2 workers, let worker 0 and worker 1 process youngGen,\n+    \/\/ and others process oldGen, so all workers can process in parallel.\n+    \/\/ Actually there are thread_num-2 worker for oldGen and worker_id should start\n+    \/\/ from 0 to calculate blocks.\n+    \/\/ See blocks_iterate_parallel for details.\n+    uint worker = worker_id - 2;\n+    uint total_workers = thread_num -2;\n+    blocks_iterate_parallel(cl, worker, total_workers);\n+  }\n+}\n+\n+\/* Divide space into blocks, every worker processes blocks that\n+ * begin at worker_id * BLOCK_SIZE + stride, where stride is\n+ * constant value calculated as number_thread * BLOCK_SIZE.\n+ * example for 4 workers:\n+ *      +========================+\n+ *      |    BLOCK 0 <worker0>   |  -----------------------\n+ *      +------------------------+           ^\n+ *      |    BLOCK 1 <worker1>   |           |\n+ *      +------------------------+           |\n+ *      |    BLOCK 2 <worker2>   |  BLOCKSIZE * number_thread\n+ *      +------------------------+           |\n+ *      |    BLOCK 3 <worker4>   |           |\n+ *      +========================+           v\n+ *      |    BLOCK 5 <worker0>   |  -----------------------\n+ *      +------------------------+\n+ *      |    BLOCK 6 <worker1>   |\n+ *      +------------------------+\n+ *      |    BLOCK 7 <worker2>   |\n+ *      +------------------------+\n+ *      |    BLOCK 8 <worker4>   |\n+ *      +========================+\n+ * The worker0 first processes BLOCK 0 and then BLOCK 5.\n+ * NOTE:\n+ * - The initial block start address may not be a valid\n+ * object address, _start_array is used to correct it.\n+ *\n+ * - The end address is not necessary to be object address.\n+ *\n+ * - If there is an object that cross blocks, it is\n+ * processed by the worker that the object start address\n+ * locates in the related block.\n+ *\n+ *\/\n+void PSOldGen::blocks_iterate_parallel(ObjectClosure* cl,\n+                                       uint worker_id,\n+                                       uint thread_num) {\n+  const int BLOCK_SIZE = 64 * 1024; \/\/ 64 KB\n+  MutableSpace *space = object_space();\n+  HeapWord* bottom = space->bottom();\n+  HeapWord* top = space->top();\n+  HeapWord* begin = bottom + worker_id * BLOCK_SIZE;\n+  uint stride = thread_num * BLOCK_SIZE;\n+\n+  while (begin < top) {\n+    \/\/ iterate objects in block.\n+    HeapWord* end = MIN2(top, begin + BLOCK_SIZE);\n+    \/\/ There can be no object between begin and end.\n+    if (start_array()->object_starts_in_range(begin, end)) {\n+      \/\/ There is objects in the range. Find the object of begin address.\n+      \/\/ Note that object_start() can reture the last object in previous block,\n+      \/\/ and the object is processed by other worker, here only focus objects that\n+      \/\/ fall into the current block.\n+      HeapWord* start = start_array()->object_start(begin);\n+      if (start < begin) {\n+        start += oop(start)->size();\n+      }\n+      assert(begin <= start && start < end,\n+             \"object %p must in the range of [%p, %p)\\n\", start, begin, end);\n+      \/\/ iterate objects\n+      HeapWord* p = start;\n+      while (p < end) {\n+        cl->do_object(oop(p));\n+        p += oop(p)->size();\n+      }\n+    }\n+    begin += stride;\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.cpp","additions":90,"deletions":0,"binary":false,"changes":90,"status":"modified"},{"patch":"@@ -165,0 +165,2 @@\n+  void object_iterate_parallel(ObjectClosure* cl, uint worker_id, uint thread_num);\n+  void blocks_iterate_parallel(ObjectClosure* cl, uint worker_id, uint worker_num);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -706,0 +706,22 @@\n+\/\/ It is hard to identify an object with given address in youngGen, so process every space\n+\/\/ seperately with different worker, and one worker for one space\n+void PSYoungGen::object_iterate_parallel(ObjectClosure* blk,\n+                                         uint worker_id,\n+                                         uint thread_num) {\n+  if (thread_num <=1) {\n+    \/\/ only one worker, iterate serially\n+    object_iterate(blk);\n+  } else {\n+    if (worker_id == 0) {\n+      \/\/ worker 0 process eden serially\n+      eden_space()->object_iterate(blk);\n+    } else if (worker_id == 1) {\n+      \/\/ worker 1 process from space and to space serially\n+      from_space()->object_iterate(blk);\n+      to_space()->object_iterate(blk);\n+    } else {\n+      \/\/ nothing to do. leave all other workers for oldGen.\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/psYoungGen.cpp","additions":22,"deletions":0,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -143,0 +143,3 @@\n+  void object_iterate_parallel(ObjectClosure* blk,\n+                               uint worker_id,\n+                               uint thread_num);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psYoungGen.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"}]}