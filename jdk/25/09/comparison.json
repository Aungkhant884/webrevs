{"files":[{"patch":"@@ -542,0 +542,61 @@\n+\/\/ The HeapBlockClaimer is used during parallel iteration over the heap,\n+\/\/ allowing workers to claim heap blocks, gaining exclusive rights to these blocks.\n+\/\/ The eden and survivor spaces are treated as single blocks as it is hard to divide\n+\/\/ these spaces.\n+\/\/ The old spaces are divided into serveral fixed-size blocks.\n+class HeapBlockClaimer : public StackObj {\n+  \/\/ Index of iterable block, negative values for indexes of young generation spaces,\n+  \/\/ zero and positive values for indexes of blocks in old generation space.\n+  ssize_t _claimed_index;\n+ public:\n+  static const ssize_t EdenIndex = -2;\n+  static const ssize_t SurvivorIndex = -1;\n+\n+  HeapBlockClaimer() : _claimed_index(EdenIndex) { }\n+  \/\/ Claim the block and get the block index.\n+  bool claim_and_get_block(ssize_t* block_index) {\n+    assert(block_index != NULL, \"Invalid index pointer\");\n+    *block_index = Atomic::fetch_and_add(&_claimed_index, 1);\n+    ssize_t iterable_blocks = (ssize_t)ParallelScavengeHeap::heap()->old_gen()->iterable_blocks();\n+    if (*block_index >= iterable_blocks) {\n+      return false;\n+    }\n+    return true;\n+  }\n+};\n+\n+void ParallelScavengeHeap::object_iterate_parallel(ObjectClosure* cl,\n+                                                   HeapBlockClaimer* claimer) {\n+  ssize_t block_index;\n+  \/\/ Iterate until all blocks are claimed\n+  while (claimer->claim_and_get_block(&block_index)) {\n+    if (block_index == HeapBlockClaimer::EdenIndex) {\n+      young_gen()->eden_space()->object_iterate(cl);\n+    } else if (block_index == HeapBlockClaimer::SurvivorIndex) {\n+      young_gen()->from_space()->object_iterate(cl);\n+      young_gen()->to_space()->object_iterate(cl);\n+    } else {\n+      old_gen()->block_iterate(cl, (size_t)block_index);\n+    }\n+  }\n+}\n+\n+class PSScavengeParallelObjectIterator : public ParallelObjectIterator {\n+private:\n+  ParallelScavengeHeap*  _heap;\n+  HeapBlockClaimer      _claimer;\n+\n+public:\n+  PSScavengeParallelObjectIterator() :\n+      _heap(ParallelScavengeHeap::heap()),\n+      _claimer() {}\n+\n+  virtual void object_iterate(ObjectClosure* cl, uint worker_id) {\n+    _heap->object_iterate_parallel(cl, &_claimer);\n+  }\n+};\n+\n+ParallelObjectIterator* ParallelScavengeHeap::parallel_object_iterator(uint thread_num) {\n+  return new PSScavengeParallelObjectIterator();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.cpp","additions":61,"deletions":0,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -48,0 +48,1 @@\n+class HeapBlockClaimer;\n@@ -210,0 +211,2 @@\n+  void object_iterate_parallel(ObjectClosure* cl, HeapBlockClaimer* claimer);\n+  virtual ParallelObjectIterator* parallel_object_iterator(uint thread_num);\n","filename":"src\/hotspot\/share\/gc\/parallel\/parallelScavengeHeap.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -176,0 +176,45 @@\n+\/*\n+ * Divide space into blocks, processes block begins at\n+ * bottom + block_index  * (IterateBlockSize \/ HeapWordSize).\n+ * NOTE:\n+ * - The initial block start address may not be a valid\n+ * object address, _start_array is used to correct it.\n+ *\n+ * - The end address is not necessary to be object address.\n+ *\n+ * - If there is an object that crosses blocks, it is\n+ * processed by the worker that owns the block within\n+ * which the object starts.\n+ *\n+ *\/\n+void PSOldGen::block_iterate(ObjectClosure* cl, size_t block_index) {\n+  MutableSpace *space = object_space();\n+  HeapWord* bottom = space->bottom();\n+  HeapWord* top = space->top();\n+  size_t block_word_size = IterateBlockSize \/ HeapWordSize;\n+  HeapWord* begin = bottom + block_index * block_word_size;\n+\n+  assert((block_word_size % (ObjectStartArray::block_size)) == 0,\n+         \"BLOCK SIZE not a multiple of start_array block\");\n+\n+  \/\/ iterate objects in block.\n+  HeapWord* end = MIN2(top, begin + block_word_size);\n+  \/\/ Only iterate if there are objects between begin and end.\n+  if (start_array()->object_starts_in_range(begin, end)) {\n+    \/\/ Process objects in the range, start from finding object at the begining\n+    \/\/ address. Note that object_start() can return the last object in previous\n+    \/\/ block, and that object is processed by other worker scanning that block.\n+    \/\/ So here only focus on objects that fall into the current block.\n+    HeapWord* start = start_array()->object_start(begin);\n+    if (start < begin) {\n+      start += oop(start)->size();\n+    }\n+    assert(begin <= start,\n+           \"object address\" PTR_FORMAT \" must be larger or equal to block address at \" PTR_FORMAT \"\\n\",\n+           start, begin);\n+    for (HeapWord* p = start; p < end; p += oop(p)->size()) {\n+      cl->do_object(oop(p));\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.cpp","additions":45,"deletions":0,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -55,0 +55,3 @@\n+  \/\/ Block size for parallel iteration\n+  static const size_t IterateBlockSize = 1024 * 1024;\n+\n@@ -165,0 +168,5 @@\n+  size_t iterable_blocks() {\n+    return (object_space()->used_in_bytes() + IterateBlockSize - 1) \/ IterateBlockSize;\n+  }\n+  \/\/ Iterate block with given block_index\n+  void block_iterate(ObjectClosure* cl, size_t block_index);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psOldGen.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"}]}