{"files":[{"patch":"@@ -1928,8 +1928,1 @@\n-\/\/\n-\/\/ <alignment_hint> is being ignored by this function. It is very probable however that the\n-\/\/ alignment requirements are met anyway, because shmat() attaches at 256M boundaries.\n-\/\/ Should this be not enogh, we can put more work into it.\n-static char* reserve_shmated_memory (\n-  size_t bytes,\n-  char* requested_addr,\n-  size_t alignment_hint) {\n+static char* reserve_shmated_memory (size_t bytes, char* requested_addr) {\n@@ -1938,5 +1931,1 @@\n-    PTR_FORMAT \", alignment_hint \" UINTX_FORMAT \"...\",\n-    bytes, p2i(requested_addr), alignment_hint);\n-\n-  \/\/ Either give me wish address or wish alignment but not both.\n-  assert0(!(requested_addr != NULL && alignment_hint != 0));\n+    PTR_FORMAT \"...\", bytes, p2i(requested_addr));\n@@ -2064,9 +2053,4 @@\n-\/\/ If <alignment_hint> is given and <requested_addr> is NULL, an attempt is made to\n-\/\/ allocate at an address aligned with the given alignment. Failing that, memory\n-\/\/ is aligned anywhere.\n-static char* reserve_mmaped_memory(size_t bytes, char* requested_addr, size_t alignment_hint) {\n-  trcVerbose(\"reserve_mmaped_memory \" UINTX_FORMAT \" bytes, wishaddress \" PTR_FORMAT \", \"\n-    \"alignment_hint \" UINTX_FORMAT \"...\",\n-    bytes, p2i(requested_addr), alignment_hint);\n-\n-  \/\/ If a wish address is given, but not aligned to 4K page boundary, mmap will fail.\n+static char* reserve_mmaped_memory(size_t bytes, char* requested_addr) {\n+  trcVerbose(\"reserve_mmaped_memory \" UINTX_FORMAT \" bytes, wishaddress \" PTR_FORMAT \"...\",\n+    bytes, p2i(requested_addr));\n+\n@@ -2087,12 +2071,7 @@\n-  \/\/ Specify one or the other but not both.\n-  assert0(!(requested_addr != NULL && alignment_hint > 0));\n-\n-  \/\/ In 64K mode, we claim the global page size (os::vm_page_size())\n-  \/\/ is 64K. This is one of the few points where that illusion may\n-  \/\/ break, because mmap() will always return memory aligned to 4K. So\n-  \/\/ we must ensure we only ever return memory aligned to 64k.\n-  if (alignment_hint) {\n-    alignment_hint = lcm(alignment_hint, os::vm_page_size());\n-  } else {\n-    alignment_hint = os::vm_page_size();\n-  }\n+  \/\/ In 64K mode, we lie and claim the global page size (os::vm_page_size()) is 64K\n+  \/\/  (complicated story). This mostly works just fine since 64K is a multiple of the\n+  \/\/  actual 4K lowest page size. Only at a few seams light shines thru, e.g. when\n+  \/\/  calling mmap. mmap will return memory aligned to the lowest pages size - 4K -\n+  \/\/  so we must make sure - transparently - that the caller only ever sees 64K\n+  \/\/  aligned mapping start addresses.\n+  const size_t alignment = os::vm_page_size();\n@@ -2105,2 +2084,2 @@\n-  assert0(alignment_hint != 0 && is_aligned_to(alignment_hint, os::vm_page_size())); \/\/ see above\n-  const size_t extra_size = size + alignment_hint;\n+  assert0(alignment != 0 && is_aligned_to(alignment, os::vm_page_size())); \/\/ see above\n+  const size_t extra_size = size + alignment;\n@@ -2134,1 +2113,1 @@\n-  char* const addr_aligned = align_up(addr, alignment_hint);\n+  char* const addr_aligned = align_up(addr, alignment);\n@@ -2350,1 +2329,1 @@\n-char* os::pd_reserve_memory(size_t bytes, size_t alignment_hint) {\n+char* os::pd_reserve_memory(size_t bytes) {\n@@ -2353,2 +2332,0 @@\n-  const size_t alignment_hint0 =\n-    alignment_hint ? align_up(alignment_hint, os::vm_page_size()) : 0;\n@@ -2359,1 +2336,1 @@\n-    return reserve_mmaped_memory(bytes, NULL \/* requested_addr *\/, alignment_hint);\n+    return reserve_mmaped_memory(bytes, NULL \/* requested_addr *\/);\n@@ -2362,1 +2339,1 @@\n-      return reserve_shmated_memory(bytes, NULL \/* requested_addr *\/, alignment_hint);\n+      return reserve_shmated_memory(bytes, NULL \/* requested_addr *\/);\n@@ -2364,1 +2341,1 @@\n-      return reserve_mmaped_memory(bytes, NULL \/* requested_addr *\/, alignment_hint);\n+      return reserve_mmaped_memory(bytes, NULL \/* requested_addr *\/);\n@@ -2541,1 +2518,1 @@\n-  result = reserve_mmaped_memory(bytes, requested_addr, 0);\n+  result = reserve_mmaped_memory(bytes, requested_addr);\n@@ -2562,1 +2539,1 @@\n-    return reserve_mmaped_memory(bytes, requested_addr, 0);\n+    return reserve_mmaped_memory(bytes, requested_addr);\n@@ -2565,1 +2542,1 @@\n-      return reserve_shmated_memory(bytes, requested_addr, 0);\n+      return reserve_shmated_memory(bytes, requested_addr);\n@@ -2567,1 +2544,1 @@\n-      return reserve_mmaped_memory(bytes, requested_addr, 0);\n+      return reserve_mmaped_memory(bytes, requested_addr);\n","filename":"src\/hotspot\/os\/aix\/os_aix.cpp","additions":24,"deletions":47,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -2033,2 +2033,1 @@\n-char* os::pd_reserve_memory(size_t bytes, size_t alignment_hint) {\n-  \/\/ Ignores alignment hint\n+char* os::pd_reserve_memory(size_t bytes) {\n","filename":"src\/hotspot\/os\/bsd\/os_bsd.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -3697,2 +3697,1 @@\n-char* os::pd_reserve_memory(size_t bytes, size_t alignment_hint) {\n-  \/\/ Ignores alignment hint\n+char* os::pd_reserve_memory(size_t bytes) {\n","filename":"src\/hotspot\/os\/linux\/os_linux.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -319,5 +319,6 @@\n-    \/\/ For file mapping, we do not call os:reserve_memory(extra_size, NULL, alignment, file_desc) because\n-    \/\/ we need to deal with shrinking of the file space later when we release extra memory after alignment.\n-    \/\/ We also cannot called os:reserve_memory() with file_desc set to -1 because on aix we might get SHM memory.\n-    \/\/ So here to call a helper function while reserve memory for us. After we have a aligned base,\n-    \/\/ we will replace anonymous mapping with file mapping.\n+    \/\/ For file mapping, we do not call os:reserve_memory_with_fd since:\n+    \/\/ - we later chop away parts of the mapping using os::release_memory and that could fail if the\n+    \/\/   original mmap call had been tied to an fd.\n+    \/\/ - The memory API os::reserve_memory uses is an implementation detail. It may (and usually is)\n+    \/\/   mmap but it also may System V shared memory which cannot be uncommitted as a whole, so\n+    \/\/   chopping off and unmapping excess bits back and front (see below) would not work.\n@@ -329,1 +330,1 @@\n-    extra_base = os::reserve_memory(extra_size, alignment);\n+    extra_base = os::reserve_memory(extra_size);\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -3089,1 +3089,1 @@\n-    char* extra_base = os::reserve_memory_with_fd(extra_size, alignment, file_desc);\n+    char* extra_base = os::reserve_memory_with_fd(extra_size, file_desc);\n@@ -3109,2 +3109,1 @@\n-char* os::pd_reserve_memory(size_t bytes, size_t alignment_hint) {\n-  \/\/ Ignores alignment hint\n+char* os::pd_reserve_memory(size_t bytes) {\n","filename":"src\/hotspot\/os\/windows\/os_windows.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -45,2 +45,1 @@\n-  const size_t alignment = (size_t)os::vm_allocation_granularity();\n-  const uintptr_t addr = (uintptr_t)os::reserve_memory(size, alignment, mtGC);\n+  const uintptr_t addr = (uintptr_t)os::reserve_memory(size, mtGC);\n","filename":"src\/hotspot\/share\/gc\/z\/zMarkStackAllocator.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -58,1 +58,0 @@\n-  int alignment = os::vm_allocation_granularity();\n@@ -60,1 +59,1 @@\n-  char* addr = os::reserve_memory(size, alignment, flags);\n+  char* addr = os::reserve_memory(size, flags);\n@@ -76,1 +75,0 @@\n-  int alignment = os::vm_allocation_granularity();\n@@ -78,1 +76,1 @@\n-  char* addr = os::reserve_memory(size, alignment, flags);\n+  char* addr = os::reserve_memory(size, flags);\n","filename":"src\/hotspot\/share\/memory\/allocation.inline.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -182,1 +182,1 @@\n-    \/\/ Optimistically assume that the OSes returns an aligned base pointer.\n+    \/\/ Optimistically assume that the OS returns an aligned base pointer.\n@@ -197,1 +197,1 @@\n-      base = os::reserve_memory_with_fd(size, alignment, _fd_for_heap);\n+      base = os::reserve_memory_with_fd(size, _fd_for_heap);\n@@ -374,8 +374,0 @@\n-    \/\/ Optimistically assume that the OSes returns an aligned base pointer.\n-    \/\/ When reserving a large address range, most OSes seem to align to at\n-    \/\/ least 64K.\n-\n-    \/\/ If the memory was requested at a particular address, use\n-    \/\/ os::attempt_reserve_memory_at() to avoid over mapping something\n-    \/\/ important.  If available space is not detected, return NULL.\n-\n@@ -385,1 +377,5 @@\n-      base = os::reserve_memory_with_fd(size, alignment, _fd_for_heap);\n+      \/\/ Optimistically assume that the OSes returns an aligned base pointer.\n+      \/\/ When reserving a large address range, most OSes seem to align to at\n+      \/\/ least 64K.\n+      \/\/ If the returned memory is not aligned we will release and retry.\n+      base = os::reserve_memory_with_fd(size, _fd_for_heap);\n","filename":"src\/hotspot\/share\/memory\/virtualspace.cpp","additions":7,"deletions":11,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1655,2 +1655,2 @@\n-char* os::reserve_memory(size_t bytes, size_t alignment_hint, MEMFLAGS flags) {\n-  char* result = pd_reserve_memory(bytes, alignment_hint);\n+char* os::reserve_memory(size_t bytes, MEMFLAGS flags) {\n+  char* result = pd_reserve_memory(bytes);\n@@ -1667,1 +1667,1 @@\n-char* os::reserve_memory_with_fd(size_t bytes, size_t alignment_hint, int file_desc) {\n+char* os::reserve_memory_with_fd(size_t bytes, int file_desc) {\n@@ -1678,1 +1678,1 @@\n-    result = pd_reserve_memory(bytes, alignment_hint);\n+    result = pd_reserve_memory(bytes);\n","filename":"src\/hotspot\/share\/runtime\/os.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -116,1 +116,1 @@\n-  static char*  pd_reserve_memory(size_t bytes, size_t alignment_hint);\n+  static char*  pd_reserve_memory(size_t bytes);\n@@ -317,1 +317,1 @@\n-  static char*  reserve_memory(size_t bytes, size_t alignment_hint = 0, MEMFLAGS flags = mtOther);\n+  static char*  reserve_memory(size_t bytes, MEMFLAGS flags = mtOther);\n@@ -321,1 +321,1 @@\n-  static char*  reserve_memory_with_fd(size_t bytes, size_t alignment_hint, int file_desc);\n+  static char*  reserve_memory_with_fd(size_t bytes, int file_desc);\n","filename":"src\/hotspot\/share\/runtime\/os.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -50,1 +50,1 @@\n-    char* polling_page = os::reserve_memory(allocation_size, page_size);\n+    char* polling_page = os::reserve_memory(allocation_size);\n","filename":"src\/hotspot\/share\/runtime\/safepointMechanism.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -104,1 +104,1 @@\n-    char* base = os::reserve_memory(size, page_sz, mtThreadStack);\n+    char* base = os::reserve_memory(size, mtThreadStack);\n@@ -172,1 +172,1 @@\n-    char* base = os::reserve_memory(size, page_sz, mtTest);\n+    char* base = os::reserve_memory(size, mtTest);\n","filename":"test\/hotspot\/gtest\/runtime\/test_committed_virtualmemory.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}