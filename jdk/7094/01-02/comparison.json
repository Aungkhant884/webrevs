{"files":[{"patch":"@@ -6467,0 +6467,15 @@\n+void Assembler::vroundps(XMMRegister dst, XMMRegister src, int32_t rmode, int vector_len) {\n+  assert(VM_Version::supports_avx(), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  emit_int24(0x08, (0xC0 | encode), (rmode));\n+}\n+\n+void Assembler::vrndscaleps(XMMRegister dst,  XMMRegister src,  int32_t rmode, int vector_len) {\n+  assert(VM_Version::supports_evex(), \"requires EVEX support\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_3A, &attributes);\n+  emit_int24(0x08, (0xC0 | encode), (rmode));\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -2252,0 +2252,4 @@\n+  \/\/ Round Packed Single precision value.\n+  void vroundps(XMMRegister dst, XMMRegister src, int32_t rmode, int vector_len);\n+  void vrndscaleps(XMMRegister dst,  XMMRegister src,  int32_t rmode, int vector_len);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4016,13 +4016,4 @@\n-\/*\n- * Algorithm for vector D2L and F2I conversions:-\n- * a) Perform vector D2L\/F2I cast.\n- * b) Choose fast path if none of the result vector lane contains 0x80000000 value.\n- *    It signifies that source value could be any of the special floating point\n- *    values(NaN,-Inf,Inf,Max,-Min).\n- * c) Set destination to zero if source is NaN value.\n- * d) Replace 0x80000000 with MaxInt if source lane contains a +ve value.\n- *\/\n-\n-void C2_MacroAssembler::vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n-                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n-                                            Register scratch, int vec_enc, bool roundD) {\n+void C2_MacroAssembler::vector_cast_float_special_cases_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                            XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                                            Register scratch, AddressLiteral float_sign_flip,\n+                                                            int vec_enc) {\n@@ -4030,31 +4021,0 @@\n-  if (roundD) {\n-    evcvtpd2qq(dst, src, vec_enc);\n-  } else {\n-    evcvttpd2qq(dst, src, vec_enc);\n-  }\n-  evmovdqul(xtmp1, k0, double_sign_flip, false, vec_enc, scratch);\n-  evpcmpeqq(ktmp1, xtmp1, dst, vec_enc);\n-  kortestwl(ktmp1, ktmp1);\n-  jccb(Assembler::equal, done);\n-\n-  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n-  evcmppd(ktmp2, k0, src, src, Assembler::UNORD_Q, vec_enc);\n-  evmovdquq(dst, ktmp2, xtmp2, true, vec_enc);\n-\n-  kxorwl(ktmp1, ktmp1, ktmp2);\n-  evcmppd(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_UQ, vec_enc);\n-  vpternlogq(xtmp2, 0x11, xtmp1, xtmp1, vec_enc);\n-  evmovdquq(dst, ktmp1, xtmp2, true, vec_enc);\n-  bind(done);\n-}\n-\n-void C2_MacroAssembler::vector_castF2I_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n-                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n-                                           AddressLiteral float_sign_flip, Register scratch, int vec_enc,\n-                                           bool roundF) {\n-  Label done;\n-  if (roundF) {\n-    vcvtps2dq(dst, src, vec_enc);\n-  } else {\n-    vcvttps2dq(dst, src, vec_enc);\n-  }\n@@ -4085,3 +4045,4 @@\n-void C2_MacroAssembler::vector_castF2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n-                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral float_sign_flip,\n-                                            Register scratch, int vec_enc, bool roundF) {\n+void C2_MacroAssembler::vector_cast_float_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                             XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                             Register scratch, AddressLiteral float_sign_flip,\n+                                                             int vec_enc) {\n@@ -4089,5 +4050,0 @@\n-  if (roundF) {\n-    vcvtps2dq(dst, src, vec_enc);\n-  } else {\n-    vcvttps2dq(dst, src, vec_enc);\n-  }\n@@ -4110,0 +4066,176 @@\n+void C2_MacroAssembler::vector_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                              XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                              Register scratch, AddressLiteral double_sign_flip,\n+                                                              int vec_enc) {\n+  Label done;\n+  evmovdqul(xtmp1, k0, double_sign_flip, false, vec_enc, scratch);\n+  evpcmpeqq(ktmp1, xtmp1, dst, vec_enc);\n+  kortestwl(ktmp1, ktmp1);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  evcmppd(ktmp2, k0, src, src, Assembler::UNORD_Q, vec_enc);\n+  evmovdquq(dst, ktmp2, xtmp2, true, vec_enc);\n+\n+  kxorwl(ktmp1, ktmp1, ktmp2);\n+  evcmppd(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_UQ, vec_enc);\n+  vpternlogq(xtmp2, 0x11, xtmp1, xtmp1, vec_enc);\n+  evmovdquq(dst, ktmp1, xtmp2, true, vec_enc);\n+  bind(done);\n+}\n+\n+\/*\n+ * Algorithm for vector D2L and F2I conversions:-\n+ * a) Perform vector D2L\/F2I cast.\n+ * b) Choose fast path if none of the result vector lane contains 0x80000000 value.\n+ *    It signifies that source value could be any of the special floating point\n+ *    values(NaN,-Inf,Inf,Max,-Min).\n+ * c) Set destination to zero if source is NaN value.\n+ * d) Replace 0x80000000 with MaxInt if source lane contains a +ve value.\n+ *\/\n+\n+void C2_MacroAssembler::vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  evcvttpd2qq(dst, src, vec_enc);\n+  vector_cast_double_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, double_sign_flip, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_castF2I_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                           AddressLiteral float_sign_flip, Register scratch, int vec_enc) {\n+  vcvttps2dq(dst, src, vec_enc);\n+  vector_cast_float_special_cases_avx(dst, src, xtmp1, xtmp2, xtmp3, xtmp4, scratch, float_sign_flip, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_castF2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral float_sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  vcvttps2dq(dst, src, vec_enc);\n+  vector_cast_float_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, float_sign_flip, vec_enc);\n+}\n+\n+#ifdef _LP64\n+void C2_MacroAssembler::vector_round_double_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                                 XMMRegister xtmp3, KRegister ktmp1, KRegister ktmp2, KRegister ktmp3,\n+                                                 AddressLiteral double_sign_flip, Register scratch, int vec_enc) {\n+  \/\/ Following assembly snippet is vectorized translation of Math.round(double) algorithm\n+  \/\/ for AVX512 target.\n+  evmovdquq(xtmp1, k0, src, true, vec_enc);\n+  movptr(scratch, 0x7ff0000000000000L);\n+  evpbroadcastq(xtmp2, scratch, vec_enc);\n+  evpandq(xtmp2, k0, xtmp2, xtmp1, true, vec_enc);\n+  Assembler::evpsraq(xtmp2, k0, xtmp2, 0x34, true, vec_enc);\n+  mov64(scratch, 0x432);\n+  evpbroadcastq(dst, scratch, vec_enc);\n+  vpsubq(dst, dst, xtmp2, vec_enc);\n+  evmovdquq(xtmp3, k0, dst, true, vec_enc);\n+  mov64(scratch, 0xffffffffffffffc0L);\n+  evpbroadcastq(xtmp2, scratch, vec_enc);\n+  evpandq(xtmp2, k0, dst, xtmp2, true, vec_enc);\n+  vpxor(dst, dst, dst, vec_enc);\n+  Assembler::evpcmpeqq(ktmp1, xtmp2, dst, vec_enc);\n+  mov64(scratch, 0xfffffffffffffL);\n+  evpbroadcastq(xtmp2, scratch, vec_enc);\n+  mov64(scratch, 0x10000000000000L);\n+  evpbroadcastq(dst, scratch, vec_enc);\n+  evpternlogq(xtmp1, 0xea, k0, xtmp2, dst, true, vec_enc);\n+  vpxor(dst, dst, dst, vec_enc);\n+  evpcmpq(ktmp2, k0, src, dst, Assembler::lt, true, vec_enc);\n+  kandwl(ktmp2, ktmp2, ktmp1);\n+  evpsubq(xtmp1, ktmp2, dst, xtmp1, true, vec_enc);\n+  evpsravq(xtmp1, ktmp1, xtmp1, xtmp3, true, vec_enc);\n+  mov64(scratch, 0x1);\n+  evpbroadcastq(xtmp3, scratch, vec_enc);\n+  evpaddq(xtmp1, ktmp1, xtmp1, xtmp3, true, vec_enc);\n+  evpsravq(xtmp3, ktmp1, xtmp1, xtmp3, true, vec_enc);\n+  evcvtpd2qq(dst, src, vec_enc);\n+  vector_cast_double_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp2, ktmp3, scratch, double_sign_flip, vec_enc);\n+  evpblendmq(dst, ktmp1, dst, xtmp3, true, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_round_float_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                                XMMRegister xtmp3, KRegister ktmp1, KRegister ktmp2, KRegister ktmp3,\n+                                                AddressLiteral float_sign_flip, Register scratch, int vec_enc) {\n+  \/\/ Following assembly snippet is vectorized translation of Math.round(float) algorithm\n+  \/\/ for AVX512 target.\n+  evmovdquq(xtmp1, k0, src, true, vec_enc);\n+  movl(scratch, 0x7F800000);\n+  evpbroadcastd(xtmp2, scratch, vec_enc);\n+  evpandd(xtmp2, k0, xtmp2, xtmp1, true, vec_enc);\n+  Assembler::evpsrad(xtmp2, k0, xtmp2, 0x17, true, vec_enc);\n+  movl(scratch, 0x95);\n+  evpbroadcastd(dst, scratch, vec_enc);\n+  vpsubd(dst, dst, xtmp2, vec_enc);\n+  evmovdquq(xtmp3, k0, dst, true, vec_enc);\n+  movl(scratch, 0XFFFFFFE0);\n+  evpbroadcastd(xtmp2, scratch, vec_enc);\n+  evpandd(xtmp2, k0, dst, xtmp2, true, vec_enc);\n+  vpxor(dst, dst, dst, vec_enc);\n+  Assembler::evpcmpeqd(ktmp1, k0, xtmp2, dst, vec_enc);\n+  movl(scratch, 0X007FFFFF);\n+  evpbroadcastd(xtmp2, scratch, vec_enc);\n+  movl(scratch, 0X00800000);\n+  evpbroadcastd(dst, scratch, vec_enc);\n+  evpternlogd(xtmp1, 0xea, k0, xtmp2, dst, true, vec_enc);\n+  vpxor(dst, dst, dst, vec_enc);\n+  evpcmpd(ktmp2, k0, src, dst, Assembler::lt, true, vec_enc);\n+  kandwl(ktmp2, ktmp2, ktmp1);\n+  evpsubd(xtmp1, ktmp2, dst, xtmp1, true, vec_enc);\n+  evpsravd(xtmp1, ktmp1, xtmp1, xtmp3, true, vec_enc);\n+  movl(scratch, 0x1);\n+  evpbroadcastd(xtmp3, scratch, vec_enc);\n+  evpaddd(xtmp1, ktmp1, xtmp1, xtmp3, true, vec_enc);\n+  evpsravd(xtmp3, ktmp1, xtmp1, xtmp3, true, vec_enc);\n+  vcvtps2dq(dst, src, vec_enc);\n+  vector_cast_float_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp2, ktmp3, scratch, float_sign_flip, vec_enc);\n+  evpblendmd(dst, ktmp1, dst, xtmp3, true, vec_enc);\n+}\n+\n+void C2_MacroAssembler::vector_round_float_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                               XMMRegister xtmp3, XMMRegister xtmp4, XMMRegister xtmp5, XMMRegister xtmp6,\n+                                               AddressLiteral float_sign_flip, Register scratch, int vec_enc) {\n+  \/\/ Following assembly snippet is vectorized translation of Math.round(float) algorithm\n+  \/\/ for AVX2 target.\n+  vmovdqu(xtmp1, src);\n+  movl(scratch, 0x7F800000);\n+  movdl(xtmp2, scratch);\n+  vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+  vpand(xtmp2, xtmp2, xtmp1, vec_enc);\n+  Assembler::vpsrad(xtmp2, xtmp2, 0x17, vec_enc);\n+  movl(scratch, 0x95);\n+  movdl(dst, scratch);\n+  vpbroadcastd(dst, dst, vec_enc);\n+  vpsubd(dst, dst, xtmp2, vec_enc);\n+  vmovdqu(xtmp3, dst);\n+  movl(scratch, 0xFFFFFFE0);\n+  movdl(xtmp2, scratch);\n+  vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+  vpand(xtmp2, dst, xtmp2, vec_enc);\n+  vpxor(dst, dst, dst, vec_enc);\n+  Assembler::vpcmpeqd(xtmp5, xtmp2, dst, vec_enc);\n+  movl(scratch, 0x007FFFFF);\n+  movdl(xtmp2, scratch);\n+  vpbroadcastd(xtmp2, xtmp2, vec_enc);\n+  movl(scratch, 0x00800000);\n+  movdl(dst, scratch);\n+  vpbroadcastd(dst, dst, vec_enc);\n+  vpand(xtmp1, xtmp2, xtmp1, vec_enc);\n+  vpor(xtmp1, xtmp1, dst, vec_enc);\n+  vpxor(dst, dst, dst, vec_enc);\n+  vpcmpCCW(xtmp4, src, dst, xtmp2, Assembler::lt, Assembler::D, vec_enc);\n+  vpand(xtmp4, xtmp4, xtmp5, vec_enc);\n+  vpsubd(dst, dst, xtmp1, vec_enc);\n+  vblendvps(xtmp1, xtmp1, dst, xtmp4, vec_enc);\n+  vpsravd(xtmp1, xtmp1, xtmp3, vec_enc);\n+  movl(scratch, 0x1);\n+  movdl(xtmp4, scratch);\n+  vpbroadcastd(xtmp4, xtmp4, vec_enc);\n+  vpaddd(xtmp1, xtmp1, xtmp4, vec_enc);\n+  Assembler::vpsrad(xtmp3, xtmp1, 0x1, vec_enc);\n+  vcvtps2dq(dst, src, vec_enc);\n+  vector_cast_float_special_cases_avx(dst, src, xtmp1, xtmp2, xtmp6, xtmp4, scratch, float_sign_flip, vec_enc);\n+  vblendvps(dst, dst, xtmp3, xtmp5, vec_enc);\n+}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":184,"deletions":52,"binary":false,"changes":236,"status":"modified"},{"patch":"@@ -301,1 +301,1 @@\n-                          AddressLiteral float_sign_flip, Register scratch, int vec_enc, bool roundF);\n+                          AddressLiteral float_sign_flip, Register scratch, int vec_enc);\n@@ -305,1 +305,2 @@\n-                           Register scratch, int vec_enc, bool roundF);\n+                           Register scratch, int vec_enc);\n+\n@@ -309,1 +310,29 @@\n-                           Register scratch, int vec_enc, bool roundD);\n+                           Register scratch, int vec_enc);\n+\n+  void vector_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                             KRegister ktmp1, KRegister ktmp2, Register scratch, AddressLiteral double_sign_flip,\n+                                             int vec_enc);\n+\n+  void vector_cast_float_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, Register scratch, AddressLiteral float_sign_flip,\n+                                            int vec_enc);\n+\n+  void vector_cast_float_special_cases_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                           Register scratch, AddressLiteral float_sign_flip,\n+                                           int vec_enc);\n+\n+#ifdef _LP64\n+  void vector_round_double_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                XMMRegister xtmp3, KRegister ktmp1, KRegister ktmp2, KRegister ktmp3,\n+                                AddressLiteral double_sign_flip, Register scratch, int vec_enc);\n+\n+\n+  void vector_round_float_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                               XMMRegister xtmp3, KRegister ktmp1, KRegister ktmp2, KRegister ktmp3,\n+                               AddressLiteral float_sign_flip, Register scratch, int vec_enc);\n+\n+  void vector_round_float_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                              XMMRegister xtmp3, XMMRegister xtmp4, XMMRegister xtmp5, XMMRegister xtmp6,\n+                              AddressLiteral float_sign_flip, Register scratch, int vec_enc);\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":32,"deletions":3,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -8915,1 +8915,1 @@\n-void MacroAssembler::convert_f2i(Register dst, XMMRegister src, bool roundF) {\n+void MacroAssembler::convert_f2i(Register dst, XMMRegister src) {\n@@ -8917,5 +8917,2 @@\n-  if (roundF) {\n-    cvtss2sil(dst, src);\n-  } else {\n-    cvttss2sil(dst, src);\n-  }\n+  cvttss2sil(dst, src);\n+\n@@ -8957,1 +8954,63 @@\n-void MacroAssembler::convert_d2l(Register dst, XMMRegister src, bool roundD) {\n+void MacroAssembler::round_float(Register dst, XMMRegister src, Register rtmp, Register rcx) {\n+  \/\/ Following code is exactly mimicking the functionality of java.lang.Math.round(float) method.\n+  Label L_special_case, L_block1, L_exit;\n+  movl(rtmp, 0x7F800000);\n+  movdl(dst, src);\n+  andl(dst, rtmp);\n+  sarl(dst, 0x17);\n+  movl(rtmp, 0x95);\n+  subl(rtmp, dst);\n+  movl(rcx, rtmp);\n+  movl(dst, 0xffffffe0);\n+  testl(rtmp, dst);\n+  jccb(Assembler::notEqual, L_special_case);\n+  movdl(dst, src);\n+  andl(dst, 0x7fffff);\n+  orl(dst, 0x800000);\n+  movdl(rtmp, src);\n+  testl(rtmp, rtmp);\n+  jccb(Assembler::greaterEqual, L_block1);\n+  negl(dst);\n+  bind(L_block1);\n+  sarl(dst);\n+  addl(dst, 0x1);\n+  sarl(dst, 0x1);\n+  jmp(L_exit);\n+  bind(L_special_case);\n+  convert_f2i(dst, src);\n+  bind(L_exit);\n+}\n+\n+void MacroAssembler::round_double(Register dst, XMMRegister src, Register rtmp, Register rcx) {\n+  \/\/ Following code is exactly mimicking the functionality of java.lang.Math.round(double) method.\n+  Label L_special_case, L_block1, L_exit;\n+  mov64(rtmp, 0x7ff0000000000000L);\n+  movq(dst, src);\n+  andq(dst, rtmp);\n+  sarq(dst, 0x34);\n+  mov64(rtmp, 0x432);\n+  subq(rtmp, dst);\n+  movq(rcx, rtmp);\n+  mov64(dst, 0xffffffffffffffc0L);\n+  testq(rtmp, dst);\n+  jccb(Assembler::notEqual, L_special_case);\n+  movq(dst, src);\n+  mov64(rtmp, 0xfffffffffffffL);\n+  andq(dst, rtmp);\n+  mov64(rtmp, 0x10000000000000L);\n+  orq(dst, rtmp);\n+  movq(rtmp, src);\n+  testq(rtmp, rtmp);\n+  jccb(Assembler::greaterEqual, L_block1);\n+  negq(dst);\n+  bind(L_block1);\n+  sarq(dst);\n+  addq(dst, 0x1);\n+  sarq(dst, 0x1);\n+  jmp(L_exit);\n+  bind(L_special_case);\n+  convert_d2l(dst, src);\n+  bind(L_exit);\n+}\n+\n+void MacroAssembler::convert_d2l(Register dst, XMMRegister src) {\n@@ -8959,5 +9018,2 @@\n-  if (roundD) {\n-    cvtsd2siq(dst, src);\n-  } else {\n-    cvttsd2siq(dst, src);\n-  }\n+  cvttsd2siq(dst, src);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":68,"deletions":12,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -1967,1 +1967,1 @@\n-  void convert_f2i(Register dst, XMMRegister src, bool roundF = false);\n+  void convert_f2i(Register dst, XMMRegister src);\n@@ -1970,1 +1970,4 @@\n-  void convert_d2l(Register dst, XMMRegister src, bool roundD = false);\n+  void convert_d2l(Register dst, XMMRegister src);\n+  void round_double(Register dst, XMMRegister src, Register rtmp, Register rcx);\n+  void round_float(Register dst, XMMRegister src, Register rtmp, Register rcx);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":5,"deletions":2,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1455,0 +1455,3 @@\n+      if (UseAVX < 2) { \/\/ enabled for AVX2 only\n+        return false;\n+      }\n@@ -7171,1 +7174,1 @@\n-instruct vround_or_castFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rRegP scratch, rFlagsReg cr) %{\n+instruct castFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rRegP scratch, rFlagsReg cr) %{\n@@ -7176,1 +7179,0 @@\n-  match(Set dst (RoundVF src));\n@@ -7178,1 +7180,1 @@\n-  format %{ \"vector_round_or_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3 and $xtmp4 as TEMP\" %}\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4 and $scratch as TEMP\" %}\n@@ -7180,1 +7182,0 @@\n-    bool is_rounding = this->ideal_Opcode() == Op_RoundVF ? true : false;\n@@ -7184,1 +7185,1 @@\n-                          ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc, is_rounding);\n+                          ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n@@ -7189,1 +7190,1 @@\n-instruct vround_or_castFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+instruct castFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n@@ -7194,1 +7195,0 @@\n-  match(Set dst (RoundVF src));\n@@ -7196,1 +7196,1 @@\n-  format %{ \"vector_round_or_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1 and $ktmp2 as TEMP\" %}\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n@@ -7198,1 +7198,0 @@\n-    bool is_rounding = this->ideal_Opcode() == Op_RoundVF ? true : false;\n@@ -7202,1 +7201,1 @@\n-                           ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc, is_rounding);\n+                           ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n@@ -7218,1 +7217,1 @@\n-instruct vround_or_castDtoL_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n+instruct castDtoL_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n@@ -7221,1 +7220,0 @@\n-  match(Set dst (RoundVD src));\n@@ -7223,1 +7221,1 @@\n-  format %{ \"vector_round_or_cast_d2l $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1 and $ktmp2 as TEMP\" %}\n+  format %{ \"vector_cast_d2l $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n@@ -7225,1 +7223,0 @@\n-    bool is_rounding = this->ideal_Opcode() == Op_RoundVD ? true : false;\n@@ -7229,1 +7226,18 @@\n-                           ExternalAddress(vector_double_signflip()), $scratch$$Register, vlen_enc, is_rounding);\n+                           ExternalAddress(vector_double_signflip()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+#ifdef _LP64\n+instruct vround_float_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, vec xtmp5, vec xtmp6, rRegP scratch, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512vl() &&\n+            Matcher::vector_length_in_bytes(n) < 64 &&\n+            Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (RoundVF src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, TEMP xtmp5, TEMP xtmp6, TEMP scratch, KILL cr);\n+  format %{ \"vector_round_float $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4, $xtmp5 ,$xtmp6 and $scratch as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_round_float_avx($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,\n+                              $xtmp3$$XMMRegister, $xtmp4$$XMMRegister, $xtmp5$$XMMRegister, $xtmp6$$XMMRegister,\n+                              ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n@@ -7234,0 +7248,30 @@\n+instruct vround_float_evex(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, kReg ktmp1, kReg ktmp2, kReg ktmp3,  rRegP scratch, rFlagsReg cr) %{\n+  predicate((VM_Version::supports_avx512vl() ||\n+             Matcher::vector_length_in_bytes(n) == 64) &&\n+             Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (RoundVF src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP ktmp1, TEMP ktmp2, TEMP ktmp3, TEMP scratch, KILL cr);\n+  format %{ \"vector_round_float $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $ktmp1, $ktmp2, $ktmp3 and $scratch as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_round_float_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,\n+                               $xtmp3$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister, $ktmp3$$KRegister,\n+                               ExternalAddress(vector_float_signflip()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vround_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, kReg ktmp1, kReg ktmp2, kReg ktmp3, rRegP scratch, rFlagsReg cr) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (RoundVD src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP ktmp1, TEMP ktmp2, TEMP ktmp3, TEMP scratch, KILL cr);\n+  format %{ \"vector_round_long $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $ktmp1, $ktmp2, $ktmp3 and $scratch as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_round_double_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,                                                                         $xtmp3$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister, $ktmp3$$KRegister,\n+                                ExternalAddress(vector_double_signflip()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+#endif\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":59,"deletions":15,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -10662,1 +10662,1 @@\n-instruct round_or_convF2I_reg_reg(rRegI dst, regF src, rFlagsReg cr)\n+instruct convF2I_reg_reg(rRegI dst, regF src, rFlagsReg cr)\n@@ -10665,1 +10665,0 @@\n-  match(Set dst (RoundF src));\n@@ -10669,2 +10668,1 @@\n-  bool is_rounding = this->ideal_Opcode() == Op_RoundF ? true : false;\n-    __ convert_f2i($dst$$Register, $src$$XMMRegister, is_rounding);\n+    __ convert_f2i($dst$$Register, $src$$XMMRegister);\n@@ -10697,1 +10695,1 @@\n-instruct round_or_convD2L_reg_reg(rRegL dst, regD src, rFlagsReg cr)\n+instruct convD2L_reg_reg(rRegL dst, regD src, rFlagsReg cr)\n@@ -10700,1 +10698,0 @@\n-  match(Set dst (RoundD src));\n@@ -10704,2 +10701,23 @@\n-  bool is_rounding = this->ideal_Opcode() == Op_RoundD ? true : false;\n-    __ convert_d2l($dst$$Register, $src$$XMMRegister, is_rounding);\n+    __ convert_d2l($dst$$Register, $src$$XMMRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct round_double_reg(rRegL dst, regD src, rRegL rtmp, rcx_RegL rcx, rFlagsReg cr)\n+%{\n+  match(Set dst (RoundD src));\n+  effect(TEMP dst, TEMP rtmp, TEMP rcx, KILL cr);\n+  format %{ \"round_double $dst,$src \\t! using $rtmp and $rcx as TEMP\"%}\n+  ins_encode %{\n+    __ round_double($dst$$Register, $src$$XMMRegister, $rtmp$$Register, $rcx$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct round_float_reg(rRegI dst, regF src, rRegL rtmp, rcx_RegL rcx, rFlagsReg cr)\n+%{\n+  match(Set dst (RoundF src));\n+  effect(TEMP dst, TEMP rtmp, TEMP rcx, KILL cr);\n+  format %{ \"round_float $dst,$src\" %}\n+  ins_encode %{\n+    __ round_float($dst$$Register, $src$$XMMRegister, $rtmp$$Register, $rcx$$Register);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":26,"deletions":8,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -971,0 +971,2 @@\n+      case Op_RoundVF: body_size += 100; break;\n+      case Op_RoundVD: body_size += 100; break;\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -362,10 +362,0 @@\n-      test_round(l0, a1);\n-      errn += verify(\"test_round: \", 0, l0[0], 0L);\n-      errn += verify(\"test_round: \", 1, l0[1], Long.MAX_VALUE);\n-      errn += verify(\"test_round: \", 2, l0[2], Long.MIN_VALUE);\n-      errn += verify(\"test_round: \", 3, l0[3], Long.MAX_VALUE);\n-      errn += verify(\"test_round: \", 4, l0[4], 0L);\n-      errn += verify(\"test_round: \", 5, l0[5], 0L);\n-      for (int i=6; i<ARRLEN; i++) {\n-        errn += verify(\"test_round: \", i, l0[i], Math.round((double)(ADD_INIT+i)));\n-      }\n@@ -439,0 +429,25 @@\n+\n+      a1[6] = +0x1.fffffffffffffp-2;\n+      a1[7] = +0x1.0p-1;\n+      a1[8] = +0x1.0000000000001p-1;\n+      a1[9] = -0x1.fffffffffffffp-2;\n+      a1[10] = -0x1.0p-1;\n+      a1[11] = -0x1.0000000000001p-1;\n+\n+      test_round(l0, a1);\n+      errn += verify(\"test_round: \", 0, l0[0], 0L);\n+      errn += verify(\"test_round: \", 1, l0[1], Long.MAX_VALUE);\n+      errn += verify(\"test_round: \", 2, l0[2], Long.MIN_VALUE);\n+      errn += verify(\"test_round: \", 3, l0[3], Long.MAX_VALUE);\n+      errn += verify(\"test_round: \", 4, l0[4], 0L);\n+      errn += verify(\"test_round: \", 5, l0[5], 0L);\n+\n+      errn += verify(\"test_round: \", 6, l0[6], 0L);\n+      errn += verify(\"test_round: \", 7, l0[7], 1L);\n+      errn += verify(\"test_round: \", 8, l0[8], 1L);\n+      errn += verify(\"test_round: \", 9, l0[9], 0L);\n+      errn += verify(\"test_round: \", 10, l0[10], 0L);\n+      errn += verify(\"test_round: \", 11, l0[11], -1L);\n+      for (int i=12; i<ARRLEN; i++) {\n+        errn += verify(\"test_round: \", i, l0[i], Math.round((double)(ADD_INIT+i)));\n+      }\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/cr6340864\/TestDoubleVect.java","additions":25,"deletions":10,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2012, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2012, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -360,11 +360,0 @@\n-      test_round(i0, a1);\n-      errn += verify(\"test_round: \", 0, i0[0], 0);\n-      errn += verify(\"test_round: \", 1, i0[1], Integer.MAX_VALUE);\n-      errn += verify(\"test_round: \", 2, i0[2], Integer.MIN_VALUE);\n-      errn += verify(\"test_round: \", 3, i0[3], Integer.MAX_VALUE);\n-      errn += verify(\"test_round: \", 4, i0[4], 0);\n-      errn += verify(\"test_round: \", 5, i0[5], 0);\n-      for (int i=6; i<ARRLEN; i++) {\n-        errn += verify(\"test_round: \", i, i0[i], Math.round(((float)(ADD_INIT+i))));\n-      }\n-\n@@ -387,0 +376,25 @@\n+      a1[6] = +0x1.fffffep-2f;\n+      a1[7] = +0x1.0p-1f;\n+      a1[8] = +0x1.000002p-1f;\n+      a1[9] = -0x1.fffffep-2f;\n+      a1[10] = -0x1.0p-1f;\n+      a1[11] = -0x1.000002p-1f;\n+\n+      test_round(i0, a1);\n+      errn += verify(\"test_round: \", 0, i0[0], 0);\n+      errn += verify(\"test_round: \", 1, i0[1], Integer.MAX_VALUE);\n+      errn += verify(\"test_round: \", 2, i0[2], Integer.MIN_VALUE);\n+      errn += verify(\"test_round: \", 3, i0[3], Integer.MAX_VALUE);\n+      errn += verify(\"test_round: \", 4, i0[4], 0);\n+      errn += verify(\"test_round: \", 5, i0[5], 0);\n+      errn += verify(\"test_round: \", 6, i0[6], 0);\n+      errn += verify(\"test_round: \", 7, i0[7], 1);\n+      errn += verify(\"test_round: \", 8, i0[8], 1);\n+      errn += verify(\"test_round: \", 9, i0[9], 0);\n+      errn += verify(\"test_round: \", 10, i0[10], 0);\n+      errn += verify(\"test_round: \", 11, i0[11], -1);\n+\n+      for (int i=12; i<ARRLEN; i++) {\n+        errn += verify(\"test_round: \", i, i0[i], Math.round(((float)(ADD_INIT+i))));\n+      }\n+\n","filename":"test\/hotspot\/jtreg\/compiler\/c2\/cr6340864\/TestFloatVect.java","additions":26,"deletions":12,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -78,1 +78,1 @@\n-  @IR(applyIf = {\"UseAVX\", \" > 0\"}, counts = {\"RoundVF\" , \" > 0 \"})\n+  @IR(applyIf = {\"UseAVX\", \" > 1\"}, counts = {\"RoundVF\" , \" > 0 \"})\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestRoundVect.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -32,0 +32,5 @@\n+        for (int i = 0; i < 100000; i++) {\n+            failures += testNearFloatHalfCases();\n+            failures += testNearDoubleHalfCases();\n+            failures += testUnityULPCases();\n+            failures += testSpecialCases();\n@@ -33,9 +38,5 @@\n-        failures += testNearFloatHalfCases();\n-        failures += testNearDoubleHalfCases();\n-        failures += testUnityULPCases();\n-        failures += testSpecialCases();\n-\n-        if (failures > 0) {\n-            System.err.println(\"Testing {Math, StrictMath}.round incurred \"\n-                               + failures + \" failures.\");\n-            throw new RuntimeException();\n+            if (failures > 0) {\n+                System.err.println(\"Testing {Math, StrictMath}.round incurred \"\n+                                   + failures + \" failures.\");\n+                throw new RuntimeException();\n+            }\n","filename":"test\/jdk\/java\/lang\/Math\/RoundTests.java","additions":10,"deletions":9,"binary":false,"changes":19,"status":"modified"}]}