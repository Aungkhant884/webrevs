{"files":[{"patch":"@@ -236,0 +236,4 @@\n+ParallelObjectIterator* ZCollectedHeap::parallel_object_iterator(uint nworkers) {\n+  return _heap.parallel_object_iterator(nworkers, true \/* visit_weaks *\/);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zCollectedHeap.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -95,0 +95,1 @@\n+  virtual ParallelObjectIterator* parallel_object_iterator(uint nworkers);\n","filename":"src\/hotspot\/share\/gc\/z\/zCollectedHeap.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -50,0 +50,3 @@\n+\n+  T get_acquire(uintptr_t offset) const;\n+  void release_put(uintptr_t offset, T value);\n","filename":"src\/hotspot\/share\/gc\/z\/zGranuleMap.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"runtime\/atomic.hpp\"\n@@ -49,1 +50,0 @@\n-\n@@ -76,0 +76,12 @@\n+template <typename T>\n+inline T ZGranuleMap<T>::get_acquire(uintptr_t offset) const {\n+  const size_t index = index_for_offset(offset);\n+  return Atomic::load_acquire(_map + index);\n+}\n+\n+template <typename T>\n+inline void ZGranuleMap<T>::release_put(uintptr_t offset, T value) {\n+  const size_t index = index_for_offset(offset);\n+  Atomic::release_store(_map + index, value);\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zGranuleMap.inline.hpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -439,0 +439,3 @@\n+  ZHeapIterator iter(1 \/* nworkers *\/, visit_weaks);\n+  iter.object_iterate(cl, 0 \/* worker_id *\/);\n+}\n@@ -440,2 +443,3 @@\n-  ZHeapIterator iter;\n-  iter.objects_do(cl, visit_weaks);\n+ParallelObjectIterator* ZHeap::parallel_object_iterator(uint nworkers, bool visit_weaks) {\n+  assert(SafepointSynchronize::is_at_safepoint(), \"Should be at safepoint\");\n+  return new ZHeapIterator(nworkers, visit_weaks);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  ParallelObjectIterator* parallel_object_iterator(uint nworkers, bool visit_weaks);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeap.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -26,1 +26,1 @@\n-#include \"classfile\/classLoaderDataGraph.hpp\"\n+#include \"gc\/shared\/taskqueue.inline.hpp\"\n@@ -28,1 +28,0 @@\n-#include \"gc\/z\/zBarrier.inline.hpp\"\n@@ -32,0 +31,1 @@\n+#include \"gc\/z\/zLock.inline.hpp\"\n@@ -33,2 +33,0 @@\n-#include \"gc\/z\/zRootsIterator.hpp\"\n-#include \"gc\/z\/zStat.hpp\"\n@@ -37,1 +35,0 @@\n-#include \"utilities\/stack.inline.hpp\"\n@@ -41,1 +38,1 @@\n-  CHeapBitMap _map;\n+  CHeapBitMap _bitmap;\n@@ -45,1 +42,1 @@\n-      _map(size_in_bits) {}\n+      _bitmap(size_in_bits, mtGC) {}\n@@ -48,2 +45,22 @@\n-    if (_map.at(index)) {\n-      return false;\n+    return _bitmap.par_set_bit(index);\n+  }\n+};\n+\n+class ZHeapIteratorContext {\n+private:\n+  ZHeapIterator* const           _iter;\n+  ZHeapIteratorQueue* const      _queue;\n+  ZHeapIteratorArrayQueue* const _array_queue;\n+  const uint                     _worker_id;\n+  ZStatTimerDisable              _timer_disable;\n+\n+public:\n+  ZHeapIteratorContext(ZHeapIterator* iter, uint worker_id) :\n+      _iter(iter),\n+      _queue(_iter->_queues.queue(worker_id)),\n+      _array_queue(_iter->_array_queues.queue(worker_id)),\n+      _worker_id(worker_id) {}\n+\n+  void mark_and_push(oop obj) const {\n+    if (_iter->mark_object(obj)) {\n+      _queue->push(obj);\n@@ -51,0 +68,13 @@\n+  }\n+\n+  void push_array(const ObjArrayTask& array) const {\n+    _array_queue->push(array);\n+  }\n+\n+  bool pop(oop& obj) const {\n+    return _queue->pop_overflow(obj) || _queue->pop_local(obj);\n+  }\n+\n+  bool pop_array(ObjArrayTask& array) const {\n+    return _array_queue->pop_overflow(array) || _array_queue->pop_local(array);\n+  }\n@@ -52,2 +82,10 @@\n-    _map.set_bit(index);\n-    return true;\n+  bool steal(oop& obj) const {\n+    return _iter->_queues.steal(_worker_id, obj);\n+  }\n+\n+  bool steal_array(ObjArrayTask& array) const {\n+    return _iter->_array_queues.steal(_worker_id, array);\n+  }\n+\n+  bool is_drained() const {\n+    return _queue->is_empty() && _array_queue->is_empty();\n@@ -60,1 +98,1 @@\n-  ZHeapIterator* const _iter;\n+  const ZHeapIteratorContext& _context;\n@@ -75,2 +113,2 @@\n-  ZHeapIteratorRootOopClosure(ZHeapIterator* iter) :\n-      _iter(iter) {}\n+  ZHeapIteratorRootOopClosure(const ZHeapIteratorContext& context) :\n+      _context(context) {}\n@@ -80,1 +118,1 @@\n-    _iter->push(obj);\n+    _context.mark_and_push(obj);\n@@ -91,2 +129,2 @@\n-  ZHeapIterator* const _iter;\n-  const oop            _base;\n+  const ZHeapIteratorContext& _context;\n+  const oop                   _base;\n@@ -103,1 +141,1 @@\n-  ZHeapIteratorOopClosure(ZHeapIterator* iter, oop base) :\n+  ZHeapIteratorOopClosure(const ZHeapIteratorContext& context, oop base) :\n@@ -105,1 +143,1 @@\n-      _iter(iter),\n+      _context(context),\n@@ -114,1 +152,1 @@\n-    _iter->push(obj);\n+    _context.mark_and_push(obj);\n@@ -128,3 +166,27 @@\n-ZHeapIterator::ZHeapIterator() :\n-    _visit_stack(),\n-    _visit_map(ZAddressOffsetMax) {}\n+ZHeapIterator::ZHeapIterator(uint nworkers, bool visit_weaks) :\n+    _visit_weaks(visit_weaks),\n+    _timer_disable(),\n+    _bitmaps(ZAddressOffsetMax),\n+    _bitmaps_lock(),\n+    _queues(nworkers),\n+    _array_queues(nworkers),\n+    _roots(),\n+    _concurrent_roots(),\n+    _weak_roots(),\n+    _concurrent_weak_roots(),\n+    _terminator(nworkers, &_queues) {\n+\n+  \/\/ Create queues\n+  for (uint i = 0; i < _queues.size(); i++) {\n+    ZHeapIteratorQueue* const queue = new ZHeapIteratorQueue();\n+    queue->initialize();\n+    _queues.register_queue(i, queue);\n+  }\n+\n+  \/\/ Create array queues\n+  for (uint i = 0; i < _array_queues.size(); i++) {\n+    ZHeapIteratorArrayQueue* const array_queue = new ZHeapIteratorArrayQueue();\n+    array_queue->initialize();\n+    _array_queues.register_queue(i, array_queue);\n+  }\n+}\n@@ -133,3 +195,14 @@\n-  ZVisitMapIterator iter(&_visit_map);\n-  for (ZHeapIteratorBitMap* map; iter.next(&map);) {\n-    delete map;\n+  \/\/ Destroy bitmaps\n+  ZHeapIteratorBitMapsIterator iter(&_bitmaps);\n+  for (ZHeapIteratorBitMap* bitmap; iter.next(&bitmap);) {\n+    delete bitmap;\n+  }\n+\n+  \/\/ Destroy array queues\n+  for (uint i = 0; i < _array_queues.size(); i++) {\n+    delete _array_queues.queue(i);\n+  }\n+\n+  \/\/ Destroy queues\n+  for (uint i = 0; i < _queues.size(); i++) {\n+    delete _queues.queue(i);\n@@ -137,1 +210,0 @@\n-  ClassLoaderDataGraph::clear_claimed_marks(ClassLoaderData::_claim_other);\n@@ -151,1 +223,1 @@\n-ZHeapIteratorBitMap* ZHeapIterator::object_map(oop obj) {\n+ZHeapIteratorBitMap* ZHeapIterator::object_bitmap(oop obj) {\n@@ -153,4 +225,9 @@\n-  ZHeapIteratorBitMap* map = _visit_map.get(offset);\n-  if (map == NULL) {\n-    map = new ZHeapIteratorBitMap(object_index_max());\n-    _visit_map.put(offset, map);\n+  ZHeapIteratorBitMap* bitmap = _bitmaps.get_acquire(offset);\n+  if (bitmap == NULL) {\n+    ZLocker<ZLock> locker(&_bitmaps_lock);\n+    bitmap = _bitmaps.get(offset);\n+    if (bitmap == NULL) {\n+      \/\/ Install new bitmap\n+      bitmap = new ZHeapIteratorBitMap(object_index_max());\n+      _bitmaps.release_put(offset, bitmap);\n+    }\n@@ -159,1 +236,1 @@\n-  return map;\n+  return bitmap;\n@@ -162,1 +239,1 @@\n-void ZHeapIterator::push(oop obj) {\n+bool ZHeapIterator::mark_object(oop obj) {\n@@ -164,2 +241,1 @@\n-    \/\/ Ignore\n-    return;\n+    return false;\n@@ -168,1 +244,1 @@\n-  ZHeapIteratorBitMap* const map = object_map(obj);\n+  ZHeapIteratorBitMap* const bitmap = object_bitmap(obj);\n@@ -170,7 +246,1 @@\n-  if (!map->try_set_bit(index)) {\n-    \/\/ Already pushed\n-    return;\n-  }\n-\n-  \/\/ Push\n-  _visit_stack.push(obj);\n+  return bitmap->try_set_bit(index);\n@@ -179,5 +249,4 @@\n-template <typename RootsIterator, bool Concurrent, bool Weak>\n-void ZHeapIterator::push_roots() {\n-  ZHeapIteratorRootOopClosure<Concurrent, Weak> cl(this);\n-  RootsIterator roots;\n-  roots.oops_do(&cl);\n+template <bool Concurrent, bool Weak, typename RootsIterator>\n+void ZHeapIterator::push_roots(const ZHeapIteratorContext& context, RootsIterator& iter) {\n+  ZHeapIteratorRootOopClosure<Concurrent, Weak> cl(context);\n+  iter.oops_do(&cl);\n@@ -187,2 +256,2 @@\n-void ZHeapIterator::push_fields(oop obj) {\n-  ZHeapIteratorOopClosure<VisitReferents> cl(this, obj);\n+void ZHeapIterator::follow_object(const ZHeapIteratorContext& context, oop obj) {\n+  ZHeapIteratorOopClosure<VisitReferents> cl(context, obj);\n@@ -192,0 +261,26 @@\n+void ZHeapIterator::follow_array(const ZHeapIteratorContext& context, oop obj) {\n+  \/\/ Follow klass\n+  ZHeapIteratorOopClosure<false \/* VisitReferents *\/> cl(context, obj);\n+  cl.do_klass(obj->klass());\n+\n+  \/\/ Push array chunk\n+  context.push_array(ObjArrayTask(obj, 0 \/* index *\/));\n+}\n+\n+void ZHeapIterator::follow_array_chunk(const ZHeapIteratorContext& context, const ObjArrayTask& array) {\n+  const objArrayOop obj = objArrayOop(array.obj());\n+  const int length = obj->length();\n+  const int start = array.index();\n+  const int stride = MIN2<int>(length - start, ObjArrayMarkingStride);\n+  const int end = start + stride;\n+\n+  \/\/ Push remaining array chunk first\n+  if (end < length) {\n+    context.push_array(ObjArrayTask(obj, end));\n+  }\n+\n+  \/\/ Follow array chunk\n+  ZHeapIteratorOopClosure<false \/* VisitReferents *\/> cl(context, obj);\n+  obj->oop_iterate_range(&cl, start, end);\n+}\n+\n@@ -193,2 +288,3 @@\n-void ZHeapIterator::objects_do(ObjectClosure* cl) {\n-  ZStatTimerDisable disable;\n+void ZHeapIterator::visit_and_follow(const ZHeapIteratorContext& context, ObjectClosure* cl, oop obj) {\n+  \/\/ Visit\n+  cl->do_object(obj);\n@@ -196,6 +292,5 @@\n-  \/\/ Push roots to visit\n-  push_roots<ZRootsIterator,                     false \/* Concurrent *\/, false \/* Weak *\/>();\n-  push_roots<ZConcurrentRootsIteratorClaimOther, true  \/* Concurrent *\/, false \/* Weak *\/>();\n-  if (VisitWeaks) {\n-    push_roots<ZWeakRootsIterator,           false \/* Concurrent *\/, true  \/* Weak *\/>();\n-    push_roots<ZConcurrentWeakRootsIterator, true  \/* Concurrent *\/, true  \/* Weak *\/>();\n+  \/\/ Follow\n+  if (obj->is_objArray()) {\n+    follow_array(context, obj);\n+  } else {\n+    follow_object<VisitWeaks>(context, obj);\n@@ -203,0 +298,1 @@\n+}\n@@ -204,3 +300,4 @@\n-  \/\/ Drain stack\n-  while (!_visit_stack.is_empty()) {\n-    const oop obj = _visit_stack.pop();\n+template <bool VisitWeaks>\n+void ZHeapIterator::drain(const ZHeapIteratorContext& context, ObjectClosure* cl) {\n+  ObjArrayTask array;\n+  oop obj;\n@@ -208,2 +305,4 @@\n-    \/\/ Visit object\n-    cl->do_object(obj);\n+  do {\n+    while (context.pop(obj)) {\n+      visit_and_follow<VisitWeaks>(context, cl, obj);\n+    }\n@@ -211,2 +310,33 @@\n-    \/\/ Push fields to visit\n-    push_fields<VisitWeaks>(obj);\n+    if (context.pop_array(array)) {\n+      follow_array_chunk(context, array);\n+    }\n+  } while (!context.is_drained());\n+}\n+\n+template <bool VisitWeaks>\n+void ZHeapIterator::steal(const ZHeapIteratorContext& context, ObjectClosure* cl) {\n+  ObjArrayTask array;\n+  oop obj;\n+\n+  if (context.steal_array(array)) {\n+    follow_array_chunk(context, array);\n+  } else if (context.steal(obj)) {\n+    visit_and_follow<VisitWeaks>(context, cl, obj);\n+  }\n+}\n+\n+template <bool VisitWeaks>\n+void ZHeapIterator::drain_and_steal(const ZHeapIteratorContext& context, ObjectClosure* cl) {\n+  do {\n+    drain<VisitWeaks>(context, cl);\n+    steal<VisitWeaks>(context, cl);\n+  } while (!context.is_drained() || !_terminator.offer_termination());\n+}\n+\n+template <bool VisitWeaks>\n+void ZHeapIterator::object_iterate_inner(const ZHeapIteratorContext& context, ObjectClosure* cl) {\n+  push_roots<false \/* Concurrent *\/, false \/* Weak *\/>(context, _roots);\n+  push_roots<true  \/* Concurrent *\/, false \/* Weak *\/>(context, _concurrent_roots);\n+  if (VisitWeaks) {\n+    push_roots<false \/* Concurrent *\/, true  \/* Weak *\/>(context, _weak_roots);\n+    push_roots<true  \/* Concurrent *\/, true  \/* Weak *\/>(context, _concurrent_weak_roots);\n@@ -214,0 +344,2 @@\n+\n+  drain_and_steal<VisitWeaks>(context, cl);\n@@ -216,3 +348,5 @@\n-void ZHeapIterator::objects_do(ObjectClosure* cl, bool visit_weaks) {\n-  if (visit_weaks) {\n-    objects_do<true \/* VisitWeaks *\/>(cl);\n+void ZHeapIterator::object_iterate(ObjectClosure* cl, uint worker_id) {\n+  ZHeapIteratorContext context(this, worker_id);\n+\n+  if (_visit_weaks) {\n+    object_iterate_inner<true \/* VisitWeaks *\/>(context, cl);\n@@ -220,1 +354,1 @@\n-    objects_do<false \/* VisitWeaks *\/>(cl);\n+    object_iterate_inner<false \/* VisitWeaks *\/>(context, cl);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.cpp","additions":205,"deletions":71,"binary":false,"changes":276,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -27,0 +27,3 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n+#include \"gc\/shared\/taskTerminator.hpp\"\n+#include \"gc\/shared\/taskqueue.hpp\"\n@@ -28,2 +31,3 @@\n-#include \"memory\/allocation.hpp\"\n-#include \"utilities\/stack.hpp\"\n+#include \"gc\/z\/zLock.hpp\"\n+#include \"gc\/z\/zRootsIterator.hpp\"\n+#include \"gc\/z\/zStat.hpp\"\n@@ -31,1 +35,0 @@\n-class ObjectClosure;\n@@ -33,0 +36,1 @@\n+class ZHeapIteratorContext;\n@@ -34,3 +38,9 @@\n-class ZHeapIterator : public StackObj {\n-  template<bool Concurrent, bool Weak> friend class ZHeapIteratorRootOopClosure;\n-  template<bool VisitReferents> friend class ZHeapIteratorOopClosure;\n+using ZHeapIteratorBitMaps = ZGranuleMap<ZHeapIteratorBitMap*>;\n+using ZHeapIteratorBitMapsIterator = ZGranuleMapIterator<ZHeapIteratorBitMap*>;\n+using ZHeapIteratorQueue = OverflowTaskQueue<oop, mtGC>;\n+using ZHeapIteratorQueues = GenericTaskQueueSet<ZHeapIteratorQueue, mtGC>;\n+using ZHeapIteratorArrayQueue = OverflowTaskQueue<ObjArrayTask, mtGC>;\n+using ZHeapIteratorArrayQueues = GenericTaskQueueSet<ZHeapIteratorArrayQueue, mtGC>;\n+\n+class ZHeapIterator : public ParallelObjectIterator {\n+  friend class ZHeapIteratorContext;\n@@ -39,3 +49,30 @@\n-  typedef ZGranuleMap<ZHeapIteratorBitMap*>         ZVisitMap;\n-  typedef ZGranuleMapIterator<ZHeapIteratorBitMap*> ZVisitMapIterator;\n-  typedef Stack<oop, mtGC>                          ZVisitStack;\n+  const bool                         _visit_weaks;\n+  ZStatTimerDisable                  _timer_disable;\n+  ZHeapIteratorBitMaps               _bitmaps;\n+  ZLock                              _bitmaps_lock;\n+  ZHeapIteratorQueues                _queues;\n+  ZHeapIteratorArrayQueues           _array_queues;\n+  ZRootsIterator                     _roots;\n+  ZConcurrentRootsIteratorClaimOther _concurrent_roots;\n+  ZWeakRootsIterator                 _weak_roots;\n+  ZConcurrentWeakRootsIterator       _concurrent_weak_roots;\n+  TaskTerminator                     _terminator;\n+\n+  ZHeapIteratorBitMap* object_bitmap(oop obj);\n+\n+  bool mark_object(oop obj);\n+\n+  template <bool Concurrent, bool Weak, typename RootsIterator>\n+  void push_roots(const ZHeapIteratorContext& context, RootsIterator& iter);\n+\n+  template <bool VisitReferents>\n+  void follow_object(const ZHeapIteratorContext& context, oop obj);\n+\n+  void follow_array(const ZHeapIteratorContext& context, oop obj);\n+  void follow_array_chunk(const ZHeapIteratorContext& context, const ObjArrayTask& array);\n+\n+  template <bool VisitWeaks>\n+  void visit_and_follow(const ZHeapIteratorContext& context, ObjectClosure* cl, oop obj);\n+\n+  template <bool VisitWeaks>\n+  void drain(const ZHeapIteratorContext& context, ObjectClosure* cl);\n@@ -43,2 +80,2 @@\n-  ZVisitStack _visit_stack;\n-  ZVisitMap   _visit_map;\n+  template <bool VisitWeaks>\n+  void steal(const ZHeapIteratorContext& context, ObjectClosure* cl);\n@@ -46,2 +83,2 @@\n-  ZHeapIteratorBitMap* object_map(oop obj);\n-  void push(oop obj);\n+  template <bool VisitWeaks>\n+  void drain_and_steal(const ZHeapIteratorContext& context, ObjectClosure* cl);\n@@ -49,3 +86,2 @@\n-  template <typename RootsIterator, bool Concurrent, bool Weak> void push_roots();\n-  template <bool VisitReferents> void push_fields(oop obj);\n-  template <bool VisitReferents> void objects_do(ObjectClosure* cl);\n+  template <bool VisitWeaks>\n+  void object_iterate_inner(const ZHeapIteratorContext& context, ObjectClosure* cl);\n@@ -54,2 +90,2 @@\n-  ZHeapIterator();\n-  ~ZHeapIterator();\n+  ZHeapIterator(uint nworkers, bool visit_weaks);\n+  virtual ~ZHeapIterator();\n@@ -57,1 +93,1 @@\n-  void objects_do(ObjectClosure* cl, bool visit_weaks);\n+  virtual void object_iterate(ObjectClosure* cl, uint worker_id);\n","filename":"src\/hotspot\/share\/gc\/z\/zHeapIterator.hpp","additions":56,"deletions":20,"binary":false,"changes":76,"status":"modified"}]}