{"files":[{"patch":"@@ -2482,0 +2482,1 @@\n+    case Op_VectorMaskGen:\n@@ -2505,0 +2506,5 @@\n+const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+  \/\/ Only SVE has partial vector operations\n+  return (UseSVE > 0) && partial_op_sve_needed(node, vt);\n+}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -92,0 +92,1 @@\n+  bool partial_op_sve_needed(Node* node, const TypeVect* vt);\n@@ -166,2 +167,20 @@\n-    if (opcode == Op_VectorRearrange) {\n-      return false;\n+    switch(opcode) {\n+      case Op_VectorRearrange:\n+        return false;\n+      \/\/ We use Op_LoadVectorMasked to implement the predicated Op_LoadVector.\n+      \/\/ Hence we turn to check whether Op_LoadVectorMasked is supported. The\n+      \/\/ same as vector store\/gather\/scatter.\n+      case Op_LoadVector:\n+        opcode = Op_LoadVectorMasked;\n+        break;\n+      case Op_StoreVector:\n+        opcode = Op_StoreVectorMasked;\n+        break;\n+      case Op_LoadVectorGather:\n+        opcode = Op_LoadVectorGatherMasked;\n+        break;\n+      case Op_StoreVectorScatter:\n+        opcode = Op_StoreVectorScatterMasked;\n+        break;\n+      default:\n+        break;\n@@ -171,0 +190,33 @@\n+\n+  bool partial_op_sve_needed(Node* node, const TypeVect* vt) {\n+    switch(node->Opcode()) {\n+      case Op_VectorLoadMask:\n+      case Op_VectorMaskCmp:\n+      case Op_LoadVectorGather:\n+      case Op_StoreVectorScatter:\n+      case Op_AddReductionVI:\n+      case Op_AddReductionVL:\n+      case Op_AddReductionVF:\n+      case Op_AddReductionVD:\n+      case Op_MinReductionV:\n+      case Op_MaxReductionV:\n+      case Op_AndReductionV:\n+      case Op_OrReductionV:\n+      case Op_XorReductionV:\n+      \/\/ Mask is needed for partial Op_VectorMaskFirstTrue, because when the\n+      \/\/ input predicate is all-false, the result should be the vector length\n+      \/\/ instead of the vector register size.\n+      case Op_VectorMaskFirstTrue:\n+        return true;\n+      case Op_MaskAll:\n+        return !node->in(1)->is_Con();\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        \/\/ We use NEON load\/store instructions if the vector length is <= 128 bits.\n+        return vt->length_in_bytes() > 16;\n+      default:\n+        \/\/ For other ops whose vector size is smaller than the max vector size, a\n+        \/\/ full-sized unpredicated operation does not impact the final vector result.\n+        return false;\n+    }\n+  }\n@@ -184,2 +236,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n-            n->as_LoadVector()->memory_size() == MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16);\n@@ -200,2 +251,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n-            n->as_StoreVector()->memory_size() == MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16);\n@@ -303,44 +353,0 @@\n-\/\/ Predicated vector load\/store, based on the vector length of the node.\n-\/\/ Only load\/store values in the range of the memory_size. This is needed\n-\/\/ when the memory_size is lower than the hardware supported max vector size.\n-\/\/ And this might happen for Vector API mask vector load\/store.\n-instruct loadV_partial(vReg dst, vmemA mem, pRegGov pgtmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n-            n->as_LoadVector()->memory_size() < MaxVectorSize);\n-  match(Set dst (LoadVector mem));\n-  effect(TEMP pgtmp, KILL cr);\n-  ins_cost(6 * SVE_COST);\n-  format %{ \"sve_ptrue $pgtmp, vector_length\\n\\t\"\n-            \"sve_ldr $dst, $pgtmp, $mem\\t# load vector partial\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    __ sve_ptrue_lanecnt(as_PRegister($pgtmp$$reg), __ elemType_to_regVariant(bt),\n-                         Matcher::vector_length(this));\n-    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n-                          as_PRegister($pgtmp$$reg), bt, bt, $mem->opcode(),\n-                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct storeV_partial(vReg src, vmemA mem, pRegGov pgtmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n-            n->as_StoreVector()->memory_size() < MaxVectorSize);\n-  match(Set mem (StoreVector mem src));\n-  effect(TEMP pgtmp, KILL cr);\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_ptrue $pgtmp, vector_length\\n\\t\"\n-            \"sve_str $src, $pgtmp, $mem\\t# store vector partial\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n-    __ sve_ptrue_lanecnt(as_PRegister($pgtmp$$reg), __ elemType_to_regVariant(bt),\n-                         Matcher::vector_length(this, $src));\n-    FloatRegister src_reg = as_FloatRegister($src$$reg);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n-                          as_PRegister($pgtmp$$reg), bt, bt, $mem->opcode(),\n-                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -469,1 +475,1 @@\n-    __ sve_ptrue_lanecnt(as_PRegister($pgtmp$$reg), __ B, length_in_bytes_resize);\n+    __ sve_gen_mask_imm(as_PRegister($pgtmp$$reg), T_BYTE, length_in_bytes_resize);\n@@ -2331,1 +2337,1 @@\n-\/\/ Combine LoadVector+VectorLoadMask when the vector element type is not T_BYTE\n+\/\/ Combined rules for vector mask load when the vector element type is not T_BYTE\n@@ -2333,3 +2339,3 @@\n-instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg tmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg vtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n@@ -2338,1 +2344,1 @@\n-  effect(TEMP tmp, KILL cr);\n+  effect(TEMP vtmp, KILL cr);\n@@ -2340,2 +2346,2 @@\n-  format %{ \"sve_ld1b $tmp, $mem\\n\\t\"\n-            \"sve_cmpne $dst, $tmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n+  format %{ \"sve_ld1b $vtmp, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n@@ -2344,1 +2350,2 @@\n-    \/\/ expected vector element type. Convert the vector to predicate.\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -2346,1 +2353,1 @@\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($tmp$$reg),\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n@@ -2350,1 +2357,1 @@\n-               ptrue, as_FloatRegister($tmp$$reg), 0);\n+               ptrue, as_FloatRegister($vtmp$$reg), 0);\n@@ -2355,1 +2362,2 @@\n-instruct vloadmask_loadV_partial(pRegGov dst, indirect mem, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadV_masked(pRegGov dst, indirect mem, pRegGov pg, vReg vtmp, rFlagsReg cr) %{\n@@ -2357,2 +2365,0 @@\n-            n->as_Vector()->length_in_bytes() > 16 &&\n-            n->as_Vector()->length_in_bytes() < MaxVectorSize &&\n@@ -2360,4 +2366,56 @@\n-  match(Set dst (VectorLoadMask (LoadVector mem)));\n-  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(6 * SVE_COST);\n-  format %{ \"vloadmask_loadV $dst, $mem\\t# load vector mask partial (sve) (H\/S\/D)\" %}\n+  match(Set dst (VectorLoadMask (LoadVector mem) pg));\n+  effect(TEMP vtmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $vtmp, $pg, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $pg, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    BasicType to_vect_bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($pg$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               as_PRegister($pg$$reg), as_FloatRegister($vtmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadVMasked(pRegGov dst, vmemA mem, pRegGov pg, vReg vtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg)));\n+  effect(TEMP vtmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $vtmp, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the full-sized predicate (ptrue) used in VectorLoadMask.\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n+    BasicType to_vect_bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n+                          ptrue, T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               ptrue, as_FloatRegister($vtmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadVMasked_masked(pRegGov dst, vmemA mem, pRegGov pg1, pRegGov pg2,\n+                                      vReg vtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg1) pg2));\n+  effect(TEMP vtmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $vtmp, $pg2, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $pg2, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n@@ -2366,1 +2424,6 @@\n-    \/\/ expected vector element type. Convert the vector to predicate.\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg1\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the \"pg2\" used in VectorLoadMask.\n@@ -2368,2 +2431,0 @@\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(to_vect_bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this));\n@@ -2371,1 +2432,1 @@\n-                          as_PRegister($ptmp$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_PRegister($pg2$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n@@ -2373,1 +2434,2 @@\n-    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($vtmp$$reg), 0);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               as_PRegister($pg2$$reg), as_FloatRegister($vtmp$$reg), 0);\n@@ -2378,1 +2440,1 @@\n-\/\/ Combine VectorStoreMask+StoreVector when the vector element type is not T_BYTE\n+\/\/ Combined rules for vector mask store when the vector element type is not T_BYTE\n@@ -2380,1 +2442,2 @@\n-instruct storeV_vstoremask(indirect mem, pRegGov src, vReg tmp, immI_gt_1 esize) %{\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeV_vstoremask(indirect mem, pRegGov src, vReg vtmp, immI_gt_1 esize) %{\n@@ -2384,1 +2447,1 @@\n-  effect(TEMP tmp);\n+  effect(TEMP vtmp);\n@@ -2386,2 +2449,2 @@\n-  format %{ \"sve_cpy $tmp, $src, 1\\n\\t\"\n-            \"sve_st1b $tmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_st1b $vtmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n@@ -2389,0 +2452,2 @@\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n@@ -2392,2 +2457,2 @@\n-    __ sve_cpy(as_FloatRegister($tmp$$reg), size, as_PRegister($src$$reg), 1, false);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n@@ -2400,2 +2465,3 @@\n-instruct storeV_vstoremask_partial(indirect mem, pRegGov src, vReg vtmp,\n-                                   immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is lower than the MaxVectorSize.\n+instruct storeV_vstoremask_masked(indirect mem, pRegGov src, vReg vtmp,\n+                                  immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n@@ -2403,2 +2469,0 @@\n-            n->as_StoreVector()->memory_size() > 16 &&\n-            type2aelembytes(n->as_StoreVector()->vect_type()->element_basic_type()) > 1 &&\n@@ -2408,2 +2472,57 @@\n-  format %{ \"storeV_vstoremask $src, $mem\\t# store vector mask partial (sve) (H\/S\/D)\" %}\n-  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_ptrue $ptmp, vector_length\\n\\t\"\n+            \"sve_st1b $vtmp, $ptmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  ins_cost(3 * SVE_COST);\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    BasicType from_vect_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(from_vect_bt);\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    __ sve_gen_mask_imm(as_PRegister($ptmp$$reg), from_vect_bt, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($ptmp$$reg), T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeVMasked_vstoremask(vmemA mem, pRegGov src, pRegGov pg, vReg vtmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP vtmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_st1b $vtmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector store with boolean type. But the predicate used in\n+    \/\/ the narrowing \"sve_st1b\" is based on the \"src\" vector type, which\n+    \/\/ is the full-sized predicate (ptrue) here.\n+    BasicType from_vect_bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is lower than the MaxVectorSize.\n+instruct storeVMasked_vstoremask_masked(vmemA mem, pRegGov src, pRegGov pg, vReg vtmp,\n+                                        immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_ptrue $ptmp, vector_length\\n\\t\"\n+            \"sve_st1b $vtmp, $ptmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  ins_cost(3 * SVE_COST);\n@@ -2411,2 +2530,7 @@\n-    \/\/ Convert the valid src predicate to vector, and store the vector\n-    \/\/ elements as boolean values.\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used for the\n+    \/\/ vector store with boolean type. But the predicate used in the narrowing\n+    \/\/ \"sve_st1b\" is based on the \"src\" vector type, which needed to be generated\n+    \/\/ here.\n@@ -2416,1 +2540,1 @@\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this, $src));\n+    __ sve_gen_mask_imm(as_PRegister($ptmp$$reg), from_vect_bt, Matcher::vector_length(this, $src));\n@@ -2427,2 +2551,1 @@\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  predicate(UseSVE > 0);\n@@ -2434,0 +2557,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2443,2 +2567,1 @@\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  predicate(UseSVE > 0);\n@@ -2450,0 +2573,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2458,2 +2582,1 @@\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  predicate(UseSVE > 0);\n@@ -2464,0 +2587,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2471,2 +2595,1 @@\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  predicate(UseSVE > 0);\n@@ -2477,0 +2600,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2483,66 +2607,0 @@\n-instruct reduce_addI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AddReductionVI src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_addI $dst, $src1, $src2\\t# addI reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_addL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AddReductionVL src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_addL $dst, $src1, $src2\\t# addL reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_addF_partial(vRegF src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set src1_dst (AddReductionVF src1_dst src2));\n-  ins_cost(SVE_COST);\n-  effect(TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_addF $src1_dst, $src1_dst, $src2\\t# addF reduction partial (sve) (S)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this, $src2));\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ S,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_addD_partial(vRegD src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set src1_dst (AddReductionVD src1_dst src2));\n-  ins_cost(SVE_COST);\n-  effect(TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_addD $src1_dst, $src1_dst, $src2\\t# addD reduction partial (sve) (D)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ D,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -2608,2 +2666,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG);\n@@ -2615,0 +2672,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2625,2 +2683,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n@@ -2632,0 +2689,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2639,38 +2697,0 @@\n-instruct reduce_andI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_andI $dst, $src1, $src2\\t# andI reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_andL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (AndReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_andL $dst, $src1, $src2\\t# andL reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -2714,2 +2734,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG);\n@@ -2721,0 +2740,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2731,2 +2751,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n@@ -2738,0 +2757,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2745,38 +2765,0 @@\n-instruct reduce_orI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_orI $dst, $src1, $src2\\t# orI reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_orL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (OrReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_orL $dst, $src1, $src2\\t# orL reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -2820,2 +2802,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG);\n@@ -2827,0 +2808,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2837,2 +2819,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n@@ -2844,0 +2825,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2851,38 +2833,0 @@\n-instruct reduce_eorI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_eorI $dst, $src1, $src2\\t# eorI reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_eorL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (XorReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_eorL $dst, $src1, $src2\\t# eorL reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -2926,1 +2870,0 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -2934,0 +2877,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2944,1 +2888,0 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -2951,0 +2894,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -2958,39 +2902,0 @@\n-instruct reduce_maxI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n-  match(Set dst (MaxReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_maxI $dst, $src1, $src2\\t# maxI reduction partial (sve)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_maxL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (MaxReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_maxL $dst, $src1, $src2\\t# maxL reduction  partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -2999,2 +2904,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n@@ -3006,0 +2910,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -3012,17 +2917,0 @@\n-instruct reduce_maxF_partial(vRegF dst, vRegF src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_maxF $dst, $src1, $src2\\t# maxF reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this, $src2));\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ S, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ fmaxs(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -3031,2 +2919,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n@@ -3038,0 +2925,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -3044,17 +2932,0 @@\n-instruct reduce_maxD_partial(vRegD dst, vRegD src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (MaxReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_maxD $dst, $src1, $src2\\t# maxD reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_fmaxv(as_FloatRegister($dst$$reg), __ D, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ fmaxd(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -3129,1 +3000,0 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -3137,0 +3007,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -3147,1 +3018,0 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -3154,0 +3024,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -3161,39 +3032,0 @@\n-instruct reduce_minI_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n-  match(Set dst (MinReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_minI $dst, $src1, $src2\\t# minI reduction partial (sve)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct reduce_minL_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst (MinReductionV src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_minL $dst, $src1, $src2\\t# minL reduction  partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -3202,2 +3034,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT);\n@@ -3209,0 +3040,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -3215,17 +3047,0 @@\n-instruct reduce_minF_partial(vRegF dst, vRegF src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_minF $dst, $src1, $src2\\t# minF reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this, $src2));\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ S, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ fmins(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -3234,2 +3049,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE);\n@@ -3241,0 +3055,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -3247,17 +3062,0 @@\n-instruct reduce_minD_partial(vRegD dst, vRegD src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (MinReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_minD $dst, $src1, $src2\\t# minD reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_fminv(as_FloatRegister($dst$$reg), __ D, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ fmind(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -5246,1 +5044,0 @@\n-            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n@@ -5253,0 +5050,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -5261,1 +5059,0 @@\n-            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n@@ -5269,0 +5066,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -5276,37 +5074,0 @@\n-\/\/ ------------------------------ Vector Load Gather Partial-------------------------------\n-\n-instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n-             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n-  match(Set dst (LoadVectorGather mem idx));\n-  effect(TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST + INSN_COST);\n-  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (S)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this));\n-    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n-                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct gatherL_partial(vReg dst, indirect mem, vReg idx, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n-             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n-  match(Set dst (LoadVectorGather mem idx));\n-  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(3 * SVE_COST + INSN_COST);\n-  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (D)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this));\n-    __ sve_uunpklo(as_FloatRegister($vtmp$$reg), __ D, as_FloatRegister($idx$$reg));\n-    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n-                       as_Register($mem$$base), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -5349,1 +5110,0 @@\n-            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n@@ -5356,0 +5116,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src) == MaxVectorSize, \"invalid vector length\");\n@@ -5364,1 +5125,0 @@\n-            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n@@ -5372,0 +5132,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src) == MaxVectorSize, \"invalid vector length\");\n@@ -5379,37 +5140,0 @@\n-\/\/ ------------------------------ Vector Store Scatter Partial -------------------------------\n-\n-instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n-            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n-             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n-  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n-  effect(TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST + INSN_COST);\n-  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (S)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this, $src));\n-    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n-                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct scatterL_partial(indirect mem, vReg src, vReg idx, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n-            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n-             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n-  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n-  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(3 * SVE_COST + INSN_COST);\n-  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (D)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src));\n-    __ sve_uunpklo(as_FloatRegister($vtmp$$reg), __ D, as_FloatRegister($idx$$reg));\n-    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n-                        as_Register($mem$$base), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -5634,1 +5358,1 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n@@ -5637,1 +5361,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -5640,1 +5364,1 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(Matcher::vector_length_in_bytes(this, $src) == MaxVectorSize, \"invalid vector length\");\n@@ -5643,8 +5367,16 @@\n-    \/\/ When the input predicate is all-false, the result should be the vector length\n-    \/\/ instead of max vector register size.\n-    if (length_in_bytes == MaxVectorSize) {\n-      __ sve_brkb(as_PRegister($ptmp$$reg), ptrue, as_PRegister($src$$reg), false);\n-    } else {\n-      __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this, $src));\n-      __ sve_brkb(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg), as_PRegister($src$$reg), false);\n-    }\n+    __ sve_brkb(as_PRegister($ptmp$$reg), ptrue, as_PRegister($src$$reg), false);\n+    __ sve_cntp($dst$$Register, size, ptrue, as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_masked(iRegINoSp dst, pReg src, pRegGov pg, pReg ptmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskFirstTrue src pg));\n+  effect(TEMP ptmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"vmask_firsttrue $dst, $pg, $src\\t# vector mask firsttrue (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_brkb(as_PRegister($ptmp$$reg), as_PRegister($pg$$reg), as_PRegister($src$$reg), false);\n@@ -5704,1 +5436,1 @@\n-\/\/ maskAll (full or partial predicate size)\n+\/\/ maskAll\n@@ -5706,1 +5438,1 @@\n-instruct vmaskAll_immI(pRegGov dst, immI src) %{\n+instruct vmaskAll_immI(pRegGov dst, immI src, rFlagsReg cr) %{\n@@ -5709,0 +5441,1 @@\n+  effect(KILL cr);\n@@ -5710,1 +5443,1 @@\n-  format %{ \"sve_ptrue_lanecnt\/sve_pfalse $dst\\t# mask all (sve) (B\/H\/S)\" %}\n+  format %{ \"sve_ptrue\/sve_pfalse $dst\\t# mask all (sve) (B\/H\/S)\" %}\n@@ -5718,2 +5451,1 @@\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-                           Matcher::vector_length(this));\n+      __ sve_gen_mask_imm(as_PRegister($dst$$reg), bt, Matcher::vector_length(this));\n@@ -5722,1 +5454,1 @@\n-  ins_pipe(pipe_slow);\n+  ins_pipe(pipe_class_default);\n@@ -5726,1 +5458,1 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n@@ -5729,1 +5461,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -5731,1 +5463,0 @@\n-            \"sve_ptrue $dst, vector_length\\n\\t\"\n@@ -5734,0 +5465,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -5736,1 +5468,0 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n@@ -5738,7 +5469,1 @@\n-    if (length_in_bytes < MaxVectorSize) {\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), size, Matcher::vector_length(this));\n-      __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n-                 as_PRegister($dst$$reg), as_FloatRegister($tmp$$reg), 0);\n-    } else {\n-      __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n-    }\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n@@ -5749,1 +5474,1 @@\n-instruct vmaskAll_immL(pRegGov dst, immL src) %{\n+instruct vmaskAll_immL(pRegGov dst, immL src, rFlagsReg cr) %{\n@@ -5752,0 +5477,1 @@\n+  effect(KILL cr);\n@@ -5753,1 +5479,1 @@\n-  format %{ \"sve_ptrue_lanecnt\/sve_pfalse $dst\\t# mask all (sve) (D)\" %}\n+  format %{ \"sve_ptrue\/sve_pfalse $dst\\t# mask all (sve) (D)\" %}\n@@ -5761,2 +5487,1 @@\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-                           Matcher::vector_length(this));\n+      __ sve_gen_mask_imm(as_PRegister($dst$$reg), bt, Matcher::vector_length(this));\n@@ -5765,1 +5490,1 @@\n-  ins_pipe(pipe_slow);\n+  ins_pipe(pipe_class_default);\n@@ -5769,1 +5494,1 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n@@ -5772,1 +5497,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -5774,1 +5499,0 @@\n-            \"sve_ptrue $dst, vector_length\\n\\t\"\n@@ -5777,0 +5501,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -5779,1 +5504,0 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n@@ -5781,7 +5505,37 @@\n-    if (length_in_bytes < MaxVectorSize) {\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), size, Matcher::vector_length(this));\n-      __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n-                 as_PRegister($dst$$reg), as_FloatRegister($tmp$$reg), 0);\n-    } else {\n-      __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n-    }\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ maskAll - predicated\n+\n+instruct vmaskAllI_masked(pRegGov dst, iRegIorL2I src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src pg));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup $tmp, $src\\n\\t\"\n+            \"sve_cmpne $dst, $pg, $dst, $tmp, 0\\t# mask all (sve) (B\/H\/S)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), size, as_Register($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n+               as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllL_masked(pRegGov dst, iRegL src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src pg));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup $tmp, $src\\n\\t\"\n+            \"sve_cmpne $dst, $pg, $dst, $tmp, 0\\t# mask all (sve) (D)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), size, as_Register($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n+               as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg), 0);\n@@ -5798,1 +5552,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(SVE_COST);\n@@ -5801,1 +5555,1 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -5803,9 +5557,2 @@\n-    if (length_in_bytes == MaxVectorSize) {\n-      __ sve_compare(as_PRegister($dst$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n-                     as_FloatRegister($src2$$reg), (int)$cond$$constant);\n-    } else {\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-                           Matcher::vector_length(this));\n-      __ sve_compare(as_PRegister($dst$$reg), bt, as_PRegister($dst$$reg), as_FloatRegister($src1$$reg),\n-                     as_FloatRegister($src2$$reg), (int)$cond$$constant);\n-    }\n+    __ sve_compare(as_PRegister($dst$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n+                   as_FloatRegister($src2$$reg), (int)$cond$$constant);\n@@ -5833,1 +5580,1 @@\n-  predicate(UseSVE > 0 &&\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n@@ -5847,1 +5594,2 @@\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() != T_BYTE);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            n->bottom_type()->is_vect()->element_basic_type() != T_BYTE);\n@@ -5861,0 +5609,73 @@\n+instruct vloadmaskB_masked(pRegGov dst, vReg src, pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vloadmaskB $dst, $pg, $src\\t# vector load mask (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ B,\n+               as_PRegister($pg$$reg), as_FloatRegister($src$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_extend_masked(pRegGov dst, vReg src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() != T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"vloadmask $dst, $pg, $src\\t# vector load mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_vector_extend(as_FloatRegister($tmp$$reg), size, as_FloatRegister($src$$reg), __ B);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n+               as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask gen\n+\n+instruct vmask_gen_I(pRegGov pd, iRegIorL2I src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen (ConvI2L src)));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_whilelow $pd, zr, $src\\t# vector mask gen (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_whilelow(as_PRegister($pd$$reg), size, zr, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct vmask_gen_L(pRegGov pd, iRegL src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen src));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"sve_whilelo $pd, zr, $src\\t# vector mask gen (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_whilelo(as_PRegister($pd$$reg), size, zr, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct vmask_gen_imm(pRegGov pd, immL src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen src));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vmask_gen_imm $pd, $src\\t# vector mask gen with imm (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_gen_mask_imm(as_PRegister($pd$$reg), bt, (uint) $src$$constant);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n@@ -5959,14 +5780,0 @@\n-instruct vmask_gen(pRegGov pg, iRegL len, rFlagsReg cr) %{\n-  predicate(UseSVE > 0);\n-  match(Set pg (VectorMaskGen len));\n-  effect(KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_whilelo $pg, zr, $len\\t # sve\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo(as_PRegister($pg$$reg), size, zr, as_Register($len$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":403,"deletions":596,"binary":false,"changes":999,"status":"modified"},{"patch":"@@ -87,0 +87,1 @@\n+  bool partial_op_sve_needed(Node* node, const TypeVect* vt);\n@@ -161,2 +162,20 @@\n-    if (opcode == Op_VectorRearrange) {\n-      return false;\n+    switch(opcode) {\n+      case Op_VectorRearrange:\n+        return false;\n+      \/\/ We use Op_LoadVectorMasked to implement the predicated Op_LoadVector.\n+      \/\/ Hence we turn to check whether Op_LoadVectorMasked is supported. The\n+      \/\/ same as vector store\/gather\/scatter.\n+      case Op_LoadVector:\n+        opcode = Op_LoadVectorMasked;\n+        break;\n+      case Op_StoreVector:\n+        opcode = Op_StoreVectorMasked;\n+        break;\n+      case Op_LoadVectorGather:\n+        opcode = Op_LoadVectorGatherMasked;\n+        break;\n+      case Op_StoreVectorScatter:\n+        opcode = Op_StoreVectorScatterMasked;\n+        break;\n+      default:\n+        break;\n@@ -166,0 +185,33 @@\n+\n+  bool partial_op_sve_needed(Node* node, const TypeVect* vt) {\n+    switch(node->Opcode()) {\n+      case Op_VectorLoadMask:\n+      case Op_VectorMaskCmp:\n+      case Op_LoadVectorGather:\n+      case Op_StoreVectorScatter:\n+      case Op_AddReductionVI:\n+      case Op_AddReductionVL:\n+      case Op_AddReductionVF:\n+      case Op_AddReductionVD:\n+      case Op_MinReductionV:\n+      case Op_MaxReductionV:\n+      case Op_AndReductionV:\n+      case Op_OrReductionV:\n+      case Op_XorReductionV:\n+      \/\/ Mask is needed for partial Op_VectorMaskFirstTrue, because when the\n+      \/\/ input predicate is all-false, the result should be the vector length\n+      \/\/ instead of the vector register size.\n+      case Op_VectorMaskFirstTrue:\n+        return true;\n+      case Op_MaskAll:\n+        return !node->in(1)->is_Con();\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        \/\/ We use NEON load\/store instructions if the vector length is <= 128 bits.\n+        return vt->length_in_bytes() > 16;\n+      default:\n+        \/\/ For other ops whose vector size is smaller than the max vector size, a\n+        \/\/ full-sized unpredicated operation does not impact the final vector result.\n+        return false;\n+    }\n+  }\n@@ -187,2 +239,1 @@\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() >= 16 &&\n-            n->as_LoadVector()->memory_size() == MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16);\n@@ -203,2 +254,1 @@\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() >= 16 &&\n-            n->as_StoreVector()->memory_size() == MaxVectorSize);\n+  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16);\n@@ -240,44 +290,0 @@\n-\/\/ Predicated vector load\/store, based on the vector length of the node.\n-\/\/ Only load\/store values in the range of the memory_size. This is needed\n-\/\/ when the memory_size is lower than the hardware supported max vector size.\n-\/\/ And this might happen for Vector API mask vector load\/store.\n-instruct loadV_partial(vReg dst, vmemA mem, pRegGov pgtmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->as_LoadVector()->memory_size() > 16 &&\n-            n->as_LoadVector()->memory_size() < MaxVectorSize);\n-  match(Set dst (LoadVector mem));\n-  effect(TEMP pgtmp, KILL cr);\n-  ins_cost(6 * SVE_COST);\n-  format %{ \"sve_ptrue $pgtmp, vector_length\\n\\t\"\n-            \"sve_ldr $dst, $pgtmp, $mem\\t# load vector partial\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    __ sve_ptrue_lanecnt(as_PRegister($pgtmp$$reg), __ elemType_to_regVariant(bt),\n-                         Matcher::vector_length(this));\n-    FloatRegister dst_reg = as_FloatRegister($dst$$reg);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, dst_reg,\n-                          as_PRegister($pgtmp$$reg), bt, bt, $mem->opcode(),\n-                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct storeV_partial(vReg src, vmemA mem, pRegGov pgtmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 && n->as_StoreVector()->memory_size() > 16 &&\n-            n->as_StoreVector()->memory_size() < MaxVectorSize);\n-  match(Set mem (StoreVector mem src));\n-  effect(TEMP pgtmp, KILL cr);\n-  ins_cost(5 * SVE_COST);\n-  format %{ \"sve_ptrue $pgtmp, vector_length\\n\\t\"\n-            \"sve_str $src, $pgtmp, $mem\\t# store vector partial\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n-    __ sve_ptrue_lanecnt(as_PRegister($pgtmp$$reg), __ elemType_to_regVariant(bt),\n-                         Matcher::vector_length(this, $src));\n-    FloatRegister src_reg = as_FloatRegister($src$$reg);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, src_reg,\n-                          as_PRegister($pgtmp$$reg), bt, bt, $mem->opcode(),\n-                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -383,1 +389,1 @@\n-    __ sve_ptrue_lanecnt(as_PRegister($pgtmp$$reg), __ B, length_in_bytes_resize);\n+    __ sve_gen_mask_imm(as_PRegister($pgtmp$$reg), T_BYTE, length_in_bytes_resize);\n@@ -1292,1 +1298,1 @@\n-\/\/ Combine LoadVector+VectorLoadMask when the vector element type is not T_BYTE\n+\/\/ Combined rules for vector mask load when the vector element type is not T_BYTE\n@@ -1294,3 +1300,3 @@\n-instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg tmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_Vector()->length_in_bytes() == MaxVectorSize &&\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg vtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n@@ -1299,1 +1305,1 @@\n-  effect(TEMP tmp, KILL cr);\n+  effect(TEMP vtmp, KILL cr);\n@@ -1301,2 +1307,2 @@\n-  format %{ \"sve_ld1b $tmp, $mem\\n\\t\"\n-            \"sve_cmpne $dst, $tmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n+  format %{ \"sve_ld1b $vtmp, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n@@ -1305,1 +1311,2 @@\n-    \/\/ expected vector element type. Convert the vector to predicate.\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -1307,1 +1314,1 @@\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($tmp$$reg),\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n@@ -1311,1 +1318,1 @@\n-               ptrue, as_FloatRegister($tmp$$reg), 0);\n+               ptrue, as_FloatRegister($vtmp$$reg), 0);\n@@ -1316,1 +1323,2 @@\n-instruct vloadmask_loadV_partial(pRegGov dst, indirect mem, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadV_masked(pRegGov dst, indirect mem, pRegGov pg, vReg vtmp, rFlagsReg cr) %{\n@@ -1318,2 +1326,0 @@\n-            n->as_Vector()->length_in_bytes() > 16 &&\n-            n->as_Vector()->length_in_bytes() < MaxVectorSize &&\n@@ -1321,4 +1327,5 @@\n-  match(Set dst (VectorLoadMask (LoadVector mem)));\n-  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(6 * SVE_COST);\n-  format %{ \"vloadmask_loadV $dst, $mem\\t# load vector mask partial (sve) (H\/S\/D)\" %}\n+  match(Set dst (VectorLoadMask (LoadVector mem) pg));\n+  effect(TEMP vtmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $vtmp, $pg, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $pg, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n@@ -1327,1 +1334,1 @@\n-    \/\/ expected vector element type. Convert the vector to predicate.\n+    \/\/ defined vector element type. Convert the vector to predicate.\n@@ -1329,2 +1336,0 @@\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(to_vect_bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this));\n@@ -1332,1 +1337,1 @@\n-                          as_PRegister($ptmp$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_PRegister($pg$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n@@ -1334,1 +1339,2 @@\n-    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($vtmp$$reg), 0);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               as_PRegister($pg$$reg), as_FloatRegister($vtmp$$reg), 0);\n@@ -1339,1 +1345,27 @@\n-\/\/ Combine VectorStoreMask+StoreVector when the vector element type is not T_BYTE\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadVMasked(pRegGov dst, vmemA mem, pRegGov pg, vReg vtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg)));\n+  effect(TEMP vtmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $vtmp, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the full-sized predicate (ptrue) used in VectorLoadMask.\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n+    BasicType to_vect_bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n+                          ptrue, T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               ptrue, as_FloatRegister($vtmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n@@ -1341,1 +1373,32 @@\n-instruct storeV_vstoremask(indirect mem, pRegGov src, vReg tmp, immI_gt_1 esize) %{\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadVMasked_masked(pRegGov dst, vmemA mem, pRegGov pg1, pRegGov pg2,\n+                                      vReg vtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(n->bottom_type()->is_vect()->element_basic_type()) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg1) pg2));\n+  effect(TEMP vtmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_ld1b $vtmp, $pg2, $mem\\n\\t\"\n+            \"sve_cmpne $dst, $pg2, $vtmp, 0\\t# load vector mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg1\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the \"pg2\" used in VectorLoadMask.\n+    BasicType to_vect_bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($pg2$$reg), T_BOOLEAN, to_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ elemType_to_regVariant(to_vect_bt),\n+               as_PRegister($pg2$$reg), as_FloatRegister($vtmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Combined rules for vector mask store when the vector element type is not T_BYTE\n+\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeV_vstoremask(indirect mem, pRegGov src, vReg vtmp, immI_gt_1 esize) %{\n@@ -1345,1 +1408,1 @@\n-  effect(TEMP tmp);\n+  effect(TEMP vtmp);\n@@ -1347,2 +1410,2 @@\n-  format %{ \"sve_cpy $tmp, $src, 1\\n\\t\"\n-            \"sve_st1b $tmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_st1b $vtmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n@@ -1350,0 +1413,2 @@\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n@@ -1353,2 +1418,2 @@\n-    __ sve_cpy(as_FloatRegister($tmp$$reg), size, as_PRegister($src$$reg), 1, false);\n-    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($tmp$$reg),\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n@@ -1361,2 +1426,3 @@\n-instruct storeV_vstoremask_partial(indirect mem, pRegGov src, vReg vtmp,\n-                                   immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is lower than the MaxVectorSize.\n+instruct storeV_vstoremask_masked(indirect mem, pRegGov src, vReg vtmp,\n+                                  immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n@@ -1364,2 +1430,0 @@\n-            n->as_StoreVector()->memory_size() > 16 &&\n-            type2aelembytes(n->as_StoreVector()->vect_type()->element_basic_type()) > 1 &&\n@@ -1369,2 +1433,57 @@\n-  format %{ \"storeV_vstoremask $src, $mem\\t# store vector mask partial (sve) (H\/S\/D)\" %}\n-  ins_cost(6 * SVE_COST);\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_ptrue $ptmp, vector_length\\n\\t\"\n+            \"sve_st1b $vtmp, $ptmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  ins_cost(3 * SVE_COST);\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    BasicType from_vect_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(from_vect_bt);\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    __ sve_gen_mask_imm(as_PRegister($ptmp$$reg), from_vect_bt, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n+                          as_PRegister($ptmp$$reg), T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeVMasked_vstoremask(vmemA mem, pRegGov src, pRegGov pg, vReg vtmp, immI_gt_1 esize) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP vtmp);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_st1b $vtmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector store with boolean type. But the predicate used in\n+    \/\/ the narrowing \"sve_st1b\" is based on the \"src\" vector type, which\n+    \/\/ is the full-sized predicate (ptrue) here.\n+    BasicType from_vect_bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(from_vect_bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy(as_FloatRegister($vtmp$$reg), size, as_PRegister($src$$reg), 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, as_FloatRegister($vtmp$$reg),\n+                          ptrue, T_BOOLEAN, from_vect_bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is lower than the MaxVectorSize.\n+instruct storeVMasked_vstoremask_masked(vmemA mem, pRegGov src, pRegGov pg, vReg vtmp,\n+                                        immI_gt_1 esize, pRegGov ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n+  format %{ \"sve_cpy $vtmp, $src, 1\\n\\t\"\n+            \"sve_ptrue $ptmp, vector_length\\n\\t\"\n+            \"sve_st1b $vtmp, $ptmp, $mem\\t# store vector mask (sve) (H\/S\/D)\" %}\n+  ins_cost(3 * SVE_COST);\n@@ -1372,2 +1491,7 @@\n-    \/\/ Convert the valid src predicate to vector, and store the vector\n-    \/\/ elements as boolean values.\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used for the\n+    \/\/ vector store with boolean type. But the predicate used in the narrowing\n+    \/\/ \"sve_st1b\" is based on the \"src\" vector type, which needed to be generated\n+    \/\/ here.\n@@ -1377,1 +1501,1 @@\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this, $src));\n+    __ sve_gen_mask_imm(as_PRegister($ptmp$$reg), from_vect_bt, Matcher::vector_length(this, $src));\n@@ -1384,0 +1508,1 @@\n+\n@@ -1390,0 +1515,1 @@\n+       `predicate(UseSVE > 0);',\n@@ -1391,4 +1517,1 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n-       `predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG);')\n@@ -1400,0 +1523,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -1414,0 +1538,1 @@\n+       `predicate(UseSVE > 0);',\n@@ -1415,4 +1540,1 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);',\n-       `predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);')\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);')\n@@ -1424,0 +1546,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -1431,49 +1554,0 @@\n-dnl REDUCE_I_PARTIAL($1,        $2     )\n-dnl REDUCE_I_PARTIAL(insn_name, op_name)\n-define(`REDUCE_I_PARTIAL', `\n-instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  ifelse($2, AddReductionVI,\n-       `predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);',\n-       `predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);')\n-  match(Set dst ($2 src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# $1I reduction partial (sve) (may extend)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n-dnl\n-dnl REDUCE_L_PARTIAL($1,        $2    )\n-dnl REDUCE_L_PARTIAL(insn_name, op_name)\n-define(`REDUCE_L_PARTIAL', `\n-instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  ifelse($2, AddReductionVL,\n-       `predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);',\n-       `predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);')\n-  match(Set dst ($2 src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# $1L reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n@@ -1485,2 +1559,1 @@\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+  predicate(UseSVE > 0);\n@@ -1491,0 +1564,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -1498,19 +1572,0 @@\n-dnl REDUCE_ADDF_PARTIAL($1,        $2,     $3,      $4  )\n-dnl REDUCE_ADDF_PARTIAL(insn_name, suffix, reg_dst, size)\n-define(`REDUCE_ADDF_PARTIAL', `\n-instruct reduce_$1_partial($3 src1_dst, vReg src2, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set src1_dst ($2 src1_dst src2));\n-  ins_cost(SVE_COST);\n-  effect(TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_$1 $src1_dst, $src1_dst, $src2\\t# $1 reduction partial (sve) ($4)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ $4, Matcher::vector_length(this, $src2));\n-    __ sve_fadda(as_FloatRegister($src1_dst$$reg), __ $4,\n-                 as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n-dnl\n-dnl\n@@ -1573,1 +1628,1 @@\n-\n+dnl\n@@ -1579,4 +1634,0 @@\n-REDUCE_I_PARTIAL(add, AddReductionVI)\n-REDUCE_L_PARTIAL(add, AddReductionVL)\n-REDUCE_ADDF_PARTIAL(addF, AddReductionVF, vRegF, S)\n-REDUCE_ADDF_PARTIAL(addD, AddReductionVD, vRegD, D)\n@@ -1593,2 +1644,0 @@\n-REDUCE_I_PARTIAL(and, AndReductionV)\n-REDUCE_L_PARTIAL(and, AndReductionV)\n@@ -1603,2 +1652,0 @@\n-REDUCE_I_PARTIAL(or, OrReductionV)\n-REDUCE_L_PARTIAL(or, OrReductionV)\n@@ -1613,2 +1660,0 @@\n-REDUCE_I_PARTIAL(eor, XorReductionV)\n-REDUCE_L_PARTIAL(eor, XorReductionV)\n@@ -1626,1 +1671,0 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -1634,0 +1678,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -1647,1 +1692,0 @@\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize &&\n@@ -1654,0 +1698,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -1661,45 +1706,0 @@\n-dnl REDUCE_MAXMIN_I_PARTIAL($1     , $2     )\n-dnl REDUCE_MAXMIN_I_PARTIAL(min_max, op_name)\n-define(`REDUCE_MAXMIN_I_PARTIAL', `\n-instruct reduce_$1I_partial(iRegINoSp dst, iRegIorL2I src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() != T_LONG &&\n-            is_integral_type(n->in(2)->bottom_type()->is_vect()->element_basic_type()));\n-  match(Set dst ($2 src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_$1I $dst, $src1, $src2\\t# $1I reduction partial (sve)\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this, $src2);\n-    Assembler::SIMD_RegVariant variant = __ elemType_to_regVariant(bt);\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), variant, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n-dnl\n-dnl REDUCE_MAXMIN_L_PARTIAL($1     , $2     )\n-dnl REDUCE_MAXMIN_L_PARTIAL(min_max, op_name)\n-define(`REDUCE_MAXMIN_L_PARTIAL', `\n-instruct reduce_$1L_partial(iRegLNoSp dst, iRegL src1, vReg src2, vRegD vtmp,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == T_LONG);\n-  match(Set dst ($2 src1 src2));\n-  effect(TEMP_DEF dst, TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST);\n-  format %{ \"sve_reduce_$1L $dst, $src1, $src2\\t# $1L reduction  partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src2));\n-    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n-                           $src1$$Register, as_FloatRegister($src2$$reg),\n-                           as_PRegister($ptmp$$reg), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n-dnl\n@@ -1751,2 +1751,1 @@\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() == MaxVectorSize);\n+            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3);\n@@ -1758,0 +1757,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src2) == MaxVectorSize, \"invalid vector length\");\n@@ -1764,20 +1764,0 @@\n-dnl REDUCE_FMINMAX_PARTIAL($1,      $2,          $3,           $4,   $5         )\n-dnl REDUCE_FMINMAX_PARTIAL(min_max, name_suffix, element_type, size, reg_src_dst)\n-define(`REDUCE_FMINMAX_PARTIAL', `\n-instruct reduce_$1$2_partial($5 dst, $5 src1, vReg src2,\n-                             pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->in(2)->bottom_type()->is_vect()->element_basic_type() == $3 &&\n-            n->in(2)->bottom_type()->is_vect()->length_in_bytes() < MaxVectorSize);\n-  match(Set dst (translit($1, `m', `M')ReductionV src1 src2));\n-  ins_cost(INSN_COST);\n-  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n-  format %{ \"sve_reduce_$1$2 $dst, $src1, $src2\\t# $1$2 reduction partial (sve)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ $4, Matcher::vector_length(this, $src2));\n-    __ sve_f$1v(as_FloatRegister($dst$$reg), __ $4, as_PRegister($ptmp$$reg), as_FloatRegister($src2$$reg));\n-    __ f`$1'translit($4, `SD', `sd')(as_FloatRegister($dst$$reg), as_FloatRegister($dst$$reg), as_FloatRegister($src1$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}')dnl\n-dnl\n@@ -1804,2 +1784,0 @@\n-REDUCE_MAXMIN_I_PARTIAL(max, MaxReductionV)\n-REDUCE_MAXMIN_L_PARTIAL(max, MaxReductionV)\n@@ -1807,1 +1785,0 @@\n-REDUCE_FMINMAX_PARTIAL(max, F, T_FLOAT,  S, vRegF)\n@@ -1809,1 +1786,0 @@\n-REDUCE_FMINMAX_PARTIAL(max, D, T_DOUBLE, D, vRegD)\n@@ -1820,2 +1796,0 @@\n-REDUCE_MAXMIN_I_PARTIAL(min, MinReductionV)\n-REDUCE_MAXMIN_L_PARTIAL(min, MinReductionV)\n@@ -1823,1 +1797,0 @@\n-REDUCE_FMINMAX_PARTIAL(min, F, T_FLOAT,  S, vRegF)\n@@ -1825,1 +1798,0 @@\n-REDUCE_FMINMAX_PARTIAL(min, D, T_DOUBLE, D, vRegD)\n@@ -2816,1 +2788,0 @@\n-            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n@@ -2823,0 +2794,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -2831,1 +2803,0 @@\n-            n->as_LoadVectorGather()->memory_size() == MaxVectorSize &&\n@@ -2839,0 +2810,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -2846,37 +2818,0 @@\n-\/\/ ------------------------------ Vector Load Gather Partial-------------------------------\n-\n-instruct gatherI_partial(vReg dst, indirect mem, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n-             n->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n-  match(Set dst (LoadVectorGather mem idx));\n-  effect(TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST + INSN_COST);\n-  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (S)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this));\n-    __ sve_ld1w_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n-                       as_Register($mem$$base), as_FloatRegister($idx$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct gatherL_partial(vReg dst, indirect mem, vReg idx, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_LoadVectorGather()->memory_size() < MaxVectorSize &&\n-            (n->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n-             n->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n-  match(Set dst (LoadVectorGather mem idx));\n-  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(3 * SVE_COST + INSN_COST);\n-  format %{ \"load_vector_gather $dst, $ptmp, $mem, $idx\\t# vector load gather partial (D)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this));\n-    __ sve_uunpklo(as_FloatRegister($vtmp$$reg), __ D, as_FloatRegister($idx$$reg));\n-    __ sve_ld1d_gather(as_FloatRegister($dst$$reg), as_PRegister($ptmp$$reg),\n-                       as_Register($mem$$base), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -2919,1 +2854,0 @@\n-            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n@@ -2926,0 +2860,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src) == MaxVectorSize, \"invalid vector length\");\n@@ -2934,1 +2869,0 @@\n-            n->as_StoreVectorScatter()->memory_size() == MaxVectorSize &&\n@@ -2942,0 +2876,1 @@\n+    assert(Matcher::vector_length_in_bytes(this, $src) == MaxVectorSize, \"invalid vector length\");\n@@ -2949,37 +2884,0 @@\n-\/\/ ------------------------------ Vector Store Scatter Partial -------------------------------\n-\n-instruct scatterI_partial(indirect mem, vReg src, vReg idx, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n-            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_INT ||\n-             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_FLOAT));\n-  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n-  effect(TEMP ptmp, KILL cr);\n-  ins_cost(2 * SVE_COST + INSN_COST);\n-  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (S)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ S, Matcher::vector_length(this, $src));\n-    __ sve_st1w_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n-                        as_Register($mem$$base), as_FloatRegister($idx$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n-instruct scatterL_partial(indirect mem, vReg src, vReg idx, vReg vtmp, pRegGov ptmp, rFlagsReg cr) %{\n-  predicate(UseSVE > 0 &&\n-            n->as_StoreVectorScatter()->memory_size() < MaxVectorSize &&\n-            (n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_LONG ||\n-             n->in(3)->in(1)->bottom_type()->is_vect()->element_basic_type() == T_DOUBLE));\n-  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n-  effect(TEMP vtmp, TEMP ptmp, KILL cr);\n-  ins_cost(3 * SVE_COST + INSN_COST);\n-  format %{ \"store_vector_scatter $mem, $ptmp, $idx, $src\\t# vector store scatter partial (D)\" %}\n-  ins_encode %{\n-    __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), __ D, Matcher::vector_length(this, $src));\n-    __ sve_uunpklo(as_FloatRegister($vtmp$$reg), __ D, as_FloatRegister($idx$$reg));\n-    __ sve_st1d_scatter(as_FloatRegister($src$$reg), as_PRegister($ptmp$$reg),\n-                        as_Register($mem$$base), as_FloatRegister($vtmp$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n@@ -3127,1 +3025,1 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n@@ -3130,1 +3028,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -3133,1 +3031,1 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(Matcher::vector_length_in_bytes(this, $src) == MaxVectorSize, \"invalid vector length\");\n@@ -3136,8 +3034,16 @@\n-    \/\/ When the input predicate is all-false, the result should be the vector length\n-    \/\/ instead of max vector register size.\n-    if (length_in_bytes == MaxVectorSize) {\n-      __ sve_brkb(as_PRegister($ptmp$$reg), ptrue, as_PRegister($src$$reg), false);\n-    } else {\n-      __ sve_ptrue_lanecnt(as_PRegister($ptmp$$reg), size, Matcher::vector_length(this, $src));\n-      __ sve_brkb(as_PRegister($ptmp$$reg), as_PRegister($ptmp$$reg), as_PRegister($src$$reg), false);\n-    }\n+    __ sve_brkb(as_PRegister($ptmp$$reg), ptrue, as_PRegister($src$$reg), false);\n+    __ sve_cntp($dst$$Register, size, ptrue, as_PRegister($ptmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_masked(iRegINoSp dst, pReg src, pRegGov pg, pReg ptmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskFirstTrue src pg));\n+  effect(TEMP ptmp);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"vmask_firsttrue $dst, $pg, $src\\t# vector mask firsttrue (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_brkb(as_PRegister($ptmp$$reg), as_PRegister($pg$$reg), as_PRegister($src$$reg), false);\n@@ -3197,1 +3103,1 @@\n-instruct vmaskAll_imm$1(pRegGov dst, imm$1 src) %{\n+instruct vmaskAll_imm$1(pRegGov dst, imm$1 src, rFlagsReg cr) %{\n@@ -3200,0 +3106,1 @@\n+  effect(KILL cr);\n@@ -3201,1 +3108,1 @@\n-  format %{ \"sve_ptrue_lanecnt\/sve_pfalse $dst\\t# mask all (sve) ($2)\" %}\n+  format %{ \"sve_ptrue\/sve_pfalse $dst\\t# mask all (sve) ($2)\" %}\n@@ -3209,2 +3116,1 @@\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-                           Matcher::vector_length(this));\n+      __ sve_gen_mask_imm(as_PRegister($dst$$reg), bt, Matcher::vector_length(this));\n@@ -3213,1 +3119,1 @@\n-  ins_pipe(pipe_slow);\n+  ins_pipe(pipe_class_default);\n@@ -3215,1 +3121,1 @@\n-\n+dnl\n@@ -3218,1 +3124,1 @@\n-  predicate(UseSVE > 0);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n@@ -3221,1 +3127,1 @@\n-  ins_cost(3 * SVE_COST);\n+  ins_cost(2 * SVE_COST);\n@@ -3223,1 +3129,0 @@\n-            \"sve_ptrue $dst, vector_length\\n\\t\"\n@@ -3226,0 +3131,1 @@\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -3228,1 +3134,0 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n@@ -3230,7 +3135,20 @@\n-    if (length_in_bytes < MaxVectorSize) {\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), size, Matcher::vector_length(this));\n-      __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n-                 as_PRegister($dst$$reg), as_FloatRegister($tmp$$reg), 0);\n-    } else {\n-      __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n-    }\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size, ptrue, as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+define(`MASKALL_PREDICATE', `\n+instruct vmaskAll$1_masked(pRegGov dst, ifelse($1, `I', iRegIorL2I, iRegL) src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src pg));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(2 * SVE_COST);\n+  format %{ \"sve_dup $tmp, $src\\n\\t\"\n+            \"sve_cmpne $dst, $pg, $dst, $tmp, 0\\t# mask all (sve) ($2)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup(as_FloatRegister($tmp$$reg), size, as_Register($src$$reg));\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n+               as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg), 0);\n@@ -3241,1 +3159,2 @@\n-\/\/ maskAll (full or partial predicate size)\n+\n+\/\/ maskAll\n@@ -3247,0 +3166,4 @@\n+\/\/ maskAll - predicated\n+MASKALL_PREDICATE(I, B\/H\/S)\n+MASKALL_PREDICATE(L, D)\n+\n@@ -3253,1 +3176,1 @@\n-  ins_cost(2 * SVE_COST);\n+  ins_cost(SVE_COST);\n@@ -3256,1 +3179,1 @@\n-    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(Matcher::vector_length_in_bytes(this) == MaxVectorSize, \"invalid vector length\");\n@@ -3258,9 +3181,2 @@\n-    if (length_in_bytes == MaxVectorSize) {\n-      __ sve_compare(as_PRegister($dst$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n-                     as_FloatRegister($src2$$reg), (int)$cond$$constant);\n-    } else {\n-      __ sve_ptrue_lanecnt(as_PRegister($dst$$reg), __ elemType_to_regVariant(bt),\n-                           Matcher::vector_length(this));\n-      __ sve_compare(as_PRegister($dst$$reg), bt, as_PRegister($dst$$reg), as_FloatRegister($src1$$reg),\n-                     as_FloatRegister($src2$$reg), (int)$cond$$constant);\n-    }\n+    __ sve_compare(as_PRegister($dst$$reg), bt, ptrue, as_FloatRegister($src1$$reg),\n+                   as_FloatRegister($src2$$reg), (int)$cond$$constant);\n@@ -3288,1 +3204,1 @@\n-  predicate(UseSVE > 0 &&\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n@@ -3302,1 +3218,2 @@\n-  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() != T_BYTE);\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            n->bottom_type()->is_vect()->element_basic_type() != T_BYTE);\n@@ -3316,0 +3233,65 @@\n+instruct vloadmaskB_masked(pRegGov dst, vReg src, pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->bottom_type()->is_vect()->element_basic_type() == T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vloadmaskB $dst, $pg, $src\\t# vector load mask (sve) (B)\" %}\n+  ins_encode %{\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), __ B,\n+               as_PRegister($pg$$reg), as_FloatRegister($src$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_extend_masked(pRegGov dst, vReg src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && n->bottom_type()->is_vect()->element_basic_type() != T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(TEMP tmp, KILL cr);\n+  ins_cost(3 * SVE_COST);\n+  format %{ \"vloadmask $dst, $pg, $src\\t# vector load mask (sve) (H\/S\/D)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_vector_extend(as_FloatRegister($tmp$$reg), size, as_FloatRegister($src$$reg), __ B);\n+    __ sve_cmp(Assembler::NE, as_PRegister($dst$$reg), size,\n+               as_PRegister($pg$$reg), as_FloatRegister($tmp$$reg), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl VMASK_GEN($1,        $2,       $3,        $4  )\n+dnl VMASK_GEN(insn_name, src_type, src_match, insn)\n+define(`VMASK_GEN', `\n+instruct $1(pRegGov pd, $2 src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen $3));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"$4 $pd, zr, $src\\t# vector mask gen (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ $4(as_PRegister($pd$$reg), size, zr, as_Register($src$$reg));\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}')dnl\n+dnl\n+\/\/ vector mask gen\n+VMASK_GEN(vmask_gen_I, iRegIorL2I, (ConvI2L src), sve_whilelow)\n+VMASK_GEN(vmask_gen_L, iRegL, src, sve_whilelo)\n+\n+instruct vmask_gen_imm(pRegGov pd, immL src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen src));\n+  effect(KILL cr);\n+  ins_cost(SVE_COST);\n+  format %{ \"vmask_gen_imm $pd, $src\\t# vector mask gen with imm (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_gen_mask_imm(as_PRegister($pd$$reg), bt, (uint) $src$$constant);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n@@ -3414,14 +3396,0 @@\n-instruct vmask_gen(pRegGov pg, iRegL len, rFlagsReg cr) %{\n-  predicate(UseSVE > 0);\n-  match(Set pg (VectorMaskGen len));\n-  effect(KILL cr);\n-  ins_cost(SVE_COST);\n-  format %{ \"sve_whilelo $pg, zr, $len\\t # sve\" %}\n-  ins_encode %{\n-    BasicType bt = Matcher::vector_element_basic_type(this);\n-    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n-    __ sve_whilelo(as_PRegister($pg$$reg), size, zr, as_Register($len$$reg));\n-  %}\n-  ins_pipe(pipe_slow);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":357,"deletions":389,"binary":false,"changes":746,"status":"modified"},{"patch":"@@ -3636,2 +3636,2 @@\n-\/\/ Predicate counted loop (SVE) (32-bit variants are not included)\n-#define INSN(NAME, decode)                                                \\\n+\/\/ SVE integer compare scalar count and limit\n+#define INSN(NAME, sf, op)                                                \\\n@@ -3642,8 +3642,15 @@\n-    zrf(Rm, 16), f(0, 15, 13), f(1, 12), f(decode >> 1, 11, 10),          \\\n-    zrf(Rn, 5), f(decode & 1, 4), prf(Pd, 0);                             \\\n-  }\n-\n-  INSN(sve_whilelt, 0b010);  \/\/ While incrementing signed scalar less than scalar\n-  INSN(sve_whilele, 0b011);  \/\/ While incrementing signed scalar less than or equal to scalar\n-  INSN(sve_whilelo, 0b110);  \/\/ While incrementing unsigned scalar lower than scalar\n-  INSN(sve_whilels, 0b111);  \/\/ While incrementing unsigned scalar lower than or the same as scalar\n+    zrf(Rm, 16), f(0, 15, 13), f(sf, 12), f(op >> 1, 11, 10),             \\\n+    zrf(Rn, 5), f(op & 1, 4), prf(Pd, 0);                                 \\\n+  }\n+  \/\/ While incrementing signed scalar less than scalar\n+  INSN(sve_whileltw, 0b0, 0b010);\n+  INSN(sve_whilelt,  0b1, 0b010);\n+  \/\/ While incrementing signed scalar less than or equal to scalar\n+  INSN(sve_whilelew, 0b0, 0b011);\n+  INSN(sve_whilele,  0b1, 0b011);\n+  \/\/ While incrementing unsigned scalar lower than scalar\n+  INSN(sve_whilelow, 0b0, 0b110);\n+  INSN(sve_whilelo,  0b1, 0b110);\n+  \/\/ While incrementing unsigned scalar lower than or the same as scalar\n+  INSN(sve_whilelsw, 0b0, 0b111);\n+  INSN(sve_whilels,  0b1, 0b111);\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":17,"deletions":10,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+#include \"opto\/matcher.hpp\"\n@@ -1341,3 +1342,14 @@\n-\/\/ Set elements of the dst predicate to true if the element number is\n-\/\/ in the range of [0, lane_cnt), or to false otherwise.\n-void C2_MacroAssembler::sve_ptrue_lanecnt(PRegister dst, SIMD_RegVariant size, int lane_cnt) {\n+\/\/ Set elements of the dst predicate to true for lanes in the range of [0, lane_cnt), or\n+\/\/ to false otherwise. The input \"lane_cnt\" should be smaller than or equal to the supported\n+\/\/ max vector length of the basic type. Clobbers: rscratch1 and the rFlagsReg.\n+void C2_MacroAssembler::sve_gen_mask_imm(PRegister dst, BasicType bt, uint32_t lane_cnt) {\n+  uint32_t max_vector_length = Matcher::max_vector_size(bt);\n+  assert(lane_cnt <= max_vector_length, \"unsupported input lane_cnt\");\n+\n+  \/\/ Set all elements to false if the input \"lane_cnt\" is zero.\n+  if (lane_cnt == 0) {\n+    sve_pfalse(dst);\n+    return;\n+  }\n+\n+  SIMD_RegVariant size = elemType_to_regVariant(bt);\n@@ -1345,0 +1357,8 @@\n+\n+  \/\/ Set all true if \"lane_cnt\" equals to the max lane count.\n+  if (lane_cnt == max_vector_length) {\n+    sve_ptrue(dst, size, \/* ALL *\/ 0b11111);\n+    return;\n+  }\n+\n+  \/\/ Fixed numbers for \"ptrue\".\n@@ -1346,28 +1366,40 @@\n-    case 1: \/* VL1 *\/\n-    case 2: \/* VL2 *\/\n-    case 3: \/* VL3 *\/\n-    case 4: \/* VL4 *\/\n-    case 5: \/* VL5 *\/\n-    case 6: \/* VL6 *\/\n-    case 7: \/* VL7 *\/\n-    case 8: \/* VL8 *\/\n-      sve_ptrue(dst, size, lane_cnt);\n-      break;\n-    case 16:\n-      sve_ptrue(dst, size, \/* VL16 *\/ 0b01001);\n-      break;\n-    case 32:\n-      sve_ptrue(dst, size, \/* VL32 *\/ 0b01010);\n-      break;\n-    case 64:\n-      sve_ptrue(dst, size, \/* VL64 *\/ 0b01011);\n-      break;\n-    case 128:\n-      sve_ptrue(dst, size, \/* VL128 *\/ 0b01100);\n-      break;\n-    case 256:\n-      sve_ptrue(dst, size, \/* VL256 *\/ 0b01101);\n-      break;\n-    default:\n-      assert(false, \"unsupported\");\n-      ShouldNotReachHere();\n+  case 1: \/* VL1 *\/\n+  case 2: \/* VL2 *\/\n+  case 3: \/* VL3 *\/\n+  case 4: \/* VL4 *\/\n+  case 5: \/* VL5 *\/\n+  case 6: \/* VL6 *\/\n+  case 7: \/* VL7 *\/\n+  case 8: \/* VL8 *\/\n+    sve_ptrue(dst, size, lane_cnt);\n+    return;\n+  case 16:\n+    sve_ptrue(dst, size, \/* VL16 *\/ 0b01001);\n+    return;\n+  case 32:\n+    sve_ptrue(dst, size, \/* VL32 *\/ 0b01010);\n+    return;\n+  case 64:\n+    sve_ptrue(dst, size, \/* VL64 *\/ 0b01011);\n+    return;\n+  case 128:\n+    sve_ptrue(dst, size, \/* VL128 *\/ 0b01100);\n+    return;\n+  case 256:\n+    sve_ptrue(dst, size, \/* VL256 *\/ 0b01101);\n+    return;\n+  default:\n+    break;\n+  }\n+\n+  \/\/ Special patterns for \"ptrue\".\n+  if (lane_cnt == round_down_power_of_2(max_vector_length)) {\n+    sve_ptrue(dst, size, \/* POW2 *\/ 0b00000);\n+  } else if (lane_cnt == max_vector_length - (max_vector_length % 4)) {\n+    sve_ptrue(dst, size, \/* MUL4 *\/ 0b11101);\n+  } else if (lane_cnt == max_vector_length - (max_vector_length % 3)) {\n+    sve_ptrue(dst, size, \/* MUL3 *\/ 0b11110);\n+  } else {\n+    \/\/ Encode to \"whilelow\" for the remaining cases.\n+    mov(rscratch1, lane_cnt);\n+    sve_whilelow(dst, size, zr, rscratch1);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":63,"deletions":31,"binary":false,"changes":94,"status":"modified"},{"patch":"@@ -96,3 +96,5 @@\n-  \/\/ Set elements of the dst predicate to true if the element number is\n-  \/\/ in the range of [0, lane_cnt), or to false otherwise.\n-  void sve_ptrue_lanecnt(PRegister dst, SIMD_RegVariant size, int lane_cnt);\n+  \/\/ Set elements of the dst predicate to true for lanes in the range of\n+  \/\/ [0, lane_cnt), or to false otherwise. The input \"lane_cnt\" should be\n+  \/\/ smaller than or equal to the supported max vector length of the basic\n+  \/\/ type. Clobbers: rscratch1 and the rFlagsReg.\n+  void sve_gen_mask_imm(PRegister dst, BasicType bt, uint32_t lane_cnt);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1003,0 +1003,4 @@\n+const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2183,0 +2183,4 @@\n+const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1836,0 +1836,4 @@\n+const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1523,0 +1523,4 @@\n+const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/s390\/s390.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2167,0 +2167,4 @@\n+const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+  return false;\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2255,1 +2255,0 @@\n-    case Op_LoadVectorMasked:\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -338,0 +338,2 @@\n+  static const bool vector_needs_partial_operations(Node* node, const TypeVect* vt);\n+\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -288,0 +288,2 @@\n+  ControlDependency control_dependency() {return _control_dependency; }\n+\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -727,1 +727,2 @@\n-          DEFINE_CLASS_ID(LoadVectorMasked, LoadVector, 1)\n+          DEFINE_CLASS_ID(LoadVectorGatherMasked, LoadVector, 1)\n+          DEFINE_CLASS_ID(LoadVectorMasked, LoadVector, 2)\n@@ -731,1 +732,2 @@\n-          DEFINE_CLASS_ID(StoreVectorMasked, StoreVector, 1)\n+          DEFINE_CLASS_ID(StoreVectorScatterMasked, StoreVector, 1)\n+          DEFINE_CLASS_ID(StoreVectorMasked, StoreVector, 2)\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -864,0 +864,56 @@\n+Node* VectorNode::try_to_gen_masked_vector(PhaseGVN* gvn, Node* node, const TypeVect* vt) {\n+  int vopc = node->Opcode();\n+  uint vlen = vt->length();\n+  BasicType bt = vt->element_basic_type();\n+\n+  \/\/ Predicated vectors do not need to add another mask input\n+  if (node->is_predicated_vector() || !Matcher::has_predicated_vectors() ||\n+      !Matcher::match_rule_supported_vector_masked(vopc, vlen, bt) ||\n+      !Matcher::match_rule_supported_vector(Op_VectorMaskGen, vlen, bt)) {\n+    return NULL;\n+  }\n+\n+  Node* mask = NULL;\n+  \/\/ Generate a vector mask for vector operation whose vector length is lower than the\n+  \/\/ hardware supported max vector length.\n+  if (vt->length_in_bytes() < (uint)MaxVectorSize) {\n+    Node* length = gvn->transform(new ConvI2LNode(gvn->makecon(TypeInt::make(vlen))));\n+    mask = gvn->transform(VectorMaskGenNode::make(length, bt, vlen));\n+  } else {\n+    return NULL;\n+  }\n+\n+  \/\/ Generate the related masked op for vector load\/store\/load_gather\/store_scatter.\n+  \/\/ Or append the mask to the vector op's input list by default.\n+  switch(vopc) {\n+  case Op_LoadVector:\n+    return new LoadVectorMaskedNode(node->in(0), node->in(1), node->in(2),\n+                                    node->as_LoadVector()->adr_type(), vt, mask,\n+                                    node->as_LoadVector()->control_dependency());\n+  case Op_LoadVectorGather:\n+    return new LoadVectorGatherMaskedNode(node->in(0), node->in(1), node->in(2),\n+                                          node->as_LoadVector()->adr_type(), vt,\n+                                          node->in(3), mask);\n+  case Op_StoreVector:\n+    return new StoreVectorMaskedNode(node->in(0), node->in(1), node->in(2), node->in(3),\n+                                     node->as_StoreVector()->adr_type(), mask);\n+  case Op_StoreVectorScatter:\n+    return new StoreVectorScatterMaskedNode(node->in(0), node->in(1), node->in(2),\n+                                            node->as_StoreVector()->adr_type(),\n+                                            node->in(3), node->in(4), mask);\n+  default:\n+    \/\/ Add the mask as an additional input to the original vector node by default.\n+    \/\/ This is used for almost all the vector nodes.\n+    node->add_req(mask);\n+    node->add_flag(Node::Flag_is_predicated_vector);\n+    return node;\n+  }\n+}\n+\n+Node* VectorNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  if (Matcher::vector_needs_partial_operations(this, vect_type())) {\n+    return try_to_gen_masked_vector(phase, this, vect_type());\n+  }\n+  return NULL;\n+}\n+\n@@ -934,0 +990,8 @@\n+Node* LoadVectorNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  const TypeVect* vt = vect_type();\n+  if (Matcher::vector_needs_partial_operations(this, vt)) {\n+    return VectorNode::try_to_gen_masked_vector(phase, this, vt);\n+  }\n+  return LoadNode::Ideal(phase, can_reshape);\n+}\n+\n@@ -935,3 +999,2 @@\n-StoreVectorNode* StoreVectorNode::make(int opc, Node* ctl, Node* mem,\n-                                       Node* adr, const TypePtr* atyp, Node* val,\n-                                       uint vlen) {\n+StoreVectorNode* StoreVectorNode::make(int opc, Node* ctl, Node* mem, Node* adr,\n+                                       const TypePtr* atyp, Node* val, uint vlen) {\n@@ -941,0 +1004,8 @@\n+Node* StoreVectorNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  const TypeVect* vt = vect_type();\n+  if (Matcher::vector_needs_partial_operations(this, vt)) {\n+    return VectorNode::try_to_gen_masked_vector(phase, this, vt);\n+  }\n+  return StoreNode::Ideal(phase, can_reshape);\n+}\n+\n@@ -957,1 +1028,1 @@\n-  return NULL;\n+  return LoadVectorNode::Ideal(phase, can_reshape);\n@@ -977,1 +1048,1 @@\n-  return NULL;\n+  return StoreVectorNode::Ideal(phase, can_reshape);\n@@ -1196,0 +1267,8 @@\n+Node* ReductionNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  const TypeVect* vt = vect_type();\n+  if (Matcher::vector_needs_partial_operations(this, vt)) {\n+    return VectorNode::try_to_gen_masked_vector(phase, this, vt);\n+  }\n+  return NULL;\n+}\n+\n@@ -1587,1 +1666,5 @@\n-  const TypeVectMask* t_vmask = TypeVectMask::make(mask_bt, max_vector);\n+  return make(length, mask_bt, max_vector);\n+}\n+\n+Node* VectorMaskGenNode::make(Node* length, BasicType mask_bt, int mask_len) {\n+  const TypeVectMask* t_vmask = TypeVectMask::make(mask_bt, mask_len);\n@@ -1607,0 +1690,8 @@\n+Node* VectorMaskOpNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  const TypeVect* vt = vect_type();\n+  if (Matcher::vector_needs_partial_operations(this, vt)) {\n+    return VectorNode::try_to_gen_masked_vector(phase, this, vt);\n+  }\n+  return NULL;\n+}\n+\n@@ -1614,1 +1705,0 @@\n-\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":97,"deletions":7,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -74,0 +74,2 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+\n@@ -110,0 +112,1 @@\n+  static Node* try_to_gen_masked_vector(PhaseGVN* gvn, Node* node, const TypeVect* vt);\n@@ -182,0 +185,1 @@\n+  const TypeVect* _vect_type;\n@@ -184,1 +188,2 @@\n-               _bottom_type(Type::get_const_basic_type(in1->bottom_type()->basic_type())) {}\n+               _bottom_type(Type::get_const_basic_type(in1->bottom_type()->basic_type())),\n+               _vect_type(in2->bottom_type()->is_vect()) {}\n@@ -195,0 +200,4 @@\n+  virtual const TypeVect* vect_type() const {\n+    return _vect_type;\n+  }\n+\n@@ -199,0 +208,2 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+\n@@ -826,0 +837,1 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -872,0 +884,1 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -873,3 +886,2 @@\n-  static StoreVectorNode* make(int opc, Node* ctl, Node* mem,\n-                               Node* adr, const TypePtr* atyp, Node* val,\n-                               uint vlen);\n+  static StoreVectorNode* make(int opc, Node* ctl, Node* mem, Node* adr,\n+                               const TypePtr* atyp, Node* val, uint vlen);\n@@ -908,1 +920,1 @@\n-    init_class_id(Class_StoreVector);\n+    init_class_id(Class_StoreVectorMasked);\n@@ -918,1 +930,1 @@\n-  Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -925,2 +937,3 @@\n-  LoadVectorMaskedNode(Node* c, Node* mem, Node* src, const TypePtr* at, const TypeVect* vt, Node* mask)\n-   : LoadVectorNode(c, mem, src, at, vt) {\n+  LoadVectorMaskedNode(Node* c, Node* mem, Node* src, const TypePtr* at, const TypeVect* vt, Node* mask,\n+                       ControlDependency control_dependency = LoadNode::DependsOnlyOnTest)\n+   : LoadVectorNode(c, mem, src, at, vt, control_dependency) {\n@@ -928,1 +941,1 @@\n-    init_class_id(Class_LoadVector);\n+    init_class_id(Class_LoadVectorMasked);\n@@ -938,1 +951,1 @@\n-  Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -947,1 +960,1 @@\n-    init_class_id(Class_LoadVector);\n+    init_class_id(Class_LoadVectorGatherMasked);\n@@ -967,1 +980,1 @@\n-     init_class_id(Class_StoreVector);\n+     init_class_id(Class_StoreVectorScatterMasked);\n@@ -1004,0 +1017,1 @@\n+  static Node* make(Node* length, BasicType vmask_bt, int vmask_len);\n@@ -1008,0 +1022,3 @@\n+ private:\n+  int _mopc;\n+  const TypeVect* _vect_type;\n@@ -1010,2 +1027,2 @@\n-    TypeNode(ty, 2), _mopc(mopc) {\n-    assert(Matcher::has_predicated_vectors() || mask->bottom_type()->is_vect()->element_basic_type() == T_BOOLEAN, \"\");\n+    TypeNode(ty, 2), _mopc(mopc), _vect_type(mask->bottom_type()->is_vect()) {\n+    assert(Matcher::has_predicated_vectors() || _vect_type->element_basic_type() == T_BOOLEAN, \"\");\n@@ -1015,0 +1032,1 @@\n+  virtual const TypeVect* vect_type() { return _vect_type; }\n@@ -1018,0 +1036,1 @@\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n@@ -1020,3 +1039,0 @@\n-\n-  private:\n-    int _mopc;\n@@ -1061,1 +1077,1 @@\n-  Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":34,"deletions":18,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -1650,171 +1650,175 @@\n-                        [\"cpy\",     \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n-                        [\"cpy\",     \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n-                        [\"cpy\",     \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n-                        [\"cpy\",     \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n-                        [\"cpy\",     \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n-                        [\"cpy\",     \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n-                        [\"cpy\",     \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n-                        [\"inc\",     \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n-                        [\"dec\",     \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n-                        [\"lsl\",     \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n-                        [\"lsl\",     \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n-                        [\"lsl\",     \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n-                        [\"lsl\",     \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n-                        [\"lsr\",     \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n-                        [\"asr\",     \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n-                        [\"lsr\",     \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n-                        [\"asr\",     \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n-                        [\"lsl\",     \"__ sve_lsl(z0, __ B, p0, 0);\",                       \"lsl\\tz0.b, p0\/m, z0.b, #0\"],\n-                        [\"lsl\",     \"__ sve_lsl(z0, __ B, p0, 5);\",                       \"lsl\\tz0.b, p0\/m, z0.b, #5\"],\n-                        [\"lsl\",     \"__ sve_lsl(z1, __ H, p1, 15);\",                      \"lsl\\tz1.h, p1\/m, z1.h, #15\"],\n-                        [\"lsl\",     \"__ sve_lsl(z2, __ S, p2, 31);\",                      \"lsl\\tz2.s, p2\/m, z2.s, #31\"],\n-                        [\"lsl\",     \"__ sve_lsl(z3, __ D, p3, 63);\",                      \"lsl\\tz3.d, p3\/m, z3.d, #63\"],\n-                        [\"lsr\",     \"__ sve_lsr(z0, __ B, p0, 1);\",                       \"lsr\\tz0.b, p0\/m, z0.b, #1\"],\n-                        [\"lsr\",     \"__ sve_lsr(z0, __ B, p0, 8);\",                       \"lsr\\tz0.b, p0\/m, z0.b, #8\"],\n-                        [\"lsr\",     \"__ sve_lsr(z1, __ H, p1, 15);\",                      \"lsr\\tz1.h, p1\/m, z1.h, #15\"],\n-                        [\"lsr\",     \"__ sve_lsr(z2, __ S, p2, 7);\",                       \"lsr\\tz2.s, p2\/m, z2.s, #7\"],\n-                        [\"lsr\",     \"__ sve_lsr(z2, __ S, p2, 31);\",                      \"lsr\\tz2.s, p2\/m, z2.s, #31\"],\n-                        [\"lsr\",     \"__ sve_lsr(z3, __ D, p3, 63);\",                      \"lsr\\tz3.d, p3\/m, z3.d, #63\"],\n-                        [\"asr\",     \"__ sve_asr(z0, __ B, p0, 1);\",                       \"asr\\tz0.b, p0\/m, z0.b, #1\"],\n-                        [\"asr\",     \"__ sve_asr(z0, __ B, p0, 7);\",                       \"asr\\tz0.b, p0\/m, z0.b, #7\"],\n-                        [\"asr\",     \"__ sve_asr(z1, __ H, p1, 5);\",                       \"asr\\tz1.h, p1\/m, z1.h, #5\"],\n-                        [\"asr\",     \"__ sve_asr(z1, __ H, p1, 15);\",                      \"asr\\tz1.h, p1\/m, z1.h, #15\"],\n-                        [\"asr\",     \"__ sve_asr(z2, __ S, p2, 31);\",                      \"asr\\tz2.s, p2\/m, z2.s, #31\"],\n-                        [\"asr\",     \"__ sve_asr(z3, __ D, p3, 63);\",                      \"asr\\tz3.d, p3\/m, z3.d, #63\"],\n-                        [\"addvl\",   \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n-                        [\"addpl\",   \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n-                        [\"cntp\",    \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n-                        [\"dup\",     \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n-                        [\"dup\",     \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n-                        [\"dup\",     \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n-                        [\"dup\",     \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n-                        [\"dup\",     \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n-                        [\"dup\",     \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n-                        [\"ld1b\",    \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n-                        [\"ld1b\",    \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n-                        [\"ld1b\",    \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n-                        [\"ld1b\",    \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n-                        [\"ld1h\",    \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n-                        [\"ld1w\",    \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n-                        [\"ld1b\",    \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n-                        [\"ld1w\",    \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n-                        [\"ld1d\",    \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n-                        [\"st1b\",    \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n-                        [\"st1b\",    \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n-                        [\"st1b\",    \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n-                        [\"st1b\",    \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n-                        [\"st1b\",    \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n-                        [\"st1w\",    \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n-                        [\"st1b\",    \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n-                        [\"st1h\",    \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n-                        [\"st1d\",    \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n-                        [\"ldr\",     \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n-                        [\"ldr\",     \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n-                        [\"str\",     \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n-                        [\"cntb\",    \"__ sve_cntb(r9);\",                                   \"cntb\\tx9\"],\n-                        [\"cnth\",    \"__ sve_cnth(r10);\",                                  \"cnth\\tx10\"],\n-                        [\"cntw\",    \"__ sve_cntw(r11);\",                                  \"cntw\\tx11\"],\n-                        [\"cntd\",    \"__ sve_cntd(r12);\",                                  \"cntd\\tx12\"],\n-                        [\"brka\",    \"__ sve_brka(p2, p0, p2, false);\",                    \"brka\\tp2.b, p0\/z, p2.b\"],\n-                        [\"brka\",    \"__ sve_brka(p1, p2, p3, true);\",                     \"brka\\tp1.b, p2\/m, p3.b\"],\n-                        [\"brkb\",    \"__ sve_brkb(p1, p2, p3, false);\",                    \"brkb\\tp1.b, p2\/z, p3.b\"],\n-                        [\"brkb\",    \"__ sve_brkb(p2, p3, p4, true);\",                     \"brkb\\tp2.b, p3\/m, p4.b\"],\n-                        [\"rev\",     \"__ sve_rev(p0, __ B, p1);\",                          \"rev\\tp0.b, p1.b\"],\n-                        [\"rev\",     \"__ sve_rev(p1, __ H, p2);\",                          \"rev\\tp1.h, p2.h\"],\n-                        [\"rev\",     \"__ sve_rev(p2, __ S, p3);\",                          \"rev\\tp2.s, p3.s\"],\n-                        [\"rev\",     \"__ sve_rev(p3, __ D, p4);\",                          \"rev\\tp3.d, p4.d\"],\n-                        [\"incp\",    \"__ sve_incp(r0, __ B, p2);\",                         \"incp\\tx0, p2.b\"],\n-                        [\"whilelt\", \"__ sve_whilelt(p0, __ B, r1, r28);\",                 \"whilelt\\tp0.b, x1, x28\"],\n-                        [\"whilele\", \"__ sve_whilele(p2, __ H, r11, r8);\",                 \"whilele\\tp2.h, x11, x8\"],\n-                        [\"whilelo\", \"__ sve_whilelo(p3, __ S, r7, r2);\",                  \"whilelo\\tp3.s, x7, x2\"],\n-                        [\"whilels\", \"__ sve_whilels(p4, __ D, r17, r10);\",                \"whilels\\tp4.d, x17, x10\"],\n-                        [\"sel\",     \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n-                        [\"sel\",     \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n-                        [\"cmpeq\",   \"__ sve_cmp(Assembler::EQ, p1, __ B, p0, z0, z1);\",   \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n-                        [\"cmpne\",   \"__ sve_cmp(Assembler::NE, p1, __ H, p0, z2, z3);\",   \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n-                        [\"cmpge\",   \"__ sve_cmp(Assembler::GE, p1, __ S, p2, z4, z5);\",   \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n-                        [\"cmpgt\",   \"__ sve_cmp(Assembler::GT, p1, __ D, p3, z6, z7);\",   \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n-                        [\"cmphi\",   \"__ sve_cmp(Assembler::HI, p1, __ S, p2, z4, z5);\",   \"cmphi\\tp1.s, p2\/z, z4.s, z5.s\"],\n-                        [\"cmphs\",   \"__ sve_cmp(Assembler::HS, p1, __ D, p3, z6, z7);\",   \"cmphs\\tp1.d, p3\/z, z6.d, z7.d\"],\n-                        [\"cmpeq\",   \"__ sve_cmp(Assembler::EQ, p1, __ B, p4, z0, 15);\",   \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n-                        [\"cmpne\",   \"__ sve_cmp(Assembler::NE, p1, __ H, p0, z2, -16);\",  \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n-                        [\"cmple\",   \"__ sve_cmp(Assembler::LE, p1, __ S, p1, z4, 0);\",    \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n-                        [\"cmplt\",   \"__ sve_cmp(Assembler::LT, p1, __ D, p2, z6, -1);\",   \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n-                        [\"cmpge\",   \"__ sve_cmp(Assembler::GE, p1, __ S, p3, z4, 5);\",    \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n-                        [\"cmpgt\",   \"__ sve_cmp(Assembler::GT, p1, __ B, p4, z6, -2);\",   \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n-                        [\"fcmeq\",   \"__ sve_fcm(Assembler::EQ, p1, __ S, p0, z0, z1);\",   \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n-                        [\"fcmne\",   \"__ sve_fcm(Assembler::NE, p1, __ D, p0, z2, z3);\",   \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n-                        [\"fcmgt\",   \"__ sve_fcm(Assembler::GT, p1, __ S, p2, z4, z5);\",   \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n-                        [\"fcmge\",   \"__ sve_fcm(Assembler::GE, p1, __ D, p3, z6, z7);\",   \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n-                        [\"uunpkhi\", \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n-                        [\"uunpklo\", \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n-                        [\"sunpkhi\", \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n-                        [\"sunpklo\", \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z1, __ D, p0, z0, __ S);\",              \"scvtf\\tz1.d, p0\/m, z0.s\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z3, __ D, p1, z2, __ D);\",              \"scvtf\\tz3.d, p1\/m, z2.d\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p2, z1, __ D);\",              \"scvtf\\tz6.s, p2\/m, z1.d\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z6, __ S, p3, z1, __ S);\",              \"scvtf\\tz6.s, p3\/m, z1.s\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ S);\",              \"scvtf\\tz6.h, p3\/m, z1.s\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ D);\",              \"scvtf\\tz6.h, p3\/m, z1.d\"],\n-                        [\"scvtf\",   \"__ sve_scvtf(z6, __ H, p3, z1, __ H);\",              \"scvtf\\tz6.h, p3\/m, z1.h\"],\n-                        [\"fcvt\",    \"__ sve_fcvt(z5, __ D, p3, z4, __ S);\",               \"fcvt\\tz5.d, p3\/m, z4.s\"],\n-                        [\"fcvt\",    \"__ sve_fcvt(z1, __ S, p3, z0, __ D);\",               \"fcvt\\tz1.s, p3\/m, z0.d\"],\n-                        [\"fcvtzs\",  \"__ sve_fcvtzs(z19, __ D, p2, z1, __ D);\",            \"fcvtzs\\tz19.d, p2\/m, z1.d\"],\n-                        [\"fcvtzs\",  \"__ sve_fcvtzs(z9, __ S, p1, z8, __ S);\",             \"fcvtzs\\tz9.s, p1\/m, z8.s\"],\n-                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p2, z0, __ D);\",             \"fcvtzs\\tz1.s, p2\/m, z0.d\"],\n-                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ D, p3, z0, __ S);\",             \"fcvtzs\\tz1.d, p3\/m, z0.s\"],\n-                        [\"fcvtzs\",  \"__ sve_fcvtzs(z1, __ S, p4, z18, __ H);\",            \"fcvtzs\\tz1.s, p4\/m, z18.h\"],\n-                        [\"lasta\",   \"__ sve_lasta(r0, __ B, p0, z15);\",                   \"lasta\\tw0, p0, z15.b\"],\n-                        [\"lastb\",   \"__ sve_lastb(r1, __ B, p1, z16);\",                   \"lastb\\tw1, p1, z16.b\"],\n-                        [\"lasta\",   \"__ sve_lasta(v0, __ B, p0, z15);\",                   \"lasta\\tb0, p0, z15.b\"],\n-                        [\"lastb\",   \"__ sve_lastb(v1, __ B, p1, z16);\",                   \"lastb\\tb1, p1, z16.b\"],\n-                        [\"index\",   \"__ sve_index(z6, __ S, 1, 1);\",                      \"index\\tz6.s, #1, #1\"],\n-                        [\"index\",   \"__ sve_index(z6, __ B, r5, 2);\",                     \"index\\tz6.b, w5, #2\"],\n-                        [\"index\",   \"__ sve_index(z6, __ H, r5, 3);\",                     \"index\\tz6.h, w5, #3\"],\n-                        [\"index\",   \"__ sve_index(z6, __ S, r5, 4);\",                     \"index\\tz6.s, w5, #4\"],\n-                        [\"index\",   \"__ sve_index(z7, __ D, r5, 5);\",                     \"index\\tz7.d, x5, #5\"],\n-                        [\"cpy\",     \"__ sve_cpy(z7, __ H, p3, r5);\",                      \"cpy\\tz7.h, p3\/m, w5\"],\n-                        [\"tbl\",     \"__ sve_tbl(z16, __ S, z17, z18);\",                   \"tbl\\tz16.s, {z17.s}, z18.s\"],\n-                        [\"ld1w\",    \"__ sve_ld1w_gather(z15, p0, r5, z16);\",              \"ld1w\\t{z15.s}, p0\/z, [x5, z16.s, uxtw #2]\"],\n-                        [\"ld1d\",    \"__ sve_ld1d_gather(z15, p0, r5, z16);\",              \"ld1d\\t{z15.d}, p0\/z, [x5, z16.d, uxtw #3]\"],\n-                        [\"st1w\",    \"__ sve_st1w_scatter(z15, p0, r5, z16);\",             \"st1w\\t{z15.s}, p0, [x5, z16.s, uxtw #2]\"],\n-                        [\"st1d\",    \"__ sve_st1d_scatter(z15, p0, r5, z16);\",             \"st1d\\t{z15.d}, p0, [x5, z16.d, uxtw #3]\"],\n-                        [\"and\",     \"__ sve_and(p0, p1, p2, p3);\",                        \"and\\tp0.b, p1\/z, p2.b, p3.b\"],\n-                        [\"ands\",    \"__ sve_ands(p4, p5, p6, p0);\",                       \"ands\\tp4.b, p5\/z, p6.b, p0.b\"],\n-                        [\"eor\",     \"__ sve_eor(p0, p1, p2, p3);\",                        \"eor\\tp0.b, p1\/z, p2.b, p3.b\"],\n-                        [\"eors\",    \"__ sve_eors(p5, p6, p0, p1);\",                       \"eors\\tp5.b, p6\/z, p0.b, p1.b\"],\n-                        [\"orr\",     \"__ sve_orr(p0, p1, p2, p3);\",                        \"orr\\tp0.b, p1\/z, p2.b, p3.b\"],\n-                        [\"orrs\",    \"__ sve_orrs(p9, p1, p4, p5);\",                       \"orrs\\tp9.b, p1\/z, p4.b, p5.b\"],\n-                        [\"bic\",     \"__ sve_bic(p10, p7, p9, p11);\",                      \"bic\\tp10.b, p7\/z, p9.b, p11.b\"],\n-                        [\"ptest\",   \"__ sve_ptest(p7, p1);\",                              \"ptest\\tp7, p1.b\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p1, __ B);\",                            \"ptrue\\tp1.b\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p1, __ B, 0b00001);\",                   \"ptrue\\tp1.b, vl1\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p1, __ B, 0b00101);\",                   \"ptrue\\tp1.b, vl5\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p1, __ B, 0b01001);\",                   \"ptrue\\tp1.b, vl16\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p1, __ B, 0b01101);\",                   \"ptrue\\tp1.b, vl256\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p2, __ H);\",                            \"ptrue\\tp2.h\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p2, __ H, 0b00010);\",                   \"ptrue\\tp2.h, vl2\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p2, __ H, 0b00110);\",                   \"ptrue\\tp2.h, vl6\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p2, __ H, 0b01010);\",                   \"ptrue\\tp2.h, vl32\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p3, __ S);\",                            \"ptrue\\tp3.s\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p3, __ S, 0b00011);\",                   \"ptrue\\tp3.s, vl3\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p3, __ S, 0b00111);\",                   \"ptrue\\tp3.s, vl7\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p3, __ S, 0b01011);\",                   \"ptrue\\tp3.s, vl64\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p4, __ D);\",                            \"ptrue\\tp4.d\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p4, __ D, 0b00100);\",                   \"ptrue\\tp4.d, vl4\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p4, __ D, 0b01000);\",                   \"ptrue\\tp4.d, vl8\"],\n-                        [\"ptrue\",   \"__ sve_ptrue(p4, __ D, 0b01100);\",                   \"ptrue\\tp4.d, vl128\"],\n-                        [\"pfalse\",  \"__ sve_pfalse(p7);\",                                 \"pfalse\\tp7.b\"],\n-                        [\"uzp1\",    \"__ sve_uzp1(p0, __ B, p0, p1);\",                     \"uzp1\\tp0.b, p0.b, p1.b\"],\n-                        [\"uzp1\",    \"__ sve_uzp1(p0, __ H, p0, p1);\",                     \"uzp1\\tp0.h, p0.h, p1.h\"],\n-                        [\"uzp1\",    \"__ sve_uzp1(p0, __ S, p0, p1);\",                     \"uzp1\\tp0.s, p0.s, p1.s\"],\n-                        [\"uzp1\",    \"__ sve_uzp1(p0, __ D, p0, p1);\",                     \"uzp1\\tp0.d, p0.d, p1.d\"],\n-                        [\"uzp2\",    \"__ sve_uzp2(p0, __ B, p0, p1);\",                     \"uzp2\\tp0.b, p0.b, p1.b\"],\n-                        [\"uzp2\",    \"__ sve_uzp2(p0, __ H, p0, p1);\",                     \"uzp2\\tp0.h, p0.h, p1.h\"],\n-                        [\"uzp2\",    \"__ sve_uzp2(p0, __ S, p0, p1);\",                     \"uzp2\\tp0.s, p0.s, p1.s\"],\n-                        [\"uzp2\",    \"__ sve_uzp2(p0, __ D, p0, p1);\",                     \"uzp2\\tp0.d, p0.d, p1.d\"],\n-                        [\"punpklo\", \"__ sve_punpklo(p1, p0);\",                            \"punpklo\\tp1.h, p0.b\"],\n-                        [\"punpkhi\", \"__ sve_punpkhi(p1, p0);\",                            \"punpkhi\\tp1.h, p0.b\"],\n-                        [\"compact\", \"__ sve_compact(z16, __ S, z16, p1);\",                \"compact\\tz16.s, p1, z16.s\"],\n-                        [\"compact\", \"__ sve_compact(z16, __ D, z16, p1);\",                \"compact\\tz16.d, p1, z16.d\"],\n-                        [\"ext\",     \"__ sve_ext(z17, z16, 63);\",                          \"ext\\tz17.b, z17.b, z16.b, #63\"],\n+                        [\"cpy\",      \"__ sve_cpy(z0, __ S, p0, v1);\",                      \"mov\\tz0.s, p0\/m, s1\"],\n+                        [\"cpy\",      \"__ sve_cpy(z0, __ B, p0, 127, true);\",               \"mov\\tz0.b, p0\/m, 127\"],\n+                        [\"cpy\",      \"__ sve_cpy(z1, __ H, p0, -128, true);\",              \"mov\\tz1.h, p0\/m, -128\"],\n+                        [\"cpy\",      \"__ sve_cpy(z2, __ S, p0, 32512, true);\",             \"mov\\tz2.s, p0\/m, 32512\"],\n+                        [\"cpy\",      \"__ sve_cpy(z5, __ D, p0, -32768, false);\",           \"mov\\tz5.d, p0\/z, -32768\"],\n+                        [\"cpy\",      \"__ sve_cpy(z10, __ B, p0, -1, false);\",              \"mov\\tz10.b, p0\/z, -1\"],\n+                        [\"cpy\",      \"__ sve_cpy(z11, __ S, p0, -1, false);\",              \"mov\\tz11.s, p0\/z, -1\"],\n+                        [\"inc\",      \"__ sve_inc(r0, __ S);\",                              \"incw\\tx0\"],\n+                        [\"dec\",      \"__ sve_dec(r1, __ H);\",                              \"dech\\tx1\"],\n+                        [\"lsl\",      \"__ sve_lsl(z0, __ B, z1, 7);\",                       \"lsl\\tz0.b, z1.b, #7\"],\n+                        [\"lsl\",      \"__ sve_lsl(z21, __ H, z1, 15);\",                     \"lsl\\tz21.h, z1.h, #15\"],\n+                        [\"lsl\",      \"__ sve_lsl(z0, __ S, z1, 31);\",                      \"lsl\\tz0.s, z1.s, #31\"],\n+                        [\"lsl\",      \"__ sve_lsl(z0, __ D, z1, 63);\",                      \"lsl\\tz0.d, z1.d, #63\"],\n+                        [\"lsr\",      \"__ sve_lsr(z0, __ B, z1, 7);\",                       \"lsr\\tz0.b, z1.b, #7\"],\n+                        [\"asr\",      \"__ sve_asr(z0, __ H, z11, 15);\",                     \"asr\\tz0.h, z11.h, #15\"],\n+                        [\"lsr\",      \"__ sve_lsr(z30, __ S, z1, 31);\",                     \"lsr\\tz30.s, z1.s, #31\"],\n+                        [\"asr\",      \"__ sve_asr(z0, __ D, z1, 63);\",                      \"asr\\tz0.d, z1.d, #63\"],\n+                        [\"lsl\",      \"__ sve_lsl(z0, __ B, p0, 0);\",                       \"lsl\\tz0.b, p0\/m, z0.b, #0\"],\n+                        [\"lsl\",      \"__ sve_lsl(z0, __ B, p0, 5);\",                       \"lsl\\tz0.b, p0\/m, z0.b, #5\"],\n+                        [\"lsl\",      \"__ sve_lsl(z1, __ H, p1, 15);\",                      \"lsl\\tz1.h, p1\/m, z1.h, #15\"],\n+                        [\"lsl\",      \"__ sve_lsl(z2, __ S, p2, 31);\",                      \"lsl\\tz2.s, p2\/m, z2.s, #31\"],\n+                        [\"lsl\",      \"__ sve_lsl(z3, __ D, p3, 63);\",                      \"lsl\\tz3.d, p3\/m, z3.d, #63\"],\n+                        [\"lsr\",      \"__ sve_lsr(z0, __ B, p0, 1);\",                       \"lsr\\tz0.b, p0\/m, z0.b, #1\"],\n+                        [\"lsr\",      \"__ sve_lsr(z0, __ B, p0, 8);\",                       \"lsr\\tz0.b, p0\/m, z0.b, #8\"],\n+                        [\"lsr\",      \"__ sve_lsr(z1, __ H, p1, 15);\",                      \"lsr\\tz1.h, p1\/m, z1.h, #15\"],\n+                        [\"lsr\",      \"__ sve_lsr(z2, __ S, p2, 7);\",                       \"lsr\\tz2.s, p2\/m, z2.s, #7\"],\n+                        [\"lsr\",      \"__ sve_lsr(z2, __ S, p2, 31);\",                      \"lsr\\tz2.s, p2\/m, z2.s, #31\"],\n+                        [\"lsr\",      \"__ sve_lsr(z3, __ D, p3, 63);\",                      \"lsr\\tz3.d, p3\/m, z3.d, #63\"],\n+                        [\"asr\",      \"__ sve_asr(z0, __ B, p0, 1);\",                       \"asr\\tz0.b, p0\/m, z0.b, #1\"],\n+                        [\"asr\",      \"__ sve_asr(z0, __ B, p0, 7);\",                       \"asr\\tz0.b, p0\/m, z0.b, #7\"],\n+                        [\"asr\",      \"__ sve_asr(z1, __ H, p1, 5);\",                       \"asr\\tz1.h, p1\/m, z1.h, #5\"],\n+                        [\"asr\",      \"__ sve_asr(z1, __ H, p1, 15);\",                      \"asr\\tz1.h, p1\/m, z1.h, #15\"],\n+                        [\"asr\",      \"__ sve_asr(z2, __ S, p2, 31);\",                      \"asr\\tz2.s, p2\/m, z2.s, #31\"],\n+                        [\"asr\",      \"__ sve_asr(z3, __ D, p3, 63);\",                      \"asr\\tz3.d, p3\/m, z3.d, #63\"],\n+                        [\"addvl\",    \"__ sve_addvl(sp, r0, 31);\",                          \"addvl\\tsp, x0, #31\"],\n+                        [\"addpl\",    \"__ sve_addpl(r1, sp, -32);\",                         \"addpl\\tx1, sp, -32\"],\n+                        [\"cntp\",     \"__ sve_cntp(r8, __ B, p0, p1);\",                     \"cntp\\tx8, p0, p1.b\"],\n+                        [\"dup\",      \"__ sve_dup(z0, __ B, 127);\",                         \"dup\\tz0.b, 127\"],\n+                        [\"dup\",      \"__ sve_dup(z1, __ H, -128);\",                        \"dup\\tz1.h, -128\"],\n+                        [\"dup\",      \"__ sve_dup(z2, __ S, 32512);\",                       \"dup\\tz2.s, 32512\"],\n+                        [\"dup\",      \"__ sve_dup(z7, __ D, -32768);\",                      \"dup\\tz7.d, -32768\"],\n+                        [\"dup\",      \"__ sve_dup(z10, __ B, -1);\",                         \"dup\\tz10.b, -1\"],\n+                        [\"dup\",      \"__ sve_dup(z11, __ S, -1);\",                         \"dup\\tz11.s, -1\"],\n+                        [\"ld1b\",     \"__ sve_ld1b(z0, __ B, p0, Address(sp));\",            \"ld1b\\t{z0.b}, p0\/z, [sp]\"],\n+                        [\"ld1b\",     \"__ sve_ld1b(z0, __ H, p1, Address(sp));\",            \"ld1b\\t{z0.h}, p1\/z, [sp]\"],\n+                        [\"ld1b\",     \"__ sve_ld1b(z0, __ S, p2, Address(sp, r8));\",        \"ld1b\\t{z0.s}, p2\/z, [sp, x8]\"],\n+                        [\"ld1b\",     \"__ sve_ld1b(z0, __ D, p3, Address(sp, 7));\",         \"ld1b\\t{z0.d}, p3\/z, [sp, #7, MUL VL]\"],\n+                        [\"ld1h\",     \"__ sve_ld1h(z10, __ H, p1, Address(sp, -8));\",       \"ld1h\\t{z10.h}, p1\/z, [sp, #-8, MUL VL]\"],\n+                        [\"ld1w\",     \"__ sve_ld1w(z20, __ S, p2, Address(r0, 7));\",        \"ld1w\\t{z20.s}, p2\/z, [x0, #7, MUL VL]\"],\n+                        [\"ld1b\",     \"__ sve_ld1b(z30, __ B, p3, Address(sp, r8));\",       \"ld1b\\t{z30.b}, p3\/z, [sp, x8]\"],\n+                        [\"ld1w\",     \"__ sve_ld1w(z0, __ S, p4, Address(sp, r28));\",       \"ld1w\\t{z0.s}, p4\/z, [sp, x28, LSL #2]\"],\n+                        [\"ld1d\",     \"__ sve_ld1d(z11, __ D, p5, Address(r0, r1));\",       \"ld1d\\t{z11.d}, p5\/z, [x0, x1, LSL #3]\"],\n+                        [\"st1b\",     \"__ sve_st1b(z22, __ B, p6, Address(sp));\",           \"st1b\\t{z22.b}, p6, [sp]\"],\n+                        [\"st1b\",     \"__ sve_st1b(z31, __ B, p7, Address(sp, -8));\",       \"st1b\\t{z31.b}, p7, [sp, #-8, MUL VL]\"],\n+                        [\"st1b\",     \"__ sve_st1b(z0, __ H, p1, Address(sp));\",            \"st1b\\t{z0.h}, p1, [sp]\"],\n+                        [\"st1b\",     \"__ sve_st1b(z0, __ S, p2, Address(sp, r8));\",        \"st1b\\t{z0.s}, p2, [sp, x8]\"],\n+                        [\"st1b\",     \"__ sve_st1b(z0, __ D, p3, Address(sp));\",            \"st1b\\t{z0.d}, p3, [sp]\"],\n+                        [\"st1w\",     \"__ sve_st1w(z0, __ S, p1, Address(r0, 7));\",         \"st1w\\t{z0.s}, p1, [x0, #7, MUL VL]\"],\n+                        [\"st1b\",     \"__ sve_st1b(z0, __ B, p2, Address(sp, r1));\",        \"st1b\\t{z0.b}, p2, [sp, x1]\"],\n+                        [\"st1h\",     \"__ sve_st1h(z0, __ H, p3, Address(sp, r8));\",        \"st1h\\t{z0.h}, p3, [sp, x8, LSL #1]\"],\n+                        [\"st1d\",     \"__ sve_st1d(z0, __ D, p4, Address(r0, r17));\",       \"st1d\\t{z0.d}, p4, [x0, x17, LSL #3]\"],\n+                        [\"ldr\",      \"__ sve_ldr(z0, Address(sp));\",                       \"ldr\\tz0, [sp]\"],\n+                        [\"ldr\",      \"__ sve_ldr(z31, Address(sp, -256));\",                \"ldr\\tz31, [sp, #-256, MUL VL]\"],\n+                        [\"str\",      \"__ sve_str(z8, Address(r8, 255));\",                  \"str\\tz8, [x8, #255, MUL VL]\"],\n+                        [\"cntb\",     \"__ sve_cntb(r9);\",                                   \"cntb\\tx9\"],\n+                        [\"cnth\",     \"__ sve_cnth(r10);\",                                  \"cnth\\tx10\"],\n+                        [\"cntw\",     \"__ sve_cntw(r11);\",                                  \"cntw\\tx11\"],\n+                        [\"cntd\",     \"__ sve_cntd(r12);\",                                  \"cntd\\tx12\"],\n+                        [\"brka\",     \"__ sve_brka(p2, p0, p2, false);\",                    \"brka\\tp2.b, p0\/z, p2.b\"],\n+                        [\"brka\",     \"__ sve_brka(p1, p2, p3, true);\",                     \"brka\\tp1.b, p2\/m, p3.b\"],\n+                        [\"brkb\",     \"__ sve_brkb(p1, p2, p3, false);\",                    \"brkb\\tp1.b, p2\/z, p3.b\"],\n+                        [\"brkb\",     \"__ sve_brkb(p2, p3, p4, true);\",                     \"brkb\\tp2.b, p3\/m, p4.b\"],\n+                        [\"rev\",      \"__ sve_rev(p0, __ B, p1);\",                          \"rev\\tp0.b, p1.b\"],\n+                        [\"rev\",      \"__ sve_rev(p1, __ H, p2);\",                          \"rev\\tp1.h, p2.h\"],\n+                        [\"rev\",      \"__ sve_rev(p2, __ S, p3);\",                          \"rev\\tp2.s, p3.s\"],\n+                        [\"rev\",      \"__ sve_rev(p3, __ D, p4);\",                          \"rev\\tp3.d, p4.d\"],\n+                        [\"incp\",     \"__ sve_incp(r0, __ B, p2);\",                         \"incp\\tx0, p2.b\"],\n+                        [\"whilelt\",  \"__ sve_whilelt(p0, __ B, r1, r28);\",                 \"whilelt\\tp0.b, x1, x28\"],\n+                        [\"whilele\",  \"__ sve_whilele(p2, __ H, r11, r8);\",                 \"whilele\\tp2.h, x11, x8\"],\n+                        [\"whilelo\",  \"__ sve_whilelo(p3, __ S, r7, r2);\",                  \"whilelo\\tp3.s, x7, x2\"],\n+                        [\"whilels\",  \"__ sve_whilels(p4, __ D, r17, r10);\",                \"whilels\\tp4.d, x17, x10\"],\n+                        [\"whileltw\", \"__ sve_whileltw(p1, __ B, r1, r28);\",                \"whilelt\\tp1.b, w1, w28\"],\n+                        [\"whilelew\", \"__ sve_whilelew(p2, __ H, r11, r8);\",                \"whilele\\tp2.h, w11, w8\"],\n+                        [\"whilelow\", \"__ sve_whilelow(p3, __ S, r7, r2);\",                 \"whilelo\\tp3.s, w7, w2\"],\n+                        [\"whilelsw\", \"__ sve_whilelsw(p4, __ D, r17, r10);\",               \"whilels\\tp4.d, w17, w10\"],\n+                        [\"sel\",      \"__ sve_sel(z0, __ B, p0, z1, z2);\",                  \"sel\\tz0.b, p0, z1.b, z2.b\"],\n+                        [\"sel\",      \"__ sve_sel(z4, __ D, p0, z5, z6);\",                  \"sel\\tz4.d, p0, z5.d, z6.d\"],\n+                        [\"cmpeq\",    \"__ sve_cmp(Assembler::EQ, p1, __ B, p0, z0, z1);\",   \"cmpeq\\tp1.b, p0\/z, z0.b, z1.b\"],\n+                        [\"cmpne\",    \"__ sve_cmp(Assembler::NE, p1, __ H, p0, z2, z3);\",   \"cmpne\\tp1.h, p0\/z, z2.h, z3.h\"],\n+                        [\"cmpge\",    \"__ sve_cmp(Assembler::GE, p1, __ S, p2, z4, z5);\",   \"cmpge\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmpgt\",    \"__ sve_cmp(Assembler::GT, p1, __ D, p3, z6, z7);\",   \"cmpgt\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmphi\",    \"__ sve_cmp(Assembler::HI, p1, __ S, p2, z4, z5);\",   \"cmphi\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"cmphs\",    \"__ sve_cmp(Assembler::HS, p1, __ D, p3, z6, z7);\",   \"cmphs\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"cmpeq\",    \"__ sve_cmp(Assembler::EQ, p1, __ B, p4, z0, 15);\",   \"cmpeq\\tp1.b, p4\/z, z0.b, #15\"],\n+                        [\"cmpne\",    \"__ sve_cmp(Assembler::NE, p1, __ H, p0, z2, -16);\",  \"cmpne\\tp1.h, p0\/z, z2.h, #-16\"],\n+                        [\"cmple\",    \"__ sve_cmp(Assembler::LE, p1, __ S, p1, z4, 0);\",    \"cmple\\tp1.s, p1\/z, z4.s, #0\"],\n+                        [\"cmplt\",    \"__ sve_cmp(Assembler::LT, p1, __ D, p2, z6, -1);\",   \"cmplt\\tp1.d, p2\/z, z6.d, #-1\"],\n+                        [\"cmpge\",    \"__ sve_cmp(Assembler::GE, p1, __ S, p3, z4, 5);\",    \"cmpge\\tp1.s, p3\/z, z4.s, #5\"],\n+                        [\"cmpgt\",    \"__ sve_cmp(Assembler::GT, p1, __ B, p4, z6, -2);\",   \"cmpgt\\tp1.b, p4\/z, z6.b, #-2\"],\n+                        [\"fcmeq\",    \"__ sve_fcm(Assembler::EQ, p1, __ S, p0, z0, z1);\",   \"fcmeq\\tp1.s, p0\/z, z0.s, z1.s\"],\n+                        [\"fcmne\",    \"__ sve_fcm(Assembler::NE, p1, __ D, p0, z2, z3);\",   \"fcmne\\tp1.d, p0\/z, z2.d, z3.d\"],\n+                        [\"fcmgt\",    \"__ sve_fcm(Assembler::GT, p1, __ S, p2, z4, z5);\",   \"fcmgt\\tp1.s, p2\/z, z4.s, z5.s\"],\n+                        [\"fcmge\",    \"__ sve_fcm(Assembler::GE, p1, __ D, p3, z6, z7);\",   \"fcmge\\tp1.d, p3\/z, z6.d, z7.d\"],\n+                        [\"uunpkhi\",  \"__ sve_uunpkhi(z0, __ H, z1);\",                      \"uunpkhi\\tz0.h, z1.b\"],\n+                        [\"uunpklo\",  \"__ sve_uunpklo(z4, __ S, z5);\",                      \"uunpklo\\tz4.s, z5.h\"],\n+                        [\"sunpkhi\",  \"__ sve_sunpkhi(z6, __ D, z7);\",                      \"sunpkhi\\tz6.d, z7.s\"],\n+                        [\"sunpklo\",  \"__ sve_sunpklo(z10, __ H, z11);\",                    \"sunpklo\\tz10.h, z11.b\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z1, __ D, p0, z0, __ S);\",              \"scvtf\\tz1.d, p0\/m, z0.s\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z3, __ D, p1, z2, __ D);\",              \"scvtf\\tz3.d, p1\/m, z2.d\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z6, __ S, p2, z1, __ D);\",              \"scvtf\\tz6.s, p2\/m, z1.d\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z6, __ S, p3, z1, __ S);\",              \"scvtf\\tz6.s, p3\/m, z1.s\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z6, __ H, p3, z1, __ S);\",              \"scvtf\\tz6.h, p3\/m, z1.s\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z6, __ H, p3, z1, __ D);\",              \"scvtf\\tz6.h, p3\/m, z1.d\"],\n+                        [\"scvtf\",    \"__ sve_scvtf(z6, __ H, p3, z1, __ H);\",              \"scvtf\\tz6.h, p3\/m, z1.h\"],\n+                        [\"fcvt\",     \"__ sve_fcvt(z5, __ D, p3, z4, __ S);\",               \"fcvt\\tz5.d, p3\/m, z4.s\"],\n+                        [\"fcvt\",     \"__ sve_fcvt(z1, __ S, p3, z0, __ D);\",               \"fcvt\\tz1.s, p3\/m, z0.d\"],\n+                        [\"fcvtzs\",   \"__ sve_fcvtzs(z19, __ D, p2, z1, __ D);\",            \"fcvtzs\\tz19.d, p2\/m, z1.d\"],\n+                        [\"fcvtzs\",   \"__ sve_fcvtzs(z9, __ S, p1, z8, __ S);\",             \"fcvtzs\\tz9.s, p1\/m, z8.s\"],\n+                        [\"fcvtzs\",   \"__ sve_fcvtzs(z1, __ S, p2, z0, __ D);\",             \"fcvtzs\\tz1.s, p2\/m, z0.d\"],\n+                        [\"fcvtzs\",   \"__ sve_fcvtzs(z1, __ D, p3, z0, __ S);\",             \"fcvtzs\\tz1.d, p3\/m, z0.s\"],\n+                        [\"fcvtzs\",   \"__ sve_fcvtzs(z1, __ S, p4, z18, __ H);\",            \"fcvtzs\\tz1.s, p4\/m, z18.h\"],\n+                        [\"lasta\",    \"__ sve_lasta(r0, __ B, p0, z15);\",                   \"lasta\\tw0, p0, z15.b\"],\n+                        [\"lastb\",    \"__ sve_lastb(r1, __ B, p1, z16);\",                   \"lastb\\tw1, p1, z16.b\"],\n+                        [\"lasta\",    \"__ sve_lasta(v0, __ B, p0, z15);\",                   \"lasta\\tb0, p0, z15.b\"],\n+                        [\"lastb\",    \"__ sve_lastb(v1, __ B, p1, z16);\",                   \"lastb\\tb1, p1, z16.b\"],\n+                        [\"index\",    \"__ sve_index(z6, __ S, 1, 1);\",                      \"index\\tz6.s, #1, #1\"],\n+                        [\"index\",    \"__ sve_index(z6, __ B, r5, 2);\",                     \"index\\tz6.b, w5, #2\"],\n+                        [\"index\",    \"__ sve_index(z6, __ H, r5, 3);\",                     \"index\\tz6.h, w5, #3\"],\n+                        [\"index\",    \"__ sve_index(z6, __ S, r5, 4);\",                     \"index\\tz6.s, w5, #4\"],\n+                        [\"index\",    \"__ sve_index(z7, __ D, r5, 5);\",                     \"index\\tz7.d, x5, #5\"],\n+                        [\"cpy\",      \"__ sve_cpy(z7, __ H, p3, r5);\",                      \"cpy\\tz7.h, p3\/m, w5\"],\n+                        [\"tbl\",      \"__ sve_tbl(z16, __ S, z17, z18);\",                   \"tbl\\tz16.s, {z17.s}, z18.s\"],\n+                        [\"ld1w\",     \"__ sve_ld1w_gather(z15, p0, r5, z16);\",              \"ld1w\\t{z15.s}, p0\/z, [x5, z16.s, uxtw #2]\"],\n+                        [\"ld1d\",     \"__ sve_ld1d_gather(z15, p0, r5, z16);\",              \"ld1d\\t{z15.d}, p0\/z, [x5, z16.d, uxtw #3]\"],\n+                        [\"st1w\",     \"__ sve_st1w_scatter(z15, p0, r5, z16);\",             \"st1w\\t{z15.s}, p0, [x5, z16.s, uxtw #2]\"],\n+                        [\"st1d\",     \"__ sve_st1d_scatter(z15, p0, r5, z16);\",             \"st1d\\t{z15.d}, p0, [x5, z16.d, uxtw #3]\"],\n+                        [\"and\",      \"__ sve_and(p0, p1, p2, p3);\",                        \"and\\tp0.b, p1\/z, p2.b, p3.b\"],\n+                        [\"ands\",     \"__ sve_ands(p4, p5, p6, p0);\",                       \"ands\\tp4.b, p5\/z, p6.b, p0.b\"],\n+                        [\"eor\",      \"__ sve_eor(p0, p1, p2, p3);\",                        \"eor\\tp0.b, p1\/z, p2.b, p3.b\"],\n+                        [\"eors\",     \"__ sve_eors(p5, p6, p0, p1);\",                       \"eors\\tp5.b, p6\/z, p0.b, p1.b\"],\n+                        [\"orr\",      \"__ sve_orr(p0, p1, p2, p3);\",                        \"orr\\tp0.b, p1\/z, p2.b, p3.b\"],\n+                        [\"orrs\",     \"__ sve_orrs(p9, p1, p4, p5);\",                       \"orrs\\tp9.b, p1\/z, p4.b, p5.b\"],\n+                        [\"bic\",      \"__ sve_bic(p10, p7, p9, p11);\",                      \"bic\\tp10.b, p7\/z, p9.b, p11.b\"],\n+                        [\"ptest\",    \"__ sve_ptest(p7, p1);\",                              \"ptest\\tp7, p1.b\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p1, __ B);\",                            \"ptrue\\tp1.b\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p1, __ B, 0b00001);\",                   \"ptrue\\tp1.b, vl1\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p1, __ B, 0b00101);\",                   \"ptrue\\tp1.b, vl5\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p1, __ B, 0b01001);\",                   \"ptrue\\tp1.b, vl16\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p1, __ B, 0b01101);\",                   \"ptrue\\tp1.b, vl256\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p2, __ H);\",                            \"ptrue\\tp2.h\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p2, __ H, 0b00010);\",                   \"ptrue\\tp2.h, vl2\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p2, __ H, 0b00110);\",                   \"ptrue\\tp2.h, vl6\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p2, __ H, 0b01010);\",                   \"ptrue\\tp2.h, vl32\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p3, __ S);\",                            \"ptrue\\tp3.s\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p3, __ S, 0b00011);\",                   \"ptrue\\tp3.s, vl3\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p3, __ S, 0b00111);\",                   \"ptrue\\tp3.s, vl7\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p3, __ S, 0b01011);\",                   \"ptrue\\tp3.s, vl64\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p4, __ D);\",                            \"ptrue\\tp4.d\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p4, __ D, 0b00100);\",                   \"ptrue\\tp4.d, vl4\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p4, __ D, 0b01000);\",                   \"ptrue\\tp4.d, vl8\"],\n+                        [\"ptrue\",    \"__ sve_ptrue(p4, __ D, 0b01100);\",                   \"ptrue\\tp4.d, vl128\"],\n+                        [\"pfalse\",   \"__ sve_pfalse(p7);\",                                 \"pfalse\\tp7.b\"],\n+                        [\"uzp1\",     \"__ sve_uzp1(p0, __ B, p0, p1);\",                     \"uzp1\\tp0.b, p0.b, p1.b\"],\n+                        [\"uzp1\",     \"__ sve_uzp1(p0, __ H, p0, p1);\",                     \"uzp1\\tp0.h, p0.h, p1.h\"],\n+                        [\"uzp1\",     \"__ sve_uzp1(p0, __ S, p0, p1);\",                     \"uzp1\\tp0.s, p0.s, p1.s\"],\n+                        [\"uzp1\",     \"__ sve_uzp1(p0, __ D, p0, p1);\",                     \"uzp1\\tp0.d, p0.d, p1.d\"],\n+                        [\"uzp2\",     \"__ sve_uzp2(p0, __ B, p0, p1);\",                     \"uzp2\\tp0.b, p0.b, p1.b\"],\n+                        [\"uzp2\",     \"__ sve_uzp2(p0, __ H, p0, p1);\",                     \"uzp2\\tp0.h, p0.h, p1.h\"],\n+                        [\"uzp2\",     \"__ sve_uzp2(p0, __ S, p0, p1);\",                     \"uzp2\\tp0.s, p0.s, p1.s\"],\n+                        [\"uzp2\",     \"__ sve_uzp2(p0, __ D, p0, p1);\",                     \"uzp2\\tp0.d, p0.d, p1.d\"],\n+                        [\"punpklo\",  \"__ sve_punpklo(p1, p0);\",                            \"punpklo\\tp1.h, p0.b\"],\n+                        [\"punpkhi\",  \"__ sve_punpkhi(p1, p0);\",                            \"punpkhi\\tp1.h, p0.b\"],\n+                        [\"compact\",  \"__ sve_compact(z16, __ S, z16, p1);\",                \"compact\\tz16.s, p1, z16.s\"],\n+                        [\"compact\",  \"__ sve_compact(z16, __ D, z16, p1);\",                \"compact\\tz16.d, p1, z16.d\"],\n+                        [\"ext\",      \"__ sve_ext(z17, z16, 63);\",                          \"ext\\tz17.b, z17.b, z16.b, #63\"],\n@@ -1822,2 +1826,2 @@\n-                        [\"histcnt\", \"__ sve_histcnt(z16, __ S, p0, z16, z16);\",           \"histcnt\\tz16.s, p0\/z, z16.s, z16.s\"],\n-                        [\"histcnt\", \"__ sve_histcnt(z17, __ D, p0, z17, z17);\",           \"histcnt\\tz17.d, p0\/z, z17.d, z17.d\"],\n+                        [\"histcnt\",  \"__ sve_histcnt(z16, __ S, p0, z16, z16);\",           \"histcnt\\tz16.s, p0\/z, z16.s, z16.s\"],\n+                        [\"histcnt\",  \"__ sve_histcnt(z17, __ D, p0, z17, z17);\",           \"histcnt\\tz17.d, p0\/z, z17.d, z17.d\"],\n","filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py","additions":177,"deletions":173,"binary":false,"changes":350,"status":"modified"},{"patch":"@@ -875,0 +875,4 @@\n+    __ sve_whileltw(p1, __ B, r1, r28);                \/\/       whilelt p1.b, w1, w28\n+    __ sve_whilelew(p2, __ H, r11, r8);                \/\/       whilele p2.h, w11, w8\n+    __ sve_whilelow(p3, __ S, r7, r2);                 \/\/       whilelo p3.s, w7, w2\n+    __ sve_whilelsw(p4, __ D, r17, r10);               \/\/       whilels p4.d, w17, w10\n@@ -1228,7 +1232,7 @@\n-    0x14000000,     0x17ffffd7,     0x140003f1,     0x94000000,\n-    0x97ffffd4,     0x940003ee,     0x3400000a,     0x34fffa2a,\n-    0x34007d6a,     0x35000008,     0x35fff9c8,     0x35007d08,\n-    0xb400000b,     0xb4fff96b,     0xb4007cab,     0xb500001d,\n-    0xb5fff91d,     0xb5007c5d,     0x10000013,     0x10fff8b3,\n-    0x10007bf3,     0x90000013,     0x36300016,     0x3637f836,\n-    0x36307b76,     0x3758000c,     0x375ff7cc,     0x37587b0c,\n+    0x14000000,     0x17ffffd7,     0x140003f5,     0x94000000,\n+    0x97ffffd4,     0x940003f2,     0x3400000a,     0x34fffa2a,\n+    0x34007dea,     0x35000008,     0x35fff9c8,     0x35007d88,\n+    0xb400000b,     0xb4fff96b,     0xb4007d2b,     0xb500001d,\n+    0xb5fff91d,     0xb5007cdd,     0x10000013,     0x10fff8b3,\n+    0x10007c73,     0x90000013,     0x36300016,     0x3637f836,\n+    0x36307bf6,     0x3758000c,     0x375ff7cc,     0x37587b8c,\n@@ -1239,13 +1243,13 @@\n-    0x540078e0,     0x54000001,     0x54fff541,     0x54007881,\n-    0x54000002,     0x54fff4e2,     0x54007822,     0x54000002,\n-    0x54fff482,     0x540077c2,     0x54000003,     0x54fff423,\n-    0x54007763,     0x54000003,     0x54fff3c3,     0x54007703,\n-    0x54000004,     0x54fff364,     0x540076a4,     0x54000005,\n-    0x54fff305,     0x54007645,     0x54000006,     0x54fff2a6,\n-    0x540075e6,     0x54000007,     0x54fff247,     0x54007587,\n-    0x54000008,     0x54fff1e8,     0x54007528,     0x54000009,\n-    0x54fff189,     0x540074c9,     0x5400000a,     0x54fff12a,\n-    0x5400746a,     0x5400000b,     0x54fff0cb,     0x5400740b,\n-    0x5400000c,     0x54fff06c,     0x540073ac,     0x5400000d,\n-    0x54fff00d,     0x5400734d,     0x5400000e,     0x54ffefae,\n-    0x540072ee,     0x5400000f,     0x54ffef4f,     0x5400728f,\n+    0x54007960,     0x54000001,     0x54fff541,     0x54007901,\n+    0x54000002,     0x54fff4e2,     0x540078a2,     0x54000002,\n+    0x54fff482,     0x54007842,     0x54000003,     0x54fff423,\n+    0x540077e3,     0x54000003,     0x54fff3c3,     0x54007783,\n+    0x54000004,     0x54fff364,     0x54007724,     0x54000005,\n+    0x54fff305,     0x540076c5,     0x54000006,     0x54fff2a6,\n+    0x54007666,     0x54000007,     0x54fff247,     0x54007607,\n+    0x54000008,     0x54fff1e8,     0x540075a8,     0x54000009,\n+    0x54fff189,     0x54007549,     0x5400000a,     0x54fff12a,\n+    0x540074ea,     0x5400000b,     0x54fff0cb,     0x5400748b,\n+    0x5400000c,     0x54fff06c,     0x5400742c,     0x5400000d,\n+    0x54fff00d,     0x540073cd,     0x5400000e,     0x54ffefae,\n+    0x5400736e,     0x5400000f,     0x54ffef4f,     0x5400730f,\n@@ -1406,1 +1410,2 @@\n-    0x25a21ce3,     0x25ea1e34,     0x0522c020,     0x05e6c0a4,\n+    0x25a21ce3,     0x25ea1e34,     0x253c0421,     0x25680572,\n+    0x25a20ce3,     0x25ea0e34,     0x0522c020,     0x05e6c0a4,\n","filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h","additions":26,"deletions":21,"binary":false,"changes":47,"status":"modified"}]}