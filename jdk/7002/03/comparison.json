{"files":[{"patch":"@@ -1496,0 +1496,31 @@\n+void C2_MacroAssembler::load_vector(XMMRegister dst, Address src, int vlen_in_bytes) {\n+  switch (vlen_in_bytes) {\n+  case 4:  movdl(dst, src);   break;\n+  case 8:  movq(dst, src);    break;\n+  case 16: movdqu(dst, src);  break;\n+  case 32: vmovdqu(dst, src); break;\n+  case 64: evmovdquq(dst, src, Assembler::AVX_512bit); break;\n+  default: ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::load_vector(XMMRegister dst, AddressLiteral src, int vlen_in_bytes, Register rscratch) {\n+  if (reachable(src)) {\n+    load_vector(dst, as_Address(src), vlen_in_bytes);\n+  } else {\n+    lea(rscratch, src);\n+    load_vector(dst, Address(rscratch, 0), vlen_in_bytes);\n+  }\n+}\n+\n+void C2_MacroAssembler::store_vector(Address dst, XMMRegister src, int vlen_in_bytes) {\n+  switch (vlen_in_bytes) {\n+  case 4:  movdl(dst, src);   break;\n+  case 8:  movq(dst, src);    break;\n+  case 16: movdqu(dst, src);  break;\n+  case 32: vmovdqu(dst, src); break;\n+  case 64: evmovdquq(dst, src, Assembler::AVX_512bit); break;\n+  default: ShouldNotReachHere();\n+  }\n+}\n+\n@@ -4074,0 +4105,109 @@\n+\/*\n+ * Convert long vectors to floating-point vectors on non-AVX512dq\n+ * The fast path downcasts the vector to an int vector to perform the\n+ * cast; the slow path, where some elements can't be cast losslessly to\n+ * int, tries to convert elements one by one.\n+ *\/\n+void C2_MacroAssembler::vector_castL2FD(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                        Register tmp, KRegister ktmp, BasicType bt, int vlen, int vec_enc) {\n+  Label slow_path;\n+  Label done;\n+  assert((ktmp == knoreg) != (vlen == 8), \"\");\n+\n+  if (vec_enc == AVX_128bit) {\n+    vpshufd(xtmp1, src, 0x08, vec_enc);\n+  } else if (UseAVX > 2) {\n+    evpmovqd(xtmp1, src, VM_Version::supports_avx512vl() ? vec_enc : AVX_512bit);\n+  } else {\n+    vpshufd(xtmp1, src, 0x08, vec_enc);\n+    vpermpd(xtmp1, xtmp1, 0x08, vec_enc);\n+  }\n+\n+  vpmovsxdq(xtmp2, xtmp1, vec_enc);\n+  if (vec_enc == AVX_512bit) {\n+    evpcmp(T_LONG, ktmp, k0, xtmp1, xtmp2, Assembler::eq, vec_enc);\n+    kortest(vlen, ktmp, ktmp);\n+  } else {\n+    vallones(dst, vec_enc);\n+    vpcmpeqq(xtmp2, src, xtmp2, vec_enc);\n+    vptest(xtmp2, dst, vec_enc);\n+  }\n+  jccb(Assembler::carryClear, slow_path);\n+\n+  \/\/ fast path\n+  if (bt == T_FLOAT) {\n+    vcvtdq2ps(dst, xtmp1, vec_enc == AVX_512bit ? AVX_256bit : AVX_128bit);\n+  } else {\n+    vcvtdq2pd(dst, xtmp1, vec_enc);\n+  }\n+  jmp(done);\n+\n+  bind(slow_path);\n+\n+#ifdef _LP64\n+  int dst_eles_per_lane = MIN2(vlen, 16 \/ type2aelembytes(bt));\n+  int dst_lane_num = vlen \/ dst_eles_per_lane;\n+  for (int dst_lane = 0; dst_lane < dst_lane_num; dst_lane++) {\n+    for (int dst_ele = dst_eles_per_lane - 1; dst_ele >= 0; dst_ele--) {\n+      int index = dst_lane * dst_eles_per_lane + dst_ele;\n+      int src_lane = index \/ 2;\n+      int src_ele = index % 2;\n+      XMMRegister src_tmp;\n+      if (src_lane == 0) {\n+        src_tmp = src;\n+      } else {\n+        src_tmp = xtmp1;\n+        if (src_ele == 1) {\n+          if (vec_enc == AVX_512bit) {\n+            vextractf32x4(xtmp1, src, src_lane);\n+          } else {\n+            vextractf128(xtmp1, src, src_lane);\n+          }\n+        }\n+      }\n+      if (src_ele == 0) {\n+        movq(tmp, src_tmp);\n+      } else {\n+        extract(T_LONG, tmp, src_tmp, src_ele);\n+      }\n+\n+      XMMRegister dst_tmp = (dst_lane == 0 ? dst : xtmp2);\n+      if (bt == T_FLOAT) {\n+        cvtsi2ssq(dst_tmp, tmp);\n+      } else {\n+        cvtsi2sdq(dst_tmp, tmp);\n+      }\n+      if (dst_ele == 0) {\n+        if (dst_lane != 0) {\n+          if (bt == T_DOUBLE && vec_enc == AVX_512bit) {\n+            vinsertf32x4(dst, dst, xtmp2, dst_lane);\n+          } else {\n+            vinsertf128(dst, dst, xtmp2, dst_lane);\n+          }\n+        }\n+      } else {\n+        vpshufd(dst_tmp, dst_tmp, bt == T_FLOAT ? 0x90 : 0x40, AVX_128bit);\n+      }\n+    }\n+  }\n+#else \/\/ _LP64\n+  int src_vlen_in_bytes = vlen * type2aelembytes(T_LONG);\n+  int dst_vlen_in_bytes = vlen * type2aelembytes(bt);\n+  assert(src_vlen_in_bytes + dst_vlen_in_bytes <= 128, \"red zone\");\n+  store_vector(Address(rsp, -src_vlen_in_bytes), src, src_vlen_in_bytes);\n+  for (int i = 0; i < vlen; i++) {\n+    int src_ele_offset = -src_vlen_in_bytes + i * type2aelembytes(T_LONG);\n+    int dst_ele_offset = -src_vlen_in_bytes - dst_vlen_in_bytes + i * type2aelembytes(bt);\n+    fild_d(Address(rsp, src_ele_offset));\n+    if (bt == T_FLOAT) {\n+      fstp_s(Address(rsp, dst_ele_offset));\n+    } else {\n+      fstp_d(Address(rsp, dst_ele_offset));\n+    }\n+  }\n+  load_vector(dst, Address(rsp, -src_vlen_in_bytes - dst_vlen_in_bytes), dst_vlen_in_bytes);\n+#endif \/\/ _LP64\n+\n+  bind(done);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":140,"deletions":0,"binary":false,"changes":140,"status":"modified"},{"patch":"@@ -147,0 +147,3 @@\n+  void load_vector(XMMRegister dst, Address src, int vlen_in_bytes);\n+  void load_vector(XMMRegister dst, AddressLiteral src, int vlen_in_bytes, Register rscratch = rscratch1);\n+  void store_vector(Address dst, XMMRegister src, int vlen_in_bytes);\n@@ -303,0 +306,3 @@\n+  void vector_castL2FD(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                       Register tmp, KRegister ktmp, BasicType bt, int vlen, int vec_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1785,14 +1785,0 @@\n-    case Op_VectorCastB2X:\n-    case Op_VectorCastS2X:\n-    case Op_VectorCastI2X:\n-      if (bt != T_DOUBLE && size_in_bits == 256 && UseAVX < 2) {\n-        return false;\n-      }\n-      break;\n-    case Op_VectorCastL2X:\n-      if (is_integral_type(bt) && size_in_bits == 256 && UseAVX < 2) {\n-        return false;\n-      } else if (!is_integral_type(bt) && !VM_Version::supports_avx512dq()) {\n-        return false;\n-      }\n-      break;\n@@ -6894,0 +6880,3 @@\n+  predicate(UseAVX > 1 ||\n+            Matcher::vector_element_basic_type(n) != T_FLOAT ||\n+            Matcher::vector_length_in_bytes(n) < 32);\n@@ -6962,2 +6951,5 @@\n-  predicate((UseAVX > 2 && VM_Version::supports_avx512vlbw()) ||\n-            (Matcher::vector_length_in_bytes(n) >= Matcher::vector_length_in_bytes(n->in(1)))); \/\/ dst >= src\n+  predicate((Matcher::vector_element_basic_type(n) == T_BYTE && UseAVX > 2 && VM_Version::supports_avx512vlbw()) ||\n+            (Matcher::vector_element_basic_type(n) == T_FLOAT && (UseAVX > 1 || Matcher::vector_length_in_bytes(n) < 32)) ||\n+            Matcher::vector_element_basic_type(n) == T_INT ||\n+            Matcher::vector_element_basic_type(n) == T_LONG ||\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n@@ -7000,0 +6992,32 @@\n+instruct vcastBStoF(vec dst, vec src, vec xtmp) %{\n+  predicate(UseAVX == 1 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT &&\n+            Matcher::vector_length_in_bytes(n) == 32);\n+  match(Set dst (VectorCastB2X src));\n+  match(Set dst (VectorCastS2X src));\n+  format %{ \"vector_cast_bs2x $dst,$src\\t! using $xtmp as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp);\n+  ins_encode %{\n+    BasicType elem_bt = Matcher::vector_element_basic_type(this, $src);\n+    switch (elem_bt) {\n+      case T_BYTE:\n+        __ pmovsxbd($dst$$XMMRegister, $src$$XMMRegister);\n+        __ pshufd($xtmp$$XMMRegister, $src$$XMMRegister, 0x01);\n+        __ pmovsxbd($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n+        __ vinsertf128_high($dst$$XMMRegister, $xtmp$$XMMRegister);\n+        __ vcvtdq2ps($dst$$XMMRegister, $dst$$XMMRegister, Assembler::AVX_256bit);\n+        break;\n+      case T_SHORT:\n+        __ pmovsxwd($dst$$XMMRegister, $src$$XMMRegister);\n+        __ pshufd($xtmp$$XMMRegister, $src$$XMMRegister, 0x0E);\n+        __ pmovsxwd($xtmp$$XMMRegister, $xtmp$$XMMRegister);\n+        __ vinsertf128_high($dst$$XMMRegister, $xtmp$$XMMRegister);\n+        __ vcvtdq2ps($dst$$XMMRegister, $dst$$XMMRegister, Assembler::AVX_256bit);\n+        break;\n+      default:\n+        ShouldNotReachHere();\n+    }\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7125,0 +7149,34 @@\n+instruct vcastLtoFD_avx(vec dst, vec src, vec xtmp1, vec xtmp2, rRegI tmp, rFlagsReg cr) %{\n+  predicate((UseAVX <= 2 || !VM_Version::supports_avx512dq()) &&\n+            is_floating_point_type(Matcher::vector_element_basic_type(n)) &&\n+            Matcher::vector_length_in_bytes(n->in(1)) <= 32);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP tmp, KILL cr);\n+  format %{ \"vector_cast_l2x  $dst,$src\\t! using $xtmp1, $xtmp2 and $tmp as TEMP\" %}\n+  ins_encode %{\n+    BasicType to_elem_bt = Matcher::vector_element_basic_type(this);\n+    int vlen = Matcher::vector_length(this);\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    __ vector_castL2FD($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,\n+                       $tmp$$Register, knoreg, to_elem_bt, vlen, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcastLtoFD_evex(vec dst, vec src, vec xtmp1, vec xtmp2, rRegI tmp, kReg ktmp, rFlagsReg cr) %{\n+  predicate((UseAVX <= 2 || !VM_Version::supports_avx512dq()) &&\n+            is_floating_point_type(Matcher::vector_element_basic_type(n)) &&\n+            Matcher::vector_length_in_bytes(n->in(1)) == 64);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP tmp, TEMP ktmp, KILL cr);\n+  format %{ \"vector_cast_l2x  $dst,$src\\t! using $xtmp1, $xtmp2, $tmp and $ktmp as TEMP\" %}\n+  ins_encode %{\n+    BasicType to_elem_bt = Matcher::vector_element_basic_type(this);\n+    int vlen = Matcher::vector_length(this);\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    __ vector_castL2FD($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,\n+                       $tmp$$Register, $ktmp$$KRegister, to_elem_bt, vlen, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7126,4 +7184,3 @@\n-  predicate(UseAVX > 2 ||\n-            (Matcher::vector_element_basic_type(n) == T_INT ||\n-             Matcher::vector_element_basic_type(n) == T_FLOAT ||\n-             Matcher::vector_element_basic_type(n) == T_DOUBLE));\n+  predicate((is_subword_type(Matcher::vector_element_basic_type(n)) && UseAVX > 2) ||\n+            Matcher::vector_element_basic_type(n) == T_INT ||\n+            (is_floating_point_type(Matcher::vector_element_basic_type(n)) && UseAVX > 2 && VM_Version::supports_avx512dq()));\n@@ -7171,1 +7228,0 @@\n-        assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"required\");\n@@ -7175,1 +7231,0 @@\n-        assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"required\");\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":77,"deletions":22,"binary":false,"changes":99,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+            makePair(BSPEC64, FSPEC256),\n@@ -49,0 +50,1 @@\n+            makePair(SSPEC128, FSPEC256),\n@@ -61,0 +63,2 @@\n+            makePair(LSPEC128, FSPEC64),\n+            makePair(LSPEC128, DSPEC128),\n@@ -73,1 +77,0 @@\n-            makePair(BSPEC64, FSPEC256),\n@@ -77,1 +80,0 @@\n-            makePair(SSPEC128, FSPEC256),\n@@ -85,0 +87,2 @@\n+            makePair(LSPEC256, FSPEC128),\n+            makePair(LSPEC256, DSPEC256),\n@@ -105,0 +109,2 @@\n+            makePair(LSPEC512, FSPEC256),\n+            makePair(LSPEC512, DSPEC512),\n@@ -116,3 +122,0 @@\n-            makePair(LSPEC128, DSPEC128),\n-            makePair(LSPEC256, DSPEC256),\n-            makePair(LSPEC512, DSPEC512),\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/reshape\/utils\/TestCastMethods.java","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -126,1 +126,7 @@\n-                    case \"long\"   -> UnsafeUtils.putLong(input, ibase, i, random.nextLong());\n+                    case \"long\"   -> {\n+                        if (normalArray) {\n+                            UnsafeUtils.putLong(input, ibase, i, random.nextInt());\n+                        } else {\n+                            UnsafeUtils.putLong(input, ibase, i, random.nextLong());\n+                        }\n+                    }\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/reshape\/utils\/VectorReshapeHelper.java","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"}]}