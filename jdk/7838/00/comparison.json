{"files":[{"patch":"@@ -1975,9 +1975,8 @@\n-\/\/ Jump if ((*counter_addr += increment) & mask) satisfies the condition.\n-void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr,\n-                                                        int increment, Address mask,\n-                                                        Register scratch, bool preloaded,\n-                                                        Condition cond, Label* where) {\n-  if (!preloaded) {\n-    movl(scratch, counter_addr);\n-  }\n-  incrementl(scratch, increment);\n+\/\/ Jump if ((*counter_addr += increment) & mask) == 0\n+void InterpreterMacroAssembler::increment_mask_and_jump(Address counter_addr, Address mask,\n+                                                        Register scratch, Label* where) {\n+  \/\/ This update is actually not atomic and can lose a number of updates\n+  \/\/ under heavy contention, but the alternative of using the (contended)\n+  \/\/ atomic update here penalizes profiling paths too much.\n+  movl(scratch, counter_addr);\n+  incrementl(scratch, InvocationCounter::count_increment);\n@@ -1987,1 +1986,1 @@\n-    jcc(cond, *where);\n+    jcc(Assembler::zero, *where);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.cpp","additions":9,"deletions":10,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -251,4 +251,2 @@\n-  void increment_mask_and_jump(Address counter_addr,\n-                               int increment, Address mask,\n-                               Register scratch, bool preloaded,\n-                               Condition cond, Label* where);\n+  void increment_mask_and_jump(Address counter_addr, Address mask,\n+                               Register scratch, Label* where);\n","filename":"src\/hotspot\/cpu\/x86\/interp_masm_x86.hpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -391,1 +391,0 @@\n-  int increment = InvocationCounter::count_increment;\n@@ -402,1 +401,1 @@\n-    __ increment_mask_and_jump(mdo_invocation_counter, increment, mask, rcx, false, Assembler::zero, overflow);\n+    __ increment_mask_and_jump(mdo_invocation_counter, mask, rcx, overflow);\n@@ -412,2 +411,1 @@\n-  __ increment_mask_and_jump(invocation_counter, increment, mask, rcx,\n-      false, Assembler::zero, overflow);\n+  __ increment_mask_and_jump(invocation_counter, mask, rcx, overflow);\n","filename":"src\/hotspot\/cpu\/x86\/templateInterpreterGenerator_x86.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2200,1 +2200,0 @@\n-    int increment = InvocationCounter::count_increment;\n@@ -2210,1 +2209,1 @@\n-      __ increment_mask_and_jump(mdo_backedge_counter, increment, mask, rax, false, Assembler::zero,\n+      __ increment_mask_and_jump(mdo_backedge_counter, mask, rax,\n@@ -2218,2 +2217,2 @@\n-    __ increment_mask_and_jump(Address(rcx, be_offset), increment, mask,\n-        rax, false, Assembler::zero, UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n+    __ increment_mask_and_jump(Address(rcx, be_offset), mask, rax,\n+        UseOnStackReplacement ? &backedge_counter_overflow : NULL);\n","filename":"src\/hotspot\/cpu\/x86\/templateTable_x86.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"}]}