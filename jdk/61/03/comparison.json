{"files":[{"patch":"@@ -2592,0 +2592,32 @@\n+void Assembler::evmovdqu(XMMRegister dst, KRegister mask, Address src, int vector_len, int type) {\n+  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  InstructionMark im(this);\n+  bool wide = type == T_SHORT || type == T_LONG || type == T_CHAR;\n+  bool bwinstr = type == T_BYTE ||  type == T_SHORT || type == T_CHAR;\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ wide, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  attributes.set_is_evex_instruction();\n+  int prefix = bwinstr ? VEX_SIMD_F2 : VEX_SIMD_F3;\n+  vex_prefix(src, 0, dst->encoding(), (Assembler::VexSimdPrefix)prefix, VEX_OPCODE_0F, &attributes);\n+  emit_int8(0x6F);\n+  emit_operand(dst, src);\n+}\n+\n+void Assembler::evmovdqu(Address dst, KRegister mask, XMMRegister src, int vector_len, int type) {\n+  assert(VM_Version::supports_avx512vlbw(), \"\");\n+  assert(src != xnoreg, \"sanity\");\n+  InstructionMark im(this);\n+  bool wide = type == T_SHORT || type == T_LONG || type == T_CHAR;\n+  bool bwinstr = type == T_BYTE ||  type == T_SHORT || type == T_CHAR;\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ wide, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false, \/* uses_vl *\/ true);\n+  attributes.set_address_attributes(\/* tuple_type *\/ EVEX_FVM, \/* input_size_in_bits *\/ EVEX_NObit);\n+  attributes.reset_is_clear_context();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  attributes.set_is_evex_instruction();\n+  int prefix = bwinstr ? VEX_SIMD_F2 : VEX_SIMD_F3;\n+  vex_prefix(dst, 0, src->encoding(), (Assembler::VexSimdPrefix)prefix, VEX_OPCODE_0F, &attributes);\n+  emit_int8(0x7F);\n+  emit_operand(src, dst);\n+}\n+\n@@ -7806,0 +7838,7 @@\n+void Assembler::shrxq(Register dst, Register src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xF7, (0xC0 | encode));\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -829,1 +829,0 @@\n-  void decq(Register dst);\n@@ -914,0 +913,1 @@\n+  void decq(Register dst);\n@@ -1522,0 +1522,4 @@\n+  \/\/ Generic move instructions.\n+  void evmovdqu(Address dst, KRegister mask, XMMRegister src, int vector_len, int type);\n+  void evmovdqu(XMMRegister dst, KRegister mask, Address src, int vector_len, int type);\n+\n@@ -2024,0 +2028,2 @@\n+  void shrxq(Register dst, Register src1, Register src2);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -7966,0 +7966,68 @@\n+\n+void MacroAssembler::copy64_masked_avx(Register dst, Register src, XMMRegister xmm,\n+                                       KRegister mask, Register length, Register index,\n+                                       Register temp, int shift, int offset,\n+                                       bool use64byteVector) {\n+  BasicType type[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+  assert(MaxVectorSize >= 32, \"vector length should be >= 32\");\n+  use64byteVector |= MaxVectorSize > 32 && AVX3Threshold == 0;\n+  if (!use64byteVector) {\n+    copy32_avx(dst, src, index, xmm, shift, offset);\n+    subptr(length, 32 >> shift);\n+    copy32_masked_avx(dst, src, xmm, mask, length, index, temp, shift, offset+32);\n+  } else {\n+    Address::ScaleFactor scale = (Address::ScaleFactor)(shift);\n+    assert(MaxVectorSize == 64, \"vector length != 64\");\n+    negptr(length);\n+    addq(length, 64);\n+    mov64(temp, -1);\n+    shrxq(temp, temp, length);\n+    kmovql(mask, temp);\n+    evmovdqu(xmm, mask, Address(src, index, scale, offset), Assembler::AVX_512bit, type[shift]);\n+    evmovdqu(Address(dst, index, scale, offset), mask, xmm, Assembler::AVX_512bit, type[shift]);\n+  }\n+}\n+\n+void MacroAssembler::copy32_masked_avx(Register dst, Register src, XMMRegister xmm,\n+                                       KRegister mask, Register length, Register index,\n+                                       Register temp, int shift, int offset) {\n+  assert(MaxVectorSize >= 32, \"vector length should be >= 32\");\n+  BasicType type[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+  Address::ScaleFactor scale = (Address::ScaleFactor)(shift);\n+  mov64(temp, 1);\n+  shlxq(temp, temp, length);\n+  decq(temp);\n+  kmovql(mask, temp);\n+  evmovdqu(xmm, mask, Address(src, index, scale, offset), Assembler::AVX_256bit, type[shift]);\n+  evmovdqu(Address(dst, index, scale, offset), mask, xmm, Assembler::AVX_256bit, type[shift]);\n+}\n+\n+\n+void MacroAssembler::copy32_avx(Register dst, Register src, Register index, XMMRegister xmm,\n+                                int shift, int offset) {\n+  assert(MaxVectorSize >= 32, \"vector length should be >= 32\");\n+  Address::ScaleFactor scale = (Address::ScaleFactor)(shift);\n+  vmovdqu(xmm, Address(src, index, scale, offset));\n+  vmovdqu(Address(dst, index, scale, offset), xmm);\n+}\n+\n+\n+void MacroAssembler::copy64_avx(Register dst, Register src, Register index, XMMRegister xmm,\n+                                bool conjoint, int shift, int offset, bool use64byteVector) {\n+  assert(MaxVectorSize == 64 || MaxVectorSize == 32, \"vector length mismatch\");\n+  use64byteVector |= MaxVectorSize > 32 && AVX3Threshold == 0;\n+  if (!use64byteVector) {\n+    if (conjoint) {\n+      copy32_avx(dst, src, index, xmm, shift, offset+32);\n+      copy32_avx(dst, src, index, xmm, shift, offset);\n+    } else {\n+      copy32_avx(dst, src, index, xmm, shift, offset);\n+      copy32_avx(dst, src, index, xmm, shift, offset+32);\n+    }\n+  } else {\n+    Address::ScaleFactor scale = (Address::ScaleFactor)(shift);\n+    evmovdquq(xmm, Address(src, index, scale, offset), Assembler::AVX_512bit);\n+    evmovdquq(Address(dst, index, scale, offset), xmm, Assembler::AVX_512bit);\n+  }\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":68,"deletions":0,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -1730,0 +1730,17 @@\n+\n+  void copy64_masked_avx(Register dst, Register src, XMMRegister xmm,\n+                         KRegister mask, Register length, Register index,\n+                         Register temp, int shift = Address::times_1, int offset = 0,\n+                         bool use64byteVector = false);\n+\n+  void copy32_masked_avx(Register dst, Register src, XMMRegister xmm,\n+                         KRegister mask, Register length, Register index,\n+                         Register temp, int shift = Address::times_1, int offset = 0);\n+\n+  void copy32_avx(Register dst, Register src, Register index, XMMRegister xmm,\n+                  int shift = Address::times_1, int offset = 0);\n+\n+  void copy64_avx(Register dst, Register src, Register index, XMMRegister xmm,\n+                  bool conjoint, int shift = Address::times_1, int offset = 0,\n+                  bool use64byteVector = false);\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1127,18 +1127,2 @@\n-      \/\/ Copy 64-bytes per iteration\n-      if (UseAVX > 2) {\n-        Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;\n-\n-        __ BIND(L_copy_bytes);\n-        __ cmpptr(qword_count, (-1 * AVX3Threshold \/ 8));\n-        __ jccb(Assembler::less, L_above_threshold);\n-        __ jmpb(L_below_threshold);\n-\n-        __ bind(L_loop_avx512);\n-        __ evmovdqul(xmm0, Address(end_from, qword_count, Address::times_8, -56), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(end_to, qword_count, Address::times_8, -56), xmm0, Assembler::AVX_512bit);\n-        __ bind(L_above_threshold);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop_avx512);\n-        __ jmpb(L_32_byte_head);\n-\n-        __ bind(L_loop_avx2);\n+      __ BIND(L_loop);\n+      if (UseAVX >= 2) {\n@@ -1149,7 +1133,0 @@\n-        __ bind(L_below_threshold);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop_avx2);\n-\n-        __ bind(L_32_byte_head);\n-        __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n-        __ jccb(Assembler::greater, L_end);\n@@ -1157,22 +1134,8 @@\n-        __ BIND(L_loop);\n-        if (UseAVX == 2) {\n-          __ vmovdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n-          __ vmovdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n-          __ vmovdqu(xmm1, Address(end_from, qword_count, Address::times_8, -24));\n-          __ vmovdqu(Address(end_to, qword_count, Address::times_8, -24), xmm1);\n-        } else {\n-          __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n-          __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);\n-          __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);\n-          __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));\n-          __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);\n-        }\n-\n-        __ BIND(L_copy_bytes);\n-        __ addptr(qword_count, 8);\n-        __ jcc(Assembler::lessEqual, L_loop);\n-        __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n-        __ jccb(Assembler::greater, L_end);\n+        __ movdqu(xmm0, Address(end_from, qword_count, Address::times_8, -56));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -56), xmm0);\n+        __ movdqu(xmm1, Address(end_from, qword_count, Address::times_8, -40));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -40), xmm1);\n+        __ movdqu(xmm2, Address(end_from, qword_count, Address::times_8, -24));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, -24), xmm2);\n+        __ movdqu(xmm3, Address(end_from, qword_count, Address::times_8, - 8));\n+        __ movdqu(Address(end_to, qword_count, Address::times_8, - 8), xmm3);\n@@ -1180,0 +1143,6 @@\n+\n+      __ BIND(L_copy_bytes);\n+      __ addptr(qword_count, 8);\n+      __ jcc(Assembler::lessEqual, L_loop);\n+      __ subptr(qword_count, 4);  \/\/ sub(8) and add(4)\n+      __ jccb(Assembler::greater, L_end);\n@@ -1235,18 +1204,2 @@\n-      \/\/ Copy 64-bytes per iteration\n-      if (UseAVX > 2) {\n-        Label L_loop_avx512, L_loop_avx2, L_32_byte_head, L_above_threshold, L_below_threshold;\n-\n-        __ BIND(L_copy_bytes);\n-        __ cmpptr(qword_count, (AVX3Threshold \/ 8));\n-        __ jccb(Assembler::greater, L_above_threshold);\n-        __ jmpb(L_below_threshold);\n-\n-        __ BIND(L_loop_avx512);\n-        __ evmovdqul(xmm0, Address(from, qword_count, Address::times_8, 0), Assembler::AVX_512bit);\n-        __ evmovdqul(Address(dest, qword_count, Address::times_8, 0), xmm0, Assembler::AVX_512bit);\n-        __ bind(L_above_threshold);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop_avx512);\n-        __ jmpb(L_32_byte_head);\n-\n-        __ bind(L_loop_avx2);\n+      __ BIND(L_loop);\n+      if (UseAVX >= 2) {\n@@ -1255,9 +1208,2 @@\n-        __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8, 0));\n-        __ vmovdqu(Address(dest, qword_count, Address::times_8, 0), xmm1);\n-        __ bind(L_below_threshold);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop_avx2);\n-\n-        __ bind(L_32_byte_head);\n-        __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n-        __ jccb(Assembler::less, L_end);\n+        __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));\n+        __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);\n@@ -1265,16 +1211,9 @@\n-        __ BIND(L_loop);\n-        if (UseAVX == 2) {\n-          __ vmovdqu(xmm0, Address(from, qword_count, Address::times_8, 32));\n-          __ vmovdqu(Address(dest, qword_count, Address::times_8, 32), xmm0);\n-          __ vmovdqu(xmm1, Address(from, qword_count, Address::times_8,  0));\n-          __ vmovdqu(Address(dest, qword_count, Address::times_8,  0), xmm1);\n-        } else {\n-          __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);\n-          __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);\n-          __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));\n-          __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);\n-          __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));\n-          __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);\n-        }\n+        __ movdqu(xmm0, Address(from, qword_count, Address::times_8, 48));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 48), xmm0);\n+        __ movdqu(xmm1, Address(from, qword_count, Address::times_8, 32));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 32), xmm1);\n+        __ movdqu(xmm2, Address(from, qword_count, Address::times_8, 16));\n+        __ movdqu(Address(dest, qword_count, Address::times_8, 16), xmm2);\n+        __ movdqu(xmm3, Address(from, qword_count, Address::times_8,  0));\n+        __ movdqu(Address(dest, qword_count, Address::times_8,  0), xmm3);\n+      }\n@@ -1282,3 +1221,3 @@\n-        __ BIND(L_copy_bytes);\n-        __ subptr(qword_count, 8);\n-        __ jcc(Assembler::greaterEqual, L_loop);\n+      __ BIND(L_copy_bytes);\n+      __ subptr(qword_count, 8);\n+      __ jcc(Assembler::greaterEqual, L_loop);\n@@ -1286,3 +1225,2 @@\n-        __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n-        __ jccb(Assembler::less, L_end);\n-      }\n+      __ addptr(qword_count, 4);  \/\/ add(8) and sub(4)\n+      __ jccb(Assembler::less, L_end);\n@@ -1326,0 +1264,566 @@\n+#ifndef PRODUCT\n+    int& get_profile_ctr(int shift) {\n+      if ( 0 == shift)\n+        return SharedRuntime::_jbyte_array_copy_ctr;\n+      else if(1 == shift)\n+        return SharedRuntime::_jshort_array_copy_ctr;\n+      else if(2 == shift)\n+        return SharedRuntime::_jint_array_copy_ctr;\n+      else\n+        return SharedRuntime::_jlong_array_copy_ctr;\n+    }\n+#endif\n+\n+  void setup_argument_regs(BasicType type) {\n+    if (type == T_BYTE || type == T_SHORT) {\n+      setup_arg_regs(); \/\/ from => rdi, to => rsi, count => rdx\n+                        \/\/ r9 and r10 may be used to save non-volatile registers\n+    } else {\n+      setup_arg_regs_using_thread(); \/\/ from => rdi, to => rsi, count => rdx\n+                                     \/\/ r9 is used to save r15_thread\n+    }\n+  }\n+\n+  void restore_argument_regs(BasicType type) {\n+    if (type == T_BYTE || type == T_SHORT) {\n+      restore_arg_regs();\n+    } else {\n+      restore_arg_regs_using_thread();\n+    }\n+  }\n+\n+  void generate_arraycopy_avx3_special_cases(XMMRegister xmm, KRegister mask, Register from,\n+                                             Register to, Register count, int shift,\n+                                             Register index, Register temp,\n+                                             bool use64byteVector, Label& L_entry, Label& L_exit) {\n+    Label L_entry_64, L_entry_96, L_entry_128;\n+    Label L_entry_160, L_entry_192;\n+\n+    int size_mat[][6] = {\n+    \/* T_BYTE *\/ {32 , 64,  96 , 128 , 160 , 192 },\n+    \/* T_SHORT*\/ {16 , 32,  48 , 64  , 80  , 96  },\n+    \/* T_INT  *\/ {8  , 16,  24 , 32  , 40  , 48  },\n+    \/* T_LONG *\/ {4  ,  8,  12 , 16  , 20  , 24  }\n+    };\n+\n+    \/\/ Case A) Special case for length less than equal to 32 bytes.\n+    __ cmpq(count, size_mat[shift][0]);\n+    __ jccb(Assembler::greater, L_entry_64);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, index, temp, shift);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case B) Special case for length less than equal to 64 bytes.\n+    __ BIND(L_entry_64);\n+    __ cmpq(count, size_mat[shift][1]);\n+    __ jccb(Assembler::greater, L_entry_96);\n+    __ copy64_masked_avx(to, from, xmm, mask, count, index, temp, shift, 0, use64byteVector);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case C) Special case for length less than equal to 96 bytes.\n+    __ BIND(L_entry_96);\n+    __ cmpq(count, size_mat[shift][2]);\n+    __ jccb(Assembler::greater, L_entry_128);\n+    __ copy64_avx(to, from, index, xmm, false, shift, 0, use64byteVector);\n+    __ subq(count, 64 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, index, temp, shift, 64);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case D) Special case for length less than equal to 128 bytes.\n+    __ BIND(L_entry_128);\n+    __ cmpq(count, size_mat[shift][3]);\n+    __ jccb(Assembler::greater, L_entry_160);\n+    __ copy64_avx(to, from, index, xmm, false, shift, 0, use64byteVector);\n+    __ copy32_avx(to, from, index, xmm, shift, 64);\n+    __ subq(count, 96 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, index, temp, shift, 96);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case E) Special case for length less than equal to 160 bytes.\n+    __ BIND(L_entry_160);\n+    __ cmpq(count, size_mat[shift][4]);\n+    __ jccb(Assembler::greater, L_entry_192);\n+    __ copy64_avx(to, from, index, xmm, false, shift, 0, use64byteVector);\n+    __ copy64_avx(to, from, index, xmm, false, shift, 64, use64byteVector);\n+    __ subq(count, 128 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, index, temp, shift, 128);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case F) Special case for length less than equal to 192 bytes.\n+    __ BIND(L_entry_192);\n+    __ cmpq(count, size_mat[shift][5]);\n+    __ jcc(Assembler::greater, L_entry);\n+    __ copy64_avx(to, from, index, xmm, false, shift, 0, use64byteVector);\n+    __ copy64_avx(to, from, index, xmm, false, shift, 64, use64byteVector);\n+    __ copy32_avx(to, from, index, xmm, shift, 128);\n+    __ subq(count, 160 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, index, temp, shift, 160);\n+    __ jmp(L_exit);\n+  }\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source array address\n+  \/\/   c_rarg1   - destination array address\n+  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n+  \/\/\n+  \/\/\n+  \/\/ Side Effects:\n+  \/\/   disjoint_copy_avx3_masked is set to the no-overlap entry point\n+  \/\/   used by generate_conjoint_[byte\/int\/short\/long]_copy().\n+  \/\/\n+  address generate_disjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n+                                             bool aligned, bool is_oop, bool dest_uninitialized) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    bool use64byteVector = false;\n+    Label L_main_loop, L_main_loop_64bytes, L_tail, L_tail64, L_exit, L_entry;\n+    Label L_repmovs, L_main_pre_loop, L_main_pre_loop_64bytes, L_pre_main_post_64;\n+    const Register from        = rdi;  \/\/ source array address\n+    const Register to          = rsi;  \/\/ destination array address\n+    const Register count       = rdx;  \/\/ elements count\n+    const Register temp1       = r8;\n+    const Register temp2       = r11;\n+    const Register temp3       = rax;\n+    const Register temp4       = rcx;\n+    \/\/ End pointers are inclusive, and if count is not zero they point\n+    \/\/ to the last unit copied:  end_to[0] := end_from[0]\n+\n+    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    assert_clean_int(c_rarg2, rax);    \/\/ Make sure 'count' is clean int.\n+\n+    if (entry != NULL) {\n+      *entry = __ pc();\n+       \/\/ caller can pass a 64-bit byte count here (from Unsafe.copyMemory)\n+      BLOCK_COMMENT(\"Entry:\");\n+    }\n+\n+    BasicType type_vec[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+    BasicType type = is_oop ? T_OBJECT : type_vec[shift];\n+\n+    setup_argument_regs(type);\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY | ARRAYCOPY_DISJOINT;\n+    if (dest_uninitialized) {\n+      decorators |= IS_DEST_UNINITIALIZED;\n+    }\n+    if (aligned) {\n+      decorators |= ARRAYCOPY_ALIGNED;\n+    }\n+    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n+\n+    {\n+      \/\/ Type(shift)           byte(0), short(1), int(2),   long(3)\n+      int loop_size[]        = { 192,     96,       48,      24};\n+      int threshold[]        = { 4096,    2048,     1024,    512};\n+\n+      \/\/ UnsafeCopyMemory page error: continue after ucm\n+      UnsafeCopyMemoryMark ucmm(this, !is_oop && !aligned, true);\n+      \/\/ 'from', 'to' and 'count' are now valid\n+\n+      \/\/ temp1 holds remaining count and temp4 holds running count used to compute\n+      \/\/ next address offset for start of to\/from addresses (temp4 * scale).\n+      __ mov64(temp4, 0);\n+      __ movq(temp1, count);\n+\n+      \/\/ Zero length check.\n+      __ BIND(L_tail);\n+      __ cmpq(temp1, 0);\n+      __ jcc(Assembler::lessEqual, L_exit);\n+\n+      \/\/ Special cases using 32 byte [masked] vector copy operations.\n+      generate_arraycopy_avx3_special_cases(xmm1, k2, from, to, temp1, shift,\n+                                            temp4, temp3, use64byteVector, L_entry, L_exit);\n+\n+      \/\/ PRE-MAIN-POST loop for aligned copy.\n+      __ BIND(L_entry);\n+\n+      if (AVX3Threshold != 0) {\n+        __ cmpq(count, threshold[shift]);\n+        if (MaxVectorSize == 64) {\n+          \/\/ Copy using 64 byte vectors.\n+          __ jcc(Assembler::greaterEqual, L_pre_main_post_64);\n+        } else {\n+          assert(MaxVectorSize < 64, \"vector size should be < 64 bytes\");\n+          \/\/ REP MOVS offer a faster copy path.\n+          __ jcc(Assembler::greaterEqual, L_repmovs);\n+        }\n+      }\n+\n+      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+        \/\/ Partial copy to make dst address 32 byte aligned.\n+        __ movq(temp2, to);\n+        __ andq(temp2, 31);\n+        __ jcc(Assembler::equal, L_main_pre_loop);\n+\n+        __ negptr(temp2);\n+        __ addq(temp2, 32);\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ movq(temp3, temp2);\n+        __ copy32_masked_avx(to, from, xmm1, k2, temp3, temp4, temp1, shift);\n+        __ movq(temp4, temp2);\n+        __ movq(temp1, count);\n+        __ subq(temp1, temp2);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail);\n+\n+        __ BIND(L_main_pre_loop);\n+        __ subq(temp1, loop_size[shift]);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at 32 byte granularity.\n+        __ BIND(L_main_loop);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 0);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 64);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 128);\n+           __ addptr(temp4, loop_size[shift]);\n+           __ subq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop);\n+\n+        __ addq(temp1, loop_size[shift]);\n+\n+        \/\/ Tail loop.\n+        __ jmp(L_tail);\n+\n+        __ BIND(L_repmovs);\n+          __ movq(temp2, temp1);\n+          \/\/ Swap to(RSI) and from(RDI) addresses to comply with REP MOVs semantics.\n+          __ movq(temp3, to);\n+          __ movq(to,  from);\n+          __ movq(from, temp3);\n+          \/\/ Save to\/from for restoration post rep_mov.\n+          __ movq(temp1, to);\n+          __ movq(temp3, from);\n+          if(shift < 3) {\n+            __ shrq(temp2, 3-shift);     \/\/ quad word count\n+          }\n+          __ movq(temp4 , temp2);        \/\/ move quad ward count into temp4(RCX).\n+          __ rep_mov();\n+          __ shlq(temp2, 3);             \/\/ convert quad words into byte count.\n+          if(shift) {\n+            __ shrq(temp2, shift);       \/\/ type specific count.\n+          }\n+          \/\/ Restore original addresses in to\/from.\n+          __ movq(to, temp3);\n+          __ movq(from, temp1);\n+          __ movq(temp4, temp2);\n+          __ movq(temp1, count);\n+          __ subq(temp1, temp2);         \/\/ tailing part (less than a quad ward size).\n+          __ jmp(L_tail);\n+      }\n+\n+      if (MaxVectorSize > 32) {\n+        __ BIND(L_pre_main_post_64);\n+        \/\/ Partial copy to make dst address 64 byte aligned.\n+        __ movq(temp2, to);\n+        __ andq(temp2, 63);\n+        __ jcc(Assembler::equal, L_main_pre_loop_64bytes);\n+\n+        __ negptr(temp2);\n+        __ addq(temp2, 64);\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ movq(temp3, temp2);\n+        __ copy64_masked_avx(to, from, xmm1, k2, temp3, temp4, temp1, shift, 0 , true);\n+        __ movq(temp4, temp2);\n+        __ movq(temp1, count);\n+        __ subq(temp1, temp2);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail64);\n+\n+        __ BIND(L_main_pre_loop_64bytes);\n+        __ subq(temp1, loop_size[shift]);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at\n+        \/\/ 64 byte copy granularity.\n+        __ BIND(L_main_loop_64bytes);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 0 , true);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 64, true);\n+           __ copy64_avx(to, from, temp4, xmm1, false, shift, 128, true);\n+           __ addptr(temp4, loop_size[shift]);\n+           __ subq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop_64bytes);\n+\n+        __ addq(temp1, loop_size[shift]);\n+        \/\/ Zero length check.\n+        __ jcc(Assembler::lessEqual, L_exit);\n+\n+        __ BIND(L_tail64);\n+\n+        \/\/ Tail handling using 64 byte [masked] vector copy operations.\n+        use64byteVector = true;\n+        generate_arraycopy_avx3_special_cases(xmm1, k2, from, to, temp1, shift,\n+                                              temp4, temp3, use64byteVector, L_entry, L_exit);\n+      }\n+      __ BIND(L_exit);\n+    }\n+\n+    address ucme_exit_pc = __ pc();\n+    \/\/ When called from generic_arraycopy r11 contains specific values\n+    \/\/ used during arraycopy epilogue, re-initializing r11.\n+    if (is_oop) {\n+      __ movq(r11, shift == 3 ? count : to);\n+    }\n+    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n+    restore_argument_regs(type);\n+    inc_counter_np(get_profile_ctr(shift)); \/\/ Update counter after rscratch1 is free\n+    __ xorptr(rax, rax); \/\/ return 0\n+    __ vzeroupper();\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+    return start;\n+  }\n+\n+  void generate_arraycopy_avx3_special_cases_conjoint(XMMRegister xmm, KRegister mask, Register from,\n+                                                      Register to, Register start_index, Register end_index,\n+                                                      Register count, int shift, Register temp,\n+                                                      bool use64byteVector, Label& L_entry, Label& L_exit) {\n+    Label L_entry_64, L_entry_96, L_entry_128;\n+    Label L_entry_160, L_entry_192;\n+    bool avx3 = MaxVectorSize > 32 && AVX3Threshold == 0;\n+\n+    int size_mat[][6] = {\n+    \/* T_BYTE *\/ {32 , 64,  96 , 128 , 160 , 192 },\n+    \/* T_SHORT*\/ {16 , 32,  48 , 64  , 80  , 96  },\n+    \/* T_INT  *\/ {8  , 16,  24 , 32  , 40  , 48  },\n+    \/* T_LONG *\/ {4  ,  8,  12 , 16  , 20  , 24  }\n+    };\n+\n+    \/\/ Case A) Special case for length less than equal to 32 bytes.\n+    __ cmpq(count, size_mat[shift][0]);\n+    __ jccb(Assembler::greater, L_entry_64);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, start_index, temp, shift);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case B) Special case for length less than equal to 64 bytes.\n+    __ BIND(L_entry_64);\n+    __ cmpq(count, size_mat[shift][1]);\n+    __ jccb(Assembler::greater, L_entry_96);\n+    if (avx3) {\n+       __ copy64_masked_avx(to, from, xmm, mask, count, start_index, temp, shift, 0, true);\n+    } else {\n+       __ copy32_avx(to, from, end_index, xmm, shift, -32);\n+       __ subq(count, 32 >> shift);\n+       __ copy32_masked_avx(to, from, xmm, mask, count, start_index, temp, shift);\n+    }\n+    __ jmp(L_exit);\n+\n+    \/\/ Case C) Special case for length less than equal to 96 bytes.\n+    __ BIND(L_entry_96);\n+    __ cmpq(count, size_mat[shift][2]);\n+    __ jccb(Assembler::greater, L_entry_128);\n+    __ copy64_avx(to, from, end_index, xmm, true, shift, -64, use64byteVector);\n+    __ subq(count, 64 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, start_index, temp, shift);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case D) Special case for length less than equal to 128 bytes.\n+    __ BIND(L_entry_128);\n+    __ cmpq(count, size_mat[shift][3]);\n+    __ jccb(Assembler::greater, L_entry_160);\n+    __ copy64_avx(to, from, end_index, xmm, true, shift, -64, use64byteVector);\n+    __ copy32_avx(to, from, end_index, xmm, shift, -96);\n+    __ subq(count, 96 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, start_index, temp, shift);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case E) Special case for length less than equal to 160 bytes.\n+    __ BIND(L_entry_160);\n+    __ cmpq(count, size_mat[shift][4]);\n+    __ jccb(Assembler::greater, L_entry_192);\n+    __ copy64_avx(to, from, end_index, xmm, true, shift, -64, use64byteVector);\n+    __ copy64_avx(to, from, end_index, xmm, true, shift, -128, use64byteVector);\n+    __ subq(count, 128 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, start_index, temp, shift);\n+    __ jmp(L_exit);\n+\n+    \/\/ Case F) Special case for length less than equal to 192 bytes.\n+    __ BIND(L_entry_192);\n+    __ cmpq(count, size_mat[shift][5]);\n+    __ jcc(Assembler::greater, L_entry);\n+    __ copy64_avx(to, from, end_index, xmm, true, shift, -64, use64byteVector);\n+    __ copy64_avx(to, from, end_index, xmm, true, shift, -128, use64byteVector);\n+    __ copy32_avx(to, from, end_index, xmm, shift, -160);\n+    __ subq(count, 160 >> shift);\n+    __ copy32_masked_avx(to, from, xmm, mask, count, start_index, temp, shift);\n+    __ jmp(L_exit);\n+  }\n+\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source array address\n+  \/\/   c_rarg1   - destination array address\n+  \/\/   c_rarg2   - element count, treated as ssize_t, can be zero\n+  \/\/\n+  \/\/\n+  address generate_conjoint_copy_avx3_masked(address* entry, const char *name, int shift,\n+                                             address nooverlap_target, bool aligned, bool is_oop,\n+                                             bool dest_uninitialized) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", name);\n+    address start = __ pc();\n+\n+    bool use64byteVector = false;\n+\n+    Label L_main_pre_loop, L_main_pre_loop_64bytes, L_pre_main_post_64;\n+    Label L_main_loop, L_main_loop_64bytes, L_tail, L_tail64, L_exit, L_entry;\n+    const Register from        = rdi;  \/\/ source array address\n+    const Register to          = rsi;  \/\/ destination array address\n+    const Register count       = rdx;  \/\/ elements count\n+    const Register temp1       = r8;\n+    const Register temp2       = rcx;\n+    const Register temp3       = r11;\n+    const Register temp4       = rax;\n+    \/\/ End pointers are inclusive, and if count is not zero they point\n+    \/\/ to the last unit copied:  end_to[0] := end_from[0]\n+\n+    __ enter(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    assert_clean_int(c_rarg2, rax);    \/\/ Make sure 'count' is clean int.\n+\n+    if (entry != NULL) {\n+      *entry = __ pc();\n+       \/\/ caller can pass a 64-bit byte count here (from Unsafe.copyMemory)\n+      BLOCK_COMMENT(\"Entry:\");\n+    }\n+\n+    array_overlap_test(nooverlap_target, (Address::ScaleFactor)(shift));\n+\n+    BasicType type_vec[] = { T_BYTE,  T_SHORT,  T_INT,   T_LONG};\n+    BasicType type = is_oop ? T_OBJECT : type_vec[shift];\n+\n+    setup_argument_regs(type);\n+\n+    DecoratorSet decorators = IN_HEAP | IS_ARRAY;\n+    if (dest_uninitialized) {\n+      decorators |= IS_DEST_UNINITIALIZED;\n+    }\n+    if (aligned) {\n+      decorators |= ARRAYCOPY_ALIGNED;\n+    }\n+    BarrierSetAssembler *bs = BarrierSet::barrier_set()->barrier_set_assembler();\n+    bs->arraycopy_prologue(_masm, decorators, type, from, to, count);\n+    {\n+      \/\/ Type(shift)       byte(0), short(1), int(2),   long(3)\n+      int loop_size[]   = { 192,     96,       48,      24};\n+      int threshold[]   = { 4096,    2048,     1024,    512};\n+\n+      \/\/ UnsafeCopyMemory page error: continue after ucm\n+      UnsafeCopyMemoryMark ucmm(this, !is_oop && !aligned, true);\n+      \/\/ 'from', 'to' and 'count' are now valid\n+\n+      \/\/ temp1 holds remaining count.\n+      __ movq(temp1, count);\n+\n+      \/\/ Zero length check.\n+      __ BIND(L_tail);\n+      __ cmpq(temp1, 0);\n+      __ jcc(Assembler::lessEqual, L_exit);\n+\n+      __ mov64(temp2, 0);\n+      __ movq(temp3, temp1);\n+      \/\/ Special cases using 32 byte [masked] vector copy operations.\n+      generate_arraycopy_avx3_special_cases_conjoint(xmm1, k2, from, to, temp2, temp3, temp1, shift,\n+                                                     temp4, use64byteVector, L_entry, L_exit);\n+\n+      \/\/ PRE-MAIN-POST loop for aligned copy.\n+      __ BIND(L_entry);\n+\n+      if (MaxVectorSize > 32 && AVX3Threshold != 0) {\n+        __ cmpq(temp1, threshold[shift]);\n+        __ jcc(Assembler::greaterEqual, L_pre_main_post_64);\n+      }\n+\n+      if (MaxVectorSize < 64  || AVX3Threshold != 0) {\n+        \/\/ Partial copy to make dst address 32 byte aligned.\n+        __ leaq(temp2, Address(to, temp1, (Address::ScaleFactor)(shift), 0));\n+        __ andq(temp2, 31);\n+        __ jcc(Assembler::equal, L_main_pre_loop);\n+\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ subq(temp1, temp2);\n+        __ copy32_masked_avx(to, from, xmm1, k2, temp2, temp1, temp3, shift);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail);\n+\n+        __ BIND(L_main_pre_loop);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at 32 byte granularity.\n+        __ BIND(L_main_loop);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -64);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -128);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -192);\n+           __ subptr(temp1, loop_size[shift]);\n+           __ cmpq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop);\n+\n+        \/\/ Tail loop.\n+        __ jmp(L_tail);\n+      }\n+\n+      if (MaxVectorSize > 32) {\n+        __ BIND(L_pre_main_post_64);\n+        \/\/ Partial copy to make dst address 64 byte aligned.\n+        __ leaq(temp2, Address(to, temp1, (Address::ScaleFactor)(shift), 0));\n+        __ andq(temp2, 63);\n+        __ jcc(Assembler::equal, L_main_pre_loop_64bytes);\n+\n+        if (shift) {\n+          __ shrq(temp2, shift);\n+        }\n+        __ subq(temp1, temp2);\n+        __ copy64_masked_avx(to, from, xmm1, k2, temp2, temp1, temp3, shift, 0 , true);\n+\n+        __ cmpq(temp1, loop_size[shift]);\n+        __ jcc(Assembler::less, L_tail64);\n+\n+        __ BIND(L_main_pre_loop_64bytes);\n+\n+        \/\/ Main loop with aligned copy block size of 192 bytes at\n+        \/\/ 64 byte copy granularity.\n+        __ BIND(L_main_loop_64bytes);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -64 , true);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -128, true);\n+           __ copy64_avx(to, from, temp1, xmm1, true, shift, -192, true);\n+           __ subq(temp1, loop_size[shift]);\n+           __ cmpq(temp1, loop_size[shift]);\n+           __ jcc(Assembler::greater, L_main_loop_64bytes);\n+\n+        \/\/ Zero length check.\n+        __ cmpq(temp1, 0);\n+        __ jcc(Assembler::lessEqual, L_exit);\n+\n+        __ BIND(L_tail64);\n+\n+        \/\/ Tail handling using 64 byte [masked] vector copy operations.\n+        use64byteVector = true;\n+        __ mov64(temp2, 0);\n+        __ movq(temp3, temp1);\n+        generate_arraycopy_avx3_special_cases_conjoint(xmm1, k2, from, to, temp2, temp3, temp1, shift,\n+                                                       temp4, use64byteVector, L_entry, L_exit);\n+      }\n+      __ BIND(L_exit);\n+    }\n+    address ucme_exit_pc = __ pc();\n+    \/\/ When called from generic_arraycopy r11 contains specific values\n+    \/\/ used during arraycopy epilogue, re-initializing r11.\n+    if(is_oop) {\n+      __ movq(r11, count);\n+    }\n+    bs->arraycopy_epilogue(_masm, decorators, type, from, to, count);\n+    restore_argument_regs(type);\n+    inc_counter_np(get_profile_ctr(shift)); \/\/ Update counter after rscratch1 is free\n+    __ xorptr(rax, rax); \/\/ return 0\n+    __ vzeroupper();\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+    return start;\n+  }\n+\n+\n@@ -1346,0 +1850,4 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jbyte_disjoint_arraycopy_avx3\", 0,\n+                                                 aligned, false, false);\n+    }\n@@ -1456,0 +1964,4 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jbyte_conjoint_arraycopy_avx3\", 0,\n+                                                 nooverlap_target, aligned, false, false);\n+    }\n@@ -1561,0 +2073,5 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jshort_disjoint_arraycopy_avx3\", 1,\n+                                                 aligned, false, false);\n+    }\n+\n@@ -1685,0 +2202,4 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jshort_conjoint_arraycopy_avx3\", 1,\n+                                                 nooverlap_target, aligned, false, false);\n+    }\n@@ -1783,0 +2304,5 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jint_disjoint_arraycopy_avx3\", 2,\n+                                                 aligned, is_oop, dest_uninitialized);\n+    }\n+\n@@ -1887,0 +2413,4 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jint_conjoint_arraycopy_avx3\", 2,\n+                                                 nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    }\n@@ -1994,0 +2524,4 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_disjoint_copy_avx3_masked(entry, \"jlong_disjoint_arraycopy_avx3\", 3,\n+                                                 aligned, is_oop, dest_uninitialized);\n+    }\n@@ -2098,0 +2632,4 @@\n+    if (VM_Version::supports_avx512vlbw() && MaxVectorSize  >= 32) {\n+       return generate_conjoint_copy_avx3_masked(entry, \"jlong_conjoint_arraycopy_avx3\", 3,\n+                                                 nooverlap_target, aligned, is_oop, dest_uninitialized);\n+    }\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":634,"deletions":96,"binary":false,"changes":730,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  code_size2 = 35300 LP64_ONLY(+11400)          \/\/ simply increase if too small (assembler will crash if too small)\n+  code_size2 = 35300 LP64_ONLY(+21400)          \/\/ simply increase if too small (assembler will crash if too small)\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -764,0 +764,2 @@\n+      _features &= ~CPU_AVX512BW;\n+      _features &= ~CPU_AVX512VL;\n@@ -1165,1 +1167,1 @@\n-    if (!is_power_of_2(AVX3Threshold)) {\n+    if (AVX3Threshold != 0 && !is_power_of_2(AVX3Threshold)) {\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -87,1 +87,1 @@\n-        assert CodeUtil.isPowerOf2(useAVX3Threshold) : \"AVX3Threshold must be power of 2\";\n+        assert useAVX3Threshold == 0 || CodeUtil.isPowerOf2(useAVX3Threshold) : \"AVX3Threshold must be power of 2\";\n","filename":"src\/jdk.internal.vm.compiler\/share\/classes\/org.graalvm.compiler.lir.amd64\/src\/org\/graalvm\/compiler\/lir\/amd64\/AMD64ArrayCompareToOp.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -74,1 +74,1 @@\n-        assert CodeUtil.isPowerOf2(useAVX3Threshold) : \"AVX3Threshold must be power of 2\";\n+        assert useAVX3Threshold == 0 || CodeUtil.isPowerOf2(useAVX3Threshold) : \"AVX3Threshold must be power of 2\";\n","filename":"src\/jdk.internal.vm.compiler\/share\/classes\/org.graalvm.compiler.lir.amd64\/src\/org\/graalvm\/compiler\/lir\/amd64\/AMD64StringLatin1InflateOp.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -79,1 +79,1 @@\n-        assert CodeUtil.isPowerOf2(useAVX3Threshold) : \"AVX3Threshold must be power of 2\";\n+        assert useAVX3Threshold == 0 || CodeUtil.isPowerOf2(useAVX3Threshold) : \"AVX3Threshold must be power of 2\";\n","filename":"src\/jdk.internal.vm.compiler\/share\/classes\/org.graalvm.compiler.lir.amd64\/src\/org\/graalvm\/compiler\/lir\/amd64\/AMD64StringUTF16CompressOp.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -0,0 +1,269 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.arraycopy;\n+import java.util.Random;\n+\n+\/**\n+ * @test\n+ * @bug 8251871\n+ * @summary Optimize arrayCopy using AVX-512 masked instructions.\n+ *\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=0 -XX:MaxVectorSize=32 -XX:+UnlockDiagnosticVMOptions\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=0 -XX:MaxVectorSize=64\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=32 -XX:+UnlockDiagnosticVMOptions -XX:MaxVectorSize=32 -XX:+UnlockDiagnosticVMOption\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=32 -XX:+UnlockDiagnosticVMOptions -XX:MaxVectorSize=64\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=64 -XX:MaxVectorSize=64\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=32 -XX:+UnlockDiagnosticVMOptions -XX:MaxVectorSize=32 -XX:+UnlockDiagnosticVMOption -XX:ArrayCopyLoadStoreMaxElem=16\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=64 -XX:MaxVectorSize=64 -XX:ArrayCopyLoadStoreMaxElem=16\n+ *      compiler.arraycopy.TestArrayCopyConjoint\n+ *\n+ *\/\n+\n+public class TestArrayCopyConjoint {\n+\n+   public static final int SIZE = 4096;\n+   public static byte[] fromByteArr, toByteArr, valByteArr;\n+   public static char[] fromCharArr, toCharArr, valCharArr;\n+   public static int[] fromIntArr, toIntArr, valIntArr;\n+   public static long[] fromLongArr, toLongArr, valLongArr;\n+\n+   static public  void reinit(Class<?> c) {\n+     if (c == byte.class) {\n+       for (int i = 0 ; i < SIZE ; i++) {\n+         fromByteArr[i] = (byte)i;\n+       }\n+     } else if (c == char.class) {\n+       for (int i = 0 ; i < SIZE ; i++) {\n+         fromCharArr[i] = (char)i;\n+       }\n+     } else if (c == int.class) {\n+       for (int i = 0 ; i < SIZE ; i++) {\n+         fromIntArr[i]  = i;\n+       }\n+     } else {\n+       assert c == long.class;\n+       for (int i = 0 ; i < SIZE ; i++) {\n+         fromLongArr[i] = i;\n+       }\n+     }\n+   }\n+\n+   static public void setup() {\n+     \/\/ Both positions aligned\n+     fromByteArr = new byte[SIZE];\n+     valByteArr  = new byte[SIZE];\n+     toByteArr = fromByteArr;\n+     fromCharArr = new char[SIZE];\n+     valCharArr  = new char[SIZE];\n+     toCharArr = fromCharArr;\n+     fromIntArr = new int[SIZE];\n+     valIntArr  = new int[SIZE];\n+     toIntArr = fromIntArr;\n+     fromLongArr = new long[SIZE];\n+     valLongArr  = new long[SIZE];\n+     toLongArr = fromLongArr;\n+\n+     for (int i = 0 ; i < SIZE ; i++) {\n+        fromByteArr[i] = (byte)i;\n+        valByteArr[i] = (byte)i;\n+        fromCharArr[i] = (char)i;\n+        valCharArr[i] = (char)i;\n+        fromIntArr[i]  = i;\n+        valIntArr[i]  = i;\n+        fromLongArr[i] = i;\n+        valLongArr[i] = i;\n+     }\n+    }\n+\n+    public static int validate_ctr = 0;\n+    public static <E> void validate(String msg, E arr, int length, int fromPos, int toPos) {\n+      validate_ctr++;\n+      if (arr instanceof byte [])  {\n+        byte [] barr = (byte [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (valByteArr[i+fromPos] != barr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + valByteArr[i+fromPos]\n+                                + \" actual   = \" + barr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \"  toPos = \" + toPos);\n+             throw new Error(\"Fail\");\n+\n+          }\n+      }\n+      else if (arr instanceof char [])  {\n+        char [] carr = (char [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (valCharArr[i+fromPos] != carr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + valCharArr[i+fromPos]\n+                                + \" actual   = \" + carr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+             throw new Error(\"Fail\");\n+          }\n+      }\n+      else if (arr instanceof int [])  {\n+        int [] iarr = (int [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (valIntArr[i+fromPos] != iarr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + valIntArr[i+fromPos]\n+                                + \" actual   = \" + iarr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+             throw new Error(\"Fail\");\n+          }\n+      }\n+      else if (arr instanceof long [])  {\n+        long [] larr = (long [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (valLongArr[i+fromPos] != larr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + valLongArr[i+fromPos]\n+                                + \" actual   = \" + larr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+             throw new Error(\"Fail\");\n+          }\n+      }\n+    }\n+\n+    public static void testByte(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromByteArr, fromPos, toByteArr, toPos, length);\n+       validate(\" Test ByteArr \", toByteArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testChar(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromCharArr, fromPos, toCharArr, toPos, length);\n+       validate(\" Test CharArr \", toCharArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testInt(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromIntArr, fromPos, toIntArr, toPos, length);\n+       validate(\" Test IntArr \", toIntArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testLong(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromLongArr, fromPos, toLongArr, toPos, length);\n+       validate(\" Test LongArr \", toLongArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testByte_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromByteArr, fromPos, toByteArr, toPos, 7);\n+       validate(\" Test Byte constant length 7 \", toByteArr, 7, fromPos, toPos);\n+    }\n+    public static void testByte_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromByteArr, fromPos, toByteArr, toPos, 45);\n+       validate(\" Test Byte constant length 45 \", toByteArr, 45, fromPos, toPos);\n+    }\n+\n+    public static void testChar_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromCharArr, fromPos, toCharArr, toPos, 7);\n+       validate(\" Test Char constant length 7 \", toCharArr, 7, fromPos, toPos);\n+    }\n+    public static void testChar_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromCharArr, fromPos, toCharArr, toPos, 22);\n+       validate(\" Test Char constant length 22 \", toCharArr, 22, fromPos, toPos);\n+    }\n+\n+    public static void testInt_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromIntArr, fromPos, toIntArr, toPos, 7);\n+       validate(\" Test Int constant length 7 \", toIntArr, 7, fromPos, toPos);\n+    }\n+    public static void testInt_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromIntArr, fromPos, toIntArr, toPos, 11);\n+       validate(\" Test Int constant length 11 \", toIntArr, 11, fromPos, toPos);\n+    }\n+\n+    public static void testLong_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromLongArr, fromPos, toLongArr, toPos, 3);\n+       validate(\" Test Long constant length 3 \", toLongArr, 3, fromPos, toPos);\n+    }\n+    public static void testLong_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromLongArr, fromPos, toLongArr, toPos, 6);\n+       validate(\" Test Long constant length 6 \", toLongArr, 6, fromPos, toPos);\n+    }\n+\n+\n+    public static void main(String [] args) {\n+      \/\/ Cases to test each new optimized stub special blocks.\n+      \/\/ Cases to test new PI handling (PI32 and PI64).\n+      \/\/ Cases to test vectorized constant array copies for all primitive types.\n+      \/\/                  LT32B   LT64B  LT96B  LT128B   LT160B   LT192B  LOOP1   LOOP2\n+      int [] lengths =  {   29,    59,    89,    125,     159,      189,   194,   1024 };\n+      Random r = new Random(1024);\n+\n+      setup();\n+\n+      try {\n+        for (int i = 0 ; i < 1000000 ; i++ ) {\n+          int index = r.nextInt(2048);\n+          testByte(lengths[i % lengths.length], index , index+2);\n+          reinit(byte.class);\n+          testByte_constant_LT32B (index , index+2);\n+          reinit(byte.class);\n+          testByte_constant_LT64B (index , index+2);\n+          reinit(byte.class);\n+\n+          testChar(lengths[i % lengths.length] >> 1, index , index+2);\n+          reinit(char.class);\n+          testChar_constant_LT32B (index , index+2);\n+          reinit(char.class);\n+          testChar_constant_LT64B (index , index+2);\n+          reinit(char.class);\n+\n+          testInt(lengths[i % lengths.length]  >> 2, index , index+2);\n+          reinit(int.class);\n+          testInt_constant_LT32B (index , index+2);\n+          reinit(int.class);\n+          testInt_constant_LT64B (index , index+2);\n+          reinit(int.class);\n+\n+          testLong(lengths[i % lengths.length] >> 3, index , index+2);\n+          reinit(long.class);\n+          testLong_constant_LT32B (index , index+2);\n+          reinit(long.class);\n+          testLong_constant_LT64B (index , index+2);\n+          reinit(long.class);\n+        }\n+        System.out.println(\"PASS : \" + validate_ctr);\n+      } catch (Exception e) {\n+        System.out.println(e.getMessage());\n+      }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/arraycopy\/TestArrayCopyConjoint.java","additions":269,"deletions":0,"binary":false,"changes":269,"status":"added"},{"patch":"@@ -0,0 +1,226 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package compiler.arraycopy;\n+import java.util.Random;\n+\n+\/**\n+ * @test\n+ * @bug 8251871\n+ * @summary Optimize arrayCopy using AVX-512 masked instructions.\n+ *\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=0 -XX:MaxVectorSize=32 -XX:+UnlockDiagnosticVMOptions\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=0 -XX:MaxVectorSize=64\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=32 -XX:+UnlockDiagnosticVMOptions -XX:MaxVectorSize=32 -XX:+UnlockDiagnosticVMOption\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=32 -XX:+UnlockDiagnosticVMOptions -XX:MaxVectorSize=64\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=64 -XX:MaxVectorSize=64\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=32 -XX:+UnlockDiagnosticVMOptions -XX:MaxVectorSize=32 -XX:+UnlockDiagnosticVMOption -XX:ArrayCopyLoadStoreMaxElem=16\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ * @run main\/othervm\/timeout=600 -XX:-TieredCompilation  -Xbatch -XX:+IgnoreUnrecognizedVMOptions\n+ *      -XX:UseAVX=3 -XX:+UnlockDiagnosticVMOptions -XX:ArrayCopyPartialInlineSize=64 -XX:MaxVectorSize=64 -XX:ArrayCopyLoadStoreMaxElem=16\n+ *      compiler.arraycopy.TestArrayCopyDisjoint\n+ *\n+ *\/\n+\n+public class TestArrayCopyDisjoint {\n+\n+   public static final int SIZE = 4096;\n+   public static byte[] fromByteArr, toByteArr;\n+   public static char[] fromCharArr, toCharArr;\n+   public static int[] fromIntArr, toIntArr;\n+   public static long[] fromLongArr, toLongArr;\n+\n+   static public void setup() {\n+     \/\/ Both positions aligned\n+     fromByteArr = new byte[SIZE];\n+     toByteArr = new byte[SIZE];\n+     fromCharArr = new char[SIZE];\n+     toCharArr = new char[SIZE];\n+     fromIntArr = new int[SIZE];\n+     toIntArr = new int[SIZE];\n+     fromLongArr = new long[SIZE];\n+     toLongArr = new long[SIZE];\n+\n+     for (int i = 0 ; i < SIZE ; i++) {\n+        fromByteArr[i] = (byte)i;\n+        fromCharArr[i] = (char)i;\n+        fromIntArr[i]  = i;\n+        fromLongArr[i] = i;\n+     }\n+    }\n+\n+    public static int validate_ctr = 0;\n+    public static <E> void validate(String msg, E arr, int length, int fromPos, int toPos) {\n+      validate_ctr++;\n+      if (arr instanceof byte [])  {\n+        byte [] barr = (byte [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (fromByteArr[i+fromPos] != barr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + fromByteArr[i+fromPos]\n+                                + \" actual   = \" + barr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+              throw new Error(\"Fail\");\n+          }\n+      }\n+      else if (arr instanceof char [])  {\n+        char [] carr = (char [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (fromCharArr[i+fromPos] != carr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + fromCharArr[i+fromPos]\n+                                + \" actual   = \" + carr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+              throw new Error(\"Fail\");\n+          }\n+      }\n+      else if (arr instanceof int [])  {\n+        int [] iarr = (int [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (fromIntArr[i+fromPos] != iarr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + fromIntArr[i+fromPos]\n+                                + \" actual   = \" + iarr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+              throw new Error(\"Fail\");\n+          }\n+      }\n+      else if (arr instanceof long [])  {\n+        long [] larr = (long [])arr;\n+        for(int i = 0 ; i < length; i++)\n+          if (fromLongArr[i+fromPos] != larr[i+toPos]) {\n+             System.out.println(msg + \"[\" + arr.getClass() + \"] Result mismtach at i = \" + i\n+                                + \" expected = \" + fromLongArr[i+fromPos]\n+                                + \" actual   = \" + larr[i+toPos]\n+                                + \" fromPos = \" + fromPos\n+                                + \" toPos = \" + toPos);\n+              throw new Error(\"Fail\");\n+          }\n+      }\n+    }\n+\n+    public static void testByte(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromByteArr, fromPos, toByteArr, toPos, length);\n+       validate(\" Test ByteArr \", toByteArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testChar(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromCharArr, fromPos, toCharArr, toPos, length);\n+       validate(\" Test CharArr \", toCharArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testInt(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromIntArr, fromPos, toIntArr, toPos, length);\n+       validate(\" Test IntArr \", toIntArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testLong(int length, int fromPos, int toPos) {\n+       System.arraycopy(fromLongArr, fromPos, toLongArr, toPos, length);\n+       validate(\" Test LongArr \", toLongArr, length, fromPos, toPos);\n+    }\n+\n+    public static void testByte_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromByteArr, fromPos, toByteArr, toPos, 7);\n+       validate(\" Test Byte constant length 7 \", toByteArr, 7, fromPos, toPos);\n+    }\n+    public static void testByte_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromByteArr, fromPos, toByteArr, toPos, 45);\n+       validate(\" Test Byte constant length 45 \", toByteArr, 45, fromPos, toPos);\n+    }\n+\n+    public static void testChar_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromCharArr, fromPos, toCharArr, toPos, 7);\n+       validate(\" Test Char constant length 7 \", toCharArr, 7, fromPos, toPos);\n+    }\n+    public static void testChar_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromCharArr, fromPos, toCharArr, toPos, 22);\n+       validate(\" Test Char constant length 22 \", toCharArr, 22, fromPos, toPos);\n+    }\n+\n+    public static void testInt_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromIntArr, fromPos, toIntArr, toPos, 7);\n+       validate(\" Test Int constant length 7 \", toIntArr, 7, fromPos, toPos);\n+    }\n+    public static void testInt_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromIntArr, fromPos, toIntArr, toPos, 11);\n+       validate(\" Test Int constant length 11 \", toIntArr, 11, fromPos, toPos);\n+    }\n+\n+    public static void testLong_constant_LT32B(int fromPos, int toPos) {\n+       System.arraycopy(fromLongArr, fromPos, toLongArr, toPos, 3);\n+       validate(\" Test Long constant length 3 \", toLongArr, 3, fromPos, toPos);\n+    }\n+    public static void testLong_constant_LT64B(int fromPos, int toPos) {\n+       System.arraycopy(fromLongArr, fromPos, toLongArr, toPos, 6);\n+       validate(\" Test Long constant length 6 \", toLongArr, 6, fromPos, toPos);\n+    }\n+\n+\n+    public static void main(String [] args) {\n+      \/\/ Cases to test each new optimized stub special blocks.\n+      \/\/ Cases to test new PI handling (PI32 and PI64).\n+      \/\/ Cases to test vectorized constant array copies for all primitive types.\n+      \/\/                  LT32B   LT64B  LT96B  LT128B   LT160B   LT192B  LOOP1   LOOP2\n+      int [] lengths =  {   29,    59,    89,    125,     159,      189,   194,   1024 };\n+      Random r = new Random(1024);\n+\n+      setup();\n+\n+      try {\n+        for (int i = 0 ; i < 1000000 ; i++ ) {\n+          testByte(lengths[i % lengths.length], r.nextInt(2048) , r.nextInt(2048));\n+          testByte_constant_LT32B (r.nextInt(2048) , r.nextInt(2048));\n+          testByte_constant_LT64B (r.nextInt(2048) , r.nextInt(2048));\n+\n+          testChar(lengths[i % lengths.length] >> 1, r.nextInt(2048) , r.nextInt(2048));\n+          testChar_constant_LT32B (r.nextInt(2048) , r.nextInt(2048));\n+          testChar_constant_LT64B (r.nextInt(2048) , r.nextInt(2048));\n+\n+          testInt(lengths[i % lengths.length]  >> 2, r.nextInt(2048) , r.nextInt(2048));\n+          testInt_constant_LT32B (r.nextInt(2048) , r.nextInt(2048));\n+          testInt_constant_LT64B (r.nextInt(2048) , r.nextInt(2048));\n+\n+          testLong(lengths[i % lengths.length] >> 3, r.nextInt(2048) , r.nextInt(2048));\n+          testLong_constant_LT32B (r.nextInt(2048) , r.nextInt(2048));\n+          testLong_constant_LT64B (r.nextInt(2048) , r.nextInt(2048));\n+        }\n+        System.out.println(\"PASS : \" + validate_ctr);\n+      } catch (Exception e) {\n+         System.out.println(e.getMessage());\n+      }\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/arraycopy\/TestArrayCopyDisjoint.java","additions":226,"deletions":0,"binary":false,"changes":226,"status":"added"},{"patch":"@@ -0,0 +1,121 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2020, Arm Limited. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package org.openjdk.bench.vm.compiler;\n+\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.results.Result;\n+import org.openjdk.jmh.results.RunResult;\n+import org.openjdk.jmh.runner.Runner;\n+import org.openjdk.jmh.runner.RunnerException;\n+import org.openjdk.jmh.runner.options.Options;\n+import org.openjdk.jmh.runner.options.OptionsBuilder;\n+import org.openjdk.jmh.runner.options.TimeValue;\n+\n+\n+\n+\n+import java.util.concurrent.TimeUnit;\n+import java.util.Arrays;\n+\n+class MyClass {\n+ public int field1;\n+ public int field2;\n+ public int field3;\n+\n+ public MyClass(int val) {\n+   field1 = val;\n+   field2 = val;\n+   field3 = val;\n+ }\n+}\n+\n+@State(Scope.Benchmark)\n+@BenchmarkMode(Mode.Throughput)\n+@OutputTimeUnit(TimeUnit.MILLISECONDS)\n+public class ArrayCopyObject {\n+    @Param({\"31\", \"63\", \"127\" , \"2047\" , \"4095\", \"8191\"}) private int size;\n+\n+    private MyClass [] src;\n+    private MyClass [] dst;\n+\n+    @Setup\n+    public void setup() {\n+      src = new MyClass[size];\n+      dst = new MyClass[size];\n+      for (int i = 0; i < src.length ; i++) {\n+        src[i] = new MyClass(i);\n+        dst[i] = new MyClass(0);\n+      }\n+    }\n+\n+    @Benchmark\n+    public void disjoint_micro() {\n+      System.arraycopy(src, 0 , dst, 0 , size);\n+    }\n+\n+    @Benchmark\n+    public void conjoint_micro() {\n+      System.arraycopy(src, 0 , src, 10 , size - 10 );\n+    }\n+\n+    public static void main(String[] args) throws RunnerException {\n+       String [] base_opts =\n+          { \"-XX:+UnlockDiagnosticVMOptions \",\n+            \"-XX:+IgnoreUnrecognizedVMOptions \",\n+          \"-XX:UseAVX=3\" };\n+       String [] opts_str1 = {\"-XX:-UseCompressedOops \"};\n+       String [] opts_str2 = {\"-XX:+UseCompressedOops \"};\n+\n+       Options baseOpts = new OptionsBuilder()\n+          .include(ArrayCopyObject.class.getName())\n+          .warmupTime(TimeValue.seconds(30))\n+          .measurementTime(TimeValue.seconds(10))\n+          .warmupIterations(1)\n+          .measurementIterations(2)\n+          .jvmArgs(base_opts)\n+          .forks(1)\n+          .build();\n+\n+       RunResult r1 = new Runner(new OptionsBuilder()\n+         .parent(baseOpts)\n+         .jvmArgs(opts_str1)\n+         .build()).runSingle();\n+\n+       RunResult r2 = new Runner(new OptionsBuilder()\n+         .parent(baseOpts)\n+         .jvmArgs(opts_str2)\n+         .build()).runSingle();\n+\n+        System.out.println(r1.getPrimaryResult().getScore() + r2.getPrimaryResult().getScore());\n+    }\n+}\n+\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/ArrayCopyObject.java","additions":121,"deletions":0,"binary":false,"changes":121,"status":"added"}]}