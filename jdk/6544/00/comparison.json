{"files":[{"patch":"@@ -2063,0 +2063,7 @@\n+void Assembler::vcvttps2dq(XMMRegister dst, XMMRegister src, int vector_len) {\n+  assert(vector_len <= AVX_256bit ? VM_Version::supports_avx() : VM_Version::supports_evex(), \"\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x5B, (0xC0 | encode));\n+}\n+\n@@ -2071,0 +2078,8 @@\n+void Assembler::evcvttpd2qq(XMMRegister dst, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x7A, (0xC0 | encode));\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -1171,0 +1171,3 @@\n+  \/\/ Convert vector float and int\n+  void vcvttps2dq(XMMRegister dst, XMMRegister src, int vector_len);\n+\n@@ -1175,0 +1178,3 @@\n+  \/\/ Convert vector double to long\n+  void evcvttpd2qq(XMMRegister dst, XMMRegister src, int vector_len);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -4062,0 +4062,76 @@\n+\/*\n+ * Algorithm for vector D2L and F2I conversions:-\n+ * a) Perform vector D2L\/F2I cast.\n+ * b) Choose fast path if none of the result vector lane contains 0x80000000 value.\n+ *    It signifies that source value could be any of the special floating point\n+ *    values(NaN,-Inf,Int,Max,-Min).\n+ * c) Set destination to zero if source is NaN value.\n+ * d) Replace 0x80000000 with MaxInt if source lane contains a +ve value.\n+ *\/\n+\n+void C2_MacroAssembler::vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, AddressLiteral double_sign_flip,\n+                                            AddressLiteral max_long, Register scratch, int vec_enc) {\n+  Label done;\n+  evcvttpd2qq(dst, src, vec_enc);\n+  evmovdqul(xtmp1, k0, double_sign_flip, true, vec_enc, scratch);\n+  evpcmpeqq(ktmp1, xtmp1, dst, vec_enc);\n+  kortestwl(ktmp1, ktmp1);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  evcmppd(ktmp1, k0, src, src, Assembler::UNORD_Q, vec_enc);\n+  evblendmpd(dst, ktmp1, dst, xtmp2, true, vec_enc);\n+\n+  evpcmpeqq(ktmp1, xtmp1, dst, vec_enc);\n+  evcmppd(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_US, vec_enc);\n+  evmovdquq(xtmp1, max_long, vec_enc, scratch);\n+  evblendmpd(dst, ktmp1, dst, xtmp1, true, vec_enc);\n+  bind(done);\n+}\n+\n+void C2_MacroAssembler::vector_castF2I_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, AddressLiteral float_sign_flip,\n+                                           AddressLiteral max_int, Register scratch, int vec_enc) {\n+  Label done;\n+  vcvttps2dq(dst, src, vec_enc);\n+  vmovdqu(xtmp1, float_sign_flip, scratch);\n+  vpcmpeqd(xtmp2, dst, xtmp1, vec_enc);\n+  vpmovmskb(scratch, xtmp2, vec_enc);\n+  testl(scratch, scratch);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  vcmpps(xtmp3, src, src, Assembler::UNORD_Q, vec_enc);\n+  vblendvps(dst, dst, xtmp2, xtmp3, vec_enc);\n+\n+  vpcmpeqd(xtmp1, dst, xtmp1, vec_enc);\n+  vpand(xtmp2, xtmp1, src, vec_enc);\n+  vpxor(xtmp3, xtmp2, xtmp1, vec_enc);\n+  vpand(xtmp3, xtmp3, xtmp1, vec_enc);\n+  vmovdqu(xtmp1, max_int, scratch);\n+  vblendvps(dst, dst, xtmp1, xtmp3, vec_enc);\n+  bind(done);\n+}\n+\n+void C2_MacroAssembler::vector_castF2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, AddressLiteral float_sign_flip,\n+                                            AddressLiteral max_int, Register scratch, int vec_enc) {\n+  Label done;\n+  vcvttps2dq(dst, src, vec_enc);\n+  evmovdqul(xtmp1, k0, float_sign_flip, false, vec_enc, scratch);\n+  Assembler::evpcmpeqd(ktmp1, k0, xtmp1, dst, vec_enc);\n+  kortestwl(ktmp1, ktmp1);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  evcmpps(ktmp1, k0, src, src, Assembler::UNORD_Q, vec_enc);\n+  evblendmps(dst, ktmp1, dst, xtmp2, true, vec_enc);\n+\n+  Assembler::evpcmpeqd(ktmp1, k0, xtmp1, dst, vec_enc);\n+  evcmpps(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_US, vec_enc);\n+  evmovdquq(xtmp1, max_int, vec_enc, scratch);\n+  evblendmps(dst, ktmp1, dst, xtmp1, true, vec_enc);\n+  bind(done);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":76,"deletions":0,"binary":false,"changes":76,"status":"modified"},{"patch":"@@ -291,0 +291,12 @@\n+\n+  void vector_castF2I_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                          XMMRegister xtmp2, XMMRegister xtmp3, AddressLiteral float_sign_flip,\n+                          AddressLiteral max_int, Register scratch, int vec_enc);\n+\n+  void vector_castF2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                           KRegister ktmp1, AddressLiteral float_sign_flip,\n+                           AddressLiteral max_int, Register scratch, int vec_enc);\n+\n+  void vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                           KRegister ktmp1, AddressLiteral double_sign_flip,\n+                           AddressLiteral max_long, Register scratch, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1385,0 +1385,4 @@\n+  static address vector_float_signflip() { return StubRoutines::x86::vector_float_sign_flip();}\n+  static address vector_double_signflip() { return StubRoutines::x86::vector_double_sign_flip();}\n+  static address vector_float_signmask() { return StubRoutines::x86::vector_float_sign_mask();}\n+  static address vector_double_signmask() { return StubRoutines::x86::vector_double_sign_mask();}\n@@ -1795,1 +1799,0 @@\n-    case Op_VectorCastF2X:\n@@ -1797,4 +1800,10 @@\n-      if (is_integral_type(bt)) {\n-        \/\/ Casts from FP to integral types require special fixup logic not easily\n-        \/\/ implementable with vectors.\n-        return false; \/\/ Implementation limitation\n+      if (is_subword_type(bt) || bt == T_INT) {\n+        return false;\n+      }\n+      if (bt == T_LONG && !VM_Version::supports_avx512dq()) {\n+        return false;\n+      }\n+      break;\n+    case Op_VectorCastF2X:\n+      if (is_subword_type(bt) || bt == T_LONG) {\n+        return false;\n@@ -1802,0 +1811,1 @@\n+      break;\n@@ -7160,1 +7170,1 @@\n-  format %{ \"vector_cast_f2x  $dst,$src\\t!\" %}\n+  format %{ \"vector_cast_f2d  $dst,$src\\t!\" %}\n@@ -7168,0 +7178,32 @@\n+instruct vcastFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP scratch, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512vl() &&\n+            Matcher::vector_length_in_bytes(n) < 64 &&\n+            Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP scratch, KILL cr);\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2 and $xtmp3 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_castF2I_avx($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                          $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, ExternalAddress(vector_float_signflip()),\n+                          ExternalAddress(vector_float_signmask()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct vcastFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, rRegP scratch, rFlagsReg cr) %{\n+  predicate((VM_Version::supports_avx512vl() ||\n+             Matcher::vector_length_in_bytes(n) == 64) &&\n+             Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP scratch, KILL cr);\n+  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2 and $ktmp1 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_castF2I_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                           $xtmp2$$XMMRegister, $ktmp1$$KRegister, ExternalAddress(vector_float_signflip()),\n+                           ExternalAddress(vector_float_signmask()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7179,0 +7221,14 @@\n+instruct vcastDtoL_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, rRegP scratch, rFlagsReg cr) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP scratch, KILL cr);\n+  format %{ \"vector_cast_d2l $dst,$src\\t! using $xtmp1, $xtmp2 and $ktmp1 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_castD2L_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                           $xtmp2$$XMMRegister, $ktmp1$$KRegister, ExternalAddress(vector_double_signflip()),\n+                           ExternalAddress(vector_double_signmask()), $scratch$$Register, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":62,"deletions":6,"binary":false,"changes":68,"status":"modified"}]}