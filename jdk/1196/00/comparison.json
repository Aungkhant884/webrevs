{"files":[{"patch":"@@ -1523,1 +1523,1 @@\n-  \/\/ Mutex\/Monitor, Thread::muxAcquire and JavaThread::sleep\n+  \/\/ Mutex\/Monitor, and JavaThread::sleep\n","filename":"src\/hotspot\/os\/posix\/os_posix.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -128,1 +128,0 @@\n-    volatile intptr_t OnList ;\n@@ -149,1 +148,0 @@\n-       OnList         = 0 ;\n","filename":"src\/hotspot\/share\/runtime\/park.hpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -230,2 +230,7 @@\n-#define NINFLATIONLOCKS 256\n-static volatile intptr_t gInflationLocks[NINFLATIONLOCKS];\n+os::PlatformMutex* ObjectSynchronizer::gInflationLocks[ObjectSynchronizer::NINFLATIONLOCKS];\n+\n+void ObjectSynchronizer::initialize() {\n+  for (int i = 0; i < NINFLATIONLOCKS; i++) {\n+    gInflationLocks[i] = new os::PlatformMutex();\n+  }\n+}\n@@ -796,3 +801,1 @@\n-        \/\/ This is conceptually similar to muxAcquire-muxRelease, except that muxRelease\n-        \/\/ wakes at most one thread whereas we need to wake the entire list.\n-        int ix = (cast_from_oop<intptr_t>(obj) >> 5) & (NINFLATIONLOCKS-1);\n+        int ix = (cast_from_oop<intptr_t>(obj) >> 5) & (ObjectSynchronizer::NINFLATIONLOCKS-1);\n@@ -800,3 +803,3 @@\n-        assert(ix >= 0 && ix < NINFLATIONLOCKS, \"invariant\");\n-        assert((NINFLATIONLOCKS & (NINFLATIONLOCKS-1)) == 0, \"invariant\");\n-        Thread::muxAcquire(gInflationLocks + ix, \"gInflationLock\");\n+        assert(ix >= 0 && ix < ObjectSynchronizer::NINFLATIONLOCKS, \"invariant\");\n+        assert((ObjectSynchronizer::NINFLATIONLOCKS & (ObjectSynchronizer::NINFLATIONLOCKS-1)) == 0, \"invariant\");\n+        ObjectSynchronizer::gInflationLocks[ix]->lock();\n@@ -804,1 +807,1 @@\n-          \/\/ Beware: NakedYield() is advisory and has almost no effect on some platforms\n+          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n@@ -813,1 +816,1 @@\n-        Thread::muxRelease(gInflationLocks + ix);\n+        ObjectSynchronizer::gInflationLocks[ix]->unlock();\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":13,"deletions":10,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -117,0 +118,4 @@\n+  static const int NINFLATIONLOCKS = 256;\n+  static os::PlatformMutex* gInflationLocks[NINFLATIONLOCKS];\n+  static void initialize();\n+\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -294,1 +294,0 @@\n-  _MuxEvent    = ParkEvent::Allocate(this);\n@@ -442,1 +441,0 @@\n-  ParkEvent::Release(_MuxEvent); _MuxEvent    = NULL;\n@@ -3574,0 +3572,1 @@\n+  ObjectSynchronizer::initialize();\n@@ -4596,4 +4595,1 @@\n-\/\/ Internal SpinLock and Mutex\n-\/\/ Based on ParkEvent\n-\n-\/\/ Ad-hoc mutual exclusion primitives: SpinLock and Mux\n+\/\/ Ad-hoc mutual exclusion primitives: SpinLock\n@@ -4604,8 +4600,0 @@\n-\/\/ The mux construct provides a spin-then-block mutual exclusion\n-\/\/ mechanism.\n-\/\/\n-\/\/ Testing has shown that contention on the ListLock guarding gFreeList\n-\/\/ is common.  If we implement ListLock as a simple SpinLock it's common\n-\/\/ for the JVM to devolve to yielding with little progress.  This is true\n-\/\/ despite the fact that the critical sections protected by ListLock are\n-\/\/ extremely short.\n@@ -4664,144 +4652,0 @@\n-\/\/ muxAcquire and muxRelease:\n-\/\/\n-\/\/ *  muxAcquire and muxRelease support a single-word lock-word construct.\n-\/\/    The LSB of the word is set IFF the lock is held.\n-\/\/    The remainder of the word points to the head of a singly-linked list\n-\/\/    of threads blocked on the lock.\n-\/\/\n-\/\/ *  The current implementation of muxAcquire-muxRelease uses its own\n-\/\/    dedicated Thread._MuxEvent instance.  If we're interested in\n-\/\/    minimizing the peak number of extant ParkEvent instances then\n-\/\/    we could eliminate _MuxEvent and \"borrow\" _ParkEvent as long\n-\/\/    as certain invariants were satisfied.  Specifically, care would need\n-\/\/    to be taken with regards to consuming unpark() \"permits\".\n-\/\/    A safe rule of thumb is that a thread would never call muxAcquire()\n-\/\/    if it's enqueued (cxq, EntryList, WaitList, etc) and will subsequently\n-\/\/    park().  Otherwise the _ParkEvent park() operation in muxAcquire() could\n-\/\/    consume an unpark() permit intended for monitorenter, for instance.\n-\/\/    One way around this would be to widen the restricted-range semaphore\n-\/\/    implemented in park().  Another alternative would be to provide\n-\/\/    multiple instances of the PlatformEvent() for each thread.  One\n-\/\/    instance would be dedicated to muxAcquire-muxRelease, for instance.\n-\/\/\n-\/\/ *  Usage:\n-\/\/    -- Only as leaf locks\n-\/\/    -- for short-term locking only as muxAcquire does not perform\n-\/\/       thread state transitions.\n-\/\/\n-\/\/ Alternatives:\n-\/\/ *  We could implement muxAcquire and muxRelease with MCS or CLH locks\n-\/\/    but with parking or spin-then-park instead of pure spinning.\n-\/\/ *  Use Taura-Oyama-Yonenzawa locks.\n-\/\/ *  It's possible to construct a 1-0 lock if we encode the lockword as\n-\/\/    (List,LockByte).  Acquire will CAS the full lockword while Release\n-\/\/    will STB 0 into the LockByte.  The 1-0 scheme admits stranding, so\n-\/\/    acquiring threads use timers (ParkTimed) to detect and recover from\n-\/\/    the stranding window.  Thread\/Node structures must be aligned on 256-byte\n-\/\/    boundaries by using placement-new.\n-\/\/ *  Augment MCS with advisory back-link fields maintained with CAS().\n-\/\/    Pictorially:  LockWord -> T1 <-> T2 <-> T3 <-> ... <-> Tn <-> Owner.\n-\/\/    The validity of the backlinks must be ratified before we trust the value.\n-\/\/    If the backlinks are invalid the exiting thread must back-track through the\n-\/\/    the forward links, which are always trustworthy.\n-\/\/ *  Add a successor indication.  The LockWord is currently encoded as\n-\/\/    (List, LOCKBIT:1).  We could also add a SUCCBIT or an explicit _succ variable\n-\/\/    to provide the usual futile-wakeup optimization.\n-\/\/    See RTStt for details.\n-\/\/\n-\n-\n-const intptr_t LOCKBIT = 1;\n-\n-void Thread::muxAcquire(volatile intptr_t * Lock, const char * LockName) {\n-  intptr_t w = Atomic::cmpxchg(Lock, (intptr_t)0, LOCKBIT);\n-  if (w == 0) return;\n-  if ((w & LOCKBIT) == 0 && Atomic::cmpxchg(Lock, w, w|LOCKBIT) == w) {\n-    return;\n-  }\n-\n-  ParkEvent * const Self = Thread::current()->_MuxEvent;\n-  assert((intptr_t(Self) & LOCKBIT) == 0, \"invariant\");\n-  for (;;) {\n-    int its = (os::is_MP() ? 100 : 0) + 1;\n-\n-    \/\/ Optional spin phase: spin-then-park strategy\n-    while (--its >= 0) {\n-      w = *Lock;\n-      if ((w & LOCKBIT) == 0 && Atomic::cmpxchg(Lock, w, w|LOCKBIT) == w) {\n-        return;\n-      }\n-    }\n-\n-    Self->reset();\n-    Self->OnList = intptr_t(Lock);\n-    \/\/ The following fence() isn't _strictly necessary as the subsequent\n-    \/\/ CAS() both serializes execution and ratifies the fetched *Lock value.\n-    OrderAccess::fence();\n-    for (;;) {\n-      w = *Lock;\n-      if ((w & LOCKBIT) == 0) {\n-        if (Atomic::cmpxchg(Lock, w, w|LOCKBIT) == w) {\n-          Self->OnList = 0;   \/\/ hygiene - allows stronger asserts\n-          return;\n-        }\n-        continue;      \/\/ Interference -- *Lock changed -- Just retry\n-      }\n-      assert(w & LOCKBIT, \"invariant\");\n-      Self->ListNext = (ParkEvent *) (w & ~LOCKBIT);\n-      if (Atomic::cmpxchg(Lock, w, intptr_t(Self)|LOCKBIT) == w) break;\n-    }\n-\n-    while (Self->OnList != 0) {\n-      Self->park();\n-    }\n-  }\n-}\n-\n-\/\/ Release() must extract a successor from the list and then wake that thread.\n-\/\/ It can \"pop\" the front of the list or use a detach-modify-reattach (DMR) scheme\n-\/\/ similar to that used by ParkEvent::Allocate() and ::Release().  DMR-based\n-\/\/ Release() would :\n-\/\/ (A) CAS() or swap() null to *Lock, releasing the lock and detaching the list.\n-\/\/ (B) Extract a successor from the private list \"in-hand\"\n-\/\/ (C) attempt to CAS() the residual back into *Lock over null.\n-\/\/     If there were any newly arrived threads and the CAS() would fail.\n-\/\/     In that case Release() would detach the RATs, re-merge the list in-hand\n-\/\/     with the RATs and repeat as needed.  Alternately, Release() might\n-\/\/     detach and extract a successor, but then pass the residual list to the wakee.\n-\/\/     The wakee would be responsible for reattaching and remerging before it\n-\/\/     competed for the lock.\n-\/\/\n-\/\/ Both \"pop\" and DMR are immune from ABA corruption -- there can be\n-\/\/ multiple concurrent pushers, but only one popper or detacher.\n-\/\/ This implementation pops from the head of the list.  This is unfair,\n-\/\/ but tends to provide excellent throughput as hot threads remain hot.\n-\/\/ (We wake recently run threads first).\n-\/\/\n-\/\/ All paths through muxRelease() will execute a CAS.\n-\/\/ Release consistency -- We depend on the CAS in muxRelease() to provide full\n-\/\/ bidirectional fence\/MEMBAR semantics, ensuring that all prior memory operations\n-\/\/ executed within the critical section are complete and globally visible before the\n-\/\/ store (CAS) to the lock-word that releases the lock becomes globally visible.\n-void Thread::muxRelease(volatile intptr_t * Lock)  {\n-  for (;;) {\n-    const intptr_t w = Atomic::cmpxchg(Lock, LOCKBIT, (intptr_t)0);\n-    assert(w & LOCKBIT, \"invariant\");\n-    if (w == LOCKBIT) return;\n-    ParkEvent * const List = (ParkEvent *) (w & ~LOCKBIT);\n-    assert(List != NULL, \"invariant\");\n-    assert(List->OnList == intptr_t(Lock), \"invariant\");\n-    ParkEvent * const nxt = List->ListNext;\n-    guarantee((intptr_t(nxt) & LOCKBIT) == 0, \"invariant\");\n-\n-    \/\/ The following CAS() releases the lock and pops the head element.\n-    \/\/ The CAS() also ratifies the previously fetched lock-word value.\n-    if (Atomic::cmpxchg(Lock, w, intptr_t(nxt)) != w) {\n-      continue;\n-    }\n-    List->OnList = 0;\n-    OrderAccess::fence();\n-    List->unpark();\n-    return;\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":2,"deletions":158,"binary":false,"changes":160,"status":"modified"},{"patch":"@@ -830,2 +830,2 @@\n-  ParkEvent * _ParkEvent;                     \/\/ for Object monitors and JVMTI raw monitors\n-  ParkEvent * _MuxEvent;                      \/\/ for low-level muxAcquire-muxRelease\n+  ParkEvent * _ParkEvent;                     \/\/ for Object monitors, JVMTI raw monitors,\n+                                              \/\/ and ObjectSynchronizer::read_stable_mark\n@@ -840,2 +840,1 @@\n-  \/\/ Low-level leaf-lock primitives used to implement synchronization\n-  \/\/ and native monitor-mutex infrastructure.\n+  \/\/ Low-level leaf-lock primitives used to implement synchronization.\n@@ -845,2 +844,0 @@\n-  static void muxAcquire(volatile intptr_t * Lock, const char * Name);\n-  static void muxRelease(volatile intptr_t * Lock);\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"}]}