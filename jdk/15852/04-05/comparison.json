{"files":[{"patch":"@@ -877,0 +877,11 @@\n+    \/\/ Check that gc overhead is not exceeded.\n+    \/\/\n+    \/\/ Shenandoah will grind along for quite a while allocating one\n+    \/\/ object at a time using shared (non-tlab) allocations. This check\n+    \/\/ is testing that the GC overhead limit has not been exceeded.\n+    \/\/ This will notify the collector to start a cycle, but will raise\n+    \/\/ an OOME to the mutator if the last Full GCs have not made progress.\n+    if (result == nullptr && !req.is_lab_alloc() && get_gc_no_progress_count() > ShenandoahNoProgressThreshold) {\n+      control_thread()->handle_alloc_failure(req, false);\n+      return nullptr;\n+    }\n@@ -878,28 +889,13 @@\n-    if (result == nullptr) {\n-      \/\/ Allocation failed.\n-\n-      \/\/ Check that gc overhead is not exceeded.\n-      \/\/\n-      \/\/ Shenandoah will grind along for quite a while allocating one\n-      \/\/ object at a time using shared (non-tlab) allocations. This check\n-      \/\/ is testing that the GC overhead limit has not been exceeded.\n-      \/\/ This will notify the collector to start a cycle, but will raise\n-      \/\/ an OOME to the mutator if the last Full GCs have not made progress.\n-      if (!req.is_lab_alloc() && get_gc_no_progress_count() > ShenandoahNoProgressThreshold) {\n-        control_thread()->handle_alloc_failure(req, false);\n-        return nullptr;\n-      }\n-\n-      \/\/ Block until control thread reacted, then retry allocation.\n-      \/\/\n-      \/\/ It might happen that one of the threads requesting allocation would unblock\n-      \/\/ way later after GC happened, only to fail the second allocation, because\n-      \/\/ other threads have already depleted the free storage. In this case, a better\n-      \/\/ strategy is to try again, as long as GC makes progress (or until at least\n-      \/\/ one full GC completes).\n-      size_t original_count = shenandoah_policy()->full_gc_count();\n-      while (result == nullptr\n-          && (get_gc_no_progress_count() == 0 || original_count == shenandoah_policy()->full_gc_count())) {\n-        control_thread()->handle_alloc_failure(req);\n-        result = allocate_memory_under_lock(req, in_new_region);\n-      }\n+    \/\/ Block until control thread reacted, then retry allocation.\n+    \/\/\n+    \/\/ It might happen that one of the threads requesting allocation would unblock\n+    \/\/ way later after GC happened, only to fail the second allocation, because\n+    \/\/ other threads have already depleted the free storage. In this case, a better\n+    \/\/ strategy is to try again, as long as GC makes progress (or until at least\n+    \/\/ one full GC has completed).\n+    size_t original_count = shenandoah_policy()->full_gc_count();\n+    while (result == nullptr\n+        && (get_gc_no_progress_count() == 0 || original_count == shenandoah_policy()->full_gc_count())) {\n+      control_thread()->handle_alloc_failure(req);\n+      result = allocate_memory_under_lock(req, in_new_region);\n+    }\n@@ -907,5 +903,4 @@\n-      if (log_is_enabled(Debug, gc, alloc)) {\n-        ResourceMark rm;\n-        log_debug(gc, alloc)(\"Thread: %s, Result: \" PTR_FORMAT \", Request: %s, Size: \" SIZE_FORMAT \", Original: \" SIZE_FORMAT \", Latest: \" SIZE_FORMAT,\n-                             Thread::current()->name(), p2i(result), req.type_string(), req.size(), original_count, get_gc_no_progress_count());\n-      }\n+    if (log_is_enabled(Debug, gc, alloc)) {\n+      ResourceMark rm;\n+      log_debug(gc, alloc)(\"Thread: %s, Result: \" PTR_FORMAT \", Request: %s, Size: \" SIZE_FORMAT \", Original: \" SIZE_FORMAT \", Latest: \" SIZE_FORMAT,\n+                           Thread::current()->name(), p2i(result), req.type_string(), req.size(), original_count, get_gc_no_progress_count());\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":28,"deletions":33,"binary":false,"changes":61,"status":"modified"},{"patch":"@@ -2458,1 +2458,2 @@\n-                env.targetVMOptions.ZGCIsSelected || env.targetVMOptions.ShenandoahGCIsSelected ||\n+                env.targetVMOptions.ZGCIsSelected ||\n+                env.targetVMOptions.ShenandoahGCIsSelected ||\n@@ -2503,1 +2504,2 @@\n-                ZGCIsSelected || ShenandoahGCIsSelected ||\n+                ZGCIsSelected ||\n+                ShenandoahGCIsSelected ||\n@@ -2556,1 +2558,2 @@\n-                env.targetVMOptions.ZGCIsSelected || env.targetVMOptions.ShenandoahGCIsSelected ||\n+                env.targetVMOptions.ZGCIsSelected ||\n+                env.targetVMOptions.ShenandoahGCIsSelected ||\n@@ -2617,1 +2620,2 @@\n-                ZGCIsSelected || ShenandoahGCIsSelected ||\n+                ZGCIsSelected ||\n+                ShenandoahGCIsSelected ||\n@@ -2823,1 +2827,2 @@\n-                env.targetVMOptions.ZGCIsSelected || env.targetVMOptions.ShenandoahGCIsSelected ||\n+                env.targetVMOptions.ZGCIsSelected ||\n+                env.targetVMOptions.ShenandoahGCIsSelected ||\n@@ -2885,1 +2890,2 @@\n-                ZGCIsSelected || ShenandoahGCIsSelected ||\n+                ZGCIsSelected ||\n+                ShenandoahGCIsSelected ||\n","filename":"test\/jdk\/com\/sun\/jdi\/EATests.java","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"}]}