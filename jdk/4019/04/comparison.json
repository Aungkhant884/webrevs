{"files":[{"patch":"@@ -948,1 +948,6 @@\n-\n+  void gfmul_avx512(XMMRegister ghash, XMMRegister hkey);\n+  void generateHtbl_48_block_zmm(Register htbl);\n+  void ghash16_encrypt16_parallel(Register key, Register subkeyHtbl, XMMRegister ctr_blockx,\n+                                  XMMRegister aad_hashx, Register in, Register out, Register data, Register pos, bool reduction,\n+                                  XMMRegister addmask, bool no_ghash_input, Register rounds, Register ghash_pos,\n+                                  bool final_reduction, int index, XMMRegister counter_inc_mask);\n@@ -954,0 +959,2 @@\n+  void aesgcm_encrypt(Register in, Register len, Register ct, Register out, Register key,\n+                      Register state, Register subkeyHtbl, Register counter);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1270,1 +1270,624 @@\n-#endif \/\/ _LP64\n+void MacroAssembler::gfmul_avx512(XMMRegister GH, XMMRegister HK) {\n+    const XMMRegister TMP1 = xmm0;\n+    const XMMRegister TMP2 = xmm1;\n+    const XMMRegister TMP3 = xmm2;\n+\n+    evpclmulqdq(TMP1, GH, HK, 0x11, Assembler::AVX_512bit);\n+    evpclmulqdq(TMP2, GH, HK, 0x00, Assembler::AVX_512bit);\n+    evpclmulqdq(TMP3, GH, HK, 0x01, Assembler::AVX_512bit);\n+    evpclmulqdq(GH, GH, HK, 0x10, Assembler::AVX_512bit);\n+    evpxorq(GH, GH, TMP3, Assembler::AVX_512bit);\n+    vpsrldq(TMP3, GH, 8, Assembler::AVX_512bit);\n+    vpslldq(GH, GH, 8, Assembler::AVX_512bit);\n+    evpxorq(TMP1, TMP1, TMP3, Assembler::AVX_512bit);\n+    evpxorq(GH, GH, TMP2, Assembler::AVX_512bit);\n+\n+    evmovdquq(TMP3, ExternalAddress(StubRoutines::x86::ghash_polynomial512_addr()), Assembler::AVX_512bit, r15);\n+    evpclmulqdq(TMP2, TMP3, GH, 0x01, Assembler::AVX_512bit);\n+    vpslldq(TMP2, TMP2, 8, Assembler::AVX_512bit);\n+    evpxorq(GH, GH, TMP2, Assembler::AVX_512bit);\n+    evpclmulqdq(TMP2, TMP3, GH, 0x00, Assembler::AVX_512bit);\n+    vpsrldq(TMP2, TMP2, 4, Assembler::AVX_512bit);\n+    evpclmulqdq(GH, TMP3, GH, 0x10, Assembler::AVX_512bit);\n+    vpslldq(GH, GH, 4, Assembler::AVX_512bit);\n+    vpternlogq(GH, 0x96, TMP1, TMP2, Assembler::AVX_512bit);\n+}\n+\n+void MacroAssembler::generateHtbl_48_block_zmm(Register htbl) {\n+    const XMMRegister HK = xmm6;\n+    const XMMRegister ZT5 = xmm4;\n+    const XMMRegister ZT7 = xmm7;\n+    const XMMRegister ZT8 = xmm8;\n+\n+    Label GFMUL_AVX512;\n+\n+    movdqu(HK, Address(htbl, 0));\n+    movdqu(xmm10, ExternalAddress(StubRoutines::x86::ghash_long_swap_mask_addr()));\n+    vpshufb(HK, HK, xmm10, Assembler::AVX_128bit);\n+\n+    movdqu(xmm11, ExternalAddress(StubRoutines::x86::ghash_polynomial512_addr() + 64)); \/\/ Poly\n+    movdqu(xmm12, ExternalAddress(StubRoutines::x86::ghash_polynomial512_addr() + 80)); \/\/ Twoone\n+    \/\/ Compute H ^ 2 from the input subkeyH\n+    movdqu(xmm2, xmm6);\n+    vpsllq(xmm6, xmm6, 1, Assembler::AVX_128bit);\n+    vpsrlq(xmm2, xmm2, 63, Assembler::AVX_128bit);\n+    movdqu(xmm1, xmm2);\n+    vpslldq(xmm2, xmm2, 8, Assembler::AVX_128bit);\n+    vpsrldq(xmm1, xmm1, 8, Assembler::AVX_128bit);\n+    vpor(xmm6, xmm6, xmm2, Assembler::AVX_128bit);\n+\n+    vpshufd(xmm2, xmm1, 0x24, Assembler::AVX_128bit);\n+    vpcmpeqd(xmm2, xmm2, xmm12, AVX_128bit);\n+    vpand(xmm2, xmm2, xmm11, Assembler::AVX_128bit);\n+    vpxor(xmm6, xmm6, xmm2, Assembler::AVX_128bit);\n+    movdqu(Address(htbl, 16 * 56), xmm6); \/\/ H ^ 2\n+    \/\/ Compute the remaining three powers of H using XMM registers and all following powers using ZMM\n+    movdqu(ZT5, HK);\n+    vinserti32x4(ZT7, ZT7, HK, 3);\n+\n+    gfmul_avx512(ZT5, HK);\n+    movdqu(Address(htbl, 16 * 55), ZT5); \/\/ H ^ 2 * 2\n+    vinserti32x4(ZT7, ZT7, ZT5, 2);\n+\n+    gfmul_avx512(ZT5, HK);\n+    movdqu(Address(htbl, 16 * 54), ZT5); \/\/ H ^ 2 * 3\n+    vinserti32x4(ZT7, ZT7, ZT5, 1);\n+\n+    gfmul_avx512(ZT5, HK);\n+    movdqu(Address(htbl, 16 * 53), ZT5); \/\/ H ^ 2 * 4\n+    vinserti32x4(ZT7, ZT7, ZT5, 0);\n+\n+    evshufi64x2(ZT5, ZT5, ZT5, 0x00, Assembler::AVX_512bit);\n+    evmovdquq(ZT8, ZT7, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT7, ZT5);\n+    evmovdquq(Address(htbl, 16 * 49), ZT7, Assembler::AVX_512bit);\n+    evshufi64x2(ZT5, ZT7, ZT7, 0x00, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT8, ZT5);\n+    evmovdquq(Address(htbl, 16 * 45), ZT8, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT7, ZT5);\n+    evmovdquq(Address(htbl, 16 * 41), ZT7, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT8, ZT5);\n+    evmovdquq(Address(htbl, 16 * 37), ZT8, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT7, ZT5);\n+    evmovdquq(Address(htbl, 16 * 33), ZT7, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT8, ZT5);\n+    evmovdquq(Address(htbl, 16 * 29), ZT8, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT7, ZT5);\n+    evmovdquq(Address(htbl, 16 * 25), ZT7, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT8, ZT5);\n+    evmovdquq(Address(htbl, 16 * 21), ZT8, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT7, ZT5);\n+    evmovdquq(Address(htbl, 16 * 17), ZT7, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT8, ZT5);\n+    evmovdquq(Address(htbl, 16 * 13), ZT8, Assembler::AVX_512bit);\n+    gfmul_avx512(ZT7, ZT5);\n+    evmovdquq(Address(htbl, 16 * 9), ZT7, Assembler::AVX_512bit);\n+    ret(0);\n+}\n+\n+#define vclmul_reduce(out, poly, hi128, lo128, tmp0, tmp1) \\\n+evpclmulqdq(tmp0, poly, lo128, 0x01, Assembler::AVX_512bit); \\\n+vpslldq(tmp0, tmp0, 8, Assembler::AVX_512bit); \\\n+evpxorq(tmp0, lo128, tmp0, Assembler::AVX_512bit); \\\n+evpclmulqdq(tmp1, poly, tmp0, 0x00, Assembler::AVX_512bit); \\\n+vpsrldq(tmp1, tmp1, 4, Assembler::AVX_512bit); \\\n+evpclmulqdq(out, poly, tmp0, 0x10, Assembler::AVX_512bit); \\\n+vpslldq(out, out, 4, Assembler::AVX_512bit); \\\n+vpternlogq(out, 0x96, tmp1, hi128, Assembler::AVX_512bit); \\\n+\n+#define vhpxori4x128(reg, tmp) \\\n+vextracti64x4(tmp, reg, 1); \\\n+evpxorq(reg, reg, tmp, Assembler::AVX_256bit); \\\n+vextracti32x4(tmp, reg, 1); \\\n+evpxorq(reg, reg, tmp, Assembler::AVX_128bit); \\\n+\n+#define roundEncode(key, dst1, dst2, dst3, dst4) \\\n+vaesenc(dst1, dst1, key, Assembler::AVX_512bit); \\\n+vaesenc(dst2, dst2, key, Assembler::AVX_512bit); \\\n+vaesenc(dst3, dst3, key, Assembler::AVX_512bit); \\\n+vaesenc(dst4, dst4, key, Assembler::AVX_512bit); \\\n+\n+#define lastroundEncode(key, dst1, dst2, dst3, dst4) \\\n+vaesenclast(dst1, dst1, key, Assembler::AVX_512bit); \\\n+vaesenclast(dst2, dst2, key, Assembler::AVX_512bit); \\\n+vaesenclast(dst3, dst3, key, Assembler::AVX_512bit); \\\n+vaesenclast(dst4, dst4, key, Assembler::AVX_512bit); \\\n+\n+#define storeData(dst, position, src1, src2, src3, src4) \\\n+evmovdquq(Address(dst, position, Address::times_1, 0 * 64), src1, Assembler::AVX_512bit); \\\n+evmovdquq(Address(dst, position, Address::times_1, 1 * 64), src2, Assembler::AVX_512bit); \\\n+evmovdquq(Address(dst, position, Address::times_1, 2 * 64), src3, Assembler::AVX_512bit); \\\n+evmovdquq(Address(dst, position, Address::times_1, 3 * 64), src4, Assembler::AVX_512bit); \\\n+\n+#define loadData(src, position, dst1, dst2, dst3, dst4) \\\n+evmovdquq(dst1, Address(src, position, Address::times_1, 0 * 64), Assembler::AVX_512bit); \\\n+evmovdquq(dst2, Address(src, position, Address::times_1, 1 * 64), Assembler::AVX_512bit); \\\n+evmovdquq(dst3, Address(src, position, Address::times_1, 2 * 64), Assembler::AVX_512bit); \\\n+evmovdquq(dst4, Address(src, position, Address::times_1, 3 * 64), Assembler::AVX_512bit); \\\n+\n+#define carrylessMultiply(dst00, dst01, dst10, dst11, ghdata, hkey) \\\n+evpclmulqdq(dst00, ghdata, hkey, 0x00, Assembler::AVX_512bit); \\\n+evpclmulqdq(dst01, ghdata, hkey, 0x01, Assembler::AVX_512bit); \\\n+evpclmulqdq(dst10, ghdata, hkey, 0x10, Assembler::AVX_512bit); \\\n+evpclmulqdq(dst11, ghdata, hkey, 0x11, Assembler::AVX_512bit); \\\n+\n+#define shuffleExorRnd1Key(dst0, dst1, dst2, dst3, shufmask, rndkey) \\\n+vpshufb(dst0, dst0, shufmask, Assembler::AVX_512bit); \\\n+evpxorq(dst0, dst0, rndkey, Assembler::AVX_512bit); \\\n+vpshufb(dst1, dst1, shufmask, Assembler::AVX_512bit); \\\n+evpxorq(dst1, dst1, rndkey, Assembler::AVX_512bit); \\\n+vpshufb(dst2, dst2, shufmask, Assembler::AVX_512bit); \\\n+evpxorq(dst2, dst2, rndkey, Assembler::AVX_512bit); \\\n+vpshufb(dst3, dst3, shufmask, Assembler::AVX_512bit); \\\n+evpxorq(dst3, dst3, rndkey, Assembler::AVX_512bit); \\\n+\n+#define xorBeforeStore(dst0, dst1, dst2, dst3, src0, src1, src2, src3) \\\n+evpxorq(dst0, dst0, src0, Assembler::AVX_512bit); \\\n+evpxorq(dst1, dst1, src1, Assembler::AVX_512bit); \\\n+evpxorq(dst2, dst2, src2, Assembler::AVX_512bit); \\\n+evpxorq(dst3, dst3, src3, Assembler::AVX_512bit); \\\n+\n+#define xorGHASH(dst0, dst1, dst2, dst3, src02, src03, src12, src13, src22, src23, src32, src33) \\\n+vpternlogq(dst0, 0x96, src02, src03, Assembler::AVX_512bit); \\\n+vpternlogq(dst1, 0x96, src12, src13, Assembler::AVX_512bit); \\\n+vpternlogq(dst2, 0x96, src22, src23, Assembler::AVX_512bit); \\\n+vpternlogq(dst3, 0x96, src32, src33, Assembler::AVX_512bit); \\\n+\n+void MacroAssembler::ghash16_encrypt16_parallel(Register key, Register subkeyHtbl, XMMRegister ctr_blockx, XMMRegister aad_hashx,\n+    Register in, Register out, Register data, Register pos, bool first_time_reduction, XMMRegister addmask, bool ghash_input, Register rounds,\n+    Register ghash_pos, bool final_reduction, int i, XMMRegister counter_inc_mask) {\n+\n+    Label AES_192, AES_256, LAST_AES_RND;\n+    const XMMRegister ZTMP0 = xmm0;\n+    const XMMRegister ZTMP1 = xmm3;\n+    const XMMRegister ZTMP2 = xmm4;\n+    const XMMRegister ZTMP3 = xmm5;\n+    const XMMRegister ZTMP5 = xmm7;\n+    const XMMRegister ZTMP6 = xmm10;\n+    const XMMRegister ZTMP7 = xmm11;\n+    const XMMRegister ZTMP8 = xmm12;\n+    const XMMRegister ZTMP9 = xmm13;\n+    const XMMRegister ZTMP10 = xmm15;\n+    const XMMRegister ZTMP11 = xmm16;\n+    const XMMRegister ZTMP12 = xmm17;\n+\n+    const XMMRegister ZTMP13 = xmm19;\n+    const XMMRegister ZTMP14 = xmm20;\n+    const XMMRegister ZTMP15 = xmm21;\n+    const XMMRegister ZTMP16 = xmm30;\n+    const XMMRegister ZTMP17 = xmm31;\n+    const XMMRegister ZTMP18 = xmm1;\n+    const XMMRegister ZTMP19 = xmm2;\n+    const XMMRegister ZTMP20 = xmm8;\n+    const XMMRegister ZTMP21 = xmm22;\n+    const XMMRegister ZTMP22 = xmm23;\n+\n+    \/\/ Pre increment counters\n+    vpaddd(ZTMP0, ctr_blockx, counter_inc_mask, Assembler::AVX_512bit);\n+    vpaddd(ZTMP1, ZTMP0, counter_inc_mask, Assembler::AVX_512bit);\n+    vpaddd(ZTMP2, ZTMP1, counter_inc_mask, Assembler::AVX_512bit);\n+    vpaddd(ZTMP3, ZTMP2, counter_inc_mask, Assembler::AVX_512bit);\n+    \/\/ Save counter value\n+    evmovdquq(ctr_blockx, ZTMP3, Assembler::AVX_512bit);\n+\n+    \/\/ Reuse ZTMP17 \/ ZTMP18 for loading AES Keys\n+    \/\/ Pre-load AES round keys\n+    ev_load_key(ZTMP17, key, 0, xmm29);\n+    ev_load_key(ZTMP18, key, 1 * 16, xmm29);\n+\n+    \/\/ ZTMP19 & ZTMP20 used for loading hash key\n+    \/\/ Pre-load hash key\n+    evmovdquq(ZTMP19, Address(subkeyHtbl, i * 64 + 144), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP20, Address(subkeyHtbl, ++i * 64 + 144), Assembler::AVX_512bit);\n+    \/\/ Load data for computing ghash\n+    evmovdquq(ZTMP21, Address(data, ghash_pos, Address::times_1, 0 * 64), Assembler::AVX_512bit);\n+    vpshufb(ZTMP21, ZTMP21, xmm24, Assembler::AVX_512bit);\n+\n+    \/\/ Xor cipher block 0 with input ghash, if available\n+    if (ghash_input) {\n+        evpxorq(ZTMP21, ZTMP21, aad_hashx, Assembler::AVX_512bit);\n+    }\n+    \/\/ Load data for computing ghash\n+    evmovdquq(ZTMP22, Address(data, ghash_pos, Address::times_1, 1 * 64), Assembler::AVX_512bit);\n+    vpshufb(ZTMP22, ZTMP22, xmm24, Assembler::AVX_512bit);\n+\n+    \/\/ stitch AES rounds with GHASH\n+    \/\/ AES round 0, xmm24 has shuffle mask\n+    shuffleExorRnd1Key(ZTMP0, ZTMP1, ZTMP2, ZTMP3, xmm24, ZTMP17);\n+    \/\/ Reuse ZTMP17 \/ ZTMP18 for loading remaining AES Keys\n+    ev_load_key(ZTMP17, key, 2 * 16, xmm29);\n+    \/\/ GHASH 4 blocks\n+    carrylessMultiply(ZTMP6, ZTMP7, ZTMP8, ZTMP5, ZTMP21, ZTMP19);\n+    \/\/ Load the next hkey and Ghash data\n+    evmovdquq(ZTMP19, Address(subkeyHtbl, ++i * 64 + 144), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP21, Address(data, ghash_pos, Address::times_1, 2 * 64), Assembler::AVX_512bit);\n+    vpshufb(ZTMP21, ZTMP21, xmm24, Assembler::AVX_512bit);\n+\n+    \/\/ AES round 1\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP18, key, 3 * 16, xmm29);\n+\n+    \/\/ GHASH 4 blocks(11 to 8)\n+    carrylessMultiply(ZTMP10, ZTMP12, ZTMP11, ZTMP9, ZTMP22, ZTMP20);\n+    \/\/ Load the next hkey and GDATA\n+    evmovdquq(ZTMP20, Address(subkeyHtbl, ++i * 64 + 144), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP22, Address(data, ghash_pos, Address::times_1, 3 * 64), Assembler::AVX_512bit);\n+    vpshufb(ZTMP22, ZTMP22, xmm24, Assembler::AVX_512bit);\n+\n+    \/\/ AES round 2\n+    roundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP17, key, 4 * 16, xmm29);\n+\n+    \/\/ GHASH 4 blocks(7 to 4)\n+    carrylessMultiply(ZTMP14, ZTMP16, ZTMP15, ZTMP13, ZTMP21, ZTMP19);\n+    \/\/ AES rounds 3\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP18, key, 5 * 16, xmm29);\n+\n+    \/\/ Gather(XOR) GHASH for 12 blocks\n+    xorGHASH(ZTMP5, ZTMP6, ZTMP8, ZTMP7, ZTMP9, ZTMP13, ZTMP10, ZTMP14, ZTMP12, ZTMP16, ZTMP11, ZTMP15);\n+\n+    \/\/ AES rounds 4\n+    roundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP17, key, 6 * 16, xmm29);\n+\n+    \/\/ load plain \/ cipher text(recycle registers)\n+    loadData(in, pos, ZTMP13, ZTMP14, ZTMP15, ZTMP16);\n+\n+    \/\/ AES rounds 5\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP18, key, 7 * 16, xmm29);\n+    \/\/ GHASH 4 blocks(3 to 0)\n+    carrylessMultiply(ZTMP10, ZTMP12, ZTMP11, ZTMP9, ZTMP22, ZTMP20);\n+\n+    \/\/  AES round 6\n+    roundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP17, key, 8 * 16, xmm29);\n+\n+    \/\/ gather GHASH in ZTMP6(low) and ZTMP5(high)\n+    if (first_time_reduction) {\n+        vpternlogq(ZTMP7, 0x96, ZTMP8, ZTMP12, Assembler::AVX_512bit);\n+        evpxorq(xmm25, ZTMP7, ZTMP11, Assembler::AVX_512bit);\n+        evpxorq(xmm27, ZTMP5, ZTMP9, Assembler::AVX_512bit);\n+        evpxorq(xmm26, ZTMP6, ZTMP10, Assembler::AVX_512bit);\n+    }\n+    else if (!first_time_reduction && !final_reduction) {\n+        xorGHASH(ZTMP7, xmm25, xmm27, xmm26, ZTMP8, ZTMP12, ZTMP7, ZTMP11, ZTMP5, ZTMP9, ZTMP6, ZTMP10);\n+    }\n+\n+    if (final_reduction) {\n+        \/\/ Phase one: Add mid products together\n+        \/\/ Also load polynomial constant for reduction\n+        vpternlogq(ZTMP7, 0x96, ZTMP8, ZTMP12, Assembler::AVX_512bit);\n+        vpternlogq(ZTMP7, 0x96, xmm25, ZTMP11, Assembler::AVX_512bit);\n+        vpsrldq(ZTMP11, ZTMP7, 8, Assembler::AVX_512bit);\n+        vpslldq(ZTMP7, ZTMP7, 8, Assembler::AVX_512bit);\n+        evmovdquq(ZTMP12, ExternalAddress(StubRoutines::x86::ghash_polynomial512_addr()), Assembler::AVX_512bit, rbx);\n+    }\n+    \/\/ AES round 7\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP18, key, 9 * 16, xmm29);\n+    if (final_reduction) {\n+        vpternlogq(ZTMP5, 0x96, ZTMP9, ZTMP11, Assembler::AVX_512bit);\n+        evpxorq(ZTMP5, ZTMP5, xmm27, Assembler::AVX_512bit);\n+        vpternlogq(ZTMP6, 0x96, ZTMP10, ZTMP7, Assembler::AVX_512bit);\n+        evpxorq(ZTMP6, ZTMP6, xmm26, Assembler::AVX_512bit);\n+    }\n+    \/\/ AES round 8\n+    roundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP17, key, 10 * 16, xmm29);\n+\n+    \/\/ Horizontal xor of low and high 4*128\n+    if (final_reduction) {\n+        vhpxori4x128(ZTMP5, ZTMP9);\n+        vhpxori4x128(ZTMP6, ZTMP10);\n+    }\n+    \/\/ AES round 9\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    \/\/ First phase of reduction\n+    if (final_reduction) {\n+        evpclmulqdq(ZTMP10, ZTMP12, ZTMP6, 0x01, Assembler::AVX_128bit);\n+        vpslldq(ZTMP10, ZTMP10, 8, Assembler::AVX_128bit);\n+        evpxorq(ZTMP10, ZTMP6, ZTMP10, Assembler::AVX_128bit);\n+    }\n+    cmpl(rounds, 52);\n+    jcc(Assembler::greaterEqual, AES_192);\n+    jmp(LAST_AES_RND);\n+    \/\/ AES rounds upto 11 (AES192) or 13 (AES256)\n+    bind(AES_192);\n+    roundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP18, key, 11 * 16, xmm29);\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP17, key, 12 * 16, xmm29);\n+    cmpl(rounds, 60);\n+    jcc(Assembler::aboveEqual, AES_256);\n+    jmp(LAST_AES_RND);\n+\n+    bind(AES_256);\n+    roundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP18, key, 13 * 16, xmm29);\n+    roundEncode(ZTMP18, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    ev_load_key(ZTMP17, key, 14 * 16, xmm29);\n+\n+    bind(LAST_AES_RND);\n+    \/\/ Second phase of reduction\n+    if (final_reduction) {\n+        evpclmulqdq(ZTMP9, ZTMP12, ZTMP10, 0x00, Assembler::AVX_128bit);\n+        vpsrldq(ZTMP9, ZTMP9, 4, Assembler::AVX_128bit); \/\/ Shift-R 1-DW to obtain 2-DWs shift-R\n+        evpclmulqdq(ZTMP11, ZTMP12, ZTMP10, 0x10, Assembler::AVX_128bit);\n+        vpslldq(ZTMP11, ZTMP11, 4, Assembler::AVX_128bit); \/\/ Shift-L 1-DW for result\n+        \/\/ ZTMP5 = ZTMP5 X ZTMP11 X ZTMP9\n+        vpternlogq(ZTMP5, 0x96, ZTMP11, ZTMP9, Assembler::AVX_128bit);\n+    }\n+    \/\/ Last AES round\n+    lastroundEncode(ZTMP17, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    \/\/ XOR against plain \/ cipher text\n+    xorBeforeStore(ZTMP0, ZTMP1, ZTMP2, ZTMP3, ZTMP13, ZTMP14, ZTMP15, ZTMP16);\n+    \/\/ store cipher \/ plain text\n+    storeData(out, pos, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+}\n+\n+void MacroAssembler::aesgcm_encrypt(Register in, Register len, Register ct, Register out, Register key,\n+                                    Register state, Register subkeyHtbl, Register counter) {\n+\n+    Label ENC_DEC_DONE, GENERATE_HTBL_48_BLKS, AES_192, AES_256, STORE_CT, GHASH_LAST_32,\n+          AES_32_BLOCKS, GHASH_AES_PARALLEL, LOOP, ACCUMULATE, GHASH_16_AES_16;\n+    const XMMRegister CTR_BLOCKx = xmm9;\n+    const XMMRegister AAD_HASHx = xmm14;\n+    const Register pos = rax;\n+    const Register rounds = r15;\n+    Register ghash_pos;\n+#ifndef _WIN64\n+    ghash_pos = r14;\n+#else\n+    ghash_pos = r11;\n+#endif \/\/ !_WIN64\n+    const XMMRegister ZTMP0 = xmm0;\n+    const XMMRegister ZTMP1 = xmm3;\n+    const XMMRegister ZTMP2 = xmm4;\n+    const XMMRegister ZTMP3 = xmm5;\n+    const XMMRegister ZTMP4 = xmm6;\n+    const XMMRegister ZTMP5 = xmm7;\n+    const XMMRegister ZTMP6 = xmm10;\n+    const XMMRegister ZTMP7 = xmm11;\n+    const XMMRegister ZTMP8 = xmm12;\n+    const XMMRegister ZTMP9 = xmm13;\n+    const XMMRegister ZTMP10 = xmm15;\n+    const XMMRegister ZTMP11 = xmm16;\n+    const XMMRegister ZTMP12 = xmm17;\n+    const XMMRegister ZTMP13 = xmm19;\n+    const XMMRegister ZTMP14 = xmm20;\n+    const XMMRegister ZTMP15 = xmm21;\n+    const XMMRegister ZTMP16 = xmm30;\n+    const XMMRegister COUNTER_INC_MASK = xmm18;\n+\n+    movl(pos, 0); \/\/ Total length processed\n+    \/\/ Min data size processed = 768 bytes\n+    cmpl(len, 768);\n+    jcc(Assembler::less, ENC_DEC_DONE);\n+\n+    \/\/ Generate 48 constants for htbl\n+    call(GENERATE_HTBL_48_BLKS, relocInfo::none);\n+    int index = 0; \/\/ Index for choosing subkeyHtbl entry\n+    movl(ghash_pos, 0); \/\/ Pointer for ghash read and store operations\n+\n+    \/\/ Move initial counter value and STATE value into variables\n+    movdqu(CTR_BLOCKx, Address(counter, 0));\n+    movdqu(AAD_HASHx, Address(state, 0));\n+    \/\/ Load lswap mask for ghash\n+    movdqu(xmm24, ExternalAddress(StubRoutines::x86::ghash_long_swap_mask_addr()), rbx);\n+    \/\/ Shuffle input state using lswap mask\n+    vpshufb(AAD_HASHx, AAD_HASHx, xmm24, Assembler::AVX_128bit);\n+\n+    \/\/ Compute #rounds for AES based on the length of the key array\n+    movl(rounds, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n+\n+    \/\/ Broadcast counter value to 512 bit register\n+    evshufi64x2(CTR_BLOCKx, CTR_BLOCKx, CTR_BLOCKx, 0, Assembler::AVX_512bit);\n+    \/\/ Load counter shuffle mask\n+    evmovdquq(xmm24, ExternalAddress(StubRoutines::x86::counter_mask_addr()), Assembler::AVX_512bit, rbx);\n+    \/\/ Shuffle counter\n+    vpshufb(CTR_BLOCKx, CTR_BLOCKx, xmm24, Assembler::AVX_512bit);\n+\n+    \/\/ Load mask for incrementing counter\n+    evmovdquq(COUNTER_INC_MASK, ExternalAddress(StubRoutines::x86::counter_mask_addr() + 128), Assembler::AVX_512bit, rbx);\n+    \/\/ Pre-increment counter\n+    vpaddd(ZTMP5, CTR_BLOCKx, ExternalAddress(StubRoutines::x86::counter_mask_addr() + 64), Assembler::AVX_512bit, rbx);\n+    vpaddd(ZTMP6, ZTMP5, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+    vpaddd(ZTMP7, ZTMP6, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+    vpaddd(ZTMP8, ZTMP7, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+\n+    \/\/ Begin 32 blocks of AES processing\n+    bind(AES_32_BLOCKS);\n+    \/\/ Save incremented counter before overwriting it with AES data\n+    evmovdquq(CTR_BLOCKx, ZTMP8, Assembler::AVX_512bit);\n+\n+    \/\/ Move 256 bytes of data\n+    loadData(in, pos, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    \/\/ Load key shuffle mask\n+    movdqu(xmm29, ExternalAddress(StubRoutines::x86::key_shuffle_mask_addr()), rbx);\n+    \/\/ Load 0th AES round key\n+    ev_load_key(ZTMP4, key, 0, xmm29);\n+    \/\/ AES-ROUND0, xmm24 has the shuffle mask\n+    shuffleExorRnd1Key(ZTMP5, ZTMP6, ZTMP7, ZTMP8, xmm24, ZTMP4);\n+\n+    for (int j = 1; j < 10; j++) {\n+        ev_load_key(ZTMP4, key, j * 16, xmm29);\n+        roundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    }\n+    ev_load_key(ZTMP4, key, 10 * 16, xmm29);\n+    \/\/ AES rounds upto 11 (AES192) or 13 (AES256)\n+    cmpl(rounds, 52);\n+    jcc(Assembler::greaterEqual, AES_192);\n+    lastroundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    jmp(STORE_CT);\n+\n+    bind(AES_192);\n+    roundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    ev_load_key(ZTMP4, key, 11 * 16, xmm29);\n+    roundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    cmpl(rounds, 60);\n+    jcc(Assembler::aboveEqual, AES_256);\n+    ev_load_key(ZTMP4, key, 12 * 16, xmm29);\n+    lastroundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    jmp(STORE_CT);\n+\n+    bind(AES_256);\n+    ev_load_key(ZTMP4, key, 12 * 16, xmm29);\n+    roundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    ev_load_key(ZTMP4, key, 13 * 16, xmm29);\n+    roundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    ev_load_key(ZTMP4, key, 14 * 16, xmm29);\n+    \/\/ Last AES round\n+    lastroundEncode(ZTMP4, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+\n+    bind(STORE_CT);\n+    \/\/ Xor the encrypted key with PT to obtain CT\n+    xorBeforeStore(ZTMP5, ZTMP6, ZTMP7, ZTMP8, ZTMP0, ZTMP1, ZTMP2, ZTMP3);\n+    storeData(out, pos, ZTMP5, ZTMP6, ZTMP7, ZTMP8);\n+    \/\/ 16 blocks encryption completed\n+    addl(pos, 256);\n+    cmpl(pos, 512);\n+    jcc(Assembler::aboveEqual, GHASH_AES_PARALLEL);\n+    vpaddd(ZTMP5, CTR_BLOCKx, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+    vpaddd(ZTMP6, ZTMP5, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+    vpaddd(ZTMP7, ZTMP6, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+    vpaddd(ZTMP8, ZTMP7, COUNTER_INC_MASK, Assembler::AVX_512bit);\n+    jmp(AES_32_BLOCKS);\n+\n+    bind(GHASH_AES_PARALLEL);\n+    \/\/ Ghash16_encrypt16_parallel takes place in the order with three reduction values:\n+    \/\/ 1) First time -> cipher xor input ghash\n+    \/\/ 2) No reduction -> accumulate multiplication values\n+    \/\/ 3) Final reduction post 48 blocks -> new ghash value is computed for the next round\n+    \/\/ Reduction value = first time\n+    ghash16_encrypt16_parallel(key, subkeyHtbl, CTR_BLOCKx, AAD_HASHx, in, out, ct, pos, true, xmm24, true, rounds, ghash_pos, false, index, COUNTER_INC_MASK);\n+    addl(pos, 256);\n+    addl(ghash_pos, 256);\n+    index += 4;\n+\n+    \/\/ At this point we have processed 768 bytes of AES and 256 bytes of GHASH.\n+    \/\/ If the remaining length is less than 768, process remaining 512 bytes of ghash in GHASH_LAST_32 code\n+    subl(len, 768);\n+    cmpl(len, 768);\n+    jcc(Assembler::less, GHASH_LAST_32);\n+\n+    \/\/ AES 16 blocks and GHASH 16 blocks in parallel\n+    \/\/ For multiples of 48 blocks we will do ghash16_encrypt16 interleaved multiple times\n+    \/\/ Reduction value = no reduction means that the carryless multiplication values are accumulated for further calculations\n+    \/\/ Each call uses 4 subkeyHtbl values, so increment the index by 4.\n+    bind(GHASH_16_AES_16);\n+    \/\/ Reduction value = no reduction\n+    ghash16_encrypt16_parallel(key, subkeyHtbl, CTR_BLOCKx, AAD_HASHx, in, out, ct, pos, false, xmm24, false, rounds, ghash_pos, false, index, COUNTER_INC_MASK);\n+    addl(pos, 256);\n+    addl(ghash_pos, 256);\n+    index += 4;\n+    \/\/ Reduction value = final reduction means that the accumulated values have to be reduced as we have completed 48 blocks of ghash\n+    ghash16_encrypt16_parallel(key, subkeyHtbl, CTR_BLOCKx, AAD_HASHx, in, out, ct, pos, false, xmm24, false, rounds, ghash_pos, true, index, COUNTER_INC_MASK);\n+    addl(pos, 256);\n+    addl(ghash_pos, 256);\n+    \/\/ Calculated ghash value needs to be moved to AAD_HASHX so that we can restart the ghash16-aes16 pipeline\n+    movdqu(AAD_HASHx, ZTMP5);\n+    index = 0; \/\/ Reset subkeyHtbl index\n+\n+    \/\/ Restart the pipeline\n+    \/\/ Reduction value = first time\n+    ghash16_encrypt16_parallel(key, subkeyHtbl, CTR_BLOCKx, AAD_HASHx, in, out, ct, pos, true, xmm24, true, rounds, ghash_pos, false, index, COUNTER_INC_MASK);\n+    addl(pos, 256);\n+    addl(ghash_pos, 256);\n+    index += 4;\n+\n+    subl(len, 768);\n+    cmpl(len, 768);\n+    jcc(Assembler::greaterEqual, GHASH_16_AES_16);\n+\n+    \/\/ GHASH last 32 blocks processed here\n+    \/\/ GHASH products accumulated in ZMM27, ZMM25 and ZMM26 during GHASH16-AES16 operation is used\n+    bind(GHASH_LAST_32);\n+    \/\/ Use rbx as a pointer to the htbl; For last 32 blocks of GHASH, use key# 4-11 entry in subkeyHtbl\n+    movl(rbx, 256);\n+    \/\/ Load cipher blocks\n+    evmovdquq(ZTMP13, Address(ct, ghash_pos, Address::times_1, 0 * 64), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP14, Address(ct, ghash_pos, Address::times_1, 1 * 64), Assembler::AVX_512bit);\n+    vpshufb(ZTMP13, ZTMP13, xmm24, Assembler::AVX_512bit);\n+    vpshufb(ZTMP14, ZTMP14, xmm24, Assembler::AVX_512bit);\n+    \/\/ Load ghash keys\n+    evmovdquq(ZTMP15, Address(subkeyHtbl, rbx, Address::times_1, 0 * 64 + 144), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP16, Address(subkeyHtbl, rbx, Address::times_1, 1 * 64 + 144), Assembler::AVX_512bit);\n+\n+    \/\/ Ghash blocks 0 - 3\n+    carrylessMultiply(ZTMP2, ZTMP3, ZTMP4, ZTMP1, ZTMP13, ZTMP15);\n+    \/\/ Ghash blocks 4 - 7\n+    carrylessMultiply(ZTMP6, ZTMP7, ZTMP8, ZTMP5, ZTMP14, ZTMP16);\n+\n+    vpternlogq(ZTMP1, 0x96, ZTMP5, xmm27, Assembler::AVX_512bit); \/\/ ZTMP1 = ZTMP1 + ZTMP5 + zmm27\n+    vpternlogq(ZTMP2, 0x96, ZTMP6, xmm26, Assembler::AVX_512bit); \/\/ ZTMP2 = ZTMP2 + ZTMP6 + zmm26\n+    vpternlogq(ZTMP3, 0x96, ZTMP7, xmm25, Assembler::AVX_512bit); \/\/ ZTMP3 = ZTMP3 + ZTMP7 + zmm25\n+    evpxorq(ZTMP4, ZTMP4, ZTMP8, Assembler::AVX_512bit);          \/\/ ZTMP4 = ZTMP4 + ZTMP8\n+\n+    addl(ghash_pos, 128);\n+    addl(rbx, 128);\n+\n+    \/\/ Ghash remaining blocks\n+    bind(LOOP);\n+    cmpl(ghash_pos, pos);\n+    jcc(Assembler::aboveEqual, ACCUMULATE);\n+    \/\/ Load next cipher blocks and corresponding ghash keys\n+    evmovdquq(ZTMP13, Address(ct, ghash_pos, Address::times_1, 0 * 64), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP14, Address(ct, ghash_pos, Address::times_1, 1 * 64), Assembler::AVX_512bit);\n+    vpshufb(ZTMP13, ZTMP13, xmm24, Assembler::AVX_512bit);\n+    vpshufb(ZTMP14, ZTMP14, xmm24, Assembler::AVX_512bit);\n+    evmovdquq(ZTMP15, Address(subkeyHtbl, rbx, Address::times_1, 0 * 64 + 144), Assembler::AVX_512bit);\n+    evmovdquq(ZTMP16, Address(subkeyHtbl, rbx, Address::times_1, 1 * 64 + 144), Assembler::AVX_512bit);\n+\n+    \/\/ ghash blocks 0 - 3\n+    carrylessMultiply(ZTMP6, ZTMP7, ZTMP8, ZTMP5, ZTMP13, ZTMP15);\n+\n+    \/\/ ghash blocks 4 - 7\n+    carrylessMultiply(ZTMP10, ZTMP11, ZTMP12, ZTMP9, ZTMP14, ZTMP16);\n+\n+    \/\/ update sums\n+    \/\/ ZTMP1 = ZTMP1 + ZTMP5 + ZTMP9\n+    \/\/ ZTMP2 = ZTMP2 + ZTMP6 + ZTMP10\n+    \/\/ ZTMP3 = ZTMP3 + ZTMP7 xor ZTMP11\n+    \/\/ ZTMP4 = ZTMP4 + ZTMP8 xor ZTMP12\n+    xorGHASH(ZTMP1, ZTMP2, ZTMP3, ZTMP4, ZTMP5, ZTMP9, ZTMP6, ZTMP10, ZTMP7, ZTMP11, ZTMP8, ZTMP12);\n+    addl(ghash_pos, 128);\n+    addl(rbx, 128);\n+    jmp(LOOP);\n+\n+    \/\/ Integrate ZTMP3\/ZTMP4 into ZTMP1 and ZTMP2\n+    bind(ACCUMULATE);\n+    evpxorq(ZTMP3, ZTMP3, ZTMP4, Assembler::AVX_512bit);\n+    vpsrldq(ZTMP7, ZTMP3, 8, Assembler::AVX_512bit);\n+    vpslldq(ZTMP8, ZTMP3, 8, Assembler::AVX_512bit);\n+    evpxorq(ZTMP1, ZTMP1, ZTMP7, Assembler::AVX_512bit);\n+    evpxorq(ZTMP2, ZTMP2, ZTMP8, Assembler::AVX_512bit);\n+\n+    \/\/ Add ZTMP1 and ZTMP2 128 - bit words horizontally\n+    vhpxori4x128(ZTMP1, ZTMP11);\n+    vhpxori4x128(ZTMP2, ZTMP12);\n+    \/\/ Load reduction polynomial and compute final reduction\n+    evmovdquq(ZTMP15, ExternalAddress(StubRoutines::x86::ghash_polynomial512_addr()), Assembler::AVX_512bit, rbx);\n+    vclmul_reduce(AAD_HASHx, ZTMP15, ZTMP1, ZTMP2, ZTMP3, ZTMP4);\n+\n+    \/\/ Pre-increment counter for next operation\n+    vpaddd(CTR_BLOCKx, CTR_BLOCKx, xmm18, Assembler::AVX_128bit);\n+    \/\/ Shuffle counter and save the updated value\n+    vpshufb(CTR_BLOCKx, CTR_BLOCKx, xmm24, Assembler::AVX_512bit);\n+    movdqu(Address(counter, 0), CTR_BLOCKx);\n+    \/\/ Load ghash lswap mask\n+    movdqu(xmm24, ExternalAddress(StubRoutines::x86::ghash_long_swap_mask_addr()));\n+    \/\/ Shuffle ghash using lbswap_mask and store it\n+    vpshufb(AAD_HASHx, AAD_HASHx, xmm24, Assembler::AVX_128bit);\n+    movdqu(Address(state, 0), AAD_HASHx);\n+    jmp(ENC_DEC_DONE);\n+\n+    bind(GENERATE_HTBL_48_BLKS);\n+    generateHtbl_48_block_zmm(subkeyHtbl);\n+\n+    bind(ENC_DEC_DONE);\n+    movq(rax, pos);\n+}\n+\n+#endif \/\/ _LP64\n\\ No newline at end of file\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_aes.cpp","additions":624,"deletions":1,"binary":false,"changes":625,"status":"modified"},{"patch":"@@ -4371,0 +4371,89 @@\n+  address ghash_polynomial512_addr() {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"_ghash_poly512_addr\");\n+    address start = __ pc();\n+    __ emit_data64(0x00000001C2000000, relocInfo::none); \/\/ POLY for reduction\n+    __ emit_data64(0xC200000000000000, relocInfo::none);\n+    __ emit_data64(0x00000001C2000000, relocInfo::none);\n+    __ emit_data64(0xC200000000000000, relocInfo::none);\n+    __ emit_data64(0x00000001C2000000, relocInfo::none);\n+    __ emit_data64(0xC200000000000000, relocInfo::none);\n+    __ emit_data64(0x00000001C2000000, relocInfo::none);\n+    __ emit_data64(0xC200000000000000, relocInfo::none);\n+    __ emit_data64(0x0000000000000001, relocInfo::none); \/\/ POLY\n+    __ emit_data64(0xC200000000000000, relocInfo::none);\n+    __ emit_data64(0x0000000000000001, relocInfo::none); \/\/ TWOONE\n+    __ emit_data64(0x0000000100000000, relocInfo::none);\n+    return start;\n+}\n+\n+  \/\/ Vector AES Galois Counter Mode implementation. Parameters:\n+  \/\/ Windows regs            |  Linux regs\n+  \/\/ in = c_rarg0 (rcx)      |  c_rarg0 (rsi)\n+  \/\/ len = c_rarg1 (rdx)     |  c_rarg1 (rdi)\n+  \/\/ ct = c_rarg2 (r8)       |  c_rarg2 (rdx)\n+  \/\/ out = c_rarg3 (r9)      |  c_rarg3 (rcx)\n+  \/\/ key = r10               |  c_rarg4 (r8)\n+  \/\/ state = r13             |  c_rarg5 (r9)\n+  \/\/ subkeyHtbl = r14        |  r11\n+  \/\/ counter = rsi           |  r12\n+  \/\/ return - number of processed bytes\n+  address generate_galoisCounterMode_AESCrypt() {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"galoisCounterMode_AESCrypt\");\n+    address start = __ pc();\n+    const Register in = c_rarg0;\n+    const Register len = c_rarg1;\n+    const Register ct = c_rarg2;\n+    const Register out = c_rarg3;\n+    \/\/ and updated with the incremented counter in the end\n+#ifndef _WIN64\n+    const Register key = c_rarg4;\n+    const Register state = c_rarg5;\n+    const Address subkeyH_mem(rbp, 2 * wordSize);\n+    const Register subkeyHtbl = r11;\n+    const Address counter_mem(rbp, 3 * wordSize);\n+    const Register counter = r12;\n+#else\n+    const Address key_mem(rbp, 6 * wordSize);\n+    const Register key = r10;\n+    const Address state_mem(rbp, 7 * wordSize);\n+    const Register state = r13;\n+    const Address subkeyH_mem(rbp, 8 * wordSize);\n+    const Register subkeyHtbl = r14;\n+    const Address counter_mem(rbp, 9 * wordSize);\n+    const Register counter = rsi;\n+#endif\n+    __ enter();\n+   \/\/ Save state before entering routine\n+    __ push(r12);\n+    __ push(r13);\n+    __ push(r14);\n+    __ push(r15);\n+    __ push(rbx);\n+#ifdef _WIN64\n+    \/\/ on win64, fill len_reg from stack position\n+    __ push(rsi);\n+    __ movptr(key, key_mem);\n+    __ movptr(state, state_mem);\n+#endif\n+    __ movptr(subkeyHtbl, subkeyH_mem);\n+    __ movptr(counter, counter_mem);\n+\n+    __ aesgcm_encrypt(in, len, ct, out, key, state, subkeyHtbl, counter);\n+\n+    \/\/ Restore state before leaving routine\n+#ifdef _WIN64\n+    __ pop(rsi);\n+#endif\n+    __ pop(rbx);\n+    __ pop(r15);\n+    __ pop(r14);\n+    __ pop(r13);\n+    __ pop(r12);\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(0);\n+     return start;\n+  }\n+\n@@ -7550,0 +7639,4 @@\n+        StubRoutines::x86::_counter_mask_addr = counter_mask_addr();\n+        StubRoutines::x86::_ghash_poly512_addr = ghash_polynomial512_addr();\n+        StubRoutines::x86::_ghash_long_swap_mask_addr = generate_ghash_long_swap_mask();\n+        StubRoutines::_galoisCounterMode_AESCrypt = generate_galoisCounterMode_AESCrypt();\n@@ -7554,0 +7647,1 @@\n+\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":94,"deletions":0,"binary":false,"changes":94,"status":"modified"},{"patch":"@@ -85,0 +85,1 @@\n+address StubRoutines::x86::_ghash_poly512_addr = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -36,1 +36,1 @@\n-  code_size2 = 35300 LP64_ONLY(+25000)          \/\/ simply increase if too small (assembler will crash if too small)\n+  code_size2 = 35300 LP64_ONLY(+32000)          \/\/ simply increase if too small (assembler will crash if too small)\n@@ -203,0 +203,1 @@\n+  static address _ghash_poly512_addr;\n@@ -259,0 +260,1 @@\n+  static address ghash_polynomial512_addr() { return _ghash_poly512_addr; }\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -185,0 +185,1 @@\n+  case vmIntrinsics::_galoisCounterMode_AESCrypt:\n@@ -432,0 +433,3 @@\n+  case vmIntrinsics::_galoisCounterMode_AESCrypt:\n+    if (!UseAESIntrinsics) return true;\n+    break;\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -418,0 +418,5 @@\n+  do_class(com_sun_crypto_provider_galoisCounterMode, \"com\/sun\/crypto\/provider\/GaloisCounterMode\")                      \\\n+   do_intrinsic(_galoisCounterMode_AESCrypt, com_sun_crypto_provider_galoisCounterMode, gcm_crypt_name, aes_gcm_signature, F_S)   \\\n+   do_name(gcm_crypt_name, \"implGCMCrypt\")                                                                                 \\\n+   do_signature(aes_gcm_signature, \"([BII[BI[BILcom\/sun\/crypto\/provider\/GCTR;Lcom\/sun\/crypto\/provider\/GHASH;)I\")                                                             \\\n+                                                                                                                        \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -311,0 +311,1 @@\n+  static_field(StubRoutines,                _galoisCounterMode_AESCrypt,                      address)                               \\\n","filename":"src\/hotspot\/share\/jvmci\/vmStructs_jvmci.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -643,0 +643,1 @@\n+  case vmIntrinsics::_galoisCounterMode_AESCrypt:\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1090,0 +1090,1 @@\n+                  strcmp(call->as_CallLeaf()->_name, \"galoisCounterMode_AESCrypt\") == 0 ||\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2538,1 +2538,1 @@\n-    \/* close each nested if ===> *\/  } } } } } } } }\n+  \/* close each nested if ===> *\/  } } } } } } } }\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -550,0 +550,3 @@\n+  case vmIntrinsics::_galoisCounterMode_AESCrypt:\n+    return inline_galoisCounterMode_AESCrypt();\n+\n@@ -716,0 +719,2 @@\n+  case vmIntrinsics::_galoisCounterMode_AESCrypt:\n+    return inline_galoisCounterMode_AESCrypt_predicate();\n@@ -6682,0 +6687,128 @@\n+\/\/------------------------------inline_galoisCounterMode_AESCrypt-----------------------\n+bool LibraryCallKit::inline_galoisCounterMode_AESCrypt() {\n+  assert(UseAES, \"need AES instruction support\");\n+  address stubAddr = NULL;\n+  const char *stubName = NULL;\n+  stubAddr = StubRoutines::galoisCounterMode_AESCrypt();\n+  stubName = \"galoisCounterMode_AESCrypt\";\n+\n+  if (stubAddr == NULL) return false;\n+\n+  Node* in      = argument(0);\n+  Node* inOfs   = argument(1);\n+  Node* len     = argument(2);\n+  Node* ct      = argument(3);\n+  Node* ctOfs   = argument(4);\n+  Node* out     = argument(5);\n+  Node* outOfs  = argument(6);\n+  Node* gctr_object = argument(7);\n+  Node* ghash_object = argument(8);\n+\n+  \/\/ (1) in, ct and out are arrays.\n+  const Type* in_type = in->Value(&_gvn);\n+  const Type* ct_type = ct->Value(&_gvn);\n+  const Type* out_type = out->Value(&_gvn);\n+  const TypeAryPtr* top_in = in_type->isa_aryptr();\n+  const TypeAryPtr* top_ct = ct_type->isa_aryptr();\n+  const TypeAryPtr* top_out = out_type->isa_aryptr();\n+  assert(top_in != NULL && top_in->klass() != NULL &&\n+         top_ct != NULL && top_ct->klass() != NULL &&\n+         top_out != NULL && top_out->klass() != NULL, \"args are strange\");\n+\n+  \/\/ checks are the responsibility of the caller\n+  Node* in_start = in;\n+  Node* ct_start = ct;\n+  Node* out_start = out;\n+  if (inOfs != NULL || ctOfs != NULL || outOfs != NULL) {\n+    assert(inOfs != NULL && ctOfs != NULL && outOfs != NULL, \"\");\n+    in_start = array_element_address(in, inOfs, T_BYTE);\n+    ct_start = array_element_address(ct, ctOfs, T_BYTE);\n+    out_start = array_element_address(out, outOfs, T_BYTE);\n+  }\n+\n+  \/\/ if we are in this set of code, we \"know\" the embeddedCipher is an AESCrypt object\n+  \/\/ (because of the predicated logic executed earlier).\n+  \/\/ so we cast it here safely.\n+  \/\/ this requires a newer class file that has this array as littleEndian ints, otherwise we revert to java\n+  Node* embeddedCipherObj = load_field_from_object(gctr_object, \"embeddedCipher\", \"Lcom\/sun\/crypto\/provider\/SymmetricCipher;\");\n+  Node* counter = load_field_from_object(gctr_object, \"counter\", \"[B\");\n+  Node* subkeyHtbl = load_field_from_object(ghash_object, \"subkeyHtbl\", \"[J\");\n+  Node* state = load_field_from_object(ghash_object, \"state\", \"[J\");\n+\n+  if (embeddedCipherObj == NULL || counter == NULL || subkeyHtbl == NULL || state == NULL) {\n+      return false;\n+  }\n+  \/\/ cast it to what we know it will be at runtime\n+  const TypeInstPtr* tinst = _gvn.type(gctr_object)->isa_instptr();\n+  assert(tinst != NULL, \"GCTR obj is null\");\n+  assert(tinst->klass()->is_loaded(), \"GCTR obj is not loaded\");\n+  ciKlass* klass_AESCrypt = tinst->klass()->as_instance_klass()->find_klass(ciSymbol::make(\"com\/sun\/crypto\/provider\/AESCrypt\"));\n+  assert(klass_AESCrypt->is_loaded(), \"predicate checks that this class is loaded\");\n+  ciInstanceKlass* instklass_AESCrypt = klass_AESCrypt->as_instance_klass();\n+  const TypeKlassPtr* aklass = TypeKlassPtr::make(instklass_AESCrypt);\n+  const TypeOopPtr* xtype = aklass->as_instance_type();\n+  Node* aescrypt_object = new CheckCastPPNode(control(), embeddedCipherObj, xtype);\n+  aescrypt_object = _gvn.transform(aescrypt_object);\n+  \/\/ we need to get the start of the aescrypt_object's expanded key array\n+  Node* k_start = get_key_start_from_aescrypt_object(aescrypt_object);\n+  if (k_start == NULL) return false;\n+\n+  \/\/ similarly, get the start address of the r vector\n+  Node* cnt_start = array_element_address(counter, intcon(0), T_BYTE);\n+  Node* state_start = array_element_address(state, intcon(0), T_LONG);\n+  Node* subkeyHtbl_start = array_element_address(subkeyHtbl, intcon(0), T_LONG);\n+\n+  \/\/ Call the stub, passing params\n+  Node* gcmCrypt = make_runtime_call(RC_LEAF|RC_NO_FP,\n+                               OptoRuntime::galoisCounterMode_aescrypt_Type(),\n+                               stubAddr, stubName, TypePtr::BOTTOM,\n+                               in_start, len, ct_start, out_start, k_start, state_start, subkeyHtbl_start, cnt_start);\n+\n+  \/\/ return cipher length (int)\n+  Node* retvalue = _gvn.transform(new ProjNode(gcmCrypt, TypeFunc::Parms));\n+  set_result(retvalue);\n+  return true;\n+}\n+\n+\/\/----------------------------inline_galoisCounterMode_AESCrypt_predicate----------------------------\n+\/\/ Return node representing slow path of predicate check.\n+\/\/ the pseudo code we want to emulate with this predicate is:\n+\/\/ for encryption:\n+\/\/    if (embeddedCipherObj instanceof AESCrypt) do_intrinsic, else do_javapath\n+\/\/ for decryption:\n+\/\/    if ((embeddedCipherObj instanceof AESCrypt) && (cipher!=plain)) do_intrinsic, else do_javapath\n+\/\/    note cipher==plain is more conservative than the original java code but that's OK\n+\/\/\n+\n+Node* LibraryCallKit::inline_galoisCounterMode_AESCrypt_predicate() {\n+  \/\/ The receiver was checked for NULL already.\n+  Node* objGCTR = argument(7);\n+  \/\/ Load embeddedCipher field of GCTR object.\n+  Node* embeddedCipherObj = load_field_from_object(objGCTR, \"embeddedCipher\", \"Lcom\/sun\/crypto\/provider\/SymmetricCipher;\");\n+  assert(embeddedCipherObj != NULL, \"embeddedCipherObj is null\");\n+\n+  \/\/ get AESCrypt klass for instanceOf check\n+  \/\/ AESCrypt might not be loaded yet if some other SymmetricCipher got us to this compile point\n+  \/\/ will have same classloader as CipherBlockChaining object\n+  const TypeInstPtr* tinst = _gvn.type(objGCTR)->isa_instptr();\n+  assert(tinst != NULL, \"GCTR obj is null\");\n+  assert(tinst->klass()->is_loaded(), \"GCTR obj is not loaded\");\n+\n+  \/\/ we want to do an instanceof comparison against the AESCrypt class\n+  ciKlass* klass_AESCrypt = tinst->klass()->as_instance_klass()->find_klass(ciSymbol::make(\"com\/sun\/crypto\/provider\/AESCrypt\"));\n+  if (!klass_AESCrypt->is_loaded()) {\n+    \/\/ if AESCrypt is not even loaded, we never take the intrinsic fast path\n+    Node* ctrl = control();\n+    set_control(top()); \/\/ no regular fast path\n+    return ctrl;\n+  }\n+\n+  ciInstanceKlass* instklass_AESCrypt = klass_AESCrypt->as_instance_klass();\n+  Node* instof = gen_instanceof(embeddedCipherObj, makecon(TypeKlassPtr::make(instklass_AESCrypt)));\n+  Node* cmp_instof = _gvn.transform(new CmpINode(instof, intcon(1)));\n+  Node* bool_instof = _gvn.transform(new BoolNode(cmp_instof, BoolTest::ne));\n+  Node* instof_false = generate_guard(bool_instof, NULL, PROB_MIN);\n+\n+  return instof_false; \/\/ even if it is NULL\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":133,"deletions":0,"binary":false,"changes":133,"status":"modified"},{"patch":"@@ -308,0 +308,2 @@\n+  bool inline_galoisCounterMode_AESCrypt();\n+  Node* inline_galoisCounterMode_AESCrypt_predicate();\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -954,0 +954,25 @@\n+  const TypeTuple* range = TypeTuple::make(TypeFunc::Parms + 1, fields);\n+  return TypeFunc::make(domain, range);\n+}\n+\n+\/\/for counterMode calls of aescrypt encrypt\/decrypt, four pointers and a length, returning int\n+const TypeFunc* OptoRuntime::galoisCounterMode_aescrypt_Type() {\n+  \/\/ create input type (domain)\n+  int num_args = 8;\n+  int argcnt = num_args;\n+  const Type** fields = TypeTuple::fields(argcnt);\n+  int argp = TypeFunc::Parms;\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ byte[] in + inOfs\n+  fields[argp++] = TypeInt::INT;     \/\/ int len\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ byte[] ct + ctOfs\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ byte[] out + outOfs\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ byte[] key from AESCrypt obj\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ long[] state from GHASH obj\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ long[] subkeyHtbl from GHASH obj\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ byte[] counter from GCTR obj\n+\n+  assert(argp == TypeFunc::Parms + argcnt, \"correct decoding\");\n+  const TypeTuple* domain = TypeTuple::make(TypeFunc::Parms + argcnt, fields);\n+  \/\/ returning cipher len (int)\n+  fields = TypeTuple::fields(1);\n+  fields[TypeFunc::Parms + 0] = TypeInt::INT;\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -260,0 +260,1 @@\n+  static const TypeFunc* galoisCounterMode_aescrypt_Type();\n","filename":"src\/hotspot\/share\/opto\/runtime.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -127,0 +127,1 @@\n+address StubRoutines::_galoisCounterMode_AESCrypt          = NULL;\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -209,0 +209,1 @@\n+  static address _galoisCounterMode_AESCrypt;\n@@ -413,0 +414,1 @@\n+  static address galoisCounterMode_AESCrypt()   { return _galoisCounterMode_AESCrypt; }\n","filename":"src\/hotspot\/share\/runtime\/stubRoutines.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -592,0 +592,1 @@\n+     static_field(StubRoutines,                _galoisCounterMode_AESCrypt,                   address)                               \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -125,1 +125,1 @@\n-    \/\/ hashtable subkeyHtbl holds 2*9 powers of subkeyH computed using\n+    \/\/ hashtable subkeyHtbl holds 2*57 powers of subkeyH computed using\n@@ -146,1 +146,3 @@\n-        subkeyHtbl = new long[2*9];\n+         \/\/ 48 keys for the interleaved implementation,\n+         \/\/ 8 for avx-ghash implementation and 1 for the original key\n+        subkeyHtbl = new long[2*57];\n@@ -267,1 +269,1 @@\n-        if (subH.length != 18) {\n+        if (subH.length != 114) {\n","filename":"src\/java.base\/share\/classes\/com\/sun\/crypto\/provider\/GHASH.java","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+import jdk.internal.misc.Unsafe;\n@@ -58,0 +59,2 @@\n+import jdk.internal.vm.annotation.IntrinsicCandidate;\n+\n@@ -85,0 +88,2 @@\n+    \/\/ x86-64 parallel intrinsic data size\n+    private static final int PARALLEL_LEN = 768;\n@@ -584,0 +589,45 @@\n+    \/**\n+     * Intrinsic for Vector AES Galois Counter Mode implementation.\n+     * AES and GHASH operations are interleaved in the intrinsic implementation.\n+     *\n+     * Requires 768 bytes (48 AES blocks) to efficiently use the intrinsic.\n+     * inLen that is less than 768 size block sizes, before or after this\n+     * intrinsic is used, will be done by the calling method\n+     * @param in input buffer\n+     * @param inOfs input offset\n+     * @param inLen lnput length\n+     * @param ct buffer that ghash will read (in for encrypt, out for decrypt)\n+     * @param ctOfs offset for ct buffer\n+     * @param out output buffer\n+     * @param outOfs output offset\n+     * @param gctr object for the GCTR operation\n+     * @param ghash object for the ghash operation\n+     * @return number of processed bytes\n+     *\/\n+    @IntrinsicCandidate\n+    private static int implGCMCrypt(byte[] in, int inOfs, int inLen,\n+        byte[] ct, int ctOfs, byte[] out, int outOfs,\n+        GCTR gctr, GHASH ghash) {\n+\n+        int len = 0;\n+        int cOfs = ctOfs;\n+        if (inLen > TRIGGERLEN) {\n+            int i = 0;\n+            int segments = (inLen \/ 6);\n+            segments -= segments % gctr.blockSize;\n+            do {\n+                len += gctr.update(in, inOfs + len, segments, out,\n+                    outOfs + len);\n+                ghash.update(ct, cOfs, segments);\n+                cOfs = ctOfs + len;\n+            } while (++i < 5);\n+\n+            inLen -= len;\n+        }\n+\n+        len += gctr.update(in, inOfs + len, inLen, out, outOfs + len);\n+        ghash.update(ct, cOfs, inLen);\n+        return len;\n+    }\n+\n+\n@@ -589,2 +639,3 @@\n-        GCTR gctrPAndC;\n-        GHASH ghashAllToS;\n+        GCTR gctr;\n+        GHASH ghash;\n+        GCMOperation op;\n@@ -610,1 +661,2 @@\n-\n+        byte[] in;\n+        byte[] out;\n@@ -619,2 +671,2 @@\n-            gctrPAndC = new GCTR(blockCipher, j0Plus1);\n-            ghashAllToS = new GHASH(subkeyH);\n+            gctr = new GCTR(blockCipher, j0Plus1);\n+            ghash = new GHASH(subkeyH);\n@@ -634,3 +686,3 @@\n-        abstract byte[] doUpdate(byte[] in, int inOff, int inLen);\n-        abstract int doUpdate(byte[] in, int inOff, int inLen, byte[] out,\n-            int outOff) throws ShortBufferException;\n+        abstract byte[] doUpdate(byte[] in, int inOfs, int inLen);\n+        abstract int doUpdate(byte[] in, int inOfs, int inLen, byte[] out,\n+            int outOfs) throws ShortBufferException;\n@@ -641,2 +693,2 @@\n-        abstract int doFinal(byte[] in, int inOff, int inLen, byte[] out,\n-            int outOff) throws IllegalBlockSizeException, AEADBadTagException,\n+        abstract int doFinal(byte[] in, int inOfs, int inLen, byte[] out,\n+            int outOfs) throws IllegalBlockSizeException, AEADBadTagException,\n@@ -660,0 +712,51 @@\n+        \/**\n+         *  ByteBuffer wrapper for intrinsic implGCMCrypt\n+         *\/\n+        int implGCMCrypt(GCMOperation op, ByteBuffer src, ByteBuffer dst) {\n+            int srcLen = src.remaining() - (src.remaining() % blockSize);\n+\n+            if (srcLen < blockSize) {\n+                return 0;\n+            }\n+\n+            int rlen = srcLen;\n+            \/\/ 'in' and 'out' are always set together, just need to check 'in'\n+            if (in == null || (in.length != PARALLEL_LEN\n+                && in.length < srcLen)) {\n+                in = new byte[Math.min(PARALLEL_LEN, srcLen)];\n+                out = new byte[Math.min(PARALLEL_LEN, srcLen)];\n+            }\n+\n+            if (srcLen >= PARALLEL_LEN) {\n+                if (src.hasArray() && dst.hasArray()) {\n+                    ByteBuffer ct = (encryption ? dst : src);\n+                    int len = GaloisCounterMode.implGCMCrypt(src.array(),\n+                        src.arrayOffset() + src.position(), srcLen,\n+                        ct.array(), ct.arrayOffset() + ct.position(),\n+                        dst.array(), dst.arrayOffset() + dst.position(),\n+                        gctr, ghash);\n+                    src.position(src.position() + len);\n+                    dst.position(dst.position() + len);\n+                    rlen -= len;\n+                } else {\n+\n+                    byte[] ct = (encryption ? out : in);\n+                    do {\n+                        src.get(in, 0, PARALLEL_LEN);\n+                        rlen -= GaloisCounterMode.implGCMCrypt(in, 0,\n+                            PARALLEL_LEN, ct, 0, out, 0, gctr, ghash);\n+                        dst.put(out, 0, PARALLEL_LEN);\n+                    } while (rlen >= PARALLEL_LEN);\n+                }\n+            }\n+\n+            if (rlen >= blockSize) {\n+                src.get(in, 0, rlen);\n+                rlen = op.update(in, 0, rlen, out, 0);\n+            }\n+\n+            dst.put(out, 0, rlen);\n+            processed += srcLen;\n+            return srcLen;\n+        }\n+\n@@ -736,1 +839,1 @@\n-                        ghashAllToS.update(aad, 0, aad.length - lastLen);\n+                        ghash.update(aad, 0, aad.length - lastLen);\n@@ -739,1 +842,1 @@\n-                        ghashAllToS.update(padded);\n+                        ghash.update(padded);\n@@ -741,1 +844,1 @@\n-                        ghashAllToS.update(aad);\n+                        ghash.update(aad);\n@@ -754,1 +857,2 @@\n-        int doLastBlock(GCM op, ByteBuffer buffer, ByteBuffer src, ByteBuffer dst) {\n+        int doLastBlock(GCMOperation op, ByteBuffer buffer, ByteBuffer src,\n+                        ByteBuffer dst) {\n@@ -761,1 +865,1 @@\n-                    resultLen += op.update(buffer, dst);\n+                    resultLen += implGCMCrypt(op, buffer, dst);\n@@ -794,1 +898,1 @@\n-                resultLen += throttleData(op, src, dst);\n+                resultLen += implGCMCrypt(op, src, dst);\n@@ -802,46 +906,0 @@\n-\n-        \/**\n-         * This segments large data into smaller chunks so hotspot will start\n-         * using GCTR and GHASH intrinsics sooner.  This is a problem for app\n-         * and perf tests that only use large input sizes.\n-         *\/\n-        int throttleData(GCM op, byte[] in, int inOfs, int inLen,\n-            byte[] out, int outOfs) {\n-\n-            int segments = (inLen \/ 6);\n-            segments -= segments % blockSize;\n-            int len = 0;\n-            int i = 0;\n-            do {\n-                len += op.update(in, inOfs + len, segments, out,outOfs + len);\n-            } while (++i < 5);\n-\n-            len += op.update(in, inOfs + len, inLen - len, out, outOfs + len);\n-            return len;\n-        }\n-\n-\n-        \/**\n-         * This segments large data into smaller chunks so hotspot will start\n-         * using GCTR and GHASH intrinsics sooner.  This is a problem for app\n-         * and perf tests that only use large input sizes.\n-         *\/\n-        int throttleData(GCM op, ByteBuffer src, ByteBuffer dst) {\n-            int inLen = src.limit();\n-            int segments = (src.remaining() \/ 6);\n-            segments -= segments % blockSize;\n-            int i = 0, resultLen = 0;\n-            do {\n-                src.limit(src.position() + segments);\n-                resultLen += op.update(src, dst);\n-            } while (++i < 5);\n-\n-            src.limit(inLen);\n-            \/\/ If there is still at least a blockSize left\n-            if (src.remaining() > blockSize) {\n-                resultLen += op.update(src, dst);\n-            }\n-\n-            return resultLen;\n-        }\n-\n@@ -903,1 +961,5 @@\n-                    if (src.position() + src.arrayOffset() >=\n+                    \/\/ If during encryption and the input offset is behind or\n+                    \/\/ the same as the output offset, the same buffer can be\n+                    \/\/ used.  But during decryption always create a new\n+                    \/\/ buffer in case of a bad auth tag.\n+                    if (encryption && src.position() + src.arrayOffset() >=\n@@ -926,1 +988,4 @@\n-         * Overlap detection for data using byte array.\n+         * This is used for both overlap detection for the data or  decryption\n+         * during in-place crypto, so to not overwrite the input if the authtag\n+         * is invalid.\n+         *\n@@ -931,1 +996,1 @@\n-            if (in == out && inOfs < outOfs) {\n+            if (in == out && (!encryption || inOfs < outOfs)) {\n@@ -972,1 +1037,0 @@\n-        GCTRGHASH gctrghash;\n@@ -976,1 +1040,1 @@\n-            gctrghash = new GCTRGHASH(gctrPAndC, ghashAllToS);\n+            op = new EncryptOp(gctr, ghash);\n@@ -1037,1 +1101,1 @@\n-                    len = gctrghash.update(block, 0, blockSize, out, outOfs);\n+                    len = op.update(block, 0, blockSize, out, outOfs);\n@@ -1046,0 +1110,9 @@\n+            if (inLen >= PARALLEL_LEN) {\n+                int r = GaloisCounterMode.implGCMCrypt(in, inOfs, inLen, out,\n+                    outOfs, out, outOfs, gctr, ghash);\n+                len += r;\n+                inOfs += r;\n+                inLen -= r;\n+                outOfs += r;\n+            }\n+\n@@ -1047,1 +1120,4 @@\n-                len += gctrghash.update(in, inOfs, inLen, out, outOfs);\n+                int r = op.update(in, inOfs, inLen, out, outOfs);\n+                len += r;\n+                inOfs += r;\n+                inLen -= r;\n@@ -1092,2 +1168,3 @@\n-                    len += cryptBlocks(\n-                            ByteBuffer.wrap(block, 0, blockSize), dst);\n+                    len += op.update(ByteBuffer.wrap(block, 0, blockSize),\n+                            dst);\n+                    processed += len;\n@@ -1100,1 +1177,1 @@\n-                len += cryptBlocks(src, dst);\n+                len += implGCMCrypt(op, src, dst);\n@@ -1153,2 +1230,1 @@\n-                    r = gctrghash.update(block, 0, blockSize, out,\n-                        outOfs);\n+                    r = op.update(block, 0, blockSize, out, outOfs);\n@@ -1159,1 +1235,1 @@\n-                    \/\/ Need to consume all the ibuffer here to prepare for doFinal()\n+                    \/\/ Need to consume the ibuffer here to prepare for doFinal()\n@@ -1170,10 +1246,1 @@\n-            if (inLen > TRIGGERLEN) {\n-                int r = throttleData(gctrghash, in, inOfs, inLen, out, outOfs);\n-                inOfs += r;\n-                inLen -= r;\n-                outOfs += r;\n-                resultLen += r;\n-                processed += r;\n-            }\n-\n-            processed += gctrghash.doFinal(in, inOfs, inLen, out, outOfs);\n+            processed += op.doFinal(in, inOfs, inLen, out, outOfs);\n@@ -1184,2 +1251,2 @@\n-            ghashAllToS.update(block);\n-            block = ghashAllToS.digest();\n+            ghash.update(block);\n+            block = ghash.digest();\n@@ -1217,1 +1284,1 @@\n-                processed += doLastBlock(gctrghash,\n+                processed += doLastBlock(op,\n@@ -1228,2 +1295,2 @@\n-            ghashAllToS.update(block);\n-            block = ghashAllToS.digest();\n+            ghash.update(block);\n+            block = ghash.digest();\n@@ -1238,12 +1305,0 @@\n-\n-        \/\/ Handler method for encrypting blocks\n-        int cryptBlocks(ByteBuffer src, ByteBuffer dst) {\n-            int len;\n-            if (src.remaining() > TRIGGERLEN) {\n-                len = throttleData(gctrghash, src, dst);\n-            } else {\n-                len = gctrghash.update(src, dst);\n-            }\n-            processed += len;\n-            return len;\n-        }\n@@ -1360,1 +1415,0 @@\n-            GHASH save = null;\n@@ -1374,1 +1428,2 @@\n-                save = ghashAllToS.clone();\n+                throw new ShortBufferException(\"Output buffer too small, must\" +\n+                    \"be at least \" + (len - tagLenBytes) + \" bytes long\");\n@@ -1379,1 +1434,0 @@\n-\n@@ -1381,4 +1435,6 @@\n-            byte[] block = getLengthBlock(sizeOfAAD,\n-                decryptBlocks(ghashAllToS, in, inOfs, inLen, null, 0));\n-            ghashAllToS.update(block);\n-            block = ghashAllToS.digest();\n+            out = overlapDetection(in, inOfs, out, outOfs);\n+\n+            len = decryptBlocks(new DecryptOp(gctr, ghash), in, inOfs, inLen, out, outOfs);\n+            byte[] block = getLengthBlock(sizeOfAAD, len);\n+            ghash.update(block);\n+            block = ghash.digest();\n@@ -1395,0 +1451,2 @@\n+                \/\/ Clear output data\n+                Arrays.fill(out, outOfs, outOfs + len, (byte) 0);\n@@ -1398,8 +1456,0 @@\n-            if (save != null) {\n-                ghashAllToS = save;\n-                throw new ShortBufferException(\"Output buffer too small, must\" +\n-                    \"be at least \" + (len - tagLenBytes) + \" bytes long\");\n-            }\n-\n-            out = overlapDetection(in, inOfs, out, outOfs);\n-            len = decryptBlocks(gctrPAndC, in, inOfs, inLen, out, outOfs);\n@@ -1418,1 +1468,0 @@\n-            GHASH save = null;\n@@ -1439,1 +1488,2 @@\n-                save = ghashAllToS.clone();\n+                throw new ShortBufferException(\"Output buffer too small, must\" +\n+                    \"be at least \" + (len - tagLenBytes) + \" bytes long\");\n@@ -1468,1 +1518,2 @@\n-\n+            dst = overlapDetection(src, dst);\n+            dst.mark();\n@@ -1471,1 +1522,2 @@\n-            doLastBlock(ghashAllToS, buffer, ct, null);\n+            processed +=\n+                doLastBlock(new DecryptOp(gctr, ghash), buffer, ct, dst);\n@@ -1474,2 +1526,2 @@\n-            ghashAllToS.update(block);\n-            block = ghashAllToS.digest();\n+            ghash.update(block);\n+            block = ghash.digest();\n@@ -1486,0 +1538,9 @@\n+                \/\/ Clear output data\n+                dst.reset();\n+                if (dst.hasArray()) {\n+                    int ofs = dst.arrayOffset() + dst.position();\n+                    Arrays.fill(dst.array(), ofs , ofs + processed, (byte)0);\n+                } else {\n+                    Unsafe.getUnsafe().setMemory(((DirectBuffer)dst).address(),\n+                        processed + dst.position(), (byte)0);\n+                }\n@@ -1489,18 +1550,0 @@\n-            if (save != null) {\n-                ghashAllToS = save;\n-                throw new ShortBufferException(\"Output buffer too small, must\" +\n-                    \" be at least \" + len + \" bytes long\");\n-            }\n-\n-            \/\/ Prepare for decryption\n-            if (buffer != null) {\n-                buffer.flip();\n-            }\n-            ct.reset();\n-            processed = 0;\n-            \/\/ Check for overlap in the bytebuffers\n-            dst = overlapDetection(src, dst);\n-\n-            \/\/ Decrypt the all the input data and put it into dst\n-            doLastBlock(gctrPAndC, buffer, ct, dst);\n-            restoreDst(dst);\n@@ -1508,3 +1551,2 @@\n-            if (ibuffer != null) {\n-                ibuffer.reset();\n-            }\n+            engine = null;\n+            restoreDst(dst);\n@@ -1520,1 +1562,1 @@\n-        int decryptBlocks(GCM op, byte[] in, int inOfs, int inLen,\n+        int decryptBlocks(GCMOperation op, byte[] in, int inOfs, int inLen,\n@@ -1525,0 +1567,1 @@\n+            int resultLen;\n@@ -1541,3 +1584,4 @@\n-                if (bLen >= blockSize) {\n-                    len += op.update(buffer, 0, bLen, out, outOfs);\n-                    outOfs += len; \/\/ noop for ghash\n+                if (bLen >= PARALLEL_LEN) {\n+                    len = GaloisCounterMode.implGCMCrypt(buffer, 0, bLen,\n+                        buffer, 0, out, outOfs, gctr, ghash);\n+                    outOfs += len;\n@@ -1548,1 +1592,0 @@\n-                \/\/ merge the remaining ibuffer with the 'in'\n@@ -1550,0 +1593,8 @@\n+                if (bufRemainder >= blockSize) {\n+                    resultLen = op.update(buffer, len, bufRemainder, out, outOfs);\n+                    len += resultLen;\n+                    outOfs += resultLen;\n+                    bufRemainder -= resultLen;\n+                }\n+\n+                \/\/ merge the remaining ibuffer with the 'in'\n@@ -1560,1 +1611,1 @@\n-                        int resultLen = op.update(block, 0, blockSize,\n+                        resultLen = op.update(block, 0, blockSize,\n@@ -1562,1 +1613,1 @@\n-                        outOfs += resultLen; \/\/ noop for ghash\n+                        outOfs += resultLen;\n@@ -1573,8 +1624,8 @@\n-            if (inLen > TRIGGERLEN) {\n-                int l = throttleData(op, in, inOfs, inLen, out, outOfs);\n-                inOfs += l;\n-                inLen -= l;\n-                outOfs += l; \/\/ noop for ghash\n-                len += l;\n-            }\n-            return len + op.doFinal(in, inOfs, inLen, out, outOfs);\n+            resultLen = GaloisCounterMode.implGCMCrypt(in, inOfs, inLen, in,\n+                inOfs, out, outOfs, gctr, ghash);\n+            inOfs += resultLen;\n+            outOfs += resultLen;\n+            inLen -= resultLen;\n+            ghash.doFinal(in, inOfs, inLen);\n+            return len + resultLen +\n+                    gctr.doFinal(in, inOfs, inLen, out, outOfs);\n@@ -1612,1 +1663,1 @@\n-    static final class GCTRGHASH implements GCM {\n+    static final class EncryptOp implements GCMOperation {\n@@ -1616,1 +1667,1 @@\n-        GCTRGHASH(GCTR c, GHASH g) {\n+        EncryptOp(GCTR c, GHASH g) {\n@@ -1648,4 +1699,9 @@\n-        public int doFinal(byte[] in, int inOfs, int inLen, byte[] out, int outOfs) {\n-            int len = gctr.doFinal(in, inOfs, inLen, out, outOfs);\n-            ghash.doFinal(out, outOfs, len);\n-            return len;\n+        public int doFinal(byte[] in, int inOfs, int inLen, byte[] out,\n+                           int outOfs) {\n+            int len = implGCMCrypt(in, inOfs, inLen, out, outOfs, out, outOfs,\n+                    gctr, ghash);\n+            inLen -= len;\n+            outOfs += len;\n+            int flen = gctr.doFinal(in, inOfs + len, inLen, out, outOfs);\n+            ghash.doFinal(out, outOfs, inLen);\n+            return len + flen;\n@@ -1663,0 +1719,65 @@\n+\n+    \/**\n+     * This class is for decryption when both GCTR and GHASH\n+     * can operation in parallel.\n+     *\/\n+    static final class DecryptOp implements GCMOperation {\n+        GCTR gctr;\n+        GHASH ghash;\n+\n+        DecryptOp(GCTR c, GHASH g) {\n+            gctr = c;\n+            ghash = g;\n+        }\n+\n+        @Override\n+        public int update(byte[] in, int inOfs, int inLen, byte[] out,\n+            int outOfs) {\n+            ghash.update(in, inOfs, inLen);\n+            return gctr.update(in, inOfs, inLen, out, outOfs);\n+        }\n+\n+        @Override\n+        public int update(byte[] in, int inOfs, int inLen, ByteBuffer dst) {\n+            ghash.update(in, inOfs, inLen);\n+            return gctr.update(in, inOfs, inLen, dst);\n+        }\n+\n+        @Override\n+        public int update(ByteBuffer src, ByteBuffer dst) {\n+            src.mark();\n+            ghash.update(src, src.remaining());\n+            src.reset();\n+            return gctr.update(src, dst);\n+        }\n+\n+        @Override\n+        public int doFinal(byte[] in, int inOfs, int inLen, byte[] out,\n+                           int outOfs) {\n+            int len = implGCMCrypt(in, inOfs, inLen, in, inOfs, out, outOfs,\n+                    gctr, ghash);\n+            ghash.doFinal(in, inOfs + len, inLen - len);\n+            return len + gctr.doFinal(in, inOfs + len, inLen - len, out,\n+                    outOfs + len);\n+        }\n+\n+        @Override\n+        public int doFinal(ByteBuffer src, ByteBuffer dst) {\n+            src.mark();\n+            ghash.doFinal(src, src.remaining());\n+            src.reset();\n+            return gctr.doFinal(src, dst);\n+        }\n+    }\n+\n+    \/**\n+     * Interface to organize encryption and decryption operations in the\n+     * proper order for GHASH and GCTR.\n+     *\/\n+    public interface GCMOperation {\n+        int update(byte[] in, int inOfs, int inLen, byte[] out, int outOfs);\n+        int update(byte[] in, int inOfs, int inLen, ByteBuffer dst);\n+        int update(ByteBuffer src, ByteBuffer dst);\n+        int doFinal(byte[] in, int inOfs, int inLen, byte[] out, int outOfs);\n+        int doFinal(ByteBuffer src, ByteBuffer dst);\n+    }\n","filename":"src\/java.base\/share\/classes\/com\/sun\/crypto\/provider\/GaloisCounterMode.java","additions":286,"deletions":165,"binary":false,"changes":451,"status":"modified"},{"patch":"@@ -101,0 +101,21 @@\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DmsgSize=2054\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DencInputOffset=1 -DmsgSize=2054\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DencOutputOffset=1 -DmsgSize=2054\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DdecOutputOffset=1 -DmsgSize=2054\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DencInputOffset=1 -DencOutputOffset=1 -DmsgSize=2054\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DencInputOffset=1 -DencOutputOffset=1 -DdecOutputOffset=1 -DmsgSize=2054\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n+ * @run main\/othervm\/timeout=600 -Xbatch -DcheckOutput=true -Dmode=GCM -DencInputOffset=1 -DencOutputOffset=1 -DdecOutputOffset=1 -DpaddingStr=NoPadding -DmsgSize=2048\n+ *      -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *      compiler.codegen.aes.TestAESMain\n","filename":"test\/hotspot\/jtreg\/compiler\/codegen\/aes\/TestAESMain.java","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"}]}