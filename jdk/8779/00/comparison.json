{"files":[{"patch":"@@ -47,1 +47,1 @@\n-    cds compiler1 compiler2 dtrace epsilongc g1gc jfr jni-check \\\n+    cds compiler1 compiler2 dtrace epsilongc g1gc hardlse jfr jni-check \\\n@@ -64,0 +64,1 @@\n+m4_define(jvm_feature_desc_hardlse, [use lse atomics instructions])\n@@ -441,0 +442,2 @@\n+  # Filter out hardlse feature by default\n+  JVM_FEATURES_PLATFORM_FILTER=\"$JVM_FEATURES_PLATFORM_FILTER hardlse\"\n","filename":"make\/autoconf\/jvm-features.m4","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -169,0 +169,8 @@\n+ifeq ($(call check-jvm-feature, hardlse), true)\n+  JVM_CFLAGS_FEATURES += -DHARD_LSE=1\n+  JVM_EXCLUDE_FILES += atomic_linux_aarch64.S\n+else\n+  JVM_EXCLUDE_FILES += atomic_linux_aarch64_lse.S\n+endif\n+\n+\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -6419,0 +6419,4 @@\n+\/\/ Compile time support for LSE is enabled,\n+\/\/ no needs to rewrite atomic stubs\n+#ifndef HARD_LSE\n+\n@@ -6613,0 +6617,1 @@\n+#endif \/\/ HARD_LSE\n@@ -7993,0 +7998,1 @@\n+#ifndef HARD_LSE\n@@ -7996,0 +8002,1 @@\n+#endif \/\/ HARD_LSE\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -253,0 +253,5 @@\n+#ifdef HARD_LSE\n+  \/\/ Compile time LSE support is enabled\n+  \/\/ Forcibly enable runtime LSE support\n+  FLAG_SET_DEFAULT(UseLSE, true);\n+#else\n@@ -262,0 +267,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,169 @@\n+\/\/ Copyright (c) 2021, 2022, Red Hat Inc. All rights reserved.\n+\/\/ DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+\/\/\n+\/\/ This code is free software; you can redistribute it and\/or modify it\n+\/\/ under the terms of the GNU General Public License version 2 only, as\n+\/\/ published by the Free Software Foundation.\n+\/\/\n+\/\/ This code is distributed in the hope that it will be useful, but WITHOUT\n+\/\/ ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+\/\/ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+\/\/ version 2 for more details (a copy is included in the LICENSE file that\n+\/\/ accompanied this code).\n+\/\/\n+\/\/ You should have received a copy of the GNU General Public License version\n+\/\/ 2 along with this work; if not, write to the Free Software Foundation,\n+\/\/ Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+\/\/\n+\/\/ Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+\/\/ or visit www.oracle.com if you need additional information or have any\n+\/\/ questions.\n+\n+\n+\n+        .text\n+\n+        .globl aarch64_atomic_fetch_add_8_default_impl\n+        .align 5\n+aarch64_atomic_fetch_add_8_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      ldaddal x1, x2, [x0]\n+        dmb     ish\n+        mov     x0, x2\n+        ret\n+\n+        .globl aarch64_atomic_fetch_add_4_default_impl\n+        .align 5\n+aarch64_atomic_fetch_add_4_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      ldaddal w1, w2, [x0]\n+        dmb     ish\n+        mov     w0, w2\n+        ret\n+\n+        .global aarch64_atomic_fetch_add_8_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_fetch_add_8_relaxed_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      ldadd   x1, x2, [x0]\n+        mov     x0, x2\n+        ret\n+\n+        .global aarch64_atomic_fetch_add_4_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_fetch_add_4_relaxed_default_impl:\n+        .globl aarch64_atomic_xchg_4_default_impl\n+        .align 5\n+        prfm    pstl1strm, [x0]\n+0:      ldadd   w1, w2, [x0]\n+        mov     w0, w2\n+        ret\n+\n+aarch64_atomic_xchg_4_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      swpal   w1, w2, [x0]\n+        dmb     ish\n+        mov     w0, w2\n+        ret\n+\n+        .globl aarch64_atomic_xchg_8_default_impl\n+        .align 5\n+aarch64_atomic_xchg_8_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      swpal   x1, x2, [x0]\n+        dmb     ish\n+        mov     x0, x2\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_1_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_1_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casalb  w3, w2, [x0]\n+        dmb     ish\n+        mov     w0, w3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_4_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_4_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casal   w3, w2, [x0]\n+        dmb     ish\n+        mov     w0, w3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_8_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_8_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casal   x3, x2, [x0]\n+        dmb     ish\n+        mov     x0, x3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_4_release_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_4_release_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casl    w3, w2, [x0]\n+        mov     w0, w3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_8_release_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_8_release_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casl    x3, x2, [x0]\n+        mov     x0, x3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_4_seq_cst_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_4_seq_cst_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casal   w3, w2, [x0]\n+        mov     w0, w3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_8_seq_cst_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_8_seq_cst_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casal   x3, x2, [x0]\n+        mov     x0, x3\n+        ret\n+\n+.globl aarch64_atomic_cmpxchg_1_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_1_relaxed_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        casb    w3, w2, [x0]\n+        mov     w0, w3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_4_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_4_relaxed_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        cas     w3, w2, [x0]\n+        mov     w0, w3\n+        ret\n+\n+        .globl aarch64_atomic_cmpxchg_8_relaxed_default_impl\n+        .align 5\n+aarch64_atomic_cmpxchg_8_relaxed_default_impl:\n+        prfm    pstl1strm, [x0]\n+0:      mov     x3, x1\n+        cas     x3, x2, [x0]\n+        mov     x0, x3\n+        ret\n","filename":"src\/hotspot\/os_cpu\/linux_aarch64\/atomic_linux_aarch64_lse.S","additions":169,"deletions":0,"binary":false,"changes":169,"status":"added"}]}