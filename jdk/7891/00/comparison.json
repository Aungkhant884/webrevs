{"files":[{"patch":"@@ -53,1 +53,1 @@\n-    G1SegmentedArrayAllocOptions(align_up(slot_size, SlotAlignment), initial_num_slots, max_num_slots, SlotAlignment) {\n+    G1SegmentedArrayAllocOptions(mtGCCardSet, slot_size, initial_num_slots, max_num_slots, SlotAlignment) {\n@@ -61,1 +61,1 @@\n-typedef G1SegmentedArraySegment<mtGCCardSet> G1CardSetSegment;\n+using G1CardSetSegment = G1SegmentedArraySegment;\n@@ -63,1 +63,1 @@\n-typedef G1SegmentedArrayFreeList<mtGCCardSet> G1CardSetFreeList;\n+using G1CardSetFreeList = G1SegmentedArrayFreeList;\n@@ -70,1 +70,1 @@\n-  G1SegmentedArray<mtGCCardSet> _segmented_array;\n+  G1SegmentedArray _segmented_array;\n@@ -95,1 +95,1 @@\n-typedef G1SegmentedArrayFreePool<mtGCCardSet> G1CardSetFreePool;\n+using G1CardSetFreePool = G1SegmentedArrayFreePool;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CardSetMemory.hpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,247 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+\n+#include \"gc\/g1\/g1SegmentedArray.inline.hpp\"\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/globalCounter.inline.hpp\"\n+\n+G1SegmentedArraySegment::G1SegmentedArraySegment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next, MEMFLAGS flag) :\n+  _slot_size(slot_size),\n+  _num_slots(num_slots),\n+  _mem_flag(flag),\n+  _next(next),\n+  _next_allocate(0) {\n+  _bottom = ((char*) this) + header_size();\n+}\n+\n+G1SegmentedArraySegment* G1SegmentedArraySegment::create_segment(uint slot_size,\n+                                                                 uint num_slots,\n+                                                                 G1SegmentedArraySegment* next,\n+                                                                 MEMFLAGS mem_flag) {\n+  size_t block_size = size_in_bytes(slot_size, num_slots);\n+  char* alloc_block = NEW_C_HEAP_ARRAY(char, block_size, mem_flag);\n+  return new (alloc_block) G1SegmentedArraySegment(slot_size, num_slots, next, mem_flag);\n+}\n+\n+void G1SegmentedArraySegment::delete_segment(G1SegmentedArraySegment* segment) {\n+  segment->~G1SegmentedArraySegment();\n+  FREE_C_HEAP_ARRAY(_mem_flag, segment);\n+}\n+\n+void G1SegmentedArrayFreeList::bulk_add(G1SegmentedArraySegment& first,\n+                                        G1SegmentedArraySegment& last,\n+                                        size_t num,\n+                                        size_t mem_size) {\n+  _list.prepend(first, last);\n+  Atomic::add(&_num_segments, num, memory_order_relaxed);\n+  Atomic::add(&_mem_size, mem_size, memory_order_relaxed);\n+}\n+\n+void G1SegmentedArrayFreeList::print_on(outputStream* out, const char* prefix) {\n+  out->print_cr(\"%s: segments %zu size %zu\",\n+                prefix, Atomic::load(&_num_segments), Atomic::load(&_mem_size));\n+}\n+\n+G1SegmentedArraySegment* G1SegmentedArrayFreeList::get_all(size_t& num_segments,\n+                                                           size_t& mem_size) {\n+  GlobalCounter::CriticalSection cs(Thread::current());\n+\n+  G1SegmentedArraySegment* result = _list.pop_all();\n+  num_segments = Atomic::load(&_num_segments);\n+  mem_size = Atomic::load(&_mem_size);\n+\n+  if (result != nullptr) {\n+    Atomic::sub(&_num_segments, num_segments, memory_order_relaxed);\n+    Atomic::sub(&_mem_size, mem_size, memory_order_relaxed);\n+  }\n+  return result;\n+}\n+\n+void G1SegmentedArrayFreeList::free_all() {\n+  size_t num_freed = 0;\n+  size_t mem_size_freed = 0;\n+  G1SegmentedArraySegment* cur;\n+\n+  while ((cur = _list.pop()) != nullptr) {\n+    mem_size_freed += cur->mem_size();\n+    num_freed++;\n+    G1SegmentedArraySegment::delete_segment(cur);\n+  }\n+\n+  Atomic::sub(&_num_segments, num_freed, memory_order_relaxed);\n+  Atomic::sub(&_mem_size, mem_size_freed, memory_order_relaxed);\n+}\n+\n+G1SegmentedArraySegment* G1SegmentedArray::create_new_segment(G1SegmentedArraySegment* const prev) {\n+  \/\/ Take an existing segment if available.\n+  G1SegmentedArraySegment* next = _free_segment_list->get();\n+  if (next == nullptr) {\n+    uint prev_num_slots = (prev != nullptr) ? prev->num_slots() : 0;\n+    uint num_slots = _alloc_options->next_num_slots(prev_num_slots);\n+\n+    next = G1SegmentedArraySegment::create_segment(slot_size(), num_slots, prev, _alloc_options->mem_flag());\n+    \/\/ next = new G1SegmentedArraySegment(slot_size(), num_slots, prev);\n+  } else {\n+    assert(slot_size() == next->slot_size() ,\n+           \"Mismatch %d != %d\", slot_size(), next->slot_size());\n+    next->reset(prev);\n+  }\n+\n+  \/\/ Install it as current allocation segment.\n+  G1SegmentedArraySegment* old = Atomic::cmpxchg(&_first, prev, next);\n+  if (old != prev) {\n+    \/\/ Somebody else installed the segment, use that one.\n+    G1SegmentedArraySegment::delete_segment(next);\n+    return old;\n+  } else {\n+    \/\/ Did we install the first segment in the list? If so, this is also the last.\n+    if (prev == nullptr) {\n+      _last = next;\n+    }\n+    \/\/ Successfully installed the segment into the list.\n+    Atomic::inc(&_num_segments, memory_order_relaxed);\n+    Atomic::add(&_mem_size, next->mem_size(), memory_order_relaxed);\n+    Atomic::add(&_num_available_slots, next->num_slots(), memory_order_relaxed);\n+    return next;\n+  }\n+}\n+\n+G1SegmentedArray::G1SegmentedArray(const G1SegmentedArrayAllocOptions* alloc_options,\n+                                   G1SegmentedArrayFreeList* free_segment_list) :\n+  _alloc_options(alloc_options),\n+  _first(nullptr),\n+  _last(nullptr),\n+  _num_segments(0),\n+  _mem_size(0),\n+  _free_segment_list(free_segment_list),\n+  _num_available_slots(0),\n+  _num_allocated_slots(0) {\n+  assert(_free_segment_list != nullptr, \"precondition!\");\n+}\n+\n+G1SegmentedArray::~G1SegmentedArray() {\n+  drop_all();\n+}\n+\n+uint G1SegmentedArray::slot_size() const {\n+  return _alloc_options->slot_size();\n+}\n+\n+void G1SegmentedArray::drop_all() {\n+  G1SegmentedArraySegment* cur = Atomic::load_acquire(&_first);\n+\n+  if (cur != nullptr) {\n+    assert(_last != nullptr, \"If there is at least one segment, there must be a last one.\");\n+\n+    G1SegmentedArraySegment* first = cur;\n+#ifdef ASSERT\n+    \/\/ Check list consistency.\n+    G1SegmentedArraySegment* last = cur;\n+    uint num_segments = 0;\n+    size_t mem_size = 0;\n+    while (cur != nullptr) {\n+      mem_size += cur->mem_size();\n+      num_segments++;\n+\n+      G1SegmentedArraySegment* next = cur->next();\n+      last = cur;\n+      cur = next;\n+    }\n+#endif\n+    assert(num_segments == _num_segments, \"Segment count inconsistent %u %u\", num_segments, _num_segments);\n+    assert(mem_size == _mem_size, \"Memory size inconsistent\");\n+    assert(last == _last, \"Inconsistent last segment\");\n+\n+    _free_segment_list->bulk_add(*first, *_last, _num_segments, _mem_size);\n+  }\n+\n+  _first = nullptr;\n+  _last = nullptr;\n+  _num_segments = 0;\n+  _mem_size = 0;\n+  _num_available_slots = 0;\n+  _num_allocated_slots = 0;\n+}\n+\n+void* G1SegmentedArray::allocate() {\n+  assert(slot_size() > 0, \"instance size not set.\");\n+\n+  G1SegmentedArraySegment* cur = Atomic::load_acquire(&_first);\n+  if (cur == nullptr) {\n+    cur = create_new_segment(cur);\n+  }\n+\n+  while (true) {\n+    void* slot = cur->get_new_slot();\n+    if (slot != nullptr) {\n+      Atomic::inc(&_num_allocated_slots, memory_order_relaxed);\n+      guarantee(is_aligned(slot, _alloc_options->slot_alignment()),\n+                \"result \" PTR_FORMAT \" not aligned at %u\", p2i(slot), _alloc_options->slot_alignment());\n+      return slot;\n+    }\n+    \/\/ The segment is full. Next round.\n+    assert(cur->is_full(), \"must be\");\n+    cur = create_new_segment(cur);\n+  }\n+}\n+\n+uint G1SegmentedArray::num_segments() const {\n+  return Atomic::load(&_num_segments);\n+}\n+\n+#ifdef ASSERT\n+class LengthClosure {\n+  uint _total;\n+public:\n+  LengthClosure() : _total(0) {}\n+  void do_segment(G1SegmentedArraySegment* segment, uint limit) {\n+    _total += limit;\n+  }\n+  uint length() const {\n+    return _total;\n+  }\n+};\n+\n+uint G1SegmentedArray::calculate_length() const {\n+  LengthClosure closure;\n+  iterate_segments(closure);\n+  return closure.length();\n+}\n+#endif\n+\n+template <typename SegmentClosure>\n+void G1SegmentedArray::iterate_segments(SegmentClosure& closure) const {\n+  G1SegmentedArraySegment* cur = Atomic::load_acquire(&_first);\n+\n+  assert((cur != nullptr) == (_last != nullptr),\n+         \"If there is at least one segment, there must be a last one\");\n+\n+  while (cur != nullptr) {\n+    closure.do_segment(cur, cur->length());\n+    cur = cur->next();\n+  }\n+}\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.cpp","additions":247,"deletions":0,"binary":false,"changes":247,"status":"added"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co. Ltd. All rights reserved.\n@@ -31,0 +31,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -35,2 +36,1 @@\n-template<MEMFLAGS flag>\n-class G1SegmentedArraySegment : public CHeapObj<flag> {\n+class G1SegmentedArraySegment {\n@@ -39,1 +39,1 @@\n-\n+  const MEMFLAGS _mem_flag;\n@@ -41,3 +41,0 @@\n-\n-  char* _segment;  \/\/ Actual data.\n-\n@@ -49,3 +46,11 @@\n-public:\n-  G1SegmentedArraySegment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next);\n-  ~G1SegmentedArraySegment();\n+  char* _bottom;  \/\/ Actual data.\n+  \/\/ Do not add class member variables beyond this point\n+\n+  static size_t header_size() { return align_up(offset_of(G1SegmentedArraySegment, _bottom), DEFAULT_CACHE_LINE_SIZE); }\n+\n+  static size_t payload_size(uint slot_size, uint num_slots) {\n+    \/\/ The cast (size_t) is required to guard against overflow wrap around.\n+    return (size_t)slot_size * num_slots;\n+  }\n+\n+  size_t payload_size() const { return payload_size(_slot_size, _num_slots); }\n@@ -53,0 +58,5 @@\n+  NONCOPYABLE(G1SegmentedArraySegment);\n+\n+  G1SegmentedArraySegment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next, MEMFLAGS flag);\n+  ~G1SegmentedArraySegment() = default;\n+public:\n@@ -70,1 +80,1 @@\n-    memset((void*)_segment, 0, (size_t)_num_slots * _slot_size);\n+    memset((void*)_bottom, 0, payload_size());\n@@ -75,1 +85,1 @@\n-  size_t mem_size() const { return sizeof(*this) + (size_t)_num_slots * _slot_size; }\n+  size_t mem_size() const { return header_size() + payload_size(); }\n@@ -83,0 +93,7 @@\n+  static size_t size_in_bytes(uint slot_size, uint num_slots) {\n+    return header_size() + payload_size(slot_size, num_slots);\n+  }\n+\n+  static G1SegmentedArraySegment* create_segment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next, MEMFLAGS mem_flag);\n+  static void delete_segment(G1SegmentedArraySegment* segment);\n+\n@@ -85,1 +102,1 @@\n-    ::memcpy(dest, _segment, length() * _slot_size);\n+    ::memcpy(dest, _bottom, length() * _slot_size);\n@@ -95,1 +112,0 @@\n-template<MEMFLAGS flag>\n@@ -97,1 +113,1 @@\n-  static G1SegmentedArraySegment<flag>* volatile* next_ptr(G1SegmentedArraySegment<flag>& segment) {\n+  static G1SegmentedArraySegment* volatile* next_ptr(G1SegmentedArraySegment& segment) {\n@@ -100,1 +116,1 @@\n-  typedef LockFreeStack<G1SegmentedArraySegment<flag>, &G1SegmentedArrayFreeList::next_ptr> SegmentStack;\n+  typedef LockFreeStack<G1SegmentedArraySegment, &G1SegmentedArrayFreeList::next_ptr> SegmentStack;\n@@ -111,1 +127,1 @@\n-  void bulk_add(G1SegmentedArraySegment<flag>& first, G1SegmentedArraySegment<flag>& last, size_t num, size_t mem_size);\n+  void bulk_add(G1SegmentedArraySegment& first, G1SegmentedArraySegment& last, size_t num, size_t mem_size);\n@@ -113,2 +129,2 @@\n-  G1SegmentedArraySegment<flag>* get();\n-  G1SegmentedArraySegment<flag>* get_all(size_t& num_segments, size_t& mem_size);\n+  G1SegmentedArraySegment* get();\n+  G1SegmentedArraySegment* get_all(size_t& num_segments, size_t& mem_size);\n@@ -129,0 +145,1 @@\n+  const MEMFLAGS _mem_flag;\n@@ -136,2 +153,3 @@\n-  G1SegmentedArrayAllocOptions(uint slot_size, uint initial_num_slots, uint max_num_slots, uint alignment) :\n-    _slot_size(slot_size),\n+  G1SegmentedArrayAllocOptions(MEMFLAGS mem_flag, uint slot_size, uint initial_num_slots, uint max_num_slots, uint alignment) :\n+    _mem_flag(mem_flag),\n+    _slot_size(align_up(slot_size, alignment)),\n@@ -154,0 +172,2 @@\n+\n+  MEMFLAGS mem_flag() const {return _mem_flag; }\n@@ -184,1 +204,1 @@\n-template <MEMFLAGS flag>\n+\n@@ -190,4 +210,4 @@\n-  G1SegmentedArraySegment<flag>* volatile _first;       \/\/ The (start of the) list of all segments.\n-  G1SegmentedArraySegment<flag>* _last;                 \/\/ The last segment of the list of all segments.\n-  volatile uint _num_segments;                          \/\/ Number of assigned segments to this allocator.\n-  volatile size_t _mem_size;                            \/\/ Memory used by all segments.\n+  G1SegmentedArraySegment* volatile _first;       \/\/ The (start of the) list of all segments.\n+  G1SegmentedArraySegment* _last;                 \/\/ The last segment of the list of all segments.\n+  volatile uint _num_segments;                    \/\/ Number of assigned segments to this allocator.\n+  volatile size_t _mem_size;                      \/\/ Memory used by all segments.\n@@ -195,2 +215,2 @@\n-  G1SegmentedArrayFreeList<flag>* _free_segment_list;   \/\/ The global free segment list to\n-                                                        \/\/ preferentially get new segments from.\n+  G1SegmentedArrayFreeList* _free_segment_list;   \/\/ The global free segment list to preferentially\n+                                                  \/\/ get new segments from.\n@@ -202,1 +222,1 @@\n-  inline G1SegmentedArraySegment<flag>* create_new_segment(G1SegmentedArraySegment<flag>* const prev);\n+  inline G1SegmentedArraySegment* create_new_segment(G1SegmentedArraySegment* const prev);\n@@ -207,1 +227,1 @@\n-  const G1SegmentedArraySegment<flag>* first_array_segment() const { return Atomic::load(&_first); }\n+  const G1SegmentedArraySegment* first_array_segment() const { return Atomic::load(&_first); }\n@@ -216,1 +236,1 @@\n-  inline uint slot_size() const;\n+  uint slot_size() const;\n@@ -219,1 +239,1 @@\n-                   G1SegmentedArrayFreeList<flag>* free_segment_list);\n+                   G1SegmentedArrayFreeList* free_segment_list);\n@@ -231,1 +251,1 @@\n-  inline uint num_segments() const;\n+  uint num_segments() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.hpp","additions":54,"deletions":34,"binary":false,"changes":88,"status":"modified"},{"patch":"@@ -2,2 +2,2 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n- * Copyright (c) 2021, Huawei Technologies Co. Ltd. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Huawei Technologies Co. Ltd. All rights reserved.\n@@ -33,14 +33,1 @@\n-template<MEMFLAGS flag>\n-G1SegmentedArraySegment<flag>::G1SegmentedArraySegment(uint slot_size, uint num_slots, G1SegmentedArraySegment* next) :\n-  _slot_size(slot_size), _num_slots(num_slots), _next(next), _next_allocate(0) {\n-\n-  _segment = NEW_C_HEAP_ARRAY(char, (size_t)_num_slots * slot_size, flag);\n-}\n-\n-template<MEMFLAGS flag>\n-G1SegmentedArraySegment<flag>::~G1SegmentedArraySegment() {\n-  FREE_C_HEAP_ARRAY(flag, _segment);\n-}\n-\n-template<MEMFLAGS flag>\n-void* G1SegmentedArraySegment<flag>::get_new_slot() {\n+inline void* G1SegmentedArraySegment::get_new_slot() {\n@@ -54,1 +41,1 @@\n-  void* r = _segment + (uint)result * _slot_size;\n+  void* r = _bottom + (size_t)result * _slot_size;\n@@ -58,18 +45,1 @@\n-template<MEMFLAGS flag>\n-void G1SegmentedArrayFreeList<flag>::bulk_add(G1SegmentedArraySegment<flag>& first,\n-                                              G1SegmentedArraySegment<flag>& last,\n-                                              size_t num,\n-                                              size_t mem_size) {\n-  _list.prepend(first, last);\n-  Atomic::add(&_num_segments, num, memory_order_relaxed);\n-  Atomic::add(&_mem_size, mem_size, memory_order_relaxed);\n-}\n-\n-template<MEMFLAGS flag>\n-void G1SegmentedArrayFreeList<flag>::print_on(outputStream* out, const char* prefix) {\n-  out->print_cr(\"%s: segments %zu size %zu\",\n-                prefix, Atomic::load(&_num_segments), Atomic::load(&_mem_size));\n-}\n-\n-template<MEMFLAGS flag>\n-G1SegmentedArraySegment<flag>* G1SegmentedArrayFreeList<flag>::get() {\n+inline G1SegmentedArraySegment* G1SegmentedArrayFreeList::get() {\n@@ -78,1 +48,1 @@\n-  G1SegmentedArraySegment<flag>* result = _list.pop();\n+  G1SegmentedArraySegment* result = _list.pop();\n@@ -86,190 +56,0 @@\n-template<MEMFLAGS flag>\n-G1SegmentedArraySegment<flag>* G1SegmentedArrayFreeList<flag>::get_all(size_t& num_segments,\n-                                                                       size_t& mem_size) {\n-  GlobalCounter::CriticalSection cs(Thread::current());\n-\n-  G1SegmentedArraySegment<flag>* result = _list.pop_all();\n-  num_segments = Atomic::load(&_num_segments);\n-  mem_size = Atomic::load(&_mem_size);\n-\n-  if (result != nullptr) {\n-    Atomic::sub(&_num_segments, num_segments, memory_order_relaxed);\n-    Atomic::sub(&_mem_size, mem_size, memory_order_relaxed);\n-  }\n-  return result;\n-}\n-\n-template<MEMFLAGS flag>\n-void G1SegmentedArrayFreeList<flag>::free_all() {\n-  size_t num_freed = 0;\n-  size_t mem_size_freed = 0;\n-  G1SegmentedArraySegment<flag>* cur;\n-\n-  while ((cur = _list.pop()) != nullptr) {\n-    mem_size_freed += cur->mem_size();\n-    num_freed++;\n-    delete cur;\n-  }\n-\n-  Atomic::sub(&_num_segments, num_freed, memory_order_relaxed);\n-  Atomic::sub(&_mem_size, mem_size_freed, memory_order_relaxed);\n-}\n-\n-template <MEMFLAGS flag>\n-G1SegmentedArraySegment<flag>* G1SegmentedArray<flag>::create_new_segment(G1SegmentedArraySegment<flag>* const prev) {\n-  \/\/ Take an existing segment if available.\n-  G1SegmentedArraySegment<flag>* next = _free_segment_list->get();\n-  if (next == nullptr) {\n-    uint prev_num_slots = (prev != nullptr) ? prev->num_slots() : 0;\n-    uint num_slots = _alloc_options->next_num_slots(prev_num_slots);\n-    next = new G1SegmentedArraySegment<flag>(slot_size(), num_slots, prev);\n-  } else {\n-    assert(slot_size() == next->slot_size() ,\n-           \"Mismatch %d != %d\", slot_size(), next->slot_size());\n-    next->reset(prev);\n-  }\n-\n-  \/\/ Install it as current allocation segment.\n-  G1SegmentedArraySegment<flag>* old = Atomic::cmpxchg(&_first, prev, next);\n-  if (old != prev) {\n-    \/\/ Somebody else installed the segment, use that one.\n-    delete next;\n-    return old;\n-  } else {\n-    \/\/ Did we install the first segment in the list? If so, this is also the last.\n-    if (prev == nullptr) {\n-      _last = next;\n-    }\n-    \/\/ Successfully installed the segment into the list.\n-    Atomic::inc(&_num_segments, memory_order_relaxed);\n-    Atomic::add(&_mem_size, next->mem_size(), memory_order_relaxed);\n-    Atomic::add(&_num_available_slots, next->num_slots(), memory_order_relaxed);\n-    return next;\n-  }\n-}\n-\n-template <MEMFLAGS flag>\n-uint G1SegmentedArray<flag>::slot_size() const {\n-  return _alloc_options->slot_size();\n-}\n-\n-template <MEMFLAGS flag>\n-G1SegmentedArray<flag>::G1SegmentedArray(const G1SegmentedArrayAllocOptions* alloc_options,\n-                                         G1SegmentedArrayFreeList<flag>* free_segment_list) :\n-     _alloc_options(alloc_options),\n-     _first(nullptr),\n-     _last(nullptr),\n-     _num_segments(0),\n-     _mem_size(0),\n-     _free_segment_list(free_segment_list),\n-     _num_available_slots(0),\n-     _num_allocated_slots(0) {\n-  assert(_free_segment_list != nullptr, \"precondition!\");\n-}\n-\n-template <MEMFLAGS flag>\n-G1SegmentedArray<flag>::~G1SegmentedArray() {\n-  drop_all();\n-}\n-\n-template <MEMFLAGS flag>\n-void G1SegmentedArray<flag>::drop_all() {\n-  G1SegmentedArraySegment<flag>* cur = Atomic::load_acquire(&_first);\n-\n-  if (cur != nullptr) {\n-    assert(_last != nullptr, \"If there is at least one segment, there must be a last one.\");\n-\n-    G1SegmentedArraySegment<flag>* first = cur;\n-#ifdef ASSERT\n-    \/\/ Check list consistency.\n-    G1SegmentedArraySegment<flag>* last = cur;\n-    uint num_segments = 0;\n-    size_t mem_size = 0;\n-    while (cur != nullptr) {\n-      mem_size += cur->mem_size();\n-      num_segments++;\n-\n-      G1SegmentedArraySegment<flag>* next = cur->next();\n-      last = cur;\n-      cur = next;\n-    }\n-#endif\n-    assert(num_segments == _num_segments, \"Segment count inconsistent %u %u\", num_segments, _num_segments);\n-    assert(mem_size == _mem_size, \"Memory size inconsistent\");\n-    assert(last == _last, \"Inconsistent last segment\");\n-\n-    _free_segment_list->bulk_add(*first, *_last, _num_segments, _mem_size);\n-  }\n-\n-  _first = nullptr;\n-  _last = nullptr;\n-  _num_segments = 0;\n-  _mem_size = 0;\n-  _num_available_slots = 0;\n-  _num_allocated_slots = 0;\n-}\n-\n-template <MEMFLAGS flag>\n-void* G1SegmentedArray<flag>::allocate() {\n-  assert(slot_size() > 0, \"instance size not set.\");\n-\n-  G1SegmentedArraySegment<flag>* cur = Atomic::load_acquire(&_first);\n-  if (cur == nullptr) {\n-    cur = create_new_segment(cur);\n-  }\n-\n-  while (true) {\n-    void* slot = cur->get_new_slot();\n-    if (slot != nullptr) {\n-      Atomic::inc(&_num_allocated_slots, memory_order_relaxed);\n-      guarantee(is_aligned(slot, _alloc_options->slot_alignment()),\n-                \"result \" PTR_FORMAT \" not aligned at %u\", p2i(slot), _alloc_options->slot_alignment());\n-      return slot;\n-    }\n-    \/\/ The segment is full. Next round.\n-    assert(cur->is_full(), \"must be\");\n-    cur = create_new_segment(cur);\n-  }\n-}\n-\n-template <MEMFLAGS flag>\n-inline uint G1SegmentedArray<flag>::num_segments() const {\n-  return Atomic::load(&_num_segments);\n-}\n-\n-#ifdef ASSERT\n-template <MEMFLAGS flag>\n-class LengthClosure {\n-  uint _total;\n-public:\n-  LengthClosure() : _total(0) {}\n-  void do_segment(G1SegmentedArraySegment<flag>* segment, uint limit) {\n-    _total += limit;\n-  }\n-  uint length() const {\n-    return _total;\n-  }\n-};\n-\n-template <MEMFLAGS flag>\n-uint G1SegmentedArray<flag>::calculate_length() const {\n-  LengthClosure<flag> closure;\n-  iterate_segments(closure);\n-  return closure.length();\n-}\n-#endif\n-\n-template <MEMFLAGS flag>\n-template <typename SegmentClosure>\n-void G1SegmentedArray<flag>::iterate_segments(SegmentClosure& closure) const {\n-  G1SegmentedArraySegment<flag>* cur = Atomic::load_acquire(&_first);\n-\n-  assert((cur != nullptr) == (_last != nullptr),\n-         \"If there is at least one segment, there must be a last one\");\n-\n-  while (cur != nullptr) {\n-    closure.do_segment(cur, cur->length());\n-    cur = cur->next();\n-  }\n-}\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArray.inline.hpp","additions":6,"deletions":226,"binary":false,"changes":232,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -55,1 +55,1 @@\n-  G1SegmentedArrayMemoryStats free = G1SegmentedArrayFreePool<mtGCCardSet>::free_list_sizes();\n+  G1SegmentedArrayMemoryStats free = G1SegmentedArrayFreePool::free_list_sizes();\n@@ -71,1 +71,1 @@\n-  G1SegmentedArrayFreePool<mtGCCardSet>::update_unlink_processors(_return_info);\n+  G1SegmentedArrayFreePool::update_unlink_processors(_return_info);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreeMemoryTask.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -59,2 +59,2 @@\n-  typedef G1SegmentedArrayFreePool<mtGCCardSet>::G1ReturnMemoryProcessor G1ReturnMemoryProcessor;\n-  typedef G1SegmentedArrayFreePool<mtGCCardSet>::G1ReturnMemoryProcessorSet G1ReturnMemoryProcessorSet;\n+  using G1ReturnMemoryProcessor = G1SegmentedArrayFreePool::G1ReturnMemoryProcessor;\n+  using G1ReturnMemoryProcessorSet = G1SegmentedArrayFreePool::G1ReturnMemoryProcessorSet;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreeMemoryTask.hpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -46,2 +46,1 @@\n-template<MEMFLAGS flag>\n-void G1SegmentedArrayFreePool<flag>::update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processor) {\n+void G1SegmentedArrayFreePool::update_unlink_processors(G1ReturnMemoryProcessorSet* unlink_processor) {\n@@ -55,2 +54,1 @@\n-template<MEMFLAGS flag>\n-void G1SegmentedArrayFreePool<flag>::G1ReturnMemoryProcessor::visit_free_list(G1SegmentedArrayFreeList<flag>* source) {\n+void G1SegmentedArrayFreePool::G1ReturnMemoryProcessor::visit_free_list(G1SegmentedArrayFreeList* source) {\n@@ -78,2 +76,1 @@\n-template<MEMFLAGS flag>\n-bool G1SegmentedArrayFreePool<flag>::G1ReturnMemoryProcessor::return_to_vm(jlong deadline) {\n+bool G1SegmentedArrayFreePool::G1ReturnMemoryProcessor::return_to_vm(jlong deadline) {\n@@ -86,2 +83,2 @@\n-  G1SegmentedArraySegment<flag>* cur = _first;\n-  G1SegmentedArraySegment<flag>* last = nullptr;\n+  G1SegmentedArraySegment* cur = _first;\n+  G1SegmentedArraySegment* last = nullptr;\n@@ -128,2 +125,1 @@\n-template<MEMFLAGS flag>\n-bool G1SegmentedArrayFreePool<flag>::G1ReturnMemoryProcessor::return_to_os(jlong deadline) {\n+bool G1SegmentedArrayFreePool::G1ReturnMemoryProcessor::return_to_os(jlong deadline) {\n@@ -138,1 +134,1 @@\n-    G1SegmentedArraySegment<flag>* next = _first->next();\n+    G1SegmentedArraySegment* next = _first->next();\n@@ -141,1 +137,1 @@\n-    delete _first;\n+    G1SegmentedArraySegment::delete_segment(_first);\n@@ -155,2 +151,1 @@\n-template<MEMFLAGS flag>\n-G1SegmentedArrayFreePool<flag> G1SegmentedArrayFreePool<flag>::_freelist_pool(G1CardSetConfiguration::num_mem_object_types());\n+G1SegmentedArrayFreePool G1SegmentedArrayFreePool::_freelist_pool(G1CardSetConfiguration::num_mem_object_types());\n@@ -158,2 +153,1 @@\n-template<MEMFLAGS flag>\n-G1SegmentedArrayFreePool<flag>::G1SegmentedArrayFreePool(uint num_free_lists) :\n+G1SegmentedArrayFreePool::G1SegmentedArrayFreePool(uint num_free_lists) :\n@@ -162,1 +156,1 @@\n-  _free_lists = NEW_C_HEAP_ARRAY(G1SegmentedArrayFreeList < flag >, _num_free_lists, mtGC);\n+  _free_lists = NEW_C_HEAP_ARRAY(G1SegmentedArrayFreeList, _num_free_lists, mtGC);\n@@ -164,1 +158,1 @@\n-    new (&_free_lists[i]) G1SegmentedArrayFreeList<flag>();\n+    new (&_free_lists[i]) G1SegmentedArrayFreeList();\n@@ -168,2 +162,1 @@\n-template<MEMFLAGS flag>\n-G1SegmentedArrayFreePool<flag>::~G1SegmentedArrayFreePool() {\n+G1SegmentedArrayFreePool::~G1SegmentedArrayFreePool() {\n@@ -171,1 +164,1 @@\n-    _free_lists[i].~G1SegmentedArrayFreeList<flag>();\n+    _free_lists[i].~G1SegmentedArrayFreeList();\n@@ -176,2 +169,1 @@\n-template<MEMFLAGS flag>\n-G1SegmentedArrayMemoryStats G1SegmentedArrayFreePool<flag>::memory_sizes() const {\n+G1SegmentedArrayMemoryStats G1SegmentedArrayFreePool::memory_sizes() const {\n@@ -187,2 +179,1 @@\n-template<MEMFLAGS flag>\n-size_t G1SegmentedArrayFreePool<flag>::mem_size() const {\n+size_t G1SegmentedArrayFreePool::mem_size() const {\n@@ -196,2 +187,1 @@\n-template<MEMFLAGS flag>\n-void G1SegmentedArrayFreePool<flag>::print_on(outputStream* out) {\n+void G1SegmentedArrayFreePool::print_on(outputStream* out) {\n@@ -204,2 +194,0 @@\n-\n-template class G1SegmentedArrayFreePool<mtGCCardSet>;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreePool.cpp","additions":18,"deletions":30,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2021, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -59,1 +59,0 @@\n-template<MEMFLAGS flag>\n@@ -65,1 +64,1 @@\n-  G1SegmentedArrayFreeList<flag>* _free_lists;\n+  G1SegmentedArrayFreeList* _free_lists;\n@@ -79,1 +78,1 @@\n-  G1SegmentedArrayFreeList<flag>* free_list(uint i) {\n+  G1SegmentedArrayFreeList* free_list(uint i) {\n@@ -94,3 +93,2 @@\n-template<MEMFLAGS flag>\n-class G1SegmentedArrayFreePool<flag>::G1ReturnMemoryProcessor : public CHeapObj<mtGC> {\n-  G1SegmentedArrayFreeList<flag>* _source;\n+class G1SegmentedArrayFreePool::G1ReturnMemoryProcessor : public CHeapObj<mtGC> {\n+  G1SegmentedArrayFreeList* _source;\n@@ -99,1 +97,1 @@\n-  G1SegmentedArraySegment<flag>* _first;\n+  G1SegmentedArraySegment* _first;\n@@ -111,1 +109,1 @@\n-  void visit_free_list(G1SegmentedArrayFreeList<flag>* source);\n+  void visit_free_list(G1SegmentedArrayFreeList* source);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1SegmentedArrayFreePool.hpp","additions":7,"deletions":9,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -84,1 +84,1 @@\n-  _card_set_mm(config, G1SegmentedArrayFreePool<mtGCCardSet>::free_list_pool()),\n+  _card_set_mm(config, G1SegmentedArrayFreePool::free_list_pool()),\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegionRemSet.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}