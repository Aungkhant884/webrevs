{"files":[{"patch":"@@ -0,0 +1,147 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n+#include \"runtime\/mutex.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/readWriteLock.hpp\"\n+\n+void ReadWriteLock::read_lock(Thread *current) {\n+  for (;;) {\n+    const int32_t count = Atomic::load_acquire(&_count);\n+    if (count < 0) {\n+      \/\/ Wait until unlocked by writer\n+      auto await = [&]() {\n+        Locker locker(&_mon);\n+        while (Atomic::load_acquire(&_count) < 0) {\n+          _mon.wait(0);\n+        }\n+      };\n+      if (current->is_Java_thread()) {\n+        ThreadBlockInVM tbivm(JavaThread::cast(current));\n+        await();\n+      } else {\n+        await();\n+      }\n+      continue;\n+    }\n+\n+    \/\/ Increment count\n+    if (Atomic::cmpxchg(&_count, count, count + 1) != count) {\n+      continue;\n+    }\n+\n+    \/\/ Entered critical region\n+    return;\n+  }\n+}\n+\n+void ReadWriteLock::read_unlock() {\n+  for (;;) {\n+    const int32_t count = Atomic::load_acquire(&_count);\n+\n+    if (count > 0) {\n+      \/\/ No writer in progress, try to decrement reader count.\n+      if (Atomic::cmpxchg(&_count, count, count - 1) != count) {\n+        continue;\n+      }\n+    } else {\n+      \/\/ Writer in progress, try to increment reader count.\n+      if (Atomic::cmpxchg(&_count, count, count + 1) != count) {\n+        continue;\n+      }\n+      \/\/ If the previous count was -2, then we just incremented it to -1,\n+      \/\/ and we should signal that all readers have now exited their\n+      \/\/ critical region and the writer may now block readers.\n+      if (count == -2) {\n+        Locker locker(&_mon);\n+        _mon.notify_all();\n+      }\n+    }\n+    \/\/ Exited critical region\n+    return;\n+  }\n+}\n+\n+void ReadWriteLock::write_lock(Thread *current) {\n+  for (;;) {\n+    const int32_t count = Atomic::load_acquire(&_count);\n+\n+    if (count < 0) {\n+      \/\/ Already has a writer, wait until unlocked\n+\n+      auto await_writers_exit = [&]() {\n+        Locker locker(&_mon);\n+        while (Atomic::load_acquire(&_count) < 0) {\n+          _mon.wait(0);\n+        }\n+      };\n+\n+      if (current->is_Java_thread()) {\n+        ThreadBlockInVM tbivm(JavaThread::cast(current));\n+        await_writers_exit();\n+      } else {\n+        await_writers_exit();\n+      }\n+      continue;\n+    }\n+\n+    \/\/ Increment and invert count\n+    if (Atomic::cmpxchg(&_count, count, -(count + 1)) != count) {\n+      continue;\n+    }\n+\n+    \/\/ If the previous count was 0, then we just incremented and inverted\n+    \/\/ it to -1 and have now blocked readers. Otherwise we wait until all reader\n+    \/\/ threads have exited the critical region.\n+    if (count != 0) {\n+      auto await_writer_entry = [&]() {\n+        \/\/ Wait until all readers exit.\n+        Locker locker(&_mon);\n+        while (Atomic::load_acquire(&_count) != -1) {\n+          _mon.wait(0);\n+        }\n+      };\n+      if (current->is_Java_thread()) {\n+        ThreadBlockInVM tbivm(JavaThread::cast(current));\n+        await_writer_entry();\n+      } else {\n+        await_writer_entry();\n+      }\n+    }\n+\n+    \/\/ Locked.\n+    return;\n+  }\n+}\n+\n+void ReadWriteLock::write_unlock() {\n+  assert(Atomic::load_acquire(&_count) == -1, \"invariant\");\n+\n+  Locker locker(&_mon);\n+  Atomic::release_store(&_count, (int32_t)0);\n+  _mon.notify_all();\n+}\n","filename":"src\/hotspot\/share\/utilities\/readWriteLock.cpp","additions":147,"deletions":0,"binary":false,"changes":147,"status":"added"},{"patch":"@@ -0,0 +1,98 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_RUNTIME_READWRITELOCK_HPP\n+#define SHARE_RUNTIME_READWRITELOCK_HPP\n+\n+#include \"memory\/allocation.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n+#include \"runtime\/mutex.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/macros.hpp\"\n+\n+\/\/  This is a multiple-reader single-writer lock implementation.\n+\/\/\n+\/\/ * This lock is unfair, high contention of readers may starve some of them.\n+\/\/   This is because registering a reader requires CASing a counter.\n+\/\/\n+\/\/ * Writers take precedence, blocking new readers from entering and allowing\n+\/\/   current readers to proceed until none are left, at which point it will\n+\/\/   unblock itself and proceed to execute its critical region.\n+\/\/\n+\/\/ * A writer cannot downgrade to a read-lock.\n+\/\/\n+\/\/ * A reader cannot upgrade to a write-lock.\n+\/\/\n+\/\/ * This lock is not recursive. It is not even safe for readers to lock recursively,\n+\/\/   as this will deadlock if there is an interleaving writer.\n+\/\/\n+\/\/ * This lock allows safe points to take place when being blocked.\n+class ReadWriteLock : public CHeapObj<mtSynchronizer> {\n+private:\n+  NONCOPYABLE(ReadWriteLock);\n+\n+  class Locker : public StackObj {\n+  private:\n+    PlatformMonitor* const _lock;\n+\n+  public:\n+    Locker(PlatformMonitor* lock)\n+      : _lock(lock) {\n+      _lock->lock();\n+    }\n+    ~Locker() {\n+      _lock->unlock();\n+    }\n+  };\n+\n+  PlatformMonitor _mon;\n+\n+  \/\/ The count reflects the number of reader threads inside a critical region and whether or not a writer is waiting.\n+  \/\/\n+  \/\/ * Normal (count >= 0). Readers are allowed to enter and exit their critical region, no writer waiting.\n+  \/\/\n+  \/\/ * Blocked (count == -1). A writer is inside its critical region.\n+  \/\/\n+  \/\/ * Block in progress (count < -1). Readers are only allowed to exit their critical region.\n+  \/\/   Attempts by readers to enter their critical region is blocked.\n+  \/\/\n+  volatile int32_t _count;\n+\n+public:\n+  ReadWriteLock()\n+    : _mon(),\n+      _count(0) {\n+  }\n+\n+  ~ReadWriteLock() {\n+  }\n+\n+  void write_lock(Thread* current = Thread::current());\n+  void write_unlock();\n+\n+  void read_lock(Thread* current = Thread::current());\n+  void read_unlock();\n+};\n+#endif \/\/ SHARE_RUNTIME_READWRITELOCK_HPP\n","filename":"src\/hotspot\/share\/utilities\/readWriteLock.hpp","additions":98,"deletions":0,"binary":false,"changes":98,"status":"added"},{"patch":"@@ -0,0 +1,112 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"runtime\/interfaceSupport.inline.hpp\"\n+#include \"runtime\/thread.hpp\"\n+#include \"threadHelper.inline.hpp\"\n+#include \"unittest.hpp\"\n+#include \"utilities\/readWriteLock.hpp\"\n+\n+class ReadWriteLockTest : public ::testing::Test {};\n+\n+TEST_VM_F(ReadWriteLockTest, WriterLockPreventsReadersFromEnteringCriticalRegion) {\n+  const int max_iter = 1000;\n+  int iter = 0;\n+  ReadWriteLock* mut = new ReadWriteLock();\n+\n+  volatile bool reader_started = false;\n+  volatile bool reader_in_critical_region = false;\n+  volatile bool reader_exited_critical_region = false;\n+\n+  auto reader = [&](int _ignored) {\n+    Atomic::release_store(&reader_started, true);\n+    mut->read_lock(Thread::current());\n+    Atomic::release_store(&reader_in_critical_region, true);\n+    mut->read_unlock();\n+    Atomic::release_store(&reader_exited_critical_region, true);\n+  };\n+\n+  Semaphore rp{};\n+  BasicTestThread<decltype(reader), int>* rt =\n+      new BasicTestThread<decltype(reader), int>(reader, 0, &rp);\n+\n+  \/\/ 1. Hold write lock\n+  mut->write_lock(Thread::current());\n+\n+  \/\/ 2. Start reader\n+  rt->doit();\n+\n+  \/\/ 3. Wait for reader to attempt to lock\n+  iter = 0;\n+  while (!Atomic::load_acquire(&reader_started) && iter < max_iter) {\n+    \/\/ Spin, waiting for reader to start up\n+    iter++;\n+  }\n+\n+  \/\/ 4. Reader should block, waiting for its turn to enter critical region\n+  \/\/ Check repeatedly to (hopefully) avoid timing issue.\n+  for (int i = 0; i < max_iter; i++) {\n+    EXPECT_FALSE(Atomic::load_acquire(&reader_in_critical_region));\n+  }\n+\n+  \/\/ 5. Let reader enter its critical region\n+  mut->write_unlock();\n+  iter = 0;\n+  while (!Atomic::load_acquire(&reader_in_critical_region) && iter < max_iter) {\n+    iter++;\n+  }\n+  ASSERT_TRUE(Atomic::load_acquire(&reader_in_critical_region));\n+\n+  \/\/ 6. Reader succesfully exits its critical region\n+  iter = 0;\n+  while (!Atomic::load_acquire(&reader_exited_critical_region) && iter < max_iter) {\n+    iter++;\n+  }\n+  ASSERT_TRUE(Atomic::load_acquire(&reader_exited_critical_region));\n+}\n+\n+TEST_VM_F(ReadWriteLockTest, MultipleReadersAtSameTime) {\n+  ReadWriteLock* mut = new ReadWriteLock();\n+  constexpr const int num_readers = 5;\n+  volatile int concurrent_readers = 0;\n+\n+  auto r = [&](int _ignored) {\n+    mut->read_lock(Thread::current());\n+    \/\/ Increment counter\n+    Atomic::add(&concurrent_readers, 1);\n+    \/\/ Don't let go of the lock, exit thread\n+  };\n+  TestThreadGroup<decltype(r), int, num_readers> ttg(r, []() {\n+    return 0;\n+  });\n+  ttg.doit();\n+  ttg.join();\n+  EXPECT_EQ(Atomic::load(&concurrent_readers), num_readers);\n+  \/\/ Unlock for all the threads.\n+  \/\/ Not strictly necessary, but locking looks weird\n+  \/\/ without the corresponding unlock\n+  for (int i = 0; i < num_readers; i++) {\n+    mut->read_unlock();\n+  }\n+}\n","filename":"test\/hotspot\/gtest\/runtime\/test_readWriteLock.cpp","additions":112,"deletions":0,"binary":false,"changes":112,"status":"added"},{"patch":"@@ -122,0 +122,54 @@\n+\/\/ Calls a single-argument function of type F with state of type S as its input\n+\/\/ in a new thread when doit() is run.\n+template<typename F, typename S>\n+class BasicTestThread : public JavaTestThread {\n+private:\n+  F _fun;\n+  S _state;\n+\n+public:\n+  BasicTestThread(F fun, S state, Semaphore* sem)\n+    : JavaTestThread(sem),\n+      _fun(fun),\n+      _state(state) {\n+  }\n+\n+  virtual ~BasicTestThread(){};\n+\n+  void main_run() override {\n+    _fun(_state);\n+  }\n+};\n+\n+\/\/ A TestThreadGroup tracks multiple threads running the same function.\n+template<typename F, typename S, int N>\n+class TestThreadGroup {\n+private:\n+  BasicTestThread<F, S>* _threads[N];\n+  Semaphore _sem;\n+\n+public:\n+  NONCOPYABLE(TestThreadGroup);\n+\n+  \/\/ Use state_fun to generate varying state of type S for each function F.\n+  template<typename StateGenerator>\n+  TestThreadGroup(F fun, StateGenerator state_fun)\n+    : _sem() {\n+    for (int i = 0; i < N; i++) {\n+      _threads[i] = new BasicTestThread<F, S>(fun, state_fun(), &_sem);\n+    }\n+  }\n+  ~TestThreadGroup() {}\n+\n+  void doit() {\n+    for (int i = 0; i < N; i++) {\n+      _threads[i]->doit();\n+    }\n+  }\n+  void join() {\n+    for (int i = 0; i < N; i++) {\n+      _sem.wait();\n+    }\n+  }\n+};\n+\n","filename":"test\/hotspot\/gtest\/threadHelper.inline.hpp","additions":54,"deletions":0,"binary":false,"changes":54,"status":"modified"}]}