{"files":[{"patch":"@@ -117,20 +117,24 @@\n-  \/\/ ... and mark it unlocked.\n-  ori(Rmark, Rmark, markWord::unlocked_value);\n-\n-  \/\/ Save unlocked object header into the displaced header location on the stack.\n-  std(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n-\n-  \/\/ Compare object markWord with Rmark and if equal exchange Rscratch with object markWord.\n-  assert(oopDesc::mark_offset_in_bytes() == 0, \"cas must take a zero displacement\");\n-  cmpxchgd(\/*flag=*\/CCR0,\n-           \/*current_value=*\/Rscratch,\n-           \/*compare_value=*\/Rmark,\n-           \/*exchange_value=*\/Rbox,\n-           \/*where=*\/Roop\/*+0==mark_offset_in_bytes*\/,\n-           MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n-           MacroAssembler::cmpxchgx_hint_acquire_lock(),\n-           noreg,\n-           &cas_failed,\n-           \/*check without membar and ldarx first*\/true);\n-  \/\/ If compare\/exchange succeeded we found an unlocked object and we now have locked it\n-  \/\/ hence we are done.\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    fast_lock(Roop, Rmark, Rscratch, slow_int);\n+  } else if (LockingMode == LM_LEGACY) {\n+    \/\/ ... and mark it unlocked.\n+    ori(Rmark, Rmark, markWord::unlocked_value);\n+\n+    \/\/ Save unlocked object header into the displaced header location on the stack.\n+    std(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n+\n+    \/\/ Compare object markWord with Rmark and if equal exchange Rscratch with object markWord.\n+    assert(oopDesc::mark_offset_in_bytes() == 0, \"cas must take a zero displacement\");\n+    cmpxchgd(\/*flag=*\/CCR0,\n+             \/*current_value=*\/Rscratch,\n+             \/*compare_value=*\/Rmark,\n+             \/*exchange_value=*\/Rbox,\n+             \/*where=*\/Roop\/*+0==mark_offset_in_bytes*\/,\n+             MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n+             MacroAssembler::cmpxchgx_hint_acquire_lock(),\n+             noreg,\n+             &cas_failed,\n+             \/*check without membar and ldarx first*\/true);\n+    \/\/ If compare\/exchange succeeded we found an unlocked object and we now have locked it\n+    \/\/ hence we are done.\n+  }\n@@ -142,7 +146,9 @@\n-  bind(cas_failed);\n-  \/\/ We did not find an unlocked object so see if this is a recursive case.\n-  sub(Rscratch, Rscratch, R1_SP);\n-  load_const_optimized(R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n-  and_(R0\/*==0?*\/, Rscratch, R0);\n-  std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n-  bne(CCR0, slow_int);\n+  if (LockingMode == LM_LEGACY) {\n+    bind(cas_failed);\n+    \/\/ We did not find an unlocked object so see if this is a recursive case.\n+    sub(Rscratch, Rscratch, R1_SP);\n+    load_const_optimized(R0, (~(os::vm_page_size()-1) | markWord::lock_mask_in_place));\n+    and_(R0\/*==0?*\/, Rscratch, R0);\n+    std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n+    bne(CCR0, slow_int);\n+  }\n@@ -151,1 +157,0 @@\n-\n@@ -164,4 +169,6 @@\n-  \/\/ Test first if it is a fast recursive unlock.\n-  ld(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n-  cmpdi(CCR0, Rmark, 0);\n-  beq(CCR0, done);\n+  if (LockingMode != LM_LIGHTWEIGHT) {\n+    \/\/ Test first if it is a fast recursive unlock.\n+    ld(Rmark, BasicLock::displaced_header_offset_in_bytes(), Rbox);\n+    cmpdi(CCR0, Rmark, 0);\n+    beq(CCR0, done);\n+  }\n@@ -173,11 +180,18 @@\n-  \/\/ Check if it is still a light weight lock, this is is true if we see\n-  \/\/ the stack address of the basicLock in the markWord of the object.\n-  cmpxchgd(\/*flag=*\/CCR0,\n-           \/*current_value=*\/R0,\n-           \/*compare_value=*\/Rbox,\n-           \/*exchange_value=*\/Rmark,\n-           \/*where=*\/Roop,\n-           MacroAssembler::MemBarRel,\n-           MacroAssembler::cmpxchgx_hint_release_lock(),\n-           noreg,\n-           &slow_int);\n+  if (LockingMode == LM_LIGHTWEIGHT) {\n+    ld(Rmark, oopDesc::mark_offset_in_bytes(), Roop);\n+    andi_(R0, Rmark, markWord::monitor_value);\n+    bne(CCR0, slow_int);\n+    fast_unlock(Roop, Rmark, slow_int);\n+  } else if (LockingMode == LM_LEGACY) {\n+    \/\/ Check if it is still a light weight lock, this is is true if we see\n+    \/\/ the stack address of the basicLock in the markWord of the object.\n+    cmpxchgd(\/*flag=*\/CCR0,\n+             \/*current_value=*\/R0,\n+             \/*compare_value=*\/Rbox,\n+             \/*exchange_value=*\/Rmark,\n+             \/*where=*\/Roop,\n+             MacroAssembler::MemBarRel,\n+             MacroAssembler::cmpxchgx_hint_release_lock(),\n+             noreg,\n+             &slow_int);\n+  }\n@@ -190,1 +204,0 @@\n-\n","filename":"src\/hotspot\/cpu\/ppc\/c1_MacroAssembler_ppc.cpp","additions":57,"deletions":44,"binary":false,"changes":101,"status":"modified"},{"patch":"@@ -927,1 +927,1 @@\n-    \/\/ template code:\n+    \/\/ template code (for LM_LEGACY):\n@@ -941,1 +941,1 @@\n-    const Register displaced_header = R7_ARG5;\n+    const Register header           = R7_ARG5;\n@@ -949,1 +949,1 @@\n-    assert_different_registers(displaced_header, object_mark_addr, current_header, tmp);\n+    assert_different_registers(header, object_mark_addr, current_header, tmp);\n@@ -953,2 +953,2 @@\n-    \/\/ Load markWord from object into displaced_header.\n-    ld(displaced_header, oopDesc::mark_offset_in_bytes(), object);\n+    \/\/ Load markWord from object into header.\n+    ld(header, oopDesc::mark_offset_in_bytes(), object);\n@@ -963,2 +963,4 @@\n-    \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n-    ori(displaced_header, displaced_header, markWord::unlocked_value);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      fast_lock(object, \/* mark word *\/ header, tmp, slow_case);\n+      b(count_locking);\n+    } else if (LockingMode == LM_LEGACY) {\n@@ -966,4 +968,2 @@\n-    \/\/ monitor->lock()->set_displaced_header(displaced_header);\n-    const int lock_offset = in_bytes(BasicObjectLock::lock_offset());\n-    const int mark_offset = lock_offset +\n-                            BasicLock::displaced_header_offset_in_bytes();\n+      \/\/ Set displaced_header to be (markWord of object | UNLOCK_VALUE).\n+      ori(header, header, markWord::unlocked_value);\n@@ -971,2 +971,4 @@\n-    \/\/ Initialize the box (Must happen before we update the object mark!).\n-    std(displaced_header, mark_offset, monitor);\n+      \/\/ monitor->lock()->set_displaced_header(displaced_header);\n+      const int lock_offset = in_bytes(BasicObjectLock::lock_offset());\n+      const int mark_offset = lock_offset +\n+                              BasicLock::displaced_header_offset_in_bytes();\n@@ -974,1 +976,2 @@\n-    \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n+      \/\/ Initialize the box (Must happen before we update the object mark!).\n+      std(header, mark_offset, monitor);\n@@ -976,19 +979,1 @@\n-    \/\/ Store stack address of the BasicObjectLock (this is monitor) into object.\n-    addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n-\n-    \/\/ Must fence, otherwise, preceding store(s) may float below cmpxchg.\n-    \/\/ CmpxchgX sets CCR0 to cmpX(current, displaced).\n-    cmpxchgd(\/*flag=*\/CCR0,\n-             \/*current_value=*\/current_header,\n-             \/*compare_value=*\/displaced_header, \/*exchange_value=*\/monitor,\n-             \/*where=*\/object_mark_addr,\n-             MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n-             MacroAssembler::cmpxchgx_hint_acquire_lock(),\n-             noreg,\n-             &cas_failed,\n-             \/*check without membar and ldarx first*\/true);\n-\n-    \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n-    \/\/ object and we have now locked it.\n-    b(count_locking);\n-    bind(cas_failed);\n+      \/\/ if (Atomic::cmpxchg(\/*addr*\/obj->mark_addr(), \/*cmp*\/displaced_header, \/*ex=*\/monitor) == displaced_header) {\n@@ -996,3 +981,2 @@\n-    \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n-    \/\/   \/\/ Simple recursive case.\n-    \/\/   monitor->lock()->set_displaced_header(nullptr);\n+      \/\/ Store stack address of the BasicObjectLock (this is monitor) into object.\n+      addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n@@ -1000,1 +984,11 @@\n-    \/\/ We did not see an unlocked object so try the fast recursive case.\n+      \/\/ Must fence, otherwise, preceding store(s) may float below cmpxchg.\n+      \/\/ CmpxchgX sets CCR0 to cmpX(current, displaced).\n+      cmpxchgd(\/*flag=*\/CCR0,\n+               \/*current_value=*\/current_header,\n+               \/*compare_value=*\/header, \/*exchange_value=*\/monitor,\n+               \/*where=*\/object_mark_addr,\n+               MacroAssembler::MemBarRel | MacroAssembler::MemBarAcq,\n+               MacroAssembler::cmpxchgx_hint_acquire_lock(),\n+               noreg,\n+               &cas_failed,\n+               \/*check without membar and ldarx first*\/true);\n@@ -1002,3 +996,4 @@\n-    \/\/ Check if owner is self by comparing the value in the markWord of object\n-    \/\/ (current_header) with the stack pointer.\n-    sub(current_header, current_header, R1_SP);\n+      \/\/ If the compare-and-exchange succeeded, then we found an unlocked\n+      \/\/ object and we have now locked it.\n+      b(count_locking);\n+      bind(cas_failed);\n@@ -1006,2 +1001,3 @@\n-    assert(os::vm_page_size() > 0xfff, \"page size too small - change the constant\");\n-    load_const_optimized(tmp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);\n+      \/\/ } else if (THREAD->is_lock_owned((address)displaced_header))\n+      \/\/   \/\/ Simple recursive case.\n+      \/\/   monitor->lock()->set_displaced_header(nullptr);\n@@ -1009,6 +1005,16 @@\n-    and_(R0\/*==0?*\/, current_header, tmp);\n-    \/\/ If condition is true we are done and hence we can store 0 in the displaced\n-    \/\/ header indicating it is a recursive lock.\n-    bne(CCR0, slow_case);\n-    std(R0\/*==0!*\/, mark_offset, monitor);\n-    b(count_locking);\n+      \/\/ We did not see an unlocked object so try the fast recursive case.\n+\n+      \/\/ Check if owner is self by comparing the value in the markWord of object\n+      \/\/ (current_header) with the stack pointer.\n+      sub(current_header, current_header, R1_SP);\n+\n+      assert(os::vm_page_size() > 0xfff, \"page size too small - change the constant\");\n+      load_const_optimized(tmp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);\n+\n+      and_(R0\/*==0?*\/, current_header, tmp);\n+      \/\/ If condition is true we are done and hence we can store 0 in the displaced\n+      \/\/ header indicating it is a recursive lock.\n+      bne(CCR0, slow_case);\n+      std(R0\/*==0!*\/, mark_offset, monitor);\n+      b(count_locking);\n+    }\n@@ -1023,1 +1029,5 @@\n-    call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter_obj), object);\n+    } else {\n+      call_VM(noreg, CAST_FROM_FN_PTR(address, InterpreterRuntime::monitorenter), monitor);\n+    }\n@@ -1045,1 +1055,1 @@\n-    \/\/ template code:\n+    \/\/ template code (for LM_LEGACY):\n@@ -1059,1 +1069,1 @@\n-    const Register displaced_header = R8_ARG6;\n+    const Register header           = R8_ARG6;\n@@ -1066,1 +1076,1 @@\n-    assert_different_registers(object, displaced_header, object_mark_addr, current_header);\n+    assert_different_registers(object, header, object_mark_addr, current_header);\n@@ -1068,3 +1078,4 @@\n-    \/\/ Test first if we are in the fast recursive case.\n-    ld(displaced_header, in_bytes(BasicObjectLock::lock_offset()) +\n-                         BasicLock::displaced_header_offset_in_bytes(), monitor);\n+    if (LockingMode != LM_LIGHTWEIGHT) {\n+      \/\/ Test first if we are in the fast recursive case.\n+      ld(header, in_bytes(BasicObjectLock::lock_offset()) +\n+                 BasicLock::displaced_header_offset_in_bytes(), monitor);\n@@ -1072,3 +1083,4 @@\n-    \/\/ If the displaced header is zero, we have a recursive unlock.\n-    cmpdi(CCR0, displaced_header, 0);\n-    beq(CCR0, free_slot); \/\/ recursive unlock\n+      \/\/ If the displaced header is zero, we have a recursive unlock.\n+      cmpdi(CCR0, header, 0);\n+      beq(CCR0, free_slot); \/\/ recursive unlock\n+    }\n@@ -1084,14 +1096,35 @@\n-    addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n-\n-    \/\/ We have the displaced header in displaced_header. If the lock is still\n-    \/\/ lightweight, it will contain the monitor address and we'll store the\n-    \/\/ displaced header back into the object's mark word.\n-    \/\/ CmpxchgX sets CCR0 to cmpX(current, monitor).\n-    cmpxchgd(\/*flag=*\/CCR0,\n-             \/*current_value=*\/current_header,\n-             \/*compare_value=*\/monitor, \/*exchange_value=*\/displaced_header,\n-             \/*where=*\/object_mark_addr,\n-             MacroAssembler::MemBarRel,\n-             MacroAssembler::cmpxchgx_hint_release_lock(),\n-             noreg,\n-             &slow_case);\n+\n+    if (LockingMode == LM_LIGHTWEIGHT) {\n+      \/\/ Check for non-symmetric locking. This is allowed by the spec and the interpreter\n+      \/\/ must handle it.\n+      Register tmp = current_header;\n+      \/\/ First check for lock-stack underflow.\n+      lwz(tmp, in_bytes(JavaThread::lock_stack_top_offset()), R16_thread);\n+      cmplwi(CCR0, tmp, (unsigned)LockStack::start_offset());\n+      ble(CCR0, slow_case);\n+      \/\/ Then check if the top of the lock-stack matches the unlocked object.\n+      addi(tmp, tmp, -oopSize);\n+      ldx(tmp, tmp, R16_thread);\n+      cmpd(CCR0, tmp, object);\n+      bne(CCR0, slow_case);\n+\n+      ld(header, oopDesc::mark_offset_in_bytes(), object);\n+      andi_(R0, header, markWord::monitor_value);\n+      bne(CCR0, slow_case);\n+      fast_unlock(object, header, slow_case);\n+    } else {\n+      addi(object_mark_addr, object, oopDesc::mark_offset_in_bytes());\n+\n+      \/\/ We have the displaced header in displaced_header. If the lock is still\n+      \/\/ lightweight, it will contain the monitor address and we'll store the\n+      \/\/ displaced header back into the object's mark word.\n+      \/\/ CmpxchgX sets CCR0 to cmpX(current, monitor).\n+      cmpxchgd(\/*flag=*\/CCR0,\n+               \/*current_value=*\/current_header,\n+               \/*compare_value=*\/monitor, \/*exchange_value=*\/header,\n+               \/*where=*\/object_mark_addr,\n+               MacroAssembler::MemBarRel,\n+               MacroAssembler::cmpxchgx_hint_release_lock(),\n+               noreg,\n+               &slow_case);\n+    }\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":105,"deletions":72,"binary":false,"changes":177,"status":"modified"},{"patch":"@@ -2632,2 +2632,1 @@\n-  assert(flag != CCR0, \"bad condition register\");\n-  Label cont;\n+  assert(LockingMode != LM_LIGHTWEIGHT || flag == CCR0, \"bad condition register\");\n@@ -2652,1 +2651,1 @@\n-                      cont, object_has_monitor);\n+                      success, object_has_monitor);\n@@ -2661,1 +2660,5 @@\n-  if (LockingMode != LM_MONITOR) {\n+  if (LockingMode == LM_MONITOR) {\n+    \/\/ Set NE to indicate 'failure' -> take slow-path.\n+    crandc(flag, Assembler::equal, flag, Assembler::equal);\n+    b(failure);\n+  } else if (LockingMode == LM_LEGACY) {\n@@ -2686,5 +2689,0 @@\n-  } else {\n-    \/\/ Set NE to indicate 'failure' -> take slow-path.\n-    crandc(flag, Assembler::equal, flag, Assembler::equal);\n-    b(failure);\n-  }\n@@ -2692,2 +2690,2 @@\n-  bind(cas_failed);\n-  \/\/ We did not see an unlocked object so try the fast recursive case.\n+    bind(cas_failed);\n+    \/\/ We did not see an unlocked object so try the fast recursive case.\n@@ -2695,4 +2693,4 @@\n-  \/\/ Check if the owner is self by comparing the value in the markWord of object\n-  \/\/ (current_header) with the stack pointer.\n-  sub(current_header, current_header, R1_SP);\n-  load_const_optimized(temp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);\n+    \/\/ Check if the owner is self by comparing the value in the markWord of object\n+    \/\/ (current_header) with the stack pointer.\n+    sub(current_header, current_header, R1_SP);\n+    load_const_optimized(temp, ~(os::vm_page_size()-1) | markWord::lock_mask_in_place);\n@@ -2700,5 +2698,4 @@\n-  and_(R0\/*==0?*\/, current_header, temp);\n-  \/\/ If condition is true we are cont and hence we can store 0 as the\n-  \/\/ displaced header in the box, which indicates that it is a recursive lock.\n-  mcrf(flag,CCR0);\n-  std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), box);\n+    and_(R0\/*==0?*\/, current_header, temp);\n+    \/\/ If condition is true we are cont and hence we can store 0 as the\n+    \/\/ displaced header in the box, which indicates that it is a recursive lock.\n+    std(R0\/*==0, perhaps*\/, BasicLock::displaced_header_offset_in_bytes(), box);\n@@ -2706,1 +2703,10 @@\n-  b(cont);\n+    if (flag != CCR0) {\n+      mcrf(flag, CCR0);\n+    }\n+    beq(CCR0, success);\n+    b(failure);\n+  } else {\n+    assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+    fast_lock(oop, displaced_header, temp, failure);\n+    b(success);\n+  }\n@@ -2717,1 +2723,2 @@\n-                         rtm_counters, method_data, profile_rtm, cont);\n+                         rtm_counters, method_data, profile_rtm, success);\n+    bne(flag, failure);\n@@ -2731,2 +2738,4 @@\n-  \/\/ Store a non-null value into the box.\n-  std(box, BasicLock::displaced_header_offset_in_bytes(), box);\n+  if (LockingMode != LM_LIGHTWEIGHT) {\n+    \/\/ Store a non-null value into the box.\n+    std(box, BasicLock::displaced_header_offset_in_bytes(), box);\n+  }\n@@ -2749,1 +2758,0 @@\n-  bind(cont);\n@@ -2752,1 +2760,0 @@\n-  bne(flag, failure);\n@@ -2762,3 +2769,2 @@\n-  assert(flag != CCR0, \"bad condition register\");\n-  Label object_has_monitor, notRecursive;\n-  Label success, failure;\n+  assert(LockingMode != LM_LIGHTWEIGHT || flag == CCR0, \"bad condition register\");\n+  Label success, failure, object_has_monitor, notRecursive;\n@@ -2779,1 +2785,1 @@\n-  if (LockingMode != LM_MONITOR) {\n+  if (LockingMode == LM_LEGACY) {\n@@ -2795,1 +2801,5 @@\n-  if (LockingMode != LM_MONITOR) {\n+  if (LockingMode == LM_MONITOR) {\n+    \/\/ Set NE to indicate 'failure' -> take slow-path.\n+    crandc(flag, Assembler::equal, flag, Assembler::equal);\n+    b(failure);\n+  } else if (LockingMode == LM_LEGACY) {\n@@ -2811,3 +2821,3 @@\n-    \/\/ Set NE to indicate 'failure' -> take slow-path.\n-    crandc(flag, Assembler::equal, flag, Assembler::equal);\n-    b(failure);\n+    assert(LockingMode == LM_LIGHTWEIGHT, \"must be\");\n+    fast_unlock(oop, current_header, failure);\n+    b(success);\n@@ -2822,1 +2832,1 @@\n-    \/\/ It's inflated.\n+  \/\/ It's inflated.\n@@ -2835,2 +2845,2 @@\n-  ld(displaced_header, in_bytes(ObjectMonitor::recursions_offset()), current_header);\n-\n+  \/\/ In case of LM_LIGHTWEIGHT, we may reach here with (temp & ObjectMonitor::ANONYMOUS_OWNER) != 0.\n+  \/\/ This is handled like owner thread mismatches: We take the slow path.\n@@ -2840,0 +2850,2 @@\n+  ld(displaced_header, in_bytes(ObjectMonitor::recursions_offset()), current_header);\n+\n@@ -2843,1 +2855,4 @@\n-  b(success); \/\/ flag is already EQ here.\n+  if (flag == CCR0) { \/\/ Otherwise, flag is already EQ, here.\n+    crorc(CCR0, Assembler::equal, CCR0, Assembler::equal); \/\/ Set CCR0 EQ\n+  }\n+  b(success);\n@@ -4413,0 +4428,1 @@\n+\/\/ Note: Must preserve CCR0 EQ (invariant).\n@@ -4421,0 +4437,1 @@\n+  crorc(CCR0, Assembler::equal, CCR0, Assembler::equal); \/\/ Restore CCR0 EQ\n@@ -4426,0 +4443,1 @@\n+\/\/ Note: Must preserve CCR0 EQ (invariant).\n@@ -4434,0 +4452,1 @@\n+  crorc(CCR0, Assembler::equal, CCR0, Assembler::equal); \/\/ Restore CCR0 EQ\n@@ -4438,0 +4457,128 @@\n+\n+\/\/ Function to flip between unlocked and locked state (fast locking).\n+\/\/ Branches to failed if the state is not as expected with CCR0 NE.\n+\/\/ Falls through upon success with CCR0 EQ.\n+\/\/ This requires fewer instructions and registers and is easier to use than the\n+\/\/ cmpxchg based implementation.\n+void MacroAssembler::atomically_flip_locked_state(bool is_unlock, Register obj, Register tmp, Label& failed, int semantics) {\n+  assert_different_registers(obj, tmp, R0);\n+  Label retry;\n+\n+  if (semantics & MemBarRel) {\n+    release();\n+  }\n+\n+  bind(retry);\n+  STATIC_ASSERT(markWord::locked_value == 0); \/\/ Or need to change this!\n+  if (!is_unlock) {\n+    ldarx(tmp, obj, MacroAssembler::cmpxchgx_hint_acquire_lock());\n+    xori(tmp, tmp, markWord::unlocked_value); \/\/ flip unlocked bit\n+    andi_(R0, tmp, markWord::lock_mask_in_place);\n+    bne(CCR0, failed); \/\/ failed if new header doesn't contain locked_value (which is 0)\n+  } else {\n+    ldarx(tmp, obj, MacroAssembler::cmpxchgx_hint_release_lock());\n+    andi_(R0, tmp, markWord::lock_mask_in_place);\n+    bne(CCR0, failed); \/\/ failed if old header doesn't contain locked_value (which is 0)\n+    ori(tmp, tmp, markWord::unlocked_value); \/\/ set unlocked bit\n+  }\n+  stdcx_(tmp, obj);\n+  bne(CCR0, retry);\n+\n+  if (semantics & MemBarFenceAfter) {\n+    fence();\n+  } else if (semantics & MemBarAcq) {\n+    isync();\n+  }\n+}\n+\n+\/\/ Implements fast-locking.\n+\/\/ Branches to slow upon failure to lock the object, with CCR0 NE.\n+\/\/ Falls through upon success with CCR0 EQ.\n+\/\/\n+\/\/  - obj: the object to be locked\n+\/\/  - hdr: the header, already loaded from obj, will be destroyed\n+\/\/  - t1: temporary register\n+void MacroAssembler::fast_lock(Register obj, Register hdr, Register t1, Label& slow) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only used with new lightweight locking\");\n+  assert_different_registers(obj, hdr, t1);\n+\n+  \/\/ Check if we would have space on lock-stack for the object.\n+  lwz(t1, in_bytes(JavaThread::lock_stack_top_offset()), R16_thread);\n+  cmplwi(CCR0, t1, LockStack::end_offset() - 1);\n+  bgt(CCR0, slow);\n+\n+  \/\/ Quick check: Do not reserve cache line for atomic update if not unlocked.\n+  \/\/ (Similar to contention_hint in cmpxchg solutions.)\n+  xori(R0, hdr, markWord::unlocked_value); \/\/ flip unlocked bit\n+  andi_(R0, R0, markWord::lock_mask_in_place);\n+  bne(CCR0, slow); \/\/ failed if new header doesn't contain locked_value (which is 0)\n+\n+  \/\/ Note: We're not publishing anything (like the displaced header in LM_LEGACY)\n+  \/\/ to other threads at this point. Hence, no release barrier, here.\n+  \/\/ (The obj has been written to the BasicObjectLock at obj_offset() within the own thread stack.)\n+  atomically_flip_locked_state(\/* is_unlock *\/ false, obj, hdr, slow, MacroAssembler::MemBarAcq);\n+\n+  \/\/ After successful lock, push object on lock-stack\n+  stdx(obj, t1, R16_thread);\n+  addi(t1, t1, oopSize);\n+  stw(t1, in_bytes(JavaThread::lock_stack_top_offset()), R16_thread);\n+}\n+\n+\/\/ Implements fast-unlocking.\n+\/\/ Branches to slow upon failure, with CCR0 NE.\n+\/\/ Falls through upon success, with CCR0 EQ.\n+\/\/\n+\/\/ - obj: the object to be unlocked\n+\/\/ - hdr: the (pre-loaded) header of the object, will be destroyed\n+void MacroAssembler::fast_unlock(Register obj, Register hdr, Label& slow) {\n+  assert(LockingMode == LM_LIGHTWEIGHT, \"only used with new lightweight locking\");\n+  assert_different_registers(obj, hdr);\n+\n+#ifdef ASSERT\n+  {\n+    \/\/ Check that hdr is fast-locked.\n+    Label hdr_ok;\n+    andi_(R0, hdr, markWord::lock_mask_in_place);\n+    beq(CCR0, hdr_ok);\n+    stop(\"Header is not fast-locked\");\n+    bind(hdr_ok);\n+  }\n+  Register t1 = hdr; \/\/ Reuse in debug build.\n+  {\n+    \/\/ The following checks rely on the fact that LockStack is only ever modified by\n+    \/\/ its owning thread, even if the lock got inflated concurrently; removal of LockStack\n+    \/\/ entries after inflation will happen delayed in that case.\n+\n+    \/\/ Check for lock-stack underflow.\n+    Label stack_ok;\n+    lwz(t1, in_bytes(JavaThread::lock_stack_top_offset()), R16_thread);\n+    cmplwi(CCR0, t1, LockStack::start_offset());\n+    bgt(CCR0, stack_ok);\n+    stop(\"Lock-stack underflow\");\n+    bind(stack_ok);\n+  }\n+  {\n+    \/\/ Check if the top of the lock-stack matches the unlocked object.\n+    Label tos_ok;\n+    addi(t1, t1, -oopSize);\n+    ldx(t1, t1, R16_thread);\n+    cmpd(CCR0, t1, obj);\n+    beq(CCR0, tos_ok);\n+    stop(\"Top of lock-stack does not match the unlocked object\");\n+    bind(tos_ok);\n+  }\n+#endif\n+\n+  \/\/ Release the lock.\n+  atomically_flip_locked_state(\/* is_unlock *\/ true, obj, hdr, slow, MacroAssembler::MemBarRel);\n+\n+  \/\/ After successful unlock, pop object from lock-stack\n+  Register t2 = hdr;\n+  lwz(t2, in_bytes(JavaThread::lock_stack_top_offset()), R16_thread);\n+  addi(t2, t2, -oopSize);\n+#ifdef ASSERT\n+  li(R0, 0);\n+  stdx(R0, t2, R16_thread);\n+#endif\n+  stw(t2, in_bytes(JavaThread::lock_stack_top_offset()), R16_thread);\n+}\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.cpp","additions":185,"deletions":38,"binary":false,"changes":223,"status":"modified"},{"patch":"@@ -609,0 +609,3 @@\n+  void atomically_flip_locked_state(bool is_unlock, Register obj, Register tmp, Label& failed, int semantics);\n+  void fast_lock(Register obj, Register hdr, Register t1, Label& slow);\n+  void fast_unlock(Register obj, Register hdr, Label& slow);\n","filename":"src\/hotspot\/cpu\/ppc\/macroAssembler_ppc.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -12142,1 +12142,1 @@\n-instruct cmpFastLock(flagsReg crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2) %{\n+instruct cmpFastLock(flagsRegCR0 crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2) %{\n@@ -12178,1 +12178,1 @@\n-instruct cmpFastUnlock(flagsReg crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2, iRegPdst tmp3) %{\n+instruct cmpFastUnlock(flagsRegCR0 crx, iRegPdst oop, iRegPdst box, iRegPdst tmp1, iRegPdst tmp2, iRegPdst tmp3) %{\n","filename":"src\/hotspot\/cpu\/ppc\/ppc.ad","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -397,0 +397,4 @@\n+    if (LockingMode != LM_LEGACY) {\n+      warning(\"UseRTMLocking requires LockingMode = 1\");\n+      FLAG_SET_DEFAULT(UseRTMLocking, false);\n+    }\n","filename":"src\/hotspot\/cpu\/ppc\/vm_version_ppc.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1908,1 +1908,1 @@\n-#if !defined(X86) && !defined(AARCH64) && !defined(RISCV64) && !defined(ARM)\n+#if !defined(X86) && !defined(AARCH64) && !defined(RISCV64) && !defined(ARM) && !defined(PPC64)\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}