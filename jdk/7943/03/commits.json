[{"commit":{"message":"Merge jdk:master\n\nChange-Id: I88b8b132a33a4156e15ff3a83efe26c1406d8c5b"},"files":[{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp"},{"filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp"},{"filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp"},{"filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py"},{"filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h"}],"sha":"8e5f1a283e9958480ba987efc9a6c5354fc6d35c"},{"commit":{"message":"refine m4\n\nChange-Id: Ic24da50fc1f49e2552de6d8ba6bac987ab976f96"},"files":[{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4"}],"sha":"deb296bc5708b6c64c59b28734d02a58bf21e8da"},{"commit":{"message":"Merge jdk:master\n\nChange-Id: Ica9cef4d72eda1ab814c5d2f86998e9b4da863ce"},"files":[{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp"},{"filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp"},{"filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py"},{"filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h"}],"sha":"03368397788f7a96079679b33cf4fcbac7a4b987"},{"commit":{"message":"8283435: AArch64: [vectorapi] Optimize SVE lane\/withLane operations for 64\/128-bit vector sizes\n\nThis patch optimizes the SVE backend implementations of Vector.lane and\nVector.withLane for 64\/128-bit vector size. The basic idea is to use\nlower costs NEON instructions when the vector size is 64\/128 bits.\n\n1. Vector.lane(int i) (Gets the lane element at lane index i)\n\nAs SVE doesnâ€™t have direct instruction support for extraction like\n\"pextr\"[1] in x86, the final code was shown as below:\n\n```\n        Byte512Vector.lane(7)\n\n        orr     x8, xzr, #0x7\n        whilele p0.b, xzr, x8\n        lastb   w10, p0, z16.b\n        sxtb    w10, w10\n```\n\nThis patch uses NEON instruction instead if the target lane is located\nin the NEON 128b range. For the same example above, the generated code\nnow is much simpler:\n\n```\n        smov    x11, v16.b[7]\n```\n\nFor those cases that target lane is located out of the NEON 128b range,\nthis patch uses EXT to shift the target to the lowest. The generated\ncode is as below:\n\n```\n        Byte512Vector.lane(63)\n\n        mov     z17.d, z16.d\n        ext     z17.b, z17.b, z17.b, #63\n        smov    x10, v17.b[0]\n```\n\n2. Vector.withLane(int i, E e) (Replaces the lane element of this vector\n                                at lane index i with value e)\n\nFor 64\/128-bit vector, insert operation could be implemented by NEON\ninstructions to get better performance. E.g., for IntVector.SPECIES_128,\n\"IntVector.withLane(0, (int)4)\" generates code as below:\n\n```\n        Before:\n        orr     w10, wzr, #0x4\n        index   z17.s, #-16, #1\n        cmpeq   p0.s, p7\/z, z17.s, #-16\n        mov     z17.d, z16.d\n        mov     z17.s, p0\/m, w10\n\n        After\n        orr     w10, wzr, #0x4\n        mov     v16.s[0], w10\n```\n\nThis patch also does a small enhancement for vectors whose sizes are\ngreater than 128 bits. It can save 1 \"DUP\" if the target index is\nsmaller than 32. E.g., For ByteVector.SPECIES_512,\n\"ByteVector.withLane(0, (byte)4)\" generates code as below:\n\n```\n        Before:\n        index   z18.b, #0, #1\n        mov     z17.b, #0\n        cmpeq   p0.b, p7\/z, z18.b, z17.b\n        mov     z17.d, z16.d\n        mov     z17.b, p0\/m, w16\n\n        After:\n        index   z17.b, #-16, #1\n        cmpeq   p0.b, p7\/z, z17.b, #-16\n        mov     z17.d, z16.d\n        mov     z17.b, p0\/m, w16\n```\n\nWith this patch, we can see up to 200% performance gain for specific\nvector micro benchmarks in my SVE testing system.\n\n[TEST]\ntest\/jdk\/jdk\/incubator\/vector, test\/hotspot\/jtreg\/compiler\/vectorapi\npassed without failure.\n\n[1] https:\/\/www.felixcloutier.com\/x86\/pextrb:pextrd:pextrq\n\nChange-Id: Ic2a48f852011978d0f252db040371431a339d73c"},"files":[{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp"},{"filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp"},{"filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp"},{"filename":"test\/hotspot\/gtest\/aarch64\/aarch64-asmtest.py"},{"filename":"test\/hotspot\/gtest\/aarch64\/asmtest.out.h"}],"sha":"cab5da784c4c2b94aaca6f201f8e731c9db1e841"}]