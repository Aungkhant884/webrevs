{"files":[{"patch":"@@ -218,5 +218,0 @@\n-      case Op_VectorLoadConst:\n-        if (is_floating_point_type(bt)) {\n-          return false;\n-        }\n-        break;\n@@ -466,1 +461,0 @@\n-  predicate(is_integral_type(Matcher::vector_element_basic_type(n)));\n@@ -474,1 +468,1 @@\n-      \/\/ The offset based on the iota indices stub for B\/H\/S\/D is 0\/16\/32\/48.\n+      \/\/ The iota indices are ordered by type B\/S\/I\/L\/F\/D, and the offset between two types is 16.\n@@ -476,0 +470,3 @@\n+      if (is_floating_point_type(bt)) {\n+        offset += 32;\n+      }\n@@ -485,0 +482,3 @@\n+      if (is_floating_point_type(bt)) {\n+        __ sve_scvtf($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister, size);\n+      }\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -208,5 +208,0 @@\n-      case Op_VectorLoadConst:\n-        if (is_floating_point_type(bt)) {\n-          return false;\n-        }\n-        break;\n@@ -405,1 +400,0 @@\n-  predicate(is_integral_type(Matcher::vector_element_basic_type(n)));\n@@ -413,1 +407,1 @@\n-      \/\/ The offset based on the iota indices stub for B\/H\/S\/D is 0\/16\/32\/48.\n+      \/\/ The iota indices are ordered by type B\/S\/I\/L\/F\/D, and the offset between two types is 16.\n@@ -415,0 +409,3 @@\n+      if (is_floating_point_type(bt)) {\n+        offset += 32;\n+      }\n@@ -424,0 +421,3 @@\n+      if (is_floating_point_type(bt)) {\n+        __ sve_scvtf($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister, size);\n+      }\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -645,0 +645,6 @@\n+    \/\/ S - FP\n+    __ emit_data64(0x3F80000000000000, relocInfo::none); \/\/ 0.0f, 1.0f\n+    __ emit_data64(0x4040000040000000, relocInfo::none); \/\/ 2.0f, 3.0f\n+    \/\/ D - FP\n+    __ emit_data64(0x0000000000000000, relocInfo::none); \/\/ 0.0d\n+    __ emit_data64(0x3FF0000000000000, relocInfo::none); \/\/ 1.0d\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -1695,1 +1695,1 @@\n-  \/\/ The offset based on the iota indices stub for B\/W\/D\/Q is 0\/64\/128\/256.\n+  \/\/ The iota indices are ordered by type B\/S\/I\/L\/F\/D, and the offset between two types is 64.\n@@ -1697,0 +1697,3 @@\n+  if (is_floating_point_type(bt)) {\n+    offset += 128;\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -850,0 +850,18 @@\n+  \/\/ D - FP\n+  __ emit_data64(0x3F80000000000000, relocInfo::none); \/\/ 0.0f, 1.0f\n+  __ emit_data64(0x4040000040000000, relocInfo::none); \/\/ 2.0f, 3.0f\n+  __ emit_data64(0x40A0000040800000, relocInfo::none); \/\/ 4.0f, 5.0f\n+  __ emit_data64(0x40E0000040C00000, relocInfo::none); \/\/ 6.0f, 7.0f\n+  __ emit_data64(0x4110000041000000, relocInfo::none); \/\/ 8.0f, 9.0f\n+  __ emit_data64(0x4130000041200000, relocInfo::none); \/\/ 10.0f, 11.0f\n+  __ emit_data64(0x4150000041400000, relocInfo::none); \/\/ 12.0f, 13.0f\n+  __ emit_data64(0x4170000041600000, relocInfo::none); \/\/ 14.0f, 15.0f\n+  \/\/ Q - FP\n+  __ emit_data64(0x0000000000000000, relocInfo::none); \/\/ 0.0d\n+  __ emit_data64(0x3FF0000000000000, relocInfo::none); \/\/ 1.0d\n+  __ emit_data64(0x4000000000000000, relocInfo::none); \/\/ 2.0d\n+  __ emit_data64(0x4008000000000000, relocInfo::none); \/\/ 3.0d\n+  __ emit_data64(0x4010000000000000, relocInfo::none); \/\/ 4.0d\n+  __ emit_data64(0x4014000000000000, relocInfo::none); \/\/ 5.0d\n+  __ emit_data64(0x4018000000000000, relocInfo::none); \/\/ 6.0d\n+  __ emit_data64(0x401c000000000000, relocInfo::none); \/\/ 7.0d\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":18,"deletions":0,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -1995,5 +1995,0 @@\n-    case Op_VectorLoadConst:\n-      if (is_floating_point_type(bt)) {\n-        return false;\n-      }\n-      break;\n@@ -8408,1 +8403,0 @@\n-  predicate(is_integral_type(Matcher::vector_element_basic_type(n)));\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2890,5 +2890,0 @@\n-  BasicType iota_bt = elem_bt;\n-  \/\/ The iota indices are integral type\n-  if (is_floating_point_type(elem_bt)) {\n-    iota_bt = elem_bt == T_FLOAT ? T_INT : T_LONG;\n-  }\n@@ -2896,10 +2891,2 @@\n-  \/\/ Get the vector add\/mul op based on the basic element type\n-  int add_op = VectorSupport::vop2ideal(VectorSupport::VECTOR_OP_ADD, elem_bt);\n-  int mul_op = VectorSupport::vop2ideal(VectorSupport::VECTOR_OP_MUL, elem_bt);\n-  int vadd_op = VectorNode::opcode(add_op, elem_bt);\n-  int vmul_op = VectorNode::opcode(mul_op, elem_bt);\n-\n-  \/\/ Check whether the basic ops are supported by the current hardware\n-  if (!arch_supports_vector(Op_VectorLoadConst, num_elem, iota_bt, VecMaskNotUsed) ||\n-      !arch_supports_vector(vmul_op, num_elem, elem_bt, VecMaskNotUsed) ||\n-      !arch_supports_vector(vadd_op, num_elem, elem_bt, VecMaskNotUsed)) {\n+  \/\/ Check whether the iota index generation op is supported by the current hardware\n+  if (!arch_supports_vector(Op_VectorLoadConst, num_elem, elem_bt, VecMaskNotUsed)) {\n@@ -2912,5 +2899,11 @@\n-  \/\/ If it is a floating point type vector, additionally check whether the\n-  \/\/ relative vector cast op is supported by the current hardware\n-  if (is_floating_point_type(elem_bt)) {\n-    int vcast_op = elem_bt == T_FLOAT ? Op_VectorCastI2X : Op_VectorCastL2X;\n-    if (!arch_supports_vector(vcast_op, num_elem, elem_bt, VecMaskNotUsed)) {\n+  int mul_op = VectorSupport::vop2ideal(VectorSupport::VECTOR_OP_MUL, elem_bt);\n+  int vmul_op = VectorNode::opcode(mul_op, elem_bt);\n+  bool needs_mul = true;\n+  Node* scale = argument(4);\n+  const TypeInt* scale_type = gvn().type(scale)->isa_int();\n+  \/\/ Multiply is not needed if the scale is a constant \"1\".\n+  if (scale_type && scale_type->is_con() && scale_type->get_con() == 1) {\n+    needs_mul = false;\n+  } else {\n+    \/\/ Check whether the vector multiply op is supported by the current hardware\n+    if (!arch_supports_vector(vmul_op, num_elem, elem_bt, VecMaskNotUsed)) {\n@@ -2922,0 +2915,13 @@\n+\n+    \/\/ Check whether the scalar cast op is supported by the current hardware\n+    if (is_floating_point_type(elem_bt) || elem_bt == T_LONG) {\n+      int cast_op = elem_bt == T_LONG ? Op_ConvI2L :\n+                    elem_bt == T_FLOAT? Op_ConvI2F : Op_ConvI2D;\n+      if (!Matcher::match_rule_supported(cast_op)) {\n+        if (C->print_intrinsics()) {\n+          tty->print_cr(\"  ** Rejected op (%s) because architecture does not support it\",\n+                        NodeClassNames[cast_op]);\n+        }\n+        return false; \/\/ not supported\n+      }\n+    }\n@@ -2935,0 +2941,16 @@\n+  int add_op = VectorSupport::vop2ideal(VectorSupport::VECTOR_OP_ADD, elem_bt);\n+  int vadd_op = VectorNode::opcode(add_op, elem_bt);\n+  bool needs_add = true;\n+  \/\/ The addition is not needed if all the element values of \"opd\" are zero\n+  if (VectorNode::is_all_zeros_vector(opd)) {\n+    needs_add = false;\n+  } else {\n+    \/\/ Check whether the vector addition op is supported by the current hardware\n+    if (!arch_supports_vector(vadd_op, num_elem, elem_bt, VecMaskNotUsed)) {\n+      if (C->print_intrinsics()) {\n+        tty->print_cr(\"  ** not supported: vlen=%d etype=%s\", num_elem, type2name(elem_bt));\n+      }\n+      return false; \/\/ not supported\n+    }\n+  }\n+\n@@ -2937,7 +2959,1 @@\n-  const TypeVect* iota_vt = TypeVect::make(iota_bt, num_elem);\n-  Node* iota = gvn().transform(new VectorLoadConstNode(gvn().makecon(TypeInt::ZERO), iota_vt));\n-  if (elem_bt == T_FLOAT) {\n-    iota = gvn().transform(new VectorCastI2XNode(iota, vt));\n-  } else if (elem_bt == T_DOUBLE) {\n-    iota = gvn().transform(new VectorCastL2XNode(iota, vt));\n-  }\n+  Node* index = gvn().transform(new VectorLoadConstNode(gvn().makecon(TypeInt::ZERO), vt));\n@@ -2945,8 +2961,2 @@\n-  Node* index = NULL;\n-  Node* scale = argument(4);\n-  const TypeInt* scale_type = gvn().type(scale)->isa_int();\n-  if (scale_type && scale_type->is_con() && scale_type->get_con() == 1) {\n-    index = iota;\n-  } else {\n-    \/\/ Multiply the \"scale\" with \"iota\" if it is not \"1\".\n-    \/\/ Broadcast the \"scale\" to a vector\n+  \/\/ Broadcast the \"scale\" to a vector, and multiply the \"scale\" with iota indice vector.\n+  if (needs_mul) {\n@@ -2971,2 +2981,1 @@\n-        scale = gvn().transform(new ConvI2LNode(scale));\n-        scale = gvn().transform(new ConvL2DNode(scale));\n+        scale = gvn().transform(new ConvI2DNode(scale));\n@@ -2978,1 +2987,1 @@\n-    index = gvn().transform(VectorNode::make(vmul_op, iota, scale, vt));\n+    index = gvn().transform(VectorNode::make(vmul_op, index, scale, vt));\n@@ -2981,2 +2990,2 @@\n-  \/\/ Add \"opd\" if it is not a zero vector.\n-  if (!VectorNode::is_all_zeros_vector(opd)) {\n+  \/\/ Add \"opd\" if addition is needed.\n+  if (needs_add) {\n","filename":"src\/hotspot\/share\/opto\/vectorIntrinsics.cpp","additions":49,"deletions":40,"binary":false,"changes":89,"status":"modified"}]}