{"files":[{"patch":"@@ -5072,1 +5072,1 @@\n-instruct vshiftcnt8B(vecD dst, iRegIorL2I cnt) %{\n+instruct lvshiftcnt8B(vecD dst, iRegIorL2I cnt) %{\n@@ -5075,1 +5075,1 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n@@ -5083,1 +5083,1 @@\n-instruct vshiftcnt16B(vecX dst, iRegIorL2I cnt) %{\n+instruct lvshiftcnt16B(vecX dst, iRegIorL2I cnt) %{\n@@ -5085,1 +5085,1 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n@@ -5093,0 +5093,25 @@\n+instruct rvshiftcnt8B(vecD dst, iRegIorL2I cnt, vecD tmp) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 4 ||\n+            n->as_Vector()->length_in_bytes() == 8);\n+  match(Set dst (RShiftCntV cnt));\n+  effect(TEMP tmp);\n+  format %{ \"dup  $dst, $cnt\\t# shift count vector (8B)\" %}\n+  ins_encode %{\n+    __ dup(as_FloatRegister($tmp$$reg), __ T8B, as_Register($cnt$$reg));\n+    __ negr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(vdup_reg_reg64);\n+%}\n+\n+instruct rvshiftcnt16B(vecX dst, iRegIorL2I cnt, vecX tmp) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 16);\n+  match(Set dst (RShiftCntV cnt));\n+  effect(TEMP tmp);\n+  format %{ \"dup  $dst, $cnt\\t# shift count vector (16B)\" %}\n+  ins_encode %{\n+    __ dup(as_FloatRegister($tmp$$reg), __ T16B, as_Register($cnt$$reg));\n+    __ negr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(vdup_reg_reg128);\n+%}\n+\n@@ -5126,1 +5151,1 @@\n-\/\/    LoadVector  ShiftCntV\n+\/\/    LoadVector  RShiftCntV\n@@ -5133,1 +5158,2 @@\n-\/\/ This case is used by Vector API(JEP 338).\n+\/\/ This case isn't supported by middle-end now. But it's supported by\n+\/\/ panama\/vectorIntrinsics(JEP 338: Vector API).\n@@ -5140,1 +5166,1 @@\n-instruct vsra8B(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsra8B(vecD dst, vecD src, vecD shift) %{\n@@ -5145,3 +5171,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (8B)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (8B)\" %}\n@@ -5149,2 +5173,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n@@ -5153,1 +5175,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5158,1 +5180,1 @@\n-instruct vsra16B(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra16B(vecX dst, vecX src, vecX shift) %{\n@@ -5162,3 +5184,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (16B)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (16B)\" %}\n@@ -5166,2 +5186,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5170,1 +5188,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5175,1 +5193,1 @@\n-instruct vsrl8B(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsrl8B(vecD dst, vecD src, vecD shift) %{\n@@ -5180,3 +5198,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (8B)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (8B)\" %}\n@@ -5184,2 +5200,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n@@ -5188,1 +5202,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5193,1 +5207,1 @@\n-instruct vsrl16B(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsrl16B(vecX dst, vecX src, vecX shift) %{\n@@ -5197,3 +5211,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (16B)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (16B)\" %}\n@@ -5201,2 +5213,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5205,1 +5215,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5213,1 +5223,1 @@\n-  match(Set dst (LShiftVB src (ShiftCntV shift)));\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n@@ -5232,1 +5242,1 @@\n-  match(Set dst (LShiftVB src (ShiftCntV shift)));\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n@@ -5252,1 +5262,1 @@\n-  match(Set dst (RShiftVB src (ShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -5266,1 +5276,1 @@\n-  match(Set dst (RShiftVB src (ShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -5281,1 +5291,1 @@\n-  match(Set dst (URShiftVB src (ShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n@@ -5300,1 +5310,1 @@\n-  match(Set dst (URShiftVB src (ShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n@@ -5344,1 +5354,1 @@\n-instruct vsra4S(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsra4S(vecD dst, vecD src, vecD shift) %{\n@@ -5349,3 +5359,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (4H)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (4H)\" %}\n@@ -5353,2 +5361,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n@@ -5357,1 +5363,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5362,1 +5368,1 @@\n-instruct vsra8S(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra8S(vecX dst, vecX src, vecX shift) %{\n@@ -5366,3 +5372,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (8H)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (8H)\" %}\n@@ -5370,2 +5374,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5374,1 +5376,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5379,1 +5381,1 @@\n-instruct vsrl4S(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsrl4S(vecD dst, vecD src, vecD shift) %{\n@@ -5384,3 +5386,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (4H)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (4H)\" %}\n@@ -5388,2 +5388,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n@@ -5392,1 +5390,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5397,1 +5395,1 @@\n-instruct vsrl8S(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsrl8S(vecX dst, vecX src, vecX shift) %{\n@@ -5401,3 +5399,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (8H)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (8H)\" %}\n@@ -5405,2 +5401,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5409,1 +5403,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5417,1 +5411,1 @@\n-  match(Set dst (LShiftVS src (ShiftCntV shift)));\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n@@ -5436,1 +5430,1 @@\n-  match(Set dst (LShiftVS src (ShiftCntV shift)));\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n@@ -5456,1 +5450,1 @@\n-  match(Set dst (RShiftVS src (ShiftCntV shift)));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -5470,1 +5464,1 @@\n-  match(Set dst (RShiftVS src (ShiftCntV shift)));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -5485,1 +5479,1 @@\n-  match(Set dst (URShiftVS src (ShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -5504,1 +5498,1 @@\n-  match(Set dst (URShiftVS src (ShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -5547,1 +5541,1 @@\n-instruct vsra2I(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsra2I(vecD dst, vecD src, vecD shift) %{\n@@ -5551,3 +5545,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (2S)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (2S)\" %}\n@@ -5555,2 +5547,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n@@ -5559,1 +5549,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5564,1 +5554,1 @@\n-instruct vsra4I(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra4I(vecX dst, vecX src, vecX shift) %{\n@@ -5568,3 +5558,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (4S)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (4S)\" %}\n@@ -5572,2 +5560,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5576,1 +5562,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5581,1 +5567,1 @@\n-instruct vsrl2I(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsrl2I(vecD dst, vecD src, vecD shift) %{\n@@ -5585,3 +5571,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (2S)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (2S)\" %}\n@@ -5589,2 +5573,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T8B,\n-            as_FloatRegister($shift$$reg));\n@@ -5593,1 +5575,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5598,1 +5580,1 @@\n-instruct vsrl4I(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsrl4I(vecX dst, vecX src, vecX shift) %{\n@@ -5602,3 +5584,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (4S)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (4S)\" %}\n@@ -5606,2 +5586,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5610,1 +5588,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5617,1 +5595,1 @@\n-  match(Set dst (LShiftVI src (ShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n@@ -5630,1 +5608,1 @@\n-  match(Set dst (LShiftVI src (ShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n@@ -5643,1 +5621,1 @@\n-  match(Set dst (RShiftVI src (ShiftCntV shift)));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -5656,1 +5634,1 @@\n-  match(Set dst (RShiftVI src (ShiftCntV shift)));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -5669,1 +5647,1 @@\n-  match(Set dst (URShiftVI src (ShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -5682,1 +5660,1 @@\n-  match(Set dst (URShiftVI src (ShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -5706,1 +5684,1 @@\n-instruct vsra2L(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra2L(vecX dst, vecX src, vecX shift) %{\n@@ -5710,3 +5688,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"sshl  $dst,$src,$tmp\\t# vector (2D)\" %}\n+  format %{ \"sshl  $dst,$src,$shift\\t# vector (2D)\" %}\n@@ -5714,2 +5690,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5718,1 +5692,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5723,1 +5697,1 @@\n-instruct vsrl2L(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsrl2L(vecX dst, vecX src, vecX shift) %{\n@@ -5727,3 +5701,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"negr  $tmp,$shift\\t\"\n-            \"ushl  $dst,$src,$tmp\\t# vector (2D)\" %}\n+  format %{ \"ushl  $dst,$src,$shift\\t# vector (2D)\" %}\n@@ -5731,2 +5703,0 @@\n-    __ negr(as_FloatRegister($tmp$$reg), __ T16B,\n-            as_FloatRegister($shift$$reg));\n@@ -5735,1 +5705,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -5742,1 +5712,1 @@\n-  match(Set dst (LShiftVL src (ShiftCntV shift)));\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n@@ -5755,1 +5725,1 @@\n-  match(Set dst (RShiftVL src (ShiftCntV shift)));\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n@@ -5768,1 +5738,1 @@\n-  match(Set dst (URShiftVL src (ShiftCntV shift)));\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n@@ -5781,1 +5751,1 @@\n-  match(Set dst (AddVB dst (RShiftVB src (ShiftCntV shift))));\n+  match(Set dst (AddVB dst (RShiftVB src (RShiftCntV shift))));\n@@ -5795,1 +5765,1 @@\n-  match(Set dst (AddVB dst (RShiftVB src (ShiftCntV shift))));\n+  match(Set dst (AddVB dst (RShiftVB src (RShiftCntV shift))));\n@@ -5809,1 +5779,1 @@\n-  match(Set dst (AddVS dst (RShiftVS src (ShiftCntV shift))));\n+  match(Set dst (AddVS dst (RShiftVS src (RShiftCntV shift))));\n@@ -5823,1 +5793,1 @@\n-  match(Set dst (AddVS dst (RShiftVS src (ShiftCntV shift))));\n+  match(Set dst (AddVS dst (RShiftVS src (RShiftCntV shift))));\n@@ -5837,1 +5807,1 @@\n-  match(Set dst (AddVI dst (RShiftVI src (ShiftCntV shift))));\n+  match(Set dst (AddVI dst (RShiftVI src (RShiftCntV shift))));\n@@ -5850,1 +5820,1 @@\n-  match(Set dst (AddVI dst (RShiftVI src (ShiftCntV shift))));\n+  match(Set dst (AddVI dst (RShiftVI src (RShiftCntV shift))));\n@@ -5863,1 +5833,1 @@\n-  match(Set dst (AddVL dst (RShiftVL src (ShiftCntV shift))));\n+  match(Set dst (AddVL dst (RShiftVL src (RShiftCntV shift))));\n@@ -5876,1 +5846,1 @@\n-  match(Set dst (AddVB dst (URShiftVB src (ShiftCntV shift))));\n+  match(Set dst (AddVB dst (URShiftVB src (RShiftCntV shift))));\n@@ -5891,1 +5861,1 @@\n-  match(Set dst (AddVB dst (URShiftVB src (ShiftCntV shift))));\n+  match(Set dst (AddVB dst (URShiftVB src (RShiftCntV shift))));\n@@ -5906,1 +5876,1 @@\n-  match(Set dst (AddVS dst (URShiftVS src (ShiftCntV shift))));\n+  match(Set dst (AddVS dst (URShiftVS src (RShiftCntV shift))));\n@@ -5921,1 +5891,1 @@\n-  match(Set dst (AddVS dst (URShiftVS src (ShiftCntV shift))));\n+  match(Set dst (AddVS dst (URShiftVS src (RShiftCntV shift))));\n@@ -5936,1 +5906,1 @@\n-  match(Set dst (AddVI dst (URShiftVI src (ShiftCntV shift))));\n+  match(Set dst (AddVI dst (URShiftVI src (RShiftCntV shift))));\n@@ -5949,1 +5919,1 @@\n-  match(Set dst (AddVI dst (URShiftVI src (ShiftCntV shift))));\n+  match(Set dst (AddVI dst (URShiftVI src (RShiftCntV shift))));\n@@ -5962,1 +5932,1 @@\n-  match(Set dst (AddVL dst (URShiftVL src (ShiftCntV shift))));\n+  match(Set dst (AddVL dst (URShiftVL src (RShiftCntV shift))));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":109,"deletions":139,"binary":false,"changes":248,"status":"modified"},{"patch":"@@ -1929,2 +1929,2 @@\n-define(`VSHIFTCNT', `\n-instruct vshiftcnt$3$4`'(vec$5 dst, iRegIorL2I cnt) %{\n+define(`LVSHIFTCNT', `\n+instruct lvshiftcnt$3$4`'(vec$5 dst, iRegIorL2I cnt) %{\n@@ -1933,1 +1933,1 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n@@ -1941,2 +1941,19 @@\n-VSHIFTCNT(dup, dup, 8,  B, D)\n-VSHIFTCNT(dup, dup, 16, B, X)\n+LVSHIFTCNT(dup, dup, 8,  B, D)\n+LVSHIFTCNT(dup, dup, 16, B, X)\n+dnl\n+define(`RVSHIFTCNT', `\n+instruct rvshiftcnt$3$4`'(vec$5 dst, iRegIorL2I cnt, vec$5 tmp) %{\n+  predicate(ifelse($3, 8, n->as_Vector()->length_in_bytes() == 4 ||`\n+            ')n->as_Vector()->length_in_bytes() == $3);\n+  match(Set dst (RShiftCntV cnt));\n+  effect(TEMP tmp);\n+  format %{ \"$1  $dst, $cnt\\t# shift count vector ($3$4)\" %}\n+  ins_encode %{\n+    __ $2(as_FloatRegister($tmp$$reg), __ T$3$4, as_Register($cnt$$reg));\n+    __ negr(as_FloatRegister($dst$$reg), __ T$3$4, as_FloatRegister($tmp$$reg));\n+  %}\n+  ins_pipe(vdup_reg_reg`'ifelse($5, D, 64, 128));\n+%}')dnl\n+dnl       $1   $2   $3  $4 $5\n+RVSHIFTCNT(dup, dup, 8,  B, D)\n+RVSHIFTCNT(dup, dup, 16, B, X)\n@@ -1962,2 +1979,2 @@\n-instruct vsra$3$4`'(vec$6 dst, vec$6 src, vec$6 shift, vec$6 tmp) %{\n-  predicate(ifelse($3$4, 8B, n->as_Vector()->length() == 4 ||`\n+instruct vsra$2$3`'(vec$5 dst, vec$5 src, vec$5 shift) %{\n+  predicate(ifelse($2$3, 8B, n->as_Vector()->length() == 4 ||`\n@@ -1965,3 +1982,3 @@\n-  $3$4, 4S, n->as_Vector()->length() == 2 ||`\n-            ')n->as_Vector()->length() == $3);\n-  match(Set dst (RShiftV$4 src shift));\n+  $2$3, 4S, n->as_Vector()->length() == 2 ||`\n+            ')n->as_Vector()->length() == $2);\n+  match(Set dst (RShiftV$3 src shift));\n@@ -1969,3 +1986,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"$1  $tmp,$shift\\t\"\n-            \"$2  $dst,$src,$tmp\\t# vector ($3$5)\" %}\n+  format %{ \"$1  $dst,$src,$shift\\t# vector ($2$4)\" %}\n@@ -1973,3 +1988,1 @@\n-    __ $1(as_FloatRegister($tmp$$reg), __ T`'ifelse($6, D, 8B, 16B),\n-            as_FloatRegister($shift$$reg));\n-    __ $2(as_FloatRegister($dst$$reg), __ T$3$5,\n+    __ $1(as_FloatRegister($dst$$reg), __ T$2$4,\n@@ -1977,1 +1990,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -1979,1 +1992,1 @@\n-  ins_pipe(vshift`'ifelse($6, D, 64, 128));\n+  ins_pipe(vshift`'ifelse($5, D, 64, 128));\n@@ -1983,2 +1996,2 @@\n-instruct vsrl$3$4`'(vec$6 dst, vec$6 src, vec$6 shift, vec$6 tmp) %{\n-  predicate(ifelse($3$4, 8B, n->as_Vector()->length() == 4 ||`\n+instruct vsrl$2$3`'(vec$5 dst, vec$5 src, vec$5 shift) %{\n+  predicate(ifelse($2$3, 8B, n->as_Vector()->length() == 4 ||`\n@@ -1986,3 +1999,3 @@\n-  $3$4, 4S, n->as_Vector()->length() == 2 ||`\n-            ')n->as_Vector()->length() == $3);\n-  match(Set dst (URShiftV$4 src shift));\n+  $2$3, 4S, n->as_Vector()->length() == 2 ||`\n+            ')n->as_Vector()->length() == $2);\n+  match(Set dst (URShiftV$3 src shift));\n@@ -1990,3 +2003,1 @@\n-  effect(TEMP tmp);\n-  format %{ \"$1  $tmp,$shift\\t\"\n-            \"$2  $dst,$src,$tmp\\t# vector ($3$5)\" %}\n+  format %{ \"$1  $dst,$src,$shift\\t# vector ($2$4)\" %}\n@@ -1994,3 +2005,1 @@\n-    __ $1(as_FloatRegister($tmp$$reg), __ T`'ifelse($6, D, 8B, 16B),\n-            as_FloatRegister($shift$$reg));\n-    __ $2(as_FloatRegister($dst$$reg), __ T$3$5,\n+    __ $1(as_FloatRegister($dst$$reg), __ T$2$4,\n@@ -1998,1 +2007,1 @@\n-            as_FloatRegister($tmp$$reg));\n+            as_FloatRegister($shift$$reg));\n@@ -2000,1 +2009,1 @@\n-  ins_pipe(vshift`'ifelse($6, D, 64, 128));\n+  ins_pipe(vshift`'ifelse($5, D, 64, 128));\n@@ -2009,1 +2018,1 @@\n-  match(Set dst (LShiftV$4 src (ShiftCntV shift)));\n+  match(Set dst (LShiftV$4 src (LShiftCntV shift)));\n@@ -2043,1 +2052,1 @@\n-  match(Set dst (RShiftV$4 src (ShiftCntV shift)));\n+  match(Set dst (RShiftV$4 src (RShiftCntV shift)));\n@@ -2068,1 +2077,1 @@\n-  match(Set dst (URShiftV$4 src (ShiftCntV shift)));\n+  match(Set dst (URShiftV$4 src (RShiftCntV shift)));\n@@ -2100,1 +2109,1 @@\n-  match(Set dst (AddV$4 dst (URShiftV$4 src (ShiftCntV shift))));\n+  match(Set dst (AddV$4 dst (URShiftV$4 src (RShiftCntV shift))));\n@@ -2124,1 +2133,1 @@\n-  match(Set dst (AddV$4 dst (RShiftV$4 src (ShiftCntV shift))));\n+  match(Set dst (AddV$4 dst (RShiftV$4 src (RShiftCntV shift))));\n@@ -2152,1 +2161,1 @@\n-\/\/    LoadVector  ShiftCntV\n+\/\/    LoadVector  RShiftCntV\n@@ -2167,4 +2176,4 @@\n-VSRA(negr, sshl, 8,  B, B, D)\n-VSRA(negr, sshl, 16, B, B, X)\n-VSRL(negr, ushl, 8,  B, B, D)\n-VSRL(negr, ushl, 16, B, B, X)\n+VSRA(sshl, 8,  B, B, D)\n+VSRA(sshl, 16, B, B, X)\n+VSRL(ushl, 8,  B, B, D)\n+VSRL(ushl, 16, B, B, X)\n@@ -2179,4 +2188,4 @@\n-VSRA(negr, sshl, 4,  S, H, D)\n-VSRA(negr, sshl, 8,  S, H, X)\n-VSRL(negr, ushl, 4,  S, H, D)\n-VSRL(negr, ushl, 8,  S, H, X)\n+VSRA(sshl, 4,  S, H, D)\n+VSRA(sshl, 8,  S, H, X)\n+VSRL(ushl, 4,  S, H, D)\n+VSRL(ushl, 8,  S, H, X)\n@@ -2191,4 +2200,4 @@\n-VSRA(negr, sshl, 2,  I, S, D)\n-VSRA(negr, sshl, 4,  I, S, X)\n-VSRL(negr, ushl, 2,  I, S, D)\n-VSRL(negr, ushl, 4,  I, S, X)\n+VSRA(sshl, 2,  I, S, D)\n+VSRA(sshl, 4,  I, S, X)\n+VSRL(ushl, 2,  I, S, D)\n+VSRL(ushl, 4,  I, S, X)\n@@ -2202,2 +2211,2 @@\n-VSRA(negr, sshl, 2,  L, D, X)\n-VSRL(negr, ushl, 2,  L, D, X)\n+VSRA(sshl, 2,  L, D, X)\n+VSRL(ushl, 2,  L, D, X)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":60,"deletions":51,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -1333,1 +1333,1 @@\n-  match(Set dst (RShiftVB src (ShiftCntV shift)));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n@@ -1352,1 +1352,1 @@\n-  match(Set dst (RShiftVS src (ShiftCntV shift)));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n@@ -1371,1 +1371,1 @@\n-  match(Set dst (RShiftVI src (ShiftCntV shift)));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n@@ -1389,1 +1389,1 @@\n-  match(Set dst (RShiftVL src (ShiftCntV shift)));\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n@@ -1407,1 +1407,1 @@\n-  match(Set dst (URShiftVB src (ShiftCntV shift)));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n@@ -1430,1 +1430,1 @@\n-  match(Set dst (URShiftVS src (ShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -1453,1 +1453,1 @@\n-  match(Set dst (URShiftVI src (ShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -1471,1 +1471,1 @@\n-  match(Set dst (URShiftVL src (ShiftCntV shift)));\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n@@ -1489,1 +1489,1 @@\n-  match(Set dst (LShiftVB src (ShiftCntV shift)));\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n@@ -1507,1 +1507,1 @@\n-  match(Set dst (LShiftVS src (ShiftCntV shift)));\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n@@ -1525,1 +1525,1 @@\n-  match(Set dst (LShiftVI src (ShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n@@ -1538,1 +1538,1 @@\n-  match(Set dst (LShiftVL src (ShiftCntV shift)));\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n@@ -1552,1 +1552,2 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n@@ -1564,1 +1565,2 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n@@ -1575,1 +1577,2 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n@@ -1586,1 +1589,2 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":20,"deletions":16,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -806,1 +806,2 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n@@ -827,12 +828,12 @@\n-VSHIFT_IMM_UNPREDICATE(vasrB_imm, RShiftVB,  ShiftCntV, B, 16, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vasrS_imm, RShiftVS,  ShiftCntV, H,  8, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vasrI_imm, RShiftVI,  ShiftCntV, S,  4, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vasrL_imm, RShiftVL,  ShiftCntV, D,  2, sve_asr)\n-VSHIFT_IMM_UNPREDICATE(vlsrB_imm, URShiftVB, ShiftCntV, B, 16, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlsrS_imm, URShiftVS, ShiftCntV, H,  8, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlsrI_imm, URShiftVI, ShiftCntV, S,  4, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlsrL_imm, URShiftVL, ShiftCntV, D,  2, sve_lsr)\n-VSHIFT_IMM_UNPREDICATE(vlslB_imm, LShiftVB,  ShiftCntV, B, 16, sve_lsl)\n-VSHIFT_IMM_UNPREDICATE(vlslS_imm, LShiftVS,  ShiftCntV, H,  8, sve_lsl)\n-VSHIFT_IMM_UNPREDICATE(vlslI_imm, LShiftVI,  ShiftCntV, S,  4, sve_lsl)\n-VSHIFT_IMM_UNPREDICATE(vlslL_imm, LShiftVL,  ShiftCntV, D,  2, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vasrB_imm, RShiftVB,  RShiftCntV, B, 16, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vasrS_imm, RShiftVS,  RShiftCntV, H,  8, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vasrI_imm, RShiftVI,  RShiftCntV, S,  4, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vasrL_imm, RShiftVL,  RShiftCntV, D,  2, sve_asr)\n+VSHIFT_IMM_UNPREDICATED(vlsrB_imm, URShiftVB, RShiftCntV, B, 16, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlsrS_imm, URShiftVS, RShiftCntV, H,  8, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlsrI_imm, URShiftVI, RShiftCntV, S,  4, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlsrL_imm, URShiftVL, RShiftCntV, D,  2, sve_lsr)\n+VSHIFT_IMM_UNPREDICATED(vlslB_imm, LShiftVB,  LShiftCntV, B, 16, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vlslS_imm, LShiftVS,  LShiftCntV, H,  8, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vlslI_imm, LShiftVI,  LShiftCntV, S,  4, sve_lsl)\n+VSHIFT_IMM_UNPREDICATED(vlslL_imm, LShiftVL,  LShiftCntV, D,  2, sve_lsl)\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":14,"deletions":13,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -936,1 +936,2 @@\n-  case Op_ShiftCntV:\n+  case Op_LShiftCntV:\n+  case Op_RShiftCntV:\n@@ -10401,0 +10402,31 @@\n+\/\/ --------------------------------- NEG --------------------------------------\n+\n+instruct vneg8B_reg(vecD dst, vecD src) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 8);\n+  effect(DEF dst, USE src);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{ \"VNEG.S8 $dst.D,$src.D\\t! neg packed8B\" %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vnegI($dst$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+instruct vneg16B_reg(vecX dst, vecX src) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 16);\n+  effect(DEF dst, USE src);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{ \"VNEG.S8 $dst.Q,$src.Q\\t! neg0 packed16B\" %}\n+  ins_encode %{\n+    bool _float = false;\n+    bool quad = true;\n+    __ vnegI($dst$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n@@ -10403,1 +10435,1 @@\n-instruct vscntD(vecD dst, iRegI cnt) %{\n+instruct vslcntD(vecD dst, iRegI cnt) %{\n@@ -10405,1 +10437,1 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n@@ -10413,1 +10445,1 @@\n-instruct vscntX(vecX dst, iRegI cnt) %{\n+instruct vslcntX(vecX dst, iRegI cnt) %{\n@@ -10415,1 +10447,1 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n@@ -10423,1 +10455,7 @@\n-\/\/ ------------------------------ LeftShift -----------------------------------\n+\/\/ Low bits of vector \"shift\" elements are used, so it\n+\/\/ doesn't matter if we treat it as ints or bytes here.\n+instruct vsrcntD(vecD dst, iRegI cnt) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 8 && VM_Version::has_simd());\n+  match(Set dst (RShiftCntV cnt));\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n@@ -10425,2 +10463,31 @@\n-\/\/ Byte vector left shift\n-instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{\n+  format %{ \"VDUP.8 $dst.D,$cnt\\n\\t\"\n+            \"VNEG.S8 $dst.D,$dst.D\\t! neg packed8B\" %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vdupI($dst$$FloatRegister, $cnt$$Register,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+instruct vsrcntX(vecX dst, iRegI cnt) %{\n+  predicate(n->as_Vector()->length_in_bytes() == 16 && VM_Version::has_simd());\n+  match(Set dst (RShiftCntV cnt));\n+  size(4*2);\n+  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  format %{ \"VDUP.8 $dst.Q,$cnt\\n\\t\"\n+            \"VNEG.S8 $dst.Q,$dst.Q\\t! neg packed16B\" %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vdupI($dst$$FloatRegister, $cnt$$Register,\n+             MacroAssembler::VELEM_SIZE_8, quad);\n+    __ vnegI($dst$$FloatRegister, $dst$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+\/\/ Byte vector logical left\/right shift based on sign\n+instruct vsh8B_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10428,1 +10495,1 @@\n-  match(Set dst (LShiftVB src shift));\n+  effect(DEF dst, USE src, USE shift);\n@@ -10432,1 +10499,1 @@\n-    \"VSHL.U8 $dst.D,$src.D,$shift.D\\t! logical left shift packed8B\"\n+    \"VSHL.U8 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed8B\"\n@@ -10435,0 +10502,1 @@\n+    bool quad = false;\n@@ -10436,1 +10504,1 @@\n-              MacroAssembler::VELEM_SIZE_8, false);\n+              MacroAssembler::VELEM_SIZE_8, quad);\n@@ -10438,2 +10506,1 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n@@ -10442,1 +10509,1 @@\n-instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{\n+instruct vsh16B_reg(vecX dst, vecX src, vecX shift) %{\n@@ -10444,1 +10511,1 @@\n-  match(Set dst (LShiftVB src shift));\n+  effect(DEF dst, USE src, USE shift);\n@@ -10448,1 +10515,1 @@\n-    \"VSHL.U8 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed16B\"\n+    \"VSHL.U8 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed16B\"\n@@ -10451,0 +10518,1 @@\n+    bool quad = true;\n@@ -10452,1 +10520,1 @@\n-              MacroAssembler::VELEM_SIZE_8, true);\n+              MacroAssembler::VELEM_SIZE_8, quad);\n@@ -10454,1 +10522,1 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n@@ -10457,3 +10525,4 @@\n-instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVB src (ShiftCntV shift)));\n+\/\/ Shorts\/Char vector logical left\/right shift based on sign\n+instruct vsh4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  effect(DEF dst, USE src, USE shift);\n@@ -10463,1 +10532,1 @@\n-    \"VSHL.I8 $dst.D,$src.D,$shift\\t! logical left shift packed8B\"\n+    \"VSHL.U16 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed4S\"\n@@ -10467,2 +10536,2 @@\n-    __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,\n-             quad);\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n@@ -10473,3 +10542,3 @@\n-instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (LShiftVB src (ShiftCntV shift)));\n+instruct vsh8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  effect(DEF dst, USE src, USE shift);\n@@ -10479,1 +10548,1 @@\n-    \"VSHL.I8 $dst.Q,$src.Q,$shift\\t! logical left shift packed16B\"\n+    \"VSHL.U16 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed8S\"\n@@ -10483,2 +10552,2 @@\n-    __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,\n-             quad);\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n@@ -10489,4 +10558,4 @@\n-\/\/ Shorts\/Chars vector logical left\/right shift\n-instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (LShiftVS src shift));\n+\/\/ Integers vector logical left\/right shift based on sign\n+instruct vsh2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2);\n+  effect(DEF dst, USE src, USE shift);\n@@ -10496,1 +10565,1 @@\n-    \"VSHL.U16 $dst.D,$src.D,$shift.D\\t! logical left shift packed4S\"\n+    \"VSHL.U32 $dst.D,$src.D,$shift.D\\t! logical left\/right shift packed2I\"\n@@ -10499,0 +10568,1 @@\n+    bool quad = false;\n@@ -10500,1 +10570,1 @@\n-              MacroAssembler::VELEM_SIZE_16, false);\n+              MacroAssembler::VELEM_SIZE_32, quad);\n@@ -10502,1 +10572,1 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n@@ -10505,1 +10575,1 @@\n-instruct vsr4S_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsh4I_reg(vecX dst, vecX src, vecX shift) %{\n@@ -10507,4 +10577,3 @@\n-  match(Set dst (URShiftVS src shift));\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n@@ -10512,3 +10581,1 @@\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.U16 $dst.D,$src.D,$tmp.D\\t! logical left shift packed4S\"\n+    \"VSHL.U32 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed4I\"\n@@ -10517,3 +10584,3 @@\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, false);\n-    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, false);\n+    bool quad = true;\n+    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n@@ -10521,1 +10588,1 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n@@ -10524,3 +10591,4 @@\n-instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (LShiftVS src shift));\n+\/\/ Longs vector logical left\/right shift based on sign\n+instruct vsh2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2);\n+  effect(DEF dst, USE src, USE shift);\n@@ -10530,1 +10598,1 @@\n-    \"VSHL.U16 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed8S\"\n+    \"VSHL.U64 $dst.Q,$src.Q,$shift.Q\\t! logical left\/right shift packed2L\"\n@@ -10533,0 +10601,1 @@\n+    bool quad = true;\n@@ -10534,1 +10603,1 @@\n-              MacroAssembler::VELEM_SIZE_16, true);\n+              MacroAssembler::VELEM_SIZE_64, quad);\n@@ -10536,1 +10605,2 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n@@ -10538,0 +10608,11 @@\n+\/\/ ------------------------------ LeftShift -----------------------------------\n+\n+\/\/ Byte vector left shift\n+instruct vsl8B_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  match(Set dst (LShiftVB src shift));\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh8B_reg(dst, src, shift);\n+  %}\n@@ -10540,1 +10621,11 @@\n-instruct vsr8S_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsl16B_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 16);\n+  match(Set dst (LShiftVB src shift));\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh16B_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsl8B_immI(vecD dst, vecD src, immI shift) %{\n@@ -10542,4 +10633,3 @@\n-  match(Set dst (URShiftVS src shift));\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n@@ -10547,3 +10637,1 @@\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.U16 $dst.Q,$src.Q,$tmp.Q\\t! logical left shift packed8S\"\n+    \"VSHL.I8 $dst.D,$src.D,$shift\\t! logical left shift packed8B\"\n@@ -10552,3 +10640,3 @@\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, true);\n-    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, true);\n+    bool quad = false;\n+    __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,\n+             quad);\n@@ -10556,1 +10644,17 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+instruct vsl16B_immI(vecX dst, vecX src, immI shift) %{\n+  predicate(n->as_Vector()->length() == 16);\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.I8 $dst.Q,$src.Q,$shift\\t! logical left shift packed16B\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshli($dst$$FloatRegister, $src$$FloatRegister, 8, $shift$$constant,\n+             quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n@@ -10559,0 +10663,22 @@\n+\/\/ Shorts\/Chars vector logical left\/right shift\n+instruct vsl4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  match(Set dst (LShiftVS src shift));\n+  match(Set dst (URShiftVS src shift));\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh4S_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsl8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  match(Set dst (LShiftVS src shift));\n+  match(Set dst (URShiftVS src shift));\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh8S_reg(dst, src, shift);\n+  %}\n+%}\n@@ -10562,1 +10688,1 @@\n-  match(Set dst (LShiftVS src (ShiftCntV shift)));\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n@@ -10596,15 +10722,0 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U32 $dst.D,$src.D,$shift.D\\t! logical left shift packed2I\"\n-  %}\n-  ins_encode %{\n-    bool quad = false;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, false);\n-  %}\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-%}\n-\n-instruct vsr2I_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n-  predicate(n->as_Vector()->length() == 2 && VM_Version::has_simd());\n@@ -10612,12 +10723,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.U32 $dst.D,$src.D,$tmp.D\\t! logical left shift packed2I\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, false);\n-    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, false);\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh2I_reg(dst, src, shift);\n@@ -10625,1 +10728,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10628,1 +10730,0 @@\n-\n@@ -10632,15 +10733,0 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U32 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed4I\"\n-  %}\n-  ins_encode %{\n-    bool quad = true;\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, quad);\n-  %}\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-%}\n-\n-instruct vsr4I_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 4 && VM_Version::has_simd());\n@@ -10648,12 +10734,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.U32 $dst.Q,$src.Q,$tmp.Q\\t! logical left shift packed4I\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, false);\n-    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, true);\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh4I_reg(dst, src, shift);\n@@ -10661,1 +10739,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n@@ -10664,1 +10741,0 @@\n-\n@@ -10667,1 +10743,1 @@\n-  match(Set dst (LShiftVI src (ShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n@@ -10683,1 +10759,1 @@\n-  match(Set dst (LShiftVI src (ShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n@@ -10701,15 +10777,0 @@\n-  size(4);\n-  ins_cost(DEFAULT_COST); \/\/ FIXME\n-  format %{\n-    \"VSHL.U64 $dst.Q,$src.Q,$shift.Q\\t! logical left shift packed2L\"\n-  %}\n-  ins_encode %{\n-    __ vshlUI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_64, true);\n-  %}\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n-%}\n-\n-instruct vsr2L_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n-  predicate(n->as_Vector()->length() == 2);\n@@ -10717,12 +10778,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.U64 $dst.Q,$src.Q,$tmp.Q\\t! logical left shift packed2L\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, true);\n-    __ vshlUI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_64, true);\n+  size(4*1);\n+  ins_cost(DEFAULT_COST*1); \/\/ FIXME\n+  expand %{\n+    vsh2L_reg(dst, src, shift);\n@@ -10730,2 +10783,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n@@ -10736,1 +10787,1 @@\n-  match(Set dst (LShiftVL src (ShiftCntV shift)));\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n@@ -10759,1 +10810,1 @@\n-  match(Set dst (URShiftVS src (ShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -10775,1 +10826,1 @@\n-  match(Set dst (URShiftVS src (ShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n@@ -10792,1 +10843,1 @@\n-  match(Set dst (URShiftVI src (ShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -10808,1 +10859,1 @@\n-  match(Set dst (URShiftVI src (ShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -10825,1 +10876,1 @@\n-  match(Set dst (URShiftVL src (ShiftCntV shift)));\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n@@ -10841,3 +10892,2 @@\n-\/\/ Byte vector arithmetic right shift\n-\n-instruct vsra8B_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+\/\/ Bytes vector arithmetic left\/right shift based on sign\n+instruct vsha8B_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10845,4 +10895,3 @@\n-  match(Set dst (RShiftVB src shift));\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n@@ -10850,3 +10899,1 @@\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.S8 $dst.D,$src.D,$tmp.D\\t! arithmetic left shift packed8B\"\n+    \"VSHL.S8 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed8B\"\n@@ -10855,3 +10902,3 @@\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, false);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_8, false);\n+    bool quad = false;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n@@ -10859,1 +10906,1 @@\n-  ins_pipe(ialu_reg_reg);\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n@@ -10862,1 +10909,1 @@\n-instruct vsrl16B_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsha16B_reg(vecX dst, vecX src, vecX shift) %{\n@@ -10864,4 +10911,3 @@\n-  match(Set dst (RShiftVB src shift));\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n@@ -10869,3 +10915,1 @@\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.Q,$shift.Q\\t! neg packed16B\\n\\t\"\n-    \"VSHL.S8 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic left shift packed16B\"\n+    \"VSHL.S8 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed16B\"\n@@ -10874,3 +10918,109 @@\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, true);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_8, true);\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_8, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+\/\/ Shorts vector arithmetic left\/right shift based on sign\n+instruct vsha4S_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S16 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed4S\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+instruct vsha8S_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S16 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed8S\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_16, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+\/\/ Integers vector arithmetic left\/right shift based on sign\n+instruct vsha2I_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 2);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S32 $dst.D,$src.D,$shift.D\\t! arithmetic right shift packed2I\"\n+  %}\n+  ins_encode %{\n+    bool quad = false;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+instruct vsha4I_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 4);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S32 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed4I\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_32, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+\/\/ Longs vector arithmetic left\/right shift based on sign\n+instruct vsha2L_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 2);\n+  effect(DEF dst, USE src, USE shift);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  format %{\n+    \"VSHL.S64 $dst.Q,$src.Q,$shift.Q\\t! arithmetic right shift packed2L\"\n+  %}\n+  ins_encode %{\n+    bool quad = true;\n+    __ vshlSI($dst$$FloatRegister, $shift$$FloatRegister, $src$$FloatRegister,\n+              MacroAssembler::VELEM_SIZE_64, quad);\n+  %}\n+  ins_pipe( ialu_reg_reg ); \/\/ FIXME\n+%}\n+\n+\/\/ Byte vector arithmetic right shift\n+\n+instruct vsra8B_reg(vecD dst, vecD src, vecD shift) %{\n+  predicate(n->as_Vector()->length() == 8);\n+  match(Set dst (RShiftVB src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha8B_reg(dst, src, shift);\n+  %}\n+%}\n+\n+instruct vsrl16B_reg(vecX dst, vecX src, vecX shift) %{\n+  predicate(n->as_Vector()->length() == 16);\n+  match(Set dst (RShiftVB src shift));\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha16B_reg(dst, src, shift);\n@@ -10878,1 +11028,0 @@\n-  ins_pipe(ialu_reg_reg);\n@@ -10914,1 +11063,1 @@\n-instruct vsra4S_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsra4S_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10917,12 +11066,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.S16 $dst.D,$src.D,$tmp.D\\t! arithmetic left shift packed4S\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, false);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, false);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha4S_reg(dst, src, shift);\n@@ -10930,2 +11071,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n@@ -10934,1 +11073,1 @@\n-instruct vsra8S_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra8S_reg(vecX dst, vecX src, vecX shift) %{\n@@ -10937,12 +11076,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.Q,$shift.Q\\t! neg packed16B\\n\\t\"\n-    \"VSHL.S16 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic left shift packed8S\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, true);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_16, true);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha8S_reg(dst, src, shift);\n@@ -10950,2 +11081,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n@@ -10987,1 +11116,1 @@\n-instruct vsra2I_reg(vecD dst, vecD src, vecD shift, vecD tmp) %{\n+instruct vsra2I_reg(vecD dst, vecD src, vecD shift) %{\n@@ -10990,12 +11119,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.D,$shift.D\\t! neg packed8B\\n\\t\"\n-    \"VSHL.S32 $dst.D,$src.D,$tmp.D\\t! arithmetic left shift packed2I\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, false);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, false);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha2I_reg(dst, src, shift);\n@@ -11003,2 +11124,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n@@ -11007,1 +11126,1 @@\n-instruct vsra4I_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra4I_reg(vecX dst, vecX src, vecX shift) %{\n@@ -11010,12 +11129,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.Q,$shift.Q\\t! neg packed16B\\n\\t\"\n-    \"VSHL.S32 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic left shift packed4I\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, true);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_32, true);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha4I_reg(dst, src, shift);\n@@ -11023,2 +11134,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n@@ -11060,1 +11169,1 @@\n-instruct vsra2L_reg(vecX dst, vecX src, vecX shift, vecX tmp) %{\n+instruct vsra2L_reg(vecX dst, vecX src, vecX shift) %{\n@@ -11063,12 +11172,4 @@\n-  effect(TEMP tmp);\n-  size(4*2);\n-  ins_cost(DEFAULT_COST*2); \/\/ FIXME\n-  format %{\n-    \"\/\/ Right shift with vector shift count is implemented as left shift by negative shift count\\n\\t\"\n-    \"VNEG.S8 $tmp.Q,$shift.Q\\t! neg packed16B\\n\\t\"\n-    \"VSHL.S64 $dst.Q,$src.Q,$tmp.Q\\t! arithmetic left shift packed2L\"\n-  %}\n-  ins_encode %{\n-    __ vnegI($tmp$$FloatRegister, $shift$$FloatRegister, MacroAssembler::VELEM_SIZE_8, true);\n-    __ vshlSI($dst$$FloatRegister, $tmp$$FloatRegister, $src$$FloatRegister,\n-              MacroAssembler::VELEM_SIZE_64, true);\n+  size(4);\n+  ins_cost(DEFAULT_COST); \/\/ FIXME\n+  expand %{\n+    vsha2L_reg(dst, src, shift);\n@@ -11076,3 +11177,0 @@\n-  ins_pipe(ialu_reg_reg); \/\/ FIXME\n-\n-\n","filename":"src\/hotspot\/cpu\/arm\/arm.ad","additions":363,"deletions":265,"binary":false,"changes":628,"status":"modified"},{"patch":"@@ -5830,1 +5830,2 @@\n-  match(Set dst (ShiftCntV cnt));\n+  match(Set dst (LShiftCntV cnt));\n+  match(Set dst (RShiftCntV cnt));\n@@ -6023,3 +6024,3 @@\n-  match(Set dst (LShiftVI src (ShiftCntV shift)));\n-  match(Set dst (RShiftVI src (ShiftCntV shift)));\n-  match(Set dst (URShiftVI src (ShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n@@ -6070,2 +6071,2 @@\n-  match(Set dst (LShiftVL src (ShiftCntV shift)));\n-  match(Set dst (URShiftVL src (ShiftCntV shift)));\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -4188,1 +4188,1 @@\n-    \"ShiftCntV\",\n+    \"LShiftCntV\",\"RShiftCntV\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -385,1 +385,2 @@\n-macro(ShiftCntV)\n+macro(LShiftCntV)\n+macro(RShiftCntV)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -351,1 +351,7 @@\n-  return is_vector_shift_count(n->Opcode());\n+  switch (n->Opcode()) {\n+  case Op_LShiftCntV:\n+  case Op_RShiftCntV:\n+    return true;\n+  default:\n+    return false;\n+  }\n@@ -556,2 +562,17 @@\n-  assert(is_shift_opcode(opc), \"Missed vector creation for '%s'\", NodeClassNames[opc]);\n-  return new ShiftCntVNode(cnt, TypeVect::make(bt, vlen));\n+  \/\/ Match shift count type with shift vector type.\n+  const TypeVect* vt = TypeVect::make(bt, vlen);\n+  switch (opc) {\n+  case Op_LShiftI:\n+  case Op_LShiftL:\n+    return new LShiftCntVNode(cnt, vt);\n+  case Op_RShiftI:\n+  case Op_RShiftL:\n+  case Op_URShiftB:\n+  case Op_URShiftS:\n+  case Op_URShiftI:\n+  case Op_URShiftL:\n+    return new RShiftCntVNode(cnt, vt);\n+  default:\n+    fatal(\"Missed vector creation for '%s'\", NodeClassNames[opc]);\n+    return NULL;\n+  }\n@@ -583,1 +604,7 @@\n-  return opc == Op_ShiftCntV;\n+  switch (opc) {\n+  case Op_RShiftCntV:\n+  case Op_LShiftCntV:\n+    return true;\n+  default:\n+    return false;\n+  }\n@@ -1137,2 +1164,2 @@\n-  shiftLCnt = phase->transform(new ShiftCntVNode(shiftLCnt, vt));\n-  shiftRCnt = phase->transform(new ShiftCntVNode(shiftRCnt, vt));\n+  shiftLCnt = phase->transform(new LShiftCntVNode(shiftLCnt, vt));\n+  shiftRCnt = phase->transform(new RShiftCntVNode(shiftRCnt, vt));\n","filename":"src\/hotspot\/share\/opto\/vectornode.cpp","additions":33,"deletions":6,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -628,3 +628,3 @@\n-\/\/------------------------------ShiftCntVNode---------------------------------\n-\/\/ Vector shift count\n-class ShiftCntVNode : public VectorNode {\n+\/\/------------------------------LShiftCntVNode---------------------------------\n+\/\/ Vector left shift count\n+class LShiftCntVNode : public VectorNode {\n@@ -632,1 +632,9 @@\n-  ShiftCntVNode(Node* cnt, const TypeVect* vt) : VectorNode(cnt,vt) {}\n+  LShiftCntVNode(Node* cnt, const TypeVect* vt) : VectorNode(cnt,vt) {}\n+  virtual int Opcode() const;\n+};\n+\n+\/\/------------------------------RShiftCntVNode---------------------------------\n+\/\/ Vector right shift count\n+class RShiftCntVNode : public VectorNode {\n+ public:\n+  RShiftCntVNode(Node* cnt, const TypeVect* vt) : VectorNode(cnt,vt) {}\n","filename":"src\/hotspot\/share\/opto\/vectornode.hpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"}]}