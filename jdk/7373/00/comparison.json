{"files":[{"patch":"@@ -166,0 +166,6 @@\n+  \/\/ Returns pre-selection estimated cost of a vector operation.\n+  static int vector_op_cost(int vopc, BasicType ety, int vlen) {\n+    return 1;\n+  }\n+\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/matcher_aarch64.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -158,0 +158,5 @@\n+  \/\/ Returns pre-selection estimated cost of a vector operation.\n+  static int vector_op_cost(int vopc, BasicType ety, int vlen) {\n+    return 1;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/arm\/matcher_arm.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -167,0 +167,6 @@\n+  \/\/ Returns pre-selection estimated cost of a vector operation.\n+  static int vector_op_cost(int vopc, BasicType ety, int vlen) {\n+    return 1;\n+  }\n+\n+\n","filename":"src\/hotspot\/cpu\/ppc\/matcher_ppc.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -156,0 +156,5 @@\n+  \/\/ Returns pre-selection estimated cost of a vector operation.\n+  static int vector_op_cost(int vopc, BasicType ety, int vlen) {\n+    return 1;\n+  }\n+\n","filename":"src\/hotspot\/cpu\/s390\/matcher_s390.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -8311,0 +8311,21 @@\n+void Assembler::vpsadbw(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ _legacy_mode_bw, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16((unsigned char)0xF6, (0xC0 | encode));\n+}\n+\n+void Assembler::vpunpckhdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ _legacy_mode_bw, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x6A, (0xC0 | encode));\n+}\n+\n+void Assembler::vpunpckldq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len) {\n+  assert(UseAVX > 0, \"requires some form of AVX\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ _legacy_mode_bw, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x62, (0xC0 | encode));\n+}\n+\n@@ -8312,0 +8333,35 @@\n+void Assembler::evpsadbw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  assert(VM_Version::supports_avx512bw() && (vector_len == AVX_512bit || VM_Version::supports_avx512vl()), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16((unsigned char)0xF6, (0xC0 | encode));\n+}\n+\n+void Assembler::evpunpckldq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  assert(vector_len == AVX_512bit || VM_Version::supports_avx512vl(), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x62, (0xC0 | encode));\n+}\n+\n+void Assembler::evpunpckhdq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len) {\n+  assert(vector_len == AVX_512bit || VM_Version::supports_avx512vl(), \"\");\n+  InstructionAttr attributes(vector_len, \/* vex_w *\/ false, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ false,\/* uses_vl *\/ true);\n+  attributes.set_is_evex_instruction();\n+  attributes.set_embedded_opmask_register_specifier(mask);\n+  if (merge) {\n+    attributes.reset_is_clear_context();\n+  }\n+  int encode = vex_prefix_and_encode(dst->encoding(), nds->encoding(), src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16(0x6A, (0xC0 | encode));\n+}\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":56,"deletions":0,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -1937,0 +1937,6 @@\n+  void vpunpckldq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evpunpckldq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+\n+  \/\/ Interleave High Doublewords\n+  void vpunpckhdq(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evpunpckhdq(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n@@ -1941,0 +1947,4 @@\n+  \/\/ Vector sum of absolute difference.\n+  void vpsadbw(XMMRegister dst, XMMRegister nds, XMMRegister src, int vector_len);\n+  void evpsadbw(XMMRegister dst, KRegister mask, XMMRegister nds, XMMRegister src, bool merge, int vector_len);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -4277,0 +4277,72 @@\n+\n+void C2_MacroAssembler::vector_popcount_int(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                            XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp,\n+                                            int vec_enc) {\n+  if (VM_Version::supports_avx512_vpopcntdq()) {\n+    vpopcntd(dst, src, vec_enc);\n+  } else if (vec_enc == Assembler::AVX_512bit) {\n+    assert(VM_Version::supports_avx512vlbw(), \"\");\n+    movl(rtmp, 0x0F0F0F0F);\n+    evpbroadcastd(xtmp1, rtmp, vec_enc);\n+    evmovdqul(xtmp2, k0, ExternalAddress(StubRoutines::x86::vector_popcount_lut()), true, vec_enc, rtmp);\n+    evpandd(xtmp3, k0, src, xtmp1, true, vec_enc);\n+    vpshufb(xtmp3, xtmp2, xtmp3, vec_enc);\n+    Assembler::evpsrlw(dst, k0, src, 4, true , vec_enc);\n+    evpandd(dst, k0, dst, xtmp1, true, vec_enc);\n+    vpshufb(dst, xtmp2, dst, vec_enc);\n+    evpaddb(xtmp3, k0, dst, xtmp3, true, vec_enc);\n+    evpxord(xtmp1, k0, xtmp1, xtmp1, true, vec_enc);\n+    evpunpckhdq(dst, k0, xtmp3, xtmp1, true, vec_enc);\n+    evpsadbw(dst, k0, dst, xtmp1, true, vec_enc);\n+    evpunpckldq(xtmp2, k0, xtmp3, xtmp1, true, vec_enc);\n+    evpsadbw(xtmp2, k0, xtmp2, xtmp1, true, vec_enc);\n+    vpackuswb(dst, xtmp2, dst, vec_enc);\n+  } else {\n+    assert(VM_Version::supports_avx2(), \"\");\n+    movl(rtmp, 0x0F0F0F0F);\n+    movdl(xtmp1, rtmp);\n+    vpbroadcastd(xtmp1, xtmp1, vec_enc);\n+    vmovdqu(xtmp2, ExternalAddress(StubRoutines::x86::vector_popcount_lut()), rtmp);\n+    vpand(xtmp3, src, xtmp1, vec_enc);\n+    vpshufb(xtmp3, xtmp2, xtmp3, vec_enc);\n+    vpsrlw(dst, src, 4, vec_enc);\n+    vpand(dst, dst, xtmp1, vec_enc);\n+    vpshufb(dst, xtmp2, dst, vec_enc);\n+    vpaddb(xtmp3, dst, xtmp3, vec_enc);\n+    vpxor(xtmp1, xtmp1, xtmp1, vec_enc);\n+    vpunpckhdq(dst, xtmp3, xtmp1, vec_enc);\n+    vpsadbw(dst, dst, xtmp1, vec_enc);\n+    vpunpckldq(xtmp2, xtmp3, xtmp1, vec_enc);\n+    vpsadbw(xtmp2, xtmp2, xtmp1, vec_enc);\n+    vpackuswb(dst, xtmp2, dst, vec_enc);\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_popcount_long(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                             XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp,\n+                                             int vec_enc) {\n+  if (VM_Version::supports_avx512_vpopcntdq()) {\n+    vpopcntq(dst, src, vec_enc);\n+  } else if (vec_enc == Assembler::AVX_512bit) {\n+    assert(VM_Version::supports_avx512vlbw(), \"\");\n+    movl(rtmp, 0x0F0F0F0F);\n+    movdl(xtmp1, rtmp);\n+    vpbroadcastd(xtmp1, xtmp1, vec_enc);\n+    evmovdqul(xtmp2, k0, ExternalAddress(StubRoutines::x86::vector_popcount_lut()), true, vec_enc, rtmp);\n+    evpandq(xtmp3, k0, src, xtmp1, true, vec_enc);\n+    vpshufb(xtmp3, xtmp2, xtmp3, vec_enc);\n+    Assembler::evpsrlw(dst, k0, src, 4, true , vec_enc);\n+    evpandq(dst, k0, dst, xtmp1, true, vec_enc);\n+    vpshufb(dst, xtmp2, dst, vec_enc);\n+    evpaddb(xtmp3, k0, dst, xtmp3, true, vec_enc);\n+    evpxorq(xtmp1, k0, xtmp1, xtmp1, true, vec_enc);\n+    evpsadbw(dst, k0, xtmp3, xtmp1, true, vec_enc);\n+  } else {\n+    \/\/ We do not see any performance benefit of running\n+    \/\/ above instruction sequence on 256 bit vector which\n+    \/\/ can operate over maximum 4 long elements.\n+    ShouldNotReachHere();\n+  }\n+  evpmovqd(dst, dst, vec_enc);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":72,"deletions":0,"binary":false,"changes":72,"status":"modified"},{"patch":"@@ -315,0 +315,8 @@\n+  void vector_popcount_int(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                           XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp,\n+                           int vec_enc);\n+\n+  void vector_popcount_long(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                            XMMRegister xtmp2, XMMRegister xtmp3, Register rtmp,\n+                            int vec_enc);\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -186,0 +186,9 @@\n+  \/\/ Returns pre-selection estimated cost of a vector operation.\n+  static int vector_op_cost(int vopc, BasicType ety, int vlen) {\n+    switch(vopc) {\n+      default: return 1;\n+      case Op_PopCountVI: return VM_Version::supports_avx512_vpopcntdq() ? 1 : 50;\n+      case Op_PopCountVL: return VM_Version::supports_avx512_vpopcntdq() ? 1 : 40;\n+    }\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -591,0 +591,24 @@\n+  address generate_popcount_avx_lut(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data(0x02010100, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x04030302, relocInfo::none, 0);\n+    __ emit_data(0x02010100, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x04030302, relocInfo::none, 0);\n+    __ emit_data(0x02010100, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x04030302, relocInfo::none, 0);\n+    __ emit_data(0x02010100, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x03020201, relocInfo::none, 0);\n+    __ emit_data(0x04030302, relocInfo::none, 0);\n+    return start;\n+  }\n+\n+\n@@ -4006,0 +4030,1 @@\n+    StubRoutines::x86::_vector_popcount_lut = generate_popcount_avx_lut(\"popcount_lut\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_32.cpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -798,0 +798,15 @@\n+  address generate_popcount_avx_lut(const char *stub_name) {\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", stub_name);\n+    address start = __ pc();\n+    __ emit_data64(0x0302020102010100, relocInfo::none);\n+    __ emit_data64(0x0403030203020201, relocInfo::none);\n+    __ emit_data64(0x0302020102010100, relocInfo::none);\n+    __ emit_data64(0x0403030203020201, relocInfo::none);\n+    __ emit_data64(0x0302020102010100, relocInfo::none);\n+    __ emit_data64(0x0403030203020201, relocInfo::none);\n+    __ emit_data64(0x0302020102010100, relocInfo::none);\n+    __ emit_data64(0x0403030203020201, relocInfo::none);\n+    return start;\n+  }\n+\n@@ -7715,0 +7730,1 @@\n+    StubRoutines::x86::_vector_popcount_lut = generate_popcount_avx_lut(\"popcount_lut\");\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -62,0 +62,1 @@\n+address StubRoutines::x86::_vector_popcount_lut = NULL;\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -180,0 +180,1 @@\n+  static address _vector_popcount_lut;\n@@ -343,0 +344,3 @@\n+  static address vector_popcount_lut() {\n+    return _vector_popcount_lut;\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/stubRoutines_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1408,0 +1408,4 @@\n+      if (!UsePopCountInstruction || (UseAVX < 2)) {\n+        return false;\n+      }\n+      break;\n@@ -1409,1 +1413,1 @@\n-      if (!UsePopCountInstruction || !VM_Version::supports_avx512_vpopcntdq()) {\n+      if (!UsePopCountInstruction || (UseAVX <= 2)) {\n@@ -1861,0 +1865,10 @@\n+    case Op_PopCountVI:\n+      if ((vlen == 16) && !VM_Version::supports_avx512vlbw()) {\n+        return false;\n+      }\n+      break;\n+    case Op_PopCountVL:\n+      if ((vlen <= 4) || ((vlen == 8) && !VM_Version::supports_avx512vlbw())) {\n+        return false;\n+      }\n+      break;\n@@ -8612,1 +8626,2 @@\n-instruct vpopcountI(vec dst, vec src) %{\n+instruct vpopcountI_popcntd(vec dst, vec src) %{\n+  predicate(VM_Version::supports_avx512_vpopcntdq());\n@@ -8614,1 +8629,1 @@\n-  format %{ \"vpopcntd  $dst,$src\\t! vector popcount packedI\" %}\n+  format %{ \"vector_popcount_int $dst, $src\\t! vector popcount packedI\" %}\n@@ -8617,0 +8632,5 @@\n+    int vlen_enc = vector_length_encoding(this);\n+    __ vector_popcount_int($dst$$XMMRegister, $src$$XMMRegister, xnoreg, xnoreg, xnoreg, noreg, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -8618,0 +8638,7 @@\n+instruct vpopcountI(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp, rFlagsReg cc) %{\n+  predicate(!VM_Version::supports_avx512_vpopcntdq());\n+  match(Set dst (PopCountVI src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, KILL cc);\n+  format %{ \"vector_popcount_int  $dst, $src\\t! using $xtmp1, $xtmp2, $xtmp3, and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    assert(UsePopCountInstruction, \"not enabled\");\n@@ -8619,1 +8646,2 @@\n-    __ vpopcntd($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n+    __ vector_popcount_int($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,\n+                           $xtmp3$$XMMRegister, $rtmp$$Register, vlen_enc);\n@@ -8624,1 +8652,2 @@\n-instruct vpopcountL(vec dst, vec src) %{\n+instruct vpopcountL_popcntd(vec dst, vec src) %{\n+  predicate(VM_Version::supports_avx512_vpopcntdq());\n@@ -8626,1 +8655,1 @@\n-  format %{ \"vpopcntq  $dst,$src\\t! vector popcount packedL\" %}\n+  format %{ \"vector_popcount_long  $dst, $src\\t! vector popcount packedL\" %}\n@@ -8629,1 +8658,0 @@\n-\n@@ -8631,2 +8659,4 @@\n-    __ vpopcntq($dst$$XMMRegister, $src$$XMMRegister, vlen_enc);\n-    __ evpmovqd($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n+    __ vector_popcount_long($dst$$XMMRegister, $src$$XMMRegister, xnoreg, xnoreg, xnoreg, noreg, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n@@ -8634,0 +8664,10 @@\n+instruct vpopcountL(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, rRegP rtmp, rFlagsReg cc) %{\n+  predicate(!VM_Version::supports_avx512_vpopcntdq());\n+  match(Set dst (PopCountVL src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP rtmp, KILL cc);\n+  format %{ \"vector_popcount_long  $dst, $src\\t! using $xtmp1, $xtmp2, $xtmp3, and $rtmp as TEMP\" %}\n+  ins_encode %{\n+    assert(UsePopCountInstruction, \"not enabled\");\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    __ vector_popcount_long($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister,\n+                           $xtmp3$$XMMRegister, $rtmp$$Register, vlen_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":49,"deletions":9,"binary":false,"changes":58,"status":"modified"},{"patch":"@@ -959,0 +959,2 @@\n+  \/\/ Rudimentary cost model to estimate loop unrolling\n+  \/\/ factor.\n@@ -971,0 +973,5 @@\n+      case Op_PopCountVI:\n+      case Op_PopCountVL: {\n+        const TypeVect * vt = n->bottom_type()->is_vect();\n+        body_size += Matcher::vector_op_cost(n->Opcode(), vt->element_basic_type(), vt->length());\n+      } break;\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -27,2 +27,0 @@\n-* @requires vm.cpu.features ~= \".*avx512dq.*\"\n-* @requires vm.cpu.features ~= \".*vpopcntdq.*\"\n@@ -30,0 +28,1 @@\n+* @requires vm.cpu.features ~= \".*avx512bw.*\"\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorization\/TestPopCountVectorLong.java","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"}]}