{"files":[{"patch":"@@ -249,0 +249,5 @@\n+\n+    \/\/ parallel thread number for heap dump, initialize based on active processor count.\n+    \/\/ Note the real number of threads used is also determined by active workers and compression\n+    \/\/ backend thread number.\n+    uint parallel_thread_num = MAX2<uint>(1, (uint)os::initial_active_processor_count() * 3 \/ 8);\n@@ -253,1 +258,1 @@\n-    dumper.dump(op->arg(0), out, (int)level);\n+    dumper.dump(path, out, (int)level, (uint)parallel_thread_num);\n","filename":"src\/hotspot\/share\/services\/attachListener.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -383,4 +383,4 @@\n-\/\/ Supports I\/O operations for a dump\n-\n-class DumpWriter : public StackObj {\n- private:\n+\/\/ Supports I\/O ooperations for a dump\n+\/\/ Base class for dump and parallel dump\n+class AbstractDumpWriter : public StackObj {\n+ protected:\n@@ -402,3 +402,1 @@\n-  CompressionBackend _backend; \/\/ Does the actual writing.\n-\n-  void flush();\n+  virtual void flush(bool force = false) = 0;\n@@ -408,1 +406,0 @@\n-  size_t position() const                       { return _pos; }\n@@ -416,1 +413,0 @@\n-\n@@ -418,4 +414,5 @@\n-  \/\/ Takes ownership of the writer and compressor.\n-  DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor);\n-\n-  ~DumpWriter();\n+  AbstractDumpWriter() :\n+    _buffer(NULL),\n+    _size(io_buffer_max_size),\n+    _pos(0),\n+    _in_dump_segment(false) { }\n@@ -424,3 +421,2 @@\n-  julong bytes_written() const          { return (julong) _backend.get_written(); }\n-\n-  char const* error() const             { return _backend.error(); }\n+  virtual julong bytes_written() const = 0;\n+  virtual char const* error() const = 0;\n@@ -428,0 +424,1 @@\n+  size_t position() const                       { return _pos; }\n@@ -429,1 +426,1 @@\n-  void write_raw(void* s, size_t len);\n+  virtual void write_raw(void* s, size_t len);\n@@ -444,6 +441,2 @@\n-  void finish_dump_segment();\n-\n-  \/\/ Called by threads used for parallel writing.\n-  void writer_loop()                    { _backend.thread_loop(false); }\n-  \/\/ Called when finished to release the threads.\n-  void deactivate()                     { flush(); _backend.deactivate(); }\n+  void finish_dump_segment(bool force_flush = false);\n+  virtual void deactivate() = 0;\n@@ -452,15 +445,1 @@\n-\/\/ Check for error after constructing the object and destroy it in case of an error.\n-DumpWriter::DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor) :\n-  _buffer(NULL),\n-  _size(0),\n-  _pos(0),\n-  _in_dump_segment(false),\n-  _backend(writer, compressor, io_buffer_max_size, io_buffer_max_waste) {\n-  flush();\n-}\n-\n-DumpWriter::~DumpWriter() {\n-  flush();\n-}\n-\n-void DumpWriter::write_fast(void* s, size_t len) {\n+void AbstractDumpWriter::write_fast(void* s, size_t len) {\n@@ -470,1 +449,0 @@\n-\n@@ -475,1 +453,1 @@\n-bool DumpWriter::can_write_fast(size_t len) {\n+bool AbstractDumpWriter::can_write_fast(size_t len) {\n@@ -480,1 +458,1 @@\n-void DumpWriter::write_raw(void* s, size_t len) {\n+void AbstractDumpWriter::write_raw(void* s, size_t len) {\n@@ -488,1 +466,0 @@\n-\n@@ -501,5 +478,0 @@\n-\/\/ flush any buffered bytes to the file\n-void DumpWriter::flush() {\n-  _backend.get_new_buffer(&_buffer, &_pos, &_size);\n-}\n-\n@@ -510,1 +482,1 @@\n-void DumpWriter::write_u1(u1 x) {\n+void AbstractDumpWriter::write_u1(u1 x) {\n@@ -514,1 +486,1 @@\n-void DumpWriter::write_u2(u2 x) {\n+void AbstractDumpWriter::write_u2(u2 x) {\n@@ -520,1 +492,1 @@\n-void DumpWriter::write_u4(u4 x) {\n+void AbstractDumpWriter::write_u4(u4 x) {\n@@ -526,1 +498,1 @@\n-void DumpWriter::write_u8(u8 x) {\n+void AbstractDumpWriter::write_u8(u8 x) {\n@@ -532,1 +504,1 @@\n-void DumpWriter::write_objectID(oop o) {\n+void AbstractDumpWriter::write_objectID(oop o) {\n@@ -541,1 +513,1 @@\n-void DumpWriter::write_symbolID(Symbol* s) {\n+void AbstractDumpWriter::write_symbolID(Symbol* s) {\n@@ -550,1 +522,1 @@\n-void DumpWriter::write_id(u4 x) {\n+void AbstractDumpWriter::write_id(u4 x) {\n@@ -559,1 +531,1 @@\n-void DumpWriter::write_classID(Klass* k) {\n+void AbstractDumpWriter::write_classID(Klass* k) {\n@@ -563,1 +535,1 @@\n-void DumpWriter::finish_dump_segment() {\n+void AbstractDumpWriter::finish_dump_segment(bool force_flush) {\n@@ -574,0 +546,4 @@\n+    } else {\n+      \/\/ Finished process huge sub record\n+      \/\/ Set _is_huge_sub_record to false so the parallel dump writer could flush data to file.\n+      _is_huge_sub_record = false;\n@@ -576,1 +552,0 @@\n-    flush();\n@@ -578,0 +553,3 @@\n+    flush(force_flush);\n+  } else {\n+    printf(\"no-op finish dump\\n\");\n@@ -581,1 +559,1 @@\n-void DumpWriter::start_sub_record(u1 tag, u4 len) {\n+void AbstractDumpWriter::start_sub_record(u1 tag, u4 len) {\n@@ -587,1 +565,1 @@\n-    assert(position() == 0, \"Must be at the start\");\n+    assert(position() == 0 && buffer_size() > dump_segment_header_size, \"Must be at the start\");\n@@ -594,0 +572,1 @@\n+    assert (Bytes::get_Java_u4((address)(buffer() + 5)) == len, \"Inconsitent size!\");\n@@ -611,1 +590,1 @@\n-void DumpWriter::end_sub_record() {\n+void AbstractDumpWriter::end_sub_record() {\n@@ -618,0 +597,267 @@\n+\/\/ Supports I\/O operations for a dump\n+\n+class DumpWriter : public AbstractDumpWriter {\n+ private:\n+  CompressionBackend _backend; \/\/ Does the actual writing.\n+ protected:\n+  virtual void flush(bool force = false);\n+\n+ public:\n+  \/\/ Takes ownership of the writer and compressor.\n+  DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor);\n+\n+  \/\/ total number of bytes written to the disk\n+  virtual julong bytes_written() const          { return (julong) _backend.get_written(); }\n+\n+  virtual char const* error() const             { return _backend.error(); }\n+\n+  \/\/ Called by threads used for parallel writing.\n+  void writer_loop()                    { _backend.thread_loop(false); }\n+  \/\/ Called when finished to release the threads.\n+  virtual void deactivate()             { flush(); _backend.deactivate(); }\n+  \/\/ Get the backend pointer, used by parallel dump writer.\n+  CompressionBackend* backend_ptr() { return &_backend; }\n+};\n+\n+\/\/ Check for error after constructing the object and destroy it in case of an error.\n+DumpWriter::DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor) :\n+  AbstractDumpWriter(),\n+  _backend(writer, compressor, io_buffer_max_size, io_buffer_max_waste) {\n+  flush();\n+}\n+\n+\/\/ flush any buffered bytes to the file\n+void DumpWriter::flush(bool force) {\n+  _backend.get_new_buffer(&_buffer, &_pos, &_size, force);\n+}\n+\n+struct ParWriterBufferQueueElem {\n+  char* _buffer;\n+  size_t _used;\n+  ParWriterBufferQueueElem* _next;\n+};\n+\n+class ParWriterBufferQueue : public CHeapObj<mtInternal> {\n+ private:\n+  ParWriterBufferQueueElem* _head;\n+  ParWriterBufferQueueElem* _tail;\n+  uint _length;\n+ public:\n+  ParWriterBufferQueue() : _head(NULL), _tail(NULL), _length(0) { }\n+\n+  void enqueue(ParWriterBufferQueueElem* entry) {\n+    if (_head == NULL) {\n+      assert(is_empty() && _tail == NULL, \"Sanity check\");\n+      _head = _tail = entry;\n+    } else {\n+      assert ((_tail->_next == NULL && _tail->_buffer != NULL), \"Buffer queue is polluted\");\n+      _tail->_next = entry;\n+      _tail = entry;\n+    }\n+    _length++;\n+    assert(_tail->_next == NULL, \"Bufer queue is polluted\");\n+  }\n+\n+  ParWriterBufferQueueElem* dequeue() {\n+    if (_head == NULL) return NULL;\n+    ParWriterBufferQueueElem* entry = _head;\n+    assert (entry->_buffer != NULL, \"polluted buffer in writer list\");\n+    _head = entry->_next;\n+    entry->_next = NULL;\n+    _length--;\n+    return entry;\n+  }\n+\n+  bool is_empty() {\n+    return _length == 0;\n+  }\n+\n+  uint length() { return _length; }\n+};\n+\n+\/\/ Support parallel heap dump.\n+class ParDumpWriter : public AbstractDumpWriter {\n+ private:\n+  \/\/ Lock used to guarantee the integrity of multiple buffers writing.\n+  static Monitor* _lock;\n+  \/\/ Pointer of backend from global DumpWriter.\n+  CompressionBackend* _backend_ptr;\n+  char const * _err;\n+  ParWriterBufferQueue* _buffer_queue;\n+  size_t _internal_buffer_used;\n+  char* _buffer_base;\n+  bool _splited_data;\n+  static const uint backend_flush_threshold = 2;\n+ protected:\n+  virtual void flush(bool force = false) {\n+    assert(_pos != 0, \"must not be zero\");\n+    if (_pos != 0) {\n+      refresh_buffer();\n+    }\n+\n+    if (_splited_data || _is_huge_sub_record) {\n+      return;\n+    }\n+\n+    if (should_flush_buf_list(force)) {\n+      assert(!_in_dump_segment && !_splited_data && !_is_huge_sub_record, \"incomplete data send to backend!\\n\");\n+        flush_to_backend(force);\n+    }\n+  }\n+\n+ public:\n+  ParDumpWriter(DumpWriter* dw) :\n+    AbstractDumpWriter(),\n+    _backend_ptr(dw->backend_ptr()),\n+    _buffer_queue((new (std::nothrow) ParWriterBufferQueue())),\n+    _buffer_base(NULL),\n+    _splited_data(false) {\n+    \/\/ prepare internal buffer\n+    allocate_internal_buffer();\n+  }\n+\n+  ~ParDumpWriter() {\n+     assert(_buffer_queue != NULL, \"Sanity check\");\n+     assert((_internal_buffer_used == 0) && (_buffer_queue->is_empty()),\n+            \"All data must be send to backend\");\n+     delete _buffer_queue;\n+     _buffer_queue = NULL;\n+  }\n+\n+  \/\/ total number of bytes written to the disk\n+  virtual julong bytes_written() const          { return (julong) _backend_ptr->get_written(); }\n+  virtual char const* error() const { return _err == NULL ? _backend_ptr->error() : _err; }\n+\n+  static void before_work() {\n+    assert(_lock == NULL, \"ParDumpWriter lock must be initialized only once\");\n+    _lock = new (std::nothrow) PaddedMonitor(Mutex::leaf, \"Parallel HProf writer lock\", true, Mutex::_safepoint_check_never);\n+  }\n+\n+  static void after_work() {\n+    assert(_lock != NULL, \"ParDumpWriter lock is not initialized\");\n+    delete _lock;\n+    _lock = NULL;\n+  }\n+\n+\/\/ write raw bytes\n+virtual void write_raw(void* s, size_t len) {\n+  assert(!_in_dump_segment || (_sub_record_left >= len), \"sub-record too large\");\n+  debug_only(_sub_record_left -= len);\n+  assert(!_splited_data, \"invalid splited data\");\n+  _splited_data = true;\n+  \/\/ flush buffer to make room.\n+  while (len > buffer_size() - position()) {\n+    assert(!_in_dump_segment || _is_huge_sub_record,\n+           \"Cannot overflow in non-huge sub-record.\");\n+    size_t to_write = buffer_size() - position();\n+    memcpy(buffer() + position(), s, to_write);\n+    s = (void*) ((char*) s + to_write);\n+    len -= to_write;\n+    set_position(position() + to_write);\n+    flush();\n+  }\n+  _splited_data = false;\n+\n+  memcpy(buffer() + position(), s, len);\n+  set_position(position() + len);\n+}\n+\n+  virtual void deactivate()             { flush(true); _backend_ptr->deactivate(); }\n+\n+ private:\n+  void allocate_internal_buffer() {\n+    assert(_buffer_queue != NULL, \"Internal buffer queue is not ready when allocate internal buffer\");\n+    assert(_buffer == NULL && _buffer_base == NULL, \"current buffer must be NULL before allocate\");\n+    _buffer_base = _buffer = (char*)os::malloc(io_buffer_max_size, mtInternal);\n+    if (_buffer == NULL) {\n+      set_error(\"Could not allocate buffer for writer\");\n+      return;\n+    }\n+    _pos = 0;\n+    _internal_buffer_used = 0;\n+    _size = io_buffer_max_size;\n+  }\n+\n+  void set_error(char const* new_error) {\n+    if ((new_error != NULL) && (_err == NULL)) {\n+      _err = new_error;\n+    }\n+  }\n+\n+  \/\/ Add buffer to internal list\n+  void refresh_buffer() {\n+    size_t expected_total = _internal_buffer_used + _pos;\n+    if (expected_total < io_buffer_max_size - io_buffer_max_waste) {\n+      \/\/ reuse current buffer.\n+      _internal_buffer_used = expected_total;\n+      assert(_size - _pos == io_buffer_max_size - expected_total, \"illegal resize of buffer\");\n+      _size -= _pos;\n+      _buffer += _pos;\n+      _pos = 0;\n+\n+      return;\n+    }\n+    \/\/ It is not possible here that expected_total is larger than io_buffer_max_size because\n+    \/\/ of limitation in write_xxx().\n+    assert(expected_total <= io_buffer_max_size, \"buffer overflow\");\n+    assert(_buffer - _buffer_base <= io_buffer_max_size, \"internal buffer overflow\");\n+    ParWriterBufferQueueElem* entry =\n+        (ParWriterBufferQueueElem*)os::malloc(sizeof(ParWriterBufferQueueElem), mtInternal);\n+    if (entry == NULL) {\n+      \/\/ \"Could not allocate buffer list for writer\"\n+      set_error(\"Heap dumper can not enqueue to internal buffer\");\n+      return;\n+    }\n+    entry->_buffer = _buffer_base;\n+    entry->_used = expected_total;\n+    entry->_next = NULL;\n+    \/\/ add to internal buffer queue\n+    _buffer_queue->enqueue(entry);\n+    _buffer_base =_buffer = NULL;\n+    allocate_internal_buffer();\n+  }\n+\n+  void reclaim_entry(ParWriterBufferQueueElem* entry) {\n+    assert(entry != NULL && entry->_buffer != NULL, \"Invalid entry to reclaim\");\n+    os::free(entry->_buffer);\n+    entry->_buffer = NULL;\n+    os::free(entry);\n+  }\n+\n+  void flush_buffer(char* buffer, size_t used) {\n+    assert(_lock->owner() == Thread::current(), \"flush buffer must hold lock\");\n+    size_t max = io_buffer_max_size;\n+    \/\/ get_new_buffer\n+    _backend_ptr->flush_external_buffer(buffer, used, max);\n+  }\n+\n+  bool should_flush_buf_list(bool force) {\n+    return force || _buffer_queue->length() > backend_flush_threshold;\n+  }\n+\n+  void flush_to_backend(bool force) {\n+    \/\/ Guarantee there is only one writer update backend buffers.\n+    MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+    while (!_buffer_queue->is_empty()) {\n+      ParWriterBufferQueueElem* entry = _buffer_queue->dequeue();\n+      flush_buffer(entry->_buffer, entry->_used);\n+      \/\/ Delete buffer and entry.\n+      reclaim_entry(entry);\n+      entry = NULL;\n+    }\n+    assert(_pos == 0, \"available buffer must be clean before flush\");\n+    \/\/ Flush internal buffer.\n+    if (_internal_buffer_used > 0) {\n+      flush_buffer(_buffer_base, _internal_buffer_used);\n+      os::free(_buffer_base);\n+      _pos = 0;\n+      _internal_buffer_used = 0;\n+      _buffer_base = _buffer = NULL;\n+      \/\/ Allocate internal buffer for future use.\n+      allocate_internal_buffer();\n+    }\n+  }\n+};\n+\n+Monitor* ParDumpWriter::_lock = NULL;\n+\n@@ -624,1 +870,1 @@\n-  static void write_header(DumpWriter* writer, hprofTag tag, u4 len);\n+  static void write_header(AbstractDumpWriter* writer, hprofTag tag, u4 len);\n@@ -637,1 +883,1 @@\n-  static void dump_float(DumpWriter* writer, jfloat f);\n+  static void dump_float(AbstractDumpWriter* writer, jfloat f);\n@@ -639,1 +885,1 @@\n-  static void dump_double(DumpWriter* writer, jdouble d);\n+  static void dump_double(AbstractDumpWriter* writer, jdouble d);\n@@ -641,1 +887,1 @@\n-  static void dump_field_value(DumpWriter* writer, char type, oop obj, int offset);\n+  static void dump_field_value(AbstractDumpWriter* writer, char type, oop obj, int offset);\n@@ -645,1 +891,1 @@\n-  static void dump_static_fields(DumpWriter* writer, Klass* k);\n+  static void dump_static_fields(AbstractDumpWriter* writer, Klass* k);\n@@ -647,1 +893,1 @@\n-  static void dump_instance_fields(DumpWriter* writer, oop o);\n+  static void dump_instance_fields(AbstractDumpWriter* writer, oop o);\n@@ -651,1 +897,1 @@\n-  static void dump_instance_field_descriptors(DumpWriter* writer, Klass* k);\n+  static void dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k);\n@@ -653,1 +899,1 @@\n-  static void dump_instance(DumpWriter* writer, oop o);\n+  static void dump_instance(AbstractDumpWriter* writer, oop o);\n@@ -656,1 +902,1 @@\n-  static void dump_class_and_array_classes(DumpWriter* writer, Klass* k);\n+  static void dump_class_and_array_classes(AbstractDumpWriter* writer, Klass* k);\n@@ -659,1 +905,1 @@\n-  static void dump_basic_type_array_class(DumpWriter* writer, Klass* k);\n+  static void dump_basic_type_array_class(AbstractDumpWriter* writer, Klass* k);\n@@ -662,1 +908,1 @@\n-  static void dump_object_array(DumpWriter* writer, objArrayOop array);\n+  static void dump_object_array(AbstractDumpWriter* writer, objArrayOop array);\n@@ -664,1 +910,1 @@\n-  static void dump_prim_array(DumpWriter* writer, typeArrayOop array);\n+  static void dump_prim_array(AbstractDumpWriter* writer, typeArrayOop array);\n@@ -666,1 +912,1 @@\n-  static void dump_stack_frame(DumpWriter* writer, int frame_serial_num, int class_serial_num, Method* m, int bci);\n+  static void dump_stack_frame(AbstractDumpWriter* writer, int frame_serial_num, int class_serial_num, Method* m, int bci);\n@@ -669,1 +915,1 @@\n-  static int calculate_array_max_length(DumpWriter* writer, arrayOop array, short header_size);\n+  static int calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size);\n@@ -672,1 +918,1 @@\n-  static void end_of_dump(DumpWriter* writer);\n+  static void end_of_dump(AbstractDumpWriter* writer);\n@@ -686,1 +932,1 @@\n-void DumperSupport:: write_header(DumpWriter* writer, hprofTag tag, u4 len) {\n+void DumperSupport:: write_header(AbstractDumpWriter* writer, hprofTag tag, u4 len) {\n@@ -740,1 +986,1 @@\n-void DumperSupport::dump_float(DumpWriter* writer, jfloat f) {\n+void DumperSupport::dump_float(AbstractDumpWriter* writer, jfloat f) {\n@@ -754,1 +1000,1 @@\n-void DumperSupport::dump_double(DumpWriter* writer, jdouble d) {\n+void DumperSupport::dump_double(AbstractDumpWriter* writer, jdouble d) {\n@@ -769,1 +1015,1 @@\n-void DumperSupport::dump_field_value(DumpWriter* writer, char type, oop obj, int offset) {\n+void DumperSupport::dump_field_value(AbstractDumpWriter* writer, char type, oop obj, int offset) {\n@@ -887,1 +1133,1 @@\n-void DumperSupport::dump_static_fields(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_static_fields(AbstractDumpWriter* writer, Klass* k) {\n@@ -930,1 +1176,1 @@\n-void DumperSupport::dump_instance_fields(DumpWriter* writer, oop o) {\n+void DumperSupport::dump_instance_fields(AbstractDumpWriter* writer, oop o) {\n@@ -953,1 +1199,1 @@\n-void DumperSupport::dump_instance_field_descriptors(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k) {\n@@ -968,1 +1214,1 @@\n-void DumperSupport::dump_instance(DumpWriter* writer, oop o) {\n+void DumperSupport::dump_instance(AbstractDumpWriter* writer, oop o) {\n@@ -991,1 +1237,1 @@\n-void DumperSupport::dump_class_and_array_classes(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_class_and_array_classes(AbstractDumpWriter* writer, Klass* k) {\n@@ -1080,1 +1326,1 @@\n-void DumperSupport::dump_basic_type_array_class(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_basic_type_array_class(AbstractDumpWriter* writer, Klass* k) {\n@@ -1115,1 +1361,1 @@\n-int DumperSupport::calculate_array_max_length(DumpWriter* writer, arrayOop array, short header_size) {\n+int DumperSupport::calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size) {\n@@ -1142,1 +1388,1 @@\n-void DumperSupport::dump_object_array(DumpWriter* writer, objArrayOop array) {\n+void DumperSupport::dump_object_array(AbstractDumpWriter* writer, objArrayOop array) {\n@@ -1155,1 +1401,0 @@\n-\n@@ -1176,1 +1421,1 @@\n-void DumperSupport::dump_prim_array(DumpWriter* writer, typeArrayOop array) {\n+void DumperSupport::dump_prim_array(AbstractDumpWriter* writer, typeArrayOop array) {\n@@ -1178,1 +1423,0 @@\n-\n@@ -1270,1 +1514,1 @@\n-void DumperSupport::dump_stack_frame(DumpWriter* writer,\n+void DumperSupport::dump_stack_frame(AbstractDumpWriter* writer,\n@@ -1299,2 +1543,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1302,1 +1546,1 @@\n-  SymbolTableDumper(DumpWriter* writer)     { _writer = writer; }\n+  SymbolTableDumper(AbstractDumpWriter* writer)     { _writer = writer; }\n@@ -1322,1 +1566,1 @@\n-  DumpWriter* _writer;\n+  AbstractDumpWriter* _writer;\n@@ -1325,1 +1569,1 @@\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1327,1 +1571,1 @@\n-  JNILocalsDumper(DumpWriter* writer, u4 thread_serial_num) {\n+  JNILocalsDumper(AbstractDumpWriter* writer, u4 thread_serial_num) {\n@@ -1356,2 +1600,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1360,1 +1604,1 @@\n-  JNIGlobalsDumper(DumpWriter* writer) {\n+  JNIGlobalsDumper(AbstractDumpWriter* writer) {\n@@ -1372,1 +1616,0 @@\n-\n@@ -1387,2 +1630,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1390,1 +1633,1 @@\n-  StickyClassDumper(DumpWriter* writer) {\n+  StickyClassDumper(AbstractDumpWriter* writer) {\n@@ -1404,1 +1647,0 @@\n-\n@@ -1411,3 +1653,1 @@\n-  DumpWriter* _writer;\n-\n-  DumpWriter* writer()                  { return _writer; }\n+  AbstractDumpWriter* _writer;\n@@ -1415,0 +1655,1 @@\n+  AbstractDumpWriter* writer()                  { return _writer; }\n@@ -1416,1 +1657,1 @@\n-  HeapObjectDumper(DumpWriter* writer) {\n+  HeapObjectDumper(AbstractDumpWriter* writer) {\n@@ -1449,0 +1690,54 @@\n+\/\/ The dumper controller for parallel heap dump\n+class DumperController : public CHeapObj<mtInternal> {\n+ private:\n+   bool     _started;\n+   Monitor* _lock;\n+   uint   _dumper_number;\n+   uint   _waiting_number;\n+   uint   _complete_number;\n+\n+ public:\n+   DumperController(uint number) :\n+     _started(false),\n+     _lock(new (std::nothrow) PaddedMonitor(Mutex::leaf, \"Dumper Controller lock\",\n+    true, Mutex::_safepoint_check_never)),\n+     _dumper_number(number),\n+     _waiting_number(0),\n+     _complete_number(0) { }\n+\n+   ~DumperController() { delete _lock; }\n+\n+   void wait_for_start_signal() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_started == false) {\n+       _waiting_number++;\n+       ml.wait();\n+     }\n+     assert(_started == true,  \"dumper is waken up with wrong state\");\n+     _waiting_number--;\n+   }\n+\n+   void start_dump() {\n+     assert (_started == false, \"start dump with wrong state\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _started = true;\n+     ml.notify_all();\n+   }\n+\n+   void dumper_complete() {\n+     assert (_started == true, \"dumper complete with wrong state\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _complete_number++;\n+     ml.notify();\n+   }\n+\n+   void wait_all_dumpers_complete() {\n+     assert (_started == true, \"wrong state when wait for dumper complete\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_complete_number != _dumper_number) {\n+        ml.wait();\n+     }\n+     _started = false;\n+   }\n+};\n+\n@@ -1452,9 +1747,60 @@\n-  static VM_HeapDumper* _global_dumper;\n-  static DumpWriter*    _global_writer;\n-  DumpWriter*           _local_writer;\n-  JavaThread*           _oome_thread;\n-  Method*               _oome_constructor;\n-  bool _gc_before_heap_dump;\n-  GrowableArray<Klass*>* _klass_map;\n-  ThreadStackTrace** _stack_traces;\n-  int _num_threads;\n+  static VM_HeapDumper*   _global_dumper;\n+  static DumpWriter*      _global_writer;\n+  DumpWriter*             _local_writer;\n+  JavaThread*             _oome_thread;\n+  Method*                 _oome_constructor;\n+  bool                    _gc_before_heap_dump;\n+  GrowableArray<Klass*>*  _klass_map;\n+  ThreadStackTrace**      _stack_traces;\n+  int                     _num_threads;\n+  \/\/ parallel heap dump support\n+  uint                    _num_dumper_threads;\n+  uint                    _num_writter_threads;\n+  DumperController*       _dumper_controller;\n+  ParallelObjectIterator* _poi;\n+\n+  static const size_t WritterType = 0;\n+  static const size_t DumperType = 1;\n+  static const size_t VMDumperType = 2;\n+\n+  size_t get_worker_type(uint worker_id) {\n+    assert(_num_writter_threads >= 1, \"Must be at least one writters\");\n+    \/\/ worker id of writter starts from 0\n+    if (worker_id < _num_writter_threads) {\n+        return WritterType;\n+    }\n+    \/\/ worker id of dumper starts from _num_dumper_threads\n+    if (worker_id < _num_writter_threads + _num_dumper_threads) {\n+        return DumperType;\n+    }\n+\n+    assert (worker_id == _num_writter_threads + _num_dumper_threads,\n+            \"Invalid worker id for heap dumper\/writter\");\n+    return VMDumperType;\n+  }\n+\n+  void prepare_parallel_dump(uint num_total) {\n+    assert (_dumper_controller == NULL, \"dumper controller must be NULL\");\n+    if (num_total < _num_dumper_threads) {\n+      _num_dumper_threads = num_total - 1 \/* VMThread *\/;\n+    }\n+    \/\/ Calculate dumper and writter threads number\n+    _num_writter_threads = num_total - _num_dumper_threads;\n+    if (_num_writter_threads < 1) {\n+      _num_writter_threads = 1;\n+      _num_dumper_threads = num_total - _num_writter_threads;\n+    }\n+    uint total_dumper_threads = _num_dumper_threads + 1 \/* VMThread *\/;\n+    \/\/ prepare parallel writer.\n+    if (_num_dumper_threads > 0) {\n+      ParDumpWriter::before_work();\n+      _dumper_controller = new (std::nothrow) DumperController(_num_dumper_threads);\n+      _poi = Universe::heap()->parallel_object_iterator(total_dumper_threads);\n+    }\n+  }\n+\n+  void finish_parallel_dump() {\n+    if (_num_dumper_threads > 0) {\n+      ParDumpWriter::after_work();\n+    }\n+  }\n@@ -1502,1 +1848,1 @@\n-  VM_HeapDumper(DumpWriter* writer, bool gc_before_heap_dump, bool oome) :\n+  VM_HeapDumper(DumpWriter* writer, bool gc_before_heap_dump, bool oome, uint num_dump_threads) :\n@@ -1513,0 +1859,3 @@\n+    _num_dumper_threads = num_dump_threads - 1; \/\/ consider vm thread.\n+    _dumper_controller = NULL;\n+    _poi = NULL;\n@@ -1526,0 +1875,1 @@\n+\n@@ -1533,0 +1883,8 @@\n+    if (_poi != NULL) {\n+      delete _poi;\n+      _poi = NULL;\n+    }\n+    if (_dumper_controller != NULL) {\n+      delete _dumper_controller;\n+      _dumper_controller = NULL;\n+    }\n@@ -1541,1 +1899,0 @@\n-\n@@ -1550,1 +1907,1 @@\n-void DumperSupport::end_of_dump(DumpWriter* writer) {\n+void DumperSupport::end_of_dump(AbstractDumpWriter* writer) {\n@@ -1774,0 +2131,1 @@\n+    prepare_parallel_dump(gang->active_workers());\n@@ -1775,0 +2133,1 @@\n+    finish_parallel_dump();\n@@ -1784,22 +2143,7 @@\n-    writer()->writer_loop();\n-    return;\n-  }\n-\n-  \/\/ Write the file header - we always use 1.0.2\n-  const char* header = \"JAVA PROFILE 1.0.2\";\n-\n-  \/\/ header is few bytes long - no chance to overflow int\n-  writer()->write_raw((void*)header, (int)strlen(header));\n-  writer()->write_u1(0); \/\/ terminator\n-  writer()->write_u4(oopSize);\n-  \/\/ timestamp is current time in ms\n-  writer()->write_u8(os::javaTimeMillis());\n-\n-  \/\/ HPROF_UTF8 records\n-  SymbolTableDumper sym_dumper(writer());\n-  SymbolTable::symbols_do(&sym_dumper);\n-\n-  \/\/ write HPROF_LOAD_CLASS records\n-  {\n-    LockedClassesDo locked_load_classes(&do_load_class);\n-    ClassLoaderDataGraph::classes_do(&locked_load_classes);\n+    if (get_worker_type(worker_id) == WritterType) {\n+      writer()->writer_loop();\n+      return;\n+    }\n+    if (_num_dumper_threads >= 1 && get_worker_type(worker_id) == DumperType) {\n+      _dumper_controller->wait_for_start_signal();\n+    }\n@@ -1807,1 +2151,21 @@\n-  Universe::basic_type_classes_do(&do_load_class);\n+  \/\/ The VM thread works on all non-heap data dumping and part of heap iteration.\n+  if (Thread::current()->is_VM_thread()) {\n+    \/\/ Write the file header - we always use 1.0.2\n+    const char* header = \"JAVA PROFILE 1.0.2\";\n+\n+    \/\/ header is few bytes long - no chance to overflow int\n+    writer()->write_raw((void*)header, (int)strlen(header));\n+    writer()->write_u1(0); \/\/ terminator\n+    writer()->write_u4(oopSize);\n+    \/\/ timestamp is current time in ms\n+    writer()->write_u8(os::javaTimeMillis());\n+    \/\/ HPROF_UTF8 records\n+    SymbolTableDumper sym_dumper(writer());\n+    SymbolTable::symbols_do(&sym_dumper);\n+\n+    \/\/ write HPROF_LOAD_CLASS records\n+    {\n+      LockedClassesDo locked_load_classes(&do_load_class);\n+      ClassLoaderDataGraph::classes_do(&locked_load_classes);\n+    }\n+    Universe::basic_type_classes_do(&do_load_class);\n@@ -1809,3 +2173,3 @@\n-  \/\/ write HPROF_FRAME and HPROF_TRACE records\n-  \/\/ this must be called after _klass_map is built when iterating the classes above.\n-  dump_stack_traces();\n+    \/\/ write HPROF_FRAME and HPROF_TRACE records\n+    \/\/ this must be called after _klass_map is built when iterating the classes above.\n+    dump_stack_traces();\n@@ -1813,4 +2177,22 @@\n-  \/\/ Writes HPROF_GC_CLASS_DUMP records\n-  {\n-    LockedClassesDo locked_dump_class(&do_class_dump);\n-    ClassLoaderDataGraph::classes_do(&locked_dump_class);\n+    \/\/ Writes HPROF_GC_CLASS_DUMP records\n+    {\n+      LockedClassesDo locked_dump_class(&do_class_dump);\n+      ClassLoaderDataGraph::classes_do(&locked_dump_class);\n+    }\n+    Universe::basic_type_classes_do(&do_basic_type_array_class_dump);\n+\n+    \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n+    do_threads();\n+\n+    \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n+    JNIGlobalsDumper jni_dumper(writer());\n+    JNIHandles::oops_do(&jni_dumper);\n+    \/\/ technically not jni roots, but global roots\n+    \/\/ for things like preallocated throwable backtraces\n+    Universe::vm_global()->oops_do(&jni_dumper);\n+\n+    \/\/ HPROF_GC_ROOT_STICKY_CLASS\n+    \/\/ These should be classes in the NULL class loader data, and not all classes\n+    \/\/ if !ClassUnloading\n+    StickyClassDumper class_dumper(writer());\n+    ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n@@ -1818,2 +2200,0 @@\n-  Universe::basic_type_classes_do(&do_basic_type_array_class_dump);\n-\n@@ -1826,18 +2206,36 @@\n-  HeapObjectDumper obj_dumper(writer());\n-  Universe::heap()->object_iterate(&obj_dumper);\n-\n-  \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n-  do_threads();\n-\n-  \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n-  JNIGlobalsDumper jni_dumper(writer());\n-  JNIHandles::oops_do(&jni_dumper);\n-  \/\/ technically not jni roots, but global roots\n-  \/\/ for things like preallocated throwable backtraces\n-  Universe::vm_global()->oops_do(&jni_dumper);\n-\n-  \/\/ HPROF_GC_ROOT_STICKY_CLASS\n-  \/\/ These should be classes in the NULL class loader data, and not all classes\n-  \/\/ if !ClassUnloading\n-  StickyClassDumper class_dumper(writer());\n-  ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n+  if (_num_dumper_threads == 0) {\n+    HeapObjectDumper obj_dumper(writer());\n+    Universe::heap()->object_iterate(&obj_dumper);\n+  } else {\n+    assert(get_worker_type(worker_id) == DumperType\n+          || get_worker_type(worker_id) == VMDumperType,\n+          \"must be dumper thread to do heap iteration\");\n+    if (get_worker_type(worker_id) == VMDumperType) {\n+      \/\/ Clear global writer's buffer.\n+      writer()->finish_dump_segment(true);\n+      \/\/ Notify dumpers to start heap iteration.\n+      _dumper_controller->start_dump();\n+    }\n+    \/\/ Heap iteration.\n+    {\n+       ParDumpWriter pw(writer());\n+       {\n+         HeapObjectDumper obj_dumper(&pw);\n+         uint dumper_id = worker_id - _num_writter_threads;\n+         _poi->object_iterate(&obj_dumper, dumper_id);\n+       }\n+\n+       if (get_worker_type(worker_id) == VMDumperType) {\n+         _dumper_controller->wait_all_dumpers_complete();\n+         \/\/ The parallel writer has updated the backend, need to update global writer's buffer.\n+         DumperSupport::end_of_dump(&pw);\n+         \/\/ done with writing. Release the worker threads.\n+         pw.deactivate();\n+       } else {\n+         pw.finish_dump_segment(true);\n+         _dumper_controller->dumper_complete();\n+       }\n+    }\n+    \/\/ All dumpers are completed and the backend has been deactivated by VM dumper.\n+    return;\n+  }\n@@ -1845,0 +2243,1 @@\n+  assert(Thread::current()->is_VM_thread(), \"Heap dumper must be VM thread.\");\n@@ -1908,1 +2307,1 @@\n-int HeapDumper::dump(const char* path, outputStream* out, int compression) {\n+int HeapDumper::dump(const char* path, outputStream* out, int compression, uint num_dump_threads) {\n@@ -1916,1 +2315,0 @@\n-\n@@ -1943,1 +2341,1 @@\n-  VM_HeapDumper dumper(&writer, _gc_before_heap_dump, _oome);\n+  VM_HeapDumper dumper(&writer, _gc_before_heap_dump, _oome, num_dump_threads);\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":572,"deletions":174,"binary":false,"changes":746,"status":"modified"},{"patch":"@@ -74,1 +74,2 @@\n-  int dump(const char* path, outputStream* out = NULL, int compression = -1);\n+  \/\/ parallel_thread_num >= 0 indicates thread numbers of parallel object dump\n+  int dump(const char* path, outputStream* out = NULL, int compression = -1, uint parallel_thread_num = 1);\n","filename":"src\/hotspot\/share\/services\/heapDumper.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -240,0 +240,25 @@\n+void CompressionBackend::flush_buffer() {\n+  assert(_active, \"Must be active\");\n+\n+  MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ Make sure we write the last partially filled buffer.\n+  if ((_current != NULL) && (_current->_in_used > 0)) {\n+    _current->_id = _next_id++;\n+    _to_compress.add_last(_current);\n+    _current = NULL;\n+    ml.notify_all();\n+  }\n+\n+  \/\/ Wait for the threads to drain the compression work list.\n+  while (!_to_compress.is_empty()) {\n+    \/\/ If we have no threads, compress the current one itself.\n+    if (_nr_of_threads == 0) {\n+      MutexUnlocker mu(_lock, Mutex::_no_safepoint_check_flag);\n+      thread_loop(true);\n+    } else {\n+      ml.wait();\n+    }\n+  }\n+}\n+\n@@ -376,1 +401,26 @@\n-void CompressionBackend::get_new_buffer(char** buffer, size_t* used, size_t* max) {\n+void CompressionBackend::flush_external_buffer(char* buffer, size_t used, size_t max) {\n+  assert(buffer != NULL && used != 0 && max != 0, \"Invalid data send to compression backend\");\n+  assert(_active == true, \"Backend must be active when flushing external buffer\");\n+  \/\/ force flush buffered data and get new buffer.\n+  char* buf;\n+  size_t tmp_used = 0;\n+  size_t tmp_max = 0;\n+\n+  MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+  \/\/ first try current work. if it is clean\n+  if (_current->_in_used == 0) {\n+    buf = _current->_in;\n+  } else {\n+    MutexUnlocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+    get_new_buffer(&buf, &tmp_used, &tmp_max, true);\n+  }\n+  assert (_current != NULL && _current->_in != NULL && _current->_in_max >= max &&\n+          _current->_in_used == 0, \"Invalid buffer from compression backend\");\n+  \/\/ copy data to backend buffer\n+  memcpy(buf, buffer, used);\n+\n+  assert(_current->_in == buf, \"Must be current\");\n+  _current->_in_used += used;\n+}\n+\n+void CompressionBackend::get_new_buffer(char** buffer, size_t* used, size_t* max, bool force_reset) {\n@@ -380,1 +430,1 @@\n-    if (*used > 0) {\n+    if (*used > 0 || force_reset) {\n@@ -385,1 +435,1 @@\n-      if (_current->_in_max - _current->_in_used <= _max_waste) {\n+      if (_current->_in_max - _current->_in_used <= _max_waste || force_reset) {\n@@ -394,1 +444,0 @@\n-\n","filename":"src\/hotspot\/share\/services\/heapDumperCompression.cpp","additions":53,"deletions":4,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -221,0 +221,3 @@\n+  \/\/ sets up a internal buffer, fill with external buffer and send to compressor\n+  void flush_external_buffer(char* buffer, size_t used, size_t max);\n+\n@@ -222,1 +225,1 @@\n-  void get_new_buffer(char** buffer, size_t* used, size_t* max);\n+  void get_new_buffer(char** buffer, size_t* used, size_t* max, bool force_reset = false);\n@@ -229,0 +232,3 @@\n+\n+  \/\/ Flush all compressed data in buffer to file\n+  void flush_buffer();\n","filename":"src\/hotspot\/share\/services\/heapDumperCompression.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"}]}