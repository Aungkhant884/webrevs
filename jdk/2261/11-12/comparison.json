{"files":[{"patch":"@@ -383,1 +383,1 @@\n-\/\/ Supports I\/O ooperations for a dump\n+\/\/ Supports I\/O operations for a dump\n@@ -443,0 +443,9 @@\n+  \/\/ Refresh to get new buffer\n+  void refresh() {\n+    assert (_in_dump_segment ==false, \"Sanity check\");\n+    _buffer = NULL;\n+    _size = io_buffer_max_size;\n+    _pos = 0;\n+    flush();\n+  }\n+\n@@ -554,2 +563,0 @@\n-  } else {\n-    printf(\"no-op finish dump\\n\");\n@@ -620,0 +627,1 @@\n+\n@@ -634,0 +642,1 @@\n+\/\/ Buffer queue used for parallel dump.\n@@ -662,1 +671,1 @@\n-    if (_head == NULL) return NULL;\n+    if (_head == NULL)  return NULL;\n@@ -666,0 +675,3 @@\n+    if (_head == NULL) {\n+      _tail = NULL;\n+    }\n@@ -704,1 +716,1 @@\n-        flush_to_backend(force);\n+      flush_to_backend(force);\n@@ -723,0 +735,4 @@\n+     if (_buffer_base != NULL) {\n+       os::free(_buffer_base);\n+        _buffer_base = NULL;\n+     }\n@@ -742,16 +758,21 @@\n-\/\/ write raw bytes\n-virtual void write_raw(void* s, size_t len) {\n-  assert(!_in_dump_segment || (_sub_record_left >= len), \"sub-record too large\");\n-  debug_only(_sub_record_left -= len);\n-  assert(!_splited_data, \"invalid splited data\");\n-  _splited_data = true;\n-  \/\/ flush buffer to make room.\n-  while (len > buffer_size() - position()) {\n-    assert(!_in_dump_segment || _is_huge_sub_record,\n-           \"Cannot overflow in non-huge sub-record.\");\n-    size_t to_write = buffer_size() - position();\n-    memcpy(buffer() + position(), s, to_write);\n-    s = (void*) ((char*) s + to_write);\n-    len -= to_write;\n-    set_position(position() + to_write);\n-    flush();\n+  \/\/ write raw bytes\n+  virtual void write_raw(void* s, size_t len) {\n+    assert(!_in_dump_segment || (_sub_record_left >= len), \"sub-record too large\");\n+    debug_only(_sub_record_left -= len);\n+    assert(!_splited_data, \"invalid splited data\");\n+    _splited_data = true;\n+    \/\/ flush buffer to make room.\n+    while (len > buffer_size() - position()) {\n+      assert(!_in_dump_segment || _is_huge_sub_record,\n+             \"Cannot overflow in non-huge sub-record.\");\n+      size_t to_write = buffer_size() - position();\n+      memcpy(buffer() + position(), s, to_write);\n+      s = (void*) ((char*) s + to_write);\n+      len -= to_write;\n+      set_position(position() + to_write);\n+      flush();\n+    }\n+    _splited_data = false;\n+  \n+    memcpy(buffer() + position(), s, len);\n+    set_position(position() + len);\n@@ -759,6 +780,1 @@\n-  _splited_data = false;\n-\n-  memcpy(buffer() + position(), s, len);\n-  set_position(position() + len);\n-}\n-\n+  \n@@ -807,2 +823,1 @@\n-      \/\/ \"Could not allocate buffer list for writer\"\n-      set_error(\"Heap dumper can not enqueue to internal buffer\");\n+      set_error(\"Heap dumper can allocate memory\");\n@@ -1401,0 +1416,1 @@\n+\n@@ -1647,0 +1663,81 @@\n+\/\/ Large object heap dump support.\n+\/\/ To avoid memory consumption, when dumping large objects such as huge array and\n+\/\/ large objects whose size are larger than LARGE_OBJECT_DUMP_THRESHOLD, the scanned\n+\/\/ partial object\/array data will be send to backend directly instead of caching the\n+\/\/ whole object\/array internal buffer.\n+\/\/ The HeapDumpLargeObjectList is used to save the large object when dumper scanning\n+\/\/ the heap. The large objects could be added (push) parallelly by multiple dumpers.\n+\/\/ But they will be removed (pop) serially only by the VM thread.\n+class HeapDumpLargeObjectList : public CHeapObj<mtInternal> {\n+ private:\n+  class HeapDumpLargeObjectListElem : public CHeapObj<mtInternal> {\n+   public:\n+    HeapDumpLargeObjectListElem(oop obj) : _obj(obj), _next(NULL) { }\n+    oop _obj;\n+    HeapDumpLargeObjectListElem* _next;\n+  };\n+\n+  HeapDumpLargeObjectListElem* _head;\n+  uint _length;\n+  uint _length1;\n+\n+ public:\n+  HeapDumpLargeObjectList() : _head(NULL),  _length(0) { _length1 = 0; }\n+\n+  void atomic_push(oop obj) {\n+    assert (obj != NULL, \"sanity check\");\n+    HeapDumpLargeObjectListElem* entry = new HeapDumpLargeObjectListElem(obj);\n+    if (entry == NULL) {\n+      warning(\"Fail to allocate element for large object list\");\n+      return; \n+    }\n+    assert (entry->_obj != NULL, \"sanity check\");\n+    Atomic::inc(&_length1);\n+    \/\/ HeapDumpLargeObjectListElem* head_val = _head;\n+    while (true) {\n+      HeapDumpLargeObjectListElem* old_head = Atomic::load_acquire(&_head);\n+      HeapDumpLargeObjectListElem* new_head = entry;\n+      if (Atomic::cmpxchg(&_head, old_head, new_head) == old_head) {\n+        \/\/ successfully push\n+        new_head->_next = old_head;\n+        Atomic::inc(&_length);\n+        assert(new_head->_obj == obj, \"must equal\");\n+        return;\n+      }\n+    }\n+  }\n+\n+  oop pop() {\n+    if (_head == NULL) {\n+      assert(_length == 0, \"sanity check\");\n+      return NULL;\n+    }\n+    HeapDumpLargeObjectListElem* entry = _head;\n+    if (_head->_next != NULL) {\n+      _head = _head->_next;\n+    }\n+    entry->_next = NULL;\n+    _length--;\n+    assert (entry != NULL, \"illegal larger object list entry\");\n+    oop ret = entry->_obj;\n+    delete entry;\n+    assert (ret != NULL, \"illegal oop pointer\");\n+    return ret;\n+  }\n+\n+  void drain(ObjectClosure* cl) {\n+    printf(\"drain large object queue at length %d\\n\", _length);\n+    while (_length > 0) {\n+      cl->do_object(pop());\n+    }\n+  }\n+\n+  bool is_empty() {\n+    return _length == 0;\n+  }\n+\n+  uint length() { return _length; }\n+\n+  static const size_t LargeObjectSizeThreshold = 128 * (1 << 20); \/\/ 128 MB\n+};\n+\n@@ -1650,1 +1747,0 @@\n-\n@@ -1654,0 +1750,1 @@\n+  HeapDumpLargeObjectList* _list;\n@@ -1656,0 +1753,2 @@\n+  \n+  bool is_large(oop o);\n@@ -1657,1 +1756,1 @@\n-  HeapObjectDumper(AbstractDumpWriter* writer) {\n+  HeapObjectDumper(AbstractDumpWriter* writer, HeapDumpLargeObjectList* list = NULL) {\n@@ -1659,0 +1758,1 @@\n+    _list = list;\n@@ -1678,0 +1778,7 @@\n+  \/\/ If large object list exist and it is large object\/array,\n+  \/\/ add oop into the list and skip scan, VM thread will process it later.\n+  if (_list != NULL && is_large(o)) {\n+    _list->atomic_push(o);\n+    return;\n+  }\n+\n@@ -1690,0 +1797,23 @@\n+bool HeapObjectDumper::is_large(oop o) {\n+  size_t size = 0;\n+  if (o->is_instance()) {\n+    InstanceKlass* ik = InstanceKlass::cast(o->klass());\n+    size = DumperSupport::instance_size(ik);\n+  } else if (o->is_objArray()) {\n+    objArrayOop array = objArrayOop(o);\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+    assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n+    int length = array->length();\n+    int type_size = sizeof(address);\n+    size = (size_t)length * type_size;\n+  } else if (o->is_typeArray()) {\n+    typeArrayOop array = typeArrayOop(o);\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+    assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n+    int length = array->length();\n+    int type_size = type2aelembytes(type);\n+    size = (size_t)length * type_size;\n+  }\n+  return size > HeapDumpLargeObjectList::LargeObjectSizeThreshold;\n+}\n+\n@@ -1761,0 +1891,1 @@\n+  HeapDumpLargeObjectList* _large_object_list;\n@@ -1852,0 +1983,3 @@\n+  \/\/ large objects\n+  void dump_large_objects(ObjectClosure* writer);\n+\n@@ -1867,0 +2001,1 @@\n+    _large_object_list = new (std::nothrow) HeapDumpLargeObjectList();\n@@ -1897,0 +2032,1 @@\n+    delete _large_object_list;\n@@ -2228,1 +2364,1 @@\n-         HeapObjectDumper obj_dumper(&pw);\n+         HeapObjectDumper obj_dumper(&pw, _large_object_list);\n@@ -2235,4 +2371,6 @@\n-         \/\/ The parallel writer has updated the backend, need to update global writer's buffer.\n-         DumperSupport::end_of_dump(&pw);\n-         \/\/ done with writing. Release the worker threads.\n-         pw.deactivate();\n+         \/\/ clear internal buffer;\n+         pw.finish_dump_segment(true);\n+\n+         \/\/ refresh the global_writer's buffer and position;\n+         writer()->refresh();\n+\n@@ -2242,0 +2380,1 @@\n+         return;\n@@ -2244,2 +2383,0 @@\n-    \/\/ All dumpers are completed and the backend has been deactivated by VM dumper.\n-    return;\n@@ -2249,0 +2386,3 @@\n+  \/\/ Use writer() rather than ParDumpWriter to avoid memory consumption.\n+  HeapObjectDumper obj_dumper(writer());\n+  dump_large_objects(&obj_dumper);\n@@ -2251,1 +2391,0 @@\n-\n@@ -2311,0 +2450,8 @@\n+\/\/ dump the large objects.\n+void VM_HeapDumper::dump_large_objects(ObjectClosure* cl) {\n+  if (_large_object_list->is_empty()) {\n+    return;\n+  }\n+  _large_object_list->drain(cl);\n+}\n+\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":186,"deletions":39,"binary":false,"changes":225,"status":"modified"},{"patch":"@@ -429,1 +429,0 @@\n-\n@@ -432,1 +431,0 @@\n-\n","filename":"src\/hotspot\/share\/services\/heapDumperCompression.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"}]}