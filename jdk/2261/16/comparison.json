{"files":[{"patch":"@@ -250,0 +250,99 @@\n+\n+    \/\/ parallel thread number for heap dump, initialize based on active processor count.\n+    \/\/ Note the real number of threads used is also determined by active workers and compression\n+    \/\/ backend thread number, see heapDumper.cpp.\n+    uint parallel_thread_num = MAX2<uint>(1, (uint)os::initial_active_processor_count() * 3 \/ 8);\n+    \/\/ Request a full GC before heap dump if live_objects_only = true\n+    \/\/ This helps reduces the amount of unreachable objects in the dump\n+    \/\/ and makes it easier to browse.\n+    HeapDumper dumper(live_objects_only \/* request GC *\/);\n+    dumper.dump(path, out, (int)level, (uint)parallel_thread_num);\n+  }\n+  return JNI_OK;\n+}\n+\n+\/\/ Return the number of arguments parsed.\n+static int parse_args(char* line, const char** args, uint args_count, const char delim) {\n+  if (line == NULL || args == NULL || delim == '\\0')\n+    return 0;\n+\n+  char* ptr = line;\n+  uint count = 0;\n+  while (count < args_count) {\n+    args[count++] = ptr;\n+    while (*ptr != delim && *ptr != '\\0') {\n+      ptr++;\n+    }\n+    if (*ptr == '\\0') {\n+      return count;\n+    }\n+    *ptr = '\\0';\n+    ptr++;\n+  }\n+  return count;\n+}\n+\n+\/\/ Implementation of \"dumpheapext\" command.\n+\/\/ See also: HeapDumpDCmd class\n+\/\/\n+\/\/ Input arguments :-\n+\/\/   arg0: Name of the dump file\n+\/\/   arg1: \"-live\" or \"-all\"\n+\/\/   arg2: more_args: \"compress_level,parallel\"\n+jint dump_heap_ext(AttachOperation* op, outputStream* out) {\n+  \/\/ Possible argument number for op->arg(2).\n+  const int MAX_EXTRA_ARGS_COUNT = 2;\n+  const char* extra_args[MAX_EXTRA_ARGS_COUNT] = {NULL};\n+  const char* arg_str = op->arg(2);\n+  const char* path = NULL;\n+  bool live_objects_only = true;   \/\/ default is true to retain the behavior before this change is made\n+\n+  \/\/ First process filename and liveopt.\n+  \/\/ filename\n+  path = op->arg(0);\n+  if (path == NULL || path[0] == '\\0') {\n+    out->print_cr(\"No dump file specified\");\n+    return JNI_ERR;\n+  } else {\n+    \/\/ -live\n+    const char* arg1 = op->arg(1);\n+    if (arg1 != NULL && (strlen(arg1) > 0)) {\n+      if (strcmp(arg1, \"-all\") != 0 && strcmp(arg1, \"-live\") != 0) {\n+        out->print_cr(\"Invalid argument to dumpheap operation: %s\", arg1);\n+        return JNI_ERR;\n+      }\n+      live_objects_only = strcmp(arg1, \"-live\") == 0;\n+    }\n+  }\n+\n+  \/\/ Then parse arguments from op->arg(2).\n+  \/\/ Format: \"compress_level,parallel\".\n+  if (arg_str != NULL && arg_str[0] != '\\0') {\n+    size_t args_len = strlen(arg_str);\n+    char* args_line = NEW_C_HEAP_ARRAY(char, args_len + 1, mtInternal);\n+    snprintf(args_line, args_len + 1, \"%s\", arg_str);\n+    int args_count = parse_args(args_line, extra_args, MAX_EXTRA_ARGS_COUNT, ',');\n+    \/\/ gz=\n+    const char* num_str = extra_args[0];\n+    uintx level = 0;\n+    if (num_str != NULL && num_str[0] != '\\0') {\n+      if (!Arguments::parse_uintx(num_str, &level, 0)) {\n+        out->print_cr(\"Invalid compress level: [%s]\", num_str);\n+        return JNI_ERR;\n+      } else if (level < 1 || level > 9) {\n+        out->print_cr(\"Compression level out of range (1-9): \" UINTX_FORMAT, level);\n+        return JNI_ERR;\n+      }\n+    }\n+    \/\/ parallel\n+    uint parallel_thread_num = MAX2<uint>(1, (uint)os::initial_active_processor_count() * 3 \/ 8);\n+    const char* par_str = extra_args[1];\n+    if (par_str != NULL && par_str[0] != '\\0') {\n+      uintx num;\n+      if (!Arguments::parse_uintx(par_str, &num, 0)) {\n+        out->print_cr(\"Invalid parallel thread number: [%s]\", par_str);\n+        return JNI_ERR;\n+      }\n+      parallel_thread_num = num == 0 ? parallel_thread_num : (uint)num;\n+    }\n+\n@@ -254,1 +353,2 @@\n-    dumper.dump(op->arg(0), out, (int)level);\n+    dumper.dump(path, out, (int)level, (uint)parallel_thread_num);\n+    FREE_C_HEAP_ARRAY(char, args_line);\n@@ -259,0 +359,1 @@\n+\n@@ -360,0 +461,1 @@\n+  { \"dumpheapext\",      dump_heap_ext },\n","filename":"src\/hotspot\/share\/services\/attachListener.cpp","additions":103,"deletions":1,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -384,3 +384,3 @@\n-\n-class DumpWriter : public StackObj {\n- private:\n+\/\/ Base class for dump and parallel dump\n+class AbstractDumpWriter : public StackObj {\n+ protected:\n@@ -402,3 +402,1 @@\n-  CompressionBackend _backend; \/\/ Does the actual writing.\n-\n-  void flush();\n+  virtual void flush(bool force = false) = 0;\n@@ -408,1 +406,0 @@\n-  size_t position() const                       { return _pos; }\n@@ -416,1 +413,0 @@\n-\n@@ -418,4 +414,5 @@\n-  \/\/ Takes ownership of the writer and compressor.\n-  DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor);\n-\n-  ~DumpWriter();\n+  AbstractDumpWriter() :\n+    _buffer(NULL),\n+    _size(io_buffer_max_size),\n+    _pos(0),\n+    _in_dump_segment(false) { }\n@@ -424,3 +421,2 @@\n-  julong bytes_written() const          { return (julong) _backend.get_written(); }\n-\n-  char const* error() const             { return _backend.error(); }\n+  virtual julong bytes_written() const = 0;\n+  virtual char const* error() const = 0;\n@@ -428,0 +424,1 @@\n+  size_t position() const                       { return _pos; }\n@@ -429,1 +426,1 @@\n-  void write_raw(void* s, size_t len);\n+  virtual void write_raw(void* s, size_t len);\n@@ -444,1 +441,10 @@\n-  void finish_dump_segment();\n+  void finish_dump_segment(bool force_flush = false);\n+  virtual void deactivate() = 0;\n+  \/\/ Refresh to get new buffer\n+  void refresh() {\n+    assert (_in_dump_segment ==false, \"Sanity check\");\n+    _buffer = NULL;\n+    _size = io_buffer_max_size;\n+    _pos = 0;\n+    flush();\n+  }\n@@ -446,4 +452,0 @@\n-  \/\/ Called by threads used for parallel writing.\n-  void writer_loop()                    { _backend.thread_loop(false); }\n-  \/\/ Called when finished to release the threads.\n-  void deactivate()                     { flush(); _backend.deactivate(); }\n@@ -452,15 +454,1 @@\n-\/\/ Check for error after constructing the object and destroy it in case of an error.\n-DumpWriter::DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor) :\n-  _buffer(NULL),\n-  _size(0),\n-  _pos(0),\n-  _in_dump_segment(false),\n-  _backend(writer, compressor, io_buffer_max_size, io_buffer_max_waste) {\n-  flush();\n-}\n-\n-DumpWriter::~DumpWriter() {\n-  flush();\n-}\n-\n-void DumpWriter::write_fast(void* s, size_t len) {\n+void AbstractDumpWriter::write_fast(void* s, size_t len) {\n@@ -470,1 +458,0 @@\n-\n@@ -475,1 +462,1 @@\n-bool DumpWriter::can_write_fast(size_t len) {\n+bool AbstractDumpWriter::can_write_fast(size_t len) {\n@@ -480,1 +467,1 @@\n-void DumpWriter::write_raw(void* s, size_t len) {\n+void AbstractDumpWriter::write_raw(void* s, size_t len) {\n@@ -488,1 +475,0 @@\n-\n@@ -501,5 +487,0 @@\n-\/\/ flush any buffered bytes to the file\n-void DumpWriter::flush() {\n-  _backend.get_new_buffer(&_buffer, &_pos, &_size);\n-}\n-\n@@ -510,1 +491,1 @@\n-void DumpWriter::write_u1(u1 x) {\n+void AbstractDumpWriter::write_u1(u1 x) {\n@@ -514,1 +495,1 @@\n-void DumpWriter::write_u2(u2 x) {\n+void AbstractDumpWriter::write_u2(u2 x) {\n@@ -520,1 +501,1 @@\n-void DumpWriter::write_u4(u4 x) {\n+void AbstractDumpWriter::write_u4(u4 x) {\n@@ -526,1 +507,1 @@\n-void DumpWriter::write_u8(u8 x) {\n+void AbstractDumpWriter::write_u8(u8 x) {\n@@ -532,1 +513,1 @@\n-void DumpWriter::write_objectID(oop o) {\n+void AbstractDumpWriter::write_objectID(oop o) {\n@@ -541,1 +522,1 @@\n-void DumpWriter::write_symbolID(Symbol* s) {\n+void AbstractDumpWriter::write_symbolID(Symbol* s) {\n@@ -550,1 +531,1 @@\n-void DumpWriter::write_id(u4 x) {\n+void AbstractDumpWriter::write_id(u4 x) {\n@@ -559,1 +540,1 @@\n-void DumpWriter::write_classID(Klass* k) {\n+void AbstractDumpWriter::write_classID(Klass* k) {\n@@ -563,1 +544,1 @@\n-void DumpWriter::finish_dump_segment() {\n+void AbstractDumpWriter::finish_dump_segment(bool force_flush) {\n@@ -574,0 +555,4 @@\n+    } else {\n+      \/\/ Finished process huge sub record\n+      \/\/ Set _is_huge_sub_record to false so the parallel dump writer could flush data to file.\n+      _is_huge_sub_record = false;\n@@ -576,1 +561,0 @@\n-    flush();\n@@ -578,0 +562,1 @@\n+    flush(force_flush);\n@@ -581,1 +566,1 @@\n-void DumpWriter::start_sub_record(u1 tag, u4 len) {\n+void AbstractDumpWriter::start_sub_record(u1 tag, u4 len) {\n@@ -587,1 +572,1 @@\n-    assert(position() == 0, \"Must be at the start\");\n+    assert(position() == 0 && buffer_size() > dump_segment_header_size, \"Must be at the start\");\n@@ -594,0 +579,1 @@\n+    assert (Bytes::get_Java_u4((address)(buffer() + 5)) == len, \"Inconsitent size!\");\n@@ -611,1 +597,1 @@\n-void DumpWriter::end_sub_record() {\n+void AbstractDumpWriter::end_sub_record() {\n@@ -618,0 +604,274 @@\n+\/\/ Supports I\/O operations for a dump\n+\n+class DumpWriter : public AbstractDumpWriter {\n+ private:\n+  CompressionBackend _backend; \/\/ Does the actual writing.\n+ protected:\n+  virtual void flush(bool force = false);\n+\n+ public:\n+  \/\/ Takes ownership of the writer and compressor.\n+  DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor);\n+\n+  \/\/ total number of bytes written to the disk\n+  virtual julong bytes_written() const          { return (julong) _backend.get_written(); }\n+\n+  virtual char const* error() const             { return _backend.error(); }\n+\n+  \/\/ Called by threads used for parallel writing.\n+  void writer_loop()                    { _backend.thread_loop(false); }\n+  \/\/ Called when finished to release the threads.\n+  virtual void deactivate()             { flush(); _backend.deactivate(); }\n+  \/\/ Get the backend pointer, used by parallel dump writer.\n+  CompressionBackend* backend_ptr() { return &_backend; }\n+\n+};\n+\n+\/\/ Check for error after constructing the object and destroy it in case of an error.\n+DumpWriter::DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor) :\n+  AbstractDumpWriter(),\n+  _backend(writer, compressor, io_buffer_max_size, io_buffer_max_waste) {\n+  flush();\n+}\n+\n+\/\/ flush any buffered bytes to the file\n+void DumpWriter::flush(bool force) {\n+  _backend.get_new_buffer(&_buffer, &_pos, &_size, force);\n+}\n+\n+\/\/ Buffer queue used for parallel dump.\n+struct ParWriterBufferQueueElem {\n+  char* _buffer;\n+  size_t _used;\n+  ParWriterBufferQueueElem* _next;\n+};\n+\n+class ParWriterBufferQueue : public CHeapObj<mtInternal> {\n+ private:\n+  ParWriterBufferQueueElem* _head;\n+  ParWriterBufferQueueElem* _tail;\n+  uint _length;\n+ public:\n+  ParWriterBufferQueue() : _head(NULL), _tail(NULL), _length(0) { }\n+\n+  void enqueue(ParWriterBufferQueueElem* entry) {\n+    if (_head == NULL) {\n+      assert(is_empty() && _tail == NULL, \"Sanity check\");\n+      _head = _tail = entry;\n+    } else {\n+      assert ((_tail->_next == NULL && _tail->_buffer != NULL), \"Buffer queue is polluted\");\n+      _tail->_next = entry;\n+      _tail = entry;\n+    }\n+    _length++;\n+    assert(_tail->_next == NULL, \"Bufer queue is polluted\");\n+  }\n+\n+  ParWriterBufferQueueElem* dequeue() {\n+    if (_head == NULL)  return NULL;\n+    ParWriterBufferQueueElem* entry = _head;\n+    assert (entry->_buffer != NULL, \"polluted buffer in writer list\");\n+    _head = entry->_next;\n+    if (_head == NULL) {\n+      _tail = NULL;\n+    }\n+    entry->_next = NULL;\n+    _length--;\n+    return entry;\n+  }\n+\n+  bool is_empty() {\n+    return _length == 0;\n+  }\n+\n+  uint length() { return _length; }\n+};\n+\n+\/\/ Support parallel heap dump.\n+class ParDumpWriter : public AbstractDumpWriter {\n+ private:\n+  \/\/ Lock used to guarantee the integrity of multiple buffers writing.\n+  static Monitor* _lock;\n+  \/\/ Pointer of backend from global DumpWriter.\n+  CompressionBackend* _backend_ptr;\n+  char const * _err;\n+  ParWriterBufferQueue* _buffer_queue;\n+  size_t _internal_buffer_used;\n+  char* _buffer_base;\n+  bool _splited_data;\n+  static const uint BackendFlushThreshold = 2;\n+ protected:\n+  virtual void flush(bool force = false) {\n+    assert(_pos != 0, \"must not be zero\");\n+    if (_pos != 0) {\n+      refresh_buffer();\n+    }\n+\n+    if (_splited_data || _is_huge_sub_record) {\n+      return;\n+    }\n+\n+    if (should_flush_buf_list(force)) {\n+      assert(!_in_dump_segment && !_splited_data && !_is_huge_sub_record, \"incomplete data send to backend!\\n\");\n+      flush_to_backend(force);\n+    }\n+  }\n+\n+ public:\n+  ParDumpWriter(DumpWriter* dw) :\n+    AbstractDumpWriter(),\n+    _backend_ptr(dw->backend_ptr()),\n+    _buffer_queue((new (std::nothrow) ParWriterBufferQueue())),\n+    _buffer_base(NULL),\n+    _splited_data(false) {\n+    \/\/ prepare internal buffer\n+    allocate_internal_buffer();\n+  }\n+\n+  ~ParDumpWriter() {\n+     assert(_buffer_queue != NULL, \"Sanity check\");\n+     assert((_internal_buffer_used == 0) && (_buffer_queue->is_empty()),\n+            \"All data must be send to backend\");\n+     if (_buffer_base != NULL) {\n+       os::free(_buffer_base);\n+        _buffer_base = NULL;\n+     }\n+     delete _buffer_queue;\n+     _buffer_queue = NULL;\n+  }\n+\n+  \/\/ total number of bytes written to the disk\n+  virtual julong bytes_written() const          { return (julong) _backend_ptr->get_written(); }\n+  virtual char const* error() const { return _err == NULL ? _backend_ptr->error() : _err; }\n+\n+  static void before_work() {\n+    assert(_lock == NULL, \"ParDumpWriter lock must be initialized only once\");\n+    _lock = new (std::nothrow) PaddedMonitor(Mutex::leaf, \"Parallel HProf writer lock\", true, Mutex::_safepoint_check_never);\n+  }\n+\n+  static void after_work() {\n+    assert(_lock != NULL, \"ParDumpWriter lock is not initialized\");\n+    delete _lock;\n+    _lock = NULL;\n+  }\n+\n+  \/\/ write raw bytes\n+  virtual void write_raw(void* s, size_t len) {\n+    assert(!_in_dump_segment || (_sub_record_left >= len), \"sub-record too large\");\n+    debug_only(_sub_record_left -= len);\n+    assert(!_splited_data, \"invalid splited data\");\n+    _splited_data = true;\n+    \/\/ flush buffer to make room.\n+    while (len > buffer_size() - position()) {\n+      assert(!_in_dump_segment || _is_huge_sub_record,\n+             \"Cannot overflow in non-huge sub-record.\");\n+      size_t to_write = buffer_size() - position();\n+      memcpy(buffer() + position(), s, to_write);\n+      s = (void*) ((char*) s + to_write);\n+      len -= to_write;\n+      set_position(position() + to_write);\n+      flush();\n+    }\n+    _splited_data = false;\n+    memcpy(buffer() + position(), s, len);\n+    set_position(position() + len);\n+  }\n+\n+  virtual void deactivate()             { flush(true); _backend_ptr->deactivate(); }\n+\n+ private:\n+  void allocate_internal_buffer() {\n+    assert(_buffer_queue != NULL, \"Internal buffer queue is not ready when allocate internal buffer\");\n+    assert(_buffer == NULL && _buffer_base == NULL, \"current buffer must be NULL before allocate\");\n+    _buffer_base = _buffer = (char*)os::malloc(io_buffer_max_size, mtInternal);\n+    if (_buffer == NULL) {\n+      set_error(\"Could not allocate buffer for writer\");\n+      return;\n+    }\n+    _pos = 0;\n+    _internal_buffer_used = 0;\n+    _size = io_buffer_max_size;\n+  }\n+\n+  void set_error(char const* new_error) {\n+    if ((new_error != NULL) && (_err == NULL)) {\n+      _err = new_error;\n+    }\n+  }\n+\n+  \/\/ Add buffer to internal list\n+  void refresh_buffer() {\n+    size_t expected_total = _internal_buffer_used + _pos;\n+    if (expected_total < io_buffer_max_size - io_buffer_max_waste) {\n+      \/\/ reuse current buffer.\n+      _internal_buffer_used = expected_total;\n+      assert(_size - _pos == io_buffer_max_size - expected_total, \"illegal resize of buffer\");\n+      _size -= _pos;\n+      _buffer += _pos;\n+      _pos = 0;\n+\n+      return;\n+    }\n+    \/\/ It is not possible here that expected_total is larger than io_buffer_max_size because\n+    \/\/ of limitation in write_xxx().\n+    assert(expected_total <= io_buffer_max_size, \"buffer overflow\");\n+    assert(_buffer - _buffer_base <= io_buffer_max_size, \"internal buffer overflow\");\n+    ParWriterBufferQueueElem* entry =\n+        (ParWriterBufferQueueElem*)os::malloc(sizeof(ParWriterBufferQueueElem), mtInternal);\n+    if (entry == NULL) {\n+      set_error(\"Heap dumper can allocate memory\");\n+      return;\n+    }\n+    entry->_buffer = _buffer_base;\n+    entry->_used = expected_total;\n+    entry->_next = NULL;\n+    \/\/ add to internal buffer queue\n+    _buffer_queue->enqueue(entry);\n+    _buffer_base =_buffer = NULL;\n+    allocate_internal_buffer();\n+  }\n+\n+  void reclaim_entry(ParWriterBufferQueueElem* entry) {\n+    assert(entry != NULL && entry->_buffer != NULL, \"Invalid entry to reclaim\");\n+    os::free(entry->_buffer);\n+    entry->_buffer = NULL;\n+    os::free(entry);\n+  }\n+\n+  void flush_buffer(char* buffer, size_t used) {\n+    assert(_lock->owner() == Thread::current(), \"flush buffer must hold lock\");\n+    size_t max = io_buffer_max_size;\n+    \/\/ get_new_buffer\n+    _backend_ptr->flush_external_buffer(buffer, used, max);\n+  }\n+\n+  bool should_flush_buf_list(bool force) {\n+    return force || _buffer_queue->length() > BackendFlushThreshold;\n+  }\n+\n+  void flush_to_backend(bool force) {\n+    \/\/ Guarantee there is only one writer update backend buffers.\n+    MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+    while (!_buffer_queue->is_empty()) {\n+      ParWriterBufferQueueElem* entry = _buffer_queue->dequeue();\n+      flush_buffer(entry->_buffer, entry->_used);\n+      \/\/ Delete buffer and entry.\n+      reclaim_entry(entry);\n+      entry = NULL;\n+    }\n+    assert(_pos == 0, \"available buffer must be clean before flush\");\n+    \/\/ Flush internal buffer.\n+    if (_internal_buffer_used > 0) {\n+      flush_buffer(_buffer_base, _internal_buffer_used);\n+      os::free(_buffer_base);\n+      _pos = 0;\n+      _internal_buffer_used = 0;\n+      _buffer_base = _buffer = NULL;\n+      \/\/ Allocate internal buffer for future use.\n+      allocate_internal_buffer();\n+    }\n+  }\n+};\n+\n+Monitor* ParDumpWriter::_lock = NULL;\n+\n@@ -624,1 +884,1 @@\n-  static void write_header(DumpWriter* writer, hprofTag tag, u4 len);\n+  static void write_header(AbstractDumpWriter* writer, hprofTag tag, u4 len);\n@@ -637,1 +897,1 @@\n-  static void dump_float(DumpWriter* writer, jfloat f);\n+  static void dump_float(AbstractDumpWriter* writer, jfloat f);\n@@ -639,1 +899,1 @@\n-  static void dump_double(DumpWriter* writer, jdouble d);\n+  static void dump_double(AbstractDumpWriter* writer, jdouble d);\n@@ -641,1 +901,1 @@\n-  static void dump_field_value(DumpWriter* writer, char type, oop obj, int offset);\n+  static void dump_field_value(AbstractDumpWriter* writer, char type, oop obj, int offset);\n@@ -645,1 +905,1 @@\n-  static void dump_static_fields(DumpWriter* writer, Klass* k);\n+  static void dump_static_fields(AbstractDumpWriter* writer, Klass* k);\n@@ -647,1 +907,1 @@\n-  static void dump_instance_fields(DumpWriter* writer, oop o);\n+  static void dump_instance_fields(AbstractDumpWriter* writer, oop o);\n@@ -651,1 +911,1 @@\n-  static void dump_instance_field_descriptors(DumpWriter* writer, Klass* k);\n+  static void dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k);\n@@ -653,1 +913,1 @@\n-  static void dump_instance(DumpWriter* writer, oop o);\n+  static void dump_instance(AbstractDumpWriter* writer, oop o);\n@@ -656,1 +916,1 @@\n-  static void dump_class_and_array_classes(DumpWriter* writer, Klass* k);\n+  static void dump_class_and_array_classes(AbstractDumpWriter* writer, Klass* k);\n@@ -659,1 +919,1 @@\n-  static void dump_basic_type_array_class(DumpWriter* writer, Klass* k);\n+  static void dump_basic_type_array_class(AbstractDumpWriter* writer, Klass* k);\n@@ -662,1 +922,1 @@\n-  static void dump_object_array(DumpWriter* writer, objArrayOop array);\n+  static void dump_object_array(AbstractDumpWriter* writer, objArrayOop array);\n@@ -664,1 +924,1 @@\n-  static void dump_prim_array(DumpWriter* writer, typeArrayOop array);\n+  static void dump_prim_array(AbstractDumpWriter* writer, typeArrayOop array);\n@@ -666,1 +926,1 @@\n-  static void dump_stack_frame(DumpWriter* writer, int frame_serial_num, int class_serial_num, Method* m, int bci);\n+  static void dump_stack_frame(AbstractDumpWriter* writer, int frame_serial_num, int class_serial_num, Method* m, int bci);\n@@ -669,1 +929,1 @@\n-  static int calculate_array_max_length(DumpWriter* writer, arrayOop array, short header_size);\n+  static int calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size);\n@@ -672,1 +932,1 @@\n-  static void end_of_dump(DumpWriter* writer);\n+  static void end_of_dump(AbstractDumpWriter* writer);\n@@ -686,1 +946,1 @@\n-void DumperSupport:: write_header(DumpWriter* writer, hprofTag tag, u4 len) {\n+void DumperSupport:: write_header(AbstractDumpWriter* writer, hprofTag tag, u4 len) {\n@@ -740,1 +1000,1 @@\n-void DumperSupport::dump_float(DumpWriter* writer, jfloat f) {\n+void DumperSupport::dump_float(AbstractDumpWriter* writer, jfloat f) {\n@@ -754,1 +1014,1 @@\n-void DumperSupport::dump_double(DumpWriter* writer, jdouble d) {\n+void DumperSupport::dump_double(AbstractDumpWriter* writer, jdouble d) {\n@@ -769,1 +1029,1 @@\n-void DumperSupport::dump_field_value(DumpWriter* writer, char type, oop obj, int offset) {\n+void DumperSupport::dump_field_value(AbstractDumpWriter* writer, char type, oop obj, int offset) {\n@@ -887,1 +1147,1 @@\n-void DumperSupport::dump_static_fields(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_static_fields(AbstractDumpWriter* writer, Klass* k) {\n@@ -930,1 +1190,1 @@\n-void DumperSupport::dump_instance_fields(DumpWriter* writer, oop o) {\n+void DumperSupport::dump_instance_fields(AbstractDumpWriter* writer, oop o) {\n@@ -953,1 +1213,1 @@\n-void DumperSupport::dump_instance_field_descriptors(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k) {\n@@ -968,1 +1228,1 @@\n-void DumperSupport::dump_instance(DumpWriter* writer, oop o) {\n+void DumperSupport::dump_instance(AbstractDumpWriter* writer, oop o) {\n@@ -991,1 +1251,1 @@\n-void DumperSupport::dump_class_and_array_classes(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_class_and_array_classes(AbstractDumpWriter* writer, Klass* k) {\n@@ -1080,1 +1340,1 @@\n-void DumperSupport::dump_basic_type_array_class(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_basic_type_array_class(AbstractDumpWriter* writer, Klass* k) {\n@@ -1115,1 +1375,1 @@\n-int DumperSupport::calculate_array_max_length(DumpWriter* writer, arrayOop array, short header_size) {\n+int DumperSupport::calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size) {\n@@ -1142,1 +1402,1 @@\n-void DumperSupport::dump_object_array(DumpWriter* writer, objArrayOop array) {\n+void DumperSupport::dump_object_array(AbstractDumpWriter* writer, objArrayOop array) {\n@@ -1176,1 +1436,1 @@\n-void DumperSupport::dump_prim_array(DumpWriter* writer, typeArrayOop array) {\n+void DumperSupport::dump_prim_array(AbstractDumpWriter* writer, typeArrayOop array) {\n@@ -1178,1 +1438,0 @@\n-\n@@ -1270,1 +1529,1 @@\n-void DumperSupport::dump_stack_frame(DumpWriter* writer,\n+void DumperSupport::dump_stack_frame(AbstractDumpWriter* writer,\n@@ -1299,2 +1558,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1302,1 +1561,1 @@\n-  SymbolTableDumper(DumpWriter* writer)     { _writer = writer; }\n+  SymbolTableDumper(AbstractDumpWriter* writer)     { _writer = writer; }\n@@ -1322,1 +1581,1 @@\n-  DumpWriter* _writer;\n+  AbstractDumpWriter* _writer;\n@@ -1325,1 +1584,1 @@\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1327,1 +1586,1 @@\n-  JNILocalsDumper(DumpWriter* writer, u4 thread_serial_num) {\n+  JNILocalsDumper(AbstractDumpWriter* writer, u4 thread_serial_num) {\n@@ -1356,2 +1615,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1360,1 +1619,1 @@\n-  JNIGlobalsDumper(DumpWriter* writer) {\n+  JNIGlobalsDumper(AbstractDumpWriter* writer) {\n@@ -1372,1 +1631,0 @@\n-\n@@ -1387,2 +1645,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1390,1 +1648,1 @@\n-  StickyClassDumper(DumpWriter* writer) {\n+  StickyClassDumper(AbstractDumpWriter* writer) {\n@@ -1404,0 +1662,78 @@\n+\/\/ Large object heap dump support.\n+\/\/ To avoid memory consumption, when dumping large objects such as huge array and\n+\/\/ large objects whose size are larger than LARGE_OBJECT_DUMP_THRESHOLD, the scanned\n+\/\/ partial object\/array data will be send to backend directly instead of caching the\n+\/\/ whole object\/array internal buffer.\n+\/\/ The HeapDumpLargeObjectList is used to save the large object when dumper scanning\n+\/\/ the heap. The large objects could be added (push) parallelly by multiple dumpers.\n+\/\/ But they will be removed (pop) serially only by the VM thread.\n+class HeapDumpLargeObjectList : public CHeapObj<mtInternal> {\n+ private:\n+  class HeapDumpLargeObjectListElem : public CHeapObj<mtInternal> {\n+   public:\n+    HeapDumpLargeObjectListElem(oop obj) : _obj(obj), _next(NULL) { }\n+    oop _obj;\n+    HeapDumpLargeObjectListElem* _next;\n+  };\n+\n+  HeapDumpLargeObjectListElem* _head;\n+  uint _length;\n+  uint _length1;\n+\n+ public:\n+  HeapDumpLargeObjectList() : _head(NULL),  _length(0) { _length1 = 0; }\n+\n+  void atomic_push(oop obj) {\n+    assert (obj != NULL, \"sanity check\");\n+    HeapDumpLargeObjectListElem* entry = new HeapDumpLargeObjectListElem(obj);\n+    if (entry == NULL) {\n+      warning(\"Fail to allocate element for large object list\");\n+      return;\n+    }\n+    assert (entry->_obj != NULL, \"sanity check\");\n+    Atomic::inc(&_length1);\n+    while (true) {\n+      HeapDumpLargeObjectListElem* old_head = Atomic::load_acquire(&_head);\n+      HeapDumpLargeObjectListElem* new_head = entry;\n+      if (Atomic::cmpxchg(&_head, old_head, new_head) == old_head) {\n+        \/\/ successfully push\n+        new_head->_next = old_head;\n+        Atomic::inc(&_length);\n+        assert(new_head->_obj == obj, \"must equal\");\n+        return;\n+      }\n+    }\n+  }\n+\n+  oop pop() {\n+    if (_head == NULL) {\n+      assert(_length == 0, \"sanity check\");\n+      return NULL;\n+    }\n+    HeapDumpLargeObjectListElem* entry = _head;\n+    if (_head->_next != NULL) {\n+      _head = _head->_next;\n+    }\n+    entry->_next = NULL;\n+    _length--;\n+    assert (entry != NULL, \"illegal larger object list entry\");\n+    oop ret = entry->_obj;\n+    delete entry;\n+    assert (ret != NULL, \"illegal oop pointer\");\n+    return ret;\n+  }\n+\n+  void drain(ObjectClosure* cl) {\n+    while (_length > 0) {\n+      cl->do_object(pop());\n+    }\n+  }\n+\n+  bool is_empty() {\n+    return _length == 0;\n+  }\n+\n+  uint length() { return _length; }\n+\n+  static const size_t LargeObjectSizeThreshold = 1 << 20; \/\/ 1 MB\n+};\n@@ -1408,1 +1744,0 @@\n-\n@@ -1411,3 +1746,2 @@\n-  DumpWriter* _writer;\n-\n-  DumpWriter* writer()                  { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  HeapDumpLargeObjectList* _list;\n@@ -1415,0 +1749,2 @@\n+  AbstractDumpWriter* writer()                  { return _writer; }\n+  bool is_large(oop o);\n@@ -1416,1 +1752,1 @@\n-  HeapObjectDumper(DumpWriter* writer) {\n+  HeapObjectDumper(AbstractDumpWriter* writer, HeapDumpLargeObjectList* list = NULL) {\n@@ -1418,0 +1754,1 @@\n+    _list = list;\n@@ -1437,0 +1774,7 @@\n+  \/\/ If large object list exist and it is large object\/array,\n+  \/\/ add oop into the list and skip scan, VM thread will process it later.\n+  if (_list != NULL && is_large(o)) {\n+    _list->atomic_push(o);\n+    return;\n+  }\n+\n@@ -1449,0 +1793,77 @@\n+bool HeapObjectDumper::is_large(oop o) {\n+  size_t size = 0;\n+  if (o->is_instance()) {\n+    InstanceKlass* ik = InstanceKlass::cast(o->klass());\n+    size = DumperSupport::instance_size(ik);\n+  } else if (o->is_objArray()) {\n+    objArrayOop array = objArrayOop(o);\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+    assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n+    int length = array->length();\n+    int type_size = sizeof(address);\n+    size = (size_t)length * type_size;\n+  } else if (o->is_typeArray()) {\n+    typeArrayOop array = typeArrayOop(o);\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+    assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n+    int length = array->length();\n+    int type_size = type2aelembytes(type);\n+    size = (size_t)length * type_size;\n+  }\n+  return size > HeapDumpLargeObjectList::LargeObjectSizeThreshold;\n+}\n+\n+\/\/ The dumper controller for parallel heap dump\n+class DumperController : public CHeapObj<mtInternal> {\n+ private:\n+   bool     _started;\n+   Monitor* _lock;\n+   uint   _dumper_number;\n+   uint   _waiting_number;\n+   uint   _complete_number;\n+\n+ public:\n+   DumperController(uint number) :\n+     _started(false),\n+     _lock(new (std::nothrow) PaddedMonitor(Mutex::leaf, \"Dumper Controller lock\",\n+    true, Mutex::_safepoint_check_never)),\n+     _dumper_number(number),\n+     _waiting_number(0),\n+     _complete_number(0) { }\n+\n+   ~DumperController() { delete _lock; }\n+\n+   void wait_for_start_signal() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_started == false) {\n+       _waiting_number++;\n+       ml.wait();\n+     }\n+     assert(_started == true,  \"dumper is waken up with wrong state\");\n+     _waiting_number--;\n+   }\n+\n+   void start_dump() {\n+     assert (_started == false, \"start dump with wrong state\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _started = true;\n+     ml.notify_all();\n+   }\n+\n+   void dumper_complete() {\n+     assert (_started == true, \"dumper complete with wrong state\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _complete_number++;\n+     ml.notify();\n+   }\n+\n+   void wait_all_dumpers_complete() {\n+     assert (_started == true, \"wrong state when wait for dumper complete\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_complete_number != _dumper_number) {\n+        ml.wait();\n+     }\n+     _started = false;\n+   }\n+};\n+\n@@ -1452,9 +1873,66 @@\n-  static VM_HeapDumper* _global_dumper;\n-  static DumpWriter*    _global_writer;\n-  DumpWriter*           _local_writer;\n-  JavaThread*           _oome_thread;\n-  Method*               _oome_constructor;\n-  bool _gc_before_heap_dump;\n-  GrowableArray<Klass*>* _klass_map;\n-  ThreadStackTrace** _stack_traces;\n-  int _num_threads;\n+  static VM_HeapDumper*   _global_dumper;\n+  static DumpWriter*      _global_writer;\n+  DumpWriter*             _local_writer;\n+  JavaThread*             _oome_thread;\n+  Method*                 _oome_constructor;\n+  bool                    _gc_before_heap_dump;\n+  GrowableArray<Klass*>*  _klass_map;\n+  ThreadStackTrace**      _stack_traces;\n+  int                     _num_threads;\n+  \/\/ parallel heap dump support\n+  uint                    _num_dumper_threads;\n+  uint                    _num_writter_threads;\n+  DumperController*       _dumper_controller;\n+  ParallelObjectIterator* _poi;\n+  HeapDumpLargeObjectList* _large_object_list;\n+\n+  static const size_t WritterType = 0;\n+  static const size_t DumperType = 1;\n+  static const size_t VMDumperType = 2;\n+\n+  size_t get_worker_type(uint worker_id) {\n+    assert(_num_writter_threads >= 1, \"Must be at least one writters\");\n+    \/\/ worker id of writter starts from 0\n+    if (worker_id < _num_writter_threads) {\n+        return WritterType;\n+    }\n+    \/\/ worker id of dumper starts from _num_dumper_threads\n+    if (worker_id < _num_writter_threads + _num_dumper_threads) {\n+        return DumperType;\n+    }\n+\n+    assert (worker_id == _num_writter_threads + _num_dumper_threads,\n+            \"Invalid worker id for heap dumper\/writter\");\n+    return VMDumperType;\n+  }\n+\n+  void prepare_parallel_dump(uint num_total) {\n+    assert (_dumper_controller == NULL, \"dumper controller must be NULL\");\n+    assert (num_total > 0, \"active workers number must >= 1\");\n+    \/\/ Dumper threads number must not be larger than active workers number.\n+    if (num_total < _num_dumper_threads) {\n+      _num_dumper_threads = num_total - 1 \/* VMThread *\/;\n+    }\n+    \/\/ Calculate dumper and writter threads number.\n+    _num_writter_threads = num_total - _num_dumper_threads;\n+    \/\/ If dumper threads number is zero, there is only VMThread work as a dumper.\n+    \/\/ If dumper threads number is equal to active workers, need at lest one thread work as writter.\n+    if (_num_dumper_threads > 0 && _num_writter_threads == 0) {\n+      _num_writter_threads = 1;\n+      _num_dumper_threads = num_total - _num_writter_threads;\n+    }\n+\n+    uint total_dumper_threads = _num_dumper_threads + 1 \/* VMThread *\/;\n+    \/\/ prepare parallel writer.\n+    if (_num_dumper_threads > 0) {\n+      ParDumpWriter::before_work();\n+      _dumper_controller = new (std::nothrow) DumperController(_num_dumper_threads);\n+      _poi = Universe::heap()->parallel_object_iterator(total_dumper_threads);\n+    }\n+  }\n+\n+  void finish_parallel_dump() {\n+    if (_num_dumper_threads > 0) {\n+      ParDumpWriter::after_work();\n+    }\n+  }\n@@ -1501,0 +1979,3 @@\n+  \/\/ large objects\n+  void dump_large_objects(ObjectClosure* writer);\n+\n@@ -1502,1 +1983,1 @@\n-  VM_HeapDumper(DumpWriter* writer, bool gc_before_heap_dump, bool oome) :\n+  VM_HeapDumper(DumpWriter* writer, bool gc_before_heap_dump, bool oome, uint num_dump_threads) :\n@@ -1513,0 +1994,4 @@\n+    _num_dumper_threads = num_dump_threads - 1; \/\/ consider vm thread.\n+    _dumper_controller = NULL;\n+    _poi = NULL;\n+    _large_object_list = new (std::nothrow) HeapDumpLargeObjectList();\n@@ -1526,0 +2011,1 @@\n+\n@@ -1533,0 +2019,8 @@\n+    if (_poi != NULL) {\n+      delete _poi;\n+      _poi = NULL;\n+    }\n+    if (_dumper_controller != NULL) {\n+      delete _dumper_controller;\n+      _dumper_controller = NULL;\n+    }\n@@ -1534,0 +2028,1 @@\n+    delete _large_object_list;\n@@ -1541,1 +2036,0 @@\n-\n@@ -1550,1 +2044,1 @@\n-void DumperSupport::end_of_dump(DumpWriter* writer) {\n+void DumperSupport::end_of_dump(AbstractDumpWriter* writer) {\n@@ -1774,0 +2268,1 @@\n+    prepare_parallel_dump(gang->active_workers());\n@@ -1775,0 +2270,1 @@\n+    finish_parallel_dump();\n@@ -1784,22 +2280,7 @@\n-    writer()->writer_loop();\n-    return;\n-  }\n-\n-  \/\/ Write the file header - we always use 1.0.2\n-  const char* header = \"JAVA PROFILE 1.0.2\";\n-\n-  \/\/ header is few bytes long - no chance to overflow int\n-  writer()->write_raw((void*)header, (int)strlen(header));\n-  writer()->write_u1(0); \/\/ terminator\n-  writer()->write_u4(oopSize);\n-  \/\/ timestamp is current time in ms\n-  writer()->write_u8(os::javaTimeMillis());\n-\n-  \/\/ HPROF_UTF8 records\n-  SymbolTableDumper sym_dumper(writer());\n-  SymbolTable::symbols_do(&sym_dumper);\n-\n-  \/\/ write HPROF_LOAD_CLASS records\n-  {\n-    LockedClassesDo locked_load_classes(&do_load_class);\n-    ClassLoaderDataGraph::classes_do(&locked_load_classes);\n+    if (get_worker_type(worker_id) == WritterType) {\n+      writer()->writer_loop();\n+      return;\n+    }\n+    if (_num_dumper_threads >= 1 && get_worker_type(worker_id) == DumperType) {\n+      _dumper_controller->wait_for_start_signal();\n+    }\n@@ -1807,1 +2288,21 @@\n-  Universe::basic_type_classes_do(&do_load_class);\n+  \/\/ The VM thread works on all non-heap data dumping and part of heap iteration.\n+  if (Thread::current()->is_VM_thread()) {\n+    \/\/ Write the file header - we always use 1.0.2\n+    const char* header = \"JAVA PROFILE 1.0.2\";\n+\n+    \/\/ header is few bytes long - no chance to overflow int\n+    writer()->write_raw((void*)header, (int)strlen(header));\n+    writer()->write_u1(0); \/\/ terminator\n+    writer()->write_u4(oopSize);\n+    \/\/ timestamp is current time in ms\n+    writer()->write_u8(os::javaTimeMillis());\n+    \/\/ HPROF_UTF8 records\n+    SymbolTableDumper sym_dumper(writer());\n+    SymbolTable::symbols_do(&sym_dumper);\n+\n+    \/\/ write HPROF_LOAD_CLASS records\n+    {\n+      LockedClassesDo locked_load_classes(&do_load_class);\n+      ClassLoaderDataGraph::classes_do(&locked_load_classes);\n+    }\n+    Universe::basic_type_classes_do(&do_load_class);\n@@ -1809,3 +2310,3 @@\n-  \/\/ write HPROF_FRAME and HPROF_TRACE records\n-  \/\/ this must be called after _klass_map is built when iterating the classes above.\n-  dump_stack_traces();\n+    \/\/ write HPROF_FRAME and HPROF_TRACE records\n+    \/\/ this must be called after _klass_map is built when iterating the classes above.\n+    dump_stack_traces();\n@@ -1813,4 +2314,22 @@\n-  \/\/ Writes HPROF_GC_CLASS_DUMP records\n-  {\n-    LockedClassesDo locked_dump_class(&do_class_dump);\n-    ClassLoaderDataGraph::classes_do(&locked_dump_class);\n+    \/\/ Writes HPROF_GC_CLASS_DUMP records\n+    {\n+      LockedClassesDo locked_dump_class(&do_class_dump);\n+      ClassLoaderDataGraph::classes_do(&locked_dump_class);\n+    }\n+    Universe::basic_type_classes_do(&do_basic_type_array_class_dump);\n+\n+    \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n+    do_threads();\n+\n+    \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n+    JNIGlobalsDumper jni_dumper(writer());\n+    JNIHandles::oops_do(&jni_dumper);\n+    \/\/ technically not jni roots, but global roots\n+    \/\/ for things like preallocated throwable backtraces\n+    Universe::vm_global()->oops_do(&jni_dumper);\n+\n+    \/\/ HPROF_GC_ROOT_STICKY_CLASS\n+    \/\/ These should be classes in the NULL class loader data, and not all classes\n+    \/\/ if !ClassUnloading\n+    StickyClassDumper class_dumper(writer());\n+    ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n@@ -1818,2 +2337,0 @@\n-  Universe::basic_type_classes_do(&do_basic_type_array_class_dump);\n-\n@@ -1826,18 +2343,37 @@\n-  HeapObjectDumper obj_dumper(writer());\n-  Universe::heap()->object_iterate(&obj_dumper);\n-\n-  \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n-  do_threads();\n-\n-  \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n-  JNIGlobalsDumper jni_dumper(writer());\n-  JNIHandles::oops_do(&jni_dumper);\n-  \/\/ technically not jni roots, but global roots\n-  \/\/ for things like preallocated throwable backtraces\n-  Universe::vm_global()->oops_do(&jni_dumper);\n-\n-  \/\/ HPROF_GC_ROOT_STICKY_CLASS\n-  \/\/ These should be classes in the NULL class loader data, and not all classes\n-  \/\/ if !ClassUnloading\n-  StickyClassDumper class_dumper(writer());\n-  ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n+  if (_num_dumper_threads == 0) {\n+    HeapObjectDumper obj_dumper(writer());\n+    Universe::heap()->object_iterate(&obj_dumper);\n+  } else {\n+    assert(get_worker_type(worker_id) == DumperType\n+          || get_worker_type(worker_id) == VMDumperType,\n+          \"must be dumper thread to do heap iteration\");\n+    if (get_worker_type(worker_id) == VMDumperType) {\n+      \/\/ Clear global writer's buffer.\n+      writer()->finish_dump_segment(true);\n+      \/\/ Notify dumpers to start heap iteration.\n+      _dumper_controller->start_dump();\n+    }\n+    \/\/ Heap iteration.\n+    {\n+       ParDumpWriter pw(writer());\n+       {\n+         HeapObjectDumper obj_dumper(&pw, _large_object_list);\n+         uint dumper_id = worker_id - _num_writter_threads;\n+         _poi->object_iterate(&obj_dumper, dumper_id);\n+       }\n+\n+       if (get_worker_type(worker_id) == VMDumperType) {\n+         _dumper_controller->wait_all_dumpers_complete();\n+         \/\/ clear internal buffer;\n+         pw.finish_dump_segment(true);\n+\n+         \/\/ refresh the global_writer's buffer and position;\n+         writer()->refresh();\n+\n+       } else {\n+         pw.finish_dump_segment(true);\n+         _dumper_controller->dumper_complete();\n+         return;\n+       }\n+    }\n+  }\n@@ -1845,0 +2381,4 @@\n+  assert(Thread::current()->is_VM_thread(), \"Heap dumper must be VM thread.\");\n+  \/\/ Use writer() rather than ParDumpWriter to avoid memory consumption.\n+  HeapObjectDumper obj_dumper(writer());\n+  dump_large_objects(&obj_dumper);\n@@ -1847,1 +2387,0 @@\n-\n@@ -1907,0 +2446,8 @@\n+\/\/ dump the large objects.\n+void VM_HeapDumper::dump_large_objects(ObjectClosure* cl) {\n+  if (_large_object_list->is_empty()) {\n+    return;\n+  }\n+  _large_object_list->drain(cl);\n+}\n+\n@@ -1908,1 +2455,1 @@\n-int HeapDumper::dump(const char* path, outputStream* out, int compression) {\n+int HeapDumper::dump(const char* path, outputStream* out, int compression, uint num_dump_threads) {\n@@ -1916,1 +2463,0 @@\n-\n@@ -1943,1 +2489,1 @@\n-  VM_HeapDumper dumper(&writer, _gc_before_heap_dump, _oome);\n+  VM_HeapDumper dumper(&writer, _gc_before_heap_dump, _oome, num_dump_threads);\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":718,"deletions":172,"binary":false,"changes":890,"status":"modified"},{"patch":"@@ -74,1 +74,2 @@\n-  int dump(const char* path, outputStream* out = NULL, int compression = -1);\n+  \/\/ parallel_thread_num >= 0 indicates thread numbers of parallel object dump\n+  int dump(const char* path, outputStream* out = NULL, int compression = -1, uint parallel_thread_num = 1);\n","filename":"src\/hotspot\/share\/services\/heapDumper.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -240,0 +240,25 @@\n+void CompressionBackend::flush_buffer() {\n+  assert(_active, \"Must be active\");\n+\n+  MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+\n+  \/\/ Make sure we write the last partially filled buffer.\n+  if ((_current != NULL) && (_current->_in_used > 0)) {\n+    _current->_id = _next_id++;\n+    _to_compress.add_last(_current);\n+    _current = NULL;\n+    ml.notify_all();\n+  }\n+\n+  \/\/ Wait for the threads to drain the compression work list.\n+  while (!_to_compress.is_empty()) {\n+    \/\/ If we have no threads, compress the current one itself.\n+    if (_nr_of_threads == 0) {\n+      MutexUnlocker mu(_lock, Mutex::_no_safepoint_check_flag);\n+      thread_loop(true);\n+    } else {\n+      ml.wait();\n+    }\n+  }\n+}\n+\n@@ -376,1 +401,26 @@\n-void CompressionBackend::get_new_buffer(char** buffer, size_t* used, size_t* max) {\n+void CompressionBackend::flush_external_buffer(char* buffer, size_t used, size_t max) {\n+  assert(buffer != NULL && used != 0 && max != 0, \"Invalid data send to compression backend\");\n+  assert(_active == true, \"Backend must be active when flushing external buffer\");\n+  \/\/ force flush buffered data and get new buffer.\n+  char* buf;\n+  size_t tmp_used = 0;\n+  size_t tmp_max = 0;\n+\n+  MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+  \/\/ first try current work. if it is clean\n+  if (_current->_in_used == 0) {\n+    buf = _current->_in;\n+  } else {\n+    MutexUnlocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+    get_new_buffer(&buf, &tmp_used, &tmp_max, true);\n+  }\n+  assert (_current != NULL && _current->_in != NULL && _current->_in_max >= max &&\n+          _current->_in_used == 0, \"Invalid buffer from compression backend\");\n+  \/\/ copy data to backend buffer\n+  memcpy(buf, buffer, used);\n+\n+  assert(_current->_in == buf, \"Must be current\");\n+  _current->_in_used += used;\n+}\n+\n+void CompressionBackend::get_new_buffer(char** buffer, size_t* used, size_t* max, bool force_reset) {\n@@ -379,2 +429,1 @@\n-\n-    if (*used > 0) {\n+    if (*used > 0 || force_reset) {\n@@ -382,1 +431,0 @@\n-\n@@ -385,1 +433,1 @@\n-      if (_current->_in_max - _current->_in_used <= _max_waste) {\n+      if (_current->_in_max - _current->_in_used <= _max_waste || force_reset) {\n@@ -394,1 +442,0 @@\n-\n","filename":"src\/hotspot\/share\/services\/heapDumperCompression.cpp","additions":53,"deletions":6,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -221,0 +221,3 @@\n+  \/\/ sets up a internal buffer, fill with external buffer and send to compressor\n+  void flush_external_buffer(char* buffer, size_t used, size_t max);\n+\n@@ -222,1 +225,1 @@\n-  void get_new_buffer(char** buffer, size_t* used, size_t* max);\n+  void get_new_buffer(char** buffer, size_t* used, size_t* max, bool force_reset = false);\n@@ -229,0 +232,3 @@\n+\n+  \/\/ Flush all compressed data in buffer to file\n+  void flush_buffer();\n","filename":"src\/hotspot\/share\/services\/heapDumperCompression.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+import com.sun.tools.attach.AttachOperationFailedException;\n@@ -212,1 +213,4 @@\n-        String compress_level = null;\n+        String compress_level = \"\";\n+        String parallel = \"\";\n+        String extraArgKV = \"\"; \/* whole key=value string of extra argument, e.g. parallel=1 *\/\n+        boolean hasExtraArgs = false;\n@@ -229,2 +233,8 @@\n-               compress_level = subopt.substring(\"gz=\".length());\n-               if (compress_level.length() == 0) {\n+                compress_level = subopt.substring(\"gz=\".length());\n+                if (compress_level.length() == 0) {\n+                     System.err.println(\"Fail: no number provided in option: '\" + subopt + \"'\");\n+                     usage(1);\n+                }\n+            } else if (subopt.startsWith(\"parallel=\")) {\n+                parallel = subopt.substring(\"parallel=\".length());\n+                if (parallel.length() == 0) {\n@@ -233,1 +243,3 @@\n-               }\n+                }\n+                hasExtraArgs = true;\n+                extraArgKV = subopt;\n@@ -247,2 +259,22 @@\n-        \/\/ dumpHeap is not the same as jcmd GC.heap_dump\n-        executeCommandForPid(pid, \"dumpheap\", filename, liveopt, compress_level);\n+        if (hasExtraArgs) {\n+            \/\/ There is a limitation that at most 3 arguments could be passed to hotspot.\n+            \/\/ For backward compatibility, pass filename and liveopt as 1st and 2nd argument and\n+            \/\/ then compose remaining arguments as the 3rd one, and use comma to seperate them.\n+            \/\/ The difinition of 3rd argument in current implementation is:\n+            \/\/        \"compress_level,parallel\"\n+            \/\/ Not that making all arguments as a whole string like jcmd did does not guarantee the\n+            \/\/ compatiabilty when the new jmap is uses on old version of JDK.\n+            \/\/ See AttachOperation::arg_count_max in attachListener.hpp for argument count limitation.\n+            String more_args = compress_level + \",\" + parallel;\n+            \/\/ dumpHeap is not the same as jcmd GC.heap_dump\n+            try {\n+              executeCommandForPid(pid, \"dumpheapext\", filename, liveopt, more_args);\n+            } catch (AttachOperationFailedException e) {\n+                \/\/ target to an old jvm which could not accept extra arguments.\n+                System.err.println(\"Fail: invalid option: '\" + extraArgKV +\"'\");\n+                usage(1);\n+            }\n+        } else {\n+            \/\/ dumpHeap is not the same as jcmd GC.heap_dump\n+            executeCommandForPid(pid, \"dumpheap\", filename, liveopt, compress_level);\n+        }\n@@ -309,6 +341,10 @@\n-        System.err.println(\"      live         dump only live objects (takes precedence if both \\\"live\\\" and \\\"all\\\" are specified)\");\n-        System.err.println(\"      all          dump all objects in the heap (default if one of \\\"live\\\" or \\\"all\\\" is not specified)\");\n-        System.err.println(\"      format=b     binary format\");\n-        System.err.println(\"      file=<file>  dump heap to <file>\");\n-        System.err.println(\"      gz=<number>  If specified, the heap dump is written in gzipped format using the given compression level.\");\n-        System.err.println(\"                   1 (recommended) is the fastest, 9 the strongest compression.\");\n+        System.err.println(\"      live                dump only live objects (takes precedence if both \\\"live\\\" and \\\"all\\\" are specified)\");\n+        System.err.println(\"      all                 dump all objects in the heap (default if one of \\\"live\\\" or \\\"all\\\" is not specified)\");\n+        System.err.println(\"      format=b            binary format\");\n+        System.err.println(\"      file=<file>         dump heap to <file>\");\n+        System.err.println(\"      gz=<number>         If specified, the heap dump is written in gzipped format using the given compression level.\");\n+        System.err.println(\"                          1 (recommended) is the fastest, 9 the strongest compression.\");\n+        System.err.println(\"      parallel=<number>   Number of parallel threads to use for heap dump:\");\n+        System.err.println(\"                          0 (the default) means let the VM determine the number of threads to use\");\n+        System.err.println(\"                          1 means use one thread (disable parallelism).\");\n+        System.err.println(\"                          For any other value the VM will try to use the specified number of threads, but might use fewer.\");\n@@ -319,7 +355,7 @@\n-        System.err.println(\"      live         count only live objects (takes precedence if both \\\"live\\\" and \\\"all\\\" are specified)\");\n-        System.err.println(\"      all          count all objects in the heap (default if one of \\\"live\\\" or \\\"all\\\" is not specified)\");\n-        System.err.println(\"      file=<file>  dump data to <file>\");\n-        System.err.println(\"      parallel=<number>  parallel threads number for heap iteration:\");\n-        System.err.println(\"                                  parallel=0 default behavior, use predefined number of threads\");\n-        System.err.println(\"                                  parallel=1 disable parallel heap iteration\");\n-        System.err.println(\"                                  parallel=<N> use N threads for parallel heap iteration\");\n+        System.err.println(\"      live                count only live objects (takes precedence if both \\\"live\\\" and \\\"all\\\" are specified)\");\n+        System.err.println(\"      all                 count all objects in the heap (default if one of \\\"live\\\" or \\\"all\\\" is not specified)\");\n+        System.err.println(\"      file=<file>         dump data to <file>\");\n+        System.err.println(\"      parallel=<number>   Number of parallel threads to use for heap inspection:\");\n+        System.err.println(\"                          0 (the default) means let the VM determine the number of threads to use\");\n+        System.err.println(\"                          1 means use one thread (disable parallelism).\");\n+        System.err.println(\"                          For any other value the VM will try to use the specified number of threads, but might use fewer.\");\n","filename":"src\/jdk.jcmd\/share\/classes\/sun\/tools\/jmap\/JMap.java","additions":55,"deletions":19,"binary":false,"changes":74,"status":"modified"}]}