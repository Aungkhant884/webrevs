[{"commit":{"message":"8277168: AArch64: Enable arraycopy partial inlining with SVE\n\nArraycopy partial inlining is a C2 compiler technique that avoids stub\ncall overhead in small-sized arraycopy operations by generating masked\nvector instructions. So far it works on x86 AVX512 only and this patch\nenables it on AArch64 with SVE.\n\nWe add AArch64 matching rule for VectorMaskGenNode and refactor that\nnode a little bit. The major change is moving the element type field\ninto its TypeVectMask bottom type. The reason is that AArch64 vector\nmasks are different for different vector element types.\n\nE.g., an x86 AVX512 vector mask value masking 3 least significant vector\nlanes (of any type) is like\n\n  0000 0000 ... 0000 0000 0000 0000 0111\n\nOn AArch64 SVE, this mask value can only be used for masking the 3 least\nsignificant lanes of bytes. But for 3 lanes of ints, the value should be\n\n  0000 0000 ... 0000 0000 0001 0001 0001\n\nwhere the least significant bit of each lane matters. So AArch64 matcher\nneeds to know the vector element type to generate right masks.\n\nAfter this patch, the C2 generated code for copying a 50-byte array on\nAArch64 SVE looks like\n\n  mov     x12, #0x32\n  whilelo p0.b, xzr, x12\n  add     x11, x11, #0x10\n  ld1b    {z16.b}, p0\/z, [x11]\n  add     x10, x10, #0x10\n  st1b    {z16.b}, p0, [x10]\n\nWe ran jtreg hotspot::hotspot_all, jdk::tier1~3 and langtools::tier1 on\nboth x86 AVX512 and AArch64 SVE machines, no issue is found. We tested\nJMH org\/openjdk\/bench\/java\/lang\/ArrayCopyAligned.java with small array\nsize arguments on a 512-bit SVE-featured CPU. We got below performance\ndata changes.\n\nBenchmark                  (length)  (Performance)\nArrayCopyAligned.testByte        10          -2.6%\nArrayCopyAligned.testByte        20          +4.7%\nArrayCopyAligned.testByte        30          +4.8%\nArrayCopyAligned.testByte        40         +21.7%\nArrayCopyAligned.testByte        50         +22.5%\nArrayCopyAligned.testByte        60         +28.4%\n\nThe test machine has SVE vector size of 512 bits, so we see performance\ngain for most array sizes less than 64 bytes. For very small arrays we\nsee a bit regression because a vector load\/store may be a bit slower\nthan 1 or 2 scalar loads\/stores."},"files":[{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad"},{"filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4"},{"filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.cpp"},{"filename":"src\/hotspot\/cpu\/arm\/arm.ad"},{"filename":"src\/hotspot\/cpu\/ppc\/ppc.ad"},{"filename":"src\/hotspot\/cpu\/s390\/s390.ad"},{"filename":"src\/hotspot\/cpu\/x86\/x86.ad"},{"filename":"src\/hotspot\/share\/opto\/c2_globals.hpp"},{"filename":"src\/hotspot\/share\/opto\/library_call.cpp"},{"filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp"},{"filename":"src\/hotspot\/share\/opto\/matcher.hpp"},{"filename":"src\/hotspot\/share\/opto\/type.cpp"},{"filename":"src\/hotspot\/share\/opto\/type.hpp"},{"filename":"src\/hotspot\/share\/opto\/vectornode.cpp"},{"filename":"src\/hotspot\/share\/opto\/vectornode.hpp"}],"sha":"0dbe96169ced3a0c9d754dd6e75ac1850b5482ce"}]