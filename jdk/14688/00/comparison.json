{"files":[{"patch":"@@ -785,0 +785,1 @@\n+#if INCLUDE_CDS_JAVA_HEAP\n@@ -789,1 +790,3 @@\n-  return CompressedKlassPointers::encode_not_null(requested_k, _requested_static_archive_bottom);\n+  address narrow_klass_base = _requested_static_archive_bottom - ArchiveHeapWriter::precomputed_narrow_klass_base_delta;\n+  const int narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+  return CompressedKlassPointers::encode_not_null(requested_k, narrow_klass_base, narrow_klass_shift);\n@@ -791,0 +794,1 @@\n+#endif \/\/ INCLUDE_CDS_JAVA_HEAP\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -195,0 +195,13 @@\n+\n+  \/\/ Archived heap object headers carry pre-computed narrow Klass ids calculated with the\n+  \/\/ following scheme:\n+  \/\/ 1) (mapping start - base) == 0, so base is the future mapping start address. nKlass are relative\n+  \/\/    to base: we can map the archive anywhere but then need to set encoding base to that address.\n+  \/\/ 2) shift must be large enough to result in an encoding range that covers the future Klass range.\n+  \/\/    That Klass range is defined by CDS archive size and future class space size. Luckily, the maximum\n+  \/\/    size can be predicted: archive size is assumed to be <1G, class space size capped at 3G, and at\n+  \/\/    runtime we put both regions adjacent to each other. Therefore, future Klass range size < 4G.\n+  \/\/    Since nKlass itself is 32 bit, our encoding range len is 4G, and since we set the base directly\n+  \/\/    at mapping start, these 4G are enough. Therefore, we don't need to shift at all (shift=0).\n+  static constexpr int precomputed_narrow_klass_shift = 0;\n+  static constexpr size_t precomputed_narrow_klass_base_delta = 0;\n","filename":"src\/hotspot\/share\/cds\/archiveHeapWriter.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -225,1 +225,7 @@\n-  _narrow_klass_shift = CompressedKlassPointers::shift();\n+#if INCLUDE_CDS_JAVA_HEAP\n+  _narrow_klass_base_delta = ArchiveHeapWriter::precomputed_narrow_klass_base_delta;\n+  _narrow_klass_shift = ArchiveHeapWriter::precomputed_narrow_klass_shift;\n+#else\n+  _narrow_klass_base_delta = 0;\n+  _narrow_klass_shift = -1;\n+#endif\n@@ -286,0 +292,1 @@\n+  st->print_cr(\"- narrow_klass_base_delta:        \" SIZE_FORMAT, _narrow_klass_base_delta);\n@@ -2021,2 +2028,2 @@\n-  log_info(cds)(\"    narrow_klass_base = \" PTR_FORMAT \", narrow_klass_shift = %d\",\n-                p2i(narrow_klass_base()), narrow_klass_shift());\n+  log_info(cds)(\"    narrow_klass_base_delta = \" SIZE_FORMAT \", narrow_klass_shift = %d\",\n+                narrow_klass_base_delta(), narrow_klass_shift());\n@@ -2040,1 +2047,3 @@\n-  if (narrow_klass_base() != CompressedKlassPointers::base() ||\n+  address archive_narrow_klass_base = (address)header()->mapped_base_address() - narrow_klass_base_delta();\n+\n+  if (archive_narrow_klass_base != CompressedKlassPointers::base() ||\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":13,"deletions":4,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -197,1 +197,2 @@\n-  int     _narrow_klass_shift;                    \/\/ save narrow klass base and shift\n+  size_t  _narrow_klass_base_delta;               \/\/ narrow Klass base and shift used to pre-calculate nKlass ids\n+  int     _narrow_klass_shift;                    \/\/  in archived objects (see comment in archiveHeapWriter.hpp)\n@@ -265,0 +266,1 @@\n+  size_t narrow_klass_base_delta()         const { return _narrow_klass_base_delta; }\n@@ -266,1 +268,0 @@\n-  address narrow_klass_base()              const { return (address)mapped_base_address(); }\n@@ -385,1 +386,1 @@\n-  address narrow_klass_base()  const { return header()->narrow_klass_base(); }\n+  size_t  narrow_klass_base_delta() const { return header()->narrow_klass_base_delta(); }\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1149,1 +1149,6 @@\n-          CompressedKlassPointers::initialize(cds_base, ccs_end - cds_base);\n+          address precomputed_narrow_klass_base = cds_base - static_mapinfo->narrow_klass_base_delta();\n+          const int precomputed_narrow_klass_shift = static_mapinfo->narrow_klass_shift();\n+          CompressedKlassPointers::initialize_for_given_encoding(\n+            cds_base, ccs_end - cds_base, \/\/ Klass range\n+            precomputed_narrow_klass_base, precomputed_narrow_klass_shift \/\/ precomputed encoding, see ArchiveHeapWriter\n+            );\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -189,0 +189,22 @@\n+\/\/ Given a klass range [addr, addr+len) and a given encoding scheme, assert that this scheme covers the range, then\n+\/\/ set this encoding scheme. Used by CDS at runtime to re-instate the scheme used to pre-compute klass ids for\n+\/\/ archived heap objects.\n+void CompressedKlassPointers::initialize_for_given_encoding(address addr, size_t len, address requested_base, int requested_shift) {\n+#ifdef _LP64\n+  assert(is_valid_base(requested_base), \"Address must be a valid encoding base\");\n+  address const end = addr + len;\n+\n+  const int narrow_klasspointer_bits = sizeof(narrowKlass) * 8;\n+  const size_t encoding_range_size = nth_bit(narrow_klasspointer_bits + requested_shift);\n+  address encoding_range_end = requested_base + encoding_range_size;\n+\n+  assert(requested_base <= addr && encoding_range_end >= end, \"Encoding does not cover the full Klass range\");\n+\n+  set_base(requested_base);\n+  set_shift(requested_shift);\n+  set_range(encoding_range_size);\n+\n+  #else\n+  fatal(\"64bit only.\");\n+#endif\n+}\n@@ -204,17 +226,4 @@\n-  if (UseSharedSpaces || DumpSharedSpaces) {\n-\n-    \/\/ Special requirements if CDS is active:\n-    \/\/ Encoding base and shift must be the same between dump and run time.\n-    \/\/   CDS takes care that the SharedBaseAddress and CompressedClassSpaceSize\n-    \/\/   are the same. Archive size will be probably different at runtime, but\n-    \/\/   it can only be smaller than at, never larger, since archives get\n-    \/\/   shrunk at the end of the dump process.\n-    \/\/   From that it follows that the range [addr, len) we are handed in at\n-    \/\/   runtime will start at the same address then at dumptime, and its len\n-    \/\/   may be smaller at runtime then it was at dump time.\n-    \/\/\n-    \/\/ To be very careful here, we avoid any optimizations and just keep using\n-    \/\/  the same address and shift value. Specifically we avoid using zero-based\n-    \/\/  encoding. We also set the expected value range to 4G (encoding range\n-    \/\/  cannot be larger than that).\n-\n+  \/\/ Otherwise we attempt to use a zero base if the range fits in lower 32G.\n+  if (end <= (address)KlassEncodingMetaspaceMax) {\n+    base = 0;\n+  } else {\n@@ -222,0 +231,1 @@\n+  }\n@@ -223,14 +233,2 @@\n-    \/\/ JDK-8265705\n-    \/\/ This is a temporary fix for aarch64: there, if the range-to-be-encoded is located\n-    \/\/  below 32g, either encoding base should be zero or base should be aligned to 4G\n-    \/\/  and shift should be zero. The simplest way to fix this for now is to force\n-    \/\/  shift to zero for both runtime and dumptime.\n-    \/\/ Note however that this is not a perfect solution. Ideally this whole function\n-    \/\/  should be CDS agnostic, that would simplify it - and testing - a lot. See JDK-8267141\n-    \/\/  for details.\n-    shift = 0;\n-\n-    \/\/ This must be true since at dumptime cds+ccs is 4G, at runtime it can\n-    \/\/  only be smaller, see comment above.\n-    assert(len <= 4 * G, \"Encoding range cannot be larger than 4G\");\n-    range = 4 * G;\n+  \/\/ Highest offset a Klass* can ever have in relation to base.\n+  range = end - base;\n@@ -238,0 +236,4 @@\n+  \/\/ We may not even need a shift if the range fits into 32bit:\n+  const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);\n+  if (range < UnscaledClassSpaceMax) {\n+    shift = 0;\n@@ -239,19 +241,1 @@\n-\n-    \/\/ Otherwise we attempt to use a zero base if the range fits in lower 32G.\n-    if (end <= (address)KlassEncodingMetaspaceMax) {\n-      base = 0;\n-    } else {\n-      base = addr;\n-    }\n-\n-    \/\/ Highest offset a Klass* can ever have in relation to base.\n-    range = end - base;\n-\n-    \/\/ We may not even need a shift if the range fits into 32bit:\n-    const uint64_t UnscaledClassSpaceMax = (uint64_t(max_juint) + 1);\n-    if (range < UnscaledClassSpaceMax) {\n-      shift = 0;\n-    } else {\n-      shift = LogKlassAlignmentInBytes;\n-    }\n-\n+    shift = LogKlassAlignmentInBytes;\n","filename":"src\/hotspot\/share\/oops\/compressedOops.cpp","additions":34,"deletions":50,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -169,0 +169,5 @@\n+  \/\/ Given a klass range [addr, addr+len) and a given encoding scheme, assert that this scheme covers the range, then\n+  \/\/ set this encoding scheme. Used by CDS at runtime to re-instate the scheme used to pre-compute klass ids for\n+  \/\/ archived heap objects.\n+  static void initialize_for_given_encoding(address addr, size_t len, address requested_base, int requested_shift);\n+\n@@ -185,1 +190,1 @@\n-  static inline Klass* decode_raw(narrowKlass v, address base);\n+  static inline Klass* decode_raw(narrowKlass v, address base, int shift);\n@@ -188,1 +193,1 @@\n-  static inline Klass* decode_not_null(narrowKlass v, address base);\n+  static inline Klass* decode_not_null(narrowKlass v, address base, int shift);\n@@ -191,1 +196,1 @@\n-  static inline narrowKlass encode_not_null(Klass* v, address base);\n+  static inline narrowKlass encode_not_null(Klass* v, address base, int shift);\n","filename":"src\/hotspot\/share\/oops\/compressedOops.hpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -126,1 +126,1 @@\n-  return decode_raw(v, base());\n+  return decode_raw(v, base(), shift());\n@@ -129,2 +129,2 @@\n-inline Klass* CompressedKlassPointers::decode_raw(narrowKlass v, address narrow_base) {\n-  return (Klass*)((uintptr_t)narrow_base +((uintptr_t)v << shift()));\n+inline Klass* CompressedKlassPointers::decode_raw(narrowKlass v, address narrow_base, int shift) {\n+  return (Klass*)((uintptr_t)narrow_base +((uintptr_t)v << shift));\n@@ -134,1 +134,1 @@\n-  return decode_not_null(v, base());\n+  return decode_not_null(v, base(), shift());\n@@ -137,1 +137,1 @@\n-inline Klass* CompressedKlassPointers::decode_not_null(narrowKlass v, address narrow_base) {\n+inline Klass* CompressedKlassPointers::decode_not_null(narrowKlass v, address narrow_base, int shift) {\n@@ -139,1 +139,1 @@\n-  Klass* result = decode_raw(v, narrow_base);\n+  Klass* result = decode_raw(v, narrow_base, shift);\n@@ -149,1 +149,1 @@\n-  return encode_not_null(v, base());\n+  return encode_not_null(v, base(), shift());\n@@ -152,1 +152,1 @@\n-inline narrowKlass CompressedKlassPointers::encode_not_null(Klass* v, address narrow_base) {\n+inline narrowKlass CompressedKlassPointers::encode_not_null(Klass* v, address narrow_base, int shift) {\n@@ -157,1 +157,1 @@\n-  uint64_t result = pd >> shift();\n+  uint64_t result = pd >> shift;\n@@ -159,1 +159,1 @@\n-  assert(decode_not_null(result, narrow_base) == v, \"reversibility\");\n+  assert(decode_not_null(result, narrow_base, shift) == v, \"reversibility\");\n","filename":"src\/hotspot\/share\/oops\/compressedOops.inline.hpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"}]}