{"files":[{"patch":"@@ -2437,0 +2437,9 @@\n+void Assembler::lzcntl(Register dst, Address src) {\n+  assert(VM_Version::supports_lzcnt(), \"encoding is treated as BSR\");\n+  InstructionMark im(this);\n+  emit_int8((unsigned char)0xF3);\n+  prefix(src, dst);\n+  emit_int16(0x0F, (unsigned char)0xBD);\n+  emit_operand(dst, src);\n+}\n+\n@@ -5864,0 +5873,9 @@\n+void Assembler::tzcntl(Register dst, Address src) {\n+  assert(VM_Version::supports_bmi1(), \"tzcnt instruction not supported\");\n+  InstructionMark im(this);\n+  emit_int8((unsigned char)0xF3);\n+  prefix(src, dst);\n+  emit_int16(0x0F, (unsigned char)0xBC);\n+  emit_operand(dst, src);\n+}\n+\n@@ -5871,0 +5889,9 @@\n+void Assembler::tzcntq(Register dst, Address src) {\n+  assert(VM_Version::supports_bmi1(), \"tzcnt instruction not supported\");\n+  InstructionMark im(this);\n+  emit_int8((unsigned char)0xF3);\n+  prefixq(src, dst);\n+  emit_int16(0x0F, (unsigned char)0xBC);\n+  emit_operand(dst, src);\n+}\n+\n@@ -11488,0 +11515,32 @@\n+void Assembler::sarxl(Register dst, Register src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xF7, (0xC0 | encode));\n+}\n+\n+void Assembler::sarxl(Register dst, Address src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  vex_prefix(src1, src2->encoding(), dst->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(dst, src1);\n+}\n+\n+void Assembler::sarxq(Register dst, Register src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src2->encoding(), src1->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xF7, (0xC0 | encode));\n+}\n+\n+void Assembler::sarxq(Register dst, Address src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  vex_prefix(src1, src2->encoding(), dst->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(dst, src1);\n+}\n+\n@@ -11495,0 +11554,9 @@\n+void Assembler::shlxl(Register dst, Address src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  vex_prefix(src1, src2->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(dst, src1);\n+}\n+\n@@ -11502,0 +11570,9 @@\n+void Assembler::shlxq(Register dst, Address src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  vex_prefix(src1, src2->encoding(), dst->encoding(), VEX_SIMD_66, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(dst, src1);\n+}\n+\n@@ -11509,0 +11586,9 @@\n+void Assembler::shrxl(Register dst, Address src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  vex_prefix(src1, src2->encoding(), dst->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(dst, src1);\n+}\n+\n@@ -11516,0 +11602,9 @@\n+void Assembler::shrxq(Register dst, Address src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  vex_prefix(src1, src2->encoding(), dst->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF7);\n+  emit_operand(dst, src1);\n+}\n+\n@@ -12470,0 +12565,9 @@\n+void Assembler::lzcntq(Register dst, Address src) {\n+  assert(VM_Version::supports_lzcnt(), \"encoding is treated as BSR\");\n+  InstructionMark im(this);\n+  emit_int8((unsigned char)0xF3);\n+  prefixq(src, dst);\n+  emit_int16(0x0F, (unsigned char)0xBD);\n+  emit_operand(dst, src);\n+}\n+\n@@ -12864,2 +12968,1 @@\n-\n-void Assembler::rorxq(Register dst, Register src, int imm8) {\n+void Assembler::rorxl(Register dst, Register src, int imm8) {\n@@ -12867,1 +12970,1 @@\n-  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n@@ -12872,1 +12975,1 @@\n-void Assembler::rorxd(Register dst, Register src, int imm8) {\n+void Assembler::rorxl(Register dst, Address src, int imm8) {\n@@ -12874,0 +12977,1 @@\n+  InstructionMark im(this);\n@@ -12875,0 +12979,9 @@\n+  vex_prefix(src, 0, dst->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_3A, &attributes);\n+  emit_int8((unsigned char)0xF0);\n+  emit_operand(dst, src);\n+  emit_int8(imm8);\n+}\n+\n+void Assembler::rorxq(Register dst, Register src, int imm8) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n@@ -12879,0 +12992,10 @@\n+void Assembler::rorxq(Register dst, Address src, int imm8) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src, 0, dst->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_3A, &attributes);\n+  emit_int8((unsigned char)0xF0);\n+  emit_operand(dst, src);\n+  emit_int8(imm8);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":127,"deletions":4,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -1439,0 +1439,1 @@\n+  void lzcntl(Register dst, Address src);\n@@ -1442,0 +1443,1 @@\n+  void lzcntq(Register dst, Address src);\n@@ -1977,0 +1979,2 @@\n+  void rorxl(Register dst, Register src, int imm8);\n+  void rorxl(Register dst, Address src, int imm8);\n@@ -1978,1 +1982,1 @@\n-  void rorxd(Register dst, Register src, int imm8);\n+  void rorxq(Register dst, Address src, int imm8);\n@@ -2114,0 +2118,1 @@\n+  void tzcntl(Register dst, Address src);\n@@ -2115,0 +2120,1 @@\n+  void tzcntq(Register dst, Address src);\n@@ -2190,0 +2196,4 @@\n+  void sarxl(Register dst, Register src1, Register src2);\n+  void sarxl(Register dst, Address src1, Register src2);\n+  void sarxq(Register dst, Register src1, Register src2);\n+  void sarxq(Register dst, Address src1, Register src2);\n@@ -2191,0 +2201,1 @@\n+  void shlxl(Register dst, Address src1, Register src2);\n@@ -2192,0 +2203,1 @@\n+  void shlxq(Register dst, Address src1, Register src2);\n@@ -2193,0 +2205,1 @@\n+  void shrxl(Register dst, Address src1, Register src2);\n@@ -2194,0 +2207,1 @@\n+  void shrxq(Register dst, Address src1, Register src2);\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -702,1 +702,1 @@\n-  Condition negate_condition(Condition cond);\n+  static Condition negate_condition(Condition cond);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -528,2 +528,2 @@\n-  rorxd(reg_y0, reg_e, 25);    \/\/ reg_y0 = reg_e >> 25   ; S1A\n-  rorxd(reg_y1, reg_e, 11);    \/\/ reg_y1 = reg_e >> 11    ; S1B\n+  rorxl(reg_y0, reg_e, 25);    \/\/ reg_y0 = reg_e >> 25   ; S1A\n+  rorxl(reg_y1, reg_e, 11);    \/\/ reg_y1 = reg_e >> 11    ; S1B\n@@ -533,1 +533,1 @@\n-  rorxd(reg_y1, reg_e, 6);     \/\/ reg_y1 = (reg_e >> 6)    ; S1\n+  rorxl(reg_y1, reg_e, 6);     \/\/ reg_y1 = (reg_e >> 6)    ; S1\n@@ -541,1 +541,1 @@\n-  rorxd(reg_T1, reg_a, 13);   \/\/ reg_T1 = reg_a >> 13    ; S0B\n+  rorxl(reg_T1, reg_a, 13);   \/\/ reg_T1 = reg_a >> 13    ; S0B\n@@ -543,1 +543,1 @@\n-  rorxd(reg_y1, reg_a, 22);   \/\/ reg_y1 = reg_a >> 22    ; S0A\n+  rorxl(reg_y1, reg_a, 22);   \/\/ reg_y1 = reg_a >> 22    ; S0A\n@@ -547,1 +547,1 @@\n-  rorxd(reg_T1, reg_a, 2);    \/\/ reg_T1 = (reg_a >> 2)    ; S0\n+  rorxl(reg_T1, reg_a, 2);    \/\/ reg_T1 = (reg_a >> 2)    ; S0\n@@ -601,2 +601,2 @@\n-  rorxd(r13, reg_e, 25);      \/\/ r13 = reg_e >> 25    ; S1A\n-  rorxd(r14, reg_e, 11);      \/\/  r14 = reg_e >> 11    ; S1B\n+  rorxl(r13, reg_e, 25);      \/\/ r13 = reg_e >> 25    ; S1A\n+  rorxl(r14, reg_e, 11);      \/\/  r14 = reg_e >> 11    ; S1B\n@@ -607,1 +607,1 @@\n-  rorxd(r12, reg_a, 13);      \/\/ r12 = reg_a >> 13      ; S0B\n+  rorxl(r12, reg_a, 13);      \/\/ r12 = reg_a >> 13      ; S0B\n@@ -611,1 +611,1 @@\n-  rorxd(r14, reg_e, 6);       \/\/ r14 = (reg_e >> 6)    ; S1\n+  rorxl(r14, reg_e, 6);       \/\/ r14 = (reg_e >> 6)    ; S1\n@@ -615,1 +615,1 @@\n-  rorxd(r14, reg_a, 22);      \/\/ r14 = reg_a >> 22    ; S0A\n+  rorxl(r14, reg_a, 22);      \/\/ r14 = reg_a >> 22    ; S0A\n@@ -621,1 +621,1 @@\n-  rorxd(r12, reg_a, 2);      \/\/ r12 = (reg_a >> 2)    ; S0\n+  rorxl(r12, reg_a, 2);      \/\/ r12 = (reg_a >> 2)    ; S0\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86_sha.cpp","additions":12,"deletions":12,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -6584,0 +6584,12 @@\n+instruct countLeadingZerosI_mem(rRegI dst, memory src, rFlagsReg cr) %{\n+  predicate(UseCountLeadingZerosInstruction);\n+  match(Set dst (CountLeadingZerosI (LoadI src)));\n+  effect(KILL cr);\n+\n+  format %{ \"lzcntl  $dst, $src\\t# count leading zeros (int)\" %}\n+  ins_encode %{\n+    __ lzcntl($dst$$Register, $src$$Address);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -6621,0 +6633,12 @@\n+instruct countLeadingZerosL_mem(rRegI dst, memory src, rFlagsReg cr) %{\n+  predicate(UseCountLeadingZerosInstruction);\n+  match(Set dst (CountLeadingZerosL (LoadL src)));\n+  effect(KILL cr);\n+\n+  format %{ \"lzcntq  $dst, $src\\t# count leading zeros (long)\" %}\n+  ins_encode %{\n+    __ lzcntq($dst$$Register, $src$$Address);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -6658,0 +6682,12 @@\n+instruct countTrailingZerosI_mem(rRegI dst, memory src, rFlagsReg cr) %{\n+  predicate(UseCountTrailingZerosInstruction);\n+  match(Set dst (CountTrailingZerosI (LoadI src)));\n+  effect(KILL cr);\n+\n+  format %{ \"tzcntl    $dst, $src\\t# count trailing zeros (int)\" %}\n+  ins_encode %{\n+    __ tzcntl($dst$$Register, $src$$Address);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -6690,0 +6726,12 @@\n+instruct countTrailingZerosL_mem(rRegI dst, memory src, rFlagsReg cr) %{\n+  predicate(UseCountTrailingZerosInstruction);\n+  match(Set dst (CountTrailingZerosL (LoadL src)));\n+  effect(KILL cr);\n+\n+  format %{ \"tzcntq    $dst, $src\\t# count trailing zeros (long)\" %}\n+  ins_encode %{\n+    __ tzcntq($dst$$Register, $src$$Address);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -7053,0 +7101,15 @@\n+instruct cmovI_imm_01(rRegI dst, immI_1 src1, immI_0 src2, rFlagsReg cr, cmpOp cop)\n+%{\n+  match(Set dst (CMoveI (Binary cop cr) (Binary src1 src2)));\n+\n+  ins_cost(150); \/\/ XXX\n+  format %{ \"setbn$cop $dst\\t# signed, int\\n\\t\"\n+            \"movzbl    $dst, $dst\" %}\n+  ins_encode %{\n+    Assembler::Condition cond = (Assembler::Condition)($cop$$cmpcode);\n+    __ setb(MacroAssembler::negate_condition(cond), $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -7065,0 +7128,15 @@\n+instruct cmovI_imm_01U(rRegI dst, immI_1 src1, immI_0 src2, rFlagsRegU cr, cmpOpU cop)\n+%{\n+  match(Set dst (CMoveI (Binary cop cr) (Binary src1 src2)));\n+\n+  ins_cost(150); \/\/ XXX\n+  format %{ \"setbn$cop $dst\\t# signed, int\\n\\t\"\n+            \"movzbl    $dst, $dst\" %}\n+  ins_encode %{\n+    Assembler::Condition cond = (Assembler::Condition)($cop$$cmpcode);\n+    __ setb(MacroAssembler::negate_condition(cond), $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -7076,0 +7154,15 @@\n+instruct cmovI_imm_01UCF(rRegI dst, immI_1 src1, immI_0 src2, rFlagsRegUCF cr, cmpOpUCF cop)\n+%{\n+  match(Set dst (CMoveI (Binary cop cr) (Binary src1 src2)));\n+\n+  ins_cost(150); \/\/ XXX\n+  format %{ \"setbn$cop $dst\\t# signed, int\\n\\t\"\n+            \"movzbl    $dst, $dst\" %}\n+  ins_encode %{\n+    Assembler::Condition cond = (Assembler::Condition)($cop$$cmpcode);\n+    __ setb(MacroAssembler::negate_condition(cond), $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -7212,0 +7305,15 @@\n+instruct cmovL_imm_01(rRegL dst, immL1 src1, immL0 src2, rFlagsReg cr, cmpOp cop)\n+%{\n+  match(Set dst (CMoveL (Binary cop cr) (Binary src1 src2)));\n+\n+  ins_cost(150); \/\/ XXX\n+  format %{ \"setbn$cop $dst\\t# signed, long\\n\\t\"\n+            \"movzbl    $dst, $dst\" %}\n+  ins_encode %{\n+    Assembler::Condition cond = (Assembler::Condition)($cop$$cmpcode);\n+    __ setb(MacroAssembler::negate_condition(cond), $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -7236,0 +7344,15 @@\n+instruct cmovL_imm_01U(rRegL dst, immL1 src1, immL0 src2, rFlagsRegU cr, cmpOpU cop)\n+%{\n+  match(Set dst (CMoveL (Binary cop cr) (Binary src1 src2)));\n+\n+  ins_cost(150); \/\/ XXX\n+  format %{ \"setbn$cop $dst\\t# unsigned, long\\n\\t\"\n+            \"movzbl    $dst, $dst\" %}\n+  ins_encode %{\n+    Assembler::Condition cond = (Assembler::Condition)($cop$$cmpcode);\n+    __ setb(MacroAssembler::negate_condition(cond), $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -7248,0 +7371,15 @@\n+instruct cmovL_imm_01UCF(rRegL dst, immL1 src1, immL0 src2, rFlagsRegUCF cr, cmpOpUCF cop)\n+%{\n+  match(Set dst (CMoveL (Binary cop cr) (Binary src1 src2)));\n+\n+  ins_cost(150); \/\/ XXX\n+  format %{ \"setbn$cop $dst\\t# unsigned, long\\n\\t\"\n+            \"movzbl    $dst, $dst\" %}\n+  ins_encode %{\n+    Assembler::Condition cond = (Assembler::Condition)($cop$$cmpcode);\n+    __ setb(MacroAssembler::negate_condition(cond), $dst$$Register);\n+    __ movzbl($dst$$Register, $dst$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -8901,0 +9039,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -8914,0 +9053,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -8924,0 +9064,25 @@\n+instruct salI_rReg_rReg(rRegI dst, rRegI src, rRegI shift)\n+%{\n+  \/\/ This is to match that of the memory variance\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (LShiftI src shift));\n+\n+  format %{ \"shlxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shlxl($dst$$Register, $src$$Register, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct salI_mem_rReg(rRegI dst, memory src, rRegI shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (LShiftI (LoadI src) shift));\n+\n+  format %{ \"shlxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shlxl($dst$$Register, $src$$Address, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -8979,0 +9144,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -8991,0 +9157,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9001,0 +9168,25 @@\n+instruct sarI_rReg_rReg(rRegI dst, rRegI src, rRegI shift)\n+%{\n+  \/\/ This is to match that of the memory variance\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (RShiftI src shift));\n+\n+  format %{ \"sarxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ sarxl($dst$$Register, $src$$Register, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct sarI_mem_rReg(rRegI dst, memory src, rRegI shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (RShiftI (LoadI src) shift));\n+\n+  format %{ \"sarxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ sarxl($dst$$Register, $src$$Address, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9056,0 +9248,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9069,0 +9262,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9079,0 +9273,25 @@\n+instruct shrI_rReg_rReg(rRegI dst, rRegI src, rRegI shift)\n+%{\n+  \/\/ This is to match that of the memory variance\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (URShiftI src shift));\n+\n+  format %{ \"shrxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shrxl($dst$$Register, $src$$Register, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct shrI_mem_rReg(rRegI dst, memory src, rRegI shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (URShiftI (LoadI src) shift));\n+\n+  format %{ \"shrxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shrxl($dst$$Register, $src$$Address, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9135,0 +9354,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9148,0 +9368,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9158,0 +9379,25 @@\n+instruct salL_rReg_rReg(rRegL dst, rRegL src, rRegI shift)\n+%{\n+  \/\/ This is to match that of the memory variance\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (LShiftL src shift));\n+\n+  format %{ \"shlxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shlxq($dst$$Register, $src$$Register, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct salL_mem_rReg(rRegL dst, memory src, rRegI shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (LShiftL (LoadL src) shift));\n+\n+  format %{ \"shlxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shlxq($dst$$Register, $src$$Address, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9213,0 +9459,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9226,0 +9473,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9236,0 +9484,25 @@\n+instruct sarL_rReg_rReg(rRegL dst, rRegL src, rRegI shift)\n+%{\n+  \/\/ This is to match that of the memory variance\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (RShiftL src shift));\n+\n+  format %{ \"sarxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ sarxq($dst$$Register, $src$$Register, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct sarL_mem_rReg(rRegL dst, memory src, rRegI shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (RShiftL (LoadL src) shift));\n+\n+  format %{ \"sarxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ sarxq($dst$$Register, $src$$Address, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9291,0 +9564,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9304,0 +9578,1 @@\n+  predicate(!VM_Version::supports_bmi2());\n@@ -9314,0 +9589,25 @@\n+instruct shrL_rReg_rReg(rRegL dst, rRegL src, rRegI shift)\n+%{\n+  \/\/ This is to match that of the memory variance\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (URShiftL src shift));\n+\n+  format %{ \"shrxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shrxq($dst$$Register, $src$$Register, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct shrL_mem_rReg(rRegL dst, memory src, rRegI shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && !n->in(2)->is_Con());\n+  match(Set dst (URShiftL (LoadL src) shift));\n+\n+  format %{ \"shrxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ shrxq($dst$$Register, $src$$Address, $shift$$Register);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9343,1 +9643,1 @@\n-instruct rolI_imm(rRegI dst, immI8 shift, rFlagsReg cr)\n+instruct rolI_immI8_legacy(rRegI dst, immI8 shift, rFlagsReg cr)\n@@ -9345,1 +9645,1 @@\n-  predicate(n->bottom_type()->basic_type() == T_INT);\n+  predicate(!VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_INT);\n@@ -9355,0 +9655,24 @@\n+instruct rolI_immI8(rRegI dst, rRegI src, immI8 shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_INT);\n+  match(Set dst (RotateLeft src shift));\n+  format %{ \"rolxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    int shift = 32 - ($shift$$constant & 31);\n+    __ rorxl($dst$$Register, $src$$Register, shift);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct rolI_mem_immI8(rRegI dst, memory src, immI8 shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_INT);\n+  match(Set dst (RotateLeft (LoadI src) shift));\n+  format %{ \"rolxl    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    int shift = 32 - ($shift$$constant & 31);\n+    __ rorxl($dst$$Register, $src$$Address, shift);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9382,1 +9706,1 @@\n-instruct rorI_immI8(rRegI dst, immI8 shift)\n+instruct rorI_immI8(rRegI dst, rRegI src, immI8 shift)\n@@ -9385,2 +9709,2 @@\n-  match(Set dst (RotateRight dst shift));\n-  format %{ \"rorxd     $dst, $shift\" %}\n+  match(Set dst (RotateRight src shift));\n+  format %{ \"rorxl     $dst, $src, $shift\" %}\n@@ -9388,1 +9712,1 @@\n-    __ rorxd($dst$$Register, $dst$$Register, $shift$$constant);\n+    __ rorxl($dst$$Register, $src$$Register, $shift$$constant);\n@@ -9393,0 +9717,11 @@\n+instruct rorI_mem_immI8(rRegI dst, memory src, immI8 shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_INT);\n+  match(Set dst (RotateRight (LoadI src) shift));\n+  format %{ \"rorxl     $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ rorxl($dst$$Register, $src$$Address, $shift$$constant);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9406,1 +9741,0 @@\n-\n@@ -9408,1 +9742,1 @@\n-instruct rolL_immI8(rRegL dst, immI8 shift, rFlagsReg cr)\n+instruct rolL_immI8_legacy(rRegL dst, immI8 shift, rFlagsReg cr)\n@@ -9410,1 +9744,1 @@\n-  predicate(n->bottom_type()->basic_type() == T_LONG);\n+  predicate(!VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_LONG);\n@@ -9420,0 +9754,24 @@\n+instruct rolL_immI8(rRegL dst, rRegL src, immI8 shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_LONG);\n+  match(Set dst (RotateLeft src shift));\n+  format %{ \"rolxq     $dst, $src, $shift\" %}\n+  ins_encode %{\n+    int shift = 64 - ($shift$$constant & 63);\n+    __ rorxq($dst$$Register, $src$$Register, shift);\n+  %}\n+  ins_pipe(ialu_reg_reg);\n+%}\n+\n+instruct rolL_mem_immI8(rRegL dst, memory src, immI8 shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_LONG);\n+  match(Set dst (RotateLeft (LoadL src) shift));\n+  format %{ \"rolxq     $dst, $src, $shift\" %}\n+  ins_encode %{\n+    int shift = 64 - ($shift$$constant & 63);\n+    __ rorxq($dst$$Register, $src$$Address, shift);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n@@ -9433,1 +9791,0 @@\n-\n@@ -9447,1 +9804,0 @@\n-\n@@ -9449,1 +9805,1 @@\n-instruct rorL_immI8(rRegL dst, immI8 shift)\n+instruct rorL_immI8(rRegL dst, rRegL src, immI8 shift)\n@@ -9452,2 +9808,2 @@\n-  match(Set dst (RotateRight dst shift));\n-  format %{ \"rorxq    $dst, $shift\" %}\n+  match(Set dst (RotateRight src shift));\n+  format %{ \"rorxq    $dst, $src, $shift\" %}\n@@ -9455,1 +9811,1 @@\n-    __ rorxq($dst$$Register, $dst$$Register, $shift$$constant);\n+    __ rorxq($dst$$Register, $src$$Register, $shift$$constant);\n@@ -9460,0 +9816,11 @@\n+instruct rorL_mem_immI8(rRegL dst, memory src, immI8 shift)\n+%{\n+  predicate(VM_Version::supports_bmi2() && n->bottom_type()->basic_type() == T_LONG);\n+  match(Set dst (RotateRight (LoadL src) shift));\n+  format %{ \"rorxq    $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ rorxq($dst$$Register, $src$$Address, $shift$$constant);\n+  %}\n+  ins_pipe(ialu_reg_mem);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":382,"deletions":15,"binary":false,"changes":397,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -112,0 +112,21 @@\n+\n+    @Benchmark\n+    public void shiftRight(Blackhole bh) {\n+        for (int i = 0; i < size; i++) {\n+            bh.consume(intsBig[i] >> intsSmall[i]);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void shiftURight(Blackhole bh) {\n+        for (int i = 0; i < size; i++) {\n+            bh.consume(intsBig[i] >>> intsSmall[i]);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void shiftLeft(Blackhole bh) {\n+        for (int i = 0; i < size; i++) {\n+            bh.consume(intsBig[i] << intsSmall[i]);\n+        }\n+    }\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/Integers.java","additions":22,"deletions":1,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -107,0 +107,21 @@\n+\n+    @Benchmark\n+    public void shiftRight(Blackhole bh) {\n+        for (int i = 0; i < size; i++) {\n+            bh.consume(longArrayBig[i] >> longArraySmall[i]);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void shiftURight(Blackhole bh) {\n+        for (int i = 0; i < size; i++) {\n+            bh.consume(longArrayBig[i] >>> longArraySmall[i]);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void shiftLeft(Blackhole bh) {\n+        for (int i = 0; i < size; i++) {\n+            bh.consume(longArrayBig[i] << longArraySmall[i]);\n+        }\n+    }\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/Longs.java","additions":22,"deletions":1,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n-\/\/ Copyright (c) 2003, 2020, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,0 +42,2 @@\n+  static final int CONSHIFT = 20;\n+\n@@ -86,1 +88,20 @@\n-\n+  @Benchmark\n+  public void testRotateLeftConI() {\n+    for (int i = 0; i < TESTSIZE; i++)\n+      ires[i] = Integer.rotateLeft(iarr[i], CONSHIFT);\n+  }\n+  @Benchmark\n+  public void testRotateRightConI() {\n+    for (int i = 0; i < TESTSIZE; i++)\n+      ires[i] = Integer.rotateRight(iarr[i], CONSHIFT);\n+  }\n+  @Benchmark\n+  public void testRotateLeftConL() {\n+    for (int i = 0; i < TESTSIZE; i++)\n+      lres[i] = Long.rotateLeft(larr[i], CONSHIFT);\n+  }\n+  @Benchmark\n+  public void testRotateRightConL() {\n+    for (int i = 0; i < TESTSIZE; i++)\n+      lres[i] = Long.rotateRight(larr[i], CONSHIFT);\n+  }\n","filename":"test\/micro\/org\/openjdk\/bench\/java\/lang\/RotateBenchmark.java","additions":23,"deletions":2,"binary":false,"changes":25,"status":"modified"}]}