{"files":[{"patch":"@@ -1057,10 +1057,11 @@\n-#if INCLUDE_JVMCI\n-          if (EnableJVMCI && UseJVMCICompiler) {\n-            \/\/ Since JVMCI takes a while to warm up, its queue inevitably backs up during\n-            \/\/ early VM execution. As of 2014-06-13, JVMCI's inliner assumes that the root\n-            \/\/ compilation method and all potential inlinees have mature profiles (which\n-            \/\/ includes type profiling). If it sees immature profiles, JVMCI's inliner\n-            \/\/ can perform pathologically bad (e.g., causing OutOfMemoryErrors due to\n-            \/\/ exploring\/inlining too many graphs). Since a rewrite of the inliner is\n-            \/\/ in progress, we simply disable the dialing back heuristic for now and will\n-            \/\/ revisit this decision once the new inliner is completed.\n+          \/\/ C1-generated fully profiled code is about 30% slower than the limited profile\n+          \/\/ code that has only invocation and backedge counters. The observation is that\n+          \/\/ if C2 queue is large enough we can spend too much time in the fully profiled code\n+          \/\/ while waiting for C2 to pick the method from the queue. To alleviate this problem\n+          \/\/ we introduce a feedback on the C2 queue size. If the C2 queue is sufficiently long\n+          \/\/ we choose to compile a limited profiled version and then recompile with full profiling\n+          \/\/ when the load on C2 goes down.\n+          if (!disable_feedback && CompileBroker::queue_size(CompLevel_full_optimization) >\n+              Tier3DelayOn * compiler_count(CompLevel_full_optimization)) {\n+            next_level = CompLevel_limited_profile;\n+          } else {\n@@ -1068,16 +1069,0 @@\n-          } else\n-#endif\n-          {\n-            \/\/ C1-generated fully profiled code is about 30% slower than the limited profile\n-            \/\/ code that has only invocation and backedge counters. The observation is that\n-            \/\/ if C2 queue is large enough we can spend too much time in the fully profiled code\n-            \/\/ while waiting for C2 to pick the method from the queue. To alleviate this problem\n-            \/\/ we introduce a feedback on the C2 queue size. If the C2 queue is sufficiently long\n-            \/\/ we choose to compile a limited profiled version and then recompile with full profiling\n-            \/\/ when the load on C2 goes down.\n-            if (!disable_feedback && CompileBroker::queue_size(CompLevel_full_optimization) >\n-                Tier3DelayOn * compiler_count(CompLevel_full_optimization)) {\n-              next_level = CompLevel_limited_profile;\n-            } else {\n-              next_level = CompLevel_full_profile;\n-            }\n","filename":"src\/hotspot\/share\/compiler\/compilationPolicy.cpp","additions":11,"deletions":26,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -447,0 +447,10 @@\n+      if (FLAG_IS_DEFAULT(Tier3DelayOn)) {\n+        \/\/ This effectively prevents the compile broker scheduling tier 2\n+        \/\/ (i.e., limited C1 profiling) compilations instead of tier 3\n+        \/\/ (i.e., full C1 profiling) compilations when the tier 4 queue\n+        \/\/ backs up (which is quite likely when using a non-AOT compiled JVMCI\n+        \/\/ compiler). The observation based on jargraal is that the downside\n+        \/\/ of skipping full profiling is much worse for performance than the\n+        \/\/ queue backing up.\n+        FLAG_SET_DEFAULT(Tier3DelayOn, 100000);\n+      }\n","filename":"src\/hotspot\/share\/compiler\/compilerDefinitions.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"}]}