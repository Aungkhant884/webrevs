{"files":[{"patch":"@@ -40,0 +40,1 @@\n+#include \"memory\/metaspaceCriticalAllocation.hpp\"\n@@ -156,2 +157,0 @@\n-  MetaWord* result;\n-\n@@ -159,16 +158,1 @@\n-  collect(GCCause::_metadata_GC_threshold);\n-\n-  \/\/ Expand and retry allocation\n-  result = loader_data->metaspace_non_null()->expand_and_allocate(size, mdtype);\n-  if (result != NULL) {\n-    return result;\n-  }\n-\n-  \/\/ Start synchronous GC\n-  collect(GCCause::_metadata_GC_clear_soft_refs);\n-\n-  \/\/ Retry allocation\n-  result = loader_data->metaspace_non_null()->allocate(size, mdtype);\n-  if (result != NULL) {\n-    return result;\n-  }\n+  Universe::heap()->collect(GCCause::_metadata_GC_threshold);\n@@ -177,1 +161,1 @@\n-  result = loader_data->metaspace_non_null()->expand_and_allocate(size, mdtype);\n+  MetaWord* result = loader_data->metaspace_non_null()->expand_and_allocate(size, mdtype);\n@@ -182,2 +166,2 @@\n-  \/\/ Out of memory\n-  return NULL;\n+  \/\/ As a last resort, try a critical allocation, riding on a synchronous full GC\n+  return MetaspaceCriticalAllocation::allocate(loader_data, size, mdtype);\n","filename":"src\/hotspot\/share\/gc\/z\/zCollectedHeap.cpp","additions":5,"deletions":21,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"memory\/metaspaceCriticalAllocation.hpp\"\n@@ -803,0 +804,3 @@\n+  \/\/ Deal with concurrent unloading failed allocation starvation\n+  MetaspaceCriticalAllocation::block_if_concurrent_purge();\n+\n@@ -905,0 +909,4 @@\n+  \/\/ The MetaspaceCritical_lock is used by a concurrent GC to block out concurrent metaspace\n+  \/\/ allocations, that would starve critical metaspace allocations, that are about to throw\n+  \/\/ OOM if they fail; they need precedence for correctness.\n+  MutexLocker ml(MetaspaceCritical_lock);\n@@ -915,0 +923,2 @@\n+\n+  MetaspaceCriticalAllocation::satisfy();\n","filename":"src\/hotspot\/share\/memory\/metaspace.cpp","additions":10,"deletions":0,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -0,0 +1,176 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"classfile\/classLoaderData.hpp\"\n+#include \"gc\/shared\/collectedHeap.hpp\"\n+#include \"logging\/log.hpp\"\n+#include \"memory\/classLoaderMetaspace.hpp\"\n+#include \"memory\/metaspaceCriticalAllocation.hpp\"\n+#include \"memory\/universe.hpp\"\n+#include \"runtime\/mutexLocker.hpp\"\n+\n+class MetadataAllocationRequest {\n+  ClassLoaderData*           _loader_data;\n+  size_t                     _word_size;\n+  Metaspace::MetadataType    _type;\n+  MetadataAllocationRequest* _next;\n+  MetaWord*                  _result;\n+  bool                       _has_result;\n+\n+public:\n+  MetadataAllocationRequest(ClassLoaderData* loader_data,\n+                            size_t word_size,\n+                            Metaspace::MetadataType type)\n+    : _loader_data(loader_data),\n+      _word_size(word_size),\n+      _type(type),\n+      _next(NULL),\n+      _result(NULL),\n+      _has_result(false) {\n+    MetaspaceCriticalAllocation::add(this);\n+  }\n+\n+  ~MetadataAllocationRequest() {\n+    MetaspaceCriticalAllocation::remove(this);\n+  }\n+\n+  ClassLoaderData*           loader_data() const { return _loader_data; }\n+  size_t                     word_size() const   { return _word_size; }\n+  Metaspace::MetadataType    type() const        { return _type; }\n+  MetadataAllocationRequest* next() const        { return _next; }\n+  MetaWord*                  result() const      { return _result; }\n+  bool                       has_result() const  { return _has_result; }\n+\n+  void set_next(MetadataAllocationRequest* next) { _next = next; }\n+  void set_result(MetaWord* result) {\n+    _result = result;\n+    _has_result = true;\n+  }\n+};\n+\n+volatile bool MetaspaceCriticalAllocation::_has_critical_allocation = false;\n+MetadataAllocationRequest* MetaspaceCriticalAllocation::_requests_head = NULL;\n+MetadataAllocationRequest* MetaspaceCriticalAllocation::_requests_tail = NULL;\n+\n+void MetaspaceCriticalAllocation::add(MetadataAllocationRequest* request) {\n+  MutexLocker ml(MetaspaceCritical_lock);\n+  log_info(metaspace)(\"Requesting critical metaspace allocation; almost out of memory\");\n+  Atomic::store(&_has_critical_allocation, true);\n+  if (_requests_head == NULL) {\n+    _requests_head = _requests_tail = request;\n+  } else {\n+    _requests_tail->set_next(request);\n+    _requests_tail = request;\n+  }\n+}\n+\n+void MetaspaceCriticalAllocation::unlink(MetadataAllocationRequest* curr, MetadataAllocationRequest* prev) {\n+  if (_requests_head == curr) {\n+    _requests_head = curr->next();\n+  }\n+  if (_requests_tail == curr) {\n+    _requests_tail = prev;\n+  }\n+  if (prev != NULL) {\n+    prev->set_next(curr->next());\n+  }\n+}\n+\n+void MetaspaceCriticalAllocation::remove(MetadataAllocationRequest* request) {\n+  MutexLocker ml(MetaspaceCritical_lock);\n+  MetadataAllocationRequest* prev = NULL;\n+  for (MetadataAllocationRequest* curr = _requests_head; curr != NULL; curr = curr->next()) {\n+    if (curr == request) {\n+      unlink(curr, prev);\n+      break;\n+    } else {\n+      prev = curr;\n+    }\n+  }\n+}\n+\n+bool MetaspaceCriticalAllocation::try_allocate_critical(MetadataAllocationRequest* request) {\n+  MutexLocker ml(MetaspaceCritical_lock);\n+  if (_requests_head == request) {\n+    \/\/ The first request can't opportunistically ride on a previous GC\n+    return false;\n+  }\n+  \/\/ Try to ride on a previous GC and hope for early satisfaction\n+  wait_for_purge(request);\n+  return request->result() != NULL;\n+}\n+\n+void MetaspaceCriticalAllocation::wait_for_purge(MetadataAllocationRequest* request) {\n+  while (!request->has_result()) {\n+    MetaspaceCritical_lock->wait();\n+  }\n+}\n+\n+void MetaspaceCriticalAllocation::block_if_concurrent_purge() {\n+  if (Atomic::load(&_has_critical_allocation)) {\n+    \/\/ If there is a concurrent Metaspace::purge() operation, we will block here,\n+    \/\/ to make sure critical allocations get precedence and don't get starved.\n+    MutexLocker ml(MetaspaceCritical_lock);\n+  }\n+}\n+\n+void MetaspaceCriticalAllocation::satisfy() {\n+  assert_lock_strong(MetaspaceCritical_lock);\n+  bool all_satisfied = true;\n+  for (MetadataAllocationRequest* curr = _requests_head; curr != NULL; curr = curr->next()) {\n+    if (curr->result() != NULL) {\n+      \/\/ Don't satisfy twice\n+      continue;\n+    }\n+    \/\/ Try to allocate metadata.\n+    MetaWord* result = curr->loader_data()->metaspace_non_null()->allocate(curr->word_size(), curr->type());\n+    if (result == NULL) {\n+      result = curr->loader_data()->metaspace_non_null()->expand_and_allocate(curr->word_size(), curr->type());\n+    }\n+    if (result == NULL) {\n+      all_satisfied = false;\n+    }\n+    curr->set_result(result);\n+  }\n+  if (all_satisfied) {\n+    Atomic::store(&_has_critical_allocation, false);\n+  }\n+  MetaspaceCritical_lock->notify_all();\n+}\n+\n+MetaWord* MetaspaceCriticalAllocation::allocate(ClassLoaderData* loader_data, size_t word_size, Metaspace::MetadataType type) {\n+  MetadataAllocationRequest request(loader_data, word_size, type);\n+\n+  if (try_allocate_critical(&request)) {\n+    \/\/ Try to allocate on a previous concurrent GC if there was one, and return if successful\n+    return request.result();\n+  }\n+\n+  \/\/ Always perform a synchronous full GC before bailing\n+  Universe::heap()->collect(GCCause::_metadata_GC_clear_soft_refs);\n+\n+  \/\/ Return the result, be that success or failure\n+  return request.result();\n+}\n","filename":"src\/hotspot\/share\/memory\/metaspaceCriticalAllocation.cpp","additions":176,"deletions":0,"binary":false,"changes":176,"status":"added"},{"patch":"@@ -0,0 +1,84 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_MEMORY_METASPACECRITICALALLOCATION_HPP\n+#define SHARE_MEMORY_METASPACECRITICALALLOCATION_HPP\n+\n+#include \"memory\/allocation.hpp\"\n+#include \"memory\/metaspace.hpp\"\n+\n+class MetadataAllocationRequest;\n+class ClassLoaderData;\n+\n+\/\/ == Critical allocation support ==\n+\/\/\n+\/\/ The critical allocation support has the purpose of preventing starvation of failed\n+\/\/ metadata allocations that need a GC, in particular for concurrent GCs.\n+\/\/ A \"critical\" allocation request is registered, then a concurrent full GC is executed.\n+\/\/ When there is any critical allocation present in the system, allocations compete for\n+\/\/ a global lock, so that allocations can be shut out from the concurrent purge() call,\n+\/\/ which takes the same lock. The reasoning is that we gather all the critical allocations\n+\/\/ that are one more failure away from throwing metaspace OOM, in a queue before the GC,\n+\/\/ then free up metaspace due to class unloading in the purge() operation of that GC,\n+\/\/ and satisfy the registered critical allocations. This allows the critical allocations\n+\/\/ to get precedence over normal metaspace allocations, so that the critical allocations\n+\/\/ that are about to throw, do not get starved by other metaspace allocations that have\n+\/\/ not gone through the same dance.\n+\/\/\n+\/\/ The solution has an intended accuracy of not one allocation, but one per thread. What\n+\/\/ I mean by that, is that the allocations are allowed to throw if they got starved by\n+\/\/ one metaspace allocation per thread, even though a more complicated dance could have\n+\/\/ survived that situation in theory. The motivation is that we are at this point so close\n+\/\/ to being out of memory, and the VM is not having a good time, so the user really ought\n+\/\/ to increase the amount of available metaspace anyway, instead of GC:ing around more\n+\/\/ to satisfy a very small number of additional allocations. But it does solve pathologial\n+\/\/ unbounded starvation scenarios where OOM can get thrown even though most of metaspace\n+\/\/ is full of dead metadata.\n+\/\/\n+\/\/ The contract for this to work for a given GC is that GCCause::_metadata_GC_clear_soft_refs\n+\/\/ yields a full synchronous GC that unloads metaspace. And it is only intended to be used\n+\/\/ by GCs with concurrent class unloading.\n+\n+class MetaspaceCriticalAllocation : public AllStatic {\n+  friend class MetadataAllocationRequest;\n+\n+  static volatile bool _has_critical_allocation;\n+  static MetadataAllocationRequest* _requests_head;\n+  static MetadataAllocationRequest* _requests_tail;\n+\n+  static void unlink(MetadataAllocationRequest* curr, MetadataAllocationRequest* prev);\n+\n+  static void add(MetadataAllocationRequest* request);\n+  static void remove(MetadataAllocationRequest* request);\n+\n+  static bool try_allocate_critical(MetadataAllocationRequest* request);\n+  static void wait_for_purge(MetadataAllocationRequest* request);\n+\n+public:\n+  static void block_if_concurrent_purge();\n+  static void satisfy();\n+  static MetaWord* allocate(ClassLoaderData* loader_data, size_t word_size, Metaspace::MetadataType type);\n+};\n+\n+#endif \/\/ SHARE_MEMORY_METASPACECRITICALALLOCATION_HPP\n","filename":"src\/hotspot\/share\/memory\/metaspaceCriticalAllocation.hpp","additions":84,"deletions":0,"binary":false,"changes":84,"status":"added"},{"patch":"@@ -143,0 +143,1 @@\n+Monitor* MetaspaceCritical_lock       = NULL;\n@@ -248,0 +249,1 @@\n+  def(MetaspaceCritical_lock       , PaddedMonitor, leaf+2,      true,  _safepoint_check_always);\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -150,0 +150,1 @@\n+extern Monitor* MetaspaceCritical_lock;          \/\/ synchronizes failed metaspace allocations that risk throwing metaspace OOM\n","filename":"src\/hotspot\/share\/runtime\/mutexLocker.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}