{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,3 @@\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiRedefineClasses.hpp\"\n+#endif\n@@ -70,1 +73,3 @@\n-      CodeCache::old_nmethods_do(&md_on_stack);\n+#if INCLUDE_JVMTI\n+      VM_RedefineClasses::old_nmethods_do(&md_on_stack);\n+#endif\n","filename":"src\/hotspot\/share\/classfile\/metadataOnStackMark.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -71,0 +71,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -1583,1 +1584,1 @@\n-    CodeCache::flush_dependents_on(k);\n+    Deoptimization::mark_and_deoptimize_dependents_on(k);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"code\/dependencies.hpp\"\n@@ -1070,32 +1069,0 @@\n-\/\/ Keeps track of time spent for checking dependencies\n-NOT_PRODUCT(static elapsedTimer dependentCheckTime;)\n-\n-int CodeCache::mark_for_deoptimization(KlassDepChange& changes) {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  int number_of_marked_CodeBlobs = 0;\n-\n-  \/\/ search the hierarchy looking for nmethods which are affected by the loading of this class\n-\n-  \/\/ then search the interfaces this class implements looking for nmethods\n-  \/\/ which might be dependent of the fact that an interface only had one\n-  \/\/ implementor.\n-  \/\/ nmethod::check_all_dependencies works only correctly, if no safepoint\n-  \/\/ can happen\n-  NoSafepointVerifier nsv;\n-  for (DepChange::ContextStream str(changes, nsv); str.next(); ) {\n-    Klass* d = str.klass();\n-    number_of_marked_CodeBlobs += InstanceKlass::cast(d)->mark_dependent_nmethods(changes);\n-  }\n-\n-#ifndef PRODUCT\n-  if (VerifyDependencies) {\n-    \/\/ Object pointers are used as unique identifiers for dependency arguments. This\n-    \/\/ is only possible if no safepoint, i.e., GC occurs during the verification code.\n-    dependentCheckTime.start();\n-    nmethod::check_all_dependencies(changes);\n-    dependentCheckTime.stop();\n-  }\n-#endif\n-\n-  return number_of_marked_CodeBlobs;\n-}\n@@ -1109,183 +1076,0 @@\n-#if INCLUDE_JVMTI\n-\/\/ RedefineClasses support for saving nmethods that are dependent on \"old\" methods.\n-\/\/ We don't really expect this table to grow very large.  If it does, it can become a hashtable.\n-static GrowableArray<CompiledMethod*>* old_compiled_method_table = NULL;\n-\n-static void add_to_old_table(CompiledMethod* c) {\n-  if (old_compiled_method_table == NULL) {\n-    old_compiled_method_table = new (ResourceObj::C_HEAP, mtCode) GrowableArray<CompiledMethod*>(100, mtCode);\n-  }\n-  old_compiled_method_table->push(c);\n-}\n-\n-static void reset_old_method_table() {\n-  if (old_compiled_method_table != NULL) {\n-    delete old_compiled_method_table;\n-    old_compiled_method_table = NULL;\n-  }\n-}\n-\n-\/\/ Remove this method when zombied or unloaded.\n-void CodeCache::unregister_old_nmethod(CompiledMethod* c) {\n-  assert_lock_strong(CodeCache_lock);\n-  if (old_compiled_method_table != NULL) {\n-    int index = old_compiled_method_table->find(c);\n-    if (index != -1) {\n-      old_compiled_method_table->delete_at(index);\n-    }\n-  }\n-}\n-\n-void CodeCache::old_nmethods_do(MetadataClosure* f) {\n-  \/\/ Walk old method table and mark those on stack.\n-  int length = 0;\n-  if (old_compiled_method_table != NULL) {\n-    length = old_compiled_method_table->length();\n-    for (int i = 0; i < length; i++) {\n-      CompiledMethod* cm = old_compiled_method_table->at(i);\n-      \/\/ Only walk alive nmethods, the dead ones will get removed by the sweeper or GC.\n-      if (cm->is_alive() && !cm->is_unloading()) {\n-        old_compiled_method_table->at(i)->metadata_do(f);\n-      }\n-    }\n-  }\n-  log_debug(redefine, class, nmethod)(\"Walked %d nmethods for mark_on_stack\", length);\n-}\n-\n-\/\/ Walk compiled methods and mark dependent methods for deoptimization.\n-int CodeCache::mark_dependents_for_evol_deoptimization() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-  \/\/ Each redefinition creates a new set of nmethods that have references to \"old\" Methods\n-  \/\/ So delete old method table and create a new one.\n-  reset_old_method_table();\n-\n-  int number_of_marked_CodeBlobs = 0;\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    \/\/ Walk all alive nmethods to check for old Methods.\n-    \/\/ This includes methods whose inline caches point to old methods, so\n-    \/\/ inline cache clearing is unnecessary.\n-    if (nm->has_evol_metadata()) {\n-      nm->mark_for_deoptimization();\n-      add_to_old_table(nm);\n-      number_of_marked_CodeBlobs++;\n-    }\n-  }\n-\n-  \/\/ return total count of nmethods marked for deoptimization, if zero the caller\n-  \/\/ can skip deoptimization\n-  return number_of_marked_CodeBlobs;\n-}\n-\n-void CodeCache::mark_all_nmethods_for_evol_deoptimization() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (!nm->method()->is_method_handle_intrinsic()) {\n-      if (nm->can_be_deoptimized()) {\n-        nm->mark_for_deoptimization();\n-      }\n-      if (nm->has_evol_metadata()) {\n-        add_to_old_table(nm);\n-      }\n-    }\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on redefined classes, that have already been\n-\/\/ marked for deoptimization.\n-void CodeCache::flush_evol_dependents() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-\n-  \/\/ CodeCache can only be updated by a thread_in_VM and they will all be\n-  \/\/ stopped during the safepoint so CodeCache will be safe to update without\n-  \/\/ holding the CodeCache_lock.\n-\n-  \/\/ At least one nmethod has been marked for deoptimization\n-\n-  Deoptimization::deoptimize_all_marked();\n-}\n-#endif \/\/ INCLUDE_JVMTI\n-\n-\/\/ Mark methods for deopt (if safe or possible).\n-void CodeCache::mark_all_nmethods_for_deoptimization() {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (!nm->is_native_method()) {\n-      nm->mark_for_deoptimization();\n-    }\n-  }\n-}\n-\n-int CodeCache::mark_for_deoptimization(Method* dependee) {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  int number_of_marked_CodeBlobs = 0;\n-\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (nm->is_dependent_on_method(dependee)) {\n-      ResourceMark rm;\n-      nm->mark_for_deoptimization();\n-      number_of_marked_CodeBlobs++;\n-    }\n-  }\n-\n-  return number_of_marked_CodeBlobs;\n-}\n-\n-void CodeCache::make_marked_nmethods_deoptimized() {\n-  SweeperBlockingCompiledMethodIterator iter(SweeperBlockingCompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (nm->is_marked_for_deoptimization() && !nm->has_been_deoptimized() && nm->can_be_deoptimized()) {\n-      nm->make_not_entrant();\n-      make_nmethod_deoptimized(nm);\n-    }\n-  }\n-}\n-\n-void CodeCache::make_nmethod_deoptimized(CompiledMethod* nm) {\n-  if (nm->is_marked_for_deoptimization() && nm->can_be_deoptimized()) {\n-    nm->make_deoptimized();\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on dependee.\n-void CodeCache::flush_dependents_on(InstanceKlass* dependee) {\n-  assert_lock_strong(Compile_lock);\n-\n-  if (number_of_nmethods_with_dependencies() == 0) return;\n-\n-  int marked = 0;\n-  if (dependee->is_linked()) {\n-    \/\/ Class initialization state change.\n-    KlassInitDepChange changes(dependee);\n-    marked = mark_for_deoptimization(changes);\n-  } else {\n-    \/\/ New class is loaded.\n-    NewKlassDepChange changes(dependee);\n-    marked = mark_for_deoptimization(changes);\n-  }\n-\n-  if (marked > 0) {\n-    \/\/ At least one nmethod has been marked for deoptimization\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on dependee\n-void CodeCache::flush_dependents_on_method(const methodHandle& m_h) {\n-  \/\/ --- Compile_lock is not held. However we are at a safepoint.\n-  assert_locked_or_safepoint(Compile_lock);\n-\n-  \/\/ Compute the dependent nmethods\n-  if (mark_for_deoptimization(m_h()) > 0) {\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-}\n-\n@@ -1552,1 +1336,1 @@\n-  tty->print_cr(\"nmethod dependency checking time %fs\", dependentCheckTime.seconds());\n+  Deoptimization::print_dependency_checking_time(tty);\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":1,"deletions":217,"binary":false,"changes":218,"status":"modified"},{"patch":"@@ -76,1 +76,0 @@\n-class KlassDepChange;\n@@ -124,0 +123,1 @@\n+    friend class SweeperBlocker;\n@@ -285,4 +285,0 @@\n-  \/\/ Deoptimization\n- private:\n-  static int  mark_for_deoptimization(KlassDepChange& changes);\n-\n@@ -290,19 +286,0 @@\n-  static void mark_all_nmethods_for_deoptimization();\n-  static int  mark_for_deoptimization(Method* dependee);\n-  static void make_marked_nmethods_deoptimized();\n-  static void make_nmethod_deoptimized(CompiledMethod* nm);\n-\n-  \/\/ Flushing and deoptimization\n-  static void flush_dependents_on(InstanceKlass* dependee);\n-\n-  \/\/ RedefineClasses support\n-  \/\/ Flushing and deoptimization in case of evolution\n-  static int  mark_dependents_for_evol_deoptimization();\n-  static void mark_all_nmethods_for_evol_deoptimization();\n-  static void flush_evol_dependents();\n-  static void old_nmethods_do(MetadataClosure* f) NOT_JVMTI_RETURN;\n-  static void unregister_old_nmethod(CompiledMethod* c) NOT_JVMTI_RETURN;\n-\n-  \/\/ Support for fullspeed debugging\n-  static void flush_dependents_on_method(const methodHandle& dependee);\n-\n@@ -329,0 +306,9 @@\n+class SweeperBlocker : public StackObj {\n+  public:\n+    SweeperBlocker() {\n+      CodeCache::Sweep::begin_compiled_method_iteration();\n+    }\n+    ~SweeperBlocker() {\n+      CodeCache::Sweep::end_compiled_method_iteration();\n+    }\n+};\n","filename":"src\/hotspot\/share\/code\/codeCache.hpp","additions":10,"deletions":24,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+CompiledMethod* CompiledMethod::_root_mark_link = nullptr;\n+\n@@ -57,1 +59,1 @@\n-    _mark_for_deoptimization_status(not_marked),\n+    _mark_link(nullptr),\n@@ -69,1 +71,1 @@\n-    _mark_for_deoptimization_status(not_marked),\n+    _mark_link(nullptr),\n@@ -121,5 +123,11 @@\n-  \/\/ assert(can_be_deoptimized(), \"\"); \/\/ in some places we check before marking, in others not.\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n-                 Mutex::_no_safepoint_check_flag);\n-  if (_mark_for_deoptimization_status != deoptimize_done) { \/\/ can't go backwards\n-     _mark_for_deoptimization_status = (inc_recompile_counts ? deoptimize : deoptimize_noupdate);\n+  assert_locked_or_safepoint(Compile_lock);\n+  MarkForDeoptimizationStatus old_mark = extract_mark(_mark_link);\n+  if (old_mark != deoptimize_done) { \/\/ can't go backwards\n+    MarkForDeoptimizationStatus new_mark = (inc_recompile_counts ? deoptimize : deoptimize_noupdate);\n+    if (old_mark == not_marked) {\n+      assert(extract_compiled_method(_mark_link) == nullptr, \"Compiled Method should not already be linked\");\n+      _mark_link = mark_link(_root_mark_link, new_mark);\n+      _root_mark_link = this;\n+    } else {\n+      _mark_link = mark_link(nullptr, new_mark);\n+    }\n@@ -129,0 +137,17 @@\n+CompiledMethod* CompiledMethod::next_marked() const {\n+  assert_locked_or_safepoint(Compile_lock);\n+  return extract_compiled_method(_mark_link);\n+}\n+\n+CompiledMethod* CompiledMethod::take_root() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  CompiledMethod* root = _root_mark_link;\n+  _root_mark_link = nullptr;\n+  return root;\n+}\n+\n+void  CompiledMethod::mark_deoptimized() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  _mark_link = mark_link(extract_compiled_method(_mark_link), deoptimize_done);\n+}\n+\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":32,"deletions":7,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  friend class Deoptimization;\n@@ -154,1 +155,1 @@\n-  MarkForDeoptimizationStatus _mark_for_deoptimization_status; \/\/ Used for stack deoptimization\n+  struct MarkedCompiledMethodLink;\n@@ -156,0 +157,14 @@\n+  static CompiledMethod* _root_mark_link;\n+  MarkedCompiledMethodLink* _mark_link;\n+\n+  static MarkedCompiledMethodLink* mark_link(CompiledMethod* cm, MarkForDeoptimizationStatus mark) {\n+    assert(((uintptr_t)cm & 0x3) == 0, \"cm pointer must have zero lower two LSB\");\n+    return (MarkedCompiledMethodLink*)(((uintptr_t)cm & ~0x3) | static_cast<u1>(mark));\n+  }\n+\n+  static MarkForDeoptimizationStatus extract_mark(MarkedCompiledMethodLink* link) {\n+    return static_cast<MarkForDeoptimizationStatus>((uintptr_t)link & 0x3);\n+  }\n+  static CompiledMethod* extract_compiled_method(MarkedCompiledMethodLink* link) {\n+    return (CompiledMethod*)((uintptr_t)link & ~0x3);\n+  }\n@@ -245,2 +260,1 @@\n-  bool  is_marked_for_deoptimization() const { return _mark_for_deoptimization_status != not_marked; }\n-  void  mark_for_deoptimization(bool inc_recompile_counts = true);\n+  bool  is_marked_for_deoptimization() const { return extract_mark(_mark_link) != not_marked; }\n@@ -248,2 +262,9 @@\n-  bool  has_been_deoptimized() const { return _mark_for_deoptimization_status == deoptimize_done; }\n-  void  mark_deoptimized() { _mark_for_deoptimization_status = deoptimize_done; }\n+  bool  has_been_deoptimized() const { return extract_mark(_mark_link) == deoptimize_done; }\n+\n+private:\n+  void  mark_for_deoptimization(bool inc_recompile_counts = true);\n+  CompiledMethod* next_marked() const;\n+  static CompiledMethod* take_root();\n+protected:\n+  void  mark_deoptimized();\n+public:\n@@ -257,2 +278,2 @@\n-    return _mark_for_deoptimization_status != deoptimize_noupdate &&\n-           _mark_for_deoptimization_status != deoptimize_done;\n+    MarkForDeoptimizationStatus mark_status = extract_mark(_mark_link);\n+    return mark_status != deoptimize_noupdate && mark_status != deoptimize_done;\n","filename":"src\/hotspot\/share\/code\/compiledMethod.hpp","additions":28,"deletions":7,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -686,1 +687,1 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) = 0;\n+  virtual void mark_for_deoptimization(nmethod* nm, Deoptimization::MarkFn mark_fn) = 0;\n@@ -784,2 +785,2 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) {\n-    nm->mark_for_deoptimization(\/*inc_recompile_counts=*\/true);\n+  virtual void mark_for_deoptimization(nmethod* nm, Deoptimization::MarkFn mark_fn) {\n+    mark_fn(nm, true \/* inc_recompile_counts *\/);\n@@ -826,2 +827,2 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) {\n-    nm->mark_for_deoptimization(\/*inc_recompile_counts=*\/false);\n+  virtual void mark_for_deoptimization(nmethod* nm, Deoptimization::MarkFn mark_fn) {\n+    mark_fn(nm, false \/* inc_recompile_counts *\/);\n","filename":"src\/hotspot\/share\/code\/dependencies.hpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -67,1 +68,1 @@\n-int DependencyContext::mark_dependent_nmethods(DepChange& changes) {\n+int DependencyContext::mark_dependent_nmethods(DepChange& changes, Deoptimization::MarkFn mark_fn) {\n@@ -81,1 +82,1 @@\n-      changes.mark_for_deoptimization(nm);\n+      changes.mark_for_deoptimization(nm, mark_fn);\n@@ -208,0 +209,6 @@\n+nmethodBucket* DependencyContext::release_and_get_next_not_unloading(nmethodBucket* b) {\n+    nmethodBucket* next = b->next_not_unloading();\n+    release(b);\n+    return next;\n+}\n+\n@@ -210,1 +217,14 @@\n-int DependencyContext::remove_all_dependents() {\n+void DependencyContext::remove_all_dependents() {\n+  nmethodBucket* b = dependencies_not_unloading();\n+  set_dependencies(NULL);\n+  int removed = 0;\n+  while (b != NULL) {\n+    b = release_and_get_next_not_unloading(b);\n+    ++removed;\n+  }\n+  if (UsePerfData && removed > 0) {\n+    _perf_total_buckets_deallocated_count->inc(removed);\n+  }\n+}\n+\n+int DependencyContext::remove_and_mark_all_dependents(Deoptimization::MarkFn mark_fn) {\n@@ -218,2 +238,2 @@\n-      nm->mark_for_deoptimization();\n-      marked++;\n+      mark_fn(nm, true \/* inc_recompile_counts *\/);\n+      ++marked;\n@@ -221,4 +241,2 @@\n-    nmethodBucket* next = b->next_not_unloading();\n-    removed++;\n-    release(b);\n-    b = next;\n+    b = release_and_get_next_not_unloading(b);\n+    ++removed;\n","filename":"src\/hotspot\/share\/code\/dependencyContext.cpp","additions":27,"deletions":9,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -88,0 +89,1 @@\n+  nmethodBucket* release_and_get_next_not_unloading(nmethodBucket* b);\n@@ -120,1 +122,1 @@\n-  int  mark_dependent_nmethods(DepChange& changes);\n+  int  mark_dependent_nmethods(DepChange& changes, Deoptimization::MarkFn mark_fn);\n@@ -123,1 +125,2 @@\n-  int  remove_all_dependents();\n+  int  remove_and_mark_all_dependents(Deoptimization::MarkFn mark_fn);\n+  void remove_all_dependents();\n","filename":"src\/hotspot\/share\/code\/dependencyContext.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -86,0 +86,3 @@\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiRedefineClasses.hpp\"\n+#endif\n@@ -1618,1 +1621,3 @@\n-  CodeCache::unregister_old_nmethod(this);\n+#if INCLUDE_JVMTI\n+  VM_RedefineClasses::unregister_old_nmethod(this);\n+#endif\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -1539,1 +1539,1 @@\n-    Deoptimization::deoptimize_all_marked(nm);\n+    Deoptimization::mark_and_deoptimize_nmethod(nm);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciEnv.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1184,1 +1184,1 @@\n-    CodeCache::flush_dependents_on(this);\n+     Deoptimization::mark_and_deoptimize_dependents_on(this);\n@@ -2337,2 +2337,2 @@\n-int InstanceKlass::mark_dependent_nmethods(KlassDepChange& changes) {\n-  return dependencies().mark_dependent_nmethods(changes);\n+int InstanceKlass::mark_dependent_nmethods(KlassDepChange& changes, Deoptimization::MarkFn mark_fn) {\n+  return dependencies().mark_dependent_nmethods(changes, mark_fn);\n@@ -3322,1 +3322,1 @@\n-int InstanceKlass::mark_osr_nmethods(const Method* m) {\n+int InstanceKlass::mark_osr_nmethods(const Method* m, Deoptimization::MarkFn mark_fn) {\n@@ -3330,1 +3330,1 @@\n-      osr->mark_for_deoptimization();\n+      mark_fn((CompiledMethod*)osr);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -940,1 +941,1 @@\n-  int  mark_dependent_nmethods(KlassDepChange& changes);\n+  int  mark_dependent_nmethods(KlassDepChange& changes, Deoptimization::MarkFn mark_fn);\n@@ -950,1 +951,1 @@\n-  int mark_osr_nmethods(const Method* m);\n+  int mark_osr_nmethods(const Method* m, Deoptimization::MarkFn mark_fn);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2037,1 +2037,1 @@\n-    CodeCache::flush_dependents_on_method(mh);\n+    Deoptimization::mark_and_deoptimize_dependents(mh);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -917,2 +918,2 @@\n-  int mark_osr_nmethods() {\n-    return method_holder()->mark_osr_nmethods(this);\n+  int mark_osr_nmethods(Deoptimization::MarkFn mark_fn) {\n+    return method_holder()->mark_osr_nmethods(this, mark_fn);\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -4078,0 +4078,45 @@\n+\/\/ RedefineClasses support for saving nmethods that are dependent on \"old\" methods.\n+\/\/ We don't really expect this table to grow very large.  If it does, it can become a hashtable.\n+static GrowableArray<CompiledMethod*>* old_compiled_method_table = NULL;\n+\n+static void add_to_old_table(CompiledMethod* c) {\n+  if (old_compiled_method_table == NULL) {\n+    old_compiled_method_table = new (ResourceObj::C_HEAP, mtCode) GrowableArray<CompiledMethod*>(100, mtCode);\n+  }\n+  old_compiled_method_table->push(c);\n+}\n+\n+static void reset_old_method_table() {\n+  if (old_compiled_method_table != NULL) {\n+    delete old_compiled_method_table;\n+    old_compiled_method_table = NULL;\n+  }\n+}\n+\n+\/\/ Remove this method when zombied or unloaded.\n+void VM_RedefineClasses::unregister_old_nmethod(CompiledMethod* c) {\n+  assert_lock_strong(CodeCache_lock);\n+  if (old_compiled_method_table != NULL) {\n+    int index = old_compiled_method_table->find(c);\n+    if (index != -1) {\n+      old_compiled_method_table->delete_at(index);\n+    }\n+  }\n+}\n+\n+void VM_RedefineClasses::old_nmethods_do(MetadataClosure* f) {\n+  \/\/ Walk old method table and mark those on stack.\n+  int length = 0;\n+  if (old_compiled_method_table != NULL) {\n+    length = old_compiled_method_table->length();\n+    for (int i = 0; i < length; i++) {\n+      CompiledMethod* cm = old_compiled_method_table->at(i);\n+      \/\/ Only walk alive nmethods, the dead ones will get removed by the sweeper or GC.\n+      if (cm->is_alive() && !cm->is_unloading()) {\n+        old_compiled_method_table->at(i)->metadata_do(f);\n+      }\n+    }\n+  }\n+  log_debug(redefine, class, nmethod)(\"Walked %d nmethods for mark_on_stack\", length);\n+}\n+\n@@ -4096,18 +4141,40 @@\n-\n-  bool deopt_needed;\n-\n-  \/\/ This is the first redefinition, mark all the nmethods for deoptimization\n-  if (!JvmtiExport::all_dependencies_are_recorded()) {\n-    log_debug(redefine, class, nmethod)(\"Marked all nmethods for deopt\");\n-    CodeCache::mark_all_nmethods_for_evol_deoptimization();\n-    deopt_needed = true;\n-  } else {\n-    int deopt = CodeCache::mark_dependents_for_evol_deoptimization();\n-    log_debug(redefine, class, nmethod)(\"Marked %d dependent nmethods for deopt\", deopt);\n-    deopt_needed = (deopt != 0);\n-  }\n-\n-  if (deopt_needed) {\n-    CodeCache::flush_evol_dependents();\n-  }\n-\n+  struct FlushDependentCodeClosure : DeoptimizationMarkerClosure {\n+    void marker_do(Deoptimization::MarkFn mark_fn) override {\n+      const bool first_call = !JvmtiExport::all_dependencies_are_recorded();\n+      assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n+      CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n+      if (first_call) {\n+        while(iter.next()) {\n+          CompiledMethod* nm = iter.method();\n+          if (!nm->method()->is_method_handle_intrinsic()) {\n+            if (nm->can_be_deoptimized()) {\n+              mark_fn(nm);\n+            }\n+            if (nm->has_evol_metadata()) {\n+              add_to_old_table(nm);\n+            }\n+          }\n+        }\n+        log_debug(redefine, class, nmethod)(\"Marked all nmethods for deopt\");\n+      } else {\n+        \/\/ Each redefinition creates a new set of nmethods that have references to \"old\" Methods\n+        \/\/ So delete old method table and create a new one.\n+        reset_old_method_table();\n+        int number_marked = 0;\n+        while(iter.next()) {\n+          CompiledMethod* nm = iter.method();\n+          \/\/ Walk all alive nmethods to check for old Methods.\n+          \/\/ This includes methods whose inline caches point to old methods, so\n+          \/\/ inline cache clearing is unnecessary.\n+          if (nm->has_evol_metadata()) {\n+            mark_fn(nm);\n+            add_to_old_table(nm);\n+            number_marked++;\n+          }\n+        }\n+        log_debug(redefine, class, nmethod)(\"Marked %d dependent nmethods for deopt\", number_marked);\n+      }\n+    }\n+  };\n+  FlushDependentCodeClosure closure;\n+  Deoptimization::mark_and_deoptimize(closure);\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":85,"deletions":18,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -538,0 +538,3 @@\n+  static void old_nmethods_do(MetadataClosure* f);\n+  static void unregister_old_nmethod(CompiledMethod* c);\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1074,2 +1074,0 @@\n-\n-  int marked = 0;\n@@ -1077,3 +1075,8 @@\n-  {\n-    NoSafepointVerifier nsv;\n-    MutexLocker mu2(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+  struct FlushDependentNmethodsClosure : DeoptimizationMarkerClosure {\n+    Handle& _call_site;\n+    CallSiteDepChange& _changes;\n+    FlushDependentNmethodsClosure(Handle& call_site, CallSiteDepChange& changes)\n+      : _call_site(call_site), _changes(changes) {}\n+    void marker_do(Deoptimization::MarkFn mark_fn) override {\n+      NoSafepointVerifier nsv;\n+      MutexLocker mu2(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n@@ -1081,8 +1084,7 @@\n-    oop context = java_lang_invoke_CallSite::context_no_keepalive(call_site());\n-    DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context);\n-    marked = deps.mark_dependent_nmethods(changes);\n-  }\n-  if (marked > 0) {\n-    \/\/ At least one nmethod has been marked for deoptimization.\n-    Deoptimization::deoptimize_all_marked();\n-  }\n+      oop context = java_lang_invoke_CallSite::context_no_keepalive(_call_site());\n+      DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context);\n+      deps.mark_dependent_nmethods(_changes, mark_fn);\n+    }\n+  };\n+  FlushDependentNmethodsClosure closure(call_site, changes);\n+  Deoptimization::mark_and_deoptimize(closure);\n@@ -1492,12 +1494,14 @@\n-\n-    int marked = 0;\n-    {\n-      NoSafepointVerifier nsv;\n-      MutexLocker mu2(THREAD, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-      DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context());\n-      marked = deps.remove_all_dependents();\n-    }\n-    if (marked > 0) {\n-      \/\/ At least one nmethod has been marked for deoptimization\n-      Deoptimization::deoptimize_all_marked();\n-    }\n+    struct ClearCallSiteContextDependenciesClosure : DeoptimizationMarkerClosure {\n+      Thread* _thread;\n+      Handle& _context;\n+      ClearCallSiteContextDependenciesClosure(Thread* thread, Handle& context)\n+        : _thread(thread), _context(context) {}\n+      void marker_do(Deoptimization::MarkFn mark_fn) override {\n+        NoSafepointVerifier nsv;\n+        MutexLocker mu2(_thread, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+        DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(_context());\n+        deps.remove_and_mark_all_dependents(mark_fn);\n+      }\n+    };\n+    ClearCallSiteContextDependenciesClosure closure(THREAD,context);\n+    Deoptimization::mark_and_deoptimize(closure);\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":29,"deletions":25,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -781,2 +781,2 @@\n-  CodeCache::mark_all_nmethods_for_deoptimization();\n-  Deoptimization::deoptimize_all_marked();\n+  MutexLocker ml(Compile_lock);\n+  Deoptimization::mark_and_deoptimize_all();\n@@ -791,10 +791,18 @@\n-  if (is_osr) {\n-    result += mh->mark_osr_nmethods();\n-  } else if (mh->code() != NULL) {\n-    mh->code()->mark_for_deoptimization();\n-    ++result;\n-  }\n-  result += CodeCache::mark_for_deoptimization(mh());\n-  if (result > 0) {\n-    Deoptimization::deoptimize_all_marked();\n-  }\n+  struct DeoptimizeMethodClosure : DeoptimizationMarkerClosure {\n+    jboolean _is_osr;\n+    methodHandle& _mh;\n+    int& _result;\n+    DeoptimizeMethodClosure(jboolean is_osr, methodHandle& mh, int& result)\n+      : _is_osr(is_osr), _mh(mh), _result(result) {}\n+    void marker_do(Deoptimization::MarkFn mark_fn) override {\n+      if (_is_osr) {\n+        _result = _mh->mark_osr_nmethods(mark_fn);\n+      } else if (_mh->code() != NULL) {\n+        mark_fn(_mh->code());\n+        ++_result;\n+      }\n+      _result += Deoptimization::mark_dependents(_mh(), mark_fn);\n+    }\n+  };\n+  DeoptimizeMethodClosure closure(is_osr, mh, result);\n+  Deoptimization::mark_and_deoptimize(closure);\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":20,"deletions":12,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"code\/dependencies.hpp\"\n@@ -923,1 +924,150 @@\n-void Deoptimization::deoptimize_all_marked(nmethod* nmethod_only) {\n+bool Deoptimization::deoptimize_all_marked() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  CompiledMethod* nm = CompiledMethod::take_root();\n+  bool anything_deoptimized = false;\n+  if (nm != nullptr) {\n+    SweeperBlocker sw;\n+    anything_deoptimized = true;\n+    do {\n+      assert(nm->is_marked_for_deoptimization(), \"All methods in list must be marked\");\n+      if (!nm->has_been_deoptimized() && nm->can_be_deoptimized()) {\n+        nm->make_not_entrant();\n+        make_nmethod_deoptimized(nm);\n+      }\n+      nm = nm->next_marked();\n+    } while(nm != nullptr);\n+  }\n+  return anything_deoptimized;\n+}\n+\n+void Deoptimization::make_nmethod_deoptimized(CompiledMethod* nm) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  if (nm->is_marked_for_deoptimization() && nm->can_be_deoptimized()) {\n+    nm->make_deoptimized();\n+  }\n+}\n+\n+void Deoptimization::mark_and_deoptimize_all() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  struct MarkAndDeoptimizeAllClosure : DeoptimizationMarkerClosure {\n+    void marker_do(Deoptimization::MarkFn mark_fn) override {\n+      MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+      CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n+      while(iter.next()) {\n+        CompiledMethod* nm = iter.method();\n+        if (!nm->is_native_method()) {\n+          mark_fn(nm);\n+        }\n+      }\n+    }\n+  };\n+  MarkAndDeoptimizeAllClosure closure;\n+  mark_and_deoptimize(closure);\n+}\n+\n+\/\/ Keeps track of time spent for checking dependencies\n+NOT_PRODUCT(static elapsedTimer dependentCheckTime;)\n+#ifndef PRODUCT\n+  void Deoptimization::print_dependency_checking_time(outputStream* stream) {\n+    stream->print_cr(\"nmethod dependency checking time %fs\", dependentCheckTime.seconds());\n+  }\n+#endif\n+\n+void Deoptimization::mark_and_deoptimize(KlassDepChange& changes) {\n+  struct MarkAndDeoptimizeClosure: DeoptimizationMarkerClosure {\n+    KlassDepChange& _changes;\n+    MarkAndDeoptimizeClosure(KlassDepChange& changes) : _changes(changes) {}\n+    void marker_do(Deoptimization::MarkFn mark_fn) override {\n+      MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+      \/\/ nmethod::check_all_dependencies works only correctly, if no safepoint\n+      \/\/ can happen\n+      NoSafepointVerifier nsv;\n+      for (DepChange::ContextStream str(_changes, nsv); str.next(); ) {\n+        Klass* d = str.klass();\n+        InstanceKlass::cast(d)->mark_dependent_nmethods(_changes, mark_fn);\n+      }\n+\n+#ifndef PRODUCT\n+      if (VerifyDependencies) {\n+        \/\/ Object pointers are used as unique identifiers for dependency arguments. This\n+        \/\/ is only possible if no safepoint, i.e., GC occurs during the verification code.\n+        dependentCheckTime.start();\n+        nmethod::check_all_dependencies(_changes);\n+        dependentCheckTime.stop();\n+      }\n+#endif\n+    }\n+  };\n+  MarkAndDeoptimizeClosure closure(changes);\n+  Deoptimization::mark_and_deoptimize(closure);\n+}\n+\n+\n+\/\/ Flushes compiled methods dependent on dependee.\n+void Deoptimization::mark_and_deoptimize_dependents_on(InstanceKlass* dependee) {\n+  assert_lock_strong(Compile_lock);\n+\n+  if (CodeCache::number_of_nmethods_with_dependencies() == 0) return;\n+\n+  if (dependee->is_linked()) {\n+    \/\/ Class initialization state change.\n+    KlassInitDepChange changes(dependee);\n+    mark_and_deoptimize(changes);\n+  } else {\n+    \/\/ New class is loaded.\n+    NewKlassDepChange changes(dependee);\n+    mark_and_deoptimize(changes);\n+  }\n+}\n+\n+void Deoptimization::MarkFn::operator()(CompiledMethod* cm, bool inc_recompile_counts) {\n+  cm->mark_for_deoptimization(inc_recompile_counts);\n+}\n+\n+void Deoptimization::mark_and_deoptimize(DeoptimizationMarkerClosure& marker_closure) {\n+  DeoptimizationMarker dm;\n+  bool anything_deoptimized = false;\n+  {\n+    NoSafepointVerifier nsv;\n+    assert_locked_or_safepoint(Compile_lock);\n+    marker_closure.marker_do(MarkFn());\n+    anything_deoptimized = deoptimize_all_marked();\n+  }\n+  if (anything_deoptimized) {\n+    run_deoptimize_closure();\n+  }\n+}\n+\n+void Deoptimization::mark_and_deoptimize_dependents(const methodHandle& m_h) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  Deoptimization::mark_and_deoptimize_dependents(m_h());\n+}\n+\n+int Deoptimization::mark_dependents(Method* dependee, Deoptimization::MarkFn mark_fn) {\n+  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+  int number_marked = 0;\n+  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n+  while(iter.next()) {\n+    CompiledMethod* nm = iter.method();\n+    if (nm->is_dependent_on_method(dependee)) {\n+      mark_fn(nm);\n+      ++number_marked;\n+    }\n+  }\n+  return number_marked;\n+}\n+\n+void Deoptimization::mark_and_deoptimize_dependents(Method* dependee) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  struct MarkAandDeoptimizeDependentsClosure : DeoptimizationMarkerClosure {\n+    Method* _dependee;\n+    MarkAandDeoptimizeDependentsClosure(Method* dependee) : _dependee(dependee) {}\n+    void marker_do(Deoptimization::MarkFn mark_fn) override {\n+      mark_dependents(_dependee, mark_fn);\n+    }\n+  };\n+  MarkAandDeoptimizeDependentsClosure closure(dependee);\n+  mark_and_deoptimize(closure);\n+}\n+\n+void Deoptimization::mark_and_deoptimize_nmethod(nmethod* nmethod) {\n@@ -926,0 +1076,3 @@\n+  {\n+    assert_locked_or_safepoint(Compile_lock);\n+    assert(nmethod != nullptr, \"nmethod connot be null\");\n@@ -927,7 +1080,3 @@\n-  \/\/ Make the dependent methods not entrant\n-  if (nmethod_only != NULL) {\n-    nmethod_only->mark_for_deoptimization();\n-    nmethod_only->make_not_entrant();\n-    CodeCache::make_nmethod_deoptimized(nmethod_only);\n-  } else {\n-    CodeCache::make_marked_nmethods_deoptimized();\n+    nmethod->mark_for_deoptimization();\n+    nmethod->make_not_entrant();\n+    Deoptimization::make_nmethod_deoptimized(nmethod);\n@@ -936,0 +1085,4 @@\n+  run_deoptimize_closure();\n+}\n+\n+void Deoptimization::run_deoptimize_closure() {\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":161,"deletions":8,"binary":false,"changes":169,"status":"modified"},{"patch":"@@ -40,0 +40,2 @@\n+class DeoptimizationMarkerClosure;\n+class KlassDepChange;\n@@ -151,5 +153,24 @@\n-  \/\/ Make all nmethods that are marked_for_deoptimization not_entrant and deoptimize any live\n-  \/\/ activations using those nmethods.  If an nmethod is passed as an argument then it is\n-  \/\/ marked_for_deoptimization and made not_entrant.  Otherwise a scan of the code cache is done to\n-  \/\/ find all marked nmethods and they are made not_entrant.\n-  static void deoptimize_all_marked(nmethod* nmethod_only = NULL);\n+private:\n+  static void mark_and_deoptimize(KlassDepChange& changes);\n+  static bool deoptimize_all_marked();\n+  static void make_nmethod_deoptimized(CompiledMethod* nm);\n+  static void run_deoptimize_closure();\n+\n+public:\n+  static void mark_and_deoptimize(DeoptimizationMarkerClosure& marker_closure);\n+  static void mark_and_deoptimize_nmethod(nmethod* nmethod);\n+  static void mark_and_deoptimize_all();\n+  static void mark_and_deoptimize_dependents(const methodHandle& dependee);\n+  static void mark_and_deoptimize_dependents(Method* dependee);\n+  static void mark_and_deoptimize_dependents_on(InstanceKlass* dependee);\n+  class MarkFn : StackObj {\n+    friend void Deoptimization::mark_and_deoptimize(DeoptimizationMarkerClosure&);\n+    MarkFn() {};\n+  public:\n+    void operator()(CompiledMethod* cm, bool inc_recompile_counts = true);\n+  };\n+  static int mark_dependents(Method* dependee, Deoptimization::MarkFn mark_fn);\n+\n+#ifndef PRODUCT\n+  static void print_dependency_checking_time(outputStream* stream);\n+#endif\n@@ -485,0 +506,5 @@\n+class DeoptimizationMarkerClosure : StackObj {\n+public:\n+  virtual void marker_do(Deoptimization::MarkFn mark_fn) = 0;\n+};\n+\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":31,"deletions":5,"binary":false,"changes":36,"status":"modified"}]}