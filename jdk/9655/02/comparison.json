{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,3 @@\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiRedefineClasses.hpp\"\n+#endif\n@@ -70,1 +73,3 @@\n-      CodeCache::old_nmethods_do(&md_on_stack);\n+#if INCLUDE_JVMTI\n+      VM_RedefineClasses::old_nmethods_do(&md_on_stack);\n+#endif\n","filename":"src\/hotspot\/share\/classfile\/metadataOnStackMark.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -1652,1 +1653,1 @@\n-    CodeCache::flush_dependents_on(k);\n+    Deoptimization::deoptimize_dependents(k);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"code\/dependencies.hpp\"\n@@ -761,1 +760,1 @@\n-void CodeCache::do_unloading(BoolObjectClosure* is_alive, bool unloading_occurred) {\n+void CodeCache::do_unloading(bool unloading_occurred) {\n@@ -763,1 +762,0 @@\n-  UnloadingScope scope(is_alive);\n@@ -1074,32 +1072,0 @@\n-\/\/ Keeps track of time spent for checking dependencies\n-NOT_PRODUCT(static elapsedTimer dependentCheckTime;)\n-\n-int CodeCache::mark_for_deoptimization(KlassDepChange& changes) {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  int number_of_marked_CodeBlobs = 0;\n-\n-  \/\/ search the hierarchy looking for nmethods which are affected by the loading of this class\n-\n-  \/\/ then search the interfaces this class implements looking for nmethods\n-  \/\/ which might be dependent of the fact that an interface only had one\n-  \/\/ implementor.\n-  \/\/ nmethod::check_all_dependencies works only correctly, if no safepoint\n-  \/\/ can happen\n-  NoSafepointVerifier nsv;\n-  for (DepChange::ContextStream str(changes, nsv); str.next(); ) {\n-    Klass* d = str.klass();\n-    number_of_marked_CodeBlobs += InstanceKlass::cast(d)->mark_dependent_nmethods(changes);\n-  }\n-\n-#ifndef PRODUCT\n-  if (VerifyDependencies) {\n-    \/\/ Object pointers are used as unique identifiers for dependency arguments. This\n-    \/\/ is only possible if no safepoint, i.e., GC occurs during the verification code.\n-    dependentCheckTime.start();\n-    nmethod::check_all_dependencies(changes);\n-    dependentCheckTime.stop();\n-  }\n-#endif\n-\n-  return number_of_marked_CodeBlobs;\n-}\n@@ -1113,183 +1079,0 @@\n-#if INCLUDE_JVMTI\n-\/\/ RedefineClasses support for saving nmethods that are dependent on \"old\" methods.\n-\/\/ We don't really expect this table to grow very large.  If it does, it can become a hashtable.\n-static GrowableArray<CompiledMethod*>* old_compiled_method_table = NULL;\n-\n-static void add_to_old_table(CompiledMethod* c) {\n-  if (old_compiled_method_table == NULL) {\n-    old_compiled_method_table = new (ResourceObj::C_HEAP, mtCode) GrowableArray<CompiledMethod*>(100, mtCode);\n-  }\n-  old_compiled_method_table->push(c);\n-}\n-\n-static void reset_old_method_table() {\n-  if (old_compiled_method_table != NULL) {\n-    delete old_compiled_method_table;\n-    old_compiled_method_table = NULL;\n-  }\n-}\n-\n-\/\/ Remove this method when zombied or unloaded.\n-void CodeCache::unregister_old_nmethod(CompiledMethod* c) {\n-  assert_lock_strong(CodeCache_lock);\n-  if (old_compiled_method_table != NULL) {\n-    int index = old_compiled_method_table->find(c);\n-    if (index != -1) {\n-      old_compiled_method_table->delete_at(index);\n-    }\n-  }\n-}\n-\n-void CodeCache::old_nmethods_do(MetadataClosure* f) {\n-  \/\/ Walk old method table and mark those on stack.\n-  int length = 0;\n-  if (old_compiled_method_table != NULL) {\n-    length = old_compiled_method_table->length();\n-    for (int i = 0; i < length; i++) {\n-      CompiledMethod* cm = old_compiled_method_table->at(i);\n-      \/\/ Only walk alive nmethods, the dead ones will get removed by the sweeper or GC.\n-      if (cm->is_alive() && !cm->is_unloading()) {\n-        old_compiled_method_table->at(i)->metadata_do(f);\n-      }\n-    }\n-  }\n-  log_debug(redefine, class, nmethod)(\"Walked %d nmethods for mark_on_stack\", length);\n-}\n-\n-\/\/ Walk compiled methods and mark dependent methods for deoptimization.\n-int CodeCache::mark_dependents_for_evol_deoptimization() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-  \/\/ Each redefinition creates a new set of nmethods that have references to \"old\" Methods\n-  \/\/ So delete old method table and create a new one.\n-  reset_old_method_table();\n-\n-  int number_of_marked_CodeBlobs = 0;\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    \/\/ Walk all alive nmethods to check for old Methods.\n-    \/\/ This includes methods whose inline caches point to old methods, so\n-    \/\/ inline cache clearing is unnecessary.\n-    if (nm->has_evol_metadata()) {\n-      nm->mark_for_deoptimization();\n-      add_to_old_table(nm);\n-      number_of_marked_CodeBlobs++;\n-    }\n-  }\n-\n-  \/\/ return total count of nmethods marked for deoptimization, if zero the caller\n-  \/\/ can skip deoptimization\n-  return number_of_marked_CodeBlobs;\n-}\n-\n-void CodeCache::mark_all_nmethods_for_evol_deoptimization() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (!nm->method()->is_method_handle_intrinsic()) {\n-      if (nm->can_be_deoptimized()) {\n-        nm->mark_for_deoptimization();\n-      }\n-      if (nm->has_evol_metadata()) {\n-        add_to_old_table(nm);\n-      }\n-    }\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on redefined classes, that have already been\n-\/\/ marked for deoptimization.\n-void CodeCache::flush_evol_dependents() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-\n-  \/\/ CodeCache can only be updated by a thread_in_VM and they will all be\n-  \/\/ stopped during the safepoint so CodeCache will be safe to update without\n-  \/\/ holding the CodeCache_lock.\n-\n-  \/\/ At least one nmethod has been marked for deoptimization\n-\n-  Deoptimization::deoptimize_all_marked();\n-}\n-#endif \/\/ INCLUDE_JVMTI\n-\n-\/\/ Mark methods for deopt (if safe or possible).\n-void CodeCache::mark_all_nmethods_for_deoptimization() {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (!nm->is_native_method()) {\n-      nm->mark_for_deoptimization();\n-    }\n-  }\n-}\n-\n-int CodeCache::mark_for_deoptimization(Method* dependee) {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  int number_of_marked_CodeBlobs = 0;\n-\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (nm->is_dependent_on_method(dependee)) {\n-      ResourceMark rm;\n-      nm->mark_for_deoptimization();\n-      number_of_marked_CodeBlobs++;\n-    }\n-  }\n-\n-  return number_of_marked_CodeBlobs;\n-}\n-\n-void CodeCache::make_marked_nmethods_deoptimized() {\n-  SweeperBlockingCompiledMethodIterator iter(SweeperBlockingCompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (nm->is_marked_for_deoptimization() && !nm->has_been_deoptimized() && nm->can_be_deoptimized()) {\n-      nm->make_not_entrant();\n-      make_nmethod_deoptimized(nm);\n-    }\n-  }\n-}\n-\n-void CodeCache::make_nmethod_deoptimized(CompiledMethod* nm) {\n-  if (nm->is_marked_for_deoptimization() && nm->can_be_deoptimized()) {\n-    nm->make_deoptimized();\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on dependee.\n-void CodeCache::flush_dependents_on(InstanceKlass* dependee) {\n-  assert_lock_strong(Compile_lock);\n-\n-  if (number_of_nmethods_with_dependencies() == 0) return;\n-\n-  int marked = 0;\n-  if (dependee->is_linked()) {\n-    \/\/ Class initialization state change.\n-    KlassInitDepChange changes(dependee);\n-    marked = mark_for_deoptimization(changes);\n-  } else {\n-    \/\/ New class is loaded.\n-    NewKlassDepChange changes(dependee);\n-    marked = mark_for_deoptimization(changes);\n-  }\n-\n-  if (marked > 0) {\n-    \/\/ At least one nmethod has been marked for deoptimization\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on dependee\n-void CodeCache::flush_dependents_on_method(const methodHandle& m_h) {\n-  \/\/ --- Compile_lock is not held. However we are at a safepoint.\n-  assert_locked_or_safepoint(Compile_lock);\n-\n-  \/\/ Compute the dependent nmethods\n-  if (mark_for_deoptimization(m_h()) > 0) {\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-}\n-\n@@ -1556,1 +1339,1 @@\n-  tty->print_cr(\"nmethod dependency checking time %fs\", dependentCheckTime.seconds());\n+  Deoptimization::print_dependency_checking_time(tty);\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":2,"deletions":219,"binary":false,"changes":221,"status":"modified"},{"patch":"@@ -76,1 +76,0 @@\n-class KlassDepChange;\n@@ -124,0 +123,1 @@\n+    friend class SweeperBlocker;\n@@ -200,1 +200,1 @@\n-  static void do_unloading(BoolObjectClosure* is_alive, bool unloading_occurred);\n+  static void do_unloading(bool unloading_occurred);\n@@ -285,4 +285,0 @@\n-  \/\/ Deoptimization\n- private:\n-  static int  mark_for_deoptimization(KlassDepChange& changes);\n-\n@@ -290,19 +286,0 @@\n-  static void mark_all_nmethods_for_deoptimization();\n-  static int  mark_for_deoptimization(Method* dependee);\n-  static void make_marked_nmethods_deoptimized();\n-  static void make_nmethod_deoptimized(CompiledMethod* nm);\n-\n-  \/\/ Flushing and deoptimization\n-  static void flush_dependents_on(InstanceKlass* dependee);\n-\n-  \/\/ RedefineClasses support\n-  \/\/ Flushing and deoptimization in case of evolution\n-  static int  mark_dependents_for_evol_deoptimization();\n-  static void mark_all_nmethods_for_evol_deoptimization();\n-  static void flush_evol_dependents();\n-  static void old_nmethods_do(MetadataClosure* f) NOT_JVMTI_RETURN;\n-  static void unregister_old_nmethod(CompiledMethod* c) NOT_JVMTI_RETURN;\n-\n-  \/\/ Support for fullspeed debugging\n-  static void flush_dependents_on_method(const methodHandle& dependee);\n-\n@@ -329,0 +306,9 @@\n+class SweeperBlocker : public StackObj {\n+  public:\n+    SweeperBlocker() {\n+      CodeCache::Sweep::begin_compiled_method_iteration();\n+    }\n+    ~SweeperBlocker() {\n+      CodeCache::Sweep::end_compiled_method_iteration();\n+    }\n+};\n","filename":"src\/hotspot\/share\/code\/codeCache.hpp","additions":11,"deletions":25,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -57,1 +57,0 @@\n-    _mark_for_deoptimization_status(not_marked),\n@@ -69,1 +68,0 @@\n-    _mark_for_deoptimization_status(not_marked),\n@@ -120,6 +118,5 @@\n-void CompiledMethod::mark_for_deoptimization(bool inc_recompile_counts) {\n-  \/\/ assert(can_be_deoptimized(), \"\"); \/\/ in some places we check before marking, in others not.\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n-                 Mutex::_no_safepoint_check_flag);\n-  if (_mark_for_deoptimization_status != deoptimize_done) { \/\/ can't go backwards\n-     _mark_for_deoptimization_status = (inc_recompile_counts ? deoptimize : deoptimize_noupdate);\n+bool CompiledMethod::enqueue_deoptimization(bool inc_recompile_counts) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  DeoptimizationStatus old_status = _deoptimization_status;\n+  if (_deoptimization_status != deoptimize_done) { \/\/ can't go backwards\n+    _deoptimization_status = (inc_recompile_counts ? enqueued : enqueued_noupdate);\n@@ -127,0 +124,6 @@\n+  return old_status == not_enqueued;\n+}\n+\n+void  CompiledMethod::make_deoptimized_done() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  _deoptimization_status = deoptimize_done;\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  friend class DeoptimizationContext;\n@@ -147,4 +148,6 @@\n-  enum MarkForDeoptimizationStatus : u1 {\n-    not_marked,\n-    deoptimize,\n-    deoptimize_noupdate,\n+  enum DeoptimizationStatus : u1 {\n+    not_enqueued,\n+    enqueued,\n+    enqueued_noupdate,\n+    \/\/ TODO: look at deoptimize_done, it is only used for continuations, misleading\n+    \/\/ see TODO comment in update_recompile_counts().\n@@ -154,1 +157,1 @@\n-  MarkForDeoptimizationStatus _mark_for_deoptimization_status; \/\/ Used for stack deoptimization\n+  DeoptimizationStatus _deoptimization_status; \/\/ Used for stack deoptimization\n@@ -245,2 +248,1 @@\n-  bool  is_marked_for_deoptimization() const { return _mark_for_deoptimization_status != not_marked; }\n-  void  mark_for_deoptimization(bool inc_recompile_counts = true);\n+  bool  has_been_enqueued_for_deoptimization() const { return _deoptimization_status != not_enqueued; }\n@@ -248,2 +250,11 @@\n-  bool  has_been_deoptimized() const { return _mark_for_deoptimization_status == deoptimize_done; }\n-  void  mark_deoptimized() { _mark_for_deoptimization_status = deoptimize_done; }\n+  \/\/ TODO: deoptimize_done is very weird in this new thing\n+  \/\/ see TODO comment in update_recompile_counts().\n+  bool  has_been_deoptimized() const { return _deoptimization_status == deoptimize_done; }\n+\n+private:\n+  bool  enqueue_deoptimization(bool inc_recompile_counts = true);\n+protected:\n+  \/\/ TODO: bad name for what it does.\n+  \/\/ see TODO comment in update_recompile_counts().\n+  void  make_deoptimized_done();\n+public:\n@@ -254,5 +265,30 @@\n-    \/\/ Update recompile counts when either the update is explicitly requested (deoptimize)\n-    \/\/ or the nmethod is not marked for deoptimization at all (not_marked).\n-    \/\/ The latter happens during uncommon traps when deoptimized nmethod is made not entrant.\n-    return _mark_for_deoptimization_status != deoptimize_noupdate &&\n-           _mark_for_deoptimization_status != deoptimize_done;\n+    \/\/ TODO: fix this logic!\n+    \/\/ Original Text with new enum terminology:\n+      \/\/ Update recompile counts when either the update is explicitly requested (enqueued)\n+      \/\/ or the nmethod has not enqueued deoptimization at all (not_enqueued).\n+      \/\/ The latter happens during uncommon traps when deoptimized nmethod is made not entrant.\n+    \/\/ Actually behaviour:\n+      \/\/ The function is only used in when an nmethod is made not entrant (or zombie) and\n+      \/\/ _deoptimization_status != deoptimize_done is always true, as it is only called in\n+      \/\/ make_deoptimized which is called right after a call to make_not_entrant. Even if\n+      \/\/ some other thread comes before that call and makes this nmethod not entrant (or zombie)\n+      \/\/ that thread will not see _deoptimization_status == deoptimize_done and if some thread\n+      \/\/ calls make_not_entrant after it will not succeed as it was already made non_entrant.\n+      \/\/ the unloaded transition will not affect this either. (the try_transition race). And it\n+      \/\/ is gone when the sweeper is removed. So now it is pretty much just update the recompile\n+      \/\/ count if not explicitly told not too (enqueued_noupdate).\n+    \/\/ _deoptimization_status != deoptimize_done sort of makes sense if it meant what it actually says,\n+    \/\/ but the semantics of deoptimize_done is unclear and need to be defined.\n+      \/\/ Right now it means nothing if continuations is turned off. And with it on it means that the\n+      \/\/ nmethod's NativePostCallNop have been patched. Neither truly means that the nmethod has been\n+      \/\/ deoptimized. As we still need to walk the frame stacks and install deopt return pc's.\n+        \/\/ frame::deoptimize also have some dead code, NativePostCallNop* inst = nativePostCallNop_at(pc()),\n+        \/\/ which has no side effects. (inst never used).\n+        \/\/ frame::patch_pc takes a Thread* and never uses it.\n+      \/\/ So maybe there should be another status, deoptimize_post_call_installed and deoptimize_done. And\n+      \/\/ deoptimize_done is only set after the frames has been walked. This does however require finding all\n+      \/\/ the nmethods again, it seems overly complicated to just have a flag which is never used. Maybe rename\n+      \/\/ deoptimize_done to deoptimize_post_call_installed is the best and not track if all the steps of the\n+      \/\/ deoptimization has been completed.\n+    return _deoptimization_status != enqueued_noupdate &&\n+        _deoptimization_status != deoptimize_done;\n","filename":"src\/hotspot\/share\/code\/compiledMethod.hpp","additions":50,"deletions":14,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -686,1 +687,1 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) = 0;\n+  virtual void enqueue_deoptimization(nmethod* nm, DeoptimizationContext* deopt) = 0;\n@@ -784,2 +785,2 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) {\n-    nm->mark_for_deoptimization(\/*inc_recompile_counts=*\/true);\n+  virtual void enqueue_deoptimization(nmethod* nm, DeoptimizationContext* deopt) {\n+    deopt->enqueue(nm);\n@@ -826,2 +827,2 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) {\n-    nm->mark_for_deoptimization(\/*inc_recompile_counts=*\/false);\n+  virtual void enqueue_deoptimization(nmethod* nm, DeoptimizationContext* deopt) {\n+    deopt->enqueue_no_recompile_count_update(nm);\n","filename":"src\/hotspot\/share\/code\/dependencies.hpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -64,2 +65,2 @@\n-\/\/ are dependent on the changes that were passed in and mark them for\n-\/\/ deoptimization.  Returns the number of nmethods found.\n+\/\/ are dependent on the changes that were passed in and enqueue\n+\/\/ deoptimization for them.  Returns the number of nmethods found.\n@@ -67,2 +68,1 @@\n-int DependencyContext::mark_dependent_nmethods(DepChange& changes) {\n-  int found = 0;\n+void DependencyContext::enqueue_deoptimization_dependent_nmethods(DepChange& changes, DeoptimizationContext* deopt) {\n@@ -73,1 +73,1 @@\n-    if (b->count() > 0 && nm->is_alive() && !nm->is_marked_for_deoptimization() && nm->check_dependency_on(changes)) {\n+    if (b->count() > 0 && nm->is_alive() && !nm->has_been_enqueued_for_deoptimization() && nm->check_dependency_on(changes)) {\n@@ -76,1 +76,1 @@\n-        tty->print_cr(\"Marked for deoptimization\");\n+        tty->print_cr(\"Enqueued deoptimization\");\n@@ -81,2 +81,1 @@\n-      changes.mark_for_deoptimization(nm);\n-      found++;\n+      changes.enqueue_deoptimization(nm, deopt);\n@@ -85,1 +84,0 @@\n-  return found;\n@@ -208,0 +206,6 @@\n+nmethodBucket* DependencyContext::release_and_get_next_not_unloading(nmethodBucket* b) {\n+  nmethodBucket* next = b->next_not_unloading();\n+  release(b);\n+  return next;\n+ }\n+\n@@ -210,1 +214,7 @@\n-int DependencyContext::remove_all_dependents() {\n+void DependencyContext::remove_all_dependents() {\n+  nmethodBucket* b = dependencies_not_unloading();\n+  set_dependencies(NULL);\n+  assert(b == nullptr, \"All dependents should be unloading\");\n+}\n+\n+void DependencyContext::remove_and_enqueue_deoptimization_all_dependents(DeoptimizationContext* deopt) {\n@@ -213,2 +223,0 @@\n-  int marked = 0;\n-  int removed = 0;\n@@ -217,3 +225,2 @@\n-    if (b->count() > 0 && nm->is_alive() && !nm->is_marked_for_deoptimization()) {\n-      nm->mark_for_deoptimization();\n-      marked++;\n+    if (b->count() > 0 && nm->is_alive() && !nm->has_been_enqueued_for_deoptimization()) {\n+      deopt->enqueue(nm);\n@@ -221,7 +228,1 @@\n-    nmethodBucket* next = b->next_not_unloading();\n-    removed++;\n-    release(b);\n-    b = next;\n-  }\n-  if (UsePerfData && removed > 0) {\n-    _perf_total_buckets_deallocated_count->inc(removed);\n+    b = release_and_get_next_not_unloading(b);\n@@ -229,1 +230,0 @@\n-  return marked;\n","filename":"src\/hotspot\/share\/code\/dependencyContext.cpp","additions":23,"deletions":23,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -88,0 +89,1 @@\n+  nmethodBucket* release_and_get_next_not_unloading(nmethodBucket* b);\n@@ -120,1 +122,1 @@\n-  int  mark_dependent_nmethods(DepChange& changes);\n+  void enqueue_deoptimization_dependent_nmethods(DepChange& changes, DeoptimizationContext* deopt);\n@@ -123,1 +125,2 @@\n-  int  remove_all_dependents();\n+  void remove_all_dependents();\n+  void remove_and_enqueue_deoptimization_all_dependents(DeoptimizationContext* deopt);\n","filename":"src\/hotspot\/share\/code\/dependencyContext.hpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -86,0 +86,3 @@\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiRedefineClasses.hpp\"\n+#endif\n@@ -1162,1 +1165,1 @@\n-  mark_deoptimized();\n+  make_deoptimized_done();\n@@ -1469,0 +1472,1 @@\n+      \/\/ TODO: Fix terminology\n@@ -1618,1 +1622,3 @@\n-  CodeCache::unregister_old_nmethod(this);\n+#if INCLUDE_JVMTI\n+  VM_RedefineClasses::unregister_old_nmethod(this);\n+#endif\n@@ -2353,2 +2359,2 @@\n-  \/\/ Iterate over live nmethods and check dependencies of all nmethods that are not\n-  \/\/ marked for deoptimization. A particular dependency is only checked once.\n+  \/\/ Iterate over live nmethods and check dependencies of all nmethods that has not\n+  \/\/ been enqueue for deoptimization. A particular dependency is only checked once.\n@@ -2359,1 +2365,1 @@\n-    if (!nm->is_marked_for_deoptimization()) {\n+    if (!nm->has_been_enqueued_for_deoptimization()) {\n@@ -2375,1 +2381,1 @@\n-            assert(false, \"Should have been marked for deoptimization\");\n+            assert(false, \"Should have enqueued deoptimization\");\n@@ -2398,1 +2404,0 @@\n-\/\/ Called from mark_for_deoptimization, when dependee is invalidated.\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":12,"deletions":7,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -2893,2 +2893,1 @@\n-void G1CollectedHeap::complete_cleaning(BoolObjectClosure* is_alive,\n-                                        bool class_unloading_occurred) {\n+void G1CollectedHeap::complete_cleaning(bool class_unloading_occurred) {\n@@ -2896,1 +2895,1 @@\n-  G1ParallelCleaningTask unlink_task(is_alive, num_workers, class_unloading_occurred);\n+  G1ParallelCleaningTask unlink_task(num_workers, class_unloading_occurred);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1264,1 +1264,1 @@\n-  void complete_cleaning(BoolObjectClosure* is_alive, bool class_unloading_occurred);\n+  void complete_cleaning(bool class_unloading_occurred);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1684,0 +1684,1 @@\n+    CodeCache::UnloadingScope scope(&g1_is_alive);\n@@ -1685,1 +1686,1 @@\n-    _g1h->complete_cleaning(&g1_is_alive, purged_classes);\n+    _g1h->complete_cleaning(purged_classes);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -304,0 +304,1 @@\n+    CodeCache::UnloadingScope unloading_scope(&_is_alive);\n@@ -306,1 +307,1 @@\n-    _heap->complete_cleaning(&_is_alive, purged_class);\n+    _heap->complete_cleaning(purged_class);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -54,2 +54,1 @@\n-G1ParallelCleaningTask::G1ParallelCleaningTask(BoolObjectClosure* is_alive,\n-                                               uint num_workers,\n+G1ParallelCleaningTask::G1ParallelCleaningTask(uint num_workers,\n@@ -59,1 +58,1 @@\n-  _code_cache_task(num_workers, is_alive, unloading_occurred),\n+  _code_cache_task(num_workers, unloading_occurred),\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParallelCleaning.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -57,2 +57,1 @@\n-  G1ParallelCleaningTask(BoolObjectClosure* is_alive,\n-                         uint num_workers,\n+  G1ParallelCleaningTask(uint num_workers,\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParallelCleaning.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2059,0 +2059,1 @@\n+    CodeCache::UnloadingScope scope(is_alive_closure());\n@@ -2064,1 +2065,1 @@\n-    CodeCache::do_unloading(is_alive_closure(), purged_class);\n+    CodeCache::do_unloading(purged_class);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -218,0 +218,1 @@\n+    CodeCache::UnloadingScope scope(&is_alive);\n@@ -223,1 +224,1 @@\n-    CodeCache::do_unloading(&is_alive, purged_class);\n+    CodeCache::do_unloading(purged_class);\n","filename":"src\/hotspot\/share\/gc\/serial\/genMarkSweep.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -35,2 +35,1 @@\n-CodeCacheUnloadingTask::CodeCacheUnloadingTask(uint num_workers, BoolObjectClosure* is_alive, bool unloading_occurred) :\n-  _unloading_scope(is_alive),\n+CodeCacheUnloadingTask::CodeCacheUnloadingTask(uint num_workers, bool unloading_occurred) :\n","filename":"src\/hotspot\/share\/gc\/shared\/parallelCleaning.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-  CodeCache::UnloadingScope _unloading_scope;\n@@ -44,1 +43,1 @@\n-  CodeCacheUnloadingTask(uint num_workers, BoolObjectClosure* is_alive, bool unloading_occurred);\n+  CodeCacheUnloadingTask(uint num_workers, bool unloading_occurred);\n","filename":"src\/hotspot\/share\/gc\/shared\/parallelCleaning.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+#include \"code\/codeCache.hpp\"\n@@ -1793,0 +1794,2 @@\n+    ShenandoahIsAliveSelector is_alive;\n+    CodeCache::UnloadingScope scope(is_alive.is_alive_closure());\n@@ -1797,1 +1800,0 @@\n-    ShenandoahIsAliveSelector is_alive;\n@@ -1799,1 +1801,1 @@\n-    ShenandoahClassUnloadingTask unlink_task(phase, is_alive.is_alive_closure(), num_workers, purged_class);\n+    ShenandoahClassUnloadingTask unlink_task(phase, num_workers, purged_class);\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahHeap.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -35,1 +35,0 @@\n-                                                           BoolObjectClosure* is_alive,\n@@ -41,1 +40,1 @@\n-  _code_cache_task(num_workers, is_alive, unloading_occurred),\n+  _code_cache_task(num_workers, unloading_occurred),\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahParallelCleaning.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -62,1 +62,0 @@\n-                               BoolObjectClosure* is_alive,\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahParallelCleaning.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1539,1 +1539,1 @@\n-    Deoptimization::deoptimize_all_marked(nm);\n+    Deoptimization::deoptimize_nmethod(nm);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciEnv.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1184,1 +1184,1 @@\n-    CodeCache::flush_dependents_on(this);\n+     Deoptimization::deoptimize_dependents(this);\n@@ -2337,2 +2337,2 @@\n-int InstanceKlass::mark_dependent_nmethods(KlassDepChange& changes) {\n-  return dependencies().mark_dependent_nmethods(changes);\n+void InstanceKlass::enqueue_deoptimization_dependent_nmethods(KlassDepChange& changes, DeoptimizationContext* deopt) {\n+  dependencies().enqueue_deoptimization_dependent_nmethods(changes, deopt);\n@@ -3322,1 +3322,1 @@\n-int InstanceKlass::mark_osr_nmethods(const Method* m) {\n+void InstanceKlass::enqueue_deoptimization_osr_nmethods(const Method* m, DeoptimizationContext* deopt) {\n@@ -3326,1 +3326,0 @@\n-  int found = 0;\n@@ -3330,2 +3329,1 @@\n-      osr->mark_for_deoptimization();\n-      found++;\n+      deopt->enqueue(osr);\n@@ -3335,1 +3333,0 @@\n-  return found;\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -940,1 +941,1 @@\n-  int  mark_dependent_nmethods(KlassDepChange& changes);\n+  void enqueue_deoptimization_dependent_nmethods(KlassDepChange& changes, DeoptimizationContext* deopt);\n@@ -950,1 +951,1 @@\n-  int mark_osr_nmethods(const Method* m);\n+  void enqueue_deoptimization_osr_nmethods(const Method* m, DeoptimizationContext* deopt);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2037,1 +2037,1 @@\n-    CodeCache::flush_dependents_on_method(mh);\n+    Deoptimization::deoptimize_dependents(mh);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -917,2 +918,2 @@\n-  int mark_osr_nmethods() {\n-    return method_holder()->mark_osr_nmethods(this);\n+  void enqueue_deoptimization_osr_nmethods(DeoptimizationContext* deopt) {\n+    method_holder()->enqueue_deoptimization_osr_nmethods(this, deopt);\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -4078,0 +4078,45 @@\n+\/\/ RedefineClasses support for saving nmethods that are dependent on \"old\" methods.\n+\/\/ We don't really expect this table to grow very large.  If it does, it can become a hashtable.\n+static GrowableArray<CompiledMethod*>* old_compiled_method_table = NULL;\n+\n+static void add_to_old_table(CompiledMethod* c) {\n+  if (old_compiled_method_table == NULL) {\n+    old_compiled_method_table = new (ResourceObj::C_HEAP, mtCode) GrowableArray<CompiledMethod*>(100, mtCode);\n+  }\n+  old_compiled_method_table->push(c);\n+}\n+\n+static void reset_old_method_table() {\n+  if (old_compiled_method_table != NULL) {\n+    delete old_compiled_method_table;\n+    old_compiled_method_table = NULL;\n+  }\n+}\n+\n+\/\/ Remove this method when zombied or unloaded.\n+void VM_RedefineClasses::unregister_old_nmethod(CompiledMethod* c) {\n+  assert_lock_strong(CodeCache_lock);\n+  if (old_compiled_method_table != NULL) {\n+    int index = old_compiled_method_table->find(c);\n+    if (index != -1) {\n+      old_compiled_method_table->delete_at(index);\n+    }\n+  }\n+}\n+\n+void VM_RedefineClasses::old_nmethods_do(MetadataClosure* f) {\n+  \/\/ Walk old method table and mark those on stack.\n+  int length = 0;\n+  if (old_compiled_method_table != NULL) {\n+    length = old_compiled_method_table->length();\n+    for (int i = 0; i < length; i++) {\n+      CompiledMethod* cm = old_compiled_method_table->at(i);\n+      \/\/ Only walk alive nmethods, the dead ones will get removed by the sweeper or GC.\n+      if (cm->is_alive() && !cm->is_unloading()) {\n+        old_compiled_method_table->at(i)->metadata_do(f);\n+      }\n+    }\n+  }\n+  log_debug(redefine, class, nmethod)(\"Walked %d nmethods for mark_on_stack\", length);\n+}\n+\n@@ -4096,8 +4141,17 @@\n-\n-  bool deopt_needed;\n-\n-  \/\/ This is the first redefinition, mark all the nmethods for deoptimization\n-  if (!JvmtiExport::all_dependencies_are_recorded()) {\n-    log_debug(redefine, class, nmethod)(\"Marked all nmethods for deopt\");\n-    CodeCache::mark_all_nmethods_for_evol_deoptimization();\n-    deopt_needed = true;\n+  DeoptimizationContext deopt;\n+  const bool first_call = !JvmtiExport::all_dependencies_are_recorded();\n+  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n+  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n+  if (first_call) {\n+    while(iter.next()) {\n+      CompiledMethod* nm = iter.method();\n+      if (!nm->method()->is_method_handle_intrinsic()) {\n+        if (nm->can_be_deoptimized()) {\n+          deopt.enqueue(nm);\n+        }\n+        if (nm->has_evol_metadata()) {\n+          add_to_old_table(nm);\n+        }\n+      }\n+    }\n+    log_debug(redefine, class, nmethod)(\"Enqueued all nmethods for deopt\");\n@@ -4105,7 +4159,14 @@\n-    int deopt = CodeCache::mark_dependents_for_evol_deoptimization();\n-    log_debug(redefine, class, nmethod)(\"Marked %d dependent nmethods for deopt\", deopt);\n-    deopt_needed = (deopt != 0);\n-  }\n-\n-  if (deopt_needed) {\n-    CodeCache::flush_evol_dependents();\n+    \/\/ Each redefinition creates a new set of nmethods that have references to \"old\" Methods\n+    \/\/ So delete old method table and create a new one.\n+    reset_old_method_table();\n+    while(iter.next()) {\n+      CompiledMethod* nm = iter.method();\n+      \/\/ Walk all alive nmethods to check for old Methods.\n+      \/\/ This includes methods whose inline caches point to old methods, so\n+      \/\/ inline cache clearing is unnecessary.\n+      if (nm->has_evol_metadata()) {\n+        deopt.enqueue(nm);\n+        add_to_old_table(nm);\n+      }\n+    }\n+    log_debug(redefine, class, nmethod)(\"Enqueued %d dependent nmethods for deopt\", deopt.enqueued());\n@@ -4113,1 +4174,1 @@\n-\n+  deopt.deoptimize();\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":77,"deletions":16,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -538,0 +538,3 @@\n+  static void old_nmethods_do(MetadataClosure* f);\n+  static void unregister_old_nmethod(CompiledMethod* c);\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1074,2 +1074,1 @@\n-\n-  int marked = 0;\n+  DeoptimizationContext deopt;\n@@ -1078,1 +1077,0 @@\n-    NoSafepointVerifier nsv;\n@@ -1080,1 +1078,0 @@\n-\n@@ -1083,5 +1080,1 @@\n-    marked = deps.mark_dependent_nmethods(changes);\n-  }\n-  if (marked > 0) {\n-    \/\/ At least one nmethod has been marked for deoptimization.\n-    Deoptimization::deoptimize_all_marked();\n+    deps.enqueue_deoptimization_dependent_nmethods(changes, &deopt);\n@@ -1089,0 +1082,1 @@\n+  deopt.deoptimize();\n@@ -1489,0 +1483,3 @@\n+  \/\/ Walk all nmethods depending on this call site.\n+  MutexLocker mu1(thread, Compile_lock);\n+  DeoptimizationContext deopt;\n@@ -1490,14 +1487,3 @@\n-    \/\/ Walk all nmethods depending on this call site.\n-    MutexLocker mu1(thread, Compile_lock);\n-\n-    int marked = 0;\n-    {\n-      NoSafepointVerifier nsv;\n-      MutexLocker mu2(THREAD, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-      DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context());\n-      marked = deps.remove_all_dependents();\n-    }\n-    if (marked > 0) {\n-      \/\/ At least one nmethod has been marked for deoptimization\n-      Deoptimization::deoptimize_all_marked();\n-    }\n+    MutexLocker mu2(thread, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context());\n+    deps.remove_and_enqueue_deoptimization_all_dependents(&deopt);\n@@ -1505,0 +1491,2 @@\n+\n+  deopt.deoptimize();\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":11,"deletions":23,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -780,2 +780,2 @@\n-  CodeCache::mark_all_nmethods_for_deoptimization();\n-  Deoptimization::deoptimize_all_marked();\n+  MutexLocker ml(Compile_lock);\n+  Deoptimization::deoptimize_all_whitebox();\n@@ -786,2 +786,1 @@\n-  int result = 0;\n-  CHECK_JNI_EXCEPTION_(env, result);\n+  CHECK_JNI_EXCEPTION_(env, 0);\n@@ -789,0 +788,1 @@\n+  DeoptimizationContext deopt;\n@@ -791,1 +791,1 @@\n-    result += mh->mark_osr_nmethods();\n+    mh->enqueue_deoptimization_osr_nmethods(&deopt);\n@@ -793,2 +793,1 @@\n-    mh->code()->mark_for_deoptimization();\n-    ++result;\n+    deopt.enqueue(mh->code());\n@@ -796,5 +795,3 @@\n-  result += CodeCache::mark_for_deoptimization(mh());\n-  if (result > 0) {\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-  return result;\n+  Deoptimization::enqueue_dependents(mh(), &deopt);\n+  deopt.deoptimize();\n+  return (jint)deopt.enqueued();\n@@ -812,1 +809,1 @@\n-  return (code->is_alive() && !code->is_marked_for_deoptimization());\n+  return (code->is_alive() && !code->has_been_enqueued_for_deoptimization());\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":10,"deletions":13,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2112,1 +2112,1 @@\n-              || (_cont.is_preempted() && f.cb()->as_compiled_method()->is_marked_for_deoptimization())) {\n+              || (_cont.is_preempted() && f.cb()->as_compiled_method()->has_been_enqueued_for_deoptimization())) {\n@@ -2360,1 +2360,1 @@\n-    if (fst.current()->cb()->is_compiled() && fst.current()->cb()->as_compiled_method()->is_marked_for_deoptimization()) {\n+    if (fst.current()->cb()->is_compiled() && fst.current()->cb()->as_compiled_method()->has_been_enqueued_for_deoptimization()) {\n","filename":"src\/hotspot\/share\/runtime\/continuationFreezeThaw.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"code\/dependencies.hpp\"\n@@ -100,2 +101,0 @@\n-bool DeoptimizationMarker::_is_active = false;\n-\n@@ -923,1 +922,1 @@\n-class DeoptimizeMarkedClosure : public HandshakeClosure {\n+class DeoptimizeEnqueueMethodFramesClosure : public HandshakeClosure {\n@@ -925,1 +924,1 @@\n-  DeoptimizeMarkedClosure() : HandshakeClosure(\"Deoptimize\") {}\n+  DeoptimizeEnqueueMethodFramesClosure() : HandshakeClosure(\"Deoptimize\") {}\n@@ -928,1 +927,1 @@\n-    jt->deoptimize_marked_methods();\n+    jt->deoptimize_enqueued_method_frames();\n@@ -932,3 +931,35 @@\n-void Deoptimization::deoptimize_all_marked(nmethod* nmethod_only) {\n-  ResourceMark rm;\n-  DeoptimizationMarker dm;\n+void Deoptimization::deoptimize_all_whitebox() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  DeoptimizationContext deopt;\n+  {\n+    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n+    while(iter.next()) {\n+      CompiledMethod* nm = iter.method();\n+      if (!nm->is_native_method()) {\n+        deopt.enqueue(nm);\n+      }\n+    }\n+  }\n+  deopt.deoptimize();\n+}\n+\n+\/\/ Keeps track of time spent for checking dependencies\n+NOT_PRODUCT(static elapsedTimer dependentCheckTime;)\n+#ifndef PRODUCT\n+  void Deoptimization::print_dependency_checking_time(outputStream* stream) {\n+    stream->print_cr(\"nmethod dependency checking time %fs\", dependentCheckTime.seconds());\n+  }\n+#endif\n+\n+void Deoptimization::deoptimize(KlassDepChange& changes) {\n+  DeoptimizationContext deopt;\n+  {\n+    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    \/\/ nmethod::check_all_dependencies works only correctly, if no safepoint\n+    \/\/ can happen\n+    NoSafepointVerifier nsv;\n+    for (DepChange::ContextStream str(changes, nsv); str.next(); ) {\n+      Klass* d = str.klass();\n+      InstanceKlass::cast(d)->enqueue_deoptimization_dependent_nmethods(changes, &deopt);\n+    }\n@@ -936,5 +967,24 @@\n-  \/\/ Make the dependent methods not entrant\n-  if (nmethod_only != NULL) {\n-    nmethod_only->mark_for_deoptimization();\n-    nmethod_only->make_not_entrant();\n-    CodeCache::make_nmethod_deoptimized(nmethod_only);\n+#ifndef PRODUCT\n+    if (VerifyDependencies) {\n+      \/\/ Object pointers are used as unique identifiers for dependency arguments. This\n+      \/\/ is only possible if no safepoint, i.e., GC occurs during the verification code.\n+      dependentCheckTime.start();\n+      nmethod::check_all_dependencies(changes);\n+      dependentCheckTime.stop();\n+    }\n+#endif\n+  }\n+  deopt.deoptimize();\n+}\n+\n+\n+\/\/ Flushes compiled methods dependent on dependee.\n+void Deoptimization::deoptimize_dependents(InstanceKlass* dependee) {\n+  assert_lock_strong(Compile_lock);\n+\n+  if (CodeCache::number_of_nmethods_with_dependencies() == 0) return;\n+\n+  if (dependee->is_linked()) {\n+    \/\/ Class initialization state change.\n+    KlassInitDepChange changes(dependee);\n+    deoptimize(changes);\n@@ -942,1 +992,32 @@\n-    CodeCache::make_marked_nmethods_deoptimized();\n+    \/\/ New class is loaded.\n+    NewKlassDepChange changes(dependee);\n+    deoptimize(changes);\n+  }\n+}\n+\n+volatile bool DeoptimizationContext::_context_active = false;\n+\n+DeoptimizationContext::DeoptimizationContext()\n+  : _nsv(),\n+    _enqueued(0),\n+    _deoptimized(false) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  assert(!Atomic::load(&_context_active), \"Cannot create a DeoptimizationContext while another one is active\");\n+  Atomic::store(&_context_active, true);\n+}\n+\n+DeoptimizationContext::~DeoptimizationContext() {\n+  assert(_enqueued == 0 || _deoptimized, \"If something got enqueued, you have to call deoptimize\");\n+}\n+\n+void DeoptimizationContext::enqueue(CompiledMethod* cm) {\n+  assert(!_deoptimized, \"Calling enqueue after deoptimize is invalid\");\n+  if (cm->enqueue_deoptimization(true \/* inc_recompile_counts *\/)) {\n+    ++_enqueued;\n+  }\n+}\n+\n+void DeoptimizationContext::enqueue_no_recompile_count_update(CompiledMethod* cm) {\n+  assert(!_deoptimized, \"Calling enqueue_no_recompile_count_update after deoptimize is invalid\");\n+  if (cm->enqueue_deoptimization(false \/* inc_recompile_counts *\/)) {\n+    ++_enqueued;\n@@ -944,0 +1025,1 @@\n+}\n@@ -945,1 +1027,27 @@\n-  DeoptimizeMarkedClosure deopt;\n+void DeoptimizationContext::deopt_compiled_methods() {\n+  SweeperBlockingCompiledMethodIterator iter(SweeperBlockingCompiledMethodIterator::only_alive_and_not_unloading);\n+  while(iter.next()) {\n+    CompiledMethod* nm = iter.method();\n+    if (nm->has_been_enqueued_for_deoptimization() && !nm->has_been_deoptimized() && nm->can_be_deoptimized()) {\n+      nm->make_not_entrant();\n+      nm->make_deoptimized();\n+    }\n+  }\n+}\n+\n+void DeoptimizationContext::deopt_frames() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  \/\/ DeoptimizationContext is considered active from its creation until\n+  \/\/ deopt_compiled_methods() finishes processing enqueued nmethods.\n+  \/\/ deopt_compiled_methods() occurs as the first step of deoptimize()\n+  assert(Atomic::load(&_context_active), \"deoptimize() must be called on an active context\");\n+  Atomic::store(&_context_active, false);\n+\n+  if (_enqueued == 0) {\n+    return; \/\/ Nothing to do\n+  }\n+\n+  \/\/ DeoptimizationContext sets up a NSV to detect bugs in the client of this API.\n+  \/\/ But we must allow safepoints when performing thread-local handshakes\n+  PauseNoSafepointVerifier pnsv(&_nsv);\n+  DeoptimizeEnqueueMethodFramesClosure deopt;\n@@ -953,0 +1061,34 @@\n+void DeoptimizationContext::deoptimize() {\n+  deopt_compiled_methods();\n+  deopt_frames();\n+}\n+\n+void Deoptimization::deoptimize_dependents(const methodHandle& m_h) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  Deoptimization::deoptimize_dependents(m_h());\n+}\n+\n+void Deoptimization::enqueue_dependents(Method* dependee, DeoptimizationContext* deopt) {\n+  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n+  while(iter.next()) {\n+    CompiledMethod* nm = iter.method();\n+    if (nm->is_dependent_on_method(dependee)) {\n+      deopt->enqueue(nm);\n+    }\n+  }\n+}\n+\n+void Deoptimization::deoptimize_dependents(Method* dependee) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  DeoptimizationContext deopt;\n+  enqueue_dependents(dependee, &deopt);\n+  deopt.deoptimize();\n+}\n+\n+void Deoptimization::deoptimize_nmethod(nmethod* nmethod) {\n+  DeoptimizationContext deopt;\n+  deopt.enqueue(nmethod);\n+  deopt.deoptimize();\n+}\n+\n@@ -1656,1 +1798,0 @@\n-  DeoptimizationMarker dm;\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":157,"deletions":16,"binary":false,"changes":173,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/safepointVerifiers.hpp\"\n@@ -32,0 +33,1 @@\n+class DeoptimizationContext;\n@@ -40,0 +42,1 @@\n+class KlassDepChange;\n@@ -151,5 +154,15 @@\n-  \/\/ Make all nmethods that are marked_for_deoptimization not_entrant and deoptimize any live\n-  \/\/ activations using those nmethods.  If an nmethod is passed as an argument then it is\n-  \/\/ marked_for_deoptimization and made not_entrant.  Otherwise a scan of the code cache is done to\n-  \/\/ find all marked nmethods and they are made not_entrant.\n-  static void deoptimize_all_marked(nmethod* nmethod_only = NULL);\n+private:\n+  static void deoptimize(KlassDepChange& changes);\n+\n+public:\n+  static void deoptimize_nmethod(nmethod* nmethod);\n+  static void deoptimize_dependents(const methodHandle& dependee);\n+  static void deoptimize_dependents(Method* dependee);\n+  static void deoptimize_dependents(InstanceKlass* dependee);\n+  static void enqueue_dependents(Method* dependee, DeoptimizationContext* deopt);\n+  \/\/ Only called from whitebox API.\n+  static void deoptimize_all_whitebox();\n+\n+#ifndef PRODUCT\n+  static void print_dependency_checking_time(outputStream* stream);\n+#endif\n@@ -476,0 +489,8 @@\n+class DeoptimizationContext : StackObj {\n+  NoSafepointVerifier _nsv;\n+  uint _enqueued;\n+  bool _deoptimized;\n+  static volatile bool _context_active;\n+\n+  void deopt_compiled_methods();\n+  void deopt_frames();\n@@ -477,2 +498,0 @@\n-class DeoptimizationMarker : StackObj {  \/\/ for profiling\n-  static bool _is_active;\n@@ -480,3 +499,8 @@\n-  DeoptimizationMarker()  { _is_active = true; }\n-  ~DeoptimizationMarker() { _is_active = false; }\n-  static bool is_active() { return _is_active; }\n+  DeoptimizationContext();\n+  ~DeoptimizationContext();\n+\n+  void enqueue(CompiledMethod* cm);\n+  void enqueue_no_recompile_count_update(CompiledMethod* cm);\n+  void deoptimize();\n+\n+  uint enqueued() { return _enqueued; }\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":34,"deletions":10,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -325,1 +325,1 @@\n-    tty->print(\"checking (%s) \", nm->is_marked_for_deoptimization() ? \"true\" : \"false\");\n+    tty->print(\"checking (%s) \", nm->has_been_enqueued_for_deoptimization() ? \"true\" : \"false\");\n@@ -330,1 +330,1 @@\n-  if( !nm->is_marked_for_deoptimization() )\n+  if( !nm->has_been_enqueued_for_deoptimization() )\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1321,1 +1321,1 @@\n-void JavaThread::deoptimize_marked_methods() {\n+void JavaThread::deoptimize_enqueued_method_frames() {\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -962,1 +962,1 @@\n-  void deoptimize_marked_methods();\n+  void deoptimize_enqueued_method_frames();\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -144,3 +144,0 @@\n-  \/\/ Deoptimizes all frames tied to marked nmethods\n-  static void deoptimized_wrt_marked_nmethods();\n-\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -120,1 +120,0 @@\n-  DeoptimizationMarker dm;\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}