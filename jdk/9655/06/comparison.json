{"files":[{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2013, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2013, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -38,0 +38,3 @@\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiRedefineClasses.hpp\"\n+#endif\n@@ -70,1 +73,3 @@\n-      CodeCache::old_nmethods_do(&md_on_stack);\n+#if INCLUDE_JVMTI\n+      VM_RedefineClasses::old_nmethods_do(&md_on_stack);\n+#endif\n","filename":"src\/hotspot\/share\/classfile\/metadataOnStackMark.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -73,0 +73,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -1652,1 +1653,1 @@\n-    CodeCache::flush_dependents_on(k);\n+    Deoptimization::deoptimize_dependents(k);\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -31,1 +31,0 @@\n-#include \"code\/dependencies.hpp\"\n@@ -1073,32 +1072,0 @@\n-\/\/ Keeps track of time spent for checking dependencies\n-NOT_PRODUCT(static elapsedTimer dependentCheckTime;)\n-\n-int CodeCache::mark_for_deoptimization(KlassDepChange& changes) {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  int number_of_marked_CodeBlobs = 0;\n-\n-  \/\/ search the hierarchy looking for nmethods which are affected by the loading of this class\n-\n-  \/\/ then search the interfaces this class implements looking for nmethods\n-  \/\/ which might be dependent of the fact that an interface only had one\n-  \/\/ implementor.\n-  \/\/ nmethod::check_all_dependencies works only correctly, if no safepoint\n-  \/\/ can happen\n-  NoSafepointVerifier nsv;\n-  for (DepChange::ContextStream str(changes, nsv); str.next(); ) {\n-    Klass* d = str.klass();\n-    number_of_marked_CodeBlobs += InstanceKlass::cast(d)->mark_dependent_nmethods(changes);\n-  }\n-\n-#ifndef PRODUCT\n-  if (VerifyDependencies) {\n-    \/\/ Object pointers are used as unique identifiers for dependency arguments. This\n-    \/\/ is only possible if no safepoint, i.e., GC occurs during the verification code.\n-    dependentCheckTime.start();\n-    nmethod::check_all_dependencies(changes);\n-    dependentCheckTime.stop();\n-  }\n-#endif\n-\n-  return number_of_marked_CodeBlobs;\n-}\n@@ -1112,183 +1079,0 @@\n-#if INCLUDE_JVMTI\n-\/\/ RedefineClasses support for saving nmethods that are dependent on \"old\" methods.\n-\/\/ We don't really expect this table to grow very large.  If it does, it can become a hashtable.\n-static GrowableArray<CompiledMethod*>* old_compiled_method_table = NULL;\n-\n-static void add_to_old_table(CompiledMethod* c) {\n-  if (old_compiled_method_table == NULL) {\n-    old_compiled_method_table = new (ResourceObj::C_HEAP, mtCode) GrowableArray<CompiledMethod*>(100, mtCode);\n-  }\n-  old_compiled_method_table->push(c);\n-}\n-\n-static void reset_old_method_table() {\n-  if (old_compiled_method_table != NULL) {\n-    delete old_compiled_method_table;\n-    old_compiled_method_table = NULL;\n-  }\n-}\n-\n-\/\/ Remove this method when zombied or unloaded.\n-void CodeCache::unregister_old_nmethod(CompiledMethod* c) {\n-  assert_lock_strong(CodeCache_lock);\n-  if (old_compiled_method_table != NULL) {\n-    int index = old_compiled_method_table->find(c);\n-    if (index != -1) {\n-      old_compiled_method_table->delete_at(index);\n-    }\n-  }\n-}\n-\n-void CodeCache::old_nmethods_do(MetadataClosure* f) {\n-  \/\/ Walk old method table and mark those on stack.\n-  int length = 0;\n-  if (old_compiled_method_table != NULL) {\n-    length = old_compiled_method_table->length();\n-    for (int i = 0; i < length; i++) {\n-      CompiledMethod* cm = old_compiled_method_table->at(i);\n-      \/\/ Only walk alive nmethods, the dead ones will get removed by the sweeper or GC.\n-      if (cm->is_alive() && !cm->is_unloading()) {\n-        old_compiled_method_table->at(i)->metadata_do(f);\n-      }\n-    }\n-  }\n-  log_debug(redefine, class, nmethod)(\"Walked %d nmethods for mark_on_stack\", length);\n-}\n-\n-\/\/ Walk compiled methods and mark dependent methods for deoptimization.\n-int CodeCache::mark_dependents_for_evol_deoptimization() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-  \/\/ Each redefinition creates a new set of nmethods that have references to \"old\" Methods\n-  \/\/ So delete old method table and create a new one.\n-  reset_old_method_table();\n-\n-  int number_of_marked_CodeBlobs = 0;\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    \/\/ Walk all alive nmethods to check for old Methods.\n-    \/\/ This includes methods whose inline caches point to old methods, so\n-    \/\/ inline cache clearing is unnecessary.\n-    if (nm->has_evol_metadata()) {\n-      nm->mark_for_deoptimization();\n-      add_to_old_table(nm);\n-      number_of_marked_CodeBlobs++;\n-    }\n-  }\n-\n-  \/\/ return total count of nmethods marked for deoptimization, if zero the caller\n-  \/\/ can skip deoptimization\n-  return number_of_marked_CodeBlobs;\n-}\n-\n-void CodeCache::mark_all_nmethods_for_evol_deoptimization() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (!nm->method()->is_method_handle_intrinsic()) {\n-      if (nm->can_be_deoptimized()) {\n-        nm->mark_for_deoptimization();\n-      }\n-      if (nm->has_evol_metadata()) {\n-        add_to_old_table(nm);\n-      }\n-    }\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on redefined classes, that have already been\n-\/\/ marked for deoptimization.\n-void CodeCache::flush_evol_dependents() {\n-  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n-\n-  \/\/ CodeCache can only be updated by a thread_in_VM and they will all be\n-  \/\/ stopped during the safepoint so CodeCache will be safe to update without\n-  \/\/ holding the CodeCache_lock.\n-\n-  \/\/ At least one nmethod has been marked for deoptimization\n-\n-  Deoptimization::deoptimize_all_marked();\n-}\n-#endif \/\/ INCLUDE_JVMTI\n-\n-\/\/ Mark methods for deopt (if safe or possible).\n-void CodeCache::mark_all_nmethods_for_deoptimization() {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (!nm->is_native_method()) {\n-      nm->mark_for_deoptimization();\n-    }\n-  }\n-}\n-\n-int CodeCache::mark_for_deoptimization(Method* dependee) {\n-  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-  int number_of_marked_CodeBlobs = 0;\n-\n-  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (nm->is_dependent_on_method(dependee)) {\n-      ResourceMark rm;\n-      nm->mark_for_deoptimization();\n-      number_of_marked_CodeBlobs++;\n-    }\n-  }\n-\n-  return number_of_marked_CodeBlobs;\n-}\n-\n-void CodeCache::make_marked_nmethods_deoptimized() {\n-  SweeperBlockingCompiledMethodIterator iter(SweeperBlockingCompiledMethodIterator::only_alive_and_not_unloading);\n-  while(iter.next()) {\n-    CompiledMethod* nm = iter.method();\n-    if (nm->is_marked_for_deoptimization() && !nm->has_been_deoptimized() && nm->can_be_deoptimized()) {\n-      nm->make_not_entrant();\n-      make_nmethod_deoptimized(nm);\n-    }\n-  }\n-}\n-\n-void CodeCache::make_nmethod_deoptimized(CompiledMethod* nm) {\n-  if (nm->is_marked_for_deoptimization() && nm->can_be_deoptimized()) {\n-    nm->make_deoptimized();\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on dependee.\n-void CodeCache::flush_dependents_on(InstanceKlass* dependee) {\n-  assert_lock_strong(Compile_lock);\n-\n-  if (number_of_nmethods_with_dependencies() == 0) return;\n-\n-  int marked = 0;\n-  if (dependee->is_linked()) {\n-    \/\/ Class initialization state change.\n-    KlassInitDepChange changes(dependee);\n-    marked = mark_for_deoptimization(changes);\n-  } else {\n-    \/\/ New class is loaded.\n-    NewKlassDepChange changes(dependee);\n-    marked = mark_for_deoptimization(changes);\n-  }\n-\n-  if (marked > 0) {\n-    \/\/ At least one nmethod has been marked for deoptimization\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-}\n-\n-\/\/ Flushes compiled methods dependent on dependee\n-void CodeCache::flush_dependents_on_method(const methodHandle& m_h) {\n-  \/\/ --- Compile_lock is not held. However we are at a safepoint.\n-  assert_locked_or_safepoint(Compile_lock);\n-\n-  \/\/ Compute the dependent nmethods\n-  if (mark_for_deoptimization(m_h()) > 0) {\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-}\n-\n@@ -1555,1 +1339,1 @@\n-  tty->print_cr(\"nmethod dependency checking time %fs\", dependentCheckTime.seconds());\n+  Deoptimization::print_dependency_checking_time(tty);\n","filename":"src\/hotspot\/share\/code\/codeCache.cpp","additions":1,"deletions":217,"binary":false,"changes":218,"status":"modified"},{"patch":"@@ -76,1 +76,0 @@\n-class KlassDepChange;\n@@ -124,0 +123,1 @@\n+    friend class SweeperBlocker;\n@@ -285,4 +285,0 @@\n-  \/\/ Deoptimization\n- private:\n-  static int  mark_for_deoptimization(KlassDepChange& changes);\n-\n@@ -290,19 +286,0 @@\n-  static void mark_all_nmethods_for_deoptimization();\n-  static int  mark_for_deoptimization(Method* dependee);\n-  static void make_marked_nmethods_deoptimized();\n-  static void make_nmethod_deoptimized(CompiledMethod* nm);\n-\n-  \/\/ Flushing and deoptimization\n-  static void flush_dependents_on(InstanceKlass* dependee);\n-\n-  \/\/ RedefineClasses support\n-  \/\/ Flushing and deoptimization in case of evolution\n-  static int  mark_dependents_for_evol_deoptimization();\n-  static void mark_all_nmethods_for_evol_deoptimization();\n-  static void flush_evol_dependents();\n-  static void old_nmethods_do(MetadataClosure* f) NOT_JVMTI_RETURN;\n-  static void unregister_old_nmethod(CompiledMethod* c) NOT_JVMTI_RETURN;\n-\n-  \/\/ Support for fullspeed debugging\n-  static void flush_dependents_on_method(const methodHandle& dependee);\n-\n@@ -329,0 +306,9 @@\n+class SweeperBlocker : public StackObj {\n+  public:\n+    SweeperBlocker() {\n+      CodeCache::Sweep::begin_compiled_method_iteration();\n+    }\n+    ~SweeperBlocker() {\n+      CodeCache::Sweep::end_compiled_method_iteration();\n+    }\n+};\n","filename":"src\/hotspot\/share\/code\/codeCache.hpp","additions":10,"deletions":24,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -53,0 +53,2 @@\n+CompiledMethod* CompiledMethod::_enqueued_deoptimization_root_method = nullptr;\n+\n@@ -57,1 +59,1 @@\n-    _mark_for_deoptimization_status(not_marked),\n+    _enqueued_deoptimization_link(nullptr),\n@@ -69,1 +71,1 @@\n-    _mark_for_deoptimization_status(not_marked),\n+    _enqueued_deoptimization_link(nullptr),\n@@ -120,6 +122,15 @@\n-void CompiledMethod::mark_for_deoptimization(bool inc_recompile_counts) {\n-  \/\/ assert(can_be_deoptimized(), \"\"); \/\/ in some places we check before marking, in others not.\n-  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? NULL : CompiledMethod_lock,\n-                 Mutex::_no_safepoint_check_flag);\n-  if (_mark_for_deoptimization_status != deoptimize_done) { \/\/ can't go backwards\n-     _mark_for_deoptimization_status = (inc_recompile_counts ? deoptimize : deoptimize_noupdate);\n+bool CompiledMethod::enqueue_deoptimization(bool inc_recompile_counts) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  assert(DeoptimizationContext::is_context_active(), \"should only be called in an active DeoptimizationContext\");\n+  DeoptimizationStatus old_status = extract_enqueued_deoptimization_status(_enqueued_deoptimization_link);\n+  DeoptimizationStatus new_status = (inc_recompile_counts ? enqueued : enqueued_noupdate);\n+  if (old_status < new_status) {\n+    if (old_status == not_enqueued) {\n+      assert(extract_enqueued_deoptimization_method(_enqueued_deoptimization_link) == nullptr, \"Compiled Method should not already be linked\");\n+      _enqueued_deoptimization_link = make_enqueued_deoptimization_link(_enqueued_deoptimization_root_method, new_status);\n+      _enqueued_deoptimization_root_method = this;\n+      return true;\n+    } else {\n+      _enqueued_deoptimization_link = make_enqueued_deoptimization_link(\n+        extract_enqueued_deoptimization_method(_enqueued_deoptimization_link), new_status);\n+    }\n@@ -127,0 +138,22 @@\n+  return false;\n+}\n+\n+CompiledMethod* CompiledMethod::next_enqueued_deoptimization_method() const {\n+  assert_locked_or_safepoint(Compile_lock);\n+  assert(DeoptimizationContext::is_context_active(), \"should only be called in an active DeoptimizationContext\");\n+  return extract_enqueued_deoptimization_method(_enqueued_deoptimization_link);\n+}\n+\n+CompiledMethod* CompiledMethod::take_enqueued_deoptimization_root_method() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  assert(DeoptimizationContext::is_context_active(), \"should only be called in an active DeoptimizationContext\");\n+  CompiledMethod* root = _enqueued_deoptimization_root_method;\n+  _enqueued_deoptimization_root_method = nullptr;\n+  return root;\n+}\n+\n+void  CompiledMethod::make_deoptimized_done() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  assert(DeoptimizationContext::is_context_active(), \"should only be called in an active DeoptimizationContext\");\n+  _enqueued_deoptimization_link = make_enqueued_deoptimization_link(\n+    extract_enqueued_deoptimization_method(_enqueued_deoptimization_link), post_make_deoptimized);\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":41,"deletions":8,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -144,0 +144,1 @@\n+  friend class DeoptimizationContext;\n@@ -147,5 +148,5 @@\n-  enum MarkForDeoptimizationStatus : u1 {\n-    not_marked,\n-    deoptimize,\n-    deoptimize_noupdate,\n-    deoptimize_done\n+  enum DeoptimizationStatus : u1 {\n+    not_enqueued,\n+    enqueued,\n+    enqueued_noupdate,\n+    post_make_deoptimized\n@@ -154,1 +155,1 @@\n-  MarkForDeoptimizationStatus _mark_for_deoptimization_status; \/\/ Used for stack deoptimization\n+  struct EnqueuedDemoptimizationLink;\n@@ -156,0 +157,14 @@\n+  static CompiledMethod* _enqueued_deoptimization_root_method;\n+  EnqueuedDemoptimizationLink* _enqueued_deoptimization_link;\n+\n+  static EnqueuedDemoptimizationLink* make_enqueued_deoptimization_link(CompiledMethod* cm, DeoptimizationStatus status) {\n+    assert(((uintptr_t)cm & 0x3) == 0, \"cm pointer must have zero lower two LSB\");\n+    return (EnqueuedDemoptimizationLink*)(((uintptr_t)cm & ~0x3) | static_cast<u1>(status));\n+  }\n+\n+  static DeoptimizationStatus extract_enqueued_deoptimization_status(EnqueuedDemoptimizationLink* link) {\n+    return static_cast<DeoptimizationStatus>((uintptr_t)link & 0x3);\n+  }\n+  static CompiledMethod* extract_enqueued_deoptimization_method(EnqueuedDemoptimizationLink* link) {\n+    return (CompiledMethod*)((uintptr_t)link & ~0x3);\n+  }\n@@ -245,2 +260,3 @@\n-  bool  is_marked_for_deoptimization() const { return _mark_for_deoptimization_status != not_marked; }\n-  void  mark_for_deoptimization(bool inc_recompile_counts = true);\n+  bool  has_enqueued_deoptimization() const {\n+    return extract_enqueued_deoptimization_status(_enqueued_deoptimization_link) != not_enqueued;\n+  }\n@@ -248,2 +264,11 @@\n-  bool  has_been_deoptimized() const { return _mark_for_deoptimization_status == deoptimize_done; }\n-  void  mark_deoptimized() { _mark_for_deoptimization_status = deoptimize_done; }\n+  bool  is_post_make_deoptimized() const {\n+    return extract_enqueued_deoptimization_status(_enqueued_deoptimization_link) == post_make_deoptimized;\n+  }\n+\n+private:\n+  bool  enqueue_deoptimization(bool inc_recompile_counts = true);\n+  CompiledMethod* next_enqueued_deoptimization_method() const;\n+  static CompiledMethod* take_enqueued_deoptimization_root_method();\n+protected:\n+  void  make_deoptimized_done();\n+public:\n@@ -254,5 +279,4 @@\n-    \/\/ Update recompile counts when either the update is explicitly requested (deoptimize)\n-    \/\/ or the nmethod is not marked for deoptimization at all (not_marked).\n-    \/\/ The latter happens during uncommon traps when deoptimized nmethod is made not entrant.\n-    return _mark_for_deoptimization_status != deoptimize_noupdate &&\n-           _mark_for_deoptimization_status != deoptimize_done;\n+    \/\/ Update recompile counts unless explicitly told not too (enqueued_noupdate) or\n+    \/\/ make_deoptimized_done() has been called.\n+    DeoptimizationStatus deoptimization_status = extract_enqueued_deoptimization_status(_enqueued_deoptimization_link);\n+    return deoptimization_status != enqueued_noupdate && deoptimization_status != post_make_deoptimized;\n","filename":"src\/hotspot\/share\/code\/compiledMethod.hpp","additions":39,"deletions":15,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -35,0 +35,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -686,1 +687,1 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) = 0;\n+  virtual void enqueue_deoptimization(nmethod* nm, DeoptimizationContext* deopt) = 0;\n@@ -784,2 +785,2 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) {\n-    nm->mark_for_deoptimization(\/*inc_recompile_counts=*\/true);\n+  virtual void enqueue_deoptimization(nmethod* nm, DeoptimizationContext* deopt) {\n+    deopt->enqueue(nm);\n@@ -826,2 +827,2 @@\n-  virtual void mark_for_deoptimization(nmethod* nm) {\n-    nm->mark_for_deoptimization(\/*inc_recompile_counts=*\/false);\n+  virtual void enqueue_deoptimization(nmethod* nm, DeoptimizationContext* deopt) {\n+    deopt->enqueue_no_recompile_count_update(nm);\n","filename":"src\/hotspot\/share\/code\/dependencies.hpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -64,2 +65,2 @@\n-\/\/ are dependent on the changes that were passed in and mark them for\n-\/\/ deoptimization.  Returns the number of nmethods found.\n+\/\/ are dependent on the changes that were passed in and enqueue\n+\/\/ deoptimization for them.  Returns the number of nmethods found.\n@@ -67,2 +68,1 @@\n-int DependencyContext::mark_dependent_nmethods(DepChange& changes) {\n-  int found = 0;\n+void DependencyContext::enqueue_deoptimization_dependent_nmethods(DepChange& changes, DeoptimizationContext* deopt) {\n@@ -73,1 +73,1 @@\n-    if (b->count() > 0 && nm->is_alive() && !nm->is_marked_for_deoptimization() && nm->check_dependency_on(changes)) {\n+    if (b->count() > 0 && nm->is_alive() && !nm->has_enqueued_deoptimization() && nm->check_dependency_on(changes)) {\n@@ -76,1 +76,1 @@\n-        tty->print_cr(\"Marked for deoptimization\");\n+        tty->print_cr(\"Enqueued deoptimization\");\n@@ -81,2 +81,1 @@\n-      changes.mark_for_deoptimization(nm);\n-      found++;\n+      changes.enqueue_deoptimization(nm, deopt);\n@@ -85,1 +84,0 @@\n-  return found;\n@@ -222,1 +220,1 @@\n-int DependencyContext::remove_and_mark_for_deoptimization_all_dependents() {\n+void DependencyContext::remove_and_enqueue_deoptimization_all_dependents(DeoptimizationContext* deopt) {\n@@ -225,1 +223,0 @@\n-  int marked = 0;\n@@ -228,3 +225,2 @@\n-    if (b->count() > 0 && nm->is_alive() && !nm->is_marked_for_deoptimization()) {\n-      nm->mark_for_deoptimization();\n-      marked++;\n+    if (b->count() > 0 && nm->is_alive() && !nm->has_enqueued_deoptimization()) {\n+      deopt->enqueue(nm);\n@@ -232,1 +228,3 @@\n-    b = release_and_get_next_not_unloading(b);\n+    nmethodBucket* next = b->next_not_unloading();\n+    release(b);\n+    b = next;\n@@ -234,1 +232,0 @@\n-  return marked;\n","filename":"src\/hotspot\/share\/code\/dependencyContext.cpp","additions":13,"deletions":16,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -120,1 +121,1 @@\n-  int  mark_dependent_nmethods(DepChange& changes);\n+  void enqueue_deoptimization_dependent_nmethods(DepChange& changes, DeoptimizationContext* deopt);\n@@ -124,1 +125,1 @@\n-  int  remove_and_mark_for_deoptimization_all_dependents();\n+  void remove_and_enqueue_deoptimization_all_dependents(DeoptimizationContext* deopt);\n","filename":"src\/hotspot\/share\/code\/dependencyContext.hpp","additions":4,"deletions":3,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -86,0 +86,3 @@\n+#if INCLUDE_JVMTI\n+#include \"prims\/jvmtiRedefineClasses.hpp\"\n+#endif\n@@ -1162,1 +1165,1 @@\n-  mark_deoptimized();\n+  make_deoptimized_done();\n@@ -1469,1 +1472,1 @@\n-      \/\/ It's a true state change, so mark the method as decompiled.\n+      \/\/ Increment the decompile count\n@@ -1618,1 +1621,3 @@\n-  CodeCache::unregister_old_nmethod(this);\n+#if INCLUDE_JVMTI\n+  VM_RedefineClasses::unregister_old_nmethod(this);\n+#endif\n@@ -2353,2 +2358,2 @@\n-  \/\/ Iterate over live nmethods and check dependencies of all nmethods that are not\n-  \/\/ marked for deoptimization. A particular dependency is only checked once.\n+  \/\/ Iterate over live nmethods and check dependencies of all nmethods that has not\n+  \/\/ been enqueue for deoptimization. A particular dependency is only checked once.\n@@ -2359,1 +2364,1 @@\n-    if (!nm->is_marked_for_deoptimization()) {\n+    if (!nm->has_enqueued_deoptimization()) {\n@@ -2375,1 +2380,1 @@\n-            assert(false, \"Should have been marked for deoptimization\");\n+            assert(false, \"Should have enqueued deoptimization\");\n@@ -2398,1 +2403,0 @@\n-\/\/ Called from mark_for_deoptimization, when dependee is invalidated.\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":12,"deletions":8,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -1539,1 +1539,1 @@\n-    Deoptimization::deoptimize_all_marked(nm);\n+    Deoptimization::deoptimize_nmethod(nm);\n","filename":"src\/hotspot\/share\/jvmci\/jvmciEnv.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1183,1 +1183,1 @@\n-    CodeCache::flush_dependents_on(this);\n+     Deoptimization::deoptimize_dependents(this);\n@@ -2336,2 +2336,2 @@\n-int InstanceKlass::mark_dependent_nmethods(KlassDepChange& changes) {\n-  return dependencies().mark_dependent_nmethods(changes);\n+void InstanceKlass::enqueue_deoptimization_dependent_nmethods(KlassDepChange& changes, DeoptimizationContext* deopt) {\n+  dependencies().enqueue_deoptimization_dependent_nmethods(changes, deopt);\n@@ -3320,1 +3320,1 @@\n-int InstanceKlass::mark_osr_nmethods(const Method* m) {\n+void InstanceKlass::enqueue_deoptimization_osr_nmethods(const Method* m, DeoptimizationContext* deopt) {\n@@ -3324,1 +3324,0 @@\n-  int found = 0;\n@@ -3328,2 +3327,1 @@\n-      osr->mark_for_deoptimization();\n-      found++;\n+      deopt->enqueue(osr);\n@@ -3333,1 +3331,0 @@\n-  return found;\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -940,1 +941,1 @@\n-  int  mark_dependent_nmethods(KlassDepChange& changes);\n+  void enqueue_deoptimization_dependent_nmethods(KlassDepChange& changes, DeoptimizationContext* deopt);\n@@ -950,1 +951,1 @@\n-  int mark_osr_nmethods(const Method* m);\n+  void enqueue_deoptimization_osr_nmethods(const Method* m, DeoptimizationContext* deopt);\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -2037,1 +2037,1 @@\n-    CodeCache::flush_dependents_on_method(mh);\n+    Deoptimization::deoptimize_dependents(mh);\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"runtime\/deoptimization.hpp\"\n@@ -915,2 +916,2 @@\n-  int mark_osr_nmethods() {\n-    return method_holder()->mark_osr_nmethods(this);\n+  void enqueue_deoptimization_osr_nmethods(DeoptimizationContext* deopt) {\n+    method_holder()->enqueue_deoptimization_osr_nmethods(this, deopt);\n","filename":"src\/hotspot\/share\/oops\/method.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -4078,0 +4078,45 @@\n+\/\/ RedefineClasses support for saving nmethods that are dependent on \"old\" methods.\n+\/\/ We don't really expect this table to grow very large.  If it does, it can become a hashtable.\n+static GrowableArray<CompiledMethod*>* old_compiled_method_table = NULL;\n+\n+static void add_to_old_table(CompiledMethod* c) {\n+  if (old_compiled_method_table == NULL) {\n+    old_compiled_method_table = new (ResourceObj::C_HEAP, mtCode) GrowableArray<CompiledMethod*>(100, mtCode);\n+  }\n+  old_compiled_method_table->push(c);\n+}\n+\n+static void reset_old_method_table() {\n+  if (old_compiled_method_table != NULL) {\n+    delete old_compiled_method_table;\n+    old_compiled_method_table = NULL;\n+  }\n+}\n+\n+\/\/ Remove this method when zombied or unloaded.\n+void VM_RedefineClasses::unregister_old_nmethod(CompiledMethod* c) {\n+  assert_lock_strong(CodeCache_lock);\n+  if (old_compiled_method_table != NULL) {\n+    int index = old_compiled_method_table->find(c);\n+    if (index != -1) {\n+      old_compiled_method_table->delete_at(index);\n+    }\n+  }\n+}\n+\n+void VM_RedefineClasses::old_nmethods_do(MetadataClosure* f) {\n+  \/\/ Walk old method table and mark those on stack.\n+  int length = 0;\n+  if (old_compiled_method_table != NULL) {\n+    length = old_compiled_method_table->length();\n+    for (int i = 0; i < length; i++) {\n+      CompiledMethod* cm = old_compiled_method_table->at(i);\n+      \/\/ Only walk alive nmethods, the dead ones will get removed by the sweeper or GC.\n+      if (cm->is_alive() && !cm->is_unloading()) {\n+        old_compiled_method_table->at(i)->metadata_do(f);\n+      }\n+    }\n+  }\n+  log_debug(redefine, class, nmethod)(\"Walked %d nmethods for mark_on_stack\", length);\n+}\n+\n@@ -4096,8 +4141,17 @@\n-\n-  bool deopt_needed;\n-\n-  \/\/ This is the first redefinition, mark all the nmethods for deoptimization\n-  if (!JvmtiExport::all_dependencies_are_recorded()) {\n-    log_debug(redefine, class, nmethod)(\"Marked all nmethods for deopt\");\n-    CodeCache::mark_all_nmethods_for_evol_deoptimization();\n-    deopt_needed = true;\n+  DeoptimizationContext deopt;\n+  const bool first_call = !JvmtiExport::all_dependencies_are_recorded();\n+  assert(SafepointSynchronize::is_at_safepoint(), \"Can only do this at a safepoint!\");\n+  CompiledMethodIterator iter(CompiledMethodIterator::only_alive);\n+  if (first_call) {\n+    while(iter.next()) {\n+      CompiledMethod* nm = iter.method();\n+      if (!nm->method()->is_method_handle_intrinsic()) {\n+        if (nm->can_be_deoptimized()) {\n+          deopt.enqueue(nm);\n+        }\n+        if (nm->has_evol_metadata()) {\n+          add_to_old_table(nm);\n+        }\n+      }\n+    }\n+    log_debug(redefine, class, nmethod)(\"Enqueued all nmethods for deopt\");\n@@ -4105,7 +4159,14 @@\n-    int deopt = CodeCache::mark_dependents_for_evol_deoptimization();\n-    log_debug(redefine, class, nmethod)(\"Marked %d dependent nmethods for deopt\", deopt);\n-    deopt_needed = (deopt != 0);\n-  }\n-\n-  if (deopt_needed) {\n-    CodeCache::flush_evol_dependents();\n+    \/\/ Each redefinition creates a new set of nmethods that have references to \"old\" Methods\n+    \/\/ So delete old method table and create a new one.\n+    reset_old_method_table();\n+    while(iter.next()) {\n+      CompiledMethod* nm = iter.method();\n+      \/\/ Walk all alive nmethods to check for old Methods.\n+      \/\/ This includes methods whose inline caches point to old methods, so\n+      \/\/ inline cache clearing is unnecessary.\n+      if (nm->has_evol_metadata()) {\n+        deopt.enqueue(nm);\n+        add_to_old_table(nm);\n+      }\n+    }\n+    log_debug(redefine, class, nmethod)(\"Enqueued %d dependent nmethods for deopt\", deopt.enqueued());\n@@ -4113,1 +4174,1 @@\n-\n+  deopt.deoptimize();\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.cpp","additions":77,"deletions":16,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2003, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2003, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -538,0 +538,3 @@\n+  static void old_nmethods_do(MetadataClosure* f);\n+  static void unregister_old_nmethod(CompiledMethod* c);\n+\n","filename":"src\/hotspot\/share\/prims\/jvmtiRedefineClasses.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1074,2 +1074,1 @@\n-\n-  int marked = 0;\n+  DeoptimizationContext deopt;\n@@ -1078,1 +1077,0 @@\n-    NoSafepointVerifier nsv;\n@@ -1080,1 +1078,0 @@\n-\n@@ -1083,5 +1080,1 @@\n-    marked = deps.mark_dependent_nmethods(changes);\n-  }\n-  if (marked > 0) {\n-    \/\/ At least one nmethod has been marked for deoptimization.\n-    Deoptimization::deoptimize_all_marked();\n+    deps.enqueue_deoptimization_dependent_nmethods(changes, &deopt);\n@@ -1089,0 +1082,1 @@\n+  deopt.deoptimize();\n@@ -1489,0 +1483,3 @@\n+  \/\/ Walk all nmethods depending on this call site.\n+  MutexLocker mu1(thread, Compile_lock);\n+  DeoptimizationContext deopt;\n@@ -1490,14 +1487,3 @@\n-    \/\/ Walk all nmethods depending on this call site.\n-    MutexLocker mu1(thread, Compile_lock);\n-\n-    int marked = 0;\n-    {\n-      NoSafepointVerifier nsv;\n-      MutexLocker mu2(THREAD, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n-      DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context());\n-      marked = deps.remove_and_mark_for_deoptimization_all_dependents();\n-    }\n-    if (marked > 0) {\n-      \/\/ At least one nmethod has been marked for deoptimization\n-      Deoptimization::deoptimize_all_marked();\n-    }\n+    MutexLocker mu2(thread, CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    DependencyContext deps = java_lang_invoke_MethodHandleNatives_CallSiteContext::vmdependencies(context());\n+    deps.remove_and_enqueue_deoptimization_all_dependents(&deopt);\n@@ -1505,0 +1491,2 @@\n+\n+  deopt.deoptimize();\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":11,"deletions":23,"binary":false,"changes":34,"status":"modified"},{"patch":"@@ -780,2 +780,2 @@\n-  CodeCache::mark_all_nmethods_for_deoptimization();\n-  Deoptimization::deoptimize_all_marked();\n+  MutexLocker ml(Compile_lock);\n+  Deoptimization::deoptimize_all_whitebox();\n@@ -786,2 +786,1 @@\n-  int result = 0;\n-  CHECK_JNI_EXCEPTION_(env, result);\n+  CHECK_JNI_EXCEPTION_(env, 0);\n@@ -789,0 +788,1 @@\n+  DeoptimizationContext deopt;\n@@ -791,1 +791,1 @@\n-    result += mh->mark_osr_nmethods();\n+    mh->enqueue_deoptimization_osr_nmethods(&deopt);\n@@ -793,2 +793,1 @@\n-    mh->code()->mark_for_deoptimization();\n-    ++result;\n+    deopt.enqueue(mh->code());\n@@ -796,5 +795,3 @@\n-  result += CodeCache::mark_for_deoptimization(mh());\n-  if (result > 0) {\n-    Deoptimization::deoptimize_all_marked();\n-  }\n-  return result;\n+  Deoptimization::enqueue_dependents(mh(), &deopt);\n+  deopt.deoptimize();\n+  return (jint)deopt.enqueued();\n@@ -812,1 +809,1 @@\n-  return (code->is_alive() && !code->is_marked_for_deoptimization());\n+  return (code->is_alive() && !code->has_enqueued_deoptimization());\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":10,"deletions":13,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -2113,1 +2113,1 @@\n-              || (_cont.is_preempted() && f.cb()->as_compiled_method()->is_marked_for_deoptimization())) {\n+              || (_cont.is_preempted() && f.cb()->as_compiled_method()->has_enqueued_deoptimization())) {\n@@ -2361,1 +2361,1 @@\n-    if (fst.current()->cb()->is_compiled() && fst.current()->cb()->as_compiled_method()->is_marked_for_deoptimization()) {\n+    if (fst.current()->cb()->is_compiled() && fst.current()->cb()->as_compiled_method()->has_enqueued_deoptimization()) {\n","filename":"src\/hotspot\/share\/runtime\/continuationFreezeThaw.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"code\/dependencies.hpp\"\n@@ -100,2 +101,0 @@\n-bool DeoptimizationMarker::_is_active = false;\n-\n@@ -923,1 +922,1 @@\n-class DeoptimizeMarkedClosure : public HandshakeClosure {\n+class DeoptimizeEnqueueMethodFramesClosure : public HandshakeClosure {\n@@ -925,1 +924,1 @@\n-  DeoptimizeMarkedClosure() : HandshakeClosure(\"Deoptimize\") {}\n+  DeoptimizeEnqueueMethodFramesClosure() : HandshakeClosure(\"Deoptimize\") {}\n@@ -928,1 +927,1 @@\n-    jt->deoptimize_marked_methods();\n+    jt->deoptimize_enqueued_method_frames();\n@@ -932,3 +931,35 @@\n-void Deoptimization::deoptimize_all_marked(nmethod* nmethod_only) {\n-  ResourceMark rm;\n-  DeoptimizationMarker dm;\n+void Deoptimization::deoptimize_all_whitebox() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  DeoptimizationContext deopt;\n+  {\n+    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n+    while(iter.next()) {\n+      CompiledMethod* nm = iter.method();\n+      if (!nm->is_native_method()) {\n+        deopt.enqueue(nm);\n+      }\n+    }\n+  }\n+  deopt.deoptimize();\n+}\n+\n+\/\/ Keeps track of time spent for checking dependencies\n+NOT_PRODUCT(static elapsedTimer dependentCheckTime;)\n+#ifndef PRODUCT\n+  void Deoptimization::print_dependency_checking_time(outputStream* stream) {\n+    stream->print_cr(\"nmethod dependency checking time %fs\", dependentCheckTime.seconds());\n+  }\n+#endif\n+\n+void Deoptimization::deoptimize(KlassDepChange& changes) {\n+  DeoptimizationContext deopt;\n+  {\n+    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+    \/\/ nmethod::check_all_dependencies works only correctly, if no safepoint\n+    \/\/ can happen\n+    NoSafepointVerifier nsv;\n+    for (DepChange::ContextStream str(changes, nsv); str.next(); ) {\n+      Klass* d = str.klass();\n+      InstanceKlass::cast(d)->enqueue_deoptimization_dependent_nmethods(changes, &deopt);\n+    }\n@@ -936,5 +967,24 @@\n-  \/\/ Make the dependent methods not entrant\n-  if (nmethod_only != NULL) {\n-    nmethod_only->mark_for_deoptimization();\n-    nmethod_only->make_not_entrant();\n-    CodeCache::make_nmethod_deoptimized(nmethod_only);\n+#ifndef PRODUCT\n+    if (VerifyDependencies) {\n+      \/\/ Object pointers are used as unique identifiers for dependency arguments. This\n+      \/\/ is only possible if no safepoint, i.e., GC occurs during the verification code.\n+      dependentCheckTime.start();\n+      nmethod::check_all_dependencies(changes);\n+      dependentCheckTime.stop();\n+    }\n+#endif\n+  }\n+  deopt.deoptimize();\n+}\n+\n+\n+\/\/ Flushes compiled methods dependent on dependee.\n+void Deoptimization::deoptimize_dependents(InstanceKlass* dependee) {\n+  assert_lock_strong(Compile_lock);\n+\n+  if (CodeCache::number_of_nmethods_with_dependencies() == 0) return;\n+\n+  if (dependee->is_linked()) {\n+    \/\/ Class initialization state change.\n+    KlassInitDepChange changes(dependee);\n+    deoptimize(changes);\n@@ -942,1 +992,62 @@\n-    CodeCache::make_marked_nmethods_deoptimized();\n+    \/\/ New class is loaded.\n+    NewKlassDepChange changes(dependee);\n+    deoptimize(changes);\n+  }\n+}\n+\n+volatile bool DeoptimizationContext::_context_active = false;\n+\n+DeoptimizationContext::DeoptimizationContext()\n+  : _nsv(),\n+    _enqueued(0),\n+    _deoptimized(false) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  assert(!Atomic::load(&_context_active), \"Cannot create a DeoptimizationContext while another one is active\");\n+  Atomic::store(&_context_active, true);\n+}\n+\n+DeoptimizationContext::~DeoptimizationContext() {\n+  assert(_enqueued == 0 || _deoptimized, \"If something got enqueued, you have to call deoptimize\");\n+}\n+\n+void DeoptimizationContext::enqueue(CompiledMethod* cm) {\n+  assert(!_deoptimized, \"Calling enqueue after deoptimize is invalid\");\n+  if (cm->enqueue_deoptimization(true \/* inc_recompile_counts *\/)) {\n+    ++_enqueued;\n+  }\n+}\n+\n+void DeoptimizationContext::enqueue_no_recompile_count_update(CompiledMethod* cm) {\n+  assert(!_deoptimized, \"Calling enqueue_no_recompile_count_update after deoptimize is invalid\");\n+  if (cm->enqueue_deoptimization(false \/* inc_recompile_counts *\/)) {\n+    ++_enqueued;\n+  }\n+}\n+\n+void DeoptimizationContext::deopt_compiled_methods() {\n+  SweeperBlocker sw;\n+  CompiledMethod* nm = CompiledMethod::take_enqueued_deoptimization_root_method();\n+  uint links_found = 0;\n+  while (nm != nullptr) {\n+    _deoptimized = true;\n+    ++links_found;\n+    assert(nm->has_enqueued_deoptimization(), \"All nmethods in list must be enqueued\");\n+    if (!nm->is_post_make_deoptimized() && nm->can_be_deoptimized()) {\n+      nm->make_not_entrant();\n+      nm->make_deoptimized();\n+    }\n+    nm = nm->next_enqueued_deoptimization_method();\n+  }\n+  assert(links_found ==_enqueued, \"All enqueued nmethods must have been found\");\n+}\n+\n+void DeoptimizationContext::deopt_frames() {\n+  assert_locked_or_safepoint(Compile_lock);\n+  \/\/ DeoptimizationContext is considered active from its creation until\n+  \/\/ deopt_compiled_methods() finishes processing enqueued nmethods.\n+  \/\/ deopt_compiled_methods() occurs as the first step of deoptimize()\n+  assert(Atomic::load(&_context_active), \"deoptimize() must be called on an active context\");\n+  Atomic::store(&_context_active, false);\n+\n+  if (_enqueued == 0) {\n+    return; \/\/ Nothing to do\n@@ -945,1 +1056,4 @@\n-  DeoptimizeMarkedClosure deopt;\n+  \/\/ DeoptimizationContext sets up a NSV to detect bugs in the client of this API.\n+  \/\/ But we must allow safepoints when performing thread-local handshakes\n+  PauseNoSafepointVerifier pnsv(&_nsv);\n+  DeoptimizeEnqueueMethodFramesClosure deopt;\n@@ -953,0 +1067,38 @@\n+void DeoptimizationContext::deoptimize() {\n+  deopt_compiled_methods();\n+  deopt_frames();\n+}\n+\n+bool DeoptimizationContext::is_context_active() {\n+  return Atomic::load(&_context_active);\n+}\n+\n+void Deoptimization::deoptimize_dependents(const methodHandle& m_h) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  Deoptimization::deoptimize_dependents(m_h());\n+}\n+\n+void Deoptimization::enqueue_dependents(Method* dependee, DeoptimizationContext* deopt) {\n+  MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n+  CompiledMethodIterator iter(CompiledMethodIterator::only_alive_and_not_unloading);\n+  while(iter.next()) {\n+    CompiledMethod* nm = iter.method();\n+    if (nm->is_dependent_on_method(dependee)) {\n+      deopt->enqueue(nm);\n+    }\n+  }\n+}\n+\n+void Deoptimization::deoptimize_dependents(Method* dependee) {\n+  assert_locked_or_safepoint(Compile_lock);\n+  DeoptimizationContext deopt;\n+  enqueue_dependents(dependee, &deopt);\n+  deopt.deoptimize();\n+}\n+\n+void Deoptimization::deoptimize_nmethod(nmethod* nmethod) {\n+  DeoptimizationContext deopt;\n+  deopt.enqueue(nmethod);\n+  deopt.deoptimize();\n+}\n+\n@@ -1656,1 +1808,0 @@\n-  DeoptimizationMarker dm;\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":167,"deletions":16,"binary":false,"changes":183,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"runtime\/safepointVerifiers.hpp\"\n@@ -32,0 +33,1 @@\n+class DeoptimizationContext;\n@@ -40,0 +42,1 @@\n+class KlassDepChange;\n@@ -151,5 +154,15 @@\n-  \/\/ Make all nmethods that are marked_for_deoptimization not_entrant and deoptimize any live\n-  \/\/ activations using those nmethods.  If an nmethod is passed as an argument then it is\n-  \/\/ marked_for_deoptimization and made not_entrant.  Otherwise a scan of the code cache is done to\n-  \/\/ find all marked nmethods and they are made not_entrant.\n-  static void deoptimize_all_marked(nmethod* nmethod_only = NULL);\n+private:\n+  static void deoptimize(KlassDepChange& changes);\n+\n+public:\n+  static void deoptimize_nmethod(nmethod* nmethod);\n+  static void deoptimize_dependents(const methodHandle& dependee);\n+  static void deoptimize_dependents(Method* dependee);\n+  static void deoptimize_dependents(InstanceKlass* dependee);\n+  static void enqueue_dependents(Method* dependee, DeoptimizationContext* deopt);\n+  \/\/ Only called from whitebox API.\n+  static void deoptimize_all_whitebox();\n+\n+#ifndef PRODUCT\n+  static void print_dependency_checking_time(outputStream* stream);\n+#endif\n@@ -476,0 +489,8 @@\n+class DeoptimizationContext : StackObj {\n+  NoSafepointVerifier _nsv;\n+  uint _enqueued;\n+  bool _deoptimized;\n+  static volatile bool _context_active;\n+\n+  void deopt_compiled_methods();\n+  void deopt_frames();\n@@ -477,2 +498,0 @@\n-class DeoptimizationMarker : StackObj {  \/\/ for profiling\n-  static bool _is_active;\n@@ -480,3 +499,10 @@\n-  DeoptimizationMarker()  { _is_active = true; }\n-  ~DeoptimizationMarker() { _is_active = false; }\n-  static bool is_active() { return _is_active; }\n+  DeoptimizationContext();\n+  ~DeoptimizationContext();\n+\n+  void enqueue(CompiledMethod* cm);\n+  void enqueue_no_recompile_count_update(CompiledMethod* cm);\n+  void deoptimize();\n+\n+  uint enqueued() { return _enqueued; }\n+\n+  static bool is_context_active();\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":36,"deletions":10,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -325,1 +325,1 @@\n-    tty->print(\"checking (%s) \", nm->is_marked_for_deoptimization() ? \"true\" : \"false\");\n+    tty->print(\"checking (%s) \", nm->has_enqueued_deoptimization() ? \"true\" : \"false\");\n@@ -330,1 +330,1 @@\n-  if( !nm->is_marked_for_deoptimization() )\n+  if( !nm->has_enqueued_deoptimization() )\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1321,1 +1321,1 @@\n-void JavaThread::deoptimize_marked_methods() {\n+void JavaThread::deoptimize_enqueued_method_frames() {\n","filename":"src\/hotspot\/share\/runtime\/javaThread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -962,1 +962,1 @@\n-  void deoptimize_marked_methods();\n+  void deoptimize_enqueued_method_frames();\n","filename":"src\/hotspot\/share\/runtime\/javaThread.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -144,3 +144,0 @@\n-  \/\/ Deoptimizes all frames tied to marked nmethods\n-  static void deoptimized_wrt_marked_nmethods();\n-\n","filename":"src\/hotspot\/share\/runtime\/threads.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -120,1 +120,0 @@\n-  DeoptimizationMarker dm;\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"}]}