{"files":[{"patch":"@@ -116,1 +116,3 @@\n-          \"Use RVV instructions for left\/right shift of BigInteger\")\n+          \"Use RVV instructions for left\/right shift of BigInteger\")             \\\n+  product(bool, UseRVVForCompressBitsIntrinsics, true,                           \\\n+          \"Use RVV instructions for bits compressing of Integer and Long\")\n","filename":"src\/hotspot\/cpu\/riscv\/globals_riscv.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -4425,0 +4425,38 @@\n+void MacroAssembler::compress_bits(Register dst, Register src, Register mask, Register tmp, bool is_long) {\n+  Assembler::SEW sew = is_long ? Assembler::e64 : Assembler::e32;\n+  \/\/ intrinsic is enabled when MaxVectorSize >= 16\n+  Assembler::LMUL lmul = is_long ? Assembler::m4 : Assembler::m2;\n+  long len = is_long ? 64 : 32;\n+\n+  \/\/ load the src data(in bits) to be compressed.\n+  vsetivli(x0, 1, sew, lmul);\n+  vmv_s_x(v0, src);\n+  \/\/ reset the src data(in bytes) to zero.\n+  mv(tmp, len);\n+  vsetvli(x0, tmp, Assembler::e8, lmul);\n+  vmv_v_i(v4, 0);\n+  \/\/ convert the src data from bits to bytes.\n+  vmerge_vim(v4, v4, 1); \/\/ v0 as the implicit mask register\n+  \/\/ reset the dst data(in bytes) to zero.\n+  vmv_v_i(v8, 0);\n+  \/\/ load the mask data(in bits).\n+  vsetivli(x0, 1, sew, lmul);\n+  vmv_v_x(v0, mask);\n+  \/\/ compress the src data(in bytes) to dst(in bytes).\n+  vsetvli(x0, tmp, Assembler::e8, lmul);\n+  vcompress_vm(v8, v4, v0);\n+  \/\/ convert the dst data from bytes to bits.\n+  vmseq_vi(v0, v8, 1);\n+  \/\/ store result back.\n+  vsetivli(x0, 1, sew, lmul);\n+  vmv_x_s(dst, v0);\n+}\n+\n+void MacroAssembler::compress_bits_i(Register dst, Register src, Register mask, Register tmp) {\n+  compress_bits(dst, src, mask, tmp, \/* is_long *\/ false);\n+}\n+\n+void MacroAssembler::compress_bits_l(Register dst, Register src, Register mask, Register tmp) {\n+  compress_bits(dst, src, mask, tmp, \/* is_long *\/ true);\n+}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.cpp","additions":38,"deletions":0,"binary":false,"changes":38,"status":"modified"},{"patch":"@@ -1400,0 +1400,2 @@\n+  void compress_bits(Register dst, Register src, Register mask, Register tmp, bool is_long);\n+\n@@ -1401,0 +1403,4 @@\n+  \/\/ compress bits, i.e. j.l.Long::compress.\n+  void compress_bits_i(Register dst, Register src, Register mask, Register tmp);\n+  void compress_bits_l(Register dst, Register src, Register mask, Register tmp);\n+\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -6800,0 +6800,50 @@\n+\/\/ CompressBits\n+\n+instruct compressBitsI(iRegINoSp dst, iRegIorL2I src, iRegIorL2I mask, iRegPNoSp tmp, vRegMask_V0 v0, vReg_V4 v4, vReg_V8 v8) %{\n+  match(Set dst (CompressBits src mask));\n+  effect(TEMP tmp, TEMP v0, TEMP v4, TEMP v8);\n+  format %{ \"vsetivli x0, 1, e32, m2, tu, mu\\t#@compressBitsI\\n\\t\"\n+            \"vmv.s.x $v0, $src\\n\\t\"\n+            \"mv $tmp, 32\\n\\t\"\n+            \"vsetvli x0, $tmp, e8, m2, tu, mu\\n\\t\"\n+            \"vmv.v.i $v4, 0\\n\\t\"\n+            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n+            \"vmv.v.i $v8, 0\\n\\t\"\n+            \"vsetivli x0, 1, e32, m2, tu, mu\\n\\t\"\n+            \"vmv.v.x $v0, $mask\\n\\t\"\n+            \"vsetvli x0, $tmp, e8, m2, tu, mu\\n\\t\"\n+            \"vcompress.vm $v8, $v4, $v0\\n\\t\"\n+            \"vmseq.vi $v0, $v8, 1\\n\\t\"\n+            \"vsetivli x0, 1, e32, m2, tu, mu\\n\\t\"\n+            \"vmv.x.s $dst, $v0\\t#@compressBitsI\\n\\t\"\n+          %}\n+  ins_encode %{\n+    __ compress_bits_i(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg), as_Register($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct compressBitsL(iRegLNoSp dst, iRegL src, iRegL mask, iRegPNoSp tmp, vRegMask_V0 v0, vReg_V4 v4, vReg_V8 v8) %{\n+  match(Set dst (CompressBits src mask));\n+  effect(TEMP tmp, TEMP v0, TEMP v4, TEMP v8);\n+  format %{ \"vsetivli x0, 1, e64, m4, tu, mu\\t#@compressBitsL\\n\\t\"\n+            \"vmv.s.x $v0, $src\\n\\t\"\n+            \"mv $tmp, 64\\n\\t\"\n+            \"vsetvli x0, $tmp, e8, m4, tu, mu\\n\\t\"\n+            \"vmv.v.i $v4, 0\\n\\t\"\n+            \"vmerge.vim $v4, $v4, 1, $v0\\n\\t\"\n+            \"vmv.v.i $v8, 0\\n\\t\"\n+            \"vsetivli x0, 1, e64, m4, tu, mu\\n\\t\"\n+            \"vmv.v.x $v0, $mask\\n\\t\"\n+            \"vsetvli x0, $tmp, e8, m4, tu, mu\\n\\t\"\n+            \"vcompress.vm $v8, $v4, $v0\\n\\t\"\n+            \"vmseq.vi $v0, $v8, 1\\n\\t\"\n+            \"vsetivli x0, 1, e64, m4, tu, mu\\n\\t\"\n+            \"vmv.x.s $dst, $v0\\t#@compressBitsL\\n\\t\"\n+          %}\n+  ins_encode %{\n+    __ compress_bits_l(as_Register($dst$$reg), as_Register($src$$reg), as_Register($mask$$reg), as_Register($tmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":50,"deletions":0,"binary":false,"changes":50,"status":"modified"},{"patch":"@@ -319,0 +319,4 @@\n+  if (!UseRVV || MaxVectorSize < 16) {\n+    FLAG_SET_DEFAULT(UseRVVForCompressBitsIntrinsics, false);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/vm_version_riscv.cpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -286,1 +286,1 @@\n-    if (!Matcher::match_rule_supported(Op_CompressBits)) return false;\n+    if (!UseRVVForCompressBitsIntrinsics || !Matcher::match_rule_supported(Op_CompressBits)) return false;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"}]}