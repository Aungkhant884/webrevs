{"files":[{"patch":"@@ -48,1 +48,0 @@\n-#include \"utilities\/lockFreeQueue.inline.hpp\"\n@@ -50,0 +49,1 @@\n+#include \"utilities\/nonblockingQueue.inline.hpp\"\n@@ -134,2 +134,2 @@\n-\/\/ the _completed queue, using the LockFreeQueue::try_pop() underneath.\n-\/\/ It has a restriction that it may return NULL when there are objects\n+\/\/ the _completed queue, using the NonblockingQueue::try_pop() underneath.\n+\/\/ It has a limitation that it may return NULL when there are objects\n@@ -138,1 +138,0 @@\n-  using Status = LockFreeQueuePopStatus;\n@@ -140,0 +139,1 @@\n+  BufferNode* result = NULL;\n@@ -150,13 +150,1 @@\n-    Pair<Status, BufferNode*> pop_result = _completed.try_pop();\n-    switch (pop_result.first) {\n-      case Status::success:\n-        return pop_result.second;\n-      case Status::operation_in_progress:\n-        \/\/ Returning NULL instead retrying, in order to mitigate the\n-        \/\/ chance of spinning for a long time. In the case of getting a\n-        \/\/ buffer to refine, it is also OK to return NULL when there is\n-        \/\/ an interfering concurrent push\/append operation.\n-        return NULL;\n-      case Status::lost_race:\n-        break;  \/\/ Try again.\n-    }\n+    if (_completed.try_pop(&result)) return result;\n@@ -180,2 +168,3 @@\n-  BufferNode* cur = _completed.top();\n-  for ( ; cur != NULL; cur = cur->next()) {\n+  for (BufferNode* cur = _completed.first();\n+       !_completed.is_end(cur);\n+       cur = cur->next()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.cpp","additions":8,"deletions":19,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -35,1 +35,1 @@\n-#include \"utilities\/lockFreeQueue.hpp\"\n+#include \"utilities\/nonblockingQueue.hpp\"\n@@ -167,3 +167,3 @@\n-  \/\/ LockFreeQueue has inner padding of one cache line.\n-  LockFreeQueue<BufferNode, &BufferNode::next_ptr> _completed;\n-  \/\/ Add a trailer padding after LockFreeQueue.\n+  \/\/ NonblockingQueue has inner padding of one cache line.\n+  NonblockingQueue<BufferNode, &BufferNode::next_ptr> _completed;\n+  \/\/ Add a trailer padding after NonblockingQueue.\n","filename":"src\/hotspot\/share\/gc\/g1\/g1DirtyCardQueue.hpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1,120 +0,0 @@\n-\/*\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n-#define SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n-\n-#include \"memory\/padded.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/pair.hpp\"\n-\n-\/\/ Return status of a LockFreeQueue::try_pop() call.\n-\/\/ See description for try_pop() below.\n-enum class LockFreeQueuePopStatus {\n-  success,\n-  lost_race,\n-  operation_in_progress\n-};\n-\n-\/\/ The LockFreeQueue template provides a lock-free FIFO. Its structure\n-\/\/ and usage is similar to LockFreeStack. It provides a try_pop() function\n-\/\/ for the client to implement pop() according to its need (e.g., whether\n-\/\/ or not to retry or prevent ABA problem). It has inner padding of one\n-\/\/ cache line between its two internal pointer fields.\n-\/\/\n-\/\/ \\tparam T is the class of the elements in the queue.\n-\/\/\n-\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n-\/\/ an object of type T must return a pointer to the list entry member\n-\/\/ of the object associated with the LockFreeQueue type.\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-class LockFreeQueue {\n-  T* volatile _head;\n-  \/\/ Padding of one cache line to avoid false sharing.\n-  DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(T*));\n-  T* volatile _tail;\n-\n-  NONCOPYABLE(LockFreeQueue);\n-\n-  \/\/ Return the entry following node in the list used by the\n-  \/\/ specialized LockFreeQueue class.\n-  static inline T* next(const T& node);\n-\n-  \/\/ Set the entry following node to new_next in the list used by the\n-  \/\/ specialized LockFreeQueue class. Not thread-safe, as it cannot\n-  \/\/ concurrently run with push or try_pop operations that modify this\n-  \/\/ node.\n-  static inline void set_next(T& node, T* new_next);\n-\n-public:\n-  inline LockFreeQueue();\n-  DEBUG_ONLY(~LockFreeQueue();)\n-\n-  \/\/ Return the first object in the queue.\n-  \/\/ Thread-safe, but the result may change immediately.\n-  inline T* top() const;\n-\n-  \/\/ Return true if the queue is empty.\n-  inline bool empty() const { return top() == NULL; }\n-\n-  \/\/ Return the number of objects in the queue.\n-  \/\/ Not thread-safe. There must be no concurrent modification\n-  \/\/ while the length is being determined.\n-  inline size_t length() const;\n-\n-  \/\/ Thread-safe add the object to the end of the queue.\n-  inline void push(T& node) { append(node, node); }\n-\n-  \/\/ Thread-safe add the objects from first to last to the end of the queue.\n-  inline void append(T& first, T& last);\n-\n-  \/\/ Thread-safe attempt to remove and return the first object in the queue.\n-  \/\/ Returns a <LockFreeQueuePopStatus, T*> pair for the caller to determine\n-  \/\/ further operation. 3 possible cases depending on pair.first:\n-  \/\/ - success:\n-  \/\/   The operation succeeded. If pair.second is NULL, the queue is empty;\n-  \/\/   otherwise caller can assume ownership of the object pointed by\n-  \/\/   pair.second. Note that this case is still subject to ABA behavior;\n-  \/\/   callers must ensure usage is safe.\n-  \/\/ - lost_race:\n-  \/\/   An atomic operation failed. pair.second is NULL.\n-  \/\/   The caller can typically retry in this case.\n-  \/\/ - operation_in_progress:\n-  \/\/   An in-progress concurrent operation interfered with taking what had been\n-  \/\/   the only remaining element in the queue. pair.second is NULL.\n-  \/\/   A concurrent try_pop may have already claimed it, but not completely\n-  \/\/   updated the queue. Alternatively, a concurrent push\/append may have not\n-  \/\/   yet linked the new entry(s) to the former sole entry. Retrying the try_pop\n-  \/\/   will continue to fail in this way until that other thread has updated the\n-  \/\/   queue's internal structure.\n-  inline Pair<LockFreeQueuePopStatus, T*> try_pop();\n-\n-  \/\/ Take all the objects from the queue, leaving the queue empty.\n-  \/\/ Not thread-safe. It should only be used when there is no concurrent\n-  \/\/ push\/append\/try_pop operation.\n-  \/\/ Returns a pair of <head, tail> pointers to the current queue.\n-  inline Pair<T*, T*> take_all();\n-};\n-\n-#endif \/\/ SHARE_UTILITIES_LOCKFREEQUEUE_HPP\n","filename":"src\/hotspot\/share\/utilities\/lockFreeQueue.hpp","additions":0,"deletions":120,"binary":false,"changes":120,"status":"deleted"},{"patch":"@@ -1,165 +0,0 @@\n-\/*\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\n- *\/\n-\n-#ifndef SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n-#define SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n-\n-#include \"utilities\/lockFreeQueue.hpp\"\n-\n-#include \"runtime\/atomic.hpp\"\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-T* LockFreeQueue<T, next_ptr>::next(const T& node) {\n-  return Atomic::load(next_ptr(const_cast<T&>(node)));\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-void LockFreeQueue<T, next_ptr>::set_next(T& node, T* new_next) {\n-    Atomic::store(next_ptr(node), new_next);\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-LockFreeQueue<T, next_ptr>::LockFreeQueue() : _head(NULL), _tail(NULL) {}\n-\n-#ifdef ASSERT\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-LockFreeQueue<T, next_ptr>::~LockFreeQueue() {\n-  assert(_head == NULL, \"precondition\");\n-  assert(_tail == NULL, \"precondition\");\n-}\n-#endif\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-T* LockFreeQueue<T, next_ptr>::top() const {\n-  return Atomic::load(&_head);\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-size_t LockFreeQueue<T, next_ptr>::length() const {\n-  size_t result = 0;\n-  for (const T* current = top(); current != NULL; current = next(*current)) {\n-    ++result;\n-  }\n-  return result;\n-}\n-\n-\/\/ An append operation atomically exchanges the new tail with the queue tail.\n-\/\/ It then sets the \"next\" value of the old tail to the head of the list being\n-\/\/ appended; it is an invariant that the old tail's \"next\" value is NULL.\n-\/\/ But if the old tail is NULL then the queue was empty.  In this case the\n-\/\/ head of the list being appended is instead stored in the queue head; it is\n-\/\/ an invariant that the queue head is NULL in this case.\n-\/\/\n-\/\/ This means there is a period between the exchange and the old tail update\n-\/\/ where the queue sequence is split into two parts, the list from the queue\n-\/\/ head to the old tail, and the list being appended.  If there are concurrent\n-\/\/ push\/append operations, each may introduce another such segment.  But they\n-\/\/ all eventually get resolved by their respective updates of their old tail's\n-\/\/ \"next\" value.  This also means that try_pop operation must handle an object\n-\/\/ with a NULL \"next\" value specially.\n-\/\/\n-\/\/ A push operation is just a degenerate append, where the object being pushed\n-\/\/ is both the head and the tail of the list being appended.\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-void LockFreeQueue<T, next_ptr>::append(T& first, T& last) {\n-  assert(next(last) == NULL, \"precondition\");\n-  T* old_tail = Atomic::xchg(&_tail, &last);\n-  if (old_tail == NULL) {       \/\/ Was empty.\n-    Atomic::store(&_head, &first);\n-  } else {\n-    assert(next(*old_tail) == NULL, \"invariant\");\n-    set_next(*old_tail, &first);\n-  }\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-Pair<LockFreeQueuePopStatus, T*> LockFreeQueue<T, next_ptr>::try_pop() {\n-  typedef Pair<LockFreeQueuePopStatus, T*> StatusPair;\n-  \/\/ We only need memory_order_consume. Upgrade it to \"load_acquire\"\n-  \/\/ as the memory_order_consume API is not ready for use yet.\n-  T* result = Atomic::load_acquire(&_head);\n-  if (result == NULL) {\n-    \/\/ Queue is empty.\n-    return StatusPair(LockFreeQueuePopStatus::success, NULL);\n-  }\n-\n-  \/\/ This relaxed load is always followed by a cmpxchg(), thus it\n-  \/\/ is OK as the reader-side of the release-acquire ordering.\n-  T* next_node = Atomic::load(next_ptr(*result));\n-  if (next_node != NULL) {\n-    \/\/ The \"usual\" lock-free pop from the head of a singly linked list.\n-    if (result == Atomic::cmpxchg(&_head, result, next_node)) {\n-      \/\/ Former head successfully taken; it is not the last.\n-      assert(Atomic::load(&_tail) != result, \"invariant\");\n-      assert(next(*result) != NULL, \"invariant\");\n-      set_next(*result, NULL);\n-      return StatusPair(LockFreeQueuePopStatus::success, result);\n-    }\n-    \/\/ Lost the race; the caller should try again.\n-    return StatusPair(LockFreeQueuePopStatus::lost_race, NULL);\n-  }\n-\n-  \/\/ next is NULL.  This case is handled differently from the \"usual\"\n-  \/\/ lock-free pop from the head of a singly linked list.\n-\n-  \/\/ If _tail == result then result is the only element in the list. We can\n-  \/\/ remove it from the list by first setting _tail to NULL and then setting\n-  \/\/ _head to NULL, the order being important.  We set _tail with cmpxchg in\n-  \/\/ case of a concurrent push\/append\/try_pop also changing _tail.  If we win\n-  \/\/ then we've claimed result.\n-  if (Atomic::cmpxchg(&_tail, result, (T*)NULL) == result) {\n-    assert(next(*result) == NULL, \"invariant\");\n-    \/\/ Now that we've claimed result, also set _head to NULL.  But we must\n-    \/\/ be careful of a concurrent push\/append after we NULLed _tail, since\n-    \/\/ it may have already performed its list-was-empty update of _head,\n-    \/\/ which we must not overwrite.\n-    Atomic::cmpxchg(&_head, result, (T*)NULL);\n-    return StatusPair(LockFreeQueuePopStatus::success, result);\n-  }\n-\n-  \/\/ If _head != result then we lost the race to take result;\n-  \/\/ the caller should try again.\n-  if (result != Atomic::load_acquire(&_head)) {\n-    return StatusPair(LockFreeQueuePopStatus::lost_race, NULL);\n-  }\n-\n-  \/\/ An in-progress concurrent operation interfered with taking the head\n-  \/\/ element when it was the only element.  A concurrent try_pop may have won\n-  \/\/ the race to clear the tail but not yet cleared the head. Alternatively,\n-  \/\/ a concurrent push\/append may have changed the tail but not yet linked\n-  \/\/ result->next(). This case slightly differs from the \"lost_race\" case,\n-  \/\/ because the caller could wait for a long time for the other concurrent\n-  \/\/ operation to finish.\n-  return StatusPair(LockFreeQueuePopStatus::operation_in_progress, NULL);\n-}\n-\n-template<typename T, T* volatile* (*next_ptr)(T&)>\n-Pair<T*, T*> LockFreeQueue<T, next_ptr>::take_all() {\n-  Pair<T*, T*> result(Atomic::load(&_head), Atomic::load(&_tail));\n-  Atomic::store(&_head, (T*)NULL);\n-  Atomic::store(&_tail, (T*)NULL);\n-  return result;\n-}\n-\n-#endif \/\/ SHARE_UTILITIES_LOCKFREEQUEUE_INLINE_HPP\n","filename":"src\/hotspot\/share\/utilities\/lockFreeQueue.inline.hpp","additions":0,"deletions":165,"binary":false,"changes":165,"status":"deleted"},{"patch":"@@ -0,0 +1,136 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_NONBLOCKINGQUEUE_HPP\n+#define SHARE_UTILITIES_NONBLOCKINGQUEUE_HPP\n+\n+#include \"memory\/padded.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/pair.hpp\"\n+\n+\/\/ The NonblockingQueue template provides a non-blocking FIFO. It provides a\n+\/\/ try_pop() function for the client to implement pop() according to its\n+\/\/ need (e.g., whether or not to retry or prevent ABA problem). It has inner\n+\/\/ padding of one cache line between its two internal pointer fields.\n+\/\/\n+\/\/ The queue is internally represented by a linked list of elements, with\n+\/\/ the link to the next element provided by a member of each element.\n+\/\/ Access to this member is provided by the next_ptr function.\n+\/\/\n+\/\/ The queue has a special pseudo-element that marks the end of the list.\n+\/\/ Each queue has its own unique special element.  A pointer to this element\n+\/\/ can be recognized using the is_end() function.  Such a pointer must never\n+\/\/ be dereferenced.  This end marker is the value of the next member of the\n+\/\/ last element in the queue, and possibly other elements while modifying\n+\/\/ the queue.\n+\/\/\n+\/\/ A queue may temporarily appear to be empty even though elements have been\n+\/\/ added and not removed.  For example, after running the following program,\n+\/\/ the value of r may be NULL.\n+\/\/\n+\/\/ thread1: q.push(a); r = q.pop();\n+\/\/ thread2: q.push(b);\n+\/\/\n+\/\/ This can occur if the push of b started before the push of a, but didn't\n+\/\/ complete until after the pop.\n+\/\/\n+\/\/ \\tparam T is the class of the elements in the queue.\n+\/\/\n+\/\/ \\tparam next_ptr is a function pointer.  Applying this function to\n+\/\/ an object of type T must return a pointer to the list entry member\n+\/\/ of the object associated with the NonblockingQueue type.\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+class NonblockingQueue {\n+  T* volatile _head;\n+  \/\/ Padding of one cache line to avoid false sharing.\n+  DEFINE_PAD_MINUS_SIZE(1, DEFAULT_CACHE_LINE_SIZE, sizeof(T*));\n+  T* volatile _tail;\n+\n+  NONCOPYABLE(NonblockingQueue);\n+\n+  \/\/ Return the entry following node in the list used by the\n+  \/\/ specialized NonblockingQueue class.\n+  static inline T* next(const T& node);\n+\n+  \/\/ Set the entry following node to new_next in the list used by the\n+  \/\/ specialized NonblockingQueue class. Not thread-safe, as it cannot\n+  \/\/ concurrently run with push or try_pop operations that modify this\n+  \/\/ node.\n+  static inline void set_next(T& node, T* new_next);\n+\n+  \/\/ A unique pseudo-object pointer associated with this specific queue.\n+  \/\/ The resulting pointer must not be dereferenced.\n+  inline T* end_marker() const;\n+\n+public:\n+  inline NonblockingQueue();\n+  inline ~NonblockingQueue() NOT_DEBUG(= default);\n+\n+  \/\/ Return true if the queue is empty.\n+  \/\/ Not thread-safe.  There must be no concurrent modification while the\n+  \/\/ queue is being tested.\n+  inline bool empty() const;\n+\n+  \/\/ Return the number of objects in the queue.\n+  \/\/ Not thread-safe. There must be no concurrent modification while the\n+  \/\/ length is being determined.\n+  inline size_t length() const;\n+\n+  \/\/ Thread-safe add the object to the end of the queue.\n+  inline void push(T& node) { append(node, node); }\n+\n+  \/\/ Thread-safe add the objects from first to last to the end of the queue.\n+  inline void append(T& first, T& last);\n+\n+  \/\/ Thread-safe attempt to remove and return the first object in the queue.\n+  \/\/ Returns true if successful.  If successful then *node_ptr is the former\n+  \/\/ first object, or NULL if the queue was empty.  If unsuccessful, because\n+  \/\/ of contention with a concurrent modification, then returns false with\n+  \/\/ the value of *node_ptr unspecified.  Subject to ABA behavior; callers\n+  \/\/ must ensure usage is safe.\n+  inline bool try_pop(T** node_ptr);\n+\n+  \/\/ Thread-safe remove and return the first object in the queue, or NULL if\n+  \/\/ the queue was empty.  This just iterates on try_pop() until it\n+  \/\/ succeeds, returning the (possibly NULL) element obtained from that.\n+  \/\/ Subject to ABA behavior; callers must ensure usage is safe.\n+  inline T* pop();\n+\n+  \/\/ Take all the objects from the queue, leaving the queue empty.\n+  \/\/ Not thread-safe.  There must be no concurrent operations.\n+  \/\/ Returns a pair of <head, tail> pointers to the current queue.\n+  inline Pair<T*, T*> take_all();\n+\n+  \/\/ Iteration support is provided by first() and is_end().  The queue must\n+  \/\/ not be modified while iterating over its elements.\n+\n+  \/\/ Return the first object in the queue, or an end marker (a pointer p for\n+  \/\/ which is_end(p) is true) if the queue is empty.\n+  inline T* first() const;\n+\n+  \/\/ Test whether entry is an end marker for this queue.\n+  inline bool is_end(const T* entry) const;\n+};\n+\n+#endif \/\/ SHARE_UTILITIES_NONBLOCKINGQUEUE_HPP\n","filename":"src\/hotspot\/share\/utilities\/nonblockingQueue.hpp","additions":136,"deletions":0,"binary":false,"changes":136,"status":"added"},{"patch":"@@ -0,0 +1,197 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\n+ *\/\n+\n+#ifndef SHARE_UTILITIES_NONBLOCKINGQUEUE_INLINE_HPP\n+#define SHARE_UTILITIES_NONBLOCKINGQUEUE_INLINE_HPP\n+\n+#include \"utilities\/nonblockingQueue.hpp\"\n+\n+#include \"runtime\/atomic.hpp\"\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::next(const T& node) {\n+  return Atomic::load(next_ptr(const_cast<T&>(node)));\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+void NonblockingQueue<T, next_ptr>::set_next(T& node, T* new_next) {\n+  Atomic::store(next_ptr(node), new_next);\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+NonblockingQueue<T, next_ptr>::NonblockingQueue() : _head(NULL), _tail(NULL) {}\n+\n+#ifdef ASSERT\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+NonblockingQueue<T, next_ptr>::~NonblockingQueue() {\n+  assert(_head == NULL, \"precondition\");\n+  assert(_tail == NULL, \"precondition\");\n+}\n+#endif\n+\n+\/\/ The end_marker must be uniquely associated with the specific queue, in\n+\/\/ case queue elements can make their way through multiple queues.  A\n+\/\/ pointer to the queue itself (after casting) satisfies that requirement.\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::end_marker() const {\n+  return const_cast<T*>(reinterpret_cast<const T*>(this));\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::first() const {\n+  T* head = Atomic::load(&_head);\n+  return head == NULL ? end_marker() : head;\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+bool NonblockingQueue<T, next_ptr>::is_end(const T* entry) const {\n+  return entry == end_marker();\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+bool NonblockingQueue<T, next_ptr>::empty() const {\n+  return Atomic::load(&_head) == NULL;\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+size_t NonblockingQueue<T, next_ptr>::length() const {\n+  size_t result = 0;\n+  for (T* cur = first(); !is_end(cur); cur = next(*cur)) {\n+    ++result;\n+  }\n+  return result;\n+}\n+\n+\/\/ An append operation atomically exchanges the new tail with the queue tail.\n+\/\/ It then sets the \"next\" value of the old tail to the head of the list being\n+\/\/ appended; it is an invariant that the old tail's \"next\" value is NULL.\n+\/\/ But if the old tail is NULL then the queue was empty.  In this case the\n+\/\/ head of the list being appended is instead stored in the queue head; it is\n+\/\/ an invariant that the queue head is NULL in this case.\n+\/\/\n+\/\/ This means there is a period between the exchange and the old tail update\n+\/\/ where the queue sequence is split into two parts, the list from the queue\n+\/\/ head to the old tail, and the list being appended.  If there are concurrent\n+\/\/ push\/append operations, each may introduce another such segment.  But they\n+\/\/ all eventually get resolved by their respective updates of their old tail's\n+\/\/ \"next\" value.  This also means that try_pop operation must handle an object\n+\/\/ with a NULL \"next\" value specially.\n+\/\/\n+\/\/ A push operation is just a degenerate append, where the object being pushed\n+\/\/ is both the head and the tail of the list being appended.\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+void NonblockingQueue<T, next_ptr>::append(T& first, T& last) {\n+  assert(next(last) == NULL, \"precondition\");\n+  set_next(last, end_marker());\n+  T* old_tail = Atomic::xchg(&_tail, &last);\n+  if ((old_tail == NULL) ||\n+      \/\/ Try to install first as old_tail's next.\n+      !is_end(Atomic::cmpxchg(next_ptr(*old_tail), end_marker(), &first))) {\n+    \/\/ Install first as the new head if either\n+    \/\/ (1) the list was empty, or\n+    \/\/ (2) a concurrent try_pop claimed old_tail, so it is no longer in the list.\n+    Atomic::store(&_head, &first);\n+  }\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+bool NonblockingQueue<T, next_ptr>::try_pop(T** node_ptr) {\n+  \/\/ We only need memory_order_consume. Upgrade it to \"load_acquire\"\n+  \/\/ as the memory_order_consume API is not ready for use yet.\n+  T* result = Atomic::load_acquire(&_head);\n+  if (result == NULL) {\n+    *node_ptr = NULL;\n+    return true;                \/\/ Queue is empty.\n+  }\n+\n+  T* next_node = Atomic::load_acquire(next_ptr(*result));\n+  if (next_node == NULL) {\n+    \/\/ A concurrent try_pop already claimed what was the last entry.  That\n+    \/\/ operation may not have cleared queue head yet, but we should still\n+    \/\/ treat the queue as empty until a push\/append operation changes head\n+    \/\/ to an entry with a non-NULL next value.\n+    *node_ptr = NULL;\n+    return true;\n+\n+  } else if (!is_end(next_node)) {\n+    \/\/ The next_node is not at the end of the queue's list.  Use the \"usual\"\n+    \/\/ lock-free pop from the head of a singly linked list to try to take it.\n+    if (result == Atomic::cmpxchg(&_head, result, next_node)) {\n+      \/\/ Former head successfully taken.\n+      set_next(*result, NULL);\n+      *node_ptr = result;\n+      return true;\n+    } else {\n+      \/\/ Lost race to take result from the head of the list.\n+      return false;\n+    }\n+\n+  } else if (is_end(Atomic::cmpxchg(next_ptr(*result), end_marker(), (T*)NULL))) {\n+    \/\/ Result was the last entry and we've claimed it by setting its next\n+    \/\/ value to NULL.  However, this leaves the queue in disarray.  Fix up\n+    \/\/ the queue, possibly in conjunction with other concurrent operations.\n+    \/\/ Any further try_pops will consider the queue empty until a\n+    \/\/ push\/append completes by installing a new head.\n+\n+    \/\/ Attempt to change the queue tail from result to NULL.  Failure of the\n+    \/\/ cmpxchg indicates that a concurrent push\/append updated the tail first.\n+    \/\/ That operation will eventually recognize the old tail (our result) is\n+    \/\/ no longer in the list and update head from the list being appended.\n+    Atomic::cmpxchg(&_tail, result, (T*)NULL);\n+\n+    \/\/ Attempt to change the queue head from result to NULL.  Failure of the\n+    \/\/ cmpxchg indicates a concurrent push\/append updated the head first.\n+    Atomic::cmpxchg(&_head, result, (T*)NULL);\n+\n+    \/\/ The queue has been restored to order, and we can return the result.\n+    *node_ptr = result;\n+    return true;\n+\n+  } else {\n+    \/\/ Result was the last entry in the list, but either a concurrent pop\n+    \/\/ claimed it first or a concurrent push\/append extended the list from\n+    \/\/ it.  Either way, we lost the race.\n+    return false;\n+  }\n+}\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+T* NonblockingQueue<T, next_ptr>::pop() {\n+  T* result = NULL;\n+  while (!try_pop(&result)) {}\n+  return result;\n+}\n+\n+\n+template<typename T, T* volatile* (*next_ptr)(T&)>\n+Pair<T*, T*> NonblockingQueue<T, next_ptr>::take_all() {\n+  T* tail = Atomic::load(&_tail);\n+  if (tail != NULL) set_next(*tail, NULL); \/\/ Clear end marker.\n+  Pair<T*, T*> result(Atomic::load(&_head), tail);\n+  Atomic::store(&_head, (T*)NULL);\n+  Atomic::store(&_tail, (T*)NULL);\n+  return result;\n+}\n+\n+#endif \/\/ SHARE_UTILITIES_NONBLOCKINGQUEUE_INLINE_HPP\n","filename":"src\/hotspot\/share\/utilities\/nonblockingQueue.inline.hpp","additions":197,"deletions":0,"binary":false,"changes":197,"status":"added"},{"patch":"@@ -1,302 +0,0 @@\n-\/*\n- * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-\n-#include \"precompiled.hpp\"\n-#include \"memory\/allocation.inline.hpp\"\n-#include \"runtime\/atomic.hpp\"\n-#include \"utilities\/globalDefinitions.hpp\"\n-#include \"utilities\/lockFreeQueue.inline.hpp\"\n-#include \"utilities\/pair.hpp\"\n-#include \"threadHelper.inline.hpp\"\n-#include \"unittest.hpp\"\n-#include <new>\n-\n-class LockFreeQueueTestElement {\n-  typedef LockFreeQueueTestElement Element;\n-\n-  Element* volatile _entry;\n-  Element* volatile _entry1;\n-  size_t _id;\n-\n-  static Element* volatile* entry_ptr(Element& e) { return &e._entry; }\n-  static Element* volatile* entry1_ptr(Element& e) { return &e._entry1; }\n-\n-public:\n-  class TestQueue: public LockFreeQueue<Element, &entry_ptr> {\n-  public:\n-    Element* pop() {\n-      using Status = LockFreeQueuePopStatus;\n-      while (true) {\n-        Pair<Status, Element*> pop_result = try_pop();\n-        if (pop_result.first == Status::success) {\n-          return pop_result.second;\n-        }\n-        \/\/ Retry until success.\n-      }\n-    }\n-  };\n-  class TestQueue1: public LockFreeQueue<Element, &entry1_ptr> {\n-  public:\n-    Element* pop() {\n-      using Status = LockFreeQueuePopStatus;\n-      while (true) {\n-        Pair<Status, Element*> pop_result = try_pop();\n-        if (pop_result.first == Status::success) {\n-          return pop_result.second;\n-        }\n-        \/\/ Retry until success.\n-      }\n-    }\n-  };\n-\n-  LockFreeQueueTestElement(size_t id = 0) : _entry(), _entry1(), _id(id) {}\n-  size_t id() const { return _id; }\n-  void set_id(size_t value) { _id = value; }\n-  Element* next() { return _entry; }\n-  Element* next1() { return _entry1; }\n-};\n-\n-typedef LockFreeQueueTestElement Element;\n-typedef Element::TestQueue TestQueue;\n-typedef Element::TestQueue1 TestQueue1;\n-\n-static void initialize(Element* elements, size_t size, TestQueue* queue) {\n-  for (size_t i = 0; i < size; ++i) {\n-    elements[i].set_id(i);\n-  }\n-  ASSERT_TRUE(queue->empty());\n-  ASSERT_EQ(0u, queue->length());\n-  ASSERT_TRUE(queue->pop() == NULL);\n-  ASSERT_TRUE(queue->top() == NULL);\n-\n-  for (size_t id = 0; id < size; ++id) {\n-    ASSERT_EQ(id, queue->length());\n-    Element* e = &elements[id];\n-    ASSERT_EQ(id, e->id());\n-    queue->push(*e);\n-    ASSERT_FALSE(queue->empty());\n-    \/\/ top() is always the oldest element.\n-    ASSERT_EQ(&elements[0], queue->top());\n-  }\n-}\n-\n-class LockFreeQueueTestBasics : public ::testing::Test {\n-public:\n-  LockFreeQueueTestBasics();\n-\n-  static const size_t nelements = 10;\n-  Element elements[nelements];\n-  TestQueue queue;\n-};\n-\n-const size_t LockFreeQueueTestBasics::nelements;\n-\n-LockFreeQueueTestBasics::LockFreeQueueTestBasics() : queue() {\n-  initialize(elements, nelements, &queue);\n-}\n-\n-TEST_F(LockFreeQueueTestBasics, pop) {\n-  for (size_t i = 0; i < nelements; ++i) {\n-    ASSERT_FALSE(queue.empty());\n-    ASSERT_EQ(nelements - i, queue.length());\n-    Element* e = queue.pop();\n-    ASSERT_TRUE(e != NULL);\n-    ASSERT_EQ(&elements[i], e);\n-    ASSERT_EQ(i, e->id());\n-  }\n-  ASSERT_TRUE(queue.empty());\n-  ASSERT_EQ(0u, queue.length());\n-  ASSERT_TRUE(queue.pop() == NULL);\n-}\n-\n-TEST_F(LockFreeQueueTestBasics, append) {\n-  TestQueue other_queue;\n-  ASSERT_TRUE(other_queue.empty());\n-  ASSERT_EQ(0u, other_queue.length());\n-  ASSERT_TRUE(other_queue.top() == NULL);\n-  ASSERT_TRUE(other_queue.pop() == NULL);\n-\n-  Pair<Element*, Element*> pair = queue.take_all();\n-  other_queue.append(*pair.first, *pair.second);\n-  ASSERT_EQ(nelements, other_queue.length());\n-  ASSERT_TRUE(queue.empty());\n-  ASSERT_EQ(0u, queue.length());\n-  ASSERT_TRUE(queue.pop() == NULL);\n-  ASSERT_TRUE(queue.top() == NULL);\n-\n-  for (size_t i = 0; i < nelements; ++i) {\n-    ASSERT_EQ(nelements - i, other_queue.length());\n-    Element* e = other_queue.pop();\n-    ASSERT_TRUE(e != NULL);\n-    ASSERT_EQ(&elements[i], e);\n-    ASSERT_EQ(i, e->id());\n-  }\n-  ASSERT_EQ(0u, other_queue.length());\n-  ASSERT_TRUE(other_queue.pop() == NULL);\n-}\n-\n-TEST_F(LockFreeQueueTestBasics, two_queues) {\n-  TestQueue1 queue1;\n-  ASSERT_TRUE(queue1.pop() == NULL);\n-\n-  for (size_t id = 0; id < nelements; ++id) {\n-    queue1.push(elements[id]);\n-  }\n-  ASSERT_EQ(nelements, queue1.length());\n-  Element* e0 = queue.top();\n-  Element* e1 = queue1.top();\n-  while (true) {\n-    ASSERT_EQ(e0, e1);\n-    if (e0 == NULL) break;\n-    e0 = e0->next();\n-    e1 = e1->next1();\n-  }\n-\n-  for (size_t i = 0; i < nelements; ++i) {\n-    ASSERT_EQ(nelements - i, queue.length());\n-    ASSERT_EQ(nelements - i, queue1.length());\n-\n-    Element* e = queue.pop();\n-    ASSERT_TRUE(e != NULL);\n-    ASSERT_EQ(&elements[i], e);\n-    ASSERT_EQ(i, e->id());\n-\n-    Element* e1 = queue1.pop();\n-    ASSERT_TRUE(e1 != NULL);\n-    ASSERT_EQ(&elements[i], e1);\n-    ASSERT_EQ(i, e1->id());\n-\n-    ASSERT_EQ(e, e1);\n-  }\n-  ASSERT_EQ(0u, queue.length());\n-  ASSERT_EQ(0u, queue1.length());\n-  ASSERT_TRUE(queue.pop() == NULL);\n-  ASSERT_TRUE(queue1.pop() == NULL);\n-}\n-\n-class LockFreeQueueTestThread : public JavaTestThread {\n-  uint _id;\n-  TestQueue* _from;\n-  TestQueue* _to;\n-  volatile size_t* _processed;\n-  size_t _process_limit;\n-  size_t _local_processed;\n-  volatile bool _ready;\n-\n-public:\n-  LockFreeQueueTestThread(Semaphore* post,\n-                          uint id,\n-                          TestQueue* from,\n-                          TestQueue* to,\n-                          volatile size_t* processed,\n-                          size_t process_limit) :\n-    JavaTestThread(post),\n-    _id(id),\n-    _from(from),\n-    _to(to),\n-    _processed(processed),\n-    _process_limit(process_limit),\n-    _local_processed(0),\n-    _ready(false)\n-  {}\n-\n-  virtual void main_run() {\n-    Atomic::release_store_fence(&_ready, true);\n-    while (true) {\n-      Element* e = _from->pop();\n-      if (e != NULL) {\n-        _to->push(*e);\n-        Atomic::inc(_processed);\n-        ++_local_processed;\n-      } else if (Atomic::load_acquire(_processed) == _process_limit) {\n-        tty->print_cr(\"thread %u processed \" SIZE_FORMAT, _id, _local_processed);\n-        return;\n-      }\n-    }\n-  }\n-\n-  bool ready() const { return Atomic::load_acquire(&_ready); }\n-};\n-\n-TEST_VM(LockFreeQueueTest, stress) {\n-  Semaphore post;\n-  TestQueue initial_queue;\n-  TestQueue start_queue;\n-  TestQueue middle_queue;\n-  TestQueue final_queue;\n-  volatile size_t stage1_processed = 0;\n-  volatile size_t stage2_processed = 0;\n-\n-  const size_t nelements = 10000;\n-  Element* elements = NEW_C_HEAP_ARRAY(Element, nelements, mtOther);\n-  for (size_t id = 0; id < nelements; ++id) {\n-    ::new (&elements[id]) Element(id);\n-    initial_queue.push(elements[id]);\n-  }\n-  ASSERT_EQ(nelements, initial_queue.length());\n-\n-  \/\/ - stage1 threads pop from start_queue and push to middle_queue.\n-  \/\/ - stage2 threads pop from middle_queue and push to final_queue.\n-  \/\/ - all threads in a stage count the number of elements processed in\n-  \/\/   their corresponding stageN_processed counter.\n-\n-  const uint stage1_threads = 2;\n-  const uint stage2_threads = 2;\n-  const uint nthreads = stage1_threads + stage2_threads;\n-  LockFreeQueueTestThread* threads[nthreads] = {};\n-\n-  for (uint i = 0; i < ARRAY_SIZE(threads); ++i) {\n-    TestQueue* from = &start_queue;\n-    TestQueue* to = &middle_queue;\n-    volatile size_t* processed = &stage1_processed;\n-    if (i >= stage1_threads) {\n-      from = &middle_queue;\n-      to = &final_queue;\n-      processed = &stage2_processed;\n-    }\n-    threads[i] =\n-      new LockFreeQueueTestThread(&post, i, from, to, processed, nelements);\n-    threads[i]->doit();\n-    while (!threads[i]->ready()) {} \/\/ Wait until ready to start test.\n-  }\n-\n-  \/\/ Transfer elements to start_queue to start test.\n-  Pair<Element*, Element*> pair = initial_queue.take_all();\n-  start_queue.append(*pair.first, *pair.second);\n-\n-  \/\/ Wait for all threads to complete.\n-  for (uint i = 0; i < nthreads; ++i) {\n-    post.wait();\n-  }\n-\n-  \/\/ Verify expected state.\n-  ASSERT_EQ(nelements, stage1_processed);\n-  ASSERT_EQ(nelements, stage2_processed);\n-  ASSERT_EQ(0u, initial_queue.length());\n-  ASSERT_EQ(0u, start_queue.length());\n-  ASSERT_EQ(0u, middle_queue.length());\n-  ASSERT_EQ(nelements, final_queue.length());\n-  while (final_queue.pop() != NULL) {}\n-\n-  FREE_C_HEAP_ARRAY(Element, elements);\n-}\n","filename":"test\/hotspot\/gtest\/utilities\/test_lockFreeQueue.cpp","additions":0,"deletions":302,"binary":false,"changes":302,"status":"deleted"},{"patch":"@@ -0,0 +1,283 @@\n+\/*\n+ * Copyright (c) 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+#include \"precompiled.hpp\"\n+#include \"memory\/allocation.inline.hpp\"\n+#include \"runtime\/atomic.hpp\"\n+#include \"utilities\/globalDefinitions.hpp\"\n+#include \"utilities\/nonblockingQueue.inline.hpp\"\n+#include \"utilities\/pair.hpp\"\n+#include \"threadHelper.inline.hpp\"\n+#include \"unittest.hpp\"\n+#include <new>\n+\n+class NonblockingQueueTestElement {\n+  typedef NonblockingQueueTestElement Element;\n+\n+  Element* volatile _entry;\n+  Element* volatile _entry1;\n+  size_t _id;\n+\n+  static Element* volatile* entry_ptr(Element& e) { return &e._entry; }\n+  static Element* volatile* entry1_ptr(Element& e) { return &e._entry1; }\n+\n+public:\n+  using TestQueue = NonblockingQueue<Element, &entry_ptr>;\n+  using TestQueue1 = NonblockingQueue<Element, &entry1_ptr>;\n+\n+  NonblockingQueueTestElement(size_t id = 0) : _entry(), _entry1(), _id(id) {}\n+  size_t id() const { return _id; }\n+  void set_id(size_t value) { _id = value; }\n+  Element* next() { return _entry; }\n+  Element* next1() { return _entry1; }\n+};\n+\n+typedef NonblockingQueueTestElement Element;\n+typedef Element::TestQueue TestQueue;\n+typedef Element::TestQueue1 TestQueue1;\n+\n+static void initialize(Element* elements, size_t size, TestQueue* queue) {\n+  for (size_t i = 0; i < size; ++i) {\n+    elements[i].set_id(i);\n+  }\n+  ASSERT_TRUE(queue->empty());\n+  ASSERT_EQ(0u, queue->length());\n+  ASSERT_TRUE(queue->is_end(queue->first()));\n+  ASSERT_TRUE(queue->pop() == NULL);\n+\n+  for (size_t id = 0; id < size; ++id) {\n+    ASSERT_EQ(id, queue->length());\n+    Element* e = &elements[id];\n+    ASSERT_EQ(id, e->id());\n+    queue->push(*e);\n+    ASSERT_FALSE(queue->empty());\n+    \/\/ first() is always the oldest element.\n+    ASSERT_EQ(&elements[0], queue->first());\n+  }\n+}\n+\n+class NonblockingQueueTestBasics : public ::testing::Test {\n+public:\n+  NonblockingQueueTestBasics();\n+\n+  static const size_t nelements = 10;\n+  Element elements[nelements];\n+  TestQueue queue;\n+};\n+\n+const size_t NonblockingQueueTestBasics::nelements;\n+\n+NonblockingQueueTestBasics::NonblockingQueueTestBasics() : queue() {\n+  initialize(elements, nelements, &queue);\n+}\n+\n+TEST_F(NonblockingQueueTestBasics, pop) {\n+  for (size_t i = 0; i < nelements; ++i) {\n+    ASSERT_FALSE(queue.empty());\n+    ASSERT_EQ(nelements - i, queue.length());\n+    Element* e = queue.pop();\n+    ASSERT_TRUE(e != NULL);\n+    ASSERT_EQ(&elements[i], e);\n+    ASSERT_EQ(i, e->id());\n+  }\n+  ASSERT_TRUE(queue.empty());\n+  ASSERT_EQ(0u, queue.length());\n+  ASSERT_TRUE(queue.pop() == NULL);\n+}\n+\n+TEST_F(NonblockingQueueTestBasics, append) {\n+  TestQueue other_queue;\n+  ASSERT_TRUE(other_queue.empty());\n+  ASSERT_EQ(0u, other_queue.length());\n+  ASSERT_TRUE(other_queue.is_end(other_queue.first()));\n+  ASSERT_TRUE(other_queue.pop() == NULL);\n+\n+  Pair<Element*, Element*> pair = queue.take_all();\n+  other_queue.append(*pair.first, *pair.second);\n+  ASSERT_EQ(nelements, other_queue.length());\n+  ASSERT_TRUE(queue.empty());\n+  ASSERT_EQ(0u, queue.length());\n+  ASSERT_TRUE(queue.is_end(queue.first()));\n+  ASSERT_TRUE(queue.pop() == NULL);\n+\n+  for (size_t i = 0; i < nelements; ++i) {\n+    ASSERT_EQ(nelements - i, other_queue.length());\n+    Element* e = other_queue.pop();\n+    ASSERT_TRUE(e != NULL);\n+    ASSERT_EQ(&elements[i], e);\n+    ASSERT_EQ(i, e->id());\n+  }\n+  ASSERT_EQ(0u, other_queue.length());\n+  ASSERT_TRUE(other_queue.pop() == NULL);\n+}\n+\n+TEST_F(NonblockingQueueTestBasics, two_queues) {\n+  TestQueue1 queue1;\n+  ASSERT_TRUE(queue1.pop() == NULL);\n+\n+  for (size_t id = 0; id < nelements; ++id) {\n+    queue1.push(elements[id]);\n+  }\n+  ASSERT_EQ(nelements, queue1.length());\n+  Element* e0 = queue.first();\n+  Element* e1 = queue1.first();\n+  ASSERT_TRUE(e0 != NULL);\n+  ASSERT_TRUE(e1 != NULL);\n+  ASSERT_FALSE(queue.is_end(e0));\n+  ASSERT_FALSE(queue1.is_end(e1));\n+  while (!queue.is_end(e0) && !queue1.is_end(e1)) {\n+    ASSERT_EQ(e0, e1);\n+    e0 = e0->next();\n+    e1 = e1->next1();\n+  }\n+  ASSERT_TRUE(queue.is_end(e0));\n+  ASSERT_TRUE(queue1.is_end(e1));\n+\n+  for (size_t i = 0; i < nelements; ++i) {\n+    ASSERT_EQ(nelements - i, queue.length());\n+    ASSERT_EQ(nelements - i, queue1.length());\n+\n+    Element* e = queue.pop();\n+    ASSERT_TRUE(e != NULL);\n+    ASSERT_EQ(&elements[i], e);\n+    ASSERT_EQ(i, e->id());\n+\n+    Element* e1 = queue1.pop();\n+    ASSERT_TRUE(e1 != NULL);\n+    ASSERT_EQ(&elements[i], e1);\n+    ASSERT_EQ(i, e1->id());\n+\n+    ASSERT_EQ(e, e1);\n+  }\n+  ASSERT_EQ(0u, queue.length());\n+  ASSERT_EQ(0u, queue1.length());\n+  ASSERT_TRUE(queue.pop() == NULL);\n+  ASSERT_TRUE(queue1.pop() == NULL);\n+}\n+\n+class NonblockingQueueTestThread : public JavaTestThread {\n+  uint _id;\n+  TestQueue* _from;\n+  TestQueue* _to;\n+  volatile size_t* _processed;\n+  size_t _process_limit;\n+  size_t _local_processed;\n+  volatile bool _ready;\n+\n+public:\n+  NonblockingQueueTestThread(Semaphore* post,\n+                             uint id,\n+                             TestQueue* from,\n+                             TestQueue* to,\n+                             volatile size_t* processed,\n+                             size_t process_limit) :\n+    JavaTestThread(post),\n+    _id(id),\n+    _from(from),\n+    _to(to),\n+    _processed(processed),\n+    _process_limit(process_limit),\n+    _local_processed(0),\n+    _ready(false)\n+  {}\n+\n+  virtual void main_run() {\n+    Atomic::release_store_fence(&_ready, true);\n+    while (true) {\n+      Element* e = _from->pop();\n+      if (e != NULL) {\n+        _to->push(*e);\n+        Atomic::inc(_processed);\n+        ++_local_processed;\n+      } else if (Atomic::load_acquire(_processed) == _process_limit) {\n+        tty->print_cr(\"thread %u processed \" SIZE_FORMAT, _id, _local_processed);\n+        return;\n+      }\n+    }\n+  }\n+\n+  bool ready() const { return Atomic::load_acquire(&_ready); }\n+};\n+\n+TEST_VM(NonblockingQueueTest, stress) {\n+  Semaphore post;\n+  TestQueue initial_queue;\n+  TestQueue start_queue;\n+  TestQueue middle_queue;\n+  TestQueue final_queue;\n+  volatile size_t stage1_processed = 0;\n+  volatile size_t stage2_processed = 0;\n+\n+  const size_t nelements = 10000;\n+  Element* elements = NEW_C_HEAP_ARRAY(Element, nelements, mtOther);\n+  for (size_t id = 0; id < nelements; ++id) {\n+    ::new (&elements[id]) Element(id);\n+    initial_queue.push(elements[id]);\n+  }\n+  ASSERT_EQ(nelements, initial_queue.length());\n+\n+  \/\/ - stage1 threads pop from start_queue and push to middle_queue.\n+  \/\/ - stage2 threads pop from middle_queue and push to final_queue.\n+  \/\/ - all threads in a stage count the number of elements processed in\n+  \/\/   their corresponding stageN_processed counter.\n+\n+  const uint stage1_threads = 2;\n+  const uint stage2_threads = 2;\n+  const uint nthreads = stage1_threads + stage2_threads;\n+  NonblockingQueueTestThread* threads[nthreads] = {};\n+\n+  for (uint i = 0; i < ARRAY_SIZE(threads); ++i) {\n+    TestQueue* from = &start_queue;\n+    TestQueue* to = &middle_queue;\n+    volatile size_t* processed = &stage1_processed;\n+    if (i >= stage1_threads) {\n+      from = &middle_queue;\n+      to = &final_queue;\n+      processed = &stage2_processed;\n+    }\n+    threads[i] =\n+      new NonblockingQueueTestThread(&post, i, from, to, processed, nelements);\n+    threads[i]->doit();\n+    while (!threads[i]->ready()) {} \/\/ Wait until ready to start test.\n+  }\n+\n+  \/\/ Transfer elements to start_queue to start test.\n+  Pair<Element*, Element*> pair = initial_queue.take_all();\n+  start_queue.append(*pair.first, *pair.second);\n+\n+  \/\/ Wait for all threads to complete.\n+  for (uint i = 0; i < nthreads; ++i) {\n+    post.wait();\n+  }\n+\n+  \/\/ Verify expected state.\n+  ASSERT_EQ(nelements, stage1_processed);\n+  ASSERT_EQ(nelements, stage2_processed);\n+  ASSERT_EQ(0u, initial_queue.length());\n+  ASSERT_EQ(0u, start_queue.length());\n+  ASSERT_EQ(0u, middle_queue.length());\n+  ASSERT_EQ(nelements, final_queue.length());\n+  while (final_queue.pop() != NULL) {}\n+\n+  FREE_C_HEAP_ARRAY(Element, elements);\n+}\n","filename":"test\/hotspot\/gtest\/utilities\/test_nonblockingQueue.cpp","additions":283,"deletions":0,"binary":false,"changes":283,"status":"added"}]}