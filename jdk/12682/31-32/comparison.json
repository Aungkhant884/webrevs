{"files":[{"patch":"@@ -1728,0 +1728,2 @@\n+  assert(is_integral_type(bt), \"unsupported element type\");\n+  assert(vm == Assembler::v0_t ? vd != v0 : true, \"should be different registers\");\n@@ -1730,1 +1732,0 @@\n-  assert(is_integral_type(bt), \"unsupported element type\");\n@@ -1746,3 +1747,2 @@\n-                                                 VectorRegister tmp1, VectorRegister tmp2, int cond, VectorMask vm) {\n-  rvv_vsetvli(bt, length_in_bytes);\n-  vmclr_m(vd);\n+                                                 VectorRegister tmp1, VectorRegister tmp2,\n+                                                 VectorRegister vmask, int cond, VectorMask vm) {\n@@ -1750,14 +1750,20 @@\n-  \/\/ vmfeq and vmfne raise the invalid operation exception\n-  \/\/ only on signaling NaN inputs.\n-  \/\/ vmflt, vmfle, vmfgt, and vmfge raise the invalid operation\n-  \/\/ exception on both signaling and quiet NaN inputs, so we should\n-  \/\/ mask the signaling compares when either input is NaN\n-  \/\/ to implement floating-point quiet compares.\n-  if (cond == BoolTest::le || cond == BoolTest::ge || cond == BoolTest::lt || cond == BoolTest::gt) {\n-    vmfeq_vv(tmp1, src1, src1);\n-    vmfeq_vv(tmp2, src2, src2);\n-    if (vm == Assembler::v0_t) {\n-      vmand_mm(tmp2, tmp1, tmp2);\n-      vmand_mm(v0, v0, tmp2);\n-    } else {\n-      vmand_mm(v0, tmp1, tmp2);\n+  assert(vd != v0, \"should be different registers\");\n+  assert(vm == Assembler::v0_t ? vmask != v0 : true, \"vmask should not be v0\");\n+  rvv_vsetvli(bt, length_in_bytes);\n+  \/\/ Check vector elements of src1 and src2 for quiet or signaling NaN.\n+  vfclass_v(tmp1, src1);\n+  vfclass_v(tmp2, src2);\n+  vsrl_vi(tmp1, tmp1, 8);\n+  vsrl_vi(tmp2, tmp2, 8);\n+  vmseq_vx(tmp1, tmp1, zr);\n+  vmseq_vx(tmp2, tmp2, zr);\n+  if (vm == Assembler::v0_t) {\n+    vmand_mm(tmp2, tmp1, tmp2);\n+    if (cond == BoolTest::ne) {\n+      vmandn_mm(tmp1, vmask, tmp2);\n+    }\n+    vmand_mm(v0, vmask, tmp2);\n+  } else {\n+    vmand_mm(v0, tmp1, tmp2);\n+    if (cond == BoolTest::ne) {\n+      vmnot_m(tmp1, v0);\n@@ -1766,0 +1772,1 @@\n+  vmclr_m(vd);\n@@ -1767,2 +1774,3 @@\n-    case BoolTest::eq: vmfeq_vv(vd, src1, src2, vm); break;\n-    case BoolTest::ne: vmfne_vv(vd, src1, src2, vm); break;\n+    case BoolTest::eq: vmfeq_vv(vd, src1, src2, Assembler::v0_t); break;\n+    case BoolTest::ne: vmfne_vv(vd, src1, src2, Assembler::v0_t);\n+                       vmor_mm(vd, vd, tmp1); break;\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":28,"deletions":20,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -208,1 +208,1 @@\n-                               int cond, VectorMask vm = Assembler::unmasked);\n+                               VectorRegister vmask, int cond, VectorMask vm = Assembler::unmasked);\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -931,5 +931,0 @@\n-\n-reg_class vmask_reg_no_v0 (\n-    V30,\n-    V31\n-);\n@@ -3659,1 +3654,0 @@\n-  match(vRegMaskNoV0);\n@@ -3666,10 +3660,0 @@\n-operand vRegMaskNoV0()\n-%{\n-  constraint(ALLOC_IN_RC(vmask_reg_no_v0));\n-  match(RegVectMask);\n-  match(vRegMask);\n-  op_cost(0);\n-  format %{ %}\n-  interface(REG_INTER);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":0,"deletions":16,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -179,3 +179,1 @@\n-\/\/ Exclude mask register v0 for 'dst' as compare_integral_v clears 'dst'\n-\/\/ register on entry before using mask value held in v0.\n-instruct vmaskcmp_masked(vRegMaskNoV0 dst, vReg src1, vReg src2, immI cond, vRegMask_V0 v0) %{\n+instruct vmaskcmp_masked(vRegMask dst, vReg src1, vReg src2, immI cond, vRegMask_V0 v0) %{\n@@ -187,0 +185,1 @@\n+  effect(TEMP_DEF dst);\n@@ -199,1 +198,1 @@\n-instruct vmaskcmp_fp(vRegMask dst, vReg src1, vReg src2, immI cond, vReg tmp1, vReg tmp2) %{\n+instruct vmaskcmp_fp(vRegMask dst, vReg src1, vReg src2, immI cond, vRegMask_V0 v0, vReg tmp1, vReg tmp2) %{\n@@ -203,2 +202,2 @@\n-  effect(TEMP tmp1, TEMP tmp2);\n-  format %{ \"vmaskcmp_fp $dst, $src1, $src2, $cond\" %}\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP v0);\n+  format %{ \"vmaskcmp_fp $dst, $src1, $src2, $cond\\t# KILL $tmp1, $tmp2\" %}\n@@ -211,1 +210,1 @@\n-                                (int)($cond$$constant));\n+                                as_VectorRegister($v0$$reg), (int)($cond$$constant));\n@@ -216,3 +215,1 @@\n-\/\/ Exclude mask register v0 for 'dst' as compare_floating_point_v clears 'dst'\n-\/\/ register on entry before using mask value held in v0.\n-instruct vmaskcmp_fp_masked(vRegMaskNoV0 dst, vReg src1, vReg src2, immI cond, vRegMask_V0 v0, vReg tmp1, vReg tmp2) %{\n+instruct vmaskcmp_fp_masked(vRegMask dst, vReg src1, vReg src2, immI cond, vRegMask vmask, vReg tmp1, vReg tmp2, vRegMask_V0 v0) %{\n@@ -221,3 +218,3 @@\n-  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond v0)));\n-  effect(TEMP tmp1, TEMP tmp2);\n-  format %{ \"vmaskcmp_fp_masked $dst, $src1, $src2, $cond, v0.t\\t# KILL $tmp1, $tmp2\" %}\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond vmask)));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP v0);\n+  format %{ \"vmaskcmp_fp_masked $dst, $src1, $src2, $cond, v0.t\\t# KILL $tmp1, $tmp2, $v0\" %}\n@@ -230,1 +227,1 @@\n-                                (int)($cond$$constant), Assembler::v0_t);\n+                                as_VectorRegister($vmask$$reg), (int)($cond$$constant), Assembler::v0_t);\n@@ -1525,2 +1522,2 @@\n-instruct vasrB_masked(vReg dst_src, vReg shift, vRegMask_V0 v0, vReg tmp) %{\n-  match(Set dst_src (RShiftVB (Binary dst_src shift) v0));\n+instruct vasrB_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (RShiftVB (Binary dst_src shift) vmask));\n@@ -1528,2 +1525,2 @@\n-  effect(TEMP_DEF dst_src, USE v0, TEMP tmp);\n-  format %{ \"vasrB_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $tmp\" %}\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vasrB_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $v0\" %}\n@@ -1531,1 +1528,0 @@\n-    __ vmv1r_v(as_VectorRegister($tmp$$reg), as_VectorRegister($v0$$reg));\n@@ -1537,1 +1533,1 @@\n-    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($tmp$$reg));\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n@@ -1544,2 +1540,2 @@\n-instruct vasrS_masked(vReg dst_src, vReg shift, vRegMask_V0 v0, vReg tmp) %{\n-  match(Set dst_src (RShiftVS (Binary dst_src shift) v0));\n+instruct vasrS_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (RShiftVS (Binary dst_src shift) vmask));\n@@ -1547,2 +1543,2 @@\n-  effect(TEMP_DEF dst_src, USE v0, TEMP tmp);\n-  format %{ \"vasrS_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $tmp\" %}\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vasrS_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $v0\" %}\n@@ -1550,1 +1546,0 @@\n-    __ vmv1r_v(as_VectorRegister($tmp$$reg), as_VectorRegister($v0$$reg));\n@@ -1556,1 +1551,1 @@\n-    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($tmp$$reg));\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n@@ -1651,2 +1646,2 @@\n-instruct vlslB_masked(vReg dst_src, vReg shift, vRegMask_V0 v0, vReg tmp) %{\n-  match(Set dst_src (LShiftVB (Binary dst_src shift) v0));\n+instruct vlslB_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (LShiftVB (Binary dst_src shift) vmask));\n@@ -1654,2 +1649,2 @@\n-  effect(TEMP_DEF dst_src, USE v0, TEMP tmp);\n-  format %{ \"vlslB_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $tmp\" %}\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlslB_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $v0\" %}\n@@ -1657,1 +1652,0 @@\n-    __ vmv1r_v(as_VectorRegister($tmp$$reg), as_VectorRegister($v0$$reg));\n@@ -1662,1 +1656,1 @@\n-                as_VectorRegister($tmp$$reg));\n+                as_VectorRegister($vmask$$reg));\n@@ -1666,1 +1660,1 @@\n-    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($tmp$$reg));\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n@@ -1673,2 +1667,2 @@\n-instruct vlslS_masked(vReg dst_src, vReg shift, vRegMask_V0 v0, vReg tmp) %{\n-  match(Set dst_src (LShiftVS (Binary dst_src shift) v0));\n+instruct vlslS_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (LShiftVS (Binary dst_src shift) vmask));\n@@ -1676,2 +1670,2 @@\n-  effect(TEMP_DEF dst_src, USE v0, TEMP tmp);\n-  format %{ \"vlslS_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $tmp\" %}\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlslS_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $v0\" %}\n@@ -1679,1 +1673,0 @@\n-    __ vmv1r_v(as_VectorRegister($tmp$$reg), as_VectorRegister($v0$$reg));\n@@ -1684,1 +1677,1 @@\n-                as_VectorRegister($tmp$$reg));\n+                as_VectorRegister($vmask$$reg));\n@@ -1688,1 +1681,1 @@\n-    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($tmp$$reg));\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n@@ -1783,2 +1776,2 @@\n-instruct vlsrB_masked(vReg dst_src, vReg shift, vRegMask_V0 v0, vReg tmp) %{\n-  match(Set dst_src (URShiftVB (Binary dst_src shift) v0));\n+instruct vlsrB_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (URShiftVB (Binary dst_src shift) vmask));\n@@ -1786,2 +1779,2 @@\n-  effect(TEMP_DEF dst_src, USE v0, TEMP tmp);\n-  format %{ \"vlsrB_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $tmp\" %}\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlsrB_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $v0\" %}\n@@ -1789,1 +1782,0 @@\n-    __ vmv1r_v(as_VectorRegister($tmp$$reg), as_VectorRegister($v0$$reg));\n@@ -1794,1 +1786,1 @@\n-                as_VectorRegister($tmp$$reg));\n+                as_VectorRegister($vmask$$reg));\n@@ -1798,1 +1790,1 @@\n-    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($tmp$$reg));\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n@@ -1805,2 +1797,2 @@\n-instruct vlsrS_masked(vReg dst_src, vReg shift, vRegMask_V0 v0, vReg tmp) %{\n-  match(Set dst_src (URShiftVS (Binary dst_src shift) v0));\n+instruct vlsrS_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (URShiftVS (Binary dst_src shift) vmask));\n@@ -1808,2 +1800,2 @@\n-  effect(TEMP_DEF dst_src, USE v0, TEMP tmp);\n-  format %{ \"vlsrS_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $tmp\" %}\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlsrS_masked $dst_src, $dst_src, $shift, v0.t\\t# KILL $v0\" %}\n@@ -1811,1 +1803,0 @@\n-    __ vmv1r_v(as_VectorRegister($tmp$$reg), as_VectorRegister($v0$$reg));\n@@ -1816,1 +1807,1 @@\n-                as_VectorRegister($tmp$$reg));\n+                as_VectorRegister($vmask$$reg));\n@@ -1820,1 +1811,1 @@\n-    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($tmp$$reg));\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":45,"deletions":54,"binary":false,"changes":99,"status":"modified"}]}