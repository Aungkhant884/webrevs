{"files":[{"patch":"@@ -1491,0 +1491,10 @@\n+#define INSN(NAME, op, funct3, vm, funct6)                                                         \\\n+  void NAME(VectorRegister Vd, VectorRegister Vs2, Register Rs1) {                                 \\\n+    patch_VArith(op, Vd, funct3, Rs1->raw_encoding(), Vs2, vm, funct6);                            \\\n+  }\n+\n+  \/\/ Vector Integer Merge Instructions\n+  INSN(vmerge_vxm,  0b1010111, 0b100, 0b0, 0b010111);\n+\n+#undef INSN\n+\n@@ -1545,0 +1555,11 @@\n+#define INSN(NAME, op, funct3, vm, funct6)                                    \\\n+  void NAME(VectorRegister Vd, VectorRegister Vs2, int32_t imm) {             \\\n+    guarantee(is_simm5(imm), \"imm is invalid\");                               \\\n+    patch_VArith(op, Vd, funct3, (uint32_t)(imm & 0x1f), Vs2, vm, funct6);    \\\n+  }\n+\n+  \/\/ Vector Integer Merge Instructions\n+  INSN(vmerge_vim,  0b1010111, 0b011, 0b0, 0b010111);\n+\n+#undef INSN\n+\n@@ -1563,0 +1584,3 @@\n+  \/\/ Vector Integer Merge Instructions\n+  INSN(vmerge_vvm,  0b1010111, 0b000, 0b0, 0b010111);\n+\n","filename":"src\/hotspot\/cpu\/riscv\/assembler_riscv.hpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -1307,1 +1307,1 @@\n-void C2_MacroAssembler::minmax_FD(FloatRegister dst, FloatRegister src1, FloatRegister src2,\n+void C2_MacroAssembler::minmax_fp(FloatRegister dst, FloatRegister src1, FloatRegister src2,\n@@ -1619,1 +1619,1 @@\n-void C2_MacroAssembler::minmax_FD_v(VectorRegister dst, VectorRegister src1, VectorRegister src2,\n+void C2_MacroAssembler::minmax_fp_v(VectorRegister dst, VectorRegister src1, VectorRegister src2,\n@@ -1635,1 +1635,1 @@\n-void C2_MacroAssembler::reduce_minmax_FD_v(FloatRegister dst,\n+void C2_MacroAssembler::reduce_minmax_fp_v(FloatRegister dst,\n@@ -1725,0 +1725,61 @@\n+\n+void C2_MacroAssembler::compare_integral_v(VectorRegister vd, BasicType bt, int length_in_bytes,\n+                                           VectorRegister src1, VectorRegister src2, int cond, VectorMask vm) {\n+  assert(is_integral_type(bt), \"unsupported element type\");\n+  assert(vm == Assembler::v0_t ? vd != v0 : true, \"should be different registers\");\n+  rvv_vsetvli(bt, length_in_bytes);\n+  vmclr_m(vd);\n+  switch (cond) {\n+    case BoolTest::eq: vmseq_vv(vd, src1, src2, vm); break;\n+    case BoolTest::ne: vmsne_vv(vd, src1, src2, vm); break;\n+    case BoolTest::le: vmsle_vv(vd, src1, src2, vm); break;\n+    case BoolTest::ge: vmsge_vv(vd, src1, src2, vm); break;\n+    case BoolTest::lt: vmslt_vv(vd, src1, src2, vm); break;\n+    case BoolTest::gt: vmsgt_vv(vd, src1, src2, vm); break;\n+    default:\n+      assert(false, \"unsupported compare condition\");\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+void C2_MacroAssembler::compare_floating_point_v(VectorRegister vd, BasicType bt, int length_in_bytes,\n+                                                 VectorRegister src1, VectorRegister src2,\n+                                                 VectorRegister tmp1, VectorRegister tmp2,\n+                                                 VectorRegister vmask, int cond, VectorMask vm) {\n+  assert(is_floating_point_type(bt), \"unsupported element type\");\n+  assert(vd != v0, \"should be different registers\");\n+  assert(vm == Assembler::v0_t ? vmask != v0 : true, \"vmask should not be v0\");\n+  rvv_vsetvli(bt, length_in_bytes);\n+  \/\/ Check vector elements of src1 and src2 for quiet or signaling NaN.\n+  vfclass_v(tmp1, src1);\n+  vfclass_v(tmp2, src2);\n+  vsrl_vi(tmp1, tmp1, 8);\n+  vsrl_vi(tmp2, tmp2, 8);\n+  vmseq_vx(tmp1, tmp1, zr);\n+  vmseq_vx(tmp2, tmp2, zr);\n+  if (vm == Assembler::v0_t) {\n+    vmand_mm(tmp2, tmp1, tmp2);\n+    if (cond == BoolTest::ne) {\n+      vmandn_mm(tmp1, vmask, tmp2);\n+    }\n+    vmand_mm(v0, vmask, tmp2);\n+  } else {\n+    vmand_mm(v0, tmp1, tmp2);\n+    if (cond == BoolTest::ne) {\n+      vmnot_m(tmp1, v0);\n+    }\n+  }\n+  vmclr_m(vd);\n+  switch (cond) {\n+    case BoolTest::eq: vmfeq_vv(vd, src1, src2, Assembler::v0_t); break;\n+    case BoolTest::ne: vmfne_vv(vd, src1, src2, Assembler::v0_t);\n+                       vmor_mm(vd, vd, tmp1); break;\n+    case BoolTest::le: vmfle_vv(vd, src1, src2, Assembler::v0_t); break;\n+    case BoolTest::ge: vmfge_vv(vd, src1, src2, Assembler::v0_t); break;\n+    case BoolTest::lt: vmflt_vv(vd, src1, src2, Assembler::v0_t); break;\n+    case BoolTest::gt: vmfgt_vv(vd, src1, src2, Assembler::v0_t); break;\n+    default:\n+      assert(false, \"unsupported compare condition\");\n+      ShouldNotReachHere();\n+  }\n+}\n\\ No newline at end of file\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.cpp","additions":64,"deletions":3,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -140,4 +140,6 @@\n-  void spill_copy_vector_stack_to_stack(int src_offset, int dst_offset, int vec_reg_size_in_bytes) {\n-    assert(vec_reg_size_in_bytes % 16 == 0, \"unexpected vector reg size\");\n-    unspill(v0, src_offset);\n-    spill(v0, dst_offset);\n+  void spill_copy_vector_stack_to_stack(int src_offset, int dst_offset, int vector_length_in_bytes) {\n+    assert(vector_length_in_bytes % 16 == 0, \"unexpected vector reg size\");\n+    for (int i = 0; i < vector_length_in_bytes \/ 8; i++) {\n+      unspill(t0, true, src_offset + (i * 8));\n+      spill(t0, true, dst_offset + (i * 8));\n+    }\n@@ -146,1 +148,1 @@\n-  void minmax_FD(FloatRegister dst,\n+  void minmax_fp(FloatRegister dst,\n@@ -186,1 +188,1 @@\n- void minmax_FD_v(VectorRegister dst,\n+ void minmax_fp_v(VectorRegister dst,\n@@ -190,1 +192,1 @@\n- void reduce_minmax_FD_v(FloatRegister dst,\n+ void reduce_minmax_fp_v(FloatRegister dst,\n@@ -201,0 +203,30 @@\n+ void compare_integral_v(VectorRegister dst, BasicType bt, int length_in_bytes,\n+                         VectorRegister src1, VectorRegister src2, int cond, VectorMask vm = Assembler::unmasked);\n+\n+ void compare_floating_point_v(VectorRegister dst, BasicType bt, int length_in_bytes,\n+                               VectorRegister src1, VectorRegister src2, VectorRegister tmp1, VectorRegister tmp2,\n+                               VectorRegister vmask, int cond, VectorMask vm = Assembler::unmasked);\n+\n+ \/\/ In Matcher::scalable_predicate_reg_slots,\n+ \/\/ we assume each predicate register is one-eighth of the size of\n+ \/\/ scalable vector register, one mask bit per vector byte.\n+ void spill_vmask(VectorRegister v, int offset){\n+   rvv_vsetvli(T_BYTE, MaxVectorSize >> 3);\n+   add(t0, sp, offset);\n+   vse8_v(v, t0);\n+ }\n+\n+ void unspill_vmask(VectorRegister v, int offset){\n+   rvv_vsetvli(T_BYTE, MaxVectorSize >> 3);\n+   add(t0, sp, offset);\n+   vle8_v(v, t0);\n+ }\n+\n+  void spill_copy_vmask_stack_to_stack(int src_offset, int dst_offset, int vector_length_in_bytes) {\n+    assert(vector_length_in_bytes % 4 == 0, \"unexpected vector mask reg size\");\n+    for (int i = 0; i < vector_length_in_bytes \/ 4; i++) {\n+      unspill(t0, false, src_offset + (i * 4));\n+      spill(t0, false, dst_offset + (i * 4));\n+    }\n+  }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/c2_MacroAssembler_riscv.hpp","additions":39,"deletions":7,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -1267,1 +1267,1 @@\n-  inline void vncvt_x_x_w(VectorRegister vd, VectorRegister vs, VectorMask vm) {\n+  inline void vncvt_x_x_w(VectorRegister vd, VectorRegister vs, VectorMask vm = unmasked) {\n@@ -1279,0 +1279,39 @@\n+  inline void vmsgt_vv(VectorRegister vd, VectorRegister vs2, VectorRegister vs1, VectorMask vm = unmasked) {\n+    vmslt_vv(vd, vs1, vs2, vm);\n+  }\n+\n+  inline void vmsgtu_vv(VectorRegister vd, VectorRegister vs2, VectorRegister vs1, VectorMask vm = unmasked) {\n+    vmsltu_vv(vd, vs1, vs2, vm);\n+  }\n+\n+  inline void vmsge_vv(VectorRegister vd, VectorRegister vs2, VectorRegister vs1, VectorMask vm = unmasked) {\n+    vmsle_vv(vd, vs1, vs2, vm);\n+  }\n+\n+  inline void vmsgeu_vv(VectorRegister vd, VectorRegister vs2, VectorRegister vs1, VectorMask vm = unmasked) {\n+    vmsleu_vv(vd, vs1, vs2, vm);\n+  }\n+\n+  inline void vmfgt_vv(VectorRegister vd, VectorRegister vs2, VectorRegister vs1, VectorMask vm = unmasked) {\n+    vmflt_vv(vd, vs1, vs2, vm);\n+  }\n+\n+  inline void vmfge_vv(VectorRegister vd, VectorRegister vs2, VectorRegister vs1, VectorMask vm = unmasked) {\n+    vmfle_vv(vd, vs1, vs2, vm);\n+  }\n+\n+  \/\/ Copy mask register\n+  inline void vmmv_m(VectorRegister vd, VectorRegister vs) {\n+    vmand_mm(vd, vs, vs);\n+  }\n+\n+  \/\/ Clear mask register\n+  inline void vmclr_m(VectorRegister vd) {\n+    vmxor_mm(vd, vd, vd);\n+  }\n+\n+  \/\/ Set mask register\n+  inline void vmset_m(VectorRegister vd) {\n+    vmxnor_mm(vd, vd, vd);\n+  }\n+\n","filename":"src\/hotspot\/cpu\/riscv\/macroAssembler_riscv.hpp","additions":40,"deletions":1,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -152,1 +152,1 @@\n-    return false;\n+    return UseRVV;\n","filename":"src\/hotspot\/cpu\/riscv\/matcher_riscv.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -833,1 +833,2 @@\n-\/\/ Class for all RVV vector registers\n+\/\/ Class for RVV vector registers\n+\/\/ Note: v0, v30 and v31 are used as mask registers.\n@@ -863,3 +864,1 @@\n-    V29, V29_H, V29_J, V29_K,\n-    V30, V30_H, V30_J, V30_K,\n-    V31, V31_H, V31_J, V31_K\n+    V29, V29_H, V29_J, V29_K\n@@ -915,0 +914,17 @@\n+\n+\/\/ Class for RVV v0 mask register\n+\/\/ https:\/\/github.com\/riscv\/riscv-v-spec\/blob\/master\/v-spec.adoc#53-vector-masking\n+\/\/ The mask value used to control execution of a masked vector\n+\/\/ instruction is always supplied by vector register v0.\n+reg_class vmask_reg_v0 (\n+    V0\n+);\n+\n+\/\/ Class for RVV mask registers\n+\/\/ We need two more vmask registers to do the vector mask logical ops,\n+\/\/ so define v30, v31 as mask register too.\n+reg_class vmask_reg (\n+    V0,\n+    V30,\n+    V31\n+);\n@@ -1525,1 +1541,1 @@\n-  if (src_hi != OptoReg::Bad) {\n+  if (src_hi != OptoReg::Bad && !bottom_type()->isa_vectmask()) {\n@@ -1561,0 +1577,19 @@\n+    } else if (bottom_type()->isa_vectmask() && cbuf) {\n+      C2_MacroAssembler _masm(cbuf);\n+      int vmask_size_in_bytes = Matcher::scalable_predicate_reg_slots() * 32 \/ 8;\n+      if (src_lo_rc == rc_stack && dst_lo_rc == rc_stack) {\n+        \/\/ stack to stack\n+        __ spill_copy_vmask_stack_to_stack(src_offset, dst_offset,\n+                                           vmask_size_in_bytes);\n+      } else if (src_lo_rc == rc_vector && dst_lo_rc == rc_stack) {\n+        \/\/ vmask to stack\n+        __ spill_vmask(as_VectorRegister(Matcher::_regEncode[src_lo]), ra_->reg2offset(dst_lo));\n+      } else if (src_lo_rc == rc_stack && dst_lo_rc == rc_vector) {\n+        \/\/ stack to vmask\n+        __ unspill_vmask(as_VectorRegister(Matcher::_regEncode[dst_lo]), ra_->reg2offset(src_lo));\n+      } else if (src_lo_rc == rc_vector && dst_lo_rc == rc_vector) {\n+        \/\/ vmask to vmask\n+        __ vmv1r_v(as_VectorRegister(Matcher::_regEncode[dst_lo]), as_VectorRegister(Matcher::_regEncode[src_lo]));\n+      } else {\n+        ShouldNotReachHere();\n+      }\n@@ -1645,1 +1680,1 @@\n-    if (bottom_type()->isa_vect() != NULL) {\n+    if (bottom_type()->isa_vect() && !bottom_type()->isa_vectmask()) {\n@@ -1653,0 +1688,4 @@\n+    } else if (ideal_reg() == Op_RegVectMask) {\n+      assert(Matcher::supports_scalable_vector(), \"bad register type for spill\");\n+      int vsize = Matcher::scalable_predicate_reg_slots() * 32;\n+      st->print(\"\\t# vmask spill size = %d\", vsize);\n@@ -1866,1 +1905,53 @@\n-  return false;\n+  if (!UseRVV) {\n+    return false;\n+  }\n+  switch (opcode) {\n+    case Op_AddVB:\n+    case Op_AddVS:\n+    case Op_AddVI:\n+    case Op_AddVL:\n+    case Op_AddVF:\n+    case Op_AddVD:\n+    case Op_SubVB:\n+    case Op_SubVS:\n+    case Op_SubVI:\n+    case Op_SubVL:\n+    case Op_SubVF:\n+    case Op_SubVD:\n+    case Op_MulVB:\n+    case Op_MulVS:\n+    case Op_MulVI:\n+    case Op_MulVL:\n+    case Op_MulVF:\n+    case Op_MulVD:\n+    case Op_DivVF:\n+    case Op_DivVD:\n+    case Op_VectorLoadMask:\n+    case Op_VectorMaskCmp:\n+    case Op_AndVMask:\n+    case Op_XorVMask:\n+    case Op_OrVMask:\n+    case Op_RShiftVB:\n+    case Op_RShiftVS:\n+    case Op_RShiftVI:\n+    case Op_RShiftVL:\n+    case Op_LShiftVB:\n+    case Op_LShiftVS:\n+    case Op_LShiftVI:\n+    case Op_LShiftVL:\n+    case Op_URShiftVB:\n+    case Op_URShiftVS:\n+    case Op_URShiftVI:\n+    case Op_URShiftVL:\n+    case Op_VectorBlend:\n+      break;\n+    case Op_LoadVector:\n+      opcode = Op_LoadVectorMasked;\n+      break;\n+    case Op_StoreVector:\n+      opcode = Op_StoreVectorMasked;\n+      break;\n+    default:\n+      return false;\n+  }\n+  return match_rule_supported_vector(opcode, vlen, bt);\n@@ -1878,1 +1969,1 @@\n-  return NULL;\n+  return &_VMASK_REG_mask;\n@@ -1882,1 +1973,1 @@\n-  return NULL;\n+  return new TypeVectMask(elemTy, length);\n@@ -3559,0 +3650,22 @@\n+operand vRegMask()\n+%{\n+  constraint(ALLOC_IN_RC(vmask_reg));\n+  match(RegVectMask);\n+  match(vRegMask_V0);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n+\/\/ The mask value used to control execution of a masked\n+\/\/ vector instruction is always supplied by vector register v0.\n+operand vRegMask_V0()\n+%{\n+  constraint(ALLOC_IN_RC(vmask_reg_v0));\n+  match(RegVectMask);\n+  match(vRegMask);\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n@@ -7274,1 +7387,1 @@\n-    __ minmax_FD(as_FloatRegister($dst$$reg),\n+    __ minmax_fp(as_FloatRegister($dst$$reg),\n@@ -7290,1 +7403,1 @@\n-    __ minmax_FD(as_FloatRegister($dst$$reg),\n+    __ minmax_fp(as_FloatRegister($dst$$reg),\n@@ -7306,1 +7419,1 @@\n-    __ minmax_FD(as_FloatRegister($dst$$reg),\n+    __ minmax_fp(as_FloatRegister($dst$$reg),\n@@ -7322,1 +7435,1 @@\n-    __ minmax_FD(as_FloatRegister($dst$$reg),\n+    __ minmax_fp(as_FloatRegister($dst$$reg),\n","filename":"src\/hotspot\/cpu\/riscv\/riscv.ad","additions":126,"deletions":13,"binary":false,"changes":139,"status":"modified"},{"patch":"@@ -38,1 +38,2 @@\n-                        VectorRegister reg, BasicType bt, Register base, int length_in_bytes) {\n+                        VectorRegister reg, BasicType bt, Register base,\n+                        int length_in_bytes, Assembler::VectorMask vm = Assembler::unmasked) {\n@@ -43,1 +44,1 @@\n-      masm.vsex_v(reg, base, sew);\n+      masm.vsex_v(reg, base, sew, vm);\n@@ -45,1 +46,4 @@\n-      masm.vlex_v(reg, base, sew);\n+      if (vm == Assembler::v0_t) {\n+        masm.vxor_vv(reg, reg, reg);\n+      }\n+      masm.vlex_v(reg, base, sew, vm);\n@@ -69,1 +73,0 @@\n-      case Op_VectorBlend:\n@@ -78,1 +81,0 @@\n-      case Op_VectorLoadMask:\n@@ -80,1 +82,0 @@\n-      case Op_VectorMaskCmp:\n@@ -83,1 +84,0 @@\n-      case Op_VectorStoreMask:\n@@ -126,0 +126,106 @@\n+\/\/ vector load mask\n+\n+instruct vloadmask(vRegMask dst, vReg src) %{\n+  match(Set dst (VectorLoadMask src));\n+  format %{ \"vloadmask $dst, $src\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_BOOLEAN, Matcher::vector_length(this));\n+    __ vmsne_vx(as_VectorRegister($dst$$reg), as_VectorRegister($src$$reg), zr);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_masked(vRegMask dst, vReg src, vRegMask_V0 v0) %{\n+  match(Set dst (VectorLoadMask src v0));\n+  format %{ \"vloadmask_masked $dst, $src, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_BOOLEAN, Matcher::vector_length(this));\n+    __ vmsne_vx(as_VectorRegister($dst$$reg), as_VectorRegister($src$$reg), zr, Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask\n+\n+instruct vstoremask(vReg dst, vRegMask_V0 v0, immI size) %{\n+  match(Set dst (VectorStoreMask v0 size));\n+  format %{ \"vstoremask $dst, V0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_BOOLEAN, Matcher::vector_length(this));\n+    __ vmv_v_x(as_VectorRegister($dst$$reg), zr);\n+    __ vmerge_vim(as_VectorRegister($dst$$reg), as_VectorRegister($dst$$reg), 1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp(vRegMask dst, vReg src1, vReg src2, immI cond) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE ||\n+            Matcher::vector_element_basic_type(n) == T_SHORT ||\n+            Matcher::vector_element_basic_type(n) == T_INT ||\n+            Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  format %{ \"vmaskcmp $dst, $src1, $src2, $cond\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ compare_integral_v(as_VectorRegister($dst$$reg), bt, length_in_bytes, as_VectorRegister($src1$$reg),\n+                          as_VectorRegister($src2$$reg), (int)($cond$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcmp_masked(vRegMask dst, vReg src1, vReg src2, immI cond, vRegMask_V0 v0) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE ||\n+            Matcher::vector_element_basic_type(n) == T_SHORT ||\n+            Matcher::vector_element_basic_type(n) == T_INT ||\n+            Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond v0)));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vmaskcmp_masked $dst, $src1, $src2, $cond, $v0\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ compare_integral_v(as_VectorRegister($dst$$reg), bt, length_in_bytes, as_VectorRegister($src1$$reg),\n+                          as_VectorRegister($src2$$reg), (int)($cond$$constant), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask float compare\n+\n+instruct vmaskcmp_fp(vRegMask dst, vReg src1, vReg src2, immI cond, vRegMask_V0 v0, vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_FLOAT ||\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP v0);\n+  format %{ \"vmaskcmp_fp $dst, $src1, $src2, $cond\\t# KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ compare_floating_point_v(as_VectorRegister($dst$$reg), bt, length_in_bytes,\n+                                as_VectorRegister($src1$$reg), as_VectorRegister($src2$$reg),\n+                                as_VectorRegister($tmp1$$reg), as_VectorRegister($tmp2$$reg),\n+                                as_VectorRegister($v0$$reg), (int)($cond$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcmp_fp_masked(vRegMask dst, vReg src1, vReg src2, immI cond, vRegMask vmask, vReg tmp1, vReg tmp2, vRegMask_V0 v0) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_FLOAT ||\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond vmask)));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP v0);\n+  format %{ \"vmaskcmp_fp_masked $dst, $src1, $src2, $cond, $vmask\\t# KILL $tmp1, $tmp2, $v0\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ compare_floating_point_v(as_VectorRegister($dst$$reg), bt, length_in_bytes,\n+                                as_VectorRegister($src1$$reg), as_VectorRegister($src2$$reg),\n+                                as_VectorRegister($tmp1$$reg), as_VectorRegister($tmp2$$reg),\n+                                as_VectorRegister($vmask$$reg), (int)($cond$$constant), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -286,0 +392,34 @@\n+\/\/ vector add - predicated\n+\n+instruct vadd_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (AddVB (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (AddVS (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (AddVI (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (AddVL (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vadd.vv $dst_src1, $src2, $v0\\t#@vadd_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vadd_vv(as_VectorRegister($dst_src1$$reg),\n+               as_VectorRegister($dst_src1$$reg),\n+               as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vadd_fp_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (AddVF (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (AddVD (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vfadd.vv $dst_src1, $src2, $v0\\t#@vadd_fp_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vfadd_vv(as_VectorRegister($dst_src1$$reg),\n+                as_VectorRegister($dst_src1$$reg),\n+                as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -293,1 +433,2 @@\n-    __ rvv_vsetvli(T_LONG, Matcher::vector_length_in_bytes(this));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n@@ -308,1 +449,2 @@\n-    __ rvv_vsetvli(T_LONG, Matcher::vector_length_in_bytes(this));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n@@ -323,1 +465,2 @@\n-    __ rvv_vsetvli(T_LONG, Matcher::vector_length_in_bytes(this));\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n@@ -359,0 +502,17 @@\n+\/\/ vector float div - predicated\n+\n+instruct vdiv_fp_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (DivVF (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (DivVD (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vfdiv.vv  $dst_src1, $src2, $v0\\t#@vdiv_fp_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vfdiv_vv(as_VectorRegister($dst_src1$$reg),\n+                as_VectorRegister($dst_src1$$reg),\n+                as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -400,1 +560,1 @@\n-    __ minmax_FD_v(as_VectorRegister($dst$$reg),\n+    __ minmax_fp_v(as_VectorRegister($dst$$reg),\n@@ -414,1 +574,1 @@\n-    __ minmax_FD_v(as_VectorRegister($dst$$reg),\n+    __ minmax_fp_v(as_VectorRegister($dst$$reg),\n@@ -428,1 +588,1 @@\n-    __ minmax_FD_v(as_VectorRegister($dst$$reg),\n+    __ minmax_fp_v(as_VectorRegister($dst$$reg),\n@@ -442,1 +602,1 @@\n-    __ minmax_FD_v(as_VectorRegister($dst$$reg),\n+    __ minmax_fp_v(as_VectorRegister($dst$$reg),\n@@ -759,0 +919,32 @@\n+\/\/ vector mul - predicated\n+\n+instruct vmul_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (MulVB (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (MulVS (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (MulVI (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (MulVL (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vmul.vv $dst_src1, $src2, $v0\\t#@vmul_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmul_vv(as_VectorRegister($dst_src1$$reg), as_VectorRegister($dst_src1$$reg),\n+               as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmul_fp_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (MulVF (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (MulVD (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vmul.vv $dst_src1, $src2, $v0\\t#@vmul_fp_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vfmul_vv(as_VectorRegister($dst_src1$$reg), as_VectorRegister($dst_src1$$reg),\n+                as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -1003,1 +1195,1 @@\n-  format %{ \"vreduce_maxI $dst, $src1, $src2, $tmp\" %}\n+  format %{ \"vreduce_maxI $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -1018,1 +1210,1 @@\n-  format %{ \"vreduce_maxL $dst, $src1, $src2, $tmp\" %}\n+  format %{ \"vreduce_maxL $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -1037,1 +1229,1 @@\n-  format %{ \"vreduce_minI $dst, $src1, $src2, $tmp\" %}\n+  format %{ \"vreduce_minI $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -1052,1 +1244,1 @@\n-  format %{ \"vreduce_minL $dst, $src1, $src2, $tmp\" %}\n+  format %{ \"vreduce_minL $dst, $src1, $src2\\t# KILL $tmp\" %}\n@@ -1071,1 +1263,1 @@\n-    __ reduce_minmax_FD_v($dst$$FloatRegister,\n+    __ reduce_minmax_fp_v($dst$$FloatRegister,\n@@ -1086,1 +1278,1 @@\n-    __ reduce_minmax_FD_v($dst$$FloatRegister,\n+    __ reduce_minmax_fp_v($dst$$FloatRegister,\n@@ -1103,1 +1295,1 @@\n-    __ reduce_minmax_FD_v($dst$$FloatRegister,\n+    __ reduce_minmax_fp_v($dst$$FloatRegister,\n@@ -1118,1 +1310,1 @@\n-    __ reduce_minmax_FD_v($dst$$FloatRegister,\n+    __ reduce_minmax_fp_v($dst$$FloatRegister,\n@@ -1268,1 +1460,1 @@\n-instruct vasrB(vReg dst, vReg src, vReg shift) %{\n+instruct vasrB(vReg dst, vReg src, vReg shift, vRegMask_V0 v0) %{\n@@ -1271,5 +1463,2 @@\n-  effect(TEMP_DEF dst);\n-  format %{ \"vmsgtu.vi v0, $shift 7\\t#@vasrB\\n\\t\"\n-            \"vsra.vi $dst, $src, 7, Assembler::v0_t\\n\\t\"\n-            \"vmnot.m v0, v0\\n\\t\"\n-            \"vsra.vv $dst, $src, $shift, Assembler::v0_t\" %}\n+  effect(TEMP_DEF dst, TEMP v0);\n+  format %{ \"vasrB $dst, $src, $shift\" %}\n@@ -1279,1 +1468,1 @@\n-    __ vmsgtu_vi(v0, as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n@@ -1283,1 +1472,1 @@\n-    __ vmnot_m(v0, v0);\n+    __ vmnot_m(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg));\n@@ -1290,1 +1479,1 @@\n-instruct vasrS(vReg dst, vReg src, vReg shift) %{\n+instruct vasrS(vReg dst, vReg src, vReg shift, vRegMask_V0 v0) %{\n@@ -1293,5 +1482,2 @@\n-  effect(TEMP_DEF dst);\n-  format %{ \"vmsgtu.vi v0, $shift, 15\\t#@vasrS\\n\\t\"\n-            \"vsra.vi $dst, $src, 15, Assembler::v0_t\\n\\t\"\n-            \"vmnot.m v0, v0\\n\\t\"\n-            \"vsra.vv $dst, $src, $shift, Assembler::v0_t\" %}\n+  effect(TEMP_DEF dst, TEMP v0);\n+  format %{ \"vasrS $dst, $src, $shift\" %}\n@@ -1301,1 +1487,1 @@\n-    __ vmsgtu_vi(v0, as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n@@ -1305,1 +1491,1 @@\n-    __ vmnot_m(v0, v0);\n+    __ vmnot_m(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg));\n@@ -1315,1 +1501,1 @@\n-  format %{ \"vsra.vv $dst, $src, $shift\\t#@vasrI\" %}\n+  format %{ \"vasrI $dst, $src, $shift\" %}\n@@ -1327,1 +1513,1 @@\n-  format %{ \"vsra.vv $dst, $src, $shift\\t#@vasrL\" %}\n+  format %{ \"vasrL $dst, $src, $shift\" %}\n@@ -1331,1 +1517,1 @@\n-         as_VectorRegister($shift$$reg));\n+               as_VectorRegister($shift$$reg));\n@@ -1336,1 +1522,63 @@\n-instruct vlslB(vReg dst, vReg src, vReg shift) %{\n+instruct vasrB_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (RShiftVB (Binary dst_src shift) vmask));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vasrB_masked $dst_src, $dst_src, $shift, $vmask\\t# KILL $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_BYTE, Matcher::vector_length_in_bytes(this));\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    \/\/ if shift > BitsPerByte - 1, clear the low BitsPerByte - 1 bits\n+    __ vmerge_vim(as_VectorRegister($shift$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    \/\/ otherwise, shift\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n+    __ vsra_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrS_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (RShiftVS (Binary dst_src shift) vmask));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vasrS_masked $dst_src, $dst_src, $shift, $vmask\\t# KILL $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_SHORT, Matcher::vector_length_in_bytes(this));\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    \/\/ if shift > BitsPerShort - 1, clear the low BitsPerShort - 1 bits\n+    __ vmerge_vim(as_VectorRegister($shift$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    \/\/ otherwise, shift\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n+    __ vsra_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrI_masked(vReg dst_src, vReg shift, vRegMask_V0 v0) %{\n+  match(Set dst_src (RShiftVI (Binary dst_src shift) v0));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src);\n+  format %{ \"vasrI_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_INT, Matcher::vector_length_in_bytes(this));\n+    __ vsra_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasrL_masked(vReg dst_src, vReg shift, vRegMask_V0 v0) %{\n+  match(Set dst_src (RShiftVL (Binary dst_src shift) v0));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src);\n+  format %{ \"vasrL_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_LONG, Matcher::vector_length_in_bytes(this));\n+    __ vsra_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslB(vReg dst, vReg src, vReg shift, vRegMask_V0 v0) %{\n@@ -1339,5 +1587,2 @@\n-  effect( TEMP_DEF dst);\n-  format %{ \"vmsgtu.vi v0, $shift, 7\\t#@vlslB\\n\\t\"\n-            \"vxor.vv $dst, $src, $src, Assembler::v0_t\\n\\t\"\n-            \"vmnot.m v0, v0\\n\\t\"\n-            \"vsll.vv $dst, $src, $shift, Assembler::v0_t\" %}\n+  effect(TEMP_DEF dst, TEMP v0);\n+  format %{ \"vlslB $dst, $src, $shift\" %}\n@@ -1347,1 +1592,1 @@\n-    __ vmsgtu_vi(v0, as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n@@ -1351,1 +1596,1 @@\n-    __ vmnot_m(v0, v0);\n+    __ vmnot_m(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg));\n@@ -1358,1 +1603,1 @@\n-instruct vlslS(vReg dst, vReg src, vReg shift) %{\n+instruct vlslS(vReg dst, vReg src, vReg shift, vRegMask_V0 v0) %{\n@@ -1361,5 +1606,2 @@\n-  effect(TEMP_DEF dst);\n-  format %{ \"vmsgtu.vi v0, $shift, 15\\t#@vlslS\\n\\t\"\n-            \"vxor.vv $dst, $src, $src, Assembler::v0_t\\n\\t\"\n-            \"vmnot.m v0, v0\\n\\t\"\n-            \"vsll.vv $dst, $src, $shift, Assembler::v0_t\" %}\n+  effect(TEMP_DEF dst, TEMP v0);\n+  format %{ \"vlslS $dst, $src, $shift\" %}\n@@ -1369,1 +1611,1 @@\n-    __ vmsgtu_vi(v0, as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n@@ -1373,1 +1615,1 @@\n-    __ vmnot_m(v0, v0);\n+    __ vmnot_m(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg));\n@@ -1383,1 +1625,1 @@\n-  format %{ \"vsll.vv $dst, $src, $shift\\t#@vlslI\" %}\n+  format %{ \"vlslI $dst, $src, $shift\" %}\n@@ -1395,1 +1637,1 @@\n-  format %{ \"vsll.vv $dst, $src, $shift\\t# vector (D)\" %}\n+  format %{ \"vlslL $dst, $src, $shift\" %}\n@@ -1404,1 +1646,69 @@\n-instruct vlsrB(vReg dst, vReg src, vReg shift) %{\n+instruct vlslB_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (LShiftVB (Binary dst_src shift) vmask));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlslB_masked $dst_src, $dst_src, $shift, $vmask\\t# KILL $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_BYTE, Matcher::vector_length_in_bytes(this));\n+    \/\/ if shift > BitsPerByte - 1, clear the element\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    __ vmand_mm(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg),\n+                as_VectorRegister($vmask$$reg));\n+    __ vxor_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($dst_src$$reg), Assembler::v0_t);\n+    \/\/ otherwise, shift\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n+    __ vsll_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslS_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (LShiftVS (Binary dst_src shift) vmask));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlslS_masked $dst_src, $dst_src, $shift, $vmask\\t# KILL $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_SHORT, Matcher::vector_length_in_bytes(this));\n+    \/\/ if shift > BitsPerShort - 1, clear the element\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    __ vmand_mm(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg),\n+                as_VectorRegister($vmask$$reg));\n+    __ vxor_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($dst_src$$reg), Assembler::v0_t);\n+    \/\/ otherwise, shift\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n+    __ vsll_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslI_masked(vReg dst_src, vReg shift, vRegMask_V0 v0) %{\n+  match(Set dst_src (LShiftVI (Binary dst_src shift) v0));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src);\n+  format %{ \"vlslI_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_INT, Matcher::vector_length_in_bytes(this));\n+    __ vsll_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlslL_masked(vReg dst_src, vReg shift, vRegMask_V0 v0) %{\n+  match(Set dst_src (LShiftVL (Binary dst_src shift) v0));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src);\n+  format %{ \"vlslL_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_LONG, Matcher::vector_length_in_bytes(this));\n+    __ vsll_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrB(vReg dst, vReg src, vReg shift, vRegMask_V0 v0) %{\n@@ -1407,5 +1717,2 @@\n-  effect(TEMP_DEF dst);\n-  format %{ \"vmsgtu.vi v0, $shift, 7\\t#@vlsrB\\n\\t\"\n-            \"vxor.vv $dst, $src, $src, Assembler::v0_t\\n\\t\"\n-            \"vmnot.m v0, v0, v0\\n\\t\"\n-            \"vsll.vv $dst, $src, $shift, Assembler::v0_t\" %}\n+  effect(TEMP_DEF dst, TEMP v0);\n+  format %{ \"vlsrB $dst, $src, $shift\" %}\n@@ -1415,1 +1722,1 @@\n-    __ vmsgtu_vi(v0, as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n@@ -1419,1 +1726,1 @@\n-    __ vmnot_m(v0, v0);\n+    __ vmnot_m(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg));\n@@ -1426,1 +1733,1 @@\n-instruct vlsrS(vReg dst, vReg src, vReg shift) %{\n+instruct vlsrS(vReg dst, vReg src, vReg shift, vRegMask_V0 v0) %{\n@@ -1429,5 +1736,2 @@\n-  effect(TEMP_DEF dst);\n-  format %{ \"vmsgtu.vi v0, $shift, 15\\t#@vlsrS\\n\\t\"\n-            \"vxor.vv $dst, $src, $src, Assembler::v0_t\\n\\t\"\n-            \"vmnot.m v0, v0\\n\\t\"\n-            \"vsll.vv $dst, $src, $shift, Assembler::v0_t\" %}\n+  effect(TEMP_DEF dst, TEMP v0);\n+  format %{ \"vlsrS $dst, $src, $shift\" %}\n@@ -1437,1 +1741,1 @@\n-    __ vmsgtu_vi(v0, as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n@@ -1441,1 +1745,1 @@\n-    __ vmnot_m(v0, v0);\n+    __ vmnot_m(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg));\n@@ -1448,1 +1752,0 @@\n-\n@@ -1452,1 +1755,1 @@\n-  format %{ \"vsrl.vv $dst, $src, $shift\\t#@vlsrI\" %}\n+  format %{ \"vlsrI $dst, $src, $shift\" %}\n@@ -1461,1 +1764,0 @@\n-\n@@ -1465,1 +1767,1 @@\n-  format %{ \"vsrl.vv $dst, $src, $shift\\t#@vlsrL\" %}\n+  format %{ \"vlsrL $dst, $src, $shift\" %}\n@@ -1474,0 +1776,68 @@\n+instruct vlsrB_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (URShiftVB (Binary dst_src shift) vmask));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlsrB_masked $dst_src, $dst_src, $shift, $vmask\\t# KILL $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_BYTE, Matcher::vector_length_in_bytes(this));\n+    \/\/ if shift > BitsPerByte - 1, clear the element\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerByte - 1);\n+    __ vmand_mm(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg),\n+                as_VectorRegister($vmask$$reg));\n+    __ vxor_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($dst_src$$reg), Assembler::v0_t);\n+    \/\/ otherwise, shift\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n+    __ vsrl_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrS_masked(vReg dst_src, vReg shift, vRegMask vmask, vRegMask_V0 v0) %{\n+  match(Set dst_src (URShiftVS (Binary dst_src shift) vmask));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src, TEMP v0);\n+  format %{ \"vlsrS_masked $dst_src, $dst_src, $shift, $vmask\\t# KILL $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_SHORT, Matcher::vector_length_in_bytes(this));\n+    \/\/ if shift > BitsPerShort - 1, clear the element\n+    __ vmsgtu_vi(as_VectorRegister($v0$$reg), as_VectorRegister($shift$$reg), BitsPerShort - 1);\n+    __ vmand_mm(as_VectorRegister($v0$$reg), as_VectorRegister($v0$$reg),\n+                as_VectorRegister($vmask$$reg));\n+    __ vxor_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($dst_src$$reg), Assembler::v0_t);\n+    \/\/ otherwise, shift\n+    __ vmv1r_v(as_VectorRegister($v0$$reg), as_VectorRegister($vmask$$reg));\n+    __ vsrl_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrI_masked(vReg dst_src, vReg shift, vRegMask_V0 v0) %{\n+  match(Set dst_src (URShiftVI (Binary dst_src shift) v0));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src);\n+  format %{ \"vlsrI_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_INT, Matcher::vector_length_in_bytes(this));\n+    __ vsrl_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsrL_masked(vReg dst_src, vReg shift, vRegMask_V0 v0) %{\n+  match(Set dst_src (URShiftVL (Binary dst_src shift) v0));\n+  ins_cost(VEC_COST);\n+  effect(TEMP_DEF dst_src);\n+  format %{ \"vlsrL_masked $dst_src, $dst_src, $shift, $v0\" %}\n+  ins_encode %{\n+    __ rvv_vsetvli(T_LONG, Matcher::vector_length_in_bytes(this));\n+    __ vsrl_vv(as_VectorRegister($dst_src$$reg), as_VectorRegister($dst_src$$reg),\n+               as_VectorRegister($shift$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -1830,0 +2200,32 @@\n+\/\/ vector sub - predicated\n+\n+instruct vsub_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (SubVB (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (SubVS (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (SubVI (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (SubVL (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vsub.vv $dst_src1, $src2, $v0\\t#@vsub_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vsub_vv(as_VectorRegister($dst_src1$$reg), as_VectorRegister($dst_src1$$reg),\n+               as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsub_fp_masked(vReg dst_src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst_src1 (SubVF (Binary dst_src1 src2) v0));\n+  match(Set dst_src1 (SubVD (Binary dst_src1 src2) v0));\n+  ins_cost(VEC_COST);\n+  format %{ \"vfsub.vv $dst_src1, $src2, $v0\\t#@vsub_fp_masked\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vfsub_vv(as_VectorRegister($dst_src1$$reg), as_VectorRegister($dst_src1$$reg),\n+                as_VectorRegister($src2$$reg), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n@@ -1832,1 +2234,1 @@\n-                         vReg_V2 v2, vReg_V3 v3, rFlagsReg cr)\n+                         vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, rFlagsReg cr)\n@@ -1836,1 +2238,1 @@\n-  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP v1, TEMP v2, TEMP v3, KILL cr);\n+  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP v1, TEMP v2, TEMP v3, TEMP v0, KILL cr);\n@@ -1849,1 +2251,1 @@\n-                         vReg_V2 v2, vReg_V3 v3, rFlagsReg cr)\n+                         vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, rFlagsReg cr)\n@@ -1853,1 +2255,1 @@\n-  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP v1, TEMP v2, TEMP v3, KILL cr);\n+  effect(USE_KILL str1, USE_KILL str2, USE_KILL cnt, TEMP v1, TEMP v2, TEMP v3, TEMP v0, KILL cr);\n@@ -1865,1 +2267,1 @@\n-                        vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, iRegP_R28 tmp, rFlagsReg cr)\n+                        vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, iRegP_R28 tmp, rFlagsReg cr)\n@@ -1869,1 +2271,1 @@\n-  effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP v1, TEMP v2, TEMP v3, KILL cr);\n+  effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP v1, TEMP v2, TEMP v3, TEMP v0, KILL cr);\n@@ -1880,1 +2282,1 @@\n-                        vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, iRegP_R28 tmp, rFlagsReg cr)\n+                        vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, iRegP_R28 tmp, rFlagsReg cr)\n@@ -1884,1 +2286,1 @@\n-  effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP v1, TEMP v2, TEMP v3, KILL cr);\n+  effect(KILL tmp, USE_KILL ary1, USE_KILL ary2, TEMP v1, TEMP v2, TEMP v3, TEMP v0, KILL cr);\n@@ -1896,1 +2298,1 @@\n-                          iRegP_R28 tmp1, iRegL_R29 tmp2)\n+                          vRegMask_V0 v0, iRegP_R28 tmp1, iRegL_R29 tmp2)\n@@ -1901,1 +2303,1 @@\n-         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5);\n+         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5, TEMP v0);\n@@ -1915,1 +2317,1 @@\n-                          iRegP_R28 tmp1, iRegL_R29 tmp2)\n+                          vRegMask_V0 v0, iRegP_R28 tmp1, iRegL_R29 tmp2)\n@@ -1920,1 +2322,1 @@\n-         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5);\n+         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5, TEMP v0);\n@@ -1934,1 +2336,1 @@\n-                           iRegP_R28 tmp1, iRegL_R29 tmp2)\n+                           vRegMask_V0 v0, iRegP_R28 tmp1, iRegL_R29 tmp2)\n@@ -1939,1 +2341,1 @@\n-         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5);\n+         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5, TEMP v0);\n@@ -1952,1 +2354,1 @@\n-                           iRegP_R28 tmp1, iRegL_R29 tmp2)\n+                           vRegMask_V0 v0, iRegP_R28 tmp1, iRegL_R29 tmp2)\n@@ -1957,1 +2359,1 @@\n-         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5);\n+         TEMP v1, TEMP v2, TEMP v3, TEMP v4, TEMP v5, TEMP v0);\n@@ -1971,1 +2373,1 @@\n-                         vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, iRegLNoSp tmp)\n+                         vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, iRegLNoSp tmp)\n@@ -1975,1 +2377,1 @@\n-  effect(TEMP v1, TEMP v2, TEMP v3, TEMP tmp, USE_KILL src, USE_KILL dst, USE_KILL len);\n+  effect(TEMP v1, TEMP v2, TEMP v3, TEMP v0, TEMP tmp, USE_KILL src, USE_KILL dst, USE_KILL len);\n@@ -1986,1 +2388,1 @@\n-                           vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, iRegLNoSp tmp)\n+                           vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, iRegLNoSp tmp)\n@@ -1991,1 +2393,1 @@\n-         TEMP v1, TEMP v2, TEMP v3, TEMP tmp);\n+         TEMP v1, TEMP v2, TEMP v3, TEMP tmp, TEMP v0);\n@@ -2003,1 +2405,1 @@\n-                          vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, iRegLNoSp tmp)\n+                          vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, iRegLNoSp tmp)\n@@ -2008,1 +2410,1 @@\n-         TEMP v1, TEMP v2, TEMP v3, TEMP tmp);\n+         TEMP v1, TEMP v2, TEMP v3, TEMP tmp, TEMP v0);\n@@ -2019,1 +2421,1 @@\n-                          vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, iRegLNoSp tmp)\n+                          vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0, iRegLNoSp tmp)\n@@ -2023,1 +2425,1 @@\n-  effect(TEMP_DEF result, USE_KILL ary, USE_KILL len, TEMP v1, TEMP v2, TEMP v3, TEMP tmp);\n+  effect(TEMP_DEF result, USE_KILL ary, USE_KILL len, TEMP v1, TEMP v2, TEMP v3, TEMP tmp, TEMP v0);\n@@ -2035,1 +2437,1 @@\n-                               vReg_V1 v1, vReg_V2 v2, vReg_V3 v3)\n+                               vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0)\n@@ -2040,1 +2442,1 @@\n-         TEMP tmp1, TEMP tmp2, TEMP v1, TEMP v2, TEMP v3);\n+         TEMP tmp1, TEMP tmp2, TEMP v1, TEMP v2, TEMP v3, TEMP v0);\n@@ -2055,1 +2457,1 @@\n-                               vReg_V1 v1, vReg_V2 v2, vReg_V3 v3)\n+                               vReg_V1 v1, vReg_V2 v2, vReg_V3 v3, vRegMask_V0 v0)\n@@ -2060,1 +2462,1 @@\n-         TEMP tmp1, TEMP tmp2, TEMP v1, TEMP v2, TEMP v3);\n+         TEMP tmp1, TEMP tmp2, TEMP v1, TEMP v2, TEMP v3, TEMP v0);\n@@ -2075,1 +2477,1 @@\n-                             vReg_V1 vReg1, vReg_V2 vReg2, vReg_V3 vReg3)\n+                             vReg_V1 vReg1, vReg_V2 vReg2, vReg_V3 vReg3, vRegMask_V0 v0)\n@@ -2079,1 +2481,1 @@\n-  effect(USE_KILL cnt, USE_KILL base, TEMP vReg1, TEMP vReg2, TEMP vReg3);\n+  effect(USE_KILL cnt, USE_KILL base, TEMP vReg1, TEMP vReg2, TEMP vReg3, TEMP v0);\n@@ -2104,0 +2506,184 @@\n+%}\n+\n+instruct vmask_gen_I(vRegMask dst, iRegI src) %{\n+  match(Set dst (VectorMaskGen (ConvI2L src)));\n+  format %{ \"vmask_gen_I $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SEW sew = Assembler::elemtype_to_sew(bt);\n+    __ vsetvli(t0, $src$$Register, sew);\n+    __ vmset_m(as_VectorRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_gen_L(vRegMask dst, iRegL src) %{\n+  match(Set dst (VectorMaskGen src));\n+  format %{ \"vmask_gen_L $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SEW sew = Assembler::elemtype_to_sew(bt);\n+    __ vsetvli(t0, $src$$Register, sew);\n+    __ vmset_m(as_VectorRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_gen_imm(vRegMask dst, immL con) %{\n+  match(Set dst (VectorMaskGen con));\n+  format %{ \"vmask_gen_imm $dst, $con\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, (uint)($con$$constant));\n+    __ vmset_m(as_VectorRegister($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAll_immI(vRegMask dst, immI src) %{\n+  match(Set dst (MaskAll src));\n+  format %{ \"vmaskAll_immI $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    int con = (int)$src$$constant;\n+    if (con == 0) {\n+      __ vmclr_m(as_VectorRegister($dst$$reg));\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      __ vmset_m(as_VectorRegister($dst$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllI(vRegMask dst, iRegI src) %{\n+  match(Set dst (MaskAll src));\n+  format %{ \"vmaskAllI $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmv_v_x(as_VectorRegister($dst$$reg), as_Register($src$$reg));\n+    __ vmsne_vx(as_VectorRegister($dst$$reg), as_VectorRegister($dst$$reg), zr);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAll_immL(vRegMask dst, immL src) %{\n+  match(Set dst (MaskAll src));\n+  format %{ \"vmaskAll_immL $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    long con = (long)$src$$constant;\n+    if (con == 0) {\n+      __ vmclr_m(as_VectorRegister($dst$$reg));\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      __ vmset_m(as_VectorRegister($dst$$reg));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllL(vRegMask dst, iRegL src) %{\n+  match(Set dst (MaskAll src));\n+  format %{ \"vmaskAllL $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmv_v_x(as_VectorRegister($dst$$reg), as_Register($src$$reg));\n+    __ vmsne_vx(as_VectorRegister($dst$$reg), as_VectorRegister($dst$$reg), zr);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask basic OPs ------------------------\n+\n+\/\/ vector mask logical ops: and\/or\/xor\n+\n+instruct vmask_and(vRegMask dst, vRegMask src1, vRegMask src2) %{\n+  match(Set dst (AndVMask src1 src2));\n+  format %{ \"vmask_and $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmand_mm(as_VectorRegister($dst$$reg),\n+                as_VectorRegister($src1$$reg),\n+                as_VectorRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_or(vRegMask dst, vRegMask src1, vRegMask src2) %{\n+  match(Set dst (OrVMask src1 src2));\n+  format %{ \"vmask_or $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmor_mm(as_VectorRegister($dst$$reg),\n+               as_VectorRegister($src1$$reg),\n+               as_VectorRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_xor(vRegMask dst, vRegMask src1, vRegMask src2) %{\n+  match(Set dst (XorVMask src1 src2));\n+  format %{ \"vmask_xor $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmxor_mm(as_VectorRegister($dst$$reg),\n+                as_VectorRegister($src1$$reg),\n+                as_VectorRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcast(vRegMask dst_src) %{\n+  match(Set dst_src (VectorMaskCast dst_src));\n+  ins_cost(0);\n+  format %{ \"vmaskcast $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+\/\/ vector load\/store - predicated\n+\n+instruct loadV_masked(vReg dst, vmemA mem, vRegMask_V0 v0) %{\n+  match(Set dst (LoadVectorMasked mem v0));\n+  format %{ \"loadV_masked $dst, $mem, $v0\" %}\n+  ins_encode %{\n+    VectorRegister dst_reg = as_VectorRegister($dst$$reg);\n+    loadStore(C2_MacroAssembler(&cbuf), false, dst_reg,\n+              Matcher::vector_element_basic_type(this), as_Register($mem$$base),\n+              Matcher::vector_length_in_bytes(this), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked(vReg src, vmemA mem, vRegMask_V0 v0) %{\n+  match(Set mem (StoreVectorMasked mem (Binary src v0)));\n+  format %{ \"storeV_masked $mem, $src, $v0\" %}\n+  ins_encode %{\n+    VectorRegister src_reg = as_VectorRegister($src$$reg);\n+    loadStore(C2_MacroAssembler(&cbuf), true, src_reg,\n+              Matcher::vector_element_basic_type(this, $src), as_Register($mem$$base),\n+              Matcher::vector_length_in_bytes(this, $src), Assembler::v0_t);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector blend ---------------------------------\n+\n+instruct vblend(vReg dst, vReg src1, vReg src2, vRegMask_V0 v0) %{\n+  match(Set dst (VectorBlend (Binary src1 src2) v0));\n+  format %{ \"vmerge_vvm $dst, $src1, $src2, v0\\t#@vector blend\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ rvv_vsetvli(bt, Matcher::vector_length_in_bytes(this));\n+    __ vmerge_vvm(as_VectorRegister($dst$$reg), as_VectorRegister($src1$$reg),\n+                  as_VectorRegister($src2$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n","filename":"src\/hotspot\/cpu\/riscv\/riscv_v.ad","additions":695,"deletions":109,"binary":false,"changes":804,"status":"modified"}]}