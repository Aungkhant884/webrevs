{"files":[{"patch":"@@ -11460,1 +11460,15 @@\n-void Assembler::pext(Register dst, Register src1, Register src2) {\n+void Assembler::pextl(Register dst, Register src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xF5, (0xC0 | encode));\n+}\n+\n+void Assembler::pdepl(Register dst, Register src1, Register src2) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  int encode = vex_prefix_and_encode(dst->encoding(), src1->encoding(), src2->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  emit_int16((unsigned char)0xF5, (0xC0 | encode));\n+}\n+\n+void Assembler::pextq(Register dst, Register src1, Register src2) {\n@@ -11467,1 +11481,1 @@\n-void Assembler::pdep(Register dst, Register src1, Register src2) {\n+void Assembler::pdepq(Register dst, Register src1, Register src2) {\n@@ -11474,0 +11488,36 @@\n+void Assembler::pextl(Register dst, Register src1, Address src2) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src2, src1->encoding(), dst->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF5);\n+  emit_operand(dst, src2);\n+}\n+\n+void Assembler::pdepl(Register dst, Register src1, Address src2) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ false, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src2, src1->encoding(), dst->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF5);\n+  emit_operand(dst, src2);\n+}\n+\n+void Assembler::pextq(Register dst, Register src1, Address src2) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src2, src1->encoding(), dst->encoding(), VEX_SIMD_F3, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF5);\n+  emit_operand(dst, src2);\n+}\n+\n+void Assembler::pdepq(Register dst, Register src1, Address src2) {\n+  assert(VM_Version::supports_bmi2(), \"bit manipulation instructions not supported\");\n+  InstructionMark im(this);\n+  InstructionAttr attributes(AVX_128bit, \/* vex_w *\/ true, \/* legacy_mode *\/ true, \/* no_mask_reg *\/ true, \/* uses_vl *\/ false);\n+  vex_prefix(src2, src1->encoding(), dst->encoding(), VEX_SIMD_F2, VEX_OPCODE_0F_38, &attributes);\n+  emit_int8((unsigned char)0xF5);\n+  emit_operand(dst, src2);\n+}\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":52,"deletions":2,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -2209,2 +2209,10 @@\n-  void pdep(Register dst, Register src1, Register src2);\n-  void pext(Register dst, Register src1, Register src2);\n+\n+  void pextl(Register dst, Register src1, Register src2);\n+  void pdepl(Register dst, Register src1, Register src2);\n+  void pextq(Register dst, Register src1, Register src2);\n+  void pdepq(Register dst, Register src1, Register src2);\n+  void pextl(Register dst, Register src1, Address src2);\n+  void pdepl(Register dst, Register src1, Address src2);\n+  void pextq(Register dst, Register src1, Address src2);\n+  void pdepq(Register dst, Register src1, Address src2);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":10,"deletions":2,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -4269,1 +4269,1 @@\n-  pdep(rtmp1, src, rtmp1);\n+  pdepq(rtmp1, src, rtmp1);\n@@ -4286,1 +4286,1 @@\n-    pdep(rtmp1, rtmp2, rtmp1);\n+    pdepq(rtmp1, rtmp2, rtmp1);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1618,0 +1618,6 @@\n+    case Op_CompressBits:\n+    case Op_ExpandBits:\n+      if (!VM_Version::supports_bmi2()) {\n+        return false;\n+      }\n+      break;\n@@ -6173,0 +6179,1 @@\n+\n@@ -6175,0 +6182,42 @@\n+\/\/----------------------------- CompressBits\/ExpandBits ------------------------\n+\n+instruct compressBitsI_reg(rRegI dst, rRegI src, rRegI mask) %{\n+  predicate(n->bottom_type()->isa_int());\n+  match(Set dst (CompressBits src mask));\n+  format %{ \"pextl  $dst, $src, $mask\\t! parallel bit extract\" %}\n+  ins_encode %{\n+    __ pextl($dst$$Register, $src$$Register, $mask$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct expandBitsI_reg(rRegI dst, rRegI src, rRegI mask) %{\n+  predicate(n->bottom_type()->isa_int());\n+  match(Set dst (ExpandBits src mask));\n+  format %{ \"pdepl  $dst, $src, $mask\\t! parallel bit deposit\" %}\n+  ins_encode %{\n+    __ pdepl($dst$$Register, $src$$Register, $mask$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct compressBitsI_mem(rRegI dst, rRegI src, memory mask) %{\n+  predicate(n->bottom_type()->isa_int());\n+  match(Set dst (CompressBits src (LoadI mask)));\n+  format %{ \"pextl  $dst, $src, $mask\\t! parallel bit extract\" %}\n+  ins_encode %{\n+    __ pextl($dst$$Register, $src$$Register, $mask$$Address);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct expandBitsI_mem(rRegI dst, rRegI src, memory mask) %{\n+  predicate(n->bottom_type()->isa_int());\n+  match(Set dst (ExpandBits src (LoadI mask)));\n+  format %{ \"pdepl  $dst, $src, $mask\\t! parallel bit deposit\" %}\n+  ins_encode %{\n+    __ pdepl($dst$$Register, $src$$Register, $mask$$Address);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":49,"deletions":0,"binary":false,"changes":49,"status":"modified"},{"patch":"@@ -216,0 +216,1 @@\n+reg_class ebpd_reg( EBP,EDI );\n@@ -3895,0 +3896,7 @@\n+operand eBDPRegL( eRegL reg ) %{\n+  constraint(ALLOC_IN_RC(ebpd_reg));\n+  match(reg);\n+\n+  format %{ \"EBP:EDI\" %}\n+  interface(REG_INTER);\n+%}\n@@ -11468,0 +11476,89 @@\n+\/\/----------------------------- CompressBits\/ExpandBits ------------------------\n+\n+instruct compressBitsL_reg(eADXRegL dst, eBCXRegL src, eBDPRegL mask, eSIRegI rtmp, regF xtmp) %{\n+  predicate(n->bottom_type()->isa_long());\n+  match(Set dst (CompressBits src mask));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"compress_bits32 $dst, $src, $mask\\t! using $rtmp and $xtmp as TEMP\" %}\n+  ins_encode %{\n+    Label exit, partail_result;\n+    \/\/ Parallely extract both upper and lower 32 bits of source into destination register pair.\n+    \/\/ Merge the results of upper and lower destination registers such that upper destination\n+    \/\/ results are contiguously laid out after the lower destination result.\n+    __ pextl($dst$$Register, $src$$Register, $mask$$Register);\n+    __ pextl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($src$$Register), HIGH_FROM_LOW($mask$$Register));\n+    __ popcntl($rtmp$$Register, $mask$$Register);\n+    \/\/ Skip merging if bit count of lower mask register is equal to 32 (register size).\n+    __ cmpl($rtmp$$Register, 32);\n+    __ jccb(Assembler::equal, exit);\n+    \/\/ Due to constraint on number of GPRs on 32 bit target, using XMM registers as potential spill slots.\n+    __ movdl($xtmp$$XMMRegister, $rtmp$$Register);\n+    \/\/ Shift left the contents of upper destination register by true bit count of lower mask register\n+    \/\/ and merge with lower destination register.\n+    __ shlxl($rtmp$$Register, HIGH_FROM_LOW($dst$$Register), $rtmp$$Register);\n+    __ orl($dst$$Register, $rtmp$$Register);\n+    __ movdl($rtmp$$Register, $xtmp$$XMMRegister);\n+    \/\/ Zero out upper destination register if true bit count of lower 32 bit mask is zero\n+    \/\/ since contents of upper destination have already been copied to lower destination\n+    \/\/ register.\n+    __ cmpl($rtmp$$Register, 0);\n+    __ jccb(Assembler::greater, partail_result);\n+    __ movl(HIGH_FROM_LOW($dst$$Register), 0);\n+    __ jmp(exit);\n+    __ bind(partail_result);\n+    \/\/ Perform right shift over upper destination register to move out bits already copied\n+    \/\/ to lower destination register.\n+    __ subl($rtmp$$Register, 32);\n+    __ negl($rtmp$$Register);\n+    __ shrxl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($dst$$Register), $rtmp$$Register);\n+    __ bind(exit);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct expandBitsL_reg(eADXRegL dst, eBCXRegL src, eBDPRegL mask, eSIRegI rtmp, regF xtmp) %{\n+  predicate(n->bottom_type()->isa_long());\n+  match(Set dst (ExpandBits src mask));\n+  effect(TEMP rtmp, TEMP xtmp);\n+  format %{ \"expand_bits32 $dst, $src, $mask\\t! using $rtmp and $xtmp as TEMP\" %}\n+  ins_encode %{\n+    \/\/ Extraction operation sequentially reads the bits from source register starting from LSB\n+    \/\/ and lays them out into destination register at bit locations corresponding to true bits\n+    \/\/ in mask register. Thus number of source bits read are equal to combined true bit count\n+    \/\/ of mask register pair.\n+    Label exit, mask_clipping;\n+    __ pdepl($dst$$Register, $src$$Register, $mask$$Register);\n+    __ pdepl(HIGH_FROM_LOW($dst$$Register), HIGH_FROM_LOW($src$$Register), HIGH_FROM_LOW($mask$$Register));\n+    __ popcntl($rtmp$$Register, $mask$$Register);\n+    \/\/ If true bit count of lower mask register is 32 then none of bit of lower source register\n+    \/\/ will feed to upper destination register.\n+    __ cmpl($rtmp$$Register, 32);\n+    __ jccb(Assembler::equal, exit);\n+    \/\/ Due to constraint on number of GPRs on 32 bit target, using XMM registers as potential spill slots.\n+    __ movdl($xtmp$$XMMRegister, $rtmp$$Register);\n+    \/\/ Shift right the contents of lower source register to remove already consumed bits.\n+    __ shrxl($rtmp$$Register, $src$$Register, $rtmp$$Register);\n+    \/\/ Extract the bits from lower source register starting from LSB under the influence\n+    \/\/ of upper mask register.\n+    __ pdepl(HIGH_FROM_LOW($dst$$Register), $rtmp$$Register, HIGH_FROM_LOW($mask$$Register));\n+    __ movdl($rtmp$$Register, $xtmp$$XMMRegister);\n+    __ subl($rtmp$$Register, 32);\n+    __ negl($rtmp$$Register);\n+    __ movdl($xtmp$$XMMRegister, $mask$$Register);\n+    __ movl($mask$$Register, HIGH_FROM_LOW($mask$$Register));\n+    \/\/ Clear the set bits in upper mask register which have been used to extract the contents\n+    \/\/ from lower source register.\n+    __ bind(mask_clipping);\n+    __ blsrl($mask$$Register, $mask$$Register);\n+    __ decrementl($rtmp$$Register, 1);\n+    __ jccb(Assembler::greater, mask_clipping);\n+    \/\/ Starting from LSB extract the bits from upper source register under the influence of\n+    \/\/ remaining set bits in upper mask register.\n+    __ pdepl($rtmp$$Register, HIGH_FROM_LOW($src$$Register), $mask$$Register);\n+    \/\/ Merge the partial results extracted from lower and upper source register bits.\n+    __ orl(HIGH_FROM_LOW($dst$$Register), $rtmp$$Register);\n+    __ movdl($mask$$Register, $xtmp$$XMMRegister);\n+    __ bind(exit);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":97,"deletions":0,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -9399,0 +9399,42 @@\n+\/\/----------------------------- CompressBits\/ExpandBits ------------------------\n+\n+instruct compressBitsL_reg(rRegL dst, rRegL src, rRegL mask) %{\n+  predicate(n->bottom_type()->isa_long());\n+  match(Set dst (CompressBits src mask));\n+  format %{ \"pextq  $dst, $src, $mask\\t! parallel bit extract\" %}\n+  ins_encode %{\n+    __ pextq($dst$$Register, $src$$Register, $mask$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct expandBitsL_reg(rRegL dst, rRegL src, rRegL mask) %{\n+  predicate(n->bottom_type()->isa_long());\n+  match(Set dst (ExpandBits src mask));\n+  format %{ \"pdepq  $dst, $src, $mask\\t! parallel bit deposit\" %}\n+  ins_encode %{\n+    __ pdepq($dst$$Register, $src$$Register, $mask$$Register);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct compressBitsL_mem(rRegL dst, rRegL src, memory mask) %{\n+  predicate(n->bottom_type()->isa_long());\n+  match(Set dst (CompressBits src (LoadL mask)));\n+  format %{ \"pextq  $dst, $src, $mask\\t! parallel bit extract\" %}\n+  ins_encode %{\n+    __ pextq($dst$$Register, $src$$Register, $mask$$Address);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+instruct expandBitsL_mem(rRegL dst, rRegL src, memory mask) %{\n+  predicate(n->bottom_type()->isa_long());\n+  match(Set dst (ExpandBits src (LoadL mask)));\n+  format %{ \"pdepq  $dst, $src, $mask\\t! parallel bit deposit\" %}\n+  ins_encode %{\n+    __ pdepq($dst$$Register, $src$$Register, $mask$$Address);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":42,"deletions":0,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -150,0 +150,1 @@\n+  do_name(expand_name,\"expand\")                                                                                         \\\n@@ -233,0 +234,4 @@\n+  do_intrinsic(_compress_i,               java_lang_Integer,      compress_name,            int2_int_signature,   F_S)  \\\n+  do_intrinsic(_compress_l,               java_lang_Long,         compress_name,            long2_long_signature, F_S)  \\\n+  do_intrinsic(_expand_i,                 java_lang_Integer,      expand_name,              int2_int_signature,   F_S)  \\\n+  do_intrinsic(_expand_l,                 java_lang_Long,         expand_name,              long2_long_signature, F_S)  \\\n@@ -246,1 +251,1 @@\n-                                                                                                                        \\\n+                                                                                                                       \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -246,0 +246,8 @@\n+  case vmIntrinsics::_compress_i:\n+  case vmIntrinsics::_compress_l:\n+    if (!Matcher::match_rule_supported(Op_CompressBits)) return false;\n+    break;\n+  case vmIntrinsics::_expand_i:\n+  case vmIntrinsics::_expand_l:\n+    if (!Matcher::match_rule_supported(Op_ExpandBits)) return false;\n+    break;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -322,0 +322,2 @@\n+macro(CompressBits)\n+macro(ExpandBits)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,0 +27,2 @@\n+#include \"opto\/addnode.hpp\"\n+#include \"opto\/mulnode.hpp\"\n@@ -115,0 +117,162 @@\n+Node* CompressBitsNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* src = in(1);\n+  Node* mask = in(2);\n+  if (bottom_type()->isa_int()) {\n+    if (mask->Opcode() == Op_LShiftI && phase->type(mask->in(1))->is_int()->is_con()) {\n+      \/\/ compress(x, 1 << n) == (x >> n & 1)\n+      if (phase->type(mask->in(1))->higher_equal(TypeInt::ONE)) {\n+        Node* rshift = phase->transform(new RShiftINode(in(1), mask->in(2)));\n+        return new AndINode(rshift, phase->makecon(TypeInt::ONE));\n+      \/\/ compress(x, -1 << n) == x >>> n\n+      } else if (phase->type(mask->in(1))->higher_equal(TypeInt::MINUS_1)) {\n+        return new URShiftINode(in(1), mask->in(2));\n+      }\n+    }\n+    \/\/ compress(expand(x, m), m) == x & compress(m, m)\n+    if (src->Opcode() == Op_ExpandBits &&\n+        src->in(2) == mask) {\n+      Node* compr = phase->transform(new CompressBitsNode(mask, mask, TypeInt::INT));\n+      return new AndINode(compr, src->in(1));\n+    }\n+  } else {\n+    assert(bottom_type()->isa_long(), \"\");\n+    if (mask->Opcode() == Op_LShiftL && phase->type(mask->in(1))->is_long()->is_con()) {\n+      \/\/ compress(x, 1 << n) == (x >> n & 1)\n+      if (phase->type(mask->in(1))->higher_equal(TypeLong::ONE)) {\n+        Node* rshift = phase->transform(new RShiftLNode(in(1), mask->in(2)));\n+        return new AndLNode(rshift, phase->makecon(TypeLong::ONE));\n+      \/\/ compress(x, -1 << n) == x >>> n\n+      } else if (phase->type(mask->in(1))->higher_equal(TypeLong::MINUS_1)) {\n+        return new URShiftLNode(in(1), mask->in(2));\n+      }\n+    }\n+    \/\/ compress(expand(x, m), m) == x & compress(m, m)\n+    if (src->Opcode() == Op_ExpandBits &&\n+        src->in(2) == mask) {\n+      Node* compr = phase->transform(new CompressBitsNode(mask, mask, TypeLong::LONG));\n+      return new AndLNode(compr, src->in(1));\n+    }\n+  }\n+  return NULL;\n+}\n+\n+Node* compress_expand_identity(PhaseGVN* phase, Node* n) {\n+  BasicType bt = n->bottom_type()->basic_type();\n+  \/\/ compress(x, 0) == 0, expand(x, 0) == 0\n+  if(phase->type(n->in(2))->higher_equal(TypeInteger::zero(bt))) return n->in(2);\n+  \/\/ compress(x, -1) == x, expand(x, -1) == x\n+  if(phase->type(n->in(2))->higher_equal(TypeInteger::minus_1(bt))) return n->in(1);\n+  return n;\n+  \/\/ expand(-1, x) == x\n+  if(n->Opcode() == Op_ExpandBits &&\n+     phase->type(n->in(1))->higher_equal(TypeInteger::minus_1(bt))) return n->in(2);\n+  return n;\n+}\n+\n+Node* CompressBitsNode::Identity(PhaseGVN* phase) {\n+  return compress_expand_identity(phase, this);\n+}\n+\n+Node* ExpandBitsNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* src = in(1);\n+  Node* mask = in(2);\n+  if (bottom_type()->isa_int()) {\n+    if (mask->Opcode() == Op_LShiftI && phase->type(mask->in(1))->is_int()->is_con()) {\n+      \/\/ expand(x, 1 << n) == (x & 1) << n\n+      if (phase->type(mask->in(1))->higher_equal(TypeInt::ONE)) {\n+        Node* andnode = phase->transform(new AndINode(in(1), phase->makecon(TypeInt::ONE)));\n+        return new LShiftINode(andnode, mask->in(2));\n+      \/\/ expand(x, -1 << n) == x << n\n+      } else if (phase->type(mask->in(1))->higher_equal(TypeInt::MINUS_1)) {\n+        return new LShiftINode(in(1), mask->in(2));\n+      }\n+    }\n+    \/\/ expand(compress(x, m), m) == x & m\n+    if (src->Opcode() == Op_CompressBits &&\n+        src->in(2) == mask) {\n+      return new AndINode(src->in(1), mask);\n+    }\n+  } else {\n+    assert(bottom_type()->isa_long(), \"\");\n+    if (mask->Opcode() == Op_LShiftL && phase->type(mask->in(1))->is_long()->is_con()) {\n+      \/\/ expand(x, 1 << n) == (x & 1) << n\n+      if (phase->type(mask->in(1))->higher_equal(TypeLong::ONE)) {\n+        Node* andnode = phase->transform(new AndLNode(in(1), phase->makecon(TypeLong::ONE)));\n+        return new LShiftLNode(andnode, mask->in(2));\n+      \/\/ expand(x, -1 << n) == x << n\n+      } else if (phase->type(mask->in(1))->higher_equal(TypeLong::MINUS_1)) {\n+        return new LShiftLNode(in(1), mask->in(2));\n+      }\n+    }\n+    \/\/ expand(compress(x, m), m) == x & m\n+    if (src->Opcode() == Op_CompressBits &&\n+        src->in(2) == mask) {\n+      return new AndLNode(src->in(1), mask);\n+    }\n+  }\n+  return NULL;\n+}\n+\n+Node* ExpandBitsNode::Identity(PhaseGVN* phase) {\n+  return compress_expand_identity(phase, this);\n+}\n+\n+const Type* CompressBitsNode::Value(PhaseGVN* phase) const {\n+  const Type* t1 = phase->type(in(1));\n+  const Type* t2 = phase->type(in(2));\n+  if (t1 == Type::TOP || t2 == Type::TOP) {\n+    return Type::TOP;\n+  }\n+\n+  BasicType bt = bottom_type()->basic_type();\n+  const TypeInteger* t1i = t1->is_integer(bt);\n+  const TypeInteger* t2i = t2->is_integer(bt);\n+  int w = bt == T_INT ? 32 : 64;\n+\n+  if (t1i->is_con() && t2i->is_con()) {\n+     jlong res = 0;\n+     jlong src = t1i->get_con_as_long(bt);\n+     jlong mask = t2i->get_con_as_long(bt);\n+     src = w == 32 ? src & 0xFFFFFFFFL : src;\n+     mask = w == 32 ? mask & 0xFFFFFFFFL : mask;\n+     for (int i = 0, j = 0; i < w; i++) {\n+       if(mask & 0x1) {\n+         res |= (src & 0x1) << j++;\n+       }\n+       src >>= 1;\n+       mask >>= 1;\n+     }\n+     return TypeInteger::make(res, res, w, bt);\n+  }\n+  return bottom_type();\n+}\n+\n+const Type* ExpandBitsNode::Value(PhaseGVN* phase) const {\n+  const Type* t1 = phase->type(in(1));\n+  const Type* t2 = phase->type(in(2));\n+  if (t1 == Type::TOP || t2 == Type::TOP) {\n+    return Type::TOP;\n+  }\n+\n+  BasicType bt = bottom_type()->basic_type();\n+  const TypeInteger* t1i = t1->is_integer(bt);\n+  const TypeInteger* t2i = t2->is_integer(bt);\n+  int w = bt == T_INT ? 32 : 64;\n+\n+  if (t1i->is_con() && t2i->is_con()) {\n+     jlong res = 0;\n+     jlong src = t1i->get_con_as_long(bt);\n+     jlong mask = t2i->get_con_as_long(bt);\n+     src = w == 32 ? src & 0xFFFFFFFFL : src;\n+     mask = w == 32 ? mask & 0xFFFFFFFFL : mask;\n+     for (int i = 0; i < w; i++) {\n+       if(mask & 0x1) {\n+         res |= (src & 0x1) << i;\n+         src >>= 1;\n+       }\n+       mask >>= 1;\n+     }\n+     return TypeInteger::make(res, res, w, bt);\n+  }\n+  return bottom_type();\n+}\n","filename":"src\/hotspot\/share\/opto\/intrinsicnode.cpp","additions":164,"deletions":0,"binary":false,"changes":164,"status":"modified"},{"patch":"@@ -265,0 +265,25 @@\n+\/\/----------------------------CompressBits\/ExpandBits---------------------------\n+class CompressBitsNode : public TypeNode {\n+ public:\n+  CompressBitsNode(Node* in1, Node* in2, const Type* type) : TypeNode(type, 3) {\n+    init_req(1, in1);\n+    init_req(2, in2);\n+  }\n+  virtual int Opcode() const;\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual Node* Identity(PhaseGVN* phase);\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+};\n+\n+class ExpandBitsNode : public TypeNode {\n+ public:\n+  ExpandBitsNode(Node* in1, Node* in2, const Type* type) : TypeNode(type, 3) {\n+    init_req(1, in1);\n+    init_req(2, in2);\n+  }\n+  virtual int Opcode() const;\n+  virtual Node* Ideal(PhaseGVN* phase, bool can_reshape);\n+  virtual Node* Identity(PhaseGVN* phase);\n+  virtual const Type* Value(PhaseGVN* phase) const;\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/intrinsicnode.hpp","additions":25,"deletions":0,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -530,0 +530,5 @@\n+  case vmIntrinsics::_compress_i:\n+  case vmIntrinsics::_compress_l:\n+  case vmIntrinsics::_expand_i:\n+  case vmIntrinsics::_expand_l:                 return inline_bitshuffle_methods(intrinsic_id());\n+\n@@ -2222,0 +2227,18 @@\n+\/\/--------------------------inline_bitshuffle_methods-----------------------------\n+\/\/ inline int Integer.compress(int, int)\n+\/\/ inline int Integer.expand(int, int)\n+\/\/ inline long Long.compress(long, long)\n+\/\/ inline long Long.expand(long, long)\n+bool LibraryCallKit::inline_bitshuffle_methods(vmIntrinsics::ID id) {\n+  Node* n = NULL;\n+  switch (id) {\n+    case vmIntrinsics::_compress_i:  n = new CompressBitsNode(argument(0), argument(1), TypeInt::INT); break;\n+    case vmIntrinsics::_expand_i:    n = new ExpandBitsNode(argument(0),  argument(1), TypeInt::INT); break;\n+    case vmIntrinsics::_compress_l:  n = new CompressBitsNode(argument(0), argument(2), TypeLong::LONG); break;\n+    case vmIntrinsics::_expand_l:    n = new ExpandBitsNode(argument(0), argument(2), TypeLong::LONG); break;\n+    default:  fatal_unexpected_iid(id);  break;\n+  }\n+  set_result(_gvn.transform(n));\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -278,0 +278,1 @@\n+  bool inline_bitshuffle_methods(vmIntrinsics::ID id);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1842,1 +1842,1 @@\n-    \/\/ @IntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -1930,1 +1930,1 @@\n-    \/\/ @IntrinsicCandidate\n+    @IntrinsicCandidate\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Integer.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1981,1 +1981,1 @@\n-    \/\/ @IntrinsicCandidate\n+    @IntrinsicCandidate\n@@ -2069,1 +2069,1 @@\n-    \/\/ @IntrinsicCandidate\n+    @IntrinsicCandidate\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Long.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -0,0 +1,443 @@\n+\/*\n+ * Copyright (c) 2022, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+\/**\n+ * @test\n+ * @bug 8285281\n+ * @key randomness\n+ * @summary To test various transforms added for bit COMPRESS_BITS and EXPAND_BITS operations\n+ * @requires vm.compiler2.enabled\n+ * @requires vm.cpu.features ~= \".*bmi2.*\"\n+ * @library \/test\/lib \/\n+ * @run driver compiler.intrinsics.TestBitShuffleOpers\n+ *\/\n+\n+package compiler.intrinsics;\n+\n+import java.util.concurrent.Callable;\n+import compiler.lib.ir_framework.*;\n+import jdk.test.lib.Utils;\n+import java.util.Random;\n+\n+public class TestBitShuffleOpers {\n+    int [] ri;\n+    int [] ai;\n+    int [] bi;\n+\n+    long [] rl;\n+    long [] al;\n+    long [] bl;\n+\n+    \/\/===================== Compress Bits Transforms ================\n+    @Test\n+    @IR(counts = {\"RShiftI\", \" > 0 \", \"AndI\", \" > 0\"})\n+    public void test1(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.compress(ai[i], 1 << bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test1\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test1() {\n+        for (int i = 0; i < 10000; i++) {\n+            test1(ri, ai, bi);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"URShiftI\", \" > 0 \"})\n+    public void test2(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.compress(ai[i], -1 << bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test2\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test2() {\n+        for (int i = 0; i < 10000; i++) {\n+            test2(ri, ai, bi);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"CompressBits\", \" > 0 \", \"AndI\" , \" > 0 \"})\n+    public void test3(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.compress(Integer.expand(ai[i], bi[i]), bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test3\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test3() {\n+        for (int i = 0; i < 10000; i++) {\n+            test3(ri, ai, bi);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"RShiftL\", \" > 0 \", \"AndL\", \" > 0\"})\n+    public void test4(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.compress(al[i], 1L << bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test4\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test4() {\n+        for (int i = 0; i < 10000; i++) {\n+            test4(rl, al, bl);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"URShiftL\", \" > 0 \"})\n+    public void test5(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.compress(al[i], -1L << bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test5\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test5() {\n+        for (int i = 0; i < 10000; i++) {\n+            test5(rl, al, bl);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"CompressBits\", \" > 0 \", \"AndL\" , \" > 0 \"})\n+    public void test6(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.compress(Long.expand(al[i], bl[i]), bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test6\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test6() {\n+        for (int i = 0; i < 10000; i++) {\n+            test6(rl, al, bl);\n+        }\n+    }\n+    \/\/===================== Expand Bits Transforms ================\n+    @Test\n+    @IR(counts = {\"LShiftI\", \" > 0 \", \"AndI\", \" > 0\"})\n+    public void test7(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.expand(ai[i], 1 << bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test7\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test7() {\n+        for (int i = 0; i < 10000; i++) {\n+            test7(ri, ai, bi);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"LShiftI\", \" > 0 \"})\n+    public void test8(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.expand(ai[i], -1 << bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test8\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test8() {\n+        for (int i = 0; i < 10000; i++) {\n+            test8(ri, ai, bi);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"AndI\" , \" > 0 \"})\n+    public void test9(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.expand(Integer.compress(ai[i], bi[i]), bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test9\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test9() {\n+        for (int i = 0; i < 10000; i++) {\n+            test9(ri, ai, bi);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"LShiftL\", \" > 0 \", \"AndL\", \" > 0\"})\n+    public void test10(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.expand(al[i], 1L << bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test10\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test10() {\n+        for (int i = 0; i < 10000; i++) {\n+            test10(rl, al, bl);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"LShiftL\", \" > 0 \"})\n+    public void test11(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.expand(al[i], -1L << bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test11\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test11() {\n+        for (int i = 0; i < 10000; i++) {\n+            test11(rl, al, bl);\n+        }\n+    }\n+\n+    @Test\n+    @IR(counts = {\"AndL\" , \" > 0 \"})\n+    public void test12(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.expand(Long.compress(al[i], bl[i]), bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test12\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test12() {\n+        for (int i = 0; i < 10000; i++) {\n+            test12(rl, al, bl);\n+        }\n+    }\n+\n+    \/\/ ================ Compress\/ExpandBits Vanilla ================= \/\/\n+\n+    @Test\n+    @IR(counts = {\"CompressBits\", \" > 0 \"})\n+    public void test13(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.compress(ai[i], bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test13\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test13() {\n+        for (int i = 0; i < 10000; i++) {\n+            test13(ri, ai, bi);\n+        }\n+        verifyCompressInt(ri, ai, bi);\n+    }\n+\n+    @Test\n+    @IR(counts = {\"CompressBits\", \" > 0 \"})\n+    public void test14(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.compress(al[i], bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test14\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test14() {\n+        for (int i = 0; i < 10000; i++) {\n+            test14(rl, al, bl);\n+        }\n+        verifyCompressLong(rl, al, bl);\n+    }\n+\n+    @Test\n+    @IR(counts = {\"ExpandBits\", \" > 0 \"})\n+    public void test15(int[] ri, int[] ai, int[] bi) {\n+        for (int i = 0; i < ri.length; i++) {\n+           ri[i] = Integer.expand(ai[i], bi[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test15\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test15() {\n+        for (int i = 0; i < 10000; i++) {\n+            test15(ri, ai, bi);\n+        }\n+        verifyExpandInt(ri, ai, bi);\n+    }\n+\n+    @Test\n+    @IR(counts = {\"ExpandBits\", \" > 0 \"})\n+    public void test16(long[] rl, long[] al, long[] bl) {\n+        for (int i = 0; i < rl.length; i++) {\n+           rl[i] = Long.expand(al[i], bl[i]);\n+        }\n+    }\n+\n+    @Run(test = {\"test16\"}, mode = RunMode.STANDALONE)\n+    public void kernel_test16() {\n+        for (int i = 0; i < 10000; i++) {\n+            test16(rl, al, bl);\n+        }\n+        verifyExpandLong(rl, al, bl);\n+    }\n+\n+    private static final Random R = Utils.getRandomInstance();\n+\n+    static int[] fillIntRandom(Callable<int[]> factory) {\n+        try {\n+            int[] arr = factory.call();\n+            for (int i = 0; i < arr.length; i++) {\n+                arr[i] = R.nextInt();\n+            }\n+            return arr;\n+        } catch (Exception e) {\n+            throw new InternalError(e);\n+        }\n+    }\n+    static long[] fillLongRandom(Callable<long[]> factory) {\n+        try {\n+            long[] arr = factory.call();\n+            for (int i = 0; i < arr.length; i++) {\n+                arr[i] = R.nextLong();\n+            }\n+            return arr;\n+        } catch (Exception e) {\n+            throw new InternalError(e);\n+        }\n+    }\n+\n+    static void verifyExpandInt(int [] actual_res, int [] inp_arr, int [] mask_arr) {\n+        assert inp_arr.length == mask_arr.length && inp_arr.length == actual_res.length;\n+        int [] exp_res = new int[inp_arr.length];\n+        for (int i = 0 ; i < inp_arr.length; i++) {\n+            int exp = 0;\n+            int src = inp_arr[i];\n+            int mask = mask_arr[i];\n+            for(int j = 0, k = 0; j < Integer.SIZE; j++) {\n+                if ((mask & 0x1) == 1) {\n+                    exp |= (src & 0x1) <<  j;\n+                    src >>= 1;\n+                }\n+                mask >>= 1;\n+            }\n+            exp_res[i] = exp;\n+        }\n+\n+        for(int i = 0; i < actual_res.length; i++) {\n+            if (actual_res[i] != exp_res[i]) {\n+                throw new Error(\"expand_int: src = \" + inp_arr[i] + \" mask = \" + mask_arr[i] +\n+                                \" acutal = \" + actual_res[i] + \" expected = \" + exp_res[i]);\n+            }\n+        }\n+    }\n+\n+    static void verifyExpandLong(long [] actual_res, long [] inp_arr, long [] mask_arr) {\n+        assert inp_arr.length == mask_arr.length && inp_arr.length == actual_res.length;\n+        long [] exp_res = new long[inp_arr.length];\n+        for (int i = 0 ; i < inp_arr.length; i++) {\n+            long exp = 0;\n+            long src = inp_arr[i];\n+            long mask = mask_arr[i];\n+            for(int j = 0, k = 0; j < Long.SIZE; j++) {\n+                if ((mask & 0x1) == 1) {\n+                    exp |= (src & 0x1) <<  j;\n+                    src >>= 1;\n+                }\n+                mask >>= 1;\n+            }\n+            exp_res[i] = exp;\n+        }\n+\n+        for(int i = 0; i < actual_res.length; i++) {\n+            if (actual_res[i] != exp_res[i]) {\n+                throw new Error(\"expand_long: src = \" + inp_arr[i] + \" mask = \" + mask_arr[i] +\n+                                \" acutal = \" + actual_res[i] + \" expected = \" + exp_res[i]);\n+            }\n+        }\n+    }\n+\n+    static void verifyCompressInt(int [] actual_res, int [] inp_arr, int [] mask_arr) {\n+        assert inp_arr.length == mask_arr.length && inp_arr.length == actual_res.length;\n+        int [] exp_res = new int[inp_arr.length];\n+        for (int i = 0 ; i < inp_arr.length; i++) {\n+            int exp = 0;\n+            int src = inp_arr[i];\n+            int mask = mask_arr[i];\n+            for(int j = 0, k = 0; j < Integer.SIZE; j++) {\n+                if ((mask & 0x1) == 1) {\n+                    exp |= (src & 0x1) <<  k++;\n+                }\n+                mask >>= 1;\n+                src >>= 1;\n+            }\n+            exp_res[i] = exp;\n+        }\n+\n+        for(int i = 0; i < actual_res.length; i++) {\n+            if (actual_res[i] != exp_res[i]) {\n+                throw new Error(\"compress_int: src = \" + inp_arr[i] + \" mask = \" + mask_arr[i] +\n+                                \" acutal = \" + actual_res[i] + \" expected = \" + exp_res[i]);\n+            }\n+        }\n+    }\n+\n+    static void verifyCompressLong(long [] actual_res, long [] inp_arr, long [] mask_arr) {\n+        assert inp_arr.length == mask_arr.length && inp_arr.length == actual_res.length;\n+        long [] exp_res = new long[inp_arr.length];\n+        for (int i = 0 ; i < inp_arr.length; i++) {\n+            long exp = 0;\n+            long src = inp_arr[i];\n+            long mask = mask_arr[i];\n+            for(int j = 0, k = 0; j < Long.SIZE; j++) {\n+                if ((mask & 0x1) == 1) {\n+                    exp |= (src & 0x1) <<  k++;\n+                }\n+                mask >>= 1;\n+                src >>= 1;\n+            }\n+            exp_res[i] = exp;\n+        }\n+\n+        for(int i = 0; i < actual_res.length; i++) {\n+            if (actual_res[i] != exp_res[i]) {\n+                throw new Error(\"compress_long: src = \" + inp_arr[i] + \" mask = \" + mask_arr[i] +\n+                                \" acutal = \" + actual_res[i] + \" expected = \" + exp_res[i]);\n+            }\n+        }\n+    }\n+\n+    \/\/ ===================================================== \/\/\n+\n+    static final int SIZE = 512;\n+\n+\n+    public TestBitShuffleOpers() {\n+        ri = new int[SIZE];\n+        ai = fillIntRandom(()-> new int[SIZE]);\n+        bi = fillIntRandom(()-> new int[SIZE]);\n+\n+        rl = new long[SIZE];\n+        al = fillLongRandom(() -> new long[SIZE]);\n+        bl = fillLongRandom(() -> new long[SIZE]);\n+\n+    }\n+\n+    public static void main(String[] args) {\n+        TestFramework.runWithFlags(\"-XX:-TieredCompilation\",\n+                                   \"-XX:CompileThresholdScaling=0.3\");\n+    }\n+}\n","filename":"test\/hotspot\/jtreg\/compiler\/intrinsics\/TestBitShuffleOpers.java","additions":443,"deletions":0,"binary":false,"changes":443,"status":"added"},{"patch":"@@ -774,0 +774,2 @@\n+# java\n+java\/lang\/CompressExpandSanityTest.java\n@@ -775,0 +777,1 @@\n+############################################################################\n","filename":"test\/jdk\/ProblemList.txt","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+ * @ignore\n","filename":"test\/jdk\/java\/lang\/CompressExpandSanityTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+ * @run testng\/othervm -XX:DisableIntrinsic=_expand_i,_expand_l,_compress_i,_compress_l CompressExpandTest\n","filename":"test\/jdk\/java\/lang\/CompressExpandTest.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"}]}