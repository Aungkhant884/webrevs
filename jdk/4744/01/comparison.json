{"files":[{"patch":"@@ -2573,18 +2573,0 @@\n-\n-  \/\/ Fill TLAB's and such\n-  {\n-    Ticks start = Ticks::now();\n-    ensure_parsability(true);\n-    Tickspan dt = Ticks::now() - start;\n-    phase_times()->record_prepare_tlab_time_ms(dt.seconds() * MILLIUNITS);\n-  }\n-\n-  if (!full) {\n-    \/\/ Flush dirty card queues to qset, so later phases don't need to account\n-    \/\/ for partially filled per-thread queues and such.  Not needed for full\n-    \/\/ collections, which ignore those logs.\n-    Ticks start = Ticks::now();\n-    G1BarrierSet::dirty_card_queue_set().concatenate_logs();\n-    Tickspan dt = Ticks::now() - start;\n-    phase_times()->record_concatenate_dirty_card_logs_time_ms(dt.seconds() * MILLIUNITS);\n-  }\n@@ -2604,4 +2586,0 @@\n-  double start = os::elapsedTime();\n-  resize_all_tlabs();\n-  phase_times()->record_resize_tlab_time_ms((os::elapsedTime() - start) * 1000.0);\n-\n@@ -2801,0 +2779,3 @@\n+  \/\/ Forget the current allocation region (we might even choose it to be part\n+  \/\/ of the collection set!) before finalizing the collection set.\n+  _allocator->release_mutator_alloc_regions();\n@@ -2991,10 +2972,1 @@\n-void G1CollectedHeap::do_collection_pause_at_safepoint_helper(double target_pause_time_ms) {\n-  GCIdMark gc_id_mark;\n-\n-  SvcGCMarker sgcm(SvcGCMarker::MINOR);\n-  ResourceMark rm;\n-\n-  policy()->note_gc_start();\n-\n-  wait_for_root_region_scanning();\n-\n+bool G1CollectedHeap::determine_start_concurrent_mark_gc(){\n@@ -3015,0 +2987,39 @@\n+  return collector_state()->in_concurrent_start_gc();\n+}\n+\n+void G1CollectedHeap::set_young_collection_default_active_worker_threads(){\n+  uint active_workers = WorkerPolicy::calc_active_workers(workers()->total_workers(),\n+                                                          workers()->active_workers(),\n+                                                          Threads::number_of_non_daemon_threads());\n+  active_workers = workers()->update_active_workers(active_workers);\n+  log_info(gc,task)(\"Using %u workers of %u for evacuation\", active_workers, workers()->total_workers());\n+}\n+\n+void G1CollectedHeap::prepare_tlabs_for_mutator() {\n+  Ticks start = Ticks::now();\n+\n+  _survivor_evac_stats.adjust_desired_plab_sz();\n+  _old_evac_stats.adjust_desired_plab_sz();\n+\n+  allocate_dummy_regions();\n+\n+  _allocator->init_mutator_alloc_regions();\n+\n+  resize_all_tlabs();\n+\n+  phase_times()->record_resize_tlab_time_ms((Ticks::now() - start).seconds() * 1000.0);\n+}\n+\n+void G1CollectedHeap::retire_tlabs() {\n+  ensure_parsability(true);\n+}\n+\n+void G1CollectedHeap::do_collection_pause_at_safepoint_helper(double target_pause_time_ms) {\n+  ResourceMark rm;\n+\n+  IsGCActiveMark active_gc_mark;\n+  GCIdMark gc_id_mark;\n+  SvcGCMarker sgcm(SvcGCMarker::MINOR);\n+\n+  GCTraceCPUTime tcpu;\n+\n@@ -3018,1 +3029,1 @@\n-  bool should_start_concurrent_mark_operation = collector_state()->in_concurrent_start_gc();\n+  bool should_start_concurrent_mark_operation = determine_start_concurrent_mark_gc();\n@@ -3021,1 +3032,4 @@\n-  \/\/ Inner scope for scope based logging, timers, and stats collection\n+  \/\/ Verification may use the gang workers, so they must be set up before.\n+  \/\/ Individual parallel phases may override this.\n+  set_young_collection_default_active_worker_threads();\n+\n@@ -3023,1 +3037,3 @@\n-    GCTraceCPUTime tcpu;\n+    \/\/ Do timing\/tracing\/statistics\/pre- and post-logging\/verification work not\n+    \/\/ directly related to the collection. They should not be accounted for in\n+    \/\/ collection work timing.\n@@ -3025,0 +3041,2 @@\n+    \/\/ The G1YoungGCTraceTime message depends on collector state, so must come after\n+    \/\/ determining collector state.\n@@ -3027,6 +3045,2 @@\n-    uint active_workers = WorkerPolicy::calc_active_workers(workers()->total_workers(),\n-                                                            workers()->active_workers(),\n-                                                            Threads::number_of_non_daemon_threads());\n-    active_workers = workers()->update_active_workers(active_workers);\n-    log_info(gc,task)(\"Using %u workers of %u for evacuation\", active_workers, workers()->total_workers());\n-\n+    \/\/ Young GC internal timing\n+    policy()->note_gc_start();\n@@ -3042,0 +3056,2 @@\n+    G1HeapVerifier::G1VerifyType verify_type = young_collection_verify_type();\n+    verify_before_young_collection(verify_type);\n@@ -3043,46 +3059,1 @@\n-      IsGCActiveMark x;\n-      gc_prologue(false);\n-\n-      G1HeapVerifier::G1VerifyType verify_type = young_collection_verify_type();\n-      verify_before_young_collection(verify_type);\n-      {\n-        \/\/ The elapsed time induced by the start time below deliberately elides\n-        \/\/ the possible verification above.\n-        double sample_start_time_sec = os::elapsedTime();\n-\n-        \/\/ Please see comment in g1CollectedHeap.hpp and\n-        \/\/ G1CollectedHeap::ref_processing_init() to see how\n-        \/\/ reference processing currently works in G1.\n-        _ref_processor_stw->start_discovery(false \/* always_clear *\/);\n-\n-        policy()->record_collection_pause_start(sample_start_time_sec);\n-\n-        \/\/ Forget the current allocation region (we might even choose it to be part\n-        \/\/ of the collection set!).\n-        _allocator->release_mutator_alloc_regions();\n-\n-        calculate_collection_set(jtm.evacuation_info(), target_pause_time_ms);\n-\n-        G1RedirtyCardsQueueSet rdcqs(G1BarrierSet::dirty_card_queue_set().allocator());\n-        G1ParScanThreadStateSet per_thread_states(this,\n-                                                  &rdcqs,\n-                                                  workers()->active_workers(),\n-                                                  collection_set()->young_region_length(),\n-                                                  collection_set()->optional_region_length());\n-        pre_evacuate_collection_set(jtm.evacuation_info(), &per_thread_states);\n-\n-        bool may_do_optional_evacuation = _collection_set.optional_region_length() != 0;\n-        \/\/ Actually do the work...\n-        evacuate_initial_collection_set(&per_thread_states, may_do_optional_evacuation);\n-\n-        if (may_do_optional_evacuation) {\n-          evacuate_optional_collection_set(&per_thread_states);\n-        }\n-        post_evacuate_collection_set(jtm.evacuation_info(), &rdcqs, &per_thread_states);\n-\n-        start_new_collection_set();\n-\n-        _survivor_evac_stats.adjust_desired_plab_sz();\n-        _old_evac_stats.adjust_desired_plab_sz();\n-\n-        allocate_dummy_regions();\n+      \/\/ Actual collection work starts and is executed (only) in this scope.\n@@ -3090,1 +3061,4 @@\n-        _allocator->init_mutator_alloc_regions();\n+      \/\/ The elapsed time induced by the start time below deliberately elides\n+      \/\/ the possible verification above.\n+      double sample_start_time_sec = os::elapsedTime();\n+      policy()->record_collection_pause_start(sample_start_time_sec);\n@@ -3092,1 +3066,1 @@\n-        expand_heap_after_young_collection();\n+      calculate_collection_set(jtm.evacuation_info(), target_pause_time_ms);\n@@ -3094,3 +3068,7 @@\n-        \/\/ Refine the type of a concurrent mark operation now that we did the\n-        \/\/ evacuation, eventually aborting it.\n-        concurrent_operation_is_full_mark = policy()->concurrent_operation_is_full_mark(\"Revise IHOP\");\n+      G1RedirtyCardsQueueSet rdcqs(G1BarrierSet::dirty_card_queue_set().allocator());\n+      G1ParScanThreadStateSet per_thread_states(this,\n+                                                &rdcqs,\n+                                                workers()->active_workers(),\n+                                                collection_set()->young_region_length(),\n+                                                collection_set()->optional_region_length());\n+      pre_evacuate_collection_set(jtm.evacuation_info(), &per_thread_states);\n@@ -3098,3 +3076,3 @@\n-        \/\/ Need to report the collection pause now since record_collection_pause_end()\n-        \/\/ modifies it to the next state.\n-        jtm.report_pause_type(collector_state()->young_gc_pause_type(concurrent_operation_is_full_mark));\n+      bool may_do_optional_evacuation = _collection_set.optional_region_length() != 0;\n+      \/\/ Actually do the work...\n+      evacuate_initial_collection_set(&per_thread_states, may_do_optional_evacuation);\n@@ -3102,3 +3080,2 @@\n-        double sample_end_time_sec = os::elapsedTime();\n-        double pause_time_ms = (sample_end_time_sec - sample_start_time_sec) * MILLIUNITS;\n-        policy()->record_collection_pause_end(pause_time_ms, concurrent_operation_is_full_mark);\n+      if (may_do_optional_evacuation) {\n+        evacuate_optional_collection_set(&per_thread_states);\n@@ -3106,0 +3083,1 @@\n+      post_evacuate_collection_set(jtm.evacuation_info(), &rdcqs, &per_thread_states);\n@@ -3107,1 +3085,3 @@\n-      verify_after_young_collection(verify_type);\n+      \/\/ Refine the type of a concurrent mark operation now that we did the\n+      \/\/ evacuation, eventually aborting it.\n+      concurrent_operation_is_full_mark = policy()->concurrent_operation_is_full_mark(\"Revise IHOP\");\n@@ -3109,1 +3089,7 @@\n-      gc_epilogue(false);\n+      \/\/ Need to report the collection pause now since record_collection_pause_end()\n+      \/\/ modifies it to the next state.\n+      jtm.report_pause_type(collector_state()->young_gc_pause_type(concurrent_operation_is_full_mark));\n+\n+      double sample_end_time_sec = os::elapsedTime();\n+      double pause_time_ms = (sample_end_time_sec - sample_start_time_sec) * MILLIUNITS;\n+      policy()->record_collection_pause_end(pause_time_ms, concurrent_operation_is_full_mark);\n@@ -3111,0 +3097,1 @@\n+    verify_after_young_collection(verify_type);\n@@ -3120,1 +3107,0 @@\n-\n@@ -3547,0 +3533,5 @@\n+  \/\/ Please see comment in g1CollectedHeap.hpp and\n+  \/\/ G1CollectedHeap::ref_processing_init() to see how\n+  \/\/ reference processing currently works in G1.\n+  _ref_processor_stw->start_discovery(false \/* always_clear *\/);\n+\n@@ -3552,0 +3543,19 @@\n+  wait_for_root_region_scanning();\n+\n+  gc_prologue(false);\n+\n+  {\n+    Ticks start = Ticks::now();\n+    retire_tlabs();\n+    phase_times()->record_prepare_tlab_time_ms((Ticks::now() - start).seconds() * 1000.0);\n+  }\n+\n+  {\n+    \/\/ Flush dirty card queues to qset, so later phases don't need to account\n+    \/\/ for partially filled per-thread queues and such.\n+    Ticks start = Ticks::now();\n+    G1BarrierSet::dirty_card_queue_set().concatenate_logs();\n+    Tickspan dt = Ticks::now() - start;\n+    phase_times()->record_concatenate_dirty_card_logs_time_ms(dt.seconds() * MILLIUNITS);\n+  }\n+\n@@ -3845,0 +3855,8 @@\n+\n+  start_new_collection_set();\n+\n+  prepare_tlabs_for_mutator();\n+\n+  gc_epilogue(false);\n+\n+  expand_heap_after_young_collection();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":119,"deletions":101,"binary":false,"changes":220,"status":"modified"},{"patch":"@@ -803,0 +803,8 @@\n+  void set_young_collection_default_active_worker_threads();\n+\n+  bool determine_start_concurrent_mark_gc();\n+\n+  void prepare_tlabs_for_mutator();\n+\n+  void retire_tlabs();\n+\n@@ -1454,1 +1462,0 @@\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":8,"deletions":1,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -177,0 +177,1 @@\n+  _heap->retire_tlabs();\n@@ -216,0 +217,2 @@\n+  _heap->resize_all_tlabs();\n+\n@@ -220,2 +223,0 @@\n-\n-  _heap->print_heap_after_full_collection();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullCollector.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"}]}