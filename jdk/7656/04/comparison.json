{"files":[{"patch":"@@ -1,1036 +1,1039 @@\n-<!DOCTYPE html>\n-<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\n-<head>\n-  <meta charset=\"utf-8\" \/>\n-  <meta name=\"generator\" content=\"pandoc\" \/>\n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\n-  <title>Building the JDK<\/title>\n-  <style type=\"text\/css\">\n-      code{white-space: pre-wrap;}\n-      span.smallcaps{font-variant: small-caps;}\n-      span.underline{text-decoration: underline;}\n-      div.column{display: inline-block; vertical-align: top; width: 50%;}\n-  <\/style>\n-  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\n-  <!--[if lt IE 9]>\n-    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\n-  <![endif]-->\n-  <style type=\"text\/css\">pre, code, tt { color: #1d6ae5; }<\/style>\n-<\/head>\n-<body>\n-<header id=\"title-block-header\">\n-<h1 class=\"title\">Building the JDK<\/h1>\n-<\/header>\n-<nav id=\"TOC\">\n-<ul>\n-<li><a href=\"#tldr-instructions-for-the-impatient\">TL;DR (Instructions for the Impatient)<\/a><\/li>\n-<li><a href=\"#introduction\">Introduction<\/a><\/li>\n-<li><a href=\"#getting-the-source-code\">Getting the Source Code<\/a><ul>\n-<li><a href=\"#special-considerations\">Special Considerations<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#build-hardware-requirements\">Build Hardware Requirements<\/a><ul>\n-<li><a href=\"#building-on-x86\">Building on x86<\/a><\/li>\n-<li><a href=\"#building-on-aarch64\">Building on aarch64<\/a><\/li>\n-<li><a href=\"#building-on-32-bit-arm\">Building on 32-bit arm<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#operating-system-requirements\">Operating System Requirements<\/a><ul>\n-<li><a href=\"#windows\">Windows<\/a><\/li>\n-<li><a href=\"#macos\">macOS<\/a><\/li>\n-<li><a href=\"#linux\">Linux<\/a><\/li>\n-<li><a href=\"#aix\">AIX<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#native-compiler-toolchain-requirements\">Native Compiler (Toolchain) Requirements<\/a><ul>\n-<li><a href=\"#gcc\">gcc<\/a><\/li>\n-<li><a href=\"#clang\">clang<\/a><\/li>\n-<li><a href=\"#apple-xcode\">Apple Xcode<\/a><\/li>\n-<li><a href=\"#microsoft-visual-studio\">Microsoft Visual Studio<\/a><\/li>\n-<li><a href=\"#ibm-xl-cc\">IBM XL C\/C++<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#boot-jdk-requirements\">Boot JDK Requirements<\/a><ul>\n-<li><a href=\"#getting-jdk-binaries\">Getting JDK binaries<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#external-library-requirements\">External Library Requirements<\/a><ul>\n-<li><a href=\"#freetype\">FreeType<\/a><\/li>\n-<li><a href=\"#cups\">CUPS<\/a><\/li>\n-<li><a href=\"#x11\">X11<\/a><\/li>\n-<li><a href=\"#alsa\">ALSA<\/a><\/li>\n-<li><a href=\"#libffi\">libffi<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#build-tools-requirements\">Build Tools Requirements<\/a><ul>\n-<li><a href=\"#autoconf\">Autoconf<\/a><\/li>\n-<li><a href=\"#gnu-make\">GNU Make<\/a><\/li>\n-<li><a href=\"#gnu-bash\">GNU Bash<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#running-configure\">Running Configure<\/a><ul>\n-<li><a href=\"#common-configure-arguments\">Common Configure Arguments<\/a><\/li>\n-<li><a href=\"#configure-control-variables\">Configure Control Variables<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#running-make\">Running Make<\/a><ul>\n-<li><a href=\"#common-make-targets\">Common Make Targets<\/a><\/li>\n-<li><a href=\"#make-control-variables\">Make Control Variables<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#running-tests\">Running Tests<\/a><\/li>\n-<li><a href=\"#cross-compiling\">Cross-compiling<\/a><ul>\n-<li><a href=\"#cross-compiling-the-easy-way-with-openjdk-devkits\">Cross compiling the easy way with OpenJDK devkits<\/a><\/li>\n-<li><a href=\"#boot-jdk-and-build-jdk\">Boot JDK and Build JDK<\/a><\/li>\n-<li><a href=\"#specifying-the-target-platform\">Specifying the Target Platform<\/a><\/li>\n-<li><a href=\"#toolchain-considerations\">Toolchain Considerations<\/a><\/li>\n-<li><a href=\"#native-libraries\">Native Libraries<\/a><\/li>\n-<li><a href=\"#cross-compiling-with-debian-sysroots\">Cross compiling with Debian sysroots<\/a><\/li>\n-<li><a href=\"#building-for-armaarch64\">Building for ARM\/aarch64<\/a><\/li>\n-<li><a href=\"#building-for-musl\">Building for musl<\/a><\/li>\n-<li><a href=\"#verifying-the-build\">Verifying the Build<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#build-performance\">Build Performance<\/a><ul>\n-<li><a href=\"#disk-speed\">Disk Speed<\/a><\/li>\n-<li><a href=\"#virus-checking\">Virus Checking<\/a><\/li>\n-<li><a href=\"#ccache\">Ccache<\/a><\/li>\n-<li><a href=\"#precompiled-headers\">Precompiled Headers<\/a><\/li>\n-<li><a href=\"#icecc-icecream\">Icecc \/ icecream<\/a><\/li>\n-<li><a href=\"#using-sjavac\">Using sjavac<\/a><\/li>\n-<li><a href=\"#building-the-right-target\">Building the Right Target<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#troubleshooting\">Troubleshooting<\/a><ul>\n-<li><a href=\"#locating-the-source-of-the-error\">Locating the Source of the Error<\/a><\/li>\n-<li><a href=\"#fixing-unexpected-build-failures\">Fixing Unexpected Build Failures<\/a><\/li>\n-<li><a href=\"#specific-build-issues\">Specific Build Issues<\/a><\/li>\n-<li><a href=\"#getting-help\">Getting Help<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#reproducible-builds\">Reproducible Builds<\/a><\/li>\n-<li><a href=\"#hints-and-suggestions-for-advanced-users\">Hints and Suggestions for Advanced Users<\/a><ul>\n-<li><a href=\"#bash-completion\">Bash Completion<\/a><\/li>\n-<li><a href=\"#using-multiple-configurations\">Using Multiple Configurations<\/a><\/li>\n-<li><a href=\"#handling-reconfigurations\">Handling Reconfigurations<\/a><\/li>\n-<li><a href=\"#using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#understanding-the-build-system\">Understanding the Build System<\/a><ul>\n-<li><a href=\"#configurations\">Configurations<\/a><\/li>\n-<li><a href=\"#build-output-structure\">Build Output Structure<\/a><\/li>\n-<li><a href=\"#fixpath\">Fixpath<\/a><\/li>\n-<li><a href=\"#native-debug-symbols\">Native Debug Symbols<\/a><\/li>\n-<li><a href=\"#autoconf-details\">Autoconf Details<\/a><\/li>\n-<li><a href=\"#developing-the-build-system-itself\">Developing the Build System Itself<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#contributing-to-the-jdk\">Contributing to the JDK<\/a><\/li>\n-<\/ul>\n-<\/nav>\n-<h2 id=\"tldr-instructions-for-the-impatient\">TL;DR (Instructions for the Impatient)<\/h2>\n-<p>If you are eager to try out building the JDK, these simple steps works most of the time. They assume that you have installed Git (and Cygwin if running on Windows) and cloned the top-level JDK repository that you want to build.<\/p>\n-<ol type=\"1\">\n-<li><p><a href=\"#getting-the-source-code\">Get the complete source code<\/a>:<br \/>\n-<code>git clone https:\/\/git.openjdk.java.net\/jdk\/<\/code><\/p><\/li>\n-<li><p><a href=\"#running-configure\">Run configure<\/a>:<br \/>\n-<code>bash configure<\/code><\/p>\n-<p>If <code>configure<\/code> fails due to missing dependencies (to either the <a href=\"#native-compiler-toolchain-requirements\">toolchain<\/a>, <a href=\"#build-tools-requirements\">build tools<\/a>, <a href=\"#external-library-requirements\">external libraries<\/a> or the <a href=\"#boot-jdk-requirements\">boot JDK<\/a>), most of the time it prints a suggestion on how to resolve the situation on your platform. Follow the instructions, and try running <code>bash configure<\/code> again.<\/p><\/li>\n-<li><p><a href=\"#running-make\">Run make<\/a>:<br \/>\n-<code>make images<\/code><\/p><\/li>\n-<li><p>Verify your newly built JDK:<br \/>\n-<code>.\/build\/*\/images\/jdk\/bin\/java -version<\/code><\/p><\/li>\n-<li><p><a href=\"##running-tests\">Run basic tests<\/a>:<br \/>\n-<code>make run-test-tier1<\/code><\/p><\/li>\n-<\/ol>\n-<p>If any of these steps failed, or if you want to know more about build requirements or build functionality, please continue reading this document.<\/p>\n-<h2 id=\"introduction\">Introduction<\/h2>\n-<p>The JDK is a complex software project. Building it requires a certain amount of technical expertise, a fair number of dependencies on external software, and reasonably powerful hardware.<\/p>\n-<p>If you just want to use the JDK and not build it yourself, this document is not for you. See for instance <a href=\"http:\/\/openjdk.java.net\/install\">OpenJDK installation<\/a> for some methods of installing a prebuilt JDK.<\/p>\n-<h2 id=\"getting-the-source-code\">Getting the Source Code<\/h2>\n-<p>Make sure you are getting the correct version. As of JDK 10, the source is no longer split into separate repositories so you only need to clone one single repository. At the <a href=\"https:\/\/git.openjdk.java.net\/\">OpenJDK Git site<\/a> you can see a list of all available repositories. If you want to build an older version, e.g. JDK 11, it is recommended that you get the <code>jdk11u<\/code> repo, which contains incremental updates, instead of the <code>jdk11<\/code> repo, which was frozen at JDK 11 GA.<\/p>\n-<p>If you are new to Git, a good place to start is the book <a href=\"https:\/\/git-scm.com\/book\/en\/v2\">Pro Git<\/a>. The rest of this document assumes a working knowledge of Git.<\/p>\n-<h3 id=\"special-considerations\">Special Considerations<\/h3>\n-<p>For a smooth building experience, it is recommended that you follow these rules on where and how to check out the source code.<\/p>\n-<ul>\n-<li><p>Do not check out the source code in a path which contains spaces. Chances are the build will not work. This is most likely to be an issue on Windows systems.<\/p><\/li>\n-<li><p>Do not check out the source code in a path which has a very long name or is nested many levels deep. Chances are you will hit an OS limitation during the build.<\/p><\/li>\n-<li><p>Put the source code on a local disk, not a network share. If possible, use an SSD. The build process is very disk intensive, and having slow disk access will significantly increase build times. If you need to use a network share for the source code, see below for suggestions on how to keep the build artifacts on a local disk.<\/p><\/li>\n-<li><p>On Windows, if using <a href=\"#cygwin\">Cygwin<\/a>, extra care must be taken to make sure the environment is consistent. It is recommended that you follow this procedure:<\/p>\n-<ul>\n-<li><p>Create the directory that is going to contain the top directory of the JDK clone by using the <code>mkdir<\/code> command in the Cygwin bash shell. That is, do <em>not<\/em> create it using Windows Explorer. This will ensure that it will have proper Cygwin attributes, and that it's children will inherit those attributes.<\/p><\/li>\n-<li><p>Do not put the JDK clone in a path under your Cygwin home directory. This is especially important if your user name contains spaces and\/or mixed upper and lower case letters.<\/p><\/li>\n-<li><p>You need to install a git client. You have two choices, Cygwin git or Git for Windows. Unfortunately there are pros and cons with each choice.<\/p>\n-<ul>\n-<li><p>The Cygwin <code>git<\/code> client has no line ending issues and understands Cygwin paths (which are used throughout the JDK build system). However, it does not currently work well with the Skara CLI tooling. Please see the <a href=\"https:\/\/wiki.openjdk.java.net\/display\/SKARA\/Skara#Skara-Git\">Skara wiki on Git clients<\/a> for up-to-date information about the Skara git client support.<\/p><\/li>\n-<li><p>The <a href=\"https:\/\/gitforwindows.org\">Git for Windows<\/a> client has issues with line endings, and do not understand Cygwin paths. It does work well with the Skara CLI tooling, however. To alleviate the line ending problems, make sure you set <code>core.autocrlf<\/code> to <code>false<\/code> (this is asked during installation).<\/p><\/li>\n-<\/ul><\/li>\n-<\/ul>\n-<p>Failure to follow this procedure might result in hard-to-debug build problems.<\/p><\/li>\n-<\/ul>\n-<h2 id=\"build-hardware-requirements\">Build Hardware Requirements<\/h2>\n-<p>The JDK is a massive project, and require machines ranging from decent to powerful to be able to build in a reasonable amount of time, or to be able to complete a build at all.<\/p>\n-<p>We <em>strongly<\/em> recommend usage of an SSD disk for the build, since disk speed is one of the limiting factors for build performance.<\/p>\n-<h3 id=\"building-on-x86\">Building on x86<\/h3>\n-<p>At a minimum, a machine with 2-4 cores is advisable, as well as 2-4 GB of RAM. (The more cores to use, the more memory you need.) At least 6 GB of free disk space is required.<\/p>\n-<p>Even for 32-bit builds, it is recommended to use a 64-bit build machine, and instead create a 32-bit target using <code>--with-target-bits=32<\/code>.<\/p>\n-<h3 id=\"building-on-aarch64\">Building on aarch64<\/h3>\n-<p>At a minimum, a machine with 8 cores is advisable, as well as 8 GB of RAM. (The more cores to use, the more memory you need.) At least 6 GB of free disk space is required.<\/p>\n-<p>If you do not have access to sufficiently powerful hardware, it is also possible to use <a href=\"#cross-compiling\">cross-compiling<\/a>.<\/p>\n-<h3 id=\"building-on-32-bit-arm\">Building on 32-bit arm<\/h3>\n-<p>This is not recommended. Instead, see the section on <a href=\"#cross-compiling\">Cross-compiling<\/a>.<\/p>\n-<h2 id=\"operating-system-requirements\">Operating System Requirements<\/h2>\n-<p>The mainline JDK project supports Linux, macOS, AIX and Windows. Support for other operating system, e.g. BSD, exists in separate &quot;port&quot; projects.<\/p>\n-<p>In general, the JDK can be built on a wide range of versions of these operating systems, but the further you deviate from what is tested on a daily basis, the more likely you are to run into problems.<\/p>\n-<p>This table lists the OS versions used by Oracle when building the JDK. Such information is always subject to change, but this table is up to date at the time of writing.<\/p>\n-<table>\n-<thead>\n-<tr class=\"header\">\n-<th style=\"text-align: left;\">Operating system<\/th>\n-<th style=\"text-align: left;\">Vendor\/version used<\/th>\n-<\/tr>\n-<\/thead>\n-<tbody>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">Linux<\/td>\n-<td style=\"text-align: left;\">Oracle Enterprise Linux 6.4 \/ 7.6<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">macOS<\/td>\n-<td style=\"text-align: left;\">Mac OS X 10.13 (High Sierra)<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">Windows<\/td>\n-<td style=\"text-align: left;\">Windows Server 2012 R2<\/td>\n-<\/tr>\n-<\/tbody>\n-<\/table>\n-<p>The double version numbers for Linux are due to the hybrid model used at Oracle, where header files and external libraries from an older version are used when building on a more modern version of the OS.<\/p>\n-<p>The Build Group has a wiki page with <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Build\/Supported+Build+Platforms\">Supported Build Platforms<\/a>. From time to time, this is updated by contributors to list successes or failures of building on different platforms.<\/p>\n-<h3 id=\"windows\">Windows<\/h3>\n-<p>Windows XP is not a supported platform, but all newer Windows should be able to build the JDK.<\/p>\n-<p>On Windows, it is important that you pay attention to the instructions in the <a href=\"#special-considerations\">Special Considerations<\/a>.<\/p>\n-<p>Windows is the only non-POSIX OS supported by the JDK, and as such, requires some extra care. A POSIX support layer is required to build on Windows. Currently, the only supported such layers are Cygwin, Windows Subsystem for Linux (WSL), and MSYS2. (MSYS is no longer supported due to an outdated bash; While OpenJDK can be built with MSYS2, support for it is still experimental, so build failures and unusual errors are not uncommon.)<\/p>\n-<p>Internally in the build system, all paths are represented as Unix-style paths, e.g. <code>\/cygdrive\/c\/git\/jdk\/Makefile<\/code> rather than <code>C:\\git\\jdk\\Makefile<\/code>. This rule also applies to input to the build system, e.g. in arguments to <code>configure<\/code>. So, use <code>--with-msvcr-dll=\/cygdrive\/c\/msvcr100.dll<\/code> rather than <code>--with-msvcr-dll=c:\\msvcr100.dll<\/code>. For details on this conversion, see the section on <a href=\"#fixpath\">Fixpath<\/a>.<\/p>\n-<h4 id=\"cygwin\">Cygwin<\/h4>\n-<p>A functioning <a href=\"http:\/\/www.cygwin.com\/\">Cygwin<\/a> environment is required for building the JDK on Windows. If you have a 64-bit OS, we strongly recommend using the 64-bit version of Cygwin.<\/p>\n-<p><strong>Note:<\/strong> Cygwin has a model of continuously updating all packages without any easy way to install or revert to a specific version of a package. This means that whenever you add or update a package in Cygwin, you might (inadvertently) update tools that are used by the JDK build process, and that can cause unexpected build problems.<\/p>\n-<p>The JDK requires GNU Make 4.0 or greater in Cygwin. This is usually not a problem, since Cygwin currently only distributes GNU Make at a version above 4.0.<\/p>\n-<p>Apart from the basic Cygwin installation, the following packages must also be installed:<\/p>\n-<ul>\n-<li><code>autoconf<\/code><\/li>\n-<li><code>make<\/code><\/li>\n-<li><code>zip<\/code><\/li>\n-<li><code>unzip<\/code><\/li>\n-<\/ul>\n-<p>Often, you can install these packages using the following command line:<\/p>\n-<pre><code>&lt;path to Cygwin setup&gt;\/setup-x86_64 -q -P autoconf -P make -P unzip -P zip<\/code><\/pre>\n-<p>Unfortunately, Cygwin can be unreliable in certain circumstances. If you experience build tool crashes or strange issues when building on Windows, please check the Cygwin FAQ on the <a href=\"https:\/\/cygwin.com\/faq\/faq.html#faq.using.bloda\">&quot;BLODA&quot; list<\/a> and the section on <a href=\"https:\/\/cygwin.com\/faq\/faq.html#faq.using.fixing-fork-failures\">fork() failures<\/a>.<\/p>\n-<h4 id=\"windows-subsystem-for-linux-wsl\">Windows Subsystem for Linux (WSL)<\/h4>\n-<p>Windows 10 1809 or newer is supported due to a dependency on the wslpath utility and support for environment variable sharing through WSLENV. Version 1803 can work but intermittent build failures have been observed.<\/p>\n-<p>It's possible to build both Windows and Linux binaries from WSL. To build Windows binaries, you must use a Windows boot JDK (located in a Windows-accessible directory). To build Linux binaries, you must use a Linux boot JDK. The default behavior is to build for Windows. To build for Linux, pass <code>--build=x86_64-unknown-linux-gnu --host=x86_64-unknown-linux-gnu<\/code> to <code>configure<\/code>.<\/p>\n-<p>If building Windows binaries, the source code must be located in a Windows- accessible directory. This is because Windows executables (such as Visual Studio and the boot JDK) must be able to access the source code. Also, the drive where the source is stored must be mounted as case-insensitive by changing either \/etc\/fstab or \/etc\/wsl.conf in WSL. Individual directories may be corrected using the fsutil tool in case the source was cloned before changing the mount options.<\/p>\n-<p>Note that while it's possible to build on WSL, testing is still not fully supported.<\/p>\n-<h3 id=\"macos\">macOS<\/h3>\n-<p>Apple is using a quite aggressive scheme of pushing OS updates, and coupling these updates with required updates of Xcode. Unfortunately, this makes it difficult for a project such as the JDK to keep pace with a continuously updated machine running macOS. See the section on <a href=\"#apple-xcode\">Apple Xcode<\/a> on some strategies to deal with this.<\/p>\n-<p>It is recommended that you use at least Mac OS X 10.13 (High Sierra). At the time of writing, the JDK has been successfully compiled on macOS 10.12 (Sierra).<\/p>\n-<p>The standard macOS environment contains the basic tooling needed to build, but for external libraries a package manager is recommended. The JDK uses <a href=\"https:\/\/brew.sh\/\">homebrew<\/a> in the examples, but feel free to use whatever manager you want (or none).<\/p>\n-<h3 id=\"linux\">Linux<\/h3>\n-<p>It is often not much problem to build the JDK on Linux. The only general advice is to try to use the compilers, external libraries and header files as provided by your distribution.<\/p>\n-<p>The basic tooling is provided as part of the core operating system, but you will most likely need to install developer packages.<\/p>\n-<p>For apt-based distributions (Debian, Ubuntu, etc), try this:<\/p>\n-<pre><code>sudo apt-get install build-essential<\/code><\/pre>\n-<p>For rpm-based distributions (Fedora, Red Hat, etc), try this:<\/p>\n-<pre><code>sudo yum groupinstall &quot;Development Tools&quot;<\/code><\/pre>\n-<p>For Alpine Linux, aside from basic tooling, install the GNU versions of some programs:<\/p>\n-<pre><code>sudo apk add build-base bash grep zip<\/code><\/pre>\n-<h3 id=\"aix\">AIX<\/h3>\n-<p>Please consult the AIX section of the <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Build\/Supported+Build+Platforms\">Supported Build Platforms<\/a> OpenJDK Build Wiki page for details about which versions of AIX are supported.<\/p>\n-<h2 id=\"native-compiler-toolchain-requirements\">Native Compiler (Toolchain) Requirements<\/h2>\n-<p>Large portions of the JDK consists of native code, that needs to be compiled to be able to run on the target platform. In theory, toolchain and operating system should be independent factors, but in practice there's more or less a one-to-one correlation between target operating system and toolchain.<\/p>\n-<table>\n-<thead>\n-<tr class=\"header\">\n-<th style=\"text-align: left;\">Operating system<\/th>\n-<th style=\"text-align: left;\">Supported toolchain<\/th>\n-<\/tr>\n-<\/thead>\n-<tbody>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">Linux<\/td>\n-<td style=\"text-align: left;\">gcc, clang<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">macOS<\/td>\n-<td style=\"text-align: left;\">Apple Xcode (using clang)<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">AIX<\/td>\n-<td style=\"text-align: left;\">IBM XL C\/C++<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">Windows<\/td>\n-<td style=\"text-align: left;\">Microsoft Visual Studio<\/td>\n-<\/tr>\n-<\/tbody>\n-<\/table>\n-<p>Please see the individual sections on the toolchains for version recommendations. As a reference, these versions of the toolchains are used, at the time of writing, by Oracle for the daily builds of the JDK. It should be possible to compile the JDK with both older and newer versions, but the closer you stay to this list, the more likely you are to compile successfully without issues.<\/p>\n-<table>\n-<thead>\n-<tr class=\"header\">\n-<th style=\"text-align: left;\">Operating system<\/th>\n-<th style=\"text-align: left;\">Toolchain version<\/th>\n-<\/tr>\n-<\/thead>\n-<tbody>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">Linux<\/td>\n-<td style=\"text-align: left;\">gcc 10.2.0<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">macOS<\/td>\n-<td style=\"text-align: left;\">Apple Xcode 10.1 (using clang 10.0.0)<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">Windows<\/td>\n-<td style=\"text-align: left;\">Microsoft Visual Studio 2019 update 16.7.2<\/td>\n-<\/tr>\n-<\/tbody>\n-<\/table>\n-<p>All compilers are expected to be able to compile to the C99 language standard, as some C99 features are used in the source code. Microsoft Visual Studio doesn't fully support C99 so in practice shared code is limited to using C99 features that it does support.<\/p>\n-<h3 id=\"gcc\">gcc<\/h3>\n-<p>The minimum accepted version of gcc is 5.0. Older versions will generate a warning by <code>configure<\/code> and are unlikely to work.<\/p>\n-<p>The JDK is currently known to be able to compile with at least version 10.2 of gcc.<\/p>\n-<p>In general, any version between these two should be usable.<\/p>\n-<h3 id=\"clang\">clang<\/h3>\n-<p>The minimum accepted version of clang is 3.5. Older versions will not be accepted by <code>configure<\/code>.<\/p>\n-<p>To use clang instead of gcc on Linux, use <code>--with-toolchain-type=clang<\/code>.<\/p>\n-<h3 id=\"apple-xcode\">Apple Xcode<\/h3>\n-<p>The oldest supported version of Xcode is 8.<\/p>\n-<p>You will need the Xcode command lines developers tools to be able to build the JDK. (Actually, <em>only<\/em> the command lines tools are needed, not the IDE.) The simplest way to install these is to run:<\/p>\n-<pre><code>xcode-select --install<\/code><\/pre>\n-<p>It is advisable to keep an older version of Xcode for building the JDK when updating Xcode. This <a href=\"http:\/\/iosdevelopertips.com\/xcode\/install-multiple-versions-of-xcode.html\">blog page<\/a> has good suggestions on managing multiple Xcode versions. To use a specific version of Xcode, use <code>xcode-select -s<\/code> before running <code>configure<\/code>, or use <code>--with-toolchain-path<\/code> to point to the version of Xcode to use, e.g. <code>configure --with-toolchain-path=\/Applications\/Xcode8.app\/Contents\/Developer\/usr\/bin<\/code><\/p>\n-<p>If you have recently (inadvertently) updated your OS and\/or Xcode version, and the JDK can no longer be built, please see the section on <a href=\"#problems-with-the-build-environment\">Problems with the Build Environment<\/a>, and <a href=\"#getting-help\">Getting Help<\/a> to find out if there are any recent, non-merged patches available for this update.<\/p>\n-<h3 id=\"microsoft-visual-studio\">Microsoft Visual Studio<\/h3>\n-<p>For aarch64 machines running Windows the minimum accepted version is Visual Studio 2019 (16.8 or higher). For all other platforms the minimum accepted version of Visual Studio is 2017. Older versions will not be accepted by <code>configure<\/code> and will not work. For all platforms the maximum accepted version of Visual Studio is 2022.<\/p>\n-<p>If you have multiple versions of Visual Studio installed, <code>configure<\/code> will by default pick the latest. You can request a specific version to be used by setting <code>--with-toolchain-version<\/code>, e.g. <code>--with-toolchain-version=2017<\/code>.<\/p>\n-<p>If you have Visual Studio installed but <code>configure<\/code> fails to detect it, it may be because of <a href=\"#spaces-in-path\">spaces in path<\/a>.<\/p>\n-<h3 id=\"ibm-xl-cc\">IBM XL C\/C++<\/h3>\n-<p>Please consult the AIX section of the <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Build\/Supported+Build+Platforms\">Supported Build Platforms<\/a> OpenJDK Build Wiki page for details about which versions of XLC are supported.<\/p>\n-<h2 id=\"boot-jdk-requirements\">Boot JDK Requirements<\/h2>\n-<p>Paradoxically, building the JDK requires a pre-existing JDK. This is called the &quot;boot JDK&quot;. The boot JDK does not, however, have to be a JDK built directly from the source code available in the OpenJDK Community. If you are porting the JDK to a new platform, chances are that there already exists another JDK for that platform that is usable as boot JDK.<\/p>\n-<p>The rule of thumb is that the boot JDK for building JDK major version <em>N<\/em> should be a JDK of major version <em>N-1<\/em>, so for building JDK 9 a JDK 8 would be suitable as boot JDK. However, the JDK should be able to &quot;build itself&quot;, so an up-to-date build of the current JDK source is an acceptable alternative. If you are following the <em>N-1<\/em> rule, make sure you've got the latest update version, since JDK 8 GA might not be able to build JDK 9 on all platforms.<\/p>\n-<p>Early in the release cycle, version <em>N-1<\/em> may not yet have been released. In that case, the preferred boot JDK will be version <em>N-2<\/em> until version <em>N-1<\/em> is available.<\/p>\n-<p>If the boot JDK is not automatically detected, or the wrong JDK is picked, use <code>--with-boot-jdk<\/code> to point to the JDK to use.<\/p>\n-<h3 id=\"getting-jdk-binaries\">Getting JDK binaries<\/h3>\n-<p>JDK binaries for Linux, Windows and macOS can be downloaded from <a href=\"http:\/\/jdk.java.net\">jdk.java.net<\/a>. An alternative is to download the <a href=\"http:\/\/www.oracle.com\/technetwork\/java\/javase\/downloads\">Oracle JDK<\/a>. Another is the <a href=\"https:\/\/adoptopenjdk.net\/\">Adopt OpenJDK Project<\/a>, which publishes experimental prebuilt binaries for various platforms.<\/p>\n-<p>On Linux you can also get a JDK from the Linux distribution. On apt-based distros (like Debian and Ubuntu), <code>sudo apt-get install openjdk-&lt;VERSION&gt;-jdk<\/code> is typically enough to install a JDK &lt;VERSION&gt;. On rpm-based distros (like Fedora and Red Hat), try <code>sudo yum install java-&lt;VERSION&gt;-openjdk-devel<\/code>.<\/p>\n-<h2 id=\"external-library-requirements\">External Library Requirements<\/h2>\n-<p>Different platforms require different external libraries. In general, libraries are not optional - that is, they are either required or not used.<\/p>\n-<p>If a required library is not detected by <code>configure<\/code>, you need to provide the path to it. There are two forms of the <code>configure<\/code> arguments to point to an external library: <code>--with-&lt;LIB&gt;=&lt;path&gt;<\/code> or <code>--with-&lt;LIB&gt;-include=&lt;path to include&gt; --with-&lt;LIB&gt;-lib=&lt;path to lib&gt;<\/code>. The first variant is more concise, but require the include files and library files to reside in a default hierarchy under this directory. In most cases, it works fine.<\/p>\n-<p>As a fallback, the second version allows you to point to the include directory and the lib directory separately.<\/p>\n-<h3 id=\"freetype\">FreeType<\/h3>\n-<p>FreeType2 from <a href=\"http:\/\/www.freetype.org\/\">The FreeType Project<\/a> is not required on any platform. The exception is on Unix-based platforms when configuring such that the build artifacts will reference a system installed library, rather than bundling the JDK's own copy.<\/p>\n-<ul>\n-<li>To install on an apt-based Linux, try running <code>sudo apt-get install libfreetype6-dev<\/code>.<\/li>\n-<li>To install on an rpm-based Linux, try running <code>sudo yum install freetype-devel<\/code>.<\/li>\n-<li>To install on Alpine Linux, try running <code>sudo apk add freetype-dev<\/code>.<\/li>\n-<li>To install on macOS, try running <code>brew install freetype<\/code>.<\/li>\n-<\/ul>\n-<p>Use <code>--with-freetype-include=&lt;path&gt;<\/code> and <code>--with-freetype-lib=&lt;path&gt;<\/code> if <code>configure<\/code> does not automatically locate the platform FreeType files.<\/p>\n-<h3 id=\"cups\">CUPS<\/h3>\n-<p>CUPS, <a href=\"http:\/\/www.cups.org\">Common UNIX Printing System<\/a> header files are required on all platforms, except Windows. Often these files are provided by your operating system.<\/p>\n-<ul>\n-<li>To install on an apt-based Linux, try running <code>sudo apt-get install libcups2-dev<\/code>.<\/li>\n-<li>To install on an rpm-based Linux, try running <code>sudo yum install cups-devel<\/code>.<\/li>\n-<li>To install on Alpine Linux, try running <code>sudo apk add cups-dev<\/code>.<\/li>\n-<\/ul>\n-<p>Use <code>--with-cups=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your CUPS files.<\/p>\n-<h3 id=\"x11\">X11<\/h3>\n-<p>Certain <a href=\"http:\/\/www.x.org\/\">X11<\/a> libraries and include files are required on Linux.<\/p>\n-<ul>\n-<li>To install on an apt-based Linux, try running <code>sudo apt-get install libx11-dev libxext-dev libxrender-dev libxrandr-dev libxtst-dev libxt-dev<\/code>.<\/li>\n-<li>To install on an rpm-based Linux, try running <code>sudo yum install libXtst-devel libXt-devel libXrender-devel libXrandr-devel libXi-devel<\/code>.<\/li>\n-<li>To install on Alpine Linux, try running <code>sudo apk add libx11-dev libxext-dev libxrender-dev libxrandr-dev libxtst-dev libxt-dev<\/code>.<\/li>\n-<\/ul>\n-<p>Use <code>--with-x=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your X11 files.<\/p>\n-<h3 id=\"alsa\">ALSA<\/h3>\n-<p>ALSA, <a href=\"https:\/\/www.alsa-project.org\/\">Advanced Linux Sound Architecture<\/a> is required on Linux. At least version 0.9.1 of ALSA is required.<\/p>\n-<ul>\n-<li>To install on an apt-based Linux, try running <code>sudo apt-get install libasound2-dev<\/code>.<\/li>\n-<li>To install on an rpm-based Linux, try running <code>sudo yum install alsa-lib-devel<\/code>.<\/li>\n-<li>To install on Alpine Linux, try running <code>sudo apk add alsa-lib-dev<\/code>.<\/li>\n-<\/ul>\n-<p>Use <code>--with-alsa=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your ALSA files.<\/p>\n-<h3 id=\"libffi\">libffi<\/h3>\n-<p>libffi, the <a href=\"http:\/\/sourceware.org\/libffi\">Portable Foreign Function Interface Library<\/a> is required when building the Zero version of Hotspot.<\/p>\n-<ul>\n-<li>To install on an apt-based Linux, try running <code>sudo apt-get install libffi-dev<\/code>.<\/li>\n-<li>To install on an rpm-based Linux, try running <code>sudo yum install libffi-devel<\/code>.<\/li>\n-<li>To install on Alpine Linux, try running <code>sudo apk add libffi-dev<\/code>.<\/li>\n-<\/ul>\n-<p>Use <code>--with-libffi=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your libffi files.<\/p>\n-<h2 id=\"build-tools-requirements\">Build Tools Requirements<\/h2>\n-<h3 id=\"autoconf\">Autoconf<\/h3>\n-<p>The JDK requires <a href=\"http:\/\/www.gnu.org\/software\/autoconf\">Autoconf<\/a> on all platforms. At least version 2.69 is required.<\/p>\n-<ul>\n-<li>To install on an apt-based Linux, try running <code>sudo apt-get install autoconf<\/code>.<\/li>\n-<li>To install on an rpm-based Linux, try running <code>sudo yum install autoconf<\/code>.<\/li>\n-<li>To install on Alpine Linux, try running <code>sudo apk add autoconf<\/code>.<\/li>\n-<li>To install on macOS, try running <code>brew install autoconf<\/code>.<\/li>\n-<li>To install on Windows, try running <code>&lt;path to Cygwin setup&gt;\/setup-x86_64 -q -P autoconf<\/code>.<\/li>\n-<\/ul>\n-<p>If <code>configure<\/code> has problems locating your installation of autoconf, you can specify it using the <code>AUTOCONF<\/code> environment variable, like this:<\/p>\n-<pre><code>AUTOCONF=&lt;path to autoconf&gt; configure ...<\/code><\/pre>\n-<h3 id=\"gnu-make\">GNU Make<\/h3>\n-<p>The JDK requires <a href=\"http:\/\/www.gnu.org\/software\/make\">GNU Make<\/a>. No other flavors of make are supported.<\/p>\n-<p>At least version 3.81 of GNU Make must be used. For distributions supporting GNU Make 4.0 or above, we strongly recommend it. GNU Make 4.0 contains useful functionality to handle parallel building (supported by <code>--with-output-sync<\/code>) and speed and stability improvements.<\/p>\n-<p>Note that <code>configure<\/code> locates and verifies a properly functioning version of <code>make<\/code> and stores the path to this <code>make<\/code> binary in the configuration. If you start a build using <code>make<\/code> on the command line, you will be using the version of make found first in your <code>PATH<\/code>, and not necessarily the one stored in the configuration. This initial make will be used as &quot;bootstrap make&quot;, and in a second stage, the make located by <code>configure<\/code> will be called. Normally, this will present no issues, but if you have a very old <code>make<\/code>, or a non-GNU Make <code>make<\/code> in your path, this might cause issues.<\/p>\n-<p>If you want to override the default make found by <code>configure<\/code>, use the <code>MAKE<\/code> configure variable, e.g. <code>configure MAKE=\/opt\/gnu\/make<\/code>.<\/p>\n-<h3 id=\"gnu-bash\">GNU Bash<\/h3>\n-<p>The JDK requires <a href=\"http:\/\/www.gnu.org\/software\/bash\">GNU Bash<\/a>. No other shells are supported.<\/p>\n-<p>At least version 3.2 of GNU Bash must be used.<\/p>\n-<h2 id=\"running-configure\">Running Configure<\/h2>\n-<p>To build the JDK, you need a &quot;configuration&quot;, which consists of a directory where to store the build output, coupled with information about the platform, the specific build machine, and choices that affect how the JDK is built.<\/p>\n-<p>The configuration is created by the <code>configure<\/code> script. The basic invocation of the <code>configure<\/code> script looks like this:<\/p>\n-<pre><code>bash configure [options]<\/code><\/pre>\n-<p>This will create an output directory containing the configuration and setup an area for the build result. This directory typically looks like <code>build\/linux-x64-server-release<\/code>, but the actual name depends on your specific configuration. (It can also be set directly, see <a href=\"#using-multiple-configurations\">Using Multiple Configurations<\/a>). This directory is referred to as <code>$BUILD<\/code> in this documentation.<\/p>\n-<p><code>configure<\/code> will try to figure out what system you are running on and where all necessary build components are. If you have all prerequisites for building installed, it should find everything. If it fails to detect any component automatically, it will exit and inform you about the problem.<\/p>\n-<p>Some command line examples:<\/p>\n-<ul>\n-<li><p>Create a 32-bit build for Windows with FreeType2 in <code>C:\\freetype-i586<\/code>:<\/p>\n-<pre><code>bash configure --with-freetype=\/cygdrive\/c\/freetype-i586 --with-target-bits=32<\/code><\/pre><\/li>\n-<li><p>Create a debug build with the <code>server<\/code> JVM and DTrace enabled:<\/p>\n-<pre><code>bash configure --enable-debug --with-jvm-variants=server --enable-dtrace<\/code><\/pre><\/li>\n-<\/ul>\n-<h3 id=\"common-configure-arguments\">Common Configure Arguments<\/h3>\n-<p>Here follows some of the most common and important <code>configure<\/code> argument.<\/p>\n-<p>To get up-to-date information on <em>all<\/em> available <code>configure<\/code> argument, please run:<\/p>\n-<pre><code>bash configure --help<\/code><\/pre>\n-<p>(Note that this help text also include general autoconf options, like <code>--dvidir<\/code>, that is not relevant to the JDK. To list only JDK-specific features, use <code>bash configure --help=short<\/code> instead.)<\/p>\n-<h4 id=\"configure-arguments-for-tailoring-the-build\">Configure Arguments for Tailoring the Build<\/h4>\n-<ul>\n-<li><code>--enable-debug<\/code> - Set the debug level to <code>fastdebug<\/code> (this is a shorthand for <code>--with-debug-level=fastdebug<\/code>)<\/li>\n-<li><code>--with-debug-level=&lt;level&gt;<\/code> - Set the debug level, which can be <code>release<\/code>, <code>fastdebug<\/code>, <code>slowdebug<\/code> or <code>optimized<\/code>. Default is <code>release<\/code>. <code>optimized<\/code> is variant of <code>release<\/code> with additional Hotspot debug code.<\/li>\n-<li><code>--with-native-debug-symbols=&lt;method&gt;<\/code> - Specify if and how native debug symbols should be built. Available methods are <code>none<\/code>, <code>internal<\/code>, <code>external<\/code>, <code>zipped<\/code>. Default behavior depends on platform. See <a href=\"#native-debug-symbols\">Native Debug Symbols<\/a> for more details.<\/li>\n-<li><code>--with-version-string=&lt;string&gt;<\/code> - Specify the version string this build will be identified with.<\/li>\n-<li><code>--with-version-&lt;part&gt;=&lt;value&gt;<\/code> - A group of options, where <code>&lt;part&gt;<\/code> can be any of <code>pre<\/code>, <code>opt<\/code>, <code>build<\/code>, <code>major<\/code>, <code>minor<\/code>, <code>security<\/code> or <code>patch<\/code>. Use these options to modify just the corresponding part of the version string from the default, or the value provided by <code>--with-version-string<\/code>.<\/li>\n-<li><code>--with-jvm-variants=&lt;variant&gt;[,&lt;variant&gt;...]<\/code> - Build the specified variant (or variants) of Hotspot. Valid variants are: <code>server<\/code>, <code>client<\/code>, <code>minimal<\/code>, <code>core<\/code>, <code>zero<\/code>, <code>custom<\/code>. Note that not all variants are possible to combine in a single build.<\/li>\n-<li><code>--enable-jvm-feature-&lt;feature&gt;<\/code> or <code>--disable-jvm-feature-&lt;feature&gt;<\/code> - Include (or exclude) <code>&lt;feature&gt;<\/code> as a JVM feature in Hotspot. You can also specify a list of features to be enabled, separated by space or comma, as <code>--with-jvm-features=&lt;feature&gt;[,&lt;feature&gt;...]<\/code>. If you prefix <code>&lt;feature&gt;<\/code> with a <code>-<\/code>, it will be disabled. These options will modify the default list of features for the JVM variant(s) you are building. For the <code>custom<\/code> JVM variant, the default list is empty. A complete list of valid JVM features can be found using <code>bash configure --help<\/code>.<\/li>\n-<li><code>--with-target-bits=&lt;bits&gt;<\/code> - Create a target binary suitable for running on a <code>&lt;bits&gt;<\/code> platform. Use this to create 32-bit output on a 64-bit build platform, instead of doing a full cross-compile. (This is known as a <em>reduced<\/em> build.)<\/li>\n-<\/ul>\n-<p>On Linux, BSD and AIX, it is possible to override where Java by default searches for runtime\/JNI libraries. This can be useful in situations where there is a special shared directory for system JNI libraries. This setting can in turn be overridden at runtime by setting the <code>java.library.path<\/code> property.<\/p>\n-<ul>\n-<li><code>--with-jni-libpath=&lt;path&gt;<\/code> - Use the specified path as a default when searching for runtime libraries.<\/li>\n-<\/ul>\n-<h4 id=\"configure-arguments-for-native-compilation\">Configure Arguments for Native Compilation<\/h4>\n-<ul>\n-<li><code>--with-devkit=&lt;path&gt;<\/code> - Use this devkit for compilers, tools and resources<\/li>\n-<li><code>--with-sysroot=&lt;path&gt;<\/code> - Use this directory as sysroot<\/li>\n-<li><code>--with-extra-path=&lt;path&gt;[;&lt;path&gt;]<\/code> - Prepend these directories to the default path when searching for all kinds of binaries<\/li>\n-<li><code>--with-toolchain-path=&lt;path&gt;[;&lt;path&gt;]<\/code> - Prepend these directories when searching for toolchain binaries (compilers etc)<\/li>\n-<li><code>--with-extra-cflags=&lt;flags&gt;<\/code> - Append these flags when compiling JDK C files<\/li>\n-<li><code>--with-extra-cxxflags=&lt;flags&gt;<\/code> - Append these flags when compiling JDK C++ files<\/li>\n-<li><code>--with-extra-ldflags=&lt;flags&gt;<\/code> - Append these flags when linking JDK libraries<\/li>\n-<\/ul>\n-<h4 id=\"configure-arguments-for-external-dependencies\">Configure Arguments for External Dependencies<\/h4>\n-<ul>\n-<li><code>--with-boot-jdk=&lt;path&gt;<\/code> - Set the path to the <a href=\"#boot-jdk-requirements\">Boot JDK<\/a><\/li>\n-<li><code>--with-freetype=&lt;path&gt;<\/code> - Set the path to <a href=\"#freetype\">FreeType<\/a><\/li>\n-<li><code>--with-cups=&lt;path&gt;<\/code> - Set the path to <a href=\"#cups\">CUPS<\/a><\/li>\n-<li><code>--with-x=&lt;path&gt;<\/code> - Set the path to <a href=\"#x11\">X11<\/a><\/li>\n-<li><code>--with-alsa=&lt;path&gt;<\/code> - Set the path to <a href=\"#alsa\">ALSA<\/a><\/li>\n-<li><code>--with-libffi=&lt;path&gt;<\/code> - Set the path to <a href=\"#libffi\">libffi<\/a><\/li>\n-<li><code>--with-jtreg=&lt;path&gt;<\/code> - Set the path to JTReg. See <a href=\"#running-tests\">Running Tests<\/a><\/li>\n-<\/ul>\n-<p>Certain third-party libraries used by the JDK (libjpeg, giflib, libpng, lcms and zlib) are included in the JDK repository. The default behavior of the JDK build is to use the included (&quot;bundled&quot;) versions of libjpeg, giflib, libpng and lcms. For zlib, the system lib (if present) is used except on Windows and AIX. However the bundled libraries may be replaced by an external version. To do so, specify <code>system<\/code> as the <code>&lt;source&gt;<\/code> option in these arguments. (The default is <code>bundled<\/code>).<\/p>\n-<ul>\n-<li><code>--with-libjpeg=&lt;source&gt;<\/code> - Use the specified source for libjpeg<\/li>\n-<li><code>--with-giflib=&lt;source&gt;<\/code> - Use the specified source for giflib<\/li>\n-<li><code>--with-libpng=&lt;source&gt;<\/code> - Use the specified source for libpng<\/li>\n-<li><code>--with-lcms=&lt;source&gt;<\/code> - Use the specified source for lcms<\/li>\n-<li><code>--with-zlib=&lt;source&gt;<\/code> - Use the specified source for zlib<\/li>\n-<\/ul>\n-<p>On Linux, it is possible to select either static or dynamic linking of the C++ runtime. The default is static linking, with dynamic linking as fallback if the static library is not found.<\/p>\n-<ul>\n-<li><code>--with-stdc++lib=&lt;method&gt;<\/code> - Use the specified method (<code>static<\/code>, <code>dynamic<\/code> or <code>default<\/code>) for linking the C++ runtime.<\/li>\n-<\/ul>\n-<h3 id=\"configure-control-variables\">Configure Control Variables<\/h3>\n-<p>It is possible to control certain aspects of <code>configure<\/code> by overriding the value of <code>configure<\/code> variables, either on the command line or in the environment.<\/p>\n-<p>Normally, this is <strong>not recommended<\/strong>. If used improperly, it can lead to a broken configuration. Unless you're well versed in the build system, this is hard to use properly. Therefore, <code>configure<\/code> will print a warning if this is detected.<\/p>\n-<p>However, there are a few <code>configure<\/code> variables, known as <em>control variables<\/em> that are supposed to be overridden on the command line. These are variables that describe the location of tools needed by the build, like <code>MAKE<\/code> or <code>GREP<\/code>. If any such variable is specified, <code>configure<\/code> will use that value instead of trying to autodetect the tool. For instance, <code>bash configure MAKE=\/opt\/gnumake4.0\/bin\/make<\/code>.<\/p>\n-<p>If a configure argument exists, use that instead, e.g. use <code>--with-jtreg<\/code> instead of setting <code>JTREGEXE<\/code>.<\/p>\n-<p>Also note that, despite what autoconf claims, setting <code>CFLAGS<\/code> will not accomplish anything. Instead use <code>--with-extra-cflags<\/code> (and similar for <code>cxxflags<\/code> and <code>ldflags<\/code>).<\/p>\n-<h2 id=\"running-make\">Running Make<\/h2>\n-<p>When you have a proper configuration, all you need to do to build the JDK is to run <code>make<\/code>. (But see the warning at <a href=\"#gnu-make\">GNU Make<\/a> about running the correct version of make.)<\/p>\n-<p>When running <code>make<\/code> without any arguments, the default target is used, which is the same as running <code>make default<\/code> or <code>make jdk<\/code>. This will build a minimal (or roughly minimal) set of compiled output (known as an &quot;exploded image&quot;) needed for a developer to actually execute the newly built JDK. The idea is that in an incremental development fashion, when doing a normal make, you should only spend time recompiling what's changed (making it purely incremental) and only do the work that's needed to actually run and test your code.<\/p>\n-<p>The output of the exploded image resides in <code>$BUILD\/jdk<\/code>. You can test the newly built JDK like this: <code>$BUILD\/jdk\/bin\/java -version<\/code>.<\/p>\n-<h3 id=\"common-make-targets\">Common Make Targets<\/h3>\n-<p>Apart from the default target, here are some common make targets:<\/p>\n-<ul>\n-<li><code>hotspot<\/code> - Build all of hotspot (but only hotspot)<\/li>\n-<li><code>hotspot-&lt;variant&gt;<\/code> - Build just the specified jvm variant<\/li>\n-<li><code>images<\/code> or <code>product-images<\/code> - Build the JDK image<\/li>\n-<li><code>docs<\/code> or <code>docs-image<\/code> - Build the documentation image<\/li>\n-<li><code>test-image<\/code> - Build the test image<\/li>\n-<li><code>all<\/code> or <code>all-images<\/code> - Build all images (product, docs and test)<\/li>\n-<li><code>bootcycle-images<\/code> - Build images twice, second time with newly built JDK (good for testing)<\/li>\n-<li><code>clean<\/code> - Remove all files generated by make, but not those generated by configure<\/li>\n-<li><code>dist-clean<\/code> - Remove all files, including configuration<\/li>\n-<\/ul>\n-<p>Run <code>make help<\/code> to get an up-to-date list of important make targets and make control variables.<\/p>\n-<p>It is possible to build just a single module, a single phase, or a single phase of a single module, by creating make targets according to these followin patterns. A phase can be either of <code>gensrc<\/code>, <code>gendata<\/code>, <code>copy<\/code>, <code>java<\/code>, <code>launchers<\/code>, or <code>libs<\/code>. See <a href=\"#using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/a> for more details about this functionality.<\/p>\n-<ul>\n-<li><code>&lt;phase&gt;<\/code> - Build the specified phase and everything it depends on<\/li>\n-<li><code>&lt;module&gt;<\/code> - Build the specified module and everything it depends on<\/li>\n-<li><code>&lt;module&gt;-&lt;phase&gt;<\/code> - Compile the specified phase for the specified module and everything it depends on<\/li>\n-<\/ul>\n-<p>Similarly, it is possible to clean just a part of the build by creating make targets according to these patterns:<\/p>\n-<ul>\n-<li><code>clean-&lt;outputdir&gt;<\/code> - Remove the subdir in the output dir with the name<\/li>\n-<li><code>clean-&lt;phase&gt;<\/code> - Remove all build results related to a certain build phase<\/li>\n-<li><code>clean-&lt;module&gt;<\/code> - Remove all build results related to a certain module<\/li>\n-<li><code>clean-&lt;module&gt;-&lt;phase&gt;<\/code> - Remove all build results related to a certain module and phase<\/li>\n-<\/ul>\n-<h3 id=\"make-control-variables\">Make Control Variables<\/h3>\n-<p>It is possible to control <code>make<\/code> behavior by overriding the value of <code>make<\/code> variables, either on the command line or in the environment.<\/p>\n-<p>Normally, this is <strong>not recommended<\/strong>. If used improperly, it can lead to a broken build. Unless you're well versed in the build system, this is hard to use properly. Therefore, <code>make<\/code> will print a warning if this is detected.<\/p>\n-<p>However, there are a few <code>make<\/code> variables, known as <em>control variables<\/em> that are supposed to be overridden on the command line. These make up the &quot;make time&quot; configuration, as opposed to the &quot;configure time&quot; configuration.<\/p>\n-<h4 id=\"general-make-control-variables\">General Make Control Variables<\/h4>\n-<ul>\n-<li><code>JOBS<\/code> - Specify the number of jobs to build with. See <a href=\"#build-performance\">Build Performance<\/a>.<\/li>\n-<li><code>LOG<\/code> - Specify the logging level and functionality. See <a href=\"#checking-the-build-log-file\">Checking the Build Log File<\/a><\/li>\n-<li><code>CONF<\/code> and <code>CONF_NAME<\/code> - Selecting the configuration(s) to use. See <a href=\"#using-multiple-configurations\">Using Multiple Configurations<\/a><\/li>\n-<\/ul>\n-<h4 id=\"test-make-control-variables\">Test Make Control Variables<\/h4>\n-<p>These make control variables only make sense when running tests. Please see <strong>Testing the JDK<\/strong> (<a href=\"testing.html\">html<\/a>, <a href=\"testing.md\">markdown<\/a>) for details.<\/p>\n-<ul>\n-<li><code>TEST<\/code><\/li>\n-<li><code>TEST_JOBS<\/code><\/li>\n-<li><code>JTREG<\/code><\/li>\n-<li><code>GTEST<\/code><\/li>\n-<\/ul>\n-<h4 id=\"advanced-make-control-variables\">Advanced Make Control Variables<\/h4>\n-<p>These advanced make control variables can be potentially unsafe. See <a href=\"#hints-and-suggestions-for-advanced-users\">Hints and Suggestions for Advanced Users<\/a> and <a href=\"#understanding-the-build-system\">Understanding the Build System<\/a> for details.<\/p>\n-<ul>\n-<li><code>SPEC<\/code><\/li>\n-<li><code>CONF_CHECK<\/code><\/li>\n-<li><code>COMPARE_BUILD<\/code><\/li>\n-<li><code>JDK_FILTER<\/code><\/li>\n-<li><code>SPEC_FILTER<\/code><\/li>\n-<\/ul>\n-<h2 id=\"running-tests\">Running Tests<\/h2>\n-<p>Most of the JDK tests are using the <a href=\"http:\/\/openjdk.java.net\/jtreg\">JTReg<\/a> test framework. Make sure that your configuration knows where to find your installation of JTReg. If this is not picked up automatically, use the <code>--with-jtreg=&lt;path to jtreg home&gt;<\/code> option to point to the JTReg framework. Note that this option should point to the JTReg home, i.e. the top directory, containing <code>lib\/jtreg.jar<\/code> etc.<\/p>\n-<p>The <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Adoption\">Adoption Group<\/a> provides recent builds of jtreg <a href=\"https:\/\/ci.adoptopenjdk.net\/view\/Dependencies\/job\/dependency_pipeline\/lastSuccessfulBuild\/artifact\/jtreg\/\">here<\/a>. Download the latest <code>.tar.gz<\/code> file, unpack it, and point <code>--with-jtreg<\/code> to the <code>jtreg<\/code> directory that you just unpacked.<\/p>\n-<p>Building of Hotspot Gtest suite requires the source code of Google Test framework. The top directory, which contains both <code>googletest<\/code> and <code>googlemock<\/code> directories, should be specified via <code>--with-gtest<\/code>. The supported version of Google Test is 1.8.1, whose source code can be obtained:<\/p>\n-<ul>\n-<li>by downloading and unpacking the source bundle from <a href=\"https:\/\/github.com\/google\/googletest\/releases\/tag\/release-1.8.1\">here<\/a><\/li>\n-<li>or by checking out <code>release-1.8.1<\/code> tag of <code>googletest<\/code> project: <code>git clone -b release-1.8.1 https:\/\/github.com\/google\/googletest<\/code><\/li>\n-<\/ul>\n-<p>To execute the most basic tests (tier 1), use:<\/p>\n-<pre><code>make run-test-tier1<\/code><\/pre>\n-<p>For more details on how to run tests, please see <strong>Testing the JDK<\/strong> (<a href=\"testing.html\">html<\/a>, <a href=\"testing.md\">markdown<\/a>).<\/p>\n-<h2 id=\"cross-compiling\">Cross-compiling<\/h2>\n-<p>Cross-compiling means using one platform (the <em>build<\/em> platform) to generate output that can ran on another platform (the <em>target<\/em> platform).<\/p>\n-<p>The typical reason for cross-compiling is that the build is performed on a more powerful desktop computer, but the resulting binaries will be able to run on a different, typically low-performing system. Most of the complications that arise when building for embedded is due to this separation of <em>build<\/em> and <em>target<\/em> systems.<\/p>\n-<p>This requires a more complex setup and build procedure. This section assumes you are familiar with cross-compiling in general, and will only deal with the particularities of cross-compiling the JDK. If you are new to cross-compiling, please see the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross_compiler#External_links\">external links at Wikipedia<\/a> for a good start on reading materials.<\/p>\n-<p>Cross-compiling the JDK requires you to be able to build both for the build platform and for the target platform. The reason for the former is that we need to build and execute tools during the build process, both native tools and Java tools.<\/p>\n-<p>If all you want to do is to compile a 32-bit version, for the same OS, on a 64-bit machine, consider using <code>--with-target-bits=32<\/code> instead of doing a full-blown cross-compilation. (While this surely is possible, it's a lot more work and will take much longer to build.)<\/p>\n-<h3 id=\"cross-compiling-the-easy-way-with-openjdk-devkits\">Cross compiling the easy way with OpenJDK devkits<\/h3>\n-<p>The OpenJDK build system provides out-of-the box support for creating and using so called devkits. A <code>devkit<\/code> is basically a collection of a cross-compiling toolchain and a sysroot environment which can easily be used together with the <code>--with-devkit<\/code> configure option to cross compile the OpenJDK. On Linux\/x86_64, the following command:<\/p>\n-<pre><code>bash configure --with-devkit=&lt;devkit-path&gt; --openjdk-target=ppc64-linux-gnu &amp;&amp; make<\/code><\/pre>\n-<p>will configure and build OpenJDK for Linux\/ppc64 assuming that <code>&lt;devkit-path&gt;<\/code> points to a Linux\/x86_64 to Linux\/ppc64 devkit.<\/p>\n-<p>Devkits can be created from the <code>make\/devkit<\/code> directory by executing:<\/p>\n-<pre><code>make [ TARGETS=&quot;&lt;TARGET_TRIPLET&gt;+&quot; ] [ BASE_OS=&lt;OS&gt; ] [ BASE_OS_VERSION=&lt;VER&gt; ]<\/code><\/pre>\n-<p>where <code>TARGETS<\/code> contains one or more <code>TARGET_TRIPLET<\/code>s of the form described in <a href=\"https:\/\/sourceware.org\/autobook\/autobook\/autobook_17.html\">section 3.4 of the GNU Autobook<\/a>. If no targets are given, a native toolchain for the current platform will be created. Currently, at least the following targets are known to work:<\/p>\n-<table>\n-<thead>\n-<tr class=\"header\">\n-<th style=\"text-align: left;\">Supported devkit targets<\/th>\n-<\/tr>\n-<\/thead>\n-<tbody>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">x86_64-linux-gnu<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">aarch64-linux-gnu<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">arm-linux-gnueabihf<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">ppc64-linux-gnu<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">ppc64le-linux-gnu<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">s390x-linux-gnu<\/td>\n-<\/tr>\n-<\/tbody>\n-<\/table>\n-<p><code>BASE_OS<\/code> must be one of &quot;OEL6&quot; for Oracle Enterprise Linux 6 or &quot;Fedora&quot; (if not specified &quot;OEL6&quot; will be the default). If the base OS is &quot;Fedora&quot; the corresponding Fedora release can be specified with the help of the <code>BASE_OS_VERSION<\/code> option (with &quot;27&quot; as default version). If the build is successful, the new devkits can be found in the <code>build\/devkit\/result<\/code> subdirectory:<\/p>\n-<pre><code>cd make\/devkit\n-make TARGETS=&quot;ppc64le-linux-gnu aarch64-linux-gnu&quot; BASE_OS=Fedora BASE_OS_VERSION=21\n-ls -1 ..\/..\/build\/devkit\/result\/\n-x86_64-linux-gnu-to-aarch64-linux-gnu\n-x86_64-linux-gnu-to-ppc64le-linux-gnu<\/code><\/pre>\n-<p>Notice that devkits are not only useful for targeting different build platforms. Because they contain the full build dependencies for a system (i.e. compiler and root file system), they can easily be used to build well-known, reliable and reproducible build environments. You can for example create and use a devkit with GCC 7.3 and a Fedora 12 sysroot environment (with glibc 2.11) on Ubuntu 14.04 (which doesn't have GCC 7.3 by default) to produce OpenJDK binaries which will run on all Linux systems with runtime libraries newer than the ones from Fedora 12 (e.g. Ubuntu 16.04, SLES 11 or RHEL 6).<\/p>\n-<h3 id=\"boot-jdk-and-build-jdk\">Boot JDK and Build JDK<\/h3>\n-<p>When cross-compiling, make sure you use a boot JDK that runs on the <em>build<\/em> system, and not on the <em>target<\/em> system.<\/p>\n-<p>To be able to build, we need a &quot;Build JDK&quot;, which is a JDK built from the current sources (that is, the same as the end result of the entire build process), but able to run on the <em>build<\/em> system, and not the <em>target<\/em> system. (In contrast, the Boot JDK should be from an older release, e.g. JDK 8 when building JDK 9.)<\/p>\n-<p>The build process will create a minimal Build JDK for you, as part of building. To speed up the build, you can use <code>--with-build-jdk<\/code> to <code>configure<\/code> to point to a pre-built Build JDK. Please note that the build result is unpredictable, and can possibly break in subtle ways, if the Build JDK does not <strong>exactly<\/strong> match the current sources.<\/p>\n-<h3 id=\"specifying-the-target-platform\">Specifying the Target Platform<\/h3>\n-<p>You <em>must<\/em> specify the target platform when cross-compiling. Doing so will also automatically turn the build into a cross-compiling mode. The simplest way to do this is to use the <code>--openjdk-target<\/code> argument, e.g. <code>--openjdk-target=arm-linux-gnueabihf<\/code>. or <code>--openjdk-target=aarch64-oe-linux<\/code>. This will automatically set the <code>--build<\/code>, <code>--host<\/code> and <code>--target<\/code> options for autoconf, which can otherwise be confusing. (In autoconf terminology, the &quot;target&quot; is known as &quot;host&quot;, and &quot;target&quot; is used for building a Canadian cross-compiler.)<\/p>\n-<h3 id=\"toolchain-considerations\">Toolchain Considerations<\/h3>\n-<p>You will need two copies of your toolchain, one which generates output that can run on the target system (the normal, or <em>target<\/em>, toolchain), and one that generates output that can run on the build system (the <em>build<\/em> toolchain). Note that cross-compiling is only supported for gcc at the time being. The gcc standard is to prefix cross-compiling toolchains with the target denominator. If you follow this standard, <code>configure<\/code> is likely to pick up the toolchain correctly.<\/p>\n-<p>The <em>build<\/em> toolchain will be autodetected just the same way the normal <em>build<\/em>\/<em>target<\/em> toolchain will be autodetected when not cross-compiling. If this is not what you want, or if the autodetection fails, you can specify a devkit containing the <em>build<\/em> toolchain using <code>--with-build-devkit<\/code> to <code>configure<\/code>, or by giving <code>BUILD_CC<\/code> and <code>BUILD_CXX<\/code> arguments.<\/p>\n-<p>It is often helpful to locate the cross-compilation tools, headers and libraries in a separate directory, outside the normal path, and point out that directory to <code>configure<\/code>. Do this by setting the sysroot (<code>--with-sysroot<\/code>) and appending the directory when searching for cross-compilations tools (<code>--with-toolchain-path<\/code>). As a compact form, you can also use <code>--with-devkit<\/code> to point to a single directory, if it is correctly setup. (See <code>basics.m4<\/code> for details.)<\/p>\n-<h3 id=\"native-libraries\">Native Libraries<\/h3>\n-<p>You will need copies of external native libraries for the <em>target<\/em> system, present on the <em>build<\/em> machine while building.<\/p>\n-<p>Take care not to replace the <em>build<\/em> system's version of these libraries by mistake, since that can render the <em>build<\/em> machine unusable.<\/p>\n-<p>Make sure that the libraries you point to (ALSA, X11, etc) are for the <em>target<\/em>, not the <em>build<\/em>, platform.<\/p>\n-<h4 id=\"alsa-1\">ALSA<\/h4>\n-<p>You will need alsa libraries suitable for your <em>target<\/em> system. For most cases, using Debian's pre-built libraries work fine.<\/p>\n-<p>Note that alsa is needed even if you only want to build a headless JDK.<\/p>\n-<ul>\n-<li><p>Go to <a href=\"https:\/\/www.debian.org\/distrib\/packages\">Debian Package Search<\/a> and search for the <code>libasound2<\/code> and <code>libasound2-dev<\/code> packages for your <em>target<\/em> system. Download them to \/tmp.<\/p><\/li>\n-<li>Install the libraries into the cross-compilation toolchain. For instance:<\/li>\n-<\/ul>\n-<pre><code>cd \/tools\/gcc-linaro-arm-linux-gnueabihf-raspbian-2012.09-20120921_linux\/arm-linux-gnueabihf\/libc\n-dpkg-deb -x \/tmp\/libasound2_1.0.25-4_armhf.deb .\n-dpkg-deb -x \/tmp\/libasound2-dev_1.0.25-4_armhf.deb .<\/code><\/pre>\n-<ul>\n-<li>If alsa is not properly detected by <code>configure<\/code>, you can point it out by <code>--with-alsa<\/code>.<\/li>\n-<\/ul>\n-<h4 id=\"x11-1\">X11<\/h4>\n-<p>You will need X11 libraries suitable for your <em>target<\/em> system. For most cases, using Debian's pre-built libraries work fine.<\/p>\n-<p>Note that X11 is needed even if you only want to build a headless JDK.<\/p>\n-<ul>\n-<li>Go to <a href=\"https:\/\/www.debian.org\/distrib\/packages\">Debian Package Search<\/a>, search for the following packages for your <em>target<\/em> system, and download them to \/tmp\/target-x11:\n-<ul>\n-<li>libxi<\/li>\n-<li>libxi-dev<\/li>\n-<li>x11proto-core-dev<\/li>\n-<li>x11proto-input-dev<\/li>\n-<li>x11proto-kb-dev<\/li>\n-<li>x11proto-render-dev<\/li>\n-<li>x11proto-xext-dev<\/li>\n-<li>libice-dev<\/li>\n-<li>libxrender<\/li>\n-<li>libxrender-dev<\/li>\n-<li>libxrandr-dev<\/li>\n-<li>libsm-dev<\/li>\n-<li>libxt-dev<\/li>\n-<li>libx11<\/li>\n-<li>libx11-dev<\/li>\n-<li>libxtst<\/li>\n-<li>libxtst-dev<\/li>\n-<li>libxext<\/li>\n-<li>libxext-dev<\/li>\n-<\/ul><\/li>\n-<li><p>Install the libraries into the cross-compilation toolchain. For instance:<\/p>\n-<pre><code>cd \/tools\/gcc-linaro-arm-linux-gnueabihf-raspbian-2012.09-20120921_linux\/arm-linux-gnueabihf\/libc\/usr\n-mkdir X11R6\n-cd X11R6\n-for deb in \/tmp\/target-x11\/*.deb ; do dpkg-deb -x $deb . ; done\n-mv usr\/* .\n-cd lib\n-cp arm-linux-gnueabihf\/* .<\/code><\/pre>\n-<p>You can ignore the following messages. These libraries are not needed to successfully complete a full JDK build.<\/p>\n-<pre><code>cp: cannot stat `arm-linux-gnueabihf\/libICE.so&#39;: No such file or directory\n-cp: cannot stat `arm-linux-gnueabihf\/libSM.so&#39;: No such file or directory\n-cp: cannot stat `arm-linux-gnueabihf\/libXt.so&#39;: No such file or directory<\/code><\/pre><\/li>\n-<li><p>If the X11 libraries are not properly detected by <code>configure<\/code>, you can point them out by <code>--with-x<\/code>.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"cross-compiling-with-debian-sysroots\">Cross compiling with Debian sysroots<\/h3>\n-<p>Fortunately, you can create sysroots for foreign architectures with tools provided by your OS. On Debian\/Ubuntu systems, one could use <code>qemu-deboostrap<\/code> to create the <em>target<\/em> system chroot, which would have the native libraries and headers specific to that <em>target<\/em> system. After that, we can use the cross-compiler on the <em>build<\/em> system, pointing into chroot to get the build dependencies right. This allows building for foreign architectures with native compilation speed.<\/p>\n-<p>For example, cross-compiling to AArch64 from x86_64 could be done like this:<\/p>\n-<ul>\n-<li><p>Install cross-compiler on the <em>build<\/em> system:<\/p>\n-<pre><code>apt install g++-aarch64-linux-gnu gcc-aarch64-linux-gnu<\/code><\/pre><\/li>\n-<li><p>Create chroot on the <em>build<\/em> system, configuring it for <em>target<\/em> system:<\/p>\n-<pre><code>sudo qemu-debootstrap \\\n-  --arch=arm64 \\\n-  --verbose \\\n-  --include=fakeroot,symlinks,build-essential,libx11-dev,libxext-dev,libxrender-dev,libxrandr-dev,libxtst-dev,libxt-dev,libcups2-dev,libfontconfig1-dev,libasound2-dev,libfreetype6-dev,libpng-dev,libffi-dev \\\n-  --resolve-deps \\\n-  buster \\\n-  ~\/sysroot-arm64 \\\n-  http:\/\/httpredir.debian.org\/debian\/<\/code><\/pre><\/li>\n-<li><p>Make sure the symlinks inside the newly created chroot point to proper locations:<\/p>\n-<pre><code>sudo chroot ~\/sysroot-arm64 symlinks -cr .<\/code><\/pre><\/li>\n-<li><p>Configure and build with newly created chroot as sysroot\/toolchain-path:<\/p>\n-<pre><code>sh .\/configure \\\n-  --openjdk-target=aarch64-linux-gnu \\\n-  --with-sysroot=~\/sysroot-arm64\n-make images\n-ls build\/linux-aarch64-server-release\/<\/code><\/pre><\/li>\n-<\/ul>\n-<p>The build does not create new files in that chroot, so it can be reused for multiple builds without additional cleanup.<\/p>\n-<p>The build system should automatically detect the toolchain paths and dependencies, but sometimes it might require a little nudge with:<\/p>\n-<ul>\n-<li><p>Native compilers: override <code>CC<\/code> or <code>CXX<\/code> for <code>.\/configure<\/code><\/p><\/li>\n-<li><p>Freetype lib location: override <code>--with-freetype-lib<\/code>, for example <code>${sysroot}\/usr\/lib\/${target}\/<\/code><\/p><\/li>\n-<li><p>Freetype includes location: override <code>--with-freetype-include<\/code> for example <code>${sysroot}\/usr\/include\/freetype2\/<\/code><\/p><\/li>\n-<li><p>X11 libraries location: override <code>--x-libraries<\/code>, for example <code>${sysroot}\/usr\/lib\/${target}\/<\/code><\/p><\/li>\n-<\/ul>\n-<p>Architectures that are known to successfully cross-compile like this are:<\/p>\n-<table>\n-<thead>\n-<tr class=\"header\">\n-<th style=\"text-align: left;\">Target<\/th>\n-<th style=\"text-align: left;\">Debian tree<\/th>\n-<th style=\"text-align: left;\">Debian arch<\/th>\n-<th style=\"text-align: left;\"><code>--openjdk-target=...<\/code><\/th>\n-<th><code>--with-jvm-variants=...<\/code><\/th>\n-<\/tr>\n-<\/thead>\n-<tbody>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">x86<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">i386<\/td>\n-<td style=\"text-align: left;\">i386-linux-gnu<\/td>\n-<td>(all)<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">arm<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">armhf<\/td>\n-<td style=\"text-align: left;\">arm-linux-gnueabihf<\/td>\n-<td>(all)<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">aarch64<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">arm64<\/td>\n-<td style=\"text-align: left;\">aarch64-linux-gnu<\/td>\n-<td>(all)<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">ppc64le<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">ppc64el<\/td>\n-<td style=\"text-align: left;\">powerpc64le-linux-gnu<\/td>\n-<td>(all)<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">s390x<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">s390x<\/td>\n-<td style=\"text-align: left;\">s390x-linux-gnu<\/td>\n-<td>(all)<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">mipsle<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">mipsel<\/td>\n-<td style=\"text-align: left;\">mipsel-linux-gnu<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">mips64le<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">mips64el<\/td>\n-<td style=\"text-align: left;\">mips64el-linux-gnueabi64<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">armel<\/td>\n-<td style=\"text-align: left;\">buster<\/td>\n-<td style=\"text-align: left;\">arm<\/td>\n-<td style=\"text-align: left;\">arm-linux-gnueabi<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">ppc<\/td>\n-<td style=\"text-align: left;\">sid<\/td>\n-<td style=\"text-align: left;\">powerpc<\/td>\n-<td style=\"text-align: left;\">powerpc-linux-gnu<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">ppc64be<\/td>\n-<td style=\"text-align: left;\">sid<\/td>\n-<td style=\"text-align: left;\">ppc64<\/td>\n-<td style=\"text-align: left;\">powerpc64-linux-gnu<\/td>\n-<td>(all)<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">m68k<\/td>\n-<td style=\"text-align: left;\">sid<\/td>\n-<td style=\"text-align: left;\">m68k<\/td>\n-<td style=\"text-align: left;\">m68k-linux-gnu<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<tr class=\"even\">\n-<td style=\"text-align: left;\">alpha<\/td>\n-<td style=\"text-align: left;\">sid<\/td>\n-<td style=\"text-align: left;\">alpha<\/td>\n-<td style=\"text-align: left;\">alpha-linux-gnu<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<tr class=\"odd\">\n-<td style=\"text-align: left;\">sh4<\/td>\n-<td style=\"text-align: left;\">sid<\/td>\n-<td style=\"text-align: left;\">sh4<\/td>\n-<td style=\"text-align: left;\">sh4-linux-gnu<\/td>\n-<td>zero<\/td>\n-<\/tr>\n-<\/tbody>\n-<\/table>\n-<h3 id=\"building-for-armaarch64\">Building for ARM\/aarch64<\/h3>\n-<p>A common cross-compilation target is the ARM CPU. When building for ARM, it is useful to set the ABI profile. A number of pre-defined ABI profiles are available using <code>--with-abi-profile<\/code>: arm-vfp-sflt, arm-vfp-hflt, arm-sflt, armv5-vfp-sflt, armv6-vfp-hflt. Note that soft-float ABIs are no longer properly supported by the JDK.<\/p>\n-<h3 id=\"building-for-musl\">Building for musl<\/h3>\n-<p>Just like it's possible to cross-compile for a different CPU, it's possible to cross-compile for musl libc on a glibc-based <em>build<\/em> system. A devkit suitable for most target CPU architectures can be obtained from <a href=\"https:\/\/musl.cc\">musl.cc<\/a>. After installing the required packages in the sysroot, configure the build with <code>--openjdk-target<\/code>:<\/p>\n-<pre><code>sh .\/configure --with-jvm-variants=server \\\n---with-boot-jdk=$BOOT_JDK \\\n---with-build-jdk=$BUILD_JDK \\\n---openjdk-target=x86_64-unknown-linux-musl \\\n---with-devkit=$DEVKIT \\\n---with-sysroot=$SYSROOT<\/code><\/pre>\n-<p>and run <code>make<\/code> normally.<\/p>\n-<h3 id=\"verifying-the-build\">Verifying the Build<\/h3>\n-<p>The build will end up in a directory named like <code>build\/linux-arm-normal-server-release<\/code>.<\/p>\n-<p>Inside this build output directory, the <code>images\/jdk<\/code> will contain the newly built JDK, for your <em>target<\/em> system.<\/p>\n-<p>Copy these folders to your <em>target<\/em> system. Then you can run e.g. <code>images\/jdk\/bin\/java -version<\/code>.<\/p>\n-<h2 id=\"build-performance\">Build Performance<\/h2>\n-<p>Building the JDK requires a lot of horsepower. Some of the build tools can be adjusted to utilize more or less of resources such as parallel threads and memory. The <code>configure<\/code> script analyzes your system and selects reasonable values for such options based on your hardware. If you encounter resource problems, such as out of memory conditions, you can modify the detected values with:<\/p>\n-<ul>\n-<li><p><code>--with-num-cores<\/code> -- number of cores in the build system, e.g. <code>--with-num-cores=8<\/code>.<\/p><\/li>\n-<li><p><code>--with-memory-size<\/code> -- memory (in MB) available in the build system, e.g. <code>--with-memory-size=1024<\/code><\/p><\/li>\n-<\/ul>\n-<p>You can also specify directly the number of build jobs to use with <code>--with-jobs=N<\/code> to <code>configure<\/code>, or <code>JOBS=N<\/code> to <code>make<\/code>. Do not use the <code>-j<\/code> flag to <code>make<\/code>. In most cases it will be ignored by the makefiles, but it can cause problems for some make targets.<\/p>\n-<p>It might also be necessary to specify the JVM arguments passed to the Boot JDK, using e.g. <code>--with-boot-jdk-jvmargs=&quot;-Xmx8G&quot;<\/code>. Doing so will override the default JVM arguments passed to the Boot JDK.<\/p>\n-<p>At the end of a successful execution of <code>configure<\/code>, you will get a performance summary, indicating how well the build will perform. Here you will also get performance hints. If you want to build fast, pay attention to those!<\/p>\n-<p>If you want to tweak build performance, run with <code>make LOG=info<\/code> to get a build time summary at the end of the build process.<\/p>\n-<h3 id=\"disk-speed\">Disk Speed<\/h3>\n-<p>If you are using network shares, e.g. via NFS, for your source code, make sure the build directory is situated on local disk (e.g. by <code>ln -s \/localdisk\/jdk-build $JDK-SHARE\/build<\/code>). The performance penalty is extremely high for building on a network share; close to unusable.<\/p>\n-<p>Also, make sure that your build tools (including Boot JDK and toolchain) is located on a local disk and not a network share.<\/p>\n-<p>As has been stressed elsewhere, do use SSD for source code and build directory, as well as (if possible) the build tools.<\/p>\n-<h3 id=\"virus-checking\">Virus Checking<\/h3>\n-<p>The use of virus checking software, especially on Windows, can <em>significantly<\/em> slow down building of the JDK. If possible, turn off such software, or exclude the directory containing the JDK source code from on-the-fly checking.<\/p>\n-<h3 id=\"ccache\">Ccache<\/h3>\n-<p>The JDK build supports building with ccache when using gcc or clang. Using ccache can radically speed up compilation of native code if you often rebuild the same sources. Your milage may vary however, so we recommend evaluating it for yourself. To enable it, make sure it's on the path and configure with <code>--enable-ccache<\/code>.<\/p>\n-<h3 id=\"precompiled-headers\">Precompiled Headers<\/h3>\n-<p>By default, the Hotspot build uses preccompiled headers (PCH) on the toolchains were it is properly supported (clang, gcc, and Visual Studio). Normally, this speeds up the build process, but in some circumstances, it can actually slow things down.<\/p>\n-<p>You can experiment by disabling precompiled headers using <code>--disable-precompiled-headers<\/code>.<\/p>\n-<h3 id=\"icecc-icecream\">Icecc \/ icecream<\/h3>\n-<p><a href=\"http:\/\/github.com\/icecc\/icecream\">icecc\/icecream<\/a> is a simple way to setup a distributed compiler network. If you have multiple machines available for building the JDK, you can drastically cut individual build times by utilizing it.<\/p>\n-<p>To use, setup an icecc network, and install icecc on the build machine. Then run <code>configure<\/code> using <code>--enable-icecc<\/code>.<\/p>\n-<h3 id=\"using-sjavac\">Using sjavac<\/h3>\n-<p>To speed up Java compilation, especially incremental compilations, you can try the experimental sjavac compiler by using <code>--enable-sjavac<\/code>.<\/p>\n-<h3 id=\"building-the-right-target\">Building the Right Target<\/h3>\n-<p>Selecting the proper target to build can have dramatic impact on build time. For normal usage, <code>jdk<\/code> or the default target is just fine. You only need to build <code>images<\/code> for shipping, or if your tests require it.<\/p>\n-<p>See also <a href=\"#using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/a> on how to build an even smaller subset of the product.<\/p>\n-<h2 id=\"troubleshooting\">Troubleshooting<\/h2>\n-<p>If your build fails, it can sometimes be difficult to pinpoint the problem or find a proper solution.<\/p>\n-<h3 id=\"locating-the-source-of-the-error\">Locating the Source of the Error<\/h3>\n-<p>When a build fails, it can be hard to pinpoint the actual cause of the error. In a typical build process, different parts of the product build in parallel, with the output interlaced.<\/p>\n-<h4 id=\"build-failure-summary\">Build Failure Summary<\/h4>\n-<p>To help you, the build system will print a failure summary at the end. It looks like this:<\/p>\n-<pre><code>ERROR: Build failed for target &#39;hotspot&#39; in configuration &#39;linux-x64&#39; (exit code 2)\n-\n-=== Output from failing command(s) repeated here ===\n-* For target hotspot_variant-server_libjvm_objs_psMemoryPool.o:\n-\/localhome\/git\/jdk-sandbox\/hotspot\/src\/share\/vm\/services\/psMemoryPool.cpp:1:1: error: &#39;failhere&#39; does not name a type\n-   ... (rest of output omitted)\n-\n-* All command lines available in \/localhome\/git\/jdk-sandbox\/build\/linux-x64\/make-support\/failure-logs.\n-=== End of repeated output ===\n-\n-=== Make failed targets repeated here ===\n-lib\/CompileJvm.gmk:207: recipe for target &#39;\/localhome\/git\/jdk-sandbox\/build\/linux-x64\/hotspot\/variant-server\/libjvm\/objs\/psMemoryPool.o&#39; failed\n-make\/Main.gmk:263: recipe for target &#39;hotspot-server-libs&#39; failed\n-=== End of repeated output ===\n-\n-Hint: Try searching the build log for the name of the first failed target.\n-Hint: If caused by a warning, try configure --disable-warnings-as-errors.<\/code><\/pre>\n-<p>Let's break it down! First, the selected configuration, and the top-level target you entered on the command line that caused the failure is printed.<\/p>\n-<p>Then, between the <code>Output from failing command(s) repeated here<\/code> and <code>End of repeated output<\/code> the first lines of output (stdout and stderr) from the actual failing command is repeated. In most cases, this is the error message that caused the build to fail. If multiple commands were failing (this can happen in a parallel build), output from all failed commands will be printed here.<\/p>\n-<p>The path to the <code>failure-logs<\/code> directory is printed. In this file you will find a <code>&lt;target&gt;.log<\/code> file that contains the output from this command in its entirety, and also a <code>&lt;target&gt;.cmd<\/code>, which contain the complete command line used for running this command. You can re-run the failing command by executing <code>. &lt;path to failure-logs&gt;\/&lt;target&gt;.cmd<\/code> in your shell.<\/p>\n-<p>Another way to trace the failure is to follow the chain of make targets, from top-level targets to individual file targets. Between <code>Make failed targets repeated here<\/code> and <code>End of repeated output<\/code> the output from make showing this chain is repeated. The first failed recipe will typically contain the full path to the file in question that failed to compile. Following lines will show a trace of make targets why we ended up trying to compile that file.<\/p>\n-<p>Finally, some hints are given on how to locate the error in the complete log. In this example, we would try searching the log file for &quot;<code>psMemoryPool.o<\/code>&quot;. Another way to quickly locate make errors in the log is to search for &quot;<code>] Error<\/code>&quot; or &quot;<code>***<\/code>&quot;.<\/p>\n-<p>Note that the build failure summary will only help you if the issue was a compilation failure or similar. If the problem is more esoteric, or is due to errors in the build machinery, you will likely get empty output logs, and <code>No indication of failed target found<\/code> instead of the make target chain.<\/p>\n-<h4 id=\"checking-the-build-log-file\">Checking the Build Log File<\/h4>\n-<p>The output (stdout and stderr) from the latest build is always stored in <code>$BUILD\/build.log<\/code>. The previous build log is stored as <code>build.log.old<\/code>. This means that it is not necessary to redirect the build output yourself if you want to process it.<\/p>\n-<p>You can increase the verbosity of the log file, by the <code>LOG<\/code> control variable to <code>make<\/code>. If you want to see the command lines used in compilations, use <code>LOG=cmdlines<\/code>. To increase the general verbosity, use <code>LOG=info<\/code>, <code>LOG=debug<\/code> or <code>LOG=trace<\/code>. Both of these can be combined with <code>cmdlines<\/code>, e.g. <code>LOG=info,cmdlines<\/code>. The <code>debug<\/code> log level will show most shell commands executed by make, and <code>trace<\/code> will show all. Beware that both these log levels will produce a massive build log!<\/p>\n-<h3 id=\"fixing-unexpected-build-failures\">Fixing Unexpected Build Failures<\/h3>\n-<p>Most of the time, the build will fail due to incorrect changes in the source code.<\/p>\n-<p>Sometimes the build can fail with no apparent changes that have caused the failure. If this is the first time you are building the JDK on this particular computer, and the build fails, the problem is likely with your build environment. But even if you have previously built the JDK with success, and it now fails, your build environment might have changed (perhaps due to OS upgrades or similar). But most likely, such failures are due to problems with the incremental rebuild.<\/p>\n-<h4 id=\"problems-with-the-build-environment\">Problems with the Build Environment<\/h4>\n-<p>Make sure your configuration is correct. Re-run <code>configure<\/code>, and look for any warnings. Warnings that appear in the middle of the <code>configure<\/code> output is also repeated at the end, after the summary. The entire log is stored in <code>$BUILD\/configure.log<\/code>.<\/p>\n-<p>Verify that the summary at the end looks correct. Are you indeed using the Boot JDK and native toolchain that you expect?<\/p>\n-<p>By default, the JDK has a strict approach where warnings from the compiler is considered errors which fail the build. For very new or very old compiler versions, this can trigger new classes of warnings, which thus fails the build. Run <code>configure<\/code> with <code>--disable-warnings-as-errors<\/code> to turn of this behavior. (The warnings will still show, but not make the build fail.)<\/p>\n-<h4 id=\"problems-with-incremental-rebuilds\">Problems with Incremental Rebuilds<\/h4>\n-<p>Incremental rebuilds mean that when you modify part of the product, only the affected parts get rebuilt. While this works great in most cases, and significantly speed up the development process, from time to time complex interdependencies will result in an incorrect build result. This is the most common cause for unexpected build problems.<\/p>\n-<p>Here are a suggested list of things to try if you are having unexpected build problems. Each step requires more time than the one before, so try them in order. Most issues will be solved at step 1 or 2.<\/p>\n-<ol type=\"1\">\n-<li><p>Make sure your repository is up-to-date<\/p>\n-<p>Run <code>git pull origin master<\/code> to make sure you have the latest changes.<\/p><\/li>\n-<li><p>Clean build results<\/p>\n-<p>The simplest way to fix incremental rebuild issues is to run <code>make clean<\/code>. This will remove all build results, but not the configuration or any build system support artifacts. In most cases, this will solve build errors resulting from incremental build mismatches.<\/p><\/li>\n-<li><p>Completely clean the build directory.<\/p>\n-<p>If this does not work, the next step is to run <code>make dist-clean<\/code>, or removing the build output directory (<code>$BUILD<\/code>). This will clean all generated output, including your configuration. You will need to re-run <code>configure<\/code> after this step. A good idea is to run <code>make print-configuration<\/code> before running <code>make dist-clean<\/code>, as this will print your current <code>configure<\/code> command line. Here's a way to do this:<\/p>\n-<pre><code>make print-configuration &gt; current-configuration\n-make dist-clean\n-bash configure $(cat current-configuration)\n-make<\/code><\/pre><\/li>\n-<li><p>Re-clone the Git repository<\/p>\n-<p>Sometimes the Git repository gets in a state that causes the product to be un-buildable. In such a case, the simplest solution is often the &quot;sledgehammer approach&quot;: delete the entire repository, and re-clone it. If you have local changes, save them first to a different location using <code>git format-patch<\/code>.<\/p><\/li>\n-<\/ol>\n-<h3 id=\"specific-build-issues\">Specific Build Issues<\/h3>\n-<h4 id=\"clock-skew\">Clock Skew<\/h4>\n-<p>If you get an error message like this:<\/p>\n-<pre><code>File &#39;xxx&#39; has modification time in the future.\n-Clock skew detected. Your build may be incomplete.<\/code><\/pre>\n-<p>then the clock on your build machine is out of sync with the timestamps on the source files. Other errors, apparently unrelated but in fact caused by the clock skew, can occur along with the clock skew warnings. These secondary errors may tend to obscure the fact that the true root cause of the problem is an out-of-sync clock.<\/p>\n-<p>If you see these warnings, reset the clock on the build machine, run <code>make clean<\/code> and restart the build.<\/p>\n-<h4 id=\"out-of-memory-errors\">Out of Memory Errors<\/h4>\n-<p>On Windows, you might get error messages like this:<\/p>\n-<pre><code>fatal error - couldn&#39;t allocate heap\n-cannot create ... Permission denied\n-spawn failed<\/code><\/pre>\n-<p>This can be a sign of a Cygwin problem. See the information about solving problems in the <a href=\"#cygwin\">Cygwin<\/a> section. Rebooting the computer might help temporarily.<\/p>\n-<h4 id=\"spaces-in-path\">Spaces in Path<\/h4>\n-<p>On Windows, when configuring, <code>fixpath.sh<\/code> may report that some directory names have spaces. Usually, it assumes those directories have <a href=\"https:\/\/docs.microsoft.com\/en-us\/windows-server\/administration\/windows-commands\/fsutil-8dot3name\">short paths<\/a>. You can run <code>fsutil file setshortname<\/code> in <code>cmd<\/code> on certain directories, such as <code>Microsoft Visual Studio<\/code> or <code>Windows Kits<\/code>, to assign arbitrary short paths so <code>configure<\/code> can access them.<\/p>\n-<h3 id=\"getting-help\">Getting Help<\/h3>\n-<p>If none of the suggestions in this document helps you, or if you find what you believe is a bug in the build system, please contact the Build Group by sending a mail to <a href=\"mailto:build-dev@openjdk.java.net\">build-dev@openjdk.java.net<\/a>. Please include the relevant parts of the configure and\/or build log.<\/p>\n-<p>If you need general help or advice about developing for the JDK, you can also contact the Adoption Group. See the section on <a href=\"#contributing-to-openjdk\">Contributing to OpenJDK<\/a> for more information.<\/p>\n-<h2 id=\"reproducible-builds\">Reproducible Builds<\/h2>\n-<p>Build reproducibility is the property of getting exactly the same bits out when building, every time, independent on who builds the product, or where. This is for many reasons a harder goal than it initially appears, but it is an important goal, for security reasons and others. Please see <a href=\"https:\/\/reproducible-builds.org\">Reproducible Builds<\/a> for more information about the background and reasons for reproducible builds.<\/p>\n-<p>Currently, it is not possible to build OpenJDK fully reproducibly, but getting there is an ongoing effort. There are some things you can do to minimize non-determinism and make a larger part of the build reproducible:<\/p>\n-<ul>\n-<li>Turn on build system support for reproducible builds<\/li>\n-<\/ul>\n-<p>Add the flag <code>--enable-reproducible-build<\/code> to your <code>configure<\/code> command line. This will turn on support for reproducible builds where it could otherwise be lacking.<\/p>\n-<ul>\n-<li>Do not rely on <code>configure<\/code>'s default adhoc version strings<\/li>\n-<\/ul>\n-<p>Default adhoc version strings OPT segment include user name, source directory and timestamp. You can either override just the OPT segment using <code>--with-version-opt=&lt;any fixed string&gt;<\/code>, or you can specify the entire version string using <code>--with-version-string=&lt;your version&gt;<\/code>.<\/p>\n-<ul>\n-<li>Specify how the build sets <code>SOURCE_DATE_EPOCH<\/code><\/li>\n-<\/ul>\n-<p>The JDK build system will set the <code>SOURCE_DATE_EPOCH<\/code> environment variable during building, depending on the value of the <code>--with-source-date<\/code> option for <code>configure<\/code>. The default value is <code>updated<\/code>, which means that <code>SOURCE_DATE_EPOCH<\/code> will be set to the current time each time you are running <code>make<\/code>.<\/p>\n-<p>The <a href=\"https:\/\/reproducible-builds.org\/docs\/source-date-epoch\/\"><code>SOURCE_DATE_EPOCH<\/code> environment variable<\/a> is an industry standard, that many tools, such as gcc, recognize, and use in place of the current time when generating output.<\/p>\n-<p>For reproducible builds, you need to set this to a fixed value. You can use the special value <code>version<\/code> which will use the nominal release date for the current JDK version, or a value describing a date, either an epoch based timestamp as an integer, or a valid ISO-8601 date.<\/p>\n-<p><strong>Hint:<\/strong> If your build environment already sets <code>SOURCE_DATE_EPOCH<\/code>, you can propagate this using <code>--with-source-date=$SOURCE_DATE_EPOCH<\/code>.<\/p>\n-<ul>\n-<li>Specify a hotspot build time<\/li>\n-<\/ul>\n-<p>Set a fixed hotspot build time. This will be included in the hotspot library (<code>libjvm.so<\/code> or <code>jvm.dll<\/code>) and defaults to the current time when building hotspot. Use <code>--with-hotspot-build-time=&lt;any fixed string&gt;<\/code> for reproducible builds. It's a string so you don't need to format it specifically, so e.g. <code>n\/a<\/code> will do. Another solution is to use the <code>SOURCE_DATE_EPOCH<\/code> variable, e.g. <code>--with-hotspot-build-time=$(date --date=@$SOURCE_DATE_EPOCH)<\/code>.<\/p>\n-<ul>\n-<li>Copyright year<\/li>\n-<\/ul>\n-<p>The copyright year in some generated text files are normally set to the current year. This can be overridden by <code>--with-copyright-year=&lt;year&gt;<\/code>. For fully reproducible builds, this needs to be set to a fixed value.<\/p>\n-<h2 id=\"hints-and-suggestions-for-advanced-users\">Hints and Suggestions for Advanced Users<\/h2>\n-<h3 id=\"bash-completion\">Bash Completion<\/h3>\n-<p>The <code>configure<\/code> and <code>make<\/code> commands tries to play nice with bash command-line completion (using <code>&lt;tab&gt;<\/code> or <code>&lt;tab&gt;&lt;tab&gt;<\/code>). To use this functionality, make sure you enable completion in your <code>~\/.bashrc<\/code> (see instructions for bash in your operating system).<\/p>\n-<p>Make completion will work out of the box, and will complete valid make targets. For instance, typing <code>make jdk-i&lt;tab&gt;<\/code> will complete to <code>make jdk-image<\/code>.<\/p>\n-<p>The <code>configure<\/code> script can get completion for options, but for this to work you need to help <code>bash<\/code> on the way. The standard way of running the script, <code>bash configure<\/code>, will not be understood by bash completion. You need <code>configure<\/code> to be the command to run. One way to achieve this is to add a simple helper script to your path:<\/p>\n-<pre><code>cat &lt;&lt; EOT &gt; \/tmp\/configure\n-#!\/bin\/bash\n-if [ \\$(pwd) = \\$(cd \\$(dirname \\$0); pwd) ] ; then\n-  echo &gt;&amp;2 &quot;Abort: Trying to call configure helper recursively&quot;\n-  exit 1\n-fi\n-\n-bash \\$PWD\/configure &quot;\\$@&quot;\n-EOT\n-chmod +x \/tmp\/configure\n-sudo mv \/tmp\/configure \/usr\/local\/bin<\/code><\/pre>\n-<p>Now <code>configure --en&lt;tab&gt;-dt&lt;tab&gt;<\/code> will result in <code>configure --enable-dtrace<\/code>.<\/p>\n-<h3 id=\"using-multiple-configurations\">Using Multiple Configurations<\/h3>\n-<p>You can have multiple configurations for a single source repository. When you create a new configuration, run <code>configure --with-conf-name=&lt;name&gt;<\/code> to create a configuration with the name <code>&lt;name&gt;<\/code>. Alternatively, you can create a directory under <code>build<\/code> and run <code>configure<\/code> from there, e.g. <code>mkdir build\/&lt;name&gt; &amp;&amp; cd build\/&lt;name&gt; &amp;&amp; bash ..\/..\/configure<\/code>.<\/p>\n-<p>Then you can build that configuration using <code>make CONF_NAME=&lt;name&gt;<\/code> or <code>make CONF=&lt;pattern&gt;<\/code>, where <code>&lt;pattern&gt;<\/code> is a substring matching one or several configurations, e.g. <code>CONF=debug<\/code>. The special empty pattern (<code>CONF=<\/code>) will match <em>all<\/em> available configuration, so <code>make CONF= hotspot<\/code> will build the <code>hotspot<\/code> target for all configurations. Alternatively, you can execute <code>make<\/code> in the configuration directory, e.g. <code>cd build\/&lt;name&gt; &amp;&amp; make<\/code>.<\/p>\n-<h3 id=\"handling-reconfigurations\">Handling Reconfigurations<\/h3>\n-<p>If you update the repository and part of the configure script has changed, the build system will force you to re-run <code>configure<\/code>.<\/p>\n-<p>Most of the time, you will be fine by running <code>configure<\/code> again with the same arguments as the last time, which can easily be performed by <code>make reconfigure<\/code>. To simplify this, you can use the <code>CONF_CHECK<\/code> make control variable, either as <code>make CONF_CHECK=auto<\/code>, or by setting an environment variable. For instance, if you add <code>export CONF_CHECK=auto<\/code> to your <code>.bashrc<\/code> file, <code>make<\/code> will always run <code>reconfigure<\/code> automatically whenever the configure script has changed.<\/p>\n-<p>You can also use <code>CONF_CHECK=ignore<\/code> to skip the check for a needed configure update. This might speed up the build, but comes at the risk of an incorrect build result. This is only recommended if you know what you're doing.<\/p>\n-<p>From time to time, you will also need to modify the command line to <code>configure<\/code> due to changes. Use <code>make print-configuration<\/code> to show the command line used for your current configuration.<\/p>\n-<h3 id=\"using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/h3>\n-<p>The default behavior for make is to create consistent and correct output, at the expense of build speed, if necessary.<\/p>\n-<p>If you are prepared to take some risk of an incorrect build, and know enough of the system to understand how things build and interact, you can speed up the build process considerably by instructing make to only build a portion of the product.<\/p>\n-<h4 id=\"building-individual-modules\">Building Individual Modules<\/h4>\n-<p>The safe way to use fine-grained make targets is to use the module specific make targets. All source code in the JDK is organized so it belongs to a module, e.g. <code>java.base<\/code> or <code>jdk.jdwp.agent<\/code>. You can build only a specific module, by giving it as make target: <code>make jdk.jdwp.agent<\/code>. If the specified module depends on other modules (e.g. <code>java.base<\/code>), those modules will be built first.<\/p>\n-<p>You can also specify a set of modules, just as you can always specify a set of make targets: <code>make jdk.crypto.cryptoki jdk.crypto.ec jdk.crypto.mscapi<\/code><\/p>\n-<h4 id=\"building-individual-module-phases\">Building Individual Module Phases<\/h4>\n-<p>The build process for each module is divided into separate phases. Not all modules need all phases. Which are needed depends on what kind of source code and other artifact the module consists of. The phases are:<\/p>\n-<ul>\n-<li><code>gensrc<\/code> (Generate source code to compile)<\/li>\n-<li><code>gendata<\/code> (Generate non-source code artifacts)<\/li>\n-<li><code>copy<\/code> (Copy resource artifacts)<\/li>\n-<li><code>java<\/code> (Compile Java code)<\/li>\n-<li><code>launchers<\/code> (Compile native executables)<\/li>\n-<li><code>libs<\/code> (Compile native libraries)<\/li>\n-<\/ul>\n-<p>You can build only a single phase for a module by using the notation <code>$MODULE-$PHASE<\/code>. For instance, to build the <code>gensrc<\/code> phase for <code>java.base<\/code>, use <code>make java.base-gensrc<\/code>.<\/p>\n-<p>Note that some phases may depend on others, e.g. <code>java<\/code> depends on <code>gensrc<\/code> (if present). Make will build all needed prerequisites before building the requested phase.<\/p>\n-<h4 id=\"skipping-the-dependency-check\">Skipping the Dependency Check<\/h4>\n-<p>When using an iterative development style with frequent quick rebuilds, the dependency check made by make can take up a significant portion of the time spent on the rebuild. In such cases, it can be useful to bypass the dependency check in make.<\/p>\n-<blockquote>\n-<p><strong>Note that if used incorrectly, this can lead to a broken build!<\/strong><\/p>\n-<\/blockquote>\n-<p>To achieve this, append <code>-only<\/code> to the build target. For instance, <code>make jdk.jdwp.agent-java-only<\/code> will <em>only<\/em> build the <code>java<\/code> phase of the <code>jdk.jdwp.agent<\/code> module. If the required dependencies are not present, the build can fail. On the other hand, the execution time measures in milliseconds.<\/p>\n-<p>A useful pattern is to build the first time normally (e.g. <code>make jdk.jdwp.agent<\/code>) and then on subsequent builds, use the <code>-only<\/code> make target.<\/p>\n-<h4 id=\"rebuilding-part-of-java.base-jdk_filter\">Rebuilding Part of java.base (JDK_FILTER)<\/h4>\n-<p>If you are modifying files in <code>java.base<\/code>, which is the by far largest module in the JDK, then you need to rebuild all those files whenever a single file has changed. (This inefficiency will hopefully be addressed in JDK 10.)<\/p>\n-<p>As a hack, you can use the make control variable <code>JDK_FILTER<\/code> to specify a pattern that will be used to limit the set of files being recompiled. For instance, <code>make java.base JDK_FILTER=javax\/crypto<\/code> (or, to combine methods, <code>make java.base-java-only JDK_FILTER=javax\/crypto<\/code>) will limit the compilation to files in the <code>javax.crypto<\/code> package.<\/p>\n-<h2 id=\"understanding-the-build-system\">Understanding the Build System<\/h2>\n-<p>This section will give you a more technical description on the details of the build system.<\/p>\n-<h3 id=\"configurations\">Configurations<\/h3>\n-<p>The build system expects to find one or more configuration. These are technically defined by the <code>spec.gmk<\/code> in a subdirectory to the <code>build<\/code> subdirectory. The <code>spec.gmk<\/code> file is generated by <code>configure<\/code>, and contains in principle the configuration (directly or by files included by <code>spec.gmk<\/code>).<\/p>\n-<p>You can, in fact, select a configuration to build by pointing to the <code>spec.gmk<\/code> file with the <code>SPEC<\/code> make control variable, e.g. <code>make SPEC=$BUILD\/spec.gmk<\/code>. While this is not the recommended way to call <code>make<\/code> as a user, it is what is used under the hood by the build system.<\/p>\n-<h3 id=\"build-output-structure\">Build Output Structure<\/h3>\n-<p>The build output for a configuration will end up in <code>build\/&lt;configuration name&gt;<\/code>, which we refer to as <code>$BUILD<\/code> in this document. The <code>$BUILD<\/code> directory contains the following important directories:<\/p>\n-<pre><code>buildtools\/\n-configure-support\/\n-hotspot\/\n-images\/\n-jdk\/\n-make-support\/\n-support\/\n-test-results\/\n-test-support\/<\/code><\/pre>\n-<p>This is what they are used for:<\/p>\n-<ul>\n-<li><p><code>images<\/code>: This is the directory were the output of the <code>*-image<\/code> make targets end up. For instance, <code>make jdk-image<\/code> ends up in <code>images\/jdk<\/code>.<\/p><\/li>\n-<li><p><code>jdk<\/code>: This is the &quot;exploded image&quot;. After <code>make jdk<\/code>, you will be able to launch the newly built JDK by running <code>$BUILD\/jdk\/bin\/java<\/code>.<\/p><\/li>\n-<li><p><code>test-results<\/code>: This directory contains the results from running tests.<\/p><\/li>\n-<li><p><code>support<\/code>: This is an area for intermediate files needed during the build, e.g. generated source code, object files and class files. Some noteworthy directories in <code>support<\/code> is <code>gensrc<\/code>, which contains the generated source code, and the <code>modules_*<\/code> directories, which contains the files in a per-module hierarchy that will later be collapsed into the <code>jdk<\/code> directory of the exploded image.<\/p><\/li>\n-<li><p><code>buildtools<\/code>: This is an area for tools compiled for the build platform that are used during the rest of the build.<\/p><\/li>\n-<li><p><code>hotspot<\/code>: This is an area for intermediate files needed when building hotspot.<\/p><\/li>\n-<li><p><code>configure-support<\/code>, <code>make-support<\/code> and <code>test-support<\/code>: These directories contain files that are needed by the build system for <code>configure<\/code>, <code>make<\/code> and for running tests.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"fixpath\">Fixpath<\/h3>\n-<p>Windows path typically look like <code>C:\\User\\foo<\/code>, while Unix paths look like <code>\/home\/foo<\/code>. Tools with roots from Unix often experience issues related to this mismatch when running on Windows.<\/p>\n-<p>In the JDK build, we always use Unix paths internally, and only just before calling a tool that does not understand Unix paths do we convert them to Windows paths.<\/p>\n-<p>This conversion is done by the <code>fixpath<\/code> tool, which is a small wrapper that modifies unix-style paths to Windows-style paths in command lines. Fixpath is compiled automatically by <code>configure<\/code>.<\/p>\n-<h3 id=\"native-debug-symbols\">Native Debug Symbols<\/h3>\n-<p>Native libraries and executables can have debug symbol (and other debug information) associated with them. How this works is very much platform dependent, but a common problem is that debug symbol information takes a lot of disk space, but is rarely needed by the end user.<\/p>\n-<p>The JDK supports different methods on how to handle debug symbols. The method used is selected by <code>--with-native-debug-symbols<\/code>, and available methods are <code>none<\/code>, <code>internal<\/code>, <code>external<\/code>, <code>zipped<\/code>.<\/p>\n-<ul>\n-<li><p><code>none<\/code> means that no debug symbols will be generated during the build.<\/p><\/li>\n-<li><p><code>internal<\/code> means that debug symbols will be generated during the build, and they will be stored in the generated binary.<\/p><\/li>\n-<li><p><code>external<\/code> means that debug symbols will be generated during the build, and after the compilation, they will be moved into a separate <code>.debuginfo<\/code> file. (This was previously known as FDS, Full Debug Symbols).<\/p><\/li>\n-<li><p><code>zipped<\/code> is like <code>external<\/code>, but the .debuginfo file will also be zipped into a <code>.diz<\/code> file.<\/p><\/li>\n-<\/ul>\n-<p>When building for distribution, <code>zipped<\/code> is a good solution. Binaries built with <code>internal<\/code> is suitable for use by developers, since they facilitate debugging, but should be stripped before distributed to end users.<\/p>\n-<h3 id=\"autoconf-details\">Autoconf Details<\/h3>\n-<p>The <code>configure<\/code> script is based on the autoconf framework, but in some details deviate from a normal autoconf <code>configure<\/code> script.<\/p>\n-<p>The <code>configure<\/code> script in the top level directory of the JDK is just a thin wrapper that calls <code>make\/autoconf\/configure<\/code>. This in turn will run <code>autoconf<\/code> to create the runnable (generated) configure script, as <code>.build\/generated-configure.sh<\/code>. Apart from being responsible for the generation of the runnable script, the <code>configure<\/code> script also provides functionality that is not easily expressed in the normal Autoconf framework. As part of this functionality, the generated script is called.<\/p>\n-<p>The build system will detect if the Autoconf source files have changed, and will trigger a regeneration of the generated script if needed. You can also manually request such an update by <code>bash configure autogen<\/code>.<\/p>\n-<p>In previous versions of the JDK, the generated script was checked in at <code>make\/autoconf\/generated-configure.sh<\/code>. This is no longer the case.<\/p>\n-<h3 id=\"developing-the-build-system-itself\">Developing the Build System Itself<\/h3>\n-<p>This section contains a few remarks about how to develop for the build system itself. It is not relevant if you are only making changes in the product source code.<\/p>\n-<p>While technically using <code>make<\/code>, the make source files of the JDK does not resemble most other Makefiles. Instead of listing specific targets and actions (perhaps using patterns), the basic modus operandi is to call a high-level function (or properly, macro) from the API in <code>make\/common<\/code>. For instance, to compile all classes in the <code>jdk.internal.foo<\/code> package in the <code>jdk.foo<\/code> module, a call like this would be made:<\/p>\n-<pre><code>$(eval $(call SetupJavaCompilation, BUILD_FOO_CLASSES, \\\n-    SETUP := GENERATE_OLDBYTECODE, \\\n-    SRC := $(TOPDIR)\/src\/jkd.foo\/share\/classes, \\\n-    INCLUDES := jdk\/internal\/foo, \\\n-    BIN := $(SUPPORT_OUTPUTDIR)\/foo_classes, \\\n-))<\/code><\/pre>\n-<p>By encapsulating and expressing the high-level knowledge of <em>what<\/em> should be done, rather than <em>how<\/em> it should be done (as is normal in Makefiles), we can build a much more powerful and flexible build system.<\/p>\n-<p>Correct dependency tracking is paramount. Sloppy dependency tracking will lead to improper parallelization, or worse, race conditions.<\/p>\n-<p>To test for\/debug race conditions, try running <code>make JOBS=1<\/code> and <code>make JOBS=100<\/code> and see if it makes any difference. (It shouldn't).<\/p>\n-<p>To compare the output of two different builds and see if, and how, they differ, run <code>$BUILD1\/compare.sh -o $BUILD2<\/code>, where <code>$BUILD1<\/code> and <code>$BUILD2<\/code> are the two builds you want to compare.<\/p>\n-<p>To automatically build two consecutive versions and compare them, use <code>COMPARE_BUILD<\/code>. The value of <code>COMPARE_BUILD<\/code> is a set of variable=value assignments, like this:<\/p>\n-<pre><code>make COMPARE_BUILD=CONF=--enable-new-hotspot-feature:MAKE=hotspot<\/code><\/pre>\n-<p>See <code>make\/InitSupport.gmk<\/code> for details on how to use <code>COMPARE_BUILD<\/code>.<\/p>\n-<p>To analyze build performance, run with <code>LOG=trace<\/code> and check <code>$BUILD\/build-trace-time.log<\/code>. Use <code>JOBS=1<\/code> to avoid parallelism.<\/p>\n-<p>Please check that you adhere to the <a href=\"http:\/\/openjdk.java.net\/groups\/build\/doc\/code-conventions.html\">Code Conventions for the Build System<\/a> before submitting patches.<\/p>\n-<h2 id=\"contributing-to-the-jdk\">Contributing to the JDK<\/h2>\n-<p>So, now you've built your JDK, and made your first patch, and want to contribute it back to the OpenJDK Community.<\/p>\n-<p>First of all: Thank you! We gladly welcome your contribution. However, please bear in mind that the JDK is a massive project, and we must ask you to follow our rules and guidelines to be able to accept your contribution.<\/p>\n-<p>The official place to start is the <a href=\"http:\/\/openjdk.java.net\/contribute\/\">'How to contribute' page<\/a>. There is also an official (but somewhat outdated and skimpy on details) <a href=\"http:\/\/openjdk.java.net\/guide\/\">Developer's Guide<\/a>.<\/p>\n-<p>If this seems overwhelming to you, the Adoption Group is there to help you! A good place to start is their <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Adoption\/New+Contributor\">'New Contributor' page<\/a>, or start reading the comprehensive <a href=\"https:\/\/adoptopenjdk.gitbooks.io\/adoptopenjdk-getting-started-kit\/en\/\">Getting Started Kit<\/a>. The Adoption Group will also happily answer any questions you have about contributing. Contact them by <a href=\"http:\/\/mail.openjdk.java.net\/mailman\/listinfo\/adoption-discuss\">mail<\/a> or <a href=\"http:\/\/openjdk.java.net\/irc\/\">IRC<\/a>.<\/p>\n-<\/body>\n-<\/html>\n+<!DOCTYPE html>\r\n+<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\r\n+<head>\r\n+  <meta charset=\"utf-8\" \/>\r\n+  <meta name=\"generator\" content=\"pandoc\" \/>\r\n+  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\r\n+  <title>Building the JDK<\/title>\r\n+  <style type=\"text\/css\">\r\n+      code{white-space: pre-wrap;}\r\n+      span.smallcaps{font-variant: small-caps;}\r\n+      span.underline{text-decoration: underline;}\r\n+      div.column{display: inline-block; vertical-align: top; width: 50%;}\r\n+  <\/style>\r\n+  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\r\n+  <!--[if lt IE 9]>\r\n+    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\r\n+  <![endif]-->\r\n+  <style type=\"text\/css\">pre, code, tt { color: #1d6ae5; }<\/style>\r\n+<\/head>\r\n+<body>\r\n+<header>\r\n+<h1 class=\"title\">Building the JDK<\/h1>\r\n+<\/header>\r\n+<nav id=\"TOC\">\r\n+<ul>\r\n+<li><a href=\"#tldr-instructions-for-the-impatient\">TL;DR (Instructions for the Impatient)<\/a><\/li>\r\n+<li><a href=\"#introduction\">Introduction<\/a><\/li>\r\n+<li><a href=\"#getting-the-source-code\">Getting the Source Code<\/a><ul>\r\n+<li><a href=\"#special-considerations\">Special Considerations<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#build-hardware-requirements\">Build Hardware Requirements<\/a><ul>\r\n+<li><a href=\"#building-on-x86\">Building on x86<\/a><\/li>\r\n+<li><a href=\"#building-on-aarch64\">Building on aarch64<\/a><\/li>\r\n+<li><a href=\"#building-on-32-bit-arm\">Building on 32-bit arm<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#operating-system-requirements\">Operating System Requirements<\/a><ul>\r\n+<li><a href=\"#windows\">Windows<\/a><\/li>\r\n+<li><a href=\"#macos\">macOS<\/a><\/li>\r\n+<li><a href=\"#linux\">Linux<\/a><\/li>\r\n+<li><a href=\"#aix\">AIX<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#native-compiler-toolchain-requirements\">Native Compiler (Toolchain) Requirements<\/a><ul>\r\n+<li><a href=\"#gcc\">gcc<\/a><\/li>\r\n+<li><a href=\"#clang\">clang<\/a><\/li>\r\n+<li><a href=\"#apple-xcode\">Apple Xcode<\/a><\/li>\r\n+<li><a href=\"#microsoft-visual-studio\">Microsoft Visual Studio<\/a><\/li>\r\n+<li><a href=\"#ibm-xl-cc\">IBM XL C\/C++<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#boot-jdk-requirements\">Boot JDK Requirements<\/a><ul>\r\n+<li><a href=\"#getting-jdk-binaries\">Getting JDK binaries<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#external-library-requirements\">External Library Requirements<\/a><ul>\r\n+<li><a href=\"#freetype\">FreeType<\/a><\/li>\r\n+<li><a href=\"#cups\">CUPS<\/a><\/li>\r\n+<li><a href=\"#x11\">X11<\/a><\/li>\r\n+<li><a href=\"#alsa\">ALSA<\/a><\/li>\r\n+<li><a href=\"#libffi\">libffi<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#build-tools-requirements\">Build Tools Requirements<\/a><ul>\r\n+<li><a href=\"#autoconf\">Autoconf<\/a><\/li>\r\n+<li><a href=\"#gnu-make\">GNU Make<\/a><\/li>\r\n+<li><a href=\"#gnu-bash\">GNU Bash<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#running-configure\">Running Configure<\/a><ul>\r\n+<li><a href=\"#common-configure-arguments\">Common Configure Arguments<\/a><\/li>\r\n+<li><a href=\"#configure-control-variables\">Configure Control Variables<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#running-make\">Running Make<\/a><ul>\r\n+<li><a href=\"#common-make-targets\">Common Make Targets<\/a><\/li>\r\n+<li><a href=\"#make-control-variables\">Make Control Variables<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#running-tests\">Running Tests<\/a><\/li>\r\n+<li><a href=\"#cross-compiling\">Cross-compiling<\/a><ul>\r\n+<li><a href=\"#cross-compiling-the-easy-way-with-openjdk-devkits\">Cross compiling the easy way with OpenJDK devkits<\/a><\/li>\r\n+<li><a href=\"#boot-jdk-and-build-jdk\">Boot JDK and Build JDK<\/a><\/li>\r\n+<li><a href=\"#specifying-the-target-platform\">Specifying the Target Platform<\/a><\/li>\r\n+<li><a href=\"#toolchain-considerations\">Toolchain Considerations<\/a><\/li>\r\n+<li><a href=\"#native-libraries\">Native Libraries<\/a><\/li>\r\n+<li><a href=\"#cross-compiling-with-debian-sysroots\">Cross compiling with Debian sysroots<\/a><\/li>\r\n+<li><a href=\"#building-for-armaarch64\">Building for ARM\/aarch64<\/a><\/li>\r\n+<li><a href=\"#building-for-musl\">Building for musl<\/a><\/li>\r\n+<li><a href=\"#verifying-the-build\">Verifying the Build<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#build-performance\">Build Performance<\/a><ul>\r\n+<li><a href=\"#disk-speed\">Disk Speed<\/a><\/li>\r\n+<li><a href=\"#virus-checking\">Virus Checking<\/a><\/li>\r\n+<li><a href=\"#ccache\">Ccache<\/a><\/li>\r\n+<li><a href=\"#precompiled-headers\">Precompiled Headers<\/a><\/li>\r\n+<li><a href=\"#icecc-icecream\">Icecc \/ icecream<\/a><\/li>\r\n+<li><a href=\"#using-sjavac\">Using sjavac<\/a><\/li>\r\n+<li><a href=\"#building-the-right-target\">Building the Right Target<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#troubleshooting\">Troubleshooting<\/a><ul>\r\n+<li><a href=\"#locating-the-source-of-the-error\">Locating the Source of the Error<\/a><\/li>\r\n+<li><a href=\"#fixing-unexpected-build-failures\">Fixing Unexpected Build Failures<\/a><\/li>\r\n+<li><a href=\"#specific-build-issues\">Specific Build Issues<\/a><\/li>\r\n+<li><a href=\"#getting-help\">Getting Help<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#reproducible-builds\">Reproducible Builds<\/a><\/li>\r\n+<li><a href=\"#hints-and-suggestions-for-advanced-users\">Hints and Suggestions for Advanced Users<\/a><ul>\r\n+<li><a href=\"#bash-completion\">Bash Completion<\/a><\/li>\r\n+<li><a href=\"#using-multiple-configurations\">Using Multiple Configurations<\/a><\/li>\r\n+<li><a href=\"#handling-reconfigurations\">Handling Reconfigurations<\/a><\/li>\r\n+<li><a href=\"#using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#understanding-the-build-system\">Understanding the Build System<\/a><ul>\r\n+<li><a href=\"#configurations\">Configurations<\/a><\/li>\r\n+<li><a href=\"#build-output-structure\">Build Output Structure<\/a><\/li>\r\n+<li><a href=\"#fixpath\">Fixpath<\/a><\/li>\r\n+<li><a href=\"#native-debug-symbols\">Native Debug Symbols<\/a><\/li>\r\n+<li><a href=\"#autoconf-details\">Autoconf Details<\/a><\/li>\r\n+<li><a href=\"#developing-the-build-system-itself\">Developing the Build System Itself<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#contributing-to-the-jdk\">Contributing to the JDK<\/a><\/li>\r\n+<\/ul>\r\n+<\/nav>\r\n+<h2 id=\"tldr-instructions-for-the-impatient\">TL;DR (Instructions for the Impatient)<\/h2>\r\n+<p>If you are eager to try out building the JDK, these simple steps works most of the time. They assume that you have installed Git (and Cygwin if running on Windows) and cloned the top-level JDK repository that you want to build.<\/p>\r\n+<ol type=\"1\">\r\n+<li><p><a href=\"#getting-the-source-code\">Get the complete source code<\/a>:<br \/>\r\n+<code>git clone https:\/\/git.openjdk.java.net\/jdk\/<\/code><\/p><\/li>\r\n+<li><p><a href=\"#running-configure\">Run configure<\/a>:<br \/>\r\n+<code>bash configure<\/code><\/p>\r\n+<p>If <code>configure<\/code> fails due to missing dependencies (to either the <a href=\"#native-compiler-toolchain-requirements\">toolchain<\/a>, <a href=\"#build-tools-requirements\">build tools<\/a>, <a href=\"#external-library-requirements\">external libraries<\/a> or the <a href=\"#boot-jdk-requirements\">boot JDK<\/a>), most of the time it prints a suggestion on how to resolve the situation on your platform. Follow the instructions, and try running <code>bash configure<\/code> again.<\/p><\/li>\r\n+<li><p><a href=\"#running-make\">Run make<\/a>:<br \/>\r\n+<code>make images<\/code><\/p><\/li>\r\n+<li><p>Verify your newly built JDK:<br \/>\r\n+<code>.\/build\/*\/images\/jdk\/bin\/java -version<\/code><\/p><\/li>\r\n+<li><p><a href=\"##running-tests\">Run basic tests<\/a>:<br \/>\r\n+<code>make run-test-tier1<\/code><\/p><\/li>\r\n+<\/ol>\r\n+<p>If any of these steps failed, or if you want to know more about build requirements or build functionality, please continue reading this document.<\/p>\r\n+<h2 id=\"introduction\">Introduction<\/h2>\r\n+<p>The JDK is a complex software project. Building it requires a certain amount of technical expertise, a fair number of dependencies on external software, and reasonably powerful hardware.<\/p>\r\n+<p>If you just want to use the JDK and not build it yourself, this document is not for you. See for instance <a href=\"http:\/\/openjdk.java.net\/install\">OpenJDK installation<\/a> for some methods of installing a prebuilt JDK.<\/p>\r\n+<h2 id=\"getting-the-source-code\">Getting the Source Code<\/h2>\r\n+<p>Make sure you are getting the correct version. As of JDK 10, the source is no longer split into separate repositories so you only need to clone one single repository. At the <a href=\"https:\/\/git.openjdk.java.net\/\">OpenJDK Git site<\/a> you can see a list of all available repositories. If you want to build an older version, e.g. JDK 11, it is recommended that you get the <code>jdk11u<\/code> repo, which contains incremental updates, instead of the <code>jdk11<\/code> repo, which was frozen at JDK 11 GA.<\/p>\r\n+<p>If you are new to Git, a good place to start is the book <a href=\"https:\/\/git-scm.com\/book\/en\/v2\">Pro Git<\/a>. The rest of this document assumes a working knowledge of Git.<\/p>\r\n+<h3 id=\"special-considerations\">Special Considerations<\/h3>\r\n+<p>For a smooth building experience, it is recommended that you follow these rules on where and how to check out the source code.<\/p>\r\n+<ul>\r\n+<li><p>Do not check out the source code in a path which contains spaces. Chances are the build will not work. This is most likely to be an issue on Windows systems.<\/p><\/li>\r\n+<li><p>Do not check out the source code in a path which has a very long name or is nested many levels deep. Chances are you will hit an OS limitation during the build.<\/p><\/li>\r\n+<li><p>Put the source code on a local disk, not a network share. If possible, use an SSD. The build process is very disk intensive, and having slow disk access will significantly increase build times. If you need to use a network share for the source code, see below for suggestions on how to keep the build artifacts on a local disk.<\/p><\/li>\r\n+<li><p>On Windows, if using <a href=\"#cygwin\">Cygwin<\/a>, extra care must be taken to make sure the environment is consistent. It is recommended that you follow this procedure:<\/p>\r\n+<ul>\r\n+<li><p>Create the directory that is going to contain the top directory of the JDK clone by using the <code>mkdir<\/code> command in the Cygwin bash shell. That is, do <em>not<\/em> create it using Windows Explorer. This will ensure that it will have proper Cygwin attributes, and that it's children will inherit those attributes.<\/p><\/li>\r\n+<li><p>Do not put the JDK clone in a path under your Cygwin home directory. This is especially important if your user name contains spaces and\/or mixed upper and lower case letters.<\/p><\/li>\r\n+<li><p>You need to install a git client. You have two choices, Cygwin git or Git for Windows. Unfortunately there are pros and cons with each choice.<\/p>\r\n+<ul>\r\n+<li><p>The Cygwin <code>git<\/code> client has no line ending issues and understands Cygwin paths (which are used throughout the JDK build system). However, it does not currently work well with the Skara CLI tooling. Please see the <a href=\"https:\/\/wiki.openjdk.java.net\/display\/SKARA\/Skara#Skara-Git\">Skara wiki on Git clients<\/a> for up-to-date information about the Skara git client support.<\/p><\/li>\r\n+<li><p>The <a href=\"https:\/\/gitforwindows.org\">Git for Windows<\/a> client has issues with line endings, and do not understand Cygwin paths. It does work well with the Skara CLI tooling, however. To alleviate the line ending problems, make sure you set <code>core.autocrlf<\/code> to <code>false<\/code> (this is asked during installation).<\/p><\/li>\r\n+<\/ul><\/li>\r\n+<\/ul>\r\n+<p>Failure to follow this procedure might result in hard-to-debug build problems.<\/p><\/li>\r\n+<\/ul>\r\n+<h2 id=\"build-hardware-requirements\">Build Hardware Requirements<\/h2>\r\n+<p>The JDK is a massive project, and require machines ranging from decent to powerful to be able to build in a reasonable amount of time, or to be able to complete a build at all.<\/p>\r\n+<p>We <em>strongly<\/em> recommend usage of an SSD disk for the build, since disk speed is one of the limiting factors for build performance.<\/p>\r\n+<h3 id=\"building-on-x86\">Building on x86<\/h3>\r\n+<p>At a minimum, a machine with 2-4 cores is advisable, as well as 2-4 GB of RAM. (The more cores to use, the more memory you need.) At least 6 GB of free disk space is required.<\/p>\r\n+<p>Even for 32-bit builds, it is recommended to use a 64-bit build machine, and instead create a 32-bit target using <code>--with-target-bits=32<\/code>.<\/p>\r\n+<h3 id=\"building-on-aarch64\">Building on aarch64<\/h3>\r\n+<p>At a minimum, a machine with 8 cores is advisable, as well as 8 GB of RAM. (The more cores to use, the more memory you need.) At least 6 GB of free disk space is required.<\/p>\r\n+<p>If you do not have access to sufficiently powerful hardware, it is also possible to use <a href=\"#cross-compiling\">cross-compiling<\/a>.<\/p>\r\n+<h4 id=\"branch-protection\">Branch Protection<\/h4>\r\n+<p>In order to use Branch Protection features in the VM, <code>--enable-branch-protection<\/code> must be used. This option requires C++ compiler support (GCC 9.1.0+ or Clang 10+). The resulting build can be run on both machines with and without support for branch protection in hardware. Branch Protection is only supported for Linux targets.<\/p>\r\n+<h3 id=\"building-on-32-bit-arm\">Building on 32-bit arm<\/h3>\r\n+<p>This is not recommended. Instead, see the section on <a href=\"#cross-compiling\">Cross-compiling<\/a>.<\/p>\r\n+<h2 id=\"operating-system-requirements\">Operating System Requirements<\/h2>\r\n+<p>The mainline JDK project supports Linux, macOS, AIX and Windows. Support for other operating system, e.g. BSD, exists in separate &quot;port&quot; projects.<\/p>\r\n+<p>In general, the JDK can be built on a wide range of versions of these operating systems, but the further you deviate from what is tested on a daily basis, the more likely you are to run into problems.<\/p>\r\n+<p>This table lists the OS versions used by Oracle when building the JDK. Such information is always subject to change, but this table is up to date at the time of writing.<\/p>\r\n+<table>\r\n+<thead>\r\n+<tr class=\"header\">\r\n+<th style=\"text-align: left;\">Operating system<\/th>\r\n+<th style=\"text-align: left;\">Vendor\/version used<\/th>\r\n+<\/tr>\r\n+<\/thead>\r\n+<tbody>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">Linux<\/td>\r\n+<td style=\"text-align: left;\">Oracle Enterprise Linux 6.4 \/ 7.6<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">macOS<\/td>\r\n+<td style=\"text-align: left;\">Mac OS X 10.13 (High Sierra)<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">Windows<\/td>\r\n+<td style=\"text-align: left;\">Windows Server 2012 R2<\/td>\r\n+<\/tr>\r\n+<\/tbody>\r\n+<\/table>\r\n+<p>The double version numbers for Linux are due to the hybrid model used at Oracle, where header files and external libraries from an older version are used when building on a more modern version of the OS.<\/p>\r\n+<p>The Build Group has a wiki page with <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Build\/Supported+Build+Platforms\">Supported Build Platforms<\/a>. From time to time, this is updated by contributors to list successes or failures of building on different platforms.<\/p>\r\n+<h3 id=\"windows\">Windows<\/h3>\r\n+<p>Windows XP is not a supported platform, but all newer Windows should be able to build the JDK.<\/p>\r\n+<p>On Windows, it is important that you pay attention to the instructions in the <a href=\"#special-considerations\">Special Considerations<\/a>.<\/p>\r\n+<p>Windows is the only non-POSIX OS supported by the JDK, and as such, requires some extra care. A POSIX support layer is required to build on Windows. Currently, the only supported such layers are Cygwin, Windows Subsystem for Linux (WSL), and MSYS2. (MSYS is no longer supported due to an outdated bash; While OpenJDK can be built with MSYS2, support for it is still experimental, so build failures and unusual errors are not uncommon.)<\/p>\r\n+<p>Internally in the build system, all paths are represented as Unix-style paths, e.g. <code>\/cygdrive\/c\/git\/jdk\/Makefile<\/code> rather than <code>C:\\git\\jdk\\Makefile<\/code>. This rule also applies to input to the build system, e.g. in arguments to <code>configure<\/code>. So, use <code>--with-msvcr-dll=\/cygdrive\/c\/msvcr100.dll<\/code> rather than <code>--with-msvcr-dll=c:\\msvcr100.dll<\/code>. For details on this conversion, see the section on <a href=\"#fixpath\">Fixpath<\/a>.<\/p>\r\n+<h4 id=\"cygwin\">Cygwin<\/h4>\r\n+<p>A functioning <a href=\"http:\/\/www.cygwin.com\/\">Cygwin<\/a> environment is required for building the JDK on Windows. If you have a 64-bit OS, we strongly recommend using the 64-bit version of Cygwin.<\/p>\r\n+<p><strong>Note:<\/strong> Cygwin has a model of continuously updating all packages without any easy way to install or revert to a specific version of a package. This means that whenever you add or update a package in Cygwin, you might (inadvertently) update tools that are used by the JDK build process, and that can cause unexpected build problems.<\/p>\r\n+<p>The JDK requires GNU Make 4.0 or greater in Cygwin. This is usually not a problem, since Cygwin currently only distributes GNU Make at a version above 4.0.<\/p>\r\n+<p>Apart from the basic Cygwin installation, the following packages must also be installed:<\/p>\r\n+<ul>\r\n+<li><code>autoconf<\/code><\/li>\r\n+<li><code>make<\/code><\/li>\r\n+<li><code>zip<\/code><\/li>\r\n+<li><code>unzip<\/code><\/li>\r\n+<\/ul>\r\n+<p>Often, you can install these packages using the following command line:<\/p>\r\n+<pre><code>&lt;path to Cygwin setup&gt;\/setup-x86_64 -q -P autoconf -P make -P unzip -P zip<\/code><\/pre>\r\n+<p>Unfortunately, Cygwin can be unreliable in certain circumstances. If you experience build tool crashes or strange issues when building on Windows, please check the Cygwin FAQ on the <a href=\"https:\/\/cygwin.com\/faq\/faq.html#faq.using.bloda\">&quot;BLODA&quot; list<\/a> and the section on <a href=\"https:\/\/cygwin.com\/faq\/faq.html#faq.using.fixing-fork-failures\">fork() failures<\/a>.<\/p>\r\n+<h4 id=\"windows-subsystem-for-linux-wsl\">Windows Subsystem for Linux (WSL)<\/h4>\r\n+<p>Windows 10 1809 or newer is supported due to a dependency on the wslpath utility and support for environment variable sharing through WSLENV. Version 1803 can work but intermittent build failures have been observed.<\/p>\r\n+<p>It's possible to build both Windows and Linux binaries from WSL. To build Windows binaries, you must use a Windows boot JDK (located in a Windows-accessible directory). To build Linux binaries, you must use a Linux boot JDK. The default behavior is to build for Windows. To build for Linux, pass <code>--build=x86_64-unknown-linux-gnu --openjdk-target=x86_64-unknown-linux-gnu<\/code> to <code>configure<\/code>.<\/p>\r\n+<p>If building Windows binaries, the source code must be located in a Windows- accessible directory. This is because Windows executables (such as Visual Studio and the boot JDK) must be able to access the source code. Also, the drive where the source is stored must be mounted as case-insensitive by changing either \/etc\/fstab or \/etc\/wsl.conf in WSL. Individual directories may be corrected using the fsutil tool in case the source was cloned before changing the mount options.<\/p>\r\n+<p>Note that while it's possible to build on WSL, testing is still not fully supported.<\/p>\r\n+<h3 id=\"macos\">macOS<\/h3>\r\n+<p>Apple is using a quite aggressive scheme of pushing OS updates, and coupling these updates with required updates of Xcode. Unfortunately, this makes it difficult for a project such as the JDK to keep pace with a continuously updated machine running macOS. See the section on <a href=\"#apple-xcode\">Apple Xcode<\/a> on some strategies to deal with this.<\/p>\r\n+<p>It is recommended that you use at least Mac OS X 10.13 (High Sierra). At the time of writing, the JDK has been successfully compiled on macOS 10.12 (Sierra).<\/p>\r\n+<p>The standard macOS environment contains the basic tooling needed to build, but for external libraries a package manager is recommended. The JDK uses <a href=\"https:\/\/brew.sh\/\">homebrew<\/a> in the examples, but feel free to use whatever manager you want (or none).<\/p>\r\n+<h3 id=\"linux\">Linux<\/h3>\r\n+<p>It is often not much problem to build the JDK on Linux. The only general advice is to try to use the compilers, external libraries and header files as provided by your distribution.<\/p>\r\n+<p>The basic tooling is provided as part of the core operating system, but you will most likely need to install developer packages.<\/p>\r\n+<p>For apt-based distributions (Debian, Ubuntu, etc), try this:<\/p>\r\n+<pre><code>sudo apt-get install build-essential<\/code><\/pre>\r\n+<p>For rpm-based distributions (Fedora, Red Hat, etc), try this:<\/p>\r\n+<pre><code>sudo yum groupinstall &quot;Development Tools&quot;<\/code><\/pre>\r\n+<p>For Alpine Linux, aside from basic tooling, install the GNU versions of some programs:<\/p>\r\n+<pre><code>sudo apk add build-base bash grep zip<\/code><\/pre>\r\n+<h3 id=\"aix\">AIX<\/h3>\r\n+<p>Please consult the AIX section of the <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Build\/Supported+Build+Platforms\">Supported Build Platforms<\/a> OpenJDK Build Wiki page for details about which versions of AIX are supported.<\/p>\r\n+<h2 id=\"native-compiler-toolchain-requirements\">Native Compiler (Toolchain) Requirements<\/h2>\r\n+<p>Large portions of the JDK consists of native code, that needs to be compiled to be able to run on the target platform. In theory, toolchain and operating system should be independent factors, but in practice there's more or less a one-to-one correlation between target operating system and toolchain.<\/p>\r\n+<table>\r\n+<thead>\r\n+<tr class=\"header\">\r\n+<th style=\"text-align: left;\">Operating system<\/th>\r\n+<th style=\"text-align: left;\">Supported toolchain<\/th>\r\n+<\/tr>\r\n+<\/thead>\r\n+<tbody>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">Linux<\/td>\r\n+<td style=\"text-align: left;\">gcc, clang<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">macOS<\/td>\r\n+<td style=\"text-align: left;\">Apple Xcode (using clang)<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">AIX<\/td>\r\n+<td style=\"text-align: left;\">IBM XL C\/C++<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">Windows<\/td>\r\n+<td style=\"text-align: left;\">Microsoft Visual Studio<\/td>\r\n+<\/tr>\r\n+<\/tbody>\r\n+<\/table>\r\n+<p>Please see the individual sections on the toolchains for version recommendations. As a reference, these versions of the toolchains are used, at the time of writing, by Oracle for the daily builds of the JDK. It should be possible to compile the JDK with both older and newer versions, but the closer you stay to this list, the more likely you are to compile successfully without issues.<\/p>\r\n+<table>\r\n+<thead>\r\n+<tr class=\"header\">\r\n+<th style=\"text-align: left;\">Operating system<\/th>\r\n+<th style=\"text-align: left;\">Toolchain version<\/th>\r\n+<\/tr>\r\n+<\/thead>\r\n+<tbody>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">Linux<\/td>\r\n+<td style=\"text-align: left;\">gcc 10.2.0<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">macOS<\/td>\r\n+<td style=\"text-align: left;\">Apple Xcode 10.1 (using clang 10.0.0)<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">Windows<\/td>\r\n+<td style=\"text-align: left;\">Microsoft Visual Studio 2019 update 16.7.2<\/td>\r\n+<\/tr>\r\n+<\/tbody>\r\n+<\/table>\r\n+<p>All compilers are expected to be able to compile to the C99 language standard, as some C99 features are used in the source code. Microsoft Visual Studio doesn't fully support C99 so in practice shared code is limited to using C99 features that it does support.<\/p>\r\n+<h3 id=\"gcc\">gcc<\/h3>\r\n+<p>The minimum accepted version of gcc is 5.0. Older versions will generate a warning by <code>configure<\/code> and are unlikely to work.<\/p>\r\n+<p>The JDK is currently known to be able to compile with at least version 10.2 of gcc.<\/p>\r\n+<p>In general, any version between these two should be usable.<\/p>\r\n+<h3 id=\"clang\">clang<\/h3>\r\n+<p>The minimum accepted version of clang is 3.5. Older versions will not be accepted by <code>configure<\/code>.<\/p>\r\n+<p>To use clang instead of gcc on Linux, use <code>--with-toolchain-type=clang<\/code>.<\/p>\r\n+<h3 id=\"apple-xcode\">Apple Xcode<\/h3>\r\n+<p>The oldest supported version of Xcode is 8.<\/p>\r\n+<p>You will need the Xcode command lines developers tools to be able to build the JDK. (Actually, <em>only<\/em> the command lines tools are needed, not the IDE.) The simplest way to install these is to run:<\/p>\r\n+<pre><code>xcode-select --install<\/code><\/pre>\r\n+<p>It is advisable to keep an older version of Xcode for building the JDK when updating Xcode. This <a href=\"http:\/\/iosdevelopertips.com\/xcode\/install-multiple-versions-of-xcode.html\">blog page<\/a> has good suggestions on managing multiple Xcode versions. To use a specific version of Xcode, use <code>xcode-select -s<\/code> before running <code>configure<\/code>, or use <code>--with-toolchain-path<\/code> to point to the version of Xcode to use, e.g. <code>configure --with-toolchain-path=\/Applications\/Xcode8.app\/Contents\/Developer\/usr\/bin<\/code><\/p>\r\n+<p>If you have recently (inadvertently) updated your OS and\/or Xcode version, and the JDK can no longer be built, please see the section on <a href=\"#problems-with-the-build-environment\">Problems with the Build Environment<\/a>, and <a href=\"#getting-help\">Getting Help<\/a> to find out if there are any recent, non-merged patches available for this update.<\/p>\r\n+<h3 id=\"microsoft-visual-studio\">Microsoft Visual Studio<\/h3>\r\n+<p>For aarch64 machines running Windows the minimum accepted version is Visual Studio 2019 (16.8 or higher). For all other platforms the minimum accepted version of Visual Studio is 2017. Older versions will not be accepted by <code>configure<\/code> and will not work. For all platforms the maximum accepted version of Visual Studio is 2022.<\/p>\r\n+<p>If you have multiple versions of Visual Studio installed, <code>configure<\/code> will by default pick the latest. You can request a specific version to be used by setting <code>--with-toolchain-version<\/code>, e.g. <code>--with-toolchain-version=2017<\/code>.<\/p>\r\n+<p>If you have Visual Studio installed but <code>configure<\/code> fails to detect it, it may be because of <a href=\"#spaces-in-path\">spaces in path<\/a>.<\/p>\r\n+<h3 id=\"ibm-xl-cc\">IBM XL C\/C++<\/h3>\r\n+<p>Please consult the AIX section of the <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Build\/Supported+Build+Platforms\">Supported Build Platforms<\/a> OpenJDK Build Wiki page for details about which versions of XLC are supported.<\/p>\r\n+<h2 id=\"boot-jdk-requirements\">Boot JDK Requirements<\/h2>\r\n+<p>Paradoxically, building the JDK requires a pre-existing JDK. This is called the &quot;boot JDK&quot;. The boot JDK does not, however, have to be a JDK built directly from the source code available in the OpenJDK Community. If you are porting the JDK to a new platform, chances are that there already exists another JDK for that platform that is usable as boot JDK.<\/p>\r\n+<p>The rule of thumb is that the boot JDK for building JDK major version <em>N<\/em> should be a JDK of major version <em>N-1<\/em>, so for building JDK 9 a JDK 8 would be suitable as boot JDK. However, the JDK should be able to &quot;build itself&quot;, so an up-to-date build of the current JDK source is an acceptable alternative. If you are following the <em>N-1<\/em> rule, make sure you've got the latest update version, since JDK 8 GA might not be able to build JDK 9 on all platforms.<\/p>\r\n+<p>Early in the release cycle, version <em>N-1<\/em> may not yet have been released. In that case, the preferred boot JDK will be version <em>N-2<\/em> until version <em>N-1<\/em> is available.<\/p>\r\n+<p>If the boot JDK is not automatically detected, or the wrong JDK is picked, use <code>--with-boot-jdk<\/code> to point to the JDK to use.<\/p>\r\n+<h3 id=\"getting-jdk-binaries\">Getting JDK binaries<\/h3>\r\n+<p>JDK binaries for Linux, Windows and macOS can be downloaded from <a href=\"http:\/\/jdk.java.net\">jdk.java.net<\/a>. An alternative is to download the <a href=\"http:\/\/www.oracle.com\/technetwork\/java\/javase\/downloads\">Oracle JDK<\/a>. Another is the <a href=\"https:\/\/adoptopenjdk.net\/\">Adopt OpenJDK Project<\/a>, which publishes experimental prebuilt binaries for various platforms.<\/p>\r\n+<p>On Linux you can also get a JDK from the Linux distribution. On apt-based distros (like Debian and Ubuntu), <code>sudo apt-get install openjdk-&lt;VERSION&gt;-jdk<\/code> is typically enough to install a JDK &lt;VERSION&gt;. On rpm-based distros (like Fedora and Red Hat), try <code>sudo yum install java-&lt;VERSION&gt;-openjdk-devel<\/code>.<\/p>\r\n+<h2 id=\"external-library-requirements\">External Library Requirements<\/h2>\r\n+<p>Different platforms require different external libraries. In general, libraries are not optional - that is, they are either required or not used.<\/p>\r\n+<p>If a required library is not detected by <code>configure<\/code>, you need to provide the path to it. There are two forms of the <code>configure<\/code> arguments to point to an external library: <code>--with-&lt;LIB&gt;=&lt;path&gt;<\/code> or <code>--with-&lt;LIB&gt;-include=&lt;path to include&gt; --with-&lt;LIB&gt;-lib=&lt;path to lib&gt;<\/code>. The first variant is more concise, but require the include files and library files to reside in a default hierarchy under this directory. In most cases, it works fine.<\/p>\r\n+<p>As a fallback, the second version allows you to point to the include directory and the lib directory separately.<\/p>\r\n+<h3 id=\"freetype\">FreeType<\/h3>\r\n+<p>FreeType2 from <a href=\"http:\/\/www.freetype.org\/\">The FreeType Project<\/a> is not required on any platform. The exception is on Unix-based platforms when configuring such that the build artifacts will reference a system installed library, rather than bundling the JDK's own copy.<\/p>\r\n+<ul>\r\n+<li>To install on an apt-based Linux, try running <code>sudo apt-get install libfreetype6-dev<\/code>.<\/li>\r\n+<li>To install on an rpm-based Linux, try running <code>sudo yum install freetype-devel<\/code>.<\/li>\r\n+<li>To install on Alpine Linux, try running <code>sudo apk add freetype-dev<\/code>.<\/li>\r\n+<li>To install on macOS, try running <code>brew install freetype<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>Use <code>--with-freetype-include=&lt;path&gt;<\/code> and <code>--with-freetype-lib=&lt;path&gt;<\/code> if <code>configure<\/code> does not automatically locate the platform FreeType files.<\/p>\r\n+<h3 id=\"cups\">CUPS<\/h3>\r\n+<p>CUPS, <a href=\"http:\/\/www.cups.org\">Common UNIX Printing System<\/a> header files are required on all platforms, except Windows. Often these files are provided by your operating system.<\/p>\r\n+<ul>\r\n+<li>To install on an apt-based Linux, try running <code>sudo apt-get install libcups2-dev<\/code>.<\/li>\r\n+<li>To install on an rpm-based Linux, try running <code>sudo yum install cups-devel<\/code>.<\/li>\r\n+<li>To install on Alpine Linux, try running <code>sudo apk add cups-dev<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>Use <code>--with-cups=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your CUPS files.<\/p>\r\n+<h3 id=\"x11\">X11<\/h3>\r\n+<p>Certain <a href=\"http:\/\/www.x.org\/\">X11<\/a> libraries and include files are required on Linux.<\/p>\r\n+<ul>\r\n+<li>To install on an apt-based Linux, try running <code>sudo apt-get install libx11-dev libxext-dev libxrender-dev libxrandr-dev libxtst-dev libxt-dev<\/code>.<\/li>\r\n+<li>To install on an rpm-based Linux, try running <code>sudo yum install libXtst-devel libXt-devel libXrender-devel libXrandr-devel libXi-devel<\/code>.<\/li>\r\n+<li>To install on Alpine Linux, try running <code>sudo apk add libx11-dev libxext-dev libxrender-dev libxrandr-dev libxtst-dev libxt-dev<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>Use <code>--with-x=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your X11 files.<\/p>\r\n+<h3 id=\"alsa\">ALSA<\/h3>\r\n+<p>ALSA, <a href=\"https:\/\/www.alsa-project.org\/\">Advanced Linux Sound Architecture<\/a> is required on Linux. At least version 0.9.1 of ALSA is required.<\/p>\r\n+<ul>\r\n+<li>To install on an apt-based Linux, try running <code>sudo apt-get install libasound2-dev<\/code>.<\/li>\r\n+<li>To install on an rpm-based Linux, try running <code>sudo yum install alsa-lib-devel<\/code>.<\/li>\r\n+<li>To install on Alpine Linux, try running <code>sudo apk add alsa-lib-dev<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>Use <code>--with-alsa=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your ALSA files.<\/p>\r\n+<h3 id=\"libffi\">libffi<\/h3>\r\n+<p>libffi, the <a href=\"http:\/\/sourceware.org\/libffi\">Portable Foreign Function Interface Library<\/a> is required when building the Zero version of Hotspot.<\/p>\r\n+<ul>\r\n+<li>To install on an apt-based Linux, try running <code>sudo apt-get install libffi-dev<\/code>.<\/li>\r\n+<li>To install on an rpm-based Linux, try running <code>sudo yum install libffi-devel<\/code>.<\/li>\r\n+<li>To install on Alpine Linux, try running <code>sudo apk add libffi-dev<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>Use <code>--with-libffi=&lt;path&gt;<\/code> if <code>configure<\/code> does not properly locate your libffi files.<\/p>\r\n+<h2 id=\"build-tools-requirements\">Build Tools Requirements<\/h2>\r\n+<h3 id=\"autoconf\">Autoconf<\/h3>\r\n+<p>The JDK requires <a href=\"http:\/\/www.gnu.org\/software\/autoconf\">Autoconf<\/a> on all platforms. At least version 2.69 is required.<\/p>\r\n+<ul>\r\n+<li>To install on an apt-based Linux, try running <code>sudo apt-get install autoconf<\/code>.<\/li>\r\n+<li>To install on an rpm-based Linux, try running <code>sudo yum install autoconf<\/code>.<\/li>\r\n+<li>To install on Alpine Linux, try running <code>sudo apk add autoconf<\/code>.<\/li>\r\n+<li>To install on macOS, try running <code>brew install autoconf<\/code>.<\/li>\r\n+<li>To install on Windows, try running <code>&lt;path to Cygwin setup&gt;\/setup-x86_64 -q -P autoconf<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>If <code>configure<\/code> has problems locating your installation of autoconf, you can specify it using the <code>AUTOCONF<\/code> environment variable, like this:<\/p>\r\n+<pre><code>AUTOCONF=&lt;path to autoconf&gt; configure ...<\/code><\/pre>\r\n+<h3 id=\"gnu-make\">GNU Make<\/h3>\r\n+<p>The JDK requires <a href=\"http:\/\/www.gnu.org\/software\/make\">GNU Make<\/a>. No other flavors of make are supported.<\/p>\r\n+<p>At least version 3.81 of GNU Make must be used. For distributions supporting GNU Make 4.0 or above, we strongly recommend it. GNU Make 4.0 contains useful functionality to handle parallel building (supported by <code>--with-output-sync<\/code>) and speed and stability improvements.<\/p>\r\n+<p>Note that <code>configure<\/code> locates and verifies a properly functioning version of <code>make<\/code> and stores the path to this <code>make<\/code> binary in the configuration. If you start a build using <code>make<\/code> on the command line, you will be using the version of make found first in your <code>PATH<\/code>, and not necessarily the one stored in the configuration. This initial make will be used as &quot;bootstrap make&quot;, and in a second stage, the make located by <code>configure<\/code> will be called. Normally, this will present no issues, but if you have a very old <code>make<\/code>, or a non-GNU Make <code>make<\/code> in your path, this might cause issues.<\/p>\r\n+<p>If you want to override the default make found by <code>configure<\/code>, use the <code>MAKE<\/code> configure variable, e.g. <code>configure MAKE=\/opt\/gnu\/make<\/code>.<\/p>\r\n+<h3 id=\"gnu-bash\">GNU Bash<\/h3>\r\n+<p>The JDK requires <a href=\"http:\/\/www.gnu.org\/software\/bash\">GNU Bash<\/a>. No other shells are supported.<\/p>\r\n+<p>At least version 3.2 of GNU Bash must be used.<\/p>\r\n+<h2 id=\"running-configure\">Running Configure<\/h2>\r\n+<p>To build the JDK, you need a &quot;configuration&quot;, which consists of a directory where to store the build output, coupled with information about the platform, the specific build machine, and choices that affect how the JDK is built.<\/p>\r\n+<p>The configuration is created by the <code>configure<\/code> script. The basic invocation of the <code>configure<\/code> script looks like this:<\/p>\r\n+<pre><code>bash configure [options]<\/code><\/pre>\r\n+<p>This will create an output directory containing the configuration and setup an area for the build result. This directory typically looks like <code>build\/linux-x64-server-release<\/code>, but the actual name depends on your specific configuration. (It can also be set directly, see <a href=\"#using-multiple-configurations\">Using Multiple Configurations<\/a>). This directory is referred to as <code>$BUILD<\/code> in this documentation.<\/p>\r\n+<p><code>configure<\/code> will try to figure out what system you are running on and where all necessary build components are. If you have all prerequisites for building installed, it should find everything. If it fails to detect any component automatically, it will exit and inform you about the problem.<\/p>\r\n+<p>Some command line examples:<\/p>\r\n+<ul>\r\n+<li><p>Create a 32-bit build for Windows with FreeType2 in <code>C:\\freetype-i586<\/code>:<\/p>\r\n+<pre><code>bash configure --with-freetype=\/cygdrive\/c\/freetype-i586 --with-target-bits=32<\/code><\/pre><\/li>\r\n+<li><p>Create a debug build with the <code>server<\/code> JVM and DTrace enabled:<\/p>\r\n+<pre><code>bash configure --enable-debug --with-jvm-variants=server --enable-dtrace<\/code><\/pre><\/li>\r\n+<\/ul>\r\n+<h3 id=\"common-configure-arguments\">Common Configure Arguments<\/h3>\r\n+<p>Here follows some of the most common and important <code>configure<\/code> argument.<\/p>\r\n+<p>To get up-to-date information on <em>all<\/em> available <code>configure<\/code> argument, please run:<\/p>\r\n+<pre><code>bash configure --help<\/code><\/pre>\r\n+<p>(Note that this help text also include general autoconf options, like <code>--dvidir<\/code>, that is not relevant to the JDK. To list only JDK-specific features, use <code>bash configure --help=short<\/code> instead.)<\/p>\r\n+<h4 id=\"configure-arguments-for-tailoring-the-build\">Configure Arguments for Tailoring the Build<\/h4>\r\n+<ul>\r\n+<li><code>--enable-debug<\/code> - Set the debug level to <code>fastdebug<\/code> (this is a shorthand for <code>--with-debug-level=fastdebug<\/code>)<\/li>\r\n+<li><code>--with-debug-level=&lt;level&gt;<\/code> - Set the debug level, which can be <code>release<\/code>, <code>fastdebug<\/code>, <code>slowdebug<\/code> or <code>optimized<\/code>. Default is <code>release<\/code>. <code>optimized<\/code> is variant of <code>release<\/code> with additional Hotspot debug code.<\/li>\r\n+<li><code>--with-native-debug-symbols=&lt;method&gt;<\/code> - Specify if and how native debug symbols should be built. Available methods are <code>none<\/code>, <code>internal<\/code>, <code>external<\/code>, <code>zipped<\/code>. Default behavior depends on platform. See <a href=\"#native-debug-symbols\">Native Debug Symbols<\/a> for more details.<\/li>\r\n+<li><code>--with-version-string=&lt;string&gt;<\/code> - Specify the version string this build will be identified with.<\/li>\r\n+<li><code>--with-version-&lt;part&gt;=&lt;value&gt;<\/code> - A group of options, where <code>&lt;part&gt;<\/code> can be any of <code>pre<\/code>, <code>opt<\/code>, <code>build<\/code>, <code>major<\/code>, <code>minor<\/code>, <code>security<\/code> or <code>patch<\/code>. Use these options to modify just the corresponding part of the version string from the default, or the value provided by <code>--with-version-string<\/code>.<\/li>\r\n+<li><code>--with-jvm-variants=&lt;variant&gt;[,&lt;variant&gt;...]<\/code> - Build the specified variant (or variants) of Hotspot. Valid variants are: <code>server<\/code>, <code>client<\/code>, <code>minimal<\/code>, <code>core<\/code>, <code>zero<\/code>, <code>custom<\/code>. Note that not all variants are possible to combine in a single build.<\/li>\r\n+<li><code>--enable-jvm-feature-&lt;feature&gt;<\/code> or <code>--disable-jvm-feature-&lt;feature&gt;<\/code> - Include (or exclude) <code>&lt;feature&gt;<\/code> as a JVM feature in Hotspot. You can also specify a list of features to be enabled, separated by space or comma, as <code>--with-jvm-features=&lt;feature&gt;[,&lt;feature&gt;...]<\/code>. If you prefix <code>&lt;feature&gt;<\/code> with a <code>-<\/code>, it will be disabled. These options will modify the default list of features for the JVM variant(s) you are building. For the <code>custom<\/code> JVM variant, the default list is empty. A complete list of valid JVM features can be found using <code>bash configure --help<\/code>.<\/li>\r\n+<li><code>--with-target-bits=&lt;bits&gt;<\/code> - Create a target binary suitable for running on a <code>&lt;bits&gt;<\/code> platform. Use this to create 32-bit output on a 64-bit build platform, instead of doing a full cross-compile. (This is known as a <em>reduced<\/em> build.)<\/li>\r\n+<\/ul>\r\n+<p>On Linux, BSD and AIX, it is possible to override where Java by default searches for runtime\/JNI libraries. This can be useful in situations where there is a special shared directory for system JNI libraries. This setting can in turn be overridden at runtime by setting the <code>java.library.path<\/code> property.<\/p>\r\n+<ul>\r\n+<li><code>--with-jni-libpath=&lt;path&gt;<\/code> - Use the specified path as a default when searching for runtime libraries.<\/li>\r\n+<\/ul>\r\n+<h4 id=\"configure-arguments-for-native-compilation\">Configure Arguments for Native Compilation<\/h4>\r\n+<ul>\r\n+<li><code>--with-devkit=&lt;path&gt;<\/code> - Use this devkit for compilers, tools and resources<\/li>\r\n+<li><code>--with-sysroot=&lt;path&gt;<\/code> - Use this directory as sysroot<\/li>\r\n+<li><code>--with-extra-path=&lt;path&gt;[;&lt;path&gt;]<\/code> - Prepend these directories to the default path when searching for all kinds of binaries<\/li>\r\n+<li><code>--with-toolchain-path=&lt;path&gt;[;&lt;path&gt;]<\/code> - Prepend these directories when searching for toolchain binaries (compilers etc)<\/li>\r\n+<li><code>--with-extra-cflags=&lt;flags&gt;<\/code> - Append these flags when compiling JDK C files<\/li>\r\n+<li><code>--with-extra-cxxflags=&lt;flags&gt;<\/code> - Append these flags when compiling JDK C++ files<\/li>\r\n+<li><code>--with-extra-ldflags=&lt;flags&gt;<\/code> - Append these flags when linking JDK libraries<\/li>\r\n+<\/ul>\r\n+<h4 id=\"configure-arguments-for-external-dependencies\">Configure Arguments for External Dependencies<\/h4>\r\n+<ul>\r\n+<li><code>--with-boot-jdk=&lt;path&gt;<\/code> - Set the path to the <a href=\"#boot-jdk-requirements\">Boot JDK<\/a><\/li>\r\n+<li><code>--with-freetype=&lt;path&gt;<\/code> - Set the path to <a href=\"#freetype\">FreeType<\/a><\/li>\r\n+<li><code>--with-cups=&lt;path&gt;<\/code> - Set the path to <a href=\"#cups\">CUPS<\/a><\/li>\r\n+<li><code>--with-x=&lt;path&gt;<\/code> - Set the path to <a href=\"#x11\">X11<\/a><\/li>\r\n+<li><code>--with-alsa=&lt;path&gt;<\/code> - Set the path to <a href=\"#alsa\">ALSA<\/a><\/li>\r\n+<li><code>--with-libffi=&lt;path&gt;<\/code> - Set the path to <a href=\"#libffi\">libffi<\/a><\/li>\r\n+<li><code>--with-jtreg=&lt;path&gt;<\/code> - Set the path to JTReg. See <a href=\"#running-tests\">Running Tests<\/a><\/li>\r\n+<\/ul>\r\n+<p>Certain third-party libraries used by the JDK (libjpeg, giflib, libpng, lcms and zlib) are included in the JDK repository. The default behavior of the JDK build is to use the included (&quot;bundled&quot;) versions of libjpeg, giflib, libpng and lcms. For zlib, the system lib (if present) is used except on Windows and AIX. However the bundled libraries may be replaced by an external version. To do so, specify <code>system<\/code> as the <code>&lt;source&gt;<\/code> option in these arguments. (The default is <code>bundled<\/code>).<\/p>\r\n+<ul>\r\n+<li><code>--with-libjpeg=&lt;source&gt;<\/code> - Use the specified source for libjpeg<\/li>\r\n+<li><code>--with-giflib=&lt;source&gt;<\/code> - Use the specified source for giflib<\/li>\r\n+<li><code>--with-libpng=&lt;source&gt;<\/code> - Use the specified source for libpng<\/li>\r\n+<li><code>--with-lcms=&lt;source&gt;<\/code> - Use the specified source for lcms<\/li>\r\n+<li><code>--with-zlib=&lt;source&gt;<\/code> - Use the specified source for zlib<\/li>\r\n+<\/ul>\r\n+<p>On Linux, it is possible to select either static or dynamic linking of the C++ runtime. The default is static linking, with dynamic linking as fallback if the static library is not found.<\/p>\r\n+<ul>\r\n+<li><code>--with-stdc++lib=&lt;method&gt;<\/code> - Use the specified method (<code>static<\/code>, <code>dynamic<\/code> or <code>default<\/code>) for linking the C++ runtime.<\/li>\r\n+<\/ul>\r\n+<h3 id=\"configure-control-variables\">Configure Control Variables<\/h3>\r\n+<p>It is possible to control certain aspects of <code>configure<\/code> by overriding the value of <code>configure<\/code> variables, either on the command line or in the environment.<\/p>\r\n+<p>Normally, this is <strong>not recommended<\/strong>. If used improperly, it can lead to a broken configuration. Unless you're well versed in the build system, this is hard to use properly. Therefore, <code>configure<\/code> will print a warning if this is detected.<\/p>\r\n+<p>However, there are a few <code>configure<\/code> variables, known as <em>control variables<\/em> that are supposed to be overridden on the command line. These are variables that describe the location of tools needed by the build, like <code>MAKE<\/code> or <code>GREP<\/code>. If any such variable is specified, <code>configure<\/code> will use that value instead of trying to autodetect the tool. For instance, <code>bash configure MAKE=\/opt\/gnumake4.0\/bin\/make<\/code>.<\/p>\r\n+<p>If a configure argument exists, use that instead, e.g. use <code>--with-jtreg<\/code> instead of setting <code>JTREGEXE<\/code>.<\/p>\r\n+<p>Also note that, despite what autoconf claims, setting <code>CFLAGS<\/code> will not accomplish anything. Instead use <code>--with-extra-cflags<\/code> (and similar for <code>cxxflags<\/code> and <code>ldflags<\/code>).<\/p>\r\n+<h2 id=\"running-make\">Running Make<\/h2>\r\n+<p>When you have a proper configuration, all you need to do to build the JDK is to run <code>make<\/code>. (But see the warning at <a href=\"#gnu-make\">GNU Make<\/a> about running the correct version of make.)<\/p>\r\n+<p>When running <code>make<\/code> without any arguments, the default target is used, which is the same as running <code>make default<\/code> or <code>make jdk<\/code>. This will build a minimal (or roughly minimal) set of compiled output (known as an &quot;exploded image&quot;) needed for a developer to actually execute the newly built JDK. The idea is that in an incremental development fashion, when doing a normal make, you should only spend time recompiling what's changed (making it purely incremental) and only do the work that's needed to actually run and test your code.<\/p>\r\n+<p>The output of the exploded image resides in <code>$BUILD\/jdk<\/code>. You can test the newly built JDK like this: <code>$BUILD\/jdk\/bin\/java -version<\/code>.<\/p>\r\n+<h3 id=\"common-make-targets\">Common Make Targets<\/h3>\r\n+<p>Apart from the default target, here are some common make targets:<\/p>\r\n+<ul>\r\n+<li><code>hotspot<\/code> - Build all of hotspot (but only hotspot)<\/li>\r\n+<li><code>hotspot-&lt;variant&gt;<\/code> - Build just the specified jvm variant<\/li>\r\n+<li><code>images<\/code> or <code>product-images<\/code> - Build the JDK image<\/li>\r\n+<li><code>docs<\/code> or <code>docs-image<\/code> - Build the documentation image<\/li>\r\n+<li><code>test-image<\/code> - Build the test image<\/li>\r\n+<li><code>all<\/code> or <code>all-images<\/code> - Build all images (product, docs and test)<\/li>\r\n+<li><code>bootcycle-images<\/code> - Build images twice, second time with newly built JDK (good for testing)<\/li>\r\n+<li><code>clean<\/code> - Remove all files generated by make, but not those generated by configure<\/li>\r\n+<li><code>dist-clean<\/code> - Remove all files, including configuration<\/li>\r\n+<\/ul>\r\n+<p>Run <code>make help<\/code> to get an up-to-date list of important make targets and make control variables.<\/p>\r\n+<p>It is possible to build just a single module, a single phase, or a single phase of a single module, by creating make targets according to these followin patterns. A phase can be either of <code>gensrc<\/code>, <code>gendata<\/code>, <code>copy<\/code>, <code>java<\/code>, <code>launchers<\/code>, or <code>libs<\/code>. See <a href=\"#using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/a> for more details about this functionality.<\/p>\r\n+<ul>\r\n+<li><code>&lt;phase&gt;<\/code> - Build the specified phase and everything it depends on<\/li>\r\n+<li><code>&lt;module&gt;<\/code> - Build the specified module and everything it depends on<\/li>\r\n+<li><code>&lt;module&gt;-&lt;phase&gt;<\/code> - Compile the specified phase for the specified module and everything it depends on<\/li>\r\n+<\/ul>\r\n+<p>Similarly, it is possible to clean just a part of the build by creating make targets according to these patterns:<\/p>\r\n+<ul>\r\n+<li><code>clean-&lt;outputdir&gt;<\/code> - Remove the subdir in the output dir with the name<\/li>\r\n+<li><code>clean-&lt;phase&gt;<\/code> - Remove all build results related to a certain build phase<\/li>\r\n+<li><code>clean-&lt;module&gt;<\/code> - Remove all build results related to a certain module<\/li>\r\n+<li><code>clean-&lt;module&gt;-&lt;phase&gt;<\/code> - Remove all build results related to a certain module and phase<\/li>\r\n+<\/ul>\r\n+<h3 id=\"make-control-variables\">Make Control Variables<\/h3>\r\n+<p>It is possible to control <code>make<\/code> behavior by overriding the value of <code>make<\/code> variables, either on the command line or in the environment.<\/p>\r\n+<p>Normally, this is <strong>not recommended<\/strong>. If used improperly, it can lead to a broken build. Unless you're well versed in the build system, this is hard to use properly. Therefore, <code>make<\/code> will print a warning if this is detected.<\/p>\r\n+<p>However, there are a few <code>make<\/code> variables, known as <em>control variables<\/em> that are supposed to be overridden on the command line. These make up the &quot;make time&quot; configuration, as opposed to the &quot;configure time&quot; configuration.<\/p>\r\n+<h4 id=\"general-make-control-variables\">General Make Control Variables<\/h4>\r\n+<ul>\r\n+<li><code>JOBS<\/code> - Specify the number of jobs to build with. See <a href=\"#build-performance\">Build Performance<\/a>.<\/li>\r\n+<li><code>LOG<\/code> - Specify the logging level and functionality. See <a href=\"#checking-the-build-log-file\">Checking the Build Log File<\/a><\/li>\r\n+<li><code>CONF<\/code> and <code>CONF_NAME<\/code> - Selecting the configuration(s) to use. See <a href=\"#using-multiple-configurations\">Using Multiple Configurations<\/a><\/li>\r\n+<\/ul>\r\n+<h4 id=\"test-make-control-variables\">Test Make Control Variables<\/h4>\r\n+<p>These make control variables only make sense when running tests. Please see <strong>Testing the JDK<\/strong> (<a href=\"testing.html\">html<\/a>, <a href=\"testing.md\">markdown<\/a>) for details.<\/p>\r\n+<ul>\r\n+<li><code>TEST<\/code><\/li>\r\n+<li><code>TEST_JOBS<\/code><\/li>\r\n+<li><code>JTREG<\/code><\/li>\r\n+<li><code>GTEST<\/code><\/li>\r\n+<\/ul>\r\n+<h4 id=\"advanced-make-control-variables\">Advanced Make Control Variables<\/h4>\r\n+<p>These advanced make control variables can be potentially unsafe. See <a href=\"#hints-and-suggestions-for-advanced-users\">Hints and Suggestions for Advanced Users<\/a> and <a href=\"#understanding-the-build-system\">Understanding the Build System<\/a> for details.<\/p>\r\n+<ul>\r\n+<li><code>SPEC<\/code><\/li>\r\n+<li><code>CONF_CHECK<\/code><\/li>\r\n+<li><code>COMPARE_BUILD<\/code><\/li>\r\n+<li><code>JDK_FILTER<\/code><\/li>\r\n+<li><code>SPEC_FILTER<\/code><\/li>\r\n+<\/ul>\r\n+<h2 id=\"running-tests\">Running Tests<\/h2>\r\n+<p>Most of the JDK tests are using the <a href=\"http:\/\/openjdk.java.net\/jtreg\">JTReg<\/a> test framework. Make sure that your configuration knows where to find your installation of JTReg. If this is not picked up automatically, use the <code>--with-jtreg=&lt;path to jtreg home&gt;<\/code> option to point to the JTReg framework. Note that this option should point to the JTReg home, i.e. the top directory, containing <code>lib\/jtreg.jar<\/code> etc.<\/p>\r\n+<p>The <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Adoption\">Adoption Group<\/a> provides recent builds of jtreg <a href=\"https:\/\/ci.adoptopenjdk.net\/view\/Dependencies\/job\/dependency_pipeline\/lastSuccessfulBuild\/artifact\/jtreg\/\">here<\/a>. Download the latest <code>.tar.gz<\/code> file, unpack it, and point <code>--with-jtreg<\/code> to the <code>jtreg<\/code> directory that you just unpacked.<\/p>\r\n+<p>Building of Hotspot Gtest suite requires the source code of Google Test framework. The top directory, which contains both <code>googletest<\/code> and <code>googlemock<\/code> directories, should be specified via <code>--with-gtest<\/code>. The supported version of Google Test is 1.8.1, whose source code can be obtained:<\/p>\r\n+<ul>\r\n+<li>by downloading and unpacking the source bundle from <a href=\"https:\/\/github.com\/google\/googletest\/releases\/tag\/release-1.8.1\">here<\/a><\/li>\r\n+<li>or by checking out <code>release-1.8.1<\/code> tag of <code>googletest<\/code> project: <code>git clone -b release-1.8.1 https:\/\/github.com\/google\/googletest<\/code><\/li>\r\n+<\/ul>\r\n+<p>To execute the most basic tests (tier 1), use:<\/p>\r\n+<pre><code>make run-test-tier1<\/code><\/pre>\r\n+<p>For more details on how to run tests, please see <strong>Testing the JDK<\/strong> (<a href=\"testing.html\">html<\/a>, <a href=\"testing.md\">markdown<\/a>).<\/p>\r\n+<h2 id=\"cross-compiling\">Cross-compiling<\/h2>\r\n+<p>Cross-compiling means using one platform (the <em>build<\/em> platform) to generate output that can ran on another platform (the <em>target<\/em> platform).<\/p>\r\n+<p>The typical reason for cross-compiling is that the build is performed on a more powerful desktop computer, but the resulting binaries will be able to run on a different, typically low-performing system. Most of the complications that arise when building for embedded is due to this separation of <em>build<\/em> and <em>target<\/em> systems.<\/p>\r\n+<p>This requires a more complex setup and build procedure. This section assumes you are familiar with cross-compiling in general, and will only deal with the particularities of cross-compiling the JDK. If you are new to cross-compiling, please see the <a href=\"https:\/\/en.wikipedia.org\/wiki\/Cross_compiler#External_links\">external links at Wikipedia<\/a> for a good start on reading materials.<\/p>\r\n+<p>Cross-compiling the JDK requires you to be able to build both for the build platform and for the target platform. The reason for the former is that we need to build and execute tools during the build process, both native tools and Java tools.<\/p>\r\n+<p>If all you want to do is to compile a 32-bit version, for the same OS, on a 64-bit machine, consider using <code>--with-target-bits=32<\/code> instead of doing a full-blown cross-compilation. (While this surely is possible, it's a lot more work and will take much longer to build.)<\/p>\r\n+<h3 id=\"cross-compiling-the-easy-way-with-openjdk-devkits\">Cross compiling the easy way with OpenJDK devkits<\/h3>\r\n+<p>The OpenJDK build system provides out-of-the box support for creating and using so called devkits. A <code>devkit<\/code> is basically a collection of a cross-compiling toolchain and a sysroot environment which can easily be used together with the <code>--with-devkit<\/code> configure option to cross compile the OpenJDK. On Linux\/x86_64, the following command:<\/p>\r\n+<pre><code>bash configure --with-devkit=&lt;devkit-path&gt; --openjdk-target=ppc64-linux-gnu &amp;&amp; make<\/code><\/pre>\r\n+<p>will configure and build OpenJDK for Linux\/ppc64 assuming that <code>&lt;devkit-path&gt;<\/code> points to a Linux\/x86_64 to Linux\/ppc64 devkit.<\/p>\r\n+<p>Devkits can be created from the <code>make\/devkit<\/code> directory by executing:<\/p>\r\n+<pre><code>make [ TARGETS=&quot;&lt;TARGET_TRIPLET&gt;+&quot; ] [ BASE_OS=&lt;OS&gt; ] [ BASE_OS_VERSION=&lt;VER&gt; ]<\/code><\/pre>\r\n+<p>where <code>TARGETS<\/code> contains one or more <code>TARGET_TRIPLET<\/code>s of the form described in <a href=\"https:\/\/sourceware.org\/autobook\/autobook\/autobook_17.html\">section 3.4 of the GNU Autobook<\/a>. If no targets are given, a native toolchain for the current platform will be created. Currently, at least the following targets are known to work:<\/p>\r\n+<table>\r\n+<thead>\r\n+<tr class=\"header\">\r\n+<th style=\"text-align: left;\">Supported devkit targets<\/th>\r\n+<\/tr>\r\n+<\/thead>\r\n+<tbody>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">x86_64-linux-gnu<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">aarch64-linux-gnu<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">arm-linux-gnueabihf<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">ppc64-linux-gnu<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">ppc64le-linux-gnu<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">s390x-linux-gnu<\/td>\r\n+<\/tr>\r\n+<\/tbody>\r\n+<\/table>\r\n+<p><code>BASE_OS<\/code> must be one of &quot;OEL6&quot; for Oracle Enterprise Linux 6 or &quot;Fedora&quot; (if not specified &quot;OEL6&quot; will be the default). If the base OS is &quot;Fedora&quot; the corresponding Fedora release can be specified with the help of the <code>BASE_OS_VERSION<\/code> option (with &quot;27&quot; as default version). If the build is successful, the new devkits can be found in the <code>build\/devkit\/result<\/code> subdirectory:<\/p>\r\n+<pre><code>cd make\/devkit\r\n+make TARGETS=&quot;ppc64le-linux-gnu aarch64-linux-gnu&quot; BASE_OS=Fedora BASE_OS_VERSION=21\r\n+ls -1 ..\/..\/build\/devkit\/result\/\r\n+x86_64-linux-gnu-to-aarch64-linux-gnu\r\n+x86_64-linux-gnu-to-ppc64le-linux-gnu<\/code><\/pre>\r\n+<p>Notice that devkits are not only useful for targeting different build platforms. Because they contain the full build dependencies for a system (i.e. compiler and root file system), they can easily be used to build well-known, reliable and reproducible build environments. You can for example create and use a devkit with GCC 7.3 and a Fedora 12 sysroot environment (with glibc 2.11) on Ubuntu 14.04 (which doesn't have GCC 7.3 by default) to produce OpenJDK binaries which will run on all Linux systems with runtime libraries newer than the ones from Fedora 12 (e.g. Ubuntu 16.04, SLES 11 or RHEL 6).<\/p>\r\n+<h3 id=\"boot-jdk-and-build-jdk\">Boot JDK and Build JDK<\/h3>\r\n+<p>When cross-compiling, make sure you use a boot JDK that runs on the <em>build<\/em> system, and not on the <em>target<\/em> system.<\/p>\r\n+<p>To be able to build, we need a &quot;Build JDK&quot;, which is a JDK built from the current sources (that is, the same as the end result of the entire build process), but able to run on the <em>build<\/em> system, and not the <em>target<\/em> system. (In contrast, the Boot JDK should be from an older release, e.g. JDK 8 when building JDK 9.)<\/p>\r\n+<p>The build process will create a minimal Build JDK for you, as part of building. To speed up the build, you can use <code>--with-build-jdk<\/code> to <code>configure<\/code> to point to a pre-built Build JDK. Please note that the build result is unpredictable, and can possibly break in subtle ways, if the Build JDK does not <strong>exactly<\/strong> match the current sources.<\/p>\r\n+<h3 id=\"specifying-the-target-platform\">Specifying the Target Platform<\/h3>\r\n+<p>You <em>must<\/em> specify the target platform when cross-compiling. Doing so will also automatically turn the build into a cross-compiling mode. The simplest way to do this is to use the <code>--openjdk-target<\/code> argument, e.g. <code>--openjdk-target=arm-linux-gnueabihf<\/code>. or <code>--openjdk-target=aarch64-oe-linux<\/code>. This will automatically set the <code>--host<\/code> and <code>--target<\/code> options for autoconf, which can otherwise be confusing. (In autoconf terminology, the &quot;target&quot; is known as &quot;host&quot;, and &quot;target&quot; is used for building a Canadian cross-compiler.)<\/p>\r\n+<p>If <code>--build<\/code> has not been explicitly passed to configure, <code>--openjdk-target<\/code> will autodetect the build platform and internally set the flag automatically, otherwise the platform that was explicitly passed to <code>--build<\/code> will be used instead.<\/p>\r\n+<h3 id=\"toolchain-considerations\">Toolchain Considerations<\/h3>\r\n+<p>You will need two copies of your toolchain, one which generates output that can run on the target system (the normal, or <em>target<\/em>, toolchain), and one that generates output that can run on the build system (the <em>build<\/em> toolchain). Note that cross-compiling is only supported for gcc at the time being. The gcc standard is to prefix cross-compiling toolchains with the target denominator. If you follow this standard, <code>configure<\/code> is likely to pick up the toolchain correctly.<\/p>\r\n+<p>The <em>build<\/em> toolchain will be autodetected just the same way the normal <em>build<\/em>\/<em>target<\/em> toolchain will be autodetected when not cross-compiling. If this is not what you want, or if the autodetection fails, you can specify a devkit containing the <em>build<\/em> toolchain using <code>--with-build-devkit<\/code> to <code>configure<\/code>, or by giving <code>BUILD_CC<\/code> and <code>BUILD_CXX<\/code> arguments.<\/p>\r\n+<p>It is often helpful to locate the cross-compilation tools, headers and libraries in a separate directory, outside the normal path, and point out that directory to <code>configure<\/code>. Do this by setting the sysroot (<code>--with-sysroot<\/code>) and appending the directory when searching for cross-compilations tools (<code>--with-toolchain-path<\/code>). As a compact form, you can also use <code>--with-devkit<\/code> to point to a single directory, if it is correctly setup. (See <code>basics.m4<\/code> for details.)<\/p>\r\n+<h3 id=\"native-libraries\">Native Libraries<\/h3>\r\n+<p>You will need copies of external native libraries for the <em>target<\/em> system, present on the <em>build<\/em> machine while building.<\/p>\r\n+<p>Take care not to replace the <em>build<\/em> system's version of these libraries by mistake, since that can render the <em>build<\/em> machine unusable.<\/p>\r\n+<p>Make sure that the libraries you point to (ALSA, X11, etc) are for the <em>target<\/em>, not the <em>build<\/em>, platform.<\/p>\r\n+<h4 id=\"alsa-1\">ALSA<\/h4>\r\n+<p>You will need alsa libraries suitable for your <em>target<\/em> system. For most cases, using Debian's pre-built libraries work fine.<\/p>\r\n+<p>Note that alsa is needed even if you only want to build a headless JDK.<\/p>\r\n+<ul>\r\n+<li><p>Go to <a href=\"https:\/\/www.debian.org\/distrib\/packages\">Debian Package Search<\/a> and search for the <code>libasound2<\/code> and <code>libasound2-dev<\/code> packages for your <em>target<\/em> system. Download them to \/tmp.<\/p><\/li>\r\n+<li>Install the libraries into the cross-compilation toolchain. For instance:<\/li>\r\n+<\/ul>\r\n+<pre><code>cd \/tools\/gcc-linaro-arm-linux-gnueabihf-raspbian-2012.09-20120921_linux\/arm-linux-gnueabihf\/libc\r\n+dpkg-deb -x \/tmp\/libasound2_1.0.25-4_armhf.deb .\r\n+dpkg-deb -x \/tmp\/libasound2-dev_1.0.25-4_armhf.deb .<\/code><\/pre>\r\n+<ul>\r\n+<li>If alsa is not properly detected by <code>configure<\/code>, you can point it out by <code>--with-alsa<\/code>.<\/li>\r\n+<\/ul>\r\n+<h4 id=\"x11-1\">X11<\/h4>\r\n+<p>You will need X11 libraries suitable for your <em>target<\/em> system. For most cases, using Debian's pre-built libraries work fine.<\/p>\r\n+<p>Note that X11 is needed even if you only want to build a headless JDK.<\/p>\r\n+<ul>\r\n+<li>Go to <a href=\"https:\/\/www.debian.org\/distrib\/packages\">Debian Package Search<\/a>, search for the following packages for your <em>target<\/em> system, and download them to \/tmp\/target-x11:\r\n+<ul>\r\n+<li>libxi<\/li>\r\n+<li>libxi-dev<\/li>\r\n+<li>x11proto-core-dev<\/li>\r\n+<li>x11proto-input-dev<\/li>\r\n+<li>x11proto-kb-dev<\/li>\r\n+<li>x11proto-render-dev<\/li>\r\n+<li>x11proto-xext-dev<\/li>\r\n+<li>libice-dev<\/li>\r\n+<li>libxrender<\/li>\r\n+<li>libxrender-dev<\/li>\r\n+<li>libxrandr-dev<\/li>\r\n+<li>libsm-dev<\/li>\r\n+<li>libxt-dev<\/li>\r\n+<li>libx11<\/li>\r\n+<li>libx11-dev<\/li>\r\n+<li>libxtst<\/li>\r\n+<li>libxtst-dev<\/li>\r\n+<li>libxext<\/li>\r\n+<li>libxext-dev<\/li>\r\n+<\/ul><\/li>\r\n+<li><p>Install the libraries into the cross-compilation toolchain. For instance:<\/p>\r\n+<pre><code>cd \/tools\/gcc-linaro-arm-linux-gnueabihf-raspbian-2012.09-20120921_linux\/arm-linux-gnueabihf\/libc\/usr\r\n+mkdir X11R6\r\n+cd X11R6\r\n+for deb in \/tmp\/target-x11\/*.deb ; do dpkg-deb -x $deb . ; done\r\n+mv usr\/* .\r\n+cd lib\r\n+cp arm-linux-gnueabihf\/* .<\/code><\/pre>\r\n+<p>You can ignore the following messages. These libraries are not needed to successfully complete a full JDK build.<\/p>\r\n+<pre><code>cp: cannot stat `arm-linux-gnueabihf\/libICE.so&#39;: No such file or directory\r\n+cp: cannot stat `arm-linux-gnueabihf\/libSM.so&#39;: No such file or directory\r\n+cp: cannot stat `arm-linux-gnueabihf\/libXt.so&#39;: No such file or directory<\/code><\/pre><\/li>\r\n+<li><p>If the X11 libraries are not properly detected by <code>configure<\/code>, you can point them out by <code>--with-x<\/code>.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"cross-compiling-with-debian-sysroots\">Cross compiling with Debian sysroots<\/h3>\r\n+<p>Fortunately, you can create sysroots for foreign architectures with tools provided by your OS. On Debian\/Ubuntu systems, one could use <code>qemu-deboostrap<\/code> to create the <em>target<\/em> system chroot, which would have the native libraries and headers specific to that <em>target<\/em> system. After that, we can use the cross-compiler on the <em>build<\/em> system, pointing into chroot to get the build dependencies right. This allows building for foreign architectures with native compilation speed.<\/p>\r\n+<p>For example, cross-compiling to AArch64 from x86_64 could be done like this:<\/p>\r\n+<ul>\r\n+<li><p>Install cross-compiler on the <em>build<\/em> system:<\/p>\r\n+<pre><code>apt install g++-aarch64-linux-gnu gcc-aarch64-linux-gnu<\/code><\/pre><\/li>\r\n+<li><p>Create chroot on the <em>build<\/em> system, configuring it for <em>target<\/em> system:<\/p>\r\n+<pre><code>sudo qemu-debootstrap \\\r\n+  --arch=arm64 \\\r\n+  --verbose \\\r\n+  --include=fakeroot,symlinks,build-essential,libx11-dev,libxext-dev,libxrender-dev,libxrandr-dev,libxtst-dev,libxt-dev,libcups2-dev,libfontconfig1-dev,libasound2-dev,libfreetype6-dev,libpng-dev,libffi-dev \\\r\n+  --resolve-deps \\\r\n+  buster \\\r\n+  ~\/sysroot-arm64 \\\r\n+  http:\/\/httpredir.debian.org\/debian\/<\/code><\/pre><\/li>\r\n+<li><p>Make sure the symlinks inside the newly created chroot point to proper locations:<\/p>\r\n+<pre><code>sudo chroot ~\/sysroot-arm64 symlinks -cr .<\/code><\/pre><\/li>\r\n+<li><p>Configure and build with newly created chroot as sysroot\/toolchain-path:<\/p>\r\n+<pre><code>sh .\/configure \\\r\n+  --openjdk-target=aarch64-linux-gnu \\\r\n+  --with-sysroot=~\/sysroot-arm64\r\n+make images\r\n+ls build\/linux-aarch64-server-release\/<\/code><\/pre><\/li>\r\n+<\/ul>\r\n+<p>The build does not create new files in that chroot, so it can be reused for multiple builds without additional cleanup.<\/p>\r\n+<p>The build system should automatically detect the toolchain paths and dependencies, but sometimes it might require a little nudge with:<\/p>\r\n+<ul>\r\n+<li><p>Native compilers: override <code>CC<\/code> or <code>CXX<\/code> for <code>.\/configure<\/code><\/p><\/li>\r\n+<li><p>Freetype lib location: override <code>--with-freetype-lib<\/code>, for example <code>${sysroot}\/usr\/lib\/${target}\/<\/code><\/p><\/li>\r\n+<li><p>Freetype includes location: override <code>--with-freetype-include<\/code> for example <code>${sysroot}\/usr\/include\/freetype2\/<\/code><\/p><\/li>\r\n+<li><p>X11 libraries location: override <code>--x-libraries<\/code>, for example <code>${sysroot}\/usr\/lib\/${target}\/<\/code><\/p><\/li>\r\n+<\/ul>\r\n+<p>Architectures that are known to successfully cross-compile like this are:<\/p>\r\n+<table>\r\n+<thead>\r\n+<tr class=\"header\">\r\n+<th style=\"text-align: left;\">Target<\/th>\r\n+<th style=\"text-align: left;\">Debian tree<\/th>\r\n+<th style=\"text-align: left;\">Debian arch<\/th>\r\n+<th style=\"text-align: left;\"><code>--openjdk-target=...<\/code><\/th>\r\n+<th><code>--with-jvm-variants=...<\/code><\/th>\r\n+<\/tr>\r\n+<\/thead>\r\n+<tbody>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">x86<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">i386<\/td>\r\n+<td style=\"text-align: left;\">i386-linux-gnu<\/td>\r\n+<td>(all)<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">arm<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">armhf<\/td>\r\n+<td style=\"text-align: left;\">arm-linux-gnueabihf<\/td>\r\n+<td>(all)<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">aarch64<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">arm64<\/td>\r\n+<td style=\"text-align: left;\">aarch64-linux-gnu<\/td>\r\n+<td>(all)<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">ppc64le<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">ppc64el<\/td>\r\n+<td style=\"text-align: left;\">powerpc64le-linux-gnu<\/td>\r\n+<td>(all)<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">s390x<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">s390x<\/td>\r\n+<td style=\"text-align: left;\">s390x-linux-gnu<\/td>\r\n+<td>(all)<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">mipsle<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">mipsel<\/td>\r\n+<td style=\"text-align: left;\">mipsel-linux-gnu<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">mips64le<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">mips64el<\/td>\r\n+<td style=\"text-align: left;\">mips64el-linux-gnueabi64<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">armel<\/td>\r\n+<td style=\"text-align: left;\">buster<\/td>\r\n+<td style=\"text-align: left;\">arm<\/td>\r\n+<td style=\"text-align: left;\">arm-linux-gnueabi<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">ppc<\/td>\r\n+<td style=\"text-align: left;\">sid<\/td>\r\n+<td style=\"text-align: left;\">powerpc<\/td>\r\n+<td style=\"text-align: left;\">powerpc-linux-gnu<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">ppc64be<\/td>\r\n+<td style=\"text-align: left;\">sid<\/td>\r\n+<td style=\"text-align: left;\">ppc64<\/td>\r\n+<td style=\"text-align: left;\">powerpc64-linux-gnu<\/td>\r\n+<td>(all)<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">m68k<\/td>\r\n+<td style=\"text-align: left;\">sid<\/td>\r\n+<td style=\"text-align: left;\">m68k<\/td>\r\n+<td style=\"text-align: left;\">m68k-linux-gnu<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<tr class=\"even\">\r\n+<td style=\"text-align: left;\">alpha<\/td>\r\n+<td style=\"text-align: left;\">sid<\/td>\r\n+<td style=\"text-align: left;\">alpha<\/td>\r\n+<td style=\"text-align: left;\">alpha-linux-gnu<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<tr class=\"odd\">\r\n+<td style=\"text-align: left;\">sh4<\/td>\r\n+<td style=\"text-align: left;\">sid<\/td>\r\n+<td style=\"text-align: left;\">sh4<\/td>\r\n+<td style=\"text-align: left;\">sh4-linux-gnu<\/td>\r\n+<td>zero<\/td>\r\n+<\/tr>\r\n+<\/tbody>\r\n+<\/table>\r\n+<h3 id=\"building-for-armaarch64\">Building for ARM\/aarch64<\/h3>\r\n+<p>A common cross-compilation target is the ARM CPU. When building for ARM, it is useful to set the ABI profile. A number of pre-defined ABI profiles are available using <code>--with-abi-profile<\/code>: arm-vfp-sflt, arm-vfp-hflt, arm-sflt, armv5-vfp-sflt, armv6-vfp-hflt. Note that soft-float ABIs are no longer properly supported by the JDK.<\/p>\r\n+<h3 id=\"building-for-musl\">Building for musl<\/h3>\r\n+<p>Just like it's possible to cross-compile for a different CPU, it's possible to cross-compile for musl libc on a glibc-based <em>build<\/em> system. A devkit suitable for most target CPU architectures can be obtained from <a href=\"https:\/\/musl.cc\">musl.cc<\/a>. After installing the required packages in the sysroot, configure the build with <code>--openjdk-target<\/code>:<\/p>\r\n+<pre><code>sh .\/configure --with-jvm-variants=server \\\r\n+--with-boot-jdk=$BOOT_JDK \\\r\n+--with-build-jdk=$BUILD_JDK \\\r\n+--openjdk-target=x86_64-unknown-linux-musl \\\r\n+--with-devkit=$DEVKIT \\\r\n+--with-sysroot=$SYSROOT<\/code><\/pre>\r\n+<p>and run <code>make<\/code> normally.<\/p>\r\n+<h3 id=\"verifying-the-build\">Verifying the Build<\/h3>\r\n+<p>The build will end up in a directory named like <code>build\/linux-arm-normal-server-release<\/code>.<\/p>\r\n+<p>Inside this build output directory, the <code>images\/jdk<\/code> will contain the newly built JDK, for your <em>target<\/em> system.<\/p>\r\n+<p>Copy these folders to your <em>target<\/em> system. Then you can run e.g. <code>images\/jdk\/bin\/java -version<\/code>.<\/p>\r\n+<h2 id=\"build-performance\">Build Performance<\/h2>\r\n+<p>Building the JDK requires a lot of horsepower. Some of the build tools can be adjusted to utilize more or less of resources such as parallel threads and memory. The <code>configure<\/code> script analyzes your system and selects reasonable values for such options based on your hardware. If you encounter resource problems, such as out of memory conditions, you can modify the detected values with:<\/p>\r\n+<ul>\r\n+<li><p><code>--with-num-cores<\/code> -- number of cores in the build system, e.g. <code>--with-num-cores=8<\/code>.<\/p><\/li>\r\n+<li><p><code>--with-memory-size<\/code> -- memory (in MB) available in the build system, e.g. <code>--with-memory-size=1024<\/code><\/p><\/li>\r\n+<\/ul>\r\n+<p>You can also specify directly the number of build jobs to use with <code>--with-jobs=N<\/code> to <code>configure<\/code>, or <code>JOBS=N<\/code> to <code>make<\/code>. Do not use the <code>-j<\/code> flag to <code>make<\/code>. In most cases it will be ignored by the makefiles, but it can cause problems for some make targets.<\/p>\r\n+<p>It might also be necessary to specify the JVM arguments passed to the Boot JDK, using e.g. <code>--with-boot-jdk-jvmargs=&quot;-Xmx8G&quot;<\/code>. Doing so will override the default JVM arguments passed to the Boot JDK.<\/p>\r\n+<p>At the end of a successful execution of <code>configure<\/code>, you will get a performance summary, indicating how well the build will perform. Here you will also get performance hints. If you want to build fast, pay attention to those!<\/p>\r\n+<p>If you want to tweak build performance, run with <code>make LOG=info<\/code> to get a build time summary at the end of the build process.<\/p>\r\n+<h3 id=\"disk-speed\">Disk Speed<\/h3>\r\n+<p>If you are using network shares, e.g. via NFS, for your source code, make sure the build directory is situated on local disk (e.g. by <code>ln -s \/localdisk\/jdk-build $JDK-SHARE\/build<\/code>). The performance penalty is extremely high for building on a network share; close to unusable.<\/p>\r\n+<p>Also, make sure that your build tools (including Boot JDK and toolchain) is located on a local disk and not a network share.<\/p>\r\n+<p>As has been stressed elsewhere, do use SSD for source code and build directory, as well as (if possible) the build tools.<\/p>\r\n+<h3 id=\"virus-checking\">Virus Checking<\/h3>\r\n+<p>The use of virus checking software, especially on Windows, can <em>significantly<\/em> slow down building of the JDK. If possible, turn off such software, or exclude the directory containing the JDK source code from on-the-fly checking.<\/p>\r\n+<h3 id=\"ccache\">Ccache<\/h3>\r\n+<p>The JDK build supports building with ccache when using gcc or clang. Using ccache can radically speed up compilation of native code if you often rebuild the same sources. Your milage may vary however, so we recommend evaluating it for yourself. To enable it, make sure it's on the path and configure with <code>--enable-ccache<\/code>.<\/p>\r\n+<h3 id=\"precompiled-headers\">Precompiled Headers<\/h3>\r\n+<p>By default, the Hotspot build uses preccompiled headers (PCH) on the toolchains were it is properly supported (clang, gcc, and Visual Studio). Normally, this speeds up the build process, but in some circumstances, it can actually slow things down.<\/p>\r\n+<p>You can experiment by disabling precompiled headers using <code>--disable-precompiled-headers<\/code>.<\/p>\r\n+<h3 id=\"icecc-icecream\">Icecc \/ icecream<\/h3>\r\n+<p><a href=\"http:\/\/github.com\/icecc\/icecream\">icecc\/icecream<\/a> is a simple way to setup a distributed compiler network. If you have multiple machines available for building the JDK, you can drastically cut individual build times by utilizing it.<\/p>\r\n+<p>To use, setup an icecc network, and install icecc on the build machine. Then run <code>configure<\/code> using <code>--enable-icecc<\/code>.<\/p>\r\n+<h3 id=\"using-sjavac\">Using sjavac<\/h3>\r\n+<p>To speed up Java compilation, especially incremental compilations, you can try the experimental sjavac compiler by using <code>--enable-sjavac<\/code>.<\/p>\r\n+<h3 id=\"building-the-right-target\">Building the Right Target<\/h3>\r\n+<p>Selecting the proper target to build can have dramatic impact on build time. For normal usage, <code>jdk<\/code> or the default target is just fine. You only need to build <code>images<\/code> for shipping, or if your tests require it.<\/p>\r\n+<p>See also <a href=\"#using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/a> on how to build an even smaller subset of the product.<\/p>\r\n+<h2 id=\"troubleshooting\">Troubleshooting<\/h2>\r\n+<p>If your build fails, it can sometimes be difficult to pinpoint the problem or find a proper solution.<\/p>\r\n+<h3 id=\"locating-the-source-of-the-error\">Locating the Source of the Error<\/h3>\r\n+<p>When a build fails, it can be hard to pinpoint the actual cause of the error. In a typical build process, different parts of the product build in parallel, with the output interlaced.<\/p>\r\n+<h4 id=\"build-failure-summary\">Build Failure Summary<\/h4>\r\n+<p>To help you, the build system will print a failure summary at the end. It looks like this:<\/p>\r\n+<pre><code>ERROR: Build failed for target &#39;hotspot&#39; in configuration &#39;linux-x64&#39; (exit code 2)\r\n+\r\n+=== Output from failing command(s) repeated here ===\r\n+* For target hotspot_variant-server_libjvm_objs_psMemoryPool.o:\r\n+\/localhome\/git\/jdk-sandbox\/hotspot\/src\/share\/vm\/services\/psMemoryPool.cpp:1:1: error: &#39;failhere&#39; does not name a type\r\n+   ... (rest of output omitted)\r\n+\r\n+* All command lines available in \/localhome\/git\/jdk-sandbox\/build\/linux-x64\/make-support\/failure-logs.\r\n+=== End of repeated output ===\r\n+\r\n+=== Make failed targets repeated here ===\r\n+lib\/CompileJvm.gmk:207: recipe for target &#39;\/localhome\/git\/jdk-sandbox\/build\/linux-x64\/hotspot\/variant-server\/libjvm\/objs\/psMemoryPool.o&#39; failed\r\n+make\/Main.gmk:263: recipe for target &#39;hotspot-server-libs&#39; failed\r\n+=== End of repeated output ===\r\n+\r\n+Hint: Try searching the build log for the name of the first failed target.\r\n+Hint: If caused by a warning, try configure --disable-warnings-as-errors.<\/code><\/pre>\r\n+<p>Let's break it down! First, the selected configuration, and the top-level target you entered on the command line that caused the failure is printed.<\/p>\r\n+<p>Then, between the <code>Output from failing command(s) repeated here<\/code> and <code>End of repeated output<\/code> the first lines of output (stdout and stderr) from the actual failing command is repeated. In most cases, this is the error message that caused the build to fail. If multiple commands were failing (this can happen in a parallel build), output from all failed commands will be printed here.<\/p>\r\n+<p>The path to the <code>failure-logs<\/code> directory is printed. In this file you will find a <code>&lt;target&gt;.log<\/code> file that contains the output from this command in its entirety, and also a <code>&lt;target&gt;.cmd<\/code>, which contain the complete command line used for running this command. You can re-run the failing command by executing <code>. &lt;path to failure-logs&gt;\/&lt;target&gt;.cmd<\/code> in your shell.<\/p>\r\n+<p>Another way to trace the failure is to follow the chain of make targets, from top-level targets to individual file targets. Between <code>Make failed targets repeated here<\/code> and <code>End of repeated output<\/code> the output from make showing this chain is repeated. The first failed recipe will typically contain the full path to the file in question that failed to compile. Following lines will show a trace of make targets why we ended up trying to compile that file.<\/p>\r\n+<p>Finally, some hints are given on how to locate the error in the complete log. In this example, we would try searching the log file for &quot;<code>psMemoryPool.o<\/code>&quot;. Another way to quickly locate make errors in the log is to search for &quot;<code>] Error<\/code>&quot; or &quot;<code>***<\/code>&quot;.<\/p>\r\n+<p>Note that the build failure summary will only help you if the issue was a compilation failure or similar. If the problem is more esoteric, or is due to errors in the build machinery, you will likely get empty output logs, and <code>No indication of failed target found<\/code> instead of the make target chain.<\/p>\r\n+<h4 id=\"checking-the-build-log-file\">Checking the Build Log File<\/h4>\r\n+<p>The output (stdout and stderr) from the latest build is always stored in <code>$BUILD\/build.log<\/code>. The previous build log is stored as <code>build.log.old<\/code>. This means that it is not necessary to redirect the build output yourself if you want to process it.<\/p>\r\n+<p>You can increase the verbosity of the log file, by the <code>LOG<\/code> control variable to <code>make<\/code>. If you want to see the command lines used in compilations, use <code>LOG=cmdlines<\/code>. To increase the general verbosity, use <code>LOG=info<\/code>, <code>LOG=debug<\/code> or <code>LOG=trace<\/code>. Both of these can be combined with <code>cmdlines<\/code>, e.g. <code>LOG=info,cmdlines<\/code>. The <code>debug<\/code> log level will show most shell commands executed by make, and <code>trace<\/code> will show all. Beware that both these log levels will produce a massive build log!<\/p>\r\n+<h3 id=\"fixing-unexpected-build-failures\">Fixing Unexpected Build Failures<\/h3>\r\n+<p>Most of the time, the build will fail due to incorrect changes in the source code.<\/p>\r\n+<p>Sometimes the build can fail with no apparent changes that have caused the failure. If this is the first time you are building the JDK on this particular computer, and the build fails, the problem is likely with your build environment. But even if you have previously built the JDK with success, and it now fails, your build environment might have changed (perhaps due to OS upgrades or similar). But most likely, such failures are due to problems with the incremental rebuild.<\/p>\r\n+<h4 id=\"problems-with-the-build-environment\">Problems with the Build Environment<\/h4>\r\n+<p>Make sure your configuration is correct. Re-run <code>configure<\/code>, and look for any warnings. Warnings that appear in the middle of the <code>configure<\/code> output is also repeated at the end, after the summary. The entire log is stored in <code>$BUILD\/configure.log<\/code>.<\/p>\r\n+<p>Verify that the summary at the end looks correct. Are you indeed using the Boot JDK and native toolchain that you expect?<\/p>\r\n+<p>By default, the JDK has a strict approach where warnings from the compiler is considered errors which fail the build. For very new or very old compiler versions, this can trigger new classes of warnings, which thus fails the build. Run <code>configure<\/code> with <code>--disable-warnings-as-errors<\/code> to turn of this behavior. (The warnings will still show, but not make the build fail.)<\/p>\r\n+<h4 id=\"problems-with-incremental-rebuilds\">Problems with Incremental Rebuilds<\/h4>\r\n+<p>Incremental rebuilds mean that when you modify part of the product, only the affected parts get rebuilt. While this works great in most cases, and significantly speed up the development process, from time to time complex interdependencies will result in an incorrect build result. This is the most common cause for unexpected build problems.<\/p>\r\n+<p>Here are a suggested list of things to try if you are having unexpected build problems. Each step requires more time than the one before, so try them in order. Most issues will be solved at step 1 or 2.<\/p>\r\n+<ol type=\"1\">\r\n+<li><p>Make sure your repository is up-to-date<\/p>\r\n+<p>Run <code>git pull origin master<\/code> to make sure you have the latest changes.<\/p><\/li>\r\n+<li><p>Clean build results<\/p>\r\n+<p>The simplest way to fix incremental rebuild issues is to run <code>make clean<\/code>. This will remove all build results, but not the configuration or any build system support artifacts. In most cases, this will solve build errors resulting from incremental build mismatches.<\/p><\/li>\r\n+<li><p>Completely clean the build directory.<\/p>\r\n+<p>If this does not work, the next step is to run <code>make dist-clean<\/code>, or removing the build output directory (<code>$BUILD<\/code>). This will clean all generated output, including your configuration. You will need to re-run <code>configure<\/code> after this step. A good idea is to run <code>make print-configuration<\/code> before running <code>make dist-clean<\/code>, as this will print your current <code>configure<\/code> command line. Here's a way to do this:<\/p>\r\n+<pre><code>make print-configuration &gt; current-configuration\r\n+make dist-clean\r\n+bash configure $(cat current-configuration)\r\n+make<\/code><\/pre><\/li>\r\n+<li><p>Re-clone the Git repository<\/p>\r\n+<p>Sometimes the Git repository gets in a state that causes the product to be un-buildable. In such a case, the simplest solution is often the &quot;sledgehammer approach&quot;: delete the entire repository, and re-clone it. If you have local changes, save them first to a different location using <code>git format-patch<\/code>.<\/p><\/li>\r\n+<\/ol>\r\n+<h3 id=\"specific-build-issues\">Specific Build Issues<\/h3>\r\n+<h4 id=\"clock-skew\">Clock Skew<\/h4>\r\n+<p>If you get an error message like this:<\/p>\r\n+<pre><code>File &#39;xxx&#39; has modification time in the future.\r\n+Clock skew detected. Your build may be incomplete.<\/code><\/pre>\r\n+<p>then the clock on your build machine is out of sync with the timestamps on the source files. Other errors, apparently unrelated but in fact caused by the clock skew, can occur along with the clock skew warnings. These secondary errors may tend to obscure the fact that the true root cause of the problem is an out-of-sync clock.<\/p>\r\n+<p>If you see these warnings, reset the clock on the build machine, run <code>make clean<\/code> and restart the build.<\/p>\r\n+<h4 id=\"out-of-memory-errors\">Out of Memory Errors<\/h4>\r\n+<p>On Windows, you might get error messages like this:<\/p>\r\n+<pre><code>fatal error - couldn&#39;t allocate heap\r\n+cannot create ... Permission denied\r\n+spawn failed<\/code><\/pre>\r\n+<p>This can be a sign of a Cygwin problem. See the information about solving problems in the <a href=\"#cygwin\">Cygwin<\/a> section. Rebooting the computer might help temporarily.<\/p>\r\n+<h4 id=\"spaces-in-path\">Spaces in Path<\/h4>\r\n+<p>On Windows, when configuring, <code>fixpath.sh<\/code> may report that some directory names have spaces. Usually, it assumes those directories have <a href=\"https:\/\/docs.microsoft.com\/en-us\/windows-server\/administration\/windows-commands\/fsutil-8dot3name\">short paths<\/a>. You can run <code>fsutil file setshortname<\/code> in <code>cmd<\/code> on certain directories, such as <code>Microsoft Visual Studio<\/code> or <code>Windows Kits<\/code>, to assign arbitrary short paths so <code>configure<\/code> can access them.<\/p>\r\n+<h3 id=\"getting-help\">Getting Help<\/h3>\r\n+<p>If none of the suggestions in this document helps you, or if you find what you believe is a bug in the build system, please contact the Build Group by sending a mail to <a href=\"mailto:build-dev@openjdk.java.net\">build-dev@openjdk.java.net<\/a>. Please include the relevant parts of the configure and\/or build log.<\/p>\r\n+<p>If you need general help or advice about developing for the JDK, you can also contact the Adoption Group. See the section on <a href=\"#contributing-to-openjdk\">Contributing to OpenJDK<\/a> for more information.<\/p>\r\n+<h2 id=\"reproducible-builds\">Reproducible Builds<\/h2>\r\n+<p>Build reproducibility is the property of getting exactly the same bits out when building, every time, independent on who builds the product, or where. This is for many reasons a harder goal than it initially appears, but it is an important goal, for security reasons and others. Please see <a href=\"https:\/\/reproducible-builds.org\">Reproducible Builds<\/a> for more information about the background and reasons for reproducible builds.<\/p>\r\n+<p>Currently, it is not possible to build OpenJDK fully reproducibly, but getting there is an ongoing effort. There are some things you can do to minimize non-determinism and make a larger part of the build reproducible:<\/p>\r\n+<ul>\r\n+<li>Turn on build system support for reproducible builds<\/li>\r\n+<\/ul>\r\n+<p>Add the flag <code>--enable-reproducible-build<\/code> to your <code>configure<\/code> command line. This will turn on support for reproducible builds where it could otherwise be lacking.<\/p>\r\n+<ul>\r\n+<li>Do not rely on <code>configure<\/code>'s default adhoc version strings<\/li>\r\n+<\/ul>\r\n+<p>Default adhoc version strings OPT segment include user name, source directory and timestamp. You can either override just the OPT segment using <code>--with-version-opt=&lt;any fixed string&gt;<\/code>, or you can specify the entire version string using <code>--with-version-string=&lt;your version&gt;<\/code>.<\/p>\r\n+<ul>\r\n+<li>Specify how the build sets <code>SOURCE_DATE_EPOCH<\/code><\/li>\r\n+<\/ul>\r\n+<p>The JDK build system will set the <code>SOURCE_DATE_EPOCH<\/code> environment variable during building, depending on the value of the <code>--with-source-date<\/code> option for <code>configure<\/code>. The default value is <code>updated<\/code>, which means that <code>SOURCE_DATE_EPOCH<\/code> will be set to the current time each time you are running <code>make<\/code>.<\/p>\r\n+<p>The <a href=\"https:\/\/reproducible-builds.org\/docs\/source-date-epoch\/\"><code>SOURCE_DATE_EPOCH<\/code> environment variable<\/a> is an industry standard, that many tools, such as gcc, recognize, and use in place of the current time when generating output.<\/p>\r\n+<p>For reproducible builds, you need to set this to a fixed value. You can use the special value <code>version<\/code> which will use the nominal release date for the current JDK version, or a value describing a date, either an epoch based timestamp as an integer, or a valid ISO-8601 date.<\/p>\r\n+<p><strong>Hint:<\/strong> If your build environment already sets <code>SOURCE_DATE_EPOCH<\/code>, you can propagate this using <code>--with-source-date=$SOURCE_DATE_EPOCH<\/code>.<\/p>\r\n+<ul>\r\n+<li>Specify a hotspot build time<\/li>\r\n+<\/ul>\r\n+<p>Set a fixed hotspot build time. This will be included in the hotspot library (<code>libjvm.so<\/code> or <code>jvm.dll<\/code>) and defaults to the current time when building hotspot. Use <code>--with-hotspot-build-time=&lt;any fixed string&gt;<\/code> for reproducible builds. It's a string so you don't need to format it specifically, so e.g. <code>n\/a<\/code> will do. Another solution is to use the <code>SOURCE_DATE_EPOCH<\/code> variable, e.g. <code>--with-hotspot-build-time=$(date --date=@$SOURCE_DATE_EPOCH)<\/code>.<\/p>\r\n+<ul>\r\n+<li>Copyright year<\/li>\r\n+<\/ul>\r\n+<p>The copyright year in some generated text files are normally set to the current year. This can be overridden by <code>--with-copyright-year=&lt;year&gt;<\/code>. For fully reproducible builds, this needs to be set to a fixed value.<\/p>\r\n+<h2 id=\"hints-and-suggestions-for-advanced-users\">Hints and Suggestions for Advanced Users<\/h2>\r\n+<h3 id=\"bash-completion\">Bash Completion<\/h3>\r\n+<p>The <code>configure<\/code> and <code>make<\/code> commands tries to play nice with bash command-line completion (using <code>&lt;tab&gt;<\/code> or <code>&lt;tab&gt;&lt;tab&gt;<\/code>). To use this functionality, make sure you enable completion in your <code>~\/.bashrc<\/code> (see instructions for bash in your operating system).<\/p>\r\n+<p>Make completion will work out of the box, and will complete valid make targets. For instance, typing <code>make jdk-i&lt;tab&gt;<\/code> will complete to <code>make jdk-image<\/code>.<\/p>\r\n+<p>The <code>configure<\/code> script can get completion for options, but for this to work you need to help <code>bash<\/code> on the way. The standard way of running the script, <code>bash configure<\/code>, will not be understood by bash completion. You need <code>configure<\/code> to be the command to run. One way to achieve this is to add a simple helper script to your path:<\/p>\r\n+<pre><code>cat &lt;&lt; EOT &gt; \/tmp\/configure\r\n+#!\/bin\/bash\r\n+if [ \\$(pwd) = \\$(cd \\$(dirname \\$0); pwd) ] ; then\r\n+  echo &gt;&amp;2 &quot;Abort: Trying to call configure helper recursively&quot;\r\n+  exit 1\r\n+fi\r\n+\r\n+bash \\$PWD\/configure &quot;\\$@&quot;\r\n+EOT\r\n+chmod +x \/tmp\/configure\r\n+sudo mv \/tmp\/configure \/usr\/local\/bin<\/code><\/pre>\r\n+<p>Now <code>configure --en&lt;tab&gt;-dt&lt;tab&gt;<\/code> will result in <code>configure --enable-dtrace<\/code>.<\/p>\r\n+<h3 id=\"using-multiple-configurations\">Using Multiple Configurations<\/h3>\r\n+<p>You can have multiple configurations for a single source repository. When you create a new configuration, run <code>configure --with-conf-name=&lt;name&gt;<\/code> to create a configuration with the name <code>&lt;name&gt;<\/code>. Alternatively, you can create a directory under <code>build<\/code> and run <code>configure<\/code> from there, e.g. <code>mkdir build\/&lt;name&gt; &amp;&amp; cd build\/&lt;name&gt; &amp;&amp; bash ..\/..\/configure<\/code>.<\/p>\r\n+<p>Then you can build that configuration using <code>make CONF_NAME=&lt;name&gt;<\/code> or <code>make CONF=&lt;pattern&gt;<\/code>, where <code>&lt;pattern&gt;<\/code> is a substring matching one or several configurations, e.g. <code>CONF=debug<\/code>. The special empty pattern (<code>CONF=<\/code>) will match <em>all<\/em> available configuration, so <code>make CONF= hotspot<\/code> will build the <code>hotspot<\/code> target for all configurations. Alternatively, you can execute <code>make<\/code> in the configuration directory, e.g. <code>cd build\/&lt;name&gt; &amp;&amp; make<\/code>.<\/p>\r\n+<h3 id=\"handling-reconfigurations\">Handling Reconfigurations<\/h3>\r\n+<p>If you update the repository and part of the configure script has changed, the build system will force you to re-run <code>configure<\/code>.<\/p>\r\n+<p>Most of the time, you will be fine by running <code>configure<\/code> again with the same arguments as the last time, which can easily be performed by <code>make reconfigure<\/code>. To simplify this, you can use the <code>CONF_CHECK<\/code> make control variable, either as <code>make CONF_CHECK=auto<\/code>, or by setting an environment variable. For instance, if you add <code>export CONF_CHECK=auto<\/code> to your <code>.bashrc<\/code> file, <code>make<\/code> will always run <code>reconfigure<\/code> automatically whenever the configure script has changed.<\/p>\r\n+<p>You can also use <code>CONF_CHECK=ignore<\/code> to skip the check for a needed configure update. This might speed up the build, but comes at the risk of an incorrect build result. This is only recommended if you know what you're doing.<\/p>\r\n+<p>From time to time, you will also need to modify the command line to <code>configure<\/code> due to changes. Use <code>make print-configuration<\/code> to show the command line used for your current configuration.<\/p>\r\n+<h3 id=\"using-fine-grained-make-targets\">Using Fine-Grained Make Targets<\/h3>\r\n+<p>The default behavior for make is to create consistent and correct output, at the expense of build speed, if necessary.<\/p>\r\n+<p>If you are prepared to take some risk of an incorrect build, and know enough of the system to understand how things build and interact, you can speed up the build process considerably by instructing make to only build a portion of the product.<\/p>\r\n+<h4 id=\"building-individual-modules\">Building Individual Modules<\/h4>\r\n+<p>The safe way to use fine-grained make targets is to use the module specific make targets. All source code in the JDK is organized so it belongs to a module, e.g. <code>java.base<\/code> or <code>jdk.jdwp.agent<\/code>. You can build only a specific module, by giving it as make target: <code>make jdk.jdwp.agent<\/code>. If the specified module depends on other modules (e.g. <code>java.base<\/code>), those modules will be built first.<\/p>\r\n+<p>You can also specify a set of modules, just as you can always specify a set of make targets: <code>make jdk.crypto.cryptoki jdk.crypto.ec jdk.crypto.mscapi<\/code><\/p>\r\n+<h4 id=\"building-individual-module-phases\">Building Individual Module Phases<\/h4>\r\n+<p>The build process for each module is divided into separate phases. Not all modules need all phases. Which are needed depends on what kind of source code and other artifact the module consists of. The phases are:<\/p>\r\n+<ul>\r\n+<li><code>gensrc<\/code> (Generate source code to compile)<\/li>\r\n+<li><code>gendata<\/code> (Generate non-source code artifacts)<\/li>\r\n+<li><code>copy<\/code> (Copy resource artifacts)<\/li>\r\n+<li><code>java<\/code> (Compile Java code)<\/li>\r\n+<li><code>launchers<\/code> (Compile native executables)<\/li>\r\n+<li><code>libs<\/code> (Compile native libraries)<\/li>\r\n+<\/ul>\r\n+<p>You can build only a single phase for a module by using the notation <code>$MODULE-$PHASE<\/code>. For instance, to build the <code>gensrc<\/code> phase for <code>java.base<\/code>, use <code>make java.base-gensrc<\/code>.<\/p>\r\n+<p>Note that some phases may depend on others, e.g. <code>java<\/code> depends on <code>gensrc<\/code> (if present). Make will build all needed prerequisites before building the requested phase.<\/p>\r\n+<h4 id=\"skipping-the-dependency-check\">Skipping the Dependency Check<\/h4>\r\n+<p>When using an iterative development style with frequent quick rebuilds, the dependency check made by make can take up a significant portion of the time spent on the rebuild. In such cases, it can be useful to bypass the dependency check in make.<\/p>\r\n+<blockquote>\r\n+<p><strong>Note that if used incorrectly, this can lead to a broken build!<\/strong><\/p>\r\n+<\/blockquote>\r\n+<p>To achieve this, append <code>-only<\/code> to the build target. For instance, <code>make jdk.jdwp.agent-java-only<\/code> will <em>only<\/em> build the <code>java<\/code> phase of the <code>jdk.jdwp.agent<\/code> module. If the required dependencies are not present, the build can fail. On the other hand, the execution time measures in milliseconds.<\/p>\r\n+<p>A useful pattern is to build the first time normally (e.g. <code>make jdk.jdwp.agent<\/code>) and then on subsequent builds, use the <code>-only<\/code> make target.<\/p>\r\n+<h4 id=\"rebuilding-part-of-java.base-jdk_filter\">Rebuilding Part of java.base (JDK_FILTER)<\/h4>\r\n+<p>If you are modifying files in <code>java.base<\/code>, which is the by far largest module in the JDK, then you need to rebuild all those files whenever a single file has changed. (This inefficiency will hopefully be addressed in JDK 10.)<\/p>\r\n+<p>As a hack, you can use the make control variable <code>JDK_FILTER<\/code> to specify a pattern that will be used to limit the set of files being recompiled. For instance, <code>make java.base JDK_FILTER=javax\/crypto<\/code> (or, to combine methods, <code>make java.base-java-only JDK_FILTER=javax\/crypto<\/code>) will limit the compilation to files in the <code>javax.crypto<\/code> package.<\/p>\r\n+<h2 id=\"understanding-the-build-system\">Understanding the Build System<\/h2>\r\n+<p>This section will give you a more technical description on the details of the build system.<\/p>\r\n+<h3 id=\"configurations\">Configurations<\/h3>\r\n+<p>The build system expects to find one or more configuration. These are technically defined by the <code>spec.gmk<\/code> in a subdirectory to the <code>build<\/code> subdirectory. The <code>spec.gmk<\/code> file is generated by <code>configure<\/code>, and contains in principle the configuration (directly or by files included by <code>spec.gmk<\/code>).<\/p>\r\n+<p>You can, in fact, select a configuration to build by pointing to the <code>spec.gmk<\/code> file with the <code>SPEC<\/code> make control variable, e.g. <code>make SPEC=$BUILD\/spec.gmk<\/code>. While this is not the recommended way to call <code>make<\/code> as a user, it is what is used under the hood by the build system.<\/p>\r\n+<h3 id=\"build-output-structure\">Build Output Structure<\/h3>\r\n+<p>The build output for a configuration will end up in <code>build\/&lt;configuration name&gt;<\/code>, which we refer to as <code>$BUILD<\/code> in this document. The <code>$BUILD<\/code> directory contains the following important directories:<\/p>\r\n+<pre><code>buildtools\/\r\n+configure-support\/\r\n+hotspot\/\r\n+images\/\r\n+jdk\/\r\n+make-support\/\r\n+support\/\r\n+test-results\/\r\n+test-support\/<\/code><\/pre>\r\n+<p>This is what they are used for:<\/p>\r\n+<ul>\r\n+<li><p><code>images<\/code>: This is the directory were the output of the <code>*-image<\/code> make targets end up. For instance, <code>make jdk-image<\/code> ends up in <code>images\/jdk<\/code>.<\/p><\/li>\r\n+<li><p><code>jdk<\/code>: This is the &quot;exploded image&quot;. After <code>make jdk<\/code>, you will be able to launch the newly built JDK by running <code>$BUILD\/jdk\/bin\/java<\/code>.<\/p><\/li>\r\n+<li><p><code>test-results<\/code>: This directory contains the results from running tests.<\/p><\/li>\r\n+<li><p><code>support<\/code>: This is an area for intermediate files needed during the build, e.g. generated source code, object files and class files. Some noteworthy directories in <code>support<\/code> is <code>gensrc<\/code>, which contains the generated source code, and the <code>modules_*<\/code> directories, which contains the files in a per-module hierarchy that will later be collapsed into the <code>jdk<\/code> directory of the exploded image.<\/p><\/li>\r\n+<li><p><code>buildtools<\/code>: This is an area for tools compiled for the build platform that are used during the rest of the build.<\/p><\/li>\r\n+<li><p><code>hotspot<\/code>: This is an area for intermediate files needed when building hotspot.<\/p><\/li>\r\n+<li><p><code>configure-support<\/code>, <code>make-support<\/code> and <code>test-support<\/code>: These directories contain files that are needed by the build system for <code>configure<\/code>, <code>make<\/code> and for running tests.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"fixpath\">Fixpath<\/h3>\r\n+<p>Windows path typically look like <code>C:\\User\\foo<\/code>, while Unix paths look like <code>\/home\/foo<\/code>. Tools with roots from Unix often experience issues related to this mismatch when running on Windows.<\/p>\r\n+<p>In the JDK build, we always use Unix paths internally, and only just before calling a tool that does not understand Unix paths do we convert them to Windows paths.<\/p>\r\n+<p>This conversion is done by the <code>fixpath<\/code> tool, which is a small wrapper that modifies unix-style paths to Windows-style paths in command lines. Fixpath is compiled automatically by <code>configure<\/code>.<\/p>\r\n+<h3 id=\"native-debug-symbols\">Native Debug Symbols<\/h3>\r\n+<p>Native libraries and executables can have debug symbol (and other debug information) associated with them. How this works is very much platform dependent, but a common problem is that debug symbol information takes a lot of disk space, but is rarely needed by the end user.<\/p>\r\n+<p>The JDK supports different methods on how to handle debug symbols. The method used is selected by <code>--with-native-debug-symbols<\/code>, and available methods are <code>none<\/code>, <code>internal<\/code>, <code>external<\/code>, <code>zipped<\/code>.<\/p>\r\n+<ul>\r\n+<li><p><code>none<\/code> means that no debug symbols will be generated during the build.<\/p><\/li>\r\n+<li><p><code>internal<\/code> means that debug symbols will be generated during the build, and they will be stored in the generated binary.<\/p><\/li>\r\n+<li><p><code>external<\/code> means that debug symbols will be generated during the build, and after the compilation, they will be moved into a separate <code>.debuginfo<\/code> file. (This was previously known as FDS, Full Debug Symbols).<\/p><\/li>\r\n+<li><p><code>zipped<\/code> is like <code>external<\/code>, but the .debuginfo file will also be zipped into a <code>.diz<\/code> file.<\/p><\/li>\r\n+<\/ul>\r\n+<p>When building for distribution, <code>zipped<\/code> is a good solution. Binaries built with <code>internal<\/code> is suitable for use by developers, since they facilitate debugging, but should be stripped before distributed to end users.<\/p>\r\n+<h3 id=\"autoconf-details\">Autoconf Details<\/h3>\r\n+<p>The <code>configure<\/code> script is based on the autoconf framework, but in some details deviate from a normal autoconf <code>configure<\/code> script.<\/p>\r\n+<p>The <code>configure<\/code> script in the top level directory of the JDK is just a thin wrapper that calls <code>make\/autoconf\/configure<\/code>. This in turn will run <code>autoconf<\/code> to create the runnable (generated) configure script, as <code>.build\/generated-configure.sh<\/code>. Apart from being responsible for the generation of the runnable script, the <code>configure<\/code> script also provides functionality that is not easily expressed in the normal Autoconf framework. As part of this functionality, the generated script is called.<\/p>\r\n+<p>The build system will detect if the Autoconf source files have changed, and will trigger a regeneration of the generated script if needed. You can also manually request such an update by <code>bash configure autogen<\/code>.<\/p>\r\n+<p>In previous versions of the JDK, the generated script was checked in at <code>make\/autoconf\/generated-configure.sh<\/code>. This is no longer the case.<\/p>\r\n+<h3 id=\"developing-the-build-system-itself\">Developing the Build System Itself<\/h3>\r\n+<p>This section contains a few remarks about how to develop for the build system itself. It is not relevant if you are only making changes in the product source code.<\/p>\r\n+<p>While technically using <code>make<\/code>, the make source files of the JDK does not resemble most other Makefiles. Instead of listing specific targets and actions (perhaps using patterns), the basic modus operandi is to call a high-level function (or properly, macro) from the API in <code>make\/common<\/code>. For instance, to compile all classes in the <code>jdk.internal.foo<\/code> package in the <code>jdk.foo<\/code> module, a call like this would be made:<\/p>\r\n+<pre><code>$(eval $(call SetupJavaCompilation, BUILD_FOO_CLASSES, \\\r\n+    SETUP := GENERATE_OLDBYTECODE, \\\r\n+    SRC := $(TOPDIR)\/src\/jkd.foo\/share\/classes, \\\r\n+    INCLUDES := jdk\/internal\/foo, \\\r\n+    BIN := $(SUPPORT_OUTPUTDIR)\/foo_classes, \\\r\n+))<\/code><\/pre>\r\n+<p>By encapsulating and expressing the high-level knowledge of <em>what<\/em> should be done, rather than <em>how<\/em> it should be done (as is normal in Makefiles), we can build a much more powerful and flexible build system.<\/p>\r\n+<p>Correct dependency tracking is paramount. Sloppy dependency tracking will lead to improper parallelization, or worse, race conditions.<\/p>\r\n+<p>To test for\/debug race conditions, try running <code>make JOBS=1<\/code> and <code>make JOBS=100<\/code> and see if it makes any difference. (It shouldn't).<\/p>\r\n+<p>To compare the output of two different builds and see if, and how, they differ, run <code>$BUILD1\/compare.sh -o $BUILD2<\/code>, where <code>$BUILD1<\/code> and <code>$BUILD2<\/code> are the two builds you want to compare.<\/p>\r\n+<p>To automatically build two consecutive versions and compare them, use <code>COMPARE_BUILD<\/code>. The value of <code>COMPARE_BUILD<\/code> is a set of variable=value assignments, like this:<\/p>\r\n+<pre><code>make COMPARE_BUILD=CONF=--enable-new-hotspot-feature:MAKE=hotspot<\/code><\/pre>\r\n+<p>See <code>make\/InitSupport.gmk<\/code> for details on how to use <code>COMPARE_BUILD<\/code>.<\/p>\r\n+<p>To analyze build performance, run with <code>LOG=trace<\/code> and check <code>$BUILD\/build-trace-time.log<\/code>. Use <code>JOBS=1<\/code> to avoid parallelism.<\/p>\r\n+<p>Please check that you adhere to the <a href=\"http:\/\/openjdk.java.net\/groups\/build\/doc\/code-conventions.html\">Code Conventions for the Build System<\/a> before submitting patches.<\/p>\r\n+<h2 id=\"contributing-to-the-jdk\">Contributing to the JDK<\/h2>\r\n+<p>So, now you've built your JDK, and made your first patch, and want to contribute it back to the OpenJDK Community.<\/p>\r\n+<p>First of all: Thank you! We gladly welcome your contribution. However, please bear in mind that the JDK is a massive project, and we must ask you to follow our rules and guidelines to be able to accept your contribution.<\/p>\r\n+<p>The official place to start is the <a href=\"http:\/\/openjdk.java.net\/contribute\/\">'How to contribute' page<\/a>. There is also an official (but somewhat outdated and skimpy on details) <a href=\"http:\/\/openjdk.java.net\/guide\/\">Developer's Guide<\/a>.<\/p>\r\n+<p>If this seems overwhelming to you, the Adoption Group is there to help you! A good place to start is their <a href=\"https:\/\/wiki.openjdk.java.net\/display\/Adoption\/New+Contributor\">'New Contributor' page<\/a>, or start reading the comprehensive <a href=\"https:\/\/adoptopenjdk.gitbooks.io\/adoptopenjdk-getting-started-kit\/en\/\">Getting Started Kit<\/a>. The Adoption Group will also happily answer any questions you have about contributing. Contact them by <a href=\"http:\/\/mail.openjdk.java.net\/mailman\/listinfo\/adoption-discuss\">mail<\/a> or <a href=\"http:\/\/openjdk.java.net\/irc\/\">IRC<\/a>.<\/p>\r\n+<\/body>\r\n+<\/html>\r\n","filename":"doc\/building.html","additions":1039,"deletions":1036,"binary":false,"changes":2075,"status":"modified"},{"patch":"@@ -247,2 +247,2 @@\n-`--build=x86_64-unknown-linux-gnu --host=x86_64-unknown-linux-gnu` to\n-`configure`.\n+`--build=x86_64-unknown-linux-gnu --openjdk-target=x86_64-unknown-linux-gnu`\n+to `configure`.\n@@ -989,1 +989,1 @@\n-This will automatically set the `--build`, `--host` and `--target` options for\n+This will automatically set the `--host` and `--target` options for\n@@ -994,0 +994,5 @@\n+If `--build` has not been explicitly passed to configure, `--openjdk-target`\n+will autodetect the build platform and internally set the flag automatically,\n+otherwise the platform that was explicitly passed to `--build` will be used\n+instead.\n+\n","filename":"doc\/building.md","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1,458 +1,458 @@\n-<!DOCTYPE html>\n-<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\n-<head>\n-  <meta charset=\"utf-8\" \/>\n-  <meta name=\"generator\" content=\"pandoc\" \/>\n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\n-  <title>HotSpot Coding Style<\/title>\n-  <style type=\"text\/css\">\n-      code{white-space: pre-wrap;}\n-      span.smallcaps{font-variant: small-caps;}\n-      span.underline{text-decoration: underline;}\n-      div.column{display: inline-block; vertical-align: top; width: 50%;}\n-  <\/style>\n-  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\n-  <!--[if lt IE 9]>\n-    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\n-  <![endif]-->\n-<\/head>\n-<body>\n-<header id=\"title-block-header\">\n-<h1 class=\"title\">HotSpot Coding Style<\/h1>\n-<\/header>\n-<nav id=\"TOC\">\n-<ul>\n-<li><a href=\"#introduction\">Introduction<\/a><ul>\n-<li><a href=\"#why-care-about-style\">Why Care About Style?<\/a><\/li>\n-<li><a href=\"#counterexamples-and-updates\">Counterexamples and Updates<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#structure-and-formatting\">Structure and Formatting<\/a><ul>\n-<li><a href=\"#factoring-and-class-design\">Factoring and Class Design<\/a><\/li>\n-<li><a href=\"#source-files\">Source Files<\/a><\/li>\n-<li><a href=\"#jtreg-tests\">JTReg Tests<\/a><\/li>\n-<li><a href=\"#naming\">Naming<\/a><\/li>\n-<li><a href=\"#commenting\">Commenting<\/a><\/li>\n-<li><a href=\"#macros\">Macros<\/a><\/li>\n-<li><a href=\"#whitespace\">Whitespace<\/a><\/li>\n-<li><a href=\"#miscellaneous\">Miscellaneous<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#use-of-c-features\">Use of C++ Features<\/a><ul>\n-<li><a href=\"#error-handling\">Error Handling<\/a><\/li>\n-<li><a href=\"#rtti-runtime-type-information\">RTTI (Runtime Type Information)<\/a><\/li>\n-<li><a href=\"#memory-allocation\">Memory Allocation<\/a><\/li>\n-<li><a href=\"#class-inheritance\">Class Inheritance<\/a><\/li>\n-<li><a href=\"#namespaces\">Namespaces<\/a><\/li>\n-<li><a href=\"#c-standard-library\">C++ Standard Library<\/a><\/li>\n-<li><a href=\"#type-deduction\">Type Deduction<\/a><\/li>\n-<li><a href=\"#expression-sfinae\">Expression SFINAE<\/a><\/li>\n-<li><a href=\"#enum\">enum<\/a><\/li>\n-<li><a href=\"#thread_local\">thread_local<\/a><\/li>\n-<li><a href=\"#nullptr\">nullptr<\/a><\/li>\n-<li><a href=\"#atomic\">&lt;atomic&gt;<\/a><\/li>\n-<li><a href=\"#uniform-initialization\">Uniform Initialization<\/a><\/li>\n-<li><a href=\"#local-function-objects\">Local Function Objects<\/a><\/li>\n-<li><a href=\"#additional-permitted-features\">Additional Permitted Features<\/a><\/li>\n-<li><a href=\"#excluded-features\">Excluded Features<\/a><\/li>\n-<li><a href=\"#undecided-features\">Undecided Features<\/a><\/li>\n-<\/ul><\/li>\n-<\/ul>\n-<\/nav>\n-<h2 id=\"introduction\">Introduction<\/h2>\n-<p>This is a collection of rules, guidelines, and suggestions for writing HotSpot code. Following these will help new code fit in with existing HotSpot code, making it easier to read and maintain. Failure to follow these guidelines may lead to discussion during code reviews, if not outright rejection of a change.<\/p>\n-<h3 id=\"why-care-about-style\">Why Care About Style?<\/h3>\n-<p>Some programmers seem to have lexers and even C preprocessors installed directly behind their eyeballs. The rest of us require code that is not only functionally correct but also easy to read. More than that, since there is no one style for easy-to-read code, and since a mashup of many styles is just as confusing as no style at all, it is important for coders to be conscious of the many implicit stylistic choices that historically have gone into the HotSpot code base.<\/p>\n-<p>Some of these guidelines are driven by the cross-platform requirements for HotSpot. Shared code must work on a variety of platforms, and may encounter deficiencies in some. Using platform conditionalization in shared code is usually avoided, while shared code is strongly preferred to multiple platform-dependent implementations, so some language features may be recommended against.<\/p>\n-<p>Some of the guidelines here are relatively arbitrary choices among equally plausible alternatives. The purpose of stating and enforcing these rules is largely to provide a consistent look to the code. That consistency makes the code more readable by avoiding non-functional distractions from the interesting functionality.<\/p>\n-<p>When changing pre-existing code, it is reasonable to adjust it to match these conventions. Exception: If the pre-existing code clearly conforms locally to its own peculiar conventions, it is not worth reformatting the whole thing. Also consider separating changes that make extensive stylistic updates from those which make functional changes.<\/p>\n-<h3 id=\"counterexamples-and-updates\">Counterexamples and Updates<\/h3>\n-<p>Many of the guidelines mentioned here have (sometimes widespread) counterexamples in the HotSpot code base. Finding a counterexample is not sufficient justification for new code to follow the counterexample as a precedent, since readers of your code will rightfully expect your code to follow the greater bulk of precedents documented here.<\/p>\n-<p>Occasionally a guideline mentioned here may be just out of synch with the actual HotSpot code base. If you find that a guideline is consistently contradicted by a large number of counterexamples, please bring it up for discussion and possible change. The architectural rule, of course, is &quot;When in Rome do as the Romans&quot;. Sometimes in the suburbs of Rome the rules are a little different; these differences can be pointed out here.<\/p>\n-<p>Proposed changes should be discussed on the <a href=\"mailto:hotspot-dev@openjdk.java.net\">HotSpot Developers<\/a> mailing list. Changes are likely to be cautious and incremental, since HotSpot coders have been using these guidelines for years.<\/p>\n-<p>Substantive changes are approved by <a href=\"https:\/\/en.wikipedia.org\/wiki\/Rough_consensus\">rough consensus<\/a> of the <a href=\"https:\/\/openjdk.java.net\/census#hotspot\">HotSpot Group<\/a> Members. The Group Lead determines whether consensus has been reached.<\/p>\n-<p>Editorial changes (changes that only affect the description of HotSpot style, not its substance) do not require the full consensus gathering process. The normal HotSpot pull request process may be used for editorial changes, with the additional requirement that the requisite reviewers are also HotSpot Group Members.<\/p>\n-<h2 id=\"structure-and-formatting\">Structure and Formatting<\/h2>\n-<h3 id=\"factoring-and-class-design\">Factoring and Class Design<\/h3>\n-<ul>\n-<li><p>Group related code together, so readers can concentrate on one section of one file.<\/p><\/li>\n-<li><p>Classes are the primary code structuring mechanism. Place related functionality in a class, or a set of related classes. Use of either namespaces or public non-member functions is rare in HotSpot code. Static non-member functions are not uncommon.<\/p><\/li>\n-<li><p>If a class <code>FooBar<\/code> is going to be used in more than one place, put it a file named fooBar.hpp and fooBar.cpp. If the class is a sidekick to a more important class <code>BazBat<\/code>, it can go in bazBat.hpp.<\/p><\/li>\n-<li><p>Put a member function <code>FooBar::bang<\/code> into the same file that defined <code>FooBar<\/code>, or its associated <em>.inline.hpp or <\/em>.cpp file.<\/p><\/li>\n-<li><p>Use public accessor functions for member variables accessed outside the class.<\/p><\/li>\n-<li><p>Assign names to constant literals and use the names instead.<\/p><\/li>\n-<li><p>Keep functions small, a screenful at most. Split out chunks of logic into file-local classes or static functions if needed.<\/p><\/li>\n-<li><p>Factor away nonessential complexity into local inline helper functions and helper classes.<\/p><\/li>\n-<li><p>Think clearly about internal invariants that apply to each class, and document them in the form of asserts within member functions.<\/p><\/li>\n-<li><p>Make simple, self-evident contracts for member functions. If you cannot communicate a simple contract, redesign the class.<\/p><\/li>\n-<li><p>Implement classes as if expecting rough usage by clients. Check for incorrect usage of a class using <code>assert(...)<\/code>, <code>guarantee(...)<\/code>, <code>ShouldNotReachHere()<\/code> and comments wherever needed. Performance is almost never a reason to omit asserts.<\/p><\/li>\n-<li><p>When possible, design as if for reusability. This forces a clear design of the class's externals, and clean hiding of its internals.<\/p><\/li>\n-<li><p>Initialize all variables and data structures to a known state. If a class has a constructor, initialize it there.<\/p><\/li>\n-<li><p>Do no optimization before its time. Prove the need to optimize.<\/p><\/li>\n-<li><p>When you must defactor to optimize, preserve as much structure as possible. If you must hand-inline some name, label the local copy with the original name.<\/p><\/li>\n-<li><p>If you need to use a hidden detail (e.g., a structure offset), name it (as a constant or function) in the class that owns it.<\/p><\/li>\n-<li><p>Don't use the Copy and Paste keys to replicate more than a couple lines of code. Name what you must repeat.<\/p><\/li>\n-<li><p>If a class needs a member function to change a user-visible attribute, the change should be done with a &quot;setter&quot; accessor matched to the simple &quot;getter&quot;.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"source-files\">Source Files<\/h3>\n-<ul>\n-<li><p>All source files must have a globally unique basename. The build system depends on this uniqueness.<\/p><\/li>\n-<li><p>Do not put non-trivial function implementations in .hpp files. If the implementation depends on other .hpp files, put it in a .cpp or a .inline.hpp file.<\/p><\/li>\n-<li><p>.inline.hpp files should only be included in .cpp or .inline.hpp files.<\/p><\/li>\n-<li><p>All .inline.hpp files should include their corresponding .hpp file as the first include line. Declarations needed by other files should be put in the .hpp file, and not in the .inline.hpp file. This rule exists to resolve problems with circular dependencies between .inline.hpp files.<\/p><\/li>\n-<li><p>All .cpp files include precompiled.hpp as the first include line.<\/p><\/li>\n-<li><p>precompiled.hpp is just a build time optimization, so don't rely on it to resolve include problems.<\/p><\/li>\n-<li><p>Keep the include lines alphabetically sorted.<\/p><\/li>\n-<li><p>Put conditional inclusions (<code>#if ...<\/code>) at the end of the include list.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"jtreg-tests\">JTReg Tests<\/h3>\n-<ul>\n-<li><p>JTReg tests should have meaningful names.<\/p><\/li>\n-<li><p>JTReg tests associated with specific bugs should be tagged with the <code>@bug<\/code> keyword in the test description.<\/p><\/li>\n-<li><p>JTReg tests should be organized by component or feature under <code>test\/<\/code>, in a directory hierarchy that generally follows that of the <code>src\/<\/code> directory. There may be additional subdirectories to further categorize tests by feature. This structure makes it easy to run a collection of tests associated with a specific feature by specifying the associated directory as the source of the tests to run.<\/p>\n-<ul>\n-<li>Some (older) tests use the associated bug number in the directory name, the test name, or both. That naming style should no longer be used, with existing tests using that style being candidates for migration.<\/li>\n-<\/ul><\/li>\n-<\/ul>\n-<h3 id=\"naming\">Naming<\/h3>\n-<ul>\n-<li><p>The length of a name may be correlated to the size of its scope. In particular, short names (even single letter names) may be fine in a small scope, but are usually inappropriate for larger scopes.<\/p><\/li>\n-<li><p>Prefer whole words rather than abbreviations, unless the abbreviation is more widely used than the long form in the code's domain.<\/p><\/li>\n-<li><p>Choose names consistently. Do not introduce spurious variations. Abbreviate corresponding terms to a consistent length.<\/p><\/li>\n-<li><p>Global names must be unique, to avoid <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/definition\" title=\"One Definition Rule\">One Definition Rule<\/a> (ODR) violations. A common prefixing scheme for related global names is often used. (This is instead of using namespaces, which are mostly avoided in HotSpot.)<\/p><\/li>\n-<li><p>Don't give two names to the semantically same thing. But use different names for semantically different things, even if they are representationally the same. (So use meaningful <code>typedef<\/code> or template alias names where appropriate.)<\/p><\/li>\n-<li><p>When choosing names, avoid categorical nouns like &quot;variable&quot;, &quot;field&quot;, &quot;parameter&quot;, &quot;value&quot;, and verbs like &quot;compute&quot;, &quot;get&quot;. (<code>storeValue(int param)<\/code> is bad.)<\/p><\/li>\n-<li><p>Type names and global names should use mixed-case with the first letter of each word capitalized (<code>FooBar<\/code>).<\/p><\/li>\n-<li><p>Embedded abbreviations in otherwise mixed-case names are usually capitalized entirely rather than being treated as a single word with only the initial letter capitalized, e.g. &quot;HTML&quot; rather than &quot;Html&quot;.<\/p><\/li>\n-<li><p>Function and local variable names use lowercase with words separated by a single underscore (<code>foo_bar<\/code>).<\/p><\/li>\n-<li><p>Class data member names have a leading underscore, and use lowercase with words separated by a single underscore (<code>_foo_bar<\/code>).<\/p><\/li>\n-<li><p>Constant names may be upper-case or mixed-case, according to historical necessity. (Note: There are many examples of constants with lowercase names.)<\/p><\/li>\n-<li><p>Constant names should follow an existing pattern, and must have a distinct appearance from other names in related APIs.<\/p><\/li>\n-<li><p>Class and type names should be noun phrases. Consider an &quot;er&quot; suffix for a class that represents an action.<\/p><\/li>\n-<li><p>Function names should be verb phrases that reflect changes of state known to a class's user, or else noun phrases if they cause no change of state visible to the class's user.<\/p><\/li>\n-<li><p>Getter accessor names are noun phrases, with no &quot;<code>get_<\/code>&quot; noise word. Boolean getters can also begin with &quot;<code>is_<\/code>&quot; or &quot;<code>has_<\/code>&quot;. Member function for reading data members usually have the same name as the data member, exclusive of the leading underscore.<\/p><\/li>\n-<li><p>Setter accessor names prepend &quot;<code>set_<\/code>&quot; to the getter name.<\/p><\/li>\n-<li><p>Other member function names are verb phrases, as if commands to the receiver.<\/p><\/li>\n-<li><p>Avoid leading underscores (as &quot;<code>_oop<\/code>&quot;) except in cases required above. (Names with leading underscores can cause portability problems.)<\/p><\/li>\n-<\/ul>\n-<h3 id=\"commenting\">Commenting<\/h3>\n-<ul>\n-<li><p>Clearly comment subtle fixes.<\/p><\/li>\n-<li><p>Clearly comment tricky classes and functions.<\/p><\/li>\n-<li><p>If you have to choose between commenting code and writing wiki content, comment the code. Link from the wiki to the source file if it makes sense.<\/p><\/li>\n-<li><p>As a general rule don't add bug numbers to comments (they would soon overwhelm the code). But if the bug report contains significant information that can't reasonably be added as a comment, then refer to the bug report.<\/p><\/li>\n-<li><p>Personal names are discouraged in the source code, which is a team product.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"macros\">Macros<\/h3>\n-<ul>\n-<li><p>You can almost always use an inline function or class instead of a macro. Use a macro only when you really need it.<\/p><\/li>\n-<li><p>Templates may be preferable to multi-line macros. (There may be subtle performance effects with templates on some platforms; revert to macros if absolutely necessary.)<\/p><\/li>\n-<li><p><code>#ifdef<\/code>s should not be used to introduce platform-specific code into shared code (except for <code>_LP64<\/code>). They must be used to manage header files, in the pattern found at the top of every source file. They should be used mainly for major build features, including <code>PRODUCT<\/code>, <code>ASSERT<\/code>, <code>_LP64<\/code>, <code>INCLUDE_SERIALGC<\/code>, <code>COMPILER1<\/code>, etc.<\/p><\/li>\n-<li><p>For build features such as <code>PRODUCT<\/code>, use <code>#ifdef PRODUCT<\/code> for multiple-line inclusions or exclusions.<\/p><\/li>\n-<li><p>For short inclusions or exclusions based on build features, use macros like <code>PRODUCT_ONLY<\/code> and <code>NOT_PRODUCT<\/code>. But avoid using them with multiple-line arguments, since debuggers do not handle that well.<\/p><\/li>\n-<li><p>Use <code>CATCH<\/code>, <code>THROW<\/code>, etc. for HotSpot-specific exception processing.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"whitespace\">Whitespace<\/h3>\n-<ul>\n-<li><p>In general, don't change whitespace unless it improves readability or consistency. Gratuitous whitespace changes will make integrations and backports more difficult.<\/p><\/li>\n-<li><p>Use One-True-Brace-Style. The opening brace for a function or class is normally at the end of the line; it is sometimes moved to the beginning of the next line for emphasis. Substatements are enclosed in braces, even if there is only a single statement. Extremely simple one-line statements may drop braces around a substatement.<\/p><\/li>\n-<li><p>Indentation levels are two columns.<\/p><\/li>\n-<li><p>There is no hard line length limit. That said, bear in mind that excessively long lines can cause difficulties. Some people like to have multiple side-by-side windows in their editors, and long lines may force them to choose among unpleasant options. They can use wide windows, reducing the number that can fit across the screen, and wasting a lot of screen real estate because most lines are not that long. Alternatively, they can have more windows across the screen, with long lines wrapping (or worse, requiring scrolling to see in their entirety), which is harder to read. Similar issues exist for side-by-side code reviews.<\/p><\/li>\n-<li><p>Tabs are not allowed in code. Set your editor accordingly.<br> (Emacs: <code>(setq-default indent-tabs-mode nil)<\/code>.)<\/p><\/li>\n-<li><p>Use good taste to break lines and align corresponding tokens on adjacent lines.<\/p><\/li>\n-<li><p>Use spaces around operators, especially comparisons and assignments. (Relaxable for boolean expressions and high-precedence operators in classic math-style formulas.)<\/p><\/li>\n-<li><p>Put spaces on both sides of control flow keywords <code>if<\/code>, <code>else<\/code>, <code>for<\/code>, <code>switch<\/code>, etc. Don't add spaces around the associated <em>control<\/em> expressions. Examples:<\/p>\n-<pre><code>while (test_foo(args...)) {   \/\/ Yes\n-while(test_foo(args...)) {    \/\/ No, missing space after while\n-while ( test_foo(args...) ) { \/\/ No, excess spaces around control<\/code><\/pre><\/li>\n-<li><p>Use extra parentheses in expressions whenever operator precedence seems doubtful. Always use parentheses in shift\/mask expressions (<code>&lt;&lt;<\/code>, <code>&amp;<\/code>, <code>|<\/code>). Don't add whitespace immediately inside parentheses.<\/p><\/li>\n-<li><p>Use more spaces and blank lines between larger constructs, such as classes or function definitions.<\/p><\/li>\n-<li><p>If the surrounding code has any sort of vertical organization, adjust new lines horizontally to be consistent with that organization. (E.g., trailing backslashes on long macro definitions often align.)<\/p><\/li>\n-<\/ul>\n-<h3 id=\"miscellaneous\">Miscellaneous<\/h3>\n-<ul>\n-<li><p>Use the <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/raii\" title=\"Resource Acquisition Is Initialization\">Resource Acquisition Is Initialization<\/a> (RAII) design pattern to manage bracketed critical sections. See class <code>ResourceMark<\/code> for an example.<\/p><\/li>\n-<li>Avoid implicit conversions to <code>bool<\/code>.\n-<ul>\n-<li>Use <code>bool<\/code> for boolean values.<\/li>\n-<li>Do not use ints or pointers as (implicit) booleans with <code>&amp;&amp;<\/code>, <code>||<\/code>, <code>if<\/code>, <code>while<\/code>. Instead, compare explicitly, i.e. <code>if (x != 0)<\/code> or <code>if (ptr != nullptr)<\/code>, etc.<\/li>\n-<li>Do not use declarations in <em>condition<\/em> forms, i.e. don't use <code>if (T v = value) { ... }<\/code>.<\/li>\n-<\/ul><\/li>\n-<li><p>Use functions from globalDefinitions.hpp and related files when performing bitwise operations on integers. Do not code directly as C operators, unless they are extremely simple. (Examples: <code>align_up<\/code>, <code>is_power_of_2<\/code>, <code>exact_log2<\/code>.)<\/p><\/li>\n-<li><p>Use arrays with abstractions supporting range checks.<\/p><\/li>\n-<li><p>Always enumerate all cases in a switch statement or provide a default case. It is ok to have an empty default with comment.<\/p><\/li>\n-<\/ul>\n-<h2 id=\"use-of-c-features\">Use of C++ Features<\/h2>\n-<p>HotSpot was originally written in a subset of the C++98\/03 language. More recently, support for C++14 is provided, though again, HotSpot only uses a subset. (Backports to JDK versions lacking support for more recent Standards must of course stick with the original C++98\/03 subset.)<\/p>\n-<p>This section describes that subset. Features from the C++98\/03 language may be used unless explicitly excluded here. Features from C++11 and C++14 may be explicitly permitted or explicitly excluded, and discussed accordingly here. There is a third category, undecided features, about which HotSpot developers have not yet reached a consensus, or perhaps have not discussed at all. Use of these features is also excluded.<\/p>\n-<p>(The use of some features may not be immediately obvious and may slip in anyway, since the compiler will accept them. The code review process is the main defense against this.)<\/p>\n-<p>Some features are discussed in their own subsection, typically to provide more extensive discussion or rationale for limitations. Features that don't have their own subsection are listed in omnibus feature sections for permitted, excluded, and undecided features.<\/p>\n-<p>Lists of new features for C++11 and C++14, along with links to their descriptions, can be found in the online documentation for some of the compilers and libraries. The C++14 Standard is the definitive description.<\/p>\n-<ul>\n-<li><a href=\"https:\/\/gcc.gnu.org\/projects\/cxx-status.html\">C++ Standards Support in GCC<\/a><\/li>\n-<li><a href=\"https:\/\/clang.llvm.org\/cxx_status.html\">C++ Support in Clang<\/a><\/li>\n-<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/cpp\/visual-cpp-language-conformance\">Visual C++ Language Conformance<\/a><\/li>\n-<li><a href=\"https:\/\/gcc.gnu.org\/onlinedocs\/libstdc++\/manual\/status.html\">libstdc++ Status<\/a><\/li>\n-<li><a href=\"https:\/\/libcxx.llvm.org\/cxx1y_status.html\">libc++ Status<\/a><\/li>\n-<\/ul>\n-<p>As a rule of thumb, permitting features which simplify writing code and, especially, reading code, is encouraged.<\/p>\n-<p>Similar discussions for some other projects:<\/p>\n-<ul>\n-<li><p><a href=\"https:\/\/google.github.io\/styleguide\/cppguide.html\">Google C++ Style Guide<\/a> — Currently (2020) targeting C++17.<\/p><\/li>\n-<li><p><a href=\"https:\/\/chromium.googlesource.com\/chromium\/src\/+\/main\/styleguide\/c++\/c++-features.md\">C++11 and C++14 use in Chromium<\/a> — Categorizes features as allowed, banned, or to be discussed.<\/p><\/li>\n-<li><p><a href=\"https:\/\/llvm.org\/docs\/CodingStandards.html\">llvm Coding Standards<\/a> — Currently (2020) targeting C++14.<\/p><\/li>\n-<li><p><a href=\"https:\/\/firefox-source-docs.mozilla.org\/code-quality\/coding-style\/using_cxx_in_firefox_code.html\">Using C++ in Mozilla code<\/a> — C++17 support is required for recent versions (2020).<\/p><\/li>\n-<\/ul>\n-<h3 id=\"error-handling\">Error Handling<\/h3>\n-<p>Do not use exceptions. Exceptions are disabled by the build configuration for some platforms.<\/p>\n-<p>Rationale: There is significant concern over the performance cost of exceptions and their usage model and implications for maintainable code. That's not just a matter of history that has been fixed; there remain questions and problems even today (2019). See, for example, <a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2018\/p0709r0.pdf\">Zero cost deterministic exceptions<\/a>. Because of this, HotSpot has always used a build configuration that disables exceptions where that is available. As a result, HotSpot code uses error handling mechanisms such as two-phase construction, factory functions, returning error codes, and immediate termination. Even if the cost of exceptions were not a concern, the existing body of code was not written with exception safety in mind. Making HotSpot exception safe would be a very large undertaking.<\/p>\n-<p>In addition to the usual alternatives to exceptions, HotSpot provides its own exception mechanism. This is based on a set of macros defined in utilities\/exceptions.hpp.<\/p>\n-<h3 id=\"rtti-runtime-type-information\">RTTI (Runtime Type Information)<\/h3>\n-<p>Do not use <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">Runtime Type Information<\/a> (RTTI). <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">RTTI<\/a> is disabled by the build configuration for some platforms. Among other things, this means <code>dynamic_cast<\/code> cannot be used.<\/p>\n-<p>Rationale: Other than to implement exceptions (which HotSpot doesn't use), most potential uses of <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">RTTI<\/a> are better done via virtual functions. Some of the remainder can be replaced by bespoke mechanisms. The cost of the additional runtime data structures needed to support <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">RTTI<\/a> are deemed not worthwhile, given the alternatives.<\/p>\n-<h3 id=\"memory-allocation\">Memory Allocation<\/h3>\n-<p>Do not use the standard global allocation and deallocation functions (operator new and related functions). Use of these functions by HotSpot code is disabled for some platforms.<\/p>\n-<p>Rationale: HotSpot often uses &quot;resource&quot; or &quot;arena&quot; allocation. Even where heap allocation is used, the standard global functions are avoided in favor of wrappers around malloc and free that support the VM's Native Memory Tracking (NMT) feature.<\/p>\n-<p>Native memory allocation failures are often treated as non-recoverable. The place where &quot;out of memory&quot; is (first) detected may be an innocent bystander, unrelated to the actual culprit.<\/p>\n-<h3 id=\"class-inheritance\">Class Inheritance<\/h3>\n-<p>Use public single inheritance.<\/p>\n-<p>Prefer composition rather than non-public inheritance.<\/p>\n-<p>Restrict inheritance to the &quot;is-a&quot; case; use composition rather than non-is-a related inheritance.<\/p>\n-<p>Avoid multiple inheritance. Never use virtual inheritance.<\/p>\n-<h3 id=\"namespaces\">Namespaces<\/h3>\n-<p>Avoid using namespaces. HotSpot code normally uses &quot;all static&quot; classes rather than namespaces for grouping. An &quot;all static&quot; class is not instantiable, has only static members, and is normally derived (possibly indirectly) from the helper class <code>AllStatic<\/code>.<\/p>\n-<p>Benefits of using such classes include:<\/p>\n-<ul>\n-<li><p>Provides access control for members, which is unavailable with namespaces.<\/p><\/li>\n-<li><p>Avoids <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/adl\" title=\"Argument Dependent Lookup\">Argument Dependent Lookup<\/a> (ADL).<\/p><\/li>\n-<li><p>Closed for additional members. Namespaces allow names to be added in multiple contexts, making it harder to see the complete API.<\/p><\/li>\n-<\/ul>\n-<p>Namespaces should be used only in cases where one of those &quot;benefits&quot; is actually a hindrance.<\/p>\n-<p>In particular, don't use anonymous namespaces. They seem like they should be useful, and indeed have some real benefits for naming and generated code size on some platforms. Unfortunately, debuggers don't seem to like them at all.<\/p>\n-<p><a href=\"https:\/\/groups.google.com\/forum\/#!topic\/mozilla.dev.platform\/KsaG3lEEaRM\" class=\"uri\">https:\/\/groups.google.com\/forum\/#!topic\/mozilla.dev.platform\/KsaG3lEEaRM<\/a><br> Suggests Visual Studio debugger might not be able to refer to anonymous namespace symbols, so can't set breakpoints in them. Though the discussion seems to go back and forth on that.<\/p>\n-<p><a href=\"https:\/\/firefox-source-docs.mozilla.org\/code-quality\/coding-style\/coding_style_cpp.html\" class=\"uri\">https:\/\/firefox-source-docs.mozilla.org\/code-quality\/coding-style\/coding_style_cpp.html<\/a><br> Search for &quot;Anonymous namespaces&quot; Suggests preferring &quot;static&quot; to anonymous namespaces where applicable, because of poor debugger support for anonymous namespaces.<\/p>\n-<p><a href=\"https:\/\/sourceware.org\/bugzilla\/show_bug.cgi?id=16874\" class=\"uri\">https:\/\/sourceware.org\/bugzilla\/show_bug.cgi?id=16874<\/a><br> Bug for similar gdb problems.<\/p>\n-<h3 id=\"c-standard-library\">C++ Standard Library<\/h3>\n-<p>Avoid using the C++ Standard Library.<\/p>\n-<p>Historically, HotSpot has mostly avoided use of the Standard Library.<\/p>\n-<p>(It used to be impossible to use most of it in shared code, because the build configuration for Solaris with Solaris Studio made all but a couple of pieces inaccessible. Support for header-only parts was added in mid-2017. Support for Solaris was removed in 2020.)<\/p>\n-<p>Some reasons for this include<\/p>\n-<ul>\n-<li><p>Exceptions. Perhaps the largest core issue with adopting the use of Standard Library facilities is exceptions. HotSpot does not use exceptions and, for platforms which allow doing so, builds with them turned off. Many Standard Library facilities implicitly or explicitly use exceptions.<\/p><\/li>\n-<li><p><code>assert<\/code>. An issue that is quickly encountered is the <code>assert<\/code> macro name collision (<a href=\"https:\/\/bugs.openjdk.java.net\/browse\/JDK-8007770\">JDK-8007770<\/a>). Some mechanism for addressing this would be needed before much of the Standard Library could be used. (Not all Standard Library implementations use assert in header files, but some do.)<\/p><\/li>\n-<li><p>Memory allocation. HotSpot requires explicit control over where allocations occur. The C++98\/03 <code>std::allocator<\/code> class is too limited to support our usage. (Changes in more recent Standards may remove this limitation.)<\/p><\/li>\n-<li><p>Implementation vagaries. Bugs, or simply different implementation choices, can lead to different behaviors among the various Standard Libraries we need to deal with.<\/p><\/li>\n-<li><p>Inconsistent naming conventions. HotSpot and the C++ Standard use different naming conventions. The coexistence of those different conventions might appear jarring and reduce readability.<\/p><\/li>\n-<\/ul>\n-<p>There are a few exceptions to this rule.<\/p>\n-<ul>\n-<li><code>#include &lt;new&gt;<\/code> to use placement <code>new<\/code>, <code>std::nothrow<\/code>, and <code>std::nothrow_t<\/code>.<\/li>\n-<li><code>#include &lt;limits&gt;<\/code> to use <code>std::numeric_limits<\/code>.<\/li>\n-<li><code>#include &lt;type_traits&gt;<\/code>.<\/li>\n-<li><code>#include &lt;cstddef&gt;<\/code> to use <code>std::nullptr_t<\/code>.<\/li>\n-<\/ul>\n-<p>TODO: Rather than directly #including (permitted) Standard Library headers, use a convention of #including wrapper headers (in some location like hotspot\/shared\/stdcpp). This provides a single place for dealing with issues we might have for any given header, esp. platform-specific issues.<\/p>\n-<h3 id=\"type-deduction\">Type Deduction<\/h3>\n-<p>Use type deduction only if it makes the code clearer or safer. Do not use it merely to avoid the inconvenience of writing an explicit type, unless that type is itself difficult to write. An example of the latter is a function template return type that depends on template parameters in a non-trivial way.<\/p>\n-<p>There are several contexts where types are deduced.<\/p>\n-<ul>\n-<li><p>Function argument deduction. This is always permitted, and indeed encouraged. It is nearly always better to allow the type of a function template argument to be deduced rather than explicitly specified.<\/p><\/li>\n-<li><p><code>auto<\/code> variable declarations (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2006\/n1984.pdf\">n1984<\/a>)<br> For local variables, this can be used to make the code clearer by eliminating type information that is obvious or irrelevant. Excessive use can make code much harder to understand.<\/p><\/li>\n-<li><p>Function return type deduction (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3638.html\">n3638<\/a>)<br> Only use if the function body has a very small number of <code>return<\/code> statements, and generally relatively little other code.<\/p><\/li>\n-<li><p>Also see <a href=\"#lambdaexpressions\">lambda expressions<\/a>.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"expression-sfinae\">Expression SFINAE<\/h3>\n-<p><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/sfinae\" title=\"Substitution Failure Is Not An Error\">Substitution Failure Is Not An Error<\/a> (SFINAE) is a template metaprogramming technique that makes use of template parameter substitution failures to make compile-time decisions.<\/p>\n-<p>C++11 relaxed the rules for what constitutes a hard-error when attempting to substitute template parameters with template arguments, making most deduction errors be substitution errors; see (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2634.html\">n2634<\/a>). This makes <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/sfinae\" title=\"Substitution Failure Is Not An Error\">SFINAE<\/a> more powerful and easier to use. However, the implementation complexity for this change is significant, and this seems to be a place where obscure corner-case bugs in various compilers can be found. So while this feature can (and indeed should) be used (and would be difficult to avoid), caution should be used when pushing to extremes.<\/p>\n-<p>Here are a few closely related example bugs:<br> <a href=\"https:\/\/gcc.gnu.org\/bugzilla\/show_bug.cgi?id=95468\" class=\"uri\">https:\/\/gcc.gnu.org\/bugzilla\/show_bug.cgi?id=95468<\/a><br> <a href=\"https:\/\/developercommunity.visualstudio.com\/content\/problem\/396562\/sizeof-deduced-type-is-sometimes-not-a-constant-ex.html\" class=\"uri\">https:\/\/developercommunity.visualstudio.com\/content\/problem\/396562\/sizeof-deduced-type-is-sometimes-not-a-constant-ex.html<\/a><\/p>\n-<h3 id=\"enum\">enum<\/h3>\n-<p>Where appropriate, <em>scoped-enums<\/em> should be used. (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2347.pdf\">n2347<\/a>)<\/p>\n-<p>Use of <em>unscoped-enums<\/em> is permitted, though ordinary constants may be preferable when the automatic initializer feature isn't used.<\/p>\n-<p>The underlying type (the <em>enum-base<\/em>) of an unscoped enum type should always be specified explicitly. When unspecified, the underlying type is dependent on the range of the enumerator values and the platform.<\/p>\n-<p>The underlying type of a <em>scoped-enum<\/em> should also be specified explicitly if conversions may be applied to values of that type.<\/p>\n-<p>Due to bugs in certain (very old) compilers, there is widespread use of enums and avoidance of in-class initialization of static integral constant members. Compilers having such bugs are no longer supported. Except where an enum is semantically appropriate, new code should use integral constants.<\/p>\n-<h3 id=\"thread_local\">thread_local<\/h3>\n-<p>Do not use <code>thread_local<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2659.htm\">n2659<\/a>); instead, use the HotSpot macro <code>THREAD_LOCAL<\/code>. The initializer must be a constant expression.<\/p>\n-<p>As was discussed in the review for <a href=\"https:\/\/mail.openjdk.java.net\/pipermail\/hotspot-dev\/2019-September\/039487.html\">JDK-8230877<\/a>, <code>thread_local<\/code> allows dynamic initialization and destruction semantics. However, that support requires a run-time penalty for references to non-function-local <code>thread_local<\/code> variables defined in a different translation unit, even if they don't need dynamic initialization. Dynamic initialization and destruction of namespace-scoped thread local variables also has the same ordering problems as for ordinary namespace-scoped variables.<\/p>\n-<h3 id=\"nullptr\">nullptr<\/h3>\n-<p>Prefer <code>nullptr<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2431.pdf\">n2431<\/a>) to <code>NULL<\/code>. Don't use (constexpr or literal) 0 for pointers.<\/p>\n-<p>For historical reasons there are widespread uses of both <code>NULL<\/code> and of integer 0 as a pointer value.<\/p>\n-<h3 id=\"atomic\">&lt;atomic&gt;<\/h3>\n-<p>Do not use facilities provided by the <code>&lt;atomic&gt;<\/code> header (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2427.html\">n2427<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2752.htm\">n2752<\/a>); instead, use the HotSpot <code>Atomic<\/code> class and related facilities.<\/p>\n-<p>Atomic operations in HotSpot code must have semantics which are consistent with those provided by the JDK's compilers for Java. There are platform-specific implementation choices that a C++ compiler might make or change that are outside the scope of the C++ Standard, and might differ from what the Java compilers implement.<\/p>\n-<p>In addition, HotSpot <code>Atomic<\/code> has a concept of &quot;conservative&quot; memory ordering, which may differ from (may be stronger than) sequentially consistent. There are algorithms in HotSpot that are believed to rely on that ordering.<\/p>\n-<h3 id=\"uniform-initialization\">Uniform Initialization<\/h3>\n-<p>The use of <em>uniform initialization<\/em> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2672.htm\">n2672<\/a>), also known as <em>brace initialization<\/em>, is permitted.<\/p>\n-<p>Some relevant sections from cppreference.com:<\/p>\n-<ul>\n-<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/initialization\">initialization<\/a><\/li>\n-<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/value_initialization\">value initialization<\/a><\/li>\n-<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/direct_initialization\">direct initialization<\/a><\/li>\n-<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/list_initialization\">list initialization<\/a><\/li>\n-<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/aggregate_initialization\">aggregate initialization<\/a><\/li>\n-<\/ul>\n-<p>Although related, the use of <code>std::initializer_list<\/code> remains forbidden, as part of the avoidance of the C++ Standard Library in HotSpot code.<\/p>\n-<h3 id=\"local-function-objects\">Local Function Objects<\/h3>\n-<ul>\n-<li>Local function objects, including lambda expressions, may be used.<\/li>\n-<li>Lambda expressions must only be used as a downward value.<\/li>\n-<li>Prefer <code>[&amp;]<\/code> as the capture list of a lambda expression.<\/li>\n-<li>Return type deduction for lambda expressions is permitted, and indeed encouraged.<\/li>\n-<li>An empty parameter list for a lambda expression may be elided.<\/li>\n-<li>A lambda expression must not be <code>mutable<\/code>.<\/li>\n-<li>Generic lambda expressions are permitted.<\/li>\n-<li>Lambda expressions should be relatively simple.<\/li>\n-<li>Anonymous lambda expressions should not overly clutter the enclosing expression.<\/li>\n-<li>An anonymous lambda expression must not be directly invoked.<\/li>\n-<li>Bind expressions are forbidden.<\/li>\n-<\/ul>\n-<p>Single-use function objects can be defined locally within a function, directly at the point of use. This is an alternative to having a function or function object class defined at class or namespace scope.<\/p>\n-<p>This usage was somewhat limited by C++03, which does not permit such a class to be used as a template parameter. That restriction was removed by C++11 (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2657.htm\">n2657<\/a>). Use of this feature is permitted.<\/p>\n-<p>Many HotSpot protocols involve &quot;function-like&quot; objects that involve some named member function rather than a call operator. For example, a function that performs some action on all threads might be written as<\/p>\n-<pre><code>void do_something() {\n-  struct DoSomething : public ThreadClosure {\n-    virtual void do_thread(Thread* t) {\n-      ... do something with t ...\n-    }\n-  } closure;\n-  Threads::threads_do(&amp;closure);\n-}<\/code><\/pre>\n-<p>HotSpot code has historically usually placed the DoSomething class at namespace (or sometimes class) scope. This separates the function's code from its use, often to the detriment of readability. It requires giving the class a globally unique name (if at namespace scope). It also loses the information that the class is intended for use in exactly one place, and does not have any subclasses. (However, the latter can now be indicated by declaring it <code>final<\/code>.) Often, for simplicity, a local class will skip things like access control and accessor functions, giving the enclosing function direct access to the implementation and eliminating some boilerplate that might be provided if the class is in some outer (more accessible) scope. On the other hand, if there is a lot of surrounding code in the function body or the local class is of significant size, defining it locally can increase clutter and reduce readability.<\/p>\n-<p><a name=\"lambdaexpressions\"><\/a> C++11 added <em>lambda expressions<\/em> as a new way to write a function object. Simple lambda expressions can be significantly more concise than a function object, eliminating a lot of boiler-plate. On the other hand, a complex lambda expression may not provide much, if any, readability benefit compared to an ordinary function object. Also, while a lambda can encapsulate a call to a &quot;function-like&quot; object, it cannot be used in place of such.<\/p>\n-<p>A common use for local functions is as one-use <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/raii\" title=\"Resource Acquisition Is Initialization\">RAII<\/a> objects. The amount of boilerplate for a function object class (local or not) makes such usage somewhat clumsy and verbose. But with the help of a small amount of supporting utility code, lambdas work particularly well for this use case.<\/p>\n-<p>Another use for local functions is <a href=\"https:\/\/en.wikipedia.org\/wiki\/Partial_application\" title=\"Partial Application\">partial application<\/a>. Again here, lambdas are typically much simpler and less verbose than function object classes.<\/p>\n-<p>Because of these benefits, lambda expressions are permitted in HotSpot code, with some restrictions and usage guidance. An anonymous lambda is one which is passed directly as an argument. A named lambda is the value of a variable, which is its name.<\/p>\n-<p>Lambda expressions should only be passed downward. In particular, a lambda should not be returned from a function or stored in a global variable, whether directly or as the value of a member of some other object. Lambda capture is syntactically subtle (by design), and propagating a lambda in such ways can easily pass references to captured values to places where they are no longer valid. In particular, members of the enclosing <code>this<\/code> object are effectively captured by reference, even if the default capture is by-value. For such uses-cases a function object class should be used to make the desired value capturing and propagation explicit.<\/p>\n-<p>Limiting the capture list to <code>[&amp;]<\/code> (implicitly capture by reference) is a simplifying restriction that still provides good support for HotSpot usage, while reducing the cases a reader must recognize and understand.<\/p>\n-<ul>\n-<li><p>Many common lambda uses require reference capture. Not permitting it would substantially reduce the utility of lambdas.<\/p><\/li>\n-<li><p>Referential transparency. Implicit reference capture makes variable references in the lambda body have the same meaning they would have in the enclosing code. There isn't a semantic barrier across which the meaning of a variable changes.<\/p><\/li>\n-<li><p>Explicit reference capture introduces significant clutter, especially when lambda expressions are relatively small and simple, as they should be in HotSpot code.<\/p><\/li>\n-<li><p>There are a number of reasons why by-value capture might be used, but for the most part they don't apply to HotSpot code, given other usage restrictions.<\/p>\n-<ul>\n-<li><p>A primary use-case for by-value capture is to support escaping uses, where values captured by-reference might become invalid. That use-case doesn't apply if only downward lambdas are used.<\/p><\/li>\n-<li><p>By-value capture can also make a lambda-local copy for mutation, which requires making the lambda <code>mutable<\/code>; see below.<\/p><\/li>\n-<li><p>By-value capture might be viewed as an optimization, avoiding any overhead for reference capture of cheap to copy values. But the compiler can often eliminate any such overhead.<\/p><\/li>\n-<li><p>By-value capture by a non-<code>mutable<\/code> lambda makes the captured values const, preventing any modification by the lambda and making the captured value unaffected by modifications to the outer variable. But this only applies to captured auto variables, not member variables, and is inconsistent with referential transparency.<\/p><\/li>\n-<\/ul><\/li>\n-<li><p>Non-capturing lambdas (with an empty capture list - <code>[]<\/code>) have limited utility. There are cases where no captures are required (pure functions, for example), but if the function is small and simple then that's obvious anyway.<\/p><\/li>\n-<li><p>Capture initializers (a C++14 feature - <a href=\"https:\/\/isocpp.org\/files\/papers\/N3649.html\">N3649<\/a>) are not permitted. Capture initializers inherently increase the complexity of the capture list, and provide little benefit over an additional in-scope local variable.<\/p><\/li>\n-<\/ul>\n-<p>The use of <code>mutable<\/code> lambda expressions is forbidden because there don't seem to be many, if any, good use-cases for them in HotSpot. A lambda expression needs to be mutable in order to modify a by-value captured value. But with only downward lambdas, such usage seems likely to be rare and complicated. It is better to use a function object class in any such cases that arise, rather than requiring all HotSpot developers to understand this relatively obscure feature.<\/p>\n-<p>While it is possible to directly invoke an anonymous lambda expression, that feature should not be used, as such a form can be confusing to readers. Instead, name the lambda and call it by name.<\/p>\n-<p>Some reasons to prefer a named lambda instead of an anonymous lambda are<\/p>\n-<ul>\n-<li><p>The body contains non-trivial control flow or declarations or other nested constructs.<\/p><\/li>\n-<li><p>Its role in an argument list is hard to guess without examining the function declaration. Give it a name that indicates its purpose.<\/p><\/li>\n-<li><p>It has an unusual capture list.<\/p><\/li>\n-<li><p>It has a complex explicit return type or parameter types.<\/p><\/li>\n-<\/ul>\n-<p>Lambda expressions, and particularly anonymous lambda expressions, should be simple and compact. One-liners are good. Anonymous lambdas should usually be limited to a couple lines of body code. More complex lambdas should be named. A named lambda should not clutter the enclosing function and make it long and complex; do continue to break up large functions via the use of separate helper functions.<\/p>\n-<p>An anonymous lambda expression should either be a one-liner in a one-line expression, or isolated in its own set of lines. Don't place part of a lambda expression on the same line as other arguments to a function. The body of a multi-line lambda argument should be indented from the start of the capture list, as if that were the start of an ordinary function definition. The body of a multi-line named lambda should be indented one step from the variable's indentation.<\/p>\n-<p>Some examples:<\/p>\n-<ol type=\"1\">\n-<li><code>foo([&amp;] { ++counter; });<\/code><\/li>\n-<li><code>foo(x, [&amp;] { ++counter; });<\/code><\/li>\n-<li><code>foo([&amp;] { if (predicate) ++counter; });<\/code><\/li>\n-<li><code>foo([&amp;] { auto tmp = process(x); tmp.f(); return tmp.g(); })<\/code><\/li>\n-<li><p>Separate one-line lambda from other arguments:<\/p>\n-<pre><code>foo(c.begin(), c.end(),\n-    [&amp;] (const X&amp; x) { do_something(x); return x.value(); });<\/code><\/pre><\/li>\n-<li><p>Indentation for multi-line lambda:<\/p>\n-<pre><code>c.do_entries([&amp;] (const X&amp; x) {\n-               do_something(x, a);\n-               do_something1(x, b);\n-               do_something2(x, c);\n-             });<\/code><\/pre><\/li>\n-<li><p>Separate multi-line lambda from other arguments:<\/p>\n-<pre><code>foo(c.begin(), c.end(),\n-    [&amp;] (const X&amp; x) {\n-      do_something(x, a);\n-      do_something1(x, b);\n-      do_something2(x, c);\n-    });<\/code><\/pre><\/li>\n-<li><p>Multi-line named lambda:<\/p>\n-<pre><code>auto do_entry = [&amp;] (const X&amp; x) {\n-  do_something(x, a);\n-  do_something1(x, b);\n-  do_something2(x, c);\n-};<\/code><\/pre><\/li>\n-<\/ol>\n-<p>Item 4, and especially items 6 and 7, are pushing the simplicity limits for anonymous lambdas. Item 6 might be better written using a named lambda:<\/p>\n-<pre><code>c.do_entries(do_entry);<\/code><\/pre>\n-<p>Note that C++11 also added <em>bind expressions<\/em> as a way to write a function object for partial application, using <code>std::bind<\/code> and related facilities from the Standard Library. <code>std::bind<\/code> generalizes and replaces some of the binders from C++03. Bind expressions are not permitted in HotSpot code. They don't provide enough benefit over lambdas or local function classes in the cases where bind expressions are applicable to warrant the introduction of yet another mechanism in this space into HotSpot code.<\/p>\n-<p>References:<\/p>\n-<ul>\n-<li>Local and unnamed types as template parameters (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2657.htm\">n2657<\/a>)<\/li>\n-<li>New wording for C++0x lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2009\/n2927.pdf\">n2927<\/a>)<\/li>\n-<li>Generalized lambda capture (init-capture) (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3648.html\">N3648<\/a>)<\/li>\n-<li>Generic (polymorphic) lambda expressions (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3649.html\">N3649<\/a>)<\/li>\n-<\/ul>\n-<p>References from C++17<\/p>\n-<ul>\n-<li>Wording for constexpr lambda (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2016\/p0170r1.pdf\">p0170r1<\/a>)<\/li>\n-<li>Lambda capture of *this by Value (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2016\/p0018r3.html\">p0018r3<\/a>)<\/li>\n-<\/ul>\n-<p>References from C++20<\/p>\n-<ul>\n-<li>Allow lambda capture [=, this] (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0409r2.html\">p0409r2<\/a>)<\/li>\n-<li>Familiar template syntax for generic lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0428r2.pdf\">p0428r2<\/a>)<\/li>\n-<li>Simplifying implicit lambda capture (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0588r1.html\">p0588r1<\/a>)<\/li>\n-<li>Default constructible and assignable stateless lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0624r2.pdf\">p0624r2<\/a>)<\/li>\n-<li>Lambdas in unevaluated contexts (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0315r4.pdf\">p0315r4<\/a>)<\/li>\n-<li>Allow pack expansion in lambda init-capture (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2018\/p0780r2.html\">p0780r2<\/a>) (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2020\/p2095r0.html\">p2095r0<\/a>)<\/li>\n-<li>Deprecate implicit capture of this via [=] (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2018\/p0806r2.html\">p0806r2<\/a>)<\/li>\n-<\/ul>\n-<p>References from C++23<\/p>\n-<ul>\n-<li>Make () more optional for lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2020\/p1102r2.html\">p1102r2<\/a>)<\/li>\n-<\/ul>\n-<h3 id=\"additional-permitted-features\">Additional Permitted Features<\/h3>\n-<ul>\n-<li><p><code>constexpr<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2235.pdf\">n2235<\/a>) (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3652.html\">n3652<\/a>)<\/p><\/li>\n-<li><p>Sized deallocation (<a href=\"https:\/\/isocpp.org\/files\/papers\/n3778.html\">n3778<\/a>)<\/p><\/li>\n-<li><p>Variadic templates (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2242.pdf\">n2242<\/a>) (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2555.pdf\">n2555<\/a>)<\/p><\/li>\n-<li><p>Static assertions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2004\/n1720.html\">n1720<\/a>)<\/p><\/li>\n-<li><p><code>decltype<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2343.pdf\">n2343<\/a>) (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2011\/n3276.pdf\">n3276<\/a>)<\/p><\/li>\n-<li><p>Right angle brackets (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2005\/n1757.html\">n1757<\/a>)<\/p><\/li>\n-<li><p>Default template arguments for function templates (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/cwg_defects.html#226\">CWG D226<\/a>)<\/p><\/li>\n-<li><p>Template aliases (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2258.pdf\">n2258<\/a>)<\/p><\/li>\n-<li><p>Delegating constructors (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2006\/n1986.pdf\">n1986<\/a>)<\/p><\/li>\n-<li><p>Explicit conversion operators (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2437.pdf\">n2437<\/a>)<\/p><\/li>\n-<li><p>Standard Layout Types (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2342.htm\">n2342<\/a>)<\/p><\/li>\n-<li><p>Defaulted and deleted functions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2346.htm\">n2346<\/a>)<\/p><\/li>\n-<li><p>Dynamic initialization and destruction with concurrency (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2660.htm\">n2660<\/a>)<\/p><\/li>\n-<li><p><code>final<\/code> virtual specifiers for classes and virtual functions (<a href=\"http:\/\/www.open-std.org\/JTC1\/SC22\/WG21\/docs\/papers\/2009\/n2928.htm\">n2928<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2010\/n3206.htm\">n3206<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2011\/n3272.htm\">n3272<\/a>)<\/p><\/li>\n-<li><p><code>override<\/code> virtual specifiers for virtual functions (<a href=\"http:\/\/www.open-std.org\/JTC1\/SC22\/WG21\/docs\/papers\/2009\/n2928.htm\">n2928<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2010\/n3206.htm\">n3206<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2011\/n3272.htm\">n3272<\/a>)<\/p><\/li>\n-<li><p>Range-based <code>for<\/code> loops (<a href=\"http:\/\/www.open-std.org\/JTC1\/SC22\/WG21\/docs\/papers\/2009\/n2930.html\">n2930<\/a>) (<a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/range-for\">range-for<\/a>)<\/p><\/li>\n-<\/ul>\n-<h3 id=\"excluded-features\">Excluded Features<\/h3>\n-<ul>\n-<li>New string and character literals\n-<ul>\n-<li>New character types (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2249.html\">n2249<\/a>)<\/li>\n-<li>Unicode string literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2442.htm\">n2442<\/a>)<\/li>\n-<li>Raw string literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2442.htm\">n2442<\/a>)<\/li>\n-<li>Universal character name literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2170.html\">n2170<\/a>)<\/li>\n-<\/ul>\n-<p>HotSpot doesn't need any of the new character and string literal types.<\/p><\/li>\n-<li><p>User-defined literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2765.pdf\">n2765<\/a>) — User-defined literals should not be added casually, but only through a proposal to add a specific UDL.<\/p><\/li>\n-<li><p>Inline namespaces (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2535.htm\">n2535<\/a>) — HotSpot makes very limited use of namespaces.<\/p><\/li>\n-<li><p><code>using namespace<\/code> directives. In particular, don't use <code>using namespace std;<\/code> to avoid needing to qualify Standard Library names.<\/p><\/li>\n-<li><p>Propagating exceptions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2179.html\">n2179<\/a>) — HotSpot does not permit the use of exceptions, so this feature isn't useful.<\/p><\/li>\n-<li><p>Avoid namespace-scoped variables with non-constexpr initialization. In particular, avoid variables with types requiring non-trivial initialization or destruction. Initialization order problems can be difficult to deal with and lead to surprises, as can destruction ordering. HotSpot doesn't generally try to cleanup on exit, and running destructors at exit can also lead to problems.<\/p><\/li>\n-<li><p><code>[[deprecated]]<\/code> attribute (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2013\/n3760.html\">n3760<\/a>) — Not relevant in HotSpot code.<\/p><\/li>\n-<li><p>Avoid most operator overloading, preferring named functions. When operator overloading is used, ensure the semantics conform to the normal expected behavior of the operation.<\/p><\/li>\n-<li><p>Avoid most implicit conversion constructors and (implicit or explicit) conversion operators. (Note that conversion to <code>bool<\/code> isn't needed in HotSpot code because of the &quot;no implicit boolean&quot; guideline.)<\/p><\/li>\n-<li><p>Avoid covariant return types.<\/p><\/li>\n-<li><p>Avoid <code>goto<\/code> statements.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"undecided-features\">Undecided Features<\/h3>\n-<p>This list is incomplete; it serves to explicitly call out some features that have not yet been discussed.<\/p>\n-<ul>\n-<li><p>Trailing return type syntax for functions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2541.htm\">n2541<\/a>)<\/p><\/li>\n-<li><p>Variable templates (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3651.pdf\">n3651<\/a>)<\/p><\/li>\n-<li><p>Member initializers and aggregates (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2013\/n3653.html\">n3653<\/a>)<\/p><\/li>\n-<li><p><code>[[noreturn]]<\/code> attribute (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2761.pdf\">n2761<\/a>)<\/p><\/li>\n-<li><p>Rvalue references and move semantics<\/p><\/li>\n-<\/ul>\n-<\/body>\n-<\/html>\n+<!DOCTYPE html>\r\n+<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\r\n+<head>\r\n+  <meta charset=\"utf-8\" \/>\r\n+  <meta name=\"generator\" content=\"pandoc\" \/>\r\n+  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\r\n+  <title>HotSpot Coding Style<\/title>\r\n+  <style type=\"text\/css\">\r\n+      code{white-space: pre-wrap;}\r\n+      span.smallcaps{font-variant: small-caps;}\r\n+      span.underline{text-decoration: underline;}\r\n+      div.column{display: inline-block; vertical-align: top; width: 50%;}\r\n+  <\/style>\r\n+  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\r\n+  <!--[if lt IE 9]>\r\n+    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\r\n+  <![endif]-->\r\n+<\/head>\r\n+<body>\r\n+<header>\r\n+<h1 class=\"title\">HotSpot Coding Style<\/h1>\r\n+<\/header>\r\n+<nav id=\"TOC\">\r\n+<ul>\r\n+<li><a href=\"#introduction\">Introduction<\/a><ul>\r\n+<li><a href=\"#why-care-about-style\">Why Care About Style?<\/a><\/li>\r\n+<li><a href=\"#counterexamples-and-updates\">Counterexamples and Updates<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#structure-and-formatting\">Structure and Formatting<\/a><ul>\r\n+<li><a href=\"#factoring-and-class-design\">Factoring and Class Design<\/a><\/li>\r\n+<li><a href=\"#source-files\">Source Files<\/a><\/li>\r\n+<li><a href=\"#jtreg-tests\">JTReg Tests<\/a><\/li>\r\n+<li><a href=\"#naming\">Naming<\/a><\/li>\r\n+<li><a href=\"#commenting\">Commenting<\/a><\/li>\r\n+<li><a href=\"#macros\">Macros<\/a><\/li>\r\n+<li><a href=\"#whitespace\">Whitespace<\/a><\/li>\r\n+<li><a href=\"#miscellaneous\">Miscellaneous<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#use-of-c-features\">Use of C++ Features<\/a><ul>\r\n+<li><a href=\"#error-handling\">Error Handling<\/a><\/li>\r\n+<li><a href=\"#rtti-runtime-type-information\">RTTI (Runtime Type Information)<\/a><\/li>\r\n+<li><a href=\"#memory-allocation\">Memory Allocation<\/a><\/li>\r\n+<li><a href=\"#class-inheritance\">Class Inheritance<\/a><\/li>\r\n+<li><a href=\"#namespaces\">Namespaces<\/a><\/li>\r\n+<li><a href=\"#c-standard-library\">C++ Standard Library<\/a><\/li>\r\n+<li><a href=\"#type-deduction\">Type Deduction<\/a><\/li>\r\n+<li><a href=\"#expression-sfinae\">Expression SFINAE<\/a><\/li>\r\n+<li><a href=\"#enum\">enum<\/a><\/li>\r\n+<li><a href=\"#thread_local\">thread_local<\/a><\/li>\r\n+<li><a href=\"#nullptr\">nullptr<\/a><\/li>\r\n+<li><a href=\"#atomic\">&lt;atomic&gt;<\/a><\/li>\r\n+<li><a href=\"#uniform-initialization\">Uniform Initialization<\/a><\/li>\r\n+<li><a href=\"#local-function-objects\">Local Function Objects<\/a><\/li>\r\n+<li><a href=\"#additional-permitted-features\">Additional Permitted Features<\/a><\/li>\r\n+<li><a href=\"#excluded-features\">Excluded Features<\/a><\/li>\r\n+<li><a href=\"#undecided-features\">Undecided Features<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<\/ul>\r\n+<\/nav>\r\n+<h2 id=\"introduction\">Introduction<\/h2>\r\n+<p>This is a collection of rules, guidelines, and suggestions for writing HotSpot code. Following these will help new code fit in with existing HotSpot code, making it easier to read and maintain. Failure to follow these guidelines may lead to discussion during code reviews, if not outright rejection of a change.<\/p>\r\n+<h3 id=\"why-care-about-style\">Why Care About Style?<\/h3>\r\n+<p>Some programmers seem to have lexers and even C preprocessors installed directly behind their eyeballs. The rest of us require code that is not only functionally correct but also easy to read. More than that, since there is no one style for easy-to-read code, and since a mashup of many styles is just as confusing as no style at all, it is important for coders to be conscious of the many implicit stylistic choices that historically have gone into the HotSpot code base.<\/p>\r\n+<p>Some of these guidelines are driven by the cross-platform requirements for HotSpot. Shared code must work on a variety of platforms, and may encounter deficiencies in some. Using platform conditionalization in shared code is usually avoided, while shared code is strongly preferred to multiple platform-dependent implementations, so some language features may be recommended against.<\/p>\r\n+<p>Some of the guidelines here are relatively arbitrary choices among equally plausible alternatives. The purpose of stating and enforcing these rules is largely to provide a consistent look to the code. That consistency makes the code more readable by avoiding non-functional distractions from the interesting functionality.<\/p>\r\n+<p>When changing pre-existing code, it is reasonable to adjust it to match these conventions. Exception: If the pre-existing code clearly conforms locally to its own peculiar conventions, it is not worth reformatting the whole thing. Also consider separating changes that make extensive stylistic updates from those which make functional changes.<\/p>\r\n+<h3 id=\"counterexamples-and-updates\">Counterexamples and Updates<\/h3>\r\n+<p>Many of the guidelines mentioned here have (sometimes widespread) counterexamples in the HotSpot code base. Finding a counterexample is not sufficient justification for new code to follow the counterexample as a precedent, since readers of your code will rightfully expect your code to follow the greater bulk of precedents documented here.<\/p>\r\n+<p>Occasionally a guideline mentioned here may be just out of synch with the actual HotSpot code base. If you find that a guideline is consistently contradicted by a large number of counterexamples, please bring it up for discussion and possible change. The architectural rule, of course, is &quot;When in Rome do as the Romans&quot;. Sometimes in the suburbs of Rome the rules are a little different; these differences can be pointed out here.<\/p>\r\n+<p>Proposed changes should be discussed on the <a href=\"mailto:hotspot-dev@openjdk.java.net\">HotSpot Developers<\/a> mailing list. Changes are likely to be cautious and incremental, since HotSpot coders have been using these guidelines for years.<\/p>\r\n+<p>Substantive changes are approved by <a href=\"https:\/\/en.wikipedia.org\/wiki\/Rough_consensus\">rough consensus<\/a> of the <a href=\"https:\/\/openjdk.java.net\/census#hotspot\">HotSpot Group<\/a> Members. The Group Lead determines whether consensus has been reached.<\/p>\r\n+<p>Editorial changes (changes that only affect the description of HotSpot style, not its substance) do not require the full consensus gathering process. The normal HotSpot pull request process may be used for editorial changes, with the additional requirement that the requisite reviewers are also HotSpot Group Members.<\/p>\r\n+<h2 id=\"structure-and-formatting\">Structure and Formatting<\/h2>\r\n+<h3 id=\"factoring-and-class-design\">Factoring and Class Design<\/h3>\r\n+<ul>\r\n+<li><p>Group related code together, so readers can concentrate on one section of one file.<\/p><\/li>\r\n+<li><p>Classes are the primary code structuring mechanism. Place related functionality in a class, or a set of related classes. Use of either namespaces or public non-member functions is rare in HotSpot code. Static non-member functions are not uncommon.<\/p><\/li>\r\n+<li><p>If a class <code>FooBar<\/code> is going to be used in more than one place, put it a file named fooBar.hpp and fooBar.cpp. If the class is a sidekick to a more important class <code>BazBat<\/code>, it can go in bazBat.hpp.<\/p><\/li>\r\n+<li><p>Put a member function <code>FooBar::bang<\/code> into the same file that defined <code>FooBar<\/code>, or its associated <em>.inline.hpp or <\/em>.cpp file.<\/p><\/li>\r\n+<li><p>Use public accessor functions for member variables accessed outside the class.<\/p><\/li>\r\n+<li><p>Assign names to constant literals and use the names instead.<\/p><\/li>\r\n+<li><p>Keep functions small, a screenful at most. Split out chunks of logic into file-local classes or static functions if needed.<\/p><\/li>\r\n+<li><p>Factor away nonessential complexity into local inline helper functions and helper classes.<\/p><\/li>\r\n+<li><p>Think clearly about internal invariants that apply to each class, and document them in the form of asserts within member functions.<\/p><\/li>\r\n+<li><p>Make simple, self-evident contracts for member functions. If you cannot communicate a simple contract, redesign the class.<\/p><\/li>\r\n+<li><p>Implement classes as if expecting rough usage by clients. Check for incorrect usage of a class using <code>assert(...)<\/code>, <code>guarantee(...)<\/code>, <code>ShouldNotReachHere()<\/code> and comments wherever needed. Performance is almost never a reason to omit asserts.<\/p><\/li>\r\n+<li><p>When possible, design as if for reusability. This forces a clear design of the class's externals, and clean hiding of its internals.<\/p><\/li>\r\n+<li><p>Initialize all variables and data structures to a known state. If a class has a constructor, initialize it there.<\/p><\/li>\r\n+<li><p>Do no optimization before its time. Prove the need to optimize.<\/p><\/li>\r\n+<li><p>When you must defactor to optimize, preserve as much structure as possible. If you must hand-inline some name, label the local copy with the original name.<\/p><\/li>\r\n+<li><p>If you need to use a hidden detail (e.g., a structure offset), name it (as a constant or function) in the class that owns it.<\/p><\/li>\r\n+<li><p>Don't use the Copy and Paste keys to replicate more than a couple lines of code. Name what you must repeat.<\/p><\/li>\r\n+<li><p>If a class needs a member function to change a user-visible attribute, the change should be done with a &quot;setter&quot; accessor matched to the simple &quot;getter&quot;.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"source-files\">Source Files<\/h3>\r\n+<ul>\r\n+<li><p>All source files must have a globally unique basename. The build system depends on this uniqueness.<\/p><\/li>\r\n+<li><p>Do not put non-trivial function implementations in .hpp files. If the implementation depends on other .hpp files, put it in a .cpp or a .inline.hpp file.<\/p><\/li>\r\n+<li><p>.inline.hpp files should only be included in .cpp or .inline.hpp files.<\/p><\/li>\r\n+<li><p>All .inline.hpp files should include their corresponding .hpp file as the first include line. Declarations needed by other files should be put in the .hpp file, and not in the .inline.hpp file. This rule exists to resolve problems with circular dependencies between .inline.hpp files.<\/p><\/li>\r\n+<li><p>All .cpp files include precompiled.hpp as the first include line.<\/p><\/li>\r\n+<li><p>precompiled.hpp is just a build time optimization, so don't rely on it to resolve include problems.<\/p><\/li>\r\n+<li><p>Keep the include lines alphabetically sorted.<\/p><\/li>\r\n+<li><p>Put conditional inclusions (<code>#if ...<\/code>) at the end of the include list.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"jtreg-tests\">JTReg Tests<\/h3>\r\n+<ul>\r\n+<li><p>JTReg tests should have meaningful names.<\/p><\/li>\r\n+<li><p>JTReg tests associated with specific bugs should be tagged with the <code>@bug<\/code> keyword in the test description.<\/p><\/li>\r\n+<li><p>JTReg tests should be organized by component or feature under <code>test\/<\/code>, in a directory hierarchy that generally follows that of the <code>src\/<\/code> directory. There may be additional subdirectories to further categorize tests by feature. This structure makes it easy to run a collection of tests associated with a specific feature by specifying the associated directory as the source of the tests to run.<\/p>\r\n+<ul>\r\n+<li>Some (older) tests use the associated bug number in the directory name, the test name, or both. That naming style should no longer be used, with existing tests using that style being candidates for migration.<\/li>\r\n+<\/ul><\/li>\r\n+<\/ul>\r\n+<h3 id=\"naming\">Naming<\/h3>\r\n+<ul>\r\n+<li><p>The length of a name may be correlated to the size of its scope. In particular, short names (even single letter names) may be fine in a small scope, but are usually inappropriate for larger scopes.<\/p><\/li>\r\n+<li><p>Prefer whole words rather than abbreviations, unless the abbreviation is more widely used than the long form in the code's domain.<\/p><\/li>\r\n+<li><p>Choose names consistently. Do not introduce spurious variations. Abbreviate corresponding terms to a consistent length.<\/p><\/li>\r\n+<li><p>Global names must be unique, to avoid <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/definition\" title=\"One Definition Rule\">One Definition Rule<\/a> (ODR) violations. A common prefixing scheme for related global names is often used. (This is instead of using namespaces, which are mostly avoided in HotSpot.)<\/p><\/li>\r\n+<li><p>Don't give two names to the semantically same thing. But use different names for semantically different things, even if they are representationally the same. (So use meaningful <code>typedef<\/code> or template alias names where appropriate.)<\/p><\/li>\r\n+<li><p>When choosing names, avoid categorical nouns like &quot;variable&quot;, &quot;field&quot;, &quot;parameter&quot;, &quot;value&quot;, and verbs like &quot;compute&quot;, &quot;get&quot;. (<code>storeValue(int param)<\/code> is bad.)<\/p><\/li>\r\n+<li><p>Type names and global names should use mixed-case with the first letter of each word capitalized (<code>FooBar<\/code>).<\/p><\/li>\r\n+<li><p>Embedded abbreviations in otherwise mixed-case names are usually capitalized entirely rather than being treated as a single word with only the initial letter capitalized, e.g. &quot;HTML&quot; rather than &quot;Html&quot;.<\/p><\/li>\r\n+<li><p>Function and local variable names use lowercase with words separated by a single underscore (<code>foo_bar<\/code>).<\/p><\/li>\r\n+<li><p>Class data member names have a leading underscore, and use lowercase with words separated by a single underscore (<code>_foo_bar<\/code>).<\/p><\/li>\r\n+<li><p>Constant names may be upper-case or mixed-case, according to historical necessity. (Note: There are many examples of constants with lowercase names.)<\/p><\/li>\r\n+<li><p>Constant names should follow an existing pattern, and must have a distinct appearance from other names in related APIs.<\/p><\/li>\r\n+<li><p>Class and type names should be noun phrases. Consider an &quot;er&quot; suffix for a class that represents an action.<\/p><\/li>\r\n+<li><p>Function names should be verb phrases that reflect changes of state known to a class's user, or else noun phrases if they cause no change of state visible to the class's user.<\/p><\/li>\r\n+<li><p>Getter accessor names are noun phrases, with no &quot;<code>get_<\/code>&quot; noise word. Boolean getters can also begin with &quot;<code>is_<\/code>&quot; or &quot;<code>has_<\/code>&quot;. Member function for reading data members usually have the same name as the data member, exclusive of the leading underscore.<\/p><\/li>\r\n+<li><p>Setter accessor names prepend &quot;<code>set_<\/code>&quot; to the getter name.<\/p><\/li>\r\n+<li><p>Other member function names are verb phrases, as if commands to the receiver.<\/p><\/li>\r\n+<li><p>Avoid leading underscores (as &quot;<code>_oop<\/code>&quot;) except in cases required above. (Names with leading underscores can cause portability problems.)<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"commenting\">Commenting<\/h3>\r\n+<ul>\r\n+<li><p>Clearly comment subtle fixes.<\/p><\/li>\r\n+<li><p>Clearly comment tricky classes and functions.<\/p><\/li>\r\n+<li><p>If you have to choose between commenting code and writing wiki content, comment the code. Link from the wiki to the source file if it makes sense.<\/p><\/li>\r\n+<li><p>As a general rule don't add bug numbers to comments (they would soon overwhelm the code). But if the bug report contains significant information that can't reasonably be added as a comment, then refer to the bug report.<\/p><\/li>\r\n+<li><p>Personal names are discouraged in the source code, which is a team product.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"macros\">Macros<\/h3>\r\n+<ul>\r\n+<li><p>You can almost always use an inline function or class instead of a macro. Use a macro only when you really need it.<\/p><\/li>\r\n+<li><p>Templates may be preferable to multi-line macros. (There may be subtle performance effects with templates on some platforms; revert to macros if absolutely necessary.)<\/p><\/li>\r\n+<li><p><code>#ifdef<\/code>s should not be used to introduce platform-specific code into shared code (except for <code>_LP64<\/code>). They must be used to manage header files, in the pattern found at the top of every source file. They should be used mainly for major build features, including <code>PRODUCT<\/code>, <code>ASSERT<\/code>, <code>_LP64<\/code>, <code>INCLUDE_SERIALGC<\/code>, <code>COMPILER1<\/code>, etc.<\/p><\/li>\r\n+<li><p>For build features such as <code>PRODUCT<\/code>, use <code>#ifdef PRODUCT<\/code> for multiple-line inclusions or exclusions.<\/p><\/li>\r\n+<li><p>For short inclusions or exclusions based on build features, use macros like <code>PRODUCT_ONLY<\/code> and <code>NOT_PRODUCT<\/code>. But avoid using them with multiple-line arguments, since debuggers do not handle that well.<\/p><\/li>\r\n+<li><p>Use <code>CATCH<\/code>, <code>THROW<\/code>, etc. for HotSpot-specific exception processing.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"whitespace\">Whitespace<\/h3>\r\n+<ul>\r\n+<li><p>In general, don't change whitespace unless it improves readability or consistency. Gratuitous whitespace changes will make integrations and backports more difficult.<\/p><\/li>\r\n+<li><p>Use One-True-Brace-Style. The opening brace for a function or class is normally at the end of the line; it is sometimes moved to the beginning of the next line for emphasis. Substatements are enclosed in braces, even if there is only a single statement. Extremely simple one-line statements may drop braces around a substatement.<\/p><\/li>\r\n+<li><p>Indentation levels are two columns.<\/p><\/li>\r\n+<li><p>There is no hard line length limit. That said, bear in mind that excessively long lines can cause difficulties. Some people like to have multiple side-by-side windows in their editors, and long lines may force them to choose among unpleasant options. They can use wide windows, reducing the number that can fit across the screen, and wasting a lot of screen real estate because most lines are not that long. Alternatively, they can have more windows across the screen, with long lines wrapping (or worse, requiring scrolling to see in their entirety), which is harder to read. Similar issues exist for side-by-side code reviews.<\/p><\/li>\r\n+<li><p>Tabs are not allowed in code. Set your editor accordingly.<br> (Emacs: <code>(setq-default indent-tabs-mode nil)<\/code>.)<\/p><\/li>\r\n+<li><p>Use good taste to break lines and align corresponding tokens on adjacent lines.<\/p><\/li>\r\n+<li><p>Use spaces around operators, especially comparisons and assignments. (Relaxable for boolean expressions and high-precedence operators in classic math-style formulas.)<\/p><\/li>\r\n+<li><p>Put spaces on both sides of control flow keywords <code>if<\/code>, <code>else<\/code>, <code>for<\/code>, <code>switch<\/code>, etc. Don't add spaces around the associated <em>control<\/em> expressions. Examples:<\/p>\r\n+<pre><code>while (test_foo(args...)) {   \/\/ Yes\r\n+while(test_foo(args...)) {    \/\/ No, missing space after while\r\n+while ( test_foo(args...) ) { \/\/ No, excess spaces around control<\/code><\/pre><\/li>\r\n+<li><p>Use extra parentheses in expressions whenever operator precedence seems doubtful. Always use parentheses in shift\/mask expressions (<code>&lt;&lt;<\/code>, <code>&amp;<\/code>, <code>|<\/code>). Don't add whitespace immediately inside parentheses.<\/p><\/li>\r\n+<li><p>Use more spaces and blank lines between larger constructs, such as classes or function definitions.<\/p><\/li>\r\n+<li><p>If the surrounding code has any sort of vertical organization, adjust new lines horizontally to be consistent with that organization. (E.g., trailing backslashes on long macro definitions often align.)<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"miscellaneous\">Miscellaneous<\/h3>\r\n+<ul>\r\n+<li><p>Use the <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/raii\" title=\"Resource Acquisition Is Initialization\">Resource Acquisition Is Initialization<\/a> (RAII) design pattern to manage bracketed critical sections. See class <code>ResourceMark<\/code> for an example.<\/p><\/li>\r\n+<li>Avoid implicit conversions to <code>bool<\/code>.\r\n+<ul>\r\n+<li>Use <code>bool<\/code> for boolean values.<\/li>\r\n+<li>Do not use ints or pointers as (implicit) booleans with <code>&amp;&amp;<\/code>, <code>||<\/code>, <code>if<\/code>, <code>while<\/code>. Instead, compare explicitly, i.e. <code>if (x != 0)<\/code> or <code>if (ptr != nullptr)<\/code>, etc.<\/li>\r\n+<li>Do not use declarations in <em>condition<\/em> forms, i.e. don't use <code>if (T v = value) { ... }<\/code>.<\/li>\r\n+<\/ul><\/li>\r\n+<li><p>Use functions from globalDefinitions.hpp and related files when performing bitwise operations on integers. Do not code directly as C operators, unless they are extremely simple. (Examples: <code>align_up<\/code>, <code>is_power_of_2<\/code>, <code>exact_log2<\/code>.)<\/p><\/li>\r\n+<li><p>Use arrays with abstractions supporting range checks.<\/p><\/li>\r\n+<li><p>Always enumerate all cases in a switch statement or provide a default case. It is ok to have an empty default with comment.<\/p><\/li>\r\n+<\/ul>\r\n+<h2 id=\"use-of-c-features\">Use of C++ Features<\/h2>\r\n+<p>HotSpot was originally written in a subset of the C++98\/03 language. More recently, support for C++14 is provided, though again, HotSpot only uses a subset. (Backports to JDK versions lacking support for more recent Standards must of course stick with the original C++98\/03 subset.)<\/p>\r\n+<p>This section describes that subset. Features from the C++98\/03 language may be used unless explicitly excluded here. Features from C++11 and C++14 may be explicitly permitted or explicitly excluded, and discussed accordingly here. There is a third category, undecided features, about which HotSpot developers have not yet reached a consensus, or perhaps have not discussed at all. Use of these features is also excluded.<\/p>\r\n+<p>(The use of some features may not be immediately obvious and may slip in anyway, since the compiler will accept them. The code review process is the main defense against this.)<\/p>\r\n+<p>Some features are discussed in their own subsection, typically to provide more extensive discussion or rationale for limitations. Features that don't have their own subsection are listed in omnibus feature sections for permitted, excluded, and undecided features.<\/p>\r\n+<p>Lists of new features for C++11 and C++14, along with links to their descriptions, can be found in the online documentation for some of the compilers and libraries. The C++14 Standard is the definitive description.<\/p>\r\n+<ul>\r\n+<li><a href=\"https:\/\/gcc.gnu.org\/projects\/cxx-status.html\">C++ Standards Support in GCC<\/a><\/li>\r\n+<li><a href=\"https:\/\/clang.llvm.org\/cxx_status.html\">C++ Support in Clang<\/a><\/li>\r\n+<li><a href=\"https:\/\/docs.microsoft.com\/en-us\/cpp\/visual-cpp-language-conformance\">Visual C++ Language Conformance<\/a><\/li>\r\n+<li><a href=\"https:\/\/gcc.gnu.org\/onlinedocs\/libstdc++\/manual\/status.html\">libstdc++ Status<\/a><\/li>\r\n+<li><a href=\"https:\/\/libcxx.llvm.org\/cxx1y_status.html\">libc++ Status<\/a><\/li>\r\n+<\/ul>\r\n+<p>As a rule of thumb, permitting features which simplify writing code and, especially, reading code, is encouraged.<\/p>\r\n+<p>Similar discussions for some other projects:<\/p>\r\n+<ul>\r\n+<li><p><a href=\"https:\/\/google.github.io\/styleguide\/cppguide.html\">Google C++ Style Guide<\/a> — Currently (2020) targeting C++17.<\/p><\/li>\r\n+<li><p><a href=\"https:\/\/chromium.googlesource.com\/chromium\/src\/+\/main\/styleguide\/c++\/c++-features.md\">C++11 and C++14 use in Chromium<\/a> — Categorizes features as allowed, banned, or to be discussed.<\/p><\/li>\r\n+<li><p><a href=\"https:\/\/llvm.org\/docs\/CodingStandards.html\">llvm Coding Standards<\/a> — Currently (2020) targeting C++14.<\/p><\/li>\r\n+<li><p><a href=\"https:\/\/firefox-source-docs.mozilla.org\/code-quality\/coding-style\/using_cxx_in_firefox_code.html\">Using C++ in Mozilla code<\/a> — C++17 support is required for recent versions (2020).<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"error-handling\">Error Handling<\/h3>\r\n+<p>Do not use exceptions. Exceptions are disabled by the build configuration for some platforms.<\/p>\r\n+<p>Rationale: There is significant concern over the performance cost of exceptions and their usage model and implications for maintainable code. That's not just a matter of history that has been fixed; there remain questions and problems even today (2019). See, for example, <a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2018\/p0709r0.pdf\">Zero cost deterministic exceptions<\/a>. Because of this, HotSpot has always used a build configuration that disables exceptions where that is available. As a result, HotSpot code uses error handling mechanisms such as two-phase construction, factory functions, returning error codes, and immediate termination. Even if the cost of exceptions were not a concern, the existing body of code was not written with exception safety in mind. Making HotSpot exception safe would be a very large undertaking.<\/p>\r\n+<p>In addition to the usual alternatives to exceptions, HotSpot provides its own exception mechanism. This is based on a set of macros defined in utilities\/exceptions.hpp.<\/p>\r\n+<h3 id=\"rtti-runtime-type-information\">RTTI (Runtime Type Information)<\/h3>\r\n+<p>Do not use <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">Runtime Type Information<\/a> (RTTI). <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">RTTI<\/a> is disabled by the build configuration for some platforms. Among other things, this means <code>dynamic_cast<\/code> cannot be used.<\/p>\r\n+<p>Rationale: Other than to implement exceptions (which HotSpot doesn't use), most potential uses of <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">RTTI<\/a> are better done via virtual functions. Some of the remainder can be replaced by bespoke mechanisms. The cost of the additional runtime data structures needed to support <a href=\"https:\/\/en.wikipedia.org\/wiki\/Run-time_type_information\" title=\"Runtime Type Information\">RTTI<\/a> are deemed not worthwhile, given the alternatives.<\/p>\r\n+<h3 id=\"memory-allocation\">Memory Allocation<\/h3>\r\n+<p>Do not use the standard global allocation and deallocation functions (operator new and related functions). Use of these functions by HotSpot code is disabled for some platforms.<\/p>\r\n+<p>Rationale: HotSpot often uses &quot;resource&quot; or &quot;arena&quot; allocation. Even where heap allocation is used, the standard global functions are avoided in favor of wrappers around malloc and free that support the VM's Native Memory Tracking (NMT) feature.<\/p>\r\n+<p>Native memory allocation failures are often treated as non-recoverable. The place where &quot;out of memory&quot; is (first) detected may be an innocent bystander, unrelated to the actual culprit.<\/p>\r\n+<h3 id=\"class-inheritance\">Class Inheritance<\/h3>\r\n+<p>Use public single inheritance.<\/p>\r\n+<p>Prefer composition rather than non-public inheritance.<\/p>\r\n+<p>Restrict inheritance to the &quot;is-a&quot; case; use composition rather than non-is-a related inheritance.<\/p>\r\n+<p>Avoid multiple inheritance. Never use virtual inheritance.<\/p>\r\n+<h3 id=\"namespaces\">Namespaces<\/h3>\r\n+<p>Avoid using namespaces. HotSpot code normally uses &quot;all static&quot; classes rather than namespaces for grouping. An &quot;all static&quot; class is not instantiable, has only static members, and is normally derived (possibly indirectly) from the helper class <code>AllStatic<\/code>.<\/p>\r\n+<p>Benefits of using such classes include:<\/p>\r\n+<ul>\r\n+<li><p>Provides access control for members, which is unavailable with namespaces.<\/p><\/li>\r\n+<li><p>Avoids <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/adl\" title=\"Argument Dependent Lookup\">Argument Dependent Lookup<\/a> (ADL).<\/p><\/li>\r\n+<li><p>Closed for additional members. Namespaces allow names to be added in multiple contexts, making it harder to see the complete API.<\/p><\/li>\r\n+<\/ul>\r\n+<p>Namespaces should be used only in cases where one of those &quot;benefits&quot; is actually a hindrance.<\/p>\r\n+<p>In particular, don't use anonymous namespaces. They seem like they should be useful, and indeed have some real benefits for naming and generated code size on some platforms. Unfortunately, debuggers don't seem to like them at all.<\/p>\r\n+<p><a href=\"https:\/\/groups.google.com\/forum\/#!topic\/mozilla.dev.platform\/KsaG3lEEaRM\" class=\"uri\">https:\/\/groups.google.com\/forum\/#!topic\/mozilla.dev.platform\/KsaG3lEEaRM<\/a><br> Suggests Visual Studio debugger might not be able to refer to anonymous namespace symbols, so can't set breakpoints in them. Though the discussion seems to go back and forth on that.<\/p>\r\n+<p><a href=\"https:\/\/firefox-source-docs.mozilla.org\/code-quality\/coding-style\/coding_style_cpp.html\" class=\"uri\">https:\/\/firefox-source-docs.mozilla.org\/code-quality\/coding-style\/coding_style_cpp.html<\/a><br> Search for &quot;Anonymous namespaces&quot; Suggests preferring &quot;static&quot; to anonymous namespaces where applicable, because of poor debugger support for anonymous namespaces.<\/p>\r\n+<p><a href=\"https:\/\/sourceware.org\/bugzilla\/show_bug.cgi?id=16874\" class=\"uri\">https:\/\/sourceware.org\/bugzilla\/show_bug.cgi?id=16874<\/a><br> Bug for similar gdb problems.<\/p>\r\n+<h3 id=\"c-standard-library\">C++ Standard Library<\/h3>\r\n+<p>Avoid using the C++ Standard Library.<\/p>\r\n+<p>Historically, HotSpot has mostly avoided use of the Standard Library.<\/p>\r\n+<p>(It used to be impossible to use most of it in shared code, because the build configuration for Solaris with Solaris Studio made all but a couple of pieces inaccessible. Support for header-only parts was added in mid-2017. Support for Solaris was removed in 2020.)<\/p>\r\n+<p>Some reasons for this include<\/p>\r\n+<ul>\r\n+<li><p>Exceptions. Perhaps the largest core issue with adopting the use of Standard Library facilities is exceptions. HotSpot does not use exceptions and, for platforms which allow doing so, builds with them turned off. Many Standard Library facilities implicitly or explicitly use exceptions.<\/p><\/li>\r\n+<li><p><code>assert<\/code>. An issue that is quickly encountered is the <code>assert<\/code> macro name collision (<a href=\"https:\/\/bugs.openjdk.java.net\/browse\/JDK-8007770\">JDK-8007770<\/a>). Some mechanism for addressing this would be needed before much of the Standard Library could be used. (Not all Standard Library implementations use assert in header files, but some do.)<\/p><\/li>\r\n+<li><p>Memory allocation. HotSpot requires explicit control over where allocations occur. The C++98\/03 <code>std::allocator<\/code> class is too limited to support our usage. (Changes in more recent Standards may remove this limitation.)<\/p><\/li>\r\n+<li><p>Implementation vagaries. Bugs, or simply different implementation choices, can lead to different behaviors among the various Standard Libraries we need to deal with.<\/p><\/li>\r\n+<li><p>Inconsistent naming conventions. HotSpot and the C++ Standard use different naming conventions. The coexistence of those different conventions might appear jarring and reduce readability.<\/p><\/li>\r\n+<\/ul>\r\n+<p>There are a few exceptions to this rule.<\/p>\r\n+<ul>\r\n+<li><code>#include &lt;new&gt;<\/code> to use placement <code>new<\/code>, <code>std::nothrow<\/code>, and <code>std::nothrow_t<\/code>.<\/li>\r\n+<li><code>#include &lt;limits&gt;<\/code> to use <code>std::numeric_limits<\/code>.<\/li>\r\n+<li><code>#include &lt;type_traits&gt;<\/code>.<\/li>\r\n+<li><code>#include &lt;cstddef&gt;<\/code> to use <code>std::nullptr_t<\/code>.<\/li>\r\n+<\/ul>\r\n+<p>TODO: Rather than directly #including (permitted) Standard Library headers, use a convention of #including wrapper headers (in some location like hotspot\/shared\/stdcpp). This provides a single place for dealing with issues we might have for any given header, esp. platform-specific issues.<\/p>\r\n+<h3 id=\"type-deduction\">Type Deduction<\/h3>\r\n+<p>Use type deduction only if it makes the code clearer or safer. Do not use it merely to avoid the inconvenience of writing an explicit type, unless that type is itself difficult to write. An example of the latter is a function template return type that depends on template parameters in a non-trivial way.<\/p>\r\n+<p>There are several contexts where types are deduced.<\/p>\r\n+<ul>\r\n+<li><p>Function argument deduction. This is always permitted, and indeed encouraged. It is nearly always better to allow the type of a function template argument to be deduced rather than explicitly specified.<\/p><\/li>\r\n+<li><p><code>auto<\/code> variable declarations (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2006\/n1984.pdf\">n1984<\/a>)<br> For local variables, this can be used to make the code clearer by eliminating type information that is obvious or irrelevant. Excessive use can make code much harder to understand.<\/p><\/li>\r\n+<li><p>Function return type deduction (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3638.html\">n3638<\/a>)<br> Only use if the function body has a very small number of <code>return<\/code> statements, and generally relatively little other code.<\/p><\/li>\r\n+<li><p>Also see <a href=\"#lambdaexpressions\">lambda expressions<\/a>.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"expression-sfinae\">Expression SFINAE<\/h3>\r\n+<p><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/sfinae\" title=\"Substitution Failure Is Not An Error\">Substitution Failure Is Not An Error<\/a> (SFINAE) is a template metaprogramming technique that makes use of template parameter substitution failures to make compile-time decisions.<\/p>\r\n+<p>C++11 relaxed the rules for what constitutes a hard-error when attempting to substitute template parameters with template arguments, making most deduction errors be substitution errors; see (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2634.html\">n2634<\/a>). This makes <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/sfinae\" title=\"Substitution Failure Is Not An Error\">SFINAE<\/a> more powerful and easier to use. However, the implementation complexity for this change is significant, and this seems to be a place where obscure corner-case bugs in various compilers can be found. So while this feature can (and indeed should) be used (and would be difficult to avoid), caution should be used when pushing to extremes.<\/p>\r\n+<p>Here are a few closely related example bugs:<br> <a href=\"https:\/\/gcc.gnu.org\/bugzilla\/show_bug.cgi?id=95468\" class=\"uri\">https:\/\/gcc.gnu.org\/bugzilla\/show_bug.cgi?id=95468<\/a><br> <a href=\"https:\/\/developercommunity.visualstudio.com\/content\/problem\/396562\/sizeof-deduced-type-is-sometimes-not-a-constant-ex.html\" class=\"uri\">https:\/\/developercommunity.visualstudio.com\/content\/problem\/396562\/sizeof-deduced-type-is-sometimes-not-a-constant-ex.html<\/a><\/p>\r\n+<h3 id=\"enum\">enum<\/h3>\r\n+<p>Where appropriate, <em>scoped-enums<\/em> should be used. (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2347.pdf\">n2347<\/a>)<\/p>\r\n+<p>Use of <em>unscoped-enums<\/em> is permitted, though ordinary constants may be preferable when the automatic initializer feature isn't used.<\/p>\r\n+<p>The underlying type (the <em>enum-base<\/em>) of an unscoped enum type should always be specified explicitly. When unspecified, the underlying type is dependent on the range of the enumerator values and the platform.<\/p>\r\n+<p>The underlying type of a <em>scoped-enum<\/em> should also be specified explicitly if conversions may be applied to values of that type.<\/p>\r\n+<p>Due to bugs in certain (very old) compilers, there is widespread use of enums and avoidance of in-class initialization of static integral constant members. Compilers having such bugs are no longer supported. Except where an enum is semantically appropriate, new code should use integral constants.<\/p>\r\n+<h3 id=\"thread_local\">thread_local<\/h3>\r\n+<p>Do not use <code>thread_local<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2659.htm\">n2659<\/a>); instead, use the HotSpot macro <code>THREAD_LOCAL<\/code>. The initializer must be a constant expression.<\/p>\r\n+<p>As was discussed in the review for <a href=\"https:\/\/mail.openjdk.java.net\/pipermail\/hotspot-dev\/2019-September\/039487.html\">JDK-8230877<\/a>, <code>thread_local<\/code> allows dynamic initialization and destruction semantics. However, that support requires a run-time penalty for references to non-function-local <code>thread_local<\/code> variables defined in a different translation unit, even if they don't need dynamic initialization. Dynamic initialization and destruction of namespace-scoped thread local variables also has the same ordering problems as for ordinary namespace-scoped variables.<\/p>\r\n+<h3 id=\"nullptr\">nullptr<\/h3>\r\n+<p>Prefer <code>nullptr<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2431.pdf\">n2431<\/a>) to <code>NULL<\/code>. Don't use (constexpr or literal) 0 for pointers.<\/p>\r\n+<p>For historical reasons there are widespread uses of both <code>NULL<\/code> and of integer 0 as a pointer value.<\/p>\r\n+<h3 id=\"atomic\">&lt;atomic&gt;<\/h3>\r\n+<p>Do not use facilities provided by the <code>&lt;atomic&gt;<\/code> header (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2427.html\">n2427<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2752.htm\">n2752<\/a>); instead, use the HotSpot <code>Atomic<\/code> class and related facilities.<\/p>\r\n+<p>Atomic operations in HotSpot code must have semantics which are consistent with those provided by the JDK's compilers for Java. There are platform-specific implementation choices that a C++ compiler might make or change that are outside the scope of the C++ Standard, and might differ from what the Java compilers implement.<\/p>\r\n+<p>In addition, HotSpot <code>Atomic<\/code> has a concept of &quot;conservative&quot; memory ordering, which may differ from (may be stronger than) sequentially consistent. There are algorithms in HotSpot that are believed to rely on that ordering.<\/p>\r\n+<h3 id=\"uniform-initialization\">Uniform Initialization<\/h3>\r\n+<p>The use of <em>uniform initialization<\/em> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2672.htm\">n2672<\/a>), also known as <em>brace initialization<\/em>, is permitted.<\/p>\r\n+<p>Some relevant sections from cppreference.com:<\/p>\r\n+<ul>\r\n+<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/initialization\">initialization<\/a><\/li>\r\n+<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/value_initialization\">value initialization<\/a><\/li>\r\n+<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/direct_initialization\">direct initialization<\/a><\/li>\r\n+<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/list_initialization\">list initialization<\/a><\/li>\r\n+<li><a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/aggregate_initialization\">aggregate initialization<\/a><\/li>\r\n+<\/ul>\r\n+<p>Although related, the use of <code>std::initializer_list<\/code> remains forbidden, as part of the avoidance of the C++ Standard Library in HotSpot code.<\/p>\r\n+<h3 id=\"local-function-objects\">Local Function Objects<\/h3>\r\n+<ul>\r\n+<li>Local function objects, including lambda expressions, may be used.<\/li>\r\n+<li>Lambda expressions must only be used as a downward value.<\/li>\r\n+<li>Prefer <code>[&amp;]<\/code> as the capture list of a lambda expression.<\/li>\r\n+<li>Return type deduction for lambda expressions is permitted, and indeed encouraged.<\/li>\r\n+<li>An empty parameter list for a lambda expression may be elided.<\/li>\r\n+<li>A lambda expression must not be <code>mutable<\/code>.<\/li>\r\n+<li>Generic lambda expressions are permitted.<\/li>\r\n+<li>Lambda expressions should be relatively simple.<\/li>\r\n+<li>Anonymous lambda expressions should not overly clutter the enclosing expression.<\/li>\r\n+<li>An anonymous lambda expression must not be directly invoked.<\/li>\r\n+<li>Bind expressions are forbidden.<\/li>\r\n+<\/ul>\r\n+<p>Single-use function objects can be defined locally within a function, directly at the point of use. This is an alternative to having a function or function object class defined at class or namespace scope.<\/p>\r\n+<p>This usage was somewhat limited by C++03, which does not permit such a class to be used as a template parameter. That restriction was removed by C++11 (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2657.htm\">n2657<\/a>). Use of this feature is permitted.<\/p>\r\n+<p>Many HotSpot protocols involve &quot;function-like&quot; objects that involve some named member function rather than a call operator. For example, a function that performs some action on all threads might be written as<\/p>\r\n+<pre><code>void do_something() {\r\n+  struct DoSomething : public ThreadClosure {\r\n+    virtual void do_thread(Thread* t) {\r\n+      ... do something with t ...\r\n+    }\r\n+  } closure;\r\n+  Threads::threads_do(&amp;closure);\r\n+}<\/code><\/pre>\r\n+<p>HotSpot code has historically usually placed the DoSomething class at namespace (or sometimes class) scope. This separates the function's code from its use, often to the detriment of readability. It requires giving the class a globally unique name (if at namespace scope). It also loses the information that the class is intended for use in exactly one place, and does not have any subclasses. (However, the latter can now be indicated by declaring it <code>final<\/code>.) Often, for simplicity, a local class will skip things like access control and accessor functions, giving the enclosing function direct access to the implementation and eliminating some boilerplate that might be provided if the class is in some outer (more accessible) scope. On the other hand, if there is a lot of surrounding code in the function body or the local class is of significant size, defining it locally can increase clutter and reduce readability.<\/p>\r\n+<p><a name=\"lambdaexpressions\"><\/a> C++11 added <em>lambda expressions<\/em> as a new way to write a function object. Simple lambda expressions can be significantly more concise than a function object, eliminating a lot of boiler-plate. On the other hand, a complex lambda expression may not provide much, if any, readability benefit compared to an ordinary function object. Also, while a lambda can encapsulate a call to a &quot;function-like&quot; object, it cannot be used in place of such.<\/p>\r\n+<p>A common use for local functions is as one-use <a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/raii\" title=\"Resource Acquisition Is Initialization\">RAII<\/a> objects. The amount of boilerplate for a function object class (local or not) makes such usage somewhat clumsy and verbose. But with the help of a small amount of supporting utility code, lambdas work particularly well for this use case.<\/p>\r\n+<p>Another use for local functions is <a href=\"https:\/\/en.wikipedia.org\/wiki\/Partial_application\" title=\"Partial Application\">partial application<\/a>. Again here, lambdas are typically much simpler and less verbose than function object classes.<\/p>\r\n+<p>Because of these benefits, lambda expressions are permitted in HotSpot code, with some restrictions and usage guidance. An anonymous lambda is one which is passed directly as an argument. A named lambda is the value of a variable, which is its name.<\/p>\r\n+<p>Lambda expressions should only be passed downward. In particular, a lambda should not be returned from a function or stored in a global variable, whether directly or as the value of a member of some other object. Lambda capture is syntactically subtle (by design), and propagating a lambda in such ways can easily pass references to captured values to places where they are no longer valid. In particular, members of the enclosing <code>this<\/code> object are effectively captured by reference, even if the default capture is by-value. For such uses-cases a function object class should be used to make the desired value capturing and propagation explicit.<\/p>\r\n+<p>Limiting the capture list to <code>[&amp;]<\/code> (implicitly capture by reference) is a simplifying restriction that still provides good support for HotSpot usage, while reducing the cases a reader must recognize and understand.<\/p>\r\n+<ul>\r\n+<li><p>Many common lambda uses require reference capture. Not permitting it would substantially reduce the utility of lambdas.<\/p><\/li>\r\n+<li><p>Referential transparency. Implicit reference capture makes variable references in the lambda body have the same meaning they would have in the enclosing code. There isn't a semantic barrier across which the meaning of a variable changes.<\/p><\/li>\r\n+<li><p>Explicit reference capture introduces significant clutter, especially when lambda expressions are relatively small and simple, as they should be in HotSpot code.<\/p><\/li>\r\n+<li><p>There are a number of reasons why by-value capture might be used, but for the most part they don't apply to HotSpot code, given other usage restrictions.<\/p>\r\n+<ul>\r\n+<li><p>A primary use-case for by-value capture is to support escaping uses, where values captured by-reference might become invalid. That use-case doesn't apply if only downward lambdas are used.<\/p><\/li>\r\n+<li><p>By-value capture can also make a lambda-local copy for mutation, which requires making the lambda <code>mutable<\/code>; see below.<\/p><\/li>\r\n+<li><p>By-value capture might be viewed as an optimization, avoiding any overhead for reference capture of cheap to copy values. But the compiler can often eliminate any such overhead.<\/p><\/li>\r\n+<li><p>By-value capture by a non-<code>mutable<\/code> lambda makes the captured values const, preventing any modification by the lambda and making the captured value unaffected by modifications to the outer variable. But this only applies to captured auto variables, not member variables, and is inconsistent with referential transparency.<\/p><\/li>\r\n+<\/ul><\/li>\r\n+<li><p>Non-capturing lambdas (with an empty capture list - <code>[]<\/code>) have limited utility. There are cases where no captures are required (pure functions, for example), but if the function is small and simple then that's obvious anyway.<\/p><\/li>\r\n+<li><p>Capture initializers (a C++14 feature - <a href=\"https:\/\/isocpp.org\/files\/papers\/N3649.html\">N3649<\/a>) are not permitted. Capture initializers inherently increase the complexity of the capture list, and provide little benefit over an additional in-scope local variable.<\/p><\/li>\r\n+<\/ul>\r\n+<p>The use of <code>mutable<\/code> lambda expressions is forbidden because there don't seem to be many, if any, good use-cases for them in HotSpot. A lambda expression needs to be mutable in order to modify a by-value captured value. But with only downward lambdas, such usage seems likely to be rare and complicated. It is better to use a function object class in any such cases that arise, rather than requiring all HotSpot developers to understand this relatively obscure feature.<\/p>\r\n+<p>While it is possible to directly invoke an anonymous lambda expression, that feature should not be used, as such a form can be confusing to readers. Instead, name the lambda and call it by name.<\/p>\r\n+<p>Some reasons to prefer a named lambda instead of an anonymous lambda are<\/p>\r\n+<ul>\r\n+<li><p>The body contains non-trivial control flow or declarations or other nested constructs.<\/p><\/li>\r\n+<li><p>Its role in an argument list is hard to guess without examining the function declaration. Give it a name that indicates its purpose.<\/p><\/li>\r\n+<li><p>It has an unusual capture list.<\/p><\/li>\r\n+<li><p>It has a complex explicit return type or parameter types.<\/p><\/li>\r\n+<\/ul>\r\n+<p>Lambda expressions, and particularly anonymous lambda expressions, should be simple and compact. One-liners are good. Anonymous lambdas should usually be limited to a couple lines of body code. More complex lambdas should be named. A named lambda should not clutter the enclosing function and make it long and complex; do continue to break up large functions via the use of separate helper functions.<\/p>\r\n+<p>An anonymous lambda expression should either be a one-liner in a one-line expression, or isolated in its own set of lines. Don't place part of a lambda expression on the same line as other arguments to a function. The body of a multi-line lambda argument should be indented from the start of the capture list, as if that were the start of an ordinary function definition. The body of a multi-line named lambda should be indented one step from the variable's indentation.<\/p>\r\n+<p>Some examples:<\/p>\r\n+<ol type=\"1\">\r\n+<li><code>foo([&amp;] { ++counter; });<\/code><\/li>\r\n+<li><code>foo(x, [&amp;] { ++counter; });<\/code><\/li>\r\n+<li><code>foo([&amp;] { if (predicate) ++counter; });<\/code><\/li>\r\n+<li><code>foo([&amp;] { auto tmp = process(x); tmp.f(); return tmp.g(); })<\/code><\/li>\r\n+<li><p>Separate one-line lambda from other arguments:<\/p>\r\n+<pre><code>foo(c.begin(), c.end(),\r\n+    [&amp;] (const X&amp; x) { do_something(x); return x.value(); });<\/code><\/pre><\/li>\r\n+<li><p>Indentation for multi-line lambda:<\/p>\r\n+<pre><code>c.do_entries([&amp;] (const X&amp; x) {\r\n+               do_something(x, a);\r\n+               do_something1(x, b);\r\n+               do_something2(x, c);\r\n+             });<\/code><\/pre><\/li>\r\n+<li><p>Separate multi-line lambda from other arguments:<\/p>\r\n+<pre><code>foo(c.begin(), c.end(),\r\n+    [&amp;] (const X&amp; x) {\r\n+      do_something(x, a);\r\n+      do_something1(x, b);\r\n+      do_something2(x, c);\r\n+    });<\/code><\/pre><\/li>\r\n+<li><p>Multi-line named lambda:<\/p>\r\n+<pre><code>auto do_entry = [&amp;] (const X&amp; x) {\r\n+  do_something(x, a);\r\n+  do_something1(x, b);\r\n+  do_something2(x, c);\r\n+};<\/code><\/pre><\/li>\r\n+<\/ol>\r\n+<p>Item 4, and especially items 6 and 7, are pushing the simplicity limits for anonymous lambdas. Item 6 might be better written using a named lambda:<\/p>\r\n+<pre><code>c.do_entries(do_entry);<\/code><\/pre>\r\n+<p>Note that C++11 also added <em>bind expressions<\/em> as a way to write a function object for partial application, using <code>std::bind<\/code> and related facilities from the Standard Library. <code>std::bind<\/code> generalizes and replaces some of the binders from C++03. Bind expressions are not permitted in HotSpot code. They don't provide enough benefit over lambdas or local function classes in the cases where bind expressions are applicable to warrant the introduction of yet another mechanism in this space into HotSpot code.<\/p>\r\n+<p>References:<\/p>\r\n+<ul>\r\n+<li>Local and unnamed types as template parameters (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2657.htm\">n2657<\/a>)<\/li>\r\n+<li>New wording for C++0x lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2009\/n2927.pdf\">n2927<\/a>)<\/li>\r\n+<li>Generalized lambda capture (init-capture) (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3648.html\">N3648<\/a>)<\/li>\r\n+<li>Generic (polymorphic) lambda expressions (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3649.html\">N3649<\/a>)<\/li>\r\n+<\/ul>\r\n+<p>References from C++17<\/p>\r\n+<ul>\r\n+<li>Wording for constexpr lambda (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2016\/p0170r1.pdf\">p0170r1<\/a>)<\/li>\r\n+<li>Lambda capture of *this by Value (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2016\/p0018r3.html\">p0018r3<\/a>)<\/li>\r\n+<\/ul>\r\n+<p>References from C++20<\/p>\r\n+<ul>\r\n+<li>Allow lambda capture [=, this] (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0409r2.html\">p0409r2<\/a>)<\/li>\r\n+<li>Familiar template syntax for generic lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0428r2.pdf\">p0428r2<\/a>)<\/li>\r\n+<li>Simplifying implicit lambda capture (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0588r1.html\">p0588r1<\/a>)<\/li>\r\n+<li>Default constructible and assignable stateless lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0624r2.pdf\">p0624r2<\/a>)<\/li>\r\n+<li>Lambdas in unevaluated contexts (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2017\/p0315r4.pdf\">p0315r4<\/a>)<\/li>\r\n+<li>Allow pack expansion in lambda init-capture (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2018\/p0780r2.html\">p0780r2<\/a>) (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2020\/p2095r0.html\">p2095r0<\/a>)<\/li>\r\n+<li>Deprecate implicit capture of this via [=] (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2018\/p0806r2.html\">p0806r2<\/a>)<\/li>\r\n+<\/ul>\r\n+<p>References from C++23<\/p>\r\n+<ul>\r\n+<li>Make () more optional for lambdas (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2020\/p1102r2.html\">p1102r2<\/a>)<\/li>\r\n+<\/ul>\r\n+<h3 id=\"additional-permitted-features\">Additional Permitted Features<\/h3>\r\n+<ul>\r\n+<li><p><code>constexpr<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2235.pdf\">n2235<\/a>) (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3652.html\">n3652<\/a>)<\/p><\/li>\r\n+<li><p>Sized deallocation (<a href=\"https:\/\/isocpp.org\/files\/papers\/n3778.html\">n3778<\/a>)<\/p><\/li>\r\n+<li><p>Variadic templates (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2242.pdf\">n2242<\/a>) (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2555.pdf\">n2555<\/a>)<\/p><\/li>\r\n+<li><p>Static assertions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2004\/n1720.html\">n1720<\/a>)<\/p><\/li>\r\n+<li><p><code>decltype<\/code> (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2343.pdf\">n2343<\/a>) (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2011\/n3276.pdf\">n3276<\/a>)<\/p><\/li>\r\n+<li><p>Right angle brackets (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2005\/n1757.html\">n1757<\/a>)<\/p><\/li>\r\n+<li><p>Default template arguments for function templates (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/cwg_defects.html#226\">CWG D226<\/a>)<\/p><\/li>\r\n+<li><p>Template aliases (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2258.pdf\">n2258<\/a>)<\/p><\/li>\r\n+<li><p>Delegating constructors (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2006\/n1986.pdf\">n1986<\/a>)<\/p><\/li>\r\n+<li><p>Explicit conversion operators (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2437.pdf\">n2437<\/a>)<\/p><\/li>\r\n+<li><p>Standard Layout Types (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2342.htm\">n2342<\/a>)<\/p><\/li>\r\n+<li><p>Defaulted and deleted functions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2346.htm\">n2346<\/a>)<\/p><\/li>\r\n+<li><p>Dynamic initialization and destruction with concurrency (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2660.htm\">n2660<\/a>)<\/p><\/li>\r\n+<li><p><code>final<\/code> virtual specifiers for classes and virtual functions (<a href=\"http:\/\/www.open-std.org\/JTC1\/SC22\/WG21\/docs\/papers\/2009\/n2928.htm\">n2928<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2010\/n3206.htm\">n3206<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2011\/n3272.htm\">n3272<\/a>)<\/p><\/li>\r\n+<li><p><code>override<\/code> virtual specifiers for virtual functions (<a href=\"http:\/\/www.open-std.org\/JTC1\/SC22\/WG21\/docs\/papers\/2009\/n2928.htm\">n2928<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2010\/n3206.htm\">n3206<\/a>), (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2011\/n3272.htm\">n3272<\/a>)<\/p><\/li>\r\n+<li><p>Range-based <code>for<\/code> loops (<a href=\"http:\/\/www.open-std.org\/JTC1\/SC22\/WG21\/docs\/papers\/2009\/n2930.html\">n2930<\/a>) (<a href=\"https:\/\/en.cppreference.com\/w\/cpp\/language\/range-for\">range-for<\/a>)<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"excluded-features\">Excluded Features<\/h3>\r\n+<ul>\r\n+<li>New string and character literals\r\n+<ul>\r\n+<li>New character types (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2249.html\">n2249<\/a>)<\/li>\r\n+<li>Unicode string literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2442.htm\">n2442<\/a>)<\/li>\r\n+<li>Raw string literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2442.htm\">n2442<\/a>)<\/li>\r\n+<li>Universal character name literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2170.html\">n2170<\/a>)<\/li>\r\n+<\/ul>\r\n+<p>HotSpot doesn't need any of the new character and string literal types.<\/p><\/li>\r\n+<li><p>User-defined literals (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2765.pdf\">n2765<\/a>) — User-defined literals should not be added casually, but only through a proposal to add a specific UDL.<\/p><\/li>\r\n+<li><p>Inline namespaces (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2535.htm\">n2535<\/a>) — HotSpot makes very limited use of namespaces.<\/p><\/li>\r\n+<li><p><code>using namespace<\/code> directives. In particular, don't use <code>using namespace std;<\/code> to avoid needing to qualify Standard Library names.<\/p><\/li>\r\n+<li><p>Propagating exceptions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2007\/n2179.html\">n2179<\/a>) — HotSpot does not permit the use of exceptions, so this feature isn't useful.<\/p><\/li>\r\n+<li><p>Avoid namespace-scoped variables with non-constexpr initialization. In particular, avoid variables with types requiring non-trivial initialization or destruction. Initialization order problems can be difficult to deal with and lead to surprises, as can destruction ordering. HotSpot doesn't generally try to cleanup on exit, and running destructors at exit can also lead to problems.<\/p><\/li>\r\n+<li><p><code>[[deprecated]]<\/code> attribute (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2013\/n3760.html\">n3760<\/a>) — Not relevant in HotSpot code.<\/p><\/li>\r\n+<li><p>Avoid most operator overloading, preferring named functions. When operator overloading is used, ensure the semantics conform to the normal expected behavior of the operation.<\/p><\/li>\r\n+<li><p>Avoid most implicit conversion constructors and (implicit or explicit) conversion operators. (Note that conversion to <code>bool<\/code> isn't needed in HotSpot code because of the &quot;no implicit boolean&quot; guideline.)<\/p><\/li>\r\n+<li><p>Avoid covariant return types.<\/p><\/li>\r\n+<li><p>Avoid <code>goto<\/code> statements.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"undecided-features\">Undecided Features<\/h3>\r\n+<p>This list is incomplete; it serves to explicitly call out some features that have not yet been discussed.<\/p>\r\n+<ul>\r\n+<li><p>Trailing return type syntax for functions (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2541.htm\">n2541<\/a>)<\/p><\/li>\r\n+<li><p>Variable templates (<a href=\"https:\/\/isocpp.org\/files\/papers\/N3651.pdf\">n3651<\/a>)<\/p><\/li>\r\n+<li><p>Member initializers and aggregates (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2013\/n3653.html\">n3653<\/a>)<\/p><\/li>\r\n+<li><p><code>[[noreturn]]<\/code> attribute (<a href=\"http:\/\/www.open-std.org\/jtc1\/sc22\/wg21\/docs\/papers\/2008\/n2761.pdf\">n2761<\/a>)<\/p><\/li>\r\n+<li><p>Rvalue references and move semantics<\/p><\/li>\r\n+<\/ul>\r\n+<\/body>\r\n+<\/html>\r\n","filename":"doc\/hotspot-style.html","additions":458,"deletions":458,"binary":false,"changes":916,"status":"modified"},{"patch":"@@ -1,223 +1,223 @@\n-<!DOCTYPE html>\n-<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\n-<head>\n-  <meta charset=\"utf-8\" \/>\n-  <meta name=\"generator\" content=\"pandoc\" \/>\n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\n-  <title>Native\/Unit Test Development Guidelines<\/title>\n-  <style type=\"text\/css\">\n-      code{white-space: pre-wrap;}\n-      span.smallcaps{font-variant: small-caps;}\n-      span.underline{text-decoration: underline;}\n-      div.column{display: inline-block; vertical-align: top; width: 50%;}\n-  <\/style>\n-  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\n-  <!--[if lt IE 9]>\n-    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\n-  <![endif]-->\n-<\/head>\n-<body>\n-<header id=\"title-block-header\">\n-<h1 class=\"title\">Native\/Unit Test Development Guidelines<\/h1>\n-<\/header>\n-<nav id=\"TOC\">\n-<ul>\n-<li><a href=\"#good-test-properties\">Good test properties<\/a><ul>\n-<li><a href=\"#lightness\">Lightness<\/a><\/li>\n-<li><a href=\"#isolation\">Isolation<\/a><\/li>\n-<li><a href=\"#atomicity-and-self-containment\">Atomicity and self-containment<\/a><\/li>\n-<li><a href=\"#repeatability\">Repeatability<\/a><\/li>\n-<li><a href=\"#informativeness\">Informativeness<\/a><\/li>\n-<li><a href=\"#testing-instead-of-visiting\">Testing instead of visiting<\/a><\/li>\n-<li><a href=\"#nearness\">Nearness<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#asserts\">Asserts<\/a><ul>\n-<li><a href=\"#several-checks\">Several checks<\/a><\/li>\n-<li><a href=\"#first-parameter-is-expected-value\">First parameter is expected value<\/a><\/li>\n-<li><a href=\"#floating-point-comparison\">Floating-point comparison<\/a><\/li>\n-<li><a href=\"#c-string-comparison\">C string comparison<\/a><\/li>\n-<li><a href=\"#error-messages\">Error messages<\/a><\/li>\n-<li><a href=\"#uncluttered-output\">Uncluttered output<\/a><\/li>\n-<li><a href=\"#failures-propagation\">Failures propagation<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#naming-and-grouping\">Naming and Grouping<\/a><ul>\n-<li><a href=\"#test-group-names\">Test group names<\/a><\/li>\n-<li><a href=\"#filename\">Filename<\/a><\/li>\n-<li><a href=\"#file-location\">File location<\/a><\/li>\n-<li><a href=\"#test-names\">Test names<\/a><\/li>\n-<li><a href=\"#fixture-classes\">Fixture classes<\/a><\/li>\n-<li><a href=\"#friend-classes\">Friend classes<\/a><\/li>\n-<li><a href=\"#oscpu-specific-tests\">OS\/CPU specific tests<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#miscellaneous\">Miscellaneous<\/a><ul>\n-<li><a href=\"#hotspot-style\">Hotspot style<\/a><\/li>\n-<li><a href=\"#codetest-metrics\">Code\/test metrics<\/a><\/li>\n-<li><a href=\"#access-to-non-public-members\">Access to non-public members<\/a><\/li>\n-<li><a href=\"#death-tests\">Death tests<\/a><\/li>\n-<li><a href=\"#external-flags\">External flags<\/a><\/li>\n-<li><a href=\"#test-specific-flags\">Test-specific flags<\/a><\/li>\n-<li><a href=\"#flag-restoring\">Flag restoring<\/a><\/li>\n-<li><a href=\"#googletest-documentation\">GoogleTest documentation<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#todo\">TODO<\/a><\/li>\n-<\/ul>\n-<\/nav>\n-<p>The purpose of these guidelines is to establish a shared vision on what kind of native tests and how we want to develop them for Hotspot using GoogleTest. Hence these guidelines include style items as well as test approach items.<\/p>\n-<p>First section of this document describes properties of good tests which are common for almost all types of test regardless of language, framework, etc. Further sections provide recommendations to achieve those properties and other HotSpot and\/or GoogleTest specific guidelines.<\/p>\n-<h2 id=\"good-test-properties\">Good test properties<\/h2>\n-<h3 id=\"lightness\">Lightness<\/h3>\n-<p>Use the most lightweight type of tests.<\/p>\n-<p>In Hotspot, there are 3 different types of tests regarding their dependency on a JVM, each next level is slower than previous<\/p>\n-<ul>\n-<li><p><code>TEST<\/code> : a test does not depend on a JVM<\/p><\/li>\n-<li><p><code>TEST_VM<\/code> : a test does depend on an initialized JVM, but are supposed not to break a JVM, i.e. leave it in a workable state.<\/p><\/li>\n-<li><p><code>TEST_OTHER_VM<\/code> : a test depends on a JVM and requires a freshly initialized JVM or leaves a JVM in non-workable state<\/p><\/li>\n-<\/ul>\n-<h3 id=\"isolation\">Isolation<\/h3>\n-<p>Tests have to be isolated: not to have visible side-effects, influences on other tests results.<\/p>\n-<p>Results of one test should not depend on test execution order, other tests, otherwise it is becoming almost impossible to find out why a test failed. Due to hotspot-specific, it is not so easy to get a full isolation, e.g. we share an initialized JVM between all <code>TEST_VM<\/code> tests, so if your test changes JVM's state too drastically and does not change it back, you had better consider <code>TEST_OTHER_VM<\/code>.<\/p>\n-<h3 id=\"atomicity-and-self-containment\">Atomicity and self-containment<\/h3>\n-<p>Tests should be <em>atomic<\/em> and <em>self-contained<\/em> at the same time.<\/p>\n-<p>One test should check a particular part of a class, subsystem, functionality, etc. Then it is quite easy to determine what parts of a product are broken basing on test failures. On the other hand, a test should test that part more-or-less entirely, because when one sees a test <code>FooTest::bar<\/code>, they assume all aspects of bar from <code>Foo<\/code> are tested.<\/p>\n-<p>However, it is impossible to cover all aspects even of a method, not to mention a subsystem. In such cases, it is recommended to have several tests, one for each aspect of a thing under test. For example one test to tests how <code>Foo::bar<\/code> works if an argument is <code>null<\/code>, another test to test how it works if an argument is acceptable but <code>Foo<\/code> is not in the right state to accept it and so on. This helps not only to make tests atomic, self-contained but also makes test name self-descriptive (discussed in more details in <a href=\"#test-names\">Test names<\/a>).<\/p>\n-<h3 id=\"repeatability\">Repeatability<\/h3>\n-<p>Tests have to be repeatable.<\/p>\n-<p>Reproducibility is very crucial for a test. No one likes sporadic test failures, they are hard to investigate, fix and verify a fix.<\/p>\n-<p>In some cases, it is quite hard to write a 100% repeatable test, since besides a test there can be other moving parts, e.g. in case of <code>TEST_VM<\/code> there are several concurrently running threads. Despite this, we should try to make a test as reproducible as possible.<\/p>\n-<h3 id=\"informativeness\">Informativeness<\/h3>\n-<p>In case of a failure, a test should be as <em>informative<\/em> as possible.<\/p>\n-<p>Having more information about a test failure than just compared values can be very useful for failure troubleshooting, it can reduce or even completely eliminate debugging hours. This is even more important in case of not 100% reproducible failures.<\/p>\n-<p>Achieving this property, one can easily make a test too verbose, so it will be really hard to find useful information in the ocean of useless information. Hence they should not only think about how to provide <a href=\"#error-messages\">good information<\/a>, but also <a href=\"#uncluttered-output\">when to do it<\/a>.<\/p>\n-<h3 id=\"testing-instead-of-visiting\">Testing instead of visiting<\/h3>\n-<p>Tests should <em>test<\/em>.<\/p>\n-<p>It is not enough just to &quot;visit&quot; some code, a test should check that code does that it has to do, compare return values with expected values, check that desired side effects are done, and undesired are not, and so on. In other words, a test should contain at least one GoogleTest assertion and do not rely on JVM asserts.<\/p>\n-<p>Generally speaking to write a good test, one should create a model of the system under tests, a model of possible bugs (or bugs which one wants to find) and design tests using those models.<\/p>\n-<h3 id=\"nearness\">Nearness<\/h3>\n-<p>Prefer having checks inside test code.<\/p>\n-<p>Not only does having test logic outside, e.g. verification method, depending on asserts in product code contradict with several items above but also decreases test’s readability and stability. It is much easier to understand that a test is testing when all testing logic is located inside a test or nearby in shared test libraries. As a rule of thumb, the closer a check to a test, the better.<\/p>\n-<h2 id=\"asserts\">Asserts<\/h2>\n-<h3 id=\"several-checks\">Several checks<\/h3>\n-<p>Prefer <code>EXPECT<\/code> over <code>ASSERT<\/code> if possible.<\/p>\n-<p>This is related to the <a href=\"#informativeness\">informativeness<\/a> property of tests, information for other checks can help to better localize a defect’s root-cause. One should use <code>ASSERT<\/code> if it is impossible to continue test execution or if it does not make much sense. Later in the text, <code>EXPECT<\/code> forms will be used to refer to both <code>ASSERT\/EXPECT<\/code>.<\/p>\n-<p>When it is possible to make several different checks, but impossible to continue test execution if at least one check fails, you can use <code>::testing::Test::HasNonfatalFailure()<\/code> function. The recommended way to express that is <code>ASSERT_FALSE(::testing::Test::HasNonfatalFailure())<\/code>. Besides making it clear why a test is aborted, it also allows you to provide more information about a failure.<\/p>\n-<h3 id=\"first-parameter-is-expected-value\">First parameter is expected value<\/h3>\n-<p>In all equality assertions, expected values should be passed as the first parameter.<\/p>\n-<p>This convention is adopted by GoogleTest, and there is a slight difference in how GoogleTest treats parameters, the most important one is <code>null<\/code> detection. Due to different reasons, <code>null<\/code> detection is enabled only for the first parameter, that is to said <code>EXPECT_EQ(NULL, object)<\/code> checks that object is <code>null<\/code>, while <code>EXPECT_EQ(object, NULL)<\/code> checks that object equals to <code>NULL<\/code>, GoogleTest is very strict regarding types of compared values so the latter will generates a compile-time error.<\/p>\n-<h3 id=\"floating-point-comparison\">Floating-point comparison<\/h3>\n-<p>Use floating-point special macros to compare <code>float\/double<\/code> values.<\/p>\n-<p>Because of floating-point number representations and round-off errors, regular equality comparison will not return true in most cases. There are special <code>EXPECT_FLOAT_EQ\/EXPECT_DOUBLE_EQ<\/code> assertions which check that the distance between compared values is not more than 4 ULPs, there is also <code>EXPECT_NEAR(v1, v2, eps)<\/code> which checks that the absolute value of the difference between <code>v1<\/code> and <code>v2<\/code> is not greater than <code>eps<\/code>.<\/p>\n-<h3 id=\"c-string-comparison\">C string comparison<\/h3>\n-<p>Use string special macros for C strings comparisons.<\/p>\n-<p><code>EXPECT_EQ<\/code> just compares pointers’ values, which is hardly what one wants comparing C strings. GoogleTest provides <code>EXPECT_STREQ<\/code> and <code>EXPECT_STRNE<\/code> macros to compare C string contents. There are also case-insensitive versions <code>EXPECT_STRCASEEQ<\/code>, <code>EXPECT_STRCASENE<\/code>.<\/p>\n-<h3 id=\"error-messages\">Error messages<\/h3>\n-<p>Provide informative, but not too verbose error messages.<\/p>\n-<p>All GoogleTest asserts print compared expressions and their values, so there is no need to have them in error messages. Asserts print only compared values, they do not print any of interim variables, e.g. <code>ASSERT_TRUE((val1 == val2 &amp;&amp; isFail(foo(8)) || i == 18)<\/code> prints only one value. If you use some complex predicates, please consider <code>EXPECT_PRED*<\/code> or <code>EXPECT_FORMAT_PRED<\/code> assertions family, they check that a predicate returns true\/success and print out all parameters values.<\/p>\n-<p>However in some cases, default information is not enough, a commonly used example is an assert inside a loop, GoogleTest will not print iteration values (unless it is an assert's parameter). Other demonstrative examples are printing error code and a corresponding error message; printing internal states which might have an impact on results. One should add this information to assert message using <code>&lt;&lt;<\/code> operator.<\/p>\n-<h3 id=\"uncluttered-output\">Uncluttered output<\/h3>\n-<p>Print information only if it is needed.<\/p>\n-<p>Too verbose tests which print all information even if they pass are very bad practice. They just pollute output, so it becomes harder to find useful information. In order not print information till it is really needed, one should consider saving it to a temporary buffer and pass to an assert. <a href=\"https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/shared\/test_memset_with_concurrent_readers.cpp\" class=\"uri\">https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/shared\/test_memset_with_concurrent_readers.cpp<\/a> has a good example how to do that.<\/p>\n-<h3 id=\"failures-propagation\">Failures propagation<\/h3>\n-<p>Wrap a subroutine call into <code>EXPECT_NO_FATAL_FAILURE<\/code> macro to propagate failures.<\/p>\n-<p><code>ASSERT<\/code> and <code>FAIL<\/code> abort only the current function, so if you have them in a subroutine, a test will not be aborted after the subroutine even if <code>ASSERT<\/code> or <code>FAIL<\/code> fails. You should call such subroutines in <code>ASSERT_NO_FATAL_FAILURE<\/code> macro to propagate fatal failures and abort a test. <code>(EXPECT|ASSERT)_NO_FATAL_FAILURE<\/code> can also be used to provide more information.<\/p>\n-<p>Due to obvious reasons, there are no <code>(EXPECT|ASSERT)_NO_NONFATAL_FAILURE<\/code> macros. However, if you need to check if a subroutine generated a nonfatal failure (failed an <code>EXPECT<\/code>), you can use <code>::testing::Test::HasNonfatalFailure<\/code> function, or <code>::testing::Test::HasFailure<\/code> function to check if a subroutine generated any failures, see <a href=\"#several-checks\">Several checks<\/a>.<\/p>\n-<h2 id=\"naming-and-grouping\">Naming and Grouping<\/h2>\n-<h3 id=\"test-group-names\">Test group names<\/h3>\n-<p>Test group names should be in CamelCase, start and end with a letter. A test group should be named after tested class, functionality, subsystem, etc.<\/p>\n-<p>This naming scheme helps to find tests, filter them and simplifies test failure analysis. For example, class <code>Foo<\/code> - test group <code>Foo<\/code>, compiler logging subsystem - test group <code>CompilerLogging<\/code>, G1 GC — test group <code>G1GC<\/code>, and so forth.<\/p>\n-<h3 id=\"filename\">Filename<\/h3>\n-<p>A test file must have <code>test_<\/code> prefix and <code>.cpp<\/code> suffix.<\/p>\n-<p>Both are actually requirements from the current build system to recognize your tests.<\/p>\n-<h3 id=\"file-location\">File location<\/h3>\n-<p>Test file location should reflect a location of the tested part of the product.<\/p>\n-<ul>\n-<li><p>All unit tests for a class from <code>foo\/bar\/baz.cpp<\/code> should be placed <code>foo\/bar\/test_baz.cpp<\/code> in <code>hotspot\/test\/native\/<\/code> directory. Having all tests for a class in one file is a common practice for unit tests, it helps to see all existing tests at once, share functions and\/or resources without losing encapsulation.<\/p><\/li>\n-<li><p>For tests which test more than one class, directory hierarchy should be the same as product hierarchy, and file name should reflect the name of the tested subsystem\/functionality. For example, if a sub-system under tests belongs to <code>gc\/g1<\/code>, tests should be placed in <code>gc\/g1<\/code> directory.<\/p><\/li>\n-<\/ul>\n-<p>Please note that framework prepends directory name to a test group name. For example, if <code>TEST(foo, check_this)<\/code> and <code>TEST(bar, check_that)<\/code> are defined in <code>hotspot\/test\/native\/gc\/shared\/test_foo.cpp<\/code> file, they will be reported as <code>gc\/shared\/foo::check_this<\/code> and <code>gc\/shared\/bar::check_that<\/code>.<\/p>\n-<h3 id=\"test-names\">Test names<\/h3>\n-<p>Test names should be in small_snake_case, start and end with a letter. A test name should reflect that a test checks.<\/p>\n-<p>Such naming makes tests self-descriptive and helps a lot during the whole test life cycle. It is easy to do test planning, test inventory, to see what things are not tested, to review tests, to analyze test failures, to evolve a test, etc. For example <code>foo_return_0_if_name_is_null<\/code> is better than <code>foo_sanity<\/code> or <code>foo_basic<\/code> or just <code>foo<\/code>, <code>humongous_objects_can_not_be_moved_by_young_gc<\/code> is better than <code>ho_young_gc<\/code>.<\/p>\n-<p>Actually using underscore is against GoogleTest project convention, because it can lead to illegal identifiers, however, this is too strict. Restricting usage of underscore for test names only and prohibiting test name starts or ends with an underscore are enough to be safe.<\/p>\n-<h3 id=\"fixture-classes\">Fixture classes<\/h3>\n-<p>Fixture classes should be named after tested classes, subsystems, etc (follow <a href=\"#test-group-names\">Test group names rule<\/a>) and have <code>Test<\/code> suffix to prevent class name conflicts.<\/p>\n-<h3 id=\"friend-classes\">Friend classes<\/h3>\n-<p>All test purpose friends should have either <code>Test<\/code> or <code>Testable<\/code> suffix.<\/p>\n-<p>It greatly simplifies understanding of friendship’s purpose and allows statically check that private members are not exposed unexpectedly. Having <code>FooTest<\/code> as a friend of <code>Foo<\/code> without any comments will be understood as a necessary evil to get testability.<\/p>\n-<h3 id=\"oscpu-specific-tests\">OS\/CPU specific tests<\/h3>\n-<p>Guard OS\/CPU specific tests by <code>#ifdef<\/code> and have OS\/CPU name in filename.<\/p>\n-<p>For the time being, we do not support separate directories for OS, CPU, OS-CPU specific tests, in case we will have lots of such tests, we will change directory layout and build system to support that in the same way it is done in hotspot.<\/p>\n-<h2 id=\"miscellaneous\">Miscellaneous<\/h2>\n-<h3 id=\"hotspot-style\">Hotspot style<\/h3>\n-<p>Abide the norms and rules accepted in Hotspot style guide.<\/p>\n-<p>Tests are a part of Hotspot, so everything (if applicable) we use for Hotspot, should be used for tests as well. Those guidelines cover test-specific things.<\/p>\n-<h3 id=\"codetest-metrics\">Code\/test metrics<\/h3>\n-<p>Coverage information and other code\/test metrics are quite useful to decide what tests should be written, what tests should be improved and what can be removed.<\/p>\n-<p>For unit tests, widely used and well-known coverage metric is branch coverage, which provides good quality of tests with relatively easy test development process. For other levels of testing, branch coverage is not as good, and one should consider others metrics, e.g. transaction flow coverage, data flow coverage.<\/p>\n-<h3 id=\"access-to-non-public-members\">Access to non-public members<\/h3>\n-<p>Use explicit friend class to get access to non-public members.<\/p>\n-<p>We do not use GoogleTest macro to declare friendship relation, because, from our point of view, it is less clear than an explicit declaration.<\/p>\n-<p>Declaring a test fixture class as a friend class of a tested test is the easiest and the clearest way to get access. However, it has some disadvantages, here is some of them:<\/p>\n-<ul>\n-<li>Each test has to be declared as a friend<\/li>\n-<li>Subclasses do not inheritance friendship relation<\/li>\n-<\/ul>\n-<p>In other words, it is harder to share code between tests. Hence if you want to share code or expect it to be useful in other tests, you should consider making members in a tested class protected and introduce a shared test-only class which expose those members via public functions, or even making members publicly accessible right away in a product class. If it is not an option to change members visibility, one can create a friend class which exposes members.<\/p>\n-<h3 id=\"death-tests\">Death tests<\/h3>\n-<p>You can not use death tests inside <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code>.<\/p>\n-<p>We tried to make Hotspot-GoogleTest integration as transparent as possible, however, due to the current implementation of <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code> tests, you cannot use death test functionality in them. These tests are implemented as GoogleTest death tests, and GoogleTest does not allow to have a death test inside another death test.<\/p>\n-<h3 id=\"external-flags\">External flags<\/h3>\n-<p>Passing external flags to a tested JVM is not supported.<\/p>\n-<p>The rationality of such design decision is to simplify both tests and a test framework and to avoid failures related to incompatible flags combination till there is a good solution for that. However there are cases when one wants to test a JVM with specific flags combination, <code>_JAVA_OPTIONS<\/code> environment variable can be used to do that. Flags from <code>_JAVA_OPTIONS<\/code> will be used in <code>TEST_VM<\/code>, <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code> tests.<\/p>\n-<h3 id=\"test-specific-flags\">Test-specific flags<\/h3>\n-<p>Passing flags to a tested JVM in <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code> should be possible, but is not implemented yet.<\/p>\n-<p>Facility to pass test-specific flags is needed for system, regression or other types of tests which require a fully initialized JVM in some particular configuration, e.g. with Serial GC selected. There is no support for such tests now, however, there is a plan to add that in upcoming releases.<\/p>\n-<p>For now, if a test depends on flags values, it should have <code>if (!&lt;flag&gt;) { return }<\/code> guards in the very beginning and <code>@requires<\/code> comment similar to jtreg <code>@requires<\/code> directive right before test macros. <a href=\"https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/g1\/test_g1IHOPControl.cpp\" class=\"uri\">https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/g1\/test_g1IHOPControl.cpp<\/a> ha an example of this temporary workaround. It is important to follow that pattern as it allows us to easily find all such tests and update them as soon as there is an implementation of flag passing facility.<\/p>\n-<p>In long-term, we expect jtreg to support GoogleTest tests as first class citizens, that is to say, jtreg will parse <span class=\"citation\" data-cites=\"requires\">@requires<\/span> comments and filter out inapplicable tests.<\/p>\n-<h3 id=\"flag-restoring\">Flag restoring<\/h3>\n-<p>Restore changed flags.<\/p>\n-<p>It is quite common for tests to configure JVM in a certain way changing flags’ values. GoogleTest provides two ways to set up environment before a test and restore it afterward: using either constructor and destructor or <code>SetUp<\/code> and <code>TearDown<\/code> functions. Both ways require to use a test fixture class, which sometimes is too wordy. The simpler facilities like <code>FLAG_GUARD<\/code> macro or <code>*FlagSetting<\/code> classes could be used in such cases to restore\/set values.<\/p>\n-<p>Caveats:<\/p>\n-<ul>\n-<li><p>Changing a flag’s value could break the invariants between flags' values and hence could lead to unexpected\/unsupported JVM state.<\/p><\/li>\n-<li><p><code>FLAG_SET_*<\/code> macros can change more than one flag (in order to maintain invariants) so it is hard to predict what flags will be changed and it makes restoring all changed flags a nontrivial task. Thus in case one uses <code>FLAG_SET_*<\/code> macros, they should use <code>TEST_OTHER_VM<\/code> test type.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"googletest-documentation\">GoogleTest documentation<\/h3>\n-<p>In case you have any questions regarding GoogleTest itself, its asserts, test declaration macros, other macros, etc, please consult its documentation.<\/p>\n-<h2 id=\"todo\">TODO<\/h2>\n-<p>Although this document provides guidelines on the most important parts of test development using GTest, it still misses a few items:<\/p>\n-<ul>\n-<li><p>Examples, esp for <a href=\"#access-to-non-public-members\">access to non-public members<\/a><\/p><\/li>\n-<li>test types: purpose, drawbacks, limitation\n-<ul>\n-<li><code>TEST_VM<\/code><\/li>\n-<li><code>TEST_VM_F<\/code><\/li>\n-<li><code>TEST_OTHER_VM<\/code><\/li>\n-<li><code>TEST_VM_ASSERT<\/code><\/li>\n-<li><code>TEST_VM_ASSERT_MSG<\/code><\/li>\n-<\/ul><\/li>\n-<li>Miscellaneous\n-<ul>\n-<li>Test libraries\n-<ul>\n-<li>where to place<\/li>\n-<li>how to write<\/li>\n-<li>how to use<\/li>\n-<\/ul><\/li>\n-<li>test your tests\n-<ul>\n-<li>how to run tests in random order<\/li>\n-<li>how to run only specific tests<\/li>\n-<li>how to run each test separately<\/li>\n-<li>check that a test can find bugs it is supposed to by introducing them<\/li>\n-<\/ul><\/li>\n-<li>mocks\/stubs\/dependency injection<\/li>\n-<li>setUp\/tearDown\n-<ul>\n-<li>vs c-tor\/d-tor<\/li>\n-<li>empty test to test them<\/li>\n-<\/ul><\/li>\n-<li>internal (declared in .cpp) struct\/classes<\/li>\n-<\/ul><\/li>\n-<\/ul>\n-<\/body>\n-<\/html>\n+<!DOCTYPE html>\r\n+<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\r\n+<head>\r\n+  <meta charset=\"utf-8\" \/>\r\n+  <meta name=\"generator\" content=\"pandoc\" \/>\r\n+  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\r\n+  <title>Native\/Unit Test Development Guidelines<\/title>\r\n+  <style type=\"text\/css\">\r\n+      code{white-space: pre-wrap;}\r\n+      span.smallcaps{font-variant: small-caps;}\r\n+      span.underline{text-decoration: underline;}\r\n+      div.column{display: inline-block; vertical-align: top; width: 50%;}\r\n+  <\/style>\r\n+  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\r\n+  <!--[if lt IE 9]>\r\n+    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\r\n+  <![endif]-->\r\n+<\/head>\r\n+<body>\r\n+<header>\r\n+<h1 class=\"title\">Native\/Unit Test Development Guidelines<\/h1>\r\n+<\/header>\r\n+<nav id=\"TOC\">\r\n+<ul>\r\n+<li><a href=\"#good-test-properties\">Good test properties<\/a><ul>\r\n+<li><a href=\"#lightness\">Lightness<\/a><\/li>\r\n+<li><a href=\"#isolation\">Isolation<\/a><\/li>\r\n+<li><a href=\"#atomicity-and-self-containment\">Atomicity and self-containment<\/a><\/li>\r\n+<li><a href=\"#repeatability\">Repeatability<\/a><\/li>\r\n+<li><a href=\"#informativeness\">Informativeness<\/a><\/li>\r\n+<li><a href=\"#testing-instead-of-visiting\">Testing instead of visiting<\/a><\/li>\r\n+<li><a href=\"#nearness\">Nearness<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#asserts\">Asserts<\/a><ul>\r\n+<li><a href=\"#several-checks\">Several checks<\/a><\/li>\r\n+<li><a href=\"#first-parameter-is-expected-value\">First parameter is expected value<\/a><\/li>\r\n+<li><a href=\"#floating-point-comparison\">Floating-point comparison<\/a><\/li>\r\n+<li><a href=\"#c-string-comparison\">C string comparison<\/a><\/li>\r\n+<li><a href=\"#error-messages\">Error messages<\/a><\/li>\r\n+<li><a href=\"#uncluttered-output\">Uncluttered output<\/a><\/li>\r\n+<li><a href=\"#failures-propagation\">Failures propagation<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#naming-and-grouping\">Naming and Grouping<\/a><ul>\r\n+<li><a href=\"#test-group-names\">Test group names<\/a><\/li>\r\n+<li><a href=\"#filename\">Filename<\/a><\/li>\r\n+<li><a href=\"#file-location\">File location<\/a><\/li>\r\n+<li><a href=\"#test-names\">Test names<\/a><\/li>\r\n+<li><a href=\"#fixture-classes\">Fixture classes<\/a><\/li>\r\n+<li><a href=\"#friend-classes\">Friend classes<\/a><\/li>\r\n+<li><a href=\"#oscpu-specific-tests\">OS\/CPU specific tests<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#miscellaneous\">Miscellaneous<\/a><ul>\r\n+<li><a href=\"#hotspot-style\">Hotspot style<\/a><\/li>\r\n+<li><a href=\"#codetest-metrics\">Code\/test metrics<\/a><\/li>\r\n+<li><a href=\"#access-to-non-public-members\">Access to non-public members<\/a><\/li>\r\n+<li><a href=\"#death-tests\">Death tests<\/a><\/li>\r\n+<li><a href=\"#external-flags\">External flags<\/a><\/li>\r\n+<li><a href=\"#test-specific-flags\">Test-specific flags<\/a><\/li>\r\n+<li><a href=\"#flag-restoring\">Flag restoring<\/a><\/li>\r\n+<li><a href=\"#googletest-documentation\">GoogleTest documentation<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#todo\">TODO<\/a><\/li>\r\n+<\/ul>\r\n+<\/nav>\r\n+<p>The purpose of these guidelines is to establish a shared vision on what kind of native tests and how we want to develop them for Hotspot using GoogleTest. Hence these guidelines include style items as well as test approach items.<\/p>\r\n+<p>First section of this document describes properties of good tests which are common for almost all types of test regardless of language, framework, etc. Further sections provide recommendations to achieve those properties and other HotSpot and\/or GoogleTest specific guidelines.<\/p>\r\n+<h2 id=\"good-test-properties\">Good test properties<\/h2>\r\n+<h3 id=\"lightness\">Lightness<\/h3>\r\n+<p>Use the most lightweight type of tests.<\/p>\r\n+<p>In Hotspot, there are 3 different types of tests regarding their dependency on a JVM, each next level is slower than previous<\/p>\r\n+<ul>\r\n+<li><p><code>TEST<\/code> : a test does not depend on a JVM<\/p><\/li>\r\n+<li><p><code>TEST_VM<\/code> : a test does depend on an initialized JVM, but are supposed not to break a JVM, i.e. leave it in a workable state.<\/p><\/li>\r\n+<li><p><code>TEST_OTHER_VM<\/code> : a test depends on a JVM and requires a freshly initialized JVM or leaves a JVM in non-workable state<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"isolation\">Isolation<\/h3>\r\n+<p>Tests have to be isolated: not to have visible side-effects, influences on other tests results.<\/p>\r\n+<p>Results of one test should not depend on test execution order, other tests, otherwise it is becoming almost impossible to find out why a test failed. Due to hotspot-specific, it is not so easy to get a full isolation, e.g. we share an initialized JVM between all <code>TEST_VM<\/code> tests, so if your test changes JVM's state too drastically and does not change it back, you had better consider <code>TEST_OTHER_VM<\/code>.<\/p>\r\n+<h3 id=\"atomicity-and-self-containment\">Atomicity and self-containment<\/h3>\r\n+<p>Tests should be <em>atomic<\/em> and <em>self-contained<\/em> at the same time.<\/p>\r\n+<p>One test should check a particular part of a class, subsystem, functionality, etc. Then it is quite easy to determine what parts of a product are broken basing on test failures. On the other hand, a test should test that part more-or-less entirely, because when one sees a test <code>FooTest::bar<\/code>, they assume all aspects of bar from <code>Foo<\/code> are tested.<\/p>\r\n+<p>However, it is impossible to cover all aspects even of a method, not to mention a subsystem. In such cases, it is recommended to have several tests, one for each aspect of a thing under test. For example one test to tests how <code>Foo::bar<\/code> works if an argument is <code>null<\/code>, another test to test how it works if an argument is acceptable but <code>Foo<\/code> is not in the right state to accept it and so on. This helps not only to make tests atomic, self-contained but also makes test name self-descriptive (discussed in more details in <a href=\"#test-names\">Test names<\/a>).<\/p>\r\n+<h3 id=\"repeatability\">Repeatability<\/h3>\r\n+<p>Tests have to be repeatable.<\/p>\r\n+<p>Reproducibility is very crucial for a test. No one likes sporadic test failures, they are hard to investigate, fix and verify a fix.<\/p>\r\n+<p>In some cases, it is quite hard to write a 100% repeatable test, since besides a test there can be other moving parts, e.g. in case of <code>TEST_VM<\/code> there are several concurrently running threads. Despite this, we should try to make a test as reproducible as possible.<\/p>\r\n+<h3 id=\"informativeness\">Informativeness<\/h3>\r\n+<p>In case of a failure, a test should be as <em>informative<\/em> as possible.<\/p>\r\n+<p>Having more information about a test failure than just compared values can be very useful for failure troubleshooting, it can reduce or even completely eliminate debugging hours. This is even more important in case of not 100% reproducible failures.<\/p>\r\n+<p>Achieving this property, one can easily make a test too verbose, so it will be really hard to find useful information in the ocean of useless information. Hence they should not only think about how to provide <a href=\"#error-messages\">good information<\/a>, but also <a href=\"#uncluttered-output\">when to do it<\/a>.<\/p>\r\n+<h3 id=\"testing-instead-of-visiting\">Testing instead of visiting<\/h3>\r\n+<p>Tests should <em>test<\/em>.<\/p>\r\n+<p>It is not enough just to &quot;visit&quot; some code, a test should check that code does that it has to do, compare return values with expected values, check that desired side effects are done, and undesired are not, and so on. In other words, a test should contain at least one GoogleTest assertion and do not rely on JVM asserts.<\/p>\r\n+<p>Generally speaking to write a good test, one should create a model of the system under tests, a model of possible bugs (or bugs which one wants to find) and design tests using those models.<\/p>\r\n+<h3 id=\"nearness\">Nearness<\/h3>\r\n+<p>Prefer having checks inside test code.<\/p>\r\n+<p>Not only does having test logic outside, e.g. verification method, depending on asserts in product code contradict with several items above but also decreases test’s readability and stability. It is much easier to understand that a test is testing when all testing logic is located inside a test or nearby in shared test libraries. As a rule of thumb, the closer a check to a test, the better.<\/p>\r\n+<h2 id=\"asserts\">Asserts<\/h2>\r\n+<h3 id=\"several-checks\">Several checks<\/h3>\r\n+<p>Prefer <code>EXPECT<\/code> over <code>ASSERT<\/code> if possible.<\/p>\r\n+<p>This is related to the <a href=\"#informativeness\">informativeness<\/a> property of tests, information for other checks can help to better localize a defect’s root-cause. One should use <code>ASSERT<\/code> if it is impossible to continue test execution or if it does not make much sense. Later in the text, <code>EXPECT<\/code> forms will be used to refer to both <code>ASSERT\/EXPECT<\/code>.<\/p>\r\n+<p>When it is possible to make several different checks, but impossible to continue test execution if at least one check fails, you can use <code>::testing::Test::HasNonfatalFailure()<\/code> function. The recommended way to express that is <code>ASSERT_FALSE(::testing::Test::HasNonfatalFailure())<\/code>. Besides making it clear why a test is aborted, it also allows you to provide more information about a failure.<\/p>\r\n+<h3 id=\"first-parameter-is-expected-value\">First parameter is expected value<\/h3>\r\n+<p>In all equality assertions, expected values should be passed as the first parameter.<\/p>\r\n+<p>This convention is adopted by GoogleTest, and there is a slight difference in how GoogleTest treats parameters, the most important one is <code>null<\/code> detection. Due to different reasons, <code>null<\/code> detection is enabled only for the first parameter, that is to said <code>EXPECT_EQ(NULL, object)<\/code> checks that object is <code>null<\/code>, while <code>EXPECT_EQ(object, NULL)<\/code> checks that object equals to <code>NULL<\/code>, GoogleTest is very strict regarding types of compared values so the latter will generates a compile-time error.<\/p>\r\n+<h3 id=\"floating-point-comparison\">Floating-point comparison<\/h3>\r\n+<p>Use floating-point special macros to compare <code>float\/double<\/code> values.<\/p>\r\n+<p>Because of floating-point number representations and round-off errors, regular equality comparison will not return true in most cases. There are special <code>EXPECT_FLOAT_EQ\/EXPECT_DOUBLE_EQ<\/code> assertions which check that the distance between compared values is not more than 4 ULPs, there is also <code>EXPECT_NEAR(v1, v2, eps)<\/code> which checks that the absolute value of the difference between <code>v1<\/code> and <code>v2<\/code> is not greater than <code>eps<\/code>.<\/p>\r\n+<h3 id=\"c-string-comparison\">C string comparison<\/h3>\r\n+<p>Use string special macros for C strings comparisons.<\/p>\r\n+<p><code>EXPECT_EQ<\/code> just compares pointers’ values, which is hardly what one wants comparing C strings. GoogleTest provides <code>EXPECT_STREQ<\/code> and <code>EXPECT_STRNE<\/code> macros to compare C string contents. There are also case-insensitive versions <code>EXPECT_STRCASEEQ<\/code>, <code>EXPECT_STRCASENE<\/code>.<\/p>\r\n+<h3 id=\"error-messages\">Error messages<\/h3>\r\n+<p>Provide informative, but not too verbose error messages.<\/p>\r\n+<p>All GoogleTest asserts print compared expressions and their values, so there is no need to have them in error messages. Asserts print only compared values, they do not print any of interim variables, e.g. <code>ASSERT_TRUE((val1 == val2 &amp;&amp; isFail(foo(8)) || i == 18)<\/code> prints only one value. If you use some complex predicates, please consider <code>EXPECT_PRED*<\/code> or <code>EXPECT_FORMAT_PRED<\/code> assertions family, they check that a predicate returns true\/success and print out all parameters values.<\/p>\r\n+<p>However in some cases, default information is not enough, a commonly used example is an assert inside a loop, GoogleTest will not print iteration values (unless it is an assert's parameter). Other demonstrative examples are printing error code and a corresponding error message; printing internal states which might have an impact on results. One should add this information to assert message using <code>&lt;&lt;<\/code> operator.<\/p>\r\n+<h3 id=\"uncluttered-output\">Uncluttered output<\/h3>\r\n+<p>Print information only if it is needed.<\/p>\r\n+<p>Too verbose tests which print all information even if they pass are very bad practice. They just pollute output, so it becomes harder to find useful information. In order not print information till it is really needed, one should consider saving it to a temporary buffer and pass to an assert. <a href=\"https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/shared\/test_memset_with_concurrent_readers.cpp\" class=\"uri\">https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/shared\/test_memset_with_concurrent_readers.cpp<\/a> has a good example how to do that.<\/p>\r\n+<h3 id=\"failures-propagation\">Failures propagation<\/h3>\r\n+<p>Wrap a subroutine call into <code>EXPECT_NO_FATAL_FAILURE<\/code> macro to propagate failures.<\/p>\r\n+<p><code>ASSERT<\/code> and <code>FAIL<\/code> abort only the current function, so if you have them in a subroutine, a test will not be aborted after the subroutine even if <code>ASSERT<\/code> or <code>FAIL<\/code> fails. You should call such subroutines in <code>ASSERT_NO_FATAL_FAILURE<\/code> macro to propagate fatal failures and abort a test. <code>(EXPECT|ASSERT)_NO_FATAL_FAILURE<\/code> can also be used to provide more information.<\/p>\r\n+<p>Due to obvious reasons, there are no <code>(EXPECT|ASSERT)_NO_NONFATAL_FAILURE<\/code> macros. However, if you need to check if a subroutine generated a nonfatal failure (failed an <code>EXPECT<\/code>), you can use <code>::testing::Test::HasNonfatalFailure<\/code> function, or <code>::testing::Test::HasFailure<\/code> function to check if a subroutine generated any failures, see <a href=\"#several-checks\">Several checks<\/a>.<\/p>\r\n+<h2 id=\"naming-and-grouping\">Naming and Grouping<\/h2>\r\n+<h3 id=\"test-group-names\">Test group names<\/h3>\r\n+<p>Test group names should be in CamelCase, start and end with a letter. A test group should be named after tested class, functionality, subsystem, etc.<\/p>\r\n+<p>This naming scheme helps to find tests, filter them and simplifies test failure analysis. For example, class <code>Foo<\/code> - test group <code>Foo<\/code>, compiler logging subsystem - test group <code>CompilerLogging<\/code>, G1 GC — test group <code>G1GC<\/code>, and so forth.<\/p>\r\n+<h3 id=\"filename\">Filename<\/h3>\r\n+<p>A test file must have <code>test_<\/code> prefix and <code>.cpp<\/code> suffix.<\/p>\r\n+<p>Both are actually requirements from the current build system to recognize your tests.<\/p>\r\n+<h3 id=\"file-location\">File location<\/h3>\r\n+<p>Test file location should reflect a location of the tested part of the product.<\/p>\r\n+<ul>\r\n+<li><p>All unit tests for a class from <code>foo\/bar\/baz.cpp<\/code> should be placed <code>foo\/bar\/test_baz.cpp<\/code> in <code>hotspot\/test\/native\/<\/code> directory. Having all tests for a class in one file is a common practice for unit tests, it helps to see all existing tests at once, share functions and\/or resources without losing encapsulation.<\/p><\/li>\r\n+<li><p>For tests which test more than one class, directory hierarchy should be the same as product hierarchy, and file name should reflect the name of the tested subsystem\/functionality. For example, if a sub-system under tests belongs to <code>gc\/g1<\/code>, tests should be placed in <code>gc\/g1<\/code> directory.<\/p><\/li>\r\n+<\/ul>\r\n+<p>Please note that framework prepends directory name to a test group name. For example, if <code>TEST(foo, check_this)<\/code> and <code>TEST(bar, check_that)<\/code> are defined in <code>hotspot\/test\/native\/gc\/shared\/test_foo.cpp<\/code> file, they will be reported as <code>gc\/shared\/foo::check_this<\/code> and <code>gc\/shared\/bar::check_that<\/code>.<\/p>\r\n+<h3 id=\"test-names\">Test names<\/h3>\r\n+<p>Test names should be in small_snake_case, start and end with a letter. A test name should reflect that a test checks.<\/p>\r\n+<p>Such naming makes tests self-descriptive and helps a lot during the whole test life cycle. It is easy to do test planning, test inventory, to see what things are not tested, to review tests, to analyze test failures, to evolve a test, etc. For example <code>foo_return_0_if_name_is_null<\/code> is better than <code>foo_sanity<\/code> or <code>foo_basic<\/code> or just <code>foo<\/code>, <code>humongous_objects_can_not_be_moved_by_young_gc<\/code> is better than <code>ho_young_gc<\/code>.<\/p>\r\n+<p>Actually using underscore is against GoogleTest project convention, because it can lead to illegal identifiers, however, this is too strict. Restricting usage of underscore for test names only and prohibiting test name starts or ends with an underscore are enough to be safe.<\/p>\r\n+<h3 id=\"fixture-classes\">Fixture classes<\/h3>\r\n+<p>Fixture classes should be named after tested classes, subsystems, etc (follow <a href=\"#test-group-names\">Test group names rule<\/a>) and have <code>Test<\/code> suffix to prevent class name conflicts.<\/p>\r\n+<h3 id=\"friend-classes\">Friend classes<\/h3>\r\n+<p>All test purpose friends should have either <code>Test<\/code> or <code>Testable<\/code> suffix.<\/p>\r\n+<p>It greatly simplifies understanding of friendship’s purpose and allows statically check that private members are not exposed unexpectedly. Having <code>FooTest<\/code> as a friend of <code>Foo<\/code> without any comments will be understood as a necessary evil to get testability.<\/p>\r\n+<h3 id=\"oscpu-specific-tests\">OS\/CPU specific tests<\/h3>\r\n+<p>Guard OS\/CPU specific tests by <code>#ifdef<\/code> and have OS\/CPU name in filename.<\/p>\r\n+<p>For the time being, we do not support separate directories for OS, CPU, OS-CPU specific tests, in case we will have lots of such tests, we will change directory layout and build system to support that in the same way it is done in hotspot.<\/p>\r\n+<h2 id=\"miscellaneous\">Miscellaneous<\/h2>\r\n+<h3 id=\"hotspot-style\">Hotspot style<\/h3>\r\n+<p>Abide the norms and rules accepted in Hotspot style guide.<\/p>\r\n+<p>Tests are a part of Hotspot, so everything (if applicable) we use for Hotspot, should be used for tests as well. Those guidelines cover test-specific things.<\/p>\r\n+<h3 id=\"codetest-metrics\">Code\/test metrics<\/h3>\r\n+<p>Coverage information and other code\/test metrics are quite useful to decide what tests should be written, what tests should be improved and what can be removed.<\/p>\r\n+<p>For unit tests, widely used and well-known coverage metric is branch coverage, which provides good quality of tests with relatively easy test development process. For other levels of testing, branch coverage is not as good, and one should consider others metrics, e.g. transaction flow coverage, data flow coverage.<\/p>\r\n+<h3 id=\"access-to-non-public-members\">Access to non-public members<\/h3>\r\n+<p>Use explicit friend class to get access to non-public members.<\/p>\r\n+<p>We do not use GoogleTest macro to declare friendship relation, because, from our point of view, it is less clear than an explicit declaration.<\/p>\r\n+<p>Declaring a test fixture class as a friend class of a tested test is the easiest and the clearest way to get access. However, it has some disadvantages, here is some of them:<\/p>\r\n+<ul>\r\n+<li>Each test has to be declared as a friend<\/li>\r\n+<li>Subclasses do not inheritance friendship relation<\/li>\r\n+<\/ul>\r\n+<p>In other words, it is harder to share code between tests. Hence if you want to share code or expect it to be useful in other tests, you should consider making members in a tested class protected and introduce a shared test-only class which expose those members via public functions, or even making members publicly accessible right away in a product class. If it is not an option to change members visibility, one can create a friend class which exposes members.<\/p>\r\n+<h3 id=\"death-tests\">Death tests<\/h3>\r\n+<p>You can not use death tests inside <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code>.<\/p>\r\n+<p>We tried to make Hotspot-GoogleTest integration as transparent as possible, however, due to the current implementation of <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code> tests, you cannot use death test functionality in them. These tests are implemented as GoogleTest death tests, and GoogleTest does not allow to have a death test inside another death test.<\/p>\r\n+<h3 id=\"external-flags\">External flags<\/h3>\r\n+<p>Passing external flags to a tested JVM is not supported.<\/p>\r\n+<p>The rationality of such design decision is to simplify both tests and a test framework and to avoid failures related to incompatible flags combination till there is a good solution for that. However there are cases when one wants to test a JVM with specific flags combination, <code>_JAVA_OPTIONS<\/code> environment variable can be used to do that. Flags from <code>_JAVA_OPTIONS<\/code> will be used in <code>TEST_VM<\/code>, <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code> tests.<\/p>\r\n+<h3 id=\"test-specific-flags\">Test-specific flags<\/h3>\r\n+<p>Passing flags to a tested JVM in <code>TEST_OTHER_VM<\/code> and <code>TEST_VM_ASSERT*<\/code> should be possible, but is not implemented yet.<\/p>\r\n+<p>Facility to pass test-specific flags is needed for system, regression or other types of tests which require a fully initialized JVM in some particular configuration, e.g. with Serial GC selected. There is no support for such tests now, however, there is a plan to add that in upcoming releases.<\/p>\r\n+<p>For now, if a test depends on flags values, it should have <code>if (!&lt;flag&gt;) { return }<\/code> guards in the very beginning and <code>@requires<\/code> comment similar to jtreg <code>@requires<\/code> directive right before test macros. <a href=\"https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/g1\/test_g1IHOPControl.cpp\" class=\"uri\">https:\/\/hg.openjdk.java.net\/jdk\/jdk\/file\/tip\/test\/hotspot\/gtest\/gc\/g1\/test_g1IHOPControl.cpp<\/a> ha an example of this temporary workaround. It is important to follow that pattern as it allows us to easily find all such tests and update them as soon as there is an implementation of flag passing facility.<\/p>\r\n+<p>In long-term, we expect jtreg to support GoogleTest tests as first class citizens, that is to say, jtreg will parse <span class=\"citation\" data-cites=\"requires\">@requires<\/span> comments and filter out inapplicable tests.<\/p>\r\n+<h3 id=\"flag-restoring\">Flag restoring<\/h3>\r\n+<p>Restore changed flags.<\/p>\r\n+<p>It is quite common for tests to configure JVM in a certain way changing flags’ values. GoogleTest provides two ways to set up environment before a test and restore it afterward: using either constructor and destructor or <code>SetUp<\/code> and <code>TearDown<\/code> functions. Both ways require to use a test fixture class, which sometimes is too wordy. The simpler facilities like <code>FLAG_GUARD<\/code> macro or <code>*FlagSetting<\/code> classes could be used in such cases to restore\/set values.<\/p>\r\n+<p>Caveats:<\/p>\r\n+<ul>\r\n+<li><p>Changing a flag’s value could break the invariants between flags' values and hence could lead to unexpected\/unsupported JVM state.<\/p><\/li>\r\n+<li><p><code>FLAG_SET_*<\/code> macros can change more than one flag (in order to maintain invariants) so it is hard to predict what flags will be changed and it makes restoring all changed flags a nontrivial task. Thus in case one uses <code>FLAG_SET_*<\/code> macros, they should use <code>TEST_OTHER_VM<\/code> test type.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"googletest-documentation\">GoogleTest documentation<\/h3>\r\n+<p>In case you have any questions regarding GoogleTest itself, its asserts, test declaration macros, other macros, etc, please consult its documentation.<\/p>\r\n+<h2 id=\"todo\">TODO<\/h2>\r\n+<p>Although this document provides guidelines on the most important parts of test development using GTest, it still misses a few items:<\/p>\r\n+<ul>\r\n+<li><p>Examples, esp for <a href=\"#access-to-non-public-members\">access to non-public members<\/a><\/p><\/li>\r\n+<li>test types: purpose, drawbacks, limitation\r\n+<ul>\r\n+<li><code>TEST_VM<\/code><\/li>\r\n+<li><code>TEST_VM_F<\/code><\/li>\r\n+<li><code>TEST_OTHER_VM<\/code><\/li>\r\n+<li><code>TEST_VM_ASSERT<\/code><\/li>\r\n+<li><code>TEST_VM_ASSERT_MSG<\/code><\/li>\r\n+<\/ul><\/li>\r\n+<li>Miscellaneous\r\n+<ul>\r\n+<li>Test libraries\r\n+<ul>\r\n+<li>where to place<\/li>\r\n+<li>how to write<\/li>\r\n+<li>how to use<\/li>\r\n+<\/ul><\/li>\r\n+<li>test your tests\r\n+<ul>\r\n+<li>how to run tests in random order<\/li>\r\n+<li>how to run only specific tests<\/li>\r\n+<li>how to run each test separately<\/li>\r\n+<li>check that a test can find bugs it is supposed to by introducing them<\/li>\r\n+<\/ul><\/li>\r\n+<li>mocks\/stubs\/dependency injection<\/li>\r\n+<li>setUp\/tearDown\r\n+<ul>\r\n+<li>vs c-tor\/d-tor<\/li>\r\n+<li>empty test to test them<\/li>\r\n+<\/ul><\/li>\r\n+<li>internal (declared in .cpp) struct\/classes<\/li>\r\n+<\/ul><\/li>\r\n+<\/ul>\r\n+<\/body>\r\n+<\/html>\r\n","filename":"doc\/hotspot-unit-tests.html","additions":223,"deletions":223,"binary":false,"changes":446,"status":"modified"},{"patch":"@@ -1,60 +1,60 @@\n-<!DOCTYPE html>\n-<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\n-<head>\n-  <meta charset=\"utf-8\" \/>\n-  <meta name=\"generator\" content=\"pandoc\" \/>\n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\n-  <title>IDE support in the JDK<\/title>\n-  <style type=\"text\/css\">\n-      code{white-space: pre-wrap;}\n-      span.smallcaps{font-variant: small-caps;}\n-      span.underline{text-decoration: underline;}\n-      div.column{display: inline-block; vertical-align: top; width: 50%;}\n-  <\/style>\n-  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\n-  <!--[if lt IE 9]>\n-    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\n-  <![endif]-->\n-<\/head>\n-<body>\n-<header id=\"title-block-header\">\n-<h1 class=\"title\">IDE support in the JDK<\/h1>\n-<\/header>\n-<nav id=\"TOC\">\n-<ul>\n-<li><a href=\"#introduction\">Introduction<\/a><ul>\n-<li><a href=\"#ide-support-for-native-code\">IDE support for native code<\/a><\/li>\n-<li><a href=\"#ide-support-for-java-code\">IDE support for Java code<\/a><\/li>\n-<\/ul><\/li>\n-<\/ul>\n-<\/nav>\n-<h2 id=\"introduction\">Introduction<\/h2>\n-<p>When you are familiar with building and testing the JDK, you may want to configure an IDE to work with the source code. The instructions differ a bit depending on whether you are interested in working with the native (C\/C++) or the Java code.<\/p>\n-<h3 id=\"ide-support-for-native-code\">IDE support for native code<\/h3>\n-<p>There are a few ways to generate IDE configuration for the native sources, depending on which IDE to use.<\/p>\n-<h4 id=\"visual-studio-code\">Visual Studio Code<\/h4>\n-<p>The make system can generate a <a href=\"https:\/\/code.visualstudio.com\">Visual Studio Code<\/a> workspace that has C\/C++ source indexing configured correctly, as well as launcher targets for tests and the Java launcher. After configuring, a workspace for the configuration can be generated using:<\/p>\n-<pre class=\"shell\"><code>make vscode-project<\/code><\/pre>\n-<p>This creates a file called <code>jdk.code-workspace<\/code> in the build output folder. The full location will be printed after the workspace has been generated. To use it, choose <code>File -&gt; Open Workspace...<\/code> in Visual Studio Code.<\/p>\n-<h5 id=\"alternative-indexers\">Alternative indexers<\/h5>\n-<p>The main <code>vscode-project<\/code> target configures the default C++ support in Visual Studio Code. There are also other source indexers that can be installed, that may provide additional features. It's currently possible to generate configuration for two such indexers, <a href=\"https:\/\/clang.llvm.org\/extra\/clangd\/\">clangd<\/a> and <a href=\"https:\/\/github.com\/Andersbakken\/rtags\">rtags<\/a>. These can be configured by appending the name of the indexer to the make target, such as:<\/p>\n-<pre class=\"shell\"><code>make vscode-project-clangd<\/code><\/pre>\n-<p>Additional instructions for configuring the given indexer will be displayed after the workspace has been generated.<\/p>\n-<h4 id=\"visual-studio\">Visual Studio<\/h4>\n-<p>The make system can generate a Visual Studio project for the Hotspot native source. After configuring, the project is generated using:<\/p>\n-<pre class=\"shell\"><code>make hotspot-ide-project<\/code><\/pre>\n-<p>This creates a file named <code>jvm.vcxproj<\/code> in <code>ide\\hotspot-visualstudio<\/code> subfolder of the build output folder. The file can be opened in Visual Studio via <code>File -&gt; Open -&gt; Project\/Solution<\/code>.<\/p>\n-<h4 id=\"compilation-database\">Compilation Database<\/h4>\n-<p>The make system can generate generic native code indexing support in the form of a <a href=\"https:\/\/clang.llvm.org\/docs\/JSONCompilationDatabase.html\">Compilation Database<\/a> that can be used by many different IDEs and source code indexers.<\/p>\n-<pre class=\"shell\"><code>make compile-commands<\/code><\/pre>\n-<p>It's also possible to generate the Compilation Database for the HotSpot source code only, which is a bit faster as it includes less information.<\/p>\n-<pre class=\"shell\"><code>make compile-commands-hotspot<\/code><\/pre>\n-<h3 id=\"ide-support-for-java-code\">IDE support for Java code<\/h3>\n-<h4 id=\"intellij-idea\">IntelliJ IDEA<\/h4>\n-<p>The JDK project has a script that can be used for indexing the project with IntelliJ. After configuring and building the JDK, an IntelliJ workspace can be generated by running the following command in the top-level folder of the cloned repository:<\/p>\n-<pre class=\"shell\"><code>bash bin\/idea.sh<\/code><\/pre>\n-<p>To use it, choose <code>File -&gt; Open...<\/code> in IntelliJ and select the folder where you ran the above script.<\/p>\n-<p>Next, configure the project SDK in IntelliJ. Open <code>File -&gt; Project Structure -&gt; Project<\/code> and select <code>build\/&lt;config&gt;\/images\/jdk<\/code> as the SDK to use.<\/p>\n-<p>In order to run the tests from the IDE, you can use the JTReg plugin. Instructions for building and using the plugin can be found <a href=\"https:\/\/github.com\/openjdk\/jtreg\/tree\/master\/plugins\/idea\">here<\/a>.<\/p>\n-<\/body>\n-<\/html>\n+<!DOCTYPE html>\r\n+<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\r\n+<head>\r\n+  <meta charset=\"utf-8\" \/>\r\n+  <meta name=\"generator\" content=\"pandoc\" \/>\r\n+  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\r\n+  <title>IDE support in the JDK<\/title>\r\n+  <style type=\"text\/css\">\r\n+      code{white-space: pre-wrap;}\r\n+      span.smallcaps{font-variant: small-caps;}\r\n+      span.underline{text-decoration: underline;}\r\n+      div.column{display: inline-block; vertical-align: top; width: 50%;}\r\n+  <\/style>\r\n+  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\r\n+  <!--[if lt IE 9]>\r\n+    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\r\n+  <![endif]-->\r\n+<\/head>\r\n+<body>\r\n+<header>\r\n+<h1 class=\"title\">IDE support in the JDK<\/h1>\r\n+<\/header>\r\n+<nav id=\"TOC\">\r\n+<ul>\r\n+<li><a href=\"#introduction\">Introduction<\/a><ul>\r\n+<li><a href=\"#ide-support-for-native-code\">IDE support for native code<\/a><\/li>\r\n+<li><a href=\"#ide-support-for-java-code\">IDE support for Java code<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<\/ul>\r\n+<\/nav>\r\n+<h2 id=\"introduction\">Introduction<\/h2>\r\n+<p>When you are familiar with building and testing the JDK, you may want to configure an IDE to work with the source code. The instructions differ a bit depending on whether you are interested in working with the native (C\/C++) or the Java code.<\/p>\r\n+<h3 id=\"ide-support-for-native-code\">IDE support for native code<\/h3>\r\n+<p>There are a few ways to generate IDE configuration for the native sources, depending on which IDE to use.<\/p>\r\n+<h4 id=\"visual-studio-code\">Visual Studio Code<\/h4>\r\n+<p>The make system can generate a <a href=\"https:\/\/code.visualstudio.com\">Visual Studio Code<\/a> workspace that has C\/C++ source indexing configured correctly, as well as launcher targets for tests and the Java launcher. After configuring, a workspace for the configuration can be generated using:<\/p>\r\n+<pre class=\"shell\"><code>make vscode-project<\/code><\/pre>\r\n+<p>This creates a file called <code>jdk.code-workspace<\/code> in the build output folder. The full location will be printed after the workspace has been generated. To use it, choose <code>File -&gt; Open Workspace...<\/code> in Visual Studio Code.<\/p>\r\n+<h5 id=\"alternative-indexers\">Alternative indexers<\/h5>\r\n+<p>The main <code>vscode-project<\/code> target configures the default C++ support in Visual Studio Code. There are also other source indexers that can be installed, that may provide additional features. It's currently possible to generate configuration for two such indexers, <a href=\"https:\/\/clang.llvm.org\/extra\/clangd\/\">clangd<\/a> and <a href=\"https:\/\/github.com\/Andersbakken\/rtags\">rtags<\/a>. These can be configured by appending the name of the indexer to the make target, such as:<\/p>\r\n+<pre class=\"shell\"><code>make vscode-project-clangd<\/code><\/pre>\r\n+<p>Additional instructions for configuring the given indexer will be displayed after the workspace has been generated.<\/p>\r\n+<h4 id=\"visual-studio\">Visual Studio<\/h4>\r\n+<p>The make system can generate a Visual Studio project for the Hotspot native source. After configuring, the project is generated using:<\/p>\r\n+<pre class=\"shell\"><code>make hotspot-ide-project<\/code><\/pre>\r\n+<p>This creates a file named <code>jvm.vcxproj<\/code> in <code>ide\\hotspot-visualstudio<\/code> subfolder of the build output folder. The file can be opened in Visual Studio via <code>File -&gt; Open -&gt; Project\/Solution<\/code>.<\/p>\r\n+<h4 id=\"compilation-database\">Compilation Database<\/h4>\r\n+<p>The make system can generate generic native code indexing support in the form of a <a href=\"https:\/\/clang.llvm.org\/docs\/JSONCompilationDatabase.html\">Compilation Database<\/a> that can be used by many different IDEs and source code indexers.<\/p>\r\n+<pre class=\"shell\"><code>make compile-commands<\/code><\/pre>\r\n+<p>It's also possible to generate the Compilation Database for the HotSpot source code only, which is a bit faster as it includes less information.<\/p>\r\n+<pre class=\"shell\"><code>make compile-commands-hotspot<\/code><\/pre>\r\n+<h3 id=\"ide-support-for-java-code\">IDE support for Java code<\/h3>\r\n+<h4 id=\"intellij-idea\">IntelliJ IDEA<\/h4>\r\n+<p>The JDK project has a script that can be used for indexing the project with IntelliJ. After configuring and building the JDK, an IntelliJ workspace can be generated by running the following command in the top-level folder of the cloned repository:<\/p>\r\n+<pre class=\"shell\"><code>bash bin\/idea.sh<\/code><\/pre>\r\n+<p>To use it, choose <code>File -&gt; Open...<\/code> in IntelliJ and select the folder where you ran the above script.<\/p>\r\n+<p>Next, configure the project SDK in IntelliJ. Open <code>File -&gt; Project Structure -&gt; Project<\/code> and select <code>build\/&lt;config&gt;\/images\/jdk<\/code> as the SDK to use.<\/p>\r\n+<p>In order to run the tests from the IDE, you can use the JTReg plugin. Instructions for building and using the plugin can be found <a href=\"https:\/\/github.com\/openjdk\/jtreg\/tree\/master\/plugins\/idea\">here<\/a>.<\/p>\r\n+<\/body>\r\n+<\/html>\r\n","filename":"doc\/ide.html","additions":60,"deletions":60,"binary":false,"changes":120,"status":"modified"},{"patch":"@@ -1,255 +1,255 @@\n-<!DOCTYPE html>\n-<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\n-<head>\n-  <meta charset=\"utf-8\" \/>\n-  <meta name=\"generator\" content=\"pandoc\" \/>\n-  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\n-  <title>Testing the JDK<\/title>\n-  <style type=\"text\/css\">\n-      code{white-space: pre-wrap;}\n-      span.smallcaps{font-variant: small-caps;}\n-      span.underline{text-decoration: underline;}\n-      div.column{display: inline-block; vertical-align: top; width: 50%;}\n-  <\/style>\n-  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\n-  <!--[if lt IE 9]>\n-    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\n-  <![endif]-->\n-  <style type=\"text\/css\">pre, code, tt { color: #1d6ae5; }<\/style>\n-<\/head>\n-<body>\n-<header id=\"title-block-header\">\n-<h1 class=\"title\">Testing the JDK<\/h1>\n-<\/header>\n-<nav id=\"TOC\">\n-<ul>\n-<li><a href=\"#using-make-test-the-run-test-framework\">Using &quot;make test&quot; (the run-test framework)<\/a><ul>\n-<li><a href=\"#configuration\">Configuration<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#test-selection\">Test selection<\/a><ul>\n-<li><a href=\"#common-test-groups\">Common Test Groups<\/a><\/li>\n-<li><a href=\"#jtreg\">JTReg<\/a><\/li>\n-<li><a href=\"#gtest\">Gtest<\/a><\/li>\n-<li><a href=\"#microbenchmarks\">Microbenchmarks<\/a><\/li>\n-<li><a href=\"#special-tests\">Special tests<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#test-results-and-summary\">Test results and summary<\/a><\/li>\n-<li><a href=\"#test-suite-control\">Test suite control<\/a><ul>\n-<li><a href=\"#general-keywords-test_opts\">General keywords (TEST_OPTS)<\/a><\/li>\n-<li><a href=\"#jtreg-keywords\">JTReg keywords<\/a><\/li>\n-<li><a href=\"#gtest-keywords\">Gtest keywords<\/a><\/li>\n-<li><a href=\"#microbenchmark-keywords\">Microbenchmark keywords<\/a><\/li>\n-<\/ul><\/li>\n-<li><a href=\"#notes-for-specific-tests\">Notes for Specific Tests<\/a><ul>\n-<li><a href=\"#docker-tests\">Docker Tests<\/a><\/li>\n-<li><a href=\"#non-us-locale\">Non-US locale<\/a><\/li>\n-<li><a href=\"#pkcs11-tests\">PKCS11 Tests<\/a><\/li>\n-<li><a href=\"#client-ui-tests\">Client UI Tests<\/a><\/li>\n-<\/ul><\/li>\n-<\/ul>\n-<\/nav>\n-<h2 id=\"using-make-test-the-run-test-framework\">Using &quot;make test&quot; (the run-test framework)<\/h2>\n-<p>This new way of running tests is developer-centric. It assumes that you have built a JDK locally and want to test it. Running common test targets is simple, and more complex ad-hoc combination of tests is possible. The user interface is forgiving, and clearly report errors it cannot resolve.<\/p>\n-<p>The main target <code>test<\/code> uses the jdk-image as the tested product. There is also an alternate target <code>exploded-test<\/code> that uses the exploded image instead. Not all tests will run successfully on the exploded image, but using this target can greatly improve rebuild times for certain workflows.<\/p>\n-<p>Previously, <code>make test<\/code> was used to invoke an old system for running tests, and <code>make run-test<\/code> was used for the new test framework. For backward compatibility with scripts and muscle memory, <code>run-test<\/code> (and variants like <code>exploded-run-test<\/code> or <code>run-test-tier1<\/code>) are kept as aliases.<\/p>\n-<p>Some example command-lines:<\/p>\n-<pre><code>$ make test-tier1\n-$ make test-jdk_lang JTREG=&quot;JOBS=8&quot;\n-$ make test TEST=jdk_lang\n-$ make test-only TEST=&quot;gtest:LogTagSet gtest:LogTagSetDescriptions&quot; GTEST=&quot;REPEAT=-1&quot;\n-$ make test TEST=&quot;hotspot:hotspot_gc&quot; JTREG=&quot;JOBS=1;TIMEOUT_FACTOR=8;JAVA_OPTIONS=-XshowSettings -Xlog:gc+ref=debug&quot;\n-$ make test TEST=&quot;jtreg:test\/hotspot:hotspot_gc test\/hotspot\/jtreg\/native_sanity\/JniVersion.java&quot;\n-$ make test TEST=&quot;micro:java.lang.reflect&quot; MICRO=&quot;FORK=1;WARMUP_ITER=2&quot;\n-$ make exploded-test TEST=tier2<\/code><\/pre>\n-<h3 id=\"configuration\">Configuration<\/h3>\n-<p>To be able to run JTReg tests, <code>configure<\/code> needs to know where to find the JTReg test framework. If it is not picked up automatically by configure, use the <code>--with-jtreg=&lt;path to jtreg home&gt;<\/code> option to point to the JTReg framework. Note that this option should point to the JTReg home, i.e. the top directory, containing <code>lib\/jtreg.jar<\/code> etc. (An alternative is to set the <code>JT_HOME<\/code> environment variable to point to the JTReg home before running <code>configure<\/code>.)<\/p>\n-<p>To be able to run microbenchmarks, <code>configure<\/code> needs to know where to find the JMH dependency. Use <code>--with-jmh=&lt;path to JMH jars&gt;<\/code> to point to a directory containing the core JMH and transitive dependencies. The recommended dependencies can be retrieved by running <code>sh make\/devkit\/createJMHBundle.sh<\/code>, after which <code>--with-jmh=build\/jmh\/jars<\/code> should work.<\/p>\n-<h2 id=\"test-selection\">Test selection<\/h2>\n-<p>All functionality is available using the <code>test<\/code> make target. In this use case, the test or tests to be executed is controlled using the <code>TEST<\/code> variable. To speed up subsequent test runs with no source code changes, <code>test-only<\/code> can be used instead, which do not depend on the source and test image build.<\/p>\n-<p>For some common top-level tests, direct make targets have been generated. This includes all JTReg test groups, the hotspot gtest, and custom tests (if present). This means that <code>make test-tier1<\/code> is equivalent to <code>make test TEST=&quot;tier1&quot;<\/code>, but the latter is more tab-completion friendly. For more complex test runs, the <code>test TEST=&quot;x&quot;<\/code> solution needs to be used.<\/p>\n-<p>The test specifications given in <code>TEST<\/code> is parsed into fully qualified test descriptors, which clearly and unambigously show which tests will be run. As an example, <code>:tier1<\/code> will expand to <code>jtreg:$(TOPDIR)\/test\/hotspot\/jtreg:tier1 jtreg:$(TOPDIR)\/test\/jdk:tier1 jtreg:$(TOPDIR)\/test\/langtools:tier1 jtreg:$(TOPDIR)\/test\/nashorn:tier1 jtreg:$(TOPDIR)\/test\/jaxp:tier1<\/code>. You can always submit a list of fully qualified test descriptors in the <code>TEST<\/code> variable if you want to shortcut the parser.<\/p>\n-<h3 id=\"common-test-groups\">Common Test Groups<\/h3>\n-<p>Ideally, all tests are run for every change but this may not be practical due to the limited testing resources, the scope of the change, etc.<\/p>\n-<p>The source tree currently defines a few common test groups in the relevant <code>TEST.groups<\/code> files. There are test groups that cover a specific component, for example <code>hotspot_gc<\/code>. It is a good idea to look into <code>TEST.groups<\/code> files to get a sense what tests are relevant to a particular JDK component.<\/p>\n-<p>Component-specific tests may miss some unintended consequences of a change, so other tests should also be run. Again, it might be impractical to run all tests, and therefore <em>tiered<\/em> test groups exist. Tiered test groups are not component-specific, but rather cover the significant parts of the entire JDK.<\/p>\n-<p>Multiple tiers allow balancing test coverage and testing costs. Lower test tiers are supposed to contain the simpler, quicker and more stable tests. Higher tiers are supposed to contain progressively more thorough, slower, and sometimes less stable tests, or the tests that require special configuration.<\/p>\n-<p>Contributors are expected to run the tests for the areas that are changed, and the first N tiers they can afford to run, but at least tier1.<\/p>\n-<p>A brief description of the tiered test groups:<\/p>\n-<ul>\n-<li><p><code>tier1<\/code>: This is the lowest test tier. Multiple developers run these tests every day. Because of the widespread use, the tests in <code>tier1<\/code> are carefully selected and optimized to run fast, and to run in the most stable manner. The test failures in <code>tier1<\/code> are usually followed up on quickly, either with fixes, or adding relevant tests to problem list. GitHub Actions workflows, if enabled, run <code>tier1<\/code> tests.<\/p><\/li>\n-<li><p><code>tier2<\/code>: This test group covers even more ground. These contain, among other things, tests that either run for too long to be at <code>tier1<\/code>, or may require special configuration, or tests that are less stable, or cover the broader range of non-core JVM and JDK features\/components (for example, XML).<\/p><\/li>\n-<li><p><code>tier3<\/code>: This test group includes more stressful tests, the tests for corner cases not covered by previous tiers, plus the tests that require GUIs. As such, this suite should either be run with low concurrency (<code>TEST_JOBS=1<\/code>), or without headful tests (<code>JTREG_KEYWORDS=\\!headful<\/code>), or both.<\/p><\/li>\n-<li><p><code>tier4<\/code>: This test group includes every other test not covered by previous tiers. It includes, for example, <code>vmTestbase<\/code> suites for Hotspot, which run for many hours even on large machines. It also runs GUI tests, so the same <code>TEST_JOBS<\/code> and <code>JTREG_KEYWORDS<\/code> caveats apply.<\/p><\/li>\n-<\/ul>\n-<h3 id=\"jtreg\">JTReg<\/h3>\n-<p>JTReg tests can be selected either by picking a JTReg test group, or a selection of files or directories containing JTReg tests.<\/p>\n-<p>JTReg test groups can be specified either without a test root, e.g. <code>:tier1<\/code> (or <code>tier1<\/code>, the initial colon is optional), or with, e.g. <code>hotspot:tier1<\/code>, <code>test\/jdk:jdk_util<\/code> or <code>$(TOPDIR)\/test\/hotspot\/jtreg:hotspot_all<\/code>. The test root can be specified either as an absolute path, or a path relative to the JDK top directory, or the <code>test<\/code> directory. For simplicity, the hotspot JTReg test root, which really is <code>hotspot\/jtreg<\/code> can be abbreviated as just <code>hotspot<\/code>.<\/p>\n-<p>When specified without a test root, all matching groups from all test roots will be added. Otherwise, only the group from the specified test root will be added.<\/p>\n-<p>Individual JTReg tests or directories containing JTReg tests can also be specified, like <code>test\/hotspot\/jtreg\/native_sanity\/JniVersion.java<\/code> or <code>hotspot\/jtreg\/native_sanity<\/code>. Just like for test root selection, you can either specify an absolute path (which can even point to JTReg tests outside the source tree), or a path relative to either the JDK top directory or the <code>test<\/code> directory. <code>hotspot<\/code> can be used as an alias for <code>hotspot\/jtreg<\/code> here as well.<\/p>\n-<p>As long as the test groups or test paths can be uniquely resolved, you do not need to enter the <code>jtreg:<\/code> prefix. If this is not possible, or if you want to use a fully qualified test descriptor, add <code>jtreg:<\/code>, e.g. <code>jtreg:test\/hotspot\/jtreg\/native_sanity<\/code>.<\/p>\n-<h3 id=\"gtest\">Gtest<\/h3>\n-<p>Since the Hotspot Gtest suite is so quick, the default is to run all tests. This is specified by just <code>gtest<\/code>, or as a fully qualified test descriptor <code>gtest:all<\/code>.<\/p>\n-<p>If you want, you can single out an individual test or a group of tests, for instance <code>gtest:LogDecorations<\/code> or <code>gtest:LogDecorations.level_test_vm<\/code>. This can be particularly useful if you want to run a shaky test repeatedly.<\/p>\n-<p>For Gtest, there is a separate test suite for each JVM variant. The JVM variant is defined by adding <code>\/&lt;variant&gt;<\/code> to the test descriptor, e.g. <code>gtest:Log\/client<\/code>. If you specify no variant, gtest will run once for each JVM variant present (e.g. server, client). So if you only have the server JVM present, then <code>gtest:all<\/code> will be equivalent to <code>gtest:all\/server<\/code>.<\/p>\n-<h3 id=\"microbenchmarks\">Microbenchmarks<\/h3>\n-<p>Which microbenchmarks to run is selected using a regular expression following the <code>micro:<\/code> test descriptor, e.g., <code>micro:java.lang.reflect<\/code>. This delegates the test selection to JMH, meaning package name, class name and even benchmark method names can be used to select tests.<\/p>\n-<p>Using special characters like <code>|<\/code> in the regular expression is possible, but needs to be escaped multiple times: <code>micro:ArrayCopy\\\\\\\\\\|reflect<\/code>.<\/p>\n-<h3 id=\"special-tests\">Special tests<\/h3>\n-<p>A handful of odd tests that are not covered by any other testing framework are accessible using the <code>special:<\/code> test descriptor. Currently, this includes <code>failure-handler<\/code> and <code>make<\/code>.<\/p>\n-<ul>\n-<li><p>Failure handler testing is run using <code>special:failure-handler<\/code> or just <code>failure-handler<\/code> as test descriptor.<\/p><\/li>\n-<li><p>Tests for the build system, including both makefiles and related functionality, is run using <code>special:make<\/code> or just <code>make<\/code> as test descriptor. This is equivalent to <code>special:make:all<\/code>.<\/p>\n-<p>A specific make test can be run by supplying it as argument, e.g. <code>special:make:idea<\/code>. As a special syntax, this can also be expressed as <code>make-idea<\/code>, which allows for command lines as <code>make test-make-idea<\/code>.<\/p><\/li>\n-<\/ul>\n-<h2 id=\"test-results-and-summary\">Test results and summary<\/h2>\n-<p>At the end of the test run, a summary of all tests run will be presented. This will have a consistent look, regardless of what test suites were used. This is a sample summary:<\/p>\n-<pre><code>==============================\n-Test summary\n-==============================\n-   TEST                                          TOTAL  PASS  FAIL ERROR\n-&gt;&gt; jtreg:jdk\/test:tier1                           1867  1865     2     0 &lt;&lt;\n-   jtreg:langtools\/test:tier1                     4711  4711     0     0\n-   jtreg:nashorn\/test:tier1                        133   133     0     0\n-==============================\n-TEST FAILURE<\/code><\/pre>\n-<p>Tests where the number of TOTAL tests does not equal the number of PASSed tests will be considered a test failure. These are marked with the <code>&gt;&gt; ... &lt;&lt;<\/code> marker for easy identification.<\/p>\n-<p>The classification of non-passed tests differs a bit between test suites. In the summary, ERROR is used as a catch-all for tests that neither passed nor are classified as failed by the framework. This might indicate test framework error, timeout or other problems.<\/p>\n-<p>In case of test failures, <code>make test<\/code> will exit with a non-zero exit value.<\/p>\n-<p>All tests have their result stored in <code>build\/$BUILD\/test-results\/$TEST_ID<\/code>, where TEST_ID is a path-safe conversion from the fully qualified test descriptor, e.g. for <code>jtreg:jdk\/test:tier1<\/code> the TEST_ID is <code>jtreg_jdk_test_tier1<\/code>. This path is also printed in the log at the end of the test run.<\/p>\n-<p>Additional work data is stored in <code>build\/$BUILD\/test-support\/$TEST_ID<\/code>. For some frameworks, this directory might contain information that is useful in determining the cause of a failed test.<\/p>\n-<h2 id=\"test-suite-control\">Test suite control<\/h2>\n-<p>It is possible to control various aspects of the test suites using make control variables.<\/p>\n-<p>These variables use a keyword=value approach to allow multiple values to be set. So, for instance, <code>JTREG=&quot;JOBS=1;TIMEOUT_FACTOR=8&quot;<\/code> will set the JTReg concurrency level to 1 and the timeout factor to 8. This is equivalent to setting <code>JTREG_JOBS=1 JTREG_TIMEOUT_FACTOR=8<\/code>, but using the keyword format means that the <code>JTREG<\/code> variable is parsed and verified for correctness, so <code>JTREG=&quot;TMIEOUT_FACTOR=8&quot;<\/code> would give an error, while <code>JTREG_TMIEOUT_FACTOR=8<\/code> would just pass unnoticed.<\/p>\n-<p>To separate multiple keyword=value pairs, use <code>;<\/code> (semicolon). Since the shell normally eats <code>;<\/code>, the recommended usage is to write the assignment inside qoutes, e.g. <code>JTREG=&quot;...;...&quot;<\/code>. This will also make sure spaces are preserved, as in <code>JTREG=&quot;JAVA_OPTIONS=-XshowSettings -Xlog:gc+ref=debug&quot;<\/code>.<\/p>\n-<p>(Other ways are possible, e.g. using backslash: <code>JTREG=JOBS=1\\;TIMEOUT_FACTOR=8<\/code>. Also, as a special technique, the string <code>%20<\/code> will be replaced with space for certain options, e.g. <code>JTREG=JAVA_OPTIONS=-XshowSettings%20-Xlog:gc+ref=debug<\/code>. This can be useful if you have layers of scripts and have trouble getting proper quoting of command line arguments through.)<\/p>\n-<p>As far as possible, the names of the keywords have been standardized between test suites.<\/p>\n-<h3 id=\"general-keywords-test_opts\">General keywords (TEST_OPTS)<\/h3>\n-<p>Some keywords are valid across different test suites. If you want to run tests from multiple test suites, or just don't want to care which test suite specific control variable to use, then you can use the general TEST_OPTS control variable.<\/p>\n-<p>There are also some keywords that applies globally to the test runner system, not to any specific test suites. These are also available as TEST_OPTS keywords.<\/p>\n-<h4 id=\"jobs\">JOBS<\/h4>\n-<p>Currently only applies to JTReg.<\/p>\n-<h4 id=\"timeout_factor\">TIMEOUT_FACTOR<\/h4>\n-<p>Currently only applies to JTReg.<\/p>\n-<h4 id=\"java_options\">JAVA_OPTIONS<\/h4>\n-<p>Applies to JTReg, GTest and Micro.<\/p>\n-<h4 id=\"vm_options\">VM_OPTIONS<\/h4>\n-<p>Applies to JTReg, GTest and Micro.<\/p>\n-<h4 id=\"aot_modules\">AOT_MODULES<\/h4>\n-<p>Applies to JTReg and GTest.<\/p>\n-<h4 id=\"jcov\">JCOV<\/h4>\n-<p>This keywords applies globally to the test runner system. If set to <code>true<\/code>, it enables JCov coverage reporting for all tests run. To be useful, the JDK under test must be run with a JDK built with JCov instrumentation (<code>configure --with-jcov=&lt;path to directory containing lib\/jcov.jar&gt;<\/code>, <code>make jcov-image<\/code>).<\/p>\n-<p>The simplest way to run tests with JCov coverage report is to use the special target <code>jcov-test<\/code> instead of <code>test<\/code>, e.g. <code>make jcov-test TEST=jdk_lang<\/code>. This will make sure the JCov image is built, and that JCov reporting is enabled.<\/p>\n-<p>The JCov report is stored in <code>build\/$BUILD\/test-results\/jcov-output\/report<\/code>.<\/p>\n-<p>Please note that running with JCov reporting can be very memory intensive.<\/p>\n-<h4 id=\"jcov_diff_changeset\">JCOV_DIFF_CHANGESET<\/h4>\n-<p>While collecting code coverage with JCov, it is also possible to find coverage for only recently changed code. JCOV_DIFF_CHANGESET specifies a source revision. A textual report will be generated showing coverage of the diff between the specified revision and the repository tip.<\/p>\n-<p>The report is stored in <code>build\/$BUILD\/test-results\/jcov-output\/diff_coverage_report<\/code> file.<\/p>\n-<h3 id=\"jtreg-keywords\">JTReg keywords<\/h3>\n-<h4 id=\"jobs-1\">JOBS<\/h4>\n-<p>The test concurrency (<code>-concurrency<\/code>).<\/p>\n-<p>Defaults to TEST_JOBS (if set by <code>--with-test-jobs=<\/code>), otherwise it defaults to JOBS, except for Hotspot, where the default is <em>number of CPU cores\/2<\/em>, but never more than <em>memory size in GB\/2<\/em>.<\/p>\n-<h4 id=\"timeout_factor-1\">TIMEOUT_FACTOR<\/h4>\n-<p>The timeout factor (<code>-timeoutFactor<\/code>).<\/p>\n-<p>Defaults to 4.<\/p>\n-<h4 id=\"failure_handler_timeout\">FAILURE_HANDLER_TIMEOUT<\/h4>\n-<p>Sets the argument <code>-timeoutHandlerTimeout<\/code> for JTReg. The default value is 0. This is only valid if the failure handler is built.<\/p>\n-<h4 id=\"test_mode\">TEST_MODE<\/h4>\n-<p>The test mode (<code>agentvm<\/code> or <code>othervm<\/code>).<\/p>\n-<p>Defaults to <code>agentvm<\/code>.<\/p>\n-<h4 id=\"assert\">ASSERT<\/h4>\n-<p>Enable asserts (<code>-ea -esa<\/code>, or none).<\/p>\n-<p>Set to <code>true<\/code> or <code>false<\/code>. If true, adds <code>-ea -esa<\/code>. Defaults to true, except for hotspot.<\/p>\n-<h4 id=\"verbose\">VERBOSE<\/h4>\n-<p>The verbosity level (<code>-verbose<\/code>).<\/p>\n-<p>Defaults to <code>fail,error,summary<\/code>.<\/p>\n-<h4 id=\"retain\">RETAIN<\/h4>\n-<p>What test data to retain (<code>-retain<\/code>).<\/p>\n-<p>Defaults to <code>fail,error<\/code>.<\/p>\n-<h4 id=\"max_mem\">MAX_MEM<\/h4>\n-<p>Limit memory consumption (<code>-Xmx<\/code> and <code>-vmoption:-Xmx<\/code>, or none).<\/p>\n-<p>Limit memory consumption for JTReg test framework and VM under test. Set to 0 to disable the limits.<\/p>\n-<p>Defaults to 512m, except for hotspot, where it defaults to 0 (no limit).<\/p>\n-<h4 id=\"max_output\">MAX_OUTPUT<\/h4>\n-<p>Set the property <code>javatest.maxOutputSize<\/code> for the launcher, to change the default JTReg log limit.<\/p>\n-<h4 id=\"keywords\">KEYWORDS<\/h4>\n-<p>JTReg keywords sent to JTReg using <code>-k<\/code>. Please be careful in making sure that spaces and special characters (like <code>!<\/code>) are properly quoted. To avoid some issues, the special value <code>%20<\/code> can be used instead of space.<\/p>\n-<h4 id=\"extra_problem_lists\">EXTRA_PROBLEM_LISTS<\/h4>\n-<p>Use additional problem lists file or files, in addition to the default ProblemList.txt located at the JTReg test roots.<\/p>\n-<p>If multiple file names are specified, they should be separated by space (or, to help avoid quoting issues, the special value <code>%20<\/code>).<\/p>\n-<p>The file names should be either absolute, or relative to the JTReg test root of the tests to be run.<\/p>\n-<h4 id=\"run_problem_lists\">RUN_PROBLEM_LISTS<\/h4>\n-<p>Use the problem lists to select tests instead of excluding them.<\/p>\n-<p>Set to <code>true<\/code> or <code>false<\/code>. If <code>true<\/code>, JTReg will use <code>-match:<\/code> option, otherwise <code>-exclude:<\/code> will be used. Default is <code>false<\/code>.<\/p>\n-<h4 id=\"options\">OPTIONS<\/h4>\n-<p>Additional options to the JTReg test framework.<\/p>\n-<p>Use <code>JTREG=&quot;OPTIONS=--help all&quot;<\/code> to see all available JTReg options.<\/p>\n-<h4 id=\"java_options-1\">JAVA_OPTIONS<\/h4>\n-<p>Additional Java options for running test classes (sent to JTReg as <code>-javaoption<\/code>).<\/p>\n-<h4 id=\"vm_options-1\">VM_OPTIONS<\/h4>\n-<p>Additional Java options to be used when compiling and running classes (sent to JTReg as <code>-vmoption<\/code>).<\/p>\n-<p>This option is only needed in special circumstances. To pass Java options to your test classes, use <code>JAVA_OPTIONS<\/code>.<\/p>\n-<h4 id=\"launcher_options\">LAUNCHER_OPTIONS<\/h4>\n-<p>Additional Java options that are sent to the java launcher that starts the JTReg harness.<\/p>\n-<h4 id=\"aot_modules-1\">AOT_MODULES<\/h4>\n-<p>Generate AOT modules before testing for the specified module, or set of modules. If multiple modules are specified, they should be separated by space (or, to help avoid quoting issues, the special value <code>%20<\/code>).<\/p>\n-<h4 id=\"retry_count\">RETRY_COUNT<\/h4>\n-<p>Retry failed tests up to a set number of times, until they pass. This allows to pass the tests with intermittent failures. Defaults to 0.<\/p>\n-<h4 id=\"repeat_count\">REPEAT_COUNT<\/h4>\n-<p>Repeat the tests up to a set number of times, stopping at first failure. This helps to reproduce intermittent test failures. Defaults to 0.<\/p>\n-<h3 id=\"gtest-keywords\">Gtest keywords<\/h3>\n-<h4 id=\"repeat\">REPEAT<\/h4>\n-<p>The number of times to repeat the tests (<code>--gtest_repeat<\/code>).<\/p>\n-<p>Default is 1. Set to -1 to repeat indefinitely. This can be especially useful combined with <code>OPTIONS=--gtest_break_on_failure<\/code> to reproduce an intermittent problem.<\/p>\n-<h4 id=\"options-1\">OPTIONS<\/h4>\n-<p>Additional options to the Gtest test framework.<\/p>\n-<p>Use <code>GTEST=&quot;OPTIONS=--help&quot;<\/code> to see all available Gtest options.<\/p>\n-<h4 id=\"aot_modules-2\">AOT_MODULES<\/h4>\n-<p>Generate AOT modules before testing for the specified module, or set of modules. If multiple modules are specified, they should be separated by space (or, to help avoid quoting issues, the special value <code>%20<\/code>).<\/p>\n-<h3 id=\"microbenchmark-keywords\">Microbenchmark keywords<\/h3>\n-<h4 id=\"fork\">FORK<\/h4>\n-<p>Override the number of benchmark forks to spawn. Same as specifying <code>-f &lt;num&gt;<\/code>.<\/p>\n-<h4 id=\"iter\">ITER<\/h4>\n-<p>Number of measurement iterations per fork. Same as specifying <code>-i &lt;num&gt;<\/code>.<\/p>\n-<h4 id=\"time\">TIME<\/h4>\n-<p>Amount of time to spend in each measurement iteration, in seconds. Same as specifying <code>-r &lt;num&gt;<\/code><\/p>\n-<h4 id=\"warmup_iter\">WARMUP_ITER<\/h4>\n-<p>Number of warmup iterations to run before the measurement phase in each fork. Same as specifying <code>-wi &lt;num&gt;<\/code>.<\/p>\n-<h4 id=\"warmup_time\">WARMUP_TIME<\/h4>\n-<p>Amount of time to spend in each warmup iteration. Same as specifying <code>-w &lt;num&gt;<\/code>.<\/p>\n-<h4 id=\"results_format\">RESULTS_FORMAT<\/h4>\n-<p>Specify to have the test run save a log of the values. Accepts the same values as <code>-rff<\/code>, i.e., <code>text<\/code>, <code>csv<\/code>, <code>scsv<\/code>, <code>json<\/code>, or <code>latex<\/code>.<\/p>\n-<h4 id=\"vm_options-2\">VM_OPTIONS<\/h4>\n-<p>Additional VM arguments to provide to forked off VMs. Same as <code>-jvmArgs &lt;args&gt;<\/code><\/p>\n-<h4 id=\"options-2\">OPTIONS<\/h4>\n-<p>Additional arguments to send to JMH.<\/p>\n-<h2 id=\"notes-for-specific-tests\">Notes for Specific Tests<\/h2>\n-<h3 id=\"docker-tests\">Docker Tests<\/h3>\n-<p>Docker tests with default parameters may fail on systems with glibc versions not compatible with the one used in the default docker image (e.g., Oracle Linux 7.6 for x86). For example, they pass on Ubuntu 16.04 but fail on Ubuntu 18.04 if run like this on x86:<\/p>\n-<pre><code>$ make test TEST=&quot;jtreg:test\/hotspot\/jtreg\/containers\/docker&quot;<\/code><\/pre>\n-<p>To run these tests correctly, additional parameters for the correct docker image are required on Ubuntu 18.04 by using <code>JAVA_OPTIONS<\/code>.<\/p>\n-<pre><code>$ make test TEST=&quot;jtreg:test\/hotspot\/jtreg\/containers\/docker&quot; \\\n-    JTREG=&quot;JAVA_OPTIONS=-Djdk.test.docker.image.name=ubuntu\n-    -Djdk.test.docker.image.version=latest&quot;<\/code><\/pre>\n-<h3 id=\"non-us-locale\">Non-US locale<\/h3>\n-<p>If your locale is non-US, some tests are likely to fail. To work around this you can set the locale to US. On Unix platforms simply setting <code>LANG=&quot;en_US&quot;<\/code> in the environment before running tests should work. On Windows or MacOS, setting <code>JTREG=&quot;VM_OPTIONS=-Duser.language=en -Duser.country=US&quot;<\/code> helps for most, but not all test cases.<\/p>\n-<p>For example:<\/p>\n-<pre><code>$ export LANG=&quot;en_US&quot; &amp;&amp; make test TEST=...\n-$ make test JTREG=&quot;VM_OPTIONS=-Duser.language=en -Duser.country=US&quot; TEST=...<\/code><\/pre>\n-<h3 id=\"pkcs11-tests\">PKCS11 Tests<\/h3>\n-<p>It is highly recommended to use the latest NSS version when running PKCS11 tests. Improper NSS version may lead to unexpected failures which are hard to diagnose. For example, sun\/security\/pkcs11\/Secmod\/AddTrustedCert.java may fail on Ubuntu 18.04 with the default NSS version in the system. To run these tests correctly, the system property <code>test.nss.lib.paths<\/code> is required on Ubuntu 18.04 to specify the alternative NSS lib directories.<\/p>\n-<p>For example:<\/p>\n-<pre><code>$ make test TEST=&quot;jtreg:sun\/security\/pkcs11\/Secmod\/AddTrustedCert.java&quot; \\\n-    JTREG=&quot;JAVA_OPTIONS=-Dtest.nss.lib.paths=\/path\/to\/your\/latest\/NSS-libs&quot;<\/code><\/pre>\n-<p>For more notes about the PKCS11 tests, please refer to test\/jdk\/sun\/security\/pkcs11\/README.<\/p>\n-<h3 id=\"client-ui-tests\">Client UI Tests<\/h3>\n-<p>Some Client UI tests use key sequences which may be reserved by the operating system. Usually that causes the test failure. So it is highly recommended to disable system key shortcuts prior testing. The steps to access and disable system key shortcuts for various platforms are provided below.<\/p>\n-<h4 id=\"macos\">MacOS<\/h4>\n-<p>Choose Apple menu; System Preferences, click Keyboard, then click Shortcuts; select or deselect desired shortcut.<\/p>\n-<p>For example, test\/jdk\/javax\/swing\/TooltipManager\/JMenuItemToolTipKeyBindingsTest\/JMenuItemToolTipKeyBindingsTest.java fails on MacOS because it uses <code>CTRL + F1<\/code> key sequence to show or hide tooltip message but the key combination is reserved by the operating system. To run the test correctly the default global key shortcut should be disabled using the steps described above, and then deselect &quot;Turn keyboard access on or off&quot; option which is responsible for <code>CTRL + F1<\/code> combination.<\/p>\n-<h4 id=\"linux\">Linux<\/h4>\n-<p>Open the Activities overview and start typing Settings; Choose Settings, click Devices, then click Keyboard; set or override desired shortcut.<\/p>\n-<h4 id=\"windows\">Windows<\/h4>\n-<p>Type <code>gpedit<\/code> in the Search and then click Edit group policy; navigate to User Configuration -&gt; Administrative Templates -&gt; Windows Components -&gt; File Explorer; in the right-side pane look for &quot;Turn off Windows key hotkeys&quot; and double click on it; enable or disable hotkeys.<\/p>\n-<p>Note: restart is required to make the settings take effect.<\/p>\n-<\/body>\n-<\/html>\n+<!DOCTYPE html>\r\n+<html xmlns=\"http:\/\/www.w3.org\/1999\/xhtml\" lang=\"\" xml:lang=\"\">\r\n+<head>\r\n+  <meta charset=\"utf-8\" \/>\r\n+  <meta name=\"generator\" content=\"pandoc\" \/>\r\n+  <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, user-scalable=yes\" \/>\r\n+  <title>Testing the JDK<\/title>\r\n+  <style type=\"text\/css\">\r\n+      code{white-space: pre-wrap;}\r\n+      span.smallcaps{font-variant: small-caps;}\r\n+      span.underline{text-decoration: underline;}\r\n+      div.column{display: inline-block; vertical-align: top; width: 50%;}\r\n+  <\/style>\r\n+  <link rel=\"stylesheet\" href=\"..\/make\/data\/docs-resources\/resources\/jdk-default.css\" \/>\r\n+  <!--[if lt IE 9]>\r\n+    <script src=\"\/\/cdnjs.cloudflare.com\/ajax\/libs\/html5shiv\/3.7.3\/html5shiv-printshiv.min.js\"><\/script>\r\n+  <![endif]-->\r\n+  <style type=\"text\/css\">pre, code, tt { color: #1d6ae5; }<\/style>\r\n+<\/head>\r\n+<body>\r\n+<header>\r\n+<h1 class=\"title\">Testing the JDK<\/h1>\r\n+<\/header>\r\n+<nav id=\"TOC\">\r\n+<ul>\r\n+<li><a href=\"#using-make-test-the-run-test-framework\">Using &quot;make test&quot; (the run-test framework)<\/a><ul>\r\n+<li><a href=\"#configuration\">Configuration<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#test-selection\">Test selection<\/a><ul>\r\n+<li><a href=\"#common-test-groups\">Common Test Groups<\/a><\/li>\r\n+<li><a href=\"#jtreg\">JTReg<\/a><\/li>\r\n+<li><a href=\"#gtest\">Gtest<\/a><\/li>\r\n+<li><a href=\"#microbenchmarks\">Microbenchmarks<\/a><\/li>\r\n+<li><a href=\"#special-tests\">Special tests<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#test-results-and-summary\">Test results and summary<\/a><\/li>\r\n+<li><a href=\"#test-suite-control\">Test suite control<\/a><ul>\r\n+<li><a href=\"#general-keywords-test_opts\">General keywords (TEST_OPTS)<\/a><\/li>\r\n+<li><a href=\"#jtreg-keywords\">JTReg keywords<\/a><\/li>\r\n+<li><a href=\"#gtest-keywords\">Gtest keywords<\/a><\/li>\r\n+<li><a href=\"#microbenchmark-keywords\">Microbenchmark keywords<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<li><a href=\"#notes-for-specific-tests\">Notes for Specific Tests<\/a><ul>\r\n+<li><a href=\"#docker-tests\">Docker Tests<\/a><\/li>\r\n+<li><a href=\"#non-us-locale\">Non-US locale<\/a><\/li>\r\n+<li><a href=\"#pkcs11-tests\">PKCS11 Tests<\/a><\/li>\r\n+<li><a href=\"#client-ui-tests\">Client UI Tests<\/a><\/li>\r\n+<\/ul><\/li>\r\n+<\/ul>\r\n+<\/nav>\r\n+<h2 id=\"using-make-test-the-run-test-framework\">Using &quot;make test&quot; (the run-test framework)<\/h2>\r\n+<p>This new way of running tests is developer-centric. It assumes that you have built a JDK locally and want to test it. Running common test targets is simple, and more complex ad-hoc combination of tests is possible. The user interface is forgiving, and clearly report errors it cannot resolve.<\/p>\r\n+<p>The main target <code>test<\/code> uses the jdk-image as the tested product. There is also an alternate target <code>exploded-test<\/code> that uses the exploded image instead. Not all tests will run successfully on the exploded image, but using this target can greatly improve rebuild times for certain workflows.<\/p>\r\n+<p>Previously, <code>make test<\/code> was used to invoke an old system for running tests, and <code>make run-test<\/code> was used for the new test framework. For backward compatibility with scripts and muscle memory, <code>run-test<\/code> (and variants like <code>exploded-run-test<\/code> or <code>run-test-tier1<\/code>) are kept as aliases.<\/p>\r\n+<p>Some example command-lines:<\/p>\r\n+<pre><code>$ make test-tier1\r\n+$ make test-jdk_lang JTREG=&quot;JOBS=8&quot;\r\n+$ make test TEST=jdk_lang\r\n+$ make test-only TEST=&quot;gtest:LogTagSet gtest:LogTagSetDescriptions&quot; GTEST=&quot;REPEAT=-1&quot;\r\n+$ make test TEST=&quot;hotspot:hotspot_gc&quot; JTREG=&quot;JOBS=1;TIMEOUT_FACTOR=8;JAVA_OPTIONS=-XshowSettings -Xlog:gc+ref=debug&quot;\r\n+$ make test TEST=&quot;jtreg:test\/hotspot:hotspot_gc test\/hotspot\/jtreg\/native_sanity\/JniVersion.java&quot;\r\n+$ make test TEST=&quot;micro:java.lang.reflect&quot; MICRO=&quot;FORK=1;WARMUP_ITER=2&quot;\r\n+$ make exploded-test TEST=tier2<\/code><\/pre>\r\n+<h3 id=\"configuration\">Configuration<\/h3>\r\n+<p>To be able to run JTReg tests, <code>configure<\/code> needs to know where to find the JTReg test framework. If it is not picked up automatically by configure, use the <code>--with-jtreg=&lt;path to jtreg home&gt;<\/code> option to point to the JTReg framework. Note that this option should point to the JTReg home, i.e. the top directory, containing <code>lib\/jtreg.jar<\/code> etc. (An alternative is to set the <code>JT_HOME<\/code> environment variable to point to the JTReg home before running <code>configure<\/code>.)<\/p>\r\n+<p>To be able to run microbenchmarks, <code>configure<\/code> needs to know where to find the JMH dependency. Use <code>--with-jmh=&lt;path to JMH jars&gt;<\/code> to point to a directory containing the core JMH and transitive dependencies. The recommended dependencies can be retrieved by running <code>sh make\/devkit\/createJMHBundle.sh<\/code>, after which <code>--with-jmh=build\/jmh\/jars<\/code> should work.<\/p>\r\n+<h2 id=\"test-selection\">Test selection<\/h2>\r\n+<p>All functionality is available using the <code>test<\/code> make target. In this use case, the test or tests to be executed is controlled using the <code>TEST<\/code> variable. To speed up subsequent test runs with no source code changes, <code>test-only<\/code> can be used instead, which do not depend on the source and test image build.<\/p>\r\n+<p>For some common top-level tests, direct make targets have been generated. This includes all JTReg test groups, the hotspot gtest, and custom tests (if present). This means that <code>make test-tier1<\/code> is equivalent to <code>make test TEST=&quot;tier1&quot;<\/code>, but the latter is more tab-completion friendly. For more complex test runs, the <code>test TEST=&quot;x&quot;<\/code> solution needs to be used.<\/p>\r\n+<p>The test specifications given in <code>TEST<\/code> is parsed into fully qualified test descriptors, which clearly and unambigously show which tests will be run. As an example, <code>:tier1<\/code> will expand to <code>jtreg:$(TOPDIR)\/test\/hotspot\/jtreg:tier1 jtreg:$(TOPDIR)\/test\/jdk:tier1 jtreg:$(TOPDIR)\/test\/langtools:tier1 jtreg:$(TOPDIR)\/test\/nashorn:tier1 jtreg:$(TOPDIR)\/test\/jaxp:tier1<\/code>. You can always submit a list of fully qualified test descriptors in the <code>TEST<\/code> variable if you want to shortcut the parser.<\/p>\r\n+<h3 id=\"common-test-groups\">Common Test Groups<\/h3>\r\n+<p>Ideally, all tests are run for every change but this may not be practical due to the limited testing resources, the scope of the change, etc.<\/p>\r\n+<p>The source tree currently defines a few common test groups in the relevant <code>TEST.groups<\/code> files. There are test groups that cover a specific component, for example <code>hotspot_gc<\/code>. It is a good idea to look into <code>TEST.groups<\/code> files to get a sense what tests are relevant to a particular JDK component.<\/p>\r\n+<p>Component-specific tests may miss some unintended consequences of a change, so other tests should also be run. Again, it might be impractical to run all tests, and therefore <em>tiered<\/em> test groups exist. Tiered test groups are not component-specific, but rather cover the significant parts of the entire JDK.<\/p>\r\n+<p>Multiple tiers allow balancing test coverage and testing costs. Lower test tiers are supposed to contain the simpler, quicker and more stable tests. Higher tiers are supposed to contain progressively more thorough, slower, and sometimes less stable tests, or the tests that require special configuration.<\/p>\r\n+<p>Contributors are expected to run the tests for the areas that are changed, and the first N tiers they can afford to run, but at least tier1.<\/p>\r\n+<p>A brief description of the tiered test groups:<\/p>\r\n+<ul>\r\n+<li><p><code>tier1<\/code>: This is the lowest test tier. Multiple developers run these tests every day. Because of the widespread use, the tests in <code>tier1<\/code> are carefully selected and optimized to run fast, and to run in the most stable manner. The test failures in <code>tier1<\/code> are usually followed up on quickly, either with fixes, or adding relevant tests to problem list. GitHub Actions workflows, if enabled, run <code>tier1<\/code> tests.<\/p><\/li>\r\n+<li><p><code>tier2<\/code>: This test group covers even more ground. These contain, among other things, tests that either run for too long to be at <code>tier1<\/code>, or may require special configuration, or tests that are less stable, or cover the broader range of non-core JVM and JDK features\/components (for example, XML).<\/p><\/li>\r\n+<li><p><code>tier3<\/code>: This test group includes more stressful tests, the tests for corner cases not covered by previous tiers, plus the tests that require GUIs. As such, this suite should either be run with low concurrency (<code>TEST_JOBS=1<\/code>), or without headful tests (<code>JTREG_KEYWORDS=\\!headful<\/code>), or both.<\/p><\/li>\r\n+<li><p><code>tier4<\/code>: This test group includes every other test not covered by previous tiers. It includes, for example, <code>vmTestbase<\/code> suites for Hotspot, which run for many hours even on large machines. It also runs GUI tests, so the same <code>TEST_JOBS<\/code> and <code>JTREG_KEYWORDS<\/code> caveats apply.<\/p><\/li>\r\n+<\/ul>\r\n+<h3 id=\"jtreg\">JTReg<\/h3>\r\n+<p>JTReg tests can be selected either by picking a JTReg test group, or a selection of files or directories containing JTReg tests.<\/p>\r\n+<p>JTReg test groups can be specified either without a test root, e.g. <code>:tier1<\/code> (or <code>tier1<\/code>, the initial colon is optional), or with, e.g. <code>hotspot:tier1<\/code>, <code>test\/jdk:jdk_util<\/code> or <code>$(TOPDIR)\/test\/hotspot\/jtreg:hotspot_all<\/code>. The test root can be specified either as an absolute path, or a path relative to the JDK top directory, or the <code>test<\/code> directory. For simplicity, the hotspot JTReg test root, which really is <code>hotspot\/jtreg<\/code> can be abbreviated as just <code>hotspot<\/code>.<\/p>\r\n+<p>When specified without a test root, all matching groups from all test roots will be added. Otherwise, only the group from the specified test root will be added.<\/p>\r\n+<p>Individual JTReg tests or directories containing JTReg tests can also be specified, like <code>test\/hotspot\/jtreg\/native_sanity\/JniVersion.java<\/code> or <code>hotspot\/jtreg\/native_sanity<\/code>. Just like for test root selection, you can either specify an absolute path (which can even point to JTReg tests outside the source tree), or a path relative to either the JDK top directory or the <code>test<\/code> directory. <code>hotspot<\/code> can be used as an alias for <code>hotspot\/jtreg<\/code> here as well.<\/p>\r\n+<p>As long as the test groups or test paths can be uniquely resolved, you do not need to enter the <code>jtreg:<\/code> prefix. If this is not possible, or if you want to use a fully qualified test descriptor, add <code>jtreg:<\/code>, e.g. <code>jtreg:test\/hotspot\/jtreg\/native_sanity<\/code>.<\/p>\r\n+<h3 id=\"gtest\">Gtest<\/h3>\r\n+<p>Since the Hotspot Gtest suite is so quick, the default is to run all tests. This is specified by just <code>gtest<\/code>, or as a fully qualified test descriptor <code>gtest:all<\/code>.<\/p>\r\n+<p>If you want, you can single out an individual test or a group of tests, for instance <code>gtest:LogDecorations<\/code> or <code>gtest:LogDecorations.level_test_vm<\/code>. This can be particularly useful if you want to run a shaky test repeatedly.<\/p>\r\n+<p>For Gtest, there is a separate test suite for each JVM variant. The JVM variant is defined by adding <code>\/&lt;variant&gt;<\/code> to the test descriptor, e.g. <code>gtest:Log\/client<\/code>. If you specify no variant, gtest will run once for each JVM variant present (e.g. server, client). So if you only have the server JVM present, then <code>gtest:all<\/code> will be equivalent to <code>gtest:all\/server<\/code>.<\/p>\r\n+<h3 id=\"microbenchmarks\">Microbenchmarks<\/h3>\r\n+<p>Which microbenchmarks to run is selected using a regular expression following the <code>micro:<\/code> test descriptor, e.g., <code>micro:java.lang.reflect<\/code>. This delegates the test selection to JMH, meaning package name, class name and even benchmark method names can be used to select tests.<\/p>\r\n+<p>Using special characters like <code>|<\/code> in the regular expression is possible, but needs to be escaped multiple times: <code>micro:ArrayCopy\\\\\\\\\\|reflect<\/code>.<\/p>\r\n+<h3 id=\"special-tests\">Special tests<\/h3>\r\n+<p>A handful of odd tests that are not covered by any other testing framework are accessible using the <code>special:<\/code> test descriptor. Currently, this includes <code>failure-handler<\/code> and <code>make<\/code>.<\/p>\r\n+<ul>\r\n+<li><p>Failure handler testing is run using <code>special:failure-handler<\/code> or just <code>failure-handler<\/code> as test descriptor.<\/p><\/li>\r\n+<li><p>Tests for the build system, including both makefiles and related functionality, is run using <code>special:make<\/code> or just <code>make<\/code> as test descriptor. This is equivalent to <code>special:make:all<\/code>.<\/p>\r\n+<p>A specific make test can be run by supplying it as argument, e.g. <code>special:make:idea<\/code>. As a special syntax, this can also be expressed as <code>make-idea<\/code>, which allows for command lines as <code>make test-make-idea<\/code>.<\/p><\/li>\r\n+<\/ul>\r\n+<h2 id=\"test-results-and-summary\">Test results and summary<\/h2>\r\n+<p>At the end of the test run, a summary of all tests run will be presented. This will have a consistent look, regardless of what test suites were used. This is a sample summary:<\/p>\r\n+<pre><code>==============================\r\n+Test summary\r\n+==============================\r\n+   TEST                                          TOTAL  PASS  FAIL ERROR\r\n+&gt;&gt; jtreg:jdk\/test:tier1                           1867  1865     2     0 &lt;&lt;\r\n+   jtreg:langtools\/test:tier1                     4711  4711     0     0\r\n+   jtreg:nashorn\/test:tier1                        133   133     0     0\r\n+==============================\r\n+TEST FAILURE<\/code><\/pre>\r\n+<p>Tests where the number of TOTAL tests does not equal the number of PASSed tests will be considered a test failure. These are marked with the <code>&gt;&gt; ... &lt;&lt;<\/code> marker for easy identification.<\/p>\r\n+<p>The classification of non-passed tests differs a bit between test suites. In the summary, ERROR is used as a catch-all for tests that neither passed nor are classified as failed by the framework. This might indicate test framework error, timeout or other problems.<\/p>\r\n+<p>In case of test failures, <code>make test<\/code> will exit with a non-zero exit value.<\/p>\r\n+<p>All tests have their result stored in <code>build\/$BUILD\/test-results\/$TEST_ID<\/code>, where TEST_ID is a path-safe conversion from the fully qualified test descriptor, e.g. for <code>jtreg:jdk\/test:tier1<\/code> the TEST_ID is <code>jtreg_jdk_test_tier1<\/code>. This path is also printed in the log at the end of the test run.<\/p>\r\n+<p>Additional work data is stored in <code>build\/$BUILD\/test-support\/$TEST_ID<\/code>. For some frameworks, this directory might contain information that is useful in determining the cause of a failed test.<\/p>\r\n+<h2 id=\"test-suite-control\">Test suite control<\/h2>\r\n+<p>It is possible to control various aspects of the test suites using make control variables.<\/p>\r\n+<p>These variables use a keyword=value approach to allow multiple values to be set. So, for instance, <code>JTREG=&quot;JOBS=1;TIMEOUT_FACTOR=8&quot;<\/code> will set the JTReg concurrency level to 1 and the timeout factor to 8. This is equivalent to setting <code>JTREG_JOBS=1 JTREG_TIMEOUT_FACTOR=8<\/code>, but using the keyword format means that the <code>JTREG<\/code> variable is parsed and verified for correctness, so <code>JTREG=&quot;TMIEOUT_FACTOR=8&quot;<\/code> would give an error, while <code>JTREG_TMIEOUT_FACTOR=8<\/code> would just pass unnoticed.<\/p>\r\n+<p>To separate multiple keyword=value pairs, use <code>;<\/code> (semicolon). Since the shell normally eats <code>;<\/code>, the recommended usage is to write the assignment inside qoutes, e.g. <code>JTREG=&quot;...;...&quot;<\/code>. This will also make sure spaces are preserved, as in <code>JTREG=&quot;JAVA_OPTIONS=-XshowSettings -Xlog:gc+ref=debug&quot;<\/code>.<\/p>\r\n+<p>(Other ways are possible, e.g. using backslash: <code>JTREG=JOBS=1\\;TIMEOUT_FACTOR=8<\/code>. Also, as a special technique, the string <code>%20<\/code> will be replaced with space for certain options, e.g. <code>JTREG=JAVA_OPTIONS=-XshowSettings%20-Xlog:gc+ref=debug<\/code>. This can be useful if you have layers of scripts and have trouble getting proper quoting of command line arguments through.)<\/p>\r\n+<p>As far as possible, the names of the keywords have been standardized between test suites.<\/p>\r\n+<h3 id=\"general-keywords-test_opts\">General keywords (TEST_OPTS)<\/h3>\r\n+<p>Some keywords are valid across different test suites. If you want to run tests from multiple test suites, or just don't want to care which test suite specific control variable to use, then you can use the general TEST_OPTS control variable.<\/p>\r\n+<p>There are also some keywords that applies globally to the test runner system, not to any specific test suites. These are also available as TEST_OPTS keywords.<\/p>\r\n+<h4 id=\"jobs\">JOBS<\/h4>\r\n+<p>Currently only applies to JTReg.<\/p>\r\n+<h4 id=\"timeout_factor\">TIMEOUT_FACTOR<\/h4>\r\n+<p>Currently only applies to JTReg.<\/p>\r\n+<h4 id=\"java_options\">JAVA_OPTIONS<\/h4>\r\n+<p>Applies to JTReg, GTest and Micro.<\/p>\r\n+<h4 id=\"vm_options\">VM_OPTIONS<\/h4>\r\n+<p>Applies to JTReg, GTest and Micro.<\/p>\r\n+<h4 id=\"aot_modules\">AOT_MODULES<\/h4>\r\n+<p>Applies to JTReg and GTest.<\/p>\r\n+<h4 id=\"jcov\">JCOV<\/h4>\r\n+<p>This keywords applies globally to the test runner system. If set to <code>true<\/code>, it enables JCov coverage reporting for all tests run. To be useful, the JDK under test must be run with a JDK built with JCov instrumentation (<code>configure --with-jcov=&lt;path to directory containing lib\/jcov.jar&gt;<\/code>, <code>make jcov-image<\/code>).<\/p>\r\n+<p>The simplest way to run tests with JCov coverage report is to use the special target <code>jcov-test<\/code> instead of <code>test<\/code>, e.g. <code>make jcov-test TEST=jdk_lang<\/code>. This will make sure the JCov image is built, and that JCov reporting is enabled.<\/p>\r\n+<p>The JCov report is stored in <code>build\/$BUILD\/test-results\/jcov-output\/report<\/code>.<\/p>\r\n+<p>Please note that running with JCov reporting can be very memory intensive.<\/p>\r\n+<h4 id=\"jcov_diff_changeset\">JCOV_DIFF_CHANGESET<\/h4>\r\n+<p>While collecting code coverage with JCov, it is also possible to find coverage for only recently changed code. JCOV_DIFF_CHANGESET specifies a source revision. A textual report will be generated showing coverage of the diff between the specified revision and the repository tip.<\/p>\r\n+<p>The report is stored in <code>build\/$BUILD\/test-results\/jcov-output\/diff_coverage_report<\/code> file.<\/p>\r\n+<h3 id=\"jtreg-keywords\">JTReg keywords<\/h3>\r\n+<h4 id=\"jobs-1\">JOBS<\/h4>\r\n+<p>The test concurrency (<code>-concurrency<\/code>).<\/p>\r\n+<p>Defaults to TEST_JOBS (if set by <code>--with-test-jobs=<\/code>), otherwise it defaults to JOBS, except for Hotspot, where the default is <em>number of CPU cores\/2<\/em>, but never more than <em>memory size in GB\/2<\/em>.<\/p>\r\n+<h4 id=\"timeout_factor-1\">TIMEOUT_FACTOR<\/h4>\r\n+<p>The timeout factor (<code>-timeoutFactor<\/code>).<\/p>\r\n+<p>Defaults to 4.<\/p>\r\n+<h4 id=\"failure_handler_timeout\">FAILURE_HANDLER_TIMEOUT<\/h4>\r\n+<p>Sets the argument <code>-timeoutHandlerTimeout<\/code> for JTReg. The default value is 0. This is only valid if the failure handler is built.<\/p>\r\n+<h4 id=\"test_mode\">TEST_MODE<\/h4>\r\n+<p>The test mode (<code>agentvm<\/code> or <code>othervm<\/code>).<\/p>\r\n+<p>Defaults to <code>agentvm<\/code>.<\/p>\r\n+<h4 id=\"assert\">ASSERT<\/h4>\r\n+<p>Enable asserts (<code>-ea -esa<\/code>, or none).<\/p>\r\n+<p>Set to <code>true<\/code> or <code>false<\/code>. If true, adds <code>-ea -esa<\/code>. Defaults to true, except for hotspot.<\/p>\r\n+<h4 id=\"verbose\">VERBOSE<\/h4>\r\n+<p>The verbosity level (<code>-verbose<\/code>).<\/p>\r\n+<p>Defaults to <code>fail,error,summary<\/code>.<\/p>\r\n+<h4 id=\"retain\">RETAIN<\/h4>\r\n+<p>What test data to retain (<code>-retain<\/code>).<\/p>\r\n+<p>Defaults to <code>fail,error<\/code>.<\/p>\r\n+<h4 id=\"max_mem\">MAX_MEM<\/h4>\r\n+<p>Limit memory consumption (<code>-Xmx<\/code> and <code>-vmoption:-Xmx<\/code>, or none).<\/p>\r\n+<p>Limit memory consumption for JTReg test framework and VM under test. Set to 0 to disable the limits.<\/p>\r\n+<p>Defaults to 512m, except for hotspot, where it defaults to 0 (no limit).<\/p>\r\n+<h4 id=\"max_output\">MAX_OUTPUT<\/h4>\r\n+<p>Set the property <code>javatest.maxOutputSize<\/code> for the launcher, to change the default JTReg log limit.<\/p>\r\n+<h4 id=\"keywords\">KEYWORDS<\/h4>\r\n+<p>JTReg keywords sent to JTReg using <code>-k<\/code>. Please be careful in making sure that spaces and special characters (like <code>!<\/code>) are properly quoted. To avoid some issues, the special value <code>%20<\/code> can be used instead of space.<\/p>\r\n+<h4 id=\"extra_problem_lists\">EXTRA_PROBLEM_LISTS<\/h4>\r\n+<p>Use additional problem lists file or files, in addition to the default ProblemList.txt located at the JTReg test roots.<\/p>\r\n+<p>If multiple file names are specified, they should be separated by space (or, to help avoid quoting issues, the special value <code>%20<\/code>).<\/p>\r\n+<p>The file names should be either absolute, or relative to the JTReg test root of the tests to be run.<\/p>\r\n+<h4 id=\"run_problem_lists\">RUN_PROBLEM_LISTS<\/h4>\r\n+<p>Use the problem lists to select tests instead of excluding them.<\/p>\r\n+<p>Set to <code>true<\/code> or <code>false<\/code>. If <code>true<\/code>, JTReg will use <code>-match:<\/code> option, otherwise <code>-exclude:<\/code> will be used. Default is <code>false<\/code>.<\/p>\r\n+<h4 id=\"options\">OPTIONS<\/h4>\r\n+<p>Additional options to the JTReg test framework.<\/p>\r\n+<p>Use <code>JTREG=&quot;OPTIONS=--help all&quot;<\/code> to see all available JTReg options.<\/p>\r\n+<h4 id=\"java_options-1\">JAVA_OPTIONS<\/h4>\r\n+<p>Additional Java options for running test classes (sent to JTReg as <code>-javaoption<\/code>).<\/p>\r\n+<h4 id=\"vm_options-1\">VM_OPTIONS<\/h4>\r\n+<p>Additional Java options to be used when compiling and running classes (sent to JTReg as <code>-vmoption<\/code>).<\/p>\r\n+<p>This option is only needed in special circumstances. To pass Java options to your test classes, use <code>JAVA_OPTIONS<\/code>.<\/p>\r\n+<h4 id=\"launcher_options\">LAUNCHER_OPTIONS<\/h4>\r\n+<p>Additional Java options that are sent to the java launcher that starts the JTReg harness.<\/p>\r\n+<h4 id=\"aot_modules-1\">AOT_MODULES<\/h4>\r\n+<p>Generate AOT modules before testing for the specified module, or set of modules. If multiple modules are specified, they should be separated by space (or, to help avoid quoting issues, the special value <code>%20<\/code>).<\/p>\r\n+<h4 id=\"retry_count\">RETRY_COUNT<\/h4>\r\n+<p>Retry failed tests up to a set number of times, until they pass. This allows to pass the tests with intermittent failures. Defaults to 0.<\/p>\r\n+<h4 id=\"repeat_count\">REPEAT_COUNT<\/h4>\r\n+<p>Repeat the tests up to a set number of times, stopping at first failure. This helps to reproduce intermittent test failures. Defaults to 0.<\/p>\r\n+<h3 id=\"gtest-keywords\">Gtest keywords<\/h3>\r\n+<h4 id=\"repeat\">REPEAT<\/h4>\r\n+<p>The number of times to repeat the tests (<code>--gtest_repeat<\/code>).<\/p>\r\n+<p>Default is 1. Set to -1 to repeat indefinitely. This can be especially useful combined with <code>OPTIONS=--gtest_break_on_failure<\/code> to reproduce an intermittent problem.<\/p>\r\n+<h4 id=\"options-1\">OPTIONS<\/h4>\r\n+<p>Additional options to the Gtest test framework.<\/p>\r\n+<p>Use <code>GTEST=&quot;OPTIONS=--help&quot;<\/code> to see all available Gtest options.<\/p>\r\n+<h4 id=\"aot_modules-2\">AOT_MODULES<\/h4>\r\n+<p>Generate AOT modules before testing for the specified module, or set of modules. If multiple modules are specified, they should be separated by space (or, to help avoid quoting issues, the special value <code>%20<\/code>).<\/p>\r\n+<h3 id=\"microbenchmark-keywords\">Microbenchmark keywords<\/h3>\r\n+<h4 id=\"fork\">FORK<\/h4>\r\n+<p>Override the number of benchmark forks to spawn. Same as specifying <code>-f &lt;num&gt;<\/code>.<\/p>\r\n+<h4 id=\"iter\">ITER<\/h4>\r\n+<p>Number of measurement iterations per fork. Same as specifying <code>-i &lt;num&gt;<\/code>.<\/p>\r\n+<h4 id=\"time\">TIME<\/h4>\r\n+<p>Amount of time to spend in each measurement iteration, in seconds. Same as specifying <code>-r &lt;num&gt;<\/code><\/p>\r\n+<h4 id=\"warmup_iter\">WARMUP_ITER<\/h4>\r\n+<p>Number of warmup iterations to run before the measurement phase in each fork. Same as specifying <code>-wi &lt;num&gt;<\/code>.<\/p>\r\n+<h4 id=\"warmup_time\">WARMUP_TIME<\/h4>\r\n+<p>Amount of time to spend in each warmup iteration. Same as specifying <code>-w &lt;num&gt;<\/code>.<\/p>\r\n+<h4 id=\"results_format\">RESULTS_FORMAT<\/h4>\r\n+<p>Specify to have the test run save a log of the values. Accepts the same values as <code>-rff<\/code>, i.e., <code>text<\/code>, <code>csv<\/code>, <code>scsv<\/code>, <code>json<\/code>, or <code>latex<\/code>.<\/p>\r\n+<h4 id=\"vm_options-2\">VM_OPTIONS<\/h4>\r\n+<p>Additional VM arguments to provide to forked off VMs. Same as <code>-jvmArgs &lt;args&gt;<\/code><\/p>\r\n+<h4 id=\"options-2\">OPTIONS<\/h4>\r\n+<p>Additional arguments to send to JMH.<\/p>\r\n+<h2 id=\"notes-for-specific-tests\">Notes for Specific Tests<\/h2>\r\n+<h3 id=\"docker-tests\">Docker Tests<\/h3>\r\n+<p>Docker tests with default parameters may fail on systems with glibc versions not compatible with the one used in the default docker image (e.g., Oracle Linux 7.6 for x86). For example, they pass on Ubuntu 16.04 but fail on Ubuntu 18.04 if run like this on x86:<\/p>\r\n+<pre><code>$ make test TEST=&quot;jtreg:test\/hotspot\/jtreg\/containers\/docker&quot;<\/code><\/pre>\r\n+<p>To run these tests correctly, additional parameters for the correct docker image are required on Ubuntu 18.04 by using <code>JAVA_OPTIONS<\/code>.<\/p>\r\n+<pre><code>$ make test TEST=&quot;jtreg:test\/hotspot\/jtreg\/containers\/docker&quot; \\\r\n+    JTREG=&quot;JAVA_OPTIONS=-Djdk.test.docker.image.name=ubuntu\r\n+    -Djdk.test.docker.image.version=latest&quot;<\/code><\/pre>\r\n+<h3 id=\"non-us-locale\">Non-US locale<\/h3>\r\n+<p>If your locale is non-US, some tests are likely to fail. To work around this you can set the locale to US. On Unix platforms simply setting <code>LANG=&quot;en_US&quot;<\/code> in the environment before running tests should work. On Windows or MacOS, setting <code>JTREG=&quot;VM_OPTIONS=-Duser.language=en -Duser.country=US&quot;<\/code> helps for most, but not all test cases.<\/p>\r\n+<p>For example:<\/p>\r\n+<pre><code>$ export LANG=&quot;en_US&quot; &amp;&amp; make test TEST=...\r\n+$ make test JTREG=&quot;VM_OPTIONS=-Duser.language=en -Duser.country=US&quot; TEST=...<\/code><\/pre>\r\n+<h3 id=\"pkcs11-tests\">PKCS11 Tests<\/h3>\r\n+<p>It is highly recommended to use the latest NSS version when running PKCS11 tests. Improper NSS version may lead to unexpected failures which are hard to diagnose. For example, sun\/security\/pkcs11\/Secmod\/AddTrustedCert.java may fail on Ubuntu 18.04 with the default NSS version in the system. To run these tests correctly, the system property <code>test.nss.lib.paths<\/code> is required on Ubuntu 18.04 to specify the alternative NSS lib directories.<\/p>\r\n+<p>For example:<\/p>\r\n+<pre><code>$ make test TEST=&quot;jtreg:sun\/security\/pkcs11\/Secmod\/AddTrustedCert.java&quot; \\\r\n+    JTREG=&quot;JAVA_OPTIONS=-Dtest.nss.lib.paths=\/path\/to\/your\/latest\/NSS-libs&quot;<\/code><\/pre>\r\n+<p>For more notes about the PKCS11 tests, please refer to test\/jdk\/sun\/security\/pkcs11\/README.<\/p>\r\n+<h3 id=\"client-ui-tests\">Client UI Tests<\/h3>\r\n+<p>Some Client UI tests use key sequences which may be reserved by the operating system. Usually that causes the test failure. So it is highly recommended to disable system key shortcuts prior testing. The steps to access and disable system key shortcuts for various platforms are provided below.<\/p>\r\n+<h4 id=\"macos\">MacOS<\/h4>\r\n+<p>Choose Apple menu; System Preferences, click Keyboard, then click Shortcuts; select or deselect desired shortcut.<\/p>\r\n+<p>For example, test\/jdk\/javax\/swing\/TooltipManager\/JMenuItemToolTipKeyBindingsTest\/JMenuItemToolTipKeyBindingsTest.java fails on MacOS because it uses <code>CTRL + F1<\/code> key sequence to show or hide tooltip message but the key combination is reserved by the operating system. To run the test correctly the default global key shortcut should be disabled using the steps described above, and then deselect &quot;Turn keyboard access on or off&quot; option which is responsible for <code>CTRL + F1<\/code> combination.<\/p>\r\n+<h4 id=\"linux\">Linux<\/h4>\r\n+<p>Open the Activities overview and start typing Settings; Choose Settings, click Devices, then click Keyboard; set or override desired shortcut.<\/p>\r\n+<h4 id=\"windows\">Windows<\/h4>\r\n+<p>Type <code>gpedit<\/code> in the Search and then click Edit group policy; navigate to User Configuration -&gt; Administrative Templates -&gt; Windows Components -&gt; File Explorer; in the right-side pane look for &quot;Turn off Windows key hotkeys&quot; and double click on it; enable or disable hotkeys.<\/p>\r\n+<p>Note: restart is required to make the settings take effect.<\/p>\r\n+<\/body>\r\n+<\/html>\r\n","filename":"doc\/testing.html","additions":255,"deletions":255,"binary":false,"changes":510,"status":"modified"},{"patch":"@@ -277,1 +277,1 @@\n-      conf_legacy_crosscompile=\"$conf_legacy_crosscompile $conf_option\" ;;\n+      conf_build_set=true ;;\n@@ -279,1 +279,1 @@\n-      conf_legacy_crosscompile=\"$conf_legacy_crosscompile $conf_option\" ;;\n+      conf_unsafe_crosscompile=\"$conf_unsafe_crosscompile $conf_option\" ;;\n@@ -281,1 +281,1 @@\n-      conf_legacy_crosscompile=\"$conf_legacy_crosscompile $conf_option\" ;;\n+      conf_unsafe_crosscompile=\"$conf_unsafe_crosscompile $conf_option\" ;;\n@@ -290,1 +290,1 @@\n-if test \"x$conf_legacy_crosscompile\" != \"x\"; then\n+if test \"x$conf_unsafe_crosscompile\" != \"x\"; then\n@@ -292,4 +292,4 @@\n-    echo \"Error: Specifying --openjdk-target together with autoconf\"\n-    echo \"legacy cross-compilation flags is not supported.\"\n-    echo \"You specified: --openjdk-target=$conf_openjdk_target and $conf_legacy_crosscompile.\"\n-    echo \"The recommended use is just --openjdk-target.\"\n+    echo \"Error: --openjdk-target was specified together with\"\n+    echo \"incompatible autoconf cross-compilation flags.\"\n+    echo \"You specified: --openjdk-target=$conf_openjdk_target and $conf_unsafe_crosscompile.\"\n+    echo \"It is recommended that you only use --openjdk-target.\"\n@@ -298,2 +298,2 @@\n-    echo \"Warning: You are using legacy autoconf cross-compilation flags.\"\n-    echo \"It is recommended that you use --openjdk-target instead.\"\n+    echo \"Warning: You are using unsafe autoconf cross-compilation flags.\"\n+    echo \"It is highly recommended that you use --openjdk-target instead.\"\n@@ -305,2 +305,7 @@\n-  conf_build_platform=`sh $conf_script_dir\/build-aux\/config.guess`\n-  conf_processed_arguments=(\"--build=$conf_build_platform\" \"--host=$conf_openjdk_target\" \"--target=$conf_openjdk_target\" \"${conf_processed_arguments[@]}\")\n+  conf_processed_arguments=(\"--host=$conf_openjdk_target\" \"--target=$conf_openjdk_target\" \"${conf_processed_arguments[@]}\")\n+  \n+  # If --build has been explicitly set don't override that flag with our own\n+  if test \"x$conf_build_set\" != xtrue; then\n+    conf_build_platform=`sh $conf_script_dir\/build-aux\/config.guess`\n+    conf_processed_arguments=(\"--build=$conf_build_platform\" \"${conf_processed_arguments[@]}\")\n+  fi\n@@ -344,1 +349,3 @@\n-                          --build=<current platform>\n+                          --build=<current platform>, or the platform you\n+                          have provided if you have explicitly passed\n+                          --build to configure\n","filename":"make\/autoconf\/configure","additions":20,"deletions":13,"binary":false,"changes":33,"status":"modified"}]}