{"files":[{"patch":"@@ -39,5 +39,1 @@\n-  D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const {\n-    D res = __atomic_add_fetch(dest, add_value, __ATOMIC_RELEASE);\n-    FULL_MEM_BARRIER;\n-    return res;\n-  }\n+  D add_and_fetch(D volatile* dest, I add_value, atomic_memory_order order) const;\n@@ -51,1 +47,88 @@\n-template<size_t byte_size>\n+template<>\n+template<typename D, typename I>\n+inline D Atomic::PlatformAdd<4>::add_and_fetch(D volatile* dest, I add_value,\n+                                               atomic_memory_order order) const {\n+  STATIC_ASSERT(4 == sizeof(I));\n+  STATIC_ASSERT(4 == sizeof(D));\n+\n+  D result;\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  __asm__ __volatile__ (\n+    \" amoadd.w %1, %2, %0  \\n\\t\"\n+    \" addw     %1, %1, %2  \\n\\t\"\n+    : \/*%0*\/\"+A\" (*dest), \/*%1*\/\"=&r\" (result)\n+    : \/*%2*\/\"r\" (add_value)\n+    : \"memory\" );\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  return result;\n+}\n+\n+\n+template<>\n+template<typename D, typename I>\n+inline D Atomic::PlatformAdd<8>::add_and_fetch(D volatile* dest, I add_value,\n+                                               atomic_memory_order order) const {\n+  STATIC_ASSERT(8 == sizeof(I));\n+  STATIC_ASSERT(8 == sizeof(D));\n+\n+  D result;\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  __asm__ __volatile__ (\n+    \" amoadd.d %1, %2, %0  \\n\\t\"\n+    \" add      %1, %1, %2  \\n\\t\"\n+    : \/*%0*\/\"+A\" (*dest), \/*%1*\/\"=&r\" (result)\n+    : \/*%2*\/\"r\" (add_value)\n+    : \"memory\" );\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  return result;\n+}\n+\n+template<>\n+template<typename T>\n+inline T Atomic::PlatformXchg<4>::operator()(T volatile* dest,\n+                                             T exchange_value,\n+                                             atomic_memory_order order) const {\n+  STATIC_ASSERT(4 == sizeof(T));\n+\n+  T old_value;\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  __asm__ __volatile__ (\n+    \" amoswap.w %1, %2, %0  \\n\\t\"\n+    : \/*%0*\/\"+A\" (*dest), \/*%1*\/\"=&r\" (old_value)\n+    : \/*%2*\/\"r\" (exchange_value)\n+    : \"memory\" );\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  return old_value;\n+}\n+\n+template<>\n@@ -53,7 +136,24 @@\n-inline T Atomic::PlatformXchg<byte_size>::operator()(T volatile* dest,\n-                                                     T exchange_value,\n-                                                     atomic_memory_order order) const {\n-  STATIC_ASSERT(byte_size == sizeof(T));\n-  T res = __atomic_exchange_n(dest, exchange_value, __ATOMIC_RELEASE);\n-  FULL_MEM_BARRIER;\n-  return res;\n+inline T Atomic::PlatformXchg<8>::operator()(T volatile* dest,\n+                                             T exchange_value,\n+                                             atomic_memory_order order) const {\n+  STATIC_ASSERT(8 == sizeof(T));\n+\n+  T old_value;\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  __asm__ __volatile__ (\n+    \" amoswap.d %1, %2, %0  \\n\\t\"\n+    : \/*%0*\/\"+A\" (*dest), \/*%1*\/\"=&r\" (old_value)\n+    : \/*%2*\/\"r\" (exchange_value)\n+    : \"memory\" );\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  return old_value;\n@@ -63,1 +163,1 @@\n-template<size_t byte_size>\n+template<>\n@@ -65,5 +165,5 @@\n-inline T Atomic::PlatformCmpxchg<byte_size>::operator()(T volatile* dest __attribute__((unused)),\n-                                                        T compare_value,\n-                                                        T exchange_value,\n-                                                        atomic_memory_order order) const {\n-  STATIC_ASSERT(byte_size == sizeof(T));\n+inline T Atomic::PlatformCmpxchg<1>::operator()(T volatile* dest __attribute__((unused)),\n+                                                T compare_value,\n+                                                T exchange_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(1 == sizeof(T));\n@@ -91,0 +191,4 @@\n+\n+  T old_value;\n+  long rc;\n+\n@@ -92,1 +196,2 @@\n-    FULL_MEM_BARRIER;\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n@@ -94,13 +199,12 @@\n-  T rv;\n-  int tmp;\n-  __asm volatile(\n-    \"1:\\n\\t\"\n-    \" addiw     %[tmp], %[cv], 0\\n\\t\" \/\/ make sure compare_value signed_extend\n-    \" lr.w.aq   %[rv], (%[dest])\\n\\t\"\n-    \" bne       %[rv], %[tmp], 2f\\n\\t\"\n-    \" sc.w.rl   %[tmp], %[ev], (%[dest])\\n\\t\"\n-    \" bnez      %[tmp], 1b\\n\\t\"\n-    \"2:\\n\\t\"\n-    : [rv] \"=&r\" (rv), [tmp] \"=&r\" (tmp)\n-    : [ev] \"r\" (exchange_value), [dest] \"r\" (dest), [cv] \"r\" (compare_value)\n-    : \"memory\");\n+\n+  __asm__ __volatile__ (\n+    \"1:  sext.w    %1, %3      \\n\\t\" \/\/ sign-extend compare_value\n+    \"    lr.w      %0, %2      \\n\\t\"\n+    \"    bne       %0, %1, 2f  \\n\\t\"\n+    \"    sc.w      %1, %4, %2  \\n\\t\"\n+    \"    bnez      %1, 1b      \\n\\t\"\n+    \"2:                        \\n\\t\"\n+    : \/*%0*\/\"=&r\" (old_value), \/*%1*\/\"=&r\" (rc), \/*%2*\/\"+A\" (*dest)\n+    : \/*%3*\/\"r\" (compare_value), \/*%4*\/\"r\" (exchange_value)\n+    : \"memory\" );\n+\n@@ -108,1 +212,21 @@\n-    FULL_MEM_BARRIER;\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  return old_value;\n+}\n+\n+template<>\n+template<typename T>\n+inline T Atomic::PlatformCmpxchg<8>::operator()(T volatile* dest __attribute__((unused)),\n+                                                T compare_value,\n+                                                T exchange_value,\n+                                                atomic_memory_order order) const {\n+  STATIC_ASSERT(8 == sizeof(T));\n+\n+  T old_value;\n+  long rc;\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n@@ -110,1 +234,17 @@\n-  return rv;\n+\n+  __asm__ __volatile__ (\n+    \"1:  lr.d      %0, %2      \\n\\t\"\n+    \"    bne       %0, %3, 2f  \\n\\t\"\n+    \"    sc.d      %1, %4, %2  \\n\\t\"\n+    \"    bnez      %1, 1b      \\n\\t\"\n+    \"2:                        \\n\\t\"\n+    : \/*%0*\/\"=&r\" (old_value), \/*%1*\/\"=&r\" (rc), \/*%2*\/\"+A\" (*dest)\n+    : \/*%3*\/\"r\" (compare_value), \/*%4*\/\"r\" (exchange_value)\n+    : \"memory\" );\n+\n+  if (order != memory_order_relaxed) {\n+    __asm__ __volatile__ (\n+      \" fence iorw, iorw  \\n\\t\" : : : \"memory\" );\n+  }\n+\n+  return old_value;\n","filename":"src\/hotspot\/os_cpu\/linux_riscv\/atomic_linux_riscv.hpp","additions":175,"deletions":35,"binary":false,"changes":210,"status":"modified"}]}