{"files":[{"patch":"@@ -5620,0 +5620,32 @@\n+\n+instruct vmask_tolong8B(iRegLNoSp dst, vecD src) %{\n+  match(Set dst (VectorMaskToLong src));\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"vmask_tolong $dst, $src\\t# convert mask to long (8B)\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    __ fmovd(as_Register($dst$$reg), as_FloatRegister($src$$reg));\n+    __ bytemask_compress(as_Register($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_tolong16B(iRegLNoSp dst, vecX src) %{\n+  match(Set dst (VectorMaskToLong src));\n+  ins_cost(11 * INSN_COST);\n+  format %{ \"vmask_tolong $dst, $src\\t# convert mask to long (16B)\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    __ umov(as_Register($dst$$reg), as_FloatRegister($src$$reg), __ D, 0);\n+    __ umov(rscratch1, as_FloatRegister($src$$reg), __ D, 1);\n+    __ bytemask_compress(as_Register($dst$$reg));\n+    __ bytemask_compress(rscratch1);\n+    __ orr(as_Register($dst$$reg), as_Register($dst$$reg),\n+           rscratch1, Assembler::LSL, 8);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon.ad","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -2484,0 +2484,32 @@\n+\n+instruct vmask_tolong8B(iRegLNoSp dst, vecD src) %{\n+  match(Set dst (VectorMaskToLong src));\n+  ins_cost(5 * INSN_COST);\n+  format %{ \"vmask_tolong $dst, $src\\t# convert mask to long (8B)\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    __ fmovd(as_Register($dst$$reg), as_FloatRegister($src$$reg));\n+    __ bytemask_compress(as_Register($dst$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_tolong16B(iRegLNoSp dst, vecX src) %{\n+  match(Set dst (VectorMaskToLong src));\n+  ins_cost(11 * INSN_COST);\n+  format %{ \"vmask_tolong $dst, $src\\t# convert mask to long (16B)\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    __ umov(as_Register($dst$$reg), as_FloatRegister($src$$reg), __ D, 0);\n+    __ umov(rscratch1, as_FloatRegister($src$$reg), __ D, 1);\n+    __ bytemask_compress(as_Register($dst$$reg));\n+    __ bytemask_compress(rscratch1);\n+    __ orr(as_Register($dst$$reg), as_Register($dst$$reg),\n+           rscratch1, Assembler::LSL, 8);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_neon_ad.m4","additions":32,"deletions":0,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -5749,0 +5749,16 @@\n+instruct vmask_tolong(iRegLNoSp dst, pReg src, vReg vtmp1, vReg vtmp2, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length() <= 64);\n+  match(Set dst (VectorMaskToLong src));\n+  effect(TEMP vtmp1, TEMP vtmp2, TEMP pgtmp, KILL cr);\n+  ins_cost(13 * SVE_COST);\n+  format %{ \"vmask_tolong $dst, $src\\t# vector mask tolong (sve)\" %}\n+  ins_encode %{\n+    __ sve_vmask_tolong(as_Register($dst$$reg), as_PRegister($src$$reg),\n+                        Matcher::vector_element_basic_type(this, $src),\n+                        Matcher::vector_length(this, $src),\n+                        as_FloatRegister($vtmp1$$reg), as_FloatRegister($vtmp2$$reg),\n+                        as_PRegister($pgtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve.ad","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -3179,0 +3179,17 @@\n+instruct vmask_tolong(iRegLNoSp dst, pReg src, vReg vtmp1, vReg vtmp2, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            n->in(1)->bottom_type()->is_vect()->length() <= 64);\n+  match(Set dst (VectorMaskToLong src));\n+  effect(TEMP vtmp1, TEMP vtmp2, TEMP pgtmp, KILL cr);\n+  ins_cost(13 * SVE_COST);\n+  format %{ \"vmask_tolong $dst, $src\\t# vector mask tolong (sve)\" %}\n+  ins_encode %{\n+    __ sve_vmask_tolong(as_Register($dst$$reg), as_PRegister($src$$reg),\n+                        Matcher::vector_element_basic_type(this, $src),\n+                        Matcher::vector_length(this, $src),\n+                        as_FloatRegister($vtmp1$$reg), as_FloatRegister($vtmp2$$reg),\n+                        as_PRegister($pgtmp$$reg));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}dnl\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_sve_ad.m4","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -949,0 +949,42 @@\n+\/\/ Compress the least significant bit of each byte to the rightmost and clear\n+\/\/ the higher garbage bits.\n+void C2_MacroAssembler::bytemask_compress(Register dst) {\n+  \/\/ Example input, dst = 0x01 00 00 00 01 01 00 01\n+  \/\/ The \"??\" bytes are garbage.\n+  orr(dst, dst, dst, Assembler::LSR, 7);  \/\/ dst = 0x?? 02 ?? 00 ?? 03 ?? 01\n+  orr(dst, dst, dst, Assembler::LSR, 14); \/\/ dst = 0x????????08 ??????0D\n+  orr(dst, dst, dst, Assembler::LSR, 28); \/\/ dst = 0x????????????????8D\n+  andr(dst, dst, 0xff);                   \/\/ dst = 0x8D\n+}\n+\n+\/\/ Pack the lowest-numbered bit of each mask element in src into a long value\n+\/\/ in dst, at most the first 64 lane elements.\n+\/\/ Clobbers: rscratch1\n+void C2_MacroAssembler::sve_vmask_tolong(Register dst, PRegister src, BasicType bt, int lane_cnt,\n+                                         FloatRegister vtmp1, FloatRegister vtmp2, PRegister pgtmp) {\n+  assert(pgtmp->is_governing(), \"This register has to be a governing predicate register.\");\n+  assert(lane_cnt <= 64 && is_power_of_2(lane_cnt), \"Unsupported lane count\");\n+  assert_different_registers(dst, rscratch1);\n+\n+  Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n+\n+  \/\/ Pack the mask into vector with sequential bytes.\n+  sve_cpy(vtmp1, size, src, 1, false);\n+  if (bt != T_BYTE) {\n+    sve_vector_narrow(vtmp1, B, vtmp1, size, vtmp2);\n+  }\n+\n+  \/\/ Compress the lowest 8 bytes.\n+  fmovd(dst, vtmp1);\n+  bytemask_compress(dst);\n+  if (lane_cnt <= 8) return;\n+\n+  \/\/ Repeat on higher bytes and join the results.\n+  \/\/ Compress 8 bytes in each iteration.\n+  for (int idx = 1; idx < (lane_cnt \/ 8); idx++) {\n+    idx == 1 ? fmovhid(rscratch1, vtmp1) : sve_extract(rscratch1, D, pgtmp, vtmp1, idx);\n+    bytemask_compress(rscratch1);\n+    orr(dst, dst, rscratch1, Assembler::LSL, idx << 3);\n+  }\n+}\n+\n@@ -1024,0 +1066,1 @@\n+  assert_different_registers(src, tmp);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":43,"deletions":0,"binary":false,"changes":43,"status":"modified"},{"patch":"@@ -58,0 +58,9 @@\n+  \/\/ Compress the least significant bit of each byte to the rightmost and clear\n+  \/\/ the higher garbage bits.\n+  void bytemask_compress(Register dst);\n+\n+  \/\/ Pack the lowest-numbered bit of each mask element in src into a long value\n+  \/\/ in dst, at most the first 64 lane elements.\n+  void sve_vmask_tolong(Register dst, PRegister src, BasicType bt, int lane_cnt,\n+                        FloatRegister vtmp1, FloatRegister vtmp2, PRegister pgtmp);\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"}]}