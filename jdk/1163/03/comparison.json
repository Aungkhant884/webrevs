{"files":[{"patch":"@@ -62,0 +62,1 @@\n+  void clear_archived_oops();\n@@ -126,0 +127,9 @@\n+void ArchivedClassLoaderData::clear_archived_oops() {\n+  assert(UseSharedSpaces, \"must be\");\n+  if (_modules != NULL) {\n+    for (int i = 0; i < _modules->length(); i++) {\n+      _modules->at(i)->clear_archived_oops();\n+    }\n+  }\n+}\n+\n@@ -186,0 +196,7 @@\n+void ClassLoaderDataShared::clear_archived_oops() {\n+  assert(UseSharedSpaces && !MetaspaceShared::use_full_module_graph(), \"must be\");\n+  _archived_boot_loader_data.clear_archived_oops();\n+  _archived_platform_loader_data.clear_archived_oops();\n+  _archived_system_loader_data.clear_archived_oops();\n+}\n+\n","filename":"src\/hotspot\/share\/classfile\/classLoaderDataShared.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+  static void clear_archived_oops();\n","filename":"src\/hotspot\/share\/classfile\/classLoaderDataShared.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -893,1 +893,1 @@\n-  if (k->is_shared() && k->has_raw_archived_mirror()) {\n+  if (k->is_shared() && k->has_archived_mirror_index()) {\n@@ -900,1 +900,1 @@\n-      k->clear_has_raw_archived_mirror();\n+      k->clear_archived_mirror_index();\n@@ -1166,3 +1166,3 @@\n-  if (k->has_raw_archived_mirror()) {\n-    assert(k->archived_java_mirror_raw() != NULL, \"no archived mirror\");\n-    return k->archived_java_mirror_raw();\n+  if (k->has_archived_mirror_index()) {\n+    assert(k->archived_java_mirror() != NULL, \"no archived mirror\");\n+    return k->archived_java_mirror();\n@@ -1200,3 +1200,1 @@\n-  k->set_archived_java_mirror_raw(archived_mirror);\n-\n-  k->set_has_raw_archived_mirror();\n+  k->set_archived_java_mirror(archived_mirror);\n@@ -1320,4 +1318,5 @@\n-  oop m = HeapShared::materialize_archived_object(k->archived_java_mirror_raw_narrow());\n-  if (m == NULL) {\n-    return false;\n-  }\n+  oop m = k->archived_java_mirror();\n+  assert(m != NULL, \"must have stored non-null archived mirror\");\n+\n+  \/\/ Sanity: clear it now to prevent re-initialization if any of the following fails\n+  k->clear_archived_mirror_index();\n@@ -1349,1 +1348,0 @@\n-  k->clear_has_raw_archived_mirror();\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":11,"deletions":13,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -470,1 +470,1 @@\n-    _archived_module_narrow_oop = CompressedOops::encode(m);\n+    _archived_module_index = HeapShared::append_root(m);\n@@ -484,2 +484,2 @@\n-void ModuleEntry::restore_archive_oops(ClassLoaderData* loader_data) {\n-  Handle module_handle(Thread::current(), HeapShared::materialize_archived_object(_archived_module_narrow_oop));\n+void ModuleEntry::restore_archived_oops(ClassLoaderData* loader_data) {\n+  Handle module_handle(Thread::current(), HeapShared::get_root(_archived_module_index, \/*clear=*\/true));\n@@ -498,0 +498,4 @@\n+void ModuleEntry::clear_archived_oops() {\n+  HeapShared::clear_root(_archived_module_index);\n+}\n+\n@@ -564,1 +568,1 @@\n-    archived_entry->restore_archive_oops(loader_data);\n+    archived_entry->restore_archived_oops(loader_data);\n","filename":"src\/hotspot\/share\/classfile\/moduleEntry.cpp","additions":8,"deletions":4,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -79,1 +79,1 @@\n-  CDS_JAVA_HEAP_ONLY(narrowOop _archived_module_narrow_oop;)\n+  CDS_JAVA_HEAP_ONLY(int _archived_module_index;)\n@@ -204,1 +204,2 @@\n-  void restore_archive_oops(ClassLoaderData* loader_data);\n+  void restore_archived_oops(ClassLoaderData* loader_data);\n+  void clear_archived_oops();\n","filename":"src\/hotspot\/share\/classfile\/moduleEntry.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1982,1 +1982,1 @@\n-  \/\/ Initialize basic classes\n+  \/\/ Resolve basic classes\n@@ -1984,0 +1984,4 @@\n+  \/\/ Resolve classes used by archived heap objects\n+  if (UseSharedSpaces) {\n+    HeapShared::resolve_classes(CHECK);\n+  }\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+  bool                         _is_early_klass;\n@@ -124,0 +125,1 @@\n+    _is_early_klass = JvmtiExport::is_early_phase();\n@@ -180,0 +182,5 @@\n+  \/\/ Was this class loaded while JvmtiExport::is_early_phase()==true\n+  bool is_early_klass() {\n+    return _is_early_klass;\n+  }\n+\n@@ -1328,0 +1335,5 @@\n+bool SystemDictionaryShared::is_early_klass(InstanceKlass* ik) {\n+  DumpTimeSharedClassInfo* info = _dumptime_table->get(ik);\n+  return (info != NULL) ? info->is_early_klass() : false;\n+}\n+\n@@ -2305,2 +2317,2 @@\n-    if (k->has_raw_archived_mirror()) {\n-      oop m = HeapShared::materialize_archived_object(k->archived_java_mirror_raw_narrow());\n+    if (k->has_archived_mirror_index()) {\n+      oop m = k->archived_java_mirror();\n","filename":"src\/hotspot\/share\/classfile\/systemDictionaryShared.cpp","additions":14,"deletions":2,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -232,0 +232,1 @@\n+  static bool is_early_klass(InstanceKlass* k);   \/\/ Was k loaded while JvmtiExport::is_early_phase()==true\n","filename":"src\/hotspot\/share\/classfile\/systemDictionaryShared.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -807,11 +807,0 @@\n-oop G1CollectedHeap::materialize_archived_object(oop obj) {\n-  assert(is_archived_object(obj), \"not an archived obj\");\n-\n-  \/\/ Loading an archived object makes it strongly reachable. If it is\n-  \/\/ loaded during concurrent marking, it must be enqueued to the SATB\n-  \/\/ queue, shading the previously white object gray.\n-  G1BarrierSet::enqueue(obj);\n-\n-  return obj;\n-}\n-\n@@ -4024,3 +4013,4 @@\n-void G1CollectedHeap::remove_from_old_sets(const uint old_regions_removed,\n-                                           const uint humongous_regions_removed) {\n-  if (old_regions_removed > 0 || humongous_regions_removed > 0) {\n+void G1CollectedHeap::remove_from_old_gen_sets(const uint old_regions_removed,\n+                                               const uint archive_regions_removed,\n+                                               const uint humongous_regions_removed) {\n+  if (old_regions_removed > 0 || archive_regions_removed > 0 || humongous_regions_removed > 0) {\n@@ -4029,0 +4019,1 @@\n+    _archive_set.bulk_remove(archive_regions_removed);\n@@ -4456,1 +4447,1 @@\n-  remove_from_old_sets(0, cl.humongous_regions_reclaimed());\n+  remove_from_old_gen_sets(0, 0, cl.humongous_regions_reclaimed());\n@@ -4531,1 +4522,1 @@\n-  \/\/ Remove the given HeapRegion from the appropriate region set.\n+\/\/ Remove the given HeapRegion from the appropriate region set.\n@@ -4533,1 +4524,5 @@\n-  if (hr->is_old()) {\n+   if (hr->is_archive()) {\n+    _archive_set.remove(hr);\n+  } else if (hr->is_humongous()) {\n+    _humongous_set.remove(hr);\n+  } else if (hr->is_old()) {\n@@ -4536,3 +4531,3 @@\n-    \/\/ Note that emptying the _young_list is postponed and instead done as\n-    \/\/ the first step when rebuilding the regions sets again. The reason for\n-    \/\/ this is that during a full GC string deduplication needs to know if\n+    \/\/ Note that emptying the eden and survivor lists is postponed and instead\n+    \/\/ done as the first step when rebuilding the regions sets again. The reason\n+    \/\/ for this is that during a full GC string deduplication needs to know if\n@@ -4543,3 +4538,1 @@\n-    \/\/ We ignore humongous and archive regions, we're not tearing down these\n-    \/\/ sets.\n-    assert(hr->is_archive() || hr->is_free() || hr->is_humongous(),\n+    assert(hr->is_free(),\n@@ -4570,0 +4563,3 @@\n+  HeapRegionSet* _archive_set;\n+  HeapRegionSet* _humongous_set;\n+\n@@ -4577,0 +4573,2 @@\n+                           HeapRegionSet* archive_set,\n+                           HeapRegionSet* humongous_set,\n@@ -4578,2 +4576,2 @@\n-    _free_list_only(free_list_only),\n-    _old_set(old_set), _hrm(hrm), _total_used(0) {\n+    _free_list_only(free_list_only), _old_set(old_set), _archive_set(archive_set),\n+    _humongous_set(humongous_set), _hrm(hrm), _total_used(0) {\n@@ -4583,0 +4581,2 @@\n+      assert(_archive_set->is_empty(), \"pre-condition\");\n+      assert(_humongous_set->is_empty(), \"pre-condition\");\n@@ -4595,2 +4595,4 @@\n-      if (r->is_archive() || r->is_humongous()) {\n-        \/\/ We ignore archive and humongous regions. We left these sets unchanged.\n+      if (r->is_humongous()) {\n+        _humongous_set->add(r);\n+      } else if (r->is_archive()) {\n+        _archive_set->add(r);\n@@ -4599,1 +4601,2 @@\n-        \/\/ We now move all (non-humongous, non-old, non-archive) regions to old gen, and register them as such.\n+        \/\/ We now move all (non-humongous, non-old, non-archive) regions to old gen,\n+        \/\/ and register them as such.\n@@ -4622,1 +4625,3 @@\n-  RebuildRegionSetsClosure cl(free_list_only, &_old_set, &_hrm);\n+  RebuildRegionSetsClosure cl(free_list_only,\n+                              &_old_set, &_archive_set, &_humongous_set,\n+                              &_hrm);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":34,"deletions":29,"binary":false,"changes":63,"status":"modified"},{"patch":"@@ -727,2 +727,0 @@\n-  oop materialize_archived_object(oop obj);\n-\n@@ -1125,1 +1123,3 @@\n-  void remove_from_old_sets(const uint old_regions_removed, const uint humongous_regions_removed);\n+  void remove_from_old_gen_sets(const uint old_regions_removed,\n+                                const uint archive_regions_removed,\n+                                const uint humongous_regions_removed);\n@@ -1317,3 +1317,1 @@\n-  \/\/ the region to which the object belongs. An object is dead\n-  \/\/ iff a) it was not allocated since the last mark, b) it\n-  \/\/ is not marked, and c) it is not in an archive region.\n+  \/\/ the region to which the object belongs.\n@@ -1321,3 +1319,1 @@\n-    return\n-      hr->is_obj_dead(obj, _cm->prev_mark_bitmap()) &&\n-      !hr->is_archive();\n+    return hr->is_obj_dead(obj, _cm->prev_mark_bitmap());\n@@ -1328,1 +1324,1 @@\n-  \/\/ been marked during this marking, and is not in an archive region.\n+  \/\/ been marked during this marking, and is not in a closed archive region.\n@@ -1333,1 +1329,1 @@\n-      !hr->is_archive();\n+      !hr->is_closed_archive();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":7,"deletions":11,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -285,1 +285,1 @@\n-   return !is_marked_next(obj) && !hr->is_archive();\n+   return !is_marked_next(obj) && !hr->is_closed_archive();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1203,0 +1203,1 @@\n+    uint _archive_regions_removed;\n@@ -1212,0 +1213,1 @@\n+      _archive_regions_removed(0),\n@@ -1216,0 +1218,1 @@\n+    const uint archive_regions_removed() { return _archive_regions_removed; }\n@@ -1219,1 +1222,3 @@\n-      if (hr->used() > 0 && hr->max_live_bytes() == 0 && !hr->is_young() && !hr->is_archive()) {\n+      if (hr->used() > 0 && hr->max_live_bytes() == 0 && !hr->is_young() && !hr->is_closed_archive()) {\n+        log_trace(gc)(\"Reclaimed empty old gen region %u (%s) bot \" PTR_FORMAT,\n+                      hr->hrm_index(), hr->get_short_type_str(), p2i(hr->bottom()));\n@@ -1225,0 +1230,3 @@\n+        } else if (hr->is_open_archive()) {\n+          _archive_regions_removed++;\n+          _g1h->free_region(hr, _local_cleanup_list);\n@@ -1231,1 +1239,0 @@\n-        log_trace(gc)(\"Reclaimed empty region %u (%s) bot \" PTR_FORMAT, hr->hrm_index(), hr->get_short_type_str(), p2i(hr->bottom()));\n@@ -1256,2 +1263,4 @@\n-    \/\/ Now update the old\/humongous region sets\n-    _g1h->remove_from_old_sets(cl.old_regions_removed(), cl.humongous_regions_removed());\n+    \/\/ Now update the old\/archive\/humongous region sets\n+    _g1h->remove_from_old_gen_sets(cl.old_regions_removed(),\n+                                   cl.archive_regions_removed(),\n+                                   cl.humongous_regions_removed());\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":13,"deletions":4,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -52,0 +52,5 @@\n+    } else if (hr->is_open_archive()) {\n+      bool is_empty = _bitmap->get_next_marked_addr(hr->bottom(), hr->top()) >= hr->top();\n+      if (is_empty) {\n+        free_open_archive_region(hr);\n+      }\n@@ -53,1 +58,3 @@\n-      assert(hr->is_archive(), \"Only archive regions can also be pinned.\");\n+      \/\/ There are no other pinned regions than humongous or all kinds of archive regions\n+      \/\/ at this time.\n+      assert(hr->is_closed_archive(), \"Only closed archive regions can also be pinned.\");\n@@ -90,2 +97,0 @@\n-  \/\/ Update humongous region sets\n-  closure.update_sets();\n@@ -107,1 +112,1 @@\n-    _humongous_regions_removed(0) { }\n+    _regions_freed(false) { }\n@@ -115,1 +120,1 @@\n-  _humongous_regions_removed++;\n+  _regions_freed = true;\n@@ -122,0 +127,16 @@\n+void G1FullGCPrepareTask::G1CalculatePointersClosure::free_open_archive_region(HeapRegion* hr) {\n+  assert(hr->is_pinned(), \"must be\");\n+  assert(!hr->is_humongous(), \"handled elsewhere\");\n+  assert(hr->is_open_archive(),\n+         \"Only Open archive regions may be freed here.\");\n+\n+  FreeRegionList dummy_free_list(\"Pinned Dummy Free List for G1MarkSweep\");\n+\n+  hr->set_containing_set(NULL);\n+  _regions_freed = true;\n+\n+  _g1h->free_region(hr, &dummy_free_list);\n+  prepare_for_compaction(hr);\n+  dummy_free_list.remove_all();\n+}\n+\n@@ -205,6 +226,0 @@\n-void G1FullGCPrepareTask::G1CalculatePointersClosure::update_sets() {\n-  \/\/ We'll recalculate total used bytes and recreate the free list\n-  \/\/ at the end of the GC, so no point in updating those values here.\n-  _g1h->remove_from_old_sets(0, _humongous_regions_removed);\n-}\n-\n@@ -212,2 +227,1 @@\n-  if (_humongous_regions_removed > 0) {\n-    \/\/ Free regions from dead humongous regions.\n+  if (_regions_freed) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.cpp","additions":27,"deletions":13,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-    uint _humongous_regions_removed;\n+    bool _regions_freed;\n@@ -64,0 +64,2 @@\n+    void free_open_archive_region(HeapRegion* hr);\n+\n@@ -70,1 +72,0 @@\n-    void update_sets();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCPrepareTask.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+#include \"gc\/g1\/g1Allocator.inline.hpp\"\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -180,0 +180,2 @@\n+  \/\/ An object is dead iff a) it was not allocated since the last mark (>TAMS), b) it\n+  \/\/ is not marked (bitmap).\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.hpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -169,1 +169,1 @@\n-         !is_open_archive();\n+         !is_closed_archive();\n","filename":"src\/hotspot\/share\/gc\/g1\/heapRegion.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -541,0 +541,3 @@\n+  product(bool, VerifyArchivedFields, trueInDebug, DIAGNOSTIC,              \\\n+          \"Verify memory when archived oop fields are loaded from CDS)\")    \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/gc\/shared\/gc_globals.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -249,0 +249,1 @@\n+    CDS_JAVA_HEAP_ONLY(_heap_obj_roots = CompressedOops::encode(HeapShared::roots());)\n@@ -1905,0 +1906,1 @@\n+      HeapShared::set_roots(header()->heap_obj_roots());\n","filename":"src\/hotspot\/share\/memory\/filemap.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -241,1 +241,1 @@\n-\n+  narrowOop _heap_obj_roots;            \/\/ An objArray that stores all the roots of archived heap objects\n@@ -289,0 +289,1 @@\n+  narrowOop heap_obj_roots()               const { return _heap_obj_roots; }\n@@ -298,0 +299,2 @@\n+  void set_heap_obj_roots(narrowOop r)           { _heap_obj_roots = r; }\n+\n","filename":"src\/hotspot\/share\/memory\/filemap.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+#include \"oops\/objArrayOop.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"prims\/jvmtiExport.hpp\"\n@@ -53,0 +55,2 @@\n+#include \"runtime\/globals_extension.hpp\"\n+#include \"runtime\/init.hpp\"\n@@ -108,0 +112,4 @@\n+GrowableArrayCHeap<oop, mtClassShared>* HeapShared::_pending_roots = NULL;\n+narrowOop HeapShared::_roots_narrow;\n+OopHandle HeapShared::_roots;\n+\n@@ -117,0 +125,7 @@\n+  if (is_mapped()) {\n+    _roots = OopHandle(Universe::vm_global(), decode_from_archive(_roots_narrow));\n+    if (!MetaspaceShared::use_full_module_graph()) {\n+      \/\/ Need to remove all the archived java.lang.Module objects from HeapShared::roots().\n+      ClassLoaderDataShared::clear_archived_oops();\n+    }\n+  }\n@@ -169,0 +184,63 @@\n+int HeapShared::append_root(oop obj) {\n+  assert(DumpSharedSpaces, \"dump-time only\");\n+\n+  \/\/ No GC should happen since we aren't scanning _pending_roots.\n+  assert(Thread::current() == (Thread*)VMThread::vm_thread(), \"should be in vm thread\");\n+\n+  if (_pending_roots == NULL) {\n+    _pending_roots = new GrowableArrayCHeap<oop, mtClassShared>(500);\n+  }\n+\n+  return _pending_roots->append(obj);\n+}\n+\n+objArrayOop HeapShared::roots() {\n+  if (DumpSharedSpaces) {\n+    assert(Thread::current() == (Thread*)VMThread::vm_thread(), \"should be in vm thread\");\n+    if (!is_heap_object_archiving_allowed()) {\n+      return NULL;\n+    }\n+  } else {\n+    assert(UseSharedSpaces, \"must be\");\n+  }\n+\n+  objArrayOop roots = (objArrayOop)_roots.resolve();\n+  assert(roots != NULL, \"should have been initialized\");\n+  return roots;\n+}\n+\n+void HeapShared::set_roots(narrowOop roots) {\n+  assert(UseSharedSpaces, \"runtime only\");\n+  assert(open_archive_heap_region_mapped(), \"must be\");\n+  _roots_narrow = roots;\n+}\n+\n+oop HeapShared::get_root(int index, bool clear) {\n+  assert(index >= 0, \"sanity\");\n+  if (DumpSharedSpaces) {\n+    assert(Thread::current() == (Thread*)VMThread::vm_thread(), \"should be in vm thread\");\n+    assert(_pending_roots != NULL, \"sanity\");\n+    return _pending_roots->at(index);\n+  } else {\n+    assert(UseSharedSpaces, \"must be\");\n+    assert(!_roots.is_empty(), \"must have loaded shared heap\");\n+    oop result = roots()->obj_at(index);\n+    if (clear) {\n+      clear_root(index);\n+    }\n+    return result;\n+  }\n+}\n+\n+void HeapShared::clear_root(int index) {\n+  assert(index >= 0, \"sanity\");\n+  assert(UseSharedSpaces, \"must be\");\n+  if (open_archive_heap_region_mapped()) {\n+    if (log_is_enabled(Debug, cds, heap)) {\n+      oop old = roots()->obj_at(index);\n+      log_debug(cds, heap)(\"Clearing root %d: was \" PTR_FORMAT, index, p2i(old));\n+    }\n+    roots()->obj_at_put(index, NULL);\n+  }\n+}\n+\n@@ -204,2 +282,5 @@\n-    log_debug(cds, heap)(\"Archived heap object \" PTR_FORMAT \" ==> \" PTR_FORMAT,\n-                         p2i(obj), p2i(archived_oop));\n+    if (log_is_enabled(Debug, cds, heap)) {\n+      ResourceMark rm;\n+      log_debug(cds, heap)(\"Archived heap object \" PTR_FORMAT \" ==> \" PTR_FORMAT \" : %s\",\n+                           p2i(obj), p2i(archived_oop), obj->klass()->external_name());\n+    }\n@@ -217,10 +298,0 @@\n-oop HeapShared::materialize_archived_object(narrowOop v) {\n-  assert(archive_heap_region_fixed(),\n-         \"must be called after archive heap regions are fixed\");\n-  if (!CompressedOops::is_null(v)) {\n-    oop obj = HeapShared::decode_from_archive(v);\n-    return G1CollectedHeap::heap()->materialize_archived_object(obj);\n-  }\n-  return NULL;\n-}\n-\n@@ -263,0 +334,1 @@\n+\/\/ Returns an objArray that contains all the roots of the archived objects\n@@ -280,4 +352,0 @@\n-    if (MetaspaceShared::use_full_module_graph()) {\n-      ClassLoaderDataShared::init_archived_oops();\n-    }\n-\n@@ -332,0 +400,1 @@\n+    ClassLoaderDataShared::init_archived_oops();\n@@ -334,0 +403,2 @@\n+  copy_roots();\n+\n@@ -338,0 +409,29 @@\n+\/\/ Copy _pending_archive_roots into an objArray\n+void HeapShared::copy_roots() {\n+  int length = _pending_roots != NULL ? _pending_roots->length() : 0;\n+  int size = objArrayOopDesc::object_size(length);\n+  Klass *k = Universe::objectArrayKlassObj(); \/\/ already relocated to point to archived klass\n+  HeapWord* mem = G1CollectedHeap::heap()->archive_mem_allocate(size);\n+\n+  memset(mem, 0, size * BytesPerWord);\n+  {\n+    \/\/ This is copied from MemAllocator::finish\n+    if (UseBiasedLocking) {\n+      oopDesc::set_mark(mem, k->prototype_header());\n+    } else {\n+      oopDesc::set_mark(mem, markWord::prototype());\n+    }\n+    oopDesc::release_set_klass(mem, k);\n+  }\n+  {\n+    \/\/ This is copied from ObjArrayAllocator::initialize\n+    arrayOopDesc::set_length(mem, length);\n+  }\n+\n+  _roots = OopHandle(Universe::vm_global(), (oop)mem);\n+  for (int i = 0; i < length; i++) {\n+    roots()->obj_at_put(i, _pending_roots->at(i));\n+  }\n+  log_info(cds)(\"archived obj roots[%d] = %d words, klass = %p, obj = %p\", length, size, k, mem);\n+}\n+\n@@ -377,1 +477,1 @@\n-      new(ResourceObj::C_HEAP, mtClass) GrowableArray<juint>(10, mtClass);\n+      new(ResourceObj::C_HEAP, mtClass) GrowableArray<int>(10, mtClass);\n@@ -379,3 +479,2 @@\n-  _subgraph_entry_fields->append((juint)static_field_offset);\n-  _subgraph_entry_fields->append(CompressedOops::narrow_oop_value(v));\n-  _subgraph_entry_fields->append(is_closed_archive ? 1 : 0);\n+  _subgraph_entry_fields->append(static_field_offset);\n+  _subgraph_entry_fields->append(HeapShared::append_root(v));\n@@ -440,0 +539,18 @@\n+  _has_non_early_klasses |= is_non_early_klass(orig_k);\n+}\n+\n+bool KlassSubGraphInfo::is_non_early_klass(Klass* k) {\n+  if (k->is_objArray_klass()) {\n+    k = ObjArrayKlass::cast(k)->bottom_klass();\n+  }\n+  if (k->is_instance_klass()) {\n+    if (!SystemDictionaryShared::is_early_klass(InstanceKlass::cast(k))) {\n+      ResourceMark rm;\n+      log_info(cds, heap)(\"non-early: %s\", k->external_name());\n+      return true;\n+    } else {\n+      return false;\n+    }\n+  } else {\n+    return false;\n+  }\n@@ -448,0 +565,8 @@\n+  _has_non_early_klasses = info->has_non_early_klasses();\n+\n+  if (_has_non_early_klasses) {\n+    ResourceMark rm;\n+    log_info(cds, heap)(\n+          \"Subgraph of klass %s has non-early klasses and cannot be used when JVMTI ClassFileLoadHook is enabled\",\n+          _k->external_name());\n+  }\n@@ -450,1 +575,1 @@\n-  GrowableArray<juint>* entry_fields = info->subgraph_entry_fields();\n+  GrowableArray<int>* entry_fields = info->subgraph_entry_fields();\n@@ -453,1 +578,1 @@\n-    assert(num_entry_fields % 3 == 0, \"sanity\");\n+    assert(num_entry_fields % 2 == 0, \"sanity\");\n@@ -455,1 +580,1 @@\n-      MetaspaceShared::new_ro_array<juint>(num_entry_fields);\n+      MetaspaceShared::new_ro_array<int>(num_entry_fields);\n@@ -528,0 +653,62 @@\n+static void verify_the_heap(Klass* k, const char* which) {\n+  if (VerifyArchivedFields) {\n+    ResourceMark rm;\n+    log_info(cds, heap)(\"Verify heap %s initializing static field(s) in %s\",\n+                        which, k->external_name());\n+    VM_Verify verify_op;\n+    VMThread::execute(&verify_op);\n+    if (!FLAG_IS_DEFAULT(VerifyArchivedFields)) {\n+      \/\/ If this -XX:+VerifyArchivedFields is specified on the command-line, do extra\n+      \/\/ checks.\n+      if (is_init_completed()) {\n+        FlagSetting fs1(VerifyBeforeGC, true);\n+        FlagSetting fs2(VerifyDuringGC, true);\n+        FlagSetting fs3(VerifyAfterGC,  true);\n+        Universe::heap()->collect(GCCause::_java_lang_system_gc);\n+      }\n+    }\n+  }\n+}\n+\n+\/\/ Before GC can execute, we must ensure that all oops reachable from HeapShared::roots()\n+\/\/ have a valid klass. I.e., oopDesc::klass() must have already been resolved.\n+\/\/\n+\/\/ Note: if a ArchivedKlassSubGraphInfoRecord contains non-early classes, and JVMTI\n+\/\/ ClassFileLoadHook is enabled, it's possible for this class to be dynamically replaced. In\n+\/\/ this case, we will not load the ArchivedKlassSubGraphInfoRecord and will clear its roots.\n+void HeapShared::resolve_classes(TRAPS) {\n+  if (!is_mapped()) {\n+    return; \/\/ nothing to do\n+  }\n+  resolve_classes_for_subgraphs(closed_archive_subgraph_entry_fields,\n+                                num_closed_archive_subgraph_entry_fields,\n+                                CHECK);\n+  resolve_classes_for_subgraphs(open_archive_subgraph_entry_fields,\n+                                num_open_archive_subgraph_entry_fields,\n+                                CHECK);\n+  resolve_classes_for_subgraphs(fmg_open_archive_subgraph_entry_fields,\n+                                num_fmg_open_archive_subgraph_entry_fields,\n+                                CHECK);\n+}\n+\n+void HeapShared::resolve_classes_for_subgraphs(ArchivableStaticFieldInfo fields[],\n+                                               int num, TRAPS) {\n+  for (int i = 0; i < num; i++) {\n+    ArchivableStaticFieldInfo* info = &fields[i];\n+    TempNewSymbol klass_name = SymbolTable::new_symbol(info->klass_name);\n+    InstanceKlass* k = SystemDictionaryShared::find_builtin_class(klass_name);\n+    assert(k != NULL && k->is_shared_boot_class(), \"sanity\");\n+    resolve_classes_for_subgraph_of(k, CHECK);\n+  }\n+}\n+\n+void HeapShared::resolve_classes_for_subgraph_of(Klass* k, TRAPS) {\n+ const ArchivedKlassSubGraphInfoRecord* record = resolve_or_init_classes_for_subgraph_of(k, \/*do_init=*\/false, THREAD);\n+ if (HAS_PENDING_EXCEPTION) {\n+   CLEAR_PENDING_EXCEPTION;\n+ }\n+ if (record == NULL) {\n+   clear_archived_roots_of(k);\n+ }\n+}\n+\n@@ -529,1 +716,1 @@\n-  if (!open_archive_heap_region_mapped()) {\n+  if (!is_mapped()) {\n@@ -532,0 +719,19 @@\n+\n+  const ArchivedKlassSubGraphInfoRecord* record =\n+    resolve_or_init_classes_for_subgraph_of(k, \/*do_init=*\/true, THREAD);\n+\n+  if (HAS_PENDING_EXCEPTION) {\n+    CLEAR_PENDING_EXCEPTION;\n+    \/\/ None of the field value will be set if there was an exception when initializing the classes.\n+    \/\/ The java code will not see any of the archived objects in the\n+    \/\/ subgraphs referenced from k in this case.\n+    return;\n+  }\n+\n+  if (record != NULL) {\n+    init_archived_fields_for(k, record, THREAD);\n+  }\n+}\n+\n+const ArchivedKlassSubGraphInfoRecord*\n+HeapShared::resolve_or_init_classes_for_subgraph_of(Klass* k, bool do_init, TRAPS) {\n@@ -541,1 +747,6 @@\n-      return;\n+      if (log_is_enabled(Info, cds, heap)) {\n+        ResourceMark rm;\n+        log_info(cds, heap)(\"subgraph %s cannot be used because full module graph is disabled\",\n+                            k->external_name());\n+      }\n+      return NULL;\n@@ -544,1 +755,11 @@\n-    int i;\n+    if (record->has_non_early_klasses() && JvmtiExport::should_post_class_file_load_hook()) {\n+      if (log_is_enabled(Info, cds, heap)) {\n+        ResourceMark rm;\n+        log_info(cds, heap)(\"subgraph %s cannot be used because JVMTI ClassFileLoadHook is enabled\",\n+                            k->external_name());\n+      }\n+      return NULL;\n+    }\n+\n+    resolve_or_init(k, do_init, CHECK_NULL);\n+\n@@ -549,19 +770,2 @@\n-      for (i = 0; i < klasses->length(); i++) {\n-        Klass* obj_k = klasses->at(i);\n-        Klass* resolved_k = SystemDictionary::resolve_or_null(\n-                                              (obj_k)->name(), THREAD);\n-        if (resolved_k != obj_k) {\n-          assert(!SystemDictionary::is_well_known_klass(resolved_k),\n-                 \"shared well-known classes must not be replaced by JVMTI ClassFileLoadHook\");\n-          ResourceMark rm(THREAD);\n-          log_info(cds, heap)(\"Failed to load subgraph because %s was not loaded from archive\",\n-                              resolved_k->external_name());\n-          return;\n-        }\n-        if ((obj_k)->is_instance_klass()) {\n-          InstanceKlass* ik = InstanceKlass::cast(obj_k);\n-          ik->initialize(THREAD);\n-        } else if ((obj_k)->is_objArray_klass()) {\n-          ObjArrayKlass* oak = ObjArrayKlass::cast(obj_k);\n-          oak->initialize(THREAD);\n-        }\n+      for (int i = 0; i < klasses->length(); i++) {\n+        resolve_or_init(klasses->at(i), do_init, CHECK_NULL);\n@@ -570,0 +774,1 @@\n+  }\n@@ -571,6 +776,45 @@\n-    if (HAS_PENDING_EXCEPTION) {\n-      CLEAR_PENDING_EXCEPTION;\n-      \/\/ None of the field value will be set if there was an exception.\n-      \/\/ The java code will not see any of the archived objects in the\n-      \/\/ subgraphs referenced from k in this case.\n-      return;\n+  return record;\n+}\n+\n+void HeapShared::resolve_or_init(Klass* k, bool do_init, TRAPS) {\n+  if (!do_init) {\n+    if (k->class_loader_data() == NULL) {\n+      Klass* resolved_k = SystemDictionary::resolve_or_null(k->name(), CHECK);\n+      assert(resolved_k == k, \"classes used by archived heap must not be replaced by JVMTI ClassFileLoadHook\");\n+    }\n+  } else {\n+    assert(k->class_loader_data() != NULL, \"must have been resolved by HeapShared::resolve_classes\");\n+    if (k->is_instance_klass()) {\n+      InstanceKlass* ik = InstanceKlass::cast(k);\n+      ik->initialize(CHECK);\n+    } else if (k->is_objArray_klass()) {\n+      ObjArrayKlass* oak = ObjArrayKlass::cast(k);\n+      oak->initialize(CHECK);\n+    }\n+  }\n+}\n+\n+void HeapShared::init_archived_fields_for(Klass* k, const ArchivedKlassSubGraphInfoRecord* record, TRAPS) {\n+  verify_the_heap(k, \"before\");\n+\n+  \/\/ Load the subgraph entry fields from the record and store them back to\n+  \/\/ the corresponding fields within the mirror.\n+  oop m = k->java_mirror();\n+  Array<int>* entry_field_records = record->entry_field_records();\n+  if (entry_field_records != NULL) {\n+    int efr_len = entry_field_records->length();\n+    assert(efr_len % 2 == 0, \"sanity\");\n+    for (int i = 0; i < efr_len; i += 2) {\n+      int field_offset = entry_field_records->at(i);\n+      int root_index = entry_field_records->at(i+1);\n+      oop v = get_root(root_index, \/*clear=*\/true);\n+      m->obj_field_put(field_offset, v);\n+      log_debug(cds, heap)(\"  \" PTR_FORMAT \" init field @ %2d = \" PTR_FORMAT, p2i(k), field_offset, p2i(v));\n+    }\n+\n+    \/\/ Done. Java code can see the archived sub-graphs referenced from k's\n+    \/\/ mirror after this point.\n+    if (log_is_enabled(Info, cds, heap)) {\n+      ResourceMark rm;\n+      log_info(cds, heap)(\"initialize_from_archived_subgraph %s \" PTR_FORMAT \"%s\",\n+                          k->external_name(), p2i(k), JvmtiExport::is_early_phase() ? \" (early)\" : \"\");\n@@ -578,0 +822,4 @@\n+  }\n+\n+  verify_the_heap(k, \"after \");\n+}\n@@ -579,4 +827,5 @@\n-    \/\/ Load the subgraph entry fields from the record and store them back to\n-    \/\/ the corresponding fields within the mirror.\n-    oop m = k->java_mirror();\n-    Array<juint>* entry_field_records = record->entry_field_records();\n+void HeapShared::clear_archived_roots_of(Klass* k) {\n+  unsigned int hash = SystemDictionaryShared::hash_for_shared_dictionary(k);\n+  const ArchivedKlassSubGraphInfoRecord* record = _run_time_subgraph_info_table.lookup(k, hash, 0);\n+  if (record != NULL) {\n+    Array<int>* entry_field_records = record->entry_field_records();\n@@ -585,29 +834,4 @@\n-      assert(efr_len % 3 == 0, \"sanity\");\n-      for (i = 0; i < efr_len;) {\n-        int field_offset = entry_field_records->at(i);\n-        narrowOop nv = CompressedOops::narrow_oop_cast(entry_field_records->at(i+1));\n-        int is_closed_archive = entry_field_records->at(i+2);\n-        oop v;\n-        if (is_closed_archive == 0) {\n-          \/\/ It's an archived object in the open archive heap regions, not shared.\n-          \/\/ The object refereced by the field becomes 'known' by GC from this\n-          \/\/ point. All objects in the subgraph reachable from the object are\n-          \/\/ also 'known' by GC.\n-          v = materialize_archived_object(nv);\n-        } else {\n-          \/\/ Shared object in the closed archive heap regions. Decode directly.\n-          assert(!CompressedOops::is_null(nv), \"shared object is null\");\n-          v = HeapShared::decode_from_archive(nv);\n-        }\n-        m->obj_field_put(field_offset, v);\n-        i += 3;\n-\n-        log_debug(cds, heap)(\"  \" PTR_FORMAT \" init field @ %2d = \" PTR_FORMAT, p2i(k), field_offset, p2i(v));\n-      }\n-\n-      \/\/ Done. Java code can see the archived sub-graphs referenced from k's\n-      \/\/ mirror after this point.\n-      if (log_is_enabled(Info, cds, heap)) {\n-        ResourceMark rm;\n-        log_info(cds, heap)(\"initialize_from_archived_subgraph %s \" PTR_FORMAT,\n-                            k->external_name(), p2i(k));\n+      assert(efr_len % 2 == 0, \"sanity\");\n+      for (int i = 0; i < efr_len; i += 2) {\n+        int root_index = entry_field_records->at(i+1);\n+        clear_root(root_index);\n","filename":"src\/hotspot\/share\/memory\/heapShared.cpp","additions":308,"deletions":84,"binary":false,"changes":392,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"oops\/oopHandle.hpp\"\n@@ -67,1 +68,1 @@\n-  GrowableArray<juint>*  _subgraph_entry_fields;\n+  GrowableArray<int>* _subgraph_entry_fields;\n@@ -69,0 +70,1 @@\n+  \/\/ Does this KlassSubGraphInfo belong to the archived full module graph\n@@ -70,0 +72,7 @@\n+\n+  \/\/ Does this KlassSubGraphInfo references any classes that were loaded while\n+  \/\/ JvmtiExport::is_early_phase()!=true. If so, this KlassSubGraphInfo cannot be\n+  \/\/ used at runtime if JVMTI ClassFileLoadHook is enabled.\n+  bool _has_non_early_klasses;\n+  static bool is_non_early_klass(Klass* k);\n+\n@@ -74,1 +83,3 @@\n-    _is_full_module_graph(is_full_module_graph) {}\n+    _is_full_module_graph(is_full_module_graph),\n+    _has_non_early_klasses(false) {}\n+\n@@ -88,1 +99,1 @@\n-  GrowableArray<juint>*  subgraph_entry_fields() {\n+  GrowableArray<int>* subgraph_entry_fields() {\n@@ -99,0 +110,1 @@\n+  bool has_non_early_klasses() const { return _has_non_early_klasses; }\n@@ -108,0 +120,1 @@\n+  bool _has_non_early_klasses;\n@@ -110,1 +123,1 @@\n-  Array<juint>* _entry_field_records;\n+  Array<int>* _entry_field_records;\n@@ -120,1 +133,1 @@\n-  Array<juint>*  entry_field_records() const { return _entry_field_records; }\n+  Array<int>* entry_field_records() const { return _entry_field_records; }\n@@ -123,0 +136,1 @@\n+  bool has_non_early_klasses() const { return _has_non_early_klasses; }\n@@ -227,0 +241,4 @@\n+  static GrowableArrayCHeap<oop, mtClassShared>* _pending_roots;\n+  static narrowOop _roots_narrow;\n+  static OopHandle _roots;\n+\n@@ -257,1 +275,10 @@\n-\n+  static void copy_roots();\n+\n+  static void resolve_classes_for_subgraphs(ArchivableStaticFieldInfo fields[],\n+                                            int num, TRAPS);\n+  static void resolve_classes_for_subgraph_of(Klass* k, TRAPS);\n+  static void clear_archived_roots_of(Klass* k);\n+  static const ArchivedKlassSubGraphInfoRecord*\n+               resolve_or_init_classes_for_subgraph_of(Klass* k, bool do_init, TRAPS);\n+  static void resolve_or_init(Klass* k, bool do_init, TRAPS);\n+  static void init_archived_fields_for(Klass* k, const ArchivedKlassSubGraphInfoRecord* record, TRAPS);\n@@ -274,1 +301,0 @@\n-  static oop materialize_archived_object(narrowOop v);\n@@ -298,0 +324,26 @@\n+\n+  \/\/ We use the HeapShared::roots() array to make sure that objects stored in the\n+  \/\/ archived heap regions are not prematurely collected. These roots include:\n+  \/\/\n+  \/\/    - mirrors of classes that have not yet been loaded.\n+  \/\/    - ConstantPool::resolved_references() of classes that have not yet been loaded.\n+  \/\/    - ArchivedKlassSubGraphInfoRecords that have not been initialized\n+  \/\/    - java.lang.Module objects that have not yet been added to the module graph\n+  \/\/\n+  \/\/ When a mirror M becomes referenced by a newly loaded class K, M will be removed\n+  \/\/ from HeapShared::roots() via clear_root(), and K will be responsible for\n+  \/\/ keeping M alive.\n+  \/\/\n+  \/\/ Other types of roots are also cleared similarly when they become referenced.\n+\n+  \/\/ Dump-time only. Returns the index of the root, which can be used at run time to read\n+  \/\/ the root using get_root(index, ...).\n+  static int append_root(oop obj);\n+\n+  \/\/ Dump-time and runtime\n+  static objArrayOop roots();\n+  static oop get_root(int index, bool clear=false);\n+\n+  \/\/ Run-time only\n+  static void set_roots(narrowOop roots);\n+  static void clear_root(int index);\n@@ -310,1 +362,1 @@\n-                               idx <= MetaspaceShared::last_open_archive_heap_region));\n+                               idx <= MetaspaceShared::last_open_archive_heap_region);)\n@@ -315,1 +367,1 @@\n-    CDS_JAVA_HEAP_ONLY(_closed_archive_heap_region_mapped = true);\n+    CDS_JAVA_HEAP_ONLY(_closed_archive_heap_region_mapped = true;)\n@@ -319,1 +371,1 @@\n-    CDS_JAVA_HEAP_ONLY(return _closed_archive_heap_region_mapped);\n+    CDS_JAVA_HEAP_ONLY(return _closed_archive_heap_region_mapped;)\n@@ -323,1 +375,1 @@\n-    CDS_JAVA_HEAP_ONLY(_open_archive_heap_region_mapped = true);\n+    CDS_JAVA_HEAP_ONLY(_open_archive_heap_region_mapped = true;)\n@@ -327,1 +379,1 @@\n-    CDS_JAVA_HEAP_ONLY(return _open_archive_heap_region_mapped);\n+    CDS_JAVA_HEAP_ONLY(return _open_archive_heap_region_mapped;)\n@@ -330,0 +382,3 @@\n+  static bool is_mapped() {\n+    return closed_archive_heap_region_mapped() && open_archive_heap_region_mapped();\n+  }\n@@ -335,0 +390,1 @@\n+  static void resolve_classes(TRAPS) NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/memory\/heapShared.hpp","additions":68,"deletions":12,"binary":false,"changes":80,"status":"modified"},{"patch":"@@ -508,1 +508,1 @@\n-  CDS_JAVA_HEAP_ONLY(ClassLoaderDataShared::serialize(soc));\n+  CDS_JAVA_HEAP_ONLY(ClassLoaderDataShared::serialize(soc);)\n@@ -1480,2 +1480,0 @@\n-\n-          disable_full_module_graph(); \/\/ Disabled temporarily for JDK-8253081\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -375,0 +375,1 @@\n+      _cache->clear_archived_references();\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -777,1 +777,1 @@\n-  if (CompressedOops::is_null(_archived_references)) {\n+  if (_archived_references_index < 0) {\n@@ -780,1 +780,8 @@\n-  return HeapShared::materialize_archived_object(_archived_references);\n+  return HeapShared::get_root(_archived_references_index);\n+}\n+\n+void ConstantPoolCache::clear_archived_references() {\n+  if (_archived_references_index >= 0) {\n+    HeapShared::clear_root(_archived_references_index);\n+    _archived_references_index = -1;\n+  }\n@@ -785,1 +792,1 @@\n-  _archived_references = CompressedOops::encode(o);\n+  _archived_references_index = HeapShared::append_root(o);\n","filename":"src\/hotspot\/share\/oops\/cpCache.cpp","additions":10,"deletions":3,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -420,1 +420,1 @@\n-  CDS_JAVA_HEAP_ONLY(narrowOop _archived_references;)\n+  CDS_JAVA_HEAP_ONLY(int _archived_references_index;)\n@@ -447,0 +447,1 @@\n+  void clear_archived_references() NOT_CDS_JAVA_HEAP_RETURN;\n","filename":"src\/hotspot\/share\/oops\/cpCache.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -92,1 +92,1 @@\n-  CDS_JAVA_HEAP_ONLY(_archived_references = narrowOop::null;)\n+  CDS_JAVA_HEAP_ONLY(_archived_references_index = -1;)\n","filename":"src\/hotspot\/share\/oops\/cpCache.inline.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -55,1 +55,7 @@\n-      if (klass->is_instance_klass() && klass->class_loader_data()->has_class_mirror_holder()) {\n+      if (klass->class_loader_data() == NULL) {\n+        \/\/ This is a mirror that belongs to a shared class that has not be loaded yet.\n+        \/\/ It's only reachable via HeapShared::roots(). All of its fields should be zero\n+        \/\/ so there's no need to scan.\n+        assert(klass->is_shared(), \"must be\");\n+        return;\n+      } else if (klass->is_instance_klass() && klass->class_loader_data()->has_class_mirror_holder()) {\n","filename":"src\/hotspot\/share\/oops\/instanceMirrorKlass.inline.hpp","additions":7,"deletions":1,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -208,1 +208,1 @@\n-  CDS_JAVA_HEAP_ONLY(_archived_mirror = narrowOop::null;)\n+  CDS_JAVA_HEAP_ONLY(_archived_mirror_index = -1;)\n@@ -577,1 +577,0 @@\n-    \/\/ Restore class_loader_data to the null class loader data\n@@ -580,1 +579,1 @@\n-    \/\/ Add to null class loader list first before creating the mirror\n+    \/\/ Add to class loader list first before creating the mirror\n@@ -601,1 +600,1 @@\n-  if (this->has_raw_archived_mirror()) {\n+  if (this->has_archived_mirror_index()) {\n@@ -616,1 +615,1 @@\n-    this->clear_has_raw_archived_mirror();\n+    this->clear_archived_mirror_index();\n@@ -629,4 +628,3 @@\n-\/\/ Used at CDS dump time to access the archived mirror. No GC barrier.\n-oop Klass::archived_java_mirror_raw() {\n-  assert(has_raw_archived_mirror(), \"must have raw archived mirror\");\n-  return CompressedOops::decode(_archived_mirror);\n+oop Klass::archived_java_mirror() {\n+  assert(has_archived_mirror_index(), \"must have archived mirror\");\n+  return HeapShared::get_root(_archived_mirror_index);\n@@ -635,3 +633,5 @@\n-narrowOop Klass::archived_java_mirror_raw_narrow() {\n-  assert(has_raw_archived_mirror(), \"must have raw archived mirror\");\n-  return _archived_mirror;\n+void Klass::clear_archived_mirror_index() {\n+  if (_archived_mirror_index >= 0) {\n+    HeapShared::clear_root(_archived_mirror_index);\n+  }\n+  _archived_mirror_index = -1;\n@@ -641,1 +641,1 @@\n-void Klass::set_archived_java_mirror_raw(oop m) {\n+void Klass::set_archived_java_mirror(oop m) {\n@@ -643,1 +643,1 @@\n-  _archived_mirror = CompressedOops::encode(m);\n+  _archived_mirror_index = HeapShared::append_root(m);\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -179,1 +179,0 @@\n-    _has_raw_archived_mirror = 1,\n@@ -184,3 +183,1 @@\n-  \/\/ The _archived_mirror is set at CDS dump time pointing to the cached mirror\n-  \/\/ in the open archive heap region when archiving java object is supported.\n-  CDS_JAVA_HEAP_ONLY(narrowOop _archived_mirror;)\n+  CDS_JAVA_HEAP_ONLY(int _archived_mirror_index;)\n@@ -265,3 +262,2 @@\n-  oop archived_java_mirror_raw() NOT_CDS_JAVA_HEAP_RETURN_(NULL); \/\/ no GC barrier\n-  narrowOop archived_java_mirror_raw_narrow() NOT_CDS_JAVA_HEAP_RETURN_(narrowOop::null); \/\/ no GC barrier\n-  void set_archived_java_mirror_raw(oop m) NOT_CDS_JAVA_HEAP_RETURN; \/\/ no GC barrier\n+  oop archived_java_mirror() NOT_CDS_JAVA_HEAP_RETURN_(NULL);\n+  void set_archived_java_mirror(oop m) NOT_CDS_JAVA_HEAP_RETURN;\n@@ -310,9 +306,3 @@\n-  void set_has_raw_archived_mirror() {\n-    CDS_ONLY(_shared_class_flags |= _has_raw_archived_mirror;)\n-  }\n-  void clear_has_raw_archived_mirror() {\n-    CDS_ONLY(_shared_class_flags &= ~_has_raw_archived_mirror;)\n-  }\n-  bool has_raw_archived_mirror() const {\n-    CDS_ONLY(return (_shared_class_flags & _has_raw_archived_mirror) != 0;)\n-    NOT_CDS(return false;)\n+  bool has_archived_mirror_index() const {\n+    CDS_JAVA_HEAP_ONLY(return _archived_mirror_index >= 0;)\n+    NOT_CDS_JAVA_HEAP(return false);\n@@ -321,0 +311,2 @@\n+  void clear_archived_mirror_index() NOT_CDS_JAVA_HEAP_RETURN;\n+\n@@ -537,1 +529,1 @@\n-    if (has_raw_archived_mirror()) {\n+    if (has_archived_mirror_index()) {\n","filename":"src\/hotspot\/share\/oops\/klass.hpp","additions":9,"deletions":17,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -88,1 +88,0 @@\n-runtime\/cds\/serviceability\/ReplaceCriticalClassesForSubgraphs.java 8253081 generic-all\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -175,4 +175,1 @@\n-        if (subgraph) {\n-            opts.addSuffix(\"-Xlog:cds,cds+heap\");\n-        }\n-\n+        opts.addSuffix(\"-Xlog:cds,cds+heap\");\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/serviceability\/ReplaceCriticalClasses.java","additions":1,"deletions":4,"binary":false,"changes":5,"status":"modified"}]}