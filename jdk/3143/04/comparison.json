{"files":[{"patch":"@@ -167,6 +167,0 @@\n-  \/\/ Second-level allocation: Should be called while holding a\n-  \/\/ lock. It will try to first allocate lock-free out of the active\n-  \/\/ region or, if it's unable to, it will try to replace the active\n-  \/\/ alloc region with a new one. We require that the caller takes the\n-  \/\/ appropriate lock before calling this so that it is easier to make\n-  \/\/ it conform to its locking protocol.\n@@ -174,4 +168,6 @@\n-  \/\/ Same as attempt_allocation_locked(size_t, bool), but allowing specification\n-  \/\/ of minimum word size of the block in min_word_size, and the maximum word\n-  \/\/ size of the allocation in desired_word_size. The actual size of the block is\n-  \/\/ returned in actual_word_size.\n+  \/\/ Second-level allocation: Should be called while holding a\n+  \/\/ lock. We require that the caller takes the appropriate lock\n+  \/\/ before calling this so that it is easier to make it conform\n+  \/\/ to the locking protocol.\n+  \/\/ Tries to allocate at least min_word_size words, and at most desired_word_size.\n+  \/\/ Returns the actual size of the block in actual_word_size.\n@@ -182,0 +178,4 @@\n+  inline HeapWord* attempt_allocation_use_new_region(size_t min_word_size,\n+                                                     size_t desired_word_size,\n+                                                     size_t* actual_word_size);\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1AllocRegion.hpp","additions":10,"deletions":10,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -101,3 +101,0 @@\n-  \/\/ First we have to redo the allocation, assuming we're holding the\n-  \/\/ appropriate lock, in case another thread changed the region while\n-  \/\/ we were waiting to get the lock.\n@@ -109,0 +106,6 @@\n+  return attempt_allocation_use_new_region(min_word_size, desired_word_size, actual_word_size);\n+}\n+\n+inline HeapWord* G1AllocRegion::attempt_allocation_use_new_region(size_t min_word_size,\n+                                                                  size_t desired_word_size,\n+                                                                  size_t* actual_word_size) {\n@@ -110,1 +113,1 @@\n-  result = new_alloc_region_and_allocate(desired_word_size, false \/* force *\/);\n+  HeapWord* result = new_alloc_region_and_allocate(desired_word_size, false \/* force *\/);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1AllocRegion.inline.hpp","additions":7,"deletions":4,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -115,0 +115,3 @@\n+  \/\/ Attempt allocation in the current alloc region. If use_retained_region_if_available\n+  \/\/ is set and a retained region is available, the allocation will first be tried in the\n+  \/\/ retained region.\n@@ -118,0 +121,7 @@\n+\n+  \/\/ Attempt allocation, retiring the current region and allocating a new one. It is\n+  \/\/ assumed that attempt_allocation() has been tried and failed already first.\n+  inline HeapWord* attempt_allocation_use_new_region(size_t word_size);\n+\n+  \/\/ This is to be called when holding an appropriate lock. It first tries in the\n+  \/\/ current allocation region, and then attempts an allocation using a new region.\n@@ -119,0 +129,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -55,0 +55,2 @@\n+\n+\n@@ -59,0 +61,1 @@\n+\n@@ -62,0 +65,9 @@\n+inline HeapWord* G1Allocator::attempt_allocation_use_new_region(size_t word_size) {\n+  uint node_index = current_node_index();\n+  size_t temp;\n+  HeapWord* result = mutator_alloc_region(node_index)->attempt_allocation_use_new_region(word_size, word_size, &temp);\n+  assert(result != NULL || mutator_alloc_region(node_index)->get() == NULL,\n+         \"Must not have a mutator alloc region if there is no memory, but is \" PTR_FORMAT, p2i(mutator_alloc_region(node_index)->get()));\n+  return result;\n+}\n+\n@@ -65,0 +77,1 @@\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Allocator.inline.hpp","additions":13,"deletions":0,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -426,0 +426,1 @@\n+    bool proactive_collection_required = false;\n@@ -430,1 +431,5 @@\n-      result = _allocator->attempt_allocation_locked(word_size);\n+\n+      \/\/ Now that we have the lock, we first retry the allocation in case another\n+      \/\/ thread changed the region while we were waiting to acquire the lock.\n+      size_t actual_size;\n+      result = _allocator->attempt_allocation(word_size, word_size, &actual_size);\n@@ -435,7 +440,5 @@\n-      \/\/ If the GCLocker is active and we are bound for a GC, try expanding young gen.\n-      \/\/ This is different to when only GCLocker::needs_gc() is set: try to avoid\n-      \/\/ waiting because the GCLocker is active to not wait too long.\n-      if (GCLocker::is_active_and_needs_gc() && policy()->can_expand_young_list()) {\n-        \/\/ No need for an ergo message here, can_expand_young_list() does this when\n-        \/\/ it returns true.\n-        result = _allocator->attempt_allocation_force(word_size);\n+      proactive_collection_required = policy()->proactive_collection_required(1);\n+      if (!proactive_collection_required) {\n+        \/\/ We've already attempted a lock-free allocation above, so we don't want to\n+        \/\/ do it again. Let's jump straight to replacing the active region.\n+        result = _allocator->attempt_allocation_use_new_region(word_size);\n@@ -445,0 +448,12 @@\n+\n+        \/\/ If the GCLocker is active and we are bound for a GC, try expanding young gen.\n+        \/\/ This is different to when only GCLocker::needs_gc() is set: try to avoid\n+        \/\/ waiting because the GCLocker is active to not wait too long.\n+        if (GCLocker::is_active_and_needs_gc() && policy()->can_expand_young_list()) {\n+          \/\/ No need for an ergo message here, can_expand_young_list() does this when\n+          \/\/ it returns true.\n+          result = _allocator->attempt_allocation_force(word_size);\n+          if (result != NULL) {\n+            return result;\n+          }\n+        }\n@@ -446,0 +461,1 @@\n+\n@@ -455,0 +471,2 @@\n+      GCCause::Cause gc_cause = proactive_collection_required ? GCCause::_g1_proactive_collection\n+                                                              : GCCause::_g1_inc_collection_pause;\n@@ -456,2 +474,1 @@\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded,\n-                                   GCCause::_g1_inc_collection_pause);\n+      result = do_collection_pause(word_size, gc_count_before, &succeeded, gc_cause);\n@@ -851,0 +868,1 @@\n+    bool proactive_collection_required = false;\n@@ -857,9 +875,12 @@\n-      \/\/ Given that humongous objects are not allocated in young\n-      \/\/ regions, we'll first try to do the allocation without doing a\n-      \/\/ collection hoping that there's enough space in the heap.\n-      result = humongous_obj_allocate(word_size);\n-      if (result != NULL) {\n-        size_t size_in_regions = humongous_obj_size_in_regions(word_size);\n-        policy()->old_gen_alloc_tracker()->\n-          add_allocated_humongous_bytes_since_last_gc(size_in_regions * HeapRegion::GrainBytes);\n-        return result;\n+      size_t size_in_regions = humongous_obj_size_in_regions(word_size);\n+      proactive_collection_required = policy()->proactive_collection_required((uint)size_in_regions);\n+      if (!proactive_collection_required) {\n+        \/\/ Given that humongous objects are not allocated in young\n+        \/\/ regions, we'll first try to do the allocation without doing a\n+        \/\/ collection hoping that there's enough space in the heap.\n+        result = humongous_obj_allocate(word_size);\n+        if (result != NULL) {\n+          policy()->old_gen_alloc_tracker()->\n+            add_allocated_humongous_bytes_since_last_gc(size_in_regions * HeapRegion::GrainBytes);\n+          return result;\n+        }\n@@ -877,0 +898,2 @@\n+      GCCause::Cause gc_cause = proactive_collection_required ? GCCause::_g1_proactive_collection\n+                                                              : GCCause::_g1_humongous_allocation;\n@@ -878,2 +901,1 @@\n-      result = do_collection_pause(word_size, gc_count_before, &succeeded,\n-                                   GCCause::_g1_humongous_allocation);\n+      result = do_collection_pause(word_size, gc_count_before, &succeeded, gc_cause);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":43,"deletions":21,"binary":false,"changes":64,"status":"modified"},{"patch":"@@ -71,0 +71,2 @@\n+  _predicted_surviving_bytes_from_survivor(0),\n+  _predicted_surviving_bytes_from_old(0),\n@@ -453,0 +455,1 @@\n+  update_survival_estimates_for_next_collection();\n@@ -782,0 +785,1 @@\n+  update_survival_estimates_for_next_collection();\n@@ -1403,0 +1407,79 @@\n+\/\/ Number of regions required to store the given number of bytes, taking\n+\/\/ into account the target amount of wasted space in PLABs.\n+static size_t get_num_regions_adjust_for_plab_waste(size_t byte_count) {\n+  size_t byte_count_adjusted = byte_count * (size_t)(100 + TargetPLABWastePct) \/ 100.0;\n+\n+  \/\/ Round up the region count\n+  return (byte_count_adjusted + HeapRegion::GrainBytes - 1) \/ HeapRegion::GrainBytes;\n+}\n+\n+bool G1Policy::proactive_collection_required(uint alloc_region_count) {\n+  if (!Universe::is_fully_initialized()) {\n+    \/\/ Don't attempt any proactive GC's before initialization is complete.\n+    return false;\n+  }\n+\n+  if (_g1h->young_regions_count() == 0 && _collection_set->candidates() != NULL && _collection_set->candidates()->is_empty()) {\n+    return false;\n+  }\n+\n+  uint eden_count = _g1h->eden_regions_count();\n+  size_t const eden_surv_bytes_pred = _eden_surv_rate_group->accum_surv_rate_pred(eden_count) * HeapRegion::GrainBytes;\n+  size_t const total_young_predicted_surviving_bytes = eden_surv_bytes_pred + _predicted_surviving_bytes_from_survivor;\n+\n+  uint required_regions = (uint)(get_num_regions_adjust_for_plab_waste(total_young_predicted_surviving_bytes) +\n+                                get_num_regions_adjust_for_plab_waste(_predicted_surviving_bytes_from_old));\n+\n+  if (required_regions > _g1h->num_free_regions() - alloc_region_count) {\n+    log_debug(gc, ergo, cset)(\"Proactive GC, insufficient free regions. Predicted need %u. Curr Eden %u (Pred %u). Curr Survivor %u (Pred %u). Curr Old %u (Pred %u) Free %u Alloc %u\",\n+            required_regions,\n+            eden_count,\n+            (uint)get_num_regions_adjust_for_plab_waste(eden_surv_bytes_pred),\n+            _g1h->survivor_regions_count(),\n+            (uint)get_num_regions_adjust_for_plab_waste(_predicted_surviving_bytes_from_survivor),\n+            _g1h->old_regions_count(),\n+            (uint)get_num_regions_adjust_for_plab_waste(_predicted_surviving_bytes_from_old),\n+            _g1h->num_free_regions(),\n+            alloc_region_count);\n+\n+    return true;\n+  }\n+\n+  return false;\n+}\n+\n+void G1Policy::update_survival_estimates_for_next_collection() {\n+  \/\/ Predict the number of bytes of surviving objects from survivor and old\n+  \/\/ regions and update the associated members.\n+\n+  \/\/ Survivor regions\n+  size_t survivor_bytes = 0;\n+  const GrowableArray<HeapRegion*>* survivor_regions = _g1h->survivor()->regions();\n+  for (GrowableArrayIterator<HeapRegion*> it = survivor_regions->begin();\n+       it != survivor_regions->end();\n+       ++it) {\n+    survivor_bytes += predict_bytes_to_copy(*it);\n+  }\n+\n+  _predicted_surviving_bytes_from_survivor = survivor_bytes;\n+\n+  \/\/ Old regions\n+  G1CollectionSetCandidates *candidates = _collection_set->candidates();\n+  if (candidates == NULL || candidates->is_empty()) {\n+    _predicted_surviving_bytes_from_old = 0;\n+    return;\n+  }\n+\n+  \/\/ Use the minimum old gen collection set as conservative estimate for the number\n+  \/\/ of regions to take for this calculation.\n+  uint iterate_count = MIN2(candidates->num_remaining(), calc_min_old_cset_length(candidates));\n+  uint current_index = candidates->cur_idx();\n+  size_t old_bytes = 0;\n+  for (uint i = 0; i < iterate_count; i++) {\n+    HeapRegion *region = candidates->at(current_index + i);\n+    old_bytes += predict_bytes_to_copy(region);\n+  }\n+\n+  _predicted_surviving_bytes_from_old = old_bytes;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":83,"deletions":0,"binary":false,"changes":83,"status":"modified"},{"patch":"@@ -101,0 +101,5 @@\n+  \/\/ These values are predictions of how much we think will survive in each\n+  \/\/ section of the heap.\n+  size_t _predicted_surviving_bytes_from_survivor;\n+  size_t _predicted_surviving_bytes_from_old;\n+\n@@ -348,0 +353,5 @@\n+  \/\/ Returns whether a collection should be done proactively, taking into\n+  \/\/ account the current number of free regions and the expected survival\n+  \/\/ rates in each section of the heap.\n+  bool proactive_collection_required(uint region_count);\n+\n@@ -349,0 +359,5 @@\n+\n+  \/\/ Predict the number of bytes of surviving objects from survivor and old\n+  \/\/ regions and update the associated members.\n+  void update_survival_estimates_for_next_collection();\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.hpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -125,1 +125,1 @@\n-  if (_word_size > 0) {\n+  if (_word_size > 0 && _gc_cause != GCCause::_g1_proactive_collection) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1VMOperations.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -102,0 +102,3 @@\n+    case _g1_proactive_collection:\n+      return \"G1 Proactive Collection\";\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/gcCause.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -76,0 +76,1 @@\n+    _g1_proactive_collection,\n","filename":"src\/hotspot\/share\/gc\/shared\/gcCause.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -317,1 +317,1 @@\n-        private static Object[] holder = new Object[200]; \/\/ Must be larger than G1EvacuationFailureALotCount\n+        private static Object[] holder = new Object[800]; \/\/ Must be larger than G1EvacuationFailureALotCount\n@@ -322,1 +322,1 @@\n-            \/\/ Create 16 MB of garbage. This should result in at least one GC,\n+            \/\/ Create 64 MB of garbage. This should result in at least one GC,\n@@ -324,1 +324,2 @@\n-            \/\/ which is larger than G1EvacuationFailureALotInterval.\n+            \/\/ which is larger than G1EvacuationFailureALotInterval and enough\n+            \/\/ will survive to cause the evacuation failure.\n@@ -326,1 +327,1 @@\n-                holder[i % holder.length] = new byte[1024];\n+                holder[i % holder.length] = new byte[4096];\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestGCLogMessages.java","additions":5,"deletions":4,"binary":false,"changes":9,"status":"modified"}]}