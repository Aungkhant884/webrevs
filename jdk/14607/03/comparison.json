{"files":[{"patch":"@@ -61,0 +61,1 @@\n+#include \"services\/memTracker.hpp\"\n@@ -336,0 +337,23 @@\n+ccstr Arguments::process_nmt_property(JavaVMInitArgs* args) {\n+  ccstr nmt = NativeMemoryTracking;\n+\n+  \/\/ Find out user NMT setting\n+  for (int index = 0; index < args->nOptions; index++) {\n+    const JavaVMOption* option = args->options + index;\n+    const char* tail;\n+    if (match_option(option, \"-XX:NativeMemoryTracking=\", &tail)) {\n+      nmt = tail;\n+    }\n+  }\n+\n+  \/\/ Verify NMT arguments\n+  const NMT_TrackingLevel level = NMTUtil::parse_tracking_level(nmt);\n+  if (level == NMT_unknown) {\n+    jio_fprintf(defaultStream::error_stream(),\n+                \"Syntax error, expecting -XX:NativeMemoryTracking=[off|summary|detail]\", nullptr);\n+    return nullptr;\n+  }\n+\n+  return nmt;\n+}\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":24,"deletions":0,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -452,0 +452,3 @@\n+\n+  static ccstr process_nmt_property(JavaVMInitArgs* args);\n+\n","filename":"src\/hotspot\/share\/runtime\/arguments.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -677,2 +677,0 @@\n-\n-  \/\/ Special handling for NMT preinit phase before arguments are parsed\n@@ -680,3 +678,0 @@\n-  if (NMTPreInit::handle_realloc(&rc, memblock, size, memflags)) {\n-    return rc;\n-  }\n","filename":"src\/hotspot\/share\/runtime\/os.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -418,0 +418,5 @@\n+  \/\/ Initialize the NMT memory tracking as early as possible\n+  ccstr nmt = Arguments::process_nmt_property(args);\n+  if (nmt == nullptr) return JNI_ERR;\n+  MemTracker::initialize(nmt);\n+\n@@ -453,2 +458,2 @@\n-  \/\/ Initialize NMT right after argument parsing to keep the pre-NMT-init window small.\n-  MemTracker::initialize();\n+  \/\/ Verify NMT flag(s) and log the initial state to the ouput\n+  MemTracker::post_initialize();\n","filename":"src\/hotspot\/share\/runtime\/threads.cpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -86,1 +86,0 @@\n-  MallocLimitHandler::initialize(MallocLimit);\n","filename":"src\/hotspot\/share\/services\/mallocTracker.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -55,1 +55,1 @@\n-void MemTracker::initialize() {\n+void MemTracker::initialize(ccstr value) {\n@@ -59,1 +59,1 @@\n-  NMT_TrackingLevel level = NMTUtil::parse_tracking_level(NativeMemoryTracking);\n+  NMT_TrackingLevel level = NMTUtil::parse_tracking_level(value);\n@@ -62,1 +62,1 @@\n-         \"Invalid setting for NativeMemoryTracking (%s)\", NativeMemoryTracking);\n+         \"Invalid setting for NativeMemoryTracking (%s)\", value);\n@@ -77,4 +77,0 @@\n-  } else {\n-    if (MallocLimit != nullptr) {\n-      warning(\"MallocLimit will be ignored since NMT is disabled.\");\n-    }\n@@ -86,0 +82,10 @@\n+}\n+\n+void MemTracker::post_initialize() {\n+  if (_tracking_level == NMT_off) {\n+    if (MallocLimit != nullptr) {\n+      warning(\"MallocLimit will be ignored since NMT is disabled.\");\n+    }\n+  } else {\n+    MallocLimitHandler::initialize(MallocLimit);\n+  }\n","filename":"src\/hotspot\/share\/services\/memTracker.cpp","additions":13,"deletions":7,"binary":false,"changes":20,"status":"modified"},{"patch":"@@ -76,1 +76,2 @@\n-  static void initialize();\n+  static void initialize(ccstr value);\n+  static void post_initialize();\n","filename":"src\/hotspot\/share\/services\/memTracker.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -37,1 +37,0 @@\n-static void* raw_realloc(void* old, size_t s)   { ALLOW_C_FUNCTION(::realloc, return ::realloc(old, s);) }\n@@ -52,8 +51,0 @@\n-static void* raw_checked_realloc(void* old, size_t s) {\n-  void* p = raw_realloc(old, s);\n-  if (p == nullptr) {\n-    vm_exit_out_of_memory(s, OOM_MALLOC_ERROR, \"VM early initialization phase\");\n-  }\n-  return p;\n-}\n-\n@@ -76,8 +67,0 @@\n-NMTPreInitAllocation* NMTPreInitAllocation::do_reallocate(NMTPreInitAllocation* a, size_t new_payload_size) {\n-  assert(a->next == nullptr, \"unhang from map first\");\n-  void* new_payload = raw_checked_realloc(a->payload, new_payload_size);\n-  NMTPreInitAllocation* a2 = new NMTPreInitAllocation(new_payload_size, new_payload);\n-  delete a;\n-  return a2;\n-}\n-\n@@ -153,6 +136,0 @@\n-  \/\/ This verifies the buildup of the lookup table, including the load and the chain lengths.\n-  \/\/ We should see chain lens of 0-1 under normal conditions. Under artificial conditions\n-  \/\/ (20000 VM args) we should see maybe 6-7. From a certain length on we can be sure something\n-  \/\/ is broken.\n-  const int longest_acceptable_chain_len = 30;\n-  int num_chains_too_long = 0;\n@@ -175,7 +152,0 @@\n-    if (len > longest_acceptable_chain_len) {\n-      num_chains_too_long++;\n-    }\n-  }\n-  if (num_chains_too_long > 0) {\n-    assert(false, \"NMT preinit lookup table degenerated (%d\/%d chains longer than %d)\",\n-                  num_chains_too_long, table_size, longest_acceptable_chain_len);\n@@ -192,1 +162,0 @@\n-unsigned NMTPreInit::_num_reallocs_pre = 0;\n@@ -217,1 +186,1 @@\n-    \/\/ That may leak about 12KB of memory for ~500 surviving pre-init allocations, which is a typical\n+    \/\/ That may leak about 64 bytes of memory for 2 surviving pre-init allocations, which is a typical\n@@ -231,2 +200,1 @@\n-  assert(_num_reallocs_pre <= _num_mallocs_pre &&\n-         _num_frees_pre <= _num_mallocs_pre, \"stats are off\");\n+  assert(_num_frees_pre <= _num_mallocs_pre, \"stats are off\");\n@@ -241,2 +209,1 @@\n-  st->print_cr(\"pre-init mallocs: %u, pre-init reallocs: %u, pre-init frees: %u\",\n-               _num_mallocs_pre, _num_reallocs_pre, _num_frees_pre);\n+  st->print_cr(\"pre-init mallocs: %u, pre-init frees: %u\", _num_mallocs_pre, _num_frees_pre);\n","filename":"src\/hotspot\/share\/services\/nmtPreInit.cpp","additions":3,"deletions":36,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -84,2 +84,2 @@\n-\/\/   -> VM initialization before arg parsing            |\n-\/\/   -> VM argument parsing                             v\n+\/\/   -> VM_Version::early_initialize()                  |\n+\/\/   -> is_supported_jni_version()                      v\n@@ -89,1 +89,1 @@\n-\/\/   -> VM life...                               NMT post-init phase : lookup table is read-only; use it in os::free() and os::realloc().\n+\/\/   -> VM life...                               NMT post-init phase : lookup table is read-only; use it in os::free().\n@@ -94,12 +94,0 @@\n-\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n-\/\/\n-\/\/ Notes:\n-\/\/ - The VM will malloc() and realloc() several thousand times before NMT initialization.\n-\/\/   Starting with a lot of arguments increases this number since argument parsing strdups\n-\/\/   around a lot.\n-\/\/ - However, *surviving* allocations (allocations not freed immediately) are much rarer:\n-\/\/   typically only about 300-500. Again, mainly depending on the number of VM args.\n-\/\/ - There are a few cases of pre-to-post-init reallocs where pre-init allocations get\n-\/\/   reallocated after NMT initialization. Those we need to handle with special care (see\n-\/\/   NMTPreInit::handle_realloc()). Because of them we need to store allocation size with\n-\/\/   every pre-init allocation.\n@@ -115,1 +103,1 @@\n-\/\/ We use a basic open hashmap, dimensioned generously - hash collisions should be very rare.\n+\/\/ We use a basic open hashmap using mersenne prime and mod operator - hash collisions should be very rare.\n@@ -128,1 +116,1 @@\n-  \/\/ These functions do raw-malloc\/realloc\/free a C-heap block of given payload size,\n+  \/\/ These functions do raw-malloc\/free a C-heap block of given payload size,\n@@ -131,1 +119,0 @@\n-  static NMTPreInitAllocation* do_reallocate(NMTPreInitAllocation* a, size_t new_payload_size);\n@@ -142,5 +129,4 @@\n-  \/\/ 8000ish is really plenty: normal VM runs have ~500 pre-init allocations to hold,\n-  \/\/  VMs with insanely long command lines maybe ~700-1000. Which gives us an expected\n-  \/\/  load factor of ~.1. Hash collisions should be very rare.\n-  \/\/ ~8000 entries cost us ~64K for this table (64-bit), which is acceptable.\n-  static const int table_size = 7919;\n+  \/\/ We chose 127, as this is a Mersenne prime (2^x - 1), which for a random\n+  \/\/  polynomial modulo p = (2^x - 1) is uniformily distributed in [p], so each\n+  \/\/  bit has the same distribution.\n+  static const int table_size = 127; \/\/ i.e. 127==(2^7 - 1);\n@@ -153,5 +139,4 @@\n-  static unsigned calculate_hash(const void* p) {\n-    uintptr_t tmp = p2i(p);\n-    unsigned hash = (unsigned)tmp\n-                     LP64_ONLY( ^ (unsigned)(tmp >> 32));\n-    return hash;\n+  static uint64_t calculate_hash(const void* p) {\n+    \/\/ Keep hash function simple, the modulo\n+    \/\/ operation in index function will do the \"heavy lifting\".\n+    return (uint64_t)(p);\n@@ -161,1 +146,2 @@\n-    const unsigned hash = calculate_hash(p);\n+    const uint64_t hash = calculate_hash(p);\n+    \/\/ \"table_size\" is a Mersenne prime, so \"modulo\" is all we need here.\n@@ -227,1 +213,0 @@\n-  static unsigned _num_reallocs_pre;          \/\/ Number of pre-init reallocs\n@@ -280,52 +265,0 @@\n-  \/\/ Called from os::realloc.\n-  \/\/ Returns true if reallocation was handled here; in that case,\n-  \/\/ *rc contains the return address.\n-  static bool handle_realloc(void** rc, void* old_p, size_t new_size, MEMFLAGS memflags) {\n-    if (old_p == nullptr) {                  \/\/ realloc(null, n)\n-      return handle_malloc(rc, new_size);\n-    }\n-    new_size = MAX2((size_t)1, new_size); \/\/ realloc(.., 0)\n-    switch (MemTracker::tracking_level()) {\n-      case NMT_unknown: {\n-        \/\/ pre-NMT-init:\n-        \/\/ - the address must already be in the lookup table\n-        \/\/ - find the old entry, remove from table, reallocate, add to table\n-        NMTPreInitAllocation* a = find_and_remove_in_map(old_p);\n-        a = NMTPreInitAllocation::do_reallocate(a, new_size);\n-        add_to_map(a);\n-        (*rc) = a->payload;\n-        _num_reallocs_pre++;\n-        return true;\n-      }\n-      break;\n-      case NMT_off: {\n-        \/\/ post-NMT-init, NMT *disabled*:\n-        \/\/ Neither pre- nor post-init-allocation use malloc headers, therefore we can just\n-        \/\/ relegate the realloc to os::realloc.\n-        return false;\n-      }\n-      break;\n-      default: {\n-        \/\/ post-NMT-init, NMT *enabled*:\n-        \/\/ Pre-init allocation does not use malloc header, but from here on we need malloc headers.\n-        \/\/ Therefore, the new block must be allocated with os::malloc.\n-        \/\/ We do this by:\n-        \/\/ - look up (but don't remove! lu table is read-only here.) the old entry\n-        \/\/ - allocate new memory via os::malloc()\n-        \/\/ - manually copy the old content over\n-        \/\/ - return the new memory\n-        \/\/ - The lu table is readonly, so we keep the old address in the table. And we leave\n-        \/\/   the old block allocated too, to prevent the libc from returning the same address\n-        \/\/   and confusing us.\n-        const NMTPreInitAllocation* a = find_in_map(old_p);\n-        if (a != nullptr) { \/\/ this was originally a pre-init allocation\n-          void* p_new = do_os_malloc(new_size, memflags);\n-          ::memcpy(p_new, a->payload, MIN2(a->size, new_size));\n-          (*rc) = p_new;\n-          return true;\n-        }\n-      }\n-    }\n-    return false;\n-  }\n-\n@@ -353,1 +286,1 @@\n-        \/\/ relegate the realloc to os::realloc.\n+        \/\/ relegate the free to os::free.\n@@ -364,1 +297,2 @@\n-        if (find_in_map(p) != nullptr) {\n+        const NMTPreInitAllocation* a = find_in_map(p);\n+        if (a != nullptr) {\n","filename":"src\/hotspot\/share\/services\/nmtPreInit.hpp","additions":18,"deletions":84,"binary":false,"changes":102,"status":"modified"},{"patch":"@@ -124,40 +124,0 @@\n-\n-\/\/\/\/\/\/\/\n-\n-\/\/ Test that we notice block corruption on realloc too\n-static void test_corruption_on_realloc(size_t s1, size_t s2) {\n-  address p1 = (address) os::malloc(s1, mtTest);\n-  *(p1 + s1) = 'a';\n-  address p2 = (address) os::realloc(p1, s2, mtTest);\n-\n-  \/\/ Still here?\n-  tty->print_cr(\"NMT did not detect corruption on os::realloc?\");\n-  \/\/ Note: don't use ASSERT here, that does not work as expected in death tests. Just\n-  \/\/ let the test run its course, it should notice something is amiss.\n-}\n-static void test_corruption_on_realloc_growing()    { test_corruption_on_realloc(0x10, 0x11); }\n-DEFINE_TEST(test_corruption_on_realloc_growing, COMMON_NMT_HEAP_CORRUPTION_MESSAGE_PREFIX);\n-static void test_corruption_on_realloc_shrinking()  { test_corruption_on_realloc(0x11, 0x10); }\n-DEFINE_TEST(test_corruption_on_realloc_shrinking, COMMON_NMT_HEAP_CORRUPTION_MESSAGE_PREFIX);\n-\n-\/\/\/\/\/\/\/\n-\n-\/\/ realloc is the trickiest of the bunch. Test that realloc works and correctly takes over\n-\/\/ NMT header and footer to the resized block. We just test that nothing crashes - if the\n-\/\/ header\/footer get corrupted, NMT heap corruption checker will trigger alert on os::free()).\n-TEST_VM(NMT, test_realloc) {\n-  \/\/ We test both directions (growing and shrinking) and a small range for each to cover all\n-  \/\/ size alignment variants. Should not matter, but this should be cheap.\n-  for (size_t s1 = 0xF0; s1 < 0x110; s1 ++) {\n-    for (size_t s2 = 0x100; s2 > 0xF0; s2 --) {\n-      address p1 = (address) os::malloc(s1, mtTest);\n-      ASSERT_NOT_NULL(p1);\n-      GtestUtils::mark_range(p1, s1);       \/\/ mark payload range...\n-      address p2 = (address) os::realloc(p1, s2, mtTest);\n-      ASSERT_NOT_NULL(p2);\n-      ASSERT_RANGE_IS_MARKED(p2, MIN2(s1, s2))        \/\/ ... and check that it survived the resize\n-         << s1 << \"->\" << s2 << std::endl;\n-      os::free(p2);                         \/\/ <- if NMT headers\/footers got corrupted this asserts\n-    }\n-  }\n-}\n","filename":"test\/hotspot\/gtest\/nmt\/test_nmt_buffer_overflow_detection.cpp","additions":0,"deletions":40,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -53,93 +53,0 @@\n-\/\/ Check correct handling of failing reallocs.\n-static void check_failing_realloc(size_t failing_request_size) {\n-\n-  \/\/ We test this with both NMT enabled and disabled.\n-  bool nmt_enabled = MemTracker::enabled();\n-  const size_t first_size = 0x100;\n-\n-  void* p = os::malloc(first_size, mtTest);\n-  EXPECT_NOT_NULL(p);\n-  if (nmt_enabled) {\n-    check_expected_malloc_header(p, mtTest, first_size);\n-  }\n-  GtestUtils::mark_range(p, first_size);\n-\n-  \/\/ should fail\n-  void* p2 = os::realloc(p, failing_request_size, mtTest);\n-  EXPECT_NULL(p2);\n-\n-  \/\/ original allocation should still be intact\n-  EXPECT_RANGE_IS_MARKED(p, first_size);\n-  if (nmt_enabled) {\n-    check_expected_malloc_header(p, mtTest, first_size);\n-  }\n-\n-  os::free(p);\n-}\n-\n-TEST_VM(NMT, realloc_failure_overflowing_size) {\n-  check_failing_realloc(SIZE_MAX);\n-  check_failing_realloc(SIZE_MAX - MemTracker::overhead_per_malloc());\n-}\n-\n-TEST_VM(NMT, realloc_failure_gigantic_size) {\n-  check_failing_realloc(SIZE_MAX - M);\n-}\n-\n-static void* do_realloc(void* p, size_t old_size, size_t new_size, uint8_t old_content, bool check_nmt_header) {\n-\n-  EXPECT_NOT_NULL(p);\n-  if (check_nmt_header) {\n-    check_expected_malloc_header(p, mtTest, old_size);\n-  }\n-\n-  void* p2 = os::realloc(p, new_size, mtTest);\n-\n-  EXPECT_NOT_NULL(p2);\n-  if (check_nmt_header) {\n-    check_expected_malloc_header(p2, mtTest, new_size);\n-  }\n-\n-  \/\/ Check old content, and possibly zapped area (if block grew)\n-  if (old_size < new_size) {\n-    EXPECT_RANGE_IS_MARKED_WITH(p2, old_size, old_content);\n-#ifdef ASSERT\n-    if (MemTracker::enabled()) {\n-      EXPECT_RANGE_IS_MARKED_WITH((char*)p2 + old_size, new_size - old_size, uninitBlockPad);\n-    }\n-#endif\n-  } else {\n-    EXPECT_RANGE_IS_MARKED_WITH(p2, new_size, old_content);\n-  }\n-\n-  return p2;\n-}\n-\n-\/\/ Check a random sequence of reallocs. For enlarging reallocs, we expect the\n-\/\/ newly allocated memory to be zapped (in debug) while the old section should be\n-\/\/ left intact.\n-TEST_VM(NMT, random_reallocs) {\n-\n-  bool nmt_enabled = MemTracker::enabled();\n-  size_t size = 256;\n-  uint8_t content = 'A';\n-\n-  void* p = os::malloc(size, mtTest);\n-  ASSERT_NOT_NULL(p);\n-  if (nmt_enabled) {\n-    check_expected_malloc_header(p, mtTest, size);\n-  }\n-  GtestUtils::mark_range_with(p, size, content);\n-\n-  for (int n = 0; n < 100; n ++) {\n-    size_t new_size = (size_t)(os::random() % 512) + 1;\n-    \/\/ LOG_HERE(\"reallocating \" SIZE_FORMAT \"->\" SIZE_FORMAT, size, new_size);\n-    p = do_realloc(p, size, new_size, content, nmt_enabled);\n-    size = new_size;\n-    content = (n % 26) + 'A';\n-    GtestUtils::mark_range_with(p, size, content);\n-  }\n-\n-  os::free(p);\n-}\n-\n","filename":"test\/hotspot\/gtest\/nmt\/test_nmt_cornercases.cpp","additions":0,"deletions":93,"binary":false,"changes":93,"status":"modified"},{"patch":"@@ -135,14 +135,0 @@\n-\/\/ Death tests.\n-\/\/ Majority of MallocLimit functional tests are done via jtreg test runtime\/NMT\/MallocLimitTest. Here, we just\n-\/\/ test that limits are triggered for specific APIs.\n-TEST_VM_FATAL_ERROR_MSG(NMT, MallocLimitDeathTestOnRealloc, \".*MallocLimit: reached category .mtTest. limit.*\") {\n-  \/\/ We fake the correct assert if NMT is off to make the test pass (there is no way to execute a death test conditionally)\n-  if (!MemTracker::enabled()) {\n-    fatal(\"Fake message please ignore: MallocLimit: reached category \\\"mtTest\\\" limit\");\n-  }\n-  \/\/ the real test\n-  MallocLimitHandler::initialize(\"test:100m:fatal\");\n-  char* p = (char*)os::malloc(2, mtTest);\n-  p = (char*)os::realloc(p, 120 * M, mtTest);\n-}\n-\n","filename":"test\/hotspot\/gtest\/nmt\/test_nmt_malloclimit.cpp","additions":0,"deletions":14,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -42,4 +42,2 @@\n-\/\/ The tests consist of two phases:\n-\/\/ 1) before NMT initialization (pre-NMT-init) we allocate and reallocate a bunch of\n-\/\/    blocks via os::malloc() and os::realloc(), and free some of them via os::free()\n-\/\/ 2) after NMT initialization, we reallocate some more, then free all of them.\n+\/\/ Before NMT initialization (pre-NMT-init) we allocate a bunch of\n+\/\/ blocks via os::malloc(), and free some of them via os::free()\n@@ -47,2 +45,1 @@\n-\/\/ The intent is to check that blocks allocated in pre-init phase and potentially realloced\n-\/\/ in pre-init phase are handled correctly if further realloc'ed or free'd post-init.\n+\/\/ The intent is to check that blocks allocated in pre-init phase are handled correctly if free'd post-init.\n@@ -60,1 +57,0 @@\n-static void* os_realloc(void* old, size_t s)  { return os::realloc(old, s, mtTest); }\n@@ -85,4 +81,0 @@\n-    p2 = os_realloc(os_malloc(10), 20);  \/\/ realloc, growing\n-    p3 = os_realloc(os_malloc(20), 10);  \/\/ realloc, shrinking\n-    p4 = os_realloc(NULL, 10);           \/\/ realloc with NULL pointer\n-    os_realloc(os_realloc(os_malloc(20), 0), 30);  \/\/ realloc to size 0 and back up again\n@@ -90,1 +82,0 @@\n-    os::free(os_realloc(os_malloc(20), 30));  \/\/ malloc, realloc, free\n@@ -105,8 +96,0 @@\n-    \/\/ case 3: overflow in realloc\n-    \/\/ void* p = os_malloc(10);\n-    \/\/ p = os_realloc(p, SIZE_MAX);\n-\n-    \/\/ case 4: failing realloc\n-    \/\/ void* p = os_malloc(10);\n-    \/\/ p = os_realloc(p, SIZE_MAX - M);\n-\n@@ -121,4 +104,0 @@\n-    p1 = os_realloc(p1, 140);  \/\/ realloc from pre-init-phase, growing\n-    p2 = os_realloc(p2, 150);  \/\/ realloc from pre-init-phase, growing\n-    p3 = os_realloc(p3, 50);   \/\/ realloc from pre-init-phase, growing\n-    p4 = os_realloc(p4, 8);    \/\/ realloc from pre-init-phase, shrinking\n","filename":"test\/hotspot\/gtest\/nmt\/test_nmtpreinit.cpp","additions":3,"deletions":24,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -67,1 +67,1 @@\n-  const int num_allocs = 32 * K; \/\/ about factor 100 more than normally expected\n+  const int num_allocs = 56 * 30; \/\/ about 30 more than normally expected\n@@ -85,11 +85,0 @@\n-  \/\/ Randomly realloc\n-  for (int j = 0; j < num_allocs\/2; j++) {\n-    int pos = os::random() % num_allocs;\n-    NMTPreInitAllocation* a1 = allocations[pos];\n-    NMTPreInitAllocation* a2 = table.find_and_remove(a1->payload);\n-    ASSERT_EQ(a1, a2);\n-    NMTPreInitAllocation* a3 = NMTPreInitAllocation::do_reallocate(a2, small_random_nonzero_size());\n-    table.add(a3);\n-    allocations[pos] = a3;\n-  }\n-\n@@ -116,17 +105,0 @@\n-\n-#ifdef ASSERT\n-\/\/ Test that we will assert if the lookup table is seriously over-booked.\n-TEST_VM_ASSERT_MSG(NMTPreInit, assert_on_lu_table_overflow, \".*NMT preinit lookup table degenerated.*\") {\n-  NMTPreInitAllocationTable table;\n-  const int num_allocs = 400 * 1000; \/\/ anything above ~250K entries should trigger the assert (note: normal number of entries is ~500)\n-  for (int i = 0; i < num_allocs; i++) {\n-    NMTPreInitAllocation* a = NMTPreInitAllocation::do_alloc(1);\n-    table.add(a);\n-  }\n-#ifdef VERBOSE\n-  table.print_state(tty);\n-  tty->cr();\n-#endif\n-  table.verify();\n-}\n-#endif \/\/ ASSERT\n","filename":"test\/hotspot\/gtest\/nmt\/test_nmtpreinitmap.cpp","additions":1,"deletions":29,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -160,1 +160,4 @@\n-        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+        Process proc = pb.start();\n+        long pid = proc.pid();\n+        System.out.println(\"Test process pid:\" + pid);\n+        OutputAnalyzer output = new OutputAnalyzer(proc);\n@@ -190,1 +193,1 @@\n-            System.out.println(\"found: \" + entries + \" - \" + sum_bytes + longest_chain + \".\");\n+            System.out.println(\"[pid\"+pid+\"] found: \" + entries + \" - \" + sum_bytes + \" - \" + longest_chain + \".\");\n@@ -203,1 +206,1 @@\n-                throw new RuntimeException(\"Suspiciously high number of pre-init allocations.\");\n+                throw new RuntimeException(\"[pid\"+pid+\"] Suspiciously high number of pre-init allocations.\");\n@@ -206,1 +209,1 @@\n-                throw new RuntimeException(\"Suspiciously high pre-init memory usage.\");\n+                throw new RuntimeException(\"[pid\"+pid+\"] Suspiciously high pre-init memory usage.\");\n@@ -212,1 +215,1 @@\n-                throw new RuntimeException(\"Suspiciously long bucket chains in lookup table.\");\n+                throw new RuntimeException(\"[pid\"+pid+\"] Suspiciously long bucket chains in lookup table.\");\n","filename":"test\/hotspot\/jtreg\/runtime\/NMT\/NMTInitializationTest.java","additions":8,"deletions":5,"binary":false,"changes":13,"status":"modified"}]}