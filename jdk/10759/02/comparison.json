{"files":[{"patch":"@@ -349,0 +349,4 @@\n+  \/\/ Visits nodes for buckets in range [start_idx, stop_id) with FUNC.\n+  template <typename FUNC>\n+  static bool do_scan_for_range(FUNC& scan_f, size_t start_idx, size_t stop_idx, InternalTable *table);\n+\n@@ -483,0 +487,1 @@\n+\n@@ -489,0 +494,6 @@\n+  class BucketsClaimer;\n+  \/\/ Visit all items with SCAN_FUNC without any protection.\n+  \/\/ Thread-safe, but must be called at safepoint.\n+  template <typename SCAN_FUNC>\n+  void do_safepoint_scan(SCAN_FUNC& scan_f, BucketsClaimer* bucket_claimer);\n+\n","filename":"src\/hotspot\/share\/utilities\/concurrentHashTable.hpp","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -1301,0 +1301,114 @@\n+template <typename CONFIG, MEMFLAGS F>\n+class ConcurrentHashTable<CONFIG, F>::BucketsClaimer {\n+  using InternalTable = ConcurrentHashTable<CONFIG, F>::InternalTable;\n+\n+  ConcurrentHashTable<CONFIG, F>* _cht;\n+\n+  struct InternalTableClaimer {\n+    volatile size_t _next;\n+    size_t _limit;\n+    size_t _size;\n+    InternalTable* _table;\n+\n+    InternalTableClaimer() : _next(0), _limit(0), _size(0), _table(nullptr) { }\n+\n+    InternalTableClaimer(size_t claim_size, InternalTable* table) :\n+      InternalTableClaimer()\n+    {\n+      set(claim_size, table);\n+    }\n+\n+    void set(size_t claim_size, InternalTable* table) {\n+      assert(table != nullptr, \"precondition\");\n+      _limit = table->_size;\n+      _size  = MIN2(claim_size, _limit);\n+      _table = table;\n+    }\n+  };\n+\n+  InternalTableClaimer _claimer;\n+  \/\/ If there is a paused resize, we also need to operate on the already resized items.\n+  InternalTableClaimer _new_table_claimer;\n+public:\n+  BucketsClaimer(ConcurrentHashTable<CONFIG, F>* cht, size_t claim_size) :\n+    _cht(cht),\n+    _claimer(claim_size, _cht->_table),\n+    _new_table_claimer()\n+  {\n+    InternalTable* new_table = _cht->get_new_table();\n+\n+    if (new_table == nullptr) { return; }\n+\n+    DEBUG_ONLY(if (new_table == POISON_PTR) { return; })\n+\n+    _new_table_claimer.set(claim_size, new_table);\n+  }\n+\n+  bool claim(InternalTableClaimer* claimer, size_t* start, size_t* stop, InternalTable** table) {\n+    if (Atomic::load(&claimer->_next) < claimer->_limit) {\n+      size_t claimed = Atomic::fetch_and_add(&claimer->_next, claimer->_size);\n+      if (claimed < claimer->_limit) {\n+        *start = claimed;\n+        *stop  = MIN2(claimed + claimer->_size, claimer->_limit);\n+        *table = claimer->_table;\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  \/\/ Returns true if you succeeded to claim the range [start, stop).\n+  bool claim(size_t* start, size_t* stop, InternalTable** table) {\n+    if (claim(&_claimer, start, stop, table)) {\n+      return true;\n+    }\n+\n+    \/\/ If there is a paused resize, we also need to operate on the already resized items.\n+    if (_new_table_claimer._limit == 0) {\n+      assert(_cht->get_new_table() == nullptr || _cht->get_new_table() == POISON_PTR, \"Precondition\");\n+      return false;\n+    }\n+\n+    return claim(&_new_table_claimer, start, stop, table);\n+  }\n+};\n+\n+template <typename CONFIG, MEMFLAGS F>\n+template <typename SCAN_FUNC>\n+inline void ConcurrentHashTable<CONFIG, F>::\n+  do_safepoint_scan(SCAN_FUNC& scan_f, BucketsClaimer* bucket_claimer)\n+{\n+  assert(SafepointSynchronize::is_at_safepoint(),\n+         \"must only be called in a safepoint\");\n+  size_t start_idx = 0, stop_idx = 0;\n+  InternalTable* table = nullptr;\n+  while (bucket_claimer->claim(&start_idx, &stop_idx, &table)) {\n+    assert(table != nullptr, \"precondition\");\n+    if (!do_scan_for_range(scan_f, start_idx, stop_idx, table)) {\n+      return;\n+    }\n+    table = nullptr;\n+  }\n+}\n+\n+template <typename CONFIG, MEMFLAGS F>\n+template <typename FUNC>\n+inline bool ConcurrentHashTable<CONFIG, F>::\n+  do_scan_for_range(FUNC& scan_f, size_t start_idx, size_t stop_idx, InternalTable* table)\n+{\n+  assert(start_idx < stop_idx, \"Must be\");\n+  assert(stop_idx <= table->_size, \"Must be\");\n+  for (size_t bucket_it = start_idx; bucket_it < stop_idx; ++bucket_it) {\n+    Bucket* bucket = table->get_bucket(bucket_it);\n+    \/\/ If bucket has a redirect, the items will be in the new table.\n+    if (!bucket->have_redirect()) {\n+      if(!visit_nodes(bucket, scan_f)) {\n+        return false;\n+      }\n+    } else {\n+      assert(bucket->is_locked(), \"Bucket must be locked.\");\n+    }\n+  }\n+  return true;\n+}\n+\n","filename":"src\/hotspot\/share\/utilities\/concurrentHashTable.inline.hpp","additions":114,"deletions":0,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -25,0 +25,1 @@\n+#include \"gc\/shared\/workerThread.hpp\"\n@@ -1148,0 +1149,76 @@\n+\n+class CHTParallelScanTask: public WorkerTask {\n+  TestTable* _cht;\n+  TestTable::BucketsClaimer* _bucket_claimer;\n+  size_t *_total_scanned;\n+\n+public:\n+  CHTParallelScanTask(TestTable* cht,\n+                      TestTable::BucketsClaimer* bc,\n+                      size_t *total_scanned) :\n+    WorkerTask(\"CHT Parallel Scan\"),\n+    _cht(cht),\n+    _bucket_claimer(bc),\n+    _total_scanned(total_scanned)\n+  { }\n+\n+  void work(uint worker_id) {\n+    ChtCountScan par_scan;\n+    _cht->do_safepoint_scan(par_scan, _bucket_claimer);\n+    Atomic::add(_total_scanned, par_scan._count);\n+  }\n+};\n+\n+class CHTWorkers : AllStatic {\n+  static WorkerThreads* _workers;\n+  static WorkerThreads* workers() {\n+    if (_workers == nullptr) {\n+      _workers = new WorkerThreads(\"CHT Workers\", MaxWorkers);\n+      _workers->initialize_workers();\n+      _workers->set_active_workers(MaxWorkers);\n+    }\n+    return _workers;\n+  }\n+\n+public:\n+  static const uint MaxWorkers = 8;\n+  static void run_task(WorkerTask* task) {\n+    workers()->run_task(task);\n+  }\n+};\n+\n+WorkerThreads* CHTWorkers::_workers = nullptr;\n+\n+class CHTParallelScan: public VM_GTestExecuteAtSafepoint {\n+  TestTable* _cht;\n+  uintptr_t _num_items;\n+public:\n+  CHTParallelScan(TestTable* cht, uintptr_t num_items) :\n+    _cht(cht), _num_items(num_items)\n+  {}\n+\n+  void doit() {\n+    size_t total_scanned = 0;\n+    TestTable::BucketsClaimer bucket_claimer(_cht, 64);\n+\n+    CHTParallelScanTask task(_cht, &bucket_claimer, &total_scanned);\n+    CHTWorkers::run_task(&task);\n+\n+     EXPECT_TRUE(total_scanned == (size_t)_num_items) << \" Should scan all inserted items: \" << total_scanned;\n+  }\n+};\n+\n+TEST_VM(ConcurrentHashTable, concurrent_par_scan) {\n+  TestTable* cht = new TestTable(16, 16, 2);\n+\n+  uintptr_t num_items = 999999;\n+  for (uintptr_t v = 1; v <= num_items; v++ ) {\n+    TestLookup tl(v);\n+    EXPECT_TRUE(cht->insert(JavaThread::current(), tl, v)) << \"Inserting an unique value should work.\";\n+  }\n+\n+  \/\/ Run the test at a safepoint.\n+  CHTParallelScan op(cht, num_items);\n+  ThreadInVMfromNative invm(JavaThread::current());\n+  VMThread::execute(&op);\n+}\n","filename":"test\/hotspot\/gtest\/utilities\/test_concurrentHashtable.cpp","additions":77,"deletions":0,"binary":false,"changes":77,"status":"modified"}]}