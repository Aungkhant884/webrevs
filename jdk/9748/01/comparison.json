{"files":[{"patch":"@@ -2123,0 +2123,7 @@\n+void Assembler::vcvttpd2dq(XMMRegister dst, XMMRegister src, int vector_len) {\n+  assert(vector_len <= AVX_256bit ? VM_Version::supports_avx() : VM_Version::supports_evex(), \"\");\n+  InstructionAttr attributes(vector_len, \/* rex_w *\/ true, \/* legacy_mode *\/ false, \/* no_mask_reg *\/ true, \/* uses_vl *\/ true);\n+  int encode = vex_prefix_and_encode(dst->encoding(), 0, src->encoding(), VEX_SIMD_66, VEX_OPCODE_0F, &attributes);\n+  emit_int16((unsigned char)0xE6, (0xC0 | encode));\n+}\n+\n@@ -2131,1 +2138,1 @@\n-  assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"\");\n+  assert(VM_Version::supports_avx512dq(), \"\");\n@@ -2139,1 +2146,1 @@\n-  assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"\");\n+  assert(VM_Version::supports_avx512dq(), \"\");\n@@ -2147,1 +2154,1 @@\n-  assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"\");\n+  assert(VM_Version::supports_avx512dq(), \"\");\n@@ -2155,1 +2162,1 @@\n-  assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"\");\n+  assert(VM_Version::supports_avx512dq(), \"\");\n@@ -2163,1 +2170,1 @@\n-  assert(UseAVX > 2 && VM_Version::supports_avx512dq(), \"\");\n+  assert(VM_Version::supports_avx512dq(), \"\");\n@@ -2171,1 +2178,1 @@\n-  assert(UseAVX > 2  && VM_Version::supports_avx512bw(), \"\");\n+  assert(VM_Version::supports_avx512bw(), \"\");\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.cpp","additions":13,"deletions":6,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -1194,0 +1194,3 @@\n+  \/\/ Convert vector double to int\n+  void vcvttpd2dq(XMMRegister dst, XMMRegister src, int vector_len);\n+\n","filename":"src\/hotspot\/cpu\/x86\/assembler_x86.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1652,2 +1652,0 @@\n-  assert(rscratch != noreg || always_reachable(src), \"missing\");\n-\n@@ -1667,1 +1665,1 @@\n-        vpbroadcastq(dst, src, vlen_enc);\n+        vpbroadcastq(dst, src, vlen_enc, noreg);\n@@ -1669,1 +1667,1 @@\n-        vmovddup(dst, src, vlen_enc);\n+        vmovddup(dst, src, vlen_enc, noreg);\n@@ -1675,1 +1673,1 @@\n-        vmovddup(dst, src, vlen_enc);\n+        vmovddup(dst, src, vlen_enc, noreg);\n@@ -1679,1 +1677,1 @@\n-        vpbroadcastd(dst, src, vlen_enc);\n+        vpbroadcastd(dst, src, vlen_enc, noreg);\n@@ -1681,1 +1679,1 @@\n-        vbroadcastss(dst, src, vlen_enc);\n+        vbroadcastss(dst, src, vlen_enc, noreg);\n@@ -2400,2 +2398,2 @@\n-void C2_MacroAssembler::evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral src2, int comparison, int vector_len, Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(src2), \"missing\");\n+void C2_MacroAssembler::evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral adr, int comparison, int vector_len, Register rscratch) {\n+  assert(rscratch != noreg || always_reachable(adr), \"missing\");\n@@ -2406,1 +2404,1 @@\n-      evpcmpb(kdmask, ksmask, src1, src2, comparison, \/*signed*\/ true, vector_len, rscratch);\n+      evpcmpb(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -2410,1 +2408,1 @@\n-      evpcmpw(kdmask, ksmask, src1, src2, comparison, \/*signed*\/ true, vector_len, rscratch);\n+      evpcmpw(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -2414,1 +2412,1 @@\n-      evpcmpd(kdmask, ksmask, src1, src2, comparison, \/*signed*\/ true, vector_len, rscratch);\n+      evpcmpd(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -2418,1 +2416,1 @@\n-      evpcmpq(kdmask, ksmask, src1, src2, comparison, \/*signed*\/ true, vector_len, rscratch);\n+      evpcmpq(kdmask, ksmask, src1, adr, comparison, \/*signed*\/ true, vector_len, rscratch);\n@@ -4362,3 +4360,4 @@\n-void C2_MacroAssembler::vector_cast_float_special_cases_avx(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                                            XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n-                                                            Register rscratch) {\n+void C2_MacroAssembler::vector_cast_float_special_cases_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                            XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                                            Register scratch, AddressLiteral float_sign_flip,\n+                                                            int vec_enc) {\n@@ -4366,1 +4365,1 @@\n-  vmovdqu(xtmp1, float_sign_flip, vec_enc, rscratch);\n+  vmovdqu(xtmp1, float_sign_flip, vec_enc, scratch);\n@@ -4390,4 +4389,4 @@\n-void C2_MacroAssembler::vector_cast_float_special_cases_evex(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                                             XMMRegister xtmp1, XMMRegister xtmp2,\n-                                                             KRegister ktmp1, KRegister ktmp2,\n-                                                             Register rscratch) {\n+void C2_MacroAssembler::vector_cast_float_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                             XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                             Register scratch, AddressLiteral float_sign_flip,\n+                                                             int vec_enc) {\n@@ -4395,1 +4394,1 @@\n-  evmovdqul(xtmp1, k0, float_sign_flip, false, vec_enc, rscratch);\n+  evmovdqul(xtmp1, k0, float_sign_flip, false, vec_enc, scratch);\n@@ -4411,7 +4410,5 @@\n-void C2_MacroAssembler::vector_cast_float_to_long_special_cases_evex(XMMRegister dst, XMMRegister src,\n-                                                                     AddressLiteral double_sign_flip, int vec_enc,\n-                                                                     XMMRegister xtmp1, XMMRegister xtmp2,\n-                                                                     KRegister ktmp1, KRegister ktmp2,\n-                                                                     Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(double_sign_flip), \"missing\");\n-\n+void C2_MacroAssembler::vector_cast_float_to_long_special_cases_evex(\n+                                                             XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                             XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                             Register scratch, AddressLiteral double_sign_flip,\n+                                                             int vec_enc) {\n@@ -4419,1 +4416,1 @@\n-  evmovdquq(xtmp1, k0, double_sign_flip, false, vec_enc, rscratch);\n+  evmovdquq(xtmp1, k0, double_sign_flip, false, vec_enc, scratch);\n@@ -4435,0 +4432,21 @@\n+void C2_MacroAssembler::vector_narrow_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                                     XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                                     Register scratch, AddressLiteral float_sign_flip,\n+                                                                     int vec_enc) {\n+  Label done;\n+  evmovdquq(xtmp1, k0, float_sign_flip, false, vec_enc, scratch);\n+  Assembler::evpcmpeqd(ktmp1, k0, xtmp1, dst, vec_enc);\n+  kortestwl(ktmp1, ktmp1);\n+  jccb(Assembler::equal, done);\n+\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  evcmppd(ktmp2, k0, src, src, Assembler::UNORD_Q, vec_enc);\n+  evmovdqul(dst, ktmp2, xtmp2, true, vec_enc);\n+\n+  kxorwl(ktmp1, ktmp1, ktmp2);\n+  evcmppd(ktmp1, ktmp1, src, xtmp2, Assembler::NLT_UQ, vec_enc);\n+  vpternlogq(xtmp2, 0x11, xtmp1, xtmp1, vec_enc);\n+  evmovdqul(dst, ktmp1, xtmp2, true, vec_enc);\n+  bind(done);\n+}\n+\n@@ -4443,6 +4461,4 @@\n-void C2_MacroAssembler::vector_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src,\n-                                                              AddressLiteral double_sign_flip, int vec_enc,\n-                                                              XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n-                                                              Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(double_sign_flip), \"missing\");\n-\n+void C2_MacroAssembler::vector_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                              XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                              Register scratch, AddressLiteral double_sign_flip,\n+                                                              int vec_enc) {\n@@ -4450,1 +4466,1 @@\n-  evmovdqul(xtmp1, k0, double_sign_flip, false, vec_enc, rscratch);\n+  evmovdqul(xtmp1, k0, double_sign_flip, false, vec_enc, scratch);\n@@ -4466,0 +4482,71 @@\n+void C2_MacroAssembler::vector_pack_lower_quadword_from_lanes_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp, int vec_enc) {\n+  if (VM_Version::supports_avx2()) {\n+    vpermq(dst, src, 0xD8, vec_enc);\n+  } else {\n+    vextractf128(xtmp, src, 0x1);\n+    pshufd(xtmp, xtmp, 0x4E);\n+    por(dst, xtmp);\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_narrow_cast_double_special_cases_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                                                    XMMRegister xtmp3, XMMRegister xtmp4, XMMRegister xtmp5, Register scratch,\n+                                                                    AddressLiteral float_sign_flip, int src_vec_enc) {\n+  Label done;\n+  \/\/ Compare the destination lanes with float_sign_flip\n+  \/\/ value to get mask for all special values.\n+  movdqu(xtmp1, float_sign_flip, scratch);\n+  vpcmpeqd(xtmp2, dst, xtmp1, Assembler::AVX_128bit);\n+  ptest(xtmp2, xtmp2);\n+  jccb(Assembler::equal, done);\n+\n+  \/\/ Flip float_sign_flip to get max integer value.\n+  vpcmpeqd(xtmp4, xtmp4, xtmp4, Assembler::AVX_128bit);\n+  pxor(xtmp1, xtmp4);\n+\n+  vpxor(xtmp4, xtmp4, xtmp4, src_vec_enc);\n+  vcmppd(xtmp3, src, src, Assembler::UNORD_Q, src_vec_enc);\n+  \/\/ Narrow down the mask for quadword lane to integer lane.\n+  vpackssdw(xtmp3, xtmp3, xtmp4, src_vec_enc);\n+  if (src_vec_enc == Assembler::AVX_256bit) {\n+    vector_pack_lower_quadword_from_lanes_avx(xtmp3, xtmp3, xtmp5, src_vec_enc);\n+  }\n+  vblendvps(dst, dst, xtmp4, xtmp3, Assembler::AVX_128bit);\n+\n+  \/\/ Recompute the mask for remaining special value.\n+  pxor(xtmp2, xtmp3);\n+  \/\/ Extract mask corresponding to non-negative source lanes.\n+  vcmppd(xtmp5, src, xtmp4, Assembler::NLT_UQ, src_vec_enc);\n+  \/\/ Narrow down the mask for quadword lane to integer lane.\n+  vpackssdw(xtmp5, xtmp5, xtmp4, src_vec_enc);\n+  if (src_vec_enc == Assembler::AVX_256bit) {\n+    vector_pack_lower_quadword_from_lanes_avx(xtmp5, xtmp5, xtmp4, src_vec_enc);\n+  }\n+  pand(xtmp5, xtmp2);\n+\n+  vblendvps(dst, dst, xtmp1, xtmp5, Assembler::AVX_128bit);\n+  bind(done);\n+}\n+\n+\/\/ Handling for downcasting from double to integer or sub-word types on AVX2.\n+void C2_MacroAssembler::vector_castD2X_avx(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4, XMMRegister xtmp5,\n+                                           AddressLiteral float_sign_flip, Register scratch, int vec_enc) {\n+  int to_elem_sz = type2aelembytes(to_elem_bt);\n+  assert(to_elem_sz < 8, \"\");\n+  vcvttpd2dq(dst, src, vec_enc);\n+  vector_narrow_cast_double_special_cases_avx(dst, src, xtmp1, xtmp2, xtmp3, xtmp4, xtmp5, scratch,\n+                                              float_sign_flip, vec_enc);\n+  vpxor(xtmp4, xtmp4, xtmp4, vec_enc);\n+  if (to_elem_sz < 4) {\n+    vector_narrow_cast_int_to_subword(to_elem_bt, dst, xtmp4, xtmp2, scratch, Assembler::AVX_128bit);\n+  }\n+}\n+\n+void C2_MacroAssembler::vector_castD2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  vcvttpd2dq(dst, src, vec_enc);\n+  vector_narrow_cast_double_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, double_sign_flip, vec_enc);\n+}\n+\n@@ -4476,4 +4563,3 @@\n-void C2_MacroAssembler::vector_castD2L_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(double_sign_flip), \"missing\");\n-\n+void C2_MacroAssembler::vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                            Register scratch, int vec_enc) {\n@@ -4481,2 +4567,1 @@\n-  vector_cast_double_special_cases_evex(dst, src, double_sign_flip, vec_enc,\n-                                        xtmp1, xtmp2, ktmp1, ktmp2, rscratch);\n+  vector_cast_double_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, double_sign_flip, vec_enc);\n@@ -4485,3 +4570,23 @@\n-void C2_MacroAssembler::vector_castF2I_avx(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                           XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4, Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(float_sign_flip), \"missing\");\n+void C2_MacroAssembler::vector_narrow_cast_int_to_subword(BasicType to_elem_bt, XMMRegister dst, XMMRegister zero,\n+                                                          XMMRegister xtmp, Register scratch, int vec_enc) {\n+  switch(to_elem_bt) {\n+    case T_SHORT:\n+      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_int_to_short_mask()), vec_enc, scratch);\n+      vpackusdw(dst, dst, zero, vec_enc);\n+      if(vec_enc == Assembler::AVX_256bit) {\n+        vector_pack_lower_quadword_from_lanes_avx(dst, dst, xtmp, vec_enc);\n+      }\n+      break;\n+    case  T_BYTE:\n+      vpand(dst, dst, ExternalAddress(StubRoutines::x86::vector_int_to_byte_mask()), vec_enc, scratch);\n+      vpackusdw(dst, dst, zero, vec_enc);\n+      if(vec_enc == Assembler::AVX_256bit) {\n+        vector_pack_lower_quadword_from_lanes_avx(dst, dst, xtmp, vec_enc);\n+      }\n+      vpackuswb(dst, dst, zero, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type %s\", type2name(to_elem_bt));\n+      break;\n+  }\n+}\n@@ -4489,0 +4594,5 @@\n+void C2_MacroAssembler::vector_castF2X_avx(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                           AddressLiteral float_sign_flip, Register scratch, int vec_enc) {\n+  int to_elem_sz = type2aelembytes(to_elem_bt);\n+  assert(to_elem_sz <= 4, \"\");\n@@ -4490,2 +4600,5 @@\n-  vector_cast_float_special_cases_avx(dst, src, float_sign_flip, vec_enc,\n-                                      xtmp1, xtmp2, xtmp3, xtmp4, rscratch);\n+  vector_cast_float_special_cases_avx(dst, src, xtmp1, xtmp2, xtmp3, xtmp4, scratch, float_sign_flip, vec_enc);\n+  vpxor(xtmp2, xtmp2, xtmp2, vec_enc);\n+  if (to_elem_sz < 4) {\n+    vector_narrow_cast_int_to_subword(to_elem_bt, dst, xtmp2, xtmp4, scratch, vec_enc);\n+  }\n@@ -4494,4 +4607,5 @@\n-void C2_MacroAssembler::vector_castF2I_evex(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(float_sign_flip), \"missing\");\n-\n+void C2_MacroAssembler::vector_castF2X_evex(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                            XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, AddressLiteral float_sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  int to_elem_sz = type2aelembytes(to_elem_bt);\n+  assert(to_elem_sz <= 4, \"\");\n@@ -4499,2 +4613,14 @@\n-  vector_cast_float_special_cases_evex(dst, src, float_sign_flip, vec_enc,\n-                                       xtmp1, xtmp2, ktmp1, ktmp2, rscratch);\n+  vector_cast_float_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, float_sign_flip, vec_enc);\n+  switch(to_elem_bt) {\n+    case T_INT:\n+      break;\n+    case T_SHORT:\n+      evpmovdw(dst, dst, vec_enc);\n+      break;\n+    case T_BYTE:\n+      evpmovdb(dst, dst, vec_enc);\n+      break;\n+    default:\n+      fatal(\"Unsupported type %s\", type2name(to_elem_bt));\n+      break;\n+  }\n@@ -4503,4 +4629,3 @@\n-void C2_MacroAssembler::vector_castF2L_evex(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(float_sign_flip), \"missing\");\n-\n+void C2_MacroAssembler::vector_castF2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                            Register scratch, int vec_enc) {\n@@ -4508,2 +4633,1 @@\n-  vector_cast_float_to_long_special_cases_evex(dst, src, float_sign_flip, vec_enc,\n-                                               xtmp1, xtmp2, ktmp1, ktmp2, rscratch);\n+  vector_cast_float_to_long_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, double_sign_flip, vec_enc);\n@@ -4512,7 +4636,6 @@\n-void C2_MacroAssembler::vector_castD2X_evex(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch) {\n-  assert(rscratch != noreg || always_reachable(double_sign_flip), \"missing\");\n-\n-  vector_castD2L_evex(dst, src, double_sign_flip, vec_enc,\n-                      xtmp1, xtmp2, ktmp1, ktmp2, rscratch);\n-  if (to_elem_bt != T_LONG) {\n+void C2_MacroAssembler::vector_castD2X_evex(BasicType to_elem_bt, XMMRegister dst, XMMRegister src,\n+                                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1,\n+                                            KRegister ktmp2, AddressLiteral sign_flip,\n+                                            Register scratch, int vec_enc) {\n+  if (VM_Version::supports_avx512dq()) {\n+    vector_castD2L_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, sign_flip, scratch, vec_enc);\n@@ -4520,0 +4643,2 @@\n+      case T_LONG:\n+        break;\n@@ -4531,1 +4656,19 @@\n-      default: assert(false, \"%s\", type2name(to_elem_bt));\n+      default:\n+        fatal(\"Unsupported type %s\", type2name(to_elem_bt));\n+        break;\n+    }\n+  } else {\n+    assert(type2aelembytes(to_elem_bt) <= 4, \"\");\n+    vector_castD2I_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, sign_flip, scratch, vec_enc);\n+    switch(to_elem_bt) {\n+      case T_INT:\n+        break;\n+      case T_SHORT:\n+        evpmovdw(dst, dst, vec_enc);\n+        break;\n+      case T_BYTE:\n+        evpmovdb(dst, dst, vec_enc);\n+        break;\n+      default:\n+        fatal(\"Unsupported type %s\", type2name(to_elem_bt));\n+        break;\n@@ -4537,3 +4680,3 @@\n-void C2_MacroAssembler::vector_round_double_evex(XMMRegister dst, XMMRegister src,\n-                                                 AddressLiteral double_sign_flip, AddressLiteral new_mxcsr, int vec_enc,\n-                                                 Register tmp, XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2) {\n+void C2_MacroAssembler::vector_round_double_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                                 KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                                 AddressLiteral new_mxcsr, Register scratch, int vec_enc) {\n@@ -4542,4 +4685,4 @@\n-  ldmxcsr(new_mxcsr, tmp \/*rscratch*\/);\n-\n-  mov64(tmp, julong_cast(0.5L));\n-  evpbroadcastq(xtmp1, tmp, vec_enc);\n+  ExternalAddress mxcsr_std(StubRoutines::x86::addr_mxcsr_std());\n+  ldmxcsr(new_mxcsr, scratch);\n+  mov64(scratch, julong_cast(0.5L));\n+  evpbroadcastq(xtmp1, scratch, vec_enc);\n@@ -4548,4 +4691,2 @@\n-  vector_cast_double_special_cases_evex(dst, src, double_sign_flip, vec_enc,\n-                                        xtmp1, xtmp2, ktmp1, ktmp2, tmp);\n-\n-  ldmxcsr(ExternalAddress(StubRoutines::x86::addr_mxcsr_std()), tmp \/*rscratch*\/);\n+  vector_cast_double_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, double_sign_flip, vec_enc);\n+  ldmxcsr(mxcsr_std, scratch);\n@@ -4554,3 +4695,3 @@\n-void C2_MacroAssembler::vector_round_float_evex(XMMRegister dst, XMMRegister src,\n-                                                AddressLiteral float_sign_flip, AddressLiteral new_mxcsr, int vec_enc,\n-                                                Register tmp, XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2) {\n+void C2_MacroAssembler::vector_round_float_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                                KRegister ktmp1, KRegister ktmp2, AddressLiteral float_sign_flip,\n+                                                AddressLiteral new_mxcsr, Register scratch, int vec_enc) {\n@@ -4559,4 +4700,4 @@\n-  ldmxcsr(new_mxcsr, tmp \/*rscratch*\/);\n-\n-  movl(tmp, jint_cast(0.5));\n-  movq(xtmp1, tmp);\n+  ExternalAddress mxcsr_std(StubRoutines::x86::addr_mxcsr_std());\n+  ldmxcsr(new_mxcsr, scratch);\n+  movl(scratch, jint_cast(0.5));\n+  movq(xtmp1, scratch);\n@@ -4566,4 +4707,2 @@\n-  vector_cast_float_special_cases_evex(dst, src, float_sign_flip, vec_enc,\n-                                       xtmp1, xtmp2, ktmp1, ktmp2, tmp);\n-\n-  ldmxcsr(ExternalAddress(StubRoutines::x86::addr_mxcsr_std()), tmp \/*rscratch*\/);\n+  vector_cast_float_special_cases_evex(dst, src, xtmp1, xtmp2, ktmp1, ktmp2, scratch, float_sign_flip, vec_enc);\n+  ldmxcsr(mxcsr_std, scratch);\n@@ -4572,3 +4711,3 @@\n-void C2_MacroAssembler::vector_round_float_avx(XMMRegister dst, XMMRegister src,\n-                                               AddressLiteral float_sign_flip, AddressLiteral new_mxcsr, int vec_enc,\n-                                               Register tmp, XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4) {\n+void C2_MacroAssembler::vector_round_float_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                               XMMRegister xtmp3, XMMRegister xtmp4, AddressLiteral float_sign_flip,\n+                                               AddressLiteral new_mxcsr, Register scratch, int vec_enc) {\n@@ -4577,4 +4716,4 @@\n-  ldmxcsr(new_mxcsr, tmp \/*rscratch*\/);\n-\n-  movl(tmp, jint_cast(0.5));\n-  movq(xtmp1, tmp);\n+  ExternalAddress mxcsr_std(StubRoutines::x86::addr_mxcsr_std());\n+  ldmxcsr(new_mxcsr, scratch);\n+  movl(scratch, jint_cast(0.5));\n+  movq(xtmp1, scratch);\n@@ -4584,4 +4723,2 @@\n-  vector_cast_float_special_cases_avx(dst, src, float_sign_flip, vec_enc,\n-                                      xtmp1, xtmp2, xtmp3, xtmp4, tmp);\n-\n-  ldmxcsr(ExternalAddress(StubRoutines::x86::addr_mxcsr_std()), tmp \/*rscratch*\/);\n+  vector_cast_float_special_cases_avx(dst, src, xtmp1, xtmp2, xtmp3, xtmp4, scratch, float_sign_flip, vec_enc);\n+  ldmxcsr(mxcsr_std, scratch);\n@@ -4589,1 +4726,1 @@\n-#endif \/\/ _LP64\n+#endif\n@@ -5149,5 +5286,2 @@\n-void C2_MacroAssembler::vector_reverse_bit_gfni(BasicType bt, XMMRegister dst, XMMRegister src, AddressLiteral mask, int vec_enc,\n-                                                XMMRegister xtmp, Register rscratch) {\n-  assert(VM_Version::supports_gfni(), \"\");\n-  assert(rscratch != noreg || always_reachable(mask), \"missing\");\n-\n+void C2_MacroAssembler::vector_reverse_bit_gfni(BasicType bt, XMMRegister dst, XMMRegister src,\n+                                                XMMRegister xtmp, AddressLiteral mask, Register rtmp, int vec_enc) {\n@@ -5156,1 +5290,2 @@\n-  vpbroadcastq(xtmp, mask, vec_enc, rscratch);\n+  assert(VM_Version::supports_gfni(), \"\");\n+  vpbroadcastq(xtmp, mask, vec_enc, rtmp);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":243,"deletions":108,"binary":false,"changes":351,"status":"modified"},{"patch":"@@ -151,2 +151,2 @@\n-  void evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, XMMRegister    src2, int comparison, int vector_len);\n-  void evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral src2, int comparison, int vector_len, Register rscratch = noreg);\n+  void evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, AddressLiteral adr, int comparison, int vector_len, Register rscratch = rscratch1);\n+  void evpcmp(BasicType typ, KRegister kdmask, KRegister ksmask, XMMRegister src1, XMMRegister src2, int comparison, int vector_len);\n@@ -155,3 +155,0 @@\n-  void load_vector(XMMRegister dst, Address        src, int vlen_in_bytes);\n-  void load_vector(XMMRegister dst, AddressLiteral src, int vlen_in_bytes, Register rscratch = noreg);\n-\n@@ -159,1 +156,1 @@\n-  void load_vector_mask(KRegister   dst, XMMRegister src, XMMRegister xtmp, bool novlbwdq, int vlen_enc);\n+  void load_vector_mask(KRegister dst, XMMRegister src, XMMRegister xtmp, bool novlbwdq, int vlen_enc);\n@@ -161,0 +158,2 @@\n+  void load_vector(XMMRegister dst, Address src, int vlen_in_bytes);\n+  void load_vector(XMMRegister dst, AddressLiteral src, int vlen_in_bytes, Register rscratch = rscratch1);\n@@ -311,2 +310,19 @@\n-  void vector_castF2I_avx(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                          XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4, Register rscratch = noreg);\n+  void vector_castF2X_avx(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                          XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                          AddressLiteral float_sign_flip, Register scratch, int vec_enc);\n+\n+  void vector_castF2X_evex(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                           XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, AddressLiteral float_sign_flip,\n+                           Register scratch, int vec_enc);\n+\n+  void vector_castF2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                           KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                           Register scratch, int vec_enc);\n+\n+  void vector_castD2L_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                           KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                           Register scratch, int vec_enc);\n+\n+  void vector_castD2X_evex(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                           XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, AddressLiteral sign_flip,\n+                           Register scratch, int vec_enc);\n@@ -314,2 +330,3 @@\n-  void vector_castF2I_evex(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                           XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch = noreg);\n+  void vector_castD2I_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                           KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                           Register scratch, int vec_enc);\n@@ -317,2 +334,3 @@\n-  void vector_castF2L_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                           XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch = noreg);\n+  void vector_castD2X_avx(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                          XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4, XMMRegister xtmp5,\n+                          AddressLiteral float_sign_flip, Register scratch, int vec_enc);\n@@ -320,2 +338,1 @@\n-  void vector_castD2L_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                           XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch = noreg );\n+  void vector_pack_lower_quadword_from_lanes_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp, int vec_enc);\n@@ -323,2 +340,2 @@\n-  void vector_castD2X_evex(BasicType to_elem_bt, XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                           XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch = noreg);\n+  void vector_narrow_cast_int_to_subword(BasicType to_elem_bt, XMMRegister dst, XMMRegister zero,\n+                                         XMMRegister xtmp, Register scratch, int vec_enc);\n@@ -326,1 +343,2 @@\n-  void vector_unsigned_cast(XMMRegister dst, XMMRegister src, int vlen_enc, BasicType from_elem_bt, BasicType to_elem_bt);\n+  void vector_unsigned_cast(XMMRegister dst, XMMRegister src, int vlen_enc,\n+                            BasicType from_elem_bt, BasicType to_elem_bt);\n@@ -328,2 +346,3 @@\n-  void vector_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch = noreg );\n+  void vector_narrow_cast_double_special_cases_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                                   XMMRegister xtmp3, XMMRegister xtmp4, XMMRegister xtmp5, Register scratch,\n+                                                   AddressLiteral float_sign_flip, int vec_enc);\n@@ -331,2 +350,4 @@\n-  void vector_cast_float_special_cases_evex(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                            XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2, Register rscratch = noreg);\n+  void vector_narrow_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                    XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                    Register scratch, AddressLiteral float_sign_flip,\n+                                                    int vec_enc);\n@@ -334,3 +355,3 @@\n-  void vector_cast_float_to_long_special_cases_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, int vec_enc,\n-                                                    XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n-                                                    Register rscratch = noreg);\n+  void vector_cast_double_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                             KRegister ktmp1, KRegister ktmp2, Register scratch, AddressLiteral double_sign_flip,\n+                                             int vec_enc);\n@@ -338,3 +359,13 @@\n-  void vector_cast_float_special_cases_avx(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, int vec_enc,\n-                                           XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n-                                           Register rscratch = noreg);\n+  void vector_cast_float_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                            KRegister ktmp1, KRegister ktmp2, Register scratch, AddressLiteral float_sign_flip,\n+                                            int vec_enc);\n+\n+  void vector_cast_float_to_long_special_cases_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                                    XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2,\n+                                                    Register scratch, AddressLiteral double_sign_flip,\n+                                                    int vec_enc);\n+\n+  void vector_cast_float_special_cases_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1,\n+                                           XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4,\n+                                           Register scratch, AddressLiteral float_sign_flip,\n+                                           int vec_enc);\n@@ -343,2 +374,3 @@\n-  void vector_round_double_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, AddressLiteral new_mxcsr, int vec_enc,\n-                                Register tmp, XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2);\n+  void vector_round_double_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                                KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                                AddressLiteral new_mxcsr, Register scratch, int vec_enc);\n@@ -346,2 +378,3 @@\n-  void vector_round_float_evex(XMMRegister dst, XMMRegister src, AddressLiteral double_sign_flip, AddressLiteral new_mxcsr, int vec_enc,\n-                               Register tmp, XMMRegister xtmp1, XMMRegister xtmp2, KRegister ktmp1, KRegister ktmp2);\n+  void vector_round_float_evex(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                               KRegister ktmp1, KRegister ktmp2, AddressLiteral double_sign_flip,\n+                               AddressLiteral new_mxcsr, Register scratch, int vec_enc);\n@@ -349,3 +382,4 @@\n-  void vector_round_float_avx(XMMRegister dst, XMMRegister src, AddressLiteral float_sign_flip, AddressLiteral new_mxcsr, int vec_enc,\n-                              Register tmp, XMMRegister xtmp1, XMMRegister xtmp2, XMMRegister xtmp3, XMMRegister xtmp4);\n-#endif \/\/ _LP64\n+  void vector_round_float_avx(XMMRegister dst, XMMRegister src, XMMRegister xtmp1, XMMRegister xtmp2,\n+                              XMMRegister xtmp3, XMMRegister xtmp4, AddressLiteral float_sign_flip,\n+                              AddressLiteral new_mxcsr, Register scratch, int vec_enc);\n+#endif\n@@ -376,2 +410,2 @@\n-  void vector_reverse_bit_gfni(BasicType bt, XMMRegister dst, XMMRegister src, AddressLiteral mask, int vec_enc,\n-                               XMMRegister xtmp, Register rscratch = noreg);\n+  void vector_reverse_bit_gfni(BasicType bt, XMMRegister dst, XMMRegister src, XMMRegister xtmp,\n+                               AddressLiteral mask, Register rtmp, int vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.hpp","additions":70,"deletions":36,"binary":false,"changes":106,"status":"modified"},{"patch":"@@ -191,0 +191,4 @@\n+      case Op_VectorCastF2X: \/\/ fall through\n+      case Op_VectorCastD2X: {\n+        return is_subword_type(ety) ? 75 : 70;\n+      }\n","filename":"src\/hotspot\/cpu\/x86\/matcher_x86.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1346,1 +1346,1 @@\n-  __ pushptr(here.addr(), noreg);\n+  __ pushptr(here.addr());\n@@ -1395,0 +1395,2 @@\n+  static address vector_float_signflip() { return StubRoutines::x86::vector_float_sign_flip();}\n+  static address vector_double_signflip() { return StubRoutines::x86::vector_double_sign_flip();}\n@@ -1880,8 +1882,6 @@\n-    case Op_VectorCastD2X:\n-      \/\/ Conversion to integral type is only supported on AVX-512 platforms with avx512dq.\n-      \/\/ Need avx512vl for size_in_bits < 512\n-      if (is_integral_type(bt)) {\n-        if (!VM_Version::supports_avx512dq()) {\n-          return false;\n-        }\n-        if (size_in_bits < 512 && !VM_Version::supports_avx512vl()) {\n+    case Op_VectorCastF2X: {\n+        \/\/ As per JLS section 5.1.3 narrowing conversion to sub-word types\n+        \/\/ happen after intermediate conversion to integer and special handling\n+        \/\/ code needs AVX2 vpcmpeqd instruction for 256 bit vectors.\n+        int src_size_in_bits = type2aelembytes(T_FLOAT) * vlen * BitsPerByte;\n+        if (is_integral_type(bt) && src_size_in_bits == 256 && UseAVX < 2) {\n@@ -1891,0 +1891,4 @@\n+    case Op_VectorCastD2X:\n+      if (bt == T_LONG && !VM_Version::supports_avx512dq()) {\n+        return false;\n+      }\n@@ -1897,17 +1901,0 @@\n-    case Op_VectorCastF2X:\n-      \/\/ F2I is supported on all AVX and above platforms\n-      \/\/ For conversion to other integral types need AVX512:\n-      \/\/     Conversion to long in addition needs avx512dq\n-      \/\/     Need avx512vl for size_in_bits < 512\n-      if (is_integral_type(bt) && (bt != T_INT)) {\n-        if (UseAVX <= 2) {\n-          return false;\n-        }\n-        if ((bt == T_LONG) && !VM_Version::supports_avx512dq()) {\n-          return false;\n-        }\n-        if (size_in_bits < 512 && !VM_Version::supports_avx512vl()) {\n-          return false;\n-        }\n-      }\n-      break;\n@@ -7342,6 +7329,3 @@\n-instruct castFtoI_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rFlagsReg cr) %{\n-  \/\/ F2I conversion for < 64 byte vector using AVX instructions\n-  \/\/ AVX512 platforms that dont support avx512vl also use AVX instructions to support F2I\n-  predicate(!VM_Version::supports_avx512vl() &&\n-            Matcher::vector_length_in_bytes(n) < 64 &&\n-            Matcher::vector_element_basic_type(n) == T_INT);\n+instruct castFtoX_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n->in(1)) < 64 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) <= 4);\n@@ -7350,1 +7334,1 @@\n-  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4 as TEMP\" %}\n+  format %{ \"vector_cast_f2x $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3 and $xtmp4 as TEMP\" %}\n@@ -7352,20 +7336,12 @@\n-    int vlen_enc = vector_length_encoding(this);\n-    __ vector_castF2I_avx($dst$$XMMRegister, $src$$XMMRegister,\n-                          ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), vlen_enc,\n-                          $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister);\n-  %}\n-  ins_pipe( pipe_slow );\n-%}\n-\n-instruct castFtoI_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rFlagsReg cr) %{\n-  predicate((VM_Version::supports_avx512vl() ||\n-             Matcher::vector_length_in_bytes(n) == 64) &&\n-             Matcher::vector_element_basic_type(n) == T_INT);\n-  match(Set dst (VectorCastF2X src));\n-  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, KILL cr);\n-  format %{ \"vector_cast_f2i $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n-  ins_encode %{\n-    int vlen_enc = vector_length_encoding(this);\n-    __ vector_castF2I_evex($dst$$XMMRegister, $src$$XMMRegister,\n-                           ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), vlen_enc,\n-                           $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType to_elem_bt = Matcher::vector_element_basic_type(this);\n+    \/\/ JDK-8292878 removed the need for an explicit scratch register needed to load greater than\n+    \/\/ 32 bit addresses for register indirect addressing mode since stub constants\n+    \/\/ are part of code cache and there is a cap of 2G on ReservedCodeCacheSize currently.\n+    \/\/ However, targets are free to increase this limit, but having a large code cache size\n+    \/\/ greater than 2G looks unreasonable in practical scenario, on the hind side with given\n+    \/\/ cap we save a temporary register allocation which in limiting case can prevent\n+    \/\/ spilling in high register pressure blocks.\n+    __ vector_castF2X_avx(to_elem_bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                          $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister,\n+                          ExternalAddress(vector_float_signflip()), noreg, vlen_enc);\n@@ -7377,4 +7353,2 @@\n-  \/\/ F2X conversion for integral non T_INT target using AVX512 instructions\n-  \/\/ Platforms that dont support avx512vl can only support 64 byte vectors\n-  predicate(is_integral_type(Matcher::vector_element_basic_type(n)) &&\n-            Matcher::vector_element_basic_type(n) != T_INT);\n+  predicate((VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n->in(1)) == 64) &&\n+            is_integral_type(Matcher::vector_element_basic_type(n)));\n@@ -7383,1 +7357,1 @@\n-  format %{ \"vector_cast_f2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n+  format %{ \"vector_cast_f2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1 and $ktmp2 as TEMP\" %}\n@@ -7388,3 +7362,3 @@\n-      __ vector_castF2L_evex($dst$$XMMRegister, $src$$XMMRegister,\n-                             ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), vlen_enc,\n-                             $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n+      __ vector_castF2L_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                             $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister,\n+                             ExternalAddress(vector_double_signflip()), noreg, vlen_enc);\n@@ -7393,9 +7367,3 @@\n-      __ vector_castF2I_evex($dst$$XMMRegister, $src$$XMMRegister,\n-                             ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), vlen_enc,\n-                             $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n-      if (to_elem_bt == T_SHORT) {\n-        __ evpmovdw($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-      } else {\n-        assert(to_elem_bt == T_BYTE, \"required\");\n-        __ evpmovdb($dst$$XMMRegister, $dst$$XMMRegister, vlen_enc);\n-      }\n+      __ vector_castF2X_evex(to_elem_bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                             $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister,\n+                             ExternalAddress(vector_float_signflip()), noreg, vlen_enc);\n@@ -7418,0 +7386,16 @@\n+instruct castDtoX_reg_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, vec xtmp5, rFlagsReg cr) %{\n+  predicate(!VM_Version::supports_avx512vl() && Matcher::vector_length_in_bytes(n->in(1)) < 64 &&\n+            is_integral_type(Matcher::vector_element_basic_type(n)));\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, TEMP xtmp5, KILL cr);\n+  format %{ \"vector_cast_d2x $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4 and $xtmp5 as TEMP\" %}\n+  ins_encode %{\n+    int vlen_enc = vector_length_encoding(this, $src);\n+    BasicType to_elem_bt = Matcher::vector_element_basic_type(this);\n+    __ vector_castD2X_avx(to_elem_bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                          $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister, $xtmp5$$XMMRegister,\n+                          ExternalAddress(vector_float_signflip()), noreg, vlen_enc);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n@@ -7419,1 +7403,2 @@\n-  predicate(is_integral_type(Matcher::vector_element_basic_type(n)));\n+  predicate((VM_Version::supports_avx512vl() || Matcher::vector_length_in_bytes(n->in(1)) == 64) &&\n+            is_integral_type(Matcher::vector_element_basic_type(n)));\n@@ -7422,1 +7407,1 @@\n-  format %{ \"vector_cast_d2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n+  format %{ \"vector_cast_d2x $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1 and $ktmp2 as TEMP\" %}\n@@ -7426,3 +7411,4 @@\n-    __ vector_castD2X_evex(to_elem_bt, $dst$$XMMRegister, $src$$XMMRegister,\n-                           ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), vlen_enc,\n-                           $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n+    AddressLiteral signflip = VM_Version::supports_avx512dq() ? ExternalAddress(vector_double_signflip()) :\n+                              ExternalAddress(vector_float_signflip());\n+    __ vector_castD2X_evex(to_elem_bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                           $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister, signflip, noreg, vlen_enc);\n@@ -7450,1 +7436,1 @@\n-instruct vround_float_avx(vec dst, vec src, rRegP tmp, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rFlagsReg cr) %{\n+instruct vround_float_avx(vec dst, vec src, vec xtmp1, vec xtmp2, vec xtmp3, vec xtmp4, rRegP scratch, rFlagsReg cr) %{\n@@ -7455,2 +7441,2 @@\n-  effect(TEMP dst, TEMP tmp, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, KILL cr);\n-  format %{ \"vector_round_float $dst,$src\\t! using $tmp, $xtmp1, $xtmp2, $xtmp3, $xtmp4 as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP xtmp3, TEMP xtmp4, TEMP scratch, KILL cr);\n+  format %{ \"vector_round_float $dst,$src\\t! using $xtmp1, $xtmp2, $xtmp3, $xtmp4 and $scratch as TEMP\" %}\n@@ -7460,3 +7446,3 @@\n-    __ vector_round_float_avx($dst$$XMMRegister, $src$$XMMRegister,\n-                              ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), new_mxcsr, vlen_enc,\n-                              $tmp$$Register, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister);\n+    __ vector_round_float_avx($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                              $xtmp2$$XMMRegister, $xtmp3$$XMMRegister, $xtmp4$$XMMRegister,\n+                              ExternalAddress(vector_float_signflip()), new_mxcsr, $scratch$$Register, vlen_enc);\n@@ -7467,1 +7453,1 @@\n-instruct vround_float_evex(vec dst, vec src, rRegP tmp, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rFlagsReg cr) %{\n+instruct vround_float_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n@@ -7472,2 +7458,2 @@\n-  effect(TEMP dst, TEMP tmp, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, KILL cr);\n-  format %{ \"vector_round_float $dst,$src\\t! using $tmp, $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n+  format %{ \"vector_round_float $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n@@ -7477,3 +7463,3 @@\n-    __ vector_round_float_evex($dst$$XMMRegister, $src$$XMMRegister,\n-                               ExternalAddress(StubRoutines::x86::vector_float_sign_flip()), new_mxcsr, vlen_enc,\n-                               $tmp$$Register, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n+    __ vector_round_float_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                               $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister,\n+                               ExternalAddress(vector_float_signflip()), new_mxcsr, $scratch$$Register, vlen_enc);\n@@ -7484,1 +7470,1 @@\n-instruct vround_reg_evex(vec dst, vec src, rRegP tmp, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rFlagsReg cr) %{\n+instruct vround_reg_evex(vec dst, vec src, vec xtmp1, vec xtmp2, kReg ktmp1, kReg ktmp2, rRegP scratch, rFlagsReg cr) %{\n@@ -7487,2 +7473,2 @@\n-  effect(TEMP dst, TEMP tmp, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2,  KILL cr);\n-  format %{ \"vector_round_long $dst,$src\\t! using $tmp, $xtmp1, $xtmp2, $ktmp1, $ktmp2 as TEMP\" %}\n+  effect(TEMP dst, TEMP xtmp1, TEMP xtmp2, TEMP ktmp1, TEMP ktmp2, TEMP scratch, KILL cr);\n+  format %{ \"vector_round_long $dst,$src\\t! using $xtmp1, $xtmp2, $ktmp1, $ktmp2 and $scratch as TEMP\" %}\n@@ -7492,3 +7478,3 @@\n-    __ vector_round_double_evex($dst$$XMMRegister, $src$$XMMRegister,\n-                                ExternalAddress(StubRoutines::x86::vector_double_sign_flip()), new_mxcsr, vlen_enc,\n-                                $tmp$$Register, $xtmp1$$XMMRegister, $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister);\n+    __ vector_round_double_evex($dst$$XMMRegister, $src$$XMMRegister, $xtmp1$$XMMRegister,\n+                                $xtmp2$$XMMRegister, $ktmp1$$KRegister, $ktmp2$$KRegister,\n+                                ExternalAddress(vector_double_signflip()), new_mxcsr, $scratch$$Register, vlen_enc);\n@@ -7498,3 +7484,1 @@\n-\n-#endif \/\/ _LP64\n-\n+#endif\n@@ -9393,2 +9377,2 @@\n-    __ vector_reverse_bit_gfni(bt, $dst$$XMMRegister, $src$$XMMRegister, addr, vec_enc,\n-                               $xtmp$$XMMRegister);\n+    __ vector_reverse_bit_gfni(bt, $dst$$XMMRegister, $src$$XMMRegister, $xtmp$$XMMRegister,\n+                               addr, noreg, vec_enc);\n","filename":"src\/hotspot\/cpu\/x86\/x86.ad","additions":82,"deletions":98,"binary":false,"changes":180,"status":"modified"},{"patch":"@@ -1007,0 +1007,2 @@\n+      case Op_VectorCastD2X:\n+      case Op_VectorCastF2X:\n","filename":"src\/hotspot\/share\/opto\/loopTransform.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -27,0 +27,1 @@\n+import java.util.Random;\n@@ -35,0 +36,2 @@\n+    @Param({\"512\", \"1024\"})\n+    static int SIZE;\n@@ -36,7 +39,6 @@\n-    FloatVector fvec256;\n-    FloatVector fvec512;\n-    DoubleVector dvec512;\n-\n-    static final float [] float_arr = {\n-      1.0f, 2.0f, 3.0f, 4.0f, 5.0f, 6.0f, 7.0f, 8.0f,\n-      9.0f, 10.0f, 11.0f, 12.0f, 13.0f, 14.0f, 15.0f, 16.0f\n+    static final float [] float_sp_vals = {\n+       Float.NaN,\n+       Float.POSITIVE_INFINITY,\n+       Float.NEGATIVE_INFINITY,\n+       0.0f,\n+       -0.0f\n@@ -45,3 +47,6 @@\n-    static final double [] double_arr = {\n-      1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0,\n-      9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0\n+    static final double [] double_sp_vals = {\n+       Double.NaN,\n+       Double.POSITIVE_INFINITY,\n+       Double.NEGATIVE_INFINITY,\n+       0.0,\n+       -0.0\n@@ -50,0 +55,12 @@\n+    static float [] float_arr;\n+\n+    static double [] double_arr;\n+\n+    static long [] long_res;\n+\n+    static int [] int_res;\n+\n+    static short [] short_res;\n+\n+    static byte [] byte_res;\n+\n@@ -52,3 +69,455 @@\n-        fvec256 = FloatVector.fromArray(FloatVector.SPECIES_256, float_arr, 0);\n-        fvec512 = FloatVector.fromArray(FloatVector.SPECIES_512, float_arr, 0);\n-        dvec512 = DoubleVector.fromArray(DoubleVector.SPECIES_512, double_arr, 0);\n+        Random r = new Random(1024);\n+        float_arr = new float[SIZE];\n+        double_arr = new double[SIZE];\n+        long_res = new long[SIZE];\n+        int_res = new int[SIZE * 2];\n+        short_res = new short[SIZE * 4];\n+        byte_res = new byte[SIZE * 8];\n+        for(int i = 0; i < SIZE; i++) {\n+            float_arr[i] = SIZE * r.nextFloat();\n+            double_arr[i] = SIZE * r.nextDouble();\n+        }\n+        for(int i = 0 ; i < SIZE; i += 100) {\n+            System.arraycopy(float_sp_vals, 0, float_arr, i, float_sp_vals.length);\n+            System.arraycopy(double_sp_vals, 0, double_arr, i, double_sp_vals.length);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToByte128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2B, ByteVector.SPECIES_128, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToByte256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2B, ByteVector.SPECIES_256, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToByte512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2B, ByteVector.SPECIES_512, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToShort128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2S, ShortVector.SPECIES_128, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToShort256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2S, ShortVector.SPECIES_256, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToShort512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2S, ShortVector.SPECIES_512, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToInteger128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2I, IntVector.SPECIES_128, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToInteger256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2I, IntVector.SPECIES_256, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToInteger512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2I, IntVector.SPECIES_512, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToLong128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2L, LongVector.SPECIES_128, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToLong256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2L, LongVector.SPECIES_256, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat128ToLong512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2L, LongVector.SPECIES_512, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToByte128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2B, ByteVector.SPECIES_128, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToByte256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2B, ByteVector.SPECIES_256, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToByte512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2B, ByteVector.SPECIES_512, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToShort128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2S, ShortVector.SPECIES_128, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToShort256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2S, ShortVector.SPECIES_256, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToShort512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2S, ShortVector.SPECIES_512, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToInteger128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2I, IntVector.SPECIES_128, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToInteger256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2I, IntVector.SPECIES_256, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToInteger512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2I, IntVector.SPECIES_512, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToLong128() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2L, LongVector.SPECIES_128, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToLong256() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2L, LongVector.SPECIES_256, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microFloat256ToLong512() {\n+        VectorSpecies<Float> SPECIES = FloatVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            FloatVector.fromArray(SPECIES, float_arr, i)\n+                .convertShape(VectorOperators.F2L, LongVector.SPECIES_512, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToByte128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2B, ByteVector.SPECIES_128, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToByte256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2B, ByteVector.SPECIES_256, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToByte512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2B, ByteVector.SPECIES_512, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToShort128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2S, ShortVector.SPECIES_128, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToShort256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2S, ShortVector.SPECIES_256, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToShort512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2S, ShortVector.SPECIES_512, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToInteger128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2I, IntVector.SPECIES_128, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToInteger256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2I, IntVector.SPECIES_256, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToInteger512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2I, IntVector.SPECIES_512, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToLong128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2L, LongVector.SPECIES_128, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToLong256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2L, LongVector.SPECIES_256, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble128ToLong512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_128;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2L, LongVector.SPECIES_512, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble256ToByte128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2B, ByteVector.SPECIES_128, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble256ToByte256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2B, ByteVector.SPECIES_256, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble256ToByte512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2B, ByteVector.SPECIES_512, 0)\n+                .reinterpretAsBytes()\n+                .intoArray(byte_res, i);\n+        }\n+    }\n+\n+    @Benchmark\n+    public void microDouble256ToShort128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2S, ShortVector.SPECIES_128, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n@@ -58,2 +527,8 @@\n-    public Vector microFloat2Int() {\n-        return fvec512.convertShape(VectorOperators.F2I, IntVector.SPECIES_512, 0);\n+    public void microDouble256ToShort256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2S, ShortVector.SPECIES_256, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n@@ -63,2 +538,8 @@\n-    public Vector microFloat2Long() {\n-        return fvec256.convertShape(VectorOperators.F2L, LongVector.SPECIES_512, 0);\n+    public void microDouble256ToShort512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2S, ShortVector.SPECIES_512, 0)\n+                .reinterpretAsShorts()\n+                .intoArray(short_res, i);\n+        }\n@@ -68,2 +549,8 @@\n-    public Vector microFloat2Short() {\n-        return fvec512.convertShape(VectorOperators.F2S, ShortVector.SPECIES_256, 0);\n+    public void microDouble256ToInteger128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2I, IntVector.SPECIES_128, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n@@ -73,2 +560,8 @@\n-    public Vector microFloat2Byte() {\n-        return fvec512.convertShape(VectorOperators.F2B, ByteVector.SPECIES_128, 0);\n+    public void microDouble256ToInteger256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2I, IntVector.SPECIES_256, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n@@ -78,2 +571,8 @@\n-    public Vector microDouble2Int() {\n-        return dvec512.convertShape(VectorOperators.D2I, IntVector.SPECIES_256, 0);\n+    public void microDouble256ToInteger512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2I, IntVector.SPECIES_512, 0)\n+                .reinterpretAsInts()\n+                .intoArray(int_res, i);\n+        }\n@@ -83,2 +582,8 @@\n-    public Vector microDouble2Long() {\n-        return dvec512.convertShape(VectorOperators.D2L, LongVector.SPECIES_512, 0);\n+    public void microDouble256ToLong128() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2L, LongVector.SPECIES_128, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n@@ -88,2 +593,8 @@\n-    public Vector microDouble2Short() {\n-        return dvec512.convertShape(VectorOperators.D2S, ShortVector.SPECIES_128, 0);\n+    public void microDouble256ToLong256() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2L, LongVector.SPECIES_256, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n@@ -93,2 +604,8 @@\n-    public Vector microDouble2Byte() {\n-        return dvec512.convertShape(VectorOperators.D2B, ByteVector.SPECIES_64, 0);\n+    public void microDouble256ToLong512() {\n+        VectorSpecies<Double> SPECIES = DoubleVector.SPECIES_256;\n+        for (int i = 0; i < SPECIES.loopBound(SIZE); i += SPECIES.length()) {\n+            DoubleVector.fromArray(SPECIES, double_arr, i)\n+                .convertShape(VectorOperators.D2L, LongVector.SPECIES_512, 0)\n+                .reinterpretAsLongs()\n+                .intoArray(long_res, i);\n+        }\n","filename":"test\/micro\/org\/openjdk\/bench\/jdk\/incubator\/vector\/VectorFPtoIntCastOperations.java","additions":546,"deletions":29,"binary":false,"changes":575,"status":"modified"}]}