{"files":[{"patch":"@@ -245,0 +245,2 @@\n+  __ nop();\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -37,19 +37,0 @@\n-class NativeNMethodBarrier: public NativeInstruction {\n-  address instruction_address() const { return addr_at(0); }\n-\n-  int *guard_addr() {\n-    return reinterpret_cast<int*>(instruction_address() + 10 * 4);\n-  }\n-\n-public:\n-  int get_value() {\n-    return Atomic::load_acquire(guard_addr());\n-  }\n-\n-  void set_value(int value) {\n-    Atomic::release_store(guard_addr(), value);\n-  }\n-\n-  void verify() const;\n-};\n-\n@@ -64,0 +45,1 @@\n+  { 0xffffffff, 0xd503201f, \"nop\" },\n@@ -76,0 +58,46 @@\n+class NativeNMethodBarrier: public NativeInstruction {\n+  address instruction_address() const { return addr_at(0); }\n+\n+  int *guard_addr() {\n+    return reinterpret_cast<int*>(instruction_address() + 11 * 4);\n+  }\n+\n+  uint32_t *bypass_addr() {\n+    return reinterpret_cast<uint32_t*>(instruction_address());\n+  }\n+\n+  address next_instruction() const {\n+    return addr_at(0) + 12 * 4;\n+  }\n+\n+public:\n+  int get_value() {\n+    return Atomic::load_acquire(guard_addr());\n+  }\n+\n+  void set_value(int value) {\n+    Atomic::release_store(guard_addr(), value);\n+  }\n+\n+  bool is_bypassed() {\n+    uint32_t inst = *bypass_addr();\n+    return inst != barrierInsn[0].bits;\n+  }\n+\n+  void patch_barrier_bypass() {\n+    uint32_t* inst_addr = bypass_addr();\n+    const int len = sizeof(barrierInsn) \/ sizeof(struct CheckInsn);\n+    *inst_addr = barrierInsn[len - 1].bits;\n+    NativeJump* jmp = reinterpret_cast<NativeJump*>(inst_addr);\n+    address dest = next_instruction();\n+    jmp->set_jump_destination(dest);\n+  }\n+\n+  void patch_barrier_on() {\n+    Atomic::release_store(bypass_addr(), barrierInsn[0].bits);\n+    ICache::invalidate_range(reinterpret_cast<address>(bypass_addr()), 4);\n+  }\n+\n+  void verify() const;\n+};\n+\n@@ -81,1 +109,1 @@\n-  for(unsigned int i = 0; i < sizeof(barrierInsn)\/sizeof(struct CheckInsn); i++ ) {\n+  for(unsigned int i = 1; i < sizeof(barrierInsn)\/sizeof(struct CheckInsn); i++ ) {\n@@ -135,1 +163,1 @@\n-static const int entry_barrier_offset = -4 * 11;\n+static const int entry_barrier_offset = -4 * 12;\n@@ -164,0 +192,17 @@\n+\n+void BarrierSetNMethod::fix_entry_barrier(nmethod* nm, bool bypass) {\n+  if (!supports_entry_barrier(nm)) {\n+    return;\n+  }\n+\n+  NativeNMethodBarrier* barrier = native_nmethod_barrier(nm);\n+  if (bypass) {\n+    if (!barrier->is_bypassed()) {\n+      barrier->patch_barrier_bypass();\n+    }\n+  } else {\n+    if (barrier->is_bypassed()) {\n+      barrier->patch_barrier_on();\n+    }\n+  }\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetNMethod_aarch64.cpp","additions":66,"deletions":21,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -320,1 +320,5 @@\n-  __ align(8);\n+  \/\/ reserved nops for patching\n+  __ nop(); __ nop(); __ nop(); __ nop(); __ nop();\n+  for (int i = 0; i < (__ offset() % 8); i++) {\n+    __ nop();\n+  }\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetAssembler_x86.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -168,37 +168,0 @@\n-class NativeJccInstruction: public NativeInstruction {\n-public:\n-  enum Intel_specific_constants {\n-    je_opcode_b0            = 0x0F,\n-    je_opcode_b1            = 0x84,\n-    instruction_size        = 6,\n-    data_offset             = 2,\n-  };\n-  bool is_je() {\n-    u_char b0 = ubyte_at(0);\n-    u_char b1 = ubyte_at(1);\n-    return b0 == je_opcode_b0 && b1 == je_opcode_b1;\n-  }\n-  void patch_to_jmp() {\n-    jint offset = int_at(NativeJccInstruction::data_offset);\n-    assert(offset == NativeCall::instruction_size, \"jump over the call\");\n-\n-    set_char_at(0, static_cast<char>(NativeJump::instruction_code));\n-    set_int_at(NativeJump::data_offset, offset + NativeInstruction::nop_instruction_size);\n-    set_char_at(NativeJump::instruction_size, static_cast<char>(NativeInstruction::nop_instruction_code));\n-  }\n-  void patch_to_je() {\n-    u_char jmp_opcode = ubyte_at(0);\n-    u_char nop_opcode = ubyte_at(NativeJump::instruction_size);\n-    assert(jmp_opcode == NativeJump::instruction_code &&\n-        nop_opcode == NativeInstruction::nop_instruction_code, \"must equal\");\n-\n-    jint offset = int_at(NativeJump::data_offset);\n-    assert(offset == NativeCall::instruction_size + NativeInstruction::nop_instruction_size,\n-        \"jump over nop and call\");\n-\n-    set_char_at(0, static_cast<char>(je_opcode_b0));\n-    set_char_at(1, static_cast<char>(je_opcode_b1));\n-    set_int_at(2, offset - NativeInstruction::nop_instruction_size);\n-  }\n-};\n-\n@@ -214,0 +177,2 @@\n+#ifdef _LP64\n+static const int entry_barrier_bypass_offset = entry_barrier_offset - NativeJump::instruction_size;\n@@ -220,4 +185,0 @@\n-#ifndef _LP64\n-  \/\/ there is a pop instruction after the cmpl instruction\n-  je_addr += NativePopReg::instruction_size;\n-#endif\n@@ -225,0 +186,4 @@\n+  address dest = jcc->jump_destination();\n+\n+  address jmp_addr = nm->code_begin() + nm->frame_complete_offset() + entry_barrier_bypass_offset;\n+  NativeJump* jmp = reinterpret_cast<NativeJump*>(jmp_addr);\n@@ -226,2 +191,4 @@\n-    if (jcc->is_je()) {\n-      jcc->patch_to_jmp();\n+    if (!jmp->is_jmp()) {\n+      \/\/ it's nops\n+      jmp->patch_to_jmp(dest);\n+      assert(jmp->int_at(NativeJump::data_offset) == entry_barrier_jump_offset, \"must be equal\");\n@@ -230,3 +197,2 @@\n-    if (!jcc->is_je()) {\n-      \/\/ has been bypassed\n-      jcc->patch_to_je();\n+    if (jmp->is_jmp()) {\n+      jmp->patch_to_nop();\n@@ -236,0 +202,1 @@\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shared\/barrierSetNMethod_x86.cpp","additions":13,"deletions":46,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -519,0 +519,16 @@\n+  bool is_jmp() {\n+    return ubyte_at(0) == instruction_code;\n+  }\n+\n+  void patch_to_jmp(address dest) {\n+    intptr_t val = dest - next_instruction_address();\n+    set_char_at(0, static_cast<char>(instruction_code));\n+    set_int_at(data_offset, (jint)val);\n+  }\n+\n+  void patch_to_nop() {\n+    for (int i = 0; i < instruction_size; i++) {\n+      set_char_at(i, static_cast<char>(NativeInstruction::nop_instruction_code));\n+    }\n+  }\n+\n@@ -534,0 +550,11 @@\n+class NativeJccInstruction: public NativeInstruction {\n+public:\n+  enum Intel_specific_constants {\n+    instruction_size        = 6,\n+    data_offset             = 2,\n+  };\n+  address jump_destination() const {\n+    return int_at(data_offset) + addr_at(instruction_size);\n+  }\n+};\n+\n","filename":"src\/hotspot\/cpu\/x86\/nativeInst_x86.hpp","additions":27,"deletions":0,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -49,1 +49,5 @@\n-  void fix_entry_barrier(nmethod* nm, bool bypass) X86_ONLY(;) NOT_X86({})\n+#if defined(AMD64) || defined(AARCH64)\n+  void fix_entry_barrier(nmethod* nm, bool bypass);\n+#else\n+  void fix_entry_barrier(nmethod* nm, bool bypass) {}\n+#endif\n","filename":"src\/hotspot\/share\/gc\/shared\/barrierSetNMethod.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"}]}