{"files":[{"patch":"@@ -853,1 +853,1 @@\n-                                           word_size)) {\n+                                        word_size)) {\n@@ -2720,1 +2720,3 @@\n-void G1CollectedHeap::do_concurrent_mark() {\n+void G1CollectedHeap::start_concurrent_cycle(bool concurrent_operation_is_full_mark) {\n+  assert(!_cm_thread->in_progress(), \"Can not start concurrent operation while in progress\");\n+\n@@ -2722,3 +2724,6 @@\n-  if (!_cm_thread->in_progress()) {\n-    _cm_thread->set_started();\n-    CGC_lock->notify();\n+  if (concurrent_operation_is_full_mark) {\n+    _cm->post_concurrent_mark_start();\n+    _cm_thread->start_full_mark();\n+  } else {\n+    _cm->post_concurrent_undo_start();\n+    _cm_thread->start_undo_mark();\n@@ -2726,0 +2731,1 @@\n+  CGC_lock->notify();\n@@ -2978,7 +2984,5 @@\n-  \/\/ Record whether this pause is a concurrent start. When the current\n-  \/\/ thread has completed its logging output and it's safe to signal\n-  \/\/ the CM thread, the flag's value in the policy has been reset.\n-  bool should_start_conc_mark = collector_state()->in_concurrent_start_gc();\n-  if (should_start_conc_mark) {\n-    _cm->gc_tracer_cm()->set_gc_cause(gc_cause());\n-  }\n+  \/\/ Record whether this pause may need to trigger a concurrent operation. Later,\n+  \/\/ when we signal the G1ConcurrentMarkThread, the collector state has already\n+  \/\/ been reset for the next pause.\n+  bool should_start_concurrent_mark_operation = collector_state()->in_concurrent_start_gc();\n+  bool concurrent_operation_is_full_mark = false;\n@@ -3061,10 +3065,0 @@\n-        if (should_start_conc_mark) {\n-          \/\/ We have to do this before we notify the CM threads that\n-          \/\/ they can start working to make sure that all the\n-          \/\/ appropriate initialization is done on the CM object.\n-          concurrent_mark()->post_concurrent_start();\n-          \/\/ Note that we don't actually trigger the CM thread at\n-          \/\/ this point. We do that later when we're sure that\n-          \/\/ the current thread has completed its logging output.\n-        }\n-\n@@ -3077,0 +3071,4 @@\n+        \/\/ Refine the type of a concurrent mark operation now that we did the\n+        \/\/ evacuation, eventually aborting it.\n+        concurrent_operation_is_full_mark = policy()->concurrent_operation_is_full_mark(\"Revise IHOP\");\n+\n@@ -3079,1 +3077,1 @@\n-        policy()->record_collection_pause_end(pause_time_ms);\n+        policy()->record_collection_pause_end(pause_time_ms, concurrent_operation_is_full_mark);\n@@ -3120,2 +3118,2 @@\n-  if (should_start_conc_mark) {\n-    \/\/ CAUTION: after the doConcurrentMark() call below, the concurrent marking\n+  if (should_start_concurrent_mark_operation) {\n+    \/\/ CAUTION: after the start_concurrent_cycle() call below, the concurrent marking\n@@ -3126,1 +3124,1 @@\n-    do_concurrent_mark();\n+    start_concurrent_cycle(concurrent_operation_is_full_mark);\n@@ -3736,1 +3734,1 @@\n-    concurrent_mark()->pre_concurrent_start();\n+    concurrent_mark()->pre_concurrent_start(gc_cause());\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.cpp","additions":25,"deletions":27,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -749,0 +749,3 @@\n+  \/\/ Start a concurrent cycle.\n+  void start_concurrent_cycle(bool concurrent_operation_is_full_mark);\n+\n@@ -1310,10 +1313,0 @@\n-  \/\/ *** Stuff related to concurrent marking.  It's not clear to me that so\n-  \/\/ many of these need to be public.\n-\n-  \/\/ The functions below are helper functions that a subclass of\n-  \/\/ \"CollectedHeap\" can use in the implementation of its virtual\n-  \/\/ functions.\n-  \/\/ This performs a concurrent marking of the live objects in a\n-  \/\/ bitmap off to the side.\n-  void do_concurrent_mark();\n-\n","filename":"src\/hotspot\/share\/gc\/g1\/g1CollectedHeap.hpp","additions":3,"deletions":10,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -610,1 +610,1 @@\n-        assert(_cm == NULL || _cm->cm_thread()->during_cycle(), \"invariant\");\n+        assert(_cm == NULL || _cm->cm_thread()->in_progress(), \"invariant\");\n@@ -659,1 +659,1 @@\n-  guarantee(cm_thread()->during_cycle(), \"invariant\");\n+  guarantee(cm_thread()->in_progress(), \"invariant\");\n@@ -670,1 +670,1 @@\n-  guarantee(cm_thread()->during_cycle(), \"invariant\");\n+  guarantee(cm_thread()->in_progress(), \"invariant\");\n@@ -687,1 +687,1 @@\n-void G1ConcurrentMark::pre_concurrent_start() {\n+void G1ConcurrentMark::pre_concurrent_start(GCCause::Cause cause) {\n@@ -698,0 +698,2 @@\n+\n+  _gc_tracer_cm->set_gc_cause(cause);\n@@ -701,1 +703,1 @@\n-void G1ConcurrentMark::post_concurrent_start() {\n+void G1ConcurrentMark::post_concurrent_mark_start() {\n@@ -722,0 +724,4 @@\n+void G1ConcurrentMark::post_concurrent_undo_start() {\n+  root_regions()->cancel_scan();\n+}\n+\n@@ -1959,1 +1965,1 @@\n-  if (!cm_thread()->during_cycle() || _has_aborted) {\n+  if (!cm_thread()->in_progress() || _has_aborted) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.cpp","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+#include \"gc\/shared\/gcCause.hpp\"\n@@ -39,0 +40,1 @@\n+#include \"utilities\/numberSeq.hpp\"\n@@ -308,1 +310,1 @@\n-  G1CMRootMemRegions         _root_regions;\n+  G1CMRootMemRegions      _root_regions;\n@@ -545,2 +547,3 @@\n-  void pre_concurrent_start();\n-  void post_concurrent_start();\n+  void pre_concurrent_start(GCCause::Cause cause);\n+  void post_concurrent_mark_start();\n+  void post_concurrent_undo_start();\n@@ -597,1 +600,0 @@\n-  G1OldTracer* gc_tracer_cm() const { return _gc_tracer_cm; }\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMark.hpp","additions":6,"deletions":4,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -45,0 +45,1 @@\n+#include \"utilities\/formatBuffer.hpp\"\n@@ -138,0 +139,1 @@\n+    assert(in_progress(), \"must be\");\n@@ -140,1 +142,2 @@\n-    GCTraceConcTime(Info, gc) tt(\"Concurrent Cycle\");\n+    GCTraceConcTime(Info, gc) tt(FormatBuffer<128>(\"Concurrent %s Cycle\",\n+                                                   _state == FullMark ? \"Mark\" : \"Undo\"));\n@@ -143,2 +146,9 @@\n-    full_concurrent_cycle_do();\n-    concurrent_cycle_end();\n+\n+    if (_state == FullMark) {\n+      concurrent_mark_cycle_do();\n+    } else {\n+      assert(_state == UndoMark, \"Must do undo mark but is %d\", _state);\n+      concurrent_undo_cycle_do();\n+    }\n+\n+    concurrent_cycle_end(_state == FullMark && !_cm->has_aborted());\n@@ -160,1 +170,1 @@\n-  while (!started() && !should_terminate()) {\n+  while (!in_progress() && !should_terminate()) {\n@@ -164,4 +174,0 @@\n-  if (started()) {\n-    set_in_progress();\n-  }\n-\n@@ -272,1 +278,1 @@\n-void G1ConcurrentMarkThread::full_concurrent_cycle_do() {\n+void G1ConcurrentMarkThread::concurrent_mark_cycle_do() {\n@@ -312,1 +318,13 @@\n-void G1ConcurrentMarkThread::concurrent_cycle_end() {\n+void G1ConcurrentMarkThread::concurrent_undo_cycle_do() {\n+  HandleMark hm(Thread::current());\n+  ResourceMark rm;\n+\n+  \/\/ We can (and should) abort if there has been a concurrent cycle abort for\n+  \/\/ some reason.\n+  if (_cm->has_aborted()) { return; }\n+\n+  \/\/ Phase 1: Clear bitmap for next mark.\n+  phase_clear_bitmap_for_next_mark();\n+}\n+\n+void G1ConcurrentMarkThread::concurrent_cycle_end(bool mark_cycle_completed) {\n@@ -319,1 +337,1 @@\n-                                                                  !_cm->has_aborted());\n+                                                                  mark_cycle_completed \/* heap_examined *\/);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMarkThread.cpp","additions":29,"deletions":11,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -43,1 +43,1 @@\n-  enum ServiceState {\n+  enum ServiceState : uint {\n@@ -45,2 +45,2 @@\n-    Started,\n-    InProgress\n+    FullMark,\n+    UndoMark\n@@ -51,1 +51,1 @@\n-  \/\/ Wait for next cycle. Returns false if the service should be stopped.\n+  \/\/ Wait for next cycle. Returns the command passed over.\n@@ -77,2 +77,4 @@\n-  void full_concurrent_cycle_do();\n-  void concurrent_cycle_end();\n+  void concurrent_mark_cycle_do();\n+  void concurrent_undo_cycle_do();\n+\n+  void concurrent_cycle_end(bool mark_cycle_completed);\n@@ -96,1 +98,1 @@\n-  G1ConcurrentMark* cm()   { return _cm; }\n+  G1ConcurrentMark* cm() { return _cm; }\n@@ -98,6 +100,4 @@\n-  void set_idle()          { assert(_state != Started, \"must not be starting a new cycle\"); _state = Idle; }\n-  bool idle()              { return _state == Idle; }\n-  void set_started()       { assert(_state == Idle, \"cycle in progress\"); _state = Started; }\n-  bool started()           { return _state == Started; }\n-  void set_in_progress()   { assert(_state == Started, \"must be starting a cycle\"); _state = InProgress; }\n-  bool in_progress()       { return _state == InProgress; }\n+  void set_idle();\n+  void start_full_mark();\n+  void start_undo_mark();\n+  void set_in_progress();\n@@ -105,1 +105,2 @@\n-  \/\/ Returns true from the moment a marking cycle is\n+  bool idle() const;\n+  \/\/ Returns true from the moment a concurrent cycle is\n@@ -109,5 +110,2 @@\n-  \/\/ cleared). While during_cycle() is true we will not start another cycle\n-  \/\/ so that cycles do not overlap. We cannot use just in_progress()\n-  \/\/ as the CM thread might take some time to wake up before noticing\n-  \/\/ that started() is set and set in_progress().\n-  bool during_cycle()      { return !idle(); }\n+  \/\/ cleared).\n+  bool in_progress() const;\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMarkThread.hpp","additions":17,"deletions":19,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -41,0 +41,21 @@\n+inline void G1ConcurrentMarkThread::set_idle() {\n+  assert(_state == FullMark || _state == UndoMark, \"must not be starting a new cycle\");\n+  _state = Idle;\n+}\n+\n+inline void G1ConcurrentMarkThread::start_full_mark() {\n+  assert(_state == Idle, \"cycle in progress\");\n+  _state = FullMark;\n+}\n+\n+inline void G1ConcurrentMarkThread::start_undo_mark() {\n+  assert(_state == Idle, \"cycle in progress\");\n+  _state = UndoMark;\n+}\n+\n+inline bool G1ConcurrentMarkThread::idle() const { return _state == Idle; }\n+\n+inline bool G1ConcurrentMarkThread::in_progress() const {\n+  return !idle();\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ConcurrentMarkThread.inline.hpp","additions":21,"deletions":0,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -42,2 +42,2 @@\n-void G1HeterogeneousHeapPolicy::record_collection_pause_end(double pause_time_ms) {\n-  G1Policy::record_collection_pause_end(pause_time_ms);\n+void G1HeterogeneousHeapPolicy::record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark) {\n+  G1Policy::record_collection_pause_end(pause_time_ms, concurrent_operation_is_full_mark);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeterogeneousHeapPolicy.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -41,1 +41,1 @@\n-  virtual void record_collection_pause_end(double pause_time_ms);\n+  virtual void record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1HeterogeneousHeapPolicy.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -455,1 +455,1 @@\n-  collector_state()->set_initiate_conc_mark_if_possible(need_to_start_conc_mark(\"end of Full GC\", 0));\n+  collector_state()->set_initiate_conc_mark_if_possible(need_to_start_conc_mark(\"end of Full GC\"));\n@@ -550,1 +550,1 @@\n-void G1Policy::record_concurrent_mark_init_end(double mark_init_elapsed_time_ms) {\n+void G1Policy::record_concurrent_mark_init_end() {\n@@ -594,1 +594,1 @@\n-  return _g1h->concurrent_mark()->cm_thread()->during_cycle() || collector_state()->in_young_gc_before_mixed();\n+  return _g1h->concurrent_mark()->cm_thread()->in_progress() || collector_state()->in_young_gc_before_mixed();\n@@ -615,1 +615,0 @@\n-\n@@ -619,0 +618,5 @@\n+bool G1Policy::concurrent_operation_is_full_mark(const char* msg) {\n+  return collector_state()->in_concurrent_start_gc() &&\n+    ((_g1h->gc_cause() != GCCause::_g1_humongous_allocation) || need_to_start_conc_mark(msg));\n+}\n+\n@@ -634,1 +638,1 @@\n-void G1Policy::record_collection_pause_end(double pause_time_ms) {\n+void G1Policy::record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark) {\n@@ -640,1 +644,1 @@\n-  PauseKind this_pause = young_gc_pause_kind();\n+  PauseKind this_pause = young_gc_pause_kind(concurrent_operation_is_full_mark);\n@@ -645,1 +649,1 @@\n-    record_concurrent_mark_init_end(0.0);\n+    record_concurrent_mark_init_end();\n@@ -784,1 +788,1 @@\n-    collector_state()->set_mark_or_rebuild_in_progress(true);\n+    collector_state()->set_mark_or_rebuild_in_progress(concurrent_operation_is_full_mark);\n@@ -813,1 +817,1 @@\n-    _concurrent_start_to_mixed.reset();\n+    abort_time_to_mixed_tracking();\n@@ -1028,1 +1032,1 @@\n-  bool during_cycle = _g1h->concurrent_mark()->cm_thread()->during_cycle();\n+  bool during_cycle = _g1h->concurrent_mark()->cm_thread()->in_progress();\n@@ -1159,1 +1163,4 @@\n-  return kind == ConcurrentStartGC || kind == LastYoungGC || kind == YoungOnlyGC;\n+  return kind == ConcurrentStartUndoGC ||\n+         kind == ConcurrentStartMarkGC ||\n+         kind == LastYoungGC ||\n+         kind == YoungOnlyGC;\n@@ -1174,1 +1181,1 @@\n-  return kind == ConcurrentStartGC;\n+  return kind == ConcurrentStartMarkGC || kind == ConcurrentStartUndoGC;\n@@ -1177,1 +1184,1 @@\n-G1Policy::PauseKind G1Policy::young_gc_pause_kind() const {\n+G1Policy::PauseKind G1Policy::young_gc_pause_kind(bool concurrent_operation_is_full_mark) const {\n@@ -1181,1 +1188,1 @@\n-    return ConcurrentStartGC;\n+    return concurrent_operation_is_full_mark ? ConcurrentStartMarkGC : ConcurrentStartUndoGC;\n@@ -1217,1 +1224,3 @@\n-void G1Policy::record_pause(PauseKind kind, double start, double end) {\n+void G1Policy::record_pause(PauseKind kind,\n+                            double start,\n+                            double end) {\n@@ -1227,0 +1236,6 @@\n+  update_time_to_mixed_tracking(kind, start, end);\n+}\n+\n+void G1Policy::update_time_to_mixed_tracking(PauseKind kind,\n+                                             double start,\n+                                             double end) {\n@@ -1238,2 +1253,7 @@\n-    case ConcurrentStartGC:\n-      if (_g1h->gc_cause() != GCCause::_g1_periodic_collection) {\n+    case ConcurrentStartMarkGC:\n+    case ConcurrentStartUndoGC:\n+      \/\/ Do not track time-to-mixed time for periodic collections as they are likely\n+      \/\/ to be not representative to regular operation as the mutators are idle at\n+      \/\/ that time. Also only track full concurrent mark cycles.\n+      if ((_g1h->gc_cause() != GCCause::_g1_periodic_collection) &&\n+        (kind != ConcurrentStartUndoGC)) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.cpp","additions":37,"deletions":17,"binary":false,"changes":54,"status":"modified"},{"patch":"@@ -267,1 +267,1 @@\n-  enum PauseKind {\n+  enum PauseKind : uint {\n@@ -272,1 +272,2 @@\n-    ConcurrentStartGC,\n+    ConcurrentStartMarkGC,\n+    ConcurrentStartUndoGC,\n@@ -282,1 +283,3 @@\n-  PauseKind young_gc_pause_kind() const;\n+  PauseKind young_gc_pause_kind(bool concurrent_operation_is_full_mark) const;\n+  \/\/ Manage time-to-mixed tracking.\n+  void update_time_to_mixed_tracking(PauseKind pause, double start, double end);\n@@ -322,0 +325,2 @@\n+  bool concurrent_operation_is_full_mark(const char* msg = NULL);\n+\n@@ -326,1 +331,1 @@\n-  virtual void record_collection_pause_end(double pause_time_ms);\n+  virtual void record_collection_pause_end(double pause_time_ms, bool concurrent_operation_is_full_mark);\n@@ -333,1 +338,1 @@\n-  void record_concurrent_mark_init_end(double mark_init_elapsed_time_ms);\n+  void record_concurrent_mark_init_end();\n","filename":"src\/hotspot\/share\/gc\/g1\/g1Policy.hpp","additions":10,"deletions":5,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -62,1 +62,1 @@\n-  if (g1h->concurrent_mark()->cm_thread()->during_cycle()) {\n+  if (g1h->concurrent_mark()->cm_thread()->in_progress()) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ServiceThread.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -95,1 +95,1 @@\n-#include \"gc\/g1\/g1ConcurrentMarkThread.hpp\"\n+#include \"gc\/g1\/g1ConcurrentMarkThread.inline.hpp\"\n@@ -476,1 +476,1 @@\n-    return g1h->concurrent_mark()->cm_thread()->during_cycle();\n+    return g1h->concurrent_mark()->cm_thread()->in_progress();\n@@ -484,1 +484,1 @@\n-    if (!g1h->concurrent_mark()->cm_thread()->during_cycle()) {\n+    if (!g1h->concurrent_mark()->cm_thread()->in_progress()) {\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -0,0 +1,129 @@\n+\/*\n+ * Copyright (c) 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+ *\n+ * This code is free software; you can redistribute it and\/or modify it\n+ * under the terms of the GNU General Public License version 2 only, as\n+ * published by the Free Software Foundation.\n+ *\n+ * This code is distributed in the hope that it will be useful, but WITHOUT\n+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+ * version 2 for more details (a copy is included in the LICENSE file that\n+ * accompanied this code).\n+ *\n+ * You should have received a copy of the GNU General Public License version\n+ * 2 along with this work; if not, write to the Free Software Foundation,\n+ * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+ *\n+ * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+ * or visit www.oracle.com if you need additional information or have any\n+ * questions.\n+ *\/\n+\n+package gc.g1;\n+\n+\/*\n+ * @test TestHumongousConcurrentStartUndo\n+ * @summary Tests an alternating sequence of Concurrent Mark and Concurrent Undo\n+ * cycles.\n+ * reclaim heap occupancy falls below the IHOP value.\n+ * @requires vm.gc.G1\n+ * @library \/test\/lib \/testlibrary \/\n+ * @modules java.base\/jdk.internal.misc\n+ *          java.management\n+ * @build sun.hotspot.WhiteBox\n+ * @run driver ClassFileInstaller sun.hotspot.WhiteBox\n+ *             sun.hotspot.WhiteBox$WhiteBoxPermission\n+ * @run main\/othervm -XX:+UnlockDiagnosticVMOptions -XX:+WhiteBoxAPI -Xbootclasspath\/a:.\n+ *                   gc.g1.TestHumongousConcurrentStartUndo\n+ *\/\n+\n+import gc.testlibrary.Helpers;\n+\n+import sun.hotspot.WhiteBox;\n+import jdk.test.lib.process.OutputAnalyzer;\n+import jdk.test.lib.process.ProcessTools;\n+\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+\n+public class TestHumongousConcurrentStartUndo {\n+    \/\/ Heap sizes < 224 MB are increased to 224 MB if vm_page_size == 64K to\n+    \/\/ fulfill alignment constraints.\n+    private static final int HeapSize                       = 224; \/\/ MB\n+    private static final int HeapRegionSize                 = 1;   \/\/ MB\n+    private static final int InitiatingHeapOccupancyPercent = 50;  \/\/ %\n+    private static final int YoungSize                      = HeapSize \/ 8;\n+\n+    public static void main(String[] args) throws Exception {\n+        ProcessBuilder pb = ProcessTools.createJavaProcessBuilder(\n+            \"-Xbootclasspath\/a:.\",\n+            \"-XX:+UseG1GC\",\n+            \"-Xms\" + HeapSize + \"m\",\n+            \"-Xmx\" + HeapSize + \"m\",\n+            \"-Xmn\" + YoungSize + \"m\",\n+            \"-XX:G1HeapRegionSize=\" + HeapRegionSize + \"m\",\n+            \"-XX:InitiatingHeapOccupancyPercent=\" + InitiatingHeapOccupancyPercent,\n+            \"-XX:-G1UseAdaptiveIHOP\",\n+            \"-XX:+UnlockDiagnosticVMOptions\",\n+            \"-XX:+WhiteBoxAPI\",\n+            \"-Xlog:gc*\",\n+            EdenObjectAllocatorWithHumongousAllocation.class.getName());\n+\n+        OutputAnalyzer output = new OutputAnalyzer(pb.start());\n+        output.shouldContain(\"Pause Young (Concurrent Start) (G1 Humongous Allocation)\");\n+        output.shouldContain(\"Concurrent Undo Cycle\");\n+        output.shouldContain(\"Concurrent Mark Cycle\");\n+        output.shouldHaveExitValue(0);\n+        System.out.println(output.getStdout());\n+    }\n+\n+    static class EdenObjectAllocatorWithHumongousAllocation {\n+        private static final WhiteBox WHITE_BOX = WhiteBox.getWhiteBox();\n+\n+        private static void allocateHumongous(int num, int objSize, Queue keeper) {\n+            for (int i = 1; i <= num; i++) {\n+                if (i % 10 == 0) {\n+                    System.out.println(\"Allocating humongous object \" + i + \"\/\" + num +\n+                                       \" of size \" + objSize + \" bytes\");\n+                }\n+                byte[] e = new byte[objSize];\n+                if (!keeper.offer(e)) {\n+                    keeper.remove();\n+                    keeper.offer(e);\n+                }\n+            }\n+        }\n+\n+        public static void main(String [] args) throws Exception {\n+            final int M = 1024 * 1024;\n+            \/\/ Make humongous object size 75% of region size\n+            final int humongousObjectSize =\n+                (int)(HeapRegionSize * M * 0.75);\n+\n+            \/\/ Number of objects to allocate to go above IHOP\n+            final int humongousObjectAllocations =\n+                (int)(((HeapSize - YoungSize) * 80 \/ 100.0) \/ HeapRegionSize);\n+\n+            ArrayBlockingQueue a;\n+            for (int iterate = 0; iterate < 3; iterate++) {\n+                WHITE_BOX.fullGC();\n+\n+                a = new ArrayBlockingQueue(1);\n+                allocateHumongous(humongousObjectAllocations, humongousObjectSize, a);\n+                Helpers.waitTillCMCFinished(WHITE_BOX, 1);\n+                a = null;\n+\n+                a = new ArrayBlockingQueue(humongousObjectAllocations);\n+                allocateHumongous(humongousObjectAllocations, humongousObjectSize, a);\n+                Helpers.waitTillCMCFinished(WHITE_BOX, 1);\n+                a = null;\n+\n+                allocateHumongous(1, humongousObjectSize, new ArrayBlockingQueue(1));\n+                Helpers.waitTillCMCFinished(WHITE_BOX, 1);\n+            }\n+        }\n+    }\n+}\n+\n","filename":"test\/hotspot\/jtreg\/gc\/g1\/TestHumongousConcurrentStartUndo.java","additions":129,"deletions":0,"binary":false,"changes":129,"status":"added"},{"patch":"@@ -1,46 +0,0 @@\n-\/*\n- * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n- * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n- *\n- * This code is free software; you can redistribute it and\/or modify it\n- * under the terms of the GNU General Public License version 2 only, as\n- * published by the Free Software Foundation.  Oracle designates this\n- * particular file as subject to the \"Classpath\" exception as provided\n- * by Oracle in the LICENSE file that accompanied this code.\n- *\n- * This code is distributed in the hope that it will be useful, but WITHOUT\n- * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n- * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n- * version 2 for more details (a copy is included in the LICENSE file that\n- * accompanied this code).\n- *\n- * You should have received a copy of the GNU General Public License version\n- * 2 along with this work; if not, write to the Free Software Foundation,\n- * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n- *\n- * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n- * or visit www.oracle.com if you need additional information or have any\n- * questions.\n- *\/\n-package jdk.jfr.event.gc.detailed;\n-\n-\/**\n- * @test\n- * @key randomness\n- * @summary Test allocates humongous objects with G1 GC. Objects\n- * considered humongous when it allocates equals or more than one region. As\n- * we're passing the size of byte array we need adjust it that entire structure\n- * fits exactly to one region, if not - G1 will allocate another almost empty\n- * region as a continue of humongous. Thus we will exhaust memory very fast and\n- * test will fail with OOME.\n- * @requires vm.hasJFR\n- * @requires vm.gc == \"null\" | vm.gc == \"G1\"\n- * @library \/test\/lib \/test\/jdk\n- * @run main\/othervm -XX:+UseG1GC -XX:MaxNewSize=5m -Xmx256m -XX:G1HeapRegionSize=1048576 jdk.jfr.event.gc.detailed.TestStressBigAllocationGCEventsWithG1 1048544\n- *\/\n-public class TestStressBigAllocationGCEventsWithG1 {\n-\n-    public static void main(String[] args) throws Exception {\n-        new StressAllocationGCEvents().run(args);\n-    }\n-}\n","filename":"test\/hotspot\/jtreg\/gc\/stress\/jfr\/TestStressBigAllocationGCEventsWithG1.java","additions":0,"deletions":46,"binary":false,"changes":46,"status":"deleted"}]}