{"files":[{"patch":"@@ -56,1 +56,12 @@\n-  update_layout(true);\n+  int lgrp_limit = (int)os::numa_get_groups_num();\n+  int *lgrp_ids = NEW_C_HEAP_ARRAY(int, lgrp_limit, mtGC);\n+  int lgrp_num = (int)os::numa_get_leaf_groups(lgrp_ids, lgrp_limit);\n+  assert(lgrp_num > 0, \"There should be at least one locality group\");\n+\n+  lgrp_spaces()->reserve(lgrp_num);\n+  \/\/ Add new spaces for the new nodes\n+  for (int i = 0; i < lgrp_num; i++) {\n+    lgrp_spaces()->append(new LGRPSpace(lgrp_ids[i], alignment));\n+  }\n+\n+  FREE_C_HEAP_ARRAY(int, lgrp_ids);\n@@ -233,35 +244,0 @@\n-\n-\/\/ Check if the NUMA topology has changed. Add and remove spaces if needed.\n-\/\/ The update can be forced by setting the force parameter equal to true.\n-bool MutableNUMASpace::update_layout(bool force) {\n-  \/\/ Check if the topology had changed.\n-  bool changed = os::numa_topology_changed();\n-  if (force || changed) {\n-    \/\/ Compute lgrp intersection. Add\/remove spaces.\n-    int lgrp_limit = (int)os::numa_get_groups_num();\n-    int *lgrp_ids = NEW_C_HEAP_ARRAY(int, lgrp_limit, mtGC);\n-    int lgrp_num = (int)os::numa_get_leaf_groups(lgrp_ids, lgrp_limit);\n-    assert(lgrp_num > 0, \"There should be at least one locality group\");\n-    \/\/ Clear existing spaces\n-    for (int i = 0; i < lgrp_spaces()->length(); ++i) {\n-      delete lgrp_spaces()->at(i);\n-    }\n-    lgrp_spaces()->clear();\n-    lgrp_spaces()->reserve(lgrp_num);\n-    \/\/ Add new spaces for the new nodes\n-    for (int i = 0; i < lgrp_num; i++) {\n-      lgrp_spaces()->append(new LGRPSpace(lgrp_ids[i], alignment()));\n-    }\n-\n-    FREE_C_HEAP_ARRAY(int, lgrp_ids);\n-\n-    if (changed) {\n-      for (JavaThreadIteratorWithHandle jtiwh; JavaThread *thread = jtiwh.next(); ) {\n-        thread->set_lgrp_id(-1);\n-      }\n-    }\n-    return true;\n-  }\n-  return false;\n-}\n-\n@@ -305,5 +281,2 @@\n-  if (update_layout(false)) {\n-    \/\/ If the topology has changed, make all chunks zero-sized.\n-    \/\/ And clear the alloc-rate statistics.\n-    \/\/ In future we may want to handle this more gracefully in order\n-    \/\/ to avoid the reallocation of the pages as much as possible.\n+  bool should_initialize = false;\n+  if (!os::numa_has_static_binding()) {\n@@ -311,5 +284,4 @@\n-      LGRPSpace *ls = lgrp_spaces()->at(i);\n-      MutableSpace *s = ls->space();\n-      s->set_end(s->bottom());\n-      s->set_top(s->bottom());\n-      ls->clear_alloc_rate();\n+      if (!lgrp_spaces()->at(i)->invalid_region().is_empty()) {\n+        should_initialize = true;\n+        break;\n+      }\n@@ -317,0 +289,4 @@\n+  }\n+\n+  if (should_initialize ||\n+      (UseAdaptiveNUMAChunkSizing && adaptation_cycles() < samples_count())) {\n@@ -321,18 +297,0 @@\n-  } else {\n-    bool should_initialize = false;\n-    if (!os::numa_has_static_binding()) {\n-      for (int i = 0; i < lgrp_spaces()->length(); i++) {\n-        if (!lgrp_spaces()->at(i)->invalid_region().is_empty()) {\n-          should_initialize = true;\n-          break;\n-        }\n-      }\n-    }\n-\n-    if (should_initialize ||\n-        (UseAdaptiveNUMAChunkSizing && adaptation_cycles() < samples_count())) {\n-      \/\/ A NUMA space is never mangled\n-      initialize(region(),\n-                 SpaceDecorator::Clear,\n-                 SpaceDecorator::DontMangle);\n-    }\n","filename":"src\/hotspot\/share\/gc\/parallel\/mutableNUMASpace.cpp","additions":22,"deletions":64,"binary":false,"changes":86,"status":"modified"}]}