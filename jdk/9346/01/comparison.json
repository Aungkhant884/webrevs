{"files":[{"patch":"@@ -145,2 +145,1 @@\n-        $d\/cpu\/$(HOTSPOT_TARGET_CPU_ARCH)\/$(HOTSPOT_TARGET_CPU_ARCH)_neon.ad \\\n-        $d\/cpu\/$(HOTSPOT_TARGET_CPU_ARCH)\/$(HOTSPOT_TARGET_CPU_ARCH)_sve.ad \\\n+        $d\/cpu\/$(HOTSPOT_TARGET_CPU_ARCH)\/$(HOTSPOT_TARGET_CPU_ARCH)_vector.ad \\\n","filename":"make\/hotspot\/gensrc\/GensrcAdlc.gmk","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -182,4 +182,0 @@\n-  reg_def V0_L ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(4) );\n-  reg_def V0_M ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(5) );\n-  reg_def V0_N ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(6) );\n-  reg_def V0_O ( SOC, SOC, Op_RegF, 0, v0->as_VMReg()->next(7) );\n@@ -191,4 +187,0 @@\n-  reg_def V1_L ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(4) );\n-  reg_def V1_M ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(5) );\n-  reg_def V1_N ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(6) );\n-  reg_def V1_O ( SOC, SOC, Op_RegF, 1, v1->as_VMReg()->next(7) );\n@@ -200,4 +192,0 @@\n-  reg_def V2_L ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(4) );\n-  reg_def V2_M ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(5) );\n-  reg_def V2_N ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(6) );\n-  reg_def V2_O ( SOC, SOC, Op_RegF, 2, v2->as_VMReg()->next(7) );\n@@ -209,4 +197,0 @@\n-  reg_def V3_L ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(4) );\n-  reg_def V3_M ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(5) );\n-  reg_def V3_N ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(6) );\n-  reg_def V3_O ( SOC, SOC, Op_RegF, 3, v3->as_VMReg()->next(7) );\n@@ -218,4 +202,0 @@\n-  reg_def V4_L ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(4) );\n-  reg_def V4_M ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(5) );\n-  reg_def V4_N ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(6) );\n-  reg_def V4_O ( SOC, SOC, Op_RegF, 4, v4->as_VMReg()->next(7) );\n@@ -227,4 +207,0 @@\n-  reg_def V5_L ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(4) );\n-  reg_def V5_M ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(5) );\n-  reg_def V5_N ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(6) );\n-  reg_def V5_O ( SOC, SOC, Op_RegF, 5, v5->as_VMReg()->next(7) );\n@@ -236,4 +212,0 @@\n-  reg_def V6_L ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(4) );\n-  reg_def V6_M ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(5) );\n-  reg_def V6_N ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(6) );\n-  reg_def V6_O ( SOC, SOC, Op_RegF, 6, v6->as_VMReg()->next(7) );\n@@ -245,4 +217,0 @@\n-  reg_def V7_L ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(4) );\n-  reg_def V7_M ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(5) );\n-  reg_def V7_N ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(6) );\n-  reg_def V7_O ( SOC, SOC, Op_RegF, 7, v7->as_VMReg()->next(7) );\n@@ -254,4 +222,0 @@\n-  reg_def V8_L ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(4) );\n-  reg_def V8_M ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(5) );\n-  reg_def V8_N ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(6) );\n-  reg_def V8_O ( SOC, SOC, Op_RegF, 8, v8->as_VMReg()->next(7) );\n@@ -263,4 +227,0 @@\n-  reg_def V9_L ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(4) );\n-  reg_def V9_M ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(5) );\n-  reg_def V9_N ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(6) );\n-  reg_def V9_O ( SOC, SOC, Op_RegF, 9, v9->as_VMReg()->next(7) );\n@@ -272,4 +232,0 @@\n-  reg_def V10_L ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(4) );\n-  reg_def V10_M ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(5) );\n-  reg_def V10_N ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(6) );\n-  reg_def V10_O ( SOC, SOC, Op_RegF, 10, v10->as_VMReg()->next(7) );\n@@ -281,4 +237,0 @@\n-  reg_def V11_L ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(4) );\n-  reg_def V11_M ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(5) );\n-  reg_def V11_N ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(6) );\n-  reg_def V11_O ( SOC, SOC, Op_RegF, 11, v11->as_VMReg()->next(7) );\n@@ -290,4 +242,0 @@\n-  reg_def V12_L ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(4) );\n-  reg_def V12_M ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(5) );\n-  reg_def V12_N ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(6) );\n-  reg_def V12_O ( SOC, SOC, Op_RegF, 12, v12->as_VMReg()->next(7) );\n@@ -299,4 +247,0 @@\n-  reg_def V13_L ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(4) );\n-  reg_def V13_M ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(5) );\n-  reg_def V13_N ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(6) );\n-  reg_def V13_O ( SOC, SOC, Op_RegF, 13, v13->as_VMReg()->next(7) );\n@@ -308,4 +252,0 @@\n-  reg_def V14_L ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(4) );\n-  reg_def V14_M ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(5) );\n-  reg_def V14_N ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(6) );\n-  reg_def V14_O ( SOC, SOC, Op_RegF, 14, v14->as_VMReg()->next(7) );\n@@ -317,4 +257,0 @@\n-  reg_def V15_L ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(4) );\n-  reg_def V15_M ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(5) );\n-  reg_def V15_N ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(6) );\n-  reg_def V15_O ( SOC, SOC, Op_RegF, 15, v15->as_VMReg()->next(7) );\n@@ -326,4 +262,0 @@\n-  reg_def V16_L ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(4) );\n-  reg_def V16_M ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(5) );\n-  reg_def V16_N ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(6) );\n-  reg_def V16_O ( SOC, SOC, Op_RegF, 16, v16->as_VMReg()->next(7) );\n@@ -335,4 +267,0 @@\n-  reg_def V17_L ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(4) );\n-  reg_def V17_M ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(5) );\n-  reg_def V17_N ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(6) );\n-  reg_def V17_O ( SOC, SOC, Op_RegF, 17, v17->as_VMReg()->next(7) );\n@@ -344,4 +272,0 @@\n-  reg_def V18_L ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(4) );\n-  reg_def V18_M ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(5) );\n-  reg_def V18_N ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(6) );\n-  reg_def V18_O ( SOC, SOC, Op_RegF, 18, v18->as_VMReg()->next(7) );\n@@ -353,4 +277,0 @@\n-  reg_def V19_L ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(4) );\n-  reg_def V19_M ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(5) );\n-  reg_def V19_N ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(6) );\n-  reg_def V19_O ( SOC, SOC, Op_RegF, 19, v19->as_VMReg()->next(7) );\n@@ -362,4 +282,0 @@\n-  reg_def V20_L ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(4) );\n-  reg_def V20_M ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(5) );\n-  reg_def V20_N ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(6) );\n-  reg_def V20_O ( SOC, SOC, Op_RegF, 20, v20->as_VMReg()->next(7) );\n@@ -371,4 +287,0 @@\n-  reg_def V21_L ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(4) );\n-  reg_def V21_M ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(5) );\n-  reg_def V21_N ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(6) );\n-  reg_def V21_O ( SOC, SOC, Op_RegF, 21, v21->as_VMReg()->next(7) );\n@@ -380,4 +292,0 @@\n-  reg_def V22_L ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(4) );\n-  reg_def V22_M ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(5) );\n-  reg_def V22_N ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(6) );\n-  reg_def V22_O ( SOC, SOC, Op_RegF, 22, v22->as_VMReg()->next(7) );\n@@ -389,4 +297,0 @@\n-  reg_def V23_L ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(4) );\n-  reg_def V23_M ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(5) );\n-  reg_def V23_N ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(6) );\n-  reg_def V23_O ( SOC, SOC, Op_RegF, 23, v23->as_VMReg()->next(7) );\n@@ -398,4 +302,0 @@\n-  reg_def V24_L ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(4) );\n-  reg_def V24_M ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(5) );\n-  reg_def V24_N ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(6) );\n-  reg_def V24_O ( SOC, SOC, Op_RegF, 24, v24->as_VMReg()->next(7) );\n@@ -407,4 +307,0 @@\n-  reg_def V25_L ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(4) );\n-  reg_def V25_M ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(5) );\n-  reg_def V25_N ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(6) );\n-  reg_def V25_O ( SOC, SOC, Op_RegF, 25, v25->as_VMReg()->next(7) );\n@@ -416,4 +312,0 @@\n-  reg_def V26_L ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(4) );\n-  reg_def V26_M ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(5) );\n-  reg_def V26_N ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(6) );\n-  reg_def V26_O ( SOC, SOC, Op_RegF, 26, v26->as_VMReg()->next(7) );\n@@ -425,4 +317,0 @@\n-  reg_def V27_L ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(4) );\n-  reg_def V27_M ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(5) );\n-  reg_def V27_N ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(6) );\n-  reg_def V27_O ( SOC, SOC, Op_RegF, 27, v27->as_VMReg()->next(7) );\n@@ -434,4 +322,0 @@\n-  reg_def V28_L ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(4) );\n-  reg_def V28_M ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(5) );\n-  reg_def V28_N ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(6) );\n-  reg_def V28_O ( SOC, SOC, Op_RegF, 28, v28->as_VMReg()->next(7) );\n@@ -443,4 +327,0 @@\n-  reg_def V29_L ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(4) );\n-  reg_def V29_M ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(5) );\n-  reg_def V29_N ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(6) );\n-  reg_def V29_O ( SOC, SOC, Op_RegF, 29, v29->as_VMReg()->next(7) );\n@@ -452,4 +332,0 @@\n-  reg_def V30_L ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(4) );\n-  reg_def V30_M ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(5) );\n-  reg_def V30_N ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(6) );\n-  reg_def V30_O ( SOC, SOC, Op_RegF, 30, v30->as_VMReg()->next(7) );\n@@ -461,5 +337,0 @@\n-  reg_def V31_L ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(4) );\n-  reg_def V31_M ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(5) );\n-  reg_def V31_N ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(6) );\n-  reg_def V31_O ( SOC, SOC, Op_RegF, 31, v31->as_VMReg()->next(7) );\n-\n@@ -553,16 +424,16 @@\n-    V16, V16_H, V16_J, V16_K, V16_L, V16_M, V16_N, V16_O,\n-    V17, V17_H, V17_J, V17_K, V17_L, V17_M, V17_N, V17_O,\n-    V18, V18_H, V18_J, V18_K, V18_L, V18_M, V18_N, V18_O,\n-    V19, V19_H, V19_J, V19_K, V19_L, V19_M, V19_N, V19_O,\n-    V20, V20_H, V20_J, V20_K, V20_L, V20_M, V20_N, V20_O,\n-    V21, V21_H, V21_J, V21_K, V21_L, V21_M, V21_N, V21_O,\n-    V22, V22_H, V22_J, V22_K, V22_L, V22_M, V22_N, V22_O,\n-    V23, V23_H, V23_J, V23_K, V23_L, V23_M, V23_N, V23_O,\n-    V24, V24_H, V24_J, V24_K, V24_L, V24_M, V24_N, V24_O,\n-    V25, V25_H, V25_J, V25_K, V25_L, V25_M, V25_N, V25_O,\n-    V26, V26_H, V26_J, V26_K, V26_L, V26_M, V26_N, V26_O,\n-    V27, V27_H, V27_J, V27_K, V27_L, V27_M, V27_N, V27_O,\n-    V28, V28_H, V28_J, V28_K, V28_L, V28_M, V28_N, V28_O,\n-    V29, V29_H, V29_J, V29_K, V29_L, V29_M, V29_N, V29_O,\n-    V30, V30_H, V30_J, V30_K, V30_L, V30_M, V30_N, V30_O,\n-    V31, V31_H, V31_J, V31_K, V31_L, V31_M, V31_N, V31_O,\n+    V16, V16_H, V16_J, V16_K,\n+    V17, V17_H, V17_J, V17_K,\n+    V18, V18_H, V18_J, V18_K,\n+    V19, V19_H, V19_J, V19_K,\n+    V20, V20_H, V20_J, V20_K,\n+    V21, V21_H, V21_J, V21_K,\n+    V22, V22_H, V22_J, V22_K,\n+    V23, V23_H, V23_J, V23_K,\n+    V24, V24_H, V24_J, V24_K,\n+    V25, V25_H, V25_J, V25_K,\n+    V26, V26_H, V26_J, V26_K,\n+    V27, V27_H, V27_J, V27_K,\n+    V28, V28_H, V28_J, V28_K,\n+    V29, V29_H, V29_J, V29_K,\n+    V30, V30_H, V30_J, V30_K,\n+    V31, V31_H, V31_J, V31_K,\n@@ -571,8 +442,8 @@\n-    V0, V0_H, V0_J, V0_K, V0_L, V0_M, V0_N, V0_O,\n-    V1, V1_H, V1_J, V1_K, V1_L, V1_M, V1_N, V1_O,\n-    V2, V2_H, V2_J, V2_K, V2_L, V2_M, V2_N, V2_O,\n-    V3, V3_H, V3_J, V3_K, V3_L, V3_M, V3_N, V3_O,\n-    V4, V4_H, V4_J, V4_K, V4_L, V4_M, V4_N, V4_O,\n-    V5, V5_H, V5_J, V5_K, V5_L, V5_M, V5_N, V5_O,\n-    V6, V6_H, V6_J, V6_K, V6_L, V6_M, V6_N, V6_O,\n-    V7, V7_H, V7_J, V7_K, V7_L, V7_M, V7_N, V7_O,\n+    V0, V0_H, V0_J, V0_K,\n+    V1, V1_H, V1_J, V1_K,\n+    V2, V2_H, V2_J, V2_K,\n+    V3, V3_H, V3_J, V3_K,\n+    V4, V4_H, V4_J, V4_K,\n+    V5, V5_H, V5_J, V5_K,\n+    V6, V6_H, V6_J, V6_K,\n+    V7, V7_H, V7_J, V7_K,\n@@ -581,8 +452,8 @@\n-    V8, V8_H, V8_J, V8_K, V8_L, V8_M, V8_N, V8_O,\n-    V9, V9_H, V9_J, V9_K, V9_L, V9_M, V9_N, V9_O,\n-    V10, V10_H, V10_J, V10_K, V10_L, V10_M, V10_N, V10_O,\n-    V11, V11_H, V11_J, V11_K, V11_L, V11_M, V11_N, V11_O,\n-    V12, V12_H, V12_J, V12_K, V12_L, V12_M, V12_N, V12_O,\n-    V13, V13_H, V13_J, V13_K, V13_L, V13_M, V13_N, V13_O,\n-    V14, V14_H, V14_J, V14_K, V14_L, V14_M, V14_N, V14_O,\n-    V15, V15_H, V15_J, V15_K, V15_L, V15_M, V15_N, V15_O,\n+    V8, V8_H, V8_J, V8_K,\n+    V9, V9_H, V9_J, V9_K,\n+    V10, V10_H, V10_J, V10_K,\n+    V11, V11_H, V11_J, V11_K,\n+    V12, V12_H, V12_J, V12_K,\n+    V13, V13_H, V13_J, V13_K,\n+    V14, V14_H, V14_J, V14_K,\n+    V15, V15_H, V15_J, V15_K,\n@@ -903,32 +774,32 @@\n-    V0, V0_H, V0_J, V0_K, V0_L, V0_M, V0_N, V0_O,\n-    V1, V1_H, V1_J, V1_K, V1_L, V1_M, V1_N, V1_O,\n-    V2, V2_H, V2_J, V2_K, V2_L, V2_M, V2_N, V2_O,\n-    V3, V3_H, V3_J, V3_K, V3_L, V3_M, V3_N, V3_O,\n-    V4, V4_H, V4_J, V4_K, V4_L, V4_M, V4_N, V4_O,\n-    V5, V5_H, V5_J, V5_K, V5_L, V5_M, V5_N, V5_O,\n-    V6, V6_H, V6_J, V6_K, V6_L, V6_M, V6_N, V6_O,\n-    V7, V7_H, V7_J, V7_K, V7_L, V7_M, V7_N, V7_O,\n-    V8, V8_H, V8_J, V8_K, V8_L, V8_M, V8_N, V8_O,\n-    V9, V9_H, V9_J, V9_K, V9_L, V9_M, V9_N, V9_O,\n-    V10, V10_H, V10_J, V10_K, V10_L, V10_M, V10_N, V10_O,\n-    V11, V11_H, V11_J, V11_K, V11_L, V11_M, V11_N, V11_O,\n-    V12, V12_H, V12_J, V12_K, V12_L, V12_M, V12_N, V12_O,\n-    V13, V13_H, V13_J, V13_K, V13_L, V13_M, V13_N, V13_O,\n-    V14, V14_H, V14_J, V14_K, V14_L, V14_M, V14_N, V14_O,\n-    V15, V15_H, V15_J, V15_K, V15_L, V15_M, V15_N, V15_O,\n-    V16, V16_H, V16_J, V16_K, V16_L, V16_M, V16_N, V16_O,\n-    V17, V17_H, V17_J, V17_K, V17_L, V17_M, V17_N, V17_O,\n-    V18, V18_H, V18_J, V18_K, V18_L, V18_M, V18_N, V18_O,\n-    V19, V19_H, V19_J, V19_K, V19_L, V19_M, V19_N, V19_O,\n-    V20, V20_H, V20_J, V20_K, V20_L, V20_M, V20_N, V20_O,\n-    V21, V21_H, V21_J, V21_K, V21_L, V21_M, V21_N, V21_O,\n-    V22, V22_H, V22_J, V22_K, V22_L, V22_M, V22_N, V22_O,\n-    V23, V23_H, V23_J, V23_K, V23_L, V23_M, V23_N, V23_O,\n-    V24, V24_H, V24_J, V24_K, V24_L, V24_M, V24_N, V24_O,\n-    V25, V25_H, V25_J, V25_K, V25_L, V25_M, V25_N, V25_O,\n-    V26, V26_H, V26_J, V26_K, V26_L, V26_M, V26_N, V26_O,\n-    V27, V27_H, V27_J, V27_K, V27_L, V27_M, V27_N, V27_O,\n-    V28, V28_H, V28_J, V28_K, V28_L, V28_M, V28_N, V28_O,\n-    V29, V29_H, V29_J, V29_K, V29_L, V29_M, V29_N, V29_O,\n-    V30, V30_H, V30_J, V30_K, V30_L, V30_M, V30_N, V30_O,\n-    V31, V31_H, V31_J, V31_K, V31_L, V31_M, V31_N, V31_O,\n+    V0, V0_H, V0_J, V0_K,\n+    V1, V1_H, V1_J, V1_K,\n+    V2, V2_H, V2_J, V2_K,\n+    V3, V3_H, V3_J, V3_K,\n+    V4, V4_H, V4_J, V4_K,\n+    V5, V5_H, V5_J, V5_K,\n+    V6, V6_H, V6_J, V6_K,\n+    V7, V7_H, V7_J, V7_K,\n+    V8, V8_H, V8_J, V8_K,\n+    V9, V9_H, V9_J, V9_K,\n+    V10, V10_H, V10_J, V10_K,\n+    V11, V11_H, V11_J, V11_K,\n+    V12, V12_H, V12_J, V12_K,\n+    V13, V13_H, V13_J, V13_K,\n+    V14, V14_H, V14_J, V14_K,\n+    V15, V15_H, V15_J, V15_K,\n+    V16, V16_H, V16_J, V16_K,\n+    V17, V17_H, V17_J, V17_K,\n+    V18, V18_H, V18_J, V18_K,\n+    V19, V19_H, V19_J, V19_K,\n+    V20, V20_H, V20_J, V20_K,\n+    V21, V21_H, V21_J, V21_K,\n+    V22, V22_H, V22_J, V22_K,\n+    V23, V23_H, V23_J, V23_K,\n+    V24, V24_H, V24_J, V24_K,\n+    V25, V25_H, V25_J, V25_K,\n+    V26, V26_H, V26_J, V26_K,\n+    V27, V27_H, V27_J, V27_K,\n+    V28, V28_H, V28_J, V28_K,\n+    V29, V29_H, V29_J, V29_K,\n+    V30, V30_H, V30_J, V30_K,\n+    V31, V31_H, V31_J, V31_K,\n@@ -1317,3 +1188,0 @@\n-  \/\/ Assert that the given node is not a variable shift.\n-  bool assert_not_var_shift(const Node* n);\n-\n@@ -1734,6 +1602,0 @@\n-\/\/ Assert that the given node is not a variable shift.\n-bool assert_not_var_shift(const Node* n) {\n-  assert(!n->as_ShiftV()->is_var_shift(), \"illegal variable shift\");\n-  return true;\n-}\n-\n@@ -2418,12 +2280,0 @@\n-    case Op_LoadVectorMasked:\n-    case Op_StoreVectorMasked:\n-    case Op_LoadVectorGatherMasked:\n-    case Op_StoreVectorScatterMasked:\n-    case Op_MaskAll:\n-    case Op_AndVMask:\n-    case Op_OrVMask:\n-    case Op_XorVMask:\n-      if (UseSVE == 0) {\n-        ret_value = false;\n-      }\n-      break;\n@@ -2435,76 +2285,0 @@\n-const bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n-  if (UseSVE == 0) {\n-    \/\/ ConvD2I and ConvL2F are not profitable to be vectorized on NEON, because no direct\n-    \/\/ NEON instructions support them. But the match rule support for them is profitable for\n-    \/\/ Vector API intrinsics.\n-    if ((opcode == Op_VectorCastD2X && bt == T_INT) ||\n-        (opcode == Op_VectorCastL2X && bt == T_FLOAT)) {\n-      return false;\n-    }\n-  }\n-  return match_rule_supported_vector(opcode, vlen, bt);\n-}\n-\n-\/\/ Identify extra cases that we might want to provide match rules for vector nodes and\n-\/\/ other intrinsics guarded with vector length (vlen) and element type (bt).\n-const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {\n-  if (!match_rule_supported(opcode)) {\n-    return false;\n-  }\n-  int bit_size = vlen * type2aelembytes(bt) * 8;\n-  if (UseSVE == 0 && bit_size > 128) {\n-    return false;\n-  }\n-  if (UseSVE > 0) {\n-    return op_sve_supported(opcode, vlen, bt);\n-  } else { \/\/ NEON\n-    \/\/ Special cases\n-    switch (opcode) {\n-    case Op_VectorMaskCmp:\n-      if (vlen < 2 || bit_size < 64) {\n-        return false;\n-      }\n-      break;\n-    case Op_MulAddVS2VI:\n-      if (bit_size < 128) {\n-        return false;\n-      }\n-      break;\n-    case Op_MulVL:\n-    case Op_PopulateIndex:\n-      return false;\n-    case Op_VectorLoadShuffle:\n-    case Op_VectorRearrange:\n-      if (vlen < 4) {\n-        return false;\n-      }\n-      break;\n-    case Op_VectorMaskGen:\n-    case Op_LoadVectorGather:\n-    case Op_StoreVectorScatter:\n-    case Op_CompressV:\n-    case Op_CompressM:\n-    case Op_ExpandV:\n-    case Op_VectorLongToMask:\n-      return false;\n-    default:\n-      break;\n-    }\n-  }\n-  return vector_size_supported(bt, vlen);\n-}\n-\n-const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n-  \/\/ Only SVE supports masked operations.\n-  if (UseSVE == 0) {\n-    return false;\n-  }\n-  return match_rule_supported(opcode) &&\n-         masked_op_sve_supported(opcode, vlen, bt);\n-}\n-\n-const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n-  \/\/ Only SVE has partial vector operations\n-  return (UseSVE > 0) && partial_op_sve_needed(node, vt);\n-}\n-\n@@ -2577,1 +2351,1 @@\n-  if (UseSVE > 0 && 2 <= len && len <= 256) {\n+  if (UseSVE > 0 && 16 < len && len <= 256) {\n@@ -2591,2 +2365,8 @@\n-MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* original_opnd, uint ideal_reg, bool is_temp) {\n-  ShouldNotReachHere(); \/\/ generic vector operands not supported\n+MachOper* Matcher::pd_specialize_generic_vector_operand(MachOper* generic_opnd, uint ideal_reg, bool is_temp) {\n+  assert(Matcher::is_generic_vector(generic_opnd), \"not generic\");\n+  switch (ideal_reg) {\n+    case Op_VecA: return new vecAOper();\n+    case Op_VecD: return new vecDOper();\n+    case Op_VecX: return new vecXOper();\n+  }\n+  ShouldNotReachHere();\n@@ -2597,1 +2377,0 @@\n-  ShouldNotReachHere();  \/\/ generic vector operands not supported\n@@ -2602,2 +2381,1 @@\n-  ShouldNotReachHere();  \/\/ generic vector operands not supported\n-  return false;\n+  return opnd->opcode() == VREG;\n@@ -3191,1 +2969,1 @@\n-  enc_class aarch64_enc_ldrvH(vecD dst, memory mem) %{\n+  enc_class aarch64_enc_ldrvH(vReg dst, memory mem) %{\n@@ -3197,1 +2975,1 @@\n-  enc_class aarch64_enc_ldrvS(vecD dst, memory mem) %{\n+  enc_class aarch64_enc_ldrvS(vReg dst, memory mem) %{\n@@ -3203,1 +2981,1 @@\n-  enc_class aarch64_enc_ldrvD(vecD dst, memory mem) %{\n+  enc_class aarch64_enc_ldrvD(vReg dst, memory mem) %{\n@@ -3209,1 +2987,1 @@\n-  enc_class aarch64_enc_ldrvQ(vecX dst, memory mem) %{\n+  enc_class aarch64_enc_ldrvQ(vReg dst, memory mem) %{\n@@ -3215,1 +2993,1 @@\n-  enc_class aarch64_enc_strvH(vecD src, memory mem) %{\n+  enc_class aarch64_enc_strvH(vReg src, memory mem) %{\n@@ -3221,1 +2999,1 @@\n-  enc_class aarch64_enc_strvS(vecD src, memory mem) %{\n+  enc_class aarch64_enc_strvS(vReg src, memory mem) %{\n@@ -3227,1 +3005,1 @@\n-  enc_class aarch64_enc_strvD(vecD src, memory mem) %{\n+  enc_class aarch64_enc_strvD(vReg src, memory mem) %{\n@@ -3233,1 +3011,1 @@\n-  enc_class aarch64_enc_strvQ(vecX src, memory mem) %{\n+  enc_class aarch64_enc_strvQ(vReg src, memory mem) %{\n@@ -4347,40 +4125,0 @@\n-operand immI_31()\n-%{\n-  predicate(n->get_int() == 31);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_2()\n-%{\n-  predicate(n->get_int() == 2);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_4()\n-%{\n-  predicate(n->get_int() == 4);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n-operand immI_8()\n-%{\n-  predicate(n->get_int() == 8);\n-  match(ConI);\n-\n-  op_cost(0);\n-  format %{ %}\n-  interface(CONST_INTER);\n-%}\n-\n@@ -5435,2 +5173,1 @@\n-\/\/ all vector operands, including NEON and SVE,\n-\/\/ but currently only used for SVE VecA.\n+\/\/ all vector operands, including NEON and SVE.\n@@ -5438,0 +5175,12 @@\n+%{\n+  constraint(ALLOC_IN_RC(dynamic));\n+  match(VecA);\n+  match(VecD);\n+  match(VecX);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(REG_INTER);\n+%}\n+\n+operand vecA()\n@@ -5441,0 +5190,1 @@\n+\n@@ -6745,284 +6495,0 @@\n-pipe_class vmul64(vecD dst, vecD src1, vecD src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vmul128(vecX dst, vecX src1, vecX src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vmla64(vecD dst, vecD src1, vecD src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  dst    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vmla128(vecX dst, vecX src1, vecX src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  dst    : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vdop64(vecD dst, vecD src1, vecD src2)\n-%{\n-  single_instruction;\n-  dst    : S4(write);\n-  src1   : S2(read);\n-  src2   : S2(read);\n-  INS01  : ISS;\n-  NEON_FP : S4;\n-%}\n-\n-pipe_class vdop128(vecX dst, vecX src1, vecX src2)\n-%{\n-  single_instruction;\n-  dst    : S4(write);\n-  src1   : S2(read);\n-  src2   : S2(read);\n-  INS0   : ISS;\n-  NEON_FP : S4;\n-%}\n-\n-pipe_class vlogical64(vecD dst, vecD src1, vecD src2)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src1   : S2(read);\n-  src2   : S2(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vlogical128(vecX dst, vecX src1, vecX src2)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src1   : S2(read);\n-  src2   : S2(read);\n-  INS0   : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vshift64(vecD dst, vecD src, vecX shift)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  shift  : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vshift128(vecX dst, vecX src, vecX shift)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  shift  : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vshift64_imm(vecD dst, vecD src, immI shift)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vshift128_imm(vecX dst, vecX src, immI shift)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vdop_fp64(vecD dst, vecD src1, vecD src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vdop_fp128(vecX dst, vecX src1, vecX src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vmuldiv_fp64(vecD dst, vecD src1, vecD src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vmuldiv_fp128(vecX dst, vecX src1, vecX src2)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src1   : S1(read);\n-  src2   : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vsqrt_fp128(vecX dst, vecX src)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src    : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vunop_fp64(vecD dst, vecD src)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vunop_fp128(vecX dst, vecX src)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  src    : S1(read);\n-  INS0   : ISS;\n-  NEON_FP : S5;\n-%}\n-\n-pipe_class vdup_reg_reg64(vecD dst, iRegI src)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vdup_reg_reg128(vecX dst, iRegI src)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vdup_reg_freg64(vecD dst, vRegF src)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vdup_reg_freg128(vecX dst, vRegF src)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vdup_reg_dreg128(vecX dst, vRegD src)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  src    : S1(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vmovi_reg_imm64(vecD dst)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vmovi_reg_imm128(vecX dst)\n-%{\n-  single_instruction;\n-  dst    : S3(write);\n-  INS0   : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vload_reg_mem64(vecD dst, vmem8 mem)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  mem    : ISS(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vload_reg_mem128(vecX dst, vmem16 mem)\n-%{\n-  single_instruction;\n-  dst    : S5(write);\n-  mem    : ISS(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vstore_reg_mem64(vecD src, vmem8 mem)\n-%{\n-  single_instruction;\n-  mem    : ISS(read);\n-  src    : S2(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n-pipe_class vstore_reg_mem128(vecD src, vmem16 mem)\n-%{\n-  single_instruction;\n-  mem    : ISS(read);\n-  src    : S2(read);\n-  INS01  : ISS;\n-  NEON_FP : S3;\n-%}\n-\n@@ -9161,22 +8627,0 @@\n-instruct castVVD(vecD dst)\n-%{\n-  match(Set dst (CastVV dst));\n-\n-  size(0);\n-  format %{ \"# castVV of $dst\" %}\n-  ins_encode(\/* empty encoding *\/);\n-  ins_cost(0);\n-  ins_pipe(pipe_class_empty);\n-%}\n-\n-instruct castVVX(vecX dst)\n-%{\n-  match(Set dst (CastVV dst));\n-\n-  size(0);\n-  format %{ \"# castVV of $dst\" %}\n-  ins_encode(\/* empty encoding *\/);\n-  ins_cost(0);\n-  ins_pipe(pipe_class_empty);\n-%}\n-\n@@ -17029,0 +16473,2 @@\n+\/\/ Intrisics for String.compareTo()\n+\n@@ -17104,0 +16550,96 @@\n+\/\/ Note that Z registers alias the corresponding NEON registers, we declare the vector operands of\n+\/\/ these string_compare variants as NEON register type for convenience so that the prototype of\n+\/\/ string_compare can be shared with all variants.\n+\n+instruct string_compareLL_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,\n+                              iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,\n+                              vRegD_V0 vtmp1, vRegD_V1 vtmp2, pRegGov_P0 pgtmp1,\n+                              pRegGov_P1 pgtmp2, rFlagsReg cr)\n+%{\n+  predicate((UseSVE > 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::LL));\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP vtmp1, TEMP vtmp2, TEMP pgtmp1, TEMP pgtmp2,\n+         USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare $str1,$cnt1,$str2,$cnt2 -> $result   # USE sve\" %}\n+  ins_encode %{\n+    \/\/ Count is in 8-bit bytes; non-Compact chars are 16 bits.\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$Register, $tmp2$$Register,\n+                      $vtmp1$$FloatRegister, $vtmp2$$FloatRegister, fnoreg,\n+                      as_PRegister($pgtmp1$$reg), as_PRegister($pgtmp2$$reg),\n+                      StrIntrinsicNode::LL);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n+instruct string_compareLU_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,\n+                              iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,\n+                              vRegD_V0 vtmp1, vRegD_V1 vtmp2, pRegGov_P0 pgtmp1,\n+                              pRegGov_P1 pgtmp2, rFlagsReg cr)\n+%{\n+  predicate((UseSVE > 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::LU));\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP vtmp1, TEMP vtmp2, TEMP pgtmp1, TEMP pgtmp2,\n+         USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare $str1,$cnt1,$str2,$cnt2 -> $result   # USE sve\" %}\n+  ins_encode %{\n+    \/\/ Count is in 8-bit bytes; non-Compact chars are 16 bits.\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$Register, $tmp2$$Register,\n+                      $vtmp1$$FloatRegister, $vtmp2$$FloatRegister, fnoreg,\n+                      as_PRegister($pgtmp1$$reg), as_PRegister($pgtmp2$$reg),\n+                      StrIntrinsicNode::LU);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n+instruct string_compareUL_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,\n+                              iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,\n+                              vRegD_V0 vtmp1, vRegD_V1 vtmp2, pRegGov_P0 pgtmp1,\n+                              pRegGov_P1 pgtmp2, rFlagsReg cr)\n+%{\n+  predicate((UseSVE > 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::UL));\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP vtmp1, TEMP vtmp2, TEMP pgtmp1, TEMP pgtmp2,\n+         USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare $str1,$cnt1,$str2,$cnt2 -> $result   # USE sve\" %}\n+  ins_encode %{\n+    \/\/ Count is in 8-bit bytes; non-Compact chars are 16 bits.\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$Register, $tmp2$$Register,\n+                      $vtmp1$$FloatRegister, $vtmp2$$FloatRegister, fnoreg,\n+                      as_PRegister($pgtmp1$$reg), as_PRegister($pgtmp2$$reg),\n+                      StrIntrinsicNode::UL);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n+instruct string_compareUU_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegP_R3 str2, iRegI_R4 cnt2,\n+                              iRegI_R0 result, iRegP_R10 tmp1, iRegL_R11 tmp2,\n+                              vRegD_V0 vtmp1, vRegD_V1 vtmp2, pRegGov_P0 pgtmp1,\n+                              pRegGov_P1 pgtmp2, rFlagsReg cr)\n+%{\n+  predicate((UseSVE > 0) && (((StrCompNode*)n)->encoding() == StrIntrinsicNode::UU));\n+  match(Set result (StrComp (Binary str1 cnt1) (Binary str2 cnt2)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP vtmp1, TEMP vtmp2, TEMP pgtmp1, TEMP pgtmp2,\n+         USE_KILL str1, USE_KILL str2, USE_KILL cnt1, USE_KILL cnt2, KILL cr);\n+\n+  format %{ \"String Compare $str1,$cnt1,$str2,$cnt2 -> $result   # USE sve\" %}\n+  ins_encode %{\n+    \/\/ Count is in 8-bit bytes; non-Compact chars are 16 bits.\n+    __ string_compare($str1$$Register, $str2$$Register,\n+                      $cnt1$$Register, $cnt2$$Register, $result$$Register,\n+                      $tmp1$$Register, $tmp2$$Register,\n+                      $vtmp1$$FloatRegister, $vtmp2$$FloatRegister, fnoreg,\n+                      as_PRegister($pgtmp1$$reg), as_PRegister($pgtmp2$$reg),\n+                      StrIntrinsicNode::UU);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n@@ -17268,0 +16810,32 @@\n+instruct stringL_indexof_char_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+                                  iRegI_R0 result, vecA ztmp1, vecA ztmp2,\n+                                  pRegGov pgtmp, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && ((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::L);\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  effect(TEMP ztmp1, TEMP ztmp2, TEMP pgtmp, TEMP ptmp, KILL cr);\n+  format %{ \"StringLatin1 IndexOf char[] $str1,$cnt1,$ch -> $result # use sve\" %}\n+  ins_encode %{\n+    __ string_indexof_char_sve($str1$$Register, $cnt1$$Register, $ch$$Register,\n+                               $result$$Register, $ztmp1$$FloatRegister,\n+                               $ztmp2$$FloatRegister, $pgtmp$$PRegister,\n+                               $ptmp$$PRegister, true \/* isL *\/);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n+instruct stringU_indexof_char_sve(iRegP_R1 str1, iRegI_R2 cnt1, iRegI_R3 ch,\n+                                  iRegI_R0 result, vecA ztmp1, vecA ztmp2,\n+                                  pRegGov pgtmp, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && ((StrIndexOfCharNode*)n)->encoding() == StrIntrinsicNode::U);\n+  match(Set result (StrIndexOfChar (Binary str1 cnt1) ch));\n+  effect(TEMP ztmp1, TEMP ztmp2, TEMP pgtmp, TEMP ptmp, KILL cr);\n+  format %{ \"StringUTF16 IndexOf char[] $str1,$cnt1,$ch -> $result # use sve\" %}\n+  ins_encode %{\n+    __ string_indexof_char_sve($str1$$Register, $cnt1$$Register, $ch$$Register,\n+                               $result$$Register, $ztmp1$$FloatRegister,\n+                               $ztmp2$$FloatRegister, $pgtmp$$PRegister,\n+                               $ptmp$$PRegister, false \/* isL *\/);\n+  %}\n+  ins_pipe(pipe_class_memory);\n+%}\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":226,"deletions":652,"binary":false,"changes":878,"status":"modified"},{"patch":"@@ -0,0 +1,6353 @@\n+\/\/\n+\/\/ Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2022, Arm Limited. All rights reserved.\n+\/\/ DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+\/\/\n+\/\/ This code is free software; you can redistribute it and\/or modify it\n+\/\/ under the terms of the GNU General Public License version 2 only, as\n+\/\/ published by the Free Software Foundation.\n+\/\/\n+\/\/ This code is distributed in the hope that it will be useful, but WITHOUT\n+\/\/ ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+\/\/ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+\/\/ version 2 for more details (a copy is included in the LICENSE file that\n+\/\/ accompanied this code).\n+\/\/\n+\/\/ You should have received a copy of the GNU General Public License version\n+\/\/ 2 along with this work; if not, write to the Free Software Foundation,\n+\/\/ Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+\/\/\n+\/\/ Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+\/\/ or visit www.oracle.com if you need additional information or have any\n+\/\/ questions.\n+\/\/\n+\/\/\n+\n+\/\/ This file is automatically generated by running \"m4 aarch64_vector_ad.m4\". Do not edit!\n+\n+\/\/ AArch64 VECTOR Architecture Description File\n+\n+\n+\/\/ 4 bit signed offset -- for predicated load\/store\n+\n+operand vmemA_immIOffset4() %{\n+  \/\/ (esize \/ msize) = 1\n+  predicate(Address::offset_ok_for_sve_immed(n->get_int(), 4,\n+            Matcher::scalable_vector_reg_size(T_BYTE)));\n+  match(ConI);\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n+operand vmemA_immLOffset4() %{\n+  \/\/ (esize \/ msize) = 1\n+  predicate(Address::offset_ok_for_sve_immed(n->get_long(), 4,\n+            Matcher::scalable_vector_reg_size(T_BYTE)));\n+  match(ConL);\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n+operand vmemA_indOffI4(iRegP reg, vmemA_immIOffset4 off) %{\n+  constraint(ALLOC_IN_RC(ptr_reg));\n+  match(AddP reg off);\n+  op_cost(0);\n+  format %{ \"[$reg, $off]\" %}\n+  interface(MEMORY_INTER) %{\n+    base($reg);\n+    index(0xffffffff);\n+    scale(0x0);\n+    disp($off);\n+  %}\n+%}\n+\n+operand vmemA_indOffL4(iRegP reg, vmemA_immLOffset4 off) %{\n+  constraint(ALLOC_IN_RC(ptr_reg));\n+  match(AddP reg off);\n+  op_cost(0);\n+  format %{ \"[$reg, $off]\" %}\n+  interface(MEMORY_INTER) %{\n+    base($reg);\n+    index(0xffffffff);\n+    scale(0x0);\n+    disp($off);\n+  %}\n+%}\n+\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n+opclass vmemA(indirect, vmemA_indOffI4, vmemA_indOffL4);\n+\n+source_hpp %{\n+  \/\/ Assert that the given node is not a variable shift.\n+  bool assert_not_var_shift(const Node* n);\n+\n+  Assembler::SIMD_Arrangement get_arrangement(const Node* n);\n+%}\n+\n+source %{\n+\n+  typedef void (C2_MacroAssembler::* sve_mem_insn_predicate)(FloatRegister Rt, Assembler::SIMD_RegVariant T,\n+                                                             PRegister Pg, const Address &adr);\n+\n+  \/\/ Predicated load\/store, with optional ptrue to all elements of given predicate register.\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n+    sve_mem_insn_predicate insn;\n+    int mesize = type2aelembytes(mem_elem_bt);\n+    if (index == -1) {\n+      assert(size == 0, \"unsupported address mode: scale size = %d\", size);\n+      switch(mesize) {\n+      case 1:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1b : &C2_MacroAssembler::sve_ld1b;\n+        break;\n+      case 2:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1h : &C2_MacroAssembler::sve_ld1h;\n+        break;\n+      case 4:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1w : &C2_MacroAssembler::sve_ld1w;\n+        break;\n+      case 8:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1d : &C2_MacroAssembler::sve_ld1d;\n+        break;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+      }\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, Assembler::elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n+    } else {\n+      assert(false, \"unimplemented\");\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  const bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+    if (UseSVE == 0) {\n+      \/\/ ConvD2I and ConvL2F are not profitable to be vectorized on NEON, because no direct\n+      \/\/ NEON instructions support them. But the match rule support for them is profitable for\n+      \/\/ Vector API intrinsics.\n+      if ((opcode == Op_VectorCastD2X && bt == T_INT) ||\n+          (opcode == Op_VectorCastL2X && bt == T_FLOAT)) {\n+        return false;\n+      }\n+    }\n+    return match_rule_supported_vector(opcode, vlen, bt);\n+  }\n+\n+  \/\/ Identify extra cases that we might want to provide match rules for vector nodes and\n+  \/\/ other intrinsics guarded with vector length (vlen) and element type (bt).\n+  const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {\n+    if (!match_rule_supported(opcode)) {\n+      return false;\n+    }\n+\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n+    if (UseSVE == 0 && length_in_bytes > 16) {\n+      return false;\n+    }\n+\n+    switch (opcode) {\n+      case Op_MulVL:\n+      case Op_AndVMask:\n+      case Op_OrVMask:\n+      case Op_XorVMask:\n+      case Op_MaskAll:\n+      case Op_VectorMaskGen:\n+      case Op_LoadVectorMasked:\n+      case Op_StoreVectorMasked:\n+      case Op_LoadVectorGather:\n+      case Op_StoreVectorScatter:\n+      case Op_LoadVectorGatherMasked:\n+      case Op_StoreVectorScatterMasked:\n+      case Op_PopulateIndex:\n+      case Op_CompressM:\n+      case Op_CompressV:\n+        if (UseSVE == 0) {\n+          return false;\n+        }\n+        break;\n+      case Op_MulAddVS2VI:\n+        return length_in_bytes == 16;\n+      case Op_MulReductionVD:\n+      case Op_MulReductionVF:\n+      case Op_MulReductionVI:\n+      case Op_MulReductionVL:\n+        \/\/ No multiply reduction instructions, and we emit scalar\n+        \/\/ instructions for 64\/128-bit vectors.\n+        return vlen >= 2 && (length_in_bytes == 8 || length_in_bytes == 16);\n+      case Op_VectorMaskCmp:\n+        if (length_in_bytes < 8) {\n+          return false;\n+        }\n+        break;\n+      case Op_VectorLoadShuffle:\n+      case Op_VectorRearrange:\n+        if (vlen < 4) {\n+          return false;\n+        }\n+        break;\n+      case Op_ExpandV:\n+        if (UseSVE < 2 || is_subword_type(bt)) {\n+          return false;\n+        }\n+        break;\n+      case Op_VectorMaskToLong:\n+        if (UseSVE > 0 && vlen > 64) {\n+          return false;\n+        }\n+        break;\n+      case Op_VectorLongToMask:\n+        if (UseSVE < 2 || vlen > 64 || !VM_Version::supports_svebitperm()) {\n+          return false;\n+        }\n+        break;\n+      default:\n+        break;\n+    }\n+    return vector_size_supported(bt, vlen);\n+  }\n+\n+  const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+    \/\/ Only SVE supports masked operations.\n+    if (UseSVE == 0) {\n+      return false;\n+    }\n+\n+    \/\/ If an opcode does not support the masked version,\n+    \/\/ unpredicated node with VectorBlend node will be used instead.\n+    switch(opcode) {\n+      case Op_VectorRearrange:\n+      case Op_MulReductionVD:\n+      case Op_MulReductionVF:\n+      case Op_MulReductionVI:\n+      case Op_MulReductionVL:\n+        return false;\n+      \/\/ We use Op_LoadVectorMasked to implement the predicated Op_LoadVector.\n+      \/\/ Hence we turn to check whether Op_LoadVectorMasked is supported. The\n+      \/\/ same as vector store\/gather\/scatter.\n+      case Op_LoadVector:\n+        opcode = Op_LoadVectorMasked;\n+        break;\n+      case Op_StoreVector:\n+        opcode = Op_StoreVectorMasked;\n+        break;\n+      case Op_LoadVectorGather:\n+        opcode = Op_LoadVectorGatherMasked;\n+        break;\n+      case Op_StoreVectorScatter:\n+        opcode = Op_StoreVectorScatterMasked;\n+        break;\n+      default:\n+        break;\n+    }\n+\n+    return match_rule_supported_vector(opcode, vlen, bt);\n+  }\n+\n+  const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+    \/\/ Only SVE has partial vector operations\n+    if (UseSVE == 0) {\n+      return false;\n+    }\n+\n+    switch(node->Opcode()) {\n+      case Op_VectorLoadMask:\n+      case Op_VectorMaskCmp:\n+      case Op_LoadVectorGather:\n+      case Op_StoreVectorScatter:\n+      case Op_AddReductionVF:\n+      case Op_AddReductionVD:\n+      case Op_AndReductionV:\n+      case Op_OrReductionV:\n+      case Op_XorReductionV:\n+      \/\/ Mask is needed for partial Op_VectorMaskFirstTrue, because when the\n+      \/\/ input predicate is all-false, the result should be the vector length\n+      \/\/ instead of the vector register size.\n+      case Op_VectorMaskFirstTrue:\n+        return true;\n+      case Op_MaskAll:\n+        return !node->in(1)->is_Con();\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        \/\/ We use NEON load\/store instructions if the vector length is <= 128 bits.\n+        return vt->length_in_bytes() > 16;\n+      case Op_AddReductionVI:\n+      case Op_AddReductionVL:\n+        \/\/ We may prefer using NEON instructions rather than SVE partial operations.\n+        return !VM_Version::use_neon_for_vector(vt->length_in_bytes());\n+      case Op_MinReductionV:\n+      case Op_MaxReductionV:\n+        \/\/ For BYTE\/SHORT\/INT\/FLOAT\/DOUBLE types, we may prefer using NEON\n+        \/\/ instructions rather than SVE partial operations.\n+        return vt->element_basic_type() == T_LONG ||\n+               !VM_Version::use_neon_for_vector(vt->length_in_bytes());\n+      default:\n+        \/\/ For other ops whose vector size is smaller than the max vector size, a\n+        \/\/ full-sized unpredicated operation does not impact the final vector result.\n+        return false;\n+    }\n+  }\n+\n+  \/\/ Assert that the given node is not a variable shift.\n+  bool assert_not_var_shift(const Node* n) {\n+    assert(!n->as_ShiftV()->is_var_shift(), \"illegal variable shift\");\n+    return true;\n+  }\n+\n+  Assembler::SIMD_Arrangement get_arrangement(const Node* n) {\n+    BasicType bt = Matcher::vector_element_basic_type(n);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(n);\n+    return Assembler::esize2arrangement((uint)type2aelembytes(bt),\n+                                        \/* isQ *\/ length_in_bytes == 16);\n+  }\n+%}\n+\n+\n+\/\/ All VECTOR instructions\n+\n+\/\/ ------------------------------ Vector load\/store ----------------------------\n+\n+\/\/ Load Vector (16 bits)\n+instruct loadV2(vReg dst, vmem2 mem) %{\n+  predicate(n->as_LoadVector()->memory_size() == 2);\n+  match(Set dst (LoadVector mem));\n+  format %{ \"loadV2 $dst, $mem\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvH(dst, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Store Vector (16 bits)\n+instruct storeV2(vReg src, vmem2 mem) %{\n+  predicate(n->as_StoreVector()->memory_size() == 2);\n+  match(Set mem (StoreVector mem src));\n+  format %{ \"storeV2 $mem, $src\\t# vector (16 bits)\" %}\n+  ins_encode( aarch64_enc_strvH(src, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (32 bits)\n+instruct loadV4(vReg dst, vmem4 mem) %{\n+  predicate(n->as_LoadVector()->memory_size() == 4);\n+  match(Set dst (LoadVector mem));\n+  format %{ \"loadV4 $dst, $mem\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvS(dst, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Store Vector (32 bits)\n+instruct storeV4(vReg src, vmem4 mem) %{\n+  predicate(n->as_StoreVector()->memory_size() == 4);\n+  match(Set mem (StoreVector mem src));\n+  format %{ \"storeV4 $mem, $src\\t# vector (32 bits)\" %}\n+  ins_encode( aarch64_enc_strvS(src, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (64 bits)\n+instruct loadV8(vReg dst, vmem8 mem) %{\n+  predicate(n->as_LoadVector()->memory_size() == 8);\n+  match(Set dst (LoadVector mem));\n+  format %{ \"loadV8 $dst, $mem\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvD(dst, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Store Vector (64 bits)\n+instruct storeV8(vReg src, vmem8 mem) %{\n+  predicate(n->as_StoreVector()->memory_size() == 8);\n+  match(Set mem (StoreVector mem src));\n+  format %{ \"storeV8 $mem, $src\\t# vector (64 bits)\" %}\n+  ins_encode( aarch64_enc_strvD(src, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (128 bits)\n+instruct loadV16(vReg dst, vmem16 mem) %{\n+  predicate(n->as_LoadVector()->memory_size() == 16);\n+  match(Set dst (LoadVector mem));\n+  format %{ \"loadV16 $dst, $mem\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_ldrvQ(dst, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Store Vector (128 bits)\n+instruct storeV16(vReg src, vmem16 mem) %{\n+  predicate(n->as_StoreVector()->memory_size() == 16);\n+  match(Set mem (StoreVector mem src));\n+  format %{ \"storeV16 $mem, $src\\t# vector (128 bits)\" %}\n+  ins_encode( aarch64_enc_strvQ(src, mem) );\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Load Vector (> 128 bits)\n+instruct loadV(vReg dst, vmemA mem) %{\n+  predicate(n->as_LoadVector()->memory_size() > 16);\n+  match(Set dst (LoadVector mem));\n+  format %{ \"loadV $dst, $mem\\t# vector (sve)\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ false,\n+                          $dst$$FloatRegister, ptrue, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Store Vector (> 128 bits)\n+instruct storeV(vReg src, vmemA mem) %{\n+  predicate(n->as_StoreVector()->memory_size() > 16);\n+  match(Set mem (StoreVector mem src));\n+  format %{ \"storeV $mem, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ true,\n+                          $src$$FloatRegister, ptrue, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load\/store - predicated\n+\n+instruct loadV_masked(vReg dst, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LoadVectorMasked mem pg));\n+  format %{ \"loadV_masked $dst, $pg, $mem\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ false, $dst$$FloatRegister,\n+                          $pg$$PRegister, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked(vReg src, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set mem (StoreVectorMasked mem (Binary src pg)));\n+  format %{ \"storeV_masked $mem, $pg, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ true, $src$$FloatRegister,\n+                          $pg$$PRegister, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load const\n+\n+instruct vloadconB(vReg dst, immI0 src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE);\n+  match(Set dst (VectorLoadConst src));\n+  format %{ \"vloadconB $dst, $src\\t# load\/generate iota indices\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      assert(length_in_bytes <= 16, \"must be\");\n+      __ lea(rscratch1, ExternalAddress(StubRoutines::aarch64::vector_iota_indices()));\n+      if (length_in_bytes == 16) {\n+        __ ldrq($dst$$FloatRegister, rscratch1);\n+      } else {\n+        __ ldrd($dst$$FloatRegister, rscratch1);\n+      }\n+    } else {\n+      __ sve_index($dst$$FloatRegister, __ B, 0, 1);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector add -----------------------------------\n+\n+\/\/ vector add\n+\n+instruct vaddB(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AddVB src1 src2));\n+  format %{ \"vaddB $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ addv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_add($dst$$FloatRegister, __ B, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddS(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AddVS src1 src2));\n+  format %{ \"vaddS $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ addv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_add($dst$$FloatRegister, __ H, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddI(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AddVI src1 src2));\n+  format %{ \"vaddI $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ addv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_add($dst$$FloatRegister, __ S, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddL(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AddVL src1 src2));\n+  format %{ \"vaddL $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ addv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_add($dst$$FloatRegister, __ D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddF(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AddVF src1 src2));\n+  format %{ \"vaddF $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fadd($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fadd($dst$$FloatRegister, __ S, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddD(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AddVD src1 src2));\n+  format %{ \"vaddD $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fadd($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fadd($dst$$FloatRegister, __ D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector add - predicated\n+\n+instruct vaddB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVB (Binary dst_src1 src2) pg));\n+  format %{ \"vaddB_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_add($dst_src1$$FloatRegister, __ B, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVS (Binary dst_src1 src2) pg));\n+  format %{ \"vaddS_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_add($dst_src1$$FloatRegister, __ H, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVI (Binary dst_src1 src2) pg));\n+  format %{ \"vaddI_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_add($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVL (Binary dst_src1 src2) pg));\n+  format %{ \"vaddL_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_add($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVF (Binary dst_src1 src2) pg));\n+  format %{ \"vaddF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fadd($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVD (Binary dst_src1 src2) pg));\n+  format %{ \"vaddD_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fadd($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector add reg imm (unpredicated)\n+\n+instruct vaddImmB(vReg dst_src, immBAddSubV con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AddVB dst_src (ReplicateB con)));\n+  format %{ \"vaddImmB $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    int val = (int)$con$$constant;\n+    if (val > 0) {\n+      __ sve_add($dst_src$$FloatRegister, __ B, val);\n+    } else {\n+      __ sve_sub($dst_src$$FloatRegister, __ B, -val);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddImmS(vReg dst_src, immIAddSubV con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AddVS dst_src (ReplicateS con)));\n+  format %{ \"vaddImmS $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    int val = (int)$con$$constant;\n+    if (val > 0) {\n+      __ sve_add($dst_src$$FloatRegister, __ H, val);\n+    } else {\n+      __ sve_sub($dst_src$$FloatRegister, __ H, -val);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddImmI(vReg dst_src, immIAddSubV con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AddVI dst_src (ReplicateI con)));\n+  format %{ \"vaddImmI $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    int val = (int)$con$$constant;\n+    if (val > 0) {\n+      __ sve_add($dst_src$$FloatRegister, __ S, val);\n+    } else {\n+      __ sve_sub($dst_src$$FloatRegister, __ S, -val);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vaddImmL(vReg dst_src, immLAddSubV con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AddVL dst_src (ReplicateL con)));\n+  format %{ \"vaddImmL $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    int val = (int)$con$$constant;\n+    if (val > 0) {\n+      __ sve_add($dst_src$$FloatRegister, __ D, val);\n+    } else {\n+      __ sve_sub($dst_src$$FloatRegister, __ D, -val);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector sub -----------------------------------\n+\n+\/\/ vector sub\n+\n+instruct vsubB(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (SubVB src1 src2));\n+  format %{ \"vsubB $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ subv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_sub($dst$$FloatRegister, __ B, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (SubVS src1 src2));\n+  format %{ \"vsubS $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ subv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_sub($dst$$FloatRegister, __ H, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (SubVI src1 src2));\n+  format %{ \"vsubI $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ subv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_sub($dst$$FloatRegister, __ S, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (SubVL src1 src2));\n+  format %{ \"vsubL $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ subv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_sub($dst$$FloatRegister, __ D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (SubVF src1 src2));\n+  format %{ \"vsubF $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fsub($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fsub($dst$$FloatRegister, __ S, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (SubVD src1 src2));\n+  format %{ \"vsubD $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fsub($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fsub($dst$$FloatRegister, __ D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sub - predicated\n+\n+instruct vsubB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVB (Binary dst_src1 src2) pg));\n+  format %{ \"vsubB_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_sub($dst_src1$$FloatRegister, __ B, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVS (Binary dst_src1 src2) pg));\n+  format %{ \"vsubS_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_sub($dst_src1$$FloatRegister, __ H, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVI (Binary dst_src1 src2) pg));\n+  format %{ \"vsubI_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_sub($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVL (Binary dst_src1 src2) pg));\n+  format %{ \"vsubL_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_sub($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVF (Binary dst_src1 src2) pg));\n+  format %{ \"vsubF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fsub($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsubD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVD (Binary dst_src1 src2) pg));\n+  format %{ \"vsubD_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fsub($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mul -----------------------------------\n+\n+\/\/ vector mul - BYTE, CHAR, SHORT, INT\n+\n+instruct vmulB_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (MulVB src1 src2));\n+  format %{ \"vmulB_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ mulv($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulB_sve(vReg dst_src1, vReg src2) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (MulVB dst_src1 src2));\n+  format %{ \"vmulB_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_mul($dst_src1$$FloatRegister, __ B, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulS_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (MulVS src1 src2));\n+  format %{ \"vmulS_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ mulv($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulS_sve(vReg dst_src1, vReg src2) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (MulVS dst_src1 src2));\n+  format %{ \"vmulS_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_mul($dst_src1$$FloatRegister, __ H, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulI_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (MulVI src1 src2));\n+  format %{ \"vmulI_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ mulv($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulI_sve(vReg dst_src1, vReg src2) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (MulVI dst_src1 src2));\n+  format %{ \"vmulI_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_mul($dst_src1$$FloatRegister, __ S, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mul - LONG\n+\n+instruct vmulL_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (MulVL src1 src2));\n+  format %{ \"vmulL_neon $dst, $src1, $src2\\t# 2L\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == 16, \"must be\");\n+    __ umov(rscratch1, $src1$$FloatRegister, __ D, 0);\n+    __ umov(rscratch2, $src2$$FloatRegister, __ D, 0);\n+    __ mul(rscratch2, rscratch2, rscratch1);\n+    __ mov($dst$$FloatRegister, __ D, 0, rscratch2);\n+    __ umov(rscratch1, $src1$$FloatRegister, __ D, 1);\n+    __ umov(rscratch2, $src2$$FloatRegister, __ D, 1);\n+    __ mul(rscratch2, rscratch2, rscratch1);\n+    __ mov($dst$$FloatRegister, __ D, 1, rscratch2);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulL_sve(vReg dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVL dst_src1 src2));\n+  format %{ \"vmulL_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_mul($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mul - floating-point\n+\n+instruct vmulF(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (MulVF src1 src2));\n+  format %{ \"vmulF $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmul($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fmul($dst$$FloatRegister, __ S, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulD(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (MulVD src1 src2));\n+  format %{ \"vmulD $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmul($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fmul($dst$$FloatRegister, __ D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mul - predicated\n+\n+instruct vmulB_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVB (Binary dst_src1 src2) pg));\n+  format %{ \"vmulB_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_mul($dst_src1$$FloatRegister, __ B, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulS_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVS (Binary dst_src1 src2) pg));\n+  format %{ \"vmulS_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_mul($dst_src1$$FloatRegister, __ H, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulI_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVI (Binary dst_src1 src2) pg));\n+  format %{ \"vmulI_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_mul($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulL_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVL (Binary dst_src1 src2) pg));\n+  format %{ \"vmulL_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_mul($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVF (Binary dst_src1 src2) pg));\n+  format %{ \"vmulF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fmul($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVD (Binary dst_src1 src2) pg));\n+  format %{ \"vmulD_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fmul($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector float div -----------------------------\n+\n+\/\/ vector float div\n+\n+instruct vdivF_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (DivVF src1 src2));\n+  format %{ \"vdivF_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ fdiv($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vdivF_sve(vReg dst_src1, vReg src2) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (DivVF dst_src1 src2));\n+  format %{ \"vdivF_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_fdiv($dst_src1$$FloatRegister, __ S, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vdivD_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (DivVD src1 src2));\n+  format %{ \"vdivD_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ fdiv($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vdivD_sve(vReg dst_src1, vReg src2) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (DivVD dst_src1 src2));\n+  format %{ \"vdivD_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_fdiv($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector float div - predicated\n+\n+instruct vdivF_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (DivVF (Binary dst_src1 src2) pg));\n+  format %{ \"vdivF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fdiv($dst_src1$$FloatRegister, __ S, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vdivD_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (DivVD (Binary dst_src1 src2) pg));\n+  format %{ \"vdivD_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fdiv($dst_src1$$FloatRegister, __ D, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector and -----------------------------------\n+\n+\/\/ vector and\n+\n+instruct vand(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (AndV src1 src2));\n+  format %{ \"vand $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ andr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_and($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector and - predicated\n+\n+instruct vand_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AndV (Binary dst_src1 src2) pg));\n+  format %{ \"vand_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_and($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector and reg imm (unpredicated)\n+\n+instruct vandImmB(vReg dst_src, immBLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AndV dst_src (ReplicateB con)));\n+  format %{ \"vandImmB $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_and($dst_src$$FloatRegister, __ B, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vandImmS(vReg dst_src, immSLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AndV dst_src (ReplicateS con)));\n+  format %{ \"vandImmS $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_and($dst_src$$FloatRegister, __ H, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vandImmI(vReg dst_src, immILog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AndV dst_src (ReplicateI con)));\n+  format %{ \"vandImmI $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_and($dst_src$$FloatRegister, __ S, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vandImmL(vReg dst_src, immLLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AndV dst_src (ReplicateL con)));\n+  format %{ \"vandImmL $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_and($dst_src$$FloatRegister, __ D, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector or ------------------------------------\n+\n+\/\/ vector or\n+\n+instruct vor(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (OrV src1 src2));\n+  format %{ \"vor $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_orr($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector or - predicated\n+\n+instruct vor_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (OrV (Binary dst_src1 src2) pg));\n+  format %{ \"vor_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_orr($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector or reg imm (unpredicated)\n+\n+instruct vorImmB(vReg dst_src, immBLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (OrV dst_src (ReplicateB con)));\n+  format %{ \"vorImmB $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_orr($dst_src$$FloatRegister, __ B, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vorImmS(vReg dst_src, immSLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (OrV dst_src (ReplicateS con)));\n+  format %{ \"vorImmS $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_orr($dst_src$$FloatRegister, __ H, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vorImmI(vReg dst_src, immILog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (OrV dst_src (ReplicateI con)));\n+  format %{ \"vorImmI $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_orr($dst_src$$FloatRegister, __ S, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vorImmL(vReg dst_src, immLLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (OrV dst_src (ReplicateL con)));\n+  format %{ \"vorImmL $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_orr($dst_src$$FloatRegister, __ D, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector xor -----------------------------------\n+\n+\/\/ vector xor\n+\n+instruct vxor(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst (XorV src1 src2));\n+  format %{ \"vxor $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ eor($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_eor($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector xor - predicated\n+\n+instruct vxor_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (XorV (Binary dst_src1 src2) pg));\n+  format %{ \"vxor_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_eor($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector xor reg imm (unpredicated)\n+\n+instruct vxorImmB(vReg dst_src, immBLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (XorV dst_src (ReplicateB con)));\n+  format %{ \"vxorImmB $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_eor($dst_src$$FloatRegister, __ B, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vxorImmS(vReg dst_src, immSLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (XorV dst_src (ReplicateS con)));\n+  format %{ \"vxorImmS $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_eor($dst_src$$FloatRegister, __ H, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vxorImmI(vReg dst_src, immILog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (XorV dst_src (ReplicateI con)));\n+  format %{ \"vxorImmI $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_eor($dst_src$$FloatRegister, __ S, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vxorImmL(vReg dst_src, immLLog con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (XorV dst_src (ReplicateL con)));\n+  format %{ \"vxorImmL $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ sve_eor($dst_src$$FloatRegister, __ D, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector not -----------------------------------\n+\n+\/\/ vector not\n+\n+instruct vnotI(vReg dst, vReg src, immI_M1 m1) %{\n+  match(Set dst (XorV src (ReplicateB m1)));\n+  match(Set dst (XorV src (ReplicateS m1)));\n+  match(Set dst (XorV src (ReplicateI m1)));\n+  format %{ \"vnotI $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ notr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_not($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnotL(vReg dst, vReg src, immL_M1 m1) %{\n+  match(Set dst (XorV src (ReplicateL m1)));\n+  format %{ \"vnotL $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ notr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_not($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector not - predicated\n+\n+instruct vnotI_masked(vReg dst_src, immI_M1 m1, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (XorV (Binary dst_src (ReplicateB m1)) pg));\n+  match(Set dst_src (XorV (Binary dst_src (ReplicateS m1)) pg));\n+  match(Set dst_src (XorV (Binary dst_src (ReplicateI m1)) pg));\n+  format %{ \"vnotI_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_not($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnotL_masked(vReg dst_src, immL_M1 m1, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (XorV (Binary dst_src (ReplicateL m1)) pg));\n+  format %{ \"vnotL_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_not($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector and_not -------------------------------\n+\n+\/\/ vector and_not\n+\n+instruct vand_notI(vReg dst, vReg src1, vReg src2, immI_M1 m1) %{\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateB m1))));\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateS m1))));\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateI m1))));\n+  format %{ \"vand_notI $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ bic($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_bic($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vand_notL(vReg dst, vReg src1, vReg src2, immL_M1 m1) %{\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateL m1))));\n+  format %{ \"vand_notL $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ bic($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_bic($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector and_not - predicated\n+\n+instruct vand_notI_masked(vReg dst_src1, vReg src2, immI_M1 m1, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateB m1))) pg));\n+  match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateS m1))) pg));\n+  match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateI m1))) pg));\n+  format %{ \"vand_notI_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_bic($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vand_notL_masked(vReg dst_src1, vReg src2, immL_M1 m1, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateL m1))) pg));\n+  format %{ \"vand_notL_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_bic($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector abs -----------------------------------\n+\n+\/\/ vector abs\n+\n+instruct vabsB(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (AbsVB src));\n+  format %{ \"vabsB $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ absr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_abs($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsS(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (AbsVS src));\n+  format %{ \"vabsS $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ absr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_abs($dst$$FloatRegister, __ H, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsI(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (AbsVI src));\n+  format %{ \"vabsI $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ absr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_abs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsL(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (AbsVL src));\n+  format %{ \"vabsL $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ absr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_abs($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsF(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (AbsVF src));\n+  format %{ \"vabsF $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fabs($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fabs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsD(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (AbsVD src));\n+  format %{ \"vabsD $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fabs($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fabs($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector abs - predicated\n+\n+instruct vabsB_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVB dst_src pg));\n+  format %{ \"vabsB_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_abs($dst_src$$FloatRegister, __ B, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsS_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVS dst_src pg));\n+  format %{ \"vabsS_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_abs($dst_src$$FloatRegister, __ H, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsI_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVI dst_src pg));\n+  format %{ \"vabsI_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_abs($dst_src$$FloatRegister, __ S, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsL_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVL dst_src pg));\n+  format %{ \"vabsL_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_abs($dst_src$$FloatRegister, __ D, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsF_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVF dst_src pg));\n+  format %{ \"vabsF_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_fabs($dst_src$$FloatRegister, __ S, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vabsD_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AbsVD dst_src pg));\n+  format %{ \"vabsD_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_fabs($dst_src$$FloatRegister, __ D, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector fabd ----------------------------------\n+\n+\/\/ vector fabs diff\n+\n+instruct vfabd(vReg dst, vReg src1, vReg src2) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (AbsVF (SubVF src1 src2)));\n+  match(Set dst (AbsVD (SubVD src1 src2)));\n+  format %{ \"vfabd $dst, $src1, $src2\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    __ fabd($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector neg -----------------------------------\n+\n+\/\/ vector neg\n+\n+instruct vnegI(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (NegVI src));\n+  format %{ \"vnegI $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ negr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_neg($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegL(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (NegVL src));\n+  format %{ \"vnegL $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ negr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_neg($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegF(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (NegVF src));\n+  format %{ \"vnegF $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fneg($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fneg($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegD(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (NegVD src));\n+  format %{ \"vnegD $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fneg($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fneg($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector neg - predicated\n+\n+instruct vnegI_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (NegVI dst_src pg));\n+  format %{ \"vnegI_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_neg($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegL_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (NegVL dst_src pg));\n+  format %{ \"vnegL_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_neg($dst_src$$FloatRegister, __ D, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegF_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (NegVF dst_src pg));\n+  format %{ \"vnegF_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_fneg($dst_src$$FloatRegister, __ S, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vnegD_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (NegVD dst_src pg));\n+  format %{ \"vnegD_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_fneg($dst_src$$FloatRegister, __ D, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector sqrt ----------------------------------\n+\n+\/\/ vector sqrt\n+\n+instruct vsqrtF(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (SqrtVF src));\n+  format %{ \"vsqrtF $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fsqrt($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fsqrt($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (SqrtVD src));\n+  format %{ \"vsqrtD $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fsqrt($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fsqrt($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector sqrt - predicated\n+\n+instruct vsqrtF_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (SqrtVF dst_src pg));\n+  format %{ \"vsqrtF_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_fsqrt($dst_src$$FloatRegister, __ S, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vsqrtD_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (SqrtVD dst_src pg));\n+  format %{ \"vsqrtD_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_fsqrt($dst_src$$FloatRegister, __ D, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector min -----------------------------------\n+\n+\/\/ vector min - LONG\n+\n+instruct vminL_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (MinV src1 src2));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vminL_neon $dst, $src1, $src2\\t# 2L\" %}\n+  ins_encode %{\n+    __ cmgt($dst$$FloatRegister, __ T2D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ bsl($dst$$FloatRegister, __ T16B, $src2$$FloatRegister, $src1$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vminL_sve(vReg dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst_src1 (MinV dst_src1 src2));\n+  format %{ \"vminL_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_smin($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector min - B\/S\/I\/F\/D\n+\n+instruct vmin_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(Matcher::vector_element_basic_type(n) != T_LONG &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (MinV src1 src2));\n+  format %{ \"vmin_neon $dst, $src1, $src2\\t# B\/S\/I\/F\/D\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ fmin($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt) && bt != T_LONG, \"unsupported type\");\n+      __ minv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmin_sve(vReg dst_src1, vReg src2) %{\n+  predicate(Matcher::vector_element_basic_type(n) != T_LONG &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (MinV dst_src1 src2));\n+  format %{ \"vmin_sve $dst_src1, $dst_src1, $src2\\t# B\/S\/I\/F\/D\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ sve_fmin($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt) && bt != T_LONG, \"unsupported type\");\n+      __ sve_smin($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector min - predicated\n+\n+instruct vmin_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MinV (Binary dst_src1 src2) pg));\n+  format %{ \"vmin_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ sve_fmin($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ sve_smin($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector max -----------------------------------\n+\n+\/\/ vector max - LONG\n+\n+instruct vmaxL_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (MaxV src1 src2));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vmaxL_neon $dst, $src1, $src2\\t# 2L\" %}\n+  ins_encode %{\n+    __ cmgt($dst$$FloatRegister, __ T2D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ bsl($dst$$FloatRegister, __ T16B, $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaxL_sve(vReg dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst_src1 (MaxV dst_src1 src2));\n+  format %{ \"vmaxL_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_smax($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector max - B\/S\/I\/F\/D\n+\n+instruct vmax_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(Matcher::vector_element_basic_type(n) != T_LONG &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (MaxV src1 src2));\n+  format %{ \"vmax_neon $dst, $src1, $src2\\t# B\/S\/I\/F\/D\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ fmax($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt) && bt != T_LONG, \"unsupported type\");\n+      __ maxv($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmax_sve(vReg dst_src1, vReg src2) %{\n+  predicate(Matcher::vector_element_basic_type(n) != T_LONG &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 (MaxV dst_src1 src2));\n+  format %{ \"vmax_sve $dst_src1, $dst_src1, $src2\\t# B\/S\/I\/F\/D\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ sve_fmax($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt) && bt != T_LONG, \"unsupported type\");\n+      __ sve_smax($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector max - predicated\n+\n+instruct vmax_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MaxV (Binary dst_src1 src2) pg));\n+  format %{ \"vmax_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ sve_fmax($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ sve_smax($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ MLA RELATED ----------------------------------\n+\n+\/\/ vector mla\n+\/\/ dst_src1 = dst_src1 + src2 * src3\n+\n+instruct vmla(vReg dst_src1, vReg src2, vReg src3) %{\n+  match(Set dst_src1 (AddVB dst_src1 (MulVB src2 src3)));\n+  match(Set dst_src1 (AddVS dst_src1 (MulVS src2 src3)));\n+  match(Set dst_src1 (AddVI dst_src1 (MulVI src2 src3)));\n+  match(Set dst_src1 (AddVL dst_src1 (MulVL src2 src3)));\n+  format %{ \"vmla $dst_src1, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes) && bt != T_LONG) {\n+      \/\/ NEON mlav does not accept T2D arrangement.\n+      __ mlav($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_mla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmla_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVB (Binary dst_src1 (MulVB src2 src3)) pg));\n+  match(Set dst_src1 (AddVS (Binary dst_src1 (MulVS src2 src3)) pg));\n+  match(Set dst_src1 (AddVI (Binary dst_src1 (MulVI src2 src3)) pg));\n+  match(Set dst_src1 (AddVL (Binary dst_src1 (MulVL src2 src3)) pg));\n+  format %{ \"vmla_masked $dst_src1, $pg, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_mla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmla\n+\/\/ dst_src1 = dst_src1 + src2 * src3\n+\n+instruct vfmla(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA);\n+  match(Set dst_src1 (FmaVF dst_src1 (Binary src2 src3)));\n+  match(Set dst_src1 (FmaVD dst_src1 (Binary src2 src3)));\n+  format %{ \"vfmla $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmla($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_fmla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmad - predicated\n+\/\/ dst_src1 = dst_src1 * src2 + src3\n+\n+instruct vfmad_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0);\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 src2) (Binary src3 pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 src2) (Binary src3 pg)));\n+  format %{ \"vfmad_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fmad($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mls\n+\/\/ dst_src1 = dst_src1 - src2 * src3\n+\n+instruct vmls(vReg dst_src1, vReg src2, vReg src3) %{\n+  match(Set dst_src1 (SubVB dst_src1 (MulVB src2 src3)));\n+  match(Set dst_src1 (SubVS dst_src1 (MulVS src2 src3)));\n+  match(Set dst_src1 (SubVI dst_src1 (MulVI src2 src3)));\n+  match(Set dst_src1 (SubVL dst_src1 (MulVL src2 src3)));\n+  format %{ \"vmls $dst_src1, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes) && bt != T_LONG) {\n+      \/\/ NEON mlsv does not accept T2D arrangement.\n+      __ mlsv($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_mls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmls_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVB (Binary dst_src1 (MulVB src2 src3)) pg));\n+  match(Set dst_src1 (SubVS (Binary dst_src1 (MulVS src2 src3)) pg));\n+  match(Set dst_src1 (SubVI (Binary dst_src1 (MulVI src2 src3)) pg));\n+  match(Set dst_src1 (SubVL (Binary dst_src1 (MulVL src2 src3)) pg));\n+  format %{ \"vmls_masked $dst_src1, $pg, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_mls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmls\n+\n+\/\/ dst_src1 = dst_src1 + -src2 * src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfmls1(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF dst_src1 (Binary (NegVF src2) src3)));\n+  match(Set dst_src1 (FmaVD dst_src1 (Binary (NegVD src2) src3)));\n+  format %{ \"vfmls1 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmls($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_fmls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ dst_src1 = dst_src1 + src2 * -src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfmls2(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && !n->in(2)->in(2)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF dst_src1 (Binary src2 (NegVF src3))));\n+  match(Set dst_src1 (FmaVD dst_src1 (Binary src2 (NegVD src3))));\n+  format %{ \"vfmls2 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmls($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_fmls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmsb - predicated\n+\n+\/\/ dst_src1 = dst_src1 * -src2 + src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfmsb_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->in(2)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 (NegVF src2)) (Binary src3 pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 (NegVD src2)) (Binary src3 pg)));\n+  format %{ \"vfmsb_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fmsb($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmla (sve)\n+\n+\/\/ dst_src1 = -dst_src1 + -src2 * src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmla1(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->as_Vector()->is_predicated_vector() &&\n+            !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (NegVF dst_src1) (Binary (NegVF src2) src3)));\n+  match(Set dst_src1 (FmaVD (NegVD dst_src1) (Binary (NegVD src2) src3)));\n+  format %{ \"vfnmla1 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ dst_src1 = -dst_src1 + src2 * -src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmla2(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->as_Vector()->is_predicated_vector() &&\n+            !n->in(2)->in(2)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (NegVF dst_src1) (Binary src2 (NegVF src3))));\n+  match(Set dst_src1 (FmaVD (NegVD dst_src1) (Binary src2 (NegVD src3))));\n+  format %{ \"vfnmla2 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmad - predicated\n+\n+\/\/ dst_src1 = -src3 + dst_src1 * -src2\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmad_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->in(2)->as_Vector()->is_predicated_vector() &&\n+            !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 (NegVF src2)) (Binary (NegVF src3) pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 (NegVD src2)) (Binary (NegVD src3) pg)));\n+  format %{ \"vfnmad_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmad($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmls (sve)\n+\n+\/\/ dst_src1 = -dst_src1 + src2 * src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmls(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (NegVF dst_src1) (Binary src2 src3)));\n+  match(Set dst_src1 (FmaVD (NegVD dst_src1) (Binary src2 src3)));\n+  format %{ \"vfnmls $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmsb - predicated\n+\n+\/\/ dst_src1 = -src3 + dst_src1 * src2\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmsb_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 src2) (Binary (NegVF src3) pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 src2) (Binary (NegVD src3) pg)));\n+  format %{ \"vfnmsb_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmsb($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ MulAddVS2VI\n+\/\/ Vector Multiply-Add Shorts into Integer\n+\n+instruct vmuladdS2I(vReg dst, vReg src1, vReg src2, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16 &&\n+            Matcher::vector_element_basic_type(n->in(1)) == T_SHORT);\n+  match(Set dst (MulAddVS2VI src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vmuladdS2I $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ smullv($tmp$$FloatRegister, __ T4H, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ smullv($dst$$FloatRegister, __ T8H, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ addpv($dst$$FloatRegister, __ T4S, $tmp$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector shift ---------------------------------\n+\n+\/\/ Vector right shift in AArch64 ASIMD\n+\/\/\n+\/\/ Right shifts with vector shift count on AArch64 ASIMD are implemented\n+\/\/ as left shift by negative shift count.\n+\/\/ There are two cases for vector shift count.\n+\/\/\n+\/\/ Case 1: The vector shift count is from replication.\n+\/\/        |            |\n+\/\/    LoadVector  RShiftCntV\n+\/\/        |       \/\n+\/\/     RShiftVI\n+\/\/\n+\/\/ Case 2: The vector shift count is from loading.\n+\/\/ This case isn't supported by middle-end now. But it's supported by\n+\/\/ panama\/vectorIntrinsics(JEP 338: Vector API).\n+\/\/        |            |\n+\/\/    LoadVector  LoadVector\n+\/\/        |       \/\n+\/\/     RShiftVI\n+\/\/\n+\/\/ The negate is conducted in RShiftCntV rule for case 1, whereas it's done in\n+\/\/ RShiftV* rules for case 2. Because there exists an optimization opportunity\n+\/\/ for case 1, that is, multiple neg instructions in inner loop can be hoisted\n+\/\/ to outer loop and merged into one neg instruction.\n+\/\/\n+\/\/ Note that ShiftVNode::is_var_shift() indicates whether the vector shift\n+\/\/ count is a variable vector(case 2) or not(a vector generated by RShiftCntV,\n+\/\/ i.e. case 1).\n+\n+\/\/ vector shift count\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  match(Set dst (LShiftCntV cnt));\n+  format %{ \"vshiftcntL $dst, $cnt\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $cnt$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_dup($dst$$FloatRegister, __ elemType_to_regVariant(bt), $cnt$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntR(vReg dst, iRegIorL2I cnt) %{\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"vshiftcntR $dst, $cnt\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      assert(length_in_bytes <= 16, \"must be\");\n+      __ negw(rscratch1, $cnt$$Register);\n+      __ dup($dst$$FloatRegister, get_arrangement(this), rscratch1);\n+    } else {\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_dup($dst$$FloatRegister, __ elemType_to_regVariant(bt), $cnt$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift left\n+\n+instruct vlsl_neon(vReg dst, vReg src, vReg shift) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (LShiftVB src shift));\n+  match(Set dst (LShiftVS src shift));\n+  match(Set dst (LShiftVI src shift));\n+  match(Set dst (LShiftVL src shift));\n+  format %{ \"vlsl_neon $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ sshl($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsl_sve(vReg dst_src, vReg shift) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src (LShiftVB dst_src shift));\n+  match(Set dst_src (LShiftVS dst_src shift));\n+  match(Set dst_src (LShiftVI dst_src shift));\n+  match(Set dst_src (LShiftVL dst_src shift));\n+  format %{ \"vlsl_sve $dst_src, $dst_src, $shift\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_lsl($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift right (arithmetic)\n+\n+instruct vasr_neon(vReg dst, vReg src, vReg shift) %{\n+  predicate(UseSVE == 0 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src shift));\n+  match(Set dst (RShiftVS src shift));\n+  match(Set dst (RShiftVI src shift));\n+  match(Set dst (RShiftVL src shift));\n+  format %{ \"vasr_neon $dst, $src, $shift\\t# not variable shift\" %}\n+  ins_encode %{\n+    __ sshl($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasr_neon_var(vReg dst, vReg src, vReg shift) %{\n+  predicate(UseSVE == 0 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (RShiftVB src shift));\n+  match(Set dst (RShiftVS src shift));\n+  match(Set dst (RShiftVI src shift));\n+  match(Set dst (RShiftVL src shift));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vasr_neon_var $dst, $src, $shift\\t# variable shift\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $shift$$FloatRegister);\n+    __ sshl($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasr_sve(vReg dst_src, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (RShiftVB dst_src shift));\n+  match(Set dst_src (RShiftVS dst_src shift));\n+  match(Set dst_src (RShiftVI dst_src shift));\n+  match(Set dst_src (RShiftVL dst_src shift));\n+  format %{ \"vasr_sve $dst_src, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_asr($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift right (logical)\n+\n+instruct vlsr_neon(vReg dst, vReg src, vReg shift) %{\n+  predicate(UseSVE == 0 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVB src shift));\n+  match(Set dst (URShiftVS src shift));\n+  match(Set dst (URShiftVI src shift));\n+  match(Set dst (URShiftVL src shift));\n+  format %{ \"vlsr_neon $dst, $src, $shift\\t# not variable shift\" %}\n+  ins_encode %{\n+    __ ushl($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsr_neon_var(vReg dst, vReg src, vReg shift) %{\n+  predicate(UseSVE == 0 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst (URShiftVB src shift));\n+  match(Set dst (URShiftVS src shift));\n+  match(Set dst (URShiftVI src shift));\n+  match(Set dst (URShiftVL src shift));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vlsr_neon_var $dst, $src, $shift\\t# variable shift\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $shift$$FloatRegister);\n+    __ ushl($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsr_sve(vReg dst_src, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (URShiftVB dst_src shift));\n+  match(Set dst_src (URShiftVS dst_src shift));\n+  match(Set dst_src (URShiftVI dst_src shift));\n+  match(Set dst_src (URShiftVL dst_src shift));\n+  format %{ \"vlsr_sve $dst_src, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_lsr($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift with imm\n+\n+instruct vlsl_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(assert_not_var_shift(n));\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  format %{ \"vlsl_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Optimize for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) {\n+        if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+          __ eor($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        } else {\n+          assert(UseSVE > 0, \"must be sve\");\n+          __ sve_eor($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+        return;\n+      }\n+    }\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ shl($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_lsl($dst$$FloatRegister, __ elemType_to_regVariant(bt), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasr_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(assert_not_var_shift(n));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  format %{ \"vasr_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Refine con for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) con = esize_in_bits - 1;\n+    }\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ sshr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_asr($dst$$FloatRegister, __ elemType_to_regVariant(bt), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsr_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(assert_not_var_shift(n));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+  format %{ \"vlsr_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Optimize for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) {\n+        if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+          __ eor($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        } else {\n+          assert(UseSVE > 0, \"must be sve\");\n+          __ sve_eor($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+        return;\n+      }\n+    }\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ ushr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_lsr($dst$$FloatRegister, __ elemType_to_regVariant(bt), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ shift right add with imm (vector length <= 128 bits only)\n+\n+instruct vasra_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (AddVB dst (RShiftVB src (RShiftCntV shift))));\n+  match(Set dst (AddVS dst (RShiftVS src (RShiftCntV shift))));\n+  match(Set dst (AddVI dst (RShiftVI src (RShiftCntV shift))));\n+  match(Set dst (AddVL dst (RShiftVL src (RShiftCntV shift))));\n+  format %{ \"vasra_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Refine con for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) con = esize_in_bits - 1;\n+    }\n+    __ ssra($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsra_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (AddVB dst (URShiftVB src (RShiftCntV shift))));\n+  match(Set dst (AddVS dst (URShiftVS src (RShiftCntV shift))));\n+  match(Set dst (AddVI dst (URShiftVI src (RShiftCntV shift))));\n+  match(Set dst (AddVL dst (URShiftVL src (RShiftCntV shift))));\n+  format %{ \"vlsra_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) { \/\/ for B\/H\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con < esize_in_bits) {\n+        __ usra($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+      }\n+    } else { \/\/ for S\/D\n+      assert(type2aelembytes(bt) == 4 || type2aelembytes(bt) == 8, \"unsupported type\");\n+      __ usra($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift - predicated\n+\n+instruct vlsl_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (LShiftVB (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (LShiftVS (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (LShiftVI (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (LShiftVL (Binary dst_src1 src2) pg));\n+  format %{ \"vlsl_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_lsl($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasr_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (RShiftVB (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (RShiftVS (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (RShiftVI (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (RShiftVL (Binary dst_src1 src2) pg));\n+  format %{ \"vasr_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_asr($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsr_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (URShiftVB (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (URShiftVS (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (URShiftVI (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 (URShiftVL (Binary dst_src1 src2) pg));\n+  format %{ \"vlsr_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_lsr($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift with imm - predicated\n+\n+instruct vlsl_imm_masked(vReg dst_src, immI shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (LShiftVB (Binary dst_src (LShiftCntV shift)) pg));\n+  match(Set dst_src (LShiftVS (Binary dst_src (LShiftCntV shift)) pg));\n+  match(Set dst_src (LShiftVI (Binary dst_src (LShiftCntV shift)) pg));\n+  match(Set dst_src (LShiftVL (Binary dst_src (LShiftCntV shift)) pg));\n+  format %{ \"vlsl_imm_masked $dst_src, $pg, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+    int con = (int)$shift$$constant;\n+    assert(con >= 0 && con < esize_in_bits, \"invalid shift immediate\");\n+    __ sve_lsl($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasr_imm_masked(vReg dst_src, immI_positive shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (RShiftVB (Binary dst_src (RShiftCntV shift)) pg));\n+  match(Set dst_src (RShiftVS (Binary dst_src (RShiftCntV shift)) pg));\n+  match(Set dst_src (RShiftVI (Binary dst_src (RShiftCntV shift)) pg));\n+  match(Set dst_src (RShiftVL (Binary dst_src (RShiftCntV shift)) pg));\n+  format %{ \"vasr_imm_masked $dst_src, $pg, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < esize_in_bits, \"invalid shift immediate\");\n+    __ sve_asr($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsr_imm_masked(vReg dst_src, immI_positive shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (URShiftVB (Binary dst_src (RShiftCntV shift)) pg));\n+  match(Set dst_src (URShiftVS (Binary dst_src (RShiftCntV shift)) pg));\n+  match(Set dst_src (URShiftVI (Binary dst_src (RShiftCntV shift)) pg));\n+  match(Set dst_src (URShiftVL (Binary dst_src (RShiftCntV shift)) pg));\n+  format %{ \"vlsr_imm_masked $dst_src, $pg, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+    int con = (int)$shift$$constant;\n+    assert(con > 0 && con < esize_in_bits, \"invalid shift immediate\");\n+    __ sve_lsr($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction add -------------------------\n+\n+\/\/ reduction addI\n+\n+instruct reduce_addI_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, vReg tmp) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))));\n+  match(Set dst (AddReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addI_neon $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_integral($dst$$Register, bt,\n+                                $isrc$$Register, $vsrc$$FloatRegister,\n+                                length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addI_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))));\n+  match(Set dst (AddReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addI_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction addL\n+\n+instruct reduce_addL_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc, vReg tmp) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))));\n+  match(Set dst (AddReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addL_neon $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_integral($dst$$Register, bt,\n+                                $isrc$$Register, $vsrc$$FloatRegister,\n+                                length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addL_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))));\n+  match(Set dst (AddReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addL_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction addF\n+\n+instruct reduce_addF_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addF_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ fadds($dst$$FloatRegister, $fsrc$$FloatRegister, $vsrc$$FloatRegister);\n+    __ ins($tmp$$FloatRegister, __ S, $vsrc$$FloatRegister, 0, 1);\n+    __ fadds($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+    if (length_in_bytes == 16) {\n+      __ ins($tmp$$FloatRegister, __ S, $vsrc$$FloatRegister, 0, 2);\n+      __ fadds($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+      __ ins($tmp$$FloatRegister, __ S, $vsrc$$FloatRegister, 0, 3);\n+      __ fadds($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addF_sve(vRegF dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionVF dst_src1 src2));\n+  format %{ \"reduce_addF_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src2);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_fadda($dst_src1$$FloatRegister, __ S, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction addD\n+\n+instruct reduce_addD_neon(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addD_neon $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  ins_encode %{\n+    __ faddd($dst$$FloatRegister, $dsrc$$FloatRegister, $vsrc$$FloatRegister);\n+    __ ins($tmp$$FloatRegister, __ D, $vsrc$$FloatRegister, 0, 1);\n+    __ faddd($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addD_sve(vRegD dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionVD dst_src1 src2));\n+  format %{ \"reduce_addD_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src2);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_fadda($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction add - predicated\n+\n+instruct reduce_addI_masked(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (AddReductionVI (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addI_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addL_masked(iRegLNoSp dst, iRegL isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (AddReductionVL (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addL_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addF_masked(vRegF dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionVF (Binary dst_src1 src2) pg));\n+  format %{ \"reduce_addF_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fadda($dst_src1$$FloatRegister, __ S,\n+                 $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_addD_masked(vRegD dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionVD (Binary dst_src1 src2) pg));\n+  format %{ \"reduce_addD_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fadda($dst_src1$$FloatRegister, __ D,\n+                 $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction mul -------------------------\n+\n+instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                     vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 8 ||\n+            Matcher::vector_length_in_bytes(n->in(2)) == 16);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n+                                $vsrc$$FloatRegister, length_in_bytes,\n+                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 16);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  ins_encode %{\n+    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n+                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) <= 16);\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 16);\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  ins_encode %{\n+    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction and -------------------------\n+\n+\/\/ reduction andI\n+\n+instruct reduce_andI_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) != T_LONG);\n+  match(Set dst (AndReductionV isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_andI_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andI_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) != T_LONG);\n+  match(Set dst (AndReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_andI_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction andL\n+\n+instruct reduce_andL_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (AndReductionV isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_andL_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (AndReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_andL_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction and - predicated\n+\n+instruct reduce_andI_masked(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) != T_LONG);\n+  match(Set dst (AndReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_andI_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_andL_masked(iRegLNoSp dst, iRegL isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_LONG);\n+  match(Set dst (AndReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_andL_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction or --------------------------\n+\n+\/\/ reduction orI\n+\n+instruct reduce_orI_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) != T_LONG);\n+  match(Set dst (OrReductionV isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_orI_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orI_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) != T_LONG);\n+  match(Set dst (OrReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_orI_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction orL\n+\n+instruct reduce_orL_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (OrReductionV isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_orL_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (OrReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_orL_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction or - predicated\n+\n+instruct reduce_orI_masked(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) != T_LONG);\n+  match(Set dst (OrReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_orI_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_orL_masked(iRegLNoSp dst, iRegL isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_LONG);\n+  match(Set dst (OrReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_orL_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction xor -------------------------\n+\n+\/\/ reduction xorI\n+\n+instruct reduce_xorI_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) != T_LONG);\n+  match(Set dst (XorReductionV isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_xorI_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_xorI_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) != T_LONG);\n+  match(Set dst (XorReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_xorI_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction xorL\n+\n+instruct reduce_xorL_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (XorReductionV isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_xorL_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_xorL_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (XorReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_xorL_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction xor - predicated\n+\n+instruct reduce_xorI_masked(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) != T_LONG);\n+  match(Set dst (XorReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_xorI_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_xorL_masked(iRegLNoSp dst, iRegL isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_LONG);\n+  match(Set dst (XorReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_xorL_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction max -------------------------\n+\n+\/\/ reduction maxI\n+\n+instruct reduce_maxI_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                          vReg tmp, rFlagsReg cr) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) &&\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_INT));\n+  match(Set dst (MaxReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_maxI_neon $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_minmax_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                                   $isrc$$Register, $vsrc$$FloatRegister,\n+                                   length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxI_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                         vRegD tmp, rFlagsReg cr) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) &&\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_INT));\n+  match(Set dst (MaxReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_maxI_sve $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction maxL\n+\n+instruct reduce_maxL_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (MaxReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, KILL cr);\n+  format %{ \"reduce_maxL_neon $dst, $isrc, $vsrc\\t# 2L. KILL cr\" %}\n+  ins_encode %{\n+    __ neon_reduce_minmax_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                                   $isrc$$Register, $vsrc$$FloatRegister,\n+                                   \/* vector_length_in_bytes *\/ 16, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxL_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc,\n+                         vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (MaxReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_maxL_sve $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction maxF\n+\n+instruct reduce_maxF(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(2)) == T_FLOAT);\n+  match(Set dst (MaxReductionV fsrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_maxF $dst, $fsrc, $vsrc\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      if (length_in_bytes == 8) {\n+        __ fmaxp($dst$$FloatRegister, $vsrc$$FloatRegister, __ S);\n+      } else {\n+        __ fmaxv($dst$$FloatRegister, __ T4S, $vsrc$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+      __ sve_fmaxv($dst$$FloatRegister, __ S, ptrue, $vsrc$$FloatRegister);\n+    }\n+    __ fmaxs($dst$$FloatRegister, $dst$$FloatRegister, $fsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction maxD\n+\n+instruct reduce_maxD(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(2)) == T_DOUBLE);\n+  match(Set dst (MaxReductionV dsrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_maxD $dst, $dsrc, $vsrc\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmaxp($dst$$FloatRegister, $vsrc$$FloatRegister, __ D);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+      __ sve_fmaxv($dst$$FloatRegister, __ D, ptrue, $vsrc$$FloatRegister);\n+    }\n+    __ fmaxd($dst$$FloatRegister, $dst$$FloatRegister, $dsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction max - predicated\n+\n+instruct reduce_maxI_masked(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, pRegGov pg,\n+                            vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_INT));\n+  match(Set dst (MaxReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_maxI_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxL_masked(iRegLNoSp dst, iRegL isrc, vReg vsrc, pRegGov pg,\n+                            vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_LONG);\n+  match(Set dst (MaxReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_maxL_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxF_masked(vRegF dst, vRegF fsrc, vReg vsrc, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_FLOAT);\n+  match(Set dst (MaxReductionV (Binary fsrc vsrc) pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_maxF_masked $dst, $fsrc, $pg, $vsrc\" %}\n+  ins_encode %{\n+    __ sve_fmaxv($dst$$FloatRegister, __ S, $pg$$PRegister, $vsrc$$FloatRegister);\n+    __ fmaxs($dst$$FloatRegister, $dst$$FloatRegister, $fsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_maxD_masked(vRegD dst, vRegD dsrc, vReg vsrc, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_DOUBLE);\n+  match(Set dst (MaxReductionV (Binary dsrc vsrc) pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_maxD_masked $dst, $dsrc, $pg, $vsrc\" %}\n+  ins_encode %{\n+    __ sve_fmaxv($dst$$FloatRegister, __ D, $pg$$PRegister, $vsrc$$FloatRegister);\n+    __ fmaxd($dst$$FloatRegister, $dst$$FloatRegister, $dsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reduction min -------------------------\n+\n+\/\/ reduction minI\n+\n+instruct reduce_minI_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                          vReg tmp, rFlagsReg cr) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) &&\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_INT));\n+  match(Set dst (MinReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_minI_neon $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_minmax_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                                   $isrc$$Register, $vsrc$$FloatRegister,\n+                                   length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minI_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                         vRegD tmp, rFlagsReg cr) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) &&\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_INT));\n+  match(Set dst (MinReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_minI_sve $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction minL\n+\n+instruct reduce_minL_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (MinReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, KILL cr);\n+  format %{ \"reduce_minL_neon $dst, $isrc, $vsrc\\t# 2L. KILL cr\" %}\n+  ins_encode %{\n+    __ neon_reduce_minmax_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                                   $isrc$$Register, $vsrc$$FloatRegister,\n+                                   \/* vector_length_in_bytes *\/ 16, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc,\n+                         vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst (MinReductionV isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_minL_sve $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction minF\n+\n+instruct reduce_minF(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(2)) == T_FLOAT);\n+  match(Set dst (MinReductionV fsrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_minF $dst, $fsrc, $vsrc\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      if (length_in_bytes == 8) {\n+        __ fminp($dst$$FloatRegister, $vsrc$$FloatRegister, __ S);\n+      } else {\n+        __ fminv($dst$$FloatRegister, __ T4S, $vsrc$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+      __ sve_fminv($dst$$FloatRegister, __ S, ptrue, $vsrc$$FloatRegister);\n+    }\n+    __ fmins($dst$$FloatRegister, $dst$$FloatRegister, $fsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction minD\n+\n+instruct reduce_minD(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(2)) == T_DOUBLE);\n+  match(Set dst (MinReductionV dsrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_minD $dst, $dsrc, $vsrc\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fminp($dst$$FloatRegister, $vsrc$$FloatRegister, __ D);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+      __ sve_fminv($dst$$FloatRegister, __ D, ptrue, $vsrc$$FloatRegister);\n+    }\n+    __ fmind($dst$$FloatRegister, $dst$$FloatRegister, $dsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ reduction min - predicated\n+\n+instruct reduce_minI_masked(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc, pRegGov pg,\n+                            vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_INT));\n+  match(Set dst (MinReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_minI_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minL_masked(iRegLNoSp dst, iRegL isrc, vReg vsrc, pRegGov pg,\n+                            vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_LONG);\n+  match(Set dst (MinReductionV (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_minL_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minF_masked(vRegF dst, vRegF fsrc, vReg vsrc, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_FLOAT);\n+  match(Set dst (MinReductionV (Binary fsrc vsrc) pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_minF_masked $dst, $fsrc, $pg, $vsrc\" %}\n+  ins_encode %{\n+    __ sve_fminv($dst$$FloatRegister, __ S, $pg$$PRegister, $vsrc$$FloatRegister);\n+    __ fmins($dst$$FloatRegister, $dst$$FloatRegister, $fsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_minD_masked(vRegD dst, vRegD dsrc, vReg vsrc, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_DOUBLE);\n+  match(Set dst (MinReductionV (Binary dsrc vsrc) pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_minD_masked $dst, $dsrc, $pg, $vsrc\" %}\n+  ins_encode %{\n+    __ sve_fminv($dst$$FloatRegister, __ D, $pg$$PRegister, $vsrc$$FloatRegister);\n+    __ fmind($dst$$FloatRegister, $dst$$FloatRegister, $dsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector reinterpret ---------------------------\n+\n+instruct reinterpret_same_size(vReg dst_src) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst_src (VectorReinterpret dst_src));\n+  ins_cost(0);\n+  format %{ \"reinterpret_same_size $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpret_resize_le128b(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_length_in_bytes(n) != Matcher::vector_length_in_bytes(n->in(1)) &&\n+            Matcher::vector_length_in_bytes(n) <= 16 &&\n+            Matcher::vector_length_in_bytes(n->in(1)) <= 16);\n+  match(Set dst (VectorReinterpret src));\n+  format %{ \"reinterpret_resize_le128b $dst, $src\\t# vector <= 128 bits.\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    \/\/ The higher bits in \"dst\" register must be cleared to zero.\n+    if ((length_in_bytes_src == 4 && length_in_bytes_dst == 8) ||\n+        (length_in_bytes_src == 8 && length_in_bytes_dst == 4)) {\n+      \/\/ Reinterpret between 32 bits and 64 bits\n+      __ dup($dst$$FloatRegister, __ S, $src$$FloatRegister);\n+    } else if ((length_in_bytes_src == 4 && length_in_bytes_dst == 16) ||\n+               (length_in_bytes_src == 16 && length_in_bytes_dst == 4)) {\n+      \/\/ Reinterpret between 32 bits and 128 bits\n+      __ dup($dst$$FloatRegister, __ S, $src$$FloatRegister);\n+    } else if ((length_in_bytes_src == 8 && length_in_bytes_dst == 16) ||\n+               (length_in_bytes_src == 16 && length_in_bytes_dst == 8)) {\n+      \/\/ Reinterpret between 64 bits and 128 bits\n+      __ orr($dst$$FloatRegister, __ T8B, $src$$FloatRegister, $src$$FloatRegister);\n+    } else {\n+      assert(false, \"invalid vector length\");\n+      ShouldNotReachHere();\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpret_resize_gt128b(vReg dst, vReg src, pReg ptmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) != Matcher::vector_length_in_bytes(n->in(1)) &&\n+            (Matcher::vector_length_in_bytes(n) > 16 ||\n+             Matcher::vector_length_in_bytes(n->in(1)) > 16));\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"reinterpret_resize_gt128b $dst, $src\\t# vector > 128 bits. KILL $ptmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ sve_gen_mask_imm($ptmp$$PRegister, T_BYTE, length_in_bytes_resize);\n+    __ sve_dup($dst$$FloatRegister, __ B, 0);\n+    __ sve_sel($dst$$FloatRegister, __ B, $ptmp$$PRegister,\n+               $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector cast ----------------------------------\n+\n+\/\/ VectorCastB2X\n+\n+instruct vcvtBtoX(vReg dst, vReg src) %{\n+  match(Set dst (VectorCastB2X src));\n+  format %{ \"vcvtBtoX $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 4B to 4S\/4I\/4F, 8B to 8S\n+      __ neon_vector_extend($dst$$FloatRegister, bt == T_FLOAT ? T_INT : bt,\n+                            length_in_bytes, $src$$FloatRegister, T_BYTE);\n+      if (bt == T_FLOAT) {\n+        __ scvtfv(__ T4S, $dst$$FloatRegister, $dst$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+      __ sve_vector_extend($dst$$FloatRegister, size, $src$$FloatRegister, __ B);\n+      if (is_floating_point_type(bt)) {\n+        __ sve_scvtf($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister, size);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastS2X\n+\n+instruct vcvtStoB_neon(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastS2X src));\n+  format %{ \"vcvtStoB_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 4S\/8S to 4B\/8B\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ neon_vector_narrow($dst$$FloatRegister, T_BYTE,\n+                          $src$$FloatRegister, T_SHORT, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoB_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP tmp);\n+  format %{ \"vcvtStoB_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_vector_narrow($dst$$FloatRegister, __ B,\n+                         $src$$FloatRegister, __ H, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoX_extend(vReg dst, vReg src) %{\n+  predicate(type2aelembytes(Matcher::vector_element_basic_type(n)) >= 4);\n+  match(Set dst (VectorCastS2X src));\n+  format %{ \"vcvtStoX_extend $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 4S to 4I\/4F\n+      __ neon_vector_extend($dst$$FloatRegister, T_INT, length_in_bytes,\n+                            $src$$FloatRegister, T_SHORT);\n+      if (bt == T_FLOAT) {\n+        __ scvtfv(__ T4S, $dst$$FloatRegister, $dst$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+      __ sve_vector_extend($dst$$FloatRegister, size, $src$$FloatRegister, __ H);\n+      if (is_floating_point_type(bt)) {\n+        __ sve_scvtf($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister, size);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastI2X\n+\n+instruct vcvtItoX_narrow_neon(vReg dst, vReg src) %{\n+  predicate((Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT) &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vcvtItoX_narrow_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 4I to 4B\/4S\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ neon_vector_narrow($dst$$FloatRegister, bt,\n+                          $src$$FloatRegister, T_INT, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoX_narrow_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate((Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT) &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtItoX_narrow_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $src$$FloatRegister, __ S, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoX(vReg dst, vReg src) %{\n+  predicate(type2aelembytes(Matcher::vector_element_basic_type(n)) >= 4);\n+  match(Set dst (VectorCastI2X src));\n+  format %{ \"vcvtItoX $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes =  Matcher::vector_length_in_bytes(this);\n+    if (bt == T_FLOAT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 2I\/4I to 2F\/4F\n+        __ scvtfv(get_arrangement(this), $dst$$FloatRegister, $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_scvtf($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ S);\n+      }\n+    } else {\n+      assert(type2aelembytes(bt) == 8, \"unsupported type\");\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 2I to 2L\/2D\n+        __ neon_vector_extend($dst$$FloatRegister, T_LONG, length_in_bytes,\n+                              $src$$FloatRegister, T_INT);\n+        if (bt == T_DOUBLE) {\n+          __ scvtfv(__ T2D, $dst$$FloatRegister, $dst$$FloatRegister);\n+        }\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ S);\n+        if (bt == T_DOUBLE) {\n+          __ sve_scvtf($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ D);\n+        }\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastL2X\n+\n+instruct vcvtLtoI_neon(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_INT &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastL2X src));\n+  format %{ \"vcvtLtoI_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 2L to 2I\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ neon_vector_narrow($dst$$FloatRegister, T_INT,\n+                          $src$$FloatRegister, T_LONG, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoI_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate((Matcher::vector_element_basic_type(n) == T_INT &&\n+             !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1)))) ||\n+            Matcher::vector_element_basic_type(n) == T_BYTE ||\n+            Matcher::vector_element_basic_type(n) == T_SHORT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtLtoI_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $src$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoF_neon(vReg dst, vReg src, vRegF tmp) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtLtoF_neon $dst, $src\\t# 2L to 2F. KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ 2L to 2F\n+    __ umov(rscratch1, $src$$FloatRegister, __ D, 0);\n+    __ scvtfs($dst$$FloatRegister, rscratch1);\n+    __ umov(rscratch1, $src$$FloatRegister, __ D, 1);\n+    __ scvtfs($tmp$$FloatRegister, rscratch1);\n+    __ ins($dst$$FloatRegister, __ S, $tmp$$FloatRegister, 1, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoF_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtLtoF_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ sve_scvtf($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ D);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ S,\n+                         $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoD(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorCastL2X src));\n+  format %{ \"vcvtLtoD $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 2L to 2D\n+      __ scvtfv(__ T2D, $dst$$FloatRegister, $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_scvtf($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister, __ D);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastF2X\n+\n+instruct vcvtFtoX_narrow_neon(vReg dst, vReg src) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))) &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT));\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vcvtFtoX_narrow_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 4F to 4B\/4S\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ fcvtzs($dst$$FloatRegister, __ T4S, $src$$FloatRegister);\n+    __ neon_vector_narrow($dst$$FloatRegister, bt,\n+                          $dst$$FloatRegister, T_INT, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoX_narrow_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))) &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT));\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtFtoX_narrow_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ S);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $dst$$FloatRegister, __ S, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoX(vReg dst, vReg src) %{\n+  predicate(type2aelembytes(Matcher::vector_element_basic_type(n)) >= 4);\n+  match(Set dst (VectorCastF2X src));\n+  format %{ \"vcvtFtoX $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes =  Matcher::vector_length_in_bytes(this);\n+    if (bt == T_INT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 2F\/4F to 2I\/4I\n+        __ fcvtzs($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ S);\n+      }\n+    } else if (bt == T_LONG) {\n+      if (UseSVE == 0) {\n+        \/\/ 2F to 2L\n+        __ fcvtl($dst$$FloatRegister, __ T2D, $src$$FloatRegister, __ T2S);\n+        __ fcvtzs($dst$$FloatRegister, __ T2D, $dst$$FloatRegister);\n+      } else {\n+        __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ S);\n+        __ sve_fcvtzs($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ S);\n+      }\n+    } else {\n+      assert(bt == T_DOUBLE, \"unsupported type\");\n+      if (length_in_bytes == 16) {\n+        \/\/ 2F to 2D\n+        __ fcvtl($dst$$FloatRegister, __ T2D, $src$$FloatRegister, __ T2S);\n+      } else {\n+        assert(UseSVE > 0 && length_in_bytes > 16, \"must be\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ S);\n+        __ sve_fcvt($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ S);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastD2X\n+\n+instruct vcvtDtoI_neon(vReg dst, vReg src) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vcvtDtoI_neon $dst, $src\\t# 2D to 2I\" %}\n+  ins_encode %{\n+    \/\/ 2D to 2I\n+    __ ins($dst$$FloatRegister, __ D, $src$$FloatRegister, 0, 1);\n+    \/\/ We can't use fcvtzs(vector, integer) instruction here because we need\n+    \/\/ saturation arithmetic. See JDK-8276151.\n+    __ fcvtzdw(rscratch1, $src$$FloatRegister);\n+    __ fcvtzdw(rscratch2, $dst$$FloatRegister);\n+    __ fmovs($dst$$FloatRegister, rscratch1);\n+    __ mov($dst$$FloatRegister, __ S, 1, rscratch2);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoI_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtDtoI_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ D);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoL(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  format %{ \"vcvtDtoL $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes =  Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 2D to 2L\n+      __ fcvtzs($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fcvtzs($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister, __ D);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF_64b(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_FLOAT &&\n+            Matcher::vector_length_in_bytes(n) == 8);\n+  match(Set dst (VectorCastD2X src));\n+  format %{ \"vcvtDtoF_64b $dst, $src\\t# 2D to 2F\" %}\n+  ins_encode %{\n+    \/\/ 2D to 2F\n+    __ fcvtn($dst$$FloatRegister, __ T2S, $src$$FloatRegister, __ T2D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF_gt64b(vReg dst, vReg src, vReg tmp) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_FLOAT &&\n+            Matcher::vector_length_in_bytes(n) > 8);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtDtoF_gt64b $dst, $src\\t# vector > 64 bits. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_fcvt($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ D);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ S,\n+                         $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Replicate ------------------------------------\n+\n+\/\/ replicate from reg\n+\n+instruct replicateB(vReg dst, iRegIorL2I src) %{\n+  match(Set dst (ReplicateB src));\n+  format %{ \"replicateB $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_dup($dst$$FloatRegister, __ B, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS(vReg dst, iRegIorL2I src) %{\n+  match(Set dst (ReplicateS src));\n+  format %{ \"replicateS $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_dup($dst$$FloatRegister, __ H, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI(vReg dst, iRegIorL2I src) %{\n+  match(Set dst (ReplicateI src));\n+  format %{ \"replicateI $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_dup($dst$$FloatRegister, __ S, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL(vReg dst, iRegL src) %{\n+  match(Set dst (ReplicateL src));\n+  format %{ \"replicateL $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_dup($dst$$FloatRegister, __ D, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateF(vReg dst, vRegF src) %{\n+  match(Set dst (ReplicateF src));\n+  format %{ \"replicateF $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_cpy($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateD(vReg dst, vRegD src) %{\n+  match(Set dst (ReplicateD src));\n+  format %{ \"replicateD $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_cpy($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ replicate from imm\n+\n+instruct replicateI_imm_le128b(vReg dst, immI con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (ReplicateB con));\n+  match(Set dst (ReplicateS con));\n+  match(Set dst (ReplicateI con));\n+  format %{ \"replicateI_imm_le128b $dst, $con\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int imm = (int)$con$$constant;\n+    if (type2aelembytes(bt) == 1) {\n+      \/\/ Refine imm for B\n+      imm = imm & 0xff;\n+    } else if (type2aelembytes(bt) == 2) {\n+      \/\/ Refine imm for S\n+      imm = imm & 0xffff;\n+    }\n+    __ mov($dst$$FloatRegister, get_arrangement(this), imm);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateB_imm8_gt128b(vReg dst, immI8 con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (ReplicateB con));\n+  format %{ \"replicateB_imm8_gt128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_dup($dst$$FloatRegister, __ B, (int)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateS_imm8_gt128b(vReg dst, immI8_shift8 con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (ReplicateS con));\n+  format %{ \"replicateS_imm8_gt128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_dup($dst$$FloatRegister, __ H, (int)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateI_imm8_gt128b(vReg dst, immI8_shift8 con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (ReplicateI con));\n+  format %{ \"replicateI_imm8_gt128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_dup($dst$$FloatRegister, __ S, (int)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL_imm_128b(vReg dst, immL con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16);\n+  match(Set dst (ReplicateL con));\n+  format %{ \"replicateL_imm_128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    __ mov($dst$$FloatRegister, __ T2D, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct replicateL_imm8_gt128b(vReg dst, immL8_shift8 con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (ReplicateL con));\n+  format %{ \"replicateL_imm8_gt128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_dup($dst$$FloatRegister, __ D, (int)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector insert --------------------------------\n+\n+\/\/ BYTE, SHORT, INT\n+\n+instruct insertI_le128b(vReg dst, vReg src, iRegIorL2I val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  format %{ \"insertI_le128b $dst, $src, $val, $idx\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ mov($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+           (int)($idx$$constant), $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertI_index_lt32(vReg dst, vReg src, iRegIorL2I val, immI idx,\n+                            vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() < 32 &&\n+            Matcher::vector_length_in_bytes(n) > 16 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"insertI_index_lt32 $dst, $src, $val, $idx\\t# vector > 128 bits, index < 31. KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index($tmp$$FloatRegister, size, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, size, ptrue,\n+               $tmp$$FloatRegister, (int)($idx$$constant) - 16);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ sve_cpy($dst$$FloatRegister, size, $pgtmp$$PRegister, $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertI_index_ge32(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1,\n+                            vReg tmp2, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() >= 32 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP pgtmp, KILL cr);\n+  format %{ \"insertI_index_ge32 $dst, $src, $val, $idx\\t# index >= 32. KILL $tmp1, $tmp2, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index($tmp1$$FloatRegister, size, 0, 1);\n+    __ sve_dup($tmp2$$FloatRegister, size, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, size, ptrue,\n+               $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ sve_cpy($dst$$FloatRegister, size, $pgtmp$$PRegister, $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ LONG\n+\n+instruct insertL_128b(vReg dst, vReg src, iRegL val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16 &&\n+            Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  format %{ \"insertL_128b $dst, $src, $val, $idx\\t# 2L\" %}\n+  ins_encode %{\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, __ T16B, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ mov($dst$$FloatRegister, __ D, (int)($idx$$constant), $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertL_gt128b(vReg dst, vReg src, iRegL val, immI idx,\n+                        vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16 &&\n+            Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"insertL_gt128b $dst, $src, $val, $idx\\t# vector > 128 bits. KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($tmp$$FloatRegister, __ D, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ D, ptrue,\n+               $tmp$$FloatRegister, (int)($idx$$constant) - 16);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ sve_cpy($dst$$FloatRegister, __ D, $pgtmp$$PRegister, $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ FLOAT\n+\n+instruct insertF_le128b(vReg dst, vReg src, vRegF val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"insertF_le128b $dst, $src, $val, $idx\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ ins($dst$$FloatRegister, __ S, $val$$FloatRegister, (int)($idx$$constant), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertF_index_lt32(vReg dst, vReg src, vRegF val, immI idx,\n+                            pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() < 32 &&\n+            Matcher::vector_length_in_bytes(n) > 16 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pgtmp, KILL cr);\n+  format %{ \"insertF_index_lt32 $dst, $src, $val, $idx\\t# vector > 128 bits, index < 32. KILL $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($dst$$FloatRegister, __ S, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ S, ptrue,\n+               $dst$$FloatRegister, (int)($idx$$constant) - 16);\n+    __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    __ sve_cpy($dst$$FloatRegister, __ S, $pgtmp$$PRegister, $val$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertF_index_ge32(vReg dst, vReg src, vRegF val, immI idx, vReg tmp,\n+                            pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() >= 32 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"insertF_index_ge32 $dst, $src, $val, $idx\\t# index >= 32. KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($tmp$$FloatRegister, __ S, 0, 1);\n+    __ sve_dup($dst$$FloatRegister, __ S, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ S, ptrue,\n+               $tmp$$FloatRegister, $dst$$FloatRegister);\n+    __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    __ sve_cpy($dst$$FloatRegister, __ S, $pgtmp$$PRegister, $val$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ DOUBLE\n+\n+instruct insertD_128b(vReg dst, vReg src, vRegD val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16 &&\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"insertD_128b $dst, $src, $val, $idx\\t# 2D\" %}\n+  ins_encode %{\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, __ T16B, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ ins($dst$$FloatRegister, __ D, $val$$FloatRegister, (int)($idx$$constant), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertD_gt128b(vReg dst, vReg src, vRegD val, immI idx,\n+                        pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16 &&\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pgtmp, KILL cr);\n+  format %{ \"insertD_gt128b $dst, $src, $val, $idx\\t# vector > 128 bits. KILL $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($dst$$FloatRegister, __ D, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ D, ptrue,\n+               $dst$$FloatRegister, (int)($idx$$constant) - 16);\n+    __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    __ sve_cpy($dst$$FloatRegister, __ D, $pgtmp$$PRegister, $val$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Extract --------------------------------------\n+\/\/ BYTE\n+\n+instruct extractB_index_lt16(iRegINoSp dst, vReg src, immI idx) %{\n+  predicate(n->in(2)->get_int() < 16);\n+  match(Set dst (ExtractB src idx));\n+  format %{ \"extractB_index_lt16 $dst, $src, $idx\\t# index < 16\" %}\n+  ins_encode %{\n+    __ smov($dst$$Register, $src$$FloatRegister, __ B, (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractB_index_ge16(iRegINoSp dst, vReg src, immI idx, vReg tmp) %{\n+  predicate(n->in(2)->get_int() >= 16);\n+  match(Set dst (ExtractB src idx));\n+  effect(TEMP tmp);\n+  format %{ \"extractB_index_ge16 $dst, $src, $idx\\t# index >=16. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_extract_integral($dst$$Register, T_BYTE, $src$$FloatRegister,\n+                            (int)($idx$$constant), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ SHORT\n+\n+instruct extractS_index_lt8(iRegINoSp dst, vReg src, immI idx) %{\n+  predicate(n->in(2)->get_int() < 8);\n+  match(Set dst (ExtractS src idx));\n+  format %{ \"extractS_index_lt8 $dst, $src, $idx\\t# index < 8\" %}\n+  ins_encode %{\n+    __ smov($dst$$Register, $src$$FloatRegister, __ H, (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractS_index_ge8(iRegINoSp dst, vReg src, immI idx, vReg tmp) %{\n+  predicate(n->in(2)->get_int() >= 8);\n+  match(Set dst (ExtractS src idx));\n+  effect(TEMP tmp);\n+  format %{ \"extractS_index_ge8 $dst, $src, $idx\\t# index >=8. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_extract_integral($dst$$Register, T_SHORT, $src$$FloatRegister,\n+                            (int)($idx$$constant), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ INT\n+\n+instruct extractI_index_lt4(iRegINoSp dst, vReg src, immI idx) %{\n+  predicate(n->in(2)->get_int() < 4);\n+  match(Set dst (ExtractI src idx));\n+  format %{ \"extractI_index_lt4 $dst, $src, $idx\\t# index < 4\" %}\n+  ins_encode %{\n+    __ umov($dst$$Register, $src$$FloatRegister, __ S, (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractI_index_ge4(iRegINoSp dst, vReg src, immI idx, vReg tmp) %{\n+  predicate(n->in(2)->get_int() >= 4);\n+  match(Set dst (ExtractI src idx));\n+  effect(TEMP tmp);\n+  format %{ \"extractI_index_ge4 $dst, $src, $idx\\t# index >=4. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_extract_integral($dst$$Register, T_INT, $src$$FloatRegister,\n+                            (int)($idx$$constant), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ LONG\n+\n+instruct extractL_index_lt2(iRegLNoSp dst, vReg src, immI idx) %{\n+  predicate(n->in(2)->get_int() < 2);\n+  match(Set dst (ExtractL src idx));\n+  format %{ \"extractL_index_lt2 $dst, $src, $idx\\t# index < 2\" %}\n+  ins_encode %{\n+    __ umov($dst$$Register, $src$$FloatRegister, __ D, (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct extractL_index_ge2(iRegLNoSp dst, vReg src, immI idx, vReg tmp) %{\n+  predicate(n->in(2)->get_int() >= 2);\n+  match(Set dst (ExtractL src idx));\n+  effect(TEMP tmp);\n+  format %{ \"extractL_index_ge2 $dst, $src, $idx\\t# index >=2. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_extract_integral($dst$$Register, T_LONG, $src$$FloatRegister,\n+                            (int)($idx$$constant), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ FLOAT\n+\n+instruct extractF(vRegF dst, vReg src, immI idx) %{\n+  match(Set dst (ExtractF src idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"extractF $dst, $src, $idx\" %}\n+  ins_encode %{\n+    int index = (int)$idx$$constant;\n+    if (index == 0) {\n+      __ fmovs($dst$$FloatRegister, $src$$FloatRegister);\n+    } else if (index < 4) {\n+      __ ins($dst$$FloatRegister, __ S, $src$$FloatRegister, 0, index);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+      __ sve_ext($dst$$FloatRegister, $dst$$FloatRegister, index << 2);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ DOUBLE\n+\n+instruct extractD(vRegD dst, vReg src, immI idx) %{\n+  match(Set dst (ExtractD src idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"extractD $dst, $src, $idx\" %}\n+  ins_encode %{\n+    int index = (int)$idx$$constant;\n+    if (index == 0) {\n+      __ fmovd($dst$$FloatRegister, $src$$FloatRegister);\n+    } else if (index < 2) {\n+      __ ins($dst$$FloatRegister, __ D, $src$$FloatRegister, 0, index);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+      __ sve_ext($dst$$FloatRegister, $dst$$FloatRegister, index << 3);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask loat\/store -----------------------\n+\n+\/\/ vector load mask\n+\n+instruct vloadmask_neon(vReg dst, vReg src) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_length_in_bytes(n) == 8 ||\n+             Matcher::vector_length_in_bytes(n) == 16));\n+  match(Set dst (VectorLoadMask src ));\n+  format %{ \"vloadmask_neon $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (bt == T_BYTE) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src$$FloatRegister);\n+    } else {\n+      __ uxtl($dst$$FloatRegister, __ T8H, $src$$FloatRegister, __ T8B);\n+      if (type2aelembytes(bt) >= 4) {\n+        __ uxtl($dst$$FloatRegister, __ T4S, $dst$$FloatRegister, __ T4H);\n+      }\n+      if (type2aelembytes(bt) == 8) {\n+        __ uxtl($dst$$FloatRegister, __ T2D, $dst$$FloatRegister, __ T2S);\n+      }\n+      __ negr($dst$$FloatRegister, get_arrangement(this), $dst$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskB_sve(pRegGov dst, vReg src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            Matcher::vector_element_basic_type(n) == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  effect(KILL cr);\n+  format %{ \"vloadmaskB_sve $dst, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ B,\n+               ptrue, $src$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_extend_sve(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            Matcher::vector_element_basic_type(n) != T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_extend_sve $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_vector_extend($tmp$$FloatRegister, size, $src$$FloatRegister, __ B);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size, ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskB_masked(pRegGov dst, vReg src, pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(KILL cr);\n+  format %{ \"vloadmaskB_masked $dst, $pg, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ B,\n+               $pg$$PRegister, $src$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_extend_masked(pRegGov dst, vReg src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) != T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_extend_masked $dst, $pg, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_vector_extend($tmp$$FloatRegister, size, $src$$FloatRegister, __ B);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size,\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask - neon\n+\n+instruct vstoremaskB_neon(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorStoreMask src size));\n+  format %{ \"vstoremaskB_neon $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_narrow_neon(vReg dst, vReg src, immI_gt_1 size) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorStoreMask src size));\n+  format %{ \"vstoremask_narrow_neon $dst, $src\" %}\n+  ins_encode %{\n+    int esize = (int)$size$$constant;\n+    if (esize == 2) {\n+      __ xtn($dst$$FloatRegister, __ T8B, $src$$FloatRegister, __ T8H);\n+    } else if (esize == 4) {\n+      __ xtn($dst$$FloatRegister, __ T4H, $src$$FloatRegister, __ T4S);\n+      __ xtn($dst$$FloatRegister, __ T8B, $dst$$FloatRegister, __ T8H);\n+    } else {\n+      assert(esize == 8, \"must be\");\n+      __ xtn($dst$$FloatRegister, __ T2S, $src$$FloatRegister, __ T2D);\n+      __ xtn($dst$$FloatRegister, __ T4H, $dst$$FloatRegister, __ T4S);\n+      __ xtn($dst$$FloatRegister, __ T8B, $dst$$FloatRegister, __ T8H);\n+    }\n+    __ negr($dst$$FloatRegister, __ T8B, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask - sve\n+\n+instruct vstoremaskB_sve(vReg dst, pRegGov src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  format %{ \"vstoremaskB_sve $dst, $src\" %}\n+  ins_encode %{\n+    __ sve_cpy($dst$$FloatRegister, __ B, $src$$PRegister, 1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_narrow_sve(vReg dst, pRegGov src, immI_gt_1 size, vReg tmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vstoremask_narrow_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant((int)$size$$constant);\n+    __ sve_cpy($dst$$FloatRegister, size, $src$$PRegister, 1, false);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ B,\n+                         $dst$$FloatRegister, size, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Combined rules for vector mask load when the vector element type is not T_BYTE\n+\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadV $dst, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadV_masked(pRegGov dst, indirect mem, pRegGov pg,\n+                                vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem) pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadV_masked $dst, $pg, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          $pg$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadVMasked(pRegGov dst, vmemA mem, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg)));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadVMasked $dst, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the full-sized predicate (ptrue) used in VectorLoadMask.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadVMasked_masked(pRegGov dst, vmemA mem, pRegGov pg1, pRegGov pg2,\n+                                      vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg1) pg2));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadVMasked_masked $dst, $pg2, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg1\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the \"pg2\" used in VectorLoadMask.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          $pg2$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               $pg2$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Combined rules for vector mask store when the vector element type is not T_BYTE\n+\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeV_vstoremask(indirect mem, pRegGov src, immI_gt_1 esize, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  format %{ \"storeV_vstoremask $mem, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(bt) == (int)$esize$$constant, \"unsupported type\");\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is less than the MaxVectorSize.\n+instruct storeV_vstoremask_masked(indirect mem, pRegGov src, immI_gt_1 esize,\n+                                  vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"storeV_vstoremask_masked $mem, $src\\t# KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    __ sve_gen_mask_imm($pgtmp$$PRegister, bt, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          $pgtmp$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeVMasked_vstoremask(vmemA mem, pRegGov src, pRegGov pg, immI_gt_1 esize, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP tmp);\n+  format %{ \"storeVMasked_vstoremask $mem, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector store with boolean type. But the predicate used in\n+    \/\/ the narrowing \"sve_st1b\" is based on the \"src\" vector type, which\n+    \/\/ is the full-sized predicate (ptrue) here.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is less than the MaxVectorSize.\n+instruct storeVMasked_vstoremask_masked(vmemA mem, pRegGov src, pRegGov pg, immI_gt_1 esize,\n+                                        vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"storeVMasked_vstoremask_masked $mem, $src\\t# KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used for the\n+    \/\/ vector store with boolean type. But the predicate used in the narrowing\n+    \/\/ \"sve_st1b\" is based on the \"src\" vector type, which needed to be generated\n+    \/\/ here.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    __ sve_gen_mask_imm($pgtmp$$PRegister, bt, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          $pgtmp$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask basic OPs ------------------------\n+\n+\/\/ vector mask logical ops: and\/or\/xor\/and_not\n+\n+instruct vmask_and(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn pm));\n+  format %{ \"vmask_and $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ sve_and($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_or(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (OrVMask pn pm));\n+  format %{ \"vmask_or $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ sve_orr($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_xor(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (XorVMask pn pm));\n+  format %{ \"vmask_xor $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ sve_eor($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_and_notI(pRegGov pd, pRegGov pn, pRegGov pm, immI_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn (XorVMask pm (MaskAll m1))));\n+  format %{ \"vmask_and_notI $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ sve_bic($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_and_notL(pRegGov pd, pRegGov pn, pRegGov pm, immL_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn (XorVMask pm (MaskAll m1))));\n+  format %{ \"vmask_and_notL $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ sve_bic($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp_neon(vReg dst, vReg src1, vReg src2, immI cond) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_length_in_bytes(n) == 8 ||\n+             Matcher::vector_length_in_bytes(n) == 16));\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  format %{ \"vmaskcmp_neon $dst, $src1, $src2, $cond\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ neon_compare($dst$$FloatRegister, bt, $src1$$FloatRegister,\n+                    $src2$$FloatRegister, (int)($cond$$constant),\n+                    \/* isQ *\/ length_in_bytes == 16);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcmp_sve(pRegGov dst, vReg src1, vReg src2, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(KILL cr);\n+  format %{ \"vmaskcmp_sve $dst, $src1, $src2, $cond\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_compare($dst$$PRegister, bt, ptrue, $src1$$FloatRegister,\n+                   $src2$$FloatRegister, (int)($cond$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcmp_masked(pRegGov dst, vReg src1, vReg src2, immI cond,\n+                         pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond pg)));\n+  effect(KILL cr);\n+  format %{ \"vmaskcmp_masked $dst, $pg, $src1, $src2, $cond\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_compare($dst$$PRegister, bt, $pg$$PRegister, $src1$$FloatRegister,\n+                   $src2$$FloatRegister, (int)($cond$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask cast\n+\n+instruct vmaskcast_same_esize_neon(vReg dst_src) %{\n+  predicate(UseSVE == 0 &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)) &&\n+            (Matcher::vector_length_in_bytes(n) == 8 || Matcher::vector_length_in_bytes(n) == 16));\n+  match(Set dst_src (VectorMaskCast dst_src));\n+  ins_cost(0);\n+  format %{ \"vmaskcast_same_esize_neon $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmaskcast_same_esize_sve(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst_src (VectorMaskCast dst_src));\n+  ins_cost(0);\n+  format %{ \"vmaskcast_same_esize_sve $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmaskcast_extend(pRegGov dst, pReg src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n) > Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst (VectorMaskCast src));\n+  format %{ \"vmaskcast_extend $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes_dst == 2 * length_in_bytes_src ||\n+           length_in_bytes_dst == 4 * length_in_bytes_src ||\n+           length_in_bytes_dst == 8 * length_in_bytes_src, \"invalid vector length\");\n+    __ sve_vmaskcast_extend($dst$$PRegister, $src$$PRegister,\n+                            length_in_bytes_dst, length_in_bytes_src);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcast_narrow(pRegGov dst, pReg src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n) < Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst (VectorMaskCast src));\n+  format %{ \"vmaskcast_narrow $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes_dst * 2 == length_in_bytes_src ||\n+           length_in_bytes_dst * 4 == length_in_bytes_src ||\n+           length_in_bytes_dst * 8 == length_in_bytes_src, \"invalid vector length\");\n+    __ sve_vmaskcast_narrow($dst$$PRegister, $src$$PRegister,\n+                            length_in_bytes_dst, length_in_bytes_src);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask reinterpret\n+\n+instruct vmask_reinterpret_same_esize(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length(n) == Matcher::vector_length(n->in(1)) &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst_src (VectorReinterpret dst_src));\n+  ins_cost(0);\n+  format %{ \"vmask_reinterpret_same_esize $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmask_reinterpret_diff_esize(pRegGov dst, pRegGov src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length(n) != Matcher::vector_length(n->in(1)) &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmask_reinterpret_diff_esize $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType from_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant from_size = __ elemType_to_regVariant(from_bt);\n+    BasicType to_bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_size = __ elemType_to_regVariant(to_bt);\n+    __ sve_cpy($tmp$$FloatRegister, from_size, $src$$PRegister, -1, false);\n+    __ sve_cmp(Assembler::EQ, $dst$$PRegister, to_size, ptrue, $tmp$$FloatRegister, -1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask reductions -----------------------\n+\n+\/\/ true count\n+\n+instruct vmask_truecount_neon(iRegINoSp dst, vReg src, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorMaskTrueCount src));\n+  effect(TEMP tmp);\n+  format %{ \"vmask_truecount_neon $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as bytes with\n+    \/\/ 0x00\/0x01 as element values.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ addv($tmp$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $src$$FloatRegister);\n+    __ umov($dst$$Register, $tmp$$FloatRegister, __ B, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_truecount_sve(iRegINoSp dst, pReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskTrueCount src));\n+  format %{ \"vmask_truecount_sve $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_cntp($dst$$Register, __ elemType_to_regVariant(bt),\n+                ptrue, $src$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ first true\n+\n+instruct vmask_firsttrue_lt8e(iRegINoSp dst, vReg src, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 &&\n+            Matcher::vector_length(n->in(1)) < 8);\n+  match(Set dst (VectorMaskFirstTrue src));\n+  effect(KILL cr);\n+  format %{ \"vmask_firsttrue_lt8e $dst, $src\\t# vector < 8 elements (neon). KILL cr\" %}\n+  ins_encode %{\n+    \/\/ Returns the index of the first active lane of the\n+    \/\/ vector mask, or VLENGTH if no lane is active.\n+    \/\/\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+    \/\/\n+    \/\/ Computed by reversing the bits and counting the leading\n+    \/\/ zero bytes.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    __ fmovd($dst$$Register, $src$$FloatRegister);\n+    __ rbit($dst$$Register, $dst$$Register);\n+    __ clz($dst$$Register, $dst$$Register);\n+    __ lsrw($dst$$Register, $dst$$Register, 3);\n+    __ movw(rscratch1, Matcher::vector_length(this, $src));\n+    __ cmpw($dst$$Register, rscratch1);\n+    __ cselw($dst$$Register, rscratch1, $dst$$Register, Assembler::GE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_8or16e(iRegINoSp dst, vReg src) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_length(n->in(1)) == 8 || Matcher::vector_length(n->in(1)) == 16));\n+  match(Set dst (VectorMaskFirstTrue src));\n+  format %{ \"vmask_firsttrue_8or16e $dst, $src\\t# vector 8B\/16B (neon)\" %}\n+  ins_encode %{\n+    \/\/ Returns the index of the first active lane of the\n+    \/\/ vector mask, or VLENGTH if no lane is active.\n+    \/\/\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+    \/\/\n+    \/\/ Computed by reversing the bits and counting the leading\n+    \/\/ zero bytes.\n+\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    if (length_in_bytes == 8) {\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ rbit($dst$$Register, $dst$$Register);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ lsrw($dst$$Register, $dst$$Register, 3);\n+    } else {\n+      assert(length_in_bytes == 16, \"must be\");\n+      Label FIRST_TRUE_INDEX;\n+\n+      \/\/ Try to compute the result from lower 64 bits.\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, zr);\n+      __ cbnz($dst$$Register, FIRST_TRUE_INDEX);\n+\n+      \/\/ Compute the result from the higher 64 bits.\n+      __ fmovhid($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, 8);\n+\n+      \/\/ Reverse the bits and count the leading zero bytes.\n+      __ bind(FIRST_TRUE_INDEX);\n+      __ rbit($dst$$Register, $dst$$Register);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ addw($dst$$Register, rscratch1, $dst$$Register, Assembler::LSR, 3);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Return the index of the first mask lane that is set, or vector length if none of\n+\/\/ them are set.\n+\n+instruct vmask_firsttrue_sve(iRegINoSp dst, pReg src, pReg ptmp) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n+  match(Set dst (VectorMaskFirstTrue src));\n+  effect(TEMP ptmp);\n+  format %{ \"vmask_firsttrue_sve $dst, $src\\t# KILL $ptmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_brkb($ptmp$$PRegister, ptrue, $src$$PRegister, false);\n+    __ sve_cntp($dst$$Register, __ elemType_to_regVariant(bt), ptrue, $ptmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_masked(iRegINoSp dst, pReg src, pRegGov pg, pReg ptmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskFirstTrue src pg));\n+  effect(TEMP ptmp);\n+  format %{ \"vmask_firsttrue_masked $dst, $pg, $src\\t# KILL $ptmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_brkb($ptmp$$PRegister, $pg$$PRegister, $src$$PRegister, false);\n+    __ sve_cntp($dst$$Register, __ elemType_to_regVariant(bt), ptrue, $ptmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ last true\n+\n+instruct vmask_lasttrue_neon(iRegINoSp dst, vReg src) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorMaskLastTrue src));\n+  format %{ \"vmask_lasttrue_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ Returns the index of the last active lane of the\n+    \/\/ vector mask, or -1 if no lane is active.\n+    \/\/\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    if (length_in_bytes <= 8) {\n+      \/\/ Computed by counting the leading zero bytes and\n+      \/\/ subtracting it by 7 (VLENGTH - 1).\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ movw(rscratch1, 7);\n+      __ subw($dst$$Register, rscratch1, $dst$$Register, Assembler::LSR, 3);\n+    } else {\n+      assert(length_in_bytes == 16, \"must be\");\n+      Label LAST_TRUE_INDEX;\n+\n+      \/\/ Try to compute the result from higher 64 bits.\n+      __ fmovhid($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, 16 - 1);\n+      __ cbnz($dst$$Register, LAST_TRUE_INDEX);\n+\n+      \/\/ Compute the result from the lower 64 bits.\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, 8 - 1);\n+\n+      \/\/ Count the leading zero bytes and subtract it by 15 (VLENGTH - 1).\n+      __ bind(LAST_TRUE_INDEX);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ subw($dst$$Register, rscratch1, $dst$$Register, Assembler::LSR, 3);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_lasttrue_sve(iRegINoSp dst, pReg src, pReg ptmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskLastTrue src));\n+  effect(TEMP ptmp);\n+  format %{ \"vmask_lasttrue_sve $dst, $src\\t# KILL $ptmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_vmask_lasttrue($dst$$Register, bt, $src$$PRegister, $ptmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ tolong\n+\n+instruct vmask_tolong_neon(iRegLNoSp dst, vReg src) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorMaskToLong src));\n+  format %{ \"vmask_tolong_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    if (length_in_bytes <= 8) {\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ bytemask_compress($dst$$Register);\n+    } else {\n+      assert(length_in_bytes == 16, \"must be\");\n+      __ umov($dst$$Register, $src$$FloatRegister, __ D, 0);\n+      __ umov(rscratch1, $src$$FloatRegister, __ D, 1);\n+      __ bytemask_compress($dst$$Register);\n+      __ bytemask_compress(rscratch1);\n+      __ orr($dst$$Register, $dst$$Register, rscratch1, Assembler::LSL, 8);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_tolong_sve(iRegLNoSp dst, pReg src, vReg tmp1, vReg tmp2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskToLong src));\n+  effect(TEMP tmp1, TEMP tmp2);\n+  format %{ \"vmask_tolong_sve $dst, $src\\t# KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    __ sve_vmask_tolong($dst$$Register, $src$$PRegister,\n+                        Matcher::vector_element_basic_type(this, $src),\n+                        Matcher::vector_length(this, $src),\n+                        $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ fromlong\n+\n+instruct vmask_fromlong(pRegGov dst, iRegL src, vReg tmp1, vReg tmp2) %{\n+  match(Set dst (VectorLongToMask src));\n+  effect(TEMP tmp1, TEMP tmp2);\n+  format %{ \"vmask_fromlong $dst, $src\\t# vector (sve2). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    __ sve_vmask_fromlong($dst$$PRegister, $src$$Register,\n+                          Matcher::vector_element_basic_type(this),\n+                          Matcher::vector_length(this),\n+                          $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask generation -----------------------\n+\n+\/\/ maskAll\n+\n+instruct vmaskAll_immI(pRegGov dst, immI src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  effect(KILL cr);\n+  format %{ \"vmaskAll_immI $dst, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    int con = (int)$src$$constant;\n+    if (con == 0) {\n+      __ sve_pfalse($dst$$PRegister);\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_gen_mask_imm($dst$$PRegister, bt, Matcher::vector_length(this));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllI(pRegGov dst, iRegIorL2I src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmaskAllI $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_dup($tmp$$FloatRegister, size, $src$$Register);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size, ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllI_masked(pRegGov dst, iRegIorL2I src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmaskAllI_masked $dst, $pg, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup($tmp$$FloatRegister, size, $src$$Register);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size,\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAll_immL(pRegGov dst, immL src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  effect(KILL cr);\n+  format %{ \"vmaskAll_immL $dst, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    long con = (long)$src$$constant;\n+    if (con == 0) {\n+      __ sve_pfalse($dst$$PRegister);\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_gen_mask_imm($dst$$PRegister, bt, Matcher::vector_length(this));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllL(pRegGov dst, iRegL src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmaskAllL $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_dup($tmp$$FloatRegister, size, $src$$Register);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size, ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskAllL_masked(pRegGov dst, iRegL src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmaskAllL_masked $dst, $pg, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup($tmp$$FloatRegister, size, $src$$Register);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size,\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vetcor mask generation\n+\n+instruct vmask_gen_I(pRegGov pd, iRegIorL2I src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen (ConvI2L src)));\n+  effect(KILL cr);\n+  format %{ \"vmask_gen_I $pd, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whilelow($pd$$PRegister, __ elemType_to_regVariant(bt), zr, $src$$Register);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct vmask_gen_L(pRegGov pd, iRegL src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen src));\n+  effect(KILL cr);\n+  format %{ \"vmask_gen_L $pd, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whilelo($pd$$PRegister, __ elemType_to_regVariant(bt), zr, $src$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_gen_imm(pRegGov pd, immL con, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen con));\n+  effect(KILL cr);\n+  format %{ \"vmask_gen_imm $pd, $con\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_gen_mask_imm($pd$$PRegister, bt, (uint)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Popcount vector ------------------------------\n+\n+\/\/ vector popcount - INT\n+\n+instruct vpopcountI(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (PopCountVI src));\n+  format %{ \"vpopcountI $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ cnt($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+               $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_cnt($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+      }\n+    } else {\n+      assert(bt == T_SHORT || bt == T_INT, \"unsupported\");\n+      if (UseSVE == 0) {\n+        assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+        __ cnt($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+               $src$$FloatRegister);\n+        __ uaddlp($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                  $dst$$FloatRegister);\n+        if (bt == T_INT) {\n+          __ uaddlp($dst$$FloatRegister, length_in_bytes == 16 ? __ T8H : __ T4H,\n+                    $dst$$FloatRegister);\n+        }\n+      } else {\n+        __ sve_cnt($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                   ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector popcount - LONG\n+\n+instruct vpopcountL(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG &&\n+            !n->as_Vector()->is_predicated_vector());\n+  match(Set dst (PopCountVL src));\n+  format %{ \"vpopcountL $dst, $src\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      __ cnt($dst$$FloatRegister, __ T16B, $src$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T16B, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T8H, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T4S, $dst$$FloatRegister);\n+    } else {\n+      __ sve_cnt($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ If the PopCountVL is generated by auto-vectorization, the dst basic\n+\/\/ type is T_INT. And once we have unified the type definition for\n+\/\/ Vector API and auto-vectorization, this rule can be merged with\n+\/\/ \"vpopcountL\" rule.\n+\n+instruct vpopcountL_I(vReg dst, vReg src, vReg tmp) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_INT &&\n+            !n->as_Vector()->is_predicated_vector());\n+  match(Set dst (PopCountVL src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vpopcountL_I $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      __ cnt($dst$$FloatRegister, __ T16B, $src$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T16B, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T8H, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T4S, $dst$$FloatRegister);\n+      __ xtn($dst$$FloatRegister, __ T2S, $dst$$FloatRegister, __ T2D);\n+    } else {\n+      __ sve_cnt($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+      __ sve_vector_narrow($dst$$FloatRegister, __ S,\n+                           $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector popcount - predicated\n+\n+instruct vpopcountI_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (PopCountVI dst_src pg));\n+  format %{ \"vpopcountI_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_cnt($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vpopcountL_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst_src (PopCountVL dst_src pg));\n+  format %{ \"vpopcountL_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_cnt($dst_src$$FloatRegister, __ D,\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector blend ---------------------------------\n+\n+instruct vblend_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) dst));\n+  format %{ \"vblend_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ bsl($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+           $src2$$FloatRegister, $src1$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vblend_sve(vReg dst, vReg src1, vReg src2, pReg pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) pg));\n+  format %{ \"vblend_sve $dst, $pg, $src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_sel($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister, $src1$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector round ---------------------------------\n+\n+\/\/ vector Math.round\n+\n+instruct vround_le128b(vReg dst, vReg src, vReg tmp1, vReg tmp2,\n+                       vReg tmp3, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (RoundVF src));\n+  match(Set dst (RoundVD src));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);\n+  format %{ \"vround_le128b $dst, $src\\t# vector <= 128 bits. KILL $tmp1, $tmp2, $tmp3, cr\" %}\n+  ins_encode %{\n+    __ vector_round_neon($dst$$FloatRegister, $src$$FloatRegister,\n+                         $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                         $tmp3$$FloatRegister, get_arrangement(this));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vround_gt128b(vReg dst, vReg src, vReg tmp1, vReg tmp2,\n+                       pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (RoundVF src));\n+  match(Set dst (RoundVD src));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp, KILL cr);\n+  format %{ \"vround_gt128b $dst, $src\\t# vector > 128 bits. KILL $tmp1, $tmp2, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ vector_round_sve($dst$$FloatRegister, $src$$FloatRegister,\n+                        $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                        $pgtmp$$PRegister, __ elemType_to_regVariant(bt));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ RoundDouble ----------------------------------\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"vroundD $dst, $src, $rmode\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      switch ($rmode$$constant) {\n+        case RoundDoubleModeNode::rmode_rint:\n+          __ frintn($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_floor:\n+          __ frintm($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_ceil:\n+          __ frintp($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+          break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      switch ($rmode$$constant) {\n+        case RoundDoubleModeNode::rmode_rint:\n+          __ sve_frintn($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_floor:\n+          __ sve_frintm($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_ceil:\n+          __ sve_frintp($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+          break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ VectorTest -----------------------------------\n+\n+\/\/ anytrue\n+\n+instruct vtest_anytrue_neon(iRegINoSp dst, vReg src1, vReg src2, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2 ));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vtest_anytrue_neon $dst, $src1\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ No need to use src2.\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src1);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ addv($tmp$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B, $src1$$FloatRegister);\n+    __ umov($dst$$Register, $tmp$$FloatRegister, __ B, 0);\n+    __ cmpw($dst$$Register, zr);\n+    __ csetw($dst$$Register, Assembler::NE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_anytrue_sve(iRegINoSp dst, pRegGov src1, pRegGov src2, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(KILL cr);\n+  format %{ \"vtest_anytrue_sve $dst, $src1\\t# KILL cr\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    __ sve_ptest(ptrue, $src1$$PRegister);\n+    __ csetw($dst$$Register, Assembler::NE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ alltrue\n+\n+instruct vtest_alltrue_neon(iRegINoSp dst, vReg src1, vReg src2, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vtest_alltrue_neon $dst, $src1\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ No need to use src2.\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src1);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ uminv($tmp$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B, $src1$$FloatRegister);\n+    __ umov($dst$$Register, $tmp$$FloatRegister, __ B, 0);\n+    __ cmpw($dst$$Register, 0xff);\n+    __ csetw($dst$$Register, Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_alltrue_sve(iRegINoSp dst, pRegGov src1, pRegGov src2, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"vtest_alltrue_sve $dst, $src1, $src2\\t# KILL $ptmp, cr\" %}\n+  ins_encode %{\n+    __ sve_eors($ptmp$$PRegister, ptrue, $src1$$PRegister, $src2$$PRegister);\n+    __ csetw($dst$$Register, Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+\n+instruct loadshuffle(vReg dst, vReg src) %{\n+  match(Set dst (VectorLoadShuffle src));\n+  format %{ \"loadshuffle $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if ($dst$$FloatRegister != $src$$FloatRegister) {\n+        if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+          __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        } else {\n+          assert(UseSVE > 0, \"must be sve\");\n+          __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+      }\n+    } else {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 4S\/8S, 4I, 4F\n+        __ uxtl($dst$$FloatRegister, __ T8H, $src$$FloatRegister, __ T8B);\n+        if (type2aelembytes(bt) == 4) {\n+          __ uxtl($dst$$FloatRegister, __ T4S, $dst$$FloatRegister, __ T4H);\n+        }\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister,  __ elemType_to_regVariant(bt),\n+                             $src$$FloatRegister, __ B);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector rearrange -----------------------------\n+\n+\/\/ Here is an example that rearranges a NEON vector with 4 ints:\n+\/\/ Rearrange V1 int[a0, a1, a2, a3] to V2 int[a2, a3, a0, a1]\n+\/\/   1. Get the indices of V1 and store them as Vi byte[0, 1, 2, 3].\n+\/\/   2. Convert Vi byte[0, 1, 2, 3] to the indices of V2 and also store them as Vi byte[2, 3, 0, 1].\n+\/\/   3. Unsigned extend Long Vi from byte[2, 3, 0, 1] to int[2, 3, 0, 1].\n+\/\/   4. Multiply Vi int[2, 3, 0, 1] with constant int[0x04040404, 0x04040404, 0x04040404, 0x04040404]\n+\/\/      and get tbl base Vm int[0x08080808, 0x0c0c0c0c, 0x00000000, 0x04040404].\n+\/\/   5. Add Vm with constant int[0x03020100, 0x03020100, 0x03020100, 0x03020100]\n+\/\/      and get tbl index Vm int[0x0b0a0908, 0x0f0e0d0c, 0x03020100, 0x07060504]\n+\/\/   6. Use Vm as index register, and use V1 as table register.\n+\/\/      Then get V2 as the result by tbl NEON instructions.\n+\/\/ Notes:\n+\/\/   Step 1 matches VectorLoadConst.\n+\/\/   Step 3 matches VectorLoadShuffle.\n+\/\/   Step 4, 5, 6 match VectorRearrange.\n+\/\/   For VectorRearrange short\/int, the reason why such complex calculation is\n+\/\/   required is because NEON tbl supports bytes table only, so for short\/int, we\n+\/\/   need to lookup 2\/4 bytes as a group. For VectorRearrange long, we use bsl\n+\/\/   to implement rearrange.\n+\n+instruct rearrange_HS_neon(vReg dst, vReg src, vReg shuffle, vReg tmp1, vReg tmp2) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             (type2aelembytes(Matcher::vector_element_basic_type(n)) == 4 &&\n+              Matcher::vector_length_in_bytes(n) == 16)));\n+  match(Set dst (VectorRearrange src shuffle));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"rearrange_HS_neon $dst, $src, $shuffle\\t# vector (4S\/8S\/4I\/4F). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (bt == T_SHORT) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+      Assembler::SIMD_Arrangement size1 = length_in_bytes == 16 ? __ T16B : __ T8B;\n+      Assembler::SIMD_Arrangement size2 = length_in_bytes == 16 ? __ T8H : __ T4H;\n+      __ mov($tmp1$$FloatRegister, size1, 0x02);\n+      __ mov($tmp2$$FloatRegister, size2, 0x0100);\n+      __ mulv($dst$$FloatRegister, size2, $shuffle$$FloatRegister, $tmp1$$FloatRegister);\n+      __ addv($dst$$FloatRegister, size1, $dst$$FloatRegister, $tmp2$$FloatRegister);\n+      __ tbl($dst$$FloatRegister, size1, $src$$FloatRegister, 1, $dst$$FloatRegister);\n+    } else {\n+      assert(bt == T_INT || bt == T_FLOAT, \"unsupported type\");\n+      __ mov($tmp1$$FloatRegister, __ T16B, 0x04);\n+      __ mov($tmp2$$FloatRegister, __ T4S, 0x03020100);\n+      __ mulv($dst$$FloatRegister, __ T4S, $shuffle$$FloatRegister, $tmp1$$FloatRegister);\n+      __ addv($dst$$FloatRegister, __ T16B, $dst$$FloatRegister, $tmp2$$FloatRegister);\n+      __ tbl($dst$$FloatRegister, __ T16B, $src$$FloatRegister, 1, $dst$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct rearrange(vReg dst, vReg src, vReg shuffle) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE || UseSVE > 0);\n+  match(Set dst (VectorRearrange src shuffle));\n+  format %{ \"rearrange $dst, $src, $shuffle\" %}\n+  ins_encode %{\n+    BasicType bt_dst = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt_dst == T_BYTE && VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ tbl($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src$$FloatRegister, 1, $shuffle$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt_src = Matcher::vector_element_basic_type(this, $src);\n+      __ sve_tbl($dst$$FloatRegister, __ elemType_to_regVariant(bt_src),\n+                 $src$$FloatRegister, $shuffle$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather ---------------------------\n+\n+instruct gather_loadS(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+  match(Set dst (LoadVectorGather mem idx));\n+  format %{ \"gather_loadS $dst, $mem, $idx\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_ld1w_gather($dst$$FloatRegister, ptrue,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+ %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadD(vReg dst, indirect mem, vReg idx, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+  match(Set dst (LoadVectorGather mem idx));\n+  effect(TEMP tmp);\n+  format %{ \"gather_loadD $dst, $mem, $idx\\t# vector (sve). KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_ld1d_gather($dst$$FloatRegister, ptrue, as_Register($mem$$base),\n+                       $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadS_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  format %{ \"gather_loadS_masked $dst, $pg, $mem, $idx\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadD_masked(vReg dst, indirect mem, vReg idx, pRegGov pg, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  effect(TEMP tmp);\n+  format %{ \"gather_loadD_masked $dst, $pg, $mem, $idx\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_ld1d_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter -------------------------\n+\n+instruct scatter_storeS(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 4);\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  format %{ \"scatter_storeS $mem, $idx, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_st1w_scatter($src$$FloatRegister, ptrue,\n+                        as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatter_storeD(indirect mem, vReg src, vReg idx, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 8);\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  effect(TEMP tmp);\n+  format %{ \"scatter_storeD $mem, $idx, $src\\t# vector (sve). KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_st1d_scatter($src$$FloatRegister, ptrue,\n+                        as_Register($mem$$base), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatter_storeS_masked(indirect mem, vReg src, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 4);\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  format %{ \"scatter_storeS_masked $mem, $pg, $idx, $src\" %}\n+  ins_encode %{\n+    __ sve_st1w_scatter($src$$FloatRegister, $pg$$PRegister,\n+                        as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatter_storeD_masked(indirect mem, vReg src, vReg idx, pRegGov pg, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 8);\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  effect(TEMP tmp);\n+  format %{ \"scatter_storeD_masked $mem, $pg, $idx, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_st1d_scatter($src$$FloatRegister, $pg$$PRegister,\n+                        as_Register($mem$$base), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ CountLeadingZerosV ---------------------------\n+\n+instruct vcountLeadingZeros(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (CountLeadingZerosV src));\n+  format %{ \"vcountLeadingZeros $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_LONG) {\n+      if (UseSVE == 0) {\n+        __ umov(rscratch1, $src$$FloatRegister, __ D, 0);\n+        __ clz(rscratch1, rscratch1);\n+        __ mov($dst$$FloatRegister, __ D, 0, rscratch1);\n+        __ umov(rscratch1, $src$$FloatRegister, __ D, 1);\n+        __ clz(rscratch1, rscratch1);\n+        __ mov($dst$$FloatRegister, __ D, 1, rscratch1);\n+      } else {\n+        __ sve_clz($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+      }\n+    } else {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ clz($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_clz($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                   ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+\n+instruct vcountLeadingZeros_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (CountLeadingZerosV dst_src pg));\n+  format %{ \"vcountLeadingZeros_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_clz($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ CountTrailingZerosV --------------------------\n+\n+instruct vcountTrailingZeros(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (CountTrailingZerosV src));\n+  format %{ \"vcountTrailingZeros $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ rbit($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                $src$$FloatRegister);\n+        __ clz($dst$$FloatRegister, get_arrangement(this), $dst$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_rbit($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+        __ sve_clz($dst$$FloatRegister, __ B, ptrue, $dst$$FloatRegister);\n+      }\n+    } else {\n+      assert(bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported type\");\n+      if (UseSVE == 0) {\n+        assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+        __ neon_reverse_bits($dst$$FloatRegister, $src$$FloatRegister,\n+                             bt, \/* isQ *\/ length_in_bytes == 16);\n+        if (bt != T_LONG) {\n+          __ clz($dst$$FloatRegister, get_arrangement(this), $dst$$FloatRegister);\n+        } else {\n+          __ umov(rscratch1, $dst$$FloatRegister, __ D, 0);\n+          __ clz(rscratch1, rscratch1);\n+          __ mov($dst$$FloatRegister, __ D, 0, rscratch1);\n+          __ umov(rscratch1, $dst$$FloatRegister, __ D, 1);\n+          __ clz(rscratch1, rscratch1);\n+          __ mov($dst$$FloatRegister, __ D, 1, rscratch1);\n+        }\n+      } else {\n+        Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+        __ sve_rbit($dst$$FloatRegister, size, ptrue, $src$$FloatRegister);\n+        __ sve_clz($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+instruct vcountTrailingZeros_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (CountTrailingZerosV dst_src pg));\n+  format %{ \"vcountTrailingZeros_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_rbit($dst_src$$FloatRegister, size,\n+                $pg$$PRegister, $dst_src$$FloatRegister);\n+    __ sve_clz($dst_src$$FloatRegister, size,\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ ReverseV -------------------------------------\n+\n+instruct vreverse(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (ReverseV src));\n+  format %{ \"vreverse $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ rbit($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_rbit($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+      }\n+    } else {\n+      assert(bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported type\");\n+      if (UseSVE == 0) {\n+        assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+        __ neon_reverse_bits($dst$$FloatRegister, $src$$FloatRegister,\n+                             bt, \/* isQ *\/ length_in_bytes == 16);\n+      } else {\n+        __ sve_rbit($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                    ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+\n+instruct vreverse_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (ReverseV dst_src pg));\n+  format %{ \"vreverse_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_rbit($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ ReverseBytesV --------------------------------\n+\n+instruct vreverseBytes(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (ReverseBytesV src));\n+  format %{ \"vreverseBytes $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+      if (bt == T_BYTE) {\n+        if ($dst$$FloatRegister != $src$$FloatRegister) {\n+          __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+      } else {\n+        __ neon_reverse_bytes($dst$$FloatRegister, $src$$FloatRegister,\n+                              bt, \/* isQ *\/ length_in_bytes == 16);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      if (bt == T_BYTE) {\n+        if ($dst$$FloatRegister != $src$$FloatRegister) {\n+          __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+      } else {\n+        __ sve_revb($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                    ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+instruct vreverseBytes_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (ReverseBytesV dst_src pg));\n+  format %{ \"vreverseBytes_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (bt == T_BYTE) {\n+      \/\/ do nothing\n+    } else {\n+      __ sve_revb($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $dst_src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Populate Index to a Vector -------------------\n+\n+instruct populateindex(vReg dst, iRegIorL2I src1, immI src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (PopulateIndex src1 src2));\n+  format %{ \"populateindex $dst, $src1, $src2\\t # populate index (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_index($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $src1$$Register, (int)($src2$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Compress\/Expand Operations -------------------\n+\n+instruct mcompress(pReg dst, pReg pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (CompressM pg));\n+  effect(KILL cr);\n+  format %{ \"mcompress $dst, $pg\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cntp(rscratch1, size, ptrue, $pg$$PRegister);\n+    __ sve_whilelo(as_PRegister($dst$$reg), size, zr, rscratch1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcompress(vReg dst, vReg src, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            !is_subword_type(Matcher::vector_element_basic_type(n)));\n+  match(Set dst (CompressV src pg));\n+  format %{ \"vcompress $dst, $src, $pg\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_compact($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                   $src$$FloatRegister, $pg$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcompressB(vReg dst, vReg src, pReg pg, vReg tmp1, vReg tmp2,\n+                    vReg tmp3, vReg tmp4, pReg ptmp, pRegGov pgtmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_BYTE);\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ptmp, TEMP pgtmp);\n+  match(Set dst (CompressV src pg));\n+  format %{ \"vcompressB $dst, $src, $pg\\t# KILL $tmp1, $tmp2, $tmp3, tmp4, $ptmp, $pgtmp\" %}\n+  ins_encode %{\n+    __ sve_compress_byte($dst$$FloatRegister, $src$$FloatRegister, $pg$$PRegister,\n+                         $tmp1$$FloatRegister,$tmp2$$FloatRegister,\n+                         $tmp3$$FloatRegister,$tmp4$$FloatRegister,\n+                         $ptmp$$PRegister, $pgtmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcompressS(vReg dst, vReg src, pReg pg,\n+                    vReg tmp1, vReg tmp2, pRegGov pgtmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_SHORT);\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp);\n+  match(Set dst (CompressV src pg));\n+  format %{ \"vcompressS $dst, $src, $pg\\t# KILL $tmp1, $tmp2, $pgtmp\" %}\n+  ins_encode %{\n+    __ sve_compress_short($dst$$FloatRegister, $src$$FloatRegister, $pg$$PRegister,\n+                          $tmp1$$FloatRegister,$tmp2$$FloatRegister, $pgtmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vexpand(vReg dst, vReg src, pRegGov pg) %{\n+  match(Set dst (ExpandV src pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vexpand $dst, $pg, $src\" %}\n+  ins_encode %{\n+    \/\/ Example input:   src   = 1 2 3 4 5 6 7 8\n+    \/\/                  pg    = 1 0 0 1 1 0 1 1\n+    \/\/ Expected result: dst   = 4 0 0 5 6 0 7 8\n+\n+    \/\/ The basic idea is to use TBL which can shuffle the elements in the given\n+    \/\/ vector flexibly. HISTCNT + SUB is used to generate the second source input\n+    \/\/ for TBL whose value is used to select the indexed element from src vector.\n+\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    assert(UseSVE == 2 && !is_subword_type(bt), \"unsupported\");\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    \/\/ dst = 0 0 0 0 0 0 0 0\n+    __ sve_dup($dst$$FloatRegister, size, 0);\n+    \/\/ dst = 5 0 0 4 3 0 2 1\n+    __ sve_histcnt($dst$$FloatRegister, size, $pg$$PRegister,\n+                   $dst$$FloatRegister, $dst$$FloatRegister);\n+    \/\/ dst = 4 -1 -1 3 2 -1 1 0\n+    __ sve_sub($dst$$FloatRegister, size, 1);\n+    \/\/ dst = 4 0 0 5 6 0 7 8\n+    __ sve_tbl($dst$$FloatRegister, size, $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector.ad","additions":6353,"deletions":0,"binary":false,"changes":6353,"status":"added"},{"patch":"@@ -0,0 +1,4693 @@\n+\/\/\n+\/\/ Copyright (c) 2020, 2022, Oracle and\/or its affiliates. All rights reserved.\n+\/\/ Copyright (c) 2020, 2022, Arm Limited. All rights reserved.\n+\/\/ DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\n+\/\/\n+\/\/ This code is free software; you can redistribute it and\/or modify it\n+\/\/ under the terms of the GNU General Public License version 2 only, as\n+\/\/ published by the Free Software Foundation.\n+\/\/\n+\/\/ This code is distributed in the hope that it will be useful, but WITHOUT\n+\/\/ ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n+\/\/ FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License\n+\/\/ version 2 for more details (a copy is included in the LICENSE file that\n+\/\/ accompanied this code).\n+\/\/\n+\/\/ You should have received a copy of the GNU General Public License version\n+\/\/ 2 along with this work; if not, write to the Free Software Foundation,\n+\/\/ Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.\n+\/\/\n+\/\/ Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA\n+\/\/ or visit www.oracle.com if you need additional information or have any\n+\/\/ questions.\n+\/\/\n+\/\/\n+\n+dnl Generate the warning\n+\/\/ This file is automatically generated by running \"m4 aarch64_vector_ad.m4\". Do not edit!\n+dnl\n+\n+\/\/ AArch64 VECTOR Architecture Description File\n+\n+\n+dnl\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET($1,            $2      )\n+dnl OPERAND_VMEMORYA_IMMEDIATE_OFFSET(imm_type_abbr, imm_type)\n+define(`OPERAND_VMEMORYA_IMMEDIATE_OFFSET', `\n+operand vmemA_imm$1Offset4() %{\n+  \/\/ (esize \/ msize) = 1\n+  predicate(Address::offset_ok_for_sve_immed(n->get_$2(), 4,\n+            Matcher::scalable_vector_reg_size(T_BYTE)));\n+  match(Con$1);\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}')dnl\n+dnl\n+dnl OPERAND_VMEMORYA_INDIRECT_OFFSET($1           )\n+dnl OPERAND_VMEMORYA_INDIRECT_OFFSET(imm_type_abbr)\n+define(`OPERAND_VMEMORYA_INDIRECT_OFFSET', `\n+operand vmemA_indOff$1`'4(iRegP reg, vmemA_imm$1Offset4 off) %{\n+  constraint(ALLOC_IN_RC(ptr_reg));\n+  match(AddP reg off);\n+  op_cost(0);\n+  format %{ \"[$reg, $off]\" %}\n+  interface(MEMORY_INTER) %{\n+    base($reg);\n+    `index'(0xffffffff);\n+    scale(0x0);\n+    disp($off);\n+  %}\n+%}')dnl\n+dnl\n+\/\/ 4 bit signed offset -- for predicated load\/store\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(I, int)\n+OPERAND_VMEMORYA_IMMEDIATE_OFFSET(L, long)\n+OPERAND_VMEMORYA_INDIRECT_OFFSET(I)\n+OPERAND_VMEMORYA_INDIRECT_OFFSET(L)\n+\n+\/\/ The indOff of vmemA is valid only when the vector element (load to\/store from)\n+\/\/ size equals to memory element (load from\/store to) size.\n+opclass vmemA(indirect, vmemA_indOffI4, vmemA_indOffL4);\n+\n+source_hpp %{\n+  \/\/ Assert that the given node is not a variable shift.\n+  bool assert_not_var_shift(const Node* n);\n+\n+  Assembler::SIMD_Arrangement get_arrangement(const Node* n);\n+%}\n+\n+source %{\n+\n+  typedef void (C2_MacroAssembler::* sve_mem_insn_predicate)(FloatRegister Rt, Assembler::SIMD_RegVariant T,\n+                                                             PRegister Pg, const Address &adr);\n+\n+  \/\/ Predicated load\/store, with optional ptrue to all elements of given predicate register.\n+  static void loadStoreA_predicated(C2_MacroAssembler masm, bool is_store, FloatRegister reg,\n+                                    PRegister pg, BasicType mem_elem_bt, BasicType vector_elem_bt,\n+                                    int opcode, Register base, int index, int size, int disp) {\n+    sve_mem_insn_predicate insn;\n+    int mesize = type2aelembytes(mem_elem_bt);\n+    if (index == -1) {\n+      assert(size == 0, \"unsupported address mode: scale size = %d\", size);\n+      switch(mesize) {\n+      case 1:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1b : &C2_MacroAssembler::sve_ld1b;\n+        break;\n+      case 2:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1h : &C2_MacroAssembler::sve_ld1h;\n+        break;\n+      case 4:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1w : &C2_MacroAssembler::sve_ld1w;\n+        break;\n+      case 8:\n+        insn = is_store ? &C2_MacroAssembler::sve_st1d : &C2_MacroAssembler::sve_ld1d;\n+        break;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+      }\n+      int imm4 = disp \/ mesize \/ Matcher::scalable_vector_reg_size(vector_elem_bt);\n+      (masm.*insn)(reg, Assembler::elemType_to_regVariant(vector_elem_bt), pg, Address(base, imm4));\n+    } else {\n+      assert(false, \"unimplemented\");\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  const bool Matcher::match_rule_supported_superword(int opcode, int vlen, BasicType bt) {\n+    if (UseSVE == 0) {\n+      \/\/ ConvD2I and ConvL2F are not profitable to be vectorized on NEON, because no direct\n+      \/\/ NEON instructions support them. But the match rule support for them is profitable for\n+      \/\/ Vector API intrinsics.\n+      if ((opcode == Op_VectorCastD2X && bt == T_INT) ||\n+          (opcode == Op_VectorCastL2X && bt == T_FLOAT)) {\n+        return false;\n+      }\n+    }\n+    return match_rule_supported_vector(opcode, vlen, bt);\n+  }\n+\n+  \/\/ Identify extra cases that we might want to provide match rules for vector nodes and\n+  \/\/ other intrinsics guarded with vector length (vlen) and element type (bt).\n+  const bool Matcher::match_rule_supported_vector(int opcode, int vlen, BasicType bt) {\n+    if (!match_rule_supported(opcode)) {\n+      return false;\n+    }\n+\n+    int length_in_bytes = vlen * type2aelembytes(bt);\n+    if (UseSVE == 0 && length_in_bytes > 16) {\n+      return false;\n+    }\n+\n+    switch (opcode) {\n+      case Op_MulVL:\n+      case Op_AndVMask:\n+      case Op_OrVMask:\n+      case Op_XorVMask:\n+      case Op_MaskAll:\n+      case Op_VectorMaskGen:\n+      case Op_LoadVectorMasked:\n+      case Op_StoreVectorMasked:\n+      case Op_LoadVectorGather:\n+      case Op_StoreVectorScatter:\n+      case Op_LoadVectorGatherMasked:\n+      case Op_StoreVectorScatterMasked:\n+      case Op_PopulateIndex:\n+      case Op_CompressM:\n+      case Op_CompressV:\n+        if (UseSVE == 0) {\n+          return false;\n+        }\n+        break;\n+      case Op_MulAddVS2VI:\n+        return length_in_bytes == 16;\n+      case Op_MulReductionVD:\n+      case Op_MulReductionVF:\n+      case Op_MulReductionVI:\n+      case Op_MulReductionVL:\n+        \/\/ No multiply reduction instructions, and we emit scalar\n+        \/\/ instructions for 64\/128-bit vectors.\n+        return vlen >= 2 && (length_in_bytes == 8 || length_in_bytes == 16);\n+      case Op_VectorMaskCmp:\n+        if (length_in_bytes < 8) {\n+          return false;\n+        }\n+        break;\n+      case Op_VectorLoadShuffle:\n+      case Op_VectorRearrange:\n+        if (vlen < 4) {\n+          return false;\n+        }\n+        break;\n+      case Op_ExpandV:\n+        if (UseSVE < 2 || is_subword_type(bt)) {\n+          return false;\n+        }\n+        break;\n+      case Op_VectorMaskToLong:\n+        if (UseSVE > 0 && vlen > 64) {\n+          return false;\n+        }\n+        break;\n+      case Op_VectorLongToMask:\n+        if (UseSVE < 2 || vlen > 64 || !VM_Version::supports_svebitperm()) {\n+          return false;\n+        }\n+        break;\n+      default:\n+        break;\n+    }\n+    return vector_size_supported(bt, vlen);\n+  }\n+\n+  const bool Matcher::match_rule_supported_vector_masked(int opcode, int vlen, BasicType bt) {\n+    \/\/ Only SVE supports masked operations.\n+    if (UseSVE == 0) {\n+      return false;\n+    }\n+\n+    \/\/ If an opcode does not support the masked version,\n+    \/\/ unpredicated node with VectorBlend node will be used instead.\n+    switch(opcode) {\n+      case Op_VectorRearrange:\n+      case Op_MulReductionVD:\n+      case Op_MulReductionVF:\n+      case Op_MulReductionVI:\n+      case Op_MulReductionVL:\n+        return false;\n+      \/\/ We use Op_LoadVectorMasked to implement the predicated Op_LoadVector.\n+      \/\/ Hence we turn to check whether Op_LoadVectorMasked is supported. The\n+      \/\/ same as vector store\/gather\/scatter.\n+      case Op_LoadVector:\n+        opcode = Op_LoadVectorMasked;\n+        break;\n+      case Op_StoreVector:\n+        opcode = Op_StoreVectorMasked;\n+        break;\n+      case Op_LoadVectorGather:\n+        opcode = Op_LoadVectorGatherMasked;\n+        break;\n+      case Op_StoreVectorScatter:\n+        opcode = Op_StoreVectorScatterMasked;\n+        break;\n+      default:\n+        break;\n+    }\n+\n+    return match_rule_supported_vector(opcode, vlen, bt);\n+  }\n+\n+  const bool Matcher::vector_needs_partial_operations(Node* node, const TypeVect* vt) {\n+    \/\/ Only SVE has partial vector operations\n+    if (UseSVE == 0) {\n+      return false;\n+    }\n+\n+    switch(node->Opcode()) {\n+      case Op_VectorLoadMask:\n+      case Op_VectorMaskCmp:\n+      case Op_LoadVectorGather:\n+      case Op_StoreVectorScatter:\n+      case Op_AddReductionVF:\n+      case Op_AddReductionVD:\n+      case Op_AndReductionV:\n+      case Op_OrReductionV:\n+      case Op_XorReductionV:\n+      \/\/ Mask is needed for partial Op_VectorMaskFirstTrue, because when the\n+      \/\/ input predicate is all-false, the result should be the vector length\n+      \/\/ instead of the vector register size.\n+      case Op_VectorMaskFirstTrue:\n+        return true;\n+      case Op_MaskAll:\n+        return !node->in(1)->is_Con();\n+      case Op_LoadVector:\n+      case Op_StoreVector:\n+        \/\/ We use NEON load\/store instructions if the vector length is <= 128 bits.\n+        return vt->length_in_bytes() > 16;\n+      case Op_AddReductionVI:\n+      case Op_AddReductionVL:\n+        \/\/ We may prefer using NEON instructions rather than SVE partial operations.\n+        return !VM_Version::use_neon_for_vector(vt->length_in_bytes());\n+      case Op_MinReductionV:\n+      case Op_MaxReductionV:\n+        \/\/ For BYTE\/SHORT\/INT\/FLOAT\/DOUBLE types, we may prefer using NEON\n+        \/\/ instructions rather than SVE partial operations.\n+        return vt->element_basic_type() == T_LONG ||\n+               !VM_Version::use_neon_for_vector(vt->length_in_bytes());\n+      default:\n+        \/\/ For other ops whose vector size is smaller than the max vector size, a\n+        \/\/ full-sized unpredicated operation does not impact the final vector result.\n+        return false;\n+    }\n+  }\n+\n+  \/\/ Assert that the given node is not a variable shift.\n+  bool assert_not_var_shift(const Node* n) {\n+    assert(!n->as_ShiftV()->is_var_shift(), \"illegal variable shift\");\n+    return true;\n+  }\n+\n+  Assembler::SIMD_Arrangement get_arrangement(const Node* n) {\n+    BasicType bt = Matcher::vector_element_basic_type(n);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(n);\n+    return Assembler::esize2arrangement((uint)type2aelembytes(bt),\n+                                        \/* isQ *\/ length_in_bytes == 16);\n+  }\n+%}\n+\n+\n+\/\/ All VECTOR instructions\n+\n+\/\/ ------------------------------ Vector load\/store ----------------------------\n+dnl\n+dnl VECTOR_LOAD_STORE($1,   $2,     $3,       $4,    $5  )\n+dnl VECTOR_LOAD_STORE(type, nbytes, arg_name, nbits, size)\n+define(`VECTOR_LOAD_STORE', `\n+\/\/ ifelse(load, $1, Load, Store) Vector ($4 bits)\n+instruct $1V$2(vReg $3, vmem$2 mem) %{\n+  predicate(`n->as_'ifelse(load, $1, Load, Store)Vector()->memory_size() == $2);\n+  match(Set ifelse(load, $1, dst (LoadVector mem), mem (StoreVector mem src)));\n+  format %{ \"$1V$2 ifelse(load, $1, `$dst, $mem', `$mem, $src')\\t# vector ($4 bits)\" %}\n+  ins_encode( `aarch64_enc_'ifelse(load, $1, ldr, str)v$5($3, mem) );\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VECTOR_LOAD_STORE(load,  2,  dst, 16,  H)\n+VECTOR_LOAD_STORE(store, 2,  src, 16,  H)\n+VECTOR_LOAD_STORE(load,  4,  dst, 32,  S)\n+VECTOR_LOAD_STORE(store, 4,  src, 32,  S)\n+VECTOR_LOAD_STORE(load,  8,  dst, 64,  D)\n+VECTOR_LOAD_STORE(store, 8,  src, 64,  D)\n+VECTOR_LOAD_STORE(load,  16, dst, 128, Q)\n+VECTOR_LOAD_STORE(store, 16, src, 128, Q)\n+\n+\/\/ Load Vector (> 128 bits)\n+instruct loadV(vReg dst, vmemA mem) %{\n+  predicate(n->as_LoadVector()->memory_size() > 16);\n+  match(Set dst (LoadVector mem));\n+  format %{ \"loadV $dst, $mem\\t# vector (sve)\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ false,\n+                          $dst$$FloatRegister, ptrue, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Store Vector (> 128 bits)\n+instruct storeV(vReg src, vmemA mem) %{\n+  predicate(n->as_StoreVector()->memory_size() > 16);\n+  match(Set mem (StoreVector mem src));\n+  format %{ \"storeV $mem, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ true,\n+                          $src$$FloatRegister, ptrue, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load\/store - predicated\n+\n+instruct loadV_masked(vReg dst, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (LoadVectorMasked mem pg));\n+  format %{ \"loadV_masked $dst, $pg, $mem\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ false, $dst$$FloatRegister,\n+                          $pg$$PRegister, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct storeV_masked(vReg src, vmemA mem, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set mem (StoreVectorMasked mem (Binary src pg)));\n+  format %{ \"storeV_masked $mem, $pg, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), \/* is_store *\/ true, $src$$FloatRegister,\n+                          $pg$$PRegister, bt, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector load const\n+\n+instruct vloadconB(vReg dst, immI0 src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE);\n+  match(Set dst (VectorLoadConst src));\n+  format %{ \"vloadconB $dst, $src\\t# load\/generate iota indices\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      assert(length_in_bytes <= 16, \"must be\");\n+      __ lea(rscratch1, ExternalAddress(StubRoutines::aarch64::vector_iota_indices()));\n+      if (length_in_bytes == 16) {\n+        __ ldrq($dst$$FloatRegister, rscratch1);\n+      } else {\n+        __ ldrd($dst$$FloatRegister, rscratch1);\n+      }\n+    } else {\n+      __ sve_index($dst$$FloatRegister, __ B, 0, 1);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl BINARY_OP($1,        $2,      $3,        $4,       $5  )\n+dnl BINARY_OP(rule_name, op_name, insn_neon, insn_sve, size)\n+define(`BINARY_OP', `\n+instruct $1(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst ($2 src1 src2));\n+  format %{ \"$1 $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ $3($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ $4($dst$$FloatRegister, __ $5, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl BINARY_OP_PREDICATE($1,        $2,      $3,   $4  )\n+dnl BINARY_OP_PREDICATE(rule_name, op_name, insn, size)\n+define(`BINARY_OP_PREDICATE', `\n+instruct $1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 ($2 (Binary dst_src1 src2) pg));\n+  format %{ \"$1_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ $3($dst_src1$$FloatRegister, __ $4, $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VADD_IMM($1,   $2,       $3  )\n+dnl VADD_IMM(type, imm_type, size)\n+define(`VADD_IMM', `\n+instruct vaddImm$1(vReg dst_src, $2 con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (AddV$1 dst_src (Replicate$1 con)));\n+  format %{ \"vaddImm$1 $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    int val = (int)$con$$constant;\n+    if (val > 0) {\n+      __ sve_add($dst_src$$FloatRegister, __ $3, val);\n+    } else {\n+      __ sve_sub($dst_src$$FloatRegister, __ $3, -val);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ------------------------------ Vector add -----------------------------------\n+\n+\/\/ vector add\n+BINARY_OP(vaddB, AddVB, addv, sve_add,  B)\n+BINARY_OP(vaddS, AddVS, addv, sve_add,  H)\n+BINARY_OP(vaddI, AddVI, addv, sve_add,  S)\n+BINARY_OP(vaddL, AddVL, addv, sve_add,  D)\n+BINARY_OP(vaddF, AddVF, fadd, sve_fadd, S)\n+BINARY_OP(vaddD, AddVD, fadd, sve_fadd, D)\n+\n+\/\/ vector add - predicated\n+BINARY_OP_PREDICATE(vaddB, AddVB, sve_add,  B)\n+BINARY_OP_PREDICATE(vaddS, AddVS, sve_add,  H)\n+BINARY_OP_PREDICATE(vaddI, AddVI, sve_add,  S)\n+BINARY_OP_PREDICATE(vaddL, AddVL, sve_add,  D)\n+BINARY_OP_PREDICATE(vaddF, AddVF, sve_fadd, S)\n+BINARY_OP_PREDICATE(vaddD, AddVD, sve_fadd, D)\n+\n+\/\/ vector add reg imm (unpredicated)\n+VADD_IMM(B, immBAddSubV, B)\n+VADD_IMM(S, immIAddSubV, H)\n+VADD_IMM(I, immIAddSubV, S)\n+VADD_IMM(L, immLAddSubV, D)\n+\n+\/\/ ------------------------------ Vector sub -----------------------------------\n+\n+\/\/ vector sub\n+BINARY_OP(vsubB, SubVB, subv, sve_sub,  B)\n+BINARY_OP(vsubS, SubVS, subv, sve_sub,  H)\n+BINARY_OP(vsubI, SubVI, subv, sve_sub,  S)\n+BINARY_OP(vsubL, SubVL, subv, sve_sub,  D)\n+BINARY_OP(vsubF, SubVF, fsub, sve_fsub, S)\n+BINARY_OP(vsubD, SubVD, fsub, sve_fsub, D)\n+\n+\/\/ vector sub - predicated\n+BINARY_OP_PREDICATE(vsubB, SubVB, sve_sub,  B)\n+BINARY_OP_PREDICATE(vsubS, SubVS, sve_sub,  H)\n+BINARY_OP_PREDICATE(vsubI, SubVI, sve_sub,  S)\n+BINARY_OP_PREDICATE(vsubL, SubVL, sve_sub,  D)\n+BINARY_OP_PREDICATE(vsubF, SubVF, sve_fsub, S)\n+BINARY_OP_PREDICATE(vsubD, SubVD, sve_fsub, D)\n+\n+dnl\n+dnl BINARY_OP_NEON_SVE_PAIRWISE($1,        $2,      $3,        $4,       $5  )\n+dnl BINARY_OP_NEON_SVE_PAIRWISE(rule_name, op_name, insn_neon, insn_sve, size)\n+define(`BINARY_OP_NEON_SVE_PAIRWISE', `\n+instruct $1_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst ($2 src1 src2));\n+  format %{ \"$1_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ $3($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct $1_sve(vReg dst_src1, vReg src2) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 ($2 dst_src1 src2));\n+  format %{ \"$1_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ $4($dst_src1$$FloatRegister, __ $5, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ------------------------------ Vector mul -----------------------------------\n+\n+\/\/ vector mul - BYTE, CHAR, SHORT, INT\n+BINARY_OP_NEON_SVE_PAIRWISE(vmulB, MulVB, mulv, sve_mul, B)\n+BINARY_OP_NEON_SVE_PAIRWISE(vmulS, MulVS, mulv, sve_mul, H)\n+BINARY_OP_NEON_SVE_PAIRWISE(vmulI, MulVI, mulv, sve_mul, S)\n+\n+\/\/ vector mul - LONG\n+\n+instruct vmulL_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (MulVL src1 src2));\n+  format %{ \"vmulL_neon $dst, $src1, $src2\\t# 2L\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == 16, \"must be\");\n+    __ umov(rscratch1, $src1$$FloatRegister, __ D, 0);\n+    __ umov(rscratch2, $src2$$FloatRegister, __ D, 0);\n+    __ mul(rscratch2, rscratch2, rscratch1);\n+    __ mov($dst$$FloatRegister, __ D, 0, rscratch2);\n+    __ umov(rscratch1, $src1$$FloatRegister, __ D, 1);\n+    __ umov(rscratch2, $src2$$FloatRegister, __ D, 1);\n+    __ mul(rscratch2, rscratch2, rscratch1);\n+    __ mov($dst$$FloatRegister, __ D, 1, rscratch2);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmulL_sve(vReg dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (MulVL dst_src1 src2));\n+  format %{ \"vmulL_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_mul($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mul - floating-point\n+BINARY_OP(vmulF, MulVF, fmul, sve_fmul, S)\n+BINARY_OP(vmulD, MulVD, fmul, sve_fmul, D)\n+\n+\/\/ vector mul - predicated\n+BINARY_OP_PREDICATE(vmulB, MulVB, sve_mul,  B)\n+BINARY_OP_PREDICATE(vmulS, MulVS, sve_mul,  H)\n+BINARY_OP_PREDICATE(vmulI, MulVI, sve_mul,  S)\n+BINARY_OP_PREDICATE(vmulL, MulVL, sve_mul,  D)\n+BINARY_OP_PREDICATE(vmulF, MulVF, sve_fmul, S)\n+BINARY_OP_PREDICATE(vmulD, MulVD, sve_fmul, D)\n+\n+\/\/ ------------------------------ Vector float div -----------------------------\n+\n+\/\/ vector float div\n+BINARY_OP_NEON_SVE_PAIRWISE(vdivF, DivVF, fdiv, sve_fdiv, S)\n+BINARY_OP_NEON_SVE_PAIRWISE(vdivD, DivVD, fdiv, sve_fdiv, D)\n+\n+\/\/ vector float div - predicated\n+BINARY_OP_PREDICATE(vdivF, DivVF, sve_fdiv, S)\n+BINARY_OP_PREDICATE(vdivD, DivVD, sve_fdiv, D)\n+dnl\n+dnl BITWISE_OP($1,        $2,      $3,        $4      )\n+dnl BITWISE_OP(rule_name, op_name, insn_neon, insn_sve)\n+define(`BITWISE_OP', `\n+instruct $1(vReg dst, vReg src1, vReg src2) %{\n+  match(Set dst ($2 src1 src2));\n+  format %{ \"$1 $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ $3($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ $4($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl BITWISE_OP_PREDICATE($1,        $2,      $3  )\n+dnl BITWISE_OP_PREDICATE(rule_name, op_name, insn)\n+define(`BITWISE_OP_PREDICATE', `\n+instruct $1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 ($2 (Binary dst_src1 src2) pg));\n+  format %{ \"$1_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ $3($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl BITWISE_OP_IMM($1,        $2,   $3,      $4,   $5  )\n+dnl BITWISE_OP_IMM(rule_name, type, op_name, insn, size)\n+define(`BITWISE_OP_IMM', `\n+instruct $1(vReg dst_src, imm$2Log con) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($3 dst_src (Replicate$2 con)));\n+  format %{ \"$1 $dst_src, $dst_src, $con\" %}\n+  ins_encode %{\n+    __ $4($dst_src$$FloatRegister, __ $5, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\n+\/\/ ------------------------------ Vector and -----------------------------------\n+\n+\/\/ vector and\n+BITWISE_OP(vand, AndV, andr, sve_and)\n+\n+\/\/ vector and - predicated\n+BITWISE_OP_PREDICATE(vand, AndV, sve_and)\n+\n+\/\/ vector and reg imm (unpredicated)\n+BITWISE_OP_IMM(vandImmB, B, AndV, sve_and, B)\n+BITWISE_OP_IMM(vandImmS, S, AndV, sve_and, H)\n+BITWISE_OP_IMM(vandImmI, I, AndV, sve_and, S)\n+BITWISE_OP_IMM(vandImmL, L, AndV, sve_and, D)\n+\n+\/\/ ------------------------------ Vector or ------------------------------------\n+\n+\/\/ vector or\n+BITWISE_OP(vor, OrV, orr, sve_orr)\n+\n+\/\/ vector or - predicated\n+BITWISE_OP_PREDICATE(vor, OrV, sve_orr)\n+\n+\/\/ vector or reg imm (unpredicated)\n+BITWISE_OP_IMM(vorImmB, B, OrV, sve_orr, B)\n+BITWISE_OP_IMM(vorImmS, S, OrV, sve_orr, H)\n+BITWISE_OP_IMM(vorImmI, I, OrV, sve_orr, S)\n+BITWISE_OP_IMM(vorImmL, L, OrV, sve_orr, D)\n+\n+\/\/ ------------------------------ Vector xor -----------------------------------\n+\n+\/\/ vector xor\n+BITWISE_OP(vxor, XorV, eor, sve_eor)\n+\n+\/\/ vector xor - predicated\n+BITWISE_OP_PREDICATE(vxor, XorV, sve_eor)\n+\n+\/\/ vector xor reg imm (unpredicated)\n+BITWISE_OP_IMM(vxorImmB, B, XorV, sve_eor, B)\n+BITWISE_OP_IMM(vxorImmS, S, XorV, sve_eor, H)\n+BITWISE_OP_IMM(vxorImmI, I, XorV, sve_eor, S)\n+BITWISE_OP_IMM(vxorImmL, L, XorV, sve_eor, D)\n+\n+\/\/ ------------------------------ Vector not -----------------------------------\n+\n+dnl\n+define(`MATCH_RULE', `ifelse($1, I,\n+`match(Set dst (XorV src (ReplicateB m1)));\n+  match(Set dst (XorV src (ReplicateS m1)));\n+  match(Set dst (XorV src (ReplicateI m1)));',\n+`match(Set dst (XorV src (ReplicateL m1)));')')dnl\n+dnl\n+dnl VECTOR_NOT($1  )\n+dnl VECTOR_NOT(type)\n+define(`VECTOR_NOT', `\n+instruct vnot$1`'(vReg dst, vReg src, imm$1_M1 m1) %{\n+  MATCH_RULE($1)\n+  format %{ \"vnot$1 $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ notr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_not($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector not\n+VECTOR_NOT(I)\n+VECTOR_NOT(L)\n+undefine(MATCH_RULE)\n+dnl\n+define(`MATCH_RULE', `ifelse($1, I,\n+`match(Set dst_src (XorV (Binary dst_src (ReplicateB m1)) pg));\n+  match(Set dst_src (XorV (Binary dst_src (ReplicateS m1)) pg));\n+  match(Set dst_src (XorV (Binary dst_src (ReplicateI m1)) pg));',\n+`match(Set dst_src (XorV (Binary dst_src (ReplicateL m1)) pg));')')dnl\n+dnl\n+dnl VECTOR_NOT_PREDICATE($1  )\n+dnl VECTOR_NOT_PREDICATE(type)\n+define(`VECTOR_NOT_PREDICATE', `\n+instruct vnot$1_masked`'(vReg dst_src, imm$1_M1 m1, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  MATCH_RULE($1)\n+  format %{ \"vnot$1_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_not($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector not - predicated\n+VECTOR_NOT_PREDICATE(I)\n+VECTOR_NOT_PREDICATE(L)\n+undefine(MATCH_RULE)\n+dnl\n+\/\/ ------------------------------ Vector and_not -------------------------------\n+\n+dnl\n+define(`MATCH_RULE', `ifelse($1, I,\n+`match(Set dst (AndV src1 (XorV src2 (ReplicateB m1))));\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateS m1))));\n+  match(Set dst (AndV src1 (XorV src2 (ReplicateI m1))));',\n+`match(Set dst (AndV src1 (XorV src2 (ReplicateL m1))));')')dnl\n+dnl\n+dnl VECTOR_AND_NOT($1  )\n+dnl VECTOR_AND_NOT(type)\n+define(`VECTOR_AND_NOT', `\n+instruct vand_not$1`'(vReg dst, vReg src1, vReg src2, imm$1_M1 m1) %{\n+  MATCH_RULE($1)\n+  format %{ \"vand_not$1 $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ bic($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_bic($dst$$FloatRegister, $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector and_not\n+VECTOR_AND_NOT(I)\n+VECTOR_AND_NOT(L)\n+undefine(MATCH_RULE)\n+dnl\n+define(`MATCH_RULE', `ifelse($1, I,\n+`match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateB m1))) pg));\n+  match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateS m1))) pg));\n+  match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateI m1))) pg));',\n+`match(Set dst_src1 (AndV (Binary dst_src1 (XorV src2 (ReplicateL m1))) pg));')')dnl\n+dnl\n+dnl VECTOR_AND_NOT_PREDICATE($1  )\n+dnl VECTOR_AND_NOT_PREDICATE(type)\n+define(`VECTOR_AND_NOT_PREDICATE', `\n+instruct vand_not$1_masked`'(vReg dst_src1, vReg src2, imm$1_M1 m1, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  MATCH_RULE($1)\n+  format %{ \"vand_not$1_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_bic($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector and_not - predicated\n+VECTOR_AND_NOT_PREDICATE(I)\n+VECTOR_AND_NOT_PREDICATE(L)\n+undefine(MATCH_RULE)\n+dnl\n+dnl UNARY_OP($1,        $2,      $3,        $4,       $5  )\n+dnl UNARY_OP(rule_name, op_name, insn_neon, insn_sve, size)\n+define(`UNARY_OP', `\n+instruct $1(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst ($2 src));\n+  format %{ \"$1 $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ $3($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ $4($dst$$FloatRegister, __ $5, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl UNARY_OP_PREDICATE($1,        $2,      $3  )\n+dnl UNARY_OP_PREDICATE(rule_name, op_name, insn)\n+define(`UNARY_OP_PREDICATE', `\n+instruct $1_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($2 dst_src pg));\n+  format %{ \"$1_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ $3($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl UNARY_OP_PREDICATE_WITH_SIZE($1,        $2,      $3,   $4  )\n+dnl UNARY_OP_PREDICATE_WITH_SIZE(rule_name, op_name, insn, size)\n+define(`UNARY_OP_PREDICATE_WITH_SIZE', `\n+instruct $1_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($2 dst_src pg));\n+  format %{ \"$1_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ $3($dst_src$$FloatRegister, __ $4, $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ------------------------------ Vector abs -----------------------------------\n+\n+\/\/ vector abs\n+UNARY_OP(vabsB, AbsVB, absr, sve_abs,  B)\n+UNARY_OP(vabsS, AbsVS, absr, sve_abs,  H)\n+UNARY_OP(vabsI, AbsVI, absr, sve_abs,  S)\n+UNARY_OP(vabsL, AbsVL, absr, sve_abs,  D)\n+UNARY_OP(vabsF, AbsVF, fabs, sve_fabs, S)\n+UNARY_OP(vabsD, AbsVD, fabs, sve_fabs, D)\n+\n+\/\/ vector abs - predicated\n+UNARY_OP_PREDICATE_WITH_SIZE(vabsB, AbsVB, sve_abs,  B)\n+UNARY_OP_PREDICATE_WITH_SIZE(vabsS, AbsVS, sve_abs,  H)\n+UNARY_OP_PREDICATE_WITH_SIZE(vabsI, AbsVI, sve_abs,  S)\n+UNARY_OP_PREDICATE_WITH_SIZE(vabsL, AbsVL, sve_abs,  D)\n+UNARY_OP_PREDICATE_WITH_SIZE(vabsF, AbsVF, sve_fabs, S)\n+UNARY_OP_PREDICATE_WITH_SIZE(vabsD, AbsVD, sve_fabs, D)\n+\n+\/\/ ------------------------------ Vector fabd ----------------------------------\n+\n+\/\/ vector fabs diff\n+\n+instruct vfabd(vReg dst, vReg src1, vReg src2) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (AbsVF (SubVF src1 src2)));\n+  match(Set dst (AbsVD (SubVD src1 src2)));\n+  format %{ \"vfabd $dst, $src1, $src2\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    __ fabd($dst$$FloatRegister, get_arrangement(this),\n+            $src1$$FloatRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector neg -----------------------------------\n+\n+\/\/ vector neg\n+\n+instruct vnegI(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (NegVI src));\n+  format %{ \"vnegI $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ negr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_neg($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+UNARY_OP(vnegL, NegVL, negr, sve_neg,  D)\n+UNARY_OP(vnegF, NegVF, fneg, sve_fneg, S)\n+UNARY_OP(vnegD, NegVD, fneg, sve_fneg, D)\n+\n+\/\/ vector neg - predicated\n+UNARY_OP_PREDICATE(vnegI, NegVI, sve_neg)\n+UNARY_OP_PREDICATE_WITH_SIZE(vnegL, NegVL, sve_neg,  D)\n+UNARY_OP_PREDICATE_WITH_SIZE(vnegF, NegVF, sve_fneg, S)\n+UNARY_OP_PREDICATE_WITH_SIZE(vnegD, NegVD, sve_fneg, D)\n+\n+\/\/ ------------------------------ Vector sqrt ----------------------------------\n+\n+\/\/ vector sqrt\n+UNARY_OP(vsqrtF, SqrtVF, fsqrt, sve_fsqrt, S)\n+UNARY_OP(vsqrtD, SqrtVD, fsqrt, sve_fsqrt, D)\n+\n+\/\/ vector sqrt - predicated\n+UNARY_OP_PREDICATE_WITH_SIZE(vsqrtF, SqrtVF, sve_fsqrt, S)\n+UNARY_OP_PREDICATE_WITH_SIZE(vsqrtD, SqrtVD, sve_fsqrt, D)\n+\n+dnl\n+dnl VMINMAX_L_NEON($1,   $2     )\n+dnl VMINMAX_L_NEON(type, op_name)\n+define(`VMINMAX_L_NEON', `\n+instruct v$1L_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst ($2 src1 src2));\n+  effect(TEMP_DEF dst);\n+  format %{ \"v$1L_neon $dst, $src1, $src2\\t# 2L\" %}\n+  ins_encode %{\n+    __ cmgt($dst$$FloatRegister, __ T2D, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ bsl($dst$$FloatRegister, __ T16B, ifelse(min, $1, $src2, $src1)$$FloatRegister, ifelse(min, $1, $src1, $src2)$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMINMAX_L_SVE($1,   $2,      $3  )\n+dnl VMINMAX_L_SVE(type, op_name, insn)\n+define(`VMINMAX_L_SVE', `\n+instruct v$1L_sve(vReg dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst_src1 ($2 dst_src1 src2));\n+  format %{ \"v$1L_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ $3($dst_src1$$FloatRegister, __ D, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMINMAX_NEON($1,   $2,      $3,      $4           )\n+dnl VMINMAX_NEON(type, op_name, insn_fp, insn_integral)\n+define(`VMINMAX_NEON', `\n+instruct v$1_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(Matcher::vector_element_basic_type(n) != T_LONG &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst ($2 src1 src2));\n+  format %{ \"v$1_neon $dst, $src1, $src2\\t# B\/S\/I\/F\/D\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ $3($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt) && bt != T_LONG, \"unsupported type\");\n+      __ $4($dst$$FloatRegister, get_arrangement(this),\n+              $src1$$FloatRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMINMAX_SVE($1,   $2,      $3,      $4           )\n+dnl VMINMAX_SVE(type, op_name, insn_fp, insn_integral)\n+define(`VMINMAX_SVE', `\n+instruct v$1_sve(vReg dst_src1, vReg src2) %{\n+  predicate(Matcher::vector_element_basic_type(n) != T_LONG &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src1 ($2 dst_src1 src2));\n+  format %{ \"v$1_sve $dst_src1, $dst_src1, $src2\\t# B\/S\/I\/F\/D\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ $3($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt) && bt != T_LONG, \"unsupported type\");\n+      __ $4($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMINMAX_PREDICATE($1,   $2,      $3,      $4           )\n+dnl VMINMAX_PREDICATE(type, op_name, insn_fp, insn_integral)\n+define(`VMINMAX_PREDICATE', `\n+instruct v$1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 ($2 (Binary dst_src1 src2) pg));\n+  format %{ \"v$1_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (is_floating_point_type(bt)) {\n+      __ $3($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $src2$$FloatRegister);\n+    } else {\n+      assert(is_integral_type(bt), \"unsupported type\");\n+      __ $4($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $src2$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ------------------------------ Vector min -----------------------------------\n+\n+\/\/ vector min - LONG\n+VMINMAX_L_NEON(min, MinV)\n+VMINMAX_L_SVE(min, MinV, sve_smin)\n+\n+\/\/ vector min - B\/S\/I\/F\/D\n+VMINMAX_NEON(min, MinV, fmin, minv)\n+VMINMAX_SVE(min, MinV, sve_fmin, sve_smin)\n+\n+\/\/ vector min - predicated\n+VMINMAX_PREDICATE(min, MinV, sve_fmin, sve_smin)\n+\n+\/\/ ------------------------------ Vector max -----------------------------------\n+\n+\/\/ vector max - LONG\n+VMINMAX_L_NEON(max, MaxV)\n+VMINMAX_L_SVE(max, MaxV, sve_smax)\n+\n+\/\/ vector max - B\/S\/I\/F\/D\n+VMINMAX_NEON(max, MaxV, fmax, maxv)\n+VMINMAX_SVE(max, MaxV, sve_fmax, sve_smax)\n+\n+\/\/ vector max - predicated\n+VMINMAX_PREDICATE(max, MaxV, sve_fmax, sve_smax)\n+\n+\/\/ ------------------------------ MLA RELATED ----------------------------------\n+\n+\/\/ vector mla\n+\/\/ dst_src1 = dst_src1 + src2 * src3\n+\n+instruct vmla(vReg dst_src1, vReg src2, vReg src3) %{\n+  match(Set dst_src1 (AddVB dst_src1 (MulVB src2 src3)));\n+  match(Set dst_src1 (AddVS dst_src1 (MulVS src2 src3)));\n+  match(Set dst_src1 (AddVI dst_src1 (MulVI src2 src3)));\n+  match(Set dst_src1 (AddVL dst_src1 (MulVL src2 src3)));\n+  format %{ \"vmla $dst_src1, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes) && bt != T_LONG) {\n+      \/\/ NEON mlav does not accept T2D arrangement.\n+      __ mlav($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_mla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmla_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddVB (Binary dst_src1 (MulVB src2 src3)) pg));\n+  match(Set dst_src1 (AddVS (Binary dst_src1 (MulVS src2 src3)) pg));\n+  match(Set dst_src1 (AddVI (Binary dst_src1 (MulVI src2 src3)) pg));\n+  match(Set dst_src1 (AddVL (Binary dst_src1 (MulVL src2 src3)) pg));\n+  format %{ \"vmla_masked $dst_src1, $pg, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_mla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmla\n+\/\/ dst_src1 = dst_src1 + src2 * src3\n+\n+instruct vfmla(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA);\n+  match(Set dst_src1 (FmaVF dst_src1 (Binary src2 src3)));\n+  match(Set dst_src1 (FmaVD dst_src1 (Binary src2 src3)));\n+  format %{ \"vfmla $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmla($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_fmla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmad - predicated\n+\/\/ dst_src1 = dst_src1 * src2 + src3\n+\n+instruct vfmad_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0);\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 src2) (Binary src3 pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 src2) (Binary src3 pg)));\n+  format %{ \"vfmad_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fmad($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mls\n+\/\/ dst_src1 = dst_src1 - src2 * src3\n+\n+instruct vmls(vReg dst_src1, vReg src2, vReg src3) %{\n+  match(Set dst_src1 (SubVB dst_src1 (MulVB src2 src3)));\n+  match(Set dst_src1 (SubVS dst_src1 (MulVS src2 src3)));\n+  match(Set dst_src1 (SubVI dst_src1 (MulVI src2 src3)));\n+  match(Set dst_src1 (SubVL dst_src1 (MulVL src2 src3)));\n+  format %{ \"vmls $dst_src1, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes) && bt != T_LONG) {\n+      \/\/ NEON mlsv does not accept T2D arrangement.\n+      __ mlsv($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_mls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmls_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (SubVB (Binary dst_src1 (MulVB src2 src3)) pg));\n+  match(Set dst_src1 (SubVS (Binary dst_src1 (MulVS src2 src3)) pg));\n+  match(Set dst_src1 (SubVI (Binary dst_src1 (MulVI src2 src3)) pg));\n+  match(Set dst_src1 (SubVL (Binary dst_src1 (MulVL src2 src3)) pg));\n+  format %{ \"vmls_masked $dst_src1, $pg, src2, src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_mls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmls\n+\n+\/\/ dst_src1 = dst_src1 + -src2 * src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfmls1(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF dst_src1 (Binary (NegVF src2) src3)));\n+  match(Set dst_src1 (FmaVD dst_src1 (Binary (NegVD src2) src3)));\n+  format %{ \"vfmls1 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmls($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_fmls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ dst_src1 = dst_src1 + src2 * -src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfmls2(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && !n->in(2)->in(2)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF dst_src1 (Binary src2 (NegVF src3))));\n+  match(Set dst_src1 (FmaVD dst_src1 (Binary src2 (NegVD src3))));\n+  format %{ \"vfmls2 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ fmls($dst_src1$$FloatRegister, get_arrangement(this),\n+              $src2$$FloatRegister, $src3$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_fmls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fmsb - predicated\n+\n+\/\/ dst_src1 = dst_src1 * -src2 + src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfmsb_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->in(2)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 (NegVF src2)) (Binary src3 pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 (NegVD src2)) (Binary src3 pg)));\n+  format %{ \"vfmsb_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fmsb($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmla (sve)\n+\n+\/\/ dst_src1 = -dst_src1 + -src2 * src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmla1(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->as_Vector()->is_predicated_vector() &&\n+            !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (NegVF dst_src1) (Binary (NegVF src2) src3)));\n+  match(Set dst_src1 (FmaVD (NegVD dst_src1) (Binary (NegVD src2) src3)));\n+  format %{ \"vfnmla1 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ dst_src1 = -dst_src1 + src2 * -src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmla2(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->as_Vector()->is_predicated_vector() &&\n+            !n->in(2)->in(2)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (NegVF dst_src1) (Binary src2 (NegVF src3))));\n+  match(Set dst_src1 (FmaVD (NegVD dst_src1) (Binary src2 (NegVD src3))));\n+  format %{ \"vfnmla2 $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmla($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmad - predicated\n+\n+\/\/ dst_src1 = -src3 + dst_src1 * -src2\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmad_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->in(2)->as_Vector()->is_predicated_vector() &&\n+            !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 (NegVF src2)) (Binary (NegVF src3) pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 (NegVD src2)) (Binary (NegVD src3) pg)));\n+  format %{ \"vfnmad_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmad($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmls (sve)\n+\n+\/\/ dst_src1 = -dst_src1 + src2 * src3\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmls(vReg dst_src1, vReg src2, vReg src3) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (NegVF dst_src1) (Binary src2 src3)));\n+  match(Set dst_src1 (FmaVD (NegVD dst_src1) (Binary src2 src3)));\n+  format %{ \"vfnmls $dst_src1, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmls($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 ptrue, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector fnmsb - predicated\n+\n+\/\/ dst_src1 = -src3 + dst_src1 * src2\n+\/\/ The NegVF\/NegVD must not be predicated.\n+instruct vfnmsb_masked(vReg dst_src1, vReg src2, vReg src3, pRegGov pg) %{\n+  predicate(UseFMA && UseSVE > 0 &&\n+            !n->in(2)->in(1)->as_Vector()->is_predicated_vector());\n+  match(Set dst_src1 (FmaVF (Binary dst_src1 src2) (Binary (NegVF src3) pg)));\n+  match(Set dst_src1 (FmaVD (Binary dst_src1 src2) (Binary (NegVD src3) pg)));\n+  format %{ \"vfnmsb_masked $dst_src1, $pg, $src2, $src3\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fnmsb($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $pg$$PRegister, $src2$$FloatRegister, $src3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ MulAddVS2VI\n+\/\/ Vector Multiply-Add Shorts into Integer\n+\n+instruct vmuladdS2I(vReg dst, vReg src1, vReg src2, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16 &&\n+            Matcher::vector_element_basic_type(n->in(1)) == T_SHORT);\n+  match(Set dst (MulAddVS2VI src1 src2));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vmuladdS2I $dst, $src1, $src2\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ smullv($tmp$$FloatRegister, __ T4H, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ smullv($dst$$FloatRegister, __ T8H, $src1$$FloatRegister, $src2$$FloatRegister);\n+    __ addpv($dst$$FloatRegister, __ T4S, $tmp$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector shift ---------------------------------\n+\n+\/\/ Vector right shift in AArch64 ASIMD\n+\/\/\n+\/\/ Right shifts with vector shift count on AArch64 ASIMD are implemented\n+\/\/ as left shift by negative shift count.\n+\/\/ There are two cases for vector shift count.\n+\/\/\n+\/\/ Case 1: The vector shift count is from replication.\n+\/\/        |            |\n+\/\/    LoadVector  RShiftCntV\n+\/\/        |       \/\n+\/\/     RShiftVI\n+\/\/\n+\/\/ Case 2: The vector shift count is from loading.\n+\/\/ This case isn't supported by middle-end now. But it's supported by\n+\/\/ panama\/vectorIntrinsics(JEP 338: Vector API).\n+\/\/        |            |\n+\/\/    LoadVector  LoadVector\n+\/\/        |       \/\n+\/\/     RShiftVI\n+\/\/\n+\/\/ The negate is conducted in RShiftCntV rule for case 1, whereas it's done in\n+\/\/ RShiftV* rules for case 2. Because there exists an optimization opportunity\n+\/\/ for case 1, that is, multiple neg instructions in inner loop can be hoisted\n+\/\/ to outer loop and merged into one neg instruction.\n+\/\/\n+\/\/ Note that ShiftVNode::is_var_shift() indicates whether the vector shift\n+\/\/ count is a variable vector(case 2) or not(a vector generated by RShiftCntV,\n+\/\/ i.e. case 1).\n+\n+\/\/ vector shift count\n+\n+instruct vshiftcntL(vReg dst, iRegIorL2I cnt) %{\n+  match(Set dst (LShiftCntV cnt));\n+  format %{ \"vshiftcntL $dst, $cnt\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $cnt$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_dup($dst$$FloatRegister, __ elemType_to_regVariant(bt), $cnt$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vshiftcntR(vReg dst, iRegIorL2I cnt) %{\n+  match(Set dst (RShiftCntV cnt));\n+  format %{ \"vshiftcntR $dst, $cnt\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      assert(length_in_bytes <= 16, \"must be\");\n+      __ negw(rscratch1, $cnt$$Register);\n+      __ dup($dst$$FloatRegister, get_arrangement(this), rscratch1);\n+    } else {\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_dup($dst$$FloatRegister, __ elemType_to_regVariant(bt), $cnt$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector shift left\n+\n+instruct vlsl_neon(vReg dst, vReg src, vReg shift) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst (LShiftVB src shift));\n+  match(Set dst (LShiftVS src shift));\n+  match(Set dst (LShiftVI src shift));\n+  match(Set dst (LShiftVL src shift));\n+  format %{ \"vlsl_neon $dst, $src, $shift\" %}\n+  ins_encode %{\n+    __ sshl($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsl_sve(vReg dst_src, vReg shift) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n)));\n+  match(Set dst_src (LShiftVB dst_src shift));\n+  match(Set dst_src (LShiftVS dst_src shift));\n+  match(Set dst_src (LShiftVI dst_src shift));\n+  match(Set dst_src (LShiftVL dst_src shift));\n+  format %{ \"vlsl_sve $dst_src, $dst_src, $shift\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_lsl($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl VRSHIFT_NEON($1,   $2,      $3  )\n+dnl VRSHIFT_NEON(type, op_name, insn)\n+define(`VRSHIFT_NEON', `\n+instruct v$1_neon(vReg dst, vReg src, vReg shift) %{\n+  predicate(UseSVE == 0 && !n->as_ShiftV()->is_var_shift());\n+  match(Set dst ($2VB src shift));\n+  match(Set dst ($2VS src shift));\n+  match(Set dst ($2VI src shift));\n+  match(Set dst ($2VL src shift));\n+  format %{ \"v$1_neon $dst, $src, $shift\\t# not variable shift\" %}\n+  ins_encode %{\n+    __ $3($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VRSHIFT_NEON_VAR($1,   $2,      $3  )\n+dnl VRSHIFT_NEON_VAR(type, op_name, insn)\n+define(`VRSHIFT_NEON_VAR', `\n+instruct v$1_neon_var(vReg dst, vReg src, vReg shift) %{\n+  predicate(UseSVE == 0 && n->as_ShiftV()->is_var_shift());\n+  match(Set dst ($2VB src shift));\n+  match(Set dst ($2VS src shift));\n+  match(Set dst ($2VI src shift));\n+  match(Set dst ($2VL src shift));\n+  effect(TEMP_DEF dst);\n+  format %{ \"v$1_neon_var $dst, $src, $shift\\t# variable shift\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $shift$$FloatRegister);\n+    __ $3($dst$$FloatRegister, get_arrangement(this),\n+            $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VRSHIFT_SVE($1,   $2,      $3  )\n+dnl VRSHIFT_SVE(type, op_name, insn)\n+define(`VRSHIFT_SVE', `\n+instruct v$1_sve(vReg dst_src, vReg shift) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($2VB dst_src shift));\n+  match(Set dst_src ($2VS dst_src shift));\n+  match(Set dst_src ($2VI dst_src shift));\n+  match(Set dst_src ($2VL dst_src shift));\n+  format %{ \"v$1_sve $dst_src, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ $3($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $shift$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector shift right (arithmetic)\n+VRSHIFT_NEON(asr, RShift, sshl)\n+VRSHIFT_NEON_VAR(asr, RShift, sshl)\n+VRSHIFT_SVE(asr, RShift, sve_asr)\n+\n+\/\/ vector shift right (logical)\n+VRSHIFT_NEON(lsr, URShift, ushl)\n+VRSHIFT_NEON_VAR(lsr, URShift, ushl)\n+VRSHIFT_SVE(lsr, URShift, sve_lsr)\n+\n+\/\/ vector shift with imm\n+\n+instruct vlsl_imm(vReg dst, vReg src, immI shift) %{\n+  predicate(assert_not_var_shift(n));\n+  match(Set dst (LShiftVB src (LShiftCntV shift)));\n+  match(Set dst (LShiftVS src (LShiftCntV shift)));\n+  match(Set dst (LShiftVI src (LShiftCntV shift)));\n+  match(Set dst (LShiftVL src (LShiftCntV shift)));\n+  format %{ \"vlsl_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Optimize for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) {\n+        if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+          __ eor($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        } else {\n+          assert(UseSVE > 0, \"must be sve\");\n+          __ sve_eor($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+        return;\n+      }\n+    }\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ shl($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_lsl($dst$$FloatRegister, __ elemType_to_regVariant(bt), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vasr_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(assert_not_var_shift(n));\n+  match(Set dst (RShiftVB src (RShiftCntV shift)));\n+  match(Set dst (RShiftVS src (RShiftCntV shift)));\n+  match(Set dst (RShiftVI src (RShiftCntV shift)));\n+  match(Set dst (RShiftVL src (RShiftCntV shift)));\n+  format %{ \"vasr_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Refine con for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) con = esize_in_bits - 1;\n+    }\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ sshr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_asr($dst$$FloatRegister, __ elemType_to_regVariant(bt), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsr_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(assert_not_var_shift(n));\n+  match(Set dst (URShiftVB src (RShiftCntV shift)));\n+  match(Set dst (URShiftVS src (RShiftCntV shift)));\n+  match(Set dst (URShiftVI src (RShiftCntV shift)));\n+  match(Set dst (URShiftVL src (RShiftCntV shift)));\n+  format %{ \"vlsr_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Optimize for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) {\n+        if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+          __ eor($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        } else {\n+          assert(UseSVE > 0, \"must be sve\");\n+          __ sve_eor($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+        return;\n+      }\n+    }\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ ushr($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_lsr($dst$$FloatRegister, __ elemType_to_regVariant(bt), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ shift right add with imm (vector length <= 128 bits only)\n+\n+instruct vasra_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (AddVB dst (RShiftVB src (RShiftCntV shift))));\n+  match(Set dst (AddVS dst (RShiftVS src (RShiftCntV shift))));\n+  match(Set dst (AddVI dst (RShiftVI src (RShiftCntV shift))));\n+  match(Set dst (AddVL dst (RShiftVL src (RShiftCntV shift))));\n+  format %{ \"vasra_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) {\n+      \/\/ Refine con for B\/S\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con >= esize_in_bits) con = esize_in_bits - 1;\n+    }\n+    __ ssra($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vlsra_imm(vReg dst, vReg src, immI_positive shift) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (AddVB dst (URShiftVB src (RShiftCntV shift))));\n+  match(Set dst (AddVS dst (URShiftVS src (RShiftCntV shift))));\n+  match(Set dst (AddVI dst (URShiftVI src (RShiftCntV shift))));\n+  match(Set dst (AddVL dst (URShiftVL src (RShiftCntV shift))));\n+  format %{ \"vlsra_imm $dst, $src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int con = (int)$shift$$constant;\n+    if (is_subword_type(bt)) { \/\/ for B\/H\n+      int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+      if (con < esize_in_bits) {\n+        __ usra($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+      }\n+    } else { \/\/ for S\/D\n+      assert(type2aelembytes(bt) == 4 || type2aelembytes(bt) == 8, \"unsupported type\");\n+      __ usra($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister, con);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl VSHIFT_PREDICATE($1,   $2,      $3  )\n+dnl VSHIFT_PREDICATE(type, op_name, insn)\n+define(`VSHIFT_PREDICATE', `\n+instruct v$1_masked(vReg dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 ($2VB (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 ($2VS (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 ($2VI (Binary dst_src1 src2) pg));\n+  match(Set dst_src1 ($2VL (Binary dst_src1 src2) pg));\n+  format %{ \"v$1_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ $3($dst_src1$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VSHIFT_IMM_PREDICATE($1,   $2,       $3,       $4,       $5  )\n+dnl VSHIFT_IMM_PREDICATE(type, arg_type, op_name1, op_name2, insn)\n+define(`VSHIFT_IMM_PREDICATE', `\n+instruct v$1_imm_masked(vReg dst_src, $2 shift, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src ($3VB (Binary dst_src ($4 shift)) pg));\n+  match(Set dst_src ($3VS (Binary dst_src ($4 shift)) pg));\n+  match(Set dst_src ($3VI (Binary dst_src ($4 shift)) pg));\n+  match(Set dst_src ($3VL (Binary dst_src ($4 shift)) pg));\n+  format %{ \"v$1_imm_masked $dst_src, $pg, $dst_src, $shift\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int esize_in_bits = type2aelembytes(bt) * BitsPerByte;\n+    int con = (int)$shift$$constant;\n+    assert(con ifelse($1, lsl, >=, >) 0 && con < esize_in_bits, \"invalid shift immediate\");\n+    __ $5($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, con);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector shift - predicated\n+VSHIFT_PREDICATE(lsl, LShift,  sve_lsl)\n+VSHIFT_PREDICATE(asr, RShift,  sve_asr)\n+VSHIFT_PREDICATE(lsr, URShift, sve_lsr)\n+\n+\/\/ vector shift with imm - predicated\n+VSHIFT_IMM_PREDICATE(lsl, immI,          LShift,  LShiftCntV, sve_lsl)\n+VSHIFT_IMM_PREDICATE(asr, immI_positive, RShift,  RShiftCntV, sve_asr)\n+VSHIFT_IMM_PREDICATE(lsr, immI_positive, URShift, RShiftCntV, sve_lsr)\n+\n+\/\/ ------------------------------ Vector reduction add -------------------------\n+\n+dnl\n+dnl REDUCE_ADD_INT_NEON_SVE_PAIRWISE($1,   $2      )\n+dnl REDUCE_ADD_INT_NEON_SVE_PAIRWISE(type, arg_type)\n+define(`REDUCE_ADD_INT_NEON_SVE_PAIRWISE', `\n+instruct reduce_add$1_neon(iReg$1NoSp dst, $2 isrc, vReg vsrc, vReg tmp) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))));\n+  match(Set dst (AddReductionV$1 isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_add$1_neon $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_add_integral($dst$$Register, bt,\n+                                $isrc$$Register, $vsrc$$FloatRegister,\n+                                length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_add$1_sve(iReg$1NoSp dst, $2 isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))));\n+  match(Set dst (AddReductionV$1 isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_add$1_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ reduction addI\n+REDUCE_ADD_INT_NEON_SVE_PAIRWISE(I, iRegIorL2I)\n+\n+\/\/ reduction addL\n+REDUCE_ADD_INT_NEON_SVE_PAIRWISE(L, iRegL)\n+\n+\/\/ reduction addF\n+\n+instruct reduce_addF_neon(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addF_neon $dst, $fsrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ fadds($dst$$FloatRegister, $fsrc$$FloatRegister, $vsrc$$FloatRegister);\n+    __ ins($tmp$$FloatRegister, __ S, $vsrc$$FloatRegister, 0, 1);\n+    __ fadds($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+    if (length_in_bytes == 16) {\n+      __ ins($tmp$$FloatRegister, __ S, $vsrc$$FloatRegister, 0, 2);\n+      __ fadds($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+      __ ins($tmp$$FloatRegister, __ S, $vsrc$$FloatRegister, 0, 3);\n+      __ fadds($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+dnl REDUCE_ADD_FP_SVE($1,   $2  )\n+dnl REDUCE_ADD_FP_SVE(type, size)\n+define(`REDUCE_ADD_FP_SVE', `\n+instruct reduce_add$1_sve(vReg$1 dst_src1, vReg src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionV$1 dst_src1 src2));\n+  format %{ \"reduce_add$1_sve $dst_src1, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src2);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_fadda($dst_src1$$FloatRegister, __ $2, ptrue, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+REDUCE_ADD_FP_SVE(F, S)\n+\n+\/\/ reduction addD\n+\n+instruct reduce_addD_neon(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (AddReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_addD_neon $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  ins_encode %{\n+    __ faddd($dst$$FloatRegister, $dsrc$$FloatRegister, $vsrc$$FloatRegister);\n+    __ ins($tmp$$FloatRegister, __ D, $vsrc$$FloatRegister, 0, 1);\n+    __ faddd($dst$$FloatRegister, $dst$$FloatRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+REDUCE_ADD_FP_SVE(D, D)\n+\n+\/\/ reduction add - predicated\n+dnl\n+dnl REDUCE_ADD_INT_PREDICATE($1,        $2     )\n+dnl REDUCE_ADD_INT_PREDICATE(insn_name, op_name)\n+define(`REDUCE_ADD_INT_PREDICATE', `\n+instruct reduce_add$1_masked(iReg$1NoSp dst, $2 isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (AddReductionV$1 (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_add$1_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_ADD_FP_PREDICATE($1,        $2     )\n+dnl REDUCE_ADD_FP_PREDICATE(insn_name, op_name)\n+define(`REDUCE_ADD_FP_PREDICATE', `\n+instruct reduce_add$1_masked(vReg$1 dst_src1, vReg src2, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src1 (AddReductionV$1 (Binary dst_src1 src2) pg));\n+  format %{ \"reduce_add$1_masked $dst_src1, $pg, $dst_src1, $src2\" %}\n+  ins_encode %{\n+    __ sve_fadda($dst_src1$$FloatRegister, __ $2,\n+                 $pg$$PRegister, $src2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+REDUCE_ADD_INT_PREDICATE(I, iRegIorL2I)\n+REDUCE_ADD_INT_PREDICATE(L, iRegL)\n+REDUCE_ADD_FP_PREDICATE(F, S)\n+REDUCE_ADD_FP_PREDICATE(D, D)\n+\n+\/\/ ------------------------------ Vector reduction mul -------------------------\n+\n+instruct reduce_mulI(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                     vReg tmp1, vReg tmp2) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 8 ||\n+            Matcher::vector_length_in_bytes(n->in(2)) == 16);\n+  match(Set dst (MulReductionVI isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"reduce_mulI $dst, $isrc, $vsrc\\t# vector (64\/128 bits). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_mul_integral($dst$$Register, bt, $isrc$$Register,\n+                                $vsrc$$FloatRegister, length_in_bytes,\n+                                $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulL(iRegLNoSp dst, iRegL isrc, vReg vsrc) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 16);\n+  match(Set dst (MulReductionVL isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_mulL $dst, $isrc, $vsrc\\t# 2L\" %}\n+  ins_encode %{\n+    __ neon_reduce_mul_integral($dst$$Register, T_LONG, $isrc$$Register,\n+                                $vsrc$$FloatRegister, 16, fnoreg, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulF(vRegF dst, vRegF fsrc, vReg vsrc, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) <= 16);\n+  match(Set dst (MulReductionVF fsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_mulF $dst, $fsrc, $vsrc\\t# 2F\/4F. KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_mul_fp($dst$$FloatRegister, T_FLOAT, $fsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reduce_mulD(vRegD dst, vRegD dsrc, vReg vsrc, vReg tmp) %{\n+  predicate(Matcher::vector_length_in_bytes(n->in(2)) == 16);\n+  match(Set dst (MulReductionVD dsrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_mulD $dst, $dsrc, $vsrc\\t# 2D. KILL $tmp\" %}\n+  ins_encode %{\n+    __ neon_reduce_mul_fp($dst$$FloatRegister, T_DOUBLE, $dsrc$$FloatRegister,\n+                          $vsrc$$FloatRegister, 16, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+dnl\n+dnl REDUCE_BITWISE_OP_NEON($1,        $2       $3    $4     )\n+dnl REDUCE_BITWISE_OP_NEON(insn_name, is_long, type, op_name)\n+define(`REDUCE_BITWIESE_OP_NEON', `\n+instruct reduce_$1$2_neon(iReg$2NoSp dst, $3 isrc, vReg vsrc) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) ifelse($2, L, ==, !=) T_LONG);\n+  match(Set dst ($4 isrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_$1$2_neon $dst, $isrc, $vsrc\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_logical(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_BITWISE_OP_SVE($1,        $2       $3    $4     )\n+dnl REDUCE_BITWISE_OP_SVE(insn_name, is_long, type, op_name)\n+define(`REDUCE_BITWIESE_OP_SVE', `\n+instruct reduce_$1$2_sve(iReg$2NoSp dst, $3 isrc, vReg vsrc, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) ifelse($2, L, ==, !=) T_LONG);\n+  match(Set dst ($4 isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_$1$2_sve $dst, $isrc, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_BITWISE_OP_PREDICATE($1,        $2       $3    $4     )\n+dnl REDUCE_BITWISE_OP_PREDICATE(insn_name, is_long, type, op_name)\n+define(`REDUCE_BITWIESE_OP_PREDICATE', `\n+instruct reduce_$1$2_masked(iReg$2NoSp dst, $3 isrc, vReg vsrc, pRegGov pg, vRegD tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) ifelse($2, L, ==, !=) T_LONG);\n+  match(Set dst ($4 (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"reduce_$1$2_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ------------------------------ Vector reduction and -------------------------\n+\n+\/\/ reduction andI\n+REDUCE_BITWIESE_OP_NEON(and, I, iRegIorL2I, AndReductionV)\n+REDUCE_BITWIESE_OP_SVE(and, I, iRegIorL2I, AndReductionV)\n+\n+\/\/ reduction andL\n+REDUCE_BITWIESE_OP_NEON(and, L, iRegL, AndReductionV)\n+REDUCE_BITWIESE_OP_SVE(and, L, iRegL, AndReductionV)\n+\n+\/\/ reduction and - predicated\n+REDUCE_BITWIESE_OP_PREDICATE(and, I, iRegIorL2I, AndReductionV)\n+REDUCE_BITWIESE_OP_PREDICATE(and, L, iRegL,      AndReductionV)\n+\n+\/\/ ------------------------------ Vector reduction or --------------------------\n+\n+\/\/ reduction orI\n+REDUCE_BITWIESE_OP_NEON(or, I, iRegIorL2I, OrReductionV)\n+REDUCE_BITWIESE_OP_SVE(or, I, iRegIorL2I, OrReductionV)\n+\n+\/\/ reduction orL\n+REDUCE_BITWIESE_OP_NEON(or, L, iRegL, OrReductionV)\n+REDUCE_BITWIESE_OP_SVE(or, L, iRegL, OrReductionV)\n+\n+\/\/ reduction or - predicated\n+REDUCE_BITWIESE_OP_PREDICATE(or, I, iRegIorL2I, OrReductionV)\n+REDUCE_BITWIESE_OP_PREDICATE(or, L, iRegL,      OrReductionV)\n+\n+\/\/ ------------------------------ Vector reduction xor -------------------------\n+\n+\/\/ reduction xorI\n+REDUCE_BITWIESE_OP_NEON(xor, I, iRegIorL2I, XorReductionV)\n+REDUCE_BITWIESE_OP_SVE(xor, I, iRegIorL2I, XorReductionV)\n+\n+\/\/ reduction xorL\n+REDUCE_BITWIESE_OP_NEON(xor, L, iRegL, XorReductionV)\n+REDUCE_BITWIESE_OP_SVE(xor, L, iRegL, XorReductionV)\n+\n+\/\/ reduction xor - predicated\n+REDUCE_BITWIESE_OP_PREDICATE(xor, I, iRegIorL2I, XorReductionV)\n+REDUCE_BITWIESE_OP_PREDICATE(xor, L, iRegL,      XorReductionV)\n+\n+dnl\n+dnl REDUCE_MAXMIN_I_NEON($1,   $2     )\n+dnl REDUCE_MAXMIN_I_NEON(type, op_name)\n+define(`REDUCE_MAXMIN_I_NEON', `\n+instruct reduce_$1I_neon(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                          vReg tmp, rFlagsReg cr) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) &&\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_INT));\n+  match(Set dst ($2 isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_$1I_neon $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    __ neon_reduce_minmax_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                                   $isrc$$Register, $vsrc$$FloatRegister,\n+                                   length_in_bytes, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_I_SVE($1,   $2     )\n+dnl REDUCE_MAXMIN_I_SVE(type, op_name)\n+define(`REDUCE_MAXMIN_I_SVE', `\n+instruct reduce_$1I_sve(iRegINoSp dst, iRegIorL2I isrc, vReg vsrc,\n+                         vRegD tmp, rFlagsReg cr) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(2))) &&\n+            (Matcher::vector_element_basic_type(n->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(2)) == T_INT));\n+  match(Set dst ($2 isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_$1I_sve $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_NEON($1,   $2     )\n+dnl REDUCE_MAXMIN_L_NEON(type, op_name)\n+define(`REDUCE_MAXMIN_L_NEON', `\n+instruct reduce_$1L_neon(iRegLNoSp dst, iRegL isrc, vReg vsrc, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst ($2 isrc vsrc));\n+  effect(TEMP_DEF dst, KILL cr);\n+  format %{ \"reduce_$1L_neon $dst, $isrc, $vsrc\\t# 2L. KILL cr\" %}\n+  ins_encode %{\n+    __ neon_reduce_minmax_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                                   $isrc$$Register, $vsrc$$FloatRegister,\n+                                   \/* vector_length_in_bytes *\/ 16, fnoreg);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_L_SVE($1,   $2     )\n+dnl REDUCE_MAXMIN_L_SVE(type, op_name)\n+define(`REDUCE_MAXMIN_L_SVE', `\n+instruct reduce_$1L_sve(iRegLNoSp dst, iRegL isrc, vReg vsrc,\n+                         vRegD tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(2)) == T_LONG);\n+  match(Set dst ($2 isrc vsrc));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_$1L_sve $dst, $isrc, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, T_LONG,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           ptrue, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_F($1,   $2,      $3,    $4,    $5,    $6   )\n+dnl REDUCE_MAXMIN_F(type, op_name, insn1, insn2, insn3, insn4)\n+define(`REDUCE_MAXMIN_F', `\n+instruct reduce_$1F(vRegF dst, vRegF fsrc, vReg vsrc) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(2)) == T_FLOAT);\n+  match(Set dst ($2 fsrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_$1F $dst, $fsrc, $vsrc\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      if (length_in_bytes == 8) {\n+        __ $3($dst$$FloatRegister, $vsrc$$FloatRegister, __ S);\n+      } else {\n+        __ $4($dst$$FloatRegister, __ T4S, $vsrc$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+      __ $5($dst$$FloatRegister, __ S, ptrue, $vsrc$$FloatRegister);\n+    }\n+    __ $6($dst$$FloatRegister, $dst$$FloatRegister, $fsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_D($1,   $2,      $3,    $4,    $5   )\n+dnl REDUCE_MAXMIN_D(type, op_name, insn1, insn2, insn3)\n+define(`REDUCE_MAXMIN_D', `\n+instruct reduce_$1D(vRegD dst, vRegD dsrc, vReg vsrc) %{\n+  predicate(Matcher::vector_element_basic_type(n->in(2)) == T_DOUBLE);\n+  match(Set dst ($2 dsrc vsrc));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_$1D $dst, $dsrc, $vsrc\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $vsrc);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ $3($dst$$FloatRegister, $vsrc$$FloatRegister, __ D);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+      __ $4($dst$$FloatRegister, __ D, ptrue, $vsrc$$FloatRegister);\n+    }\n+    __ $5($dst$$FloatRegister, $dst$$FloatRegister, $dsrc$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_INT_PREDICATE($1,   $2,      $3,       $4     )\n+dnl REDUCE_MAXMIN_INT_PREDICATE(type, is_long, arg_type, op_name)\n+define(`REDUCE_MAXMIN_INT_PREDICATE', `\n+instruct reduce_$1$2_masked(iReg$2NoSp dst, $3 isrc, vReg vsrc, pRegGov pg,\n+                            vRegD tmp, rFlagsReg cr) %{\n+  ifelse($2, I,\n+       `predicate(UseSVE > 0 &&\n+            (Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_INT));',\n+       `predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == T_LONG);')\n+  match(Set dst ($4 (Binary isrc vsrc) pg));\n+  effect(TEMP_DEF dst, TEMP tmp, KILL cr);\n+  format %{ \"reduce_$1$2_masked $dst, $isrc, $pg, $vsrc\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $vsrc);\n+    __ sve_reduce_integral(this->ideal_Opcode(), $dst$$Register, bt,\n+                           $isrc$$Register, $vsrc$$FloatRegister,\n+                           $pg$$PRegister, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REDUCE_MAXMIN_FP_PREDICATE($1,   $2,       $3,       $4,      $5,    $6   )\n+dnl REDUCE_MAXMIN_FP_PREDICATE(type, is_float, arg_name, op_name, insn1, insn2)\n+define(`REDUCE_MAXMIN_FP_PREDICATE', `\n+instruct reduce_$1$2_masked(vReg$2 dst, vReg$2 $3, vReg vsrc, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n->in(1)->in(2)) == ifelse($2, F, T_FLOAT, T_DOUBLE));\n+  match(Set dst ($4 (Binary $3 vsrc) pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"reduce_$1$2_masked $dst, $$3, $pg, $vsrc\" %}\n+  ins_encode %{\n+    __ $5($dst$$FloatRegister, __ ifelse($2, F, S, D), $pg$$PRegister, $vsrc$$FloatRegister);\n+    __ $6($dst$$FloatRegister, $dst$$FloatRegister, $$3$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ ------------------------------ Vector reduction max -------------------------\n+\n+\/\/ reduction maxI\n+REDUCE_MAXMIN_I_NEON(max, MaxReductionV)\n+REDUCE_MAXMIN_I_SVE(max, MaxReductionV)\n+\n+\/\/ reduction maxL\n+REDUCE_MAXMIN_L_NEON(max, MaxReductionV)\n+REDUCE_MAXMIN_L_SVE(max, MaxReductionV)\n+\n+\/\/ reduction maxF\n+REDUCE_MAXMIN_F(max, MaxReductionV, fmaxp, fmaxv, sve_fmaxv, fmaxs)\n+\n+\/\/ reduction maxD\n+REDUCE_MAXMIN_D(max, MaxReductionV, fmaxp, sve_fmaxv, fmaxd)\n+\n+\/\/ reduction max - predicated\n+REDUCE_MAXMIN_INT_PREDICATE(max, I, iRegIorL2I, MaxReductionV)\n+REDUCE_MAXMIN_INT_PREDICATE(max, L, iRegL,      MaxReductionV)\n+REDUCE_MAXMIN_FP_PREDICATE(max, F, fsrc, MaxReductionV, sve_fmaxv, fmaxs)\n+REDUCE_MAXMIN_FP_PREDICATE(max, D, dsrc, MaxReductionV, sve_fmaxv, fmaxd)\n+\n+\/\/ ------------------------------ Vector reduction min -------------------------\n+\n+\/\/ reduction minI\n+REDUCE_MAXMIN_I_NEON(min, MinReductionV)\n+REDUCE_MAXMIN_I_SVE(min, MinReductionV)\n+\n+\/\/ reduction minL\n+REDUCE_MAXMIN_L_NEON(min, MinReductionV)\n+REDUCE_MAXMIN_L_SVE(min, MinReductionV)\n+\n+\/\/ reduction minF\n+REDUCE_MAXMIN_F(min, MinReductionV, fminp, fminv, sve_fminv, fmins)\n+\n+\/\/ reduction minD\n+REDUCE_MAXMIN_D(min, MinReductionV, fminp, sve_fminv, fmind)\n+\n+\/\/ reduction min - predicated\n+REDUCE_MAXMIN_INT_PREDICATE(min, I, iRegIorL2I, MinReductionV)\n+REDUCE_MAXMIN_INT_PREDICATE(min, L, iRegL,      MinReductionV)\n+REDUCE_MAXMIN_FP_PREDICATE(min, F, fsrc, MinReductionV, sve_fminv, fmins)\n+REDUCE_MAXMIN_FP_PREDICATE(min, D, dsrc, MinReductionV, sve_fminv, fmind)\n+\n+\/\/ ------------------------------ Vector reinterpret ---------------------------\n+\n+instruct reinterpret_same_size(vReg dst_src) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst_src (VectorReinterpret dst_src));\n+  ins_cost(0);\n+  format %{ \"reinterpret_same_size $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct reinterpret_resize_le128b(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_length_in_bytes(n) != Matcher::vector_length_in_bytes(n->in(1)) &&\n+            Matcher::vector_length_in_bytes(n) <= 16 &&\n+            Matcher::vector_length_in_bytes(n->in(1)) <= 16);\n+  match(Set dst (VectorReinterpret src));\n+  format %{ \"reinterpret_resize_le128b $dst, $src\\t# vector <= 128 bits.\" %}\n+  ins_encode %{\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    \/\/ The higher bits in \"dst\" register must be cleared to zero.\n+    if ((length_in_bytes_src == 4 && length_in_bytes_dst == 8) ||\n+        (length_in_bytes_src == 8 && length_in_bytes_dst == 4)) {\n+      \/\/ Reinterpret between 32 bits and 64 bits\n+      __ dup($dst$$FloatRegister, __ S, $src$$FloatRegister);\n+    } else if ((length_in_bytes_src == 4 && length_in_bytes_dst == 16) ||\n+               (length_in_bytes_src == 16 && length_in_bytes_dst == 4)) {\n+      \/\/ Reinterpret between 32 bits and 128 bits\n+      __ dup($dst$$FloatRegister, __ S, $src$$FloatRegister);\n+    } else if ((length_in_bytes_src == 8 && length_in_bytes_dst == 16) ||\n+               (length_in_bytes_src == 16 && length_in_bytes_dst == 8)) {\n+      \/\/ Reinterpret between 64 bits and 128 bits\n+      __ orr($dst$$FloatRegister, __ T8B, $src$$FloatRegister, $src$$FloatRegister);\n+    } else {\n+      assert(false, \"invalid vector length\");\n+      ShouldNotReachHere();\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct reinterpret_resize_gt128b(vReg dst, vReg src, pReg ptmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) != Matcher::vector_length_in_bytes(n->in(1)) &&\n+            (Matcher::vector_length_in_bytes(n) > 16 ||\n+             Matcher::vector_length_in_bytes(n->in(1)) > 16));\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP_DEF dst, TEMP ptmp, KILL cr);\n+  format %{ \"reinterpret_resize_gt128b $dst, $src\\t# vector > 128 bits. KILL $ptmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    uint length_in_bytes_resize = length_in_bytes_src < length_in_bytes_dst ?\n+                                  length_in_bytes_src : length_in_bytes_dst;\n+    assert(length_in_bytes_src <= MaxVectorSize && length_in_bytes_dst <= MaxVectorSize,\n+           \"invalid vector length\");\n+    __ sve_gen_mask_imm($ptmp$$PRegister, T_BYTE, length_in_bytes_resize);\n+    __ sve_dup($dst$$FloatRegister, __ B, 0);\n+    __ sve_sel($dst$$FloatRegister, __ B, $ptmp$$PRegister,\n+               $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector cast ----------------------------------\n+\n+\/\/ VectorCastB2X\n+\n+instruct vcvtBtoX(vReg dst, vReg src) %{\n+  match(Set dst (VectorCastB2X src));\n+  format %{ \"vcvtBtoX $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 4B to 4S\/4I\/4F, 8B to 8S\n+      __ neon_vector_extend($dst$$FloatRegister, bt == T_FLOAT ? T_INT : bt,\n+                            length_in_bytes, $src$$FloatRegister, T_BYTE);\n+      if (bt == T_FLOAT) {\n+        __ scvtfv(__ T4S, $dst$$FloatRegister, $dst$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+      __ sve_vector_extend($dst$$FloatRegister, size, $src$$FloatRegister, __ B);\n+      if (is_floating_point_type(bt)) {\n+        __ sve_scvtf($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister, size);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastS2X\n+\n+instruct vcvtStoB_neon(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastS2X src));\n+  format %{ \"vcvtStoB_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 4S\/8S to 4B\/8B\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ neon_vector_narrow($dst$$FloatRegister, T_BYTE,\n+                          $src$$FloatRegister, T_SHORT, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoB_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastS2X src));\n+  effect(TEMP tmp);\n+  format %{ \"vcvtStoB_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_vector_narrow($dst$$FloatRegister, __ B,\n+                         $src$$FloatRegister, __ H, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtStoX_extend(vReg dst, vReg src) %{\n+  predicate(type2aelembytes(Matcher::vector_element_basic_type(n)) >= 4);\n+  match(Set dst (VectorCastS2X src));\n+  format %{ \"vcvtStoX_extend $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 4S to 4I\/4F\n+      __ neon_vector_extend($dst$$FloatRegister, T_INT, length_in_bytes,\n+                            $src$$FloatRegister, T_SHORT);\n+      if (bt == T_FLOAT) {\n+        __ scvtfv(__ T4S, $dst$$FloatRegister, $dst$$FloatRegister);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+      __ sve_vector_extend($dst$$FloatRegister, size, $src$$FloatRegister, __ H);\n+      if (is_floating_point_type(bt)) {\n+        __ sve_scvtf($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister, size);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastI2X\n+\n+instruct vcvtItoX_narrow_neon(vReg dst, vReg src) %{\n+  predicate((Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT) &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vcvtItoX_narrow_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 4I to 4B\/4S\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ neon_vector_narrow($dst$$FloatRegister, bt,\n+                          $src$$FloatRegister, T_INT, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoX_narrow_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate((Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT) &&\n+            !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastI2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtItoX_narrow_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $src$$FloatRegister, __ S, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtItoX(vReg dst, vReg src) %{\n+  predicate(type2aelembytes(Matcher::vector_element_basic_type(n)) >= 4);\n+  match(Set dst (VectorCastI2X src));\n+  format %{ \"vcvtItoX $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes =  Matcher::vector_length_in_bytes(this);\n+    if (bt == T_FLOAT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 2I\/4I to 2F\/4F\n+        __ scvtfv(get_arrangement(this), $dst$$FloatRegister, $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_scvtf($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ S);\n+      }\n+    } else {\n+      assert(type2aelembytes(bt) == 8, \"unsupported type\");\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 2I to 2L\/2D\n+        __ neon_vector_extend($dst$$FloatRegister, T_LONG, length_in_bytes,\n+                              $src$$FloatRegister, T_INT);\n+        if (bt == T_DOUBLE) {\n+          __ scvtfv(__ T2D, $dst$$FloatRegister, $dst$$FloatRegister);\n+        }\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ S);\n+        if (bt == T_DOUBLE) {\n+          __ sve_scvtf($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ D);\n+        }\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastL2X\n+\n+instruct vcvtLtoI_neon(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_INT &&\n+            VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))));\n+  match(Set dst (VectorCastL2X src));\n+  format %{ \"vcvtLtoI_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 2L to 2I\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ neon_vector_narrow($dst$$FloatRegister, T_INT,\n+                          $src$$FloatRegister, T_LONG, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoI_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate((Matcher::vector_element_basic_type(n) == T_INT &&\n+             !VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1)))) ||\n+            Matcher::vector_element_basic_type(n) == T_BYTE ||\n+            Matcher::vector_element_basic_type(n) == T_SHORT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtLtoI_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $src$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoF_neon(vReg dst, vReg src, vRegF tmp) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtLtoF_neon $dst, $src\\t# 2L to 2F. KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ 2L to 2F\n+    __ umov(rscratch1, $src$$FloatRegister, __ D, 0);\n+    __ scvtfs($dst$$FloatRegister, rscratch1);\n+    __ umov(rscratch1, $src$$FloatRegister, __ D, 1);\n+    __ scvtfs($tmp$$FloatRegister, rscratch1);\n+    __ ins($dst$$FloatRegister, __ S, $tmp$$FloatRegister, 1, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoF_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorCastL2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtLtoF_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ sve_scvtf($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ D);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ S,\n+                         $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtLtoD(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorCastL2X src));\n+  format %{ \"vcvtLtoD $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 2L to 2D\n+      __ scvtfv(__ T2D, $dst$$FloatRegister, $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_scvtf($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister, __ D);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastF2X\n+\n+instruct vcvtFtoX_narrow_neon(vReg dst, vReg src) %{\n+  predicate(VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))) &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT));\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vcvtFtoX_narrow_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ 4F to 4B\/4S\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ fcvtzs($dst$$FloatRegister, __ T4S, $src$$FloatRegister);\n+    __ neon_vector_narrow($dst$$FloatRegister, bt,\n+                          $dst$$FloatRegister, T_INT, length_in_bytes);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoX_narrow_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(!VM_Version::use_neon_for_vector(Matcher::vector_length_in_bytes(n->in(1))) &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT));\n+  match(Set dst (VectorCastF2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtFtoX_narrow_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ S);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $dst$$FloatRegister, __ S, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtFtoX(vReg dst, vReg src) %{\n+  predicate(type2aelembytes(Matcher::vector_element_basic_type(n)) >= 4);\n+  match(Set dst (VectorCastF2X src));\n+  format %{ \"vcvtFtoX $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes =  Matcher::vector_length_in_bytes(this);\n+    if (bt == T_INT) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 2F\/4F to 2I\/4I\n+        __ fcvtzs($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ S);\n+      }\n+    } else if (bt == T_LONG) {\n+      if (UseSVE == 0) {\n+        \/\/ 2F to 2L\n+        __ fcvtl($dst$$FloatRegister, __ T2D, $src$$FloatRegister, __ T2S);\n+        __ fcvtzs($dst$$FloatRegister, __ T2D, $dst$$FloatRegister);\n+      } else {\n+        __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ S);\n+        __ sve_fcvtzs($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ S);\n+      }\n+    } else {\n+      assert(bt == T_DOUBLE, \"unsupported type\");\n+      if (length_in_bytes == 16) {\n+        \/\/ 2F to 2D\n+        __ fcvtl($dst$$FloatRegister, __ T2D, $src$$FloatRegister, __ T2S);\n+      } else {\n+        assert(UseSVE > 0 && length_in_bytes > 16, \"must be\");\n+        __ sve_vector_extend($dst$$FloatRegister, __ D, $src$$FloatRegister, __ S);\n+        __ sve_fcvt($dst$$FloatRegister, __ D, ptrue, $dst$$FloatRegister, __ S);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorCastD2X\n+\n+instruct vcvtDtoI_neon(vReg dst, vReg src) %{\n+  predicate(UseSVE == 0 && Matcher::vector_element_basic_type(n) == T_INT);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vcvtDtoI_neon $dst, $src\\t# 2D to 2I\" %}\n+  ins_encode %{\n+    \/\/ 2D to 2I\n+    __ ins($dst$$FloatRegister, __ D, $src$$FloatRegister, 0, 1);\n+    \/\/ We can't use fcvtzs(vector, integer) instruction here because we need\n+    \/\/ saturation arithmetic. See JDK-8276151.\n+    __ fcvtzdw(rscratch1, $src$$FloatRegister);\n+    __ fcvtzdw(rscratch2, $dst$$FloatRegister);\n+    __ fmovs($dst$$FloatRegister, rscratch1);\n+    __ mov($dst$$FloatRegister, __ S, 1, rscratch2);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoI_sve(vReg dst, vReg src, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtDtoI_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_fcvtzs($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ D);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                         $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoL(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorCastD2X src));\n+  format %{ \"vcvtDtoL $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes =  Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      \/\/ 2D to 2L\n+      __ fcvtzs($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_fcvtzs($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister, __ D);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF_64b(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_FLOAT &&\n+            Matcher::vector_length_in_bytes(n) == 8);\n+  match(Set dst (VectorCastD2X src));\n+  format %{ \"vcvtDtoF_64b $dst, $src\\t# 2D to 2F\" %}\n+  ins_encode %{\n+    \/\/ 2D to 2F\n+    __ fcvtn($dst$$FloatRegister, __ T2S, $src$$FloatRegister, __ T2D);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcvtDtoF_gt64b(vReg dst, vReg src, vReg tmp) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_FLOAT &&\n+            Matcher::vector_length_in_bytes(n) > 8);\n+  match(Set dst (VectorCastD2X src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vcvtDtoF_gt64b $dst, $src\\t# vector > 64 bits. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_fcvt($dst$$FloatRegister, __ S, ptrue, $src$$FloatRegister, __ D);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ S,\n+                         $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Replicate ------------------------------------\n+\n+dnl REPLICATE_INT($1,   $2,       $3  )\n+dnl REPLICATE_INT(type, arg_type, size)\n+define(`REPLICATE_INT', `\n+instruct replicate$1(vReg dst, $2 src) %{\n+  match(Set dst (Replicate$1 src));\n+  format %{ \"replicate$1 $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$Register);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_dup($dst$$FloatRegister, __ $3, $src$$Register);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REPLICATE_FP($1,   $2  )\n+dnl REPLICATE_FP(type, size)\n+define(`REPLICATE_FP', `\n+instruct replicate$1(vReg dst, vReg$1 src) %{\n+  match(Set dst (Replicate$1 src));\n+  format %{ \"replicate$1 $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ dup($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_cpy($dst$$FloatRegister, __ $2, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl REPLICATE_IMM_SVE($1,   $2,       $3  )\n+dnl REPLICATE_IMM_SVE(type, arg_type, size)\n+define(`REPLICATE_IMM_SVE', `\n+instruct replicate$1_imm8_gt128b(vReg dst, $2 con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (Replicate$1 con));\n+  format %{ \"replicate$1_imm8_gt128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_dup($dst$$FloatRegister, __ $3, (int)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ replicate from reg\n+REPLICATE_INT(B, iRegIorL2I, B)\n+REPLICATE_INT(S, iRegIorL2I, H)\n+REPLICATE_INT(I, iRegIorL2I, S)\n+REPLICATE_INT(L, iRegL,      D)\n+REPLICATE_FP(F, S)\n+REPLICATE_FP(D, D)\n+\n+\/\/ replicate from imm\n+\n+instruct replicateI_imm_le128b(vReg dst, immI con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (ReplicateB con));\n+  match(Set dst (ReplicateS con));\n+  match(Set dst (ReplicateI con));\n+  format %{ \"replicateI_imm_le128b $dst, $con\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    int imm = (int)$con$$constant;\n+    if (type2aelembytes(bt) == 1) {\n+      \/\/ Refine imm for B\n+      imm = imm & 0xff;\n+    } else if (type2aelembytes(bt) == 2) {\n+      \/\/ Refine imm for S\n+      imm = imm & 0xffff;\n+    }\n+    __ mov($dst$$FloatRegister, get_arrangement(this), imm);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+REPLICATE_IMM_SVE(B, immI8,        B)\n+REPLICATE_IMM_SVE(S, immI8_shift8, H)\n+REPLICATE_IMM_SVE(I, immI8_shift8, S)\n+\n+instruct replicateL_imm_128b(vReg dst, immL con) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16);\n+  match(Set dst (ReplicateL con));\n+  format %{ \"replicateL_imm_128b $dst, $con\\t# vector > 128 bits\" %}\n+  ins_encode %{\n+    __ mov($dst$$FloatRegister, __ T2D, (uint64_t)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+dnl\n+REPLICATE_IMM_SVE(L, immL8_shift8, D)\n+\n+\/\/ ------------------------------ Vector insert --------------------------------\n+\n+\/\/ BYTE, SHORT, INT\n+\n+instruct insertI_le128b(vReg dst, vReg src, iRegIorL2I val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  format %{ \"insertI_le128b $dst, $src, $val, $idx\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ mov($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+           (int)($idx$$constant), $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertI_index_lt32(vReg dst, vReg src, iRegIorL2I val, immI idx,\n+                            vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() < 32 &&\n+            Matcher::vector_length_in_bytes(n) > 16 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"insertI_index_lt32 $dst, $src, $val, $idx\\t# vector > 128 bits, index < 31. KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index($tmp$$FloatRegister, size, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, size, ptrue,\n+               $tmp$$FloatRegister, (int)($idx$$constant) - 16);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ sve_cpy($dst$$FloatRegister, size, $pgtmp$$PRegister, $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertI_index_ge32(vReg dst, vReg src, iRegIorL2I val, immI idx, vReg tmp1,\n+                            vReg tmp2, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() >= 32 &&\n+            (Matcher::vector_element_basic_type(n) == T_BYTE ||\n+             Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             Matcher::vector_element_basic_type(n) == T_INT));\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP pgtmp, KILL cr);\n+  format %{ \"insertI_index_ge32 $dst, $src, $val, $idx\\t# index >= 32. KILL $tmp1, $tmp2, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_index($tmp1$$FloatRegister, size, 0, 1);\n+    __ sve_dup($tmp2$$FloatRegister, size, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, size, ptrue,\n+               $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ sve_cpy($dst$$FloatRegister, size, $pgtmp$$PRegister, $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ LONG\n+\n+instruct insertL_128b(vReg dst, vReg src, iRegL val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16 &&\n+            Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  format %{ \"insertL_128b $dst, $src, $val, $idx\\t# 2L\" %}\n+  ins_encode %{\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, __ T16B, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ mov($dst$$FloatRegister, __ D, (int)($idx$$constant), $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertL_gt128b(vReg dst, vReg src, iRegL val, immI idx,\n+                        vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16 &&\n+            Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"insertL_gt128b $dst, $src, $val, $idx\\t# vector > 128 bits. KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($tmp$$FloatRegister, __ D, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ D, ptrue,\n+               $tmp$$FloatRegister, (int)($idx$$constant) - 16);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ sve_cpy($dst$$FloatRegister, __ D, $pgtmp$$PRegister, $val$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ FLOAT\n+\n+instruct insertF_le128b(vReg dst, vReg src, vRegF val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"insertF_le128b $dst, $src, $val, $idx\\t# vector <= 128 bits\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ ins($dst$$FloatRegister, __ S, $val$$FloatRegister, (int)($idx$$constant), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertF_index_lt32(vReg dst, vReg src, vRegF val, immI idx,\n+                            pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() < 32 &&\n+            Matcher::vector_length_in_bytes(n) > 16 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pgtmp, KILL cr);\n+  format %{ \"insertF_index_lt32 $dst, $src, $val, $idx\\t# vector > 128 bits, index < 32. KILL $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($dst$$FloatRegister, __ S, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ S, ptrue,\n+               $dst$$FloatRegister, (int)($idx$$constant) - 16);\n+    __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    __ sve_cpy($dst$$FloatRegister, __ S, $pgtmp$$PRegister, $val$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertF_index_ge32(vReg dst, vReg src, vRegF val, immI idx, vReg tmp,\n+                            pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(n->in(2)->get_int() >= 32 &&\n+            Matcher::vector_element_basic_type(n) == T_FLOAT);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"insertF_index_ge32 $dst, $src, $val, $idx\\t# index >= 32. KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($tmp$$FloatRegister, __ S, 0, 1);\n+    __ sve_dup($dst$$FloatRegister, __ S, (int)($idx$$constant));\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ S, ptrue,\n+               $tmp$$FloatRegister, $dst$$FloatRegister);\n+    __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    __ sve_cpy($dst$$FloatRegister, __ S, $pgtmp$$PRegister, $val$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ DOUBLE\n+\n+instruct insertD_128b(vReg dst, vReg src, vRegD val, immI idx) %{\n+  predicate(Matcher::vector_length_in_bytes(n) == 16 &&\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"insertD_128b $dst, $src, $val, $idx\\t# 2D\" %}\n+  ins_encode %{\n+    if ($dst$$FloatRegister != $src$$FloatRegister) {\n+      __ orr($dst$$FloatRegister, __ T16B, $src$$FloatRegister, $src$$FloatRegister);\n+    }\n+    __ ins($dst$$FloatRegister, __ D, $val$$FloatRegister, (int)($idx$$constant), 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct insertD_gt128b(vReg dst, vReg src, vRegD val, immI idx,\n+                        pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16 &&\n+            Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (VectorInsert (Binary src val) idx));\n+  effect(TEMP_DEF dst, TEMP pgtmp, KILL cr);\n+  format %{ \"insertD_gt128b $dst, $src, $val, $idx\\t# vector > 128 bits. KILL $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_index($dst$$FloatRegister, __ D, -16, 1);\n+    __ sve_cmp(Assembler::EQ, $pgtmp$$PRegister, __ D, ptrue,\n+               $dst$$FloatRegister, (int)($idx$$constant) - 16);\n+    __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+    __ sve_cpy($dst$$FloatRegister, __ D, $pgtmp$$PRegister, $val$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Extract --------------------------------------\n+dnl\n+dnl EXTRACT_INT_SMALL($1,   $2,    $3,       $4,   $5  )\n+dnl EXTRACT_INT_SMALL(type, index, arg_type, insn, size)\n+define(`EXTRACT_INT_SMALL', `\n+instruct extract$1_index_lt$2($3 dst, vReg src, immI idx) %{\n+  predicate(n->in(2)->get_int() < $2);\n+  match(Set dst (Extract$1 src idx));\n+  format %{ \"extract$1_index_lt$2 $dst, $src, $idx\\t# index < $2\" %}\n+  ins_encode %{\n+    __ $4($dst$$Register, $src$$FloatRegister, __ $5, (int)($idx$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl\n+dnl EXTRACT_INT_LARGE($1,   $2,    $3,       $4       )\n+dnl EXTRACT_INT_LARGE(type, index, arg_type, data_type)\n+define(`EXTRACT_INT_LARGE', `\n+instruct extract$1_index_ge$2($3 dst, vReg src, immI idx, vReg tmp) %{\n+  predicate(n->in(2)->get_int() >= $2);\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP tmp);\n+  format %{ \"extract$1_index_ge$2 $dst, $src, $idx\\t# index >=$2. KILL $tmp\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    __ sve_extract_integral($dst$$Register, $4, $src$$FloatRegister,\n+                            (int)($idx$$constant), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ BYTE\n+EXTRACT_INT_SMALL(B, 16, iRegINoSp, smov, B)\n+EXTRACT_INT_LARGE(B, 16, iRegINoSp, T_BYTE)\n+\n+\/\/ SHORT\n+EXTRACT_INT_SMALL(S, 8, iRegINoSp, smov, H)\n+EXTRACT_INT_LARGE(S, 8, iRegINoSp, T_SHORT)\n+\n+\/\/ INT\n+EXTRACT_INT_SMALL(I, 4, iRegINoSp, umov, S)\n+EXTRACT_INT_LARGE(I, 4, iRegINoSp, T_INT)\n+\n+\/\/ LONG\n+EXTRACT_INT_SMALL(L, 2, iRegLNoSp, umov, D)\n+EXTRACT_INT_LARGE(L, 2, iRegLNoSp, T_LONG)\n+\n+dnl\n+dnl EXTRACT_FP($1,   $2,   $3,    $4,   $5   )\n+dnl EXTRACT_FP(type, insn, index, size, shift)\n+define(`EXTRACT_FP', `\n+instruct extract$1(vReg$1 dst, vReg src, immI idx) %{\n+  match(Set dst (Extract$1 src idx));\n+  effect(TEMP_DEF dst);\n+  format %{ \"extract$1 $dst, $src, $idx\" %}\n+  ins_encode %{\n+    int index = (int)$idx$$constant;\n+    if (index == 0) {\n+      __ $2($dst$$FloatRegister, $src$$FloatRegister);\n+    } else if (index < $3) {\n+      __ ins($dst$$FloatRegister, __ $4, $src$$FloatRegister, 0, index);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+      __ sve_ext($dst$$FloatRegister, $dst$$FloatRegister, index << $5);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ FLOAT\n+EXTRACT_FP(F, fmovs, 4, S, 2)\n+\n+\/\/ DOUBLE\n+EXTRACT_FP(D, fmovd, 2, D, 3)\n+\n+\/\/ ------------------------------ Vector mask loat\/store -----------------------\n+\n+\/\/ vector load mask\n+\n+instruct vloadmask_neon(vReg dst, vReg src) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_length_in_bytes(n) == 8 ||\n+             Matcher::vector_length_in_bytes(n) == 16));\n+  match(Set dst (VectorLoadMask src ));\n+  format %{ \"vloadmask_neon $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (bt == T_BYTE) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+              $src$$FloatRegister);\n+    } else {\n+      __ uxtl($dst$$FloatRegister, __ T8H, $src$$FloatRegister, __ T8B);\n+      if (type2aelembytes(bt) >= 4) {\n+        __ uxtl($dst$$FloatRegister, __ T4S, $dst$$FloatRegister, __ T4H);\n+      }\n+      if (type2aelembytes(bt) == 8) {\n+        __ uxtl($dst$$FloatRegister, __ T2D, $dst$$FloatRegister, __ T2S);\n+      }\n+      __ negr($dst$$FloatRegister, get_arrangement(this), $dst$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskB_sve(pRegGov dst, vReg src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            Matcher::vector_element_basic_type(n) == T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  effect(KILL cr);\n+  format %{ \"vloadmaskB_sve $dst, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ B,\n+               ptrue, $src$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_extend_sve(pRegGov dst, vReg src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            Matcher::vector_element_basic_type(n) != T_BYTE);\n+  match(Set dst (VectorLoadMask src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_extend_sve $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_vector_extend($tmp$$FloatRegister, size, $src$$FloatRegister, __ B);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size, ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmaskB_masked(pRegGov dst, vReg src, pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(KILL cr);\n+  format %{ \"vloadmaskB_masked $dst, $pg, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ B,\n+               $pg$$PRegister, $src$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vloadmask_extend_masked(pRegGov dst, vReg src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) != T_BYTE);\n+  match(Set dst (VectorLoadMask src pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_extend_masked $dst, $pg, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_vector_extend($tmp$$FloatRegister, size, $src$$FloatRegister, __ B);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size,\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask - neon\n+\n+instruct vstoremaskB_neon(vReg dst, vReg src, immI_1 size) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorStoreMask src size));\n+  format %{ \"vstoremaskB_neon $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ negr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_narrow_neon(vReg dst, vReg src, immI_gt_1 size) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorStoreMask src size));\n+  format %{ \"vstoremask_narrow_neon $dst, $src\" %}\n+  ins_encode %{\n+    int esize = (int)$size$$constant;\n+    if (esize == 2) {\n+      __ xtn($dst$$FloatRegister, __ T8B, $src$$FloatRegister, __ T8H);\n+    } else if (esize == 4) {\n+      __ xtn($dst$$FloatRegister, __ T4H, $src$$FloatRegister, __ T4S);\n+      __ xtn($dst$$FloatRegister, __ T8B, $dst$$FloatRegister, __ T8H);\n+    } else {\n+      assert(esize == 8, \"must be\");\n+      __ xtn($dst$$FloatRegister, __ T2S, $src$$FloatRegister, __ T2D);\n+      __ xtn($dst$$FloatRegister, __ T4H, $dst$$FloatRegister, __ T4S);\n+      __ xtn($dst$$FloatRegister, __ T8B, $dst$$FloatRegister, __ T8H);\n+    }\n+    __ negr($dst$$FloatRegister, __ T8B, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector store mask - sve\n+\n+instruct vstoremaskB_sve(vReg dst, pRegGov src, immI_1 size) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  format %{ \"vstoremaskB_sve $dst, $src\" %}\n+  ins_encode %{\n+    __ sve_cpy($dst$$FloatRegister, __ B, $src$$PRegister, 1, false);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vstoremask_narrow_sve(vReg dst, pRegGov src, immI_gt_1 size, vReg tmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorStoreMask src size));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vstoremask_narrow_sve $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant((int)$size$$constant);\n+    __ sve_cpy($dst$$FloatRegister, size, $src$$PRegister, 1, false);\n+    __ sve_vector_narrow($dst$$FloatRegister, __ B,\n+                         $dst$$FloatRegister, size, $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Combined rules for vector mask load when the vector element type is not T_BYTE\n+\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadV(pRegGov dst, indirect mem, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem)));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadV $dst, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVector, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadV_masked(pRegGov dst, indirect mem, pRegGov pg,\n+                                vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVector mem) pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadV_masked $dst, $pg, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          $pg$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is unpredicated.\n+instruct vloadmask_loadVMasked(pRegGov dst, vmemA mem, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector() &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg)));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadVMasked $dst, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the full-sized predicate (ptrue) used in VectorLoadMask.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ VectorLoadMask+LoadVectorMasked, and the VectorLoadMask is predicated.\n+instruct vloadmask_loadVMasked_masked(pRegGov dst, vmemA mem, pRegGov pg1, pRegGov pg2,\n+                                      vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) > 1);\n+  match(Set dst (VectorLoadMask (LoadVectorMasked mem pg1) pg2));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vloadmask_loadVMasked_masked $dst, $pg2, $mem\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Load valid mask values which are boolean type, and extend them to the\n+    \/\/ defined vector element type. Convert the vector to predicate.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg1\" here, since it is the predicate used\n+    \/\/ for the vector load with boolean type. But the predicate used in\n+    \/\/ the extending \"sve_ld1b\" is based on the final extended vector type,\n+    \/\/ which is the \"pg2\" used in VectorLoadMask.\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), false, $tmp$$FloatRegister,\n+                          $pg2$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, __ elemType_to_regVariant(bt),\n+               $pg2$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Combined rules for vector mask store when the vector element type is not T_BYTE\n+\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeV_vstoremask(indirect mem, pRegGov src, immI_gt_1 esize, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp);\n+  format %{ \"storeV_vstoremask $mem, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(bt) == (int)$esize$$constant, \"unsupported type\");\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVector+VectorStoreMask, and the vector size of \"src\" is less than the MaxVectorSize.\n+instruct storeV_vstoremask_masked(indirect mem, pRegGov src, immI_gt_1 esize,\n+                                  vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVector mem (VectorStoreMask src esize)));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"storeV_vstoremask_masked $mem, $src\\t# KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    __ sve_gen_mask_imm($pgtmp$$PRegister, bt, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          $pgtmp$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is equal to the MaxVectorSize.\n+instruct storeVMasked_vstoremask(vmemA mem, pRegGov src, pRegGov pg, immI_gt_1 esize, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) == MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP tmp);\n+  format %{ \"storeVMasked_vstoremask $mem, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used\n+    \/\/ for the vector store with boolean type. But the predicate used in\n+    \/\/ the narrowing \"sve_st1b\" is based on the \"src\" vector type, which\n+    \/\/ is the full-sized predicate (ptrue) here.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(type2aelembytes(bt) == (int)$esize$$constant, \"unsupported type.\");\n+    Assembler::SIMD_RegVariant size = __ elemBytes_to_regVariant($esize$$constant);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          ptrue, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ StoreVectorMasked+VectorStoreMask, and the vector size of \"src\" is less than the MaxVectorSize.\n+instruct storeVMasked_vstoremask_masked(vmemA mem, pRegGov src, pRegGov pg, immI_gt_1 esize,\n+                                        vReg tmp, pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n->as_StoreVector()->in(MemNode::ValueIn)->in(1)) < MaxVectorSize);\n+  match(Set mem (StoreVectorMasked mem (Binary (VectorStoreMask src esize) pg)));\n+  effect(TEMP tmp, TEMP pgtmp, KILL cr);\n+  format %{ \"storeVMasked_vstoremask_masked $mem, $src\\t# KILL $tmp, $pgtmp, cr\" %}\n+  ins_encode %{\n+    \/\/ Convert the valid src predicate to vector, and store the vector elements\n+    \/\/ as boolean values.\n+    \/\/\n+    \/\/ Note that we cannot use \"pg\" here, since it is the predicate used for the\n+    \/\/ vector store with boolean type. But the predicate used in the narrowing\n+    \/\/ \"sve_st1b\" is based on the \"src\" vector type, which needed to be generated\n+    \/\/ here.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cpy($tmp$$FloatRegister, size, $src$$PRegister, 1, false);\n+    __ sve_gen_mask_imm($pgtmp$$PRegister, bt, Matcher::vector_length(this, $src));\n+    loadStoreA_predicated(C2_MacroAssembler(&cbuf), true, $tmp$$FloatRegister,\n+                          $pgtmp$$PRegister, T_BOOLEAN, bt, $mem->opcode(),\n+                          as_Register($mem$$base), $mem$$index, $mem$$scale, $mem$$disp);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask basic OPs ------------------------\n+\n+dnl\n+dnl VMASK_BITWISE_OP($1,   $2,      $3  )\n+dnl VMASK_BITWISE_OP(type, op_name, insn)\n+define(`VMASK_BITWISE_OP', `\n+instruct vmask_$1(pRegGov pd, pRegGov pn, pRegGov pm) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd ($2 pn pm));\n+  format %{ \"vmask_$1 $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ $3($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMASK_AND_NOT($1  )\n+dnl VMASK_AND_NOT(type)\n+define(`VMASK_AND_NOT', `\n+instruct vmask_and_not$1(pRegGov pd, pRegGov pn, pRegGov pm, imm$1_M1 m1) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (AndVMask pn (XorVMask pm (MaskAll m1))));\n+  format %{ \"vmask_and_not$1 $pd, $pn, $pm\" %}\n+  ins_encode %{\n+    __ sve_bic($pd$$PRegister, ptrue, $pn$$PRegister, $pm$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+\/\/ vector mask logical ops: and\/or\/xor\/and_not\n+VMASK_BITWISE_OP(and, AndVMask, sve_and)\n+VMASK_BITWISE_OP(or,  OrVMask,  sve_orr)\n+VMASK_BITWISE_OP(xor, XorVMask, sve_eor)\n+VMASK_AND_NOT(I)\n+VMASK_AND_NOT(L)\n+\n+\/\/ vector mask compare\n+\n+instruct vmaskcmp_neon(vReg dst, vReg src1, vReg src2, immI cond) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_length_in_bytes(n) == 8 ||\n+             Matcher::vector_length_in_bytes(n) == 16));\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  format %{ \"vmaskcmp_neon $dst, $src1, $src2, $cond\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    __ neon_compare($dst$$FloatRegister, bt, $src1$$FloatRegister,\n+                    $src2$$FloatRegister, (int)($cond$$constant),\n+                    \/* isQ *\/ length_in_bytes == 16);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcmp_sve(pRegGov dst, vReg src1, vReg src2, immI cond, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) cond));\n+  effect(KILL cr);\n+  format %{ \"vmaskcmp_sve $dst, $src1, $src2, $cond\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_compare($dst$$PRegister, bt, ptrue, $src1$$FloatRegister,\n+                   $src2$$FloatRegister, (int)($cond$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcmp_masked(pRegGov dst, vReg src1, vReg src2, immI cond,\n+                         pRegGov pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskCmp (Binary src1 src2) (Binary cond pg)));\n+  effect(KILL cr);\n+  format %{ \"vmaskcmp_masked $dst, $pg, $src1, $src2, $cond\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_compare($dst$$PRegister, bt, $pg$$PRegister, $src1$$FloatRegister,\n+                   $src2$$FloatRegister, (int)($cond$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask cast\n+\n+instruct vmaskcast_same_esize_neon(vReg dst_src) %{\n+  predicate(UseSVE == 0 &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)) &&\n+            (Matcher::vector_length_in_bytes(n) == 8 || Matcher::vector_length_in_bytes(n) == 16));\n+  match(Set dst_src (VectorMaskCast dst_src));\n+  ins_cost(0);\n+  format %{ \"vmaskcast_same_esize_neon $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmaskcast_same_esize_sve(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst_src (VectorMaskCast dst_src));\n+  ins_cost(0);\n+  format %{ \"vmaskcast_same_esize_sve $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmaskcast_extend(pRegGov dst, pReg src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n) > Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst (VectorMaskCast src));\n+  format %{ \"vmaskcast_extend $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes_dst == 2 * length_in_bytes_src ||\n+           length_in_bytes_dst == 4 * length_in_bytes_src ||\n+           length_in_bytes_dst == 8 * length_in_bytes_src, \"invalid vector length\");\n+    __ sve_vmaskcast_extend($dst$$PRegister, $src$$PRegister,\n+                            length_in_bytes_dst, length_in_bytes_src);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmaskcast_narrow(pRegGov dst, pReg src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length_in_bytes(n) < Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst (VectorMaskCast src));\n+  format %{ \"vmaskcast_narrow $dst, $src\" %}\n+  ins_encode %{\n+    uint length_in_bytes_dst = Matcher::vector_length_in_bytes(this);\n+    uint length_in_bytes_src = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes_dst * 2 == length_in_bytes_src ||\n+           length_in_bytes_dst * 4 == length_in_bytes_src ||\n+           length_in_bytes_dst * 8 == length_in_bytes_src, \"invalid vector length\");\n+    __ sve_vmaskcast_narrow($dst$$PRegister, $src$$PRegister,\n+                            length_in_bytes_dst, length_in_bytes_src);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector mask reinterpret\n+\n+instruct vmask_reinterpret_same_esize(pRegGov dst_src) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length(n) == Matcher::vector_length(n->in(1)) &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst_src (VectorReinterpret dst_src));\n+  ins_cost(0);\n+  format %{ \"vmask_reinterpret_same_esize $dst_src\\t# do nothing\" %}\n+  ins_encode(\/* empty encoding *\/);\n+  ins_pipe(pipe_class_empty);\n+%}\n+\n+instruct vmask_reinterpret_diff_esize(pRegGov dst, pRegGov src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            Matcher::vector_length(n) != Matcher::vector_length(n->in(1)) &&\n+            Matcher::vector_length_in_bytes(n) == Matcher::vector_length_in_bytes(n->in(1)));\n+  match(Set dst (VectorReinterpret src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmask_reinterpret_diff_esize $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType from_bt = Matcher::vector_element_basic_type(this, $src);\n+    Assembler::SIMD_RegVariant from_size = __ elemType_to_regVariant(from_bt);\n+    BasicType to_bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant to_size = __ elemType_to_regVariant(to_bt);\n+    __ sve_cpy($tmp$$FloatRegister, from_size, $src$$PRegister, -1, false);\n+    __ sve_cmp(Assembler::EQ, $dst$$PRegister, to_size, ptrue, $tmp$$FloatRegister, -1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask reductions -----------------------\n+\n+\/\/ true count\n+\n+instruct vmask_truecount_neon(iRegINoSp dst, vReg src, vReg tmp) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorMaskTrueCount src));\n+  effect(TEMP tmp);\n+  format %{ \"vmask_truecount_neon $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as bytes with\n+    \/\/ 0x00\/0x01 as element values.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    __ addv($tmp$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+            $src$$FloatRegister);\n+    __ umov($dst$$Register, $tmp$$FloatRegister, __ B, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_truecount_sve(iRegINoSp dst, pReg src) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskTrueCount src));\n+  format %{ \"vmask_truecount_sve $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_cntp($dst$$Register, __ elemType_to_regVariant(bt),\n+                ptrue, $src$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ first true\n+\n+instruct vmask_firsttrue_lt8e(iRegINoSp dst, vReg src, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 &&\n+            Matcher::vector_length(n->in(1)) < 8);\n+  match(Set dst (VectorMaskFirstTrue src));\n+  effect(KILL cr);\n+  format %{ \"vmask_firsttrue_lt8e $dst, $src\\t# vector < 8 elements (neon). KILL cr\" %}\n+  ins_encode %{\n+    \/\/ Returns the index of the first active lane of the\n+    \/\/ vector mask, or VLENGTH if no lane is active.\n+    \/\/\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+    \/\/\n+    \/\/ Computed by reversing the bits and counting the leading\n+    \/\/ zero bytes.\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    __ fmovd($dst$$Register, $src$$FloatRegister);\n+    __ rbit($dst$$Register, $dst$$Register);\n+    __ clz($dst$$Register, $dst$$Register);\n+    __ lsrw($dst$$Register, $dst$$Register, 3);\n+    __ movw(rscratch1, Matcher::vector_length(this, $src));\n+    __ cmpw($dst$$Register, rscratch1);\n+    __ cselw($dst$$Register, rscratch1, $dst$$Register, Assembler::GE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_8or16e(iRegINoSp dst, vReg src) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_length(n->in(1)) == 8 || Matcher::vector_length(n->in(1)) == 16));\n+  match(Set dst (VectorMaskFirstTrue src));\n+  format %{ \"vmask_firsttrue_8or16e $dst, $src\\t# vector 8B\/16B (neon)\" %}\n+  ins_encode %{\n+    \/\/ Returns the index of the first active lane of the\n+    \/\/ vector mask, or VLENGTH if no lane is active.\n+    \/\/\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+    \/\/\n+    \/\/ Computed by reversing the bits and counting the leading\n+    \/\/ zero bytes.\n+\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    if (length_in_bytes == 8) {\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ rbit($dst$$Register, $dst$$Register);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ lsrw($dst$$Register, $dst$$Register, 3);\n+    } else {\n+      assert(length_in_bytes == 16, \"must be\");\n+      Label FIRST_TRUE_INDEX;\n+\n+      \/\/ Try to compute the result from lower 64 bits.\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, zr);\n+      __ cbnz($dst$$Register, FIRST_TRUE_INDEX);\n+\n+      \/\/ Compute the result from the higher 64 bits.\n+      __ fmovhid($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, 8);\n+\n+      \/\/ Reverse the bits and count the leading zero bytes.\n+      __ bind(FIRST_TRUE_INDEX);\n+      __ rbit($dst$$Register, $dst$$Register);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ addw($dst$$Register, rscratch1, $dst$$Register, Assembler::LSR, 3);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ Return the index of the first mask lane that is set, or vector length if none of\n+\/\/ them are set.\n+\n+instruct vmask_firsttrue_sve(iRegINoSp dst, pReg src, pReg ptmp) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n+  match(Set dst (VectorMaskFirstTrue src));\n+  effect(TEMP ptmp);\n+  format %{ \"vmask_firsttrue_sve $dst, $src\\t# KILL $ptmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_brkb($ptmp$$PRegister, ptrue, $src$$PRegister, false);\n+    __ sve_cntp($dst$$Register, __ elemType_to_regVariant(bt), ptrue, $ptmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_firsttrue_masked(iRegINoSp dst, pReg src, pRegGov pg, pReg ptmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskFirstTrue src pg));\n+  effect(TEMP ptmp);\n+  format %{ \"vmask_firsttrue_masked $dst, $pg, $src\\t# KILL $ptmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_brkb($ptmp$$PRegister, $pg$$PRegister, $src$$PRegister, false);\n+    __ sve_cntp($dst$$Register, __ elemType_to_regVariant(bt), ptrue, $ptmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ last true\n+\n+instruct vmask_lasttrue_neon(iRegINoSp dst, vReg src) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorMaskLastTrue src));\n+  format %{ \"vmask_lasttrue_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ Returns the index of the last active lane of the\n+    \/\/ vector mask, or -1 if no lane is active.\n+    \/\/\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    assert(bt == T_BOOLEAN, \"unsupported type\");\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    if (length_in_bytes <= 8) {\n+      \/\/ Computed by counting the leading zero bytes and\n+      \/\/ subtracting it by 7 (VLENGTH - 1).\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ movw(rscratch1, 7);\n+      __ subw($dst$$Register, rscratch1, $dst$$Register, Assembler::LSR, 3);\n+    } else {\n+      assert(length_in_bytes == 16, \"must be\");\n+      Label LAST_TRUE_INDEX;\n+\n+      \/\/ Try to compute the result from higher 64 bits.\n+      __ fmovhid($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, 16 - 1);\n+      __ cbnz($dst$$Register, LAST_TRUE_INDEX);\n+\n+      \/\/ Compute the result from the lower 64 bits.\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ movw(rscratch1, 8 - 1);\n+\n+      \/\/ Count the leading zero bytes and subtract it by 15 (VLENGTH - 1).\n+      __ bind(LAST_TRUE_INDEX);\n+      __ clz($dst$$Register, $dst$$Register);\n+      __ subw($dst$$Register, rscratch1, $dst$$Register, Assembler::LSR, 3);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_lasttrue_sve(iRegINoSp dst, pReg src, pReg ptmp) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskLastTrue src));\n+  effect(TEMP ptmp);\n+  format %{ \"vmask_lasttrue_sve $dst, $src\\t# KILL $ptmp\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this, $src);\n+    __ sve_vmask_lasttrue($dst$$Register, bt, $src$$PRegister, $ptmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ tolong\n+\n+instruct vmask_tolong_neon(iRegLNoSp dst, vReg src) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorMaskToLong src));\n+  format %{ \"vmask_tolong_neon $dst, $src\" %}\n+  ins_encode %{\n+    \/\/ Input \"src\" is a vector of boolean represented as\n+    \/\/ bytes with 0x00\/0x01 as element values.\n+\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    if (length_in_bytes <= 8) {\n+      __ fmovd($dst$$Register, $src$$FloatRegister);\n+      __ bytemask_compress($dst$$Register);\n+    } else {\n+      assert(length_in_bytes == 16, \"must be\");\n+      __ umov($dst$$Register, $src$$FloatRegister, __ D, 0);\n+      __ umov(rscratch1, $src$$FloatRegister, __ D, 1);\n+      __ bytemask_compress($dst$$Register);\n+      __ bytemask_compress(rscratch1);\n+      __ orr($dst$$Register, $dst$$Register, rscratch1, Assembler::LSL, 8);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_tolong_sve(iRegLNoSp dst, pReg src, vReg tmp1, vReg tmp2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorMaskToLong src));\n+  effect(TEMP tmp1, TEMP tmp2);\n+  format %{ \"vmask_tolong_sve $dst, $src\\t# KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    __ sve_vmask_tolong($dst$$Register, $src$$PRegister,\n+                        Matcher::vector_element_basic_type(this, $src),\n+                        Matcher::vector_length(this, $src),\n+                        $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ fromlong\n+\n+instruct vmask_fromlong(pRegGov dst, iRegL src, vReg tmp1, vReg tmp2) %{\n+  match(Set dst (VectorLongToMask src));\n+  effect(TEMP tmp1, TEMP tmp2);\n+  format %{ \"vmask_fromlong $dst, $src\\t# vector (sve2). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    __ sve_vmask_fromlong($dst$$PRegister, $src$$Register,\n+                          Matcher::vector_element_basic_type(this),\n+                          Matcher::vector_length(this),\n+                          $tmp1$$FloatRegister, $tmp2$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector mask generation -----------------------\n+\n+\/\/ maskAll\n+dnl\n+dnl VMASKALL_IMM($1,   $2      )\n+dnl VMASKALL_IMM(type, var_type)\n+define(`VMASKALL_IMM', `\n+instruct vmaskAll_imm$1(pRegGov dst, imm$1 src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src));\n+  effect(KILL cr);\n+  format %{ \"vmaskAll_imm$1 $dst, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    $2 con = ($2)$src$$constant;\n+    if (con == 0) {\n+      __ sve_pfalse($dst$$PRegister);\n+    } else {\n+      assert(con == -1, \"invalid constant value for mask\");\n+      BasicType bt = Matcher::vector_element_basic_type(this);\n+      __ sve_gen_mask_imm($dst$$PRegister, bt, Matcher::vector_length(this));\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMASKALL($1,   $2      )\n+dnl VMASKALL(type, arg_type)\n+define(`VMASKALL', `\n+instruct vmaskAll$1(pRegGov dst, $2 src, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 && !n->is_predicated_vector());\n+  match(Set dst (MaskAll src));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmaskAll$1 $dst, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_dup($tmp$$FloatRegister, size, $src$$Register);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size, ptrue, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+dnl VMASKALL_PREDICATE($1,   $2      )\n+dnl VMASKALL_PREDICATE(type, arg_type)\n+define(`VMASKALL_PREDICATE', `\n+instruct vmaskAll$1_masked(pRegGov dst, $2 src, pRegGov pg, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (MaskAll src pg));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vmaskAll$1_masked $dst, $pg, $src\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_dup($tmp$$FloatRegister, size, $src$$Register);\n+    __ sve_cmp(Assembler::NE, $dst$$PRegister, size,\n+               $pg$$PRegister, $tmp$$FloatRegister, 0);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}')dnl\n+dnl\n+VMASKALL_IMM(I, int)\n+VMASKALL(I, iRegIorL2I)\n+VMASKALL_PREDICATE(I, iRegIorL2I)\n+VMASKALL_IMM(L, long)\n+VMASKALL(L, iRegL)\n+VMASKALL_PREDICATE(L, iRegL)\n+\n+\/\/ vetcor mask generation\n+\n+instruct vmask_gen_I(pRegGov pd, iRegIorL2I src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen (ConvI2L src)));\n+  effect(KILL cr);\n+  format %{ \"vmask_gen_I $pd, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whilelow($pd$$PRegister, __ elemType_to_regVariant(bt), zr, $src$$Register);\n+  %}\n+  ins_pipe(pipe_class_default);\n+%}\n+\n+instruct vmask_gen_L(pRegGov pd, iRegL src, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen src));\n+  effect(KILL cr);\n+  format %{ \"vmask_gen_L $pd, $src\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_whilelo($pd$$PRegister, __ elemType_to_regVariant(bt), zr, $src$$Register);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vmask_gen_imm(pRegGov pd, immL con, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set pd (VectorMaskGen con));\n+  effect(KILL cr);\n+  format %{ \"vmask_gen_imm $pd, $con\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_gen_mask_imm($pd$$PRegister, bt, (uint)($con$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Popcount vector ------------------------------\n+\n+\/\/ vector popcount - INT\n+\n+instruct vpopcountI(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (PopCountVI src));\n+  format %{ \"vpopcountI $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ cnt($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+               $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_cnt($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+      }\n+    } else {\n+      assert(bt == T_SHORT || bt == T_INT, \"unsupported\");\n+      if (UseSVE == 0) {\n+        assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+        __ cnt($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+               $src$$FloatRegister);\n+        __ uaddlp($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                  $dst$$FloatRegister);\n+        if (bt == T_INT) {\n+          __ uaddlp($dst$$FloatRegister, length_in_bytes == 16 ? __ T8H : __ T4H,\n+                    $dst$$FloatRegister);\n+        }\n+      } else {\n+        __ sve_cnt($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                   ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector popcount - LONG\n+\n+instruct vpopcountL(vReg dst, vReg src) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_LONG &&\n+            !n->as_Vector()->is_predicated_vector());\n+  match(Set dst (PopCountVL src));\n+  format %{ \"vpopcountL $dst, $src\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      __ cnt($dst$$FloatRegister, __ T16B, $src$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T16B, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T8H, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T4S, $dst$$FloatRegister);\n+    } else {\n+      __ sve_cnt($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ If the PopCountVL is generated by auto-vectorization, the dst basic\n+\/\/ type is T_INT. And once we have unified the type definition for\n+\/\/ Vector API and auto-vectorization, this rule can be merged with\n+\/\/ \"vpopcountL\" rule.\n+\n+instruct vpopcountL_I(vReg dst, vReg src, vReg tmp) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_INT &&\n+            !n->as_Vector()->is_predicated_vector());\n+  match(Set dst (PopCountVL src));\n+  effect(TEMP_DEF dst, TEMP tmp);\n+  format %{ \"vpopcountL_I $dst, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    if (UseSVE == 0) {\n+      __ cnt($dst$$FloatRegister, __ T16B, $src$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T16B, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T8H, $dst$$FloatRegister);\n+      __ uaddlp($dst$$FloatRegister, __ T4S, $dst$$FloatRegister);\n+      __ xtn($dst$$FloatRegister, __ T2S, $dst$$FloatRegister, __ T2D);\n+    } else {\n+      __ sve_cnt($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+      __ sve_vector_narrow($dst$$FloatRegister, __ S,\n+                           $dst$$FloatRegister, __ D, $tmp$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ vector popcount - predicated\n+UNARY_OP_PREDICATE(vpopcountI, PopCountVI, sve_cnt)\n+\n+instruct vpopcountL_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_LONG);\n+  match(Set dst_src (PopCountVL dst_src pg));\n+  format %{ \"vpopcountL_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    __ sve_cnt($dst_src$$FloatRegister, __ D,\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector blend ---------------------------------\n+\n+instruct vblend_neon(vReg dst, vReg src1, vReg src2) %{\n+  predicate(UseSVE == 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) dst));\n+  format %{ \"vblend_neon $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ bsl($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+           $src2$$FloatRegister, $src1$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vblend_sve(vReg dst, vReg src1, vReg src2, pReg pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (VectorBlend (Binary src1 src2) pg));\n+  format %{ \"vblend_sve $dst, $pg, $src1, $src2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_sel($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+               $pg$$PRegister, $src2$$FloatRegister, $src1$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector round ---------------------------------\n+\n+\/\/ vector Math.round\n+\n+instruct vround_le128b(vReg dst, vReg src, vReg tmp1, vReg tmp2,\n+                       vReg tmp3, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) <= 16);\n+  match(Set dst (RoundVF src));\n+  match(Set dst (RoundVD src));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP tmp3, KILL cr);\n+  format %{ \"vround_le128b $dst, $src\\t# vector <= 128 bits. KILL $tmp1, $tmp2, $tmp3, cr\" %}\n+  ins_encode %{\n+    __ vector_round_neon($dst$$FloatRegister, $src$$FloatRegister,\n+                         $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                         $tmp3$$FloatRegister, get_arrangement(this));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vround_gt128b(vReg dst, vReg src, vReg tmp1, vReg tmp2,\n+                       pRegGov pgtmp, rFlagsReg cr) %{\n+  predicate(Matcher::vector_length_in_bytes(n) > 16);\n+  match(Set dst (RoundVF src));\n+  match(Set dst (RoundVD src));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp, KILL cr);\n+  format %{ \"vround_gt128b $dst, $src\\t# vector > 128 bits. KILL $tmp1, $tmp2, $pgtmp, cr\" %}\n+  ins_encode %{\n+    assert(UseSVE > 0, \"must be sve\");\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ vector_round_sve($dst$$FloatRegister, $src$$FloatRegister,\n+                        $tmp1$$FloatRegister, $tmp2$$FloatRegister,\n+                        $pgtmp$$PRegister, __ elemType_to_regVariant(bt));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ RoundDouble ----------------------------------\n+\n+\/\/ vector Math.rint, floor, ceil\n+\n+instruct vroundD(vReg dst, vReg src, immI rmode) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_DOUBLE);\n+  match(Set dst (RoundDoubleModeV src rmode));\n+  format %{ \"vroundD $dst, $src, $rmode\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      switch ($rmode$$constant) {\n+        case RoundDoubleModeNode::rmode_rint:\n+          __ frintn($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_floor:\n+          __ frintm($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_ceil:\n+          __ frintp($dst$$FloatRegister, __ T2D, $src$$FloatRegister);\n+          break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      switch ($rmode$$constant) {\n+        case RoundDoubleModeNode::rmode_rint:\n+          __ sve_frintn($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_floor:\n+          __ sve_frintm($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+          break;\n+        case RoundDoubleModeNode::rmode_ceil:\n+          __ sve_frintp($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+          break;\n+        default:\n+          assert(false, \"unsupported\");\n+          ShouldNotReachHere();\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ VectorTest -----------------------------------\n+\n+\/\/ anytrue\n+\n+instruct vtest_anytrue_neon(iRegINoSp dst, vReg src1, vReg src2, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2 ));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vtest_anytrue_neon $dst, $src1\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ No need to use src2.\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src1);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ addv($tmp$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B, $src1$$FloatRegister);\n+    __ umov($dst$$Register, $tmp$$FloatRegister, __ B, 0);\n+    __ cmpw($dst$$Register, zr);\n+    __ csetw($dst$$Register, Assembler::NE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_anytrue_sve(iRegINoSp dst, pRegGov src1, pRegGov src2, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::ne);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(KILL cr);\n+  format %{ \"vtest_anytrue_sve $dst, $src1\\t# KILL cr\" %}\n+  ins_encode %{\n+    \/\/ \"src2\" is not used for sve.\n+    __ sve_ptest(ptrue, $src1$$PRegister);\n+    __ csetw($dst$$Register, Assembler::NE);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ alltrue\n+\n+instruct vtest_alltrue_neon(iRegINoSp dst, vReg src1, vReg src2, vReg tmp, rFlagsReg cr) %{\n+  predicate(UseSVE == 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP tmp, KILL cr);\n+  format %{ \"vtest_alltrue_neon $dst, $src1\\t# KILL $tmp, cr\" %}\n+  ins_encode %{\n+    \/\/ No need to use src2.\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src1);\n+    assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+    __ uminv($tmp$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B, $src1$$FloatRegister);\n+    __ umov($dst$$Register, $tmp$$FloatRegister, __ B, 0);\n+    __ cmpw($dst$$Register, 0xff);\n+    __ csetw($dst$$Register, Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vtest_alltrue_sve(iRegINoSp dst, pRegGov src1, pRegGov src2, pReg ptmp, rFlagsReg cr) %{\n+  predicate(UseSVE > 0 &&\n+            static_cast<const VectorTestNode*>(n)->get_predicate() == BoolTest::overflow);\n+  match(Set dst (VectorTest src1 src2));\n+  effect(TEMP ptmp, KILL cr);\n+  format %{ \"vtest_alltrue_sve $dst, $src1, $src2\\t# KILL $ptmp, cr\" %}\n+  ins_encode %{\n+    __ sve_eors($ptmp$$PRegister, ptrue, $src1$$PRegister, $src2$$PRegister);\n+    __ csetw($dst$$Register, Assembler::EQ);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector shuffle -------------------------------\n+\n+instruct loadshuffle(vReg dst, vReg src) %{\n+  match(Set dst (VectorLoadShuffle src));\n+  format %{ \"loadshuffle $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if ($dst$$FloatRegister != $src$$FloatRegister) {\n+        if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+          __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        } else {\n+          assert(UseSVE > 0, \"must be sve\");\n+          __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+      }\n+    } else {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        \/\/ 4S\/8S, 4I, 4F\n+        __ uxtl($dst$$FloatRegister, __ T8H, $src$$FloatRegister, __ T8B);\n+        if (type2aelembytes(bt) == 4) {\n+          __ uxtl($dst$$FloatRegister, __ T4S, $dst$$FloatRegister, __ T4H);\n+        }\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_vector_extend($dst$$FloatRegister,  __ elemType_to_regVariant(bt),\n+                             $src$$FloatRegister, __ B);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector rearrange -----------------------------\n+\n+\/\/ Here is an example that rearranges a NEON vector with 4 ints:\n+\/\/ Rearrange V1 int[a0, a1, a2, a3] to V2 int[a2, a3, a0, a1]\n+\/\/   1. Get the indices of V1 and store them as Vi byte[0, 1, 2, 3].\n+\/\/   2. Convert Vi byte[0, 1, 2, 3] to the indices of V2 and also store them as Vi byte[2, 3, 0, 1].\n+\/\/   3. Unsigned extend Long Vi from byte[2, 3, 0, 1] to int[2, 3, 0, 1].\n+\/\/   4. Multiply Vi int[2, 3, 0, 1] with constant int[0x04040404, 0x04040404, 0x04040404, 0x04040404]\n+\/\/      and get tbl base Vm int[0x08080808, 0x0c0c0c0c, 0x00000000, 0x04040404].\n+\/\/   5. Add Vm with constant int[0x03020100, 0x03020100, 0x03020100, 0x03020100]\n+\/\/      and get tbl index Vm int[0x0b0a0908, 0x0f0e0d0c, 0x03020100, 0x07060504]\n+\/\/   6. Use Vm as index register, and use V1 as table register.\n+\/\/      Then get V2 as the result by tbl NEON instructions.\n+\/\/ Notes:\n+\/\/   Step 1 matches VectorLoadConst.\n+\/\/   Step 3 matches VectorLoadShuffle.\n+\/\/   Step 4, 5, 6 match VectorRearrange.\n+\/\/   For VectorRearrange short\/int, the reason why such complex calculation is\n+\/\/   required is because NEON tbl supports bytes table only, so for short\/int, we\n+\/\/   need to lookup 2\/4 bytes as a group. For VectorRearrange long, we use bsl\n+\/\/   to implement rearrange.\n+\n+instruct rearrange_HS_neon(vReg dst, vReg src, vReg shuffle, vReg tmp1, vReg tmp2) %{\n+  predicate(UseSVE == 0 &&\n+            (Matcher::vector_element_basic_type(n) == T_SHORT ||\n+             (type2aelembytes(Matcher::vector_element_basic_type(n)) == 4 &&\n+              Matcher::vector_length_in_bytes(n) == 16)));\n+  match(Set dst (VectorRearrange src shuffle));\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2);\n+  format %{ \"rearrange_HS_neon $dst, $src, $shuffle\\t# vector (4S\/8S\/4I\/4F). KILL $tmp1, $tmp2\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (bt == T_SHORT) {\n+      uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+      assert(length_in_bytes == 8 || length_in_bytes == 16, \"must be\");\n+      Assembler::SIMD_Arrangement size1 = length_in_bytes == 16 ? __ T16B : __ T8B;\n+      Assembler::SIMD_Arrangement size2 = length_in_bytes == 16 ? __ T8H : __ T4H;\n+      __ mov($tmp1$$FloatRegister, size1, 0x02);\n+      __ mov($tmp2$$FloatRegister, size2, 0x0100);\n+      __ mulv($dst$$FloatRegister, size2, $shuffle$$FloatRegister, $tmp1$$FloatRegister);\n+      __ addv($dst$$FloatRegister, size1, $dst$$FloatRegister, $tmp2$$FloatRegister);\n+      __ tbl($dst$$FloatRegister, size1, $src$$FloatRegister, 1, $dst$$FloatRegister);\n+    } else {\n+      assert(bt == T_INT || bt == T_FLOAT, \"unsupported type\");\n+      __ mov($tmp1$$FloatRegister, __ T16B, 0x04);\n+      __ mov($tmp2$$FloatRegister, __ T4S, 0x03020100);\n+      __ mulv($dst$$FloatRegister, __ T4S, $shuffle$$FloatRegister, $tmp1$$FloatRegister);\n+      __ addv($dst$$FloatRegister, __ T16B, $dst$$FloatRegister, $tmp2$$FloatRegister);\n+      __ tbl($dst$$FloatRegister, __ T16B, $src$$FloatRegister, 1, $dst$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct rearrange(vReg dst, vReg src, vReg shuffle) %{\n+  predicate(Matcher::vector_element_basic_type(n) == T_BYTE || UseSVE > 0);\n+  match(Set dst (VectorRearrange src shuffle));\n+  format %{ \"rearrange $dst, $src, $shuffle\" %}\n+  ins_encode %{\n+    BasicType bt_dst = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt_dst == T_BYTE && VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      __ tbl($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+             $src$$FloatRegister, 1, $shuffle$$FloatRegister);\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      BasicType bt_src = Matcher::vector_element_basic_type(this, $src);\n+      __ sve_tbl($dst$$FloatRegister, __ elemType_to_regVariant(bt_src),\n+                 $src$$FloatRegister, $shuffle$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Load Gather ---------------------------\n+\n+instruct gather_loadS(vReg dst, indirect mem, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+  match(Set dst (LoadVectorGather mem idx));\n+  format %{ \"gather_loadS $dst, $mem, $idx\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_ld1w_gather($dst$$FloatRegister, ptrue,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+ %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadD(vReg dst, indirect mem, vReg idx, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+  match(Set dst (LoadVectorGather mem idx));\n+  effect(TEMP tmp);\n+  format %{ \"gather_loadD $dst, $mem, $idx\\t# vector (sve). KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_ld1d_gather($dst$$FloatRegister, ptrue, as_Register($mem$$base),\n+                       $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadS_masked(vReg dst, indirect mem, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 4);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  format %{ \"gather_loadS_masked $dst, $pg, $mem, $idx\" %}\n+  ins_encode %{\n+    __ sve_ld1w_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct gather_loadD_masked(vReg dst, indirect mem, vReg idx, pRegGov pg, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n)) == 8);\n+  match(Set dst (LoadVectorGatherMasked mem (Binary idx pg)));\n+  effect(TEMP tmp);\n+  format %{ \"gather_loadD_masked $dst, $pg, $mem, $idx\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_ld1d_gather($dst$$FloatRegister, $pg$$PRegister,\n+                       as_Register($mem$$base), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Vector Store Scatter -------------------------\n+\n+instruct scatter_storeS(indirect mem, vReg src, vReg idx) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 4);\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  format %{ \"scatter_storeS $mem, $idx, $src\\t# vector (sve)\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_st1w_scatter($src$$FloatRegister, ptrue,\n+                        as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatter_storeD(indirect mem, vReg src, vReg idx, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 8);\n+  match(Set mem (StoreVectorScatter mem (Binary src idx)));\n+  effect(TEMP tmp);\n+  format %{ \"scatter_storeD $mem, $idx, $src\\t# vector (sve). KILL $tmp\" %}\n+  ins_encode %{\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this, $src);\n+    assert(length_in_bytes == MaxVectorSize, \"invalid vector length\");\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_st1d_scatter($src$$FloatRegister, ptrue,\n+                        as_Register($mem$$base), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatter_storeS_masked(indirect mem, vReg src, vReg idx, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 4);\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  format %{ \"scatter_storeS_masked $mem, $pg, $idx, $src\" %}\n+  ins_encode %{\n+    __ sve_st1w_scatter($src$$FloatRegister, $pg$$PRegister,\n+                        as_Register($mem$$base), $idx$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct scatter_storeD_masked(indirect mem, vReg src, vReg idx, pRegGov pg, vReg tmp) %{\n+  predicate(UseSVE > 0 &&\n+            type2aelembytes(Matcher::vector_element_basic_type(n->in(3)->in(1))) == 8);\n+  match(Set mem (StoreVectorScatterMasked mem (Binary src (Binary idx pg))));\n+  effect(TEMP tmp);\n+  format %{ \"scatter_storeD_masked $mem, $pg, $idx, $src\\t# KILL $tmp\" %}\n+  ins_encode %{\n+    __ sve_uunpklo($tmp$$FloatRegister, __ D, $idx$$FloatRegister);\n+    __ sve_st1d_scatter($src$$FloatRegister, $pg$$PRegister,\n+                        as_Register($mem$$base), $tmp$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ CountLeadingZerosV ---------------------------\n+\n+instruct vcountLeadingZeros(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (CountLeadingZerosV src));\n+  format %{ \"vcountLeadingZeros $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_LONG) {\n+      if (UseSVE == 0) {\n+        __ umov(rscratch1, $src$$FloatRegister, __ D, 0);\n+        __ clz(rscratch1, rscratch1);\n+        __ mov($dst$$FloatRegister, __ D, 0, rscratch1);\n+        __ umov(rscratch1, $src$$FloatRegister, __ D, 1);\n+        __ clz(rscratch1, rscratch1);\n+        __ mov($dst$$FloatRegister, __ D, 1, rscratch1);\n+      } else {\n+        __ sve_clz($dst$$FloatRegister, __ D, ptrue, $src$$FloatRegister);\n+      }\n+    } else {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ clz($dst$$FloatRegister, get_arrangement(this), $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_clz($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                   ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+UNARY_OP_PREDICATE(vcountLeadingZeros, CountLeadingZerosV, sve_clz)\n+\n+\/\/ ------------------------------ CountTrailingZerosV --------------------------\n+\n+instruct vcountTrailingZeros(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (CountTrailingZerosV src));\n+  format %{ \"vcountTrailingZeros $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ rbit($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                $src$$FloatRegister);\n+        __ clz($dst$$FloatRegister, get_arrangement(this), $dst$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_rbit($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+        __ sve_clz($dst$$FloatRegister, __ B, ptrue, $dst$$FloatRegister);\n+      }\n+    } else {\n+      assert(bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported type\");\n+      if (UseSVE == 0) {\n+        assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+        __ neon_reverse_bits($dst$$FloatRegister, $src$$FloatRegister,\n+                             bt, \/* isQ *\/ length_in_bytes == 16);\n+        if (bt != T_LONG) {\n+          __ clz($dst$$FloatRegister, get_arrangement(this), $dst$$FloatRegister);\n+        } else {\n+          __ umov(rscratch1, $dst$$FloatRegister, __ D, 0);\n+          __ clz(rscratch1, rscratch1);\n+          __ mov($dst$$FloatRegister, __ D, 0, rscratch1);\n+          __ umov(rscratch1, $dst$$FloatRegister, __ D, 1);\n+          __ clz(rscratch1, rscratch1);\n+          __ mov($dst$$FloatRegister, __ D, 1, rscratch1);\n+        }\n+      } else {\n+        Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+        __ sve_rbit($dst$$FloatRegister, size, ptrue, $src$$FloatRegister);\n+        __ sve_clz($dst$$FloatRegister, size, ptrue, $dst$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+instruct vcountTrailingZeros_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (CountTrailingZerosV dst_src pg));\n+  format %{ \"vcountTrailingZeros_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_rbit($dst_src$$FloatRegister, size,\n+                $pg$$PRegister, $dst_src$$FloatRegister);\n+    __ sve_clz($dst_src$$FloatRegister, size,\n+               $pg$$PRegister, $dst_src$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ ReverseV -------------------------------------\n+\n+instruct vreverse(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (ReverseV src));\n+  format %{ \"vreverse $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (bt == T_BYTE) {\n+      if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+        __ rbit($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                $src$$FloatRegister);\n+      } else {\n+        assert(UseSVE > 0, \"must be sve\");\n+        __ sve_rbit($dst$$FloatRegister, __ B, ptrue, $src$$FloatRegister);\n+      }\n+    } else {\n+      assert(bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported type\");\n+      if (UseSVE == 0) {\n+        assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+        __ neon_reverse_bits($dst$$FloatRegister, $src$$FloatRegister,\n+                             bt, \/* isQ *\/ length_in_bytes == 16);\n+      } else {\n+        __ sve_rbit($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                    ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+UNARY_OP_PREDICATE(vreverse, ReverseV, sve_rbit)\n+\n+\/\/ ------------------------------ ReverseBytesV --------------------------------\n+\n+instruct vreverseBytes(vReg dst, vReg src) %{\n+  predicate(!n->as_Vector()->is_predicated_vector());\n+  match(Set dst (ReverseBytesV src));\n+  format %{ \"vreverseBytes $dst, $src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    uint length_in_bytes = Matcher::vector_length_in_bytes(this);\n+    if (VM_Version::use_neon_for_vector(length_in_bytes)) {\n+      assert(length_in_bytes == 8 || length_in_bytes == 16, \"unsupported\");\n+      if (bt == T_BYTE) {\n+        if ($dst$$FloatRegister != $src$$FloatRegister) {\n+          __ orr($dst$$FloatRegister, length_in_bytes == 16 ? __ T16B : __ T8B,\n+                 $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+      } else {\n+        __ neon_reverse_bytes($dst$$FloatRegister, $src$$FloatRegister,\n+                              bt, \/* isQ *\/ length_in_bytes == 16);\n+      }\n+    } else {\n+      assert(UseSVE > 0, \"must be sve\");\n+      if (bt == T_BYTE) {\n+        if ($dst$$FloatRegister != $src$$FloatRegister) {\n+          __ sve_orr($dst$$FloatRegister, $src$$FloatRegister, $src$$FloatRegister);\n+        }\n+      } else {\n+        __ sve_revb($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                    ptrue, $src$$FloatRegister);\n+      }\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ The dst and src should use the same register to make sure the\n+\/\/ inactive lanes in dst save the same elements as src.\n+instruct vreverseBytes_masked(vReg dst_src, pRegGov pg) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst_src (ReverseBytesV dst_src pg));\n+  format %{ \"vreverseBytes_masked $dst_src, $pg, $dst_src\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    if (bt == T_BYTE) {\n+      \/\/ do nothing\n+    } else {\n+      __ sve_revb($dst_src$$FloatRegister, __ elemType_to_regVariant(bt),\n+                  $pg$$PRegister, $dst_src$$FloatRegister);\n+    }\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Populate Index to a Vector -------------------\n+\n+instruct populateindex(vReg dst, iRegIorL2I src1, immI src2) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (PopulateIndex src1 src2));\n+  format %{ \"populateindex $dst, $src1, $src2\\t # populate index (sve)\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_index($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                 $src1$$Register, (int)($src2$$constant));\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/ ------------------------------ Compress\/Expand Operations -------------------\n+\n+instruct mcompress(pReg dst, pReg pg, rFlagsReg cr) %{\n+  predicate(UseSVE > 0);\n+  match(Set dst (CompressM pg));\n+  effect(KILL cr);\n+  format %{ \"mcompress $dst, $pg\\t# KILL cr\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    __ sve_cntp(rscratch1, size, ptrue, $pg$$PRegister);\n+    __ sve_whilelo(as_PRegister($dst$$reg), size, zr, rscratch1);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcompress(vReg dst, vReg src, pRegGov pg) %{\n+  predicate(UseSVE > 0 &&\n+            !is_subword_type(Matcher::vector_element_basic_type(n)));\n+  match(Set dst (CompressV src pg));\n+  format %{ \"vcompress $dst, $src, $pg\" %}\n+  ins_encode %{\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    __ sve_compact($dst$$FloatRegister, __ elemType_to_regVariant(bt),\n+                   $src$$FloatRegister, $pg$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcompressB(vReg dst, vReg src, pReg pg, vReg tmp1, vReg tmp2,\n+                    vReg tmp3, vReg tmp4, pReg ptmp, pRegGov pgtmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_BYTE);\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, TEMP ptmp, TEMP pgtmp);\n+  match(Set dst (CompressV src pg));\n+  format %{ \"vcompressB $dst, $src, $pg\\t# KILL $tmp1, $tmp2, $tmp3, tmp4, $ptmp, $pgtmp\" %}\n+  ins_encode %{\n+    __ sve_compress_byte($dst$$FloatRegister, $src$$FloatRegister, $pg$$PRegister,\n+                         $tmp1$$FloatRegister,$tmp2$$FloatRegister,\n+                         $tmp3$$FloatRegister,$tmp4$$FloatRegister,\n+                         $ptmp$$PRegister, $pgtmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vcompressS(vReg dst, vReg src, pReg pg,\n+                    vReg tmp1, vReg tmp2, pRegGov pgtmp) %{\n+  predicate(UseSVE > 0 && Matcher::vector_element_basic_type(n) == T_SHORT);\n+  effect(TEMP_DEF dst, TEMP tmp1, TEMP tmp2, TEMP pgtmp);\n+  match(Set dst (CompressV src pg));\n+  format %{ \"vcompressS $dst, $src, $pg\\t# KILL $tmp1, $tmp2, $pgtmp\" %}\n+  ins_encode %{\n+    __ sve_compress_short($dst$$FloatRegister, $src$$FloatRegister, $pg$$PRegister,\n+                          $tmp1$$FloatRegister,$tmp2$$FloatRegister, $pgtmp$$PRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n+\n+instruct vexpand(vReg dst, vReg src, pRegGov pg) %{\n+  match(Set dst (ExpandV src pg));\n+  effect(TEMP_DEF dst);\n+  format %{ \"vexpand $dst, $pg, $src\" %}\n+  ins_encode %{\n+    \/\/ Example input:   src   = 1 2 3 4 5 6 7 8\n+    \/\/                  pg    = 1 0 0 1 1 0 1 1\n+    \/\/ Expected result: dst   = 4 0 0 5 6 0 7 8\n+\n+    \/\/ The basic idea is to use TBL which can shuffle the elements in the given\n+    \/\/ vector flexibly. HISTCNT + SUB is used to generate the second source input\n+    \/\/ for TBL whose value is used to select the indexed element from src vector.\n+\n+    BasicType bt = Matcher::vector_element_basic_type(this);\n+    assert(UseSVE == 2 && !is_subword_type(bt), \"unsupported\");\n+    Assembler::SIMD_RegVariant size = __ elemType_to_regVariant(bt);\n+    \/\/ dst = 0 0 0 0 0 0 0 0\n+    __ sve_dup($dst$$FloatRegister, size, 0);\n+    \/\/ dst = 5 0 0 4 3 0 2 1\n+    __ sve_histcnt($dst$$FloatRegister, size, $pg$$PRegister,\n+                   $dst$$FloatRegister, $dst$$FloatRegister);\n+    \/\/ dst = 4 -1 -1 3 2 -1 1 0\n+    __ sve_sub($dst$$FloatRegister, size, 1);\n+    \/\/ dst = 4 0 0 5 6 0 7 8\n+    __ sve_tbl($dst$$FloatRegister, size, $src$$FloatRegister, $dst$$FloatRegister);\n+  %}\n+  ins_pipe(pipe_slow);\n+%}\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64_vector_ad.m4","additions":4693,"deletions":0,"binary":false,"changes":4693,"status":"added"},{"patch":"@@ -990,1 +990,1 @@\n-      sve_extract_integral(rscratch1, D, vtmp1, idx, \/* is_signed *\/ false, vtmp2);\n+      sve_extract_integral(rscratch1, T_LONG, vtmp1, idx, vtmp2);\n@@ -1094,0 +1094,1 @@\n+\/\/ Clobbers: rflags\n@@ -1131,0 +1132,55 @@\n+\/\/ Extend integer vector src to dst with the same lane count\n+\/\/ but larger element size, e.g. 4B -> 4I\n+void C2_MacroAssembler::neon_vector_extend(FloatRegister dst, BasicType dst_bt, unsigned dst_vlen_in_bytes,\n+                                           FloatRegister src, BasicType src_bt) {\n+  if (src_bt == T_BYTE) {\n+    if (dst_bt == T_SHORT) {\n+      \/\/ 4B\/8B to 4S\/8S\n+      assert(dst_vlen_in_bytes == 8 || dst_vlen_in_bytes == 16, \"unsupported\");\n+      sxtl(dst, T8H, src, T8B);\n+    } else {\n+      \/\/ 4B to 4I\n+      assert(dst_vlen_in_bytes == 16 && dst_bt == T_INT, \"unsupported\");\n+      sxtl(dst, T8H, src, T8B);\n+      sxtl(dst, T4S, dst, T4H);\n+    }\n+  } else if (src_bt == T_SHORT) {\n+    \/\/ 4S to 4I\n+    assert(dst_vlen_in_bytes == 16 && dst_bt == T_INT, \"unsupported\");\n+    sxtl(dst, T4S, src, T4H);\n+  } else if (src_bt == T_INT) {\n+    \/\/ 2I to 2L\n+    assert(dst_vlen_in_bytes == 16 && dst_bt == T_LONG, \"unsupported\");\n+    sxtl(dst, T2D, src, T2S);\n+  } else {\n+    ShouldNotReachHere();\n+  }\n+}\n+\n+\/\/ Narrow integer vector src down to dst with the same lane count\n+\/\/ but smaller element size, e.g. 4I -> 4B\n+void C2_MacroAssembler::neon_vector_narrow(FloatRegister dst, BasicType dst_bt,\n+                                           FloatRegister src, BasicType src_bt, unsigned src_vlen_in_bytes) {\n+  if (src_bt == T_SHORT) {\n+    \/\/ 4S\/8S to 4B\/8B\n+    assert(src_vlen_in_bytes == 8 || src_vlen_in_bytes == 16, \"unsupported\");\n+    assert(dst_bt == T_BYTE, \"unsupported\");\n+    xtn(dst, T8B, src, T8H);\n+  } else if (src_bt == T_INT) {\n+    \/\/ 4I to 4B\/4S\n+    assert(src_vlen_in_bytes == 16, \"unsupported\");\n+    assert(dst_bt == T_BYTE || dst_bt == T_SHORT, \"unsupported\");\n+    xtn(dst, T4H, src, T4S);\n+    if (dst_bt == T_BYTE) {\n+      xtn(dst, T8B, dst, T8H);\n+    }\n+  } else if (src_bt == T_LONG) {\n+    \/\/ 2L to 2I\n+    assert(src_vlen_in_bytes == 16, \"unsupported\");\n+    assert(dst_bt == T_INT, \"unsupported\");\n+    xtn(dst, T2S, src, T2D);\n+  } else {\n+    ShouldNotReachHere();\n+  }\n+}\n+\n@@ -1243,0 +1299,269 @@\n+\/\/ Vector reduction add for integral type with ASIMD instructions.\n+void C2_MacroAssembler::neon_reduce_add_integral(Register dst, BasicType bt,\n+                                                 Register isrc, FloatRegister vsrc,\n+                                                 unsigned vector_length_in_bytes,\n+                                                 FloatRegister vtmp) {\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  assert_different_registers(dst, isrc);\n+  bool isQ = vector_length_in_bytes == 16;\n+\n+  BLOCK_COMMENT(\"neon_reduce_add_integral {\");\n+    switch(bt) {\n+      case T_BYTE:\n+        addv(vtmp, isQ ? T16B : T8B, vsrc);\n+        smov(dst, vtmp, B, 0);\n+        addw(dst, dst, isrc, ext::sxtb);\n+        break;\n+      case T_SHORT:\n+        addv(vtmp, isQ ? T8H : T4H, vsrc);\n+        smov(dst, vtmp, H, 0);\n+        addw(dst, dst, isrc, ext::sxth);\n+        break;\n+      case T_INT:\n+        isQ ? addv(vtmp, T4S, vsrc) : addpv(vtmp, T2S, vsrc, vsrc);\n+        umov(dst, vtmp, S, 0);\n+        addw(dst, dst, isrc);\n+        break;\n+      case T_LONG:\n+        assert(isQ, \"unsupported\");\n+        addpd(vtmp, vsrc);\n+        umov(dst, vtmp, D, 0);\n+        add(dst, dst, isrc);\n+        break;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+    }\n+  BLOCK_COMMENT(\"} neon_reduce_add_integral\");\n+}\n+\n+\/\/ Vector reduction multiply for integral type with ASIMD instructions.\n+\/\/ Note: temporary registers vtmp1 and vtmp2 are not used in some cases.\n+\/\/ Clobbers: rscratch1\n+void C2_MacroAssembler::neon_reduce_mul_integral(Register dst, BasicType bt,\n+                                                 Register isrc, FloatRegister vsrc,\n+                                                 unsigned vector_length_in_bytes,\n+                                                 FloatRegister vtmp1, FloatRegister vtmp2) {\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  bool isQ = vector_length_in_bytes == 16;\n+\n+  BLOCK_COMMENT(\"neon_reduce_mul_integral {\");\n+    switch(bt) {\n+      case T_BYTE:\n+        if (isQ) {\n+          \/\/ Multiply the lower half and higher half of vector iteratively.\n+          \/\/ vtmp1 = vsrc[8:15]\n+          ins(vtmp1, D, vsrc, 0, 1);\n+          \/\/ vtmp1[n] = vsrc[n] * vsrc[n + 8], where n=[0, 7]\n+          mulv(vtmp1, T8B, vtmp1, vsrc);\n+          \/\/ vtmp2 = vtmp1[4:7]\n+          ins(vtmp2, S, vtmp1, 0, 1);\n+          \/\/ vtmp1[n] = vtmp1[n] * vtmp1[n + 4], where n=[0, 3]\n+          mulv(vtmp1, T8B, vtmp2, vtmp1);\n+        } else {\n+          ins(vtmp1, S, vsrc, 0, 1);\n+          mulv(vtmp1, T8B, vtmp1, vsrc);\n+        }\n+        \/\/ vtmp2 = vtmp1[2:3]\n+        ins(vtmp2, H, vtmp1, 0, 1);\n+        \/\/ vtmp2[n] = vtmp1[n] * vtmp1[n + 2], where n=[0, 1]\n+        mulv(vtmp2, T8B, vtmp2, vtmp1);\n+        \/\/ dst = vtmp2[0] * isrc * vtmp2[1]\n+        umov(rscratch1, vtmp2, B, 0);\n+        mulw(dst, rscratch1, isrc);\n+        sxtb(dst, dst);\n+        umov(rscratch1, vtmp2, B, 1);\n+        mulw(dst, rscratch1, dst);\n+        sxtb(dst, dst);\n+        break;\n+      case T_SHORT:\n+        if (isQ) {\n+          ins(vtmp2, D, vsrc, 0, 1);\n+          mulv(vtmp2, T4H, vtmp2, vsrc);\n+          ins(vtmp1, S, vtmp2, 0, 1);\n+          mulv(vtmp1, T4H, vtmp1, vtmp2);\n+        } else {\n+          ins(vtmp1, S, vsrc, 0, 1);\n+          mulv(vtmp1, T4H, vtmp1, vsrc);\n+        }\n+        umov(rscratch1, vtmp1, H, 0);\n+        mulw(dst, rscratch1, isrc);\n+        sxth(dst, dst);\n+        umov(rscratch1, vtmp1, H, 1);\n+        mulw(dst, rscratch1, dst);\n+        sxth(dst, dst);\n+        break;\n+      case T_INT:\n+        if (isQ) {\n+          ins(vtmp1, D, vsrc, 0, 1);\n+          mulv(vtmp1, T2S, vtmp1, vsrc);\n+        } else {\n+          vtmp1 = vsrc;\n+        }\n+        umov(rscratch1, vtmp1, S, 0);\n+        mul(dst, rscratch1, isrc);\n+        umov(rscratch1, vtmp1, S, 1);\n+        mul(dst, rscratch1, dst);\n+        break;\n+      case T_LONG:\n+        umov(rscratch1, vsrc, D, 0);\n+        mul(dst, isrc, rscratch1);\n+        umov(rscratch1, vsrc, D, 1);\n+        mul(dst, dst, rscratch1);\n+        break;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+    }\n+  BLOCK_COMMENT(\"} neon_reduce_mul_integral\");\n+}\n+\n+\/\/ Vector reduction multiply for floating-point type with ASIMD instructions.\n+void C2_MacroAssembler::neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n+                                           FloatRegister fsrc, FloatRegister vsrc,\n+                                           unsigned vector_length_in_bytes,\n+                                           FloatRegister vtmp) {\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  bool isQ = vector_length_in_bytes == 16;\n+\n+  BLOCK_COMMENT(\"neon_reduce_mul_fp {\");\n+    switch(bt) {\n+      case T_FLOAT:\n+        fmuls(dst, fsrc, vsrc);\n+        ins(vtmp, S, vsrc, 0, 1);\n+        fmuls(dst, dst, vtmp);\n+        if (isQ) {\n+          ins(vtmp, S, vsrc, 0, 2);\n+          fmuls(dst, dst, vtmp);\n+          ins(vtmp, S, vsrc, 0, 3);\n+          fmuls(dst, dst, vtmp);\n+         }\n+        break;\n+      case T_DOUBLE:\n+        assert(isQ, \"unsupported\");\n+        fmuld(dst, fsrc, vsrc);\n+        ins(vtmp, D, vsrc, 0, 1);\n+        fmuld(dst, dst, vtmp);\n+        break;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+    }\n+  BLOCK_COMMENT(\"} neon_reduce_mul_fp\");\n+}\n+\n+\/\/ Helper to select logical instruction\n+void C2_MacroAssembler::neon_reduce_logical_helper(int opc, bool is64, Register Rd,\n+                                                   Register Rn, Register Rm,\n+                                                   enum shift_kind kind, unsigned shift) {\n+  switch(opc) {\n+    case Op_AndReductionV:\n+      is64 ? andr(Rd, Rn, Rm, kind, shift) : andw(Rd, Rn, Rm, kind, shift);\n+      break;\n+    case Op_OrReductionV:\n+      is64 ? orr(Rd, Rn, Rm, kind, shift) : orrw(Rd, Rn, Rm, kind, shift);\n+      break;\n+    case Op_XorReductionV:\n+      is64 ? eor(Rd, Rn, Rm, kind, shift) : eorw(Rd, Rn, Rm, kind, shift);\n+      break;\n+    default:\n+      assert(false, \"unsupported\");\n+      ShouldNotReachHere();\n+  }\n+}\n+\n+\/\/ Vector reduction logical operations And, Or, Xor\n+\/\/ Clobbers: rscratch1\n+void C2_MacroAssembler::neon_reduce_logical(int opc, Register dst, BasicType bt,\n+                                            Register isrc, FloatRegister vsrc,\n+                                            unsigned vector_length_in_bytes) {\n+  assert(opc == Op_AndReductionV || opc == Op_OrReductionV || opc == Op_XorReductionV,\n+         \"unsupported\");\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  assert_different_registers(dst, isrc);\n+  bool isQ = vector_length_in_bytes == 16;\n+\n+  BLOCK_COMMENT(\"neon_reduce_logical {\");\n+    umov(rscratch1, vsrc, isQ ? D : S, 0);\n+    umov(dst, vsrc, isQ ? D : S, 1);\n+    neon_reduce_logical_helper(opc, \/* is64 *\/ true, dst, dst, rscratch1);\n+    switch(bt) {\n+      case T_BYTE:\n+        if (isQ) {\n+          neon_reduce_logical_helper(opc, \/* is64 *\/ true, dst, dst, dst, Assembler::LSR, 32);\n+        }\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ false, dst, dst, dst, Assembler::LSR, 16);\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ false, dst, dst, dst, Assembler::LSR, 8);\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ false, dst, isrc, dst);\n+        sxtb(dst, dst);\n+        break;\n+      case T_SHORT:\n+        if (isQ) {\n+          neon_reduce_logical_helper(opc, \/* is64 *\/ true, dst, dst, dst, Assembler::LSR, 32);\n+        }\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ false, dst, dst, dst, Assembler::LSR, 16);\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ false, dst, isrc, dst);\n+        sxth(dst, dst);\n+        break;\n+      case T_INT:\n+        if (isQ) {\n+          neon_reduce_logical_helper(opc, \/* is64 *\/ true, dst, dst, dst, Assembler::LSR, 32);\n+        }\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ false, dst, isrc, dst);\n+        break;\n+      case T_LONG:\n+        assert(isQ, \"unsupported\");\n+        neon_reduce_logical_helper(opc, \/* is64 *\/ true, dst, isrc, dst);\n+        break;\n+      default:\n+        assert(false, \"unsupported\");\n+        ShouldNotReachHere();\n+    }\n+  BLOCK_COMMENT(\"} neon_reduce_logical\");\n+}\n+\n+\/\/ Vector reduction min\/max for integral type with ASIMD instructions.\n+\/\/ Note: vtmp is not used and expected to be fnoreg for T_LONG case.\n+\/\/ Clobbers: rscratch1, rflags\n+void C2_MacroAssembler::neon_reduce_minmax_integral(int opc, Register dst, BasicType bt,\n+                                                    Register isrc, FloatRegister vsrc,\n+                                                    unsigned vector_length_in_bytes,\n+                                                    FloatRegister vtmp) {\n+  assert(opc == Op_MinReductionV || opc == Op_MaxReductionV, \"unsupported\");\n+  assert(vector_length_in_bytes == 8 || vector_length_in_bytes == 16, \"unsupported\");\n+  assert(bt == T_BYTE || bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported\");\n+  assert_different_registers(dst, isrc);\n+  bool isQ = vector_length_in_bytes == 16;\n+  bool is_min = opc == Op_MinReductionV;\n+\n+  BLOCK_COMMENT(\"neon_reduce_minmax_integral {\");\n+    if (bt == T_LONG) {\n+      assert(vtmp == fnoreg, \"should be\");\n+      assert(isQ, \"should be\");\n+      umov(rscratch1, vsrc, D, 0);\n+      cmp(isrc, rscratch1);\n+      csel(dst, isrc, rscratch1, is_min ? LT : GT);\n+      umov(rscratch1, vsrc, D, 1);\n+      cmp(dst, rscratch1);\n+      csel(dst, dst, rscratch1, is_min ? LT : GT);\n+    } else {\n+      SIMD_Arrangement size = esize2arrangement((unsigned)type2aelembytes(bt), isQ);\n+      if (size == T2S) {\n+        is_min ? sminp(vtmp, size, vsrc, vsrc) : smaxp(vtmp, size, vsrc, vsrc);\n+      } else {\n+        is_min ? sminv(vtmp, size, vsrc) : smaxv(vtmp, size, vsrc);\n+      }\n+      if (bt == T_INT) {\n+        umov(dst, vtmp, S, 0);\n+      } else {\n+        smov(dst, vtmp, elemType_to_regVariant(bt), 0);\n+      }\n+      cmpw(dst, isrc);\n+      cselw(dst, dst, isrc, is_min ? LT : GT);\n+    }\n+  BLOCK_COMMENT(\"} neon_reduce_minmax_integral\");\n+}\n+\n+\/\/ Vector reduction for integral type with SVE instruction.\n+\/\/ Supported operations are Add, And, Or, Xor, Max, Min.\n+\/\/ rflags would be clobbered if opc is Op_MaxReductionV or Op_MinReductionV.\n@@ -1253,1 +1578,0 @@\n-      smov(dst, tmp, size, 0);\n@@ -1255,0 +1579,1 @@\n+        smov(dst, tmp, size, 0);\n@@ -1257,0 +1582,1 @@\n+        smov(dst, tmp, size, 0);\n@@ -1259,0 +1585,1 @@\n+        umov(dst, tmp, size, 0);\n@@ -1271,1 +1598,1 @@\n-      if (bt == T_LONG) {\n+      if (bt == T_INT || bt == T_LONG) {\n@@ -1273,1 +1600,0 @@\n-        andr(dst, dst, src1);\n@@ -1276,0 +1602,4 @@\n+      }\n+      if (bt == T_LONG) {\n+        andr(dst, dst, src1);\n+      } else {\n@@ -1282,1 +1612,1 @@\n-      if (bt == T_LONG) {\n+      if (bt == T_INT || bt == T_LONG) {\n@@ -1284,1 +1614,0 @@\n-        orr(dst, dst, src1);\n@@ -1287,0 +1616,4 @@\n+      }\n+      if (bt == T_LONG) {\n+        orr(dst, dst, src1);\n+      } else {\n@@ -1293,1 +1626,1 @@\n-      if (bt == T_LONG) {\n+      if (bt == T_INT || bt == T_LONG) {\n@@ -1295,1 +1628,0 @@\n-        eor(dst, dst, src1);\n@@ -1298,0 +1630,4 @@\n+      }\n+      if (bt == T_LONG) {\n+        eor(dst, dst, src1);\n+      } else {\n@@ -1304,1 +1640,1 @@\n-      if (bt == T_LONG) {\n+      if (bt == T_INT || bt == T_LONG) {\n@@ -1306,0 +1642,4 @@\n+      } else {\n+        smov(dst, tmp, size, 0);\n+      }\n+      if (bt == T_LONG) {\n@@ -1309,1 +1649,0 @@\n-        smov(dst, tmp, size, 0);\n@@ -1317,1 +1656,1 @@\n-      if (bt == T_LONG) {\n+      if (bt == T_INT || bt == T_LONG) {\n@@ -1319,0 +1658,4 @@\n+      } else {\n+        smov(dst, tmp, size, 0);\n+      }\n+      if (bt == T_LONG) {\n@@ -1322,1 +1665,0 @@\n-        smov(dst, tmp, size, 0);\n@@ -1559,4 +1901,4 @@\n-void C2_MacroAssembler::sve_extract_integral(Register dst, SIMD_RegVariant size, FloatRegister src, int idx,\n-                                             bool is_signed, FloatRegister vtmp) {\n-  assert(UseSVE > 0 && size != Q, \"unsupported\");\n-  assert(!(is_signed && size == D), \"signed extract (D) not supported.\");\n+void C2_MacroAssembler::sve_extract_integral(Register dst, BasicType bt, FloatRegister src,\n+                                             int idx, FloatRegister vtmp) {\n+  assert(bt == T_BYTE || bt == T_SHORT || bt == T_INT || bt == T_LONG, \"unsupported element type\");\n+  Assembler::SIMD_RegVariant size = elemType_to_regVariant(bt);\n@@ -1564,1 +1906,5 @@\n-    is_signed ? smov(dst, src, size, idx) : umov(dst, src, size, idx);\n+    if (bt == T_INT || bt == T_LONG) {\n+      umov(dst, src, size, idx);\n+    } else {\n+      smov(dst, src, size, idx);\n+    }\n@@ -1568,1 +1914,5 @@\n-    is_signed ? smov(dst, vtmp, size, 0) : umov(dst, vtmp, size, 0);\n+    if (bt == T_INT || bt == T_LONG) {\n+      umov(dst, vtmp, size, 0);\n+    } else {\n+      smov(dst, vtmp, size, 0);\n+    }\n@@ -1574,0 +1924,1 @@\n+\/\/ Clobbers: rscratch1, rflags\n@@ -1575,1 +1926,1 @@\n-                                       FloatRegister tmp2, FloatRegister tmp3, SIMD_Arrangement T) {\n+                                          FloatRegister tmp2, FloatRegister tmp3, SIMD_Arrangement T) {\n@@ -1606,0 +1957,1 @@\n+\/\/ Clobbers: rscratch1, rflags\n@@ -1607,1 +1959,2 @@\n-                                      FloatRegister tmp2, PRegister ptmp, SIMD_RegVariant T) {\n+                                         FloatRegister tmp2, PRegister pgtmp, SIMD_RegVariant T) {\n+  assert(pgtmp->is_governing(), \"This register has to be a governing predicate register\");\n@@ -1618,1 +1971,1 @@\n-      assert(T == S || T == D, \"invalid arrangement\");\n+      assert(T == S || T == D, \"invalid register variant\");\n@@ -1628,1 +1981,1 @@\n-  sve_cmp(HS, ptmp, T, ptrue, tmp2, tmp1);\n+  sve_cmp(HS, pgtmp, T, ptrue, tmp2, tmp1);\n@@ -1631,3 +1984,3 @@\n-    sve_cpy(tmp1, T, ptmp, 0.5);\n-    sve_fadd(tmp1, T, ptmp, src);\n-    sve_frintm(dst, T, ptmp, tmp1);\n+    sve_cpy(tmp1, T, pgtmp, 0.5);\n+    sve_fadd(tmp1, T, pgtmp, src);\n+    sve_frintm(dst, T, pgtmp, tmp1);\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.cpp","additions":378,"deletions":25,"binary":false,"changes":403,"status":"modified"},{"patch":"@@ -30,0 +30,5 @@\n+ private:\n+\n+  void neon_reduce_logical_helper(int opc, bool sf, Register Rd, Register Rn, Register Rm,\n+                                  enum shift_kind kind = Assembler::LSL, unsigned shift = 0);\n+\n@@ -81,0 +86,7 @@\n+  \/\/ Vector cast\n+  void neon_vector_extend(FloatRegister dst, BasicType dst_bt, unsigned dst_vlen_in_bytes,\n+                          FloatRegister src, BasicType src_bt);\n+\n+  void neon_vector_narrow(FloatRegister dst, BasicType dst_bt,\n+                          FloatRegister src, BasicType src_bt, unsigned src_vlen_in_bytes);\n+\n@@ -93,0 +105,21 @@\n+  \/\/ Vector reduction\n+  void neon_reduce_add_integral(Register dst, BasicType bt,\n+                                Register isrc, FloatRegister vsrc,\n+                                unsigned vector_length_in_bytes, FloatRegister vtmp);\n+\n+  void neon_reduce_mul_integral(Register dst, BasicType bt,\n+                                Register isrc, FloatRegister vsrc,\n+                                unsigned vector_length_in_bytes,\n+                                FloatRegister vtmp1, FloatRegister vtmp2);\n+\n+  void neon_reduce_mul_fp(FloatRegister dst, BasicType bt,\n+                          FloatRegister fsrc, FloatRegister vsrc,\n+                          unsigned vector_length_in_bytes, FloatRegister vtmp);\n+\n+  void neon_reduce_logical(int opc, Register dst, BasicType bt, Register isrc,\n+                           FloatRegister vsrc, unsigned vector_length_in_bytes);\n+\n+  void neon_reduce_minmax_integral(int opc, Register dst, BasicType bt,\n+                                   Register isrc, FloatRegister vsrc,\n+                                   unsigned vector_length_in_bytes, FloatRegister vtmp);\n+\n@@ -104,2 +137,2 @@\n-  void sve_extract_integral(Register dst, SIMD_RegVariant size, FloatRegister src, int idx,\n-                            bool is_signed, FloatRegister vtmp);\n+  void sve_extract_integral(Register dst, BasicType bt, FloatRegister src,\n+                            int idx, FloatRegister vtmp);\n@@ -112,1 +145,1 @@\n-                        FloatRegister tmp2, PRegister ptmp,\n+                        FloatRegister tmp2, PRegister pgtmp,\n","filename":"src\/hotspot\/cpu\/aarch64\/c2_MacroAssembler_aarch64.hpp","additions":36,"deletions":3,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -55,2 +55,2 @@\n-  \/\/ No support for generic vector operands.\n-  static const bool supports_generic_vector_operands = false;\n+  \/\/ aarch64 supports generic vector operands: vReg.\n+  static const bool supports_generic_vector_operands = true;\n","filename":"src\/hotspot\/cpu\/aarch64\/matcher_aarch64.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -140,1 +140,1 @@\n-    max_slots_per_register = 8,\n+    max_slots_per_register = 4,\n","filename":"src\/hotspot\/cpu\/aarch64\/register_aarch64.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -171,0 +171,6 @@\n+\n+  \/\/ For common 64\/128-bit unpredicated vector operations, we may prefer\n+  \/\/ emitting NEON instructions rather than the corresponding SVE instructions.\n+  static bool use_neon_for_vector(int vector_length_in_bytes) {\n+    return vector_length_in_bytes <= 16;\n+  }\n","filename":"src\/hotspot\/cpu\/aarch64\/vm_version_aarch64.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1998, 2021, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1998, 2022, Oracle and\/or its affiliates. All rights reserved.\n@@ -2277,0 +2277,3 @@\n+#endif\n+#if defined(AARCH64)\n+    if (strcmp(rep_var,\"$PRegister\") == 0)  return \"as_PRegister\";\n","filename":"src\/hotspot\/share\/adlc\/output_c.cpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -138,0 +138,8 @@\n+#if defined(AARCH64)\n+  PRegister as_PRegister(PhaseRegAlloc* ra_, const Node* node) const {\n+    return ::as_PRegister(reg(ra_, node));\n+  }\n+  PRegister as_PRegister(PhaseRegAlloc* ra_, const Node* node, int idx) const {\n+    return ::as_PRegister(reg(ra_, node, idx));\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -102,1 +102,1 @@\n-         SlotsPerVecA = RISCV_ONLY(4) NOT_RISCV(8),\n+         SlotsPerVecA = 4,\n","filename":"src\/hotspot\/share\/opto\/regmask.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -87,1 +87,1 @@\n-    @IR(counts = { \"bic\", \" >= 1\" })\n+    @IR(counts = { \"vand_notI\", \" >= 1\" })\n@@ -101,1 +101,1 @@\n-    @IR(counts = { \"bic\", \" >= 1\" })\n+    @IR(counts = { \"and_notL\", \" >= 1\" })\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/AllBitsSetVectorMatchRuleTest.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -227,1 +227,1 @@\n-    @IR(counts = { \"sve_mla\", \">= 1\" })\n+    @IR(counts = { \"vmla_masked\", \">= 1\" })\n@@ -240,1 +240,1 @@\n-    @IR(counts = { \"sve_mls\", \">= 1\" })\n+    @IR(counts = { \"vmls_masked\", \">= 1\" })\n@@ -253,1 +253,1 @@\n-    @IR(counts = { \"sve_mla\", \">= 1\" })\n+    @IR(counts = { \"vmla_masked\", \">= 1\" })\n@@ -266,1 +266,1 @@\n-    @IR(counts = { \"sve_mls\", \">= 1\" })\n+    @IR(counts = { \"vmls_masked\", \">= 1\" })\n@@ -279,1 +279,1 @@\n-    @IR(counts = { \"sve_mla\", \">= 1\" })\n+    @IR(counts = { \"vmla_masked\", \">= 1\" })\n@@ -292,1 +292,1 @@\n-    @IR(counts = { \"sve_mls\", \">= 1\" })\n+    @IR(counts = { \"vmls_masked\", \">= 1\" })\n@@ -305,1 +305,1 @@\n-    @IR(counts = { \"sve_mla\", \">= 1\" })\n+    @IR(counts = { \"vmla_masked\", \">= 1\" })\n@@ -318,1 +318,1 @@\n-    @IR(counts = { \"sve_mls\", \">= 1\" })\n+    @IR(counts = { \"vmls_masked\", \">= 1\" })\n@@ -331,1 +331,1 @@\n-    @IR(counts = { \"sve_fmsb\", \">= 1\" })\n+    @IR(counts = { \"vfmsb_masked\", \">= 1\" })\n@@ -344,1 +344,1 @@\n-    @IR(counts = { \"sve_fnmad\", \">= 1\" })\n+    @IR(counts = { \"vfnmad_masked\", \">= 1\" })\n@@ -357,1 +357,1 @@\n-    @IR(counts = { \"sve_fnmsb\", \">= 1\" })\n+    @IR(counts = { \"vfnmsb_masked\", \">= 1\" })\n@@ -370,1 +370,1 @@\n-    @IR(counts = { \"sve_fmsb\", \">= 1\" })\n+    @IR(counts = { \"vfmsb_masked\", \">= 1\" })\n@@ -383,1 +383,1 @@\n-    @IR(counts = { \"sve_fnmad\", \">= 1\" })\n+    @IR(counts = { \"vfnmad_masked\", \">= 1\" })\n@@ -396,1 +396,1 @@\n-    @IR(counts = { \"sve_fnmsb\", \">= 1\" })\n+    @IR(counts = { \"vfnmsb_masked\", \">= 1\" })\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/VectorFusedMultiplyAddSubTest.java","additions":14,"deletions":14,"binary":false,"changes":28,"status":"modified"},{"patch":"@@ -80,1 +80,1 @@\n-    @IR(counts = { \"sve_not\", \">= 1\" })\n+    @IR(counts = { \"vnotI_masked\", \">= 1\" })\n@@ -98,1 +98,1 @@\n-    @IR(counts = { \"sve_not\", \">= 1\" })\n+    @IR(counts = { \"vnotL_masked\", \">= 1\" })\n","filename":"test\/hotspot\/jtreg\/compiler\/vectorapi\/VectorMaskedNotTest.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"}]}