{"files":[{"patch":"@@ -158,4 +158,0 @@\n-void Assembler::adrp(Register reg1, const Address &dest, uint64_t &byte_offset) {\n-  ShouldNotReachHere();\n-}\n-\n@@ -192,1 +188,1 @@\n-    rf(Rd, 0);\n+    zrf(Rd, 0);\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.cpp","additions":1,"deletions":5,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -223,1 +223,1 @@\n-  static void patch(address a, int msb, int lsb, uint64_t val) {\n+  static ALWAYSINLINE void patch(address a, int msb, int lsb, uint64_t val) {\n@@ -721,1 +721,1 @@\n-  void adrp(Register Rd, const Address &dest, uint64_t &offset);\n+  void adrp(Register Rd, const Address &dest, uint64_t &offset) = delete;\n","filename":"src\/hotspot\/cpu\/aarch64\/assembler_aarch64.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2701,1 +2701,1 @@\n-  if (offset) __ add(res, res, offset);\n+  __ add(res, res, offset);\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -173,1 +173,6 @@\n-  lea(rdispatch, Address(rdispatch, offset));\n+  \/\/ Use add() here after ARDP, rather than lea().\n+  \/\/ lea() does not generate anything if its offset is zero.\n+  \/\/ However, relocs expect to find either an ADD or a load\/store\n+  \/\/ insn after an ADRP.  add() always generates an ADD insn, even\n+  \/\/ for add(Rn, Rn, 0).\n+  add(rdispatch, rdispatch, offset);\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -55,0 +55,1 @@\n+#include \"runtime\/safefetch.hpp\"\n@@ -76,65 +77,149 @@\n-\/\/ Patch any kind of instruction; there may be several instructions.\n-\/\/ Return the total length (in bytes) of the instructions.\n-int MacroAssembler::pd_patch_instruction_size(address branch, address target) {\n-  int instructions = 1;\n-  assert((uint64_t)target < (1ull << 48), \"48-bit overflow in address constant\");\n-  intptr_t offset = (target - branch) >> 2;\n-  unsigned insn = *(unsigned*)branch;\n-  if ((Instruction_aarch64::extract(insn, 29, 24) & 0b111011) == 0b011000) {\n-    \/\/ Load register (literal)\n-    Instruction_aarch64::spatch(branch, 23, 5, offset);\n-  } else if (Instruction_aarch64::extract(insn, 30, 26) == 0b00101) {\n-    \/\/ Unconditional branch (immediate)\n-    Instruction_aarch64::spatch(branch, 25, 0, offset);\n-  } else if (Instruction_aarch64::extract(insn, 31, 25) == 0b0101010) {\n-    \/\/ Conditional branch (immediate)\n-    Instruction_aarch64::spatch(branch, 23, 5, offset);\n-  } else if (Instruction_aarch64::extract(insn, 30, 25) == 0b011010) {\n-    \/\/ Compare & branch (immediate)\n-    Instruction_aarch64::spatch(branch, 23, 5, offset);\n-  } else if (Instruction_aarch64::extract(insn, 30, 25) == 0b011011) {\n-    \/\/ Test & branch (immediate)\n-    Instruction_aarch64::spatch(branch, 18, 5, offset);\n-  } else if (Instruction_aarch64::extract(insn, 28, 24) == 0b10000) {\n-    \/\/ PC-rel. addressing\n-    offset = target-branch;\n-    int shift = Instruction_aarch64::extract(insn, 31, 31);\n-    if (shift) {\n-      uint64_t dest = (uint64_t)target;\n-      uint64_t pc_page = (uint64_t)branch >> 12;\n-      uint64_t adr_page = (uint64_t)target >> 12;\n-      unsigned offset_lo = dest & 0xfff;\n-      offset = adr_page - pc_page;\n-\n-      \/\/ We handle 4 types of PC relative addressing\n-      \/\/   1 - adrp    Rx, target_page\n-      \/\/       ldr\/str Ry, [Rx, #offset_in_page]\n-      \/\/   2 - adrp    Rx, target_page\n-      \/\/       add     Ry, Rx, #offset_in_page\n-      \/\/   3 - adrp    Rx, target_page (page aligned reloc, offset == 0)\n-      \/\/       movk    Rx, #imm16<<32\n-      \/\/   4 - adrp    Rx, target_page (page aligned reloc, offset == 0)\n-      \/\/ In the first 3 cases we must check that Rx is the same in the adrp and the\n-      \/\/ subsequent ldr\/str, add or movk instruction. Otherwise we could accidentally end\n-      \/\/ up treating a type 4 relocation as a type 1, 2 or 3 just because it happened\n-      \/\/ to be followed by a random unrelated ldr\/str, add or movk instruction.\n-      \/\/\n-      unsigned insn2 = ((unsigned*)branch)[1];\n-      if (Instruction_aarch64::extract(insn2, 29, 24) == 0b111001 &&\n-                Instruction_aarch64::extract(insn, 4, 0) ==\n-                        Instruction_aarch64::extract(insn2, 9, 5)) {\n-        \/\/ Load\/store register (unsigned immediate)\n-        unsigned size = Instruction_aarch64::extract(insn2, 31, 30);\n-        Instruction_aarch64::patch(branch + sizeof (unsigned),\n-                                    21, 10, offset_lo >> size);\n-        guarantee(((dest >> size) << size) == dest, \"misaligned target\");\n-        instructions = 2;\n-      } else if (Instruction_aarch64::extract(insn2, 31, 22) == 0b1001000100 &&\n-                Instruction_aarch64::extract(insn, 4, 0) ==\n-                        Instruction_aarch64::extract(insn2, 4, 0)) {\n-        \/\/ add (immediate)\n-        Instruction_aarch64::patch(branch + sizeof (unsigned),\n-                                   21, 10, offset_lo);\n-        instructions = 2;\n-      } else if (Instruction_aarch64::extract(insn2, 31, 21) == 0b11110010110 &&\n-                   Instruction_aarch64::extract(insn, 4, 0) ==\n+#ifdef ASSERT\n+extern \"C\" void disnm(intptr_t p);\n+#endif\n+\/\/ Target-dependent relocation processing\n+\/\/\n+\/\/ Instruction sequences whose target may need to be retrieved or\n+\/\/ patched are distinguished by their leading instruction, sorting\n+\/\/ them into three main instruction groups and related subgroups.\n+\/\/\n+\/\/ 1) Branch, Exception and System (insn count = 1)\n+\/\/    1a) Unconditional branch (immediate):\n+\/\/      b\/bl imm19\n+\/\/    1b) Compare & branch (immediate):\n+\/\/      cbz\/cbnz Rt imm19\n+\/\/    1c) Test & branch (immediate):\n+\/\/      tbz\/tbnz Rt imm14\n+\/\/    1d) Conditional branch (immediate):\n+\/\/      b.cond imm19\n+\/\/\n+\/\/ 2) Loads and Stores (insn count = 1)\n+\/\/    2a) Load register literal:\n+\/\/      ldr Rt imm19\n+\/\/\n+\/\/ 3) Data Processing Immediate (insn count = 2 or 3)\n+\/\/    3a) PC-rel. addressing\n+\/\/      adr\/adrp Rx imm21; ldr\/str Ry Rx  #imm12\n+\/\/      adr\/adrp Rx imm21; add Ry Rx  #imm12\n+\/\/      adr\/adrp Rx imm21; movk Rx #imm16<<32; ldr\/str Ry, [Rx, #offset_in_page]\n+\/\/      adr\/adrp Rx imm21\n+\/\/      adr\/adrp Rx imm21; movk Rx #imm16<<32\n+\/\/      adr\/adrp Rx imm21; movk Rx #imm16<<32; add Ry, Rx, #offset_in_page\n+\/\/      The latter form can only happen when the target is an\n+\/\/      ExternalAddress, and (by definition) ExternalAddresses don't\n+\/\/      move. Because of that property, there is never any need to\n+\/\/      patch the last of the three instructions. However,\n+\/\/      MacroAssembler::target_addr_for_insn takes all three\n+\/\/      instructions into account and returns the correct address.\n+\/\/    3b) Move wide (immediate)\n+\/\/      movz Rx #imm16; movk Rx #imm16 << 16; movk Rx #imm16 << 32;\n+\/\/\n+\/\/ A switch on a subset of the instruction's bits provides an\n+\/\/ efficient dispatch to these subcases.\n+\/\/\n+\/\/ insn[28:26] -> main group ('x' == don't care)\n+\/\/   00x -> UNALLOCATED\n+\/\/   100 -> Data Processing Immediate\n+\/\/   101 -> Branch, Exception and System\n+\/\/   x1x -> Loads and Stores\n+\/\/\n+\/\/ insn[30:25] -> subgroup ('_' == group, 'x' == don't care).\n+\/\/ n.b. in some cases extra bits need to be checked to verify the\n+\/\/ instruction is as expected\n+\/\/\n+\/\/ 1) ... xx101x Branch, Exception and System\n+\/\/   1a)  00___x Unconditional branch (immediate)\n+\/\/   1b)  01___0 Compare & branch (immediate)\n+\/\/   1c)  01___1 Test & branch (immediate)\n+\/\/   1d)  10___0 Conditional branch (immediate)\n+\/\/        other  Should not happen\n+\/\/\n+\/\/ 2) ... xxx1x0 Loads and Stores\n+\/\/   2a)  xx1__00 Load\/Store register (insn[28] == 1 && insn[24] == 0)\n+\/\/   2aa) x01__00 Load register literal (i.e. requires insn[29] == 0)\n+\/\/                strictly should be 64 bit non-FP\/SIMD i.e.\n+\/\/       0101_000 (i.e. requires insn[31:24] == 01011000)\n+\/\/\n+\/\/ 3) ... xx100x Data Processing Immediate\n+\/\/   3a)  xx___00 PC-rel. addressing (n.b. requires insn[24] == 0)\n+\/\/   3b)  xx___101 Move wide (immediate) (n.b. requires insn[24:23] == 01)\n+\/\/                 strictly should be 64 bit movz #imm16<<0\n+\/\/       110___10100 (i.e. requires insn[31:21] == 11010010100)\n+\/\/\n+class RelocActions {\n+protected:\n+  typedef int (*reloc_insn)(address insn_addr, address &target);\n+\n+  virtual reloc_insn adrpMem() = 0;\n+  virtual reloc_insn adrpAdd() = 0;\n+  virtual reloc_insn adrpMovk() = 0;\n+\n+  const uint32_t _insn;\n+\n+public:\n+\n+  RelocActions(address insn_addr) : _insn(*(uint32_t*)insn_addr) {}\n+  RelocActions(address insn_addr, uint32_t insn) : _insn(insn) {}\n+\n+  virtual int unconditionalBranch(address insn_addr, address &target) = 0;\n+  virtual int conditionalBranch(address insn_addr, address &target) = 0;\n+  virtual int testAndBranch(address insn_addr, address &target) = 0;\n+  virtual int loadStore(address insn_addr, address &target) = 0;\n+  virtual int adr(address insn_addr, address &target) = 0;\n+  virtual int adrp(address insn_addr, address &target, reloc_insn inner) = 0;\n+  virtual int immediate(address insn_addr, address &target) = 0;\n+  virtual void verify(address insn_addr, address &target) = 0;\n+\n+  int ALWAYSINLINE run(address insn_addr, address &target) {\n+    int instructions = 1;\n+\n+    uint32_t dispatch = Instruction_aarch64::extract(_insn, 30, 25);\n+    switch(dispatch) {\n+      case 0b001010:\n+      case 0b001011: {\n+        instructions = unconditionalBranch(insn_addr, target);\n+        break;\n+      }\n+      case 0b101010:   \/\/ Conditional branch (immediate)\n+      case 0b011010: { \/\/ Compare & branch (immediate)\n+        instructions = conditionalBranch(insn_addr, target);\n+          break;\n+      }\n+      case 0b011011: {\n+        instructions = testAndBranch(insn_addr, target);\n+        break;\n+      }\n+      case 0b001100:\n+      case 0b001110:\n+      case 0b011100:\n+      case 0b011110:\n+      case 0b101100:\n+      case 0b101110:\n+      case 0b111100:\n+      case 0b111110: {\n+        \/\/ load\/store\n+        if ((Instruction_aarch64::extract(_insn, 29, 24) & 0b111011) == 0b011000) {\n+          \/\/ Load register (literal)\n+          instructions = loadStore(insn_addr, target);\n+          break;\n+        } else {\n+          \/\/ nothing to do\n+          assert(target == 0, \"did not expect to relocate target for polling page load\");\n+        }\n+        break;\n+      }\n+      case 0b001000:\n+      case 0b011000:\n+      case 0b101000:\n+      case 0b111000: {\n+        \/\/ adr\/adrp\n+        assert(Instruction_aarch64::extract(_insn, 28, 24) == 0b10000, \"must be\");\n+        int shift = Instruction_aarch64::extract(_insn, 31, 31);\n+        if (shift) {\n+          uint32_t insn2 = ((uint32_t*)insn_addr)[1];\n+          if (Instruction_aarch64::extract(insn2, 29, 24) == 0b111001 &&\n+              Instruction_aarch64::extract(_insn, 4, 0) ==\n+              Instruction_aarch64::extract(insn2, 9, 5)) {\n+            instructions = adrp(insn_addr, target, adrpMem());\n+          } else if (Instruction_aarch64::extract(insn2, 31, 22) == 0b1001000100 &&\n+                     Instruction_aarch64::extract(_insn, 4, 0) ==\n@@ -142,7 +227,22 @@\n-        \/\/ movk #imm16<<32\n-        Instruction_aarch64::patch(branch + 4, 20, 5, (uint64_t)target >> 32);\n-        uintptr_t dest = ((uintptr_t)target & 0xffffffffULL) | ((uintptr_t)branch & 0xffff00000000ULL);\n-        uintptr_t pc_page = (uintptr_t)branch >> 12;\n-        uintptr_t adr_page = (uintptr_t)dest >> 12;\n-        offset = adr_page - pc_page;\n-        instructions = 2;\n+            instructions = adrp(insn_addr, target, adrpAdd());\n+          } else if (Instruction_aarch64::extract(insn2, 31, 21) == 0b11110010110 &&\n+                     Instruction_aarch64::extract(_insn, 4, 0) ==\n+                     Instruction_aarch64::extract(insn2, 4, 0)) {\n+            instructions = adrp(insn_addr, target, adrpMovk());\n+          } else {\n+            ShouldNotReachHere();\n+          }\n+        } else {\n+          instructions = adr(insn_addr, target);\n+        }\n+        break;\n+      }\n+      case 0b001001:\n+      case 0b011001:\n+      case 0b101001:\n+      case 0b111001: {\n+        instructions = immediate(insn_addr, target);\n+        break;\n+      }\n+      default: {\n+        ShouldNotReachHere();\n@@ -151,0 +251,40 @@\n+\n+    verify(insn_addr, target);\n+    return instructions * NativeInstruction::instruction_size;\n+  }\n+};\n+\n+class Patcher : public RelocActions {\n+  virtual reloc_insn adrpMem() { return &Patcher::adrpMem_impl; }\n+  virtual reloc_insn adrpAdd() { return &Patcher::adrpAdd_impl; }\n+  virtual reloc_insn adrpMovk() { return &Patcher::adrpMovk_impl; }\n+\n+public:\n+  Patcher(address insn_addr) : RelocActions(insn_addr) {}\n+\n+  virtual int unconditionalBranch(address insn_addr, address &target) {\n+    intptr_t offset = (target - insn_addr) >> 2;\n+    Instruction_aarch64::spatch(insn_addr, 25, 0, offset);\n+    return 1;\n+  }\n+  virtual int conditionalBranch(address insn_addr, address &target) {\n+    intptr_t offset = (target - insn_addr) >> 2;\n+    Instruction_aarch64::spatch(insn_addr, 23, 5, offset);\n+    return 1;\n+  }\n+  virtual int testAndBranch(address insn_addr, address &target) {\n+    intptr_t offset = (target - insn_addr) >> 2;\n+    Instruction_aarch64::spatch(insn_addr, 18, 5, offset);\n+    return 1;\n+  }\n+  virtual int loadStore(address insn_addr, address &target) {\n+    intptr_t offset = (target - insn_addr) >> 2;\n+    Instruction_aarch64::spatch(insn_addr, 23, 5, offset);\n+    return 1;\n+  }\n+  virtual int adr(address insn_addr, address &target) {\n+#ifdef ASSERT\n+    assert(Instruction_aarch64::extract(_insn, 28, 24) == 0b10000, \"must be\");\n+#endif\n+    \/\/ PC-rel. addressing\n+    ptrdiff_t offset = target - insn_addr;\n@@ -153,3 +293,50 @@\n-    Instruction_aarch64::spatch(branch, 23, 5, offset);\n-    Instruction_aarch64::patch(branch, 30, 29, offset_lo);\n-  } else if (Instruction_aarch64::extract(insn, 31, 21) == 0b11010010100) {\n+    Instruction_aarch64::spatch(insn_addr, 23, 5, offset);\n+    Instruction_aarch64::patch(insn_addr, 30, 29, offset_lo);\n+    return 1;\n+  }\n+  virtual int adrp(address insn_addr, address &target, reloc_insn inner) {\n+    int instructions = 1;\n+#ifdef ASSERT\n+    assert(Instruction_aarch64::extract(_insn, 28, 24) == 0b10000, \"must be\");\n+#endif\n+    ptrdiff_t offset = target - insn_addr;\n+    if (inner) {\n+      instructions = 2;\n+      uintptr_t dest = (uintptr_t)target;\n+      uintptr_t pc_page = (uintptr_t)insn_addr >> 12;\n+      uintptr_t adr_page = (uintptr_t)target >> 12;\n+      uint32_t offset_lo = dest & 0xfff;\n+      offset = adr_page - pc_page;\n+      instructions = (*inner)(insn_addr, target);\n+    }\n+    \/\/ Now we extract the lower 21 bits of the signed offset field for\n+    \/\/ the ADR or ADRP.\n+    offset = offset << (64-21) >> (64-21);\n+    int offset_lo = offset & 3;\n+    offset >>= 2;\n+    Instruction_aarch64::spatch(insn_addr, 23, 5, offset);\n+    Instruction_aarch64::patch(insn_addr, 30, 29, offset_lo);\n+    return instructions;\n+  }\n+  static int adrpMem_impl(address insn_addr, address &target) {\n+    uintptr_t dest = (uintptr_t)target;\n+    int offset_lo = dest & 0xfff;\n+    uint32_t insn2 = ((uint32_t*)insn_addr)[1];\n+    uint32_t size = Instruction_aarch64::extract(insn2, 31, 30);\n+    Instruction_aarch64::patch(insn_addr + sizeof (uint32_t), 21, 10, offset_lo >> size);\n+    guarantee(((dest >> size) << size) == dest, \"misaligned target\");\n+    return 2;\n+  }\n+  static int adrpAdd_impl(address insn_addr, address &target) {\n+    uintptr_t dest = (uintptr_t)target;\n+    int offset_lo = dest & 0xfff;\n+    Instruction_aarch64::patch(insn_addr + sizeof (uint32_t), 21, 10, offset_lo);\n+    return 2;\n+  }\n+  static int adrpMovk_impl(address insn_addr, address &target) {\n+    uintptr_t dest = (uintptr_t)target;\n+    Instruction_aarch64::patch(insn_addr + sizeof (uint32_t), 20, 5, (uintptr_t)target >> 32);\n+    return 2;\n+  }\n+  virtual int immediate(address insn_addr, address &target) {\n+    assert(Instruction_aarch64::extract(_insn, 31, 21) == 0b11010010100, \"must be\");\n@@ -158,12 +345,6 @@\n-    assert(nativeInstruction_at(branch+4)->is_movk(), \"wrong insns in patch\");\n-    assert(nativeInstruction_at(branch+8)->is_movk(), \"wrong insns in patch\");\n-    Instruction_aarch64::patch(branch, 20, 5, dest & 0xffff);\n-    Instruction_aarch64::patch(branch+4, 20, 5, (dest >>= 16) & 0xffff);\n-    Instruction_aarch64::patch(branch+8, 20, 5, (dest >>= 16) & 0xffff);\n-    assert(target_addr_for_insn(branch) == target, \"should be\");\n-    instructions = 3;\n-  } else if (NativeInstruction::is_ldrw_to_zr(address(&insn))) {\n-    \/\/ nothing to do\n-    assert(target == 0, \"did not expect to relocate target for polling page load\");\n-  } else {\n-    ShouldNotReachHere();\n+    assert(nativeInstruction_at(insn_addr+4)->is_movk(), \"wrong insns in patch\");\n+    assert(nativeInstruction_at(insn_addr+8)->is_movk(), \"wrong insns in patch\");\n+    Instruction_aarch64::patch(insn_addr, 20, 5, dest & 0xffff);\n+    Instruction_aarch64::patch(insn_addr+4, 20, 5, (dest >>= 16) & 0xffff);\n+    Instruction_aarch64::patch(insn_addr+8, 20, 5, (dest >>= 16) & 0xffff);\n+    return 3;\n@@ -171,1 +352,147 @@\n-  return instructions * NativeInstruction::instruction_size;\n+  virtual void verify(address insn_addr, address &target) {\n+#ifdef ASSERT\n+    address address_is = MacroAssembler::target_addr_for_insn(insn_addr);\n+    if (!(address_is == target)) {\n+      tty->print_cr(\"%p at %p should be %p\", address_is, insn_addr, target);\n+      disnm((intptr_t)insn_addr);\n+      assert(address_is == target, \"should be\");\n+    }\n+#endif\n+  }\n+};\n+\n+\/\/ If insn1 and insn2 use the same register to form an address, either\n+\/\/ by an offsetted LDR or a simple ADD, return the offset. If the\n+\/\/ second instruction is an LDR, the offset may be scaled.\n+static bool offset_for(uint32_t insn1, uint32_t insn2, ptrdiff_t &byte_offset) {\n+  if (Instruction_aarch64::extract(insn2, 29, 24) == 0b111001 &&\n+      Instruction_aarch64::extract(insn1, 4, 0) ==\n+      Instruction_aarch64::extract(insn2, 9, 5)) {\n+    \/\/ Load\/store register (unsigned immediate)\n+    byte_offset = Instruction_aarch64::extract(insn2, 21, 10);\n+    uint32_t size = Instruction_aarch64::extract(insn2, 31, 30);\n+    byte_offset <<= size;\n+    return true;\n+  } else if (Instruction_aarch64::extract(insn2, 31, 22) == 0b1001000100 &&\n+             Instruction_aarch64::extract(insn1, 4, 0) ==\n+             Instruction_aarch64::extract(insn2, 4, 0)) {\n+    \/\/ add (immediate)\n+    byte_offset = Instruction_aarch64::extract(insn2, 21, 10);\n+    return true;\n+  }\n+  return false;\n+}\n+\n+class Decoder : public RelocActions {\n+  virtual reloc_insn adrpMem() { return &Decoder::adrpMem_impl; }\n+  virtual reloc_insn adrpAdd() { return &Decoder::adrpAdd_impl; }\n+  virtual reloc_insn adrpMovk() { return &Decoder::adrpMovk_impl; }\n+\n+public:\n+  Decoder(address insn_addr, uint32_t insn) : RelocActions(insn_addr, insn) {}\n+\n+  virtual int loadStore(address insn_addr, address &target) {\n+    intptr_t offset = Instruction_aarch64::sextract(_insn, 23, 5);\n+    target = insn_addr + (offset << 2);\n+    return 1;\n+  }\n+  virtual int unconditionalBranch(address insn_addr, address &target) {\n+    intptr_t offset = Instruction_aarch64::sextract(_insn, 25, 0);\n+    target = insn_addr + (offset << 2);\n+    return 1;\n+  }\n+  virtual int conditionalBranch(address insn_addr, address &target) {\n+    intptr_t offset = Instruction_aarch64::sextract(_insn, 23, 5);\n+    target = address(((uint64_t)insn_addr + (offset << 2)));\n+    return 1;\n+  }\n+  virtual int testAndBranch(address insn_addr, address &target) {\n+    intptr_t offset = Instruction_aarch64::sextract(_insn, 18, 5);\n+    target = address(((uint64_t)insn_addr + (offset << 2)));\n+    return 1;\n+  }\n+  virtual int adr(address insn_addr, address &target) {\n+    \/\/ PC-rel. addressing\n+    intptr_t offset = Instruction_aarch64::extract(_insn, 30, 29);\n+    offset |= Instruction_aarch64::sextract(_insn, 23, 5) << 2;\n+    target = address((uint64_t)insn_addr + offset);\n+    return 1;\n+  }\n+  virtual int adrp(address insn_addr, address &target, reloc_insn inner) {\n+    assert(Instruction_aarch64::extract(_insn, 28, 24) == 0b10000, \"must be\");\n+    intptr_t offset = Instruction_aarch64::extract(_insn, 30, 29);\n+    offset |= Instruction_aarch64::sextract(_insn, 23, 5) << 2;\n+    int shift = 12;\n+    offset <<= shift;\n+    uint64_t target_page = ((uint64_t)insn_addr) + offset;\n+    target_page &= ((uint64_t)-1) << shift;\n+    uint32_t insn2 = ((uint32_t*)insn_addr)[1];\n+    target = address(target_page);\n+    (*inner)(insn_addr, target);\n+    return 2;\n+  }\n+  static int adrpMem_impl(address insn_addr, address &target) {\n+    uint32_t insn2 = ((uint32_t*)insn_addr)[1];\n+    \/\/ Load\/store register (unsigned immediate)\n+    ptrdiff_t byte_offset = Instruction_aarch64::extract(insn2, 21, 10);\n+    uint32_t size = Instruction_aarch64::extract(insn2, 31, 30);\n+    byte_offset <<= size;\n+    target += byte_offset;\n+    return 2;\n+  }\n+  static int adrpAdd_impl(address insn_addr, address &target) {\n+    uint32_t insn2 = ((uint32_t*)insn_addr)[1];\n+    \/\/ add (immediate)\n+    ptrdiff_t byte_offset = Instruction_aarch64::extract(insn2, 21, 10);\n+    target += byte_offset;\n+    return 2;\n+  }\n+  static int adrpMovk_impl(address insn_addr, address &target) {\n+    uint32_t insn2 = ((uint32_t*)insn_addr)[1];\n+    uint64_t dest = uint64_t(target);\n+    dest = (dest & 0xffffffff) |\n+      ((uint64_t)Instruction_aarch64::extract(insn2, 20, 5) << 32);\n+    target = address(dest);\n+\n+    \/\/ We know the destination 4k page. Maybe we have a third\n+    \/\/ instruction.\n+    uint32_t insn = ((uint32_t*)insn_addr)[0];\n+    int *insn3_addr = &((int*)insn_addr)[2];\n+    uint32_t insn3 = (uint32_t)SafeFetch32(insn3_addr, -1);\n+    ptrdiff_t byte_offset;\n+    if (offset_for(insn, insn3, byte_offset)) {\n+      target += byte_offset;\n+      return 3;\n+    } else {\n+      return 2;\n+    }\n+  }\n+  virtual int immediate(address insn_addr, address &target) {\n+    uint32_t *insns = (uint32_t *)insn_addr;\n+    assert(Instruction_aarch64::extract(_insn, 31, 21) == 0b11010010100, \"must be\");\n+    \/\/ Move wide constant: movz, movk, movk.  See movptr().\n+    assert(nativeInstruction_at(insns+1)->is_movk(), \"wrong insns in patch\");\n+    assert(nativeInstruction_at(insns+2)->is_movk(), \"wrong insns in patch\");\n+    target = address(uint64_t(Instruction_aarch64::extract(_insn, 20, 5))\n+                 + (uint64_t(Instruction_aarch64::extract(insns[1], 20, 5)) << 16)\n+                 + (uint64_t(Instruction_aarch64::extract(insns[2], 20, 5)) << 32));\n+    assert(nativeInstruction_at(insn_addr+4)->is_movk(), \"wrong insns in patch\");\n+    assert(nativeInstruction_at(insn_addr+8)->is_movk(), \"wrong insns in patch\");\n+    return 3;\n+  }\n+  virtual void verify(address insn_addr, address &target) {\n+  }\n+};\n+\n+address MacroAssembler::target_addr_for_insn(address insn_addr, uint32_t insn) {\n+  Decoder decoder(insn_addr, insn);\n+  address target;\n+  decoder.run(insn_addr, target);\n+  return target;\n+}\n+\n+\/\/ Patch any kind of instruction; there may be several instructions.\n+\/\/ Return the total length (in bytes) of the instructions.\n+int MacroAssembler::pd_patch_instruction_size(address insn_addr, address target) {\n+  Patcher patcher(insn_addr);\n+  return patcher.run(insn_addr, target);\n@@ -213,81 +540,0 @@\n-address MacroAssembler::target_addr_for_insn(address insn_addr, unsigned insn) {\n-  intptr_t offset = 0;\n-  if ((Instruction_aarch64::extract(insn, 29, 24) & 0b011011) == 0b00011000) {\n-    \/\/ Load register (literal)\n-    offset = Instruction_aarch64::sextract(insn, 23, 5);\n-    return address(((uint64_t)insn_addr + (offset << 2)));\n-  } else if (Instruction_aarch64::extract(insn, 30, 26) == 0b00101) {\n-    \/\/ Unconditional branch (immediate)\n-    offset = Instruction_aarch64::sextract(insn, 25, 0);\n-  } else if (Instruction_aarch64::extract(insn, 31, 25) == 0b0101010) {\n-    \/\/ Conditional branch (immediate)\n-    offset = Instruction_aarch64::sextract(insn, 23, 5);\n-  } else if (Instruction_aarch64::extract(insn, 30, 25) == 0b011010) {\n-    \/\/ Compare & branch (immediate)\n-    offset = Instruction_aarch64::sextract(insn, 23, 5);\n-   } else if (Instruction_aarch64::extract(insn, 30, 25) == 0b011011) {\n-    \/\/ Test & branch (immediate)\n-    offset = Instruction_aarch64::sextract(insn, 18, 5);\n-  } else if (Instruction_aarch64::extract(insn, 28, 24) == 0b10000) {\n-    \/\/ PC-rel. addressing\n-    offset = Instruction_aarch64::extract(insn, 30, 29);\n-    offset |= Instruction_aarch64::sextract(insn, 23, 5) << 2;\n-    int shift = Instruction_aarch64::extract(insn, 31, 31) ? 12 : 0;\n-    if (shift) {\n-      offset <<= shift;\n-      uint64_t target_page = ((uint64_t)insn_addr) + offset;\n-      target_page &= ((uint64_t)-1) << shift;\n-      \/\/ Return the target address for the following sequences\n-      \/\/   1 - adrp    Rx, target_page\n-      \/\/       ldr\/str Ry, [Rx, #offset_in_page]\n-      \/\/   2 - adrp    Rx, target_page\n-      \/\/       add     Ry, Rx, #offset_in_page\n-      \/\/   3 - adrp    Rx, target_page (page aligned reloc, offset == 0)\n-      \/\/       movk    Rx, #imm12<<32\n-      \/\/   4 - adrp    Rx, target_page (page aligned reloc, offset == 0)\n-      \/\/\n-      \/\/ In the first two cases  we check that the register is the same and\n-      \/\/ return the target_page + the offset within the page.\n-      \/\/ Otherwise we assume it is a page aligned relocation and return\n-      \/\/ the target page only.\n-      \/\/\n-      unsigned insn2 = ((unsigned*)insn_addr)[1];\n-      if (Instruction_aarch64::extract(insn2, 29, 24) == 0b111001 &&\n-                Instruction_aarch64::extract(insn, 4, 0) ==\n-                        Instruction_aarch64::extract(insn2, 9, 5)) {\n-        \/\/ Load\/store register (unsigned immediate)\n-        unsigned int byte_offset = Instruction_aarch64::extract(insn2, 21, 10);\n-        unsigned int size = Instruction_aarch64::extract(insn2, 31, 30);\n-        return address(target_page + (byte_offset << size));\n-      } else if (Instruction_aarch64::extract(insn2, 31, 22) == 0b1001000100 &&\n-                Instruction_aarch64::extract(insn, 4, 0) ==\n-                        Instruction_aarch64::extract(insn2, 4, 0)) {\n-        \/\/ add (immediate)\n-        unsigned int byte_offset = Instruction_aarch64::extract(insn2, 21, 10);\n-        return address(target_page + byte_offset);\n-      } else {\n-        if (Instruction_aarch64::extract(insn2, 31, 21) == 0b11110010110  &&\n-               Instruction_aarch64::extract(insn, 4, 0) ==\n-                 Instruction_aarch64::extract(insn2, 4, 0)) {\n-          target_page = (target_page & 0xffffffff) |\n-                         ((uint64_t)Instruction_aarch64::extract(insn2, 20, 5) << 32);\n-        }\n-        return (address)target_page;\n-      }\n-    } else {\n-      ShouldNotReachHere();\n-    }\n-  } else if (Instruction_aarch64::extract(insn, 31, 23) == 0b110100101) {\n-    uint32_t *insns = (uint32_t *)insn_addr;\n-    \/\/ Move wide constant: movz, movk, movk.  See movptr().\n-    assert(nativeInstruction_at(insns+1)->is_movk(), \"wrong insns in patch\");\n-    assert(nativeInstruction_at(insns+2)->is_movk(), \"wrong insns in patch\");\n-    return address(uint64_t(Instruction_aarch64::extract(insns[0], 20, 5))\n-                   + (uint64_t(Instruction_aarch64::extract(insns[1], 20, 5)) << 16)\n-                   + (uint64_t(Instruction_aarch64::extract(insns[2], 20, 5)) << 32));\n-  } else {\n-    ShouldNotReachHere();\n-  }\n-  return address(((uint64_t)insn_addr + (offset << 2)));\n-}\n-\n@@ -296,1 +542,1 @@\n-    return 0;\n+    return nullptr;\n@@ -3453,1 +3699,0 @@\n-  uint64_t offset;\n@@ -3462,2 +3707,5 @@\n-    adrp(table0, ExternalAddress(StubRoutines::crc_table_addr()), offset);\n-    if (offset) add(table0, table0, offset);\n+    {\n+      uint64_t offset;\n+      adrp(table0, ExternalAddress(StubRoutines::crc_table_addr()), offset);\n+      add(table0, table0, offset);\n+    }\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":421,"deletions":173,"binary":false,"changes":594,"status":"modified"},{"patch":"@@ -6952,0 +6952,16 @@\n+#ifdef ASSERT\n+    {\n+      \/\/ Stress relocs for adrp() by trying to reach a page beyond\n+      \/\/ the range of a simple ADRP instruction.\n+      ExternalAddress longWayAway(__ pc() - (1ll << 34));\n+      if (! __ is_valid_AArch64_address(longWayAway.target())) {\n+        longWayAway = ExternalAddress(__ pc() + (1ll << 34));\n+      }\n+      if (__ is_valid_AArch64_address(longWayAway.target())) {\n+        uint64_t offset;\n+        __ adrp(rscratch1, longWayAway, offset);\n+        __ add(rscratch1, rscratch1, offset);\n+      }\n+    }\n+#endif \/\/ ASSERT\n+\n@@ -6962,1 +6978,0 @@\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":16,"deletions":1,"binary":false,"changes":17,"status":"modified"}]}