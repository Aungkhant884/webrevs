{"files":[{"patch":"@@ -89,9 +89,0 @@\n-  # All \"special\" variants share the same output directory (\"server\")\n-  VALID_MULTIPLE_JVM_VARIANTS=\"server client minimal\"\n-  UTIL_GET_NON_MATCHING_VALUES(INVALID_MULTIPLE_VARIANTS, $JVM_VARIANTS, \\\n-      $VALID_MULTIPLE_JVM_VARIANTS)\n-  if  test \"x$INVALID_MULTIPLE_VARIANTS\" != x && \\\n-      test \"x$BUILDING_MULTIPLE_JVM_VARIANTS\" = xtrue; then\n-    AC_MSG_ERROR([You can only build multiple variants using these variants: '$VALID_MULTIPLE_JVM_VARIANTS'])\n-  fi\n-\n@@ -101,1 +92,1 @@\n-    MAIN_VARIANT_PRIO_ORDER=\"server client minimal\"\n+    MAIN_VARIANT_PRIO_ORDER=\"server client minimal zero\"\n","filename":"make\/autoconf\/hotspot.m4","additions":1,"deletions":10,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -252,1 +252,1 @@\n-            \"--with-exclude-translations=de,es,fr,it,ko,pt_BR,sv,ca,tr,cs,sk,ja_JP_A,ja_JP_HA,ja_JP_HI,ja_JP_I,zh_TW,zh_HK\",\n+            \"--with-exclude-translations=es,fr,it,ko,pt_BR,sv,ca,tr,cs,sk,ja_JP_A,ja_JP_HA,ja_JP_HI,ja_JP_I,zh_TW,zh_HK\",\n@@ -397,7 +397,2 @@\n-    if (input.build_os == 'macosx' && input.build_cpu == 'aarch64') {\n-        common.boot_jdk_version = \"17\";\n-        common.boot_jdk_build_number = \"24\";\n-    } else {\n-        common.boot_jdk_version = \"16\";\n-        common.boot_jdk_build_number = \"36\";\n-    }\n+    common.boot_jdk_version = \"17\";\n+    common.boot_jdk_build_number = \"35\";\n@@ -641,1 +636,1 @@\n-    [ \"linux-x64\", \"macosx-x64\", \"windows-x64\" ]\n+    [ \"linux-x64\", \"macosx-x64\", \"windows-x64\", \"linux-aarch64\" ]\n@@ -1076,5 +1071,1 @@\n-        if (input.build_cpu == \"aarch64\") {\n-            boot_jdk_os = \"macos\";\n-        } else {\n-            boot_jdk_os = \"osx\";\n-        }\n+        boot_jdk_os = \"macos\";\n","filename":"make\/conf\/jib-profiles.js","additions":5,"deletions":14,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -40,1 +40,1 @@\n-DEFAULT_ACCEPTABLE_BOOT_VERSIONS=\"16 17 18\"\n+DEFAULT_ACCEPTABLE_BOOT_VERSIONS=\"17 18\"\n","filename":"make\/conf\/version-numbers.conf","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -61,0 +61,4 @@\n+ifeq ($(JVM_VARIANT), core)\n+  JVM_CFLAGS_FEATURES += -DVMTYPE=\\\"Core\\\"\n+endif\n+\n","filename":"make\/hotspot\/lib\/JvmFeatures.gmk","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1905,1 +1905,1 @@\n-  if (C->max_vector_size() >= 16) {\n+  if (C->max_vector_size() > 0) {\n@@ -2407,1 +2407,1 @@\n-  if (!match_rule_supported(opcode) || !vector_size_supported(bt, vlen)) {\n+  if (!match_rule_supported(opcode)) {\n@@ -2415,1 +2415,1 @@\n-    return op_sve_supported(opcode);\n+    return op_sve_supported(opcode, vlen, bt);\n@@ -2457,0 +2457,3 @@\n+    case Op_LoadVectorGather:\n+    case Op_StoreVectorScatter:\n+      return false;\n@@ -2461,1 +2464,1 @@\n-  return true; \/\/ Per default match rules are supported.\n+  return vector_size_supported(bt, vlen);\n@@ -2507,0 +2510,1 @@\n+\n@@ -2509,15 +2513,8 @@\n-  if ((UseSVE > 0) && (MaxVectorSize >= 16)) {\n-    \/\/ Currently vector length less than SVE vector register size is not supported.\n-    return max_size;\n-  } else { \/\/ NEON\n-    \/\/ Limit the vector size to 8 bytes\n-    int size = 8 \/ type2aelembytes(bt);\n-    if (bt == T_BYTE) {\n-      \/\/ To support vector api shuffle\/rearrange.\n-      size = 4;\n-    } else if (bt == T_BOOLEAN) {\n-      \/\/ To support vector api load\/store mask.\n-      size = 2;\n-    }\n-    if (size < 2) size = 2;\n-    return MIN2(size,max_size);\n+  \/\/ Limit the min vector size to 8 bytes.\n+  int size = 8 \/ type2aelembytes(bt);\n+  if (bt == T_BYTE) {\n+    \/\/ To support vector api shuffle\/rearrange.\n+    size = 4;\n+  } else if (bt == T_BOOLEAN) {\n+    \/\/ To support vector api load\/store mask.\n+    size = 2;\n@@ -2525,0 +2522,2 @@\n+  if (size < 2) size = 2;\n+  return MIN2(size, max_size);\n@@ -2534,1 +2533,1 @@\n-  if (UseSVE > 0 && 16 <= len && len <= 256) {\n+  if (UseSVE > 0 && 2 <= len && len <= 256) {\n@@ -2661,0 +2660,7 @@\n+    if (u->is_LoadStore()) {\n+      \/\/ On AArch64, LoadStoreNodes (i.e. compare and swap\n+      \/\/ instructions) only take register indirect as an operand, so\n+      \/\/ any attempt to use an AddPNode as an input to a LoadStoreNode\n+      \/\/ must fail.\n+      return false;\n+    }\n@@ -3732,1 +3738,1 @@\n-    if (Compile::current()->max_vector_size() >= 16 && uncommon_trap_request() == 0) {\n+    if (Compile::current()->max_vector_size() > 0 && uncommon_trap_request() == 0) {\n@@ -3744,1 +3750,1 @@\n-    } else if (Compile::current()->max_vector_size() >= 16) {\n+    } else if (Compile::current()->max_vector_size() > 0) {\n@@ -3793,1 +3799,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -3806,1 +3812,1 @@\n-    if (Compile::current()->max_vector_size() >= 16) {\n+    if (Compile::current()->max_vector_size() > 0) {\n@@ -4184,0 +4190,10 @@\n+operand immI_gt_1()\n+%{\n+  predicate(n->get_int() > 1);\n+  match(ConI);\n+\n+  op_cost(0);\n+  format %{ %}\n+  interface(CONST_INTER);\n+%}\n+\n@@ -16935,0 +16951,1 @@\n+  predicate(!((EncodeISOArrayNode*)n)->is_ascii());\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":41,"deletions":24,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -850,1 +850,0 @@\n-void frame::pd_ps() {}\n","filename":"src\/hotspot\/cpu\/aarch64\/frame_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -309,1 +309,1 @@\n-  __ ldr(rscratch2, Address(rscratch1, ClassLoaderData::keep_alive_offset()));\n+  __ ldrw(rscratch2, Address(rscratch1, ClassLoaderData::keep_alive_offset()));\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/shared\/barrierSetAssembler_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-define_pd_global(intx, InlineFrequencyCount,     100);\n","filename":"src\/hotspot\/cpu\/aarch64\/globals_aarch64.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2702,1 +2702,3 @@\n-  if (restore_vectors) {\n+  \/\/ We may use predicate registers and rely on ptrue with SVE,\n+  \/\/ regardless of wide vector (> 8 bytes) used or not.\n+  if (use_sve) {\n@@ -5175,1 +5177,8 @@\n-\/\/    scratch1 = cnt & 7;\n+\/\/    if (cnt == 0) {\n+\/\/      return;\n+\/\/    }\n+\/\/    if ((p & 8) != 0) {\n+\/\/      *p++ = v;\n+\/\/    }\n+\/\/\n+\/\/    scratch1 = cnt & 14;\n@@ -5178,1 +5187,1 @@\n-\/\/    switch (scratch1) {\n+\/\/    switch (scratch1 \/ 2) {\n@@ -5180,2 +5189,3 @@\n-\/\/        cnt -= 8;\n-\/\/          p[-8] = v;\n+\/\/        cnt -= 16;\n+\/\/          p[-16] = v;\n+\/\/          p[-15] = v;\n@@ -5183,1 +5193,2 @@\n-\/\/          p[-7] = v;\n+\/\/          p[-14] = v;\n+\/\/          p[-13] = v;\n@@ -5185,1 +5196,2 @@\n-\/\/          p[-6] = v;\n+\/\/          p[-12] = v;\n+\/\/          p[-11] = v;\n@@ -5188,0 +5200,1 @@\n+\/\/          p[-2] = v;\n@@ -5190,1 +5203,1 @@\n-\/\/          p += 8;\n+\/\/          p += 16;\n@@ -5192,0 +5205,3 @@\n+\/\/    }\n+\/\/    if ((cnt & 1) == 1) {\n+\/\/      *p++ = v;\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":24,"deletions":8,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -1380,0 +1380,6 @@\n+\n+  void ghash_modmul (FloatRegister result,\n+                     FloatRegister result_lo, FloatRegister result_hi, FloatRegister b,\n+                     FloatRegister a, FloatRegister vzr, FloatRegister a1_xor_a0, FloatRegister p,\n+                     FloatRegister t1, FloatRegister t2, FloatRegister t3);\n+  void ghash_load_wide(int index, Register data, FloatRegister result, FloatRegister state);\n@@ -1385,0 +1391,20 @@\n+  void ghash_multiply(FloatRegister result_lo, FloatRegister result_hi,\n+                      FloatRegister a, FloatRegister b, FloatRegister a1_xor_a0,\n+                      FloatRegister tmp1, FloatRegister tmp2, FloatRegister tmp3);\n+  void ghash_multiply_wide(int index,\n+                           FloatRegister result_lo, FloatRegister result_hi,\n+                           FloatRegister a, FloatRegister b, FloatRegister a1_xor_a0,\n+                           FloatRegister tmp1, FloatRegister tmp2, FloatRegister tmp3);\n+  void ghash_reduce(FloatRegister result, FloatRegister lo, FloatRegister hi,\n+                    FloatRegister p, FloatRegister z, FloatRegister t1);\n+  void ghash_reduce_wide(int index, FloatRegister result, FloatRegister lo, FloatRegister hi,\n+                    FloatRegister p, FloatRegister z, FloatRegister t1);\n+  void ghash_processBlocks_wide(address p, Register state, Register subkeyH,\n+                                Register data, Register blocks, int unrolls);\n+\n+\n+  void aesenc_loadkeys(Register key, Register keylen);\n+  void aesecb_encrypt(Register from, Register to, Register keylen,\n+                      FloatRegister data = v0, int unrolls = 1);\n+  void aesecb_decrypt(Register from, Register to, Register key, Register keylen);\n+  void aes_round(FloatRegister input, FloatRegister subkey);\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":26,"deletions":0,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -2589,2 +2589,0 @@\n-    Label L_doLast;\n-\n@@ -2601,69 +2599,2 @@\n-    __ ld1(v0, __ T16B, from); \/\/ get 16 bytes of input\n-\n-    __ ld1(v1, v2, v3, v4, __ T16B, __ post(key, 64));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-    __ rev32(v3, __ T16B, v3);\n-    __ rev32(v4, __ T16B, v4);\n-    __ aese(v0, v1);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v2);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v3);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v4);\n-    __ aesmc(v0, v0);\n-\n-    __ ld1(v1, v2, v3, v4, __ T16B, __ post(key, 64));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-    __ rev32(v3, __ T16B, v3);\n-    __ rev32(v4, __ T16B, v4);\n-    __ aese(v0, v1);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v2);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v3);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v4);\n-    __ aesmc(v0, v0);\n-\n-    __ ld1(v1, v2, __ T16B, __ post(key, 32));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-\n-    __ cmpw(keylen, 44);\n-    __ br(Assembler::EQ, L_doLast);\n-\n-    __ aese(v0, v1);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v2);\n-    __ aesmc(v0, v0);\n-\n-    __ ld1(v1, v2, __ T16B, __ post(key, 32));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-\n-    __ cmpw(keylen, 52);\n-    __ br(Assembler::EQ, L_doLast);\n-\n-    __ aese(v0, v1);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v2);\n-    __ aesmc(v0, v0);\n-\n-    __ ld1(v1, v2, __ T16B, __ post(key, 32));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-\n-    __ BIND(L_doLast);\n-\n-    __ aese(v0, v1);\n-    __ aesmc(v0, v0);\n-    __ aese(v0, v2);\n-\n-    __ ld1(v1, __ T16B, key);\n-    __ rev32(v1, __ T16B, v1);\n-    __ eor(v0, __ T16B, v0, v1);\n-\n-    __ st1(v0, __ T16B, to);\n+    __ aesenc_loadkeys(key, keylen);\n+    __ aesecb_encrypt(from, to, keylen);\n@@ -2702,70 +2633,1 @@\n-    __ ld1(v0, __ T16B, from); \/\/ get 16 bytes of input\n-\n-    __ ld1(v5, __ T16B, __ post(key, 16));\n-    __ rev32(v5, __ T16B, v5);\n-\n-    __ ld1(v1, v2, v3, v4, __ T16B, __ post(key, 64));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-    __ rev32(v3, __ T16B, v3);\n-    __ rev32(v4, __ T16B, v4);\n-    __ aesd(v0, v1);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v2);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v3);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v4);\n-    __ aesimc(v0, v0);\n-\n-    __ ld1(v1, v2, v3, v4, __ T16B, __ post(key, 64));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-    __ rev32(v3, __ T16B, v3);\n-    __ rev32(v4, __ T16B, v4);\n-    __ aesd(v0, v1);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v2);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v3);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v4);\n-    __ aesimc(v0, v0);\n-\n-    __ ld1(v1, v2, __ T16B, __ post(key, 32));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-\n-    __ cmpw(keylen, 44);\n-    __ br(Assembler::EQ, L_doLast);\n-\n-    __ aesd(v0, v1);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v2);\n-    __ aesimc(v0, v0);\n-\n-    __ ld1(v1, v2, __ T16B, __ post(key, 32));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-\n-    __ cmpw(keylen, 52);\n-    __ br(Assembler::EQ, L_doLast);\n-\n-    __ aesd(v0, v1);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v2);\n-    __ aesimc(v0, v0);\n-\n-    __ ld1(v1, v2, __ T16B, __ post(key, 32));\n-    __ rev32(v1, __ T16B, v1);\n-    __ rev32(v2, __ T16B, v2);\n-\n-    __ BIND(L_doLast);\n-\n-    __ aesd(v0, v1);\n-    __ aesimc(v0, v0);\n-    __ aesd(v0, v2);\n-\n-    __ eor(v0, __ T16B, v0, v5);\n-\n-    __ st1(v0, __ T16B, to);\n+    __ aesecb_decrypt(from, to, key, keylen);\n@@ -2993,0 +2855,384 @@\n+  \/\/ CTR AES crypt.\n+  \/\/ Arguments:\n+  \/\/\n+  \/\/ Inputs:\n+  \/\/   c_rarg0   - source byte array address\n+  \/\/   c_rarg1   - destination byte array address\n+  \/\/   c_rarg2   - K (key) in little endian int array\n+  \/\/   c_rarg3   - counter vector byte array address\n+  \/\/   c_rarg4   - input length\n+  \/\/   c_rarg5   - saved encryptedCounter start\n+  \/\/   c_rarg6   - saved used length\n+  \/\/\n+  \/\/ Output:\n+  \/\/   r0       - input length\n+  \/\/\n+  address generate_counterMode_AESCrypt() {\n+    const Register in = c_rarg0;\n+    const Register out = c_rarg1;\n+    const Register key = c_rarg2;\n+    const Register counter = c_rarg3;\n+    const Register saved_len = c_rarg4, len = r10;\n+    const Register saved_encrypted_ctr = c_rarg5;\n+    const Register used_ptr = c_rarg6, used = r12;\n+\n+    const Register offset = r7;\n+    const Register keylen = r11;\n+\n+    const unsigned char block_size = 16;\n+    const int bulk_width = 4;\n+    \/\/ NB: bulk_width can be 4 or 8. 8 gives slightly faster\n+    \/\/ performance with larger data sizes, but it also means that the\n+    \/\/ fast path isn't used until you have at least 8 blocks, and up\n+    \/\/ to 127 bytes of data will be executed on the slow path. For\n+    \/\/ that reason, and also so as not to blow away too much icache, 4\n+    \/\/ blocks seems like a sensible compromise.\n+\n+    \/\/ Algorithm:\n+    \/\/\n+    \/\/    if (len == 0) {\n+    \/\/        goto DONE;\n+    \/\/    }\n+    \/\/    int result = len;\n+    \/\/    do {\n+    \/\/        if (used >= blockSize) {\n+    \/\/            if (len >= bulk_width * blockSize) {\n+    \/\/                CTR_large_block();\n+    \/\/                if (len == 0)\n+    \/\/                    goto DONE;\n+    \/\/            }\n+    \/\/            for (;;) {\n+    \/\/                16ByteVector v0 = counter;\n+    \/\/                embeddedCipher.encryptBlock(v0, 0, encryptedCounter, 0);\n+    \/\/                used = 0;\n+    \/\/                if (len < blockSize)\n+    \/\/                    break;    \/* goto NEXT *\/\n+    \/\/                16ByteVector v1 = load16Bytes(in, offset);\n+    \/\/                v1 = v1 ^ encryptedCounter;\n+    \/\/                store16Bytes(out, offset);\n+    \/\/                used = blockSize;\n+    \/\/                offset += blockSize;\n+    \/\/                len -= blockSize;\n+    \/\/                if (len == 0)\n+    \/\/                    goto DONE;\n+    \/\/            }\n+    \/\/        }\n+    \/\/      NEXT:\n+    \/\/        out[outOff++] = (byte)(in[inOff++] ^ encryptedCounter[used++]);\n+    \/\/        len--;\n+    \/\/    } while (len != 0);\n+    \/\/  DONE:\n+    \/\/    return result;\n+    \/\/\n+    \/\/ CTR_large_block()\n+    \/\/    Wide bulk encryption of whole blocks.\n+\n+    __ align(CodeEntryAlignment);\n+    StubCodeMark mark(this, \"StubRoutines\", \"counterMode_AESCrypt\");\n+    const address start = __ pc();\n+    __ enter();\n+\n+    Label DONE, CTR_large_block, large_block_return;\n+    __ ldrw(used, Address(used_ptr));\n+    __ cbzw(saved_len, DONE);\n+\n+    __ mov(len, saved_len);\n+    __ mov(offset, 0);\n+\n+    \/\/ Compute #rounds for AES based on the length of the key array\n+    __ ldrw(keylen, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n+\n+    __ aesenc_loadkeys(key, keylen);\n+\n+    {\n+      Label L_CTR_loop, NEXT;\n+\n+      __ bind(L_CTR_loop);\n+\n+      __ cmp(used, block_size);\n+      __ br(__ LO, NEXT);\n+\n+      \/\/ Maybe we have a lot of data\n+      __ subsw(rscratch1, len, bulk_width * block_size);\n+      __ br(__ HS, CTR_large_block);\n+      __ BIND(large_block_return);\n+      __ cbzw(len, DONE);\n+\n+      \/\/ Setup the counter\n+      __ movi(v4, __ T4S, 0);\n+      __ movi(v5, __ T4S, 1);\n+      __ ins(v4, __ S, v5, 3, 3); \/\/ v4 contains { 0, 0, 0, 1 }\n+\n+      __ ld1(v0, __ T16B, counter); \/\/ Load the counter into v0\n+      __ rev32(v16, __ T16B, v0);\n+      __ addv(v16, __ T4S, v16, v4);\n+      __ rev32(v16, __ T16B, v16);\n+      __ st1(v16, __ T16B, counter); \/\/ Save the incremented counter back\n+\n+      {\n+        \/\/ We have fewer than bulk_width blocks of data left. Encrypt\n+        \/\/ them one by one until there is less than a full block\n+        \/\/ remaining, being careful to save both the encrypted counter\n+        \/\/ and the counter.\n+\n+        Label inner_loop;\n+        __ bind(inner_loop);\n+        \/\/ Counter to encrypt is in v0\n+        __ aesecb_encrypt(noreg, noreg, keylen);\n+        __ st1(v0, __ T16B, saved_encrypted_ctr);\n+\n+        \/\/ Do we have a remaining full block?\n+\n+        __ mov(used, 0);\n+        __ cmp(len, block_size);\n+        __ br(__ LO, NEXT);\n+\n+        \/\/ Yes, we have a full block\n+        __ ldrq(v1, Address(in, offset));\n+        __ eor(v1, __ T16B, v1, v0);\n+        __ strq(v1, Address(out, offset));\n+        __ mov(used, block_size);\n+        __ add(offset, offset, block_size);\n+\n+        __ subw(len, len, block_size);\n+        __ cbzw(len, DONE);\n+\n+        \/\/ Increment the counter, store it back\n+        __ orr(v0, __ T16B, v16, v16);\n+        __ rev32(v16, __ T16B, v16);\n+        __ addv(v16, __ T4S, v16, v4);\n+        __ rev32(v16, __ T16B, v16);\n+        __ st1(v16, __ T16B, counter); \/\/ Save the incremented counter back\n+\n+        __ b(inner_loop);\n+      }\n+\n+      __ BIND(NEXT);\n+\n+      \/\/ Encrypt a single byte, and loop.\n+      \/\/ We expect this to be a rare event.\n+      __ ldrb(rscratch1, Address(in, offset));\n+      __ ldrb(rscratch2, Address(saved_encrypted_ctr, used));\n+      __ eor(rscratch1, rscratch1, rscratch2);\n+      __ strb(rscratch1, Address(out, offset));\n+      __ add(offset, offset, 1);\n+      __ add(used, used, 1);\n+      __ subw(len, len,1);\n+      __ cbnzw(len, L_CTR_loop);\n+    }\n+\n+    __ bind(DONE);\n+    __ strw(used, Address(used_ptr));\n+    __ mov(r0, saved_len);\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(lr);\n+\n+    \/\/ Bulk encryption\n+\n+    __ BIND (CTR_large_block);\n+    assert(bulk_width == 4 || bulk_width == 8, \"must be\");\n+\n+    if (bulk_width == 8) {\n+      __ sub(sp, sp, 4 * 16);\n+      __ st1(v12, v13, v14, v15, __ T16B, Address(sp));\n+    }\n+    __ sub(sp, sp, 4 * 16);\n+    __ st1(v8, v9, v10, v11, __ T16B, Address(sp));\n+    RegSet saved_regs = (RegSet::of(in, out, offset)\n+                         + RegSet::of(saved_encrypted_ctr, used_ptr, len));\n+    __ push(saved_regs, sp);\n+    __ andr(len, len, -16 * bulk_width);  \/\/ 8\/4 encryptions, 16 bytes per encryption\n+    __ add(in, in, offset);\n+    __ add(out, out, offset);\n+\n+    \/\/ Keys should already be loaded into the correct registers\n+\n+    __ ld1(v0, __ T16B, counter); \/\/ v0 contains the first counter\n+    __ rev32(v16, __ T16B, v0); \/\/ v16 contains byte-reversed counter\n+\n+    \/\/ AES\/CTR loop\n+    {\n+      Label L_CTR_loop;\n+      __ BIND(L_CTR_loop);\n+\n+      \/\/ Setup the counters\n+      __ movi(v8, __ T4S, 0);\n+      __ movi(v9, __ T4S, 1);\n+      __ ins(v8, __ S, v9, 3, 3); \/\/ v8 contains { 0, 0, 0, 1 }\n+\n+      for (FloatRegister f = v0; f < v0 + bulk_width; f++) {\n+        __ rev32(f, __ T16B, v16);\n+        __ addv(v16, __ T4S, v16, v8);\n+      }\n+\n+      __ ld1(v8, v9, v10, v11, __ T16B, __ post(in, 4 * 16));\n+\n+      \/\/ Encrypt the counters\n+      __ aesecb_encrypt(noreg, noreg, keylen, v0, bulk_width);\n+\n+      if (bulk_width == 8) {\n+        __ ld1(v12, v13, v14, v15, __ T16B, __ post(in, 4 * 16));\n+      }\n+\n+      \/\/ XOR the encrypted counters with the inputs\n+      for (int i = 0; i < bulk_width; i++) {\n+        __ eor(v0 + i, __ T16B, v0 + i, v8 + i);\n+      }\n+\n+      \/\/ Write the encrypted data\n+      __ st1(v0, v1, v2, v3, __ T16B, __ post(out, 4 * 16));\n+      if (bulk_width == 8) {\n+        __ st1(v4, v5, v6, v7, __ T16B, __ post(out, 4 * 16));\n+      }\n+\n+      __ subw(len, len, 16 * bulk_width);\n+      __ cbnzw(len, L_CTR_loop);\n+    }\n+\n+    \/\/ Save the counter back where it goes\n+    __ rev32(v16, __ T16B, v16);\n+    __ st1(v16, __ T16B, counter);\n+\n+    __ pop(saved_regs, sp);\n+\n+    __ ld1(v8, v9, v10, v11, __ T16B, __ post(sp, 4 * 16));\n+    if (bulk_width == 8) {\n+      __ ld1(v12, v13, v14, v15, __ T16B, __ post(sp, 4 * 16));\n+    }\n+\n+    __ andr(rscratch1, len, -16 * bulk_width);\n+    __ sub(len, len, rscratch1);\n+    __ add(offset, offset, rscratch1);\n+    __ mov(used, 16);\n+    __ strw(used, Address(used_ptr));\n+    __ b(large_block_return);\n+\n+    return start;\n+  }\n+\n+  \/\/ Vector AES Galois Counter Mode implementation. Parameters:\n+  \/\/\n+  \/\/ in = c_rarg0\n+  \/\/ len = c_rarg1\n+  \/\/ ct = c_rarg2 - ciphertext that ghash will read (in for encrypt, out for decrypt)\n+  \/\/ out = c_rarg3\n+  \/\/ key = c_rarg4\n+  \/\/ state = c_rarg5 - GHASH.state\n+  \/\/ subkeyHtbl = c_rarg6 - powers of H\n+  \/\/ subkeyHtbl_48_entries = c_rarg7 (not used)\n+  \/\/ counter = [sp, #0] pointer to 16 bytes of CTR\n+  \/\/ return - number of processed bytes\n+  address generate_galoisCounterMode_AESCrypt() {\n+    address ghash_polynomial = __ pc();\n+    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n+                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n+                          \/\/ repeated in the low and high parts of a\n+                          \/\/ 128-bit vector\n+    __ emit_int64(0x87);\n+\n+    __ align(CodeEntryAlignment);\n+     StubCodeMark mark(this, \"StubRoutines\", \"galoisCounterMode_AESCrypt\");\n+    address start = __ pc();\n+    __ enter();\n+\n+    const Register in = c_rarg0;\n+    const Register len = c_rarg1;\n+    const Register ct = c_rarg2;\n+    const Register out = c_rarg3;\n+    \/\/ and updated with the incremented counter in the end\n+\n+    const Register key = c_rarg4;\n+    const Register state = c_rarg5;\n+\n+    const Register subkeyHtbl = c_rarg6;\n+\n+    \/\/ Pointer to CTR is passed on the stack before the (fp, lr) pair.\n+    const Address counter_mem(sp, 2 * wordSize);\n+    const Register counter = c_rarg7;\n+    __ ldr(counter, counter_mem);\n+\n+    const Register keylen = r10;\n+    \/\/ Save state before entering routine\n+    __ sub(sp, sp, 4 * 16);\n+    __ st1(v12, v13, v14, v15, __ T16B, Address(sp));\n+    __ sub(sp, sp, 4 * 16);\n+    __ st1(v8, v9, v10, v11, __ T16B, Address(sp));\n+\n+    \/\/ __ andr(len, len, -512);\n+    __ andr(len, len, -16 * 8);  \/\/ 8 encryptions, 16 bytes per encryption\n+    __ str(len, __ pre(sp, -2 * wordSize));\n+\n+    Label DONE;\n+    __ cbz(len, DONE);\n+\n+    \/\/ Compute #rounds for AES based on the length of the key array\n+    __ ldrw(keylen, Address(key, arrayOopDesc::length_offset_in_bytes() - arrayOopDesc::base_offset_in_bytes(T_INT)));\n+\n+    __ aesenc_loadkeys(key, keylen);\n+    __ ld1(v0, __ T16B, counter); \/\/ v0 contains the first counter\n+    __ rev32(v16, __ T16B, v0); \/\/ v16 contains byte-reversed counter\n+\n+    \/\/ AES\/CTR loop\n+    {\n+      Label L_CTR_loop;\n+      __ BIND(L_CTR_loop);\n+\n+      \/\/ Setup the counters\n+      __ movi(v8, __ T4S, 0);\n+      __ movi(v9, __ T4S, 1);\n+      __ ins(v8, __ S, v9, 3, 3); \/\/ v8 contains { 0, 0, 0, 1 }\n+      for (FloatRegister f = v0; f < v8; f++) {\n+        __ rev32(f, __ T16B, v16);\n+        __ addv(v16, __ T4S, v16, v8);\n+      }\n+\n+      __ ld1(v8, v9, v10, v11, __ T16B, __ post(in, 4 * 16));\n+\n+      \/\/ Encrypt the counters\n+      __ aesecb_encrypt(noreg, noreg, keylen, v0, \/*unrolls*\/8);\n+\n+      __ ld1(v12, v13, v14, v15, __ T16B, __ post(in, 4 * 16));\n+\n+      \/\/ XOR the encrypted counters with the inputs\n+      for (int i = 0; i < 8; i++) {\n+        __ eor(v0 + i, __ T16B, v0 + i, v8 + i);\n+      }\n+      __ st1(v0, v1, v2, v3, __ T16B, __ post(out, 4 * 16));\n+      __ st1(v4, v5, v6, v7, __ T16B, __ post(out, 4 * 16));\n+\n+      __ subw(len, len, 16 * 8);\n+      __ cbnzw(len, L_CTR_loop);\n+    }\n+\n+    __ rev32(v16, __ T16B, v16);\n+    __ st1(v16, __ T16B, counter);\n+\n+    __ ldr(len, Address(sp));\n+    __ lsr(len, len, exact_log2(16));  \/\/ We want the count of blocks\n+\n+    \/\/ GHASH\/CTR loop\n+    __ ghash_processBlocks_wide(ghash_polynomial, state, subkeyHtbl, ct,\n+                                len, \/*unrolls*\/4);\n+\n+#ifdef ASSERT\n+    { Label L;\n+      __ cmp(len, (unsigned char)0);\n+      __ br(Assembler::EQ, L);\n+      __ stop(\"stubGenerator: abort\");\n+      __ bind(L);\n+  }\n+#endif\n+\n+  __ bind(DONE);\n+    \/\/ Return the number of bytes processed\n+    __ ldr(r0, __ post(sp, 2 * wordSize));\n+\n+    __ ld1(v8, v9, v10, v11, __ T16B, __ post(sp, 4 * 16));\n+    __ ld1(v12, v13, v14, v15, __ T16B, __ post(sp, 4 * 16));\n+\n+    __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+    __ ret(lr);\n+     return start;\n+  }\n+\n@@ -4256,63 +4502,0 @@\n-  void ghash_multiply(FloatRegister result_lo, FloatRegister result_hi,\n-                      FloatRegister a, FloatRegister b, FloatRegister a1_xor_a0,\n-                      FloatRegister tmp1, FloatRegister tmp2, FloatRegister tmp3, FloatRegister tmp4) {\n-    \/\/ Karatsuba multiplication performs a 128*128 -> 256-bit\n-    \/\/ multiplication in three 128-bit multiplications and a few\n-    \/\/ additions.\n-    \/\/\n-    \/\/ (C1:C0) = A1*B1, (D1:D0) = A0*B0, (E1:E0) = (A0+A1)(B0+B1)\n-    \/\/ (A1:A0)(B1:B0) = C1:(C0+C1+D1+E1):(D1+C0+D0+E0):D0\n-    \/\/\n-    \/\/ Inputs:\n-    \/\/\n-    \/\/ A0 in a.d[0]     (subkey)\n-    \/\/ A1 in a.d[1]\n-    \/\/ (A1+A0) in a1_xor_a0.d[0]\n-    \/\/\n-    \/\/ B0 in b.d[0]     (state)\n-    \/\/ B1 in b.d[1]\n-\n-    __ ext(tmp1, __ T16B, b, b, 0x08);\n-    __ pmull2(result_hi, __ T1Q, b, a, __ T2D);  \/\/ A1*B1\n-    __ eor(tmp1, __ T16B, tmp1, b);            \/\/ (B1+B0)\n-    __ pmull(result_lo,  __ T1Q, b, a, __ T1D);  \/\/ A0*B0\n-    __ pmull(tmp2, __ T1Q, tmp1, a1_xor_a0, __ T1D); \/\/ (A1+A0)(B1+B0)\n-\n-    __ ext(tmp4, __ T16B, result_lo, result_hi, 0x08);\n-    __ eor(tmp3, __ T16B, result_hi, result_lo); \/\/ A1*B1+A0*B0\n-    __ eor(tmp2, __ T16B, tmp2, tmp4);\n-    __ eor(tmp2, __ T16B, tmp2, tmp3);\n-\n-    \/\/ Register pair <result_hi:result_lo> holds the result of carry-less multiplication\n-    __ ins(result_hi, __ D, tmp2, 0, 1);\n-    __ ins(result_lo, __ D, tmp2, 1, 0);\n-  }\n-\n-  void ghash_reduce(FloatRegister result, FloatRegister lo, FloatRegister hi,\n-                    FloatRegister p, FloatRegister z, FloatRegister t1) {\n-    const FloatRegister t0 = result;\n-\n-    \/\/ The GCM field polynomial f is z^128 + p(z), where p =\n-    \/\/ z^7+z^2+z+1.\n-    \/\/\n-    \/\/    z^128 === -p(z)  (mod (z^128 + p(z)))\n-    \/\/\n-    \/\/ so, given that the product we're reducing is\n-    \/\/    a == lo + hi * z^128\n-    \/\/ substituting,\n-    \/\/      === lo - hi * p(z)  (mod (z^128 + p(z)))\n-    \/\/\n-    \/\/ we reduce by multiplying hi by p(z) and subtracting the result\n-    \/\/ from (i.e. XORing it with) lo.  Because p has no nonzero high\n-    \/\/ bits we can do this with two 64-bit multiplications, lo*p and\n-    \/\/ hi*p.\n-\n-    __ pmull2(t0, __ T1Q, hi, p, __ T2D);\n-    __ ext(t1, __ T16B, t0, z, 8);\n-    __ eor(hi, __ T16B, hi, t1);\n-    __ ext(t1, __ T16B, z, t0, 8);\n-    __ eor(lo, __ T16B, lo, t1);\n-    __ pmull(t0, __ T1Q, hi, p, __ T1D);\n-    __ eor(result, __ T16B, lo, t0);\n-  }\n-\n@@ -5416,0 +5599,2 @@\n+    __ ldrq(v24, p);    \/\/ The field polynomial\n+\n@@ -5424,4 +5609,2 @@\n-    __ ldrq(v26, p);\n-\n-    __ ext(v16, __ T16B, v1, v1, 0x08); \/\/ long-swap subkeyH into v1\n-    __ eor(v16, __ T16B, v16, v1);      \/\/ xor subkeyH into subkeyL (Karatsuba: (A1+A0))\n+    __ ext(v4, __ T16B, v1, v1, 0x08); \/\/ long-swap subkeyH into v1\n+    __ eor(v4, __ T16B, v4, v1);       \/\/ xor subkeyH into subkeyL (Karatsuba: (A1+A0))\n@@ -5439,3 +5622,3 @@\n-      ghash_multiply(\/*result_lo*\/v5, \/*result_hi*\/v7,\n-                     \/*a*\/v1, \/*b*\/v2, \/*a1_xor_a0*\/v16,\n-                     \/*temps*\/v6, v20, v18, v21);\n+      __ ghash_multiply(\/*result_lo*\/v5, \/*result_hi*\/v7,\n+                        \/*a*\/v1, \/*b*\/v2, \/*a1_xor_a0*\/v4,\n+                        \/*temps*\/v6, v3, \/*reuse\/clobber b*\/v2);\n@@ -5443,1 +5626,1 @@\n-      ghash_reduce(v0, v5, v7, v26, vzr, v20);\n+      __ ghash_reduce(\/*result*\/v0, \/*lo*\/v5, \/*hi*\/v7, \/*p*\/v24, vzr, \/*temp*\/v3);\n@@ -5450,2 +5633,52 @@\n-    __ rev64(v1, __ T16B, v0);\n-    __ rbit(v1, __ T16B, v1);\n+    __ rev64(v0, __ T16B, v0);\n+    __ rbit(v0, __ T16B, v0);\n+\n+    __ st1(v0, __ T16B, state);\n+    __ ret(lr);\n+\n+    return start;\n+  }\n+\n+  address generate_ghash_processBlocks_wide() {\n+    address small = generate_ghash_processBlocks();\n+\n+    StubCodeMark mark(this, \"StubRoutines\", \"ghash_processBlocks_wide\");\n+    __ align(wordSize * 2);\n+    address p = __ pc();\n+    __ emit_int64(0x87);  \/\/ The low-order bits of the field\n+                          \/\/ polynomial (i.e. p = z^7+z^2+z+1)\n+                          \/\/ repeated in the low and high parts of a\n+                          \/\/ 128-bit vector\n+    __ emit_int64(0x87);\n+\n+    __ align(CodeEntryAlignment);\n+    address start = __ pc();\n+\n+    Register state   = c_rarg0;\n+    Register subkeyH = c_rarg1;\n+    Register data    = c_rarg2;\n+    Register blocks  = c_rarg3;\n+\n+    const int unroll = 4;\n+\n+    __ cmp(blocks, (unsigned char)(unroll * 2));\n+    __ br(__ LT, small);\n+\n+    if (unroll > 1) {\n+    \/\/ Save state before entering routine\n+      __ sub(sp, sp, 4 * 16);\n+      __ st1(v12, v13, v14, v15, __ T16B, Address(sp));\n+      __ sub(sp, sp, 4 * 16);\n+      __ st1(v8, v9, v10, v11, __ T16B, Address(sp));\n+    }\n+\n+    __ ghash_processBlocks_wide(p, state, subkeyH, data, blocks, unroll);\n+\n+    if (unroll > 1) {\n+      \/\/ And restore state\n+      __ ld1(v8, v9, v10, v11, __ T16B, __ post(sp, 4 * 16));\n+      __ ld1(v12, v13, v14, v15, __ T16B, __ post(sp, 4 * 16));\n+    }\n+\n+    __ cmp(blocks, (unsigned char)0);\n+    __ br(__ GT, small);\n@@ -5453,1 +5686,0 @@\n-    __ st1(v1, __ T16B, state);\n@@ -7295,1 +7527,2 @@\n-      StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();\n+      \/\/ StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks();\n+      StubRoutines::_ghash_processBlocks = generate_ghash_processBlocks_wide();\n@@ -7312,0 +7545,2 @@\n+      StubRoutines::_galoisCounterMode_AESCrypt = generate_galoisCounterMode_AESCrypt();\n+      StubRoutines::_counterMode_AESCrypt = generate_counterMode_AESCrypt();\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":451,"deletions":216,"binary":false,"changes":667,"status":"modified"},{"patch":"@@ -61,1 +61,0 @@\n-define_pd_global(intx,  InlineFrequencyCount,  100);\n","filename":"src\/hotspot\/cpu\/ppc\/globals_ppc.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -760,1 +760,0 @@\n-void frame::pd_ps() {}\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -685,1 +685,0 @@\n-  if (os::is_MP()) __ lock();\n@@ -688,0 +687,1 @@\n+    __ lock();\n@@ -692,0 +692,1 @@\n+    __ lock();\n@@ -768,1 +769,0 @@\n-  if (os::is_MP()) __ lock();\n@@ -771,0 +771,1 @@\n+    __ lock();\n@@ -775,0 +776,1 @@\n+    __ lock();\n@@ -794,1 +796,0 @@\n-  if (os::is_MP()) __ lock();\n@@ -797,0 +798,1 @@\n+    __ lock();\n@@ -801,0 +803,1 @@\n+    __ lock();\n","filename":"src\/hotspot\/cpu\/x86\/gc\/shenandoah\/shenandoahBarrierSetAssembler_x86.cpp","additions":6,"deletions":3,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -52,1 +52,0 @@\n-define_pd_global(intx, InlineFrequencyCount,     100);\n","filename":"src\/hotspot\/cpu\/x86\/globals_x86.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1179,0 +1179,11 @@\n+\/\/ See 8273459.  Function for ensuring 64-byte alignment, intended for stubs only.\n+\/\/ Stub code is generated once and never copied.\n+\/\/ NMethods can't use this because they get copied and we can't force alignment > 32 bytes.\n+void MacroAssembler::align64() {\n+  align(64, (unsigned long long) pc());\n+}\n+\n+void MacroAssembler::align32() {\n+  align(32, (unsigned long long) pc());\n+}\n+\n@@ -1180,0 +1191,2 @@\n+  \/\/ 8273459: Ensure alignment is possible with current segment alignment\n+  assert(modulus <= CodeEntryAlignment, \"Alignment must be <= CodeEntryAlignment\");\n@@ -6122,1 +6135,1 @@\n-\/\/ encode char[] to byte[] in ISO_8859_1\n+\/\/ encode char[] to byte[] in ISO_8859_1 or ASCII\n@@ -6135,0 +6148,13 @@\n+   \/\/\n+   \/\/@IntrinsicCandidate\n+   \/\/private static int implEncodeAsciiArray(char[] sa, int sp,\n+   \/\/    byte[] da, int dp, int len) {\n+   \/\/  int i = 0;\n+   \/\/  for (; i < len; i++) {\n+   \/\/    char c = sa[sp++];\n+   \/\/    if (c >= '\\u0080')\n+   \/\/      break;\n+   \/\/    da[dp++] = (byte)c;\n+   \/\/  }\n+   \/\/  return i;\n+   \/\/}\n@@ -6138,1 +6164,1 @@\n-  Register tmp5, Register result) {\n+  Register tmp5, Register result, bool ascii) {\n@@ -6149,0 +6175,3 @@\n+  int mask = ascii ? 0xff80ff80 : 0xff00ff00;\n+  int short_mask = ascii ? 0xff80 : 0xff00;\n+\n@@ -6168,1 +6197,1 @@\n-      movl(tmp5, 0xff00ff00);   \/\/ create mask to test for Unicode chars in vector\n+      movl(tmp5, mask);   \/\/ create mask to test for Unicode or non-ASCII chars in vector\n@@ -6177,1 +6206,1 @@\n-      vptest(tmp2Reg, tmp1Reg);       \/\/ check for Unicode chars in  vector\n+      vptest(tmp2Reg, tmp1Reg);       \/\/ check for Unicode or non-ASCII chars in vector\n@@ -6192,1 +6221,1 @@\n-      movl(tmp5, 0xff00ff00);   \/\/ create mask to test for Unicode chars in vector\n+      movl(tmp5, mask);   \/\/ create mask to test for Unicode or non-ASCII chars in vector\n@@ -6216,1 +6245,1 @@\n-      ptest(tmp2Reg, tmp1Reg);       \/\/ check for Unicode chars in  vector\n+      ptest(tmp2Reg, tmp1Reg);       \/\/ check for Unicode or non-ASCII chars in vector\n@@ -6254,1 +6283,1 @@\n-  testl(tmp5, 0xff00);      \/\/ check if Unicode char\n+  testl(tmp5, short_mask);      \/\/ check if Unicode or non-ASCII char\n@@ -7588,1 +7617,1 @@\n-  align(32);\n+  align32();\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":37,"deletions":8,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -231,0 +231,2 @@\n+  void align32();\n+  void align64();\n@@ -1009,1 +1011,1 @@\n-  void generateHtbl_48_block_zmm(Register htbl);\n+  void generateHtbl_48_block_zmm(Register htbl, Register avx512_subkeyHtbl);\n@@ -1020,1 +1022,1 @@\n-                      Register state, Register subkeyHtbl, Register counter);\n+                      Register state, Register subkeyHtbl, Register avx512_subkeyHtbl, Register counter);\n@@ -1802,1 +1804,1 @@\n-                        XMMRegister tmp4, Register tmp5, Register result);\n+                        XMMRegister tmp4, Register tmp5, Register result, bool ascii);\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1502,1 +1502,1 @@\n-        __ align(32);\n+        __ align32();\n@@ -1569,1 +1569,1 @@\n-        __ align(32);\n+        __ align32();\n@@ -1709,1 +1709,1 @@\n-        __ align(32);\n+        __ align32();\n@@ -1742,1 +1742,1 @@\n-        __ align(32);\n+        __ align32();\n@@ -4236,1 +4236,1 @@\n-    __ align(64);\n+    __ align64();\n@@ -4245,1 +4245,1 @@\n-    __ align(64);\n+    __ align64();\n@@ -4290,1 +4290,1 @@\n-    __ align(64);\n+    __ align64();\n@@ -4316,1 +4316,1 @@\n-    __ align(32);\n+    __ align32();\n@@ -4454,1 +4454,3 @@\n-    const Address counter_mem(rbp, 3 * wordSize);\n+    const Address avx512_subkeyH_mem(rbp, 3 * wordSize);\n+    const Register avx512_subkeyHtbl = r13;\n+    const Address counter_mem(rbp, 4 * wordSize);\n@@ -4463,1 +4465,3 @@\n-    const Address counter_mem(rbp, 9 * wordSize);\n+    const Address avx512_subkeyH_mem(rbp, 9 * wordSize);\n+    const Register avx512_subkeyHtbl = r12;\n+    const Address counter_mem(rbp, 10 * wordSize);\n@@ -4480,0 +4484,1 @@\n+    __ movptr(avx512_subkeyHtbl, avx512_subkeyH_mem);\n@@ -4482,1 +4487,1 @@\n-    __ aesgcm_encrypt(in, len, ct, out, key, state, subkeyHtbl, counter);\n+    __ aesgcm_encrypt(in, len, ct, out, key, state, subkeyHtbl, avx512_subkeyHtbl, counter);\n@@ -4501,1 +4506,1 @@\n-    __ align(64);\n+    __ align64();\n@@ -5420,1 +5425,1 @@\n-    __ align(64, (unsigned long long)__ pc());\n+    __ align64();\n@@ -5438,1 +5443,1 @@\n-    __ align(32);\n+    __ align32();\n@@ -5450,1 +5455,1 @@\n-    __ align(32);\n+    __ align32();\n@@ -5462,1 +5467,1 @@\n-    __ align(32);\n+    __ align32();\n@@ -5480,1 +5485,1 @@\n-    __ align(64, (unsigned long long)__ pc());\n+    __ align64();\n@@ -5567,1 +5572,1 @@\n-      __ align(32);\n+      __ align32();\n@@ -5767,1 +5772,1 @@\n-      __ align(32);\n+      __ align32();\n@@ -5887,1 +5892,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -5904,1 +5909,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -5920,1 +5925,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -5937,1 +5942,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -5954,1 +5959,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -5971,1 +5976,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -5988,1 +5993,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -6005,1 +6010,1 @@\n-    __ align(64, (unsigned long long) __ pc());\n+    __ align64();\n@@ -6214,1 +6219,1 @@\n-      __ align(32);\n+      __ align32();\n@@ -6296,1 +6301,1 @@\n-      __ align(32);\n+      __ align32();\n@@ -6432,1 +6437,1 @@\n-      __ align(32);\n+      __ align32();\n@@ -6476,1 +6481,1 @@\n-    __ align(32);\n+    __ align32();\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":36,"deletions":31,"binary":false,"changes":67,"status":"modified"},{"patch":"@@ -1769,9 +1769,9 @@\n-    \/\/ 06_8EH | 9 | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Amber Lake Y\n-    \/\/ 06_8EH | 9 | 7th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake U\n-    \/\/ 06_8EH | 9 | 7th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake U 23e\n-    \/\/ 06_8EH | 9 | 7th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake Y\n-    \/\/ 06_8EH | A | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Coffee Lake U43e\n-    \/\/ 06_8EH | B | 8th Generation Intel® Core™ Processors based on microarchitecture code name Whiskey Lake U\n-    \/\/ 06_8EH | C | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Amber Lake Y\n-    \/\/ 06_8EH | C | 10th Generation Intel® Core™ Processor Family based on microarchitecture code name Comet Lake U42\n-    \/\/ 06_8EH | C | 8th Generation Intel® Core™ Processors based on microarchitecture code name Whiskey Lake U\n+    \/\/ 06_8EH | 9 | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Amber Lake Y\n+    \/\/ 06_8EH | 9 | 7th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake U\n+    \/\/ 06_8EH | 9 | 7th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake U 23e\n+    \/\/ 06_8EH | 9 | 7th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake Y\n+    \/\/ 06_8EH | A | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Coffee Lake U43e\n+    \/\/ 06_8EH | B | 8th Generation Intel(R) Core(TM) Processors based on microarchitecture code name Whiskey Lake U\n+    \/\/ 06_8EH | C | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Amber Lake Y\n+    \/\/ 06_8EH | C | 10th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Comet Lake U42\n+    \/\/ 06_8EH | C | 8th Generation Intel(R) Core(TM) Processors based on microarchitecture code name Whiskey Lake U\n@@ -1780,3 +1780,3 @@\n-    \/\/ 06_4E  | 3 | 6th Generation Intel® Core™ Processors based on microarchitecture code name Skylake U\n-    \/\/ 06_4E  | 3 | 6th Generation Intel® Core™ Processor Family based on microarchitecture code name Skylake U23e\n-    \/\/ 06_4E  | 3 | 6th Generation Intel® Core™ Processors based on microarchitecture code name Skylake Y\n+    \/\/ 06_4E  | 3 | 6th Generation Intel(R) Core(TM) Processors based on microarchitecture code name Skylake U\n+    \/\/ 06_4E  | 3 | 6th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Skylake U23e\n+    \/\/ 06_4E  | 3 | 6th Generation Intel(R) Core(TM) Processors based on microarchitecture code name Skylake Y\n@@ -1785,6 +1785,6 @@\n-    \/\/ 06_55H | 4 | Intel® Xeon® Processor D Family based on microarchitecture code name Skylake D, Bakerville\n-    \/\/ 06_55H | 4 | Intel® Xeon® Scalable Processors based on microarchitecture code name Skylake Server\n-    \/\/ 06_55H | 4 | Intel® Xeon® Processor W Family based on microarchitecture code name Skylake W\n-    \/\/ 06_55H | 4 | Intel® Core™ X-series Processors based on microarchitecture code name Skylake X\n-    \/\/ 06_55H | 4 | Intel® Xeon® Processor E3 v5 Family based on microarchitecture code name Skylake Xeon E3\n-    \/\/ 06_55  | 7 | 2nd Generation Intel® Xeon® Scalable Processors based on microarchitecture code name Cascade Lake (server)\n+    \/\/ 06_55H | 4 | Intel(R) Xeon(R) Processor D Family based on microarchitecture code name Skylake D, Bakerville\n+    \/\/ 06_55H | 4 | Intel(R) Xeon(R) Scalable Processors based on microarchitecture code name Skylake Server\n+    \/\/ 06_55H | 4 | Intel(R) Xeon(R) Processor W Family based on microarchitecture code name Skylake W\n+    \/\/ 06_55H | 4 | Intel(R) Core(TM) X-series Processors based on microarchitecture code name Skylake X\n+    \/\/ 06_55H | 4 | Intel(R) Xeon(R) Processor E3 v5 Family based on microarchitecture code name Skylake Xeon E3\n+    \/\/ 06_55  | 7 | 2nd Generation Intel(R) Xeon(R) Scalable Processors based on microarchitecture code name Cascade Lake (server)\n@@ -1793,2 +1793,2 @@\n-    \/\/ 06_5E  | 3 | 6th Generation Intel® Core™ Processor Family based on microarchitecture code name Skylake H\n-    \/\/ 06_5E  | 3 | 6th Generation Intel® Core™ Processor Family based on microarchitecture code name Skylake S\n+    \/\/ 06_5E  | 3 | 6th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Skylake H\n+    \/\/ 06_5E  | 3 | 6th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Skylake S\n@@ -1797,14 +1797,14 @@\n-    \/\/ 06_9EH | 9 | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake G\n-    \/\/ 06_9EH | 9 | 7th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake H\n-    \/\/ 06_9EH | 9 | 7th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake S\n-    \/\/ 06_9EH | 9 | Intel® Core™ X-series Processors based on microarchitecture code name Kaby Lake X\n-    \/\/ 06_9EH | 9 | Intel® Xeon® Processor E3 v6 Family Kaby Lake Xeon E3\n-    \/\/ 06_9EH | A | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Coffee Lake H\n-    \/\/ 06_9EH | A | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Coffee Lake S\n-    \/\/ 06_9EH | A | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Coffee Lake S (6+2) x\/KBP\n-    \/\/ 06_9EH | A | Intel® Xeon® Processor E Family based on microarchitecture code name Coffee Lake S (6+2)\n-    \/\/ 06_9EH | A | Intel® Xeon® Processor E Family based on microarchitecture code name Coffee Lake S (4+2)\n-    \/\/ 06_9EH | B | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Coffee Lake S (4+2)\n-    \/\/ 06_9EH | B | Intel® Celeron® Processor G Series based on microarchitecture code name Coffee Lake S (4+2)\n-    \/\/ 06_9EH | D | 9th Generation Intel® Core™ Processor Family based on microarchitecturecode name Coffee Lake H (8+2)\n-    \/\/ 06_9EH | D | 9th Generation Intel® Core™ Processor Family based on microarchitecture code name Coffee Lake S (8+2)\n+    \/\/ 06_9EH | 9 | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake G\n+    \/\/ 06_9EH | 9 | 7th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake H\n+    \/\/ 06_9EH | 9 | 7th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake S\n+    \/\/ 06_9EH | 9 | Intel(R) Core(TM) X-series Processors based on microarchitecture code name Kaby Lake X\n+    \/\/ 06_9EH | 9 | Intel(R) Xeon(R) Processor E3 v6 Family Kaby Lake Xeon E3\n+    \/\/ 06_9EH | A | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Coffee Lake H\n+    \/\/ 06_9EH | A | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Coffee Lake S\n+    \/\/ 06_9EH | A | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Coffee Lake S (6+2) x\/KBP\n+    \/\/ 06_9EH | A | Intel(R) Xeon(R) Processor E Family based on microarchitecture code name Coffee Lake S (6+2)\n+    \/\/ 06_9EH | A | Intel(R) Xeon(R) Processor E Family based on microarchitecture code name Coffee Lake S (4+2)\n+    \/\/ 06_9EH | B | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Coffee Lake S (4+2)\n+    \/\/ 06_9EH | B | Intel(R) Celeron(R) Processor G Series based on microarchitecture code name Coffee Lake S (4+2)\n+    \/\/ 06_9EH | D | 9th Generation Intel(R) Core(TM) Processor Family based on microarchitecturecode name Coffee Lake H (8+2)\n+    \/\/ 06_9EH | D | 9th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Coffee Lake S (8+2)\n@@ -1814,1 +1814,1 @@\n-    \/\/ 06_A5H |    | 10th Generation Intel® Core™ Processor Family based on microarchitecture code name Comet Lake S\/H\n+    \/\/ 06_A5H |    | 10th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Comet Lake S\/H\n@@ -1817,1 +1817,1 @@\n-    \/\/ 06_A6H | 0  | 10th Generation Intel® Core™ Processor Family based on microarchitecture code name Comet Lake U62\n+    \/\/ 06_A6H | 0  | 10th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Comet Lake U62\n@@ -1820,1 +1820,1 @@\n-    \/\/ 06_AEH | A | 8th Generation Intel® Core™ Processor Family based on microarchitecture code name Kaby Lake Refresh U (4+2)\n+    \/\/ 06_AEH | A | 8th Generation Intel(R) Core(TM) Processor Family based on microarchitecture code name Kaby Lake Refresh U (4+2)\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":37,"deletions":37,"binary":false,"changes":74,"status":"modified"},{"patch":"@@ -12199,0 +12199,1 @@\n+  predicate(!((EncodeISOArrayNode*)n)->is_ascii());\n@@ -12202,1 +12203,1 @@\n-  format %{ \"Encode array $src,$dst,$len -> $result    \/\/ KILL ECX, EDX, $tmp1, $tmp2, $tmp3, $tmp4, ESI, EDI \" %}\n+  format %{ \"Encode iso array $src,$dst,$len -> $result    \/\/ KILL ECX, EDX, $tmp1, $tmp2, $tmp3, $tmp4, ESI, EDI \" %}\n@@ -12206,1 +12207,1 @@\n-                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register);\n+                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register, false);\n@@ -12211,0 +12212,16 @@\n+\/\/ encode char[] to byte[] in ASCII\n+instruct encode_ascii_array(eSIRegP src, eDIRegP dst, eDXRegI len,\n+                            regD tmp1, regD tmp2, regD tmp3, regD tmp4,\n+                            eCXRegI tmp5, eAXRegI result, eFlagsReg cr) %{\n+  predicate(((EncodeISOArrayNode*)n)->is_ascii());\n+  match(Set result (EncodeISOArray src (Binary dst len)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n+\n+  format %{ \"Encode ascii array $src,$dst,$len -> $result    \/\/ KILL ECX, EDX, $tmp1, $tmp2, $tmp3, $tmp4, ESI, EDI \" %}\n+  ins_encode %{\n+    __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,\n+                        $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n+                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register, true);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n","filename":"src\/hotspot\/cpu\/x86\/x86_32.ad","additions":19,"deletions":2,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -12013,0 +12013,1 @@\n+  predicate(!((EncodeISOArrayNode*)n)->is_ascii());\n@@ -12016,1 +12017,1 @@\n-  format %{ \"Encode array $src,$dst,$len -> $result    \/\/ KILL RCX, RDX, $tmp1, $tmp2, $tmp3, $tmp4, RSI, RDI \" %}\n+  format %{ \"Encode iso array $src,$dst,$len -> $result    \/\/ KILL RCX, RDX, $tmp1, $tmp2, $tmp3, $tmp4, RSI, RDI \" %}\n@@ -12020,1 +12021,18 @@\n-                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register);\n+                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register, false);\n+  %}\n+  ins_pipe( pipe_slow );\n+%}\n+\n+\/\/ encode char[] to byte[] in ASCII\n+instruct encode_ascii_array(rsi_RegP src, rdi_RegP dst, rdx_RegI len,\n+                            legRegD tmp1, legRegD tmp2, legRegD tmp3, legRegD tmp4,\n+                            rcx_RegI tmp5, rax_RegI result, rFlagsReg cr) %{\n+  predicate(((EncodeISOArrayNode*)n)->is_ascii());\n+  match(Set result (EncodeISOArray src (Binary dst len)));\n+  effect(TEMP tmp1, TEMP tmp2, TEMP tmp3, TEMP tmp4, USE_KILL src, USE_KILL dst, USE_KILL len, KILL tmp5, KILL cr);\n+\n+  format %{ \"Encode ascii array $src,$dst,$len -> $result    \/\/ KILL RCX, RDX, $tmp1, $tmp2, $tmp3, $tmp4, RSI, RDI \" %}\n+  ins_encode %{\n+    __ encode_iso_array($src$$Register, $dst$$Register, $len$$Register,\n+                        $tmp1$$XMMRegister, $tmp2$$XMMRegister, $tmp3$$XMMRegister,\n+                        $tmp4$$XMMRegister, $tmp5$$Register, $result$$Register, true);\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":20,"deletions":2,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -42,1 +42,0 @@\n-define_pd_global(intx,  InlineFrequencyCount, 100);\n","filename":"src\/hotspot\/cpu\/zero\/globals_zero.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -34,1 +34,0 @@\n-class CodeStrings;\n@@ -283,3 +282,1 @@\n-class CodeString;\n-class CodeStrings {\n-private:\n+\n@@ -287,9 +284,2 @@\n-  CodeString* _strings;\n-  CodeString* _strings_last;\n-#ifdef ASSERT\n-  \/\/ Becomes true after copy-out, forbids further use.\n-  bool _defunct; \/\/ Zero bit pattern is \"valid\", see memset call in decode_env::decode_env\n-#endif\n-  static const char* _prefix; \/\/ defaults to \" ;; \"\n-  CodeString* find(intptr_t offset) const;\n-  CodeString* find_last(intptr_t offset) const;\n+class AsmRemarkCollection;\n+class DbgStringCollection;\n@@ -298,8 +288,4 @@\n-  void set_null_and_invalidate() {\n-    _strings = NULL;\n-    _strings_last = NULL;\n-#ifdef ASSERT\n-    _defunct = true;\n-#endif\n-  }\n-#endif\n+\/\/ The assumption made here is that most code remarks (or comments) added to\n+\/\/ the generated assembly code are unique, i.e. there is very little gain in\n+\/\/ trying to share the strings between the different offsets tracked in a\n+\/\/ buffer (or blob).\n@@ -307,10 +293,4 @@\n-public:\n-  CodeStrings() {\n-#ifndef PRODUCT\n-    _strings = NULL;\n-    _strings_last = NULL;\n-#ifdef ASSERT\n-    _defunct = false;\n-#endif\n-#endif\n-  }\n+class AsmRemarks {\n+ public:\n+  AsmRemarks();\n+ ~AsmRemarks();\n@@ -318,8 +298,1 @@\n-#ifndef PRODUCT\n-  bool is_null() {\n-#ifdef ASSERT\n-    return _strings == NULL;\n-#else\n-    return true;\n-#endif\n-  }\n+  const char* insert(uint offset, const char* remstr);\n@@ -327,1 +300,1 @@\n-  const char* add_string(const char * string);\n+  bool is_empty() const;\n@@ -329,7 +302,3 @@\n-  void add_comment(intptr_t offset, const char * comment);\n-  void print_block_comment(outputStream* stream, intptr_t offset) const;\n-  int  count() const;\n-  \/\/ COPY strings from other to this; leave other valid.\n-  void copy(CodeStrings& other);\n-  \/\/ FREE strings; invalidate this.\n-  void free();\n+  void share(const AsmRemarks &src);\n+  void clear();\n+  uint print(uint offset, outputStream* strm = tty) const;\n@@ -337,4 +306,2 @@\n-  \/\/ Guarantee that _strings are used at most once; assign and free invalidate a buffer.\n-  inline void check_valid() const {\n-    assert(!_defunct, \"Use of invalid CodeStrings\");\n-  }\n+  \/\/ For testing purposes only.\n+  const AsmRemarkCollection* ref() const { return _remarks; }\n@@ -342,2 +309,36 @@\n-  static void set_prefix(const char *prefix) {\n-    _prefix = prefix;\n+private:\n+  AsmRemarkCollection* _remarks;\n+};\n+\n+\/\/ The assumption made here is that the number of debug strings (with a fixed\n+\/\/ address requirement) is a rather small set per compilation unit.\n+\n+class DbgStrings {\n+ public:\n+  DbgStrings();\n+ ~DbgStrings();\n+\n+  const char* insert(const char* dbgstr);\n+\n+  bool is_empty() const;\n+\n+  void share(const DbgStrings &src);\n+  void clear();\n+\n+  \/\/ For testing purposes only.\n+  const DbgStringCollection* ref() const { return _strings; }\n+\n+private:\n+  DbgStringCollection* _strings;\n+};\n+#endif \/\/ not PRODUCT\n+\n+\n+#ifdef ASSERT\n+#include \"utilities\/copy.hpp\"\n+\n+class Scrubber {\n+ public:\n+  Scrubber(void* addr, size_t size) : _addr(addr), _size(size) {}\n+ ~Scrubber() {\n+    Copy::fill_to_bytes(_addr, _size, badResourceValue);\n@@ -345,1 +346,3 @@\n-#endif \/\/ !PRODUCT\n+ private:\n+  void*  _addr;\n+  size_t _size;\n@@ -347,0 +350,1 @@\n+#endif \/\/ ASSERT\n@@ -372,1 +376,1 @@\n-class CodeBuffer: public StackObj {\n+class CodeBuffer: public StackObj DEBUG_ONLY(COMMA private Scrubber) {\n@@ -421,1 +425,2 @@\n-  CodeStrings  _code_strings;\n+  AsmRemarks   _asm_remarks;\n+  DbgStrings   _dbg_strings;\n@@ -439,1 +444,0 @@\n-    _code_strings    = CodeStrings();\n@@ -494,1 +498,3 @@\n-  CodeBuffer(address code_start, csize_t code_size) {\n+  CodeBuffer(address code_start, csize_t code_size)\n+    DEBUG_ONLY(: Scrubber(this, sizeof(*this)))\n+  {\n@@ -507,1 +513,3 @@\n-  CodeBuffer(const char* name) {\n+  CodeBuffer(const char* name)\n+    DEBUG_ONLY(: Scrubber(this, sizeof(*this)))\n+  {\n@@ -514,1 +522,3 @@\n-  CodeBuffer(const char* name, csize_t code_size, csize_t locs_size) {\n+  CodeBuffer(const char* name, csize_t code_size, csize_t locs_size)\n+    DEBUG_ONLY(: Scrubber(this, sizeof(*this)))\n+  {\n@@ -644,1 +654,2 @@\n-  CodeStrings& strings() { return _code_strings; }\n+  AsmRemarks &asm_remarks() { return _asm_remarks; }\n+  DbgStrings &dbg_strings() { return _dbg_strings; }\n@@ -646,4 +657,3 @@\n-  void free_strings() {\n-    if (!_code_strings.is_null()) {\n-      _code_strings.free(); \/\/ sets _strings Null as a side-effect.\n-    }\n+  void clear_strings() {\n+    _asm_remarks.clear();\n+    _dbg_strings.clear();\n@@ -676,1 +686,1 @@\n-  void block_comment(intptr_t offset, const char * comment) PRODUCT_RETURN;\n+  void block_comment(ptrdiff_t offset, const char* comment) PRODUCT_RETURN;\n","filename":"src\/hotspot\/share\/asm\/codeBuffer.hpp","additions":76,"deletions":66,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -660,1 +660,1 @@\n-    assert(klass->size_helper() >= 0, \"illegal instance size\");\n+    assert(klass->size_helper() > 0, \"illegal instance size\");\n","filename":"src\/hotspot\/share\/c1\/c1_LIRGenerator.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -118,1 +118,0 @@\n-    uintx FLAG_MASK = 0x03; \/\/ See comments around MetaspaceClosure::FLAG_MASK\n@@ -122,3 +121,1 @@\n-    uintx old_p_and_bits = (uintx)(*ptr_loc);\n-    uintx flag_bits = (old_p_and_bits & FLAG_MASK);\n-    address old_p = (address)(old_p_and_bits & (~FLAG_MASK));\n+    address old_p = *ptr_loc;\n@@ -126,1 +123,0 @@\n-    uintx new_p_and_bits = ((uintx)new_p) | flag_bits;\n@@ -131,1 +127,1 @@\n-    ArchivePtrMarker::set_and_mark_pointer(ptr_loc, (address)(new_p_and_bits));\n+    ArchivePtrMarker::set_and_mark_pointer(ptr_loc, new_p);\n@@ -1135,1 +1131,1 @@\n-                                        MetaspaceShared::max_closed_heap_region);\n+                                        MetaspaceShared::max_num_closed_heap_regions);\n@@ -1140,1 +1136,1 @@\n-                                        MetaspaceShared::max_open_heap_region);\n+                                        MetaspaceShared::max_num_open_heap_regions);\n","filename":"src\/hotspot\/share\/cds\/archiveBuilder.cpp","additions":4,"deletions":8,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"cds\/unregisteredClasses.hpp\"\n@@ -123,0 +124,7 @@\n+      ResourceMark rm(THREAD);\n+      char* ex_msg = (char*)\"\";\n+      oop message = java_lang_Throwable::message(PENDING_EXCEPTION);\n+      if (message != NULL) {\n+        ex_msg = java_lang_String::as_utf8_string(message);\n+      }\n+      log_warning(cds)(\"%s: %s\", PENDING_EXCEPTION->klass()->external_name(), ex_msg);\n@@ -461,1 +469,1 @@\n-  InstanceKlass* k = ClassLoaderExt::load_class(class_name, _source, CHECK_NULL);\n+  InstanceKlass* k = UnregisteredClasses::load_class(class_name, _source, CHECK_NULL);\n@@ -507,1 +515,3 @@\n-  bool added = SystemDictionaryShared::add_unregistered_class_for_static_archive(THREAD, k);\n+  assert(k->is_shared_unregistered_class(), \"must be\");\n+\n+  bool added = SystemDictionaryShared::add_unregistered_class(THREAD, k);\n@@ -513,4 +523,0 @@\n-  \/\/ This tells JVM_FindLoadedClass to not find this class.\n-  k->set_shared_classpath_index(UNREGISTERED_INDEX);\n-  k->clear_shared_class_loader_type();\n-\n","filename":"src\/hotspot\/share\/cds\/classListParser.cpp","additions":12,"deletions":6,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -280,1 +280,1 @@\n-  if (HeapShared::is_heap_object_archiving_allowed()) {\n+  if (DumpSharedSpaces && HeapShared::can_write()) {\n@@ -1671,2 +1671,1 @@\n-bool FileMapInfo::read_region(int i, char* base, size_t size) {\n-  assert(MetaspaceShared::use_windows_memory_mapping(), \"used by windows only\");\n+bool FileMapInfo::read_region(int i, char* base, size_t size, bool do_commit) {\n@@ -1674,7 +1673,9 @@\n-  log_info(cds)(\"Commit %s region #%d at base \" INTPTR_FORMAT \" top \" INTPTR_FORMAT \" (%s)%s\",\n-                is_static() ? \"static \" : \"dynamic\", i, p2i(base), p2i(base + size),\n-                shared_region_name[i], si->allow_exec() ? \" exec\" : \"\");\n-  if (!os::commit_memory(base, size, si->allow_exec())) {\n-    log_error(cds)(\"Failed to commit %s region #%d (%s)\", is_static() ? \"static \" : \"dynamic\",\n-                   i, shared_region_name[i]);\n-    return false;\n+  if (do_commit) {\n+    log_info(cds)(\"Commit %s region #%d at base \" INTPTR_FORMAT \" top \" INTPTR_FORMAT \" (%s)%s\",\n+                  is_static() ? \"static \" : \"dynamic\", i, p2i(base), p2i(base + size),\n+                  shared_region_name[i], si->allow_exec() ? \" exec\" : \"\");\n+    if (!os::commit_memory(base, size, si->allow_exec())) {\n+      log_error(cds)(\"Failed to commit %s region #%d (%s)\", is_static() ? \"static \" : \"dynamic\",\n+                     i, shared_region_name[i]);\n+      return false;\n+    }\n@@ -1686,0 +1687,5 @@\n+\n+  if (VerifySharedSpaces && !region_crc_check(base, si->used(), si->crc())) {\n+    return false;\n+  }\n+\n@@ -1716,1 +1722,1 @@\n-    if (!read_region(i, requested_addr, size)) {\n+    if (!read_region(i, requested_addr, size, \/* do_commit = *\/ true)) {\n@@ -1878,19 +1884,11 @@\n-\/\/\n-\/\/ Map the closed and open archive heap objects to the runtime java heap.\n-\/\/\n-\/\/ The shared objects are mapped at (or close to ) the java heap top in\n-\/\/ closed archive regions. The mapped objects contain no out-going\n-\/\/ references to any other java heap regions. GC does not write into the\n-\/\/ mapped closed archive heap region.\n-\/\/\n-\/\/ The open archive heap objects are mapped below the shared objects in\n-\/\/ the runtime java heap. The mapped open archive heap data only contains\n-\/\/ references to the shared objects and open archive objects initially.\n-\/\/ During runtime execution, out-going references to any other java heap\n-\/\/ regions may be added. GC may mark and update references in the mapped\n-\/\/ open archive objects.\n-void FileMapInfo::map_heap_regions_impl() {\n-  if (!HeapShared::is_heap_object_archiving_allowed()) {\n-    log_info(cds)(\"CDS heap data is being ignored. UseG1GC, \"\n-                  \"UseCompressedOops and UseCompressedClassPointers are required.\");\n-    return;\n+void FileMapInfo::map_or_load_heap_regions() {\n+  bool success = false;\n+\n+  if (can_use_heap_regions()) {\n+    if (HeapShared::can_map()) {\n+      success = map_heap_regions();\n+    } else if (HeapShared::can_load()) {\n+      success = HeapShared::load_heap_regions(this);\n+    } else {\n+      log_info(cds)(\"Cannot use CDS heap data. UseEpsilonGC, UseG1GC or UseSerialGC are required.\");\n+    }\n@@ -1899,0 +1897,9 @@\n+  if (!success) {\n+    MetaspaceShared::disable_full_module_graph();\n+  }\n+}\n+\n+bool FileMapInfo::can_use_heap_regions() {\n+  if (!has_heap_regions()) {\n+    return false;\n+  }\n@@ -1933,1 +1940,1 @@\n-    return;\n+    return false;\n@@ -1935,0 +1942,2 @@\n+  return true;\n+}\n@@ -1936,0 +1945,16 @@\n+\n+\/\/\n+\/\/ Map the closed and open archive heap objects to the runtime java heap.\n+\/\/\n+\/\/ The shared objects are mapped at (or close to ) the java heap top in\n+\/\/ closed archive regions. The mapped objects contain no out-going\n+\/\/ references to any other java heap regions. GC does not write into the\n+\/\/ mapped closed archive heap region.\n+\/\/\n+\/\/ The open archive heap objects are mapped below the shared objects in\n+\/\/ the runtime java heap. The mapped open archive heap data only contains\n+\/\/ references to the shared objects and open archive objects initially.\n+\/\/ During runtime execution, out-going references to any other java heap\n+\/\/ regions may be added. GC may mark and update references in the mapped\n+\/\/ open archive objects.\n+void FileMapInfo::map_heap_regions_impl() {\n@@ -1994,1 +2019,1 @@\n-                       MetaspaceShared::max_closed_heap_region,\n+                       MetaspaceShared::max_num_closed_heap_regions,\n@@ -2001,1 +2026,1 @@\n-                         MetaspaceShared::max_open_heap_region,\n+                         MetaspaceShared::max_num_open_heap_regions,\n@@ -2010,4 +2035,2 @@\n-void FileMapInfo::map_heap_regions() {\n-  if (has_heap_regions()) {\n-    map_heap_regions_impl();\n-  }\n+bool FileMapInfo::map_heap_regions() {\n+  map_heap_regions_impl();\n@@ -2022,1 +2045,3 @@\n-    MetaspaceShared::disable_full_module_graph();\n+    return false;\n+  } else {\n+    return true;\n@@ -2427,1 +2452,1 @@\n-    for (int i = 0; i < MetaspaceShared::num_non_heap_spaces; i++) {\n+    for (int i = 0; i < MetaspaceShared::num_non_heap_regions; i++) {\n","filename":"src\/hotspot\/share\/cds\/filemap.cpp","additions":64,"deletions":39,"binary":false,"changes":103,"status":"modified"},{"patch":"@@ -141,0 +141,1 @@\n+public:\n@@ -148,1 +149,0 @@\n-public:\n@@ -212,1 +212,1 @@\n-  friend class CDSOffsets;\n+  friend class CDSConstants;\n@@ -215,0 +215,1 @@\n+private:\n@@ -241,1 +242,0 @@\n-\n@@ -458,0 +458,2 @@\n+  narrowOop heap_obj_roots()               const    { return header()->heap_obj_roots(); }\n+\n@@ -505,1 +507,1 @@\n-  void  map_heap_regions() NOT_CDS_JAVA_HEAP_RETURN;\n+  void  map_or_load_heap_regions() NOT_CDS_JAVA_HEAP_RETURN;\n@@ -512,0 +514,2 @@\n+  bool  read_region(int i, char* base, size_t size, bool do_commit);\n+  char* map_bitmap_region();\n@@ -611,0 +615,3 @@\n+  bool  can_use_heap_regions();\n+  bool  load_heap_regions() NOT_CDS_JAVA_HEAP_RETURN_(false);\n+  bool  map_heap_regions() NOT_CDS_JAVA_HEAP_RETURN_(false);\n@@ -612,2 +619,0 @@\n-  char* map_bitmap_region();\n-  bool  read_region(int i, char* base, size_t size);\n@@ -619,0 +624,2 @@\n+  address decode_start_address(FileMapRegion* spc, bool with_current_oop_encoding_mode);\n+\n@@ -623,1 +630,1 @@\n-\n+public:\n@@ -629,1 +636,1 @@\n-  address decode_start_address(FileMapRegion* spc, bool with_current_oop_encoding_mode);\n+private:\n","filename":"src\/hotspot\/share\/cds\/filemap.hpp","additions":15,"deletions":8,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"gc\/shared\/collectedHeap.hpp\"\n@@ -72,0 +73,1 @@\n+bool HeapShared::_is_loaded = false;\n@@ -76,0 +78,12 @@\n+uintptr_t HeapShared::_loaded_heap_bottom = 0;\n+uintptr_t HeapShared::_loaded_heap_top = 0;\n+uintptr_t HeapShared::_dumptime_base_0 = UINTPTR_MAX;\n+uintptr_t HeapShared::_dumptime_base_1 = UINTPTR_MAX;\n+uintptr_t HeapShared::_dumptime_base_2 = UINTPTR_MAX;\n+uintptr_t HeapShared::_dumptime_base_3 = UINTPTR_MAX;\n+uintptr_t HeapShared::_dumptime_top    = 0;\n+intx HeapShared::_runtime_offset_0 = 0;\n+intx HeapShared::_runtime_offset_1 = 0;\n+intx HeapShared::_runtime_offset_2 = 0;\n+intx HeapShared::_runtime_offset_3 = 0;\n+bool HeapShared::_loading_failed = false;\n@@ -121,1 +135,1 @@\n-  assert(HeapShared::is_heap_object_archiving_allowed(), \"must be\");\n+  assert(HeapShared::can_write(), \"must be\");\n@@ -132,3 +146,2 @@\n-void HeapShared::fixup_mapped_regions() {\n-  FileMapInfo *mapinfo = FileMapInfo::current_info();\n-  mapinfo->fixup_mapped_heap_regions();\n+void HeapShared::fixup_regions() {\n+  FileMapInfo* mapinfo = FileMapInfo::current_info();\n@@ -136,0 +149,5 @@\n+    mapinfo->fixup_mapped_heap_regions();\n+  } else if (_loading_failed) {\n+    fill_failed_loaded_region();\n+  }\n+  if (is_fully_available()) {\n@@ -211,1 +229,1 @@\n-    if (!is_heap_object_archiving_allowed()) {\n+    if (!HeapShared::can_write()) {\n@@ -225,1 +243,1 @@\n-  assert(open_regions_mapped(), \"must be\");\n+  assert(is_fully_available(), \"must be\");\n@@ -250,1 +268,1 @@\n-  if (open_regions_mapped()) {\n+  if (is_fully_available()) {\n@@ -329,1 +347,1 @@\n-  if (is_heap_object_archiving_allowed()) {\n+  if (HeapShared::can_write()) {\n@@ -373,1 +391,1 @@\n-  assert(is_heap_object_archiving_allowed(), \"Cannot archive java heap objects\");\n+  assert(HeapShared::can_write(), \"must be\");\n@@ -390,1 +408,1 @@\n-  assert(is_heap_object_archiving_allowed(), \"Cannot archive java heap objects\");\n+  assert(HeapShared::can_write(), \"must be\");\n@@ -664,1 +682,1 @@\n-  if (VerifyArchivedFields) {\n+  if (VerifyArchivedFields > 0) {\n@@ -672,9 +690,14 @@\n-    if (!FLAG_IS_DEFAULT(VerifyArchivedFields)) {\n-      \/\/ If VerifyArchivedFields has a non-default value (e.g., specified on the command-line), do\n-      \/\/ more expensive checks.\n-      if (is_init_completed()) {\n-        FlagSetting fs1(VerifyBeforeGC, true);\n-        FlagSetting fs2(VerifyDuringGC, true);\n-        FlagSetting fs3(VerifyAfterGC,  true);\n-        Universe::heap()->collect(GCCause::_java_lang_system_gc);\n-      }\n+    if (VerifyArchivedFields > 1 && is_init_completed()) {\n+      \/\/ At this time, the oop->klass() of some archived objects in the heap may not\n+      \/\/ have been loaded into the system dictionary yet. Nevertheless, oop->klass() should\n+      \/\/ have enough information (object size, oop maps, etc) so that a GC can be safely\n+      \/\/ performed.\n+      \/\/\n+      \/\/ -XX:VerifyArchivedFields=2 force a GC to happen in such an early stage\n+      \/\/ to check for GC safety.\n+      log_info(cds, heap)(\"Trigger GC %s initializing static field(s) in %s\",\n+                          which, k->external_name());\n+      FlagSetting fs1(VerifyBeforeGC, true);\n+      FlagSetting fs2(VerifyDuringGC, true);\n+      FlagSetting fs3(VerifyAfterGC,  true);\n+      Universe::heap()->collect(GCCause::_java_lang_system_gc);\n@@ -692,1 +715,1 @@\n-  if (!is_mapped()) {\n+  if (!is_fully_available()) {\n@@ -730,1 +753,1 @@\n-  if (!is_mapped()) {\n+  if (!is_fully_available()) {\n@@ -1285,1 +1308,1 @@\n-  assert(is_heap_object_archiving_allowed(), \"Sanity check\");\n+  assert(HeapShared::can_write(), \"must be\");\n@@ -1301,1 +1324,1 @@\n-  if (is_heap_object_archiving_allowed()) {\n+  if (HeapShared::can_write()) {\n@@ -1461,0 +1484,289 @@\n+\/\/ The CDS archive remembers each heap object by its address at dump time, but\n+\/\/ the heap object may be loaded at a different address at run time. This structure is used\n+\/\/ to translate the dump time addresses for all objects in FileMapInfo::space_at(region_index)\n+\/\/ to their runtime addresses.\n+struct LoadedArchiveHeapRegion {\n+  int       _region_index;   \/\/ index for FileMapInfo::space_at(index)\n+  size_t    _region_size;    \/\/ number of bytes in this region\n+  uintptr_t _dumptime_base;  \/\/ The dump-time (decoded) address of the first object in this region\n+  intx      _runtime_offset; \/\/ If an object's dump time address P is within in this region, its\n+                             \/\/ runtime address is P + _runtime_offset\n+\n+  static int comparator(const void* a, const void* b) {\n+    LoadedArchiveHeapRegion* reg_a = (LoadedArchiveHeapRegion*)a;\n+    LoadedArchiveHeapRegion* reg_b = (LoadedArchiveHeapRegion*)b;\n+    if (reg_a->_dumptime_base < reg_b->_dumptime_base) {\n+      return -1;\n+    } else if (reg_a->_dumptime_base == reg_b->_dumptime_base) {\n+      return 0;\n+    } else {\n+      return 1;\n+    }\n+  }\n+\n+  uintptr_t top() {\n+    return _dumptime_base + _region_size;\n+  }\n+};\n+\n+void HeapShared::init_loaded_heap_relocation(LoadedArchiveHeapRegion* loaded_regions,\n+                                             int num_loaded_regions) {\n+  _dumptime_base_0 = loaded_regions[0]._dumptime_base;\n+  _dumptime_base_1 = loaded_regions[1]._dumptime_base;\n+  _dumptime_base_2 = loaded_regions[2]._dumptime_base;\n+  _dumptime_base_3 = loaded_regions[3]._dumptime_base;\n+  _dumptime_top = loaded_regions[num_loaded_regions-1].top();\n+\n+  _runtime_offset_0 = loaded_regions[0]._runtime_offset;\n+  _runtime_offset_1 = loaded_regions[1]._runtime_offset;\n+  _runtime_offset_2 = loaded_regions[2]._runtime_offset;\n+  _runtime_offset_3 = loaded_regions[3]._runtime_offset;\n+\n+  assert(2 <= num_loaded_regions && num_loaded_regions <= 4, \"must be\");\n+  if (num_loaded_regions < 4) {\n+    _dumptime_base_3 = UINTPTR_MAX;\n+  }\n+  if (num_loaded_regions < 3) {\n+    _dumptime_base_2 = UINTPTR_MAX;\n+  }\n+}\n+\n+bool HeapShared::can_load() {\n+  return Universe::heap()->can_load_archived_objects();\n+}\n+\n+template <int NUM_LOADED_REGIONS>\n+class PatchLoadedRegionPointers: public BitMapClosure {\n+  narrowOop* _start;\n+  intx _offset_0;\n+  intx _offset_1;\n+  intx _offset_2;\n+  intx _offset_3;\n+  uintptr_t _base_0;\n+  uintptr_t _base_1;\n+  uintptr_t _base_2;\n+  uintptr_t _base_3;\n+  uintptr_t _top;\n+\n+  static_assert(MetaspaceShared::max_num_heap_regions == 4, \"can't handle more than 4 regions\");\n+  static_assert(NUM_LOADED_REGIONS >= 2, \"we have at least 2 loaded regions\");\n+  static_assert(NUM_LOADED_REGIONS <= 4, \"we have at most 4 loaded regions\");\n+\n+ public:\n+  PatchLoadedRegionPointers(narrowOop* start, LoadedArchiveHeapRegion* loaded_regions)\n+    : _start(start),\n+      _offset_0(loaded_regions[0]._runtime_offset),\n+      _offset_1(loaded_regions[1]._runtime_offset),\n+      _offset_2(loaded_regions[2]._runtime_offset),\n+      _offset_3(loaded_regions[3]._runtime_offset),\n+      _base_0(loaded_regions[0]._dumptime_base),\n+      _base_1(loaded_regions[1]._dumptime_base),\n+      _base_2(loaded_regions[2]._dumptime_base),\n+      _base_3(loaded_regions[3]._dumptime_base) {\n+    _top = loaded_regions[NUM_LOADED_REGIONS-1].top();\n+  }\n+\n+  bool do_bit(size_t offset) {\n+    narrowOop* p = _start + offset;\n+    narrowOop v = *p;\n+    assert(!CompressedOops::is_null(v), \"null oops should have been filtered out at dump time\");\n+    uintptr_t o = cast_from_oop<uintptr_t>(HeapShared::decode_from_archive(v));\n+    assert(_base_0 <= o && o < _top, \"must be\");\n+\n+\n+    \/\/ We usually have only 2 regions for the default archive. Use template to avoid unnecessary comparisons.\n+    if (NUM_LOADED_REGIONS > 3 && o >= _base_3) {\n+      o += _offset_3;\n+    } else if (NUM_LOADED_REGIONS > 2 && o >= _base_2) {\n+      o += _offset_2;\n+    } else if (o >= _base_1) {\n+      o += _offset_1;\n+    } else {\n+      o += _offset_0;\n+    }\n+    HeapShared::assert_in_loaded_heap(o);\n+    RawAccess<IS_NOT_NULL>::oop_store(p, cast_to_oop(o));\n+    return true;\n+  }\n+};\n+\n+int HeapShared::init_loaded_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n+                                    MemRegion& archive_space) {\n+  size_t total_bytes = 0;\n+  int num_loaded_regions = 0;\n+  for (int i = MetaspaceShared::first_archive_heap_region;\n+       i <= MetaspaceShared::last_archive_heap_region; i++) {\n+    FileMapRegion* r = mapinfo->space_at(i);\n+    r->assert_is_heap_region();\n+    if (r->used() > 0) {\n+      assert(is_aligned(r->used(), HeapWordSize), \"must be\");\n+      total_bytes += r->used();\n+      LoadedArchiveHeapRegion* ri = &loaded_regions[num_loaded_regions++];\n+      ri->_region_index = i;\n+      ri->_region_size = r->used();\n+      ri->_dumptime_base = (uintptr_t)mapinfo->start_address_as_decoded_from_archive(r);\n+    }\n+  }\n+\n+  assert(is_aligned(total_bytes, HeapWordSize), \"must be\");\n+  size_t word_size = total_bytes \/ HeapWordSize;\n+  HeapWord* buffer = Universe::heap()->allocate_loaded_archive_space(word_size);\n+  if (buffer == nullptr) {\n+    return 0;\n+  }\n+\n+  archive_space = MemRegion(buffer, word_size);\n+  _loaded_heap_bottom = (uintptr_t)archive_space.start();\n+  _loaded_heap_top    = _loaded_heap_bottom + total_bytes;\n+\n+  return num_loaded_regions;\n+}\n+\n+void HeapShared::sort_loaded_regions(LoadedArchiveHeapRegion* loaded_regions, int num_loaded_regions,\n+                                     uintptr_t buffer) {\n+  \/\/ Find the relocation offset of the pointers in each region\n+  qsort(loaded_regions, num_loaded_regions, sizeof(LoadedArchiveHeapRegion),\n+        LoadedArchiveHeapRegion::comparator);\n+\n+  uintptr_t p = buffer;\n+  for (int i = 0; i < num_loaded_regions; i++) {\n+    \/\/ This region will be loaded at p, so all objects inside this\n+    \/\/ region will be shifted by ri->offset\n+    LoadedArchiveHeapRegion* ri = &loaded_regions[i];\n+    ri->_runtime_offset = p - ri->_dumptime_base;\n+    p += ri->_region_size;\n+  }\n+  assert(p == _loaded_heap_top, \"must be\");\n+}\n+\n+bool HeapShared::load_regions(FileMapInfo* mapinfo, LoadedArchiveHeapRegion* loaded_regions,\n+                              int num_loaded_regions, uintptr_t buffer) {\n+  uintptr_t bitmap_base = (uintptr_t)mapinfo->map_bitmap_region();\n+  uintptr_t load_address = buffer;\n+  for (int i = 0; i < num_loaded_regions; i++) {\n+    LoadedArchiveHeapRegion* ri = &loaded_regions[i];\n+    FileMapRegion* r = mapinfo->space_at(ri->_region_index);\n+\n+    if (!mapinfo->read_region(ri->_region_index, (char*)load_address, r->used(), \/* do_commit = *\/ false)) {\n+      \/\/ There's no easy way to free the buffer, so we will fill it with zero later\n+      \/\/ in fill_failed_loaded_region(), and it will eventually be GC'ed.\n+      log_warning(cds)(\"Loading of heap region %d has failed. Archived objects are disabled\", i);\n+      _loading_failed = true;\n+      return false;\n+    }\n+    log_info(cds)(\"Loaded heap    region #%d at base \" INTPTR_FORMAT \" top \" INTPTR_FORMAT\n+                  \" size \" SIZE_FORMAT_W(6) \" delta \" INTX_FORMAT,\n+                  ri->_region_index, load_address, load_address + ri->_region_size,\n+                  ri->_region_size, ri->_runtime_offset);\n+\n+    uintptr_t oopmap = bitmap_base + r->oopmap_offset();\n+    BitMapView bm((BitMap::bm_word_t*)oopmap, r->oopmap_size_in_bits());\n+\n+    if (num_loaded_regions == 4) {\n+      PatchLoadedRegionPointers<4> patcher((narrowOop*)load_address, loaded_regions);\n+      bm.iterate(&patcher);\n+    } else if (num_loaded_regions == 3) {\n+      PatchLoadedRegionPointers<3> patcher((narrowOop*)load_address, loaded_regions);\n+      bm.iterate(&patcher);\n+    } else {\n+      assert(num_loaded_regions == 2, \"must be\");\n+      PatchLoadedRegionPointers<2> patcher((narrowOop*)load_address, loaded_regions);\n+      bm.iterate(&patcher);\n+    }\n+\n+    load_address += r->used();\n+  }\n+\n+  return true;\n+}\n+\n+bool HeapShared::load_heap_regions(FileMapInfo* mapinfo) {\n+  init_narrow_oop_decoding(mapinfo->narrow_oop_base(), mapinfo->narrow_oop_shift());\n+\n+  LoadedArchiveHeapRegion loaded_regions[MetaspaceShared::max_num_heap_regions];\n+  memset(loaded_regions, 0, sizeof(loaded_regions));\n+\n+  MemRegion archive_space;\n+  int num_loaded_regions = init_loaded_regions(mapinfo, loaded_regions, archive_space);\n+  if (num_loaded_regions <= 0) {\n+    return false;\n+  }\n+  sort_loaded_regions(loaded_regions, num_loaded_regions, (uintptr_t)archive_space.start());\n+  if (!load_regions(mapinfo, loaded_regions, num_loaded_regions, (uintptr_t)archive_space.start())) {\n+    assert(_loading_failed, \"must be\");\n+    return false;\n+  }\n+\n+  init_loaded_heap_relocation(loaded_regions, num_loaded_regions);\n+  _is_loaded = true;\n+  set_roots(mapinfo->heap_obj_roots());\n+\n+  return true;\n+}\n+\n+class VerifyLoadedHeapEmbeddedPointers: public BasicOopIterateClosure {\n+  ResourceHashtable<uintptr_t, bool>* _table;\n+\n+ public:\n+  VerifyLoadedHeapEmbeddedPointers(ResourceHashtable<uintptr_t, bool>* table) : _table(table) {}\n+\n+  virtual void do_oop(narrowOop* p) {\n+    \/\/ This should be called before the loaded regions are modified, so all the embedded pointers\n+    \/\/ must be NULL, or must point to a valid object in the loaded regions.\n+    narrowOop v = *p;\n+    if (!CompressedOops::is_null(v)) {\n+      oop o = CompressedOops::decode_not_null(v);\n+      uintptr_t u = cast_from_oop<uintptr_t>(o);\n+      HeapShared::assert_in_loaded_heap(u);\n+      guarantee(_table->contains(u), \"must point to beginning of object in loaded archived regions\");\n+    }\n+  }\n+  virtual void do_oop(oop* p) {\n+    ShouldNotReachHere();\n+  }\n+};\n+\n+void HeapShared::finish_initialization() {\n+  if (is_loaded()) {\n+    HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n+    HeapWord* top    = (HeapWord*)_loaded_heap_top;\n+\n+    MemRegion archive_space = MemRegion(bottom, top);\n+    Universe::heap()->complete_loaded_archive_space(archive_space);\n+  }\n+\n+  if (VerifyArchivedFields <= 0 || !is_loaded()) {\n+    return;\n+  }\n+\n+  log_info(cds, heap)(\"Verify all oops and pointers in loaded heap\");\n+\n+  ResourceMark rm;\n+  ResourceHashtable<uintptr_t, bool> table;\n+  VerifyLoadedHeapEmbeddedPointers verifier(&table);\n+  HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n+  HeapWord* top    = (HeapWord*)_loaded_heap_top;\n+\n+  for (HeapWord* p = bottom; p < top; ) {\n+    oop o = cast_to_oop(p);\n+    table.put(cast_from_oop<uintptr_t>(o), true);\n+    p += o->size();\n+  }\n+\n+  for (HeapWord* p = bottom; p < top; ) {\n+    oop o = cast_to_oop(p);\n+    o->oop_iterate(&verifier);\n+    p += o->size();\n+  }\n+}\n+\n+void HeapShared::fill_failed_loaded_region() {\n+  assert(_loading_failed, \"must be\");\n+  if (_loaded_heap_bottom != 0) {\n+    assert(_loaded_heap_top != 0, \"must be\");\n+    HeapWord* bottom = (HeapWord*)_loaded_heap_bottom;\n+    HeapWord* top = (HeapWord*)_loaded_heap_top;\n+    Universe::heap()->fill_with_objects(bottom, top - bottom);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/cds\/heapShared.cpp","additions":336,"deletions":24,"binary":false,"changes":360,"status":"modified"},{"patch":"@@ -372,0 +372,5 @@\n+  \/\/ Need to do this first, as subsequent steps may call virtual functions\n+  \/\/ in archived Metadata objects.\n+  CppVtables::serialize(soc);\n+  soc->do_tag(--tag);\n+\n@@ -393,3 +398,0 @@\n-  CppVtables::serialize(soc);\n-  soc->do_tag(--tag);\n-\n@@ -587,0 +589,2 @@\n+  GrowableArray<Handle> _loaded_cld_handles; \/\/ keep the CLDs alive\n+  Thread* _current_thread;\n@@ -588,1 +592,1 @@\n-  CollectCLDClosure() {}\n+  CollectCLDClosure(Thread* thread) : _current_thread(thread) {}\n@@ -592,1 +596,0 @@\n-      cld->dec_keep_alive();\n@@ -597,1 +600,1 @@\n-      cld->inc_keep_alive();\n+      _loaded_cld_handles.append(Handle(_current_thread, cld->holder_phantom()));\n@@ -644,4 +647,3 @@\n-  \/\/ Collect all loaded ClassLoaderData.\n-  ResourceMark rm;\n-\n-  CollectCLDClosure collect_cld;\n+\n+  \/\/ Collect all loaded ClassLoaderData.\n+  CollectCLDClosure collect_cld(THREAD);\n@@ -832,1 +834,1 @@\n-  if(!HeapShared::is_heap_object_archiving_allowed()) {\n+  if(!HeapShared::can_write()) {\n@@ -869,1 +871,1 @@\n-  if (HeapShared::is_heap_object_archiving_allowed()) {\n+  if (HeapShared::can_write()) {\n@@ -1141,1 +1143,1 @@\n-          static_mapinfo->map_heap_regions();\n+          static_mapinfo->map_or_load_heap_regions();\n@@ -1425,1 +1427,1 @@\n-  \/\/ shared string\/symbol tables\n+  \/\/ shared string\/symbol tables.\n@@ -1434,0 +1436,2 @@\n+  \/\/ Finish up archived heap initialization. These must be\n+  \/\/ done after ReadClosure.\n@@ -1435,0 +1439,1 @@\n+  HeapShared::finish_initialization();\n@@ -1517,2 +1522,9 @@\n-  bool result = _use_optimized_module_handling && _use_full_module_graph &&\n-    (UseSharedSpaces || DumpSharedSpaces) && HeapShared::is_heap_object_archiving_allowed();\n+  bool result = _use_optimized_module_handling && _use_full_module_graph;\n+  if (DumpSharedSpaces) {\n+    result &= HeapShared::can_write();\n+  } else if (UseSharedSpaces) {\n+    result &= HeapShared::can_use();\n+  } else {\n+    result = false;\n+  }\n+\n","filename":"src\/hotspot\/share\/cds\/metaspaceShared.cpp","additions":28,"deletions":16,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"classfile\/javaClasses.inline.hpp\"\n@@ -52,0 +53,1 @@\n+#include \"interpreter\/bytecodeStream.hpp\"\n@@ -68,0 +70,1 @@\n+#include \"runtime\/fieldDescriptor.inline.hpp\"\n@@ -170,0 +173,4 @@\n+\n+  _dyno_klasses = NULL;\n+  _dyno_locs = NULL;\n+  _dyno_name[0] = '\\0';\n@@ -172,0 +179,61 @@\n+\/\/ Record components of a location descriptor string.  Components are appended by the constructor and\n+\/\/ removed by the destructor, like a stack, so scope matters.  These location descriptors are used to\n+\/\/ locate dynamic classes, and terminate at a Method* or oop field associated with dynamic\/hidden class.\n+\/\/\n+\/\/ Example use:\n+\/\/\n+\/\/ {\n+\/\/   RecordLocation fp(this, \"field1\");\n+\/\/   \/\/ location: \"field1\"\n+\/\/   { RecordLocation fp(this, \" field2\"); \/\/ location: \"field1 field2\" }\n+\/\/   \/\/ location: \"field1\"\n+\/\/   { RecordLocation fp(this, \" field3\"); \/\/ location: \"field1 field3\" }\n+\/\/   \/\/ location: \"field1\"\n+\/\/ }\n+\/\/ \/\/ location: \"\"\n+\/\/\n+\/\/ Examples of actual locations\n+\/\/ @bci compiler\/ciReplay\/CiReplayBase$TestMain test (I)V 1 <appendix> argL0 ;\n+\/\/ \/\/ resolve invokedynamic at bci 1 of TestMain.test, then read field \"argL0\" from appendix\n+\/\/ @bci compiler\/ciReplay\/CiReplayBase$TestMain main ([Ljava\/lang\/String;)V 0 <appendix> form vmentry <vmtarget> ;\n+\/\/ \/\/ resolve invokedynamic at bci 0 of TestMain.main, then read field \"form.vmentry.method.vmtarget\" from appendix\n+\/\/ @cpi compiler\/ciReplay\/CiReplayBase$TestMain 56 form vmentry <vmtarget> ;\n+\/\/ \/\/ resolve MethodHandle at cpi 56 of TestMain, then read field \"vmentry.method.vmtarget\" from resolved MethodHandle\n+class RecordLocation {\n+private:\n+  char* end;\n+\n+  ATTRIBUTE_PRINTF(3, 4)\n+  void push(ciEnv* ci, const char* fmt, ...) {\n+    va_list args;\n+    va_start(args, fmt);\n+    push_va(ci, fmt, args);\n+    va_end(args);\n+  }\n+\n+public:\n+  ATTRIBUTE_PRINTF(3, 0)\n+  void push_va(ciEnv* ci, const char* fmt, va_list args) {\n+    char *e = ci->_dyno_name + strlen(ci->_dyno_name);\n+    char *m = ci->_dyno_name + ARRAY_SIZE(ci->_dyno_name) - 1;\n+    os::vsnprintf(e, m - e, fmt, args);\n+    assert(strlen(ci->_dyno_name) < (ARRAY_SIZE(ci->_dyno_name) - 1), \"overflow\");\n+  }\n+\n+  \/\/ append a new component\n+  ATTRIBUTE_PRINTF(3, 4)\n+  RecordLocation(ciEnv* ci, const char* fmt, ...) {\n+    end = ci->_dyno_name + strlen(ci->_dyno_name);\n+    va_list args;\n+    va_start(args, fmt);\n+    push(ci, \" \");\n+    push_va(ci, fmt, args);\n+    va_end(args);\n+  }\n+\n+  \/\/ reset to previous state\n+  ~RecordLocation() {\n+    *end = '\\0';\n+  }\n+};\n+\n@@ -226,0 +294,3 @@\n+\n+  _dyno_klasses = NULL;\n+  _dyno_locs = NULL;\n@@ -1228,1 +1299,114 @@\n-\/\/ ciEnv::dump_replay_data*\n+\/\/ Replay support\n+\n+\n+\/\/ Lookup location descriptor for the class, if any.\n+\/\/ Returns false if not found.\n+bool ciEnv::dyno_loc(const InstanceKlass* ik, const char *&loc) const {\n+  bool found = false;\n+  int pos = _dyno_klasses->find_sorted<const InstanceKlass*, klass_compare>(ik, found);\n+  if (!found) {\n+    return false;\n+  }\n+  loc = _dyno_locs->at(pos);\n+  return found;\n+}\n+\n+\/\/ Associate the current location descriptor with the given class and record for later lookup.\n+void ciEnv::set_dyno_loc(const InstanceKlass* ik) {\n+  const char *loc = os::strdup(_dyno_name);\n+  bool found = false;\n+  int pos = _dyno_klasses->find_sorted<const InstanceKlass*, klass_compare>(ik, found);\n+  if (found) {\n+    _dyno_locs->at_put(pos, loc);\n+  } else {\n+    _dyno_klasses->insert_before(pos, ik);\n+    _dyno_locs->insert_before(pos, loc);\n+  }\n+}\n+\n+\/\/ Associate the current location descriptor with the given class and record for later lookup.\n+\/\/ If it turns out that there are multiple locations for the given class, that conflict should\n+\/\/ be handled here.  Currently we choose the first location found.\n+void ciEnv::record_best_dyno_loc(const InstanceKlass* ik) {\n+  if (!ik->is_hidden()) {\n+    return;\n+  }\n+  const char *loc0;\n+  if (dyno_loc(ik, loc0)) {\n+    \/\/ TODO: found multiple references, see if we can improve\n+    if (Verbose) {\n+      tty->print_cr(\"existing call site @ %s for %s\",\n+                     loc0, ik->external_name());\n+    }\n+  } else {\n+    set_dyno_loc(ik);\n+  }\n+}\n+\n+\/\/ Look up the location descriptor for the given class and print it to the output stream.\n+bool ciEnv::print_dyno_loc(outputStream* out, const InstanceKlass* ik) const {\n+  const char *loc;\n+  if (dyno_loc(ik, loc)) {\n+    out->print(\"%s\", loc);\n+    return true;\n+  } else {\n+    return false;\n+  }\n+}\n+\n+\/\/ Look up the location descriptor for the given class and return it as a string.\n+\/\/ Returns NULL if no location is found.\n+const char *ciEnv::dyno_name(const InstanceKlass* ik) const {\n+  if (ik->is_hidden()) {\n+    stringStream ss;\n+    if (print_dyno_loc(&ss, ik)) {\n+      ss.print(\" ;\"); \/\/ add terminator\n+      const char* call_site = ss.as_string();\n+      return call_site;\n+    }\n+  }\n+  return NULL;\n+}\n+\n+\/\/ Look up the location descriptor for the given class and return it as a string.\n+\/\/ Returns the class name as a fallback if no location is found.\n+const char *ciEnv::replay_name(ciKlass* k) const {\n+  if (k->is_instance_klass()) {\n+    return replay_name(k->as_instance_klass()->get_instanceKlass());\n+  }\n+  return k->name()->as_quoted_ascii();\n+}\n+\n+\/\/ Look up the location descriptor for the given class and return it as a string.\n+\/\/ Returns the class name as a fallback if no location is found.\n+const char *ciEnv::replay_name(const InstanceKlass* ik) const {\n+  const char* name = dyno_name(ik);\n+  if (name != NULL) {\n+      return name;\n+  }\n+  return ik->name()->as_quoted_ascii();\n+}\n+\n+\/\/ Process a java.lang.invoke.MemberName object and record any dynamic locations.\n+void ciEnv::record_member(Thread* thread, oop member) {\n+  assert(java_lang_invoke_MemberName::is_instance(member), \"!\");\n+  \/\/ Check MemberName.clazz field\n+  oop clazz = java_lang_invoke_MemberName::clazz(member);\n+  if (clazz->klass()->is_instance_klass()) {\n+    RecordLocation fp(this, \"clazz\");\n+    InstanceKlass* ik = InstanceKlass::cast(clazz->klass());\n+    record_best_dyno_loc(ik);\n+  }\n+  \/\/ Check MemberName.method.vmtarget field\n+  Method* vmtarget = java_lang_invoke_MemberName::vmtarget(member);\n+  if (vmtarget != NULL) {\n+    RecordLocation fp2(this, \"<vmtarget>\");\n+    InstanceKlass* ik = vmtarget->method_holder();\n+    record_best_dyno_loc(ik);\n+  }\n+}\n+\n+\/\/ Read an object field.  Lookup is done by name only.\n+static inline oop obj_field(oop obj, const char* name) {\n+    return ciReplay::obj_field(obj, name);\n+}\n@@ -1230,2 +1414,219 @@\n-\/\/ Don't change thread state and acquire any locks.\n-\/\/ Safe to call from VM error reporter.\n+\/\/ Process a java.lang.invoke.LambdaForm object and record any dynamic locations.\n+void ciEnv::record_lambdaform(Thread* thread, oop form) {\n+  assert(java_lang_invoke_LambdaForm::is_instance(form), \"!\");\n+\n+  {\n+    \/\/ Check LambdaForm.vmentry field\n+    oop member = java_lang_invoke_LambdaForm::vmentry(form);\n+    RecordLocation fp0(this, \"vmentry\");\n+    record_member(thread, member);\n+  }\n+\n+  \/\/ Check LambdaForm.names array\n+  objArrayOop names = (objArrayOop)obj_field(form, \"names\");\n+  if (names != NULL) {\n+    RecordLocation lp0(this, \"names\");\n+    int len = names->length();\n+    for (int i = 0; i < len; ++i) {\n+      oop name = names->obj_at(i);\n+      RecordLocation lp1(this, \"%d\", i);\n+     \/\/ Check LambdaForm.names[i].function field\n+      RecordLocation lp2(this, \"function\");\n+      oop function = obj_field(name, \"function\");\n+      if (function != NULL) {\n+        \/\/ Check LambdaForm.names[i].function.member field\n+        oop member = obj_field(function, \"member\");\n+        if (member != NULL) {\n+          RecordLocation lp3(this, \"member\");\n+          record_member(thread, member);\n+        }\n+        \/\/ Check LambdaForm.names[i].function.resolvedHandle field\n+        oop mh = obj_field(function, \"resolvedHandle\");\n+        if (mh != NULL) {\n+          RecordLocation lp3(this, \"resolvedHandle\");\n+          record_mh(thread, mh);\n+        }\n+        \/\/ Check LambdaForm.names[i].function.invoker field\n+        oop invoker = obj_field(function, \"invoker\");\n+        if (invoker != NULL) {\n+          RecordLocation lp3(this, \"invoker\");\n+          record_mh(thread, invoker);\n+        }\n+      }\n+    }\n+  }\n+}\n+\n+\/\/ Process a java.lang.invoke.MethodHandle object and record any dynamic locations.\n+void ciEnv::record_mh(Thread* thread, oop mh) {\n+  {\n+    \/\/ Check MethodHandle.form field\n+    oop form = java_lang_invoke_MethodHandle::form(mh);\n+    RecordLocation fp(this, \"form\");\n+    record_lambdaform(thread, form);\n+  }\n+  \/\/ Check DirectMethodHandle.member field\n+  if (java_lang_invoke_DirectMethodHandle::is_instance(mh)) {\n+    oop member = java_lang_invoke_DirectMethodHandle::member(mh);\n+    RecordLocation fp(this, \"member\");\n+    record_member(thread, member);\n+  } else {\n+    \/\/ Check <MethodHandle subclass>.argL0 field\n+    \/\/ Probably BoundMethodHandle.Species_L, but we only care if the field exists\n+    oop arg = obj_field(mh, \"argL0\");\n+    if (arg != NULL) {\n+      RecordLocation fp(this, \"argL0\");\n+      if (arg->klass()->is_instance_klass()) {\n+        InstanceKlass* ik2 = InstanceKlass::cast(arg->klass());\n+        record_best_dyno_loc(ik2);\n+      }\n+    }\n+  }\n+}\n+\n+\/\/ Process an object found at an invokedynamic\/invokehandle call site and record any dynamic locations.\n+\/\/ Types currently supported are MethodHandle and CallSite.\n+\/\/ The object is typically the \"appendix\" object, or Bootstrap Method (BSM) object.\n+void ciEnv::record_call_site_obj(Thread* thread, const constantPoolHandle& pool, const Handle obj)\n+{\n+  if (obj.not_null()) {\n+    if (java_lang_invoke_MethodHandle::is_instance(obj())) {\n+        record_mh(thread, obj());\n+    } else if (java_lang_invoke_ConstantCallSite::is_instance(obj())) {\n+      oop target = java_lang_invoke_CallSite::target(obj());\n+      if (target->klass()->is_instance_klass()) {\n+        RecordLocation fp(this, \"target\");\n+        InstanceKlass* ik = InstanceKlass::cast(target->klass());\n+        record_best_dyno_loc(ik);\n+      }\n+    }\n+  }\n+}\n+\n+\/\/ Process an adapter Method* found at an invokedynamic\/invokehandle call site and record any dynamic locations.\n+void ciEnv::record_call_site_method(Thread* thread, const constantPoolHandle& pool, Method* adapter) {\n+  InstanceKlass* holder = adapter->method_holder();\n+  if (!holder->is_hidden()) {\n+    return;\n+  }\n+  RecordLocation fp(this, \"<adapter>\");\n+  record_best_dyno_loc(holder);\n+}\n+\n+\/\/ Process an invokedynamic call site and record any dynamic locations.\n+void ciEnv::process_invokedynamic(const constantPoolHandle &cp, int indy_index, JavaThread* thread) {\n+  ConstantPoolCacheEntry* cp_cache_entry = cp->invokedynamic_cp_cache_entry_at(indy_index);\n+  if (cp_cache_entry->is_resolved(Bytecodes::_invokedynamic)) {\n+    \/\/ process the adapter\n+    Method* adapter = cp_cache_entry->f1_as_method();\n+    record_call_site_method(thread, cp, adapter);\n+    \/\/ process the appendix\n+    Handle appendix(thread, cp_cache_entry->appendix_if_resolved(cp));\n+    {\n+      RecordLocation fp(this, \"<appendix>\");\n+      record_call_site_obj(thread, cp, appendix);\n+    }\n+    \/\/ process the BSM\n+    int pool_index = cp_cache_entry->constant_pool_index();\n+    BootstrapInfo bootstrap_specifier(cp, pool_index, indy_index);\n+    oop bsm_oop = cp->resolve_possibly_cached_constant_at(bootstrap_specifier.bsm_index(), thread);\n+    Handle bsm(thread, bsm_oop);\n+    {\n+      RecordLocation fp(this, \"<bsm>\");\n+      record_call_site_obj(thread, cp, bsm);\n+    }\n+  }\n+}\n+\n+\/\/ Process an invokehandle call site and record any dynamic locations.\n+void ciEnv::process_invokehandle(const constantPoolHandle &cp, int index, JavaThread* thread) {\n+  const int holder_index = cp->klass_ref_index_at(index);\n+  if (!cp->tag_at(holder_index).is_klass()) {\n+    return;  \/\/ not resolved\n+  }\n+  Klass* holder = ConstantPool::klass_at_if_loaded(cp, holder_index);\n+  Symbol* name = cp->name_ref_at(index);\n+  if (MethodHandles::is_signature_polymorphic_name(holder, name)) {\n+    ConstantPoolCacheEntry* cp_cache_entry = cp->cache()->entry_at(cp->decode_cpcache_index(index));\n+    if (cp_cache_entry->is_resolved(Bytecodes::_invokehandle)) {\n+      \/\/ process the adapter\n+      Method* adapter = cp_cache_entry->f1_as_method();\n+      Handle appendix(thread, cp_cache_entry->appendix_if_resolved(cp));\n+      record_call_site_method(thread, cp, adapter);\n+      \/\/ process the appendix\n+      {\n+        RecordLocation fp(this, \"<appendix>\");\n+        record_call_site_obj(thread, cp, appendix);\n+      }\n+    }\n+  }\n+}\n+\n+\/\/ Search the class hierarchy for dynamic classes reachable through dynamic call sites or\n+\/\/ constant pool entries and record for future lookup.\n+void ciEnv::find_dynamic_call_sites() {\n+  _dyno_klasses = new (arena()) GrowableArray<const InstanceKlass*>(arena(), 100, 0, NULL);\n+  _dyno_locs    = new (arena()) GrowableArray<const char *>(arena(), 100, 0, NULL);\n+\n+  \/\/ Iterate over the class hierarchy\n+  for (ClassHierarchyIterator iter(vmClasses::Object_klass()); !iter.done(); iter.next()) {\n+    Klass* sub = iter.klass();\n+    if (sub->is_instance_klass()) {\n+      InstanceKlass *isub = InstanceKlass::cast(sub);\n+      InstanceKlass* ik = isub;\n+      if (!ik->is_linked()) {\n+        continue;\n+      }\n+      if (ik->is_hidden()) {\n+        continue;\n+      }\n+      JavaThread* thread = JavaThread::current();\n+      const constantPoolHandle pool(thread, ik->constants());\n+\n+      \/\/ Look for invokedynamic\/invokehandle call sites\n+      for (int i = 0; i < ik->methods()->length(); ++i) {\n+        Method* m = ik->methods()->at(i);\n+\n+        BytecodeStream bcs(methodHandle(thread, m));\n+        while (!bcs.is_last_bytecode()) {\n+          Bytecodes::Code opcode = bcs.next();\n+          opcode = bcs.raw_code();\n+          switch (opcode) {\n+          case Bytecodes::_invokedynamic:\n+          case Bytecodes::_invokehandle: {\n+            RecordLocation fp(this, \"@bci %s %s %s %d\",\n+                         ik->name()->as_quoted_ascii(),\n+                         m->name()->as_quoted_ascii(), m->signature()->as_quoted_ascii(),\n+                         bcs.bci());\n+            if (opcode == Bytecodes::_invokedynamic) {\n+              int index = bcs.get_index_u4();\n+              process_invokedynamic(pool, index, thread);\n+            } else {\n+              assert(opcode == Bytecodes::_invokehandle, \"new switch label added?\");\n+              int cp_cache_index = bcs.get_index_u2_cpcache();\n+              process_invokehandle(pool, cp_cache_index, thread);\n+            }\n+            break;\n+          }\n+          default:\n+            break;\n+          }\n+        }\n+      }\n+\n+      \/\/ Look for MethodHandle contant pool entries\n+      RecordLocation fp(this, \"@cpi %s\", ik->name()->as_quoted_ascii());\n+      int len = pool->length();\n+      for (int i = 0; i < len; ++i) {\n+        if (pool->tag_at(i).is_method_handle()) {\n+          bool found_it;\n+          oop mh = pool->find_cached_constant_at(i, found_it, thread);\n+          if (mh != NULL) {\n+            RecordLocation fp(this, \"%d\", i);\n+            record_mh(thread, mh);\n+          }\n+        }\n+      }\n+    }\n+  }\n+}\n@@ -1239,5 +1640,3 @@\n-    out->print(\"compile %s %s %s %d %d\",\n-               method->klass_name()->as_quoted_ascii(),\n-               method->name()->as_quoted_ascii(),\n-               method->signature()->as_quoted_ascii(),\n-               entry_bci, comp_level);\n+    out->print(\"compile \");\n+    get_method(method)->dump_name_as_ascii(out);\n+    out->print(\" %d %d\", entry_bci, comp_level);\n@@ -1261,1 +1660,5 @@\n-void ciEnv::dump_replay_data_unsafe(outputStream* out) {\n+\/\/ Called from VM error reporter, so be careful.\n+\/\/ Don't safepoint or acquire any locks.\n+\/\/\n+void ciEnv::dump_replay_data_helper(outputStream* out) {\n+  NoSafepointVerifier no_safepoint;\n@@ -1263,0 +1666,1 @@\n+\n@@ -1269,0 +1673,2 @@\n+  find_dynamic_call_sites();\n+\n@@ -1278,0 +1684,9 @@\n+\/\/ Called from VM error reporter, so be careful.\n+\/\/ Don't safepoint or acquire any locks.\n+\/\/\n+void ciEnv::dump_replay_data_unsafe(outputStream* out) {\n+  GUARDED_VM_ENTRY(\n+    dump_replay_data_helper(out);\n+  )\n+}\n+\n@@ -1281,1 +1696,1 @@\n-    dump_replay_data_unsafe(out);\n+    dump_replay_data_helper(out);\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":425,"deletions":10,"binary":false,"changes":435,"status":"modified"},{"patch":"@@ -47,1 +47,0 @@\n-\n@@ -50,0 +49,1 @@\n+  friend class RecordLocation;\n@@ -469,0 +469,23 @@\n+  \/\/ Replay support\n+private:\n+  static int klass_compare(const InstanceKlass* const &ik1, const InstanceKlass* const &ik2) {\n+    if (ik1 > ik2) {\n+      return 1;\n+    } else if (ik1 < ik2) {\n+      return -1;\n+    } else {\n+      return 0;\n+    }\n+  }\n+  bool dyno_loc(const InstanceKlass* ik, const char *&loc) const;\n+  void set_dyno_loc(const InstanceKlass* ik);\n+  void record_best_dyno_loc(const InstanceKlass* ik);\n+  bool print_dyno_loc(outputStream* out, const InstanceKlass* ik) const;\n+\n+  GrowableArray<const InstanceKlass*>* _dyno_klasses;\n+  GrowableArray<const char *>*         _dyno_locs;\n+\n+#define MAX_DYNO_NAME_LENGTH 1024\n+  char _dyno_name[MAX_DYNO_NAME_LENGTH+1];\n+\n+public:\n@@ -474,0 +497,1 @@\n+  void dump_replay_data_helper(outputStream* out);\n@@ -479,0 +503,13 @@\n+\n+  const char *dyno_name(const InstanceKlass* ik) const;\n+  const char *replay_name(const InstanceKlass* ik) const;\n+  const char *replay_name(ciKlass* i) const;\n+\n+  void record_lambdaform(Thread* thread, oop obj);\n+  void record_member(Thread* thread, oop obj);\n+  void record_mh(Thread* thread, oop obj);\n+  void record_call_site_obj(Thread* thread, const constantPoolHandle& pool, const Handle appendix);\n+  void record_call_site_method(Thread* thread, const constantPoolHandle& pool, Method* adapter);\n+  void process_invokedynamic(const constantPoolHandle &cp, int index, JavaThread* thread);\n+  void process_invokehandle(const constantPoolHandle &cp, int index, JavaThread* thread);\n+  void find_dynamic_call_sites();\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":38,"deletions":1,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -211,1 +211,1 @@\n-  if (!(offset >= 0 && offset < layout_helper())) {\n+  if (!(offset >= 0 && offset < layout_helper_size_in_bytes())) {\n@@ -216,1 +216,1 @@\n-  assert(offset >= 0 && offset < layout_helper(), \"offset must be tame\");\n+  assert(offset >= 0 && offset < layout_helper_size_in_bytes(), \"offset must be tame\");\n@@ -233,1 +233,3 @@\n-      if (super == NULL || super->nof_nonstatic_fields() == 0) {\n+      if (super == NULL ||\n+          super->nof_nonstatic_fields() == 0 ||\n+          super->layout_helper_size_in_bytes() <= offset) {\n@@ -847,0 +849,3 @@\n+const char *ciInstanceKlass::replay_name() const {\n+  return CURRENT_ENV->replay_name(get_instanceKlass());\n+}\n@@ -857,2 +862,12 @@\n-    if (sub->is_instance_klass() && !sub->is_hidden()) {\n-      out->print_cr(\"instanceKlass %s\", sub->name()->as_quoted_ascii());\n+    if (sub->is_instance_klass()) {\n+      InstanceKlass *isub = InstanceKlass::cast(sub);\n+      if (isub->is_hidden()) {\n+        const char *name = CURRENT_ENV->dyno_name(isub);\n+        if (name != NULL) {\n+          out->print_cr(\"instanceKlass %s # %s\", name, sub->name()->as_quoted_ascii());\n+        } else {\n+          out->print_cr(\"# instanceKlass %s\", sub->name()->as_quoted_ascii());\n+        }\n+      } else {\n+        out->print_cr(\"instanceKlass %s\", sub->name()->as_quoted_ascii());\n+      }\n@@ -867,1 +882,2 @@\n-  out->print(\"ciInstanceKlass %s %d %d %d\", ik->name()->as_quoted_ascii(),\n+  const char *name = replay_name();\n+  out->print(\"ciInstanceKlass %s %d %d %d\", name,\n@@ -876,1 +892,1 @@\n-    StaticFinalFieldPrinter sffp(out, ik->name()->as_quoted_ascii());\n+    StaticFinalFieldPrinter sffp(out, name);\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.cpp","additions":23,"deletions":7,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -169,0 +169,3 @@\n+  jint                   layout_helper_size_in_bytes()  {\n+    return Klass::layout_helper_size_in_bytes(layout_helper());\n+  }\n@@ -302,0 +305,2 @@\n+  \/\/ Replay support\n+\n@@ -305,0 +310,3 @@\n+  \/\/ Return stable class name suitable for replay file.\n+  const char *replay_name() const;\n+\n","filename":"src\/hotspot\/share\/ci\/ciInstanceKlass.hpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -74,0 +74,1 @@\n+  assert(_holder->get_instanceKlass() == h_m->method_holder(), \"\");\n@@ -1338,2 +1339,1 @@\n-void ciMethod::dump_name_as_ascii(outputStream* st) {\n-  Method* method = get_Method();\n+void ciMethod::dump_name_as_ascii(outputStream* st, Method* method) {\n@@ -1341,1 +1341,1 @@\n-            method->klass_name()->as_quoted_ascii(),\n+            CURRENT_ENV->replay_name(method->method_holder()),\n@@ -1346,0 +1346,5 @@\n+void ciMethod::dump_name_as_ascii(outputStream* st) {\n+  Method* method = get_Method();\n+  dump_name_as_ascii(st, method);\n+}\n+\n@@ -1349,0 +1354,4 @@\n+  if (MethodHandles::is_signature_polymorphic_method(method)) {\n+    \/\/ ignore for now\n+    return;\n+  }\n","filename":"src\/hotspot\/share\/ci\/ciMethod.cpp","additions":12,"deletions":3,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -374,0 +374,1 @@\n+  static void dump_name_as_ascii(outputStream* st, Method* method);\n","filename":"src\/hotspot\/share\/ci\/ciMethod.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -654,1 +654,2 @@\n-      out->print(\" %d %s\", (int)(dp_to_di(pdata->dp() + in_bytes(offset)) \/ sizeof(intptr_t)), k->name()->as_quoted_ascii());\n+      out->print(\" %d %s\", (int)(dp_to_di(pdata->dp() + in_bytes(offset)) \/ sizeof(intptr_t)),\n+                           CURRENT_ENV->replay_name(k));\n@@ -710,7 +711,3 @@\n-  Klass* holder = method->method_holder();\n-  out->print(\"ciMethodData %s %s %s %d %d\",\n-             holder->name()->as_quoted_ascii(),\n-             method->name()->as_quoted_ascii(),\n-             method->signature()->as_quoted_ascii(),\n-             _state,\n-             current_mileage());\n+  out->print(\"ciMethodData \");\n+  ciMethod::dump_name_as_ascii(out, method);\n+  out->print(\" %d %d\", _state, current_mileage());\n","filename":"src\/hotspot\/share\/ci\/ciMethodData.cpp","additions":5,"deletions":8,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -37,0 +37,1 @@\n+#include \"interpreter\/linkResolver.hpp\"\n@@ -41,0 +42,2 @@\n+#include \"oops\/cpCache.inline.hpp\"\n+#include \"oops\/fieldStreams.inline.hpp\"\n@@ -46,0 +49,1 @@\n+#include \"prims\/methodHandles.hpp\"\n@@ -261,1 +265,1 @@\n-  const char* parse_escaped_string() {\n+  char* parse_escaped_string() {\n@@ -344,1 +348,1 @@\n-  Symbol* parse_symbol(TRAPS) {\n+  Symbol* parse_symbol() {\n@@ -353,0 +357,157 @@\n+  bool parse_terminator() {\n+    char* terminator = parse_string();\n+    if (terminator != NULL && strcmp(terminator, \";\") == 0) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  \/\/ Parse a special hidden klass location syntax\n+  \/\/ syntax: @bci <klass> <name> <signature> <bci> <location>* ;\n+  \/\/ syntax: @cpi <klass> <cpi> <location>* ;\n+  Klass* parse_cp_ref(TRAPS) {\n+    JavaThread* thread = THREAD;\n+    oop obj = NULL;\n+    char* ref = parse_string();\n+    if (strcmp(ref, \"bci\") == 0) {\n+      Method* m = parse_method(CHECK_NULL);\n+      if (m == NULL) {\n+        return NULL;\n+      }\n+\n+      InstanceKlass* ik = m->method_holder();\n+      const constantPoolHandle cp(Thread::current(), ik->constants());\n+\n+      \/\/ invokedynamic or invokehandle\n+\n+      methodHandle caller(Thread::current(), m);\n+      int bci = parse_int(\"bci\");\n+      if (m->validate_bci(bci) != bci) {\n+        report_error(\"bad bci\");\n+        return NULL;\n+      }\n+\n+      ik->link_class(CHECK_NULL);\n+\n+      Bytecode_invoke bytecode(caller, bci);\n+      int index = bytecode.index();\n+\n+      ConstantPoolCacheEntry* cp_cache_entry = NULL;\n+      CallInfo callInfo;\n+      Bytecodes::Code bc = bytecode.invoke_code();\n+      LinkResolver::resolve_invoke(callInfo, Handle(), cp, index, bc, CHECK_NULL);\n+      if (bytecode.is_invokedynamic()) {\n+        cp_cache_entry = cp->invokedynamic_cp_cache_entry_at(index);\n+        cp_cache_entry->set_dynamic_call(cp, callInfo);\n+      } else if (bytecode.is_invokehandle()) {\n+#ifdef ASSERT\n+        Klass* holder = cp->klass_ref_at(index, CHECK_NULL);\n+        Symbol* name = cp->name_ref_at(index);\n+        assert(MethodHandles::is_signature_polymorphic_name(holder, name), \"\");\n+#endif\n+        cp_cache_entry = cp->cache()->entry_at(cp->decode_cpcache_index(index));\n+        cp_cache_entry->set_method_handle(cp, callInfo);\n+      } else {\n+        report_error(\"no dynamic invoke found\");\n+        return NULL;\n+      }\n+      char* dyno_ref = parse_string();\n+      if (strcmp(dyno_ref, \"<appendix>\") == 0) {\n+        obj = cp_cache_entry->appendix_if_resolved(cp);\n+      } else if (strcmp(dyno_ref, \"<adapter>\") == 0) {\n+        if (!parse_terminator()) {\n+          report_error(\"no dynamic invoke found\");\n+          return NULL;\n+        }\n+        Method* adapter = cp_cache_entry->f1_as_method();\n+        if (adapter == NULL) {\n+          report_error(\"no adapter found\");\n+          return NULL;\n+        }\n+        return adapter->method_holder();\n+      } else if (strcmp(dyno_ref, \"<bsm>\") == 0) {\n+        int pool_index = cp_cache_entry->constant_pool_index();\n+        BootstrapInfo bootstrap_specifier(cp, pool_index, index);\n+        obj = cp->resolve_possibly_cached_constant_at(bootstrap_specifier.bsm_index(), thread);\n+      } else {\n+        report_error(\"unrecognized token\");\n+        return NULL;\n+      }\n+    } else {\n+      \/\/ constant pool ref (MethodHandle)\n+      if (strcmp(ref, \"cpi\") != 0) {\n+        report_error(\"unexpected token\");\n+        return NULL;\n+      }\n+\n+      Klass* k = parse_klass(CHECK_NULL);\n+      if (k == NULL) {\n+        return NULL;\n+      }\n+      InstanceKlass* ik = InstanceKlass::cast(k);\n+      const constantPoolHandle cp(Thread::current(), ik->constants());\n+\n+      int cpi = parse_int(\"cpi\");\n+\n+      if (cpi >= cp->length()) {\n+        report_error(\"bad cpi\");\n+        return NULL;\n+      }\n+      if (!cp->tag_at(cpi).is_method_handle()) {\n+        report_error(\"no method handle found at cpi\");\n+        return NULL;\n+      }\n+      {\n+        bool found_it;\n+        obj = cp->find_cached_constant_at(cpi, found_it, thread);\n+      }\n+    }\n+    Klass* k = NULL;\n+    if (obj != NULL) {\n+      skip_ws();\n+      \/\/ loop: read fields\n+      char* field = NULL;\n+      do {\n+        field = parse_string();\n+        if (field == NULL) {\n+          report_error(\"no field found\");\n+          return NULL;\n+        }\n+        if (strcmp(field, \";\") == 0) {\n+          break;\n+        }\n+        \/\/ raw Method*\n+        if (strcmp(field, \"<vmtarget>\") == 0) {\n+          Method* vmtarget = java_lang_invoke_MemberName::vmtarget(obj);\n+          k = (vmtarget == NULL) ? NULL : vmtarget->method_holder();\n+          if (k == NULL) {\n+            report_error(\"null vmtarget found\");\n+            return NULL;\n+          }\n+          if (!parse_terminator()) {\n+            report_error(\"missing terminator\");\n+            return NULL;\n+          }\n+          return k;\n+        }\n+        obj = ciReplay::obj_field(obj, field);\n+        \/\/ array\n+        if (obj != NULL && obj->is_objArray()) {\n+          objArrayOop arr = (objArrayOop)obj;\n+          int index = parse_int(\"index\");\n+          if (index >= arr->length()) {\n+            report_error(\"bad array index\");\n+            return NULL;\n+          }\n+          obj = arr->obj_at(index);\n+        }\n+      } while (obj != NULL);\n+      if (obj == NULL) {\n+        report_error(\"null field found\");\n+        return NULL;\n+      }\n+      k = obj->klass();\n+    }\n+    return k;\n+  }\n+\n@@ -354,0 +515,2 @@\n+  \/\/ syntax: <name>\n+  \/\/ syntax: <constant pool ref>\n@@ -355,1 +518,13 @@\n-    const char* str = parse_escaped_string();\n+    skip_ws();\n+    \/\/ check for constant pool object reference (for a dynamic\/hidden class)\n+    bool cp_ref = (*_bufptr == '@');\n+    if (cp_ref) {\n+      ++_bufptr;\n+      Klass* k = parse_cp_ref(CHECK_NULL);\n+      if (k != NULL && !k->is_hidden()) {\n+        report_error(\"expected hidden class\");\n+        return NULL;\n+      }\n+      return k;\n+    }\n+    char* str = parse_escaped_string();\n@@ -393,2 +568,2 @@\n-    Symbol* method_name = parse_symbol(CHECK_NULL);\n-    Symbol* method_signature = parse_symbol(CHECK_NULL);\n+    Symbol* method_name = parse_symbol();\n+    Symbol* method_signature = parse_symbol();\n@@ -683,0 +858,1 @@\n+  \/\/ instanceKlass <constant pool ref> # <original hidden class name>\n@@ -689,0 +865,13 @@\n+    if (k == NULL) {\n+      return;\n+    }\n+    const char* comment = parse_string();\n+    bool is_comment = comment != NULL && strcmp(comment, \"#\") == 0;\n+    if (k->is_hidden() != is_comment) {\n+      report_error(\"hidden class with comment expected\");\n+      return;\n+    }\n+    if (is_comment && Verbose) {\n+      const char* hidden = parse_string();\n+      tty->print_cr(\"Found %s for %s\", k->name()->as_quoted_ascii(), hidden);\n+    }\n@@ -1391,0 +1580,37 @@\n+\n+oop ciReplay::obj_field(oop obj, Symbol* name) {\n+  InstanceKlass* ik = InstanceKlass::cast(obj->klass());\n+\n+  do {\n+    if (!ik->has_nonstatic_fields()) {\n+      ik = ik->java_super();\n+      continue;\n+    }\n+\n+    for (JavaFieldStream fs(ik); !fs.done(); fs.next()) {\n+      if (fs.access_flags().is_static()) {\n+        continue;\n+      }\n+      if (fs.name() == name) {\n+        int offset = fs.offset();\n+#ifdef ASSERT\n+        fieldDescriptor fd = fs.field_descriptor();\n+        assert(fd.offset() == ik->field_offset(fd.index()), \"!\");\n+#endif\n+        oop f = obj->obj_field(offset);\n+        return f;\n+      }\n+    }\n+\n+    ik = ik->java_super();\n+  } while (ik != NULL);\n+  return NULL;\n+}\n+\n+oop ciReplay::obj_field(oop obj, const char *name) {\n+  Symbol* fname = SymbolTable::probe(name, (int)strlen(name));\n+  if (fname == NULL) {\n+    return NULL;\n+  }\n+  return obj_field(obj, fname);\n+}\n","filename":"src\/hotspot\/share\/ci\/ciReplay.cpp","additions":231,"deletions":5,"binary":false,"changes":236,"status":"modified"},{"patch":"@@ -137,1 +137,1 @@\n-  _metaspace_lock(new Mutex(Mutex::leaf+1, \"Metaspace allocation lock\", true,\n+  _metaspace_lock(new Mutex(Mutex::nosafepoint-2, \"MetaspaceAllocation_lock\",\n@@ -306,3 +306,1 @@\n-    if (!Arguments::is_dumping_archive()) {\n-      assert(_keep_alive > 0, \"Invalid keep alive increment count\");\n-    }\n+    assert(_keep_alive > 0, \"Invalid keep alive increment count\");\n","filename":"src\/hotspot\/share\/classfile\/classLoaderData.cpp","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -907,1 +907,1 @@\n-    if (HeapShared::open_regions_mapped()) {\n+    if (HeapShared::are_archived_mirrors_available()) {\n@@ -1188,2 +1188,1 @@\n-  assert(HeapShared::is_heap_object_archiving_allowed(),\n-         \"HeapShared::is_heap_object_archiving_allowed() must be true\");\n+  assert(HeapShared::can_write(), \"must be\");\n@@ -1227,2 +1226,1 @@\n-  assert(HeapShared::is_heap_object_archiving_allowed(),\n-         \"HeapShared::is_heap_object_archiving_allowed() must be true\");\n+  assert(HeapShared::can_write(), \"must be\");\n@@ -1388,1 +1386,3 @@\n-  assert(Universe::heap()->is_archived_object(m), \"must be archived mirror object\");\n+  if (HeapShared::is_mapped()) {\n+    assert(Universe::heap()->is_archived_object(m), \"must be archived mirror object\");\n+  }\n@@ -4520,0 +4520,1 @@\n+    initialized = true;\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":7,"deletions":6,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -141,0 +141,1 @@\n+  do_klass(URLClassLoader_klass,                        java_net_URLClassLoader                               ) \\\n","filename":"src\/hotspot\/share\/classfile\/vmClassMacros.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -514,0 +514,1 @@\n+  case vmIntrinsics::_encodeAsciiArray:\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -360,0 +360,3 @@\n+  do_intrinsic(_encodeAsciiArray,       java_lang_StringCoding, encodeAsciiArray_name, encodeISOArray_signature, F_S)   \\\n+   do_name(     encodeAsciiArray_name,                           \"implEncodeAsciiArray\")                                \\\n+                                                                                                                        \\\n@@ -424,1 +427,1 @@\n-   do_name(gcm_crypt_name, \"implGCMCrypt\")                                                                                 \\\n+   do_name(gcm_crypt_name, \"implGCMCrypt0\")                                                                                 \\\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -122,0 +122,1 @@\n+  template(java_net_URLClassLoader,                   \"java\/net\/URLClassLoader\")                  \\\n@@ -559,0 +560,1 @@\n+  template(string_boolean_class_signature,            \"(Ljava\/lang\/String;Z)Ljava\/lang\/Class;\")                   \\\n@@ -706,1 +708,1 @@\n-  template(dumpSharedArchive_signature,                     \"(ZLjava\/lang\/String;)V\")                             \\\n+  template(dumpSharedArchive_signature,                     \"(ZLjava\/lang\/String;)Ljava\/lang\/String;\")            \\\n@@ -720,0 +722,1 @@\n+  template(url_array_classloader_void_signature,            \"([Ljava\/net\/URL;Ljava\/lang\/ClassLoader;)V\")          \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -97,1 +97,0 @@\n-  NOT_PRODUCT(COMMA _strings(CodeStrings()))\n@@ -110,1 +109,1 @@\n-CodeBlob::CodeBlob(const char* name, CompilerType type, const CodeBlobLayout& layout, CodeBuffer* cb, int frame_complete_offset, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments) :\n+CodeBlob::CodeBlob(const char* name, CompilerType type, const CodeBlobLayout& layout, CodeBuffer* cb \/*UNUSED*\/, int frame_complete_offset, int frame_size, OopMapSet* oop_maps, bool caller_must_gc_arguments) :\n@@ -125,1 +124,0 @@\n-  NOT_PRODUCT(COMMA _strings(CodeStrings()))\n@@ -167,1 +165,2 @@\n-  NOT_PRODUCT(_strings.free();)\n+  NOT_PRODUCT(_asm_remarks.clear());\n+  NOT_PRODUCT(_dbg_strings.clear());\n@@ -193,1 +192,2 @@\n-      Disassembler::decode(stub->code_begin(), stub->code_end(), tty);\n+      Disassembler::decode(stub->code_begin(), stub->code_end(), tty\n+                           NOT_PRODUCT(COMMA &stub->asm_remarks()));\n","filename":"src\/hotspot\/share\/code\/codeBlob.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -115,1 +115,9 @@\n-  NOT_PRODUCT(CodeStrings _strings;)\n+#ifndef PRODUCT\n+  AsmRemarks _asm_remarks;\n+  DbgStrings _dbg_strings;\n+\n+ ~CodeBlob() {\n+    _asm_remarks.clear();\n+    _dbg_strings.clear();\n+  }\n+#endif \/\/ not PRODUCT\n@@ -122,2 +130,1 @@\n-  CodeBlob()\n-    : _type(compiler_none) {}\n+  CodeBlob() : _type(compiler_none) {}\n@@ -236,1 +243,1 @@\n-  \/\/ Print the comment associated with offset on stream, if there is one\n+  \/\/ Print to stream, any comments associated with offset.\n@@ -238,4 +245,5 @@\n-  #ifndef PRODUCT\n-    intptr_t offset = (intptr_t)(block_begin - code_begin());\n-    _strings.print_block_comment(stream, offset);\n-  #endif\n+#ifndef PRODUCT\n+    ptrdiff_t offset = block_begin - code_begin();\n+    assert(offset >= 0, \"Expecting non-negative offset!\");\n+    _asm_remarks.print(uint(offset), stream);\n+#endif\n@@ -245,3 +253,5 @@\n-  void set_strings(CodeStrings& strings) {\n-    _strings.copy(strings);\n-  }\n+  AsmRemarks &asm_remarks() { return _asm_remarks; }\n+  DbgStrings &dbg_strings() { return _dbg_strings; }\n+\n+  void use_remarks(AsmRemarks &remarks) { _asm_remarks.share(remarks); }\n+  void use_strings(DbgStrings &strings) { _dbg_strings.share(strings); }\n","filename":"src\/hotspot\/share\/code\/codeBlob.hpp","additions":21,"deletions":11,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -1220,1 +1220,3 @@\n-  assert(Universe::heap()->is_gc_active() || Thread::current()->is_ConcurrentGC_thread(),\n+  assert(Universe::heap()->is_gc_active() ||\n+         Thread::current()->is_ConcurrentGC_thread() ||\n+         Thread::current()->is_Worker_thread(),\n@@ -1260,1 +1262,3 @@\n-  assert(SafepointSynchronize::is_at_safepoint() || Thread::current()->is_ConcurrentGC_thread(),\n+  assert(SafepointSynchronize::is_at_safepoint() ||\n+         Thread::current()->is_ConcurrentGC_thread() ||\n+         Thread::current()->is_Worker_thread(),\n@@ -1581,1 +1585,3 @@\n-  DEBUG_ONLY(bool called_by_gc = Universe::heap()->is_gc_active() || Thread::current()->is_ConcurrentGC_thread();)\n+  DEBUG_ONLY(bool called_by_gc = Universe::heap()->is_gc_active() ||\n+                                 Thread::current()->is_ConcurrentGC_thread() ||\n+                                 Thread::current()->is_Worker_thread();)\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -1403,1 +1403,1 @@\n-  if (comp->is_c2()) {\n+  if (comp->is_c2() || comp->is_jvmci()) {\n","filename":"src\/hotspot\/share\/compiler\/compileBroker.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -33,1 +33,0 @@\n-    _threshold(NULL),\n@@ -52,1 +51,1 @@\n-    _threshold = _current_region->initialize_threshold();\n+    _current_region->initialize_bot_threshold();\n@@ -126,3 +125,1 @@\n-  if (_compaction_top > _threshold) {\n-    _threshold = _current_region->cross_threshold(_compaction_top - size, _compaction_top);\n-  }\n+  _current_region->alloc_block_in_bot(_compaction_top - size, _compaction_top);\n","filename":"src\/hotspot\/share\/gc\/g1\/g1FullGCCompactionPoint.cpp","additions":2,"deletions":5,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -29,0 +29,1 @@\n+#include \"gc\/g1\/g1EvacFailureRegions.inline.hpp\"\n@@ -34,0 +35,1 @@\n+#include \"gc\/g1\/g1YoungGCEvacFailureInjector.inline.hpp\"\n@@ -35,0 +37,1 @@\n+#include \"gc\/shared\/preservedMarks.inline.hpp\"\n@@ -55,0 +58,1 @@\n+                                           PreservedMarks* preserved_marks,\n@@ -58,1 +62,2 @@\n-                                           size_t optional_cset_length)\n+                                           size_t optional_cset_length,\n+                                           G1EvacFailureRegions* evac_failure_regions)\n@@ -82,1 +87,5 @@\n-    _obj_alloc_stat(NULL)\n+    _obj_alloc_stat(NULL),\n+    NOT_PRODUCT(_evac_failure_inject_counter(0) COMMA)\n+    _preserved_marks(preserved_marks),\n+    _evacuation_failed_info(),\n+    _evac_failure_regions(evac_failure_regions)\n@@ -111,0 +120,4 @@\n+  if (_evacuation_failed_info.has_failed()) {\n+     _g1h->gc_tracer_stw()->report_evacuation_failed(_evacuation_failed_info);\n+  }\n+\n@@ -201,8 +214,1 @@\n-  assert(obj != NULL, \"Must be\");\n-  if (HeapRegion::is_in_same_region(p, obj)) {\n-    return;\n-  }\n-  HeapRegion* from = _g1h->heap_region_containing(p);\n-  if (!from->is_young()) {\n-    enqueue_card_if_tracked(_g1h->region_attr(obj), p, obj);\n-  }\n+  write_ref_field_post(p, obj);\n@@ -233,1 +239,1 @@\n-  G1ScanInYoungSetter x(&_scanner, hr->is_young());\n+  G1SkipCardEnqueueSetter x(&_scanner, hr->is_young());\n@@ -265,1 +271,1 @@\n-  G1ScanInYoungSetter x(&_scanner, dest_attr.is_young());\n+  G1SkipCardEnqueueSetter x(&_scanner, dest_attr.is_young());\n@@ -372,3 +378,3 @@\n-    _g1h->_gc_tracer_stw->report_promotion_in_new_plab_event(old->klass(), word_sz * HeapWordSize, age,\n-                                                             dest_attr.type() == G1HeapRegionAttr::Old,\n-                                                             alloc_buf->word_sz() * HeapWordSize);\n+    _g1h->gc_tracer_stw()->report_promotion_in_new_plab_event(old->klass(), word_sz * HeapWordSize, age,\n+                                                              dest_attr.type() == G1HeapRegionAttr::Old,\n+                                                              alloc_buf->word_sz() * HeapWordSize);\n@@ -376,2 +382,2 @@\n-    _g1h->_gc_tracer_stw->report_promotion_outside_plab_event(old->klass(), word_sz * HeapWordSize, age,\n-                                                              dest_attr.type() == G1HeapRegionAttr::Old);\n+    _g1h->gc_tracer_stw()->report_promotion_outside_plab_event(old->klass(), word_sz * HeapWordSize, age,\n+                                                               dest_attr.type() == G1HeapRegionAttr::Old);\n@@ -404,1 +410,1 @@\n-    if (_g1h->_gc_tracer_stw->should_report_promotion_events()) {\n+    if (_g1h->gc_tracer_stw()->should_report_promotion_events()) {\n@@ -412,0 +418,6 @@\n+#ifndef PRODUCT\n+bool G1ParScanThreadState::inject_evacuation_failure() {\n+  return _g1h->evac_failure_injector()->evacuation_should_fail(_evac_failure_inject_counter);\n+}\n+#endif\n+\n@@ -448,1 +460,1 @@\n-      return handle_evacuation_failure_par(old, old_mark);\n+      return handle_evacuation_failure_par(old, old_mark, word_sz);\n@@ -455,2 +467,1 @@\n-#ifndef PRODUCT\n-  if (_g1h->evacuation_should_fail()) {\n+  if (inject_evacuation_failure()) {\n@@ -461,1 +472,1 @@\n-    return handle_evacuation_failure_par(old, old_mark);\n+    return handle_evacuation_failure_par(old, old_mark, word_sz);\n@@ -463,1 +474,0 @@\n-#endif \/\/ !PRODUCT\n@@ -513,1 +523,1 @@\n-    G1ScanInYoungSetter x(&_scanner, dest_attr.is_young());\n+    G1SkipCardEnqueueSetter x(&_scanner, dest_attr.is_young());\n@@ -516,1 +526,0 @@\n-\n@@ -535,1 +544,2 @@\n-      new G1ParScanThreadState(_g1h, _rdcqs,\n+      new G1ParScanThreadState(_g1h, rdcqs(),\n+                               _preserved_marks_set->get(worker_id),\n@@ -537,1 +547,2 @@\n-                               _young_cset_length, _optional_cset_length);\n+                               _young_cset_length, _optional_cset_length,\n+                               _evac_failure_regions);\n@@ -583,1 +594,1 @@\n-oop G1ParScanThreadState::handle_evacuation_failure_par(oop old, markWord m) {\n+oop G1ParScanThreadState::handle_evacuation_failure_par(oop old, markWord m, size_t word_sz) {\n@@ -591,1 +602,1 @@\n-    if (_g1h->notify_region_failed_evacuation(r->hrm_index())) {\n+    if (_evac_failure_regions->record(r->hrm_index())) {\n@@ -595,1 +606,2 @@\n-    _g1h->preserve_mark_during_evac_failure(_worker_id, old, m);\n+    _preserved_marks->push_if_necessary(old, m);\n+    _evacuation_failed_info.register_copy_failure(word_sz);\n@@ -597,1 +609,1 @@\n-    G1ScanInYoungSetter x(&_scanner, r->is_young());\n+    G1SkipCardEnqueueSetter x(&_scanner, r->is_young());\n@@ -641,0 +653,1 @@\n+                                                 PreservedMarksSet* preserved_marks_set,\n@@ -643,1 +656,2 @@\n-                                                 size_t optional_cset_length) :\n+                                                 size_t optional_cset_length,\n+                                                 G1EvacFailureRegions* evac_failure_regions) :\n@@ -646,0 +660,1 @@\n+    _preserved_marks_set(preserved_marks_set),\n@@ -651,1 +666,2 @@\n-    _flushed(false) {\n+    _flushed(false),\n+    _evac_failure_regions(evac_failure_regions) {\n","filename":"src\/hotspot\/share\/gc\/g1\/g1ParScanThreadState.cpp","additions":49,"deletions":33,"binary":false,"changes":82,"status":"modified"},{"patch":"@@ -96,2 +96,2 @@\n-  _shadow_region_monitor = new Monitor(Mutex::barrier, \"CompactionManager monitor\",\n-                                       Mutex::_allow_vm_block_flag, Monitor::_safepoint_check_never);\n+  _shadow_region_monitor = new Monitor(Mutex::nosafepoint, \"CompactionManager_lock\",\n+                                       Monitor::_safepoint_check_never);\n","filename":"src\/hotspot\/share\/gc\/parallel\/psCompactionManager.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -2071,0 +2071,1 @@\n+    BarrierEnqueueDiscoveredFieldClosure enqueue;\n@@ -2072,1 +2073,1 @@\n-    _rp_task->rp_work(worker_id, PSParallelCompact::is_alive_closure(), &keep_alive, &complete_gc);\n+    _rp_task->rp_work(worker_id, PSParallelCompact::is_alive_closure(), &keep_alive, &enqueue, &complete_gc);\n@@ -2149,1 +2150,1 @@\n-    assert(Thread::current()->is_GC_task_thread(), \"Must be a GC thread\");\n+    assert(Thread::current()->is_Worker_thread(), \"Must be a GC thread\");\n","filename":"src\/hotspot\/share\/gc\/parallel\/psParallelCompact.cpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -373,2 +373,0 @@\n-  log_develop_trace(gc, scavenge)(\"{promotion-failure %s \" PTR_FORMAT \" (%d)}\", obj->klass()->internal_name(), p2i(obj), obj->size());\n-\n","filename":"src\/hotspot\/share\/gc\/parallel\/psPromotionManager.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -485,0 +485,6 @@\n+  \/\/ Support for loading objects from CDS archive into the heap\n+  \/\/ (usually as a snapshot of the old generation).\n+  virtual bool can_load_archived_objects() const { return false; }\n+  virtual HeapWord* allocate_loaded_archive_space(size_t size) { return NULL; }\n+  virtual void complete_loaded_archive_space(MemRegion archive_space) { }\n+\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2170,42 +2170,1 @@\n-              Node* head = in->in(0);\n-              assert(head->is_Region(), \"unexpected infinite loop graph shape\");\n-\n-              Node* phi_mem = NULL;\n-              for (DUIterator_Fast jmax, j = head->fast_outs(jmax); j < jmax; j++) {\n-                Node* u = head->fast_out(j);\n-                if (u->is_Phi() && u->bottom_type() == Type::MEMORY) {\n-                  if (_phase->C->get_alias_index(u->adr_type()) == _alias) {\n-                    assert(phi_mem == NULL || phi_mem->adr_type() == TypePtr::BOTTOM, \"\");\n-                    phi_mem = u;\n-                  } else if (u->adr_type() == TypePtr::BOTTOM) {\n-                    assert(phi_mem == NULL || _phase->C->get_alias_index(phi_mem->adr_type()) == _alias, \"\");\n-                    if (phi_mem == NULL) {\n-                      phi_mem = u;\n-                    }\n-                  }\n-                }\n-              }\n-              if (phi_mem == NULL) {\n-                for (uint j = 1; j < head->req(); j++) {\n-                  Node* tail = head->in(j);\n-                  if (!_phase->is_dominator(head, tail)) {\n-                    continue;\n-                  }\n-                  Node* c = tail;\n-                  while (c != head) {\n-                    if (c->is_SafePoint() && !c->is_CallLeaf()) {\n-                      Node* m =c->in(TypeFunc::Memory);\n-                      if (m->is_MergeMem()) {\n-                        m = m->as_MergeMem()->memory_at(_alias);\n-                      }\n-                      assert(mem == NULL || mem == m, \"several memory states\");\n-                      mem = m;\n-                    }\n-                    c = _phase->idom(c);\n-                  }\n-                  assert(mem != NULL, \"should have found safepoint\");\n-                }\n-                assert(mem != NULL, \"should have found safepoint\");\n-              } else {\n-                mem = phi_mem;\n-              }\n+              mem = collect_memory_for_infinite_loop(in);\n@@ -2435,0 +2394,61 @@\n+Node* MemoryGraphFixer::collect_memory_for_infinite_loop(const Node* in) {\n+  Node* mem = NULL;\n+  Node* head = in->in(0);\n+  assert(head->is_Region(), \"unexpected infinite loop graph shape\");\n+\n+  Node* phi_mem = NULL;\n+  for (DUIterator_Fast jmax, j = head->fast_outs(jmax); j < jmax; j++) {\n+    Node* u = head->fast_out(j);\n+    if (u->is_Phi() && u->bottom_type() == Type::MEMORY) {\n+      if (_phase->C->get_alias_index(u->adr_type()) == _alias) {\n+        assert(phi_mem == NULL || phi_mem->adr_type() == TypePtr::BOTTOM, \"\");\n+        phi_mem = u;\n+      } else if (u->adr_type() == TypePtr::BOTTOM) {\n+        assert(phi_mem == NULL || _phase->C->get_alias_index(phi_mem->adr_type()) == _alias, \"\");\n+        if (phi_mem == NULL) {\n+          phi_mem = u;\n+        }\n+      }\n+    }\n+  }\n+  if (phi_mem == NULL) {\n+    ResourceMark rm;\n+    Node_Stack stack(0);\n+    stack.push(head, 1);\n+    do {\n+      Node* n = stack.node();\n+      uint i = stack.index();\n+      if (i >= n->req()) {\n+        stack.pop();\n+      } else {\n+        stack.set_index(i + 1);\n+        Node* c = n->in(i);\n+        assert(c != head, \"should have found a safepoint on the way\");\n+        if (stack.size() != 1 || _phase->is_dominator(head, c)) {\n+          for (;;) {\n+            if (c->is_Region()) {\n+              stack.push(c, 1);\n+              break;\n+            } else if (c->is_SafePoint() && !c->is_CallLeaf()) {\n+              Node* m = c->in(TypeFunc::Memory);\n+              if (m->is_MergeMem()) {\n+                m = m->as_MergeMem()->memory_at(_alias);\n+              }\n+              assert(mem == NULL || mem == m, \"several memory states\");\n+              mem = m;\n+              break;\n+            } else {\n+              assert(c != c->in(0), \"\");\n+              c = c->in(0);\n+            }\n+          }\n+        }\n+      }\n+    } while (stack.size() > 0);\n+    assert(mem != NULL, \"should have found safepoint\");\n+  } else {\n+    mem = phi_mem;\n+  }\n+  return mem;\n+}\n+\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/c2\/shenandoahSupport.cpp","additions":62,"deletions":42,"binary":false,"changes":104,"status":"modified"},{"patch":"@@ -1555,1 +1555,2 @@\n-              Disassembler::decode(handler, handler + buffer.insts_size());\n+              Disassembler::decode(handler, handler + buffer.insts_size(), tty\n+                                   NOT_PRODUCT(COMMA &buffer.asm_remarks()));\n","filename":"src\/hotspot\/share\/interpreter\/interpreterRuntime.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -425,1 +425,1 @@\n-  void* operator new [](size_t size, allocation_type type, MEMFLAGS flags) throw();\n+  void* operator new [](size_t size, allocation_type type, MEMFLAGS flags) throw() = delete;\n@@ -429,2 +429,1 @@\n-      allocation_type type, MEMFLAGS flags) throw();\n-\n+      allocation_type type, MEMFLAGS flags) throw() = delete;\n@@ -432,2 +431,1 @@\n-\n-  void* operator new [](size_t size, Arena *arena) throw();\n+  void* operator new [](size_t size, Arena *arena) throw() = delete;\n@@ -447,12 +445,2 @@\n-  void* operator new [](size_t size) throw() {\n-      address res = (address)resource_allocate_bytes(size);\n-      DEBUG_ONLY(set_allocation_type(res, RESOURCE_AREA);)\n-      return res;\n-  }\n-\n-  void* operator new [](size_t size, const std::nothrow_t& nothrow_constant) throw() {\n-      address res = (address)resource_allocate_bytes(size, AllocFailStrategy::RETURN_NULL);\n-      DEBUG_ONLY(if (res != NULL) set_allocation_type(res, RESOURCE_AREA);)\n-      return res;\n-  }\n-\n+  void* operator new [](size_t size) throw() = delete;\n+  void* operator new [](size_t size, const std::nothrow_t& nothrow_constant) throw() = delete;\n@@ -460,1 +448,1 @@\n-  void  operator delete [](void* p);\n+  void  operator delete [](void* p) = delete;\n","filename":"src\/hotspot\/share\/memory\/allocation.hpp","additions":6,"deletions":18,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -699,1 +699,1 @@\n-    MutexLocker x(&_mutex);\n+    MutexLocker x(&_mutex, Mutex::_no_safepoint_check_flag);\n","filename":"src\/hotspot\/share\/memory\/heapInspection.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2002, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2002, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -253,1 +253,1 @@\n-      _mutex(Mutex::leaf, \"Parallel heap iteration data merge lock\") {}\n+      _mutex(Mutex::nosafepoint, \"ParHeapInspectTask_lock\", Mutex::_safepoint_check_never) {}\n","filename":"src\/hotspot\/share\/memory\/heapInspection.hpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -135,4 +135,1 @@\n-      \/\/ In some rare cases we store some flags in the lowest 2 bits of a\n-      \/\/ MetaspaceObj pointer. Unmask these when manipulating the pointer.\n-      uintx p = (uintx)*mpp();\n-      return (address)(p & (~FLAG_MASK));\n+      return *addr();\n@@ -154,8 +151,0 @@\n-\n-  private:\n-    static const uintx FLAG_MASK = 0x03;\n-\n-    int flag_bits() const {\n-      uintx p = (uintx)*mpp();\n-      return (int)(p & FLAG_MASK);\n-    }\n","filename":"src\/hotspot\/share\/memory\/metaspaceClosure.hpp","additions":1,"deletions":12,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -127,1 +127,0 @@\n-bool Universe::_verify_in_progress                    = false;\n@@ -253,1 +252,1 @@\n-        if (HeapShared::is_heap_object_archiving_allowed()) {\n+        if (HeapShared::can_write()) {\n@@ -456,1 +455,1 @@\n-        HeapShared::open_regions_mapped() &&\n+        HeapShared::are_archived_mirrors_available() &&\n@@ -458,1 +457,1 @@\n-      assert(HeapShared::is_heap_object_archiving_allowed(), \"Sanity\");\n+      assert(HeapShared::can_use(), \"Sanity\");\n@@ -810,0 +809,3 @@\n+    if (HeapShared::is_loaded()) {\n+      StringTable::transfer_shared_strings_to_local_table();\n+    }\n@@ -1126,6 +1128,0 @@\n-  \/\/ The use of _verify_in_progress is a temporary work around for\n-  \/\/ 6320749.  Don't bother with a creating a class to set and clear\n-  \/\/ it since it is only used in this method and the control flow is\n-  \/\/ straight forward.\n-  _verify_in_progress = true;\n-\n@@ -1162,1 +1158,0 @@\n-    MutexLocker mu(CodeCache_lock, Mutex::_no_safepoint_check_flag);\n@@ -1194,2 +1189,0 @@\n-\n-  _verify_in_progress = false;\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":6,"deletions":13,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -192,3 +192,0 @@\n-\n-  \/\/ True during call to verify().  Should only be set\/cleared in verify().\n-  static bool _verify_in_progress;\n@@ -371,1 +368,0 @@\n-  static bool verify_in_progress() { return _verify_in_progress; }\n","filename":"src\/hotspot\/share\/memory\/universe.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -93,8 +93,8 @@\n-    \/\/ Arrays don't add any new methods, so their vtable is the same size as\n-    \/\/ the vtable of klass Object.\n-    set_vtable_length(Universe::base_vtable_size());\n-    set_name(name);\n-    set_super(Universe::is_bootstrapping() ? NULL : vmClasses::Object_klass());\n-    set_layout_helper(Klass::_lh_neutral_value);\n-    set_is_cloneable(); \/\/ All arrays are considered to be cloneable (See JLS 20.1.5)\n-    JFR_ONLY(INIT_ID(this);)\n+  \/\/ Arrays don't add any new methods, so their vtable is the same size as\n+  \/\/ the vtable of klass Object.\n+  set_vtable_length(Universe::base_vtable_size());\n+  set_name(name);\n+  set_super(Universe::is_bootstrapping() ? NULL : vmClasses::Object_klass());\n+  set_layout_helper(Klass::_lh_neutral_value);\n+  set_is_cloneable(); \/\/ All arrays are considered to be cloneable (See JLS 20.1.5)\n+  JFR_ONLY(INIT_ID(this);)\n","filename":"src\/hotspot\/share\/oops\/arrayKlass.cpp","additions":8,"deletions":8,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -352,1 +352,1 @@\n-    if (HeapShared::open_regions_mapped() &&\n+    if (HeapShared::is_fully_available() &&\n","filename":"src\/hotspot\/share\/oops\/constantPool.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -392,4 +392,0 @@\n-  void clear_shared_class_loader_type() {\n-    _misc_flags &= ~shared_loader_type_bits();\n-  }\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -608,1 +608,1 @@\n-    if (HeapShared::open_regions_mapped()) {\n+    if (HeapShared::are_archived_mirrors_available()) {\n","filename":"src\/hotspot\/share\/oops\/klass.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -141,1 +141,1 @@\n-  markWord() { \/* uninitialized *\/}\n+  markWord() = default;         \/\/ Doesn't initialize _value.\n@@ -145,0 +145,3 @@\n+  ~markWord() = default;\n+  markWord(const markWord&) = default;\n+  markWord& operator=(const markWord&) = default;\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -1253,1 +1253,2 @@\n-    _extra_data_lock(Mutex::leaf, \"MDO extra data lock\"),\n+    \/\/ Holds Compile_lock\n+    _extra_data_lock(Mutex::nonleaf-2, \"MDOExtraData_lock\", Mutex::_safepoint_check_always),\n","filename":"src\/hotspot\/share\/oops\/methodData.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -35,0 +36,1 @@\n+#include <type_traits>\n@@ -70,0 +72,4 @@\n+  \/\/ There may be ordering constraints on the initialization of fields that\n+  \/\/ make use of the C++ copy\/assign incorrect.\n+  NONCOPYABLE(oopDesc);\n+\n@@ -71,0 +77,3 @@\n+  \/\/ Must be trivial; see verifying static assert after the class.\n+  oopDesc() = default;\n+\n@@ -329,0 +338,7 @@\n+\/\/ An oopDesc is not initialized via a constructor.  Space is allocated in\n+\/\/ the Java heap, and static functions provided here on HeapWord* are used\n+\/\/ to fill in certain parts of that memory.  The allocated memory is then\n+\/\/ treated as referring to an oopDesc.  For that to be valid, the oopDesc\n+\/\/ class must have a trivial default constructor (C++14 3.8\/1).\n+static_assert(std::is_trivially_default_constructible<oopDesc>::value, \"required\");\n+\n","filename":"src\/hotspot\/share\/oops\/oop.hpp","additions":16,"deletions":0,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,1 @@\n+#include <type_traits>\n@@ -137,0 +138,3 @@\n+\/\/ See similar requirement for oopDesc.\n+static_assert(std::is_trivially_default_constructible<typeArrayOopDesc>::value, \"required\");\n+\n","filename":"src\/hotspot\/share\/oops\/typeArrayOop.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -400,0 +400,7 @@\n+  \/\/ Convert (~x+1) into -x. Note there isn't a bitwise not bytecode,\n+  \/\/ \"~x\" would typically represented as \"x^(-1)\", so (~x+1) will\n+  \/\/ be (x^(-1))+1.\n+  if (op1 == Op_XorI && phase->type(in2) == TypeInt::ONE &&\n+      phase->type(in1->in(2)) == TypeInt::MINUS_1) {\n+    return new SubINode(phase->makecon(TypeInt::ZERO), in1->in(1));\n+  }\n@@ -557,1 +564,7 @@\n-\n+  \/\/ Convert (~x+1) into -x. Note there isn't a bitwise not bytecode,\n+  \/\/ \"~x\" would typically represented as \"x^(-1)\", so (~x+1) will\n+  \/\/ be (x^(-1))+1\n+  if (op1 == Op_XorL && phase->type(in2) == TypeLong::ONE &&\n+      phase->type(in1->in(2)) == TypeLong::MINUS_1) {\n+    return new SubLNode(phase->makecon(TypeLong::ZERO), in1->in(1));\n+  }\n@@ -982,0 +995,15 @@\n+\/\/------------------------------Idealize---------------------------------------\n+Node* XorINode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* in1 = in(1);\n+  Node* in2 = in(2);\n+  int op1 = in1->Opcode();\n+  \/\/ Convert ~(x-1) into -x. Note there isn't a bitwise not bytecode,\n+  \/\/ \"~x\" would typically represented as \"x^(-1)\", and \"x-c0\" would\n+  \/\/ convert into \"x+ -c0\" in SubXNode::Ideal. So ~(x-1) will eventually\n+  \/\/ be (x+(-1))^-1.\n+  if (op1 == Op_AddI && phase->type(in2) == TypeInt::MINUS_1 &&\n+      phase->type(in1->in(2)) == TypeInt::MINUS_1) {\n+    return new SubINode(phase->makecon(TypeInt::ZERO), in1->in(1));\n+  }\n+  return AddNode::Ideal(phase, can_reshape);\n+}\n@@ -1047,0 +1075,15 @@\n+Node* XorLNode::Ideal(PhaseGVN* phase, bool can_reshape) {\n+  Node* in1 = in(1);\n+  Node* in2 = in(2);\n+  int op1 = in1->Opcode();\n+  \/\/ Convert ~(x-1) into -x. Note there isn't a bitwise not bytecode,\n+  \/\/ \"~x\" would typically represented as \"x^(-1)\", and \"x-c0\" would\n+  \/\/ convert into \"x+ -c0\" in SubXNode::Ideal. So ~(x-1) will eventually\n+  \/\/ be (x+(-1))^-1.\n+  if (op1 == Op_AddL && phase->type(in2) == TypeLong::MINUS_1 &&\n+      phase->type(in1->in(2)) == TypeLong::MINUS_1) {\n+    return new SubLNode(phase->makecon(TypeLong::ZERO), in1->in(1));\n+  }\n+  return AddNode::Ideal(phase, can_reshape);\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":44,"deletions":1,"binary":false,"changes":45,"status":"modified"},{"patch":"@@ -159,1 +159,1 @@\n-  int freq = call_site_count \/ invoke_count;\n+  double freq = (double)call_site_count \/ (double)invoke_count;\n@@ -163,1 +163,0 @@\n-      (call_site_count >= InlineFrequencyCount) ||\n@@ -170,1 +169,1 @@\n-      tty->print_cr(\"Inlined frequent method (freq=%d count=%d):\", freq, call_site_count);\n+      tty->print_cr(\"Inlined frequent method (freq=%lf):\", freq);\n","filename":"src\/hotspot\/share\/opto\/bytecodeInfo.cpp","additions":2,"deletions":3,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -219,0 +219,3 @@\n+  case vmIntrinsics::_encodeAsciiArray:\n+    if (!Matcher::match_rule_supported(Op_EncodeISOArray) || !Matcher::supports_encode_ascii_array) return false;\n+    break;\n","filename":"src\/hotspot\/share\/opto\/c2compiler.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -489,1 +489,3 @@\n-    _unique_id(0), _inline_cg(NULL), _callee(NULL), _is_pure_call(false), _prof_factor(prof_factor) {}\n+    _unique_id(0), _inline_cg(NULL), _callee(NULL), _is_pure_call(false), _prof_factor(prof_factor) {\n+    assert(IncrementalInlineVirtual, \"required\");\n+  }\n@@ -543,0 +545,6 @@\n+  \/\/ Implicit receiver null checks introduce problems when exception states are combined.\n+  Node* receiver = jvms->map()->argument(jvms, 0);\n+  const Type* recv_type = C->initial_gvn()->type(receiver);\n+  if (recv_type->maybe_null()) {\n+    return false;\n+  }\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":9,"deletions":1,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -373,0 +373,2 @@\n+    case Type::AryKlassPtr:\n+    case Type::InstKlassPtr:\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1159,1 +1159,1 @@\n-  const TypeKlassPtr* ttkp = (ttp != NULL) ? ttp->isa_klassptr() : NULL;\n+  const TypeKlassPtr* ttkp = (ttp != NULL) ? ttp->isa_instklassptr() : NULL;\n@@ -1247,1 +1247,1 @@\n-    const TypeKlassPtr *jtkp = (jtp != NULL) ? jtp->isa_klassptr() : NULL;\n+    const TypeKlassPtr *jtkp = (jtp != NULL) ? jtp->isa_instklassptr() : NULL;\n@@ -2826,1 +2826,1 @@\n-  if (can_reshape && !in(0)->is_Loop()) {\n+  if (can_reshape && !in(0)->is_Region()) {\n","filename":"src\/hotspot\/share\/opto\/cfgnode.cpp","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -788,2 +788,6 @@\n-    _stress_seed = FLAG_IS_DEFAULT(StressSeed) ?\n-      static_cast<uint>(Ticks::now().nanoseconds()) : StressSeed;\n+    if (FLAG_IS_DEFAULT(StressSeed) || (FLAG_IS_ERGO(StressSeed) && RepeatCompilation)) {\n+      _stress_seed = static_cast<uint>(Ticks::now().nanoseconds());\n+      FLAG_SET_ERGO(StressSeed, _stress_seed);\n+    } else {\n+      _stress_seed = StressSeed;\n+    }\n@@ -1395,1 +1399,1 @@\n-          offset < k->size_helper() * wordSize) {\n+          offset < k->layout_helper_size_in_bytes()) {\n@@ -1419,1 +1423,1 @@\n-    } else if (offset < 0 || offset >= k->size_helper() * wordSize) {\n+    } else if (offset < 0 || offset >= k->layout_helper_size_in_bytes()) {\n@@ -1429,0 +1433,1 @@\n+      assert(offset < canonical_holder->layout_helper_size_in_bytes(), \"\");\n@@ -1449,1 +1454,1 @@\n-                                   TypeKlassPtr::OBJECT->klass(),\n+                                   TypeInstKlassPtr::OBJECT->klass(),\n@@ -1496,1 +1501,3 @@\n-    case Type::KlassPtr: tj = TypeKlassPtr::OBJECT; break;\n+    case Type::KlassPtr:\n+    case Type::AryKlassPtr:\n+    case Type::InstKlassPtr: tj = TypeInstKlassPtr::OBJECT; break;\n@@ -1714,1 +1721,1 @@\n-          tinst->offset() >= (tinst->klass()->as_instance_klass()->size_helper() * wordSize)) {\n+          tinst->offset() >= (tinst->klass()->as_instance_klass()->layout_helper_size_in_bytes())) {\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":14,"deletions":7,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -140,1 +140,1 @@\n-      } else if (should_delay_vector_inlining(callee, jvms)) {\n+      } else if (IncrementalInline && should_delay_vector_inlining(callee, jvms)) {\n@@ -934,1 +934,1 @@\n-    ex_klass_node = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+    ex_klass_node = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n@@ -943,1 +943,1 @@\n-      ex_klass_node = new PhiNode(ex_node->in(0), TypeKlassPtr::OBJECT);\n+      ex_klass_node = new PhiNode(ex_node->in(0), TypeInstKlassPtr::OBJECT);\n@@ -952,1 +952,1 @@\n-        Node* k = _gvn.transform( LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+        Node* k = _gvn.transform( LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n@@ -955,1 +955,1 @@\n-      _gvn.set_type(ex_klass_node, TypeKlassPtr::OBJECT);\n+      _gvn.set_type(ex_klass_node, TypeInstKlassPtr::OBJECT);\n","filename":"src\/hotspot\/share\/opto\/doCall.cpp","additions":5,"deletions":5,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -123,2 +123,2 @@\n-  GrowableArray<Node*> storestore_worklist;\n-  GrowableArray<ArrayCopyNode*> arraycopy_worklist;\n+  GrowableArray<MemBarStoreStoreNode*> storestore_worklist;\n+  GrowableArray<ArrayCopyNode*>  arraycopy_worklist;\n@@ -130,0 +130,1 @@\n+  GrowableArray<MergeMemNode*>   mergemem_worklist;\n@@ -175,16 +176,25 @@\n-    if (n->is_MergeMem()) {\n-      \/\/ Collect all MergeMem nodes to add memory slices for\n-      \/\/ scalar replaceable objects in split_unique_types().\n-      _mergemem_worklist.append(n->as_MergeMem());\n-    } else if (OptimizePtrCompare && n->is_Cmp() &&\n-               (n->Opcode() == Op_CmpP || n->Opcode() == Op_CmpN)) {\n-      \/\/ Collect compare pointers nodes.\n-      ptr_cmp_worklist.append(n);\n-    } else if (n->is_MemBarStoreStore()) {\n-      \/\/ Collect all MemBarStoreStore nodes so that depending on the\n-      \/\/ escape status of the associated Allocate node some of them\n-      \/\/ may be eliminated.\n-      storestore_worklist.append(n);\n-    } else if (n->is_MemBar() && (n->Opcode() == Op_MemBarRelease) &&\n-               (n->req() > MemBarNode::Precedent)) {\n-      record_for_optimizer(n);\n+    \/\/ Collect some interesting nodes for futher use.\n+    switch (n->Opcode()) {\n+      case Op_MergeMem:\n+        \/\/ Collect all MergeMem nodes to add memory slices for\n+        \/\/ scalar replaceable objects in split_unique_types().\n+        mergemem_worklist.append(n->as_MergeMem());\n+        break;\n+      case Op_CmpP:\n+      case Op_CmpN:\n+        \/\/ Collect compare pointers nodes.\n+        if (OptimizePtrCompare) {\n+          ptr_cmp_worklist.append(n);\n+        }\n+        break;\n+      case Op_MemBarStoreStore:\n+        \/\/ Collect all MemBarStoreStore nodes so that depending on the\n+        \/\/ escape status of the associated Allocate node some of them\n+        \/\/ may be eliminated.\n+        storestore_worklist.append(n->as_MemBarStoreStore());\n+        break;\n+      case Op_MemBarRelease:\n+        if (n->req() > MemBarNode::Precedent) {\n+          record_for_optimizer(n);\n+        }\n+        break;\n@@ -192,3 +202,4 @@\n-    } else if (n->is_AddP()) {\n-      \/\/ Collect address nodes for graph verification.\n-      addp_worklist.append(n);\n+      case Op_AddP:\n+        \/\/ Collect address nodes for graph verification.\n+        addp_worklist.append(n);\n+        break;\n@@ -196,4 +207,8 @@\n-    } else if (n->is_ArrayCopy()) {\n-      \/\/ Keep a list of ArrayCopy nodes so if one of its input is non\n-      \/\/ escaping, we can record a unique type\n-      arraycopy_worklist.append(n->as_ArrayCopy());\n+      case Op_ArrayCopy:\n+        \/\/ Keep a list of ArrayCopy nodes so if one of its input is non\n+        \/\/ escaping, we can record a unique type\n+        arraycopy_worklist.append(n->as_ArrayCopy());\n+        break;\n+      default:\n+        \/\/ not interested now, ignore...\n+        break;\n@@ -205,1 +220,1 @@\n-    if (n-> is_SafePoint()) {\n+    if (n->is_SafePoint()) {\n@@ -316,1 +331,1 @@\n-    split_unique_types(alloc_worklist, arraycopy_worklist);\n+    split_unique_types(alloc_worklist, arraycopy_worklist, mergemem_worklist);\n@@ -526,2 +541,1 @@\n-      add_local_var_and_edge(n, PointsToNode::NoEscape,\n-                             n->in(1), delayed_worklist);\n+      add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(1), delayed_worklist);\n@@ -596,2 +610,1 @@\n-        add_local_var_and_edge(n, PointsToNode::NoEscape,\n-                               n->in(0), delayed_worklist);\n+        add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(0), delayed_worklist);\n@@ -606,2 +619,1 @@\n-        add_local_var_and_edge(n, PointsToNode::GlobalEscape,\n-                               n->in(TypeFunc::Parms), delayed_worklist);\n+        add_local_var_and_edge(n, PointsToNode::GlobalEscape, n->in(TypeFunc::Parms), delayed_worklist);\n@@ -652,11 +664,0 @@\n-#ifdef ASSERT\n-#define ELSE_FAIL(name)                               \\\n-      \/* Should not be called for not pointer type. *\/  \\\n-      n->dump(1);                                       \\\n-      assert(false, name);                              \\\n-      break;\n-#else\n-#define ELSE_FAIL(name) \\\n-      break;\n-#endif\n-\n@@ -698,2 +699,1 @@\n-      add_local_var_and_edge(n, PointsToNode::NoEscape,\n-                             n->in(1), NULL);\n+      add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(1), NULL);\n@@ -723,7 +723,3 @@\n-      const Type* t = _igvn->type(n);\n-      if (t->make_ptr() != NULL) {\n-        Node* adr = n->in(MemNode::Address);\n-        add_local_var_and_edge(n, PointsToNode::NoEscape, adr, NULL);\n-        break;\n-      }\n-      ELSE_FAIL(\"Op_LoadP\");\n+      assert(_igvn->type(n)->make_ptr() != NULL, \"Unexpected node type\");\n+      add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(MemNode::Address), NULL);\n+      break;\n@@ -734,14 +730,5 @@\n-      const Type* t = n->as_Phi()->type();\n-      if (t->make_ptr() != NULL) {\n-        for (uint i = 1; i < n->req(); i++) {\n-          Node* in = n->in(i);\n-          if (in == NULL) {\n-            continue;  \/\/ ignore NULL\n-          }\n-          Node* uncast_in = in->uncast();\n-          if (uncast_in->is_top() || uncast_in == n) {\n-            continue;  \/\/ ignore top or inputs which go back this node\n-          }\n-          PointsToNode* ptn = ptnode_adr(in->_idx);\n-          assert(ptn != NULL, \"node should be registered\");\n-          add_edge(n_ptn, ptn);\n+      assert(n->as_Phi()->type()->make_ptr() != NULL, \"Unexpected node type\");\n+      for (uint i = 1; i < n->req(); i++) {\n+        Node* in = n->in(i);\n+        if (in == NULL) {\n+          continue;  \/\/ ignore NULL\n@@ -749,1 +736,7 @@\n-        break;\n+        Node* uncast_in = in->uncast();\n+        if (uncast_in->is_top() || uncast_in == n) {\n+          continue;  \/\/ ignore top or inputs which go back this node\n+        }\n+        PointsToNode* ptn = ptnode_adr(in->_idx);\n+        assert(ptn != NULL, \"node should be registered\");\n+        add_edge(n_ptn, ptn);\n@@ -751,1 +744,1 @@\n-      ELSE_FAIL(\"Op_Phi\");\n+      break;\n@@ -755,8 +748,4 @@\n-      if (n->as_Proj()->_con >= TypeFunc::Parms && n->in(0)->is_Call() &&\n-          (n->in(0)->as_Call()->returns_pointer()|| n->bottom_type()->isa_ptr())) {\n-        assert((n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->as_Call()->returns_pointer()) ||\n-               n->in(0)->as_Call()->tf()->returns_inline_type_as_fields(), \"what kind of oop return is it?\");\n-        add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(0), NULL);\n-        break;\n-      }\n-      ELSE_FAIL(\"Op_Proj\");\n+      assert((n->as_Proj()->_con == TypeFunc::Parms && n->in(0)->as_Call()->returns_pointer()) ||\n+             n->in(0)->as_Call()->tf()->returns_inline_type_as_fields(), \"what kind of oop return is it?\");\n+      add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(0), NULL);\n+      break;\n@@ -766,8 +755,5 @@\n-      if (n->req() > TypeFunc::Parms &&\n-          _igvn->type(n->in(TypeFunc::Parms))->isa_oopptr()) {\n-        \/\/ Treat Return value as LocalVar with GlobalEscape escape state.\n-        add_local_var_and_edge(n, PointsToNode::GlobalEscape,\n-                               n->in(TypeFunc::Parms), NULL);\n-        break;\n-      }\n-      ELSE_FAIL(\"Op_Return\");\n+      assert(n->req() > TypeFunc::Parms && _igvn->type(n->in(TypeFunc::Parms))->isa_oopptr(),\n+             \"Unexpected node type\");\n+      \/\/ Treat Return value as LocalVar with GlobalEscape escape state.\n+      add_local_var_and_edge(n, PointsToNode::GlobalEscape, n->in(TypeFunc::Parms), NULL);\n+      break;\n@@ -775,4 +761,0 @@\n-    case Op_StoreP:\n-    case Op_StoreN:\n-    case Op_StoreNKlass:\n-    case Op_StorePConditional:\n@@ -781,0 +763,6 @@\n+    case Op_GetAndSetP:\n+    case Op_GetAndSetN:{\n+      assert(_igvn->type(n)->make_ptr() != NULL, \"Unexpected node type\");\n+      add_local_var_and_edge(n, PointsToNode::NoEscape, n->in(MemNode::Address), NULL);\n+      \/\/ fall-through\n+    }\n@@ -785,6 +773,6 @@\n-    case Op_GetAndSetP:\n-    case Op_GetAndSetN: {\n-      if (add_final_edges_unsafe_access(n, opcode)) {\n-        break;\n-      }\n-      ELSE_FAIL(\"Op_StoreP\");\n+    case Op_StoreP:\n+    case Op_StoreN:\n+    case Op_StoreNKlass:\n+    case Op_StorePConditional:{\n+      add_final_edges_unsafe_access(n, opcode);\n+      break;\n@@ -881,5 +869,0 @@\n-  if (opcode == Op_GetAndSetP || opcode == Op_GetAndSetN ||\n-      opcode == Op_CompareAndExchangeN || opcode == Op_CompareAndExchangeP) {\n-    add_local_var_and_edge(n, PointsToNode::NoEscape, adr, NULL);\n-  }\n-\n@@ -914,0 +897,4 @@\n+#ifdef ASSERT\n+  n->dump(1);\n+  assert(false, \"not unsafe\");\n+#endif\n@@ -2020,1 +2007,1 @@\n-                                           GrowableArray<Node*>& storestore_worklist) {\n+                                           GrowableArray<MemBarStoreStoreNode*>& storestore_worklist) {\n@@ -2072,1 +2059,0 @@\n-    assert(storestore->is_MemBarStoreStore(), \"\");\n@@ -2092,0 +2078,1 @@\n+  assert(n->Opcode() == Op_CmpN || n->Opcode() == Op_CmpP, \"must be\");\n@@ -3147,1 +3134,3 @@\n-void ConnectionGraph::split_unique_types(GrowableArray<Node *>  &alloc_worklist, GrowableArray<ArrayCopyNode*> &arraycopy_worklist) {\n+void ConnectionGraph::split_unique_types(GrowableArray<Node *>  &alloc_worklist,\n+                                         GrowableArray<ArrayCopyNode*> &arraycopy_worklist,\n+                                         GrowableArray<MergeMemNode*> &mergemem_worklist) {\n@@ -3202,1 +3191,1 @@\n-              igvn->type(alloc->in(AllocateNode::KlassNode)) != TypeKlassPtr::OBJECT)) {\n+              igvn->type(alloc->in(AllocateNode::KlassNode)) != TypeInstKlassPtr::OBJECT)) {\n@@ -3393,1 +3382,1 @@\n-        assert(_mergemem_worklist.contains(use->as_MergeMem()), \"EA: missing MergeMem node in the worklist\");\n+        assert(mergemem_worklist.contains(use->as_MergeMem()), \"EA: missing MergeMem node in the worklist\");\n@@ -3399,1 +3388,1 @@\n-          assert(_mergemem_worklist.contains(m->as_MergeMem()), \"EA: missing MergeMem node in the worklist\");\n+          assert(mergemem_worklist.contains(m->as_MergeMem()), \"EA: missing MergeMem node in the worklist\");\n@@ -3538,1 +3527,1 @@\n-        assert(_mergemem_worklist.contains(use->as_MergeMem()), \"EA: missing MergeMem node in the worklist\");\n+        assert(mergemem_worklist.contains(use->as_MergeMem()), \"EA: missing MergeMem node in the worklist\");\n@@ -3570,1 +3559,1 @@\n-  uint length = _mergemem_worklist.length();\n+  uint length = mergemem_worklist.length();\n@@ -3572,1 +3561,1 @@\n-    MergeMemNode* nmm = _mergemem_worklist.at(next);\n+    MergeMemNode* nmm = mergemem_worklist.at(next);\n","filename":"src\/hotspot\/share\/opto\/escape.cpp","additions":98,"deletions":109,"binary":false,"changes":207,"status":"modified"},{"patch":"@@ -1196,1 +1196,1 @@\n-  return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+  return _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n@@ -1820,1 +1820,1 @@\n-Node* GraphKit::load_array_element(Node* ctl, Node* ary, Node* idx, const TypeAryPtr* arytype) {\n+Node* GraphKit::load_array_element(Node* ary, Node* idx, const TypeAryPtr* arytype, bool set_ctrl) {\n@@ -1828,1 +1828,2 @@\n-  Node* ld = make_load(ctl, adr, elemtype, elembt, arytype, MemNode::unordered);\n+  Node* ld = access_load_at(ary, adr, arytype, elemtype, elembt,\n+                            IN_HEAP | IS_ARRAY | (set_ctrl ? C2_CONTROL_DEPENDENT_LOAD : 0));\n@@ -2615,1 +2616,2 @@\n-                                  Node* parm6, Node* parm7) {\n+                                  Node* parm6, Node* parm7,\n+                                  Node* parm8) {\n@@ -2662,1 +2664,2 @@\n-  \/* close each nested if ===> *\/  } } } } } } } }\n+  if (parm8 != NULL) { call->init_req(TypeFunc::Parms+8, parm8);\n+  \/* close each nested if ===> *\/  } } } } } } } } }\n@@ -2994,1 +2997,1 @@\n-  Node *nkls = gvn.transform(LoadKlassNode::make(gvn, NULL, kmem, p2, gvn.type(p2)->is_ptr(), TypeKlassPtr::OBJECT_OR_NULL));\n+  Node *nkls = gvn.transform(LoadKlassNode::make(gvn, NULL, kmem, p2, gvn.type(p2)->is_ptr(), TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -4192,1 +4195,1 @@\n-  if (!tklass)  tklass = TypeKlassPtr::OBJECT;\n+  if (!tklass)  tklass = TypeInstKlassPtr::OBJECT;\n@@ -4711,1 +4714,1 @@\n-  Node* ch = load_array_element(control(), src, i_byte, TypeAryPtr::BYTES);\n+  Node* ch = load_array_element(src, i_byte, TypeAryPtr::BYTES, \/* set_ctrl *\/ true);\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -674,1 +674,1 @@\n-  Node* load_array_element(Node* ctl, Node* ary, Node* idx, const TypeAryPtr* arytype);\n+  Node* load_array_element(Node* ary, Node* idx, const TypeAryPtr* arytype, bool set_ctrl);\n@@ -835,1 +835,2 @@\n-                          Node* parm6 = NULL, Node* parm7 = NULL);\n+                          Node* parm6 = NULL, Node* parm7 = NULL,\n+                          Node* parm8 = NULL);\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -602,1 +602,3 @@\n-    return inline_encodeISOArray();\n+    return inline_encodeISOArray(false);\n+  case vmIntrinsics::_encodeAsciiArray:\n+    return inline_encodeISOArray(true);\n@@ -3044,1 +3046,1 @@\n-                                                 TypeRawPtr::BOTTOM, TypeKlassPtr::OBJECT_OR_NULL));\n+                                                 TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -3074,1 +3076,1 @@\n-                                                   TypeRawPtr::BOTTOM, TypeKlassPtr::OBJECT_OR_NULL));\n+                                                   TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -3158,1 +3160,1 @@\n-  const TypeKlassPtr*  kls_type = TypeKlassPtr::OBJECT_OR_NULL;\n+  const TypeKlassPtr*  kls_type = TypeInstKlassPtr::OBJECT_OR_NULL;\n@@ -3348,1 +3350,1 @@\n-    kls = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeRawPtr::BOTTOM, TypeKlassPtr::OBJECT_OR_NULL));\n+    kls = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), p, TypeRawPtr::BOTTOM, TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -3557,1 +3559,1 @@\n-  const TypeKlassPtr* kls_type = TypeKlassPtr::OBJECT_OR_NULL;\n+  const TypeKlassPtr* kls_type = TypeInstKlassPtr::OBJECT_OR_NULL;\n@@ -4430,0 +4432,23 @@\n+\n+static bool has_wide_mem(PhaseGVN& gvn, Node* addr, Node* base) {\n+  const TypeAryPtr* addr_t = gvn.type(addr)->isa_aryptr();\n+  const Type*       base_t = gvn.type(base);\n+\n+  bool in_native = (base_t == TypePtr::NULL_PTR);\n+  bool in_heap   = !TypePtr::NULL_PTR->higher_equal(base_t);\n+  bool is_mixed  = !in_heap && !in_native;\n+\n+  if (is_mixed) {\n+    return true; \/\/ mixed accesses can touch both on-heap and off-heap memory\n+  }\n+  if (in_heap) {\n+    bool is_prim_array = (addr_t != NULL) && (addr_t->elem() != Type::BOTTOM);\n+    if (!is_prim_array) {\n+      \/\/ Though Unsafe.copyMemory() ensures at runtime for on-heap accesses that base is a primitive array,\n+      \/\/ there's not enough type information available to determine proper memory slice for it.\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n@@ -4437,5 +4462,5 @@\n-  Node* src_ptr =         argument(1);   \/\/ type: oop\n-  Node* src_off = ConvL2X(argument(2));  \/\/ type: long\n-  Node* dst_ptr =         argument(4);   \/\/ type: oop\n-  Node* dst_off = ConvL2X(argument(5));  \/\/ type: long\n-  Node* size    = ConvL2X(argument(7));  \/\/ type: long\n+  Node* src_base =         argument(1);  \/\/ type: oop\n+  Node* src_off  = ConvL2X(argument(2)); \/\/ type: long\n+  Node* dst_base =         argument(4);  \/\/ type: oop\n+  Node* dst_off  = ConvL2X(argument(5)); \/\/ type: long\n+  Node* size     = ConvL2X(argument(7)); \/\/ type: long\n@@ -4446,6 +4471,2 @@\n-  Node* src = make_unsafe_address(src_ptr, src_off);\n-  Node* dst = make_unsafe_address(dst_ptr, dst_off);\n-\n-  \/\/ Conservatively insert a memory barrier on all memory slices.\n-  \/\/ Do not let writes of the copy source or destination float below the copy.\n-  insert_mem_bar(Op_MemBarCPUOrder);\n+  Node* src_addr = make_unsafe_address(src_base, src_off);\n+  Node* dst_addr = make_unsafe_address(dst_base, dst_off);\n@@ -4461,0 +4482,15 @@\n+  int flags = RC_LEAF | RC_NO_FP;\n+\n+  const TypePtr* dst_type = TypePtr::BOTTOM;\n+\n+  \/\/ Adjust memory effects of the runtime call based on input values.\n+  if (!has_wide_mem(_gvn, src_addr, src_base) &&\n+      !has_wide_mem(_gvn, dst_addr, dst_base)) {\n+    dst_type = _gvn.type(dst_addr)->is_ptr(); \/\/ narrow out memory\n+\n+    const TypePtr* src_type = _gvn.type(src_addr)->is_ptr();\n+    if (C->get_alias_index(src_type) == C->get_alias_index(dst_type)) {\n+      flags |= RC_NARROW_MEM; \/\/ narrow in memory\n+    }\n+  }\n+\n@@ -4462,1 +4498,1 @@\n-  make_runtime_call(RC_LEAF|RC_NO_FP,\n+  make_runtime_call(flags,\n@@ -4466,2 +4502,2 @@\n-                    TypeRawPtr::BOTTOM,\n-                    src, dst, size XTOP);\n+                    dst_type,\n+                    src_addr, dst_addr, size XTOP);\n@@ -4471,3 +4507,0 @@\n-  \/\/ Do not let reads of the copy destination float above the copy.\n-  insert_mem_bar(Op_MemBarCPUOrder);\n-\n@@ -5247,2 +5280,2 @@\n-\/\/ encode char[] to byte[] in ISO_8859_1\n-bool LibraryCallKit::inline_encodeISOArray() {\n+\/\/ encode char[] to byte[] in ISO_8859_1 or ASCII\n+bool LibraryCallKit::inline_encodeISOArray(bool ascii) {\n@@ -5283,1 +5316,1 @@\n-  Node* enc = new EncodeISOArrayNode(control(), memory(mtype), src_start, dst_start, length);\n+  Node* enc = new EncodeISOArrayNode(control(), memory(mtype), src_start, dst_start, length, ascii);\n@@ -6369,1 +6402,1 @@\n-  const TypeOopPtr* xtype = aklass->as_instance_type();\n+  const TypeOopPtr* xtype = aklass->as_instance_type()->cast_to_ptr_type(TypePtr::NotNull);\n@@ -6457,1 +6490,1 @@\n-  const TypeOopPtr* xtype = aklass->as_instance_type();\n+  const TypeOopPtr* xtype = aklass->as_instance_type()->cast_to_ptr_type(TypePtr::NotNull);\n@@ -6528,1 +6561,1 @@\n-  const TypeOopPtr* xtype = aklass->as_instance_type();\n+  const TypeOopPtr* xtype = aklass->as_instance_type()->cast_to_ptr_type(TypePtr::NotNull);\n@@ -6568,1 +6601,1 @@\n-  Node* objAESCryptKey = load_array_element(control(), objSessionK, intcon(0), TypeAryPtr::OOPS);\n+  Node* objAESCryptKey = load_array_element(objSessionK, intcon(0), TypeAryPtr::OOPS, \/* set_ctrl *\/ true);\n@@ -7046,1 +7079,1 @@\n-  const TypeOopPtr* xtype = aklass->as_instance_type();\n+  const TypeOopPtr* xtype = aklass->as_instance_type()->cast_to_ptr_type(TypePtr::NotNull);\n@@ -7154,0 +7187,17 @@\n+  ciKlass* klass = ciTypeArrayKlass::make(T_LONG);\n+  Node* klass_node = makecon(TypeKlassPtr::make(klass));\n+\n+  \/\/ Does this target support this intrinsic?\n+  if (Matcher::htbl_entries == -1) return false;\n+\n+  Node* subkeyHtbl_48_entries_start;\n+  if (Matcher::htbl_entries != 0) {\n+    \/\/ new array to hold 48 computed htbl entries\n+    Node* subkeyHtbl_48_entries = new_array(klass_node, intcon(Matcher::htbl_entries), 0);\n+    if (subkeyHtbl_48_entries == NULL) return false;\n+    subkeyHtbl_48_entries_start = array_element_address(subkeyHtbl_48_entries, intcon(0), T_LONG);\n+  } else {\n+    \/\/ This target doesn't need the extra-large Htbl.\n+    subkeyHtbl_48_entries_start = ConvL2X(intcon(0));\n+  }\n+\n@@ -7158,1 +7208,1 @@\n-                               in_start, len, ct_start, out_start, k_start, state_start, subkeyHtbl_start, cnt_start);\n+                               in_start, len, ct_start, out_start, k_start, state_start, subkeyHtbl_start, subkeyHtbl_48_entries_start, cnt_start);\n","filename":"src\/hotspot\/share\/opto\/library_call.cpp","additions":82,"deletions":32,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -321,1 +321,1 @@\n-  bool inline_encodeISOArray();\n+  bool inline_encodeISOArray(bool ascii);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -743,1 +743,1 @@\n-  bool is_range_check_if(IfNode *iff, PhaseIdealLoop *phase, Invariance& invar) const;\n+  bool is_range_check_if(IfNode *iff, PhaseIdealLoop *phase, Invariance& invar DEBUG_ONLY(COMMA ProjNode *predicate_proj)) const;\n@@ -1281,0 +1281,7 @@\n+  \/\/ Enum to determine the action to be performed in create_new_if_for_predicate() when processing phis of UCT regions.\n+  enum class UnswitchingAction {\n+    None,            \/\/ No special action.\n+    FastLoopCloning, \/\/ Need to clone nodes for the fast loop.\n+    SlowLoopRewiring \/\/ Need to rewire nodes for the slow loop.\n+  };\n+\n@@ -1283,1 +1290,5 @@\n-                                        int opcode, bool if_cont_is_true_proj = true);\n+                                        int opcode, bool if_cont_is_true_proj = true, Node_List* old_new = NULL,\n+                                        UnswitchingAction unswitching_action = UnswitchingAction::None);\n+\n+  \/\/ Clone data nodes for the fast loop while creating a new If with create_new_if_for_predicate.\n+  Node* clone_data_nodes_for_fast_loop(Node* phi_input, ProjNode* uncommon_proj, Node* if_uct, Node_List* old_new);\n@@ -1571,2 +1582,3 @@\n-  void clone_predicates_to_unswitched_loop(IdealLoopTree* loop, const Node_List& old_new, ProjNode*& iffast_pred, ProjNode*& ifslow_pred);\n-  ProjNode* clone_predicate_to_unswitched_loop(ProjNode* predicate_proj, Node* new_entry, Deoptimization::DeoptReason reason);\n+  void clone_predicates_to_unswitched_loop(IdealLoopTree* loop, Node_List& old_new, ProjNode*& iffast_pred, ProjNode*& ifslow_pred);\n+  ProjNode* clone_predicate_to_unswitched_loop(ProjNode* predicate_proj, Node* new_entry, Deoptimization::DeoptReason reason,\n+                                               Node_List* old_new = NULL);\n@@ -1577,1 +1589,1 @@\n-  void check_created_predicate_for_unswitching(const Node* new_entry) const PRODUCT_RETURN;\n+  static void check_created_predicate_for_unswitching(const Node* new_entry) PRODUCT_RETURN;\n","filename":"src\/hotspot\/share\/opto\/loopnode.hpp","additions":17,"deletions":5,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -1004,1 +1004,0 @@\n-    ResourceMark rm;\n@@ -1617,1 +1616,2 @@\n-      n->Opcode() != Op_Opaque4) {\n+      n->Opcode() != Op_Opaque4 &&\n+      !n->is_Type()) {\n@@ -1620,0 +1620,10 @@\n+\n+    if (n->in(0) != NULL) {\n+      IdealLoopTree* loop_ctrl = get_loop(n->in(0));\n+      if (n_loop != loop_ctrl && n_loop->is_member(loop_ctrl)) {\n+        \/\/ n has a control input inside a loop but get_ctrl() is member of an outer loop. This could happen, for example,\n+        \/\/ for Div nodes inside a loop (control input inside loop) without a use except for an UCT (outside the loop).\n+        \/\/ Rewire control of n to right outside of the loop, regardless if its input(s) are later sunk or not.\n+        _igvn.replace_input_of(n, 0, place_outside_loop(n_ctrl, loop_ctrl));\n+      }\n+    }\n","filename":"src\/hotspot\/share\/opto\/loopopts.cpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -700,0 +700,1 @@\n+#ifndef _LP64\n@@ -718,0 +719,1 @@\n+#endif\n","filename":"src\/hotspot\/share\/opto\/machnode.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -952,2 +952,1 @@\n-  bool returns_long() const { return tf()->return_type() == T_LONG; }\n-  bool return_value_is_used() const;\n+  NOT_LP64(bool return_value_is_used() const;)\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2499,1 +2499,1 @@\n-    Node* klass_node = transform_later(new CheckCastPPNode(allocation_ctl, rawklassptr, TypeKlassPtr::OBJECT_OR_NULL));\n+    Node* klass_node = transform_later(new CheckCastPPNode(allocation_ctl, rawklassptr, TypeInstKlassPtr::OBJECT_OR_NULL));\n@@ -2668,1 +2668,1 @@\n-      subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+      subklass = _igvn.transform(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), k_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n@@ -2734,1 +2734,1 @@\n-        Node* klass = _igvn.transform(LoadKlassNode::make(_igvn, ctrl, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+        Node* klass = _igvn.transform(LoadKlassNode::make(_igvn, ctrl, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n@@ -2762,1 +2762,1 @@\n-      Node* klass = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+      Node* klass = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":4,"deletions":4,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -293,1 +293,1 @@\n-  Node* klass = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeKlassPtr::OBJECT));\n+  Node* klass = transform_later(LoadKlassNode::make(_igvn, NULL, C->immutable_memory(), klass_adr, TypeInstPtr::KLASS, TypeInstKlassPtr::OBJECT));\n","filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1671,1 +1671,8 @@\n-        x->set_req(0, in);\n+        if (mem->is_Phi() && (mem->in(0) == region) && mem->in(i)->in(0) != NULL &&\n+            MemNode::all_controls_dominate(address, region)) {\n+          \/\/ Enable other optimizations such as loop predication which does not work\n+          \/\/ if we directly pin the node to node `in`\n+          x->set_req(0, mem->in(i)->in(0)); \/\/ Use same control as memory\n+        } else {\n+          x->set_req(0, in);\n+        }\n@@ -2039,1 +2046,1 @@\n-  } else if (tp->base() == Type::KlassPtr) {\n+  } else if (tp->base() == Type::KlassPtr || tp->base() == Type::InstKlassPtr || tp->base() == Type::AryKlassPtr) {\n@@ -2431,1 +2438,1 @@\n-      return TypeKlassPtr::make(TypePtr::NotNull, ik, Type::Offset(0), tinst->flatten_array());\n+      return TypeInstKlassPtr::make(TypePtr::NotNull, ik, Type::Offset(0), tinst->flatten_array());\n@@ -2464,1 +2471,1 @@\n-        return TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0), false, tary->is_not_flat(), tary->is_not_null_free());\n+        return TypeAryKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0), tary->is_not_flat(), tary->is_not_null_free(), tary->is_null_free());\n@@ -2491,1 +2498,1 @@\n-      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), \/* flatten_array= *\/ true);\n+      return TypeInstKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), \/* flatten_array= *\/ true);\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":12,"deletions":5,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -292,1 +292,0 @@\n-  void pin() { _control_dependency = Pinned; }\n@@ -536,1 +535,1 @@\n-                    const TypeKlassPtr* tk = TypeKlassPtr::OBJECT);\n+                    const TypeKlassPtr* tk = TypeInstKlassPtr::OBJECT);\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -62,3 +62,26 @@\n-  const Type *t1 = phase->type( in(1) );\n-  const Type *t2 = phase->type( in(2) );\n-  Node *progress = NULL;        \/\/ Progress flag\n+  Node* in1 = in(1);\n+  Node* in2 = in(2);\n+  Node* progress = NULL;        \/\/ Progress flag\n+\n+  \/\/ This code is used by And nodes too, but some conversions are\n+  \/\/ only valid for the actual Mul nodes.\n+  uint op = Opcode();\n+  bool real_mul = (op == Op_MulI) || (op == Op_MulL) ||\n+                  (op == Op_MulF) || (op == Op_MulD);\n+\n+  \/\/ Convert \"(-a)*(-b)\" into \"a*b\".\n+  if (real_mul && in1->is_Sub() && in2->is_Sub()) {\n+    if (phase->type(in1->in(1))->is_zero_type() &&\n+        phase->type(in2->in(1))->is_zero_type()) {\n+      set_req(1, in1->in(2));\n+      set_req(2, in2->in(2));\n+      PhaseIterGVN* igvn = phase->is_IterGVN();\n+      if (igvn) {\n+        igvn->_worklist.push(in1);\n+        igvn->_worklist.push(in2);\n+      }\n+      in1 = in(1);\n+      in2 = in(2);\n+      progress = this;\n+    }\n+  }\n@@ -67,2 +90,0 @@\n-  Node *in1 = in(1);\n-  Node *in2 = in(2);\n@@ -86,0 +107,2 @@\n+      in1 = in(1);\n+      in2 = in(2);\n@@ -90,0 +113,3 @@\n+  const Type* t1 = phase->type(in1);\n+  const Type* t2 = phase->type(in2);\n+\n@@ -107,1 +133,0 @@\n-  uint op = Opcode();\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":31,"deletions":6,"binary":false,"changes":37,"status":"modified"},{"patch":"@@ -2177,1 +2177,4 @@\n-  if (C->max_vector_size() > 8)\n+  \/\/ And when the scalable vector register is used, we may spill\/unspill\n+  \/\/ the whole reg regardless of the max vector size.\n+  if (C->max_vector_size() > 8 ||\n+      (C->max_vector_size() > 0 && Matcher::supports_scalable_vector())) {\n@@ -2179,0 +2182,1 @@\n+  }\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -511,1 +511,1 @@\n-      } else {\n+      } else if (!slow_ctl->is_top()) {\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -197,1 +197,1 @@\n-    } else if (!too_many_traps(Deoptimization::Reason_array_check) && tak != TypeKlassPtr::OBJECT) {\n+    } else if (!too_many_traps(Deoptimization::Reason_array_check) && tak != TypeInstKlassPtr::OBJECT) {\n","filename":"src\/hotspot\/share\/opto\/parseHelper.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -967,1 +967,1 @@\n-  int num_args = 8;\n+  int num_args = 9;\n@@ -978,0 +978,1 @@\n+  fields[argp++] = TypePtr::NOTNULL; \/\/ long[] avx512_subkeyHtbl newly created\n","filename":"src\/hotspot\/share\/opto\/runtime.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -68,1 +68,2 @@\n-    StringNullCheckMode\n+    StringNullCheckMode,\n+    NegativeIntCheckMode\n@@ -125,0 +126,1 @@\n+\n@@ -128,0 +130,5 @@\n+\n+  void push_negative_int_check(Node* value) {\n+    push(value, NegativeIntCheckMode);\n+  }\n+\n@@ -131,0 +138,1 @@\n+\n@@ -280,0 +288,14 @@\n+    } else if (n->is_Region()) {\n+      Node* iff = n->in(1)->in(0);\n+      assert(n->req() == 3 && n->in(2)->in(0) == iff, \"not a diamond\");\n+      assert(iff->is_If(), \"no if for the diamond\");\n+      Node* bol = iff->in(1);\n+      assert(bol->is_Bool(), \"unexpected if shape\");\n+      Node* cmp = bol->in(1);\n+      assert(cmp->is_Cmp(), \"unexpected if shape\");\n+      if (cmp->in(1)->is_top() || cmp->in(2)->is_top()) {\n+        \/\/ This region should lose its Phis and be optimized out by igvn but there's a chance the if folds to top first\n+        \/\/ which then causes a reachable part of the graph to become dead.\n+        Compile* C = _stringopts->C;\n+        C->gvn_replace_by(n, iff->in(0));\n+      }\n@@ -491,1 +513,2 @@\n-                  alloc->jvms()->dump_spec(tty); tty->cr();\n+                  alloc->jvms()->dump_spec(tty);\n+                  tty->cr();\n@@ -498,0 +521,21 @@\n+            } else if (sig == ciSymbols::int_void_signature()) {\n+              \/\/ StringBuilder(int) case.\n+              Node* parm = use->in(TypeFunc::Parms + 1);\n+              assert(parm != NULL, \"must exist\");\n+              const TypeInt* type = _gvn->type(parm)->is_int();\n+              if (type->_hi < 0) {\n+                \/\/ Initial capacity argument is always negative in which case StringBuilder(int) throws\n+                \/\/ a NegativeArraySizeException. Bail out from string opts.\n+#ifndef PRODUCT\n+                if (PrintOptimizeStringConcat) {\n+                  tty->print(\"giving up because a negative argument is passed to StringBuilder(int) which \"\n+                             \"throws a NegativeArraySizeException\");\n+                  alloc->jvms()->dump_spec(tty);\n+                  tty->cr();\n+                }\n+#endif\n+                return NULL;\n+              } else if (type->_lo < 0) {\n+                \/\/ Argument could be negative: We need a runtime check to throw NegativeArraySizeException in that case.\n+                sc->push_negative_int_check(parm);\n+              }\n@@ -1006,0 +1050,1 @@\n+        _control.push(ptr);\n@@ -1232,1 +1277,1 @@\n-    Node* value = kit.load_array_element(NULL, sizeTable, index, TypeAryPtr::INTS);\n+    Node* value = kit.load_array_element(sizeTable, index, TypeAryPtr::INTS, \/* set_ctrl *\/ false);\n@@ -1782,0 +1827,17 @@\n+      case StringConcat::NegativeIntCheckMode: {\n+        \/\/ Initial capacity argument might be negative in which case StringBuilder(int) throws\n+        \/\/ a NegativeArraySizeException. Insert a runtime check with an uncommon trap.\n+        const TypeInt* type = kit.gvn().type(arg)->is_int();\n+        assert(type->_hi >= 0 && type->_lo < 0, \"no runtime int check needed\");\n+        Node* p = __ Bool(__ CmpI(arg, kit.intcon(0)), BoolTest::ge);\n+        IfNode* iff = kit.create_and_map_if(kit.control(), p, PROB_MIN, COUNT_UNKNOWN);\n+        {\n+          \/\/ Negative int -> uncommon trap.\n+          PreserveJVMState pjvms(&kit);\n+          kit.set_control(__ IfFalse(iff));\n+          kit.uncommon_trap(Deoptimization::Reason_intrinsic,\n+                            Deoptimization::Action_maybe_recompile);\n+        }\n+        kit.set_control(__ IfTrue(iff));\n+        break;\n+      }\n@@ -1951,0 +2013,2 @@\n+          case StringConcat::NegativeIntCheckMode:\n+            break; \/\/ Nothing to do, was only needed to add a runtime check earlier.\n","filename":"src\/hotspot\/share\/opto\/stringopts.cpp","additions":67,"deletions":3,"binary":false,"changes":70,"status":"modified"},{"patch":"@@ -251,1 +251,1 @@\n-          Node* nkls = phase->transform(LoadKlassNode::make(*phase, NULL, C->immutable_memory(), p2, phase->type(p2)->is_ptr(), TypeKlassPtr::OBJECT_OR_NULL));\n+          Node* nkls = phase->transform(LoadKlassNode::make(*phase, NULL, C->immutable_memory(), p2, phase->type(p2)->is_ptr(), TypeInstKlassPtr::OBJECT_OR_NULL));\n","filename":"src\/hotspot\/share\/opto\/subtypenode.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -147,0 +147,2 @@\n+  { Bad,             T_METADATA,   \"instklass:\",    false, Op_RegP,              relocInfo::metadata_type },  \/\/ InstKlassPtr\n+  { Bad,             T_METADATA,   \"aryklass:\",     false, Op_RegP,              relocInfo::metadata_type },  \/\/ AryKlassPtr\n@@ -669,2 +671,2 @@\n-  TypeKlassPtr::OBJECT = TypeKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0));\n-  TypeKlassPtr::OBJECT_OR_NULL = TypeKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0));\n+  TypeInstKlassPtr::OBJECT = TypeInstKlassPtr::make(TypePtr::NotNull, current->env()->Object_klass(), Offset(0), false);\n+  TypeInstKlassPtr::OBJECT_OR_NULL = TypeInstKlassPtr::make(TypePtr::BotPTR, current->env()->Object_klass(), Offset(0), false);\n@@ -1005,0 +1007,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -1179,0 +1183,2 @@\n+    case Type::InstKlassPtr:\n+    case Type::AryKlassPtr:\n@@ -1266,0 +1272,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -1377,0 +1385,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -1548,0 +1558,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -1810,0 +1822,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -2506,0 +2520,1 @@\n+  case AnyPtr:\n@@ -2519,0 +2534,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -2842,0 +2859,3 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n+  case InlineType:\n@@ -3209,1 +3229,1 @@\n-const Type *TypeRawPtr::cast_to_ptr_type(PTR ptr) const {\n+const TypeRawPtr* TypeRawPtr::cast_to_ptr_type(PTR ptr) const {\n@@ -3253,0 +3273,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -3432,1 +3454,1 @@\n-const Type *TypeOopPtr::cast_to_ptr_type(PTR ptr) const {\n+const TypeOopPtr* TypeOopPtr::cast_to_ptr_type(PTR ptr) const {\n@@ -3455,7 +3477,3 @@\n-const TypeKlassPtr* TypeOopPtr::as_klass_type() const {\n-  ciKlass* k = klass();\n-  bool    xk = klass_is_exact();\n-  if (k == NULL)\n-    return TypeKlassPtr::OBJECT;\n-  else\n-    return TypeKlassPtr::make(xk? Constant: NotNull, k, Offset(0));\n+const TypeKlassPtr* TypeOopPtr::as_klass_type(bool try_for_exact) const {\n+  ShouldNotReachHere();\n+  return NULL;\n@@ -3494,0 +3512,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -3960,1 +3980,1 @@\n-const Type *TypeInstPtr::cast_to_ptr_type(PTR ptr) const {\n+const TypeInstPtr *TypeInstPtr::cast_to_ptr_type(PTR ptr) const {\n@@ -4062,0 +4082,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -4137,2 +4159,2 @@\n-    Offset off = meet_offset( tinst->offset() );\n-    PTR ptr = meet_ptr( tinst->ptr() );\n+    Offset off = meet_offset(tinst->offset());\n+    PTR ptr = meet_ptr(tinst->ptr());\n@@ -4142,12 +4164,1 @@\n-\n-    \/\/ Check for easy case; klasses are equal (and perhaps not loaded!)\n-    \/\/ If we have constants, then we created oops so classes are loaded\n-    \/\/ and we can handle the constants further down.  This case handles\n-    \/\/ both-not-loaded or both-loaded classes\n-    if (ptr != Constant && klass()->equals(tinst->klass()) && klass_is_exact() == tinst->klass_is_exact() &&\n-        flatten_array() == tinst->flatten_array()) {\n-      return make(ptr, klass(), klass_is_exact(), NULL, off, flatten_array(), instance_id, speculative, depth);\n-    }\n-\n-    \/\/ Classes require inspection in the Java klass hierarchy.  Must be loaded.\n-    ciKlass* this_klass  = this->klass();\n+    ciKlass* this_klass  = klass();\n@@ -4159,1 +4170,9 @@\n-    if (!tinst_klass->is_loaded() || !this_klass->is_loaded() ) {\n+\n+    ciKlass* res_klass = NULL;\n+    bool res_xk = false;\n+    bool res_flatten_array = false;\n+    const Type* res;\n+    MeetResult kind = meet_instptr(ptr, this_klass, tinst_klass, this_xk, tinst_xk, this->_ptr, tinst->_ptr,\n+                                   this_flatten_array, tinst_flatten_array,\n+                                   res_klass, res_xk, res_flatten_array);\n+    if (kind == UNLOADED) {\n@@ -4161,1 +4180,1 @@\n-      const TypeInstPtr *unloaded_meet = xmeet_unloaded(tinst);\n+      const TypeInstPtr* unloaded_meet = xmeet_unloaded(tinst);\n@@ -4163,4 +4182,10 @@\n-      if( PrintOpto && Verbose ) {\n-        tty->print(\"meet of unloaded classes resulted in: \"); unloaded_meet->dump(); tty->cr();\n-        tty->print(\"  this == \"); this->dump(); tty->cr();\n-        tty->print(\" tinst == \"); tinst->dump(); tty->cr();\n+      if (PrintOpto && Verbose) {\n+        tty->print(\"meet of unloaded classes resulted in: \");\n+        unloaded_meet->dump();\n+        tty->cr();\n+        tty->print(\"  this == \");\n+        dump();\n+        tty->cr();\n+        tty->print(\" tinst == \");\n+        tinst->dump();\n+        tty->cr();\n@@ -4169,119 +4194,6 @@\n-      return unloaded_meet;\n-    }\n-\n-    \/\/ Handle mixing oops and interfaces first.\n-    if( this_klass->is_interface() && !(tinst_klass->is_interface() ||\n-                                        tinst_klass == ciEnv::current()->Object_klass())) {\n-      ciKlass *tmp = tinst_klass; \/\/ Swap interface around\n-      tinst_klass = this_klass;\n-      this_klass = tmp;\n-      bool tmp2 = tinst_xk;\n-      tinst_xk = this_xk;\n-      this_xk = tmp2;\n-      tmp2 = tinst_flatten_array;\n-      tinst_flatten_array = this_flatten_array;\n-      this_flatten_array = tmp2;\n-    }\n-    if (tinst_klass->is_interface() &&\n-        !(this_klass->is_interface() ||\n-          \/\/ Treat java\/lang\/Object as an honorary interface,\n-          \/\/ because we need a bottom for the interface hierarchy.\n-          this_klass == ciEnv::current()->Object_klass())) {\n-      \/\/ Oop meets interface!\n-\n-      \/\/ See if the oop subtypes (implements) interface.\n-      ciKlass *k;\n-      bool xk;\n-      bool flat_array;\n-      if( this_klass->is_subtype_of( tinst_klass ) ) {\n-        \/\/ Oop indeed subtypes.  Now keep oop or interface depending\n-        \/\/ on whether we are both above the centerline or either is\n-        \/\/ below the centerline.  If we are on the centerline\n-        \/\/ (e.g., Constant vs. AnyNull interface), use the constant.\n-        k  = below_centerline(ptr) ? tinst_klass : this_klass;\n-        \/\/ If we are keeping this_klass, keep its exactness too.\n-        xk = below_centerline(ptr) ? tinst_xk    : this_xk;\n-        flat_array = below_centerline(ptr) ? tinst_flatten_array    : this_flatten_array;\n-      } else {                  \/\/ Does not implement, fall to Object\n-        \/\/ Oop does not implement interface, so mixing falls to Object\n-        \/\/ just like the verifier does (if both are above the\n-        \/\/ centerline fall to interface)\n-        k = above_centerline(ptr) ? tinst_klass : ciEnv::current()->Object_klass();\n-        xk = above_centerline(ptr) ? tinst_xk : false;\n-        flat_array = above_centerline(ptr) ? tinst_flatten_array : false;\n-        \/\/ Watch out for Constant vs. AnyNull interface.\n-        if (ptr == Constant) {\n-          ptr = NotNull;  \/\/ forget it was a constant\n-        }\n-        if (instance_id > 0) {\n-          instance_id = InstanceBot;\n-        }\n-      }\n-      ciObject* o = NULL;  \/\/ the Constant value, if any\n-      if (ptr == Constant) {\n-        \/\/ Find out which constant.\n-        o = (this_klass == klass()) ? const_oop() : tinst->const_oop();\n-      }\n-      return make(ptr, k, xk, o, off, flat_array, instance_id, speculative, depth);\n-    }\n-\n-    \/\/ Either oop vs oop or interface vs interface or interface vs Object\n-\n-    \/\/ !!! Here's how the symmetry requirement breaks down into invariants:\n-    \/\/ If we split one up & one down AND they subtype, take the down man.\n-    \/\/ If we split one up & one down AND they do NOT subtype, \"fall hard\".\n-    \/\/ If both are up and they subtype, take the subtype class.\n-    \/\/ If both are up and they do NOT subtype, \"fall hard\".\n-    \/\/ If both are down and they subtype, take the supertype class.\n-    \/\/ If both are down and they do NOT subtype, \"fall hard\".\n-    \/\/ Constants treated as down.\n-\n-    \/\/ Now, reorder the above list; observe that both-down+subtype is also\n-    \/\/ \"fall hard\"; \"fall hard\" becomes the default case:\n-    \/\/ If we split one up & one down AND they subtype, take the down man.\n-    \/\/ If both are up and they subtype, take the subtype class.\n-\n-    \/\/ If both are down and they subtype, \"fall hard\".\n-    \/\/ If both are down and they do NOT subtype, \"fall hard\".\n-    \/\/ If both are up and they do NOT subtype, \"fall hard\".\n-    \/\/ If we split one up & one down AND they do NOT subtype, \"fall hard\".\n-\n-    \/\/ If a proper subtype is exact, and we return it, we return it exactly.\n-    \/\/ If a proper supertype is exact, there can be no subtyping relationship!\n-    \/\/ If both types are equal to the subtype, exactness is and-ed below the\n-    \/\/ centerline and or-ed above it.  (N.B. Constants are always exact.)\n-\n-    \/\/ Check for subtyping:\n-    ciKlass *subtype = NULL;\n-    bool subtype_exact = false;\n-    bool flat_array = false;\n-    if (tinst_klass->equals(this_klass)) {\n-      subtype = this_klass;\n-      subtype_exact = below_centerline(ptr) ? (this_xk && tinst_xk) : (this_xk || tinst_xk);\n-      flat_array = below_centerline(ptr) ? (this_flatten_array && tinst_flatten_array) : (this_flatten_array || tinst_flatten_array);\n-    } else if (!tinst_xk && this_klass->is_subtype_of(tinst_klass) && (!tinst_flatten_array || this_flatten_array)) {\n-      subtype = this_klass;     \/\/ Pick subtyping class\n-      subtype_exact = this_xk;\n-      flat_array = this_flatten_array;\n-    } else if (!this_xk && tinst_klass->is_subtype_of(this_klass) && (!this_flatten_array || tinst_flatten_array)) {\n-      subtype = tinst_klass;    \/\/ Pick subtyping class\n-      subtype_exact = tinst_xk;\n-      flat_array = tinst_flatten_array;\n-    }\n-\n-    if (subtype) {\n-      if (above_centerline(ptr)) { \/\/ both are up?\n-        this_klass = tinst_klass = subtype;\n-        this_xk = tinst_xk = subtype_exact;\n-        this_flatten_array = tinst_flatten_array = flat_array;\n-      } else if (above_centerline(this ->_ptr) && !above_centerline(tinst->_ptr)) {\n-        this_klass = tinst_klass; \/\/ tinst is down; keep down man\n-        this_xk = tinst_xk;\n-        this_flatten_array = tinst_flatten_array;\n-      } else if (above_centerline(tinst->_ptr) && !above_centerline(this ->_ptr)) {\n-        tinst_klass = this_klass; \/\/ this is down; keep down man\n-        tinst_xk = this_xk;\n-        tinst_flatten_array = this_flatten_array;\n-      } else {\n-        this_xk = subtype_exact;  \/\/ either they are equal, or we'll do an LCA\n-        this_flatten_array = flat_array;\n+      res = unloaded_meet;\n+    } else {\n+      if (kind == NOT_SUBTYPE && instance_id > 0) {\n+        instance_id = InstanceBot;\n+      } else if (kind == LCA) {\n+        instance_id = InstanceBot;\n@@ -4289,8 +4201,1 @@\n-    }\n-\n-    \/\/ Check for classes now being equal\n-    if (tinst_klass->equals(this_klass)) {\n-      \/\/ If the klasses are equal, the constants may still differ.  Fall to\n-      \/\/ NotNull if they do (neither constant is NULL; that is a special case\n-      \/\/ handled elsewhere).\n-      ciObject* this_oop  = const_oop();\n+      ciObject* this_oop = const_oop();\n@@ -4299,1 +4204,1 @@\n-      if( ptr == Constant ) {\n+      if (ptr == Constant) {\n@@ -4301,1 +4206,1 @@\n-            this_oop->equals(tinst_oop) )\n+            this_oop->equals(tinst_oop))\n@@ -4303,1 +4208,2 @@\n-        else if (above_centerline(this ->_ptr))\n+        else if (above_centerline(_ptr)) {\n+          assert(!tinst_klass->is_interface(), \"\");\n@@ -4305,1 +4211,2 @@\n-        else if (above_centerline(tinst ->_ptr))\n+        } else if (above_centerline(tinst->_ptr)) {\n+          assert(!this_klass->is_interface(), \"\");\n@@ -4307,1 +4214,1 @@\n-        else\n+        } else\n@@ -4310,7 +4217,1 @@\n-      return make(ptr, this_klass, this_xk, o, off, this_flatten_array, instance_id, speculative, depth);\n-    } \/\/ Else classes are not equal\n-\n-    \/\/ Since klasses are different, we require a LCA in the Java\n-    \/\/ class hierarchy - which means we have to fall to at least NotNull.\n-    if (ptr == TopPTR || ptr == AnyNull || ptr == Constant) {\n-      ptr = NotNull;\n+      res = make(ptr, res_klass, res_xk, o, off, res_flatten_array, instance_id, speculative, depth);\n@@ -4318,4 +4219,2 @@\n-    instance_id = InstanceBot;\n-    \/\/ Now we find the LCA of Java classes\n-    ciKlass* k = this_klass->least_common_ancestor(tinst_klass);\n-    return make(ptr, k, false, NULL, off, flatten_array() && tinst->flatten_array(), instance_id, speculative, depth);\n+    return res;\n+\n@@ -4350,0 +4249,157 @@\n+TypePtr::MeetResult TypePtr::meet_instptr(PTR &ptr, ciKlass* this_klass, ciKlass* tinst_klass, bool this_xk, bool tinst_xk,\n+                                          PTR this_ptr, PTR tinst_ptr, bool this_flatten_array, bool tinst_flatten_array,\n+                                          ciKlass*&res_klass, bool &res_xk, bool& res_flatten_array) {\n+\n+  bool this_flatten_array_orig = this_flatten_array;\n+  bool tinst_flatten_array_orig = tinst_flatten_array;\n+\n+  \/\/ Check for easy case; klasses are equal (and perhaps not loaded!)\n+  \/\/ If we have constants, then we created oops so classes are loaded\n+  \/\/ and we can handle the constants further down.  This case handles\n+  \/\/ both-not-loaded or both-loaded classes\n+  if (ptr != Constant && this_klass->equals(tinst_klass) && this_xk == tinst_xk && this_flatten_array == tinst_flatten_array) {\n+    res_klass = this_klass;\n+    res_xk = this_xk;\n+    res_flatten_array = this_flatten_array;\n+    return QUICK;\n+  }\n+\n+  \/\/ Classes require inspection in the Java klass hierarchy.  Must be loaded.\n+  if (!tinst_klass->is_loaded() || !this_klass->is_loaded()) {\n+    return UNLOADED;\n+  }\n+\n+  \/\/ Handle mixing oops and interfaces first.\n+  if (this_klass->is_interface() && !(tinst_klass->is_interface() ||\n+                                      tinst_klass == ciEnv::current()->Object_klass())) {\n+    ciKlass *tmp = tinst_klass; \/\/ Swap interface around\n+    tinst_klass = this_klass;\n+    this_klass = tmp;\n+    bool tmp2 = tinst_xk;\n+    tinst_xk = this_xk;\n+    this_xk = tmp2;\n+    tmp2 = tinst_flatten_array;\n+    tinst_flatten_array = this_flatten_array;\n+    this_flatten_array = tmp2;\n+  }\n+  if (tinst_klass->is_interface() &&\n+      !(this_klass->is_interface() ||\n+        \/\/ Treat java\/lang\/Object as an honorary interface,\n+        \/\/ because we need a bottom for the interface hierarchy.\n+        this_klass == ciEnv::current()->Object_klass())) {\n+    \/\/ Oop meets interface!\n+\n+    \/\/ See if the oop subtypes (implements) interface.\n+    if (this_klass->is_subtype_of(tinst_klass)) {\n+      \/\/ Oop indeed subtypes.  Now keep oop or interface depending\n+      \/\/ on whether we are both above the centerline or either is\n+      \/\/ below the centerline.  If we are on the centerline\n+      \/\/ (e.g., Constant vs. AnyNull interface), use the constant.\n+      res_klass  = below_centerline(ptr) ? tinst_klass : this_klass;\n+      \/\/ If we are keeping this_klass, keep its exactness too.\n+      res_xk = below_centerline(ptr) ? tinst_xk    : this_xk;\n+      res_flatten_array = below_centerline(ptr) ? tinst_flatten_array    : this_flatten_array;\n+      return SUBTYPE;\n+    } else {                  \/\/ Does not implement, fall to Object\n+      \/\/ Oop does not implement interface, so mixing falls to Object\n+      \/\/ just like the verifier does (if both are above the\n+      \/\/ centerline fall to interface)\n+      res_klass = above_centerline(ptr) ? tinst_klass : ciEnv::current()->Object_klass();\n+      res_xk = above_centerline(ptr) ? tinst_xk : false;\n+      res_flatten_array = above_centerline(ptr) ? tinst_flatten_array : false;\n+      \/\/ Watch out for Constant vs. AnyNull interface.\n+      if (ptr == Constant)  ptr = NotNull;   \/\/ forget it was a constant\n+      return NOT_SUBTYPE;\n+    }\n+  }\n+\n+  \/\/ Either oop vs oop or interface vs interface or interface vs Object\n+\n+  \/\/ !!! Here's how the symmetry requirement breaks down into invariants:\n+  \/\/ If we split one up & one down AND they subtype, take the down man.\n+  \/\/ If we split one up & one down AND they do NOT subtype, \"fall hard\".\n+  \/\/ If both are up and they subtype, take the subtype class.\n+  \/\/ If both are up and they do NOT subtype, \"fall hard\".\n+  \/\/ If both are down and they subtype, take the supertype class.\n+  \/\/ If both are down and they do NOT subtype, \"fall hard\".\n+  \/\/ Constants treated as down.\n+\n+  \/\/ Now, reorder the above list; observe that both-down+subtype is also\n+  \/\/ \"fall hard\"; \"fall hard\" becomes the default case:\n+  \/\/ If we split one up & one down AND they subtype, take the down man.\n+  \/\/ If both are up and they subtype, take the subtype class.\n+\n+  \/\/ If both are down and they subtype, \"fall hard\".\n+  \/\/ If both are down and they do NOT subtype, \"fall hard\".\n+  \/\/ If both are up and they do NOT subtype, \"fall hard\".\n+  \/\/ If we split one up & one down AND they do NOT subtype, \"fall hard\".\n+\n+  \/\/ If a proper subtype is exact, and we return it, we return it exactly.\n+  \/\/ If a proper supertype is exact, there can be no subtyping relationship!\n+  \/\/ If both types are equal to the subtype, exactness is and-ed below the\n+  \/\/ centerline and or-ed above it.  (N.B. Constants are always exact.)\n+\n+  \/\/ Check for subtyping:\n+  ciKlass *subtype = NULL;\n+  bool subtype_exact = false;\n+  bool flat_array = false;\n+  if (tinst_klass->equals(this_klass)) {\n+    subtype = this_klass;\n+    subtype_exact = below_centerline(ptr) ? (this_xk && tinst_xk) : (this_xk || tinst_xk);\n+    flat_array = below_centerline(ptr) ? (this_flatten_array && tinst_flatten_array) : (this_flatten_array || tinst_flatten_array);\n+  } else if (!tinst_xk && this_klass->is_subtype_of(tinst_klass) && (!tinst_flatten_array || this_flatten_array)) {\n+    subtype = this_klass;     \/\/ Pick subtyping class\n+    subtype_exact = this_xk;\n+    flat_array = this_flatten_array;\n+  } else if (!this_xk && tinst_klass->is_subtype_of(this_klass) && (!this_flatten_array || tinst_flatten_array)) {\n+    subtype = tinst_klass;    \/\/ Pick subtyping class\n+    subtype_exact = tinst_xk;\n+    flat_array = tinst_flatten_array;\n+  }\n+\n+  if (subtype) {\n+    if (above_centerline(ptr)) { \/\/ both are up?\n+      this_klass = tinst_klass = subtype;\n+      this_xk = tinst_xk = subtype_exact;\n+      this_flatten_array = tinst_flatten_array = flat_array;\n+    } else if (above_centerline(this_ptr) && !above_centerline(tinst_ptr)) {\n+      this_klass = tinst_klass; \/\/ tinst is down; keep down man\n+      this_xk = tinst_xk;\n+      this_flatten_array = tinst_flatten_array;\n+    } else if (above_centerline(tinst_ptr) && !above_centerline(this_ptr)) {\n+      tinst_klass = this_klass; \/\/ this is down; keep down man\n+      tinst_xk = this_xk;\n+      tinst_flatten_array = this_flatten_array;\n+    } else {\n+      this_xk = subtype_exact;  \/\/ either they are equal, or we'll do an LCA\n+      this_flatten_array = flat_array;\n+    }\n+  }\n+\n+  \/\/ Check for classes now being equal\n+  if (tinst_klass->equals(this_klass)) {\n+    \/\/ If the klasses are equal, the constants may still differ.  Fall to\n+    \/\/ NotNull if they do (neither constant is NULL; that is a special case\n+    \/\/ handled elsewhere).\n+    res_klass = this_klass;\n+    res_xk = this_xk;\n+    res_flatten_array = this_flatten_array;\n+    return SUBTYPE;\n+  } \/\/ Else classes are not equal\n+\n+  \/\/ Since klasses are different, we require a LCA in the Java\n+  \/\/ class hierarchy - which means we have to fall to at least NotNull.\n+  if (ptr == TopPTR || ptr == AnyNull || ptr == Constant) {\n+    ptr = NotNull;\n+  }\n+\n+  \/\/ Now we find the LCA of Java classes\n+  ciKlass* k = this_klass->least_common_ancestor(tinst_klass);\n+\n+  res_klass = k;\n+  res_xk = false;\n+  res_flatten_array = this_flatten_array_orig && tinst_flatten_array_orig;\n+\n+  return LCA;\n+}\n+\n@@ -4471,0 +4527,11 @@\n+const TypeKlassPtr* TypeInstPtr::as_klass_type(bool try_for_exact) const {\n+  bool xk = klass_is_exact();\n+  ciInstanceKlass* ik = klass()->as_instance_klass();\n+  if (try_for_exact && !xk && !ik->has_subklass() && !ik->is_final() && !ik->is_interface()) {\n+    Compile* C = Compile::current();\n+    Dependencies* deps = C->dependencies();\n+    deps->assert_leaf_type(ik);\n+    xk = true;\n+  }\n+  return TypeInstKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, klass(), Offset(0), flatten_array());\n+}\n@@ -4509,1 +4576,1 @@\n-const Type *TypeAryPtr::cast_to_ptr_type(PTR ptr) const {\n+const TypeAryPtr* TypeAryPtr::cast_to_ptr_type(PTR ptr) const {\n@@ -4757,0 +4824,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -4768,31 +4837,12 @@\n-    ciKlass* lazy_klass = NULL;\n-    if (tary->_elem->isa_int()) {\n-      \/\/ Integral array element types have irrelevant lattice relations.\n-      \/\/ It is the klass that determines array layout, not the element type.\n-      if (_klass == NULL)\n-        lazy_klass = tap->_klass;\n-      else if (tap->_klass == NULL || tap->_klass == _klass) {\n-        lazy_klass = _klass;\n-      } else {\n-        \/\/ Something like byte[int+] meets char[int+].\n-        \/\/ This must fall to bottom, not (int[-128..65535])[int+].\n-        instance_id = InstanceBot;\n-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);\n-      }\n-    } else \/\/ Non integral arrays.\n-      \/\/ Must fall to bottom if exact klasses in upper lattice\n-      \/\/ are not equal or super klass is exact.\n-      if ((above_centerline(ptr) || ptr == Constant) && klass() != tap->klass() &&\n-          \/\/ meet with top[] and bottom[] are processed further down:\n-          tap->_klass != NULL && this->_klass != NULL &&\n-          \/\/ both are exact and not equal:\n-          ((tap->_klass_is_exact && this->_klass_is_exact) ||\n-           \/\/ 'tap' is exact and super or unrelated:\n-           (tap->_klass_is_exact && !tap->klass()->is_subtype_of(klass())) ||\n-           \/\/ 'this' is exact and super or unrelated:\n-           (this->_klass_is_exact && !klass()->is_subtype_of(tap->klass())))) {\n-      if (above_centerline(ptr) || (tary->_elem->make_ptr() && above_centerline(tary->_elem->make_ptr()->_ptr)) ||\n-          tary->_elem->isa_inlinetype()) {\n-        tary = TypeAry::make(Type::BOTTOM, tary->_size, tary->_stable, tary->_not_flat, tary->_not_null_free);\n-      }\n-      return make(NotNull, NULL, tary, lazy_klass, false, off, field_off, InstanceBot, speculative, depth);\n+\n+    ciKlass* res_klass = NULL;\n+    bool res_xk = false;\n+    bool res_not_flat = false;\n+    bool res_not_null_free = false;\n+    const Type* elem = tary->_elem;\n+    if (meet_aryptr(ptr, elem, this->klass(), tap->klass(),\n+                    this->klass_is_exact(), tap->klass_is_exact(), this->ptr(), tap->ptr(),\n+                    this->is_not_flat(), tap->is_not_flat(),\n+                    this->is_not_null_free(), tap->is_not_null_free(),\n+                    res_klass, res_xk, res_not_flat, res_not_null_free) == NOT_SUBTYPE) {\n+      instance_id = InstanceBot;\n@@ -4812,36 +4862,11 @@\n-    bool xk = false;\n-    switch (tap->ptr()) {\n-    case AnyNull:\n-    case TopPTR:\n-      \/\/ Compute new klass on demand, do not use tap->_klass\n-      if (below_centerline(this->_ptr)) {\n-        xk = this->_klass_is_exact;\n-      } else {\n-        xk = (tap->_klass_is_exact || this->_klass_is_exact);\n-      }\n-      return make(ptr, const_oop(), tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n-    case Constant: {\n-      ciObject* o = const_oop();\n-      if( _ptr == Constant ) {\n-        if( tap->const_oop() != NULL && !o->equals(tap->const_oop()) ) {\n-          xk = (klass() == tap->klass());\n-          ptr = NotNull;\n-          o = NULL;\n-          instance_id = InstanceBot;\n-        } else {\n-          xk = true;\n-        }\n-      } else if(above_centerline(_ptr)) {\n-        o = tap->const_oop();\n-        xk = true;\n-      } else {\n-        \/\/ Only precise for identical arrays\n-        xk = this->_klass_is_exact && (klass() == tap->klass());\n-      }\n-      return make(ptr, o, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n-    }\n-    case NotNull:\n-    case BotPTR:\n-      \/\/ Compute new klass on demand, do not use tap->_klass\n-      if (above_centerline(this->_ptr)) {\n-        xk = tap->_klass_is_exact;\n+    ciObject* o = NULL;             \/\/ Assume not constant when done\n+    ciObject* this_oop = const_oop();\n+    ciObject* tap_oop = tap->const_oop();\n+    if (ptr == Constant) {\n+      if (this_oop != NULL && tap_oop != NULL &&\n+          this_oop->equals(tap_oop)) {\n+        o = tap_oop;\n+      } else if (above_centerline(_ptr)) {\n+        o = tap_oop;\n+      } else if (above_centerline(tap->_ptr)) {\n+        o = this_oop;\n@@ -4849,2 +4874,1 @@\n-        xk = (tap->_klass_is_exact & this->_klass_is_exact) &&\n-             (klass() == tap->klass()); \/\/ Only precise for identical arrays\n+        ptr = NotNull;\n@@ -4852,2 +4876,1 @@\n-      return make(ptr, NULL, tary, lazy_klass, xk, off, field_off, instance_id, speculative, depth);\n-    default: ShouldNotReachHere();\n+    return make(ptr, o, TypeAry::make(elem, tary->_size, tary->_stable, res_not_flat, res_not_null_free), res_klass, res_xk, off, field_off, instance_id, speculative, depth);\n@@ -4924,0 +4947,87 @@\n+\n+TypePtr::MeetResult TypePtr::meet_aryptr(PTR& ptr, const Type*& elem, ciKlass* this_klass, ciKlass* tap_klass,\n+                                         bool this_xk, bool tap_xk, PTR this_ptr, PTR tap_ptr,\n+                                         bool this_not_flat, bool tap_not_flat,\n+                                         bool this_not_null_free, bool tap_not_null_free,\n+                                         ciKlass*& res_klass, bool& res_xk, bool& res_not_flat, bool& res_not_null_free) {\n+  res_klass = NULL;\n+  MeetResult result = SUBTYPE;\n+  res_not_flat = this_not_flat && tap_not_flat;\n+  res_not_null_free = this_not_null_free && tap_not_null_free;\n+\n+  if (elem->isa_int()) {\n+    \/\/ Integral array element types have irrelevant lattice relations.\n+    \/\/ It is the klass that determines array layout, not the element type.\n+    if (this_klass == NULL) {\n+      res_klass = tap_klass;\n+    } else if (tap_klass == NULL || tap_klass == this_klass) {\n+      res_klass = this_klass;\n+    } else {\n+      \/\/ Something like byte[int+] meets char[int+].\n+      \/\/ This must fall to bottom, not (int[-128..65535])[int+].\n+      \/\/ instance_id = InstanceBot;\n+      elem = Type::BOTTOM;\n+      result = NOT_SUBTYPE;\n+    }\n+  } else \/\/ Non integral arrays.\n+    \/\/ Must fall to bottom if exact klasses in upper lattice\n+    \/\/ are not equal or super klass is exact.\n+    if ((above_centerline(ptr) || ptr == Constant) && this_klass != tap_klass &&\n+        \/\/ meet with top[] and bottom[] are processed further down:\n+        tap_klass != NULL  && this_klass != NULL   &&\n+        \/\/ both are exact and not equal:\n+        ((tap_xk && this_xk) ||\n+         \/\/ 'tap'  is exact and super or unrelated:\n+         (tap_xk && !tap_klass->is_subtype_of(this_klass)) ||\n+         \/\/ 'this' is exact and super or unrelated:\n+         (this_xk && !this_klass->is_subtype_of(tap_klass)))) {\n+      if (above_centerline(ptr) || (elem->make_ptr() && above_centerline(elem->make_ptr()->_ptr)) ||\n+          elem->isa_inlinetype()) {\n+        elem = Type::BOTTOM;\n+      }\n+      ptr = NotNull;\n+      res_xk = false;\n+      return NOT_SUBTYPE;\n+    }\n+\n+  res_xk = false;\n+  switch (tap_ptr) {\n+    case AnyNull:\n+    case TopPTR:\n+      \/\/ Compute new klass on demand, do not use tap->_klass\n+      if (below_centerline(this_ptr)) {\n+        res_xk = this_xk;\n+      } else {\n+        res_xk = (tap_xk || this_xk);\n+      }\n+      return result;\n+    case Constant: {\n+      if (this_ptr == Constant) {\n+        res_xk = true;\n+      } else if(above_centerline(this_ptr)) {\n+        res_xk = true;\n+      } else {\n+        \/\/ Only precise for identical arrays\n+        res_xk = this_xk && (this_klass == tap_klass);\n+      }\n+      return result;\n+    }\n+    case NotNull:\n+    case BotPTR:\n+      \/\/ Compute new klass on demand, do not use tap->_klass\n+      if (above_centerline(this_ptr)) {\n+        res_xk = tap_xk;\n+      } else {\n+        res_xk = (tap_xk && this_xk) &&\n+          (this_klass == tap_klass); \/\/ Only precise for identical arrays\n+      }\n+      return result;\n+    default:  {\n+      ShouldNotReachHere();\n+      return result;\n+    }\n+  }\n+  return result;\n+}\n+\n+\n@@ -5183,0 +5293,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -5309,1 +5421,1 @@\n-const Type *TypeMetadataPtr::cast_to_ptr_type(PTR ptr) const {\n+const TypeMetadataPtr* TypeMetadataPtr::cast_to_ptr_type(PTR ptr) const {\n@@ -5363,0 +5475,2 @@\n+  case InstKlassPtr:\n+  case AryKlassPtr:\n@@ -5436,2 +5550,11 @@\n-\/\/=============================================================================\n-\/\/ Convenience common pre-built types.\n+const TypeKlassPtr* TypeAryPtr::as_klass_type(bool try_for_exact) const {\n+  const Type* elem = _ary->_elem;\n+  bool xk = klass_is_exact();\n+  if (elem->make_oopptr() != NULL) {\n+    elem = elem->make_oopptr()->as_klass_type(try_for_exact);\n+    if (elem->is_klassptr()->klass_is_exact()) {\n+      xk = true;\n+    }\n+  }\n+  return TypeAryKlassPtr::make(xk ? TypePtr::Constant : TypePtr::NotNull, elem, klass(), Offset(0), is_not_flat(), is_not_null_free(), is_null_free());\n+}\n@@ -5439,3 +5562,6 @@\n-\/\/ Not-null object klass or below\n-const TypeKlassPtr *TypeKlassPtr::OBJECT;\n-const TypeKlassPtr *TypeKlassPtr::OBJECT_OR_NULL;\n+const TypeKlassPtr* TypeKlassPtr::make(ciKlass *klass) {\n+  if (klass->is_instance_klass()) {\n+    return TypeInstKlassPtr::make(klass);\n+  }\n+  return TypeAryKlassPtr::make(klass);\n+}\n@@ -5443,6 +5569,5 @@\n-\/\/------------------------------TypeKlassPtr-----------------------------------\n-TypeKlassPtr::TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array, bool not_flat, bool not_null_free)\n-  : TypePtr(KlassPtr, ptr, offset), _klass(klass), _klass_is_exact(ptr == Constant),\n-    _flatten_array(flatten_array), _not_flat(not_flat), _not_null_free(not_null_free) {\n-  assert(!klass->flatten_array() || flatten_array, \"Should be flat in array\");\n-  assert(!flatten_array || can_be_inline_type(), \"Only inline types can be flat in array\");\n+const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* klass, Offset offset) {\n+  if (klass->is_instance_klass()) {\n+    return TypeInstKlassPtr::make(ptr, klass, offset);\n+  }\n+  return TypeAryKlassPtr::make(klass, ptr, offset);\n@@ -5451,7 +5576,3 @@\n-\/\/------------------------------make-------------------------------------------\n-\/\/ ptr to klass 'k', if Constant, or possibly to a sub-klass if not a Constant\n-const TypeKlassPtr* TypeKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array, bool not_flat, bool not_null_free) {\n-  assert(k == NULL || k->is_instance_klass() || k->is_array_klass(), \"Incorrect type of klass oop\");\n-  \/\/ Check if this type is known to be flat in arrays\n-  flatten_array = flatten_array || k->flatten_array();\n-  return (TypeKlassPtr*)(new TypeKlassPtr(ptr, k, offset, flatten_array, not_flat, not_null_free))->hashcons();\n+\/\/------------------------------TypeKlassPtr-----------------------------------\n+TypeKlassPtr::TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, Offset offset)\n+  : TypePtr(t, ptr, offset), _klass(klass) {\n@@ -5462,1 +5583,1 @@\n-bool TypeKlassPtr::eq( const Type *t ) const {\n+bool TypeKlassPtr::eq(const Type *t) const {\n@@ -5464,2 +5585,2 @@\n-  return klass() == p->klass() && TypePtr::eq(p) && flatten_array() == p->flatten_array() &&\n-      is_not_flat() == p->is_not_flat() && is_not_null_free() == p->is_not_null_free();\n+  return\n+    TypePtr::eq(p);\n@@ -5471,2 +5592,1 @@\n-  return java_add(java_add(java_add(java_add(klass() != NULL ? klass()->hash() : (jint)0, (jint)TypePtr::hash()),\n-      (jint)flatten_array()), (jint)is_not_flat()), (jint)is_not_null_free());\n+  return TypePtr::hash();\n@@ -5489,2 +5609,2 @@\n-  const TypeKlassPtr* ftkp = ft->isa_klassptr();\n-  const TypeKlassPtr* ktkp = kills->isa_klassptr();\n+  const TypeKlassPtr* ftkp = ft->isa_instklassptr();\n+  const TypeKlassPtr* ktkp = kills->isa_instklassptr();\n@@ -5511,0 +5631,356 @@\n+\/\/------------------------------get_con----------------------------------------\n+intptr_t TypeKlassPtr::get_con() const {\n+  assert( _ptr == Null || _ptr == Constant, \"\" );\n+  assert( offset() >= 0, \"\" );\n+\n+  if (offset() != 0) {\n+    \/\/ After being ported to the compiler interface, the compiler no longer\n+    \/\/ directly manipulates the addresses of oops.  Rather, it only has a pointer\n+    \/\/ to a handle at compile time.  This handle is embedded in the generated\n+    \/\/ code and dereferenced at the time the nmethod is made.  Until that time,\n+    \/\/ it is not reasonable to do arithmetic with the addresses of oops (we don't\n+    \/\/ have access to the addresses!).  This does not seem to currently happen,\n+    \/\/ but this assertion here is to help prevent its occurence.\n+    tty->print_cr(\"Found oop constant with non-zero offset\");\n+    ShouldNotReachHere();\n+  }\n+\n+  return (intptr_t)klass()->constant_encoding();\n+}\n+\n+\/\/------------------------------dump2------------------------------------------\n+\/\/ Dump Klass Type\n+#ifndef PRODUCT\n+void TypeInstKlassPtr::dump2(Dict & d, uint depth, outputStream *st) const {\n+  switch(_ptr) {\n+  case Constant:\n+    st->print(\"precise \");\n+  case NotNull:\n+    {\n+      const char *name = klass()->name()->as_utf8();\n+      if (name) {\n+        st->print(\"%s: \" INTPTR_FORMAT, name, p2i(klass()));\n+      } else {\n+        ShouldNotReachHere();\n+      }\n+    }\n+  case BotPTR:\n+    if (!WizardMode && !Verbose && _ptr != Constant) break;\n+  case TopPTR:\n+  case AnyNull:\n+    st->print(\":%s\", ptr_msg[_ptr]);\n+    if (_ptr == Constant) st->print(\":exact\");\n+    break;\n+  default:\n+    break;\n+  }\n+  if (Verbose) {\n+    if (_flatten_array) st->print(\":flatten array\");\n+  }\n+  _offset.dump2(st);\n+  st->print(\" *\");\n+}\n+#endif\n+\n+\/\/=============================================================================\n+\/\/ Convenience common pre-built types.\n+\n+\/\/ Not-null object klass or below\n+const TypeInstKlassPtr *TypeInstKlassPtr::OBJECT;\n+const TypeInstKlassPtr *TypeInstKlassPtr::OBJECT_OR_NULL;\n+\n+bool TypeInstKlassPtr::eq(const Type *t) const {\n+  const TypeKlassPtr *p = t->is_klassptr();\n+  return\n+    klass()->equals(p->klass()) &&\n+    flatten_array() == p->flatten_array() &&\n+    TypeKlassPtr::eq(p);\n+}\n+\n+int TypeInstKlassPtr::hash(void) const {\n+  return java_add(java_add((jint)klass()->hash(), TypeKlassPtr::hash()), (jint)flatten_array());\n+}\n+\n+const TypeInstKlassPtr *TypeInstKlassPtr::make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array) {\n+  flatten_array = flatten_array || k->flatten_array();\n+\n+  TypeInstKlassPtr *r =\n+    (TypeInstKlassPtr*)(new TypeInstKlassPtr(ptr, k, offset, flatten_array))->hashcons();\n+\n+  return r;\n+}\n+\n+\/\/------------------------------add_offset-------------------------------------\n+\/\/ Access internals of klass object\n+const TypePtr *TypeInstKlassPtr::add_offset( intptr_t offset ) const {\n+  return make(_ptr, klass(), xadd_offset(offset), flatten_array());\n+}\n+\n+const TypeKlassPtr *TypeInstKlassPtr::with_offset(intptr_t offset) const {\n+  return make(_ptr, klass(), Offset(offset), flatten_array());\n+}\n+\n+\/\/------------------------------cast_to_ptr_type-------------------------------\n+const TypePtr* TypeInstKlassPtr::cast_to_ptr_type(PTR ptr) const {\n+  assert(_base == InstKlassPtr, \"subclass must override cast_to_ptr_type\");\n+  if( ptr == _ptr ) return this;\n+  return make(ptr, _klass, _offset, flatten_array());\n+}\n+\n+\n+bool TypeInstKlassPtr::must_be_exact() const {\n+  if (!_klass->is_loaded())  return false;\n+  ciInstanceKlass* ik = _klass->as_instance_klass();\n+  if (ik->is_final())  return true;  \/\/ cannot clear xk\n+  return false;\n+}\n+\n+\/\/-----------------------------cast_to_exactness-------------------------------\n+const TypeKlassPtr* TypeInstKlassPtr::cast_to_exactness(bool klass_is_exact) const {\n+  if (klass_is_exact == (_ptr == Constant)) return this;\n+  if (must_be_exact()) return this;\n+  ciKlass* k = klass();\n+  return make(klass_is_exact ? Constant : NotNull, k, _offset, flatten_array());\n+}\n+\n+\n+\/\/-----------------------------as_instance_type--------------------------------\n+\/\/ Corresponding type for an instance of the given class.\n+\/\/ It will be NotNull, and exact if and only if the klass type is exact.\n+const TypeOopPtr* TypeInstKlassPtr::as_instance_type() const {\n+  ciKlass* k = klass();\n+  bool    xk = klass_is_exact();\n+  return TypeInstPtr::make(TypePtr::BotPTR, k, xk, NULL, Offset(0), flatten_array() && !klass()->is_inlinetype());\n+}\n+\n+\/\/------------------------------xmeet------------------------------------------\n+\/\/ Compute the MEET of two types, return a new Type object.\n+const Type    *TypeInstKlassPtr::xmeet( const Type *t ) const {\n+  \/\/ Perform a fast test for common case; meeting the same types together.\n+  if( this == t ) return this;  \/\/ Meeting same type-rep?\n+\n+  \/\/ Current \"this->_base\" is Pointer\n+  switch (t->base()) {          \/\/ switch on original type\n+\n+  case Int:                     \/\/ Mixing ints & oops happens when javac\n+  case Long:                    \/\/ reuses local variables\n+  case FloatTop:\n+  case FloatCon:\n+  case FloatBot:\n+  case DoubleTop:\n+  case DoubleCon:\n+  case DoubleBot:\n+  case NarrowOop:\n+  case NarrowKlass:\n+  case Bottom:                  \/\/ Ye Olde Default\n+    return Type::BOTTOM;\n+  case Top:\n+    return this;\n+\n+  default:                      \/\/ All else is a mistake\n+    typerr(t);\n+\n+  case AnyPtr: {                \/\/ Meeting to AnyPtrs\n+    \/\/ Found an AnyPtr type vs self-KlassPtr type\n+    const TypePtr *tp = t->is_ptr();\n+    Offset offset = meet_offset(tp->offset());\n+    PTR ptr = meet_ptr(tp->ptr());\n+    switch (tp->ptr()) {\n+    case TopPTR:\n+      return this;\n+    case Null:\n+      if( ptr == Null ) return TypePtr::make(AnyPtr, ptr, offset, tp->speculative(), tp->inline_depth());\n+    case AnyNull:\n+      return make(ptr, klass(), offset, flatten_array());\n+    case BotPTR:\n+    case NotNull:\n+      return TypePtr::make(AnyPtr, ptr, offset, tp->speculative(), tp->inline_depth());\n+    default: typerr(t);\n+    }\n+  }\n+\n+  case RawPtr:\n+  case MetadataPtr:\n+  case OopPtr:\n+  case AryPtr:                  \/\/ Meet with AryPtr\n+  case InstPtr:                 \/\/ Meet with InstPtr\n+      return TypePtr::BOTTOM;\n+\n+  \/\/\n+  \/\/             A-top         }\n+  \/\/           \/   |   \\       }  Tops\n+  \/\/       B-top A-any C-top   }\n+  \/\/          | \/  |  \\ |      }  Any-nulls\n+  \/\/       B-any   |   C-any   }\n+  \/\/          |    |    |\n+  \/\/       B-con A-con C-con   } constants; not comparable across classes\n+  \/\/          |    |    |\n+  \/\/       B-not   |   C-not   }\n+  \/\/          | \\  |  \/ |      }  not-nulls\n+  \/\/       B-bot A-not C-bot   }\n+  \/\/           \\   |   \/       }  Bottoms\n+  \/\/             A-bot         }\n+  \/\/\n+\n+  case InstKlassPtr: {  \/\/ Meet two KlassPtr types\n+    const TypeInstKlassPtr *tkls = t->is_instklassptr();\n+    Offset  off     = meet_offset(tkls->offset());\n+    PTR  ptr     = meet_ptr(tkls->ptr());\n+    ciKlass* tkls_klass = tkls->klass();\n+    ciKlass* this_klass  = klass();\n+    bool tkls_xk = tkls->klass_is_exact();\n+    bool this_xk  = klass_is_exact();\n+    bool tkls_flatten_array = tkls->flatten_array();\n+    bool this_flatten_array  = this->flatten_array();\n+\n+    ciKlass* res_klass = NULL;\n+    bool res_xk = false;\n+    bool res_flatten_array = false;\n+    switch(meet_instptr(ptr, this_klass, tkls_klass, this_xk, tkls_xk, this->_ptr, tkls->_ptr,\n+                        this_flatten_array, tkls_flatten_array, res_klass, res_xk, res_flatten_array)) {\n+      case UNLOADED:\n+        ShouldNotReachHere();\n+      case SUBTYPE:\n+      case NOT_SUBTYPE:\n+      case LCA:\n+      case QUICK: {\n+        assert(res_xk == (ptr == Constant), \"\");\n+        const Type* res1 = make(ptr, res_klass, off, res_flatten_array);\n+        return res1;\n+      }\n+      default:\n+        ShouldNotReachHere();\n+    }\n+  } \/\/ End of case KlassPtr\n+  case AryKlassPtr: {                \/\/ All arrays inherit from Object class\n+    const TypeAryKlassPtr *tp = t->is_aryklassptr();\n+    Offset offset = meet_offset(tp->offset());\n+    PTR ptr = meet_ptr(tp->ptr());\n+\n+    switch (ptr) {\n+    case TopPTR:\n+    case AnyNull:                \/\/ Fall 'down' to dual of object klass\n+      \/\/ For instances when a subclass meets a superclass we fall\n+      \/\/ below the centerline when the superclass is exact. We need to\n+      \/\/ do the same here.\n+      if (klass()->equals(ciEnv::current()->Object_klass()) && !klass_is_exact()) {\n+        return TypeAryKlassPtr::make(ptr, tp->elem(), tp->klass(), offset, tp->is_not_flat(), tp->is_not_null_free(), tp->null_free());\n+      } else {\n+        \/\/ cannot subclass, so the meet has to fall badly below the centerline\n+        ptr = NotNull;\n+        return make(ptr, ciEnv::current()->Object_klass(), offset, false);\n+      }\n+    case Constant:\n+    case NotNull:\n+    case BotPTR:                \/\/ Fall down to object klass\n+      \/\/ LCA is object_klass, but if we subclass from the top we can do better\n+      if( above_centerline(_ptr) ) { \/\/ if( _ptr == TopPTR || _ptr == AnyNull )\n+        \/\/ If 'this' (InstPtr) is above the centerline and it is Object class\n+        \/\/ then we can subclass in the Java class hierarchy.\n+        \/\/ For instances when a subclass meets a superclass we fall\n+        \/\/ below the centerline when the superclass is exact. We need\n+        \/\/ to do the same here.\n+        if (klass()->equals(ciEnv::current()->Object_klass())) {\n+          \/\/ that is, tp's array type is a subtype of my klass\n+          return TypeAryKlassPtr::make(ptr,\n+                                       tp->elem(), tp->klass(), offset, tp->is_not_flat(), tp->is_not_null_free(), tp->null_free());\n+        }\n+      }\n+      \/\/ The other case cannot happen, since I cannot be a subtype of an array.\n+      \/\/ The meet falls down to Object class below centerline.\n+      if( ptr == Constant )\n+         ptr = NotNull;\n+      return make(ptr, ciEnv::current()->Object_klass(), offset, false);\n+    default: typerr(t);\n+    }\n+  }\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return t;\n+      } else {\n+        return TypeInstPtr::NOTNULL;\n+      }\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n+      }\n+      if (tv->inline_klass()->is_subtype_of(_klass)) {\n+        return make(ptr, _klass, Offset(0), _flatten_array);\n+      } else {\n+        return make(ptr, ciEnv::current()->Object_klass(), Offset(0));\n+      }\n+    }\n+  }\n+\n+  } \/\/ End of switch\n+  return this;                  \/\/ Return the double constant\n+}\n+\n+\/\/------------------------------xdual------------------------------------------\n+\/\/ Dual: compute field-by-field dual\n+const Type    *TypeInstKlassPtr::xdual() const {\n+  return new TypeInstKlassPtr(dual_ptr(), klass(), dual_offset(), flatten_array());\n+}\n+\n+const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, const Type* elem, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, int null_free) {\n+  return (TypeAryKlassPtr*)(new TypeAryKlassPtr(ptr, elem, k, offset, not_flat, not_null_free, null_free))->hashcons();\n+}\n+\n+const TypeAryKlassPtr *TypeAryKlassPtr::make(PTR ptr, ciKlass* klass, Offset offset, bool not_flat, bool not_null_free, int null_free) {\n+  if (klass->is_obj_array_klass()) {\n+    \/\/ Element is an object array. Recursively call ourself.\n+    ciKlass* eklass = klass->as_obj_array_klass()->element_klass();\n+    const TypeKlassPtr *etype = TypeKlassPtr::make(eklass)->cast_to_exactness(false);\n+    const TypeAryKlassPtr* res = TypeAryKlassPtr::make(ptr, etype, NULL, offset, not_flat, not_null_free, null_free ? 1 : 0);\n+    assert(res->klass() == klass, \"\");\n+    return res;\n+  } else if (klass->is_type_array_klass()) {\n+    \/\/ Element is an typeArray\n+    const Type* etype = get_const_basic_type(klass->as_type_array_klass()->element_type());\n+    return TypeAryKlassPtr::make(ptr, etype, klass, offset, not_flat, not_null_free, null_free);\n+  } else if (klass->is_flat_array_klass()) {\n+    ciInlineKlass* vk = klass->as_array_klass()->element_klass()->as_inline_klass();\n+    return TypeAryKlassPtr::make(ptr, TypeInlineType::make(vk), klass, offset, not_flat, not_null_free, null_free);\n+  } else {\n+    ShouldNotReachHere();\n+    return NULL;\n+  }\n+}\n+\n+const TypeAryKlassPtr* TypeAryKlassPtr::make(ciKlass* k, PTR ptr, Offset offset) {\n+  bool not_null_free = k->is_array_klass() && (k->as_array_klass()->element_klass() == NULL ||\n+                                               !k->as_array_klass()->element_klass()->can_be_inline_klass(true));\n+  bool not_flat = k->is_array_klass() && !k->is_flat_array_klass();\n+  bool null_free = k->is_array_klass() && k->as_array_klass()->is_elem_null_free();\n+  if (k->is_obj_array_klass() && ptr == Constant) {\n+    \/\/ An object array can't be flat or null-free if the klass is exact\n+    not_flat = true;\n+    if (!null_free) {\n+      not_null_free = true;\n+    }\n+  }\n+\n+  return TypeAryKlassPtr::make(ptr, k, offset, not_flat, not_null_free, null_free);\n+}\n+\n+\/\/------------------------------eq---------------------------------------------\n+\/\/ Structural equality check for Type representations\n+bool TypeAryKlassPtr::eq(const Type *t) const {\n+  const TypeAryKlassPtr *p = t->is_aryklassptr();\n+  return\n+    _elem == p->_elem &&  \/\/ Check array\n+    _not_flat == p->_not_flat &&\n+    _not_null_free == p->_not_null_free &&\n+    _null_free == p->_null_free &&\n+    TypeKlassPtr::eq(p);  \/\/ Check sub-parts\n+}\n+\n+\/\/------------------------------hash-------------------------------------------\n+\/\/ Type-specific hashing function.\n+int TypeAryKlassPtr::hash(void) const {\n+  return (intptr_t)_elem + TypeKlassPtr::hash();\n+}\n+\n@@ -5606,2 +6082,6 @@\n-const TypePtr *TypeKlassPtr::add_offset( intptr_t offset ) const {\n-  return make(_ptr, klass(), xadd_offset(offset), flatten_array(), is_not_flat(), is_not_null_free());\n+const TypePtr *TypeAryKlassPtr::add_offset(intptr_t offset) const {\n+  return make(_ptr, elem(), klass(), xadd_offset(offset), is_not_flat(), is_not_null_free(), _null_free);\n+}\n+\n+const TypeKlassPtr *TypeAryKlassPtr::with_offset(intptr_t offset) const {\n+  return make(_ptr, elem(), klass(), Offset(offset), is_not_flat(), is_not_null_free(), _null_free);\n@@ -5611,4 +6091,12 @@\n-const Type *TypeKlassPtr::cast_to_ptr_type(PTR ptr) const {\n-  assert(_base == KlassPtr, \"subclass must override cast_to_ptr_type\");\n-  if( ptr == _ptr ) return this;\n-  return make(ptr, _klass, _offset, _flatten_array, _not_flat, _not_null_free);\n+const TypePtr* TypeAryKlassPtr::cast_to_ptr_type(PTR ptr) const {\n+  assert(_base == AryKlassPtr, \"subclass must override cast_to_ptr_type\");\n+  if (ptr == _ptr) return this;\n+  return make(ptr, elem(), _klass, _offset, is_not_flat(), is_not_null_free(), _null_free);\n+}\n+\n+bool TypeAryKlassPtr::must_be_exact() const {\n+  if (_elem == Type::BOTTOM) return false;\n+  if (_elem == Type::TOP   ) return false;\n+  const TypeKlassPtr*  tk = _elem->isa_klassptr();\n+  if (!tk)             return true;   \/\/ a primitive type, like int\n+  return tk->must_be_exact();\n@@ -5619,3 +6107,15 @@\n-const Type *TypeKlassPtr::cast_to_exactness(bool klass_is_exact) const {\n-  if( klass_is_exact == _klass_is_exact ) return this;\n-  return make(klass_is_exact ? Constant : NotNull, _klass, _offset, _flatten_array, _not_flat, _not_null_free);\n+const TypeKlassPtr *TypeAryKlassPtr::cast_to_exactness(bool klass_is_exact) const {\n+  if (must_be_exact() && !klass_is_exact) return this;  \/\/ cannot clear xk\n+  ciKlass* k = _klass;\n+  const Type* elem = this->elem();\n+  if (elem->isa_klassptr() && !klass_is_exact) {\n+    elem = elem->is_klassptr()->cast_to_exactness(klass_is_exact);\n+  }\n+  bool not_flat = is_not_flat();\n+  bool not_null_free = is_not_null_free();\n+  if (klass() != NULL && klass()->is_obj_array_klass() && klass_is_exact) {\n+    \/\/ An object array can't be flat or null-free if the klass is exact\n+    not_flat = true;\n+    not_null_free = true;\n+  }\n+  return make(klass_is_exact ? Constant : NotNull, elem, k, _offset, not_flat, not_null_free, _null_free);\n@@ -5627,2 +6127,2 @@\n-\/\/ It will be NotNull, and exact if and only if the klass type is exact.\n-const TypeOopPtr* TypeKlassPtr::as_instance_type() const {\n+\/\/ It will be exact if and only if the klass type is exact.\n+const TypeOopPtr* TypeAryKlassPtr::as_instance_type() const {\n@@ -5632,9 +6132,4 @@\n-  const TypeOopPtr* toop = TypeOopPtr::make_from_klass_raw(k);\n-  guarantee(toop != NULL, \"need type for given klass\");\n-  toop = toop->cast_to_ptr_type(TypePtr::NotNull)->is_oopptr();\n-  if (flatten_array() && !klass()->is_inlinetype()) {\n-    toop = toop->is_instptr()->cast_to_flatten_array();\n-  } else if (is_not_null_free()) {\n-    toop = toop->is_aryptr()->cast_to_not_null_free();\n-  } else if (is_not_flat()) {\n-    toop = toop->is_aryptr()->cast_to_not_flat();\n+  const Type* el = elem()->isa_klassptr() ? elem()->is_klassptr()->as_instance_type()->is_oopptr()->cast_to_exactness(false) : elem();\n+  bool null_free = _null_free != 0;\n+  if (null_free && el->isa_ptr()) {\n+    el = el->is_ptr()->join_speculative(TypePtr::NOTNULL);\n@@ -5642,1 +6137,3 @@\n-  return toop->cast_to_exactness(xk)->is_oopptr();\n+  bool not_flat = is_not_flat();\n+  bool not_null_free = is_not_null_free();\n+  return TypeAryPtr::make(TypePtr::BotPTR, TypeAry::make(el, TypeInt::POS, false, not_flat, not_null_free), k, xk, Offset(0));\n@@ -5648,1 +6145,1 @@\n-const Type    *TypeKlassPtr::xmeet( const Type *t ) const {\n+const Type    *TypeAryKlassPtr::xmeet( const Type *t ) const {\n@@ -5684,1 +6181,1 @@\n-      return make(ptr, klass(), offset, flatten_array(), is_not_flat(), is_not_null_free());\n+      return make(ptr, _elem, klass(), offset, is_not_flat(), is_not_null_free(), _null_free);\n@@ -5715,9 +6212,27 @@\n-  case KlassPtr: {  \/\/ Meet two KlassPtr types\n-    const TypeKlassPtr *tkls = t->is_klassptr();\n-    Offset  off  = meet_offset(tkls->offset());\n-    PTR  ptr     = meet_ptr(tkls->ptr());\n-\n-    if (klass() == NULL || tkls->klass() == NULL) {\n-      ciKlass* k = NULL;\n-      if (ptr == Constant) {\n-        k = (klass() == NULL) ? tkls->klass() : klass();\n+  case AryKlassPtr: {  \/\/ Meet two KlassPtr types\n+    const TypeAryKlassPtr *tap = t->is_aryklassptr();\n+    Offset off = meet_offset(tap->offset());\n+    const Type* elem = _elem->meet(tap->_elem);\n+    PTR ptr = meet_ptr(tap->ptr());\n+    ciKlass* res_klass = NULL;\n+    bool res_xk = false;\n+    bool res_not_flat = false;\n+    bool res_not_null_free = false;\n+    MeetResult res = meet_aryptr(ptr, elem, this->klass(), tap->klass(), this->klass_is_exact(), tap->klass_is_exact(),\n+                                 this->ptr(), tap->ptr(), this->is_not_flat(), tap->is_not_flat(),\n+                                 this->is_not_null_free(), tap->is_not_null_free(),\n+                                 res_klass, res_xk, res_not_flat, res_not_null_free);\n+    assert(res_xk == (ptr == Constant), \"\");\n+    int null_free = _null_free & tap->_null_free;\n+    if (res == NOT_SUBTYPE) {\n+      null_free = 0;\n+    } else if (res == SUBTYPE) {\n+      \/\/ FIXME: should this be done for TypeAryPtr::xmeet() as well? Does this need to be moved into meet_aryptr()?\n+      if (above_centerline(tap->ptr()) && _elem->isa_inlinetype()) {\n+        elem = _elem;\n+      } else if (above_centerline(_ptr) && tap->_elem->isa_inlinetype()) {\n+        elem = tap->_elem;\n+      } else if (below_centerline(tap->ptr()) && _elem->isa_inlinetype()) {\n+        elem = tap->_elem;\n+      } else if (below_centerline(_ptr) && tap->_elem->isa_inlinetype()) {\n+        elem = _elem;\n@@ -5725,2 +6240,0 @@\n-      return make(ptr, k, off);\n-    }\n@@ -5728,6 +6241,5 @@\n-    \/\/ Check for easy case; klasses are equal (and perhaps not loaded!)\n-    \/\/ If we have constants, then we created oops so classes are loaded\n-    \/\/ and we can handle the constants further down.  This case handles\n-    \/\/ not-loaded classes\n-    if (ptr != Constant && tkls->klass()->equals(klass()) && flatten_array() == tkls->flatten_array() && is_not_flat() == tkls->is_not_flat() && is_not_null_free() && tkls->is_not_null_free()) {\n-      return make(ptr, klass(), off, flatten_array(), is_not_flat(), is_not_null_free());\n+      if (above_centerline(tap->ptr()) && !above_centerline(this->ptr())) {\n+        null_free = _null_free;\n+      } else if (above_centerline(this->ptr()) && !above_centerline(tap->ptr())) {\n+        null_free = tap->_null_free;\n+      }\n@@ -5735,0 +6247,6 @@\n+    return make(ptr, elem, res_klass, off, res_not_flat, res_not_null_free, null_free);\n+  } \/\/ End of case KlassPtr\n+  case InstKlassPtr: {\n+    const TypeInstKlassPtr *tp = t->is_instklassptr();\n+    Offset offset = meet_offset(tp->offset());\n+    PTR ptr = meet_ptr(tp->ptr());\n@@ -5736,20 +6254,34 @@\n-    \/\/ Classes require inspection in the Java klass hierarchy.  Must be loaded.\n-    ciKlass* tkls_klass = tkls->klass();\n-    ciKlass* this_klass = this->klass();\n-    assert( tkls_klass->is_loaded(), \"This class should have been loaded.\");\n-    assert( this_klass->is_loaded(), \"This class should have been loaded.\");\n-    bool flatten_array = below_centerline(ptr) ? (this->flatten_array() && tkls->flatten_array()) : (this->flatten_array() || tkls->flatten_array());\n-    bool is_not_flat = this->is_not_flat() && tkls->is_not_flat();\n-    bool is_not_null_free = this->is_not_null_free() && tkls->is_not_null_free();\n-\n-    \/\/ If 'this' type is above the centerline and is a superclass of the\n-    \/\/ other, we can treat 'this' as having the same type as the other.\n-    if ((above_centerline(this->ptr())) &&\n-        tkls_klass->is_subtype_of(this_klass)) {\n-      this_klass = tkls_klass;\n-    }\n-    \/\/ If 'tinst' type is above the centerline and is a superclass of the\n-    \/\/ other, we can treat 'tinst' as having the same type as the other.\n-    if ((above_centerline(tkls->ptr())) &&\n-        this_klass->is_subtype_of(tkls_klass)) {\n-      tkls_klass = this_klass;\n+    switch (ptr) {\n+    case TopPTR:\n+    case AnyNull:                \/\/ Fall 'down' to dual of object klass\n+      \/\/ For instances when a subclass meets a superclass we fall\n+      \/\/ below the centerline when the superclass is exact. We need to\n+      \/\/ do the same here.\n+      if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n+        return TypeAryKlassPtr::make(ptr, _elem, _klass, offset, is_not_flat(), is_not_null_free(), _null_free);\n+      } else {\n+        \/\/ cannot subclass, so the meet has to fall badly below the centerline\n+        ptr = NotNull;\n+        return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), offset, false);\n+      }\n+    case Constant:\n+    case NotNull:\n+    case BotPTR:                \/\/ Fall down to object klass\n+      \/\/ LCA is object_klass, but if we subclass from the top we can do better\n+      if (above_centerline(tp->ptr())) {\n+        \/\/ If 'tp'  is above the centerline and it is Object class\n+        \/\/ then we can subclass in the Java class hierarchy.\n+        \/\/ For instances when a subclass meets a superclass we fall\n+        \/\/ below the centerline when the superclass is exact. We need\n+        \/\/ to do the same here.\n+        if (tp->klass()->equals(ciEnv::current()->Object_klass()) && !tp->klass_is_exact()) {\n+          \/\/ that is, my array type is a subtype of 'tp' klass\n+          return make(ptr, _elem, _klass, offset, is_not_flat(), is_not_null_free(), _null_free);\n+        }\n+      }\n+      \/\/ The other case cannot happen, since t cannot be a subtype of an array.\n+      \/\/ The meet falls down to Object class below centerline.\n+      if (ptr == Constant)\n+         ptr = NotNull;\n+      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), offset, false);\n+    default: typerr(t);\n@@ -5757,13 +6289,9 @@\n-\n-    \/\/ Check for classes now being equal\n-    if (tkls_klass->equals(this_klass)) {\n-      \/\/ If the klasses are equal, the constants may still differ.  Fall to\n-      \/\/ NotNull if they do (neither constant is NULL; that is a special case\n-      \/\/ handled elsewhere).\n-      if( ptr == Constant ) {\n-        if (this->_ptr == Constant && tkls->_ptr == Constant &&\n-            this->klass()->equals(tkls->klass()));\n-        else if (above_centerline(this->ptr()));\n-        else if (above_centerline(tkls->ptr()));\n-        else\n-          ptr = NotNull;\n+  }\n+  case InlineType: {\n+    const TypeInlineType* tv = t->is_inlinetype();\n+    if (above_centerline(ptr())) {\n+      return TypeInstKlassPtr::BOTTOM;\n+    } else {\n+      PTR ptr = this->_ptr;\n+      if (ptr == Constant) {\n+        ptr = NotNull;\n@@ -5771,11 +6299,3 @@\n-      return make(ptr, this_klass, off, flatten_array, is_not_flat, is_not_null_free);\n-    } \/\/ Else classes are not equal\n-\n-    \/\/ Since klasses are different, we require the LCA in the Java\n-    \/\/ class hierarchy - which means we have to fall to at least NotNull.\n-    if( ptr == TopPTR || ptr == AnyNull || ptr == Constant )\n-      ptr = NotNull;\n-    \/\/ Now we find the LCA of Java classes\n-    ciKlass* k = this_klass->least_common_ancestor(tkls_klass);\n-    return make(ptr, k, off, this->flatten_array() && tkls->flatten_array(), is_not_flat, is_not_null_free);\n-  } \/\/ End of case KlassPtr\n+      return TypeInstKlassPtr::make(ptr, ciEnv::current()->Object_klass(), Offset(0));\n+    }\n+  }\n@@ -5789,2 +6309,2 @@\n-const Type    *TypeKlassPtr::xdual() const {\n-  return new TypeKlassPtr(dual_ptr(), klass(), dual_offset(), flatten_array(), !is_not_flat(), !is_not_null_free());\n+const Type    *TypeAryKlassPtr::xdual() const {\n+  return new TypeAryKlassPtr(dual_ptr(), elem()->dual(), klass(), dual_offset(), !is_not_flat(), !is_not_null_free(), -_null_free);\n@@ -5794,14 +6314,3 @@\n-intptr_t TypeKlassPtr::get_con() const {\n-  assert( _ptr == Null || _ptr == Constant, \"\" );\n-  assert(offset() >= 0, \"\");\n-\n-  if (offset() != 0) {\n-    \/\/ After being ported to the compiler interface, the compiler no longer\n-    \/\/ directly manipulates the addresses of oops.  Rather, it only has a pointer\n-    \/\/ to a handle at compile time.  This handle is embedded in the generated\n-    \/\/ code and dereferenced at the time the nmethod is made.  Until that time,\n-    \/\/ it is not reasonable to do arithmetic with the addresses of oops (we don't\n-    \/\/ have access to the addresses!).  This does not seem to currently happen,\n-    \/\/ but this assertion here is to help prevent its occurence.\n-    tty->print_cr(\"Found oop constant with non-zero offset\");\n-    ShouldNotReachHere();\n+ciKlass* TypeAryKlassPtr::klass() const {\n+    if (_klass != NULL) {\n+    return _klass;\n@@ -5809,2 +6318,27 @@\n-\n-  return (intptr_t)klass()->constant_encoding();\n+  ciKlass* k = NULL;\n+  const Type* el = elem();\n+  if (el->isa_instklassptr()) {\n+    \/\/ Compute object array klass from element klass\n+    bool null_free = el->is_instklassptr()->klass()->is_inlinetype() && el->isa_instklassptr()->ptr() != TypePtr::TopPTR && (_null_free != 0);\n+    k = ciArrayKlass::make(el->is_klassptr()->klass(), null_free);\n+    ((TypeAryKlassPtr*)this)->_klass = k;\n+  } else if (el->isa_inlinetype()) {\n+    \/\/ If element type is TypeInlineType::BOTTOM, inline_klass() will be null.\n+    if (el->inline_klass() != NULL) {\n+      k = ciArrayKlass::make(el->inline_klass(), \/* null_free *\/ true);\n+      ((TypeAryKlassPtr*)this)->_klass = k;\n+    }\n+  } else if (el->isa_aryklassptr() != NULL) {\n+    \/\/ Compute array klass from element klass\n+    ciKlass* k_elem = el->is_aryklassptr()->klass();\n+    \/\/ If element type is something like bottom[], k_elem will be null.\n+    if (k_elem != NULL) {\n+      k = ciObjArrayKlass::make(k_elem);\n+      ((TypeAryKlassPtr*)this)->_klass = k;\n+    }\n+  } else if ((elem()->base() == Type::Top) ||\n+             (elem()->base() == Type::Bottom)) {\n+  } else {\n+    k = ciTypeArrayKlass::make(elem()->basic_type());\n+  }\n+  return k;\n@@ -5812,0 +6346,1 @@\n+\n@@ -5815,1 +6350,1 @@\n-void TypeKlassPtr::dump2( Dict & d, uint depth, outputStream *st ) const {\n+void TypeAryKlassPtr::dump2( Dict & d, uint depth, outputStream *st ) const {\n@@ -5821,5 +6356,4 @@\n-      if (klass() != NULL) {\n-        const char* name = klass()->name()->as_utf8();\n-        st->print(\"klass %s: \" INTPTR_FORMAT, name, p2i(klass()));\n-      } else {\n-        st->print(\"klass BOTTOM\");\n+      st->print(\"[\");\n+      if (_elem->isa_inlinetype()) {\n+        const char *name = _elem->is_inlinetype()->inline_klass()->name()->as_utf8();\n+        st->print(\"precise %s: \" INTPTR_FORMAT \" \", name, p2i(klass()));\n@@ -5827,0 +6361,2 @@\n+      _elem->dump2(d, depth, st);\n+      st->print(\": \");\n@@ -5829,1 +6365,1 @@\n-    if( !WizardMode && !Verbose && !_klass_is_exact ) break;\n+    if( !WizardMode && !Verbose && _ptr != Constant ) break;\n@@ -5833,1 +6369,1 @@\n-    if( _klass_is_exact ) st->print(\":exact\");\n+    if( _ptr == Constant ) st->print(\":exact\");\n@@ -5839,1 +6375,0 @@\n-    if (_flatten_array) st->print(\":flatten array\");\n@@ -5842,0 +6377,1 @@\n+    if (_null_free != 0) st->print(\":null free(%d)\", _null_free);\n@@ -5850,1 +6386,9 @@\n-\n+const Type* TypeAryKlassPtr::base_element_type(int& dims) const {\n+  const Type* elem = this->elem();\n+  dims = 1;\n+  while (elem->isa_aryklassptr()) {\n+    elem = elem->is_aryklassptr()->elem();\n+    dims++;\n+  }\n+  return elem;\n+}\n","filename":"src\/hotspot\/share\/opto\/type.cpp","additions":929,"deletions":385,"binary":false,"changes":1314,"status":"modified"},{"patch":"@@ -73,0 +73,2 @@\n+class       TypeInstKlassPtr;\n+class       TypeAryKlassPtr;\n@@ -115,0 +117,2 @@\n+    InstKlassPtr,\n+    AryKlassPtr,\n@@ -351,0 +355,4 @@\n+  const TypeInstKlassPtr  *isa_instklassptr() const;  \/\/ Returns NULL if not IntKlassPtr\n+  const TypeInstKlassPtr  *is_instklassptr() const;   \/\/ assert if not IntKlassPtr\n+  const TypeAryKlassPtr   *isa_aryklassptr() const;   \/\/ Returns NULL if not AryKlassPtr\n+  const TypeAryKlassPtr   *is_aryklassptr() const;    \/\/ assert if not AryKlassPtr\n@@ -995,0 +1003,22 @@\n+  \/\/ TypeInstPtr (TypeAryPtr resp.) and TypeInstKlassPtr (TypeAryKlassPtr resp.) implement very similar meet logic.\n+  \/\/ The logic for meeting 2 instances (2 arrays resp.) is shared in the 2 utility methods below. However the logic for\n+  \/\/ the oop and klass versions can be slightly different and extra logic may have to be executed depending on what\n+  \/\/ exact case the meet falls into. The MeetResult struct is used by the utility methods to communicate what case was\n+  \/\/ encountered so the right logic specific to klasses or oops can be executed.,\n+  enum MeetResult {\n+    QUICK,\n+    UNLOADED,\n+    SUBTYPE,\n+    NOT_SUBTYPE,\n+    LCA\n+  };\n+  static MeetResult\n+  meet_instptr(PTR &ptr, ciKlass* this_klass, ciKlass* tinst_klass, bool this_xk, bool tinst_xk, PTR this_ptr,\n+               PTR tinst_ptr, bool this_flatten_array, bool tinst_flatten_array, ciKlass*&res_klass, bool &res_xk,\n+               bool& res_flatten_array);\n+  static MeetResult\n+  meet_aryptr(PTR& ptr, const Type*& elem, ciKlass* this_klass, ciKlass* tap_klass, bool this_xk, bool tap_xk,\n+              PTR this_ptr, PTR tap_ptr, bool this_not_flat, bool tap_not_flat,\n+              bool this_not_null_free, bool tap_not_null_free, ciKlass*& res_klass,\n+              bool& res_xk, bool& res_not_flat, bool& res_not_null_free);\n+\n@@ -1084,1 +1114,1 @@\n-  virtual const Type *cast_to_ptr_type(PTR ptr) const;\n+  virtual const TypeRawPtr* cast_to_ptr_type(PTR ptr) const;\n@@ -1185,1 +1215,1 @@\n-  virtual const Type *cast_to_ptr_type(PTR ptr) const;\n+  virtual const TypeOopPtr* cast_to_ptr_type(PTR ptr) const;\n@@ -1192,1 +1222,1 @@\n-  const TypeKlassPtr* as_klass_type() const;\n+  virtual const TypeKlassPtr* as_klass_type(bool try_for_exact = false) const;\n@@ -1272,1 +1302,1 @@\n-  virtual const Type *cast_to_ptr_type(PTR ptr) const;\n+  virtual const TypeInstPtr* cast_to_ptr_type(PTR ptr) const;\n@@ -1293,0 +1323,2 @@\n+  const TypeKlassPtr* as_klass_type(bool try_for_exact = false) const;\n+\n@@ -1375,1 +1407,1 @@\n-  virtual const Type *cast_to_ptr_type(PTR ptr) const;\n+  virtual const TypeAryPtr* cast_to_ptr_type(PTR ptr) const;\n@@ -1415,0 +1447,1 @@\n+  virtual const TypeKlassPtr* as_klass_type(bool try_for_exact = false) const;\n@@ -1467,1 +1500,1 @@\n-  virtual const Type *cast_to_ptr_type(PTR ptr) const;\n+  virtual const TypeMetadataPtr* cast_to_ptr_type(PTR ptr) const;\n@@ -1487,2 +1520,2 @@\n-  TypeKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array, bool not_flat, bool not_null_free);\n-\n+  TypeKlassPtr(TYPES t, PTR ptr, ciKlass* klass, Offset offset);\n+\n@@ -1491,1 +1524,2 @@\n- public:\n+\n+public:\n@@ -1493,1 +1527,1 @@\n-  virtual int hash() const;             \/\/ Type specific hashing\n+  virtual int hash() const;\n@@ -1495,1 +1529,3 @@\n- private:\n+  virtual bool must_be_exact() const { ShouldNotReachHere(); return false; }\n+\n+protected:\n@@ -1499,2 +1535,35 @@\n-  \/\/ Does the type exclude subclasses of the klass?  (Inexact == polymorphic.)\n-  bool _klass_is_exact;\n+public:\n+\n+  virtual ciKlass* klass() const { return  _klass; }\n+  bool klass_is_exact()    const { return _ptr == Constant; }\n+  bool  is_loaded() const { return klass()->is_loaded(); }\n+\n+  static const TypeKlassPtr* make(ciKlass* klass);\n+  static const TypeKlassPtr *make(PTR ptr, ciKlass* klass, Offset offset);\n+\n+\n+  virtual const TypePtr* cast_to_ptr_type(PTR ptr) const { ShouldNotReachHere(); return NULL; }\n+\n+  virtual const TypeKlassPtr *cast_to_exactness(bool klass_is_exact) const { ShouldNotReachHere(); return NULL; }\n+\n+  \/\/ corresponding pointer to instance, for a given class\n+  virtual const TypeOopPtr* as_instance_type() const { ShouldNotReachHere(); return NULL; }\n+\n+  virtual const TypePtr *add_offset( intptr_t offset ) const { ShouldNotReachHere(); return NULL; }\n+  virtual const Type    *xmeet( const Type *t ) const { ShouldNotReachHere(); return NULL; }\n+  virtual const Type    *xdual() const { ShouldNotReachHere(); return NULL; }\n+\n+  virtual intptr_t get_con() const;\n+\n+  virtual const TypeKlassPtr* with_offset(intptr_t offset) const { ShouldNotReachHere(); return NULL; }\n+};\n+\n+\/\/ Instance klass pointer, mirrors TypeInstPtr\n+class TypeInstKlassPtr : public TypeKlassPtr {\n+\n+  TypeInstKlassPtr(PTR ptr, ciKlass* klass, Offset offset, bool flatten_array)\n+    : TypeKlassPtr(InstKlassPtr, ptr, klass, offset), _flatten_array(flatten_array) {\n+  }\n+\n+  virtual bool must_be_exact() const;\n+\n@@ -1502,2 +1571,0 @@\n-  const bool _not_flat;      \/\/ Array is never flattened\n-  const bool _not_null_free; \/\/ Array is never null-free\n@@ -1506,2 +1573,23 @@\n-  ciKlass* klass() const { return  _klass; }\n-  bool klass_is_exact()    const { return _klass_is_exact; }\n+  \/\/ Instance klass ignoring any interface\n+  ciInstanceKlass* instance_klass() const { return klass()->as_instance_klass();     }\n+\n+  virtual bool can_be_inline_type() const { return EnableValhalla && (_klass == NULL || _klass->can_be_inline_klass(klass_is_exact())); }\n+\n+  static const TypeInstKlassPtr *make(ciKlass* k) {\n+    return make(TypePtr::Constant, k, Offset(0), false);\n+  }\n+  static const TypeInstKlassPtr *make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array = false);\n+\n+  virtual const TypePtr* cast_to_ptr_type(PTR ptr) const;\n+\n+  virtual const TypeKlassPtr *cast_to_exactness(bool klass_is_exact) const;\n+\n+  \/\/ corresponding pointer to instance, for a given class\n+  virtual const TypeOopPtr* as_instance_type() const;\n+  virtual int hash() const;\n+  virtual bool eq(const Type *t) const;\n+\n+  virtual const TypePtr *add_offset( intptr_t offset ) const;\n+  virtual const Type    *xmeet( const Type *t ) const;\n+  virtual const Type    *xdual() const;\n+  virtual const TypeKlassPtr* with_offset(intptr_t offset) const;\n@@ -1509,1 +1597,0 @@\n-  virtual bool can_be_inline_type() const { return EnableValhalla && (_klass == NULL || _klass->can_be_inline_klass(_klass_is_exact)); }\n@@ -1511,2 +1598,0 @@\n-  virtual bool is_not_flat() const { return _not_flat; }\n-  virtual bool is_not_null_free() const { return _not_null_free; }\n@@ -1514,1 +1599,8 @@\n-  bool  is_loaded() const { return klass() != NULL && klass()->is_loaded(); }\n+  \/\/ Convenience common pre-built types.\n+  static const TypeInstKlassPtr* OBJECT; \/\/ Not-null object klass or below\n+  static const TypeInstKlassPtr* OBJECT_OR_NULL; \/\/ Maybe-null version of same\n+\n+#ifndef PRODUCT\n+  virtual void dump2( Dict &d, uint depth, outputStream *st ) const; \/\/ Specialized per-Type dumping\n+#endif\n+};\n@@ -1516,6 +1608,9 @@\n-  \/\/ ptr to klass 'k'\n-  static const TypeKlassPtr* make(ciKlass* k) {\n-    bool not_null_free = k->is_array_klass() && ( k->as_array_klass()->element_klass() == NULL ||\n-                                                 !k->as_array_klass()->element_klass()->can_be_inline_klass(true));\n-    bool not_flat = k->is_array_klass() && !k->is_flat_array_klass();\n-    return make(TypePtr::Constant, k, Offset(0), false, not_flat, not_null_free);\n+\/\/ Array klass pointer, mirrors TypeAryPtr\n+class TypeAryKlassPtr : public TypeKlassPtr {\n+  const Type *_elem;\n+  const bool _not_flat;      \/\/ Array is never flattened\n+  const bool _not_null_free; \/\/ Array is never null-free\n+  const int _null_free;\n+\n+  TypeAryKlassPtr(PTR ptr, const Type *elem, ciKlass* klass, Offset offset, bool not_flat, int not_null_free, bool null_free)\n+    : TypeKlassPtr(AryKlassPtr, ptr, klass, offset), _elem(elem), _not_flat(not_flat), _not_null_free(not_null_free), _null_free(null_free) {\n@@ -1523,3 +1618,1 @@\n-  \/\/ ptr to klass 'k' or sub-klass\n-  static const TypeKlassPtr* make(PTR ptr, ciKlass* k, Offset offset, bool flatten_array = false, bool not_flat = false, bool not_null_free = false);\n-  virtual const Type *cast_to_ptr_type(PTR ptr) const;\n+  virtual bool must_be_exact() const;\n@@ -1528,1 +1621,18 @@\n-  virtual const Type *cast_to_exactness(bool klass_is_exact) const;\n+public:\n+  virtual ciKlass* klass() const;\n+\n+  \/\/ returns base element type, an instance klass (and not interface) for object arrays\n+  const Type* base_element_type(int& dims) const;\n+\n+  static const TypeAryKlassPtr *make(PTR ptr, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, int null_free);\n+  static const TypeAryKlassPtr *make(PTR ptr, const Type *elem, ciKlass* k, Offset offset, bool not_flat, bool not_null_free, int null_free);\n+  static const TypeAryKlassPtr* make(ciKlass* klass, PTR ptr = Constant, Offset offset= Offset(0));\n+\n+  const Type *elem() const { return _elem; }\n+\n+  virtual bool eq(const Type *t) const;\n+  virtual int hash() const;             \/\/ Type specific hashing\n+\n+  virtual const TypePtr* cast_to_ptr_type(PTR ptr) const;\n+\n+  virtual const TypeKlassPtr *cast_to_exactness(bool klass_is_exact) const;\n@@ -1531,1 +1641,1 @@\n-  const TypeOopPtr* as_instance_type() const;\n+  virtual const TypeOopPtr* as_instance_type() const;\n@@ -1537,1 +1647,9 @@\n-  virtual intptr_t get_con() const;\n+  virtual const TypeKlassPtr* with_offset(intptr_t offset) const;\n+\n+  virtual bool empty(void) const {\n+    return TypeKlassPtr::empty() || _elem->empty();\n+  }\n+\n+  virtual bool is_not_flat() const { return _not_flat; }\n+  virtual bool is_not_null_free() const { return _not_null_free; }\n+  bool null_free() const { return _null_free; }\n@@ -1539,3 +1657,0 @@\n-  \/\/ Convenience common pre-built types.\n-  static const TypeKlassPtr* OBJECT; \/\/ Not-null object klass or below\n-  static const TypeKlassPtr* OBJECT_OR_NULL; \/\/ Maybe-null version of same\n@@ -1849,1 +1964,1 @@\n-  assert(_base >= AnyPtr && _base <= KlassPtr, \"Not a pointer\");\n+  assert(_base >= AnyPtr && _base <= AryKlassPtr, \"Not a pointer\");\n@@ -1855,1 +1970,1 @@\n-  return (_base >= AnyPtr && _base <= KlassPtr) ? (TypePtr*)this : NULL;\n+  return (_base >= AnyPtr && _base <= AryKlassPtr) ? (TypePtr*)this : NULL;\n@@ -1936,1 +2051,1 @@\n-  return (_base == KlassPtr) ? (TypeKlassPtr*)this : NULL;\n+  return (_base >= KlassPtr && _base <= AryKlassPtr ) ? (TypeKlassPtr*)this : NULL;\n@@ -1940,1 +2055,1 @@\n-  assert( _base == KlassPtr, \"Not a klass pointer\" );\n+  assert(_base >= KlassPtr && _base <= AryKlassPtr, \"Not a klass pointer\");\n@@ -1944,0 +2059,18 @@\n+inline const TypeInstKlassPtr *Type::isa_instklassptr() const {\n+  return (_base == InstKlassPtr) ? (TypeInstKlassPtr*)this : NULL;\n+}\n+\n+inline const TypeInstKlassPtr *Type::is_instklassptr() const {\n+  assert(_base == InstKlassPtr, \"Not a klass pointer\");\n+  return (TypeInstKlassPtr*)this;\n+}\n+\n+inline const TypeAryKlassPtr *Type::isa_aryklassptr() const {\n+  return (_base == AryKlassPtr) ? (TypeAryKlassPtr*)this : NULL;\n+}\n+\n+inline const TypeAryKlassPtr *Type::is_aryklassptr() const {\n+  assert(_base == AryKlassPtr, \"Not a klass pointer\");\n+  return (TypeAryKlassPtr*)this;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/type.hpp","additions":173,"deletions":40,"binary":false,"changes":213,"status":"modified"},{"patch":"@@ -209,3 +209,1 @@\n-  if (_class_holder.peek() != NULL) {\n-    _class_holder.release(JvmtiExport::jvmti_oop_storage());\n-  }\n+  _class_holder.release(JvmtiExport::jvmti_oop_storage());\n","filename":"src\/hotspot\/share\/prims\/jvmtiImpl.cpp","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -27,1 +27,1 @@\n-#include \"cds\/cdsoffsets.hpp\"\n+#include \"cds\/cdsConstants.hpp\"\n@@ -2094,2 +2094,2 @@\n-WB_ENTRY(jboolean, WB_IsJavaHeapArchiveSupported(JNIEnv* env))\n-  return HeapShared::is_heap_object_archiving_allowed();\n+WB_ENTRY(jboolean, WB_CanWriteJavaHeapArchive(JNIEnv* env))\n+  return HeapShared::can_write();\n@@ -2109,1 +2109,1 @@\n-WB_ENTRY(jint, WB_GetOffsetForName(JNIEnv* env, jobject o, jstring name))\n+WB_ENTRY(jint, WB_GetCDSOffsetForName(JNIEnv* env, jobject o, jstring name))\n@@ -2112,2 +2112,9 @@\n-  int result = CDSOffsets::find_offset(c_name);\n-  return (jint)result;\n+  jint result = (jint)CDSConstants::get_cds_offset(c_name);\n+  return result;\n+WB_END\n+\n+WB_ENTRY(jint, WB_GetCDSConstantForName(JNIEnv* env, jobject o, jstring name))\n+  ResourceMark rm;\n+  char* c_name = java_lang_String::as_utf8_string(JNIHandles::resolve_non_null(name));\n+  jint result = (jint)CDSConstants::get_cds_constant(c_name);\n+  return result;\n@@ -2476,5 +2483,1 @@\n-  intx tty_token = -1;\n-  if (log) {\n-    tty_token = ttyLocker::hold_tty();\n-    tty->print_cr(\"[WhiteBox::VerifyFrames] Walking Frames\");\n-  }\n+  stringStream st;\n@@ -2485,1 +2488,1 @@\n-      current_frame->print_value();\n+      current_frame->print_value_on(&st, NULL);\n@@ -2490,0 +2493,2 @@\n+    tty->print_cr(\"[WhiteBox::VerifyFrames] Walking Frames\");\n+    tty->print_raw(st.as_string());\n@@ -2491,1 +2496,0 @@\n-    ttyLocker::release_tty(tty_token);\n@@ -2550,1 +2554,2 @@\n-  {CC\"getOffsetForName0\", CC\"(Ljava\/lang\/String;)I\",  (void*)&WB_GetOffsetForName},\n+  {CC\"getCDSOffsetForName0\", CC\"(Ljava\/lang\/String;)I\",  (void*)&WB_GetCDSOffsetForName},\n+  {CC\"getCDSConstantForName0\", CC\"(Ljava\/lang\/String;)I\",  (void*)&WB_GetCDSConstantForName},\n@@ -2742,1 +2747,1 @@\n-  {CC\"isJavaHeapArchiveSupported\",        CC\"()Z\",    (void*)&WB_IsJavaHeapArchiveSupported },\n+  {CC\"canWriteJavaHeapArchive\",           CC\"()Z\",    (void*)&WB_CanWriteJavaHeapArchive },\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":20,"deletions":15,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -75,1 +75,0 @@\n-const char*  Arguments::_gc_log_filename        = NULL;\n@@ -96,0 +95,2 @@\n+LegacyGCLogging Arguments::_legacyGCLogging     = { 0, 0 };\n+\n@@ -537,0 +538,1 @@\n+  { \"InlineFrequencyCount\",         JDK_Version::undefined(), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n@@ -2344,1 +2346,3 @@\n-        LogConfiguration::configure_stdout(LogLevel::Info, true, LOG_TAGS(gc));\n+        if (_legacyGCLogging.lastFlag == 0) {\n+          _legacyGCLogging.lastFlag = 1;\n+        }\n@@ -2751,1 +2755,2 @@\n-      _gc_log_filename = os::strdup_check_oom(tail);\n+      _legacyGCLogging.lastFlag = 2;\n+      _legacyGCLogging.file = os::strdup_check_oom(tail);\n@@ -3757,1 +3762,1 @@\n-  if (_gc_log_filename != NULL) {\n+  if (_legacyGCLogging.lastFlag == 2) {\n@@ -3763,2 +3768,2 @@\n-    return LogConfiguration::parse_log_arguments(_gc_log_filename, gc_conf, NULL, NULL, &errstream);\n-  } else if (PrintGC || PrintGCDetails) {\n+    return LogConfiguration::parse_log_arguments(_legacyGCLogging.file, gc_conf, NULL, NULL, &errstream);\n+  } else if (PrintGC || PrintGCDetails || (_legacyGCLogging.lastFlag == 1)) {\n@@ -4051,0 +4056,5 @@\n+\n+  if (LogTouchedMethods) {\n+    warning(\"LogTouchedMethods is not supported for Zero\");\n+    FLAG_SET_DEFAULT(LogTouchedMethods, false);\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":16,"deletions":6,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -149,4 +149,5 @@\n-  ttyLocker ttyl;\n-  tty->print_cr(\"UnrollBlock\");\n-  tty->print_cr(\"  size_of_deoptimized_frame = %d\", _size_of_deoptimized_frame);\n-  tty->print(   \"  frame_sizes: \");\n+  ResourceMark rm;\n+  stringStream st;\n+  st.print_cr(\"UnrollBlock\");\n+  st.print_cr(\"  size_of_deoptimized_frame = %d\", _size_of_deoptimized_frame);\n+  st.print(   \"  frame_sizes: \");\n@@ -154,1 +155,1 @@\n-    tty->print(INTX_FORMAT \" \", frame_sizes()[index]);\n+    st.print(INTX_FORMAT \" \", frame_sizes()[index]);\n@@ -156,1 +157,2 @@\n-  tty->cr();\n+  st.cr();\n+  tty->print_raw(st.as_string());\n@@ -185,0 +187,36 @@\n+#ifndef PRODUCT\n+\/\/ print information about reallocated objects\n+static void print_objects(JavaThread* deoptee_thread,\n+                          GrowableArray<ScopeValue*>* objects, bool realloc_failures) {\n+  ResourceMark rm;\n+  stringStream st;  \/\/ change to logStream with logging\n+  st.print_cr(\"REALLOC OBJECTS in thread \" INTPTR_FORMAT, p2i(deoptee_thread));\n+  fieldDescriptor fd;\n+\n+  for (int i = 0; i < objects->length(); i++) {\n+    ObjectValue* sv = (ObjectValue*) objects->at(i);\n+    Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());\n+    Handle obj = sv->value();\n+\n+    st.print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(sv->value()()));\n+    k->print_value_on(&st);\n+    assert(obj.not_null() || k->is_inline_klass() || realloc_failures, \"reallocation was missed\");\n+    if (obj.is_null()) {\n+      if (k->is_inline_klass()) {\n+        st.print(\" is null\");\n+      } else {\n+        st.print(\" allocation failed\");\n+      }\n+    } else {\n+      st.print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n+    }\n+    st.cr();\n+\n+    if (Verbose && !obj.is_null()) {\n+      k->oop_print_on(obj(), &st);\n+    }\n+  }\n+  tty->print_raw(st.as_string());\n+}\n+#endif\n+\n@@ -227,1 +265,0 @@\n-      ttyLocker ttyl;\n@@ -260,3 +297,1 @@\n-      ttyLocker ttyl;\n-      tty->print_cr(\"REALLOC OBJECTS in thread \" INTPTR_FORMAT, p2i(deoptee_thread));\n-      Deoptimization::print_objects(objects, realloc_failures);\n+      print_objects(deoptee_thread, objects, realloc_failures);\n@@ -293,1 +328,2 @@\n-        ttyLocker ttyl;\n+        ResourceMark rm;\n+        stringStream st;\n@@ -299,1 +335,1 @@\n-              tty->print_cr(\"RELOCK OBJECTS in thread \" INTPTR_FORMAT, p2i(thread));\n+              st.print_cr(\"RELOCK OBJECTS in thread \" INTPTR_FORMAT, p2i(thread));\n@@ -304,1 +340,1 @@\n-                tty->print_cr(\"     object <\" INTPTR_FORMAT \"> DEFERRED relocking after wait\", p2i(mi->owner()));\n+                st.print_cr(\"     object <\" INTPTR_FORMAT \"> DEFERRED relocking after wait\", p2i(mi->owner()));\n@@ -310,1 +346,1 @@\n-              tty->print_cr(\"     failed reallocation for klass %s\", k->external_name());\n+              st.print_cr(\"     failed reallocation for klass %s\", k->external_name());\n@@ -312,1 +348,1 @@\n-              tty->print_cr(\"     object <\" INTPTR_FORMAT \"> locked\", p2i(mi->owner()));\n+              st.print_cr(\"     object <\" INTPTR_FORMAT \"> locked\", p2i(mi->owner()));\n@@ -316,0 +352,1 @@\n+        tty->print_raw(st.as_string());\n@@ -634,1 +671,0 @@\n-      ttyLocker ttyl;\n@@ -728,1 +764,0 @@\n-    ttyLocker ttyl;\n@@ -850,2 +885,0 @@\n-          ttyLocker ttyl;\n-\n@@ -872,1 +905,1 @@\n-        } \/\/ release tty lock before calling guarantee\n+        }\n@@ -1556,33 +1589,0 @@\n-\n-\n-#ifndef PRODUCT\n-\/\/ print information about reallocated objects\n-void Deoptimization::print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures) {\n-  fieldDescriptor fd;\n-  for (int i = 0; i < objects->length(); i++) {\n-    ObjectValue* sv = (ObjectValue*) objects->at(i);\n-    Klass* k = java_lang_Class::as_Klass(sv->klass()->as_ConstantOopReadValue()->value()());\n-    print_object(k, sv->value(), realloc_failures);\n-  }\n-}\n-\n-void Deoptimization::print_object(Klass* k, Handle obj, bool realloc_failures) {\n-  tty->print(\"     object <\" INTPTR_FORMAT \"> of type \", p2i(obj()));\n-  k->print_value();\n-  if (obj.is_null()) {\n-    if (k->is_inline_klass()) {\n-      tty->print(\" is null\");\n-    } else {\n-      assert(realloc_failures, \"reallocation was missed\");\n-      tty->print(\" allocation failed\");\n-    }\n-  } else {\n-    tty->print(\" allocated (%d bytes)\", obj->size() * HeapWordSize);\n-  }\n-  tty->cr();\n-\n-  if (Verbose && !obj.is_null()) {\n-    k->oop_print_on(obj(), tty);\n-  }\n-}\n-#endif\n@@ -1596,4 +1596,5 @@\n-    ttyLocker ttyl;\n-    tty->print(\"DEOPT PACKING thread \" INTPTR_FORMAT \" \", p2i(thread));\n-    fr.print_on(tty);\n-    tty->print_cr(\"     Virtual frames (innermost first):\");\n+    ResourceMark rm;\n+    stringStream st;\n+    st.print(\"DEOPT PACKING thread \" INTPTR_FORMAT \" \", p2i(thread));\n+    fr.print_on(&st);\n+    st.print_cr(\"     Virtual frames (innermost first):\");\n@@ -1602,2 +1603,2 @@\n-      tty->print(\"       %2d - \", index);\n-      vf->print_value();\n+      st.print(\"       %2d - \", index);\n+      vf->print_value_on(&st);\n@@ -1612,2 +1613,2 @@\n-      tty->print(\" - %s\", code_name);\n-      tty->print_cr(\" @ bci %d \", bci);\n+      st.print(\" - %s\", code_name);\n+      st.print_cr(\" @ bci %d \", bci);\n@@ -1615,2 +1616,2 @@\n-        vf->print();\n-        tty->cr();\n+        vf->print_on(&st);\n+        st.cr();\n@@ -1619,0 +1620,1 @@\n+    tty->print_raw(st.as_string());\n@@ -1641,1 +1643,0 @@\n-    ttyLocker ttyl;\n@@ -1949,1 +1950,0 @@\n-      ttyLocker ttyl;\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.cpp","additions":65,"deletions":65,"binary":false,"changes":130,"status":"modified"},{"patch":"@@ -187,4 +187,0 @@\n-#ifndef PRODUCT\n-  static void print_objects(GrowableArray<ScopeValue*>* objects, bool realloc_failures);\n-  static void print_object(Klass* k, Handle obj, bool realloc_failures);\n-#endif\n","filename":"src\/hotspot\/share\/runtime\/deoptimization.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -59,1 +59,1 @@\n-  return NULL;\n+  return vmSymbols::void_signature(); \/\/ return a default value (for code analyzers)\n","filename":"src\/hotspot\/share\/runtime\/fieldDescriptor.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -404,2 +404,0 @@\n-  NOT_PRODUCT(void pd_ps();)  \/\/ platform dependent frame printing\n-\n","filename":"src\/hotspot\/share\/runtime\/frame.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1421,1 +1421,1 @@\n-  develop(intx, InlineFrequencyRatio,    20,                                \\\n+  product(double, InlineFrequencyRatio, 0.25, DIAGNOSTIC,                   \\\n@@ -1423,6 +1423,0 @@\n-          range(0, max_jint)                                                \\\n-                                                                            \\\n-  product_pd(intx, InlineFrequencyCount, DIAGNOSTIC,                        \\\n-          \"Count of call site execution necessary to trigger frequent \"     \\\n-          \"inlining\")                                                       \\\n-          range(0, max_jint)                                                \\\n@@ -1462,1 +1456,1 @@\n-  product(bool, MetaspaceGuardAllocations, false, DIAGNOSTIC,               \\\n+  develop(bool, MetaspaceGuardAllocations, false,                           \\\n@@ -1465,1 +1459,1 @@\n-  product(bool, MetaspaceHandleDeallocations, true, DIAGNOSTIC,             \\\n+  develop(bool, MetaspaceHandleDeallocations, true,                         \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":3,"deletions":9,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -3160,1 +3160,2 @@\n-        Disassembler::decode(first_pc, first_pc + insts_size);\n+        Disassembler::decode(first_pc, first_pc + insts_size, tty\n+                             NOT_PRODUCT(COMMA &new_adapter->asm_remarks()));\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1007,1 +1007,1 @@\n-void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure) {\n+void ObjectSynchronizer::monitors_iterate(MonitorClosure* closure, JavaThread* thread) {\n@@ -1011,0 +1011,3 @@\n+    if (mid->owner() != thread) {\n+      continue;\n+    }\n@@ -1500,3 +1503,1 @@\n-    if (mid->owner() == _thread) {\n-      (void)mid->complete_exit(_thread);\n-    }\n+    (void)mid->complete_exit(_thread);\n@@ -1525,1 +1526,1 @@\n-  ObjectSynchronizer::monitors_iterate(&rjmc);\n+  ObjectSynchronizer::monitors_iterate(&rjmc, current);\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":6,"deletions":5,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -952,0 +952,9 @@\n+\n+  \/\/ Macos\/aarch64 should be in the right state for safepoint (e.g.\n+  \/\/ deoptimization needs WXWrite).  Crashes caused by the wrong state rarely\n+  \/\/ happens in practice, making such issues hard to find and reproduce.\n+#if defined(__APPLE__) && defined(AARCH64)\n+  if (AssertWXAtThreadSync) {\n+    assert_wx_state(WXWrite);\n+  }\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -337,4 +337,0 @@\n-  \/\/ True iff the thread can perform GC operations at a safepoint.\n-  \/\/ Generally will be true only of VM thread and parallel GC WorkGang\n-  \/\/ threads.\n-  virtual bool is_GC_task_thread() const             { return false; }\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":0,"deletions":4,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -371,2 +371,1 @@\n-  Monitor timer(Mutex::leaf, \"VM_Exit timer\", true,\n-                Monitor::_safepoint_check_never);\n+  Monitor timer(Mutex::nosafepoint, \"VM_ExitTimer_lock\", Monitor::_safepoint_check_never);\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.cpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -991,1 +991,1 @@\n-    output()->print_cr(\"Static dump:\");\n+    output()->print(\"Static dump: \");\n@@ -994,1 +994,1 @@\n-    output()->print_cr(\"Dynamic dump:\");\n+    output()->print(\"Dynamic dump: \");\n@@ -1015,1 +1015,1 @@\n-  JavaValue result(T_VOID);\n+  JavaValue result(T_OBJECT);\n@@ -1024,0 +1024,6 @@\n+  if (!HAS_PENDING_EXCEPTION) {\n+    assert(result.get_type() == T_OBJECT, \"Sanity check\");\n+    \/\/ result contains the archive name\n+    char* archive_name = java_lang_String::as_utf8_string(result.get_oop());\n+    output()->print_cr(\"%s\", archive_name);\n+  }\n","filename":"src\/hotspot\/share\/services\/diagnosticCommand.cpp","additions":9,"deletions":3,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -391,1 +391,1 @@\n-    friend class DumpWriter;\n+    friend class AbstractDumpWriter;\n@@ -403,3 +403,3 @@\n-\n-class DumpWriter : public StackObj {\n- private:\n+\/\/ Base class for dump and parallel dump\n+class AbstractDumpWriter : public StackObj {\n+ protected:\n@@ -421,3 +421,1 @@\n-  CompressionBackend _backend; \/\/ Does the actual writing.\n-\n-  void flush();\n+  virtual void flush(bool force = false) = 0;\n@@ -427,1 +425,0 @@\n-  size_t position() const                       { return _pos; }\n@@ -439,4 +436,5 @@\n-  \/\/ Takes ownership of the writer and compressor.\n-  DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor);\n-\n-  ~DumpWriter();\n+  AbstractDumpWriter() :\n+    _buffer(NULL),\n+    _size(io_buffer_max_size),\n+    _pos(0),\n+    _in_dump_segment(false) { }\n@@ -445,3 +443,2 @@\n-  julong bytes_written() const          { return (julong) _backend.get_written(); }\n-\n-  char const* error() const             { return _backend.error(); }\n+  virtual julong bytes_written() const = 0;\n+  virtual char const* error() const = 0;\n@@ -451,0 +448,1 @@\n+  size_t position() const                       { return _pos; }\n@@ -452,1 +450,1 @@\n-  void write_raw(void* s, size_t len);\n+  virtual void write_raw(void* s, size_t len);\n@@ -468,4 +466,10 @@\n-  void finish_dump_segment();\n-\n-  \/\/ Called by threads used for parallel writing.\n-  void writer_loop()                    { _backend.thread_loop(); }\n+  void finish_dump_segment(bool force_flush = false);\n+  \/\/ Refresh to get new buffer\n+  void refresh() {\n+    assert (_in_dump_segment ==false, \"Sanity check\");\n+    _buffer = NULL;\n+    _size = io_buffer_max_size;\n+    _pos = 0;\n+    \/\/ Force flush to guarantee data from parallel dumper are written.\n+    flush(true);\n+  }\n@@ -473,1 +477,1 @@\n-  void deactivate()                     { flush(); _backend.deactivate(); }\n+  virtual void deactivate() = 0;\n@@ -476,15 +480,1 @@\n-\/\/ Check for error after constructing the object and destroy it in case of an error.\n-DumpWriter::DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor) :\n-  _buffer(NULL),\n-  _size(0),\n-  _pos(0),\n-  _in_dump_segment(false),\n-  _backend(writer, compressor, io_buffer_max_size, io_buffer_max_waste) {\n-  flush();\n-}\n-\n-DumpWriter::~DumpWriter() {\n-  flush();\n-}\n-\n-void DumpWriter::write_fast(void* s, size_t len) {\n+void AbstractDumpWriter::write_fast(void* s, size_t len) {\n@@ -494,1 +484,0 @@\n-\n@@ -499,1 +488,1 @@\n-bool DumpWriter::can_write_fast(size_t len) {\n+bool AbstractDumpWriter::can_write_fast(size_t len) {\n@@ -504,1 +493,1 @@\n-void DumpWriter::write_raw(void* s, size_t len) {\n+void AbstractDumpWriter::write_raw(void* s, size_t len) {\n@@ -512,1 +501,0 @@\n-\n@@ -525,5 +513,0 @@\n-\/\/ flush any buffered bytes to the file\n-void DumpWriter::flush() {\n-  _backend.get_new_buffer(&_buffer, &_pos, &_size);\n-}\n-\n@@ -534,1 +517,1 @@\n-void DumpWriter::write_u1(u1 x) {\n+void AbstractDumpWriter::write_u1(u1 x) {\n@@ -538,1 +521,1 @@\n-void DumpWriter::write_u2(u2 x) {\n+void AbstractDumpWriter::write_u2(u2 x) {\n@@ -544,1 +527,1 @@\n-void DumpWriter::write_u4(u4 x) {\n+void AbstractDumpWriter::write_u4(u4 x) {\n@@ -550,1 +533,1 @@\n-void DumpWriter::write_u8(u8 x) {\n+void AbstractDumpWriter::write_u8(u8 x) {\n@@ -556,1 +539,1 @@\n-void DumpWriter::write_objectID(oop o) {\n+void AbstractDumpWriter::write_objectID(oop o) {\n@@ -565,1 +548,1 @@\n-void DumpWriter::write_inlinedObjectID(InlinedObjectSupport& inlinedObjectSupport) {\n+void AbstractDumpWriter::write_inlinedObjectID(InlinedObjectSupport& inlinedObjectSupport) {\n@@ -573,1 +556,1 @@\n-void DumpWriter::write_symbolID(Symbol* s) {\n+void AbstractDumpWriter::write_symbolID(Symbol* s) {\n@@ -582,1 +565,1 @@\n-void DumpWriter::write_id(u4 x) {\n+void AbstractDumpWriter::write_id(u4 x) {\n@@ -591,1 +574,1 @@\n-void DumpWriter::write_classID(Klass* k) {\n+void AbstractDumpWriter::write_classID(Klass* k) {\n@@ -595,1 +578,1 @@\n-void DumpWriter::finish_dump_segment() {\n+void AbstractDumpWriter::finish_dump_segment(bool force_flush) {\n@@ -606,0 +589,4 @@\n+    } else {\n+      \/\/ Finish process huge sub record\n+      \/\/ Set _is_huge_sub_record to false so the parallel dump writer can flush data to file.\n+      _is_huge_sub_record = false;\n@@ -608,1 +595,1 @@\n-    flush();\n+    flush(force_flush);\n@@ -613,1 +600,1 @@\n-void DumpWriter::start_sub_record(u1 tag, u4 len) {\n+void AbstractDumpWriter::start_sub_record(u1 tag, u4 len) {\n@@ -619,1 +606,1 @@\n-    assert(position() == 0, \"Must be at the start\");\n+    assert(position() == 0 && buffer_size() > dump_segment_header_size, \"Must be at the start\");\n@@ -626,0 +613,1 @@\n+    assert(Bytes::get_Java_u4((address)(buffer() + 5)) == len, \"Inconsitent size!\");\n@@ -643,1 +631,1 @@\n-void DumpWriter::end_sub_record() {\n+void AbstractDumpWriter::end_sub_record() {\n@@ -650,0 +638,275 @@\n+\/\/ Supports I\/O operations for a dump\n+\n+class DumpWriter : public AbstractDumpWriter {\n+ private:\n+  CompressionBackend _backend; \/\/ Does the actual writing.\n+ protected:\n+  virtual void flush(bool force = false);\n+\n+ public:\n+  \/\/ Takes ownership of the writer and compressor.\n+  DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor);\n+\n+  \/\/ total number of bytes written to the disk\n+  virtual julong bytes_written() const          { return (julong) _backend.get_written(); }\n+\n+  virtual char const* error() const             { return _backend.error(); }\n+\n+  \/\/ Called by threads used for parallel writing.\n+  void writer_loop()                    { _backend.thread_loop(); }\n+  \/\/ Called when finish to release the threads.\n+  virtual void deactivate()             { flush(); _backend.deactivate(); }\n+  \/\/ Get the backend pointer, used by parallel dump writer.\n+  CompressionBackend* backend_ptr() { return &_backend; }\n+\n+};\n+\n+\/\/ Check for error after constructing the object and destroy it in case of an error.\n+DumpWriter::DumpWriter(AbstractWriter* writer, AbstractCompressor* compressor) :\n+  AbstractDumpWriter(),\n+  _backend(writer, compressor, io_buffer_max_size, io_buffer_max_waste) {\n+  flush();\n+}\n+\n+\/\/ flush any buffered bytes to the file\n+void DumpWriter::flush(bool force) {\n+  _backend.get_new_buffer(&_buffer, &_pos, &_size, force);\n+}\n+\n+\/\/ Buffer queue used for parallel dump.\n+struct ParWriterBufferQueueElem {\n+  char* _buffer;\n+  size_t _used;\n+  ParWriterBufferQueueElem* _next;\n+};\n+\n+class ParWriterBufferQueue : public CHeapObj<mtInternal> {\n+ private:\n+  ParWriterBufferQueueElem* _head;\n+  ParWriterBufferQueueElem* _tail;\n+  uint _length;\n+ public:\n+  ParWriterBufferQueue() : _head(NULL), _tail(NULL), _length(0) { }\n+\n+  void enqueue(ParWriterBufferQueueElem* entry) {\n+    if (_head == NULL) {\n+      assert(is_empty() && _tail == NULL, \"Sanity check\");\n+      _head = _tail = entry;\n+    } else {\n+      assert ((_tail->_next == NULL && _tail->_buffer != NULL), \"Buffer queue is polluted\");\n+      _tail->_next = entry;\n+      _tail = entry;\n+    }\n+    _length++;\n+    assert(_tail->_next == NULL, \"Bufer queue is polluted\");\n+  }\n+\n+  ParWriterBufferQueueElem* dequeue() {\n+    if (_head == NULL)  return NULL;\n+    ParWriterBufferQueueElem* entry = _head;\n+    assert (entry->_buffer != NULL, \"polluted buffer in writer list\");\n+    _head = entry->_next;\n+    if (_head == NULL) {\n+      _tail = NULL;\n+    }\n+    entry->_next = NULL;\n+    _length--;\n+    return entry;\n+  }\n+\n+  bool is_empty() {\n+    return _length == 0;\n+  }\n+\n+  uint length() { return _length; }\n+};\n+\n+\/\/ Support parallel heap dump.\n+class ParDumpWriter : public AbstractDumpWriter {\n+ private:\n+  \/\/ Lock used to guarantee the integrity of multiple buffers writing.\n+  static Monitor* _lock;\n+  \/\/ Pointer of backend from global DumpWriter.\n+  CompressionBackend* _backend_ptr;\n+  char const * _err;\n+  ParWriterBufferQueue* _buffer_queue;\n+  size_t _internal_buffer_used;\n+  char* _buffer_base;\n+  bool _split_data;\n+  static const uint BackendFlushThreshold = 2;\n+ protected:\n+  virtual void flush(bool force = false) {\n+    assert(_pos != 0, \"must not be zero\");\n+    if (_pos != 0) {\n+      refresh_buffer();\n+    }\n+\n+    if (_split_data || _is_huge_sub_record) {\n+      return;\n+    }\n+\n+    if (should_flush_buf_list(force)) {\n+      assert(!_in_dump_segment && !_split_data && !_is_huge_sub_record, \"incomplete data send to backend!\\n\");\n+      flush_to_backend(force);\n+    }\n+  }\n+\n+ public:\n+  \/\/ Check for error after constructing the object and destroy it in case of an error.\n+  ParDumpWriter(DumpWriter* dw) :\n+    AbstractDumpWriter(),\n+    _backend_ptr(dw->backend_ptr()),\n+    _buffer_queue((new (std::nothrow) ParWriterBufferQueue())),\n+    _buffer_base(NULL),\n+    _split_data(false) {\n+    \/\/ prepare internal buffer\n+    allocate_internal_buffer();\n+  }\n+\n+  ~ParDumpWriter() {\n+     assert(_buffer_queue != NULL, \"Sanity check\");\n+     assert((_internal_buffer_used == 0) && (_buffer_queue->is_empty()),\n+            \"All data must be send to backend\");\n+     if (_buffer_base != NULL) {\n+       os::free(_buffer_base);\n+       _buffer_base = NULL;\n+     }\n+     delete _buffer_queue;\n+     _buffer_queue = NULL;\n+  }\n+\n+  \/\/ total number of bytes written to the disk\n+  virtual julong bytes_written() const          { return (julong) _backend_ptr->get_written(); }\n+  virtual char const* error() const { return _err == NULL ? _backend_ptr->error() : _err; }\n+\n+  static void before_work() {\n+    assert(_lock == NULL, \"ParDumpWriter lock must be initialized only once\");\n+    _lock = new (std::nothrow) PaddedMonitor(Mutex::nonleaf, \"ParallelHProfWriter_lock\", Mutex::_safepoint_check_always);\n+  }\n+\n+  static void after_work() {\n+    assert(_lock != NULL, \"ParDumpWriter lock is not initialized\");\n+    delete _lock;\n+    _lock = NULL;\n+  }\n+\n+  \/\/ write raw bytes\n+  virtual void write_raw(void* s, size_t len) {\n+    assert(!_in_dump_segment || (_sub_record_left >= len), \"sub-record too large\");\n+    debug_only(_sub_record_left -= len);\n+    assert(!_split_data, \"Invalid split data\");\n+    _split_data = true;\n+    \/\/ flush buffer to make room.\n+    while (len > buffer_size() - position()) {\n+      assert(!_in_dump_segment || _is_huge_sub_record,\n+             \"Cannot overflow in non-huge sub-record.\");\n+      size_t to_write = buffer_size() - position();\n+      memcpy(buffer() + position(), s, to_write);\n+      s = (void*) ((char*) s + to_write);\n+      len -= to_write;\n+      set_position(position() + to_write);\n+      flush();\n+    }\n+    _split_data = false;\n+    memcpy(buffer() + position(), s, len);\n+    set_position(position() + len);\n+  }\n+\n+  virtual void deactivate()             { flush(true); _backend_ptr->deactivate(); }\n+\n+ private:\n+  void allocate_internal_buffer() {\n+    assert(_buffer_queue != NULL, \"Internal buffer queue is not ready when allocate internal buffer\");\n+    assert(_buffer == NULL && _buffer_base == NULL, \"current buffer must be NULL before allocate\");\n+    _buffer_base = _buffer = (char*)os::malloc(io_buffer_max_size, mtInternal);\n+    if (_buffer == NULL) {\n+      set_error(\"Could not allocate buffer for writer\");\n+      return;\n+    }\n+    _pos = 0;\n+    _internal_buffer_used = 0;\n+    _size = io_buffer_max_size;\n+  }\n+\n+  void set_error(char const* new_error) {\n+    if ((new_error != NULL) && (_err == NULL)) {\n+      _err = new_error;\n+    }\n+  }\n+\n+  \/\/ Add buffer to internal list\n+  void refresh_buffer() {\n+    size_t expected_total = _internal_buffer_used + _pos;\n+    if (expected_total < io_buffer_max_size - io_buffer_max_waste) {\n+      \/\/ reuse current buffer.\n+      _internal_buffer_used = expected_total;\n+      assert(_size - _pos == io_buffer_max_size - expected_total, \"illegal resize of buffer\");\n+      _size -= _pos;\n+      _buffer += _pos;\n+      _pos = 0;\n+\n+      return;\n+    }\n+    \/\/ It is not possible here that expected_total is larger than io_buffer_max_size because\n+    \/\/ of limitation in write_xxx().\n+    assert(expected_total <= io_buffer_max_size, \"buffer overflow\");\n+    assert(_buffer - _buffer_base <= io_buffer_max_size, \"internal buffer overflow\");\n+    ParWriterBufferQueueElem* entry =\n+        (ParWriterBufferQueueElem*)os::malloc(sizeof(ParWriterBufferQueueElem), mtInternal);\n+    if (entry == NULL) {\n+      set_error(\"Heap dumper can allocate memory\");\n+      return;\n+    }\n+    entry->_buffer = _buffer_base;\n+    entry->_used = expected_total;\n+    entry->_next = NULL;\n+    \/\/ add to internal buffer queue\n+    _buffer_queue->enqueue(entry);\n+    _buffer_base =_buffer = NULL;\n+    allocate_internal_buffer();\n+  }\n+\n+  void reclaim_entry(ParWriterBufferQueueElem* entry) {\n+    assert(entry != NULL && entry->_buffer != NULL, \"Invalid entry to reclaim\");\n+    os::free(entry->_buffer);\n+    entry->_buffer = NULL;\n+    os::free(entry);\n+  }\n+\n+  void flush_buffer(char* buffer, size_t used) {\n+    assert(_lock->owner() == Thread::current(), \"flush buffer must hold lock\");\n+    size_t max = io_buffer_max_size;\n+    \/\/ get_new_buffer\n+    _backend_ptr->flush_external_buffer(buffer, used, max);\n+  }\n+\n+  bool should_flush_buf_list(bool force) {\n+    return force || _buffer_queue->length() > BackendFlushThreshold;\n+  }\n+\n+  void flush_to_backend(bool force) {\n+    \/\/ Guarantee there is only one writer updating the backend buffers.\n+    MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+    while (!_buffer_queue->is_empty()) {\n+      ParWriterBufferQueueElem* entry = _buffer_queue->dequeue();\n+      flush_buffer(entry->_buffer, entry->_used);\n+      \/\/ Delete buffer and entry.\n+      reclaim_entry(entry);\n+      entry = NULL;\n+    }\n+    assert(_pos == 0, \"available buffer must be empty before flush\");\n+    \/\/ Flush internal buffer.\n+    if (_internal_buffer_used > 0) {\n+      flush_buffer(_buffer_base, _internal_buffer_used);\n+      os::free(_buffer_base);\n+      _pos = 0;\n+      _internal_buffer_used = 0;\n+      _buffer_base = _buffer = NULL;\n+      \/\/ Allocate internal buffer for future use.\n+      allocate_internal_buffer();\n+    }\n+  }\n+};\n+\n+Monitor* ParDumpWriter::_lock = NULL;\n+\n@@ -656,1 +919,1 @@\n-  static void write_header(DumpWriter* writer, hprofTag tag, u4 len);\n+  static void write_header(AbstractDumpWriter* writer, hprofTag tag, u4 len);\n@@ -669,1 +932,1 @@\n-  static void dump_float(DumpWriter* writer, jfloat f);\n+  static void dump_float(AbstractDumpWriter* writer, jfloat f);\n@@ -671,1 +934,1 @@\n-  static void dump_double(DumpWriter* writer, jdouble d);\n+  static void dump_double(AbstractDumpWriter* writer, jdouble d);\n@@ -674,1 +937,1 @@\n-  static void dump_field_value(DumpWriter* writer, const FieldStream& fld, oop obj, int offset);\n+  static void dump_field_value(AbstractDumpWriter* writer, const FieldStream& fld, oop obj, int offset);\n@@ -678,1 +941,1 @@\n-  static void dump_static_fields(DumpWriter* writer, Klass* k);\n+  static void dump_static_fields(AbstractDumpWriter* writer, Klass* k);\n@@ -682,1 +945,1 @@\n-  static void dump_instance_fields(DumpWriter* writer, oop o, int offset, Klass* klass);\n+  static void dump_instance_fields(AbstractDumpWriter* writer, oop o, int offset, Klass* klass);\n@@ -686,1 +949,1 @@\n-  static void dump_inlined_instance_fields(DumpWriter* writer, oop o, int offset, Klass* klass, InlinedObjectSupport &ios);\n+  static void dump_inlined_instance_fields(AbstractDumpWriter* writer, oop o, int offset, Klass* klass, InlinedObjectSupport &ios);\n@@ -691,1 +954,1 @@\n-  static void dump_instance_field_descriptors(DumpWriter* writer, Klass* k);\n+  static void dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k);\n@@ -693,1 +956,1 @@\n-  static void dump_inlined_object(DumpWriter* writer, oop holder, int offset, InlineKlass* klass, InlinedObjectSupport& ios);\n+  static void dump_inlined_object(AbstractDumpWriter* writer, oop holder, int offset, InlineKlass* klass, InlinedObjectSupport& ios);\n@@ -695,1 +958,1 @@\n-  static void dump_instance(DumpWriter* writer, oop o);\n+  static void dump_instance(AbstractDumpWriter* writer, oop o);\n@@ -698,1 +961,1 @@\n-  static void dump_class_and_array_classes(DumpWriter* writer, Klass* k);\n+  static void dump_class_and_array_classes(AbstractDumpWriter* writer, Klass* k);\n@@ -701,1 +964,1 @@\n-  static void dump_basic_type_array_class(DumpWriter* writer, Klass* k);\n+  static void dump_basic_type_array_class(AbstractDumpWriter* writer, Klass* k);\n@@ -704,2 +967,1 @@\n-  \/\/static void dump_object_array(DumpWriter* writer, objArrayOop array);\n-  static void dump_object_array(DumpWriter* writer, arrayOop array);\n+  static void dump_object_array(AbstractDumpWriter* writer, arrayOop array);\n@@ -707,1 +969,1 @@\n-  static void dump_prim_array(DumpWriter* writer, typeArrayOop array);\n+  static void dump_prim_array(AbstractDumpWriter* writer, typeArrayOop array);\n@@ -709,1 +971,1 @@\n-  static void dump_stack_frame(DumpWriter* writer, int frame_serial_num, int class_serial_num, Method* m, int bci);\n+  static void dump_stack_frame(AbstractDumpWriter* writer, int frame_serial_num, int class_serial_num, Method* m, int bci);\n@@ -712,1 +974,1 @@\n-  static int calculate_array_max_length(DumpWriter* writer, arrayOop array, short header_size);\n+  static int calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size);\n@@ -715,1 +977,1 @@\n-  static void end_of_dump(DumpWriter* writer);\n+  static void end_of_dump(AbstractDumpWriter* writer);\n@@ -729,1 +991,1 @@\n-void DumperSupport:: write_header(DumpWriter* writer, hprofTag tag, u4 len) {\n+void DumperSupport:: write_header(AbstractDumpWriter* writer, hprofTag tag, u4 len) {\n@@ -785,1 +1047,1 @@\n-void DumperSupport::dump_float(DumpWriter* writer, jfloat f) {\n+void DumperSupport::dump_float(AbstractDumpWriter* writer, jfloat f) {\n@@ -799,1 +1061,1 @@\n-void DumperSupport::dump_double(DumpWriter* writer, jdouble d) {\n+void DumperSupport::dump_double(AbstractDumpWriter* writer, jdouble d) {\n@@ -815,1 +1077,1 @@\n-void DumperSupport::dump_field_value(DumpWriter* writer, const FieldStream& fld, oop obj, int offset) {\n+void DumperSupport::dump_field_value(AbstractDumpWriter* writer, const FieldStream& fld, oop obj, int offset) {\n@@ -942,1 +1204,1 @@\n-void DumperSupport::dump_static_fields(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_static_fields(AbstractDumpWriter* writer, Klass* k) {\n@@ -989,1 +1251,1 @@\n-void DumperSupport::dump_instance_fields(DumpWriter* writer, oop o, int offset, Klass *klass) {\n+void DumperSupport::dump_instance_fields(AbstractDumpWriter* writer, oop o, int offset, Klass *klass) {\n@@ -999,1 +1261,1 @@\n-void DumperSupport::dump_inlined_instance_fields(DumpWriter *writer, oop o, int offset, Klass *klass, InlinedObjectSupport &ios) {\n+void DumperSupport::dump_inlined_instance_fields(AbstractDumpWriter *writer, oop o, int offset, Klass *klass, InlinedObjectSupport &ios) {\n@@ -1027,1 +1289,1 @@\n-void DumperSupport::dump_instance_field_descriptors(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_instance_field_descriptors(AbstractDumpWriter* writer, Klass* k) {\n@@ -1042,1 +1304,1 @@\n-void DumperSupport::dump_inlined_object(DumpWriter* writer, oop holder, int offset, InlineKlass* klass, InlinedObjectSupport& ios) {\n+void DumperSupport::dump_inlined_object(AbstractDumpWriter* writer, oop holder, int offset, InlineKlass* klass, InlinedObjectSupport& ios) {\n@@ -1073,1 +1335,1 @@\n-void DumperSupport::dump_instance(DumpWriter* writer, oop o) {\n+void DumperSupport::dump_instance(AbstractDumpWriter* writer, oop o) {\n@@ -1101,1 +1363,1 @@\n-void DumperSupport::dump_class_and_array_classes(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_class_and_array_classes(AbstractDumpWriter* writer, Klass* k) {\n@@ -1190,1 +1452,1 @@\n-void DumperSupport::dump_basic_type_array_class(DumpWriter* writer, Klass* k) {\n+void DumperSupport::dump_basic_type_array_class(AbstractDumpWriter* writer, Klass* k) {\n@@ -1225,1 +1487,1 @@\n-int DumperSupport::calculate_array_max_length(DumpWriter* writer, arrayOop array, short header_size) {\n+int DumperSupport::calculate_array_max_length(AbstractDumpWriter* writer, arrayOop array, short header_size) {\n@@ -1252,1 +1514,1 @@\n-void DumperSupport::dump_object_array(DumpWriter* writer, arrayOop array) {\n+void DumperSupport::dump_object_array(AbstractDumpWriter* writer, arrayOop array) {\n@@ -1309,1 +1571,1 @@\n-void DumperSupport::dump_prim_array(DumpWriter* writer, typeArrayOop array) {\n+void DumperSupport::dump_prim_array(AbstractDumpWriter* writer, typeArrayOop array) {\n@@ -1311,1 +1573,0 @@\n-\n@@ -1403,1 +1664,1 @@\n-void DumperSupport::dump_stack_frame(DumpWriter* writer,\n+void DumperSupport::dump_stack_frame(AbstractDumpWriter* writer,\n@@ -1432,2 +1693,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1435,1 +1696,1 @@\n-  SymbolTableDumper(DumpWriter* writer)     { _writer = writer; }\n+  SymbolTableDumper(AbstractDumpWriter* writer)     { _writer = writer; }\n@@ -1455,1 +1716,1 @@\n-  DumpWriter* _writer;\n+  AbstractDumpWriter* _writer;\n@@ -1458,1 +1719,1 @@\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1460,1 +1721,1 @@\n-  JNILocalsDumper(DumpWriter* writer, u4 thread_serial_num) {\n+  JNILocalsDumper(AbstractDumpWriter* writer, u4 thread_serial_num) {\n@@ -1489,2 +1750,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1493,1 +1754,1 @@\n-  JNIGlobalsDumper(DumpWriter* writer) {\n+  JNIGlobalsDumper(AbstractDumpWriter* writer) {\n@@ -1501,1 +1762,1 @@\n-  oop o = *obj_p;\n+  oop o = NativeAccess<AS_NO_KEEPALIVE>::oop_load(obj_p);\n@@ -1505,1 +1766,0 @@\n-\n@@ -1520,2 +1780,2 @@\n-  DumpWriter* _writer;\n-  DumpWriter* writer() const                { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  AbstractDumpWriter* writer() const                { return _writer; }\n@@ -1523,1 +1783,1 @@\n-  StickyClassDumper(DumpWriter* writer) {\n+  StickyClassDumper(AbstractDumpWriter* writer) {\n@@ -1537,0 +1797,66 @@\n+\/\/ Large object heap dump support.\n+\/\/ To avoid memory consumption, when dumping large objects such as huge array and\n+\/\/ large objects whose size are larger than LARGE_OBJECT_DUMP_THRESHOLD, the scanned\n+\/\/ partial object\/array data will be sent to the backend directly instead of caching\n+\/\/ the whole object\/array in the internal buffer.\n+\/\/ The HeapDumpLargeObjectList is used to save the large object when dumper scans\n+\/\/ the heap. The large objects could be added (push) parallelly by multiple dumpers,\n+\/\/ But they will be removed (popped) serially only by the VM thread.\n+class HeapDumpLargeObjectList : public CHeapObj<mtInternal> {\n+ private:\n+  class HeapDumpLargeObjectListElem : public CHeapObj<mtInternal> {\n+   public:\n+    HeapDumpLargeObjectListElem(oop obj) : _obj(obj), _next(NULL) { }\n+    oop _obj;\n+    HeapDumpLargeObjectListElem* _next;\n+  };\n+\n+  volatile HeapDumpLargeObjectListElem* _head;\n+\n+ public:\n+  HeapDumpLargeObjectList() : _head(NULL) { }\n+\n+  void atomic_push(oop obj) {\n+    assert (obj != NULL, \"sanity check\");\n+    HeapDumpLargeObjectListElem* entry = new HeapDumpLargeObjectListElem(obj);\n+    if (entry == NULL) {\n+      warning(\"failed to allocate element for large object list\");\n+      return;\n+    }\n+    assert (entry->_obj != NULL, \"sanity check\");\n+    while (true) {\n+      volatile HeapDumpLargeObjectListElem* old_head = Atomic::load_acquire(&_head);\n+      HeapDumpLargeObjectListElem* new_head = entry;\n+      if (Atomic::cmpxchg(&_head, old_head, new_head) == old_head) {\n+        \/\/ successfully push\n+        new_head->_next = (HeapDumpLargeObjectListElem*)old_head;\n+        return;\n+      }\n+    }\n+  }\n+\n+  oop pop() {\n+    if (_head == NULL) {\n+      return NULL;\n+    }\n+    HeapDumpLargeObjectListElem* entry = (HeapDumpLargeObjectListElem*)_head;\n+    _head = _head->_next;\n+    assert (entry != NULL, \"illegal larger object list entry\");\n+    oop ret = entry->_obj;\n+    delete entry;\n+    assert (ret != NULL, \"illegal oop pointer\");\n+    return ret;\n+  }\n+\n+  void drain(ObjectClosure* cl) {\n+    while (_head !=  NULL) {\n+      cl->do_object(pop());\n+    }\n+  }\n+\n+  bool is_empty() {\n+    return _head == NULL;\n+  }\n+\n+  static const size_t LargeObjectSizeThreshold = 1 << 20; \/\/ 1 MB\n+};\n@@ -1541,1 +1867,0 @@\n-\n@@ -1544,3 +1869,2 @@\n-  DumpWriter* _writer;\n-\n-  DumpWriter* writer()                  { return _writer; }\n+  AbstractDumpWriter* _writer;\n+  HeapDumpLargeObjectList* _list;\n@@ -1548,0 +1872,2 @@\n+  AbstractDumpWriter* writer()                  { return _writer; }\n+  bool is_large(oop o);\n@@ -1549,1 +1875,1 @@\n-  HeapObjectDumper(DumpWriter* writer) {\n+  HeapObjectDumper(AbstractDumpWriter* writer, HeapDumpLargeObjectList* list = NULL) {\n@@ -1551,0 +1877,1 @@\n+    _list = list;\n@@ -1570,0 +1897,7 @@\n+  \/\/ If large object list exists and it is large object\/array,\n+  \/\/ add oop into the list and skip scan. VM thread will process it later.\n+  if (_list != NULL && is_large(o)) {\n+    _list->atomic_push(o);\n+    return;\n+  }\n+\n@@ -1582,0 +1916,73 @@\n+bool HeapObjectDumper::is_large(oop o) {\n+  size_t size = 0;\n+  if (o->is_instance()) {\n+    \/\/ Use o->size() * 8 as the upper limit of instance size to avoid iterating static fields\n+    size = o->size() * 8;\n+  } else if (o->is_objArray()) {\n+    objArrayOop array = objArrayOop(o);\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+    assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n+    int length = array->length();\n+    int type_size = sizeof(address);\n+    size = (size_t)length * type_size;\n+  } else if (o->is_typeArray()) {\n+    typeArrayOop array = typeArrayOop(o);\n+    BasicType type = ArrayKlass::cast(array->klass())->element_type();\n+    assert(type >= T_BOOLEAN && type <= T_OBJECT, \"invalid array element type\");\n+    int length = array->length();\n+    int type_size = type2aelembytes(type);\n+    size = (size_t)length * type_size;\n+  }\n+  return size > HeapDumpLargeObjectList::LargeObjectSizeThreshold;\n+}\n+\n+\/\/ The dumper controller for parallel heap dump\n+class DumperController : public CHeapObj<mtInternal> {\n+ private:\n+   bool     _started;\n+   Monitor* _lock;\n+   uint   _dumper_number;\n+   uint   _complete_number;\n+\n+ public:\n+   DumperController(uint number) :\n+     _started(false),\n+     _lock(new (std::nothrow) PaddedMonitor(Mutex::nonleaf, \"DumperController_lock\",\n+    Mutex::_safepoint_check_always)),\n+     _dumper_number(number),\n+     _complete_number(0) { }\n+\n+   ~DumperController() { delete _lock; }\n+\n+   void wait_for_start_signal() {\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_started == false) {\n+       ml.wait();\n+     }\n+     assert(_started == true,  \"dumper woke up with wrong state\");\n+   }\n+\n+   void start_dump() {\n+     assert (_started == false, \"start dump with wrong state\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _started = true;\n+     ml.notify_all();\n+   }\n+\n+   void dumper_complete() {\n+     assert (_started == true, \"dumper complete with wrong state\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     _complete_number++;\n+     ml.notify();\n+   }\n+\n+   void wait_all_dumpers_complete() {\n+     assert (_started == true, \"wrong state when wait for dumper complete\");\n+     MonitorLocker ml(_lock, Mutex::_no_safepoint_check_flag);\n+     while (_complete_number != _dumper_number) {\n+        ml.wait();\n+     }\n+     _started = false;\n+   }\n+};\n+\n@@ -1585,9 +1992,69 @@\n-  static VM_HeapDumper* _global_dumper;\n-  static DumpWriter*    _global_writer;\n-  DumpWriter*           _local_writer;\n-  JavaThread*           _oome_thread;\n-  Method*               _oome_constructor;\n-  bool _gc_before_heap_dump;\n-  GrowableArray<Klass*>* _klass_map;\n-  ThreadStackTrace** _stack_traces;\n-  int _num_threads;\n+  static VM_HeapDumper*   _global_dumper;\n+  static DumpWriter*      _global_writer;\n+  DumpWriter*             _local_writer;\n+  JavaThread*             _oome_thread;\n+  Method*                 _oome_constructor;\n+  bool                    _gc_before_heap_dump;\n+  GrowableArray<Klass*>*  _klass_map;\n+  ThreadStackTrace**      _stack_traces;\n+  int                     _num_threads;\n+  \/\/ parallel heap dump support\n+  uint                    _num_dumper_threads;\n+  uint                    _num_writer_threads;\n+  DumperController*       _dumper_controller;\n+  ParallelObjectIterator* _poi;\n+  HeapDumpLargeObjectList* _large_object_list;\n+\n+  \/\/ VMDumperType is for thread that dumps both heap and non-heap data.\n+  static const size_t VMDumperType = 0;\n+  static const size_t WriterType = 1;\n+  static const size_t DumperType = 2;\n+  \/\/ worker id of VMDumper thread.\n+  static const size_t VMDumperWorkerId = 0;\n+\n+  size_t get_worker_type(uint worker_id) {\n+    assert(_num_writer_threads >= 1, \"Must be at least one writer\");\n+    \/\/ worker id of VMDumper that dump heap and non-heap data\n+    if (worker_id == VMDumperWorkerId) {\n+      return VMDumperType;\n+    }\n+\n+    \/\/ worker id of dumper starts from 1, which only dump heap datar\n+    if (worker_id < _num_dumper_threads) {\n+      return DumperType;\n+    }\n+\n+    \/\/ worker id of writer starts from _num_dumper_threads\n+    return WriterType;\n+  }\n+\n+  void prepare_parallel_dump(uint num_total) {\n+    assert (_dumper_controller == NULL, \"dumper controller must be NULL\");\n+    assert (num_total > 0, \"active workers number must >= 1\");\n+    \/\/ Dumper threads number must not be larger than active workers number.\n+    if (num_total < _num_dumper_threads) {\n+      _num_dumper_threads = num_total - 1;\n+    }\n+    \/\/ Calculate dumper and writer threads number.\n+    _num_writer_threads = num_total - _num_dumper_threads;\n+    \/\/ If dumper threads number is 1, only the VMThread works as a dumper.\n+    \/\/ If dumper threads number is equal to active workers, need at lest one worker thread as writer.\n+    if (_num_dumper_threads > 0 && _num_writer_threads == 0) {\n+      _num_writer_threads = 1;\n+      _num_dumper_threads = num_total - _num_writer_threads;\n+    }\n+    \/\/ Prepare parallel writer.\n+    if (_num_dumper_threads > 1) {\n+      ParDumpWriter::before_work();\n+      \/\/ Number of dumper threads that only iterate heap.\n+      uint _heap_only_dumper_threads = _num_dumper_threads - 1 \/* VMDumper thread *\/;\n+      _dumper_controller = new (std::nothrow) DumperController(_heap_only_dumper_threads);\n+      _poi = Universe::heap()->parallel_object_iterator(_num_dumper_threads);\n+    }\n+  }\n+\n+  void finish_parallel_dump() {\n+    if (_num_dumper_threads > 1) {\n+      ParDumpWriter::after_work();\n+    }\n+  }\n@@ -1634,0 +2101,3 @@\n+  \/\/ large objects\n+  void dump_large_objects(ObjectClosure* writer);\n+\n@@ -1635,1 +2105,1 @@\n-  VM_HeapDumper(DumpWriter* writer, bool gc_before_heap_dump, bool oome) :\n+  VM_HeapDumper(DumpWriter* writer, bool gc_before_heap_dump, bool oome, uint num_dump_threads) :\n@@ -1646,0 +2116,4 @@\n+    _num_dumper_threads = num_dump_threads;\n+    _dumper_controller = NULL;\n+    _poi = NULL;\n+    _large_object_list = new (std::nothrow) HeapDumpLargeObjectList();\n@@ -1659,0 +2133,1 @@\n+\n@@ -1666,0 +2141,8 @@\n+    if (_poi != NULL) {\n+      delete _poi;\n+      _poi = NULL;\n+    }\n+    if (_dumper_controller != NULL) {\n+      delete _dumper_controller;\n+      _dumper_controller = NULL;\n+    }\n@@ -1667,0 +2150,1 @@\n+    delete _large_object_list;\n@@ -1674,1 +2158,0 @@\n-\n@@ -1683,1 +2166,1 @@\n-void DumperSupport::end_of_dump(DumpWriter* writer) {\n+void DumperSupport::end_of_dump(AbstractDumpWriter* writer) {\n@@ -1905,0 +2388,3 @@\n+    \/\/ Use serial dump, set dumper threads and writer threads number to 1.\n+    _num_dumper_threads=1;\n+    _num_writer_threads=1;\n@@ -1907,1 +2393,3 @@\n-    gang->run_task(this, gang->active_workers(), true);\n+    prepare_parallel_dump(gang->active_workers());\n+    gang->run_task(this);\n+    finish_parallel_dump();\n@@ -1916,25 +2404,29 @@\n-  if (!Thread::current()->is_VM_thread()) {\n-    writer()->writer_loop();\n-    return;\n-  }\n-\n-  \/\/ Write the file header - we always use 1.0.2\n-  const char* header = \"JAVA PROFILE 1.0.2\";\n-\n-  \/\/ header is few bytes long - no chance to overflow int\n-  writer()->write_raw((void*)header, (int)strlen(header));\n-  writer()->write_u1(0); \/\/ terminator\n-  writer()->write_u4(oopSize);\n-  \/\/ timestamp is current time in ms\n-  writer()->write_u8(os::javaTimeMillis());\n-\n-  \/\/ HPROF_UTF8 records\n-  SymbolTableDumper sym_dumper(writer());\n-  SymbolTable::symbols_do(&sym_dumper);\n-\n-  \/\/ write HPROF_LOAD_CLASS records\n-  {\n-    LockedClassesDo locked_load_classes(&do_load_class);\n-    ClassLoaderDataGraph::classes_do(&locked_load_classes);\n-  }\n-  Universe::basic_type_classes_do(&do_load_class);\n+  if (worker_id != 0) {\n+    if (get_worker_type(worker_id) == WriterType) {\n+      writer()->writer_loop();\n+      return;\n+    }\n+    if (_num_dumper_threads > 1 && get_worker_type(worker_id) == DumperType) {\n+      _dumper_controller->wait_for_start_signal();\n+    }\n+  } else {\n+    \/\/ The worker 0 on all non-heap data dumping and part of heap iteration.\n+    \/\/ Write the file header - we always use 1.0.2\n+    const char* header = \"JAVA PROFILE 1.0.2\";\n+\n+    \/\/ header is few bytes long - no chance to overflow int\n+    writer()->write_raw((void*)header, (int)strlen(header));\n+    writer()->write_u1(0); \/\/ terminator\n+    writer()->write_u4(oopSize);\n+    \/\/ timestamp is current time in ms\n+    writer()->write_u8(os::javaTimeMillis());\n+    \/\/ HPROF_UTF8 records\n+    SymbolTableDumper sym_dumper(writer());\n+    SymbolTable::symbols_do(&sym_dumper);\n+\n+    \/\/ write HPROF_LOAD_CLASS records\n+    {\n+      LockedClassesDo locked_load_classes(&do_load_class);\n+      ClassLoaderDataGraph::classes_do(&locked_load_classes);\n+    }\n+    Universe::basic_type_classes_do(&do_load_class);\n@@ -1942,3 +2434,3 @@\n-  \/\/ write HPROF_FRAME and HPROF_TRACE records\n-  \/\/ this must be called after _klass_map is built when iterating the classes above.\n-  dump_stack_traces();\n+    \/\/ write HPROF_FRAME and HPROF_TRACE records\n+    \/\/ this must be called after _klass_map is built when iterating the classes above.\n+    dump_stack_traces();\n@@ -1946,4 +2438,21 @@\n-  \/\/ Writes HPROF_GC_CLASS_DUMP records\n-  {\n-    LockedClassesDo locked_dump_class(&do_class_dump);\n-    ClassLoaderDataGraph::classes_do(&locked_dump_class);\n+    \/\/ Writes HPROF_GC_CLASS_DUMP records\n+    {\n+      LockedClassesDo locked_dump_class(&do_class_dump);\n+      ClassLoaderDataGraph::classes_do(&locked_dump_class);\n+    }\n+    Universe::basic_type_classes_do(&do_basic_type_array_class_dump);\n+\n+    \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n+    do_threads();\n+\n+    \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n+    JNIGlobalsDumper jni_dumper(writer());\n+    JNIHandles::oops_do(&jni_dumper);\n+    \/\/ technically not jni roots, but global roots\n+    \/\/ for things like preallocated throwable backtraces\n+    Universe::vm_global()->oops_do(&jni_dumper);\n+    \/\/ HPROF_GC_ROOT_STICKY_CLASS\n+    \/\/ These should be classes in the NULL class loader data, and not all classes\n+    \/\/ if !ClassUnloading\n+    StickyClassDumper class_dumper(writer());\n+    ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n@@ -1951,2 +2460,0 @@\n-  Universe::basic_type_classes_do(&do_basic_type_array_class_dump);\n-\n@@ -1959,18 +2466,34 @@\n-  HeapObjectDumper obj_dumper(writer());\n-  Universe::heap()->object_iterate(&obj_dumper);\n-\n-  \/\/ HPROF_GC_ROOT_THREAD_OBJ + frames + jni locals\n-  do_threads();\n-\n-  \/\/ HPROF_GC_ROOT_JNI_GLOBAL\n-  JNIGlobalsDumper jni_dumper(writer());\n-  JNIHandles::oops_do(&jni_dumper);\n-  \/\/ technically not jni roots, but global roots\n-  \/\/ for things like preallocated throwable backtraces\n-  Universe::vm_global()->oops_do(&jni_dumper);\n-\n-  \/\/ HPROF_GC_ROOT_STICKY_CLASS\n-  \/\/ These should be classes in the NULL class loader data, and not all classes\n-  \/\/ if !ClassUnloading\n-  StickyClassDumper class_dumper(writer());\n-  ClassLoaderData::the_null_class_loader_data()->classes_do(&class_dumper);\n+  if (_num_dumper_threads <= 1) {\n+    HeapObjectDumper obj_dumper(writer());\n+    Universe::heap()->object_iterate(&obj_dumper);\n+  } else {\n+    assert(get_worker_type(worker_id) == DumperType\n+          || get_worker_type(worker_id) == VMDumperType,\n+          \"must be dumper thread to do heap iteration\");\n+    if (get_worker_type(worker_id) == VMDumperType) {\n+      \/\/ Clear global writer's buffer.\n+      writer()->finish_dump_segment(true);\n+      \/\/ Notify dumpers to start heap iteration.\n+      _dumper_controller->start_dump();\n+    }\n+    \/\/ Heap iteration.\n+    {\n+       ParDumpWriter pw(writer());\n+       {\n+         HeapObjectDumper obj_dumper(&pw, _large_object_list);\n+         _poi->object_iterate(&obj_dumper, worker_id);\n+       }\n+\n+       if (get_worker_type(worker_id) == VMDumperType) {\n+         _dumper_controller->wait_all_dumpers_complete();\n+         \/\/ clear internal buffer;\n+         pw.finish_dump_segment(true);\n+         \/\/ refresh the global_writer's buffer and position;\n+         writer()->refresh();\n+       } else {\n+         pw.finish_dump_segment(true);\n+         _dumper_controller->dumper_complete();\n+         return;\n+       }\n+    }\n+  }\n@@ -1978,0 +2501,4 @@\n+  assert(get_worker_type(worker_id) == VMDumperType, \"Heap dumper must be VMDumper\");\n+  \/\/ Use writer() rather than ParDumpWriter to avoid memory consumption.\n+  HeapObjectDumper obj_dumper(writer());\n+  dump_large_objects(&obj_dumper);\n@@ -1980,1 +2507,0 @@\n-\n@@ -1998,1 +2524,4 @@\n-      ResourceMark rm;\n+      Thread* current_thread = Thread::current();\n+      ResourceMark rm(current_thread);\n+      HandleMark hm(current_thread);\n+\n@@ -2040,0 +2569,5 @@\n+\/\/ dump the large objects.\n+void VM_HeapDumper::dump_large_objects(ObjectClosure* cl) {\n+  _large_object_list->drain(cl);\n+}\n+\n@@ -2041,1 +2575,1 @@\n-int HeapDumper::dump(const char* path, outputStream* out, int compression, bool overwrite) {\n+int HeapDumper::dump(const char* path, outputStream* out, int compression, bool overwrite, uint num_dump_threads) {\n@@ -2049,1 +2583,0 @@\n-\n@@ -2076,1 +2609,1 @@\n-  VM_HeapDumper dumper(&writer, _gc_before_heap_dump, _oome);\n+  VM_HeapDumper dumper(&writer, _gc_before_heap_dump, _oome, num_dump_threads);\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":716,"deletions":183,"binary":false,"changes":899,"status":"modified"},{"patch":"@@ -458,1 +458,1 @@\n-  \/\/ that element is not already in the list.  Assumes the list is\n+  \/\/ that element if not already in the list.  Assumes the list is\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -571,1 +571,1 @@\n-     * <p>When a subclass is replacing objects it must insure that either a\n+     * <p>When a subclass is replacing objects it must ensure that either a\n@@ -1424,1 +1424,1 @@\n-     * Writes representation of a \"ordinary\" (i.e., not a String, Class,\n+     * Writes representation of an \"ordinary\" (i.e., not a String, Class,\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1719,3 +1719,1 @@\n-            IOException ex = new IOException(\"unexpected exception type\");\n-            ex.initCause(th);\n-            throw ex;\n+            throw new IOException(\"unexpected exception type\", th);\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectStreamClass.java","additions":1,"deletions":3,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -246,1 +246,1 @@\n-            s.concat(\".ref\");\n+            s = s.concat(\".ref\");\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2018, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2018, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -103,1 +103,1 @@\n-                (packageName.length() > 0 ? \"\/\" : \"\") + className + \";\");\n+                \"\/\" + className + \";\");\n","filename":"src\/java.base\/share\/classes\/java\/lang\/constant\/ClassDesc.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -36,1 +36,0 @@\n-import java.lang.ref.WeakReference;\n@@ -368,3 +367,1 @@\n-            if (UNSAFE.shouldBeInitialized(cls)) {\n-                UNSAFE.ensureClassInitialized(cls);\n-            }\n+            UNSAFE.ensureClassInitialized(cls);\n@@ -376,13 +373,0 @@\n-    private static class EnsureInitialized extends ClassValue<WeakReference<Thread>> {\n-        @Override\n-        protected WeakReference<Thread> computeValue(Class<?> type) {\n-            UNSAFE.ensureClassInitialized(type);\n-            if (UNSAFE.shouldBeInitialized(type))\n-                \/\/ If the previous call didn't block, this can happen.\n-                \/\/ We are executing inside <clinit>.\n-                return new WeakReference<>(Thread.currentThread());\n-            return null;\n-        }\n-        static final EnsureInitialized INSTANCE = new EnsureInitialized();\n-    }\n-\n@@ -402,18 +386,6 @@\n-        WeakReference<Thread> ref = EnsureInitialized.INSTANCE.get(defc);\n-        if (ref == null) {\n-            return true;  \/\/ the final state\n-        }\n-        \/\/ Somebody may still be running defc.<clinit>.\n-        if (ref.refersTo(Thread.currentThread())) {\n-            \/\/ If anybody is running defc.<clinit>, it is this thread.\n-            if (UNSAFE.shouldBeInitialized(defc))\n-                \/\/ Yes, we are running it; keep the barrier for now.\n-                return false;\n-        } else {\n-            \/\/ We are in a random thread.  Block.\n-            UNSAFE.ensureClassInitialized(defc);\n-        }\n-        assert(!UNSAFE.shouldBeInitialized(defc));\n-        \/\/ put it into the final state\n-        EnsureInitialized.INSTANCE.remove(defc);\n-        return true;\n+        UNSAFE.ensureClassInitialized(defc);\n+        \/\/ Once we get here either defc was fully initialized by another thread, or\n+        \/\/ defc was already being initialized by the current thread. In the latter case\n+        \/\/ the barrier must remain. We can detect this simply by checking if initialization\n+        \/\/ is still needed.\n+        return !UNSAFE.shouldBeInitialized(defc);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/DirectMethodHandle.java","additions":7,"deletions":35,"binary":false,"changes":42,"status":"modified"},{"patch":"@@ -497,1 +497,1 @@\n-                return asTypeCache = asFixedArity().asType(newType);\n+                return asFixedArity().asType(newType);\n@@ -502,1 +502,1 @@\n-                return asTypeCache = acc.asType(newType);\n+                return acc.asType(newType);\n@@ -513,1 +513,1 @@\n-            return asTypeCache = collector.asType(newType);\n+            return collector.asType(newType);\n@@ -741,1 +741,1 @@\n-            return (asTypeCache = wrapper);\n+            return wrapper;\n@@ -1217,1 +1217,1 @@\n-            return asTypeCache = target.asType(newType);\n+            return target.asType(newType);\n@@ -1280,1 +1280,1 @@\n-            return asTypeCache = target.asType(newType);\n+            return target.asType(newType);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleImpl.java","additions":6,"deletions":6,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2801,0 +2801,4 @@\n+         * <p>\n+         * This method returns when {@code targetClass} is fully initialized, or\n+         * when {@code targetClass} is being initialized by the current thread.\n+         *\n@@ -2802,1 +2806,2 @@\n-         * @return {@code targetClass} that has been initialized\n+         * @return {@code targetClass} that has been initialized, or that is being\n+         *         initialized by the current thread.\n@@ -4449,1 +4454,1 @@\n-     * an {@code index}, {@code T} and it's corresponding boxed type,\n+     * an {@code index}, {@code T} and its corresponding boxed type,\n@@ -4536,1 +4541,1 @@\n-     * {@code index}, {@code T} and it's corresponding boxed type,\n+     * {@code index}, {@code T} and its corresponding boxed type,\n@@ -5916,2 +5921,2 @@\n-        if (filterType.parameterList().size() > 1) {\n-            for (int i = 0 ; i < filterType.parameterList().size() - 1 ; i++) {\n+        if (filterType.parameterCount() > 1) {\n+            for (int i = 0 ; i < filterType.parameterCount() - 1 ; i++) {\n@@ -6769,1 +6774,1 @@\n-        return longest.size() == 0 ? empty : longest.subList(skipSize, longest.size());\n+        return longest.isEmpty() ? empty : longest.subList(skipSize, longest.size());\n@@ -7053,1 +7058,1 @@\n-        } else if (innerList.size() == 0 || innerList.get(0) != returnType) {\n+        } else if (innerList.isEmpty() || innerList.get(0) != returnType) {\n@@ -7383,1 +7388,1 @@\n-        if (vsize != 0 && (innerList.size() == 0 || innerList.get(0) != returnType)) {\n+        if (vsize != 0 && (innerList.isEmpty() || innerList.get(0) != returnType)) {\n@@ -7607,1 +7612,1 @@\n-        if (vsize != 0 && (internalParamList.size() == 0 || internalParamList.get(0) != returnType)) {\n+        if (vsize != 0 && (internalParamList.isEmpty() || internalParamList.get(0) != returnType)) {\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandles.java","additions":14,"deletions":9,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -796,1 +796,1 @@\n-        return Collections.unmodifiableList(Arrays.asList(ptypes.clone()));\n+        return List.of(ptypes);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodType.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2014, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2014, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -385,1 +385,1 @@\n- * access it's variables is unrestricted.\n+ * access its variables is unrestricted.\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/VarHandle.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -137,1 +137,1 @@\n-     *   [active\/enqeued]\n+     *   [active\/enqueued]\n@@ -517,2 +517,1 @@\n-     * <p> This method establishes an ordering for\n-     * <a href=\"package-summary.html#reachability\"><em>strong reachability<\/em><\/a>\n+     * <p> This method establishes an ordering for <em>strong reachability<\/em>\n@@ -616,1 +615,0 @@\n-     * @jls 12.6 Finalization of Class Instances\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Reference.java","additions":2,"deletions":4,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+import jdk.internal.vm.annotation.Stable;\n@@ -65,0 +66,1 @@\n+    @Stable\n@@ -69,0 +71,1 @@\n+    @Stable\n@@ -97,1 +100,2 @@\n-    private volatile ConstructorAccessor constructorAccessor;\n+    @Stable\n+    private ConstructorAccessor constructorAccessor;\n@@ -495,1 +499,1 @@\n-        ConstructorAccessor ca = constructorAccessor;   \/\/ read volatile\n+        ConstructorAccessor ca = constructorAccessor;   \/\/ read @Stable\n@@ -536,2 +540,2 @@\n-        ConstructorAccessor tmp = null;\n-        if (root != null) tmp = root.getConstructorAccessor();\n+        Constructor<?> root = this.root;\n+        ConstructorAccessor tmp = root == null ? null : root.getConstructorAccessor();\n@@ -560,0 +564,1 @@\n+        Constructor<?> root = this.root;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Constructor.java","additions":9,"deletions":4,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -33,0 +33,1 @@\n+import jdk.internal.vm.annotation.Stable;\n@@ -68,0 +69,1 @@\n+    @Stable\n@@ -73,0 +75,1 @@\n+    @Stable\n@@ -74,0 +77,1 @@\n+    @Stable\n@@ -82,0 +86,1 @@\n+    @Stable\n@@ -84,0 +89,1 @@\n+    @Stable\n@@ -433,0 +439,3 @@\n+            return getFieldAccessor().get(obj);\n+        } else {\n+            return getOverrideFieldAccessor().get(obj);\n@@ -434,1 +443,0 @@\n-        return getFieldAccessor(obj).get(obj);\n@@ -467,0 +475,3 @@\n+            return getFieldAccessor().getBoolean(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getBoolean(obj);\n@@ -468,1 +479,0 @@\n-        return getFieldAccessor(obj).getBoolean(obj);\n@@ -501,0 +511,3 @@\n+            return getFieldAccessor().getByte(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getByte(obj);\n@@ -502,1 +515,0 @@\n-        return getFieldAccessor(obj).getByte(obj);\n@@ -537,0 +549,3 @@\n+            return getFieldAccessor().getChar(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getChar(obj);\n@@ -538,1 +553,0 @@\n-        return getFieldAccessor(obj).getChar(obj);\n@@ -573,0 +587,3 @@\n+            return getFieldAccessor().getShort(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getShort(obj);\n@@ -574,1 +591,0 @@\n-        return getFieldAccessor(obj).getShort(obj);\n@@ -609,0 +625,3 @@\n+            return getFieldAccessor().getInt(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getInt(obj);\n@@ -610,1 +629,0 @@\n-        return getFieldAccessor(obj).getInt(obj);\n@@ -645,0 +663,3 @@\n+            return getFieldAccessor().getLong(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getLong(obj);\n@@ -646,1 +667,0 @@\n-        return getFieldAccessor(obj).getLong(obj);\n@@ -681,0 +701,3 @@\n+            return getFieldAccessor().getFloat(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getFloat(obj);\n@@ -682,1 +705,0 @@\n-        return getFieldAccessor(obj).getFloat(obj);\n@@ -717,0 +739,3 @@\n+            return getFieldAccessor().getDouble(obj);\n+        } else {\n+            return getOverrideFieldAccessor().getDouble(obj);\n@@ -718,1 +743,0 @@\n-        return getFieldAccessor(obj).getDouble(obj);\n@@ -809,0 +833,3 @@\n+            getFieldAccessor().set(obj, value);\n+        } else {\n+            getOverrideFieldAccessor().set(obj, value);\n@@ -810,1 +837,0 @@\n-        getFieldAccessor(obj).set(obj, value);\n@@ -846,0 +872,3 @@\n+            getFieldAccessor().setBoolean(obj, z);\n+        } else {\n+            getOverrideFieldAccessor().setBoolean(obj, z);\n@@ -847,1 +876,0 @@\n-        getFieldAccessor(obj).setBoolean(obj, z);\n@@ -883,0 +911,3 @@\n+            getFieldAccessor().setByte(obj, b);\n+        } else {\n+            getOverrideFieldAccessor().setByte(obj, b);\n@@ -884,1 +915,0 @@\n-        getFieldAccessor(obj).setByte(obj, b);\n@@ -920,0 +950,3 @@\n+            getFieldAccessor().setChar(obj, c);\n+        } else {\n+            getOverrideFieldAccessor().setChar(obj, c);\n@@ -921,1 +954,0 @@\n-        getFieldAccessor(obj).setChar(obj, c);\n@@ -957,0 +989,3 @@\n+            getFieldAccessor().setShort(obj, s);\n+        } else {\n+            getOverrideFieldAccessor().setShort(obj, s);\n@@ -958,1 +993,0 @@\n-        getFieldAccessor(obj).setShort(obj, s);\n@@ -994,0 +1028,3 @@\n+            getFieldAccessor().setInt(obj, i);\n+        } else {\n+            getOverrideFieldAccessor().setInt(obj, i);\n@@ -995,1 +1032,0 @@\n-        getFieldAccessor(obj).setInt(obj, i);\n@@ -1031,0 +1067,3 @@\n+            getFieldAccessor().setLong(obj, l);\n+        } else {\n+            getOverrideFieldAccessor().setLong(obj, l);\n@@ -1032,1 +1071,0 @@\n-        getFieldAccessor(obj).setLong(obj, l);\n@@ -1068,0 +1106,3 @@\n+            getFieldAccessor().setFloat(obj, f);\n+        } else {\n+            getOverrideFieldAccessor().setFloat(obj, f);\n@@ -1069,1 +1110,0 @@\n-        getFieldAccessor(obj).setFloat(obj, f);\n@@ -1105,0 +1145,3 @@\n+            getFieldAccessor().setDouble(obj, d);\n+        } else {\n+            getOverrideFieldAccessor().setDouble(obj, d);\n@@ -1106,1 +1149,0 @@\n-        getFieldAccessor(obj).setDouble(obj, d);\n@@ -1119,6 +1161,8 @@\n-    private FieldAccessor getFieldAccessor(Object obj)\n-        throws IllegalAccessException\n-    {\n-        boolean ov = override;\n-        FieldAccessor a = (ov) ? overrideFieldAccessor : fieldAccessor;\n-        return (a != null) ? a : acquireFieldAccessor(ov);\n+    private FieldAccessor getFieldAccessor() {\n+        FieldAccessor a = fieldAccessor;\n+        return (a != null) ? a : acquireFieldAccessor();\n+    }\n+\n+    private FieldAccessor getOverrideFieldAccessor() {\n+        FieldAccessor a = overrideFieldAccessor;\n+        return (a != null) ? a : acquireOverrideFieldAccessor();\n@@ -1131,1 +1175,1 @@\n-    private FieldAccessor acquireFieldAccessor(boolean overrideFinalCheck) {\n+    private FieldAccessor acquireFieldAccessor() {\n@@ -1134,2 +1178,2 @@\n-        FieldAccessor tmp = null;\n-        if (root != null) tmp = root.getFieldAccessor(overrideFinalCheck);\n+        Field root = this.root;\n+        FieldAccessor tmp = root == null ? null : root.fieldAccessor;\n@@ -1137,4 +1181,1 @@\n-            if (overrideFinalCheck)\n-                overrideFieldAccessor = tmp;\n-            else\n-                fieldAccessor = tmp;\n+            fieldAccessor = tmp;\n@@ -1143,2 +1184,2 @@\n-            tmp = reflectionFactory.newFieldAccessor(this, overrideFinalCheck);\n-            setFieldAccessor(tmp, overrideFinalCheck);\n+            tmp = reflectionFactory.newFieldAccessor(this, false);\n+            setFieldAccessor(tmp);\n@@ -1146,0 +1187,2 @@\n+        return tmp;\n+    }\n@@ -1147,0 +1190,12 @@\n+    private FieldAccessor acquireOverrideFieldAccessor() {\n+        \/\/ First check to see if one has been created yet, and take it\n+        \/\/ if so\n+        Field root = this.root;\n+        FieldAccessor tmp = root == null ? null : root.overrideFieldAccessor;\n+        if (tmp != null) {\n+            overrideFieldAccessor = tmp;\n+        } else {\n+            \/\/ Otherwise fabricate one and propagate it up to the root\n+            tmp = reflectionFactory.newFieldAccessor(this, true);\n+            setOverrideFieldAccessor(tmp);\n+        }\n@@ -1150,4 +1205,9 @@\n-    \/\/ Returns FieldAccessor for this Field object, not looking up\n-    \/\/ the chain to the root\n-    private FieldAccessor getFieldAccessor(boolean overrideFinalCheck) {\n-        return (overrideFinalCheck)? overrideFieldAccessor : fieldAccessor;\n+    \/\/ Sets the fieldAccessor for this Field object and\n+    \/\/ (recursively) its root\n+    private void setFieldAccessor(FieldAccessor accessor) {\n+        fieldAccessor = accessor;\n+        \/\/ Propagate up\n+        Field root = this.root;\n+        if (root != null) {\n+            root.setFieldAccessor(accessor);\n+        }\n@@ -1156,1 +1216,1 @@\n-    \/\/ Sets the FieldAccessor for this Field object and\n+    \/\/ Sets the overrideFieldAccessor for this Field object and\n@@ -1158,5 +1218,2 @@\n-    private void setFieldAccessor(FieldAccessor accessor, boolean overrideFinalCheck) {\n-        if (overrideFinalCheck)\n-            overrideFieldAccessor = accessor;\n-        else\n-            fieldAccessor = accessor;\n+    private void setOverrideFieldAccessor(FieldAccessor accessor) {\n+        overrideFieldAccessor = accessor;\n@@ -1164,0 +1221,1 @@\n+        Field root = this.root;\n@@ -1165,1 +1223,1 @@\n-            root.setFieldAccessor(accessor, overrideFinalCheck);\n+            root.setOverrideFieldAccessor(accessor);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Field.java","additions":102,"deletions":44,"binary":false,"changes":146,"status":"modified"},{"patch":"@@ -88,1 +88,2 @@\n-    private volatile MethodAccessor methodAccessor;\n+    @Stable\n+    private MethodAccessor      methodAccessor;\n@@ -669,2 +670,2 @@\n-        MethodAccessor tmp = null;\n-        if (root != null) tmp = root.getMethodAccessor();\n+        Method root = this.root;\n+        MethodAccessor tmp = root == null ? null : root.getMethodAccessor();\n@@ -693,0 +694,1 @@\n+        Method root = this.root;\n","filename":"src\/java.base\/share\/classes\/java\/lang\/reflect\/Method.java","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -40,0 +40,2 @@\n+import static java.util.Objects.requireNonNull;\n+\n@@ -324,2 +326,2 @@\n-     *                     components. Maybe be null, if the {@code methodName}\n-     *                     is {@code \"equals\"} or {@code \"hashCode\"}.\n+     *                     components. This parameter is ignored if the {@code methodName}\n+     *                     parameter is {@code \"equals\"} or {@code \"hashCode\"}\n@@ -331,0 +333,3 @@\n+     * @throws NullPointerException if any argument but {@code lookup} is {@code null},\n+     *                              in the case of the {@code getters} argument, its\n+     *                              contents cannot be {@code null} either\n@@ -337,2 +342,6 @@\n-        Objects.requireNonNull(type);\n-        Objects.requireNonNull(recordClass);\n+        requireNonNull(methodName);\n+        requireNonNull(type);\n+        requireNonNull(recordClass);\n+        requireNonNull(names);\n+        requireNonNull(getters);\n+        Arrays.stream(getters).forEach(Objects::requireNonNull);\n@@ -341,5 +350,4 @@\n-\n-        if (type instanceof MethodType) {\n-            methodType = (MethodType) type;\n-            if (((MethodType) type).parameterType(0) != receiverType) {\n-                throw new IllegalArgumentException(\"Bad method type: \" + methodType);\n+        if (type instanceof MethodType mt) {\n+            methodType = mt;\n+            if (mt.parameterType(0) != receiverType) {\n+                throw new IllegalArgumentException(\"Bad method type: \" + mt);\n","filename":"src\/java.base\/share\/classes\/java\/lang\/runtime\/ObjectMethods.java","additions":17,"deletions":9,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -1266,3 +1266,8 @@\n-     * Ensures the given class has been initialized. This is often\n-     * needed in conjunction with obtaining the static field base of a\n-     * class.\n+     * Ensures the given class has been initialized (see JVMS-5.5 for details).\n+     * This is often needed in conjunction with obtaining the static field base\n+     * of a class.\n+     *\n+     * The call returns when either class {@code c} is fully initialized or\n+     * class {@code c} is being initialized and the call is performed from\n+     * the initializing thread. In the latter case a subsequent call to\n+     * {@link #shouldBeInitialized} will return {@code true}.\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/misc\/Unsafe.java","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+import jdk.internal.vm.annotation.Stable;\n@@ -42,1 +43,1 @@\n-    protected final Field   field;\n+    @Stable\n@@ -47,1 +48,1 @@\n-        this.field = field;\n+        super(field);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/reflect\/UnsafeFieldAccessorImpl.java","additions":3,"deletions":2,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -320,1 +320,2 @@\n-        java.naming;\n+        java.naming,\n+        jdk.jartool;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2005, 2020, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2005, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -700,1 +700,1 @@\n-         * An implementation-reserved node. This is the not the node\n+         * An implementation-reserved node. This is not the node\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/tree\/Tree.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -34,1 +34,1 @@\n- * When a visitor is passed to an tree's {@link Tree#accept\n+ * When a visitor is passed to a tree's {@link Tree#accept\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/tree\/TreeVisitor.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -259,1 +259,3 @@\n-                    return ((DCTree) tree).getSourcePosition((DCDocComment) comment);\n+                    DCDocComment dcComment = (DCDocComment) comment;\n+                    DCTree dcTree = (DCTree) tree;\n+                    return dcComment.getSourcePosition(dcTree.getStartPosition());\n@@ -261,1 +263,2 @@\n-                @Override  @DefinedBy(Api.COMPILER_TREE) @SuppressWarnings(\"fallthrough\")\n+\n+                @Override  @DefinedBy(Api.COMPILER_TREE)\n@@ -264,68 +267,2 @@\n-                    if (tree instanceof DCEndPosTree<?> dcEndPosTree) {\n-                        int endPos = dcEndPosTree.getEndPos(dcComment);\n-\n-                        if (endPos != Position.NOPOS) {\n-                            return endPos;\n-                        }\n-                    }\n-                    int correction = 0;\n-                    switch (tree.getKind()) {\n-                        case TEXT:\n-                            DCText text = (DCText) tree;\n-\n-                            return dcComment.comment.getSourcePos(text.pos + text.text.length());\n-                        case ERRONEOUS:\n-                            DCErroneous err = (DCErroneous) tree;\n-\n-                            return dcComment.comment.getSourcePos(err.pos + err.body.length());\n-                        case IDENTIFIER:\n-                            DCIdentifier ident = (DCIdentifier) tree;\n-\n-                            return dcComment.comment.getSourcePos(ident.pos + (ident.name != names.error ? ident.name.length() : 0));\n-                        case PARAM:\n-                            DCParam param = (DCParam) tree;\n-\n-                            if (param.isTypeParameter && param.getDescription().isEmpty()) {\n-                                correction = 1;\n-                            }\n-                        case AUTHOR: case DEPRECATED: case RETURN: case SEE:\n-                        case SERIAL: case SERIAL_DATA: case SERIAL_FIELD: case SINCE:\n-                        case THROWS: case UNKNOWN_BLOCK_TAG: case VERSION: {\n-                            DocTree last = getLastChild(tree);\n-\n-                            if (last != null) {\n-                                return getEndPosition(file, comment, last) + correction;\n-                            }\n-\n-                            int pos;\n-                            String name;\n-                            if (tree.getKind() == DocTree.Kind.RETURN) {\n-                                DCTree.DCReturn dcReturn = (DCTree.DCReturn) tree;\n-                                pos = dcReturn.pos;\n-                                name = dcReturn.getTagName();\n-                            } else {\n-                                DCBlockTag block = (DCBlockTag) tree;\n-                                pos = block.pos;\n-                                name = block.getTagName();\n-                            }\n-\n-                            return dcComment.comment.getSourcePos(pos + name.length() + 1);\n-                        }\n-                        case ENTITY: {\n-                            DCEntity endEl = (DCEntity) tree;\n-                            return dcComment.comment.getSourcePos(endEl.pos + (endEl.name != names.error ? endEl.name.length() : 0) + 2);\n-                        }\n-                        case COMMENT: {\n-                            DCComment endEl = (DCComment) tree;\n-                            return dcComment.comment.getSourcePos(endEl.pos + endEl.body.length());\n-                        }\n-                        default:\n-                            DocTree last = getLastChild(tree);\n-\n-                            if (last != null) {\n-                                return getEndPosition(file, comment, last);\n-                            }\n-                            break;\n-                    }\n-\n-                    return Position.NOPOS;\n+                    DCTree dcTree = (DCTree) tree;\n+                    return dcComment.getSourcePosition(dcTree.getEndPosition());\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/api\/JavacTrees.java","additions":7,"deletions":70,"binary":false,"changes":77,"status":"modified"},{"patch":"@@ -1535,0 +1535,1 @@\n+            RecordComponent toRemove = null;\n@@ -1540,1 +1541,9 @@\n-                    return rc;\n+                    if (rc.type.hasTag(TypeTag.ERROR) && !var.sym.type.hasTag(TypeTag.ERROR)) {\n+                        \/\/ Found a record component with an erroneous type: save it so that it can be removed later.\n+                        \/\/ If the class type of the record component is generated by annotation processor, it should\n+                        \/\/ use the new actual class type and symbol instead of the old dummy ErrorType.\n+                        toRemove = rc;\n+                    } else {\n+                        \/\/ Found a good record component: just return.\n+                        return rc;\n+                    }\n@@ -1544,1 +1553,6 @@\n-            if (addIfMissing) {\n+            if (toRemove != null) {\n+                \/\/ Found a record component with an erroneous type: remove it and create a new one\n+                recordComponents = List.filter(recordComponents, toRemove);\n+                recordComponents = recordComponents.append(rc = new RecordComponent(var.sym, annotations));\n+            } else if (addIfMissing) {\n+                \/\/ Didn't find the record component: create one.\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Symbol.java","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -941,1 +941,3 @@\n-            return kind == UNBOUND;\n+            \/\/ is it `?` or `? extends Object`?\n+            return kind == UNBOUND ||\n+                    (kind == EXTENDS && type.tsym.flatName() == type.tsym.name.table.names.java_lang_Object);\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Type.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -633,1 +633,4 @@\n-                    if (pt == Type.recoveryType) {\n+                    boolean needsReport = pt == Type.recoveryType ||\n+                            (details.getDiagnosticPosition() != null &&\n+                            details.getDiagnosticPosition().getTree().hasTag(LAMBDA));\n+                    if (needsReport) {\n@@ -1616,1 +1619,1 @@\n-                            loopEnv, exprType, names.iterator, List.nil(), List.nil());\n+                            loopEnv, types.skipTypeVars(exprType, false), names.iterator, List.nil(), List.nil());\n@@ -2692,1 +2695,1 @@\n-                    msym.owner == syms.objectType.tsym &&\n+                    (msym.owner == syms.objectType.tsym || msym.owner.isInterface()) &&\n@@ -4317,7 +4320,2 @@\n-        \/\/ (1) Also find the environment current for the class where\n-        \/\/     sym is defined (`symEnv').\n-        \/\/ Only for pre-tiger versions (1.4 and earlier):\n-        \/\/ (2) Also determine whether we access symbol out of an anonymous\n-        \/\/     class in a this or super call.  This is illegal for instance\n-        \/\/     members since such classes don't carry a this$n link.\n-        \/\/     (`noOuterThisPath').\n+        \/\/ Also find the environment current for the class where\n+        \/\/ sym is defined (`symEnv').\n@@ -4325,1 +4323,0 @@\n-        boolean noOuterThisPath = false;\n@@ -4334,2 +4331,0 @@\n-                if ((symEnv.enclClass.sym.flags() & NOOUTERTHIS) != 0)\n-                    noOuterThisPath = false;\n@@ -4357,1 +4352,1 @@\n-        if ((symEnv.info.isSelfCall || noOuterThisPath) &&\n+        if (symEnv.info.isSelfCall &&\n@@ -5513,3 +5508,10 @@\n-                    boolean hasErrorSuper = types.directSupertypes(c.type)\n-                                                 .stream()\n-                                                 .anyMatch(s -> s.tsym.kind == Kind.ERR);\n+                    boolean hasErrorSuper = false;\n+\n+                    hasErrorSuper |= types.directSupertypes(c.type)\n+                                          .stream()\n+                                          .anyMatch(s -> s.tsym.kind == Kind.ERR);\n+\n+                    ClassType ct = (ClassType) c.type;\n+\n+                    hasErrorSuper |= !ct.isCompound() && ct.interfaces_field != ct.all_interfaces_field;\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":19,"deletions":17,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -3354,1 +3354,3 @@\n-            t = ((Attribute.Class)l.head.snd).getValue();\n+            if (l.head.snd instanceof Attribute.Class) {\n+                t = ((Attribute.Class)l.head.snd).getValue();\n+            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -212,0 +212,1 @@\n+    private final DeferredCompletionFailureHandler dcfh;\n@@ -336,0 +337,1 @@\n+        dcfh = DeferredCompletionFailureHandler.instance(context);\n@@ -775,6 +777,3 @@\n-                            if (sup.tsym.kind == TYP && sup.tsym.isAbstract() && sup.tsym.isSealed()) {\n-                                boolean hasAll = ((ClassSymbol) sup.tsym).permitted\n-                                                                         .stream()\n-                                                                         .allMatch(covered::contains);\n-\n-                                if (hasAll && covered.add(sup.tsym)) {\n+                            if (sup.tsym.kind == TYP) {\n+                                if (isTransitivelyCovered(sup.tsym, covered) &&\n+                                    covered.add(sup.tsym)) {\n@@ -790,0 +789,20 @@\n+        private boolean isTransitivelyCovered(Symbol sealed, Set<Symbol> covered) {\n+            DeferredCompletionFailureHandler.Handler prevHandler =\n+                    dcfh.setHandler(dcfh.speculativeCodeHandler);\n+            try {\n+                if (covered.stream().anyMatch(c -> sealed.isSubClass(c, types)))\n+                    return true;\n+                if (sealed.kind == TYP && sealed.isAbstract() && sealed.isSealed()) {\n+                    return ((ClassSymbol) sealed).permitted\n+                                                 .stream()\n+                                                 .allMatch(s -> isTransitivelyCovered(s, covered));\n+                }\n+                return false;\n+            } catch (CompletionFailure cf) {\n+                \/\/safe to ignore, the symbol will be un-completed when the speculative handler is removed.\n+                return false;\n+            } finally {\n+                dcfh.setHandler(prevHandler);\n+            }\n+        }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Flow.java","additions":25,"deletions":6,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -493,1 +493,1 @@\n-        return (s2 == null || s2 == sym || sym.owner == s2.owner ||\n+        return (s2 == null || s2 == sym || sym.owner == s2.owner || (sym.owner.isInterface() && s2.owner == syms.objectType.tsym) ||\n@@ -1877,1 +1877,2 @@\n-        for (TypeSymbol s : superclasses(intype)) {\n+        boolean isInterface = site.tsym.isInterface();\n+        for (TypeSymbol s : isInterface ? List.of(intype.tsym) : superclasses(intype)) {\n@@ -1915,0 +1916,13 @@\n+        if (isInterface && bestSoFar.kind.isResolutionError()) {\n+            bestSoFar = findMethodInScope(env, site, name, argtypes, typeargtypes,\n+                    syms.objectType.tsym.members(), bestSoFar, allowBoxing, useVarargs, true);\n+            if (bestSoFar.kind.isValid()) {\n+                Symbol baseSymbol = bestSoFar;\n+                bestSoFar = new MethodSymbol(bestSoFar.flags_field, bestSoFar.name, bestSoFar.type, intype.tsym) {\n+                    @Override\n+                    public Symbol baseSymbol() {\n+                        return baseSymbol;\n+                    }\n+                };\n+            }\n+        }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Resolve.java","additions":16,"deletions":2,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -794,1 +794,1 @@\n-                if (!types.isSameType(ec, tree.type)) {\n+                if (!types.isSameType(ec, tree.type) && (!types.isSameType(ec, pt))) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TransTypes.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -556,0 +556,10 @@\n+        \/** Generate a base clause for a record type.\n+         *  @param pos              The position for trees and diagnostics, if any\n+         *  @param c                The class symbol of the record\n+         *\/\n+        protected  JCExpression recordBase(int pos, ClassSymbol c) {\n+            JCExpression result = make.at(pos).\n+                QualIdent(syms.recordType.tsym);\n+            return result;\n+        }\n+\n@@ -695,1 +705,1 @@\n-                ? attr.attribBase(enumBase(tree.pos, sym), baseEnv,\n+                ? attr.attribBase(extending = enumBase(tree.pos, sym), baseEnv,\n@@ -699,1 +709,4 @@\n-                : sym.isRecord() ? syms.recordType : syms.objectType;\n+                : sym.isRecord()\n+                ? attr.attribBase(extending = recordBase(tree.pos, sym), baseEnv,\n+                                  true, false, false)\n+                : syms.objectType;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":15,"deletions":2,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1564,2 +1564,2 @@\n-         *  @param catchers  The lis of catch clauses.\n-         *  @param env       the environment current for the body.\n+         *  @param catchers  The list of catch clauses.\n+         *  @param env       The current environment of the body.\n@@ -1577,1 +1577,7 @@\n-            Chain exitChain = code.branch(goto_);\n+            Chain exitChain;\n+            boolean actualTry = env.tree.hasTag(TRY);\n+            if (startpc == endpc && actualTry) {\n+                exitChain = code.branch(dontgoto);\n+            } else {\n+                exitChain = code.branch(goto_);\n+            }\n@@ -1595,1 +1601,1 @@\n-            if (hasFinalizer) {\n+            if (hasFinalizer && (startpc != endpc || !actualTry)) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/jvm\/Gen.java","additions":10,"deletions":4,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -134,1 +134,1 @@\n-    annotation type not applicable to this kind of declaration\n+    annotation interface not applicable to this kind of declaration\n@@ -365,1 +365,1 @@\n-    annotation type declaration not allowed here\n+    annotation interface declaration not allowed here\n@@ -419,1 +419,1 @@\n-    default value only allowed in an annotation type declaration\n+    default value only allowed in an annotation interface declaration\n@@ -435,1 +435,1 @@\n-    {0} is not a repeatable annotation type\n+    {0} is not a repeatable annotation interface\n@@ -455,1 +455,1 @@\n-    containing annotation type ({0}) must declare an element named ''value'' of type {2}\n+    containing annotation interface ({0}) must declare an element named ''value'' of type {2}\n@@ -459,1 +459,1 @@\n-    containing annotation type ({0}) does not have a default value for element {1}\n+    containing annotation interface ({0}) does not have a default value for element {1}\n@@ -463,1 +463,1 @@\n-    retention of containing annotation type ({0}) is shorter than the retention of repeatable annotation type ({2})\n+    retention of containing annotation interface ({0}) is shorter than the retention of repeatable annotation interface ({2})\n@@ -467,1 +467,1 @@\n-    repeatable annotation type ({1}) is @Documented while containing annotation type ({0}) is not\n+    repeatable annotation interface ({1}) is @Documented while containing annotation interface ({0}) is not\n@@ -471,1 +471,1 @@\n-    repeatable annotation type ({1}) is @Inherited while containing annotation type ({0}) is not\n+    repeatable annotation interface ({1}) is @Inherited while containing annotation interface ({0}) is not\n@@ -475,1 +475,1 @@\n-    containing annotation type ({0}) is applicable to more targets than repeatable annotation type ({1})\n+    containing annotation interface ({0}) is applicable to more targets than repeatable annotation interface ({1})\n@@ -536,1 +536,1 @@\n-    enum types may not be instantiated\n+    enum classes may not be instantiated\n@@ -545,1 +545,1 @@\n-    enum types are not extensible\n+    enum classes are not extensible\n@@ -704,1 +704,1 @@\n-    elements in annotation type declarations cannot declare formal parameters\n+    elements in annotation interface declarations cannot declare formal parameters\n@@ -708,1 +708,1 @@\n-    annotation type {0} cannot be generic\n+    annotation interface {0} cannot be generic\n@@ -711,1 +711,1 @@\n-    elements in annotation type declarations cannot be generic methods\n+    elements in annotation interface declarations cannot be generic methods\n@@ -715,1 +715,1 @@\n-    annotation type {1} declares an element with the same name as method {0}\n+    annotation interface {1} declares an element with the same name as method {0}\n@@ -724,1 +724,1 @@\n-    invalid type for annotation type element\n+    invalid type for annotation interface element\n@@ -762,1 +762,1 @@\n-    enum types must not be local\n+    enum classes must not be local\n@@ -929,1 +929,1 @@\n-    {0} is not an annotation type\n+    {0} is not an annotation interface\n@@ -1990,1 +1990,1 @@\n-    Malformed string ''{0}'' for a supported annotation type returned by processor ''{1}''\n+    Malformed string ''{0}'' for a supported annotation interface returned by processor ''{1}''\n@@ -2006,1 +2006,1 @@\n-    Duplicate supported annotation type ''{0}'' returned by annotation processor ''{1}''\n+    Duplicate supported annotation interface ''{0}'' returned by annotation processor ''{1}''\n@@ -2010,1 +2010,1 @@\n-    Annotation processor ''{0}'' redundantly supports both ''*'' and other annotation types\n+    Annotation processor ''{0}'' redundantly supports both ''*'' and other annotation interfaces\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":22,"deletions":22,"binary":false,"changes":44,"status":"modified"},{"patch":"@@ -815,0 +815,1 @@\n+            @SuppressWarnings(\"serial\") \/\/ List not statically Serilizable\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/TreeInfo.java","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -132,0 +132,1 @@\n+    public final Name jdk_unsupported;\n@@ -325,0 +326,1 @@\n+        jdk_unsupported = fromString(\"jdk.unsupported\");\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/util\/Names.java","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2017, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2017, 2021, Oracle and\/or its affiliates. All rights reserved.\n@@ -30,0 +30,2 @@\n+#ifndef ZERO\n+\n@@ -53,0 +55,2 @@\n+\n+#endif\n","filename":"test\/hotspot\/gtest\/code\/test_vtableStub.cpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -95,1 +95,3 @@\n-runtime\/InvocationTests\/invokevirtualTests.java 8271125 generic-all\n+runtime\/InvocationTests\/invokevirtualTests.java#current-int 8271125 generic-all\n+runtime\/InvocationTests\/invokevirtualTests.java#current-comp 8271125 generic-all\n+runtime\/InvocationTests\/invokevirtualTests.java#old-int 8271125 generic-all\n@@ -100,3 +102,3 @@\n-runtime\/os\/TestTracePageSizes.java#with-G1 8267460 linux-aarch64\n-runtime\/os\/TestTracePageSizes.java#with-Parallel 8267460 linux-aarch64\n-runtime\/os\/TestTracePageSizes.java#with-Serial 8267460 linux-aarch64\n+runtime\/os\/TestTracePageSizes.java#G1 8267460 linux-aarch64\n+runtime\/os\/TestTracePageSizes.java#Parallel 8267460 linux-aarch64\n+runtime\/os\/TestTracePageSizes.java#Serial 8267460 linux-aarch64\n@@ -116,1 +118,0 @@\n-resourcehogs\/serviceability\/sa\/TestHeapDumpForLargeArray.java 8262386 generic-all\n@@ -122,3 +123,5 @@\n-serviceability\/sa\/ClhsdbFindPC.java#id1 8269982 macosx-aarch64\n-serviceability\/sa\/ClhsdbFindPC.java#id3 8269982 macosx-aarch64\n-serviceability\/sa\/ClhsdbPstack.java#id1 8269982 macosx-aarch64\n+serviceability\/sa\/ClhsdbFindPC.java#xcomp-core 8269982 macosx-aarch64\n+serviceability\/sa\/ClhsdbFindPC.java#no-xcomp-core 8269982 macosx-aarch64\n+serviceability\/sa\/ClhsdbPstack.java#core 8269982 macosx-aarch64\n+\n+resourcehogs\/serviceability\/sa\/TestHeapDumpForLargeArray.java 8274620 macosx-x64\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":11,"deletions":8,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -216,0 +216,1 @@\n+  :tier1_gc_epsilon \\\n@@ -223,1 +224,0 @@\n-  :gc_epsilon \\\n@@ -229,1 +229,1 @@\n-  -:gc_epsilon \\\n+  -gc\/CriticalNativeArgs.java \\\n@@ -234,0 +234,1 @@\n+  -gc\/epsilon \\\n@@ -236,2 +237,8 @@\n-gc_epsilon = \\\n-  gc\/epsilon\/ \\\n+hotspot_gc_epsilon = \\\n+  :tier1_gc_epsilon \\\n+  :tier2_gc_epsilon\n+\n+tier1_gc_epsilon = \\\n+  gc\/epsilon\/\n+\n+tier2_gc_epsilon = \\\n@@ -256,2 +263,1 @@\n-  gc\/shenandoah\/oom\/ \\\n-  gc\/CriticalNativeArgs.java\n+  gc\/shenandoah\/oom\/\n@@ -279,0 +285,2 @@\n+  gc\/CriticalNativeArgs.java \\\n+  gc\/stress\/CriticalNativeStress.java \\\n@@ -281,1 +289,0 @@\n-  -gc\/stress\/CriticalNativeStress.java \\\n@@ -290,1 +297,0 @@\n-  gc\/stress\/CriticalNativeStress.java \\\n@@ -315,0 +321,2 @@\n+ -runtime\/Metaspace\/elastic\/TestMetaspaceAllocationMT1.java \\\n+ -runtime\/Metaspace\/elastic\/TestMetaspaceAllocationMT2.java \\\n@@ -381,0 +389,2 @@\n+ -runtime\/cds\/appcds\/TestEpsilonGCWithCDS.java \\\n+ -runtime\/cds\/appcds\/TestSerialGCWithCDS.java \\\n@@ -412,0 +422,13 @@\n+# No need to run every test with EpsilonGC. A small subset will provide enough\n+# coverage. Also avoid some tests that may OOM.\n+hotspot_cds_epsilongc = \\\n+  runtime\/cds\/appcds\/HelloTest.java \\\n+  runtime\/cds\/appcds\/MultiProcessSharing.java \\\n+  runtime\/cds\/appcds\/StaticArchiveWithLambda.java \\\n+  runtime\/cds\/appcds\/cacheObject \\\n+  runtime\/cds\/appcds\/customLoader\/ParallelTestSingleFP.java \\\n+  runtime\/cds\/appcds\/dynamicArchive\/HelloDynamic.java \\\n+  runtime\/cds\/appcds\/javaldr \\\n+  runtime\/cds\/appcds\/jigsaw \\\n+  runtime\/cds\/appcds\/loaderConstraints\n+\n@@ -466,0 +489,18 @@\n+tier2 = \\\n+  :hotspot_tier2_runtime \\\n+  :hotspot_tier2_runtime_platform_agnostic \\\n+  :hotspot_tier2_serviceability \\\n+  :tier2_gc_epsilon \\\n+  :tier2_gc_shenandoah\n+\n+tier3 = \\\n+  :hotspot_tier3_runtime \\\n+  :tier3_gc_shenandoah\n+\n+# Everything that is not in other tiers, but not apps\n+tier4 = \\\n+  :hotspot_all_no_apps \\\n+ -:tier1 \\\n+ -:tier2 \\\n+ -:tier3\n+\n","filename":"test\/hotspot\/jtreg\/TEST.groups","additions":49,"deletions":8,"binary":false,"changes":57,"status":"modified"},{"patch":"@@ -117,2 +117,2 @@\n-        protected static final String MYVALUE_ARRAY_KLASS = \"precise klass \\\\[(L|Q)compiler\/valhalla\/inlinetypes\/MyValue\";\n-        protected static final String ALLOC  = \"(.*precise klass compiler\/valhalla\/inlinetypes\/MyValue.*\\\\R(.*(?i:mov|xorl|nop|spill).*\\\\R)*.*_new_instance_Java\" + END;\n+        protected static final String MYVALUE_ARRAY_KLASS = \"\\\\[precise compiler\/valhalla\/inlinetypes\/MyValue\";\n+        protected static final String ALLOC  = \"(.*precise compiler\/valhalla\/inlinetypes\/MyValue.*\\\\R(.*(?i:mov|xorl|nop|spill).*\\\\R)*.*_new_instance_Java\" + END;\n@@ -146,1 +146,1 @@\n-        protected static final String CHECKCAST_ARRAY = \"(((?i:cmp|CLFI|CLR).*\" + MYVALUE_ARRAY_KLASS + \".*;:|.*(?i:mov|or).*\" + MYVALUE_ARRAY_KLASS + \".*;:.*\\\\R.*(cmp|CMP|CLR))\" + END;\n+        protected static final String CHECKCAST_ARRAY = \"(((?i:cmp|CLFI|CLR).*\" + MYVALUE_ARRAY_KLASS + \".*:|.*(?i:mov|or).*\" + MYVALUE_ARRAY_KLASS + \".*;:.*\\\\R.*(cmp|CMP|CLR))\" + END;\n","filename":"test\/hotspot\/jtreg\/compiler\/valhalla\/inlinetypes\/InlineTypes.java","additions":3,"deletions":3,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -28,1 +28,1 @@\n- * @requires vm.cds.archived.java.heap\n+ * @requires vm.cds.write.archived.java.heap\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/cacheObject\/CheckCachedMirrorTest.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+import jdk.test.lib.cds.CDSOptions;\n@@ -47,0 +48,4 @@\n+    static {\n+        \/\/ EpsilonGC does not support class unloading.\n+        CDSOptions.disableRuntimePrefixForEpsilonGC();\n+    }\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/customLoader\/HelloCustom.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+import jdk.test.lib.cds.CDSOptions;\n@@ -46,0 +47,4 @@\n+    static {\n+        \/\/ EpsilonGC does not support class unloading.\n+        CDSOptions.disableRuntimePrefixForEpsilonGC();\n+    }\n","filename":"test\/hotspot\/jtreg\/runtime\/cds\/appcds\/customLoader\/UnloadUnregisteredLoaderTest.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -79,0 +79,7 @@\n+# Everything not in other tiers\n+tier4 = \\\n+    \/ \\\n+   -:tier1 \\\n+   -:tier2 \\\n+   -:tier3\n+\n","filename":"test\/jdk\/TEST.groups","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+import java.util.List;\n@@ -106,1 +107,1 @@\n-        CallSite cs = (CallSite)ObjectMethods.bootstrap(LOOKUP, \"hashCode\", C.HASHCODE_DESC, C.class, null, C.ACCESSORS);\n+        CallSite cs = (CallSite)ObjectMethods.bootstrap(LOOKUP, \"hashCode\", C.HASHCODE_DESC, C.class, \"x;y\", C.ACCESSORS);\n@@ -154,10 +155,0 @@\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, \"toString\", C.TO_STRING_DESC, C.class, \"x;y\", null)       );\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, \"toString\", C.TO_STRING_DESC, C.class, null,  C.ACCESSORS));\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, \"toString\", C.TO_STRING_DESC, null,    \"x;y\", C.ACCESSORS));\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, \"equals\",   C.EQUALS_DESC,    null,    \"x;y\", C.ACCESSORS));\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, \"hashCode\", C.HASHCODE_DESC,  null,    \"x;y\", C.ACCESSORS));\n-\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, \"toString\", null,             C.class, \"x;y\", C.ACCESSORS));\n-        assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, null,       C.TO_STRING_DESC, C.class, \"x;y\", C.ACCESSORS));\n-      \/\/assertThrows(NPE, () -> ObjectMethods.bootstrap(null,   \"toString\", C.TO_STRING_DESC, C.class, \"x;y\", C.ACCESSORS));\n-\n@@ -170,0 +161,16 @@\n+\n+        record NamePlusType(String mn, MethodType mt) {}\n+        List<NamePlusType> namePlusTypeList = List.of(\n+                new NamePlusType(\"toString\", C.TO_STRING_DESC),\n+                new NamePlusType(\"equals\", C.EQUALS_DESC),\n+                new NamePlusType(\"hashCode\", C.HASHCODE_DESC)\n+        );\n+\n+        for (NamePlusType npt : namePlusTypeList) {\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, npt.mn(), npt.mt(), C.class, \"x;y\", null));\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, npt.mn(), npt.mt(), C.class, \"x;y\", new MethodHandle[]{null}));\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, npt.mn(), npt.mt(), C.class, null,  C.ACCESSORS));\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, npt.mn(), npt.mt(), null,    \"x;y\", C.ACCESSORS));\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, npt.mn(), null,     C.class, \"x;y\", C.ACCESSORS));\n+            assertThrows(NPE, () -> ObjectMethods.bootstrap(LOOKUP, null,     npt.mt(), C.class, \"x;y\", C.ACCESSORS));\n+        }\n","filename":"test\/jdk\/java\/lang\/runtime\/ObjectMethodsTest.java","additions":18,"deletions":11,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -113,1 +113,1 @@\n-        map.put(\"vm.cds.archived.java.heap\", this::vmCDSForArchivedJavaHeap);\n+        map.put(\"vm.cds.write.archived.java.heap\", this::vmCDSCanWriteArchivedJavaHeap);\n@@ -124,0 +124,1 @@\n+        vmGCforCDS(map); \/\/ may set vm.gc\n@@ -294,0 +295,28 @@\n+    \/**\n+     * \"jtreg -vmoptions:-Dtest.cds.runtime.options=...\" can be used to specify\n+     * the GC type to be used when running with a CDS archive. Set \"vm.gc\" accordingly,\n+     * so that tests that need to explicitly choose the GC type can be excluded\n+     * with \"@requires vm.gc == null\".\n+     *\n+     * @param map - property-value pairs\n+     *\/\n+    protected void vmGCforCDS(SafeMap map) {\n+        if (!GC.isSelectedErgonomically()) {\n+            \/\/ The GC has been explicitly specified on the command line, so\n+            \/\/ jtreg will set the \"vm.gc\" property. Let's not interfere with it.\n+            return;\n+        }\n+\n+        String GC_PREFIX  = \"-XX:+Use\";\n+        String GC_SUFFIX  = \"GC\";\n+        String jtropts = System.getProperty(\"test.cds.runtime.options\");\n+        if (jtropts != null) {\n+            for (String opt : jtropts.split(\",\")) {\n+                if (opt.startsWith(GC_PREFIX) && opt.endsWith(GC_SUFFIX)) {\n+                    String gc = opt.substring(GC_PREFIX.length(), opt.length() - GC_SUFFIX.length());\n+                    map.put(\"vm.gc\", () -> gc);\n+                }\n+            }\n+        }\n+    }\n+\n@@ -382,3 +411,1 @@\n-     * Check for CDS support for archived Java heap regions.\n-     *\n-     * @return true if CDS provides support for archive Java heap regions in the VM to be tested.\n+     * @return true if this VM can write Java heap objects into the CDS archive\n@@ -386,2 +413,2 @@\n-    protected String vmCDSForArchivedJavaHeap() {\n-        return \"\" + (\"true\".equals(vmCDS()) && WB.isJavaHeapArchiveSupported());\n+    protected String vmCDSCanWriteArchivedJavaHeap() {\n+        return \"\" + (\"true\".equals(vmCDS()) && WB.canWriteJavaHeapArchive());\n","filename":"test\/jtreg-ext\/requires\/VMProps.java","additions":33,"deletions":6,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -577,3 +577,3 @@\n-  public native int getOffsetForName0(String name);\n-  public int getOffsetForName(String name) throws Exception {\n-    int offset = getOffsetForName0(name);\n+  public native int getCDSOffsetForName0(String name);\n+  public int getCDSOffsetForName(String name) throws Exception {\n+    int offset = getCDSOffsetForName0(name);\n@@ -585,0 +585,8 @@\n+  public native int getCDSConstantForName0(String name);\n+  public int getCDSConstantForName(String name) throws Exception {\n+    int constant = getCDSConstantForName0(name);\n+    if (constant == -1) {\n+      throw new RuntimeException(name + \" not found\");\n+    }\n+    return constant;\n+  }\n@@ -613,1 +621,1 @@\n-  public native boolean isJavaHeapArchiveSupported();\n+  public native boolean canWriteJavaHeapArchive();\n","filename":"test\/lib\/sun\/hotspot\/WhiteBox.java","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"}]}