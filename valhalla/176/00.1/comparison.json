{"files":[{"patch":"@@ -492,0 +492,1 @@\n+d2aa5d494481a1039a092d70efa1f5c9826c5b77 lw1_0\n@@ -514,0 +515,1 @@\n+6132641c6ff61b7b8f3f10b9cd385aafadbd72ef lworld_stable\n@@ -570,0 +572,4 @@\n+6132641c6ff61b7b8f3f10b9cd385aafadbd72ef lworld_stable\n+2b098533f1e52d7d541121409b745d9420886945 lworld_stable\n+2b098533f1e52d7d541121409b745d9420886945 lworld_stable\n+7c637fd25e7d6fccdab1098bedd48ed195a86cc7 lworld_stable\n","filename":".hgtags","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -51,0 +51,1 @@\n+    case T_INLINE_TYPE : i = 10; break;\n","filename":"src\/hotspot\/cpu\/aarch64\/abstractInterpreter_aarch64.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -36,0 +36,1 @@\n+#include \"ci\/ciInlineKlass.hpp\"\n@@ -105,0 +106,6 @@\n+void LIRGenerator::init_temps_for_substitutability_check(LIR_Opr& tmp1, LIR_Opr& tmp2) {\n+  tmp1 = new_register(T_INT);\n+  tmp2 = LIR_OprFact::illegalOpr;\n+}\n+\n+\n@@ -336,1 +343,1 @@\n-  if (UseBiasedLocking) {\n+  if (UseBiasedLocking || x->maybe_inlinetype()) {\n@@ -344,0 +351,6 @@\n+\n+  CodeStub* throw_imse_stub =\n+      x->maybe_inlinetype() ?\n+      new SimpleExceptionStub(Runtime1::throw_illegal_monitor_state_exception_id, LIR_OprFact::illegalOpr, state_for(x)) :\n+      NULL;\n+\n@@ -348,1 +361,1 @@\n-                        x->monitor_no(), info_for_exception, info);\n+                        x->monitor_no(), info_for_exception, info, throw_imse_stub);\n@@ -1156,0 +1169,16 @@\n+void LIRGenerator::do_NewInlineTypeInstance(NewInlineTypeInstance* x) {\n+  \/\/ Mapping to do_NewInstance (same code)\n+  CodeEmitInfo* info = state_for(x, x->state());\n+  x->set_to_object_type();\n+  LIR_Opr reg = result_register_for(x->type());\n+  new_instance(reg, x->klass(), x->is_unresolved(),\n+             FrameMap::r2_oop_opr,\n+             FrameMap::r5_oop_opr,\n+             FrameMap::r4_oop_opr,\n+             LIR_OprFact::illegalOpr,\n+             FrameMap::r3_metadata_opr, info);\n+  LIR_Opr result = rlock_result(x);\n+  __ move(reg, result);\n+\n+}\n+\n@@ -1201,2 +1230,2 @@\n-  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info);\n-  ciKlass* obj = (ciKlass*) ciObjArrayKlass::make(x->klass());\n+  ciKlass* obj = (ciKlass*) x->exact_type();\n+  CodeStub* slow_path = new NewObjectArrayStub(klass_reg, len, reg, info, x->is_null_free());\n@@ -1206,0 +1235,1 @@\n+\n@@ -1207,1 +1237,5 @@\n-  __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  if (x->is_null_free()) {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_INLINE_TYPE, klass_reg, slow_path);\n+  } else {\n+    __ allocate_array(reg, len, tmp1, tmp2, tmp3, tmp4, T_OBJECT, klass_reg, slow_path);\n+  }\n@@ -1283,0 +1317,3 @@\n+  if (x->is_null_free()) {\n+    __ null_check(obj.result(), new CodeEmitInfo(info_for_exception));\n+  }\n@@ -1301,0 +1338,2 @@\n+\n+\n@@ -1304,1 +1343,2 @@\n-               x->profiled_method(), x->profiled_bci());\n+               x->profiled_method(), x->profiled_bci(), x->is_null_free());\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRGenerator_aarch64.cpp","additions":46,"deletions":6,"binary":false,"changes":52,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -438,0 +439,5 @@\n+\n+  if (state == atos && InlineTypeReturnedAsFields) {\n+    __ store_inline_type_fields_to_buf(NULL, true);\n+  }\n+\n@@ -556,0 +562,1 @@\n+  case T_INLINE_TYPE: \/\/ fall through (value types are handled with oops)\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":7,"deletions":0,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -275,0 +275,1 @@\n+  oop obj_buffer_allocate(Klass* klass, int size, TRAPS); \/\/ doesn't clear memory\n","filename":"src\/hotspot\/share\/gc\/shared\/collectedHeap.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -147,1 +147,1 @@\n-    static bool oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,\n+    static void oop_arraycopy_in_heap(arrayOop src_obj, size_t src_offset_in_bytes, T* src_raw,\n","filename":"src\/hotspot\/share\/gc\/shenandoah\/shenandoahBarrierSet.hpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -972,0 +972,1 @@\n+         byte == Bytecodes::_withfield ||\n@@ -976,1 +977,2 @@\n-  bool is_put    = (byte == Bytecodes::_putfield  || byte == Bytecodes::_putstatic || byte == Bytecodes::_nofast_putfield);\n+  bool is_put    = (byte == Bytecodes::_putfield  || byte == Bytecodes::_putstatic ||\n+                    byte == Bytecodes::_nofast_putfield || byte == Bytecodes::_withfield);\n@@ -1014,0 +1016,2 @@\n+    \/\/ (3) by withfield when field is in a value type and the\n+    \/\/     selected class and current class are nest mates.\n@@ -1017,0 +1021,9 @@\n+      \/\/ If byte code is a withfield check if they are nestmates.\n+      bool are_nestmates = false;\n+      if (sel_klass->is_instance_klass() &&\n+          InstanceKlass::cast(sel_klass)->is_inline_klass() &&\n+          current_klass->is_instance_klass()) {\n+        are_nestmates = InstanceKlass::cast(link_info.current_klass())->has_nestmate_access_to(\n+                                                        InstanceKlass::cast(sel_klass), THREAD);\n+      }\n+      if (!are_nestmates) {\n@@ -1021,1 +1034,1 @@\n-                current_klass->external_name());\n+                  current_klass->external_name());\n@@ -1024,0 +1037,1 @@\n+      }\n@@ -1030,1 +1044,1 @@\n-                                                   !m->is_static_initializer());\n+                                                   !m->is_class_initializer());\n@@ -1033,1 +1047,1 @@\n-                                                     !m->is_object_initializer());\n+                                                     !m->is_object_constructor());\n@@ -1152,0 +1166,2 @@\n+  \/\/ Since this method is never inherited from a super, any appearance here under\n+  \/\/ the wrong class would be an error.\n@@ -1225,1 +1241,1 @@\n-      \/\/ check if the method is not <init>\n+      \/\/ check if the method is not <init>, which is never inherited\n@@ -1645,2 +1661,2 @@\n-                             const methodHandle& attached_method,\n-                             Bytecodes::Code byte, TRAPS) {\n+                                  const methodHandle& attached_method,\n+                                  Bytecodes::Code byte, bool check_null_and_abstract, TRAPS) {\n@@ -1651,0 +1667,1 @@\n+  Klass* recv_klass = recv.is_null() ? defc : recv->klass();\n@@ -1653,2 +1670,2 @@\n-      resolve_virtual_call(result, recv, recv->klass(), link_info,\n-                           \/*check_null_and_abstract=*\/true, CHECK);\n+      resolve_virtual_call(result, recv, recv_klass, link_info,\n+                           check_null_and_abstract, CHECK);\n@@ -1657,2 +1674,2 @@\n-      resolve_interface_call(result, recv, recv->klass(), link_info,\n-                             \/*check_null_and_abstract=*\/true, CHECK);\n+      resolve_interface_call(result, recv, recv_klass, link_info,\n+                             check_null_and_abstract, CHECK);\n","filename":"src\/hotspot\/share\/interpreter\/linkResolver.cpp","additions":28,"deletions":11,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -367,1 +367,1 @@\n-    align_up(SharedRuntime::trampoline_size(), BytesPerWord) +\n+    align_up(SharedRuntime::trampoline_size(), BytesPerWord) * 3 +\n@@ -396,0 +396,2 @@\n+\n+      \/\/ TODO:CDS - JDK-8234693 will consolidate this with Method::unlink()\n@@ -401,0 +403,10 @@\n+      address c2i_inline_ro_entry_trampoline = (address)p;\n+      p += SharedRuntime::trampoline_size();\n+      assert(p >= mc_space->base() && p <= mc_space->top(), \"must be\");\n+      m->set_from_compiled_inline_ro_entry(to_target(c2i_inline_ro_entry_trampoline));\n+\n+      address c2i_inline_entry_trampoline = (address)p;\n+      p +=  SharedRuntime::trampoline_size();\n+      assert(p >= mc_space->base() && p <= mc_space->top(), \"must be\");\n+      m->set_from_compiled_inline_entry(to_target(c2i_inline_entry_trampoline));\n+\n","filename":"src\/hotspot\/share\/memory\/dynamicArchive.cpp","additions":13,"deletions":1,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"oops\/inlineKlass.inline.hpp\"\n@@ -40,0 +41,1 @@\n+#include \"runtime\/fieldDescriptor.inline.hpp\"\n@@ -518,0 +520,132 @@\n+\n+class FindClassByNameClosure : public KlassInfoClosure {\n+ private:\n+  GrowableArray<Klass*>* _klasses;\n+  Symbol* _classname;\n+ public:\n+  FindClassByNameClosure(GrowableArray<Klass*>* klasses, Symbol* classname) :\n+    _klasses(klasses), _classname(classname) { }\n+\n+  void do_cinfo(KlassInfoEntry* cie) {\n+    if (cie->klass()->name() == _classname) {\n+      _klasses->append(cie->klass());\n+    }\n+  }\n+};\n+\n+class FieldDesc {\n+private:\n+  Symbol* _name;\n+  Symbol* _signature;\n+  int _offset;\n+  int _index;\n+  InstanceKlass* _holder;\n+  AccessFlags _access_flags;\n+ public:\n+  FieldDesc() {\n+    _name = NULL;\n+    _signature = NULL;\n+    _offset = -1;\n+    _index = -1;\n+    _holder = NULL;\n+    _access_flags = AccessFlags();\n+  }\n+  FieldDesc(fieldDescriptor& fd) {\n+    _name = fd.name();\n+    _signature = fd.signature();\n+    _offset = fd.offset();\n+    _index = fd.index();\n+    _holder = fd.field_holder();\n+    _access_flags = fd.access_flags();\n+  }\n+  const Symbol* name() { return _name;}\n+  const Symbol* signature() { return _signature; }\n+  const int offset() { return _offset; }\n+  const int index() { return _index; }\n+  const InstanceKlass* holder() { return _holder; }\n+  const AccessFlags& access_flags() { return _access_flags; }\n+  const bool is_inline_type() { return Signature::basic_type(_signature) == T_INLINE_TYPE; }\n+};\n+\n+static int compare_offset(FieldDesc* f1, FieldDesc* f2) {\n+   return f1->offset() > f2->offset() ? 1 : -1;\n+}\n+\n+static void print_field(outputStream* st, int level, int offset, FieldDesc& fd, bool is_inline_type, bool is_inlined ) {\n+  const char* inlined_msg = \"\";\n+  if (is_inline_type) {\n+    inlined_msg = is_inlined ? \"inlined\" : \"not inlined\";\n+  }\n+  st->print_cr(\"  @ %d %*s \\\"%s\\\" %s %s %s\",\n+      offset, level * 3, \"\",\n+      fd.name()->as_C_string(),\n+      fd.signature()->as_C_string(),\n+      is_inline_type ? \" \/\/ inline type \" : \"\",\n+      inlined_msg);\n+}\n+\n+static void print_inlined_field(outputStream* st, int level, int offset, InstanceKlass* klass) {\n+  assert(klass->is_inline_klass(), \"Only inline types can be inlined\");\n+  InlineKlass* vklass = InlineKlass::cast(klass);\n+  GrowableArray<FieldDesc>* fields = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<FieldDesc>(100, mtServiceability);\n+  for (FieldStream fd(klass, false, false); !fd.eos(); fd.next()) {\n+    if (!fd.access_flags().is_static()) {\n+      fields->append(FieldDesc(fd.field_descriptor()));\n+    }\n+  }\n+  fields->sort(compare_offset);\n+  for(int i = 0; i < fields->length(); i++) {\n+    FieldDesc fd = fields->at(i);\n+    int offset2 = offset + fd.offset() - vklass->first_field_offset();\n+    print_field(st, level, offset2, fd,\n+        fd.is_inline_type(), fd.holder()->field_is_inlined(fd.index()));\n+    if (fd.holder()->field_is_inlined(fd.index())) {\n+      print_inlined_field(st, level + 1, offset2 ,\n+          InstanceKlass::cast(fd.holder()->get_inline_type_field_klass(fd.index())));\n+    }\n+  }\n+}\n+\n+void PrintClassLayout::print_class_layout(outputStream* st, char* class_name) {\n+  KlassInfoTable cit(true);\n+  if (cit.allocation_failed()) {\n+    st->print_cr(\"ERROR: Ran out of C-heap; hierarchy not generated\");\n+    return;\n+  }\n+\n+  Thread* THREAD = Thread::current();\n+\n+  Symbol* classname = SymbolTable::probe(class_name, (int)strlen(class_name));\n+\n+  GrowableArray<Klass*>* klasses = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<Klass*>(100, mtServiceability);\n+\n+  FindClassByNameClosure fbnc(klasses, classname);\n+  cit.iterate(&fbnc);\n+\n+  for(int i = 0; i < klasses->length(); i++) {\n+    Klass* klass = klasses->at(i);\n+    if (!klass->is_instance_klass()) continue;  \/\/ Skip\n+    InstanceKlass* ik = InstanceKlass::cast(klass);\n+    int tab = 1;\n+    st->print_cr(\"Class %s [@%s]:\", klass->name()->as_C_string(),\n+        klass->class_loader_data()->name()->as_C_string());\n+    ResourceMark rm;\n+    GrowableArray<FieldDesc>* fields = new (ResourceObj::C_HEAP, mtServiceability) GrowableArray<FieldDesc>(100, mtServiceability);\n+    for (FieldStream fd(ik, false, false); !fd.eos(); fd.next()) {\n+      if (!fd.access_flags().is_static()) {\n+        fields->append(FieldDesc(fd.field_descriptor()));\n+      }\n+    }\n+    fields->sort(compare_offset);\n+    for(int i = 0; i < fields->length(); i++) {\n+      FieldDesc fd = fields->at(i);\n+      print_field(st, 0, fd.offset(), fd, fd.is_inline_type(), fd.holder()->field_is_inlined(fd.index()));\n+      if (fd.holder()->field_is_inlined(fd.index())) {\n+        print_inlined_field(st, 1, fd.offset(),\n+            InstanceKlass::cast(fd.holder()->get_inline_type_field_klass(fd.index())));\n+      }\n+    }\n+  }\n+  st->cr();\n+}\n+\n","filename":"src\/hotspot\/share\/memory\/heapInspection.cpp","additions":134,"deletions":0,"binary":false,"changes":134,"status":"modified"},{"patch":"@@ -210,0 +210,5 @@\n+class PrintClassLayout : AllStatic {\n+ public:\n+  static void print_class_layout(outputStream* st, char* classname);\n+};\n+\n","filename":"src\/hotspot\/share\/memory\/heapInspection.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -79,1 +79,5 @@\n-    _method_entry_ref\n+    \/\/ A field that points to a method entry. E.g., Method::_i2i_entry\n+    _method_entry_ref,\n+\n+    \/\/ A field that points to a location inside the current object.\n+    _internal_pointer_ref,\n@@ -316,1 +320,9 @@\n-    push_special(_method_entry_ref, ref, (intptr_t*)p);\n+    push_special(_method_entry_ref, ref, p);\n+    if (!ref->keep_after_pushing()) {\n+      delete ref;\n+    }\n+  }\n+\n+  template <class T> void push_internal_pointer(T** mpp, intptr_t* p) {\n+    Ref* ref = new ObjectRef<T>(mpp, _default);\n+    push_special(_internal_pointer_ref, ref, p);\n@@ -325,1 +337,5 @@\n-    assert(type == _method_entry_ref, \"only special type allowed for now\");\n+    assert_valid(type);\n+  }\n+\n+  static void assert_valid(SpecialRef type) {\n+    assert(type == _method_entry_ref || type == _internal_pointer_ref, \"only special types allowed for now\");\n","filename":"src\/hotspot\/share\/memory\/metaspaceClosure.hpp","additions":19,"deletions":3,"binary":false,"changes":22,"status":"modified"},{"patch":"@@ -52,0 +52,2 @@\n+#include \"oops\/flatArrayKlass.hpp\"\n+#include \"oops\/inlineKlass.hpp\"\n@@ -711,1 +713,1 @@\n-  f(InstanceKlass) \\\n+  f(InstanceKlass) \\\n@@ -717,1 +719,3 @@\n-  f(TypeArrayKlass)\n+  f(TypeArrayKlass) \\\n+  f(FlatArrayKlass) \\\n+  f(InlineKlass)\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":6,"deletions":2,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -118,0 +118,2 @@\n+LatestMethodCache* Universe::_is_substitutable_cache  = NULL;\n+LatestMethodCache* Universe::_inline_type_hash_code_cache = NULL;\n@@ -126,0 +128,1 @@\n+Array<InstanceKlass*>* Universe::_the_single_IdentityObject_klass_array = NULL;\n@@ -228,0 +231,1 @@\n+  it->push(&_the_single_IdentityObject_klass_array);\n@@ -234,0 +238,2 @@\n+  _is_substitutable_cache->metaspace_pointers_do(it);\n+  _inline_type_hash_code_cache->metaspace_pointers_do(it);\n@@ -272,0 +278,1 @@\n+  f->do_ptr((void**)&_the_single_IdentityObject_klass_array);\n@@ -277,0 +284,2 @@\n+  _is_substitutable_cache->serialize(f);\n+  _inline_type_hash_code_cache->serialize(f);\n@@ -326,1 +335,1 @@\n-        _the_array_interfaces_array     = MetadataFactory::new_array<Klass*>(null_cld, 2, NULL, CHECK);\n+        _the_array_interfaces_array     = MetadataFactory::new_array<Klass*>(null_cld, 3, NULL, CHECK);\n@@ -353,0 +362,5 @@\n+      assert(_the_array_interfaces_array->at(2) ==\n+                   SystemDictionary::IdentityObject_klass(), \"u3\");\n+\n+      assert(_the_single_IdentityObject_klass_array->at(0) ==\n+          SystemDictionary::IdentityObject_klass(), \"u3\");\n@@ -359,0 +373,1 @@\n+      _the_array_interfaces_array->at_put(2, SystemDictionary::IdentityObject_klass());\n@@ -463,0 +478,8 @@\n+void Universe::initialize_the_single_IdentityObject_klass_array(InstanceKlass* ik, TRAPS) {\n+    assert(_the_single_IdentityObject_klass_array == NULL, \"Must not be initialized twice\");\n+    assert(ik->name() == vmSymbols::java_lang_IdentityObject(), \"Must be\");\n+    Array<InstanceKlass*>* array = MetadataFactory::new_array<InstanceKlass*>(ik->class_loader_data(), 1, NULL, CHECK);\n+    array->at_put(0, ik);\n+    _the_single_IdentityObject_klass_array = array;\n+  }\n+\n@@ -751,1 +774,0 @@\n-\n@@ -774,0 +796,2 @@\n+  Universe::_is_substitutable_cache = new LatestMethodCache();\n+  Universe::_inline_type_hash_code_cache = new LatestMethodCache();\n@@ -942,0 +966,11 @@\n+\n+  \/\/ Set up substitutability testing\n+  ResourceMark rm;\n+  initialize_known_method(_is_substitutable_cache,\n+                          SystemDictionary::ValueBootstrapMethods_klass(),\n+                          vmSymbols::isSubstitutable_name()->as_C_string(),\n+                          vmSymbols::object_object_boolean_signature(), true, CHECK);\n+  initialize_known_method(_inline_type_hash_code_cache,\n+                          SystemDictionary::ValueBootstrapMethods_klass(),\n+                          vmSymbols::inlineObjectHashCode_name()->as_C_string(),\n+                          vmSymbols::object_int_signature(), true, CHECK);\n","filename":"src\/hotspot\/share\/memory\/universe.cpp","additions":37,"deletions":2,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -140,1 +140,1 @@\n-    if (!is_static)\n+    if (!is_static) {\n@@ -142,0 +142,1 @@\n+    }\n@@ -838,1 +839,1 @@\n-  assert(cts.is_reference() || cts.is_value() || cts.is_address(),\n+  assert(cts.is_reference() || cts.is_inline_type() || cts.is_address(),\n@@ -1379,0 +1380,3 @@\n+    case Bytecodes::_defaultvalue:      ppush1(CellTypeState::make_line_ref(itr->bci())); break;\n+    case Bytecodes::_withfield:         do_withfield(itr->get_index_u2_cpcache(), itr->bci()); break;\n+\n@@ -1592,2 +1596,2 @@\n-    case Bytecodes::_getstatic:         do_field(true,  true,  itr->get_index_u2_cpcache(), itr->bci()); break;\n-    case Bytecodes::_putstatic:         do_field(false, true,  itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_getstatic:         do_field(true,  true, itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_putstatic:         do_field(false, true, itr->get_index_u2_cpcache(), itr->bci()); break;\n@@ -1597,0 +1601,1 @@\n+    case Bytecodes::_invokeinterface:\n@@ -1598,4 +1603,3 @@\n-    case Bytecodes::_invokespecial:     do_method(false, false, itr->get_index_u2_cpcache(), itr->bci()); break;\n-    case Bytecodes::_invokestatic:      do_method(true,  false, itr->get_index_u2_cpcache(), itr->bci()); break;\n-    case Bytecodes::_invokedynamic:     do_method(true,  false, itr->get_index_u4(),         itr->bci()); break;\n-    case Bytecodes::_invokeinterface:   do_method(false, true,  itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_invokespecial:     do_method(false, itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_invokestatic:      do_method(true , itr->get_index_u2_cpcache(), itr->bci()); break;\n+    case Bytecodes::_invokedynamic:     do_method(true , itr->get_index_u4(),         itr->bci()); break;\n@@ -1621,0 +1625,1 @@\n+\n@@ -1727,1 +1732,1 @@\n-  assert(in.is_reference() | in.is_value(), \"sanity check\");\n+  assert(in.is_reference() || in.is_inline_type(), \"sanity check\");\n@@ -1946,1 +1951,3 @@\n-  if (!is_static) in[i++] = CellTypeState::ref;\n+  if (!is_static) {\n+    in[i++] = CellTypeState::ref;\n+  }\n@@ -1952,1 +1959,1 @@\n-void GenerateOopMap::do_method(int is_static, int is_interface, int idx, int bci) {\n+void GenerateOopMap::do_method(int is_static, int idx, int bci) {\n@@ -1989,0 +1996,27 @@\n+void GenerateOopMap::do_withfield(int idx, int bci) {\n+  \/\/ Dig up signature for field in constant pool\n+  ConstantPool* cp = method()->constants();\n+  int nameAndTypeIdx = cp->name_and_type_ref_index_at(idx);\n+  int signatureIdx = cp->signature_ref_index_at(nameAndTypeIdx);\n+  Symbol* signature = cp->symbol_at(signatureIdx);\n+\n+  \/\/ Parse signature (especially simple for fields)\n+  assert(signature->utf8_length() > 0,\n+      \"field signatures cannot have zero length\");\n+  \/\/ The signature is UFT8 encoded, but the first char is always ASCII for signatures.\n+  CellTypeState temp[4];\n+  CellTypeState *eff = signature_to_effect(signature, bci, temp);\n+\n+  CellTypeState in[4];\n+  int i = copy_cts(in, eff);\n+  in[i++] = CellTypeState::ref;\n+  in[i] = CellTypeState::bottom;\n+  assert(i <= 3, \"sanity check\");\n+\n+  CellTypeState out[2];\n+  out[0] = CellTypeState::ref;\n+  out[1] = CellTypeState::bottom;\n+\n+  pp(in, out);\n+}\n+\n","filename":"src\/hotspot\/share\/oops\/generateOopMap.cpp","additions":45,"deletions":11,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -94,1 +94,1 @@\n-  enum { info_mask            = right_n_bits(28),\n+  enum { info_mask            = right_n_bits(27),\n@@ -107,3 +107,3 @@\n-  enum { top_info_bit         = nth_bit(27),\n-         not_bottom_info_bit  = nth_bit(26),\n-         info_data_mask       = right_n_bits(26),\n+  enum { top_info_bit         = nth_bit(26),\n+         not_bottom_info_bit  = nth_bit(25),\n+         info_data_mask       = right_n_bits(25),\n@@ -114,2 +114,2 @@\n-  enum { ref_not_lock_bit     = nth_bit(25),  \/\/ 0 if this reference is locked as a monitor\n-         ref_slot_bit         = nth_bit(24),  \/\/ 1 if this reference is a \"slot\" reference,\n+  enum { ref_not_lock_bit     = nth_bit(24),  \/\/ 0 if this reference is locked as a monitor\n+         ref_slot_bit         = nth_bit(23),  \/\/ 1 if this reference is a \"slot\" reference,\n@@ -117,1 +117,1 @@\n-         ref_data_mask        = right_n_bits(24) };\n+         ref_data_mask        = right_n_bits(23) };\n@@ -119,0 +119,5 @@\n+  \/\/ Within the INFO data, these values are used to distinguish different\n+  \/\/ kinds of value types.\n+  enum { valuetype_slot_bit   = nth_bit(24),  \/\/ 1 if this reference is a \"slot\" value type,\n+    \/\/ 0 if it is a \"line\" value type.\n+    valuetype_data_mask  = right_n_bits(24) };\n@@ -199,1 +204,1 @@\n-  bool is_value() const                 { return ((_state & bits_mask) == val_bit); }\n+  bool is_inline_type() const           { return ((_state & bits_mask) == val_bit); }\n@@ -400,1 +405,2 @@\n-  void  do_method                           (int is_static, int is_interface, int idx, int bci);\n+  void  do_method                           (int is_static, int idx, int bci);\n+  void  do_withfield                       (int idx, int bci);\n","filename":"src\/hotspot\/share\/oops\/generateOopMap.hpp","additions":15,"deletions":9,"binary":false,"changes":24,"status":"modified"},{"patch":"@@ -1123,3 +1123,4 @@\n-  if (m->is_static())           return false;   \/\/ e.g., Stream.empty\n-  if (m->is_initializer())      return false;   \/\/ <init> or <clinit>\n-  if (m->is_private())          return false;   \/\/ uses direct call\n+  if (m->is_static())             return false;   \/\/ e.g., Stream.empty\n+  if (m->is_private())            return false;   \/\/ uses direct call\n+  if (m->is_object_constructor()) return false;   \/\/ <init>(...)V\n+  if (m->is_class_initializer())  return false;   \/\/ <clinit>()V\n@@ -1358,0 +1359,12 @@\n+int count_interface_methods_needing_itable_index(Array<Method*>* methods) {\n+  int method_count = 0;\n+  if (methods->length() > 0) {\n+    for (int i = methods->length(); --i >= 0; ) {\n+      if (interface_method_needs_itable_index(methods->at(i))) {\n+        method_count++;\n+      }\n+    }\n+  }\n+  return method_count;\n+}\n+\n@@ -1426,1 +1439,1 @@\n-  \/\/ There's alway an extra itable entry so we can null-terminate it.\n+  \/\/ There's always an extra itable entry so we can null-terminate it.\n","filename":"src\/hotspot\/share\/oops\/klassVtable.cpp","additions":17,"deletions":4,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -289,1 +289,4 @@\n-  int size_offset_table()                { return _size_offset_table; }\n+  InstanceKlass* klass() const          { return _klass; }\n+  int table_offset() const              { return _table_offset; }\n+  int size_offset_table() const         { return _size_offset_table; }\n+  int size_method_table() const         { return _size_method_table; }\n","filename":"src\/hotspot\/share\/oops\/klassVtable.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -41,0 +41,1 @@\n+\/\/             \"1\"        :23 epoch:2 age:4    biased_lock:1 lock:2 (biased always locked object)\n@@ -46,0 +47,1 @@\n+\/\/  \"1\"        :54 epoch:2 unused:1   age:4    biased_lock:1 lock:2 (biased always locked object)\n@@ -90,0 +92,12 @@\n+\/\/    Always locked: since displaced and monitor references require memory at a\n+\/\/    fixed address, and hash code can be displaced, an efficiently providing a\n+\/\/    *permanent lock* leaves us with specializing the biased pattern (even when\n+\/\/    biased locking isn't enabled). Since biased_lock_alignment for the thread\n+\/\/    reference doesn't use the lowest bit (\"2 << thread_shift\"), we can use\n+\/\/    this illegal thread pointer alignment to denote \"always locked\" pattern.\n+\/\/\n+\/\/    [ <unused> | larval |1| epoch | age | 1 | 01]       permanently locked\n+\/\/\n+\/\/    A private buffered value is always locked and can be in a larval state.\n+\/\/\n+\/\/\n@@ -135,0 +149,3 @@\n+  static const int always_locked_bits             = 1;\n+  static const int larval_bits                    = 1;\n+\n@@ -144,0 +161,2 @@\n+  static const int thread_shift                   = epoch_shift + epoch_bits;\n+  static const int larval_shift                   = thread_shift + always_locked_bits;\n@@ -154,0 +173,2 @@\n+  static const uintptr_t larval_mask              = right_n_bits(larval_bits);\n+  static const uintptr_t larval_mask_in_place     = larval_mask << larval_shift;\n@@ -159,1 +180,1 @@\n-  static const size_t biased_lock_alignment       = 2 << (epoch_shift + epoch_bits);\n+  static const size_t biased_lock_alignment       = 2 << thread_shift;\n@@ -166,0 +187,1 @@\n+  static const uintptr_t always_locked_pattern    = 1 << thread_shift | biased_lock_pattern;\n@@ -178,0 +200,8 @@\n+  enum { larval_state_pattern     = (1 << larval_shift) };\n+\n+  static markWord always_locked_prototype() {\n+    return markWord(always_locked_pattern);\n+  }\n+\n+  bool is_always_locked() const { return mask_bits(value(), always_locked_pattern) == always_locked_pattern; }\n+\n@@ -189,0 +219,1 @@\n+    assert(!is_always_locked(), \"invariant\");\n@@ -206,0 +237,1 @@\n+    assert(!is_always_locked(), \"Rebias needs to fail\");\n@@ -348,0 +380,11 @@\n+  \/\/ private buffered value operations\n+  markWord enter_larval_state() const {\n+    return markWord((value() & ~larval_mask_in_place) | larval_state_pattern);\n+  }\n+  markWord exit_larval_state() const {\n+    return markWord(value() & ~larval_mask_in_place);\n+  }\n+  bool is_larval_state() const {\n+    return (value() & larval_mask_in_place) == larval_state_pattern;\n+  }\n+\n@@ -363,1 +406,1 @@\n-  inline void* decode_pointer() { if (UseBiasedLocking && has_bias_pattern()) return NULL; return (void*)clear_lock_bits().value(); }\n+  inline void* decode_pointer() { if (has_bias_pattern()) return NULL; return (void*)clear_lock_bits().value(); }\n","filename":"src\/hotspot\/share\/oops\/markWord.hpp","additions":45,"deletions":2,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -179,0 +179,46 @@\n+\/\/ Array of RegMask, one per returned values (inline type instances can\n+\/\/ be returned as multiple return values, one per field)\n+RegMask* Matcher::return_values_mask(const TypeTuple *range) {\n+  uint cnt = range->cnt() - TypeFunc::Parms;\n+  if (cnt == 0) {\n+    return NULL;\n+  }\n+  RegMask* mask = NEW_RESOURCE_ARRAY(RegMask, cnt);\n+\n+  if (!InlineTypeReturnedAsFields) {\n+    \/\/ Get ideal-register return type\n+    uint ireg = range->field_at(TypeFunc::Parms)->ideal_reg();\n+    \/\/ Get machine return register\n+    OptoRegPair regs = return_value(ireg, false);\n+\n+    \/\/ And mask for same\n+    mask[0].Clear();\n+    mask[0].Insert(regs.first());\n+    if (OptoReg::is_valid(regs.second())) {\n+      mask[0].Insert(regs.second());\n+    }\n+  } else {\n+    BasicType* sig_bt = NEW_RESOURCE_ARRAY(BasicType, cnt);\n+    VMRegPair* vm_parm_regs = NEW_RESOURCE_ARRAY(VMRegPair, cnt);\n+\n+    for (uint i = 0; i < cnt; i++) {\n+      sig_bt[i] = range->field_at(i+TypeFunc::Parms)->basic_type();\n+    }\n+\n+    int regs = SharedRuntime::java_return_convention(sig_bt, vm_parm_regs, cnt);\n+    assert(regs > 0, \"should have been tested during graph construction\");\n+    for (uint i = 0; i < cnt; i++) {\n+      mask[i].Clear();\n+\n+      OptoReg::Name reg1 = OptoReg::as_OptoReg(vm_parm_regs[i].first());\n+      if (OptoReg::is_valid(reg1)) {\n+        mask[i].Insert(reg1);\n+      }\n+      OptoReg::Name reg2 = OptoReg::as_OptoReg(vm_parm_regs[i].second());\n+      if (OptoReg::is_valid(reg2)) {\n+        mask[i].Insert(reg2);\n+      }\n+    }\n+  }\n+  return mask;\n+}\n@@ -194,15 +240,4 @@\n-  \/\/ Map a Java-signature return type into return register-value\n-  \/\/ machine registers for 0, 1 and 2 returned values.\n-  const TypeTuple *range = C->tf()->range();\n-  if( range->cnt() > TypeFunc::Parms ) { \/\/ If not a void function\n-    \/\/ Get ideal-register return type\n-    uint ireg = range->field_at(TypeFunc::Parms)->ideal_reg();\n-    \/\/ Get machine return register\n-    uint sop = C->start()->Opcode();\n-    OptoRegPair regs = return_value(ireg, false);\n-\n-    \/\/ And mask for same\n-    _return_value_mask = RegMask(regs.first());\n-    if( OptoReg::is_valid(regs.second()) )\n-      _return_value_mask.Insert(regs.second());\n-  }\n+  \/\/ Map Java-signature return types into return register-value\n+  \/\/ machine registers.\n+  const TypeTuple *range = C->tf()->range_cc();\n+  _return_values_mask = return_values_mask(range);\n@@ -216,1 +251,1 @@\n-  const TypeTuple *domain = C->tf()->domain();\n+  const TypeTuple *domain = C->tf()->domain_cc();\n@@ -482,0 +517,19 @@\n+\n+  \/\/ Check if the method has a reserved entry in the argument stack area that\n+  \/\/ should not be used for spilling because it may hold the return address.\n+  if (!C->is_osr_compilation() && C->method() != NULL && C->method()->has_scalarized_args()) {\n+    ExtendedSignature sig_cc = ExtendedSignature(C->method()->get_sig_cc(), SigEntryFilter());\n+    for (int off = 0; !sig_cc.at_end(); ) {\n+      BasicType bt = (*sig_cc)._bt;\n+      off += type2size[bt];\n+      while (SigEntry::next_is_reserved(sig_cc, bt)) {\n+        \/\/ Remove reserved stack slot from mask to avoid spilling\n+        OptoRegPair reg = _parm_regs[off];\n+        assert(OptoReg::is_valid(reg.first()), \"invalid reserved register\");\n+        C->FIRST_STACK_mask().Remove(reg.first());\n+        C->FIRST_STACK_mask().Remove(reg.first()+1); \/\/ Always occupies two stack slots\n+        off += type2size[bt];\n+      }\n+    }\n+  }\n+\n@@ -659,1 +713,1 @@\n-  uint ret_edge_cnt = TypeFunc::Parms + ((C->tf()->range()->cnt() == TypeFunc::Parms) ? 0 : 1);\n+  uint ret_edge_cnt = C->tf()->range_cc()->cnt();\n@@ -661,4 +715,3 @@\n-  \/\/ Returns have 0 or 1 returned values depending on call signature.\n-  \/\/ Return register is specified by return_value in the AD file.\n-  if (ret_edge_cnt > TypeFunc::Parms)\n-    ret_rms[TypeFunc::Parms+0] = _return_value_mask;\n+  for (i = TypeFunc::Parms; i < ret_edge_cnt; i++) {\n+    ret_rms[i] = _return_values_mask[i-TypeFunc::Parms];\n+  }\n@@ -731,1 +784,1 @@\n-  int proj_cnt = C->tf()->domain()->cnt();\n+  int proj_cnt = C->tf()->domain_cc()->cnt();\n@@ -1001,1 +1054,5 @@\n-              m = n->in(0)->as_Multi()->match( n->as_Proj(), this );\n+              RegMask* mask = NULL;\n+              if (n->in(0)->is_Call()) {\n+                mask = return_values_mask(n->in(0)->as_Call()->tf()->range_cc());\n+              }\n+              m = n->in(0)->as_Multi()->match(n->as_Proj(), this, mask);\n@@ -1146,1 +1203,1 @@\n-    domain = call->tf()->domain();\n+    domain = call->tf()->domain_cc();\n@@ -1221,1 +1278,4 @@\n-  int argcnt = cnt - TypeFunc::Parms;\n+  \/\/ Null entry point is a special cast where the target of the call\n+  \/\/ is in a register.\n+  int adj = (call != NULL && call->entry_point() == NULL) ? 1 : 0;\n+  int argcnt = cnt - TypeFunc::Parms - adj;\n@@ -1227,1 +1287,1 @@\n-      sig_bt[i] = domain->field_at(i+TypeFunc::Parms)->basic_type();\n+      sig_bt[i] = domain->field_at(i+TypeFunc::Parms+adj)->basic_type();\n@@ -1268,1 +1328,1 @@\n-      RegMask *rm = &mcall->_in_rms[i+TypeFunc::Parms];\n+      RegMask *rm = &mcall->_in_rms[i+TypeFunc::Parms+adj];\n@@ -1275,1 +1335,1 @@\n-      if (OptoReg::is_valid(reg1))\n+      if (OptoReg::is_valid(reg1)) {\n@@ -1277,0 +1337,1 @@\n+      }\n@@ -1279,1 +1340,1 @@\n-      if (OptoReg::is_valid(reg2))\n+      if (OptoReg::is_valid(reg2)) {\n@@ -1281,0 +1342,1 @@\n+      }\n@@ -1300,1 +1362,1 @@\n-    uint r_cnt = mcall->tf()->range()->cnt();\n+    uint r_cnt = mcall->tf()->range_sig()->cnt();\n@@ -1321,1 +1383,1 @@\n-         (mcall->jvms()->debug_start() + mcall->_jvmadj == mcall->tf()->domain()->cnt()), \"\");\n+         (mcall->jvms()->debug_start() + mcall->_jvmadj == mcall->tf()->domain_cc()->cnt()), \"\");\n@@ -2285,0 +2347,7 @@\n+    case Op_ClearArray: {\n+      Node* pair = new BinaryNode(n->in(2), n->in(3));\n+      n->set_req(2, pair);\n+      n->set_req(3, n->in(4));\n+      n->del_req(4);\n+      break;\n+    }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":100,"deletions":31,"binary":false,"changes":131,"status":"modified"},{"patch":"@@ -262,0 +262,2 @@\n+  RegMask* return_values_mask(const TypeTuple *range);\n+\n@@ -386,1 +388,1 @@\n-  RegMask                     _return_value_mask;\n+  RegMask*             _return_values_mask;\n","filename":"src\/hotspot\/share\/opto\/matcher.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -26,0 +26,1 @@\n+#include \"ci\/ciFlatArrayKlass.hpp\"\n@@ -27,0 +28,1 @@\n+#include \"classfile\/systemDictionary.hpp\"\n@@ -39,0 +41,1 @@\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -240,1 +243,1 @@\n-               tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n+        tp->isa_aryptr() &&        tp->offset() == Type::OffsetBot &&\n@@ -857,0 +860,1 @@\n+  case T_INLINE_TYPE:\n@@ -984,1 +988,1 @@\n-      BasicType ary_elem  = ary_t->klass()->as_array_klass()->element_type()->basic_type();\n+      BasicType ary_elem = ary_t->klass()->as_array_klass()->element_type()->basic_type();\n@@ -987,0 +991,4 @@\n+      if (ary_t->klass()->is_flat_array_klass()) {\n+        ciFlatArrayKlass* vak = ary_t->klass()->as_flat_array_klass();\n+        shift = vak->log2_element_size();\n+      }\n@@ -1114,0 +1122,6 @@\n+      assert(memory_type() != T_INLINE_TYPE, \"should not be used for inline types\");\n+      Node* default_value = ld_alloc->in(AllocateNode::DefaultValue);\n+      if (default_value != NULL) {\n+        return default_value;\n+      }\n+      assert(ld_alloc->in(AllocateNode::RawDefaultValue) == NULL, \"default value may not be null\");\n@@ -1176,0 +1190,27 @@\n+  \/\/ Loading from an InlineTypePtr? The InlineTypePtr has the values of\n+  \/\/ all fields as input. Look for the field with matching offset.\n+  Node* addr = in(Address);\n+  intptr_t offset;\n+  Node* base = AddPNode::Ideal_base_and_offset(addr, phase, offset);\n+  if (base != NULL && base->is_InlineTypePtr() && offset > oopDesc::klass_offset_in_bytes()) {\n+    Node* value = base->as_InlineTypePtr()->field_value_by_offset((int)offset, true);\n+    if (value->is_InlineType()) {\n+      \/\/ Non-flattened inline type field\n+      InlineTypeNode* vt = value->as_InlineType();\n+      if (vt->is_allocated(phase)) {\n+        value = vt->get_oop();\n+      } else {\n+        \/\/ Not yet allocated, bail out\n+        value = NULL;\n+      }\n+    }\n+    if (value != NULL) {\n+      if (Opcode() == Op_LoadN) {\n+        \/\/ Encode oop value if we are loading a narrow oop\n+        assert(!phase->type(value)->isa_narrowoop(), \"should already be decoded\");\n+        value = phase->transform(new EncodePNode(value, bottom_type()));\n+      }\n+      return value;\n+    }\n+  }\n+\n@@ -1733,2 +1774,6 @@\n-  AllocateNode* alloc = is_new_object_mark_load(phase);\n-  if (alloc != NULL && alloc->Opcode() == Op_Allocate && UseBiasedLocking) {\n+  AllocateNode* alloc = AllocateNode::Ideal_allocation(address, phase);\n+  if (alloc != NULL && mem->is_Proj() &&\n+      mem->in(0) != NULL &&\n+      mem->in(0) == alloc->initialization() &&\n+      Opcode() == Op_LoadX &&\n+      alloc->initialization()->proj_out_or_null(0) != NULL) {\n@@ -1737,1 +1782,1 @@\n-    return alloc->make_ideal_mark(phase, address, control, mem);\n+    return alloc->make_ideal_mark(phase, control, mem);\n@@ -1829,0 +1874,1 @@\n+        && t->isa_inlinetype() == NULL\n@@ -1863,0 +1909,1 @@\n+            tp->is_oopptr()->klass() == ciEnv::current()->Class_klass() ||\n@@ -1868,1 +1915,3 @@\n-    \/\/ Optimize loads from constant fields.\n+    BasicType bt = memory_type();\n+\n+    \/\/ Optimize loads from constant fields.\n@@ -1872,1 +1921,10 @@\n-      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), memory_type());\n+      ciType* mirror_type = const_oop->as_instance()->java_mirror_type();\n+      if (mirror_type != NULL && mirror_type->is_inlinetype()) {\n+        ciInlineKlass* vk = mirror_type->as_inline_klass();\n+        if (off == vk->default_value_offset()) {\n+          \/\/ Loading a special hidden field that contains the oop of the default inline type\n+          const Type* const_oop = TypeInstPtr::make(vk->default_instance());\n+          return (bt == T_NARROWOOP) ? const_oop->make_narrowoop() : const_oop;\n+        }\n+      }\n+      const Type* con_type = Type::make_constant_from_field(const_oop->as_instance(), off, is_unsigned(), bt);\n@@ -1880,0 +1938,1 @@\n+            tp->is_klassptr()->klass() == NULL ||\n@@ -1886,15 +1945,31 @@\n-  } else if (tp->base() == Type::RawPtr && adr->is_Load() && off == 0) {\n-    \/* With mirrors being an indirect in the Klass*\n-     * the VM is now using two loads. LoadKlass(LoadP(LoadP(Klass, mirror_offset), zero_offset))\n-     * The LoadP from the Klass has a RawPtr type (see LibraryCallKit::load_mirror_from_klass).\n-     *\n-     * So check the type and klass of the node before the LoadP.\n-     *\/\n-    Node* adr2 = adr->in(MemNode::Address);\n-    const TypeKlassPtr* tkls = phase->type(adr2)->isa_klassptr();\n-    if (tkls != NULL && !StressReflectiveCode) {\n-      ciKlass* klass = tkls->klass();\n-      if (klass->is_loaded() && tkls->klass_is_exact() && tkls->offset() == in_bytes(Klass::java_mirror_offset())) {\n-        assert(adr->Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n-        assert(Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n-        return TypeInstPtr::make(klass->java_mirror());\n+  } else if (tp->base() == Type::RawPtr && !StressReflectiveCode) {\n+    if (adr->is_Load() && off == 0) {\n+      \/* With mirrors being an indirect in the Klass*\n+       * the VM is now using two loads. LoadKlass(LoadP(LoadP(Klass, mirror_offset), zero_offset))\n+       * The LoadP from the Klass has a RawPtr type (see LibraryCallKit::load_mirror_from_klass).\n+       *\n+       * So check the type and klass of the node before the LoadP.\n+       *\/\n+      Node* adr2 = adr->in(MemNode::Address);\n+      const TypeKlassPtr* tkls = phase->type(adr2)->isa_klassptr();\n+      if (tkls != NULL) {\n+        ciKlass* klass = tkls->klass();\n+        if (klass != NULL && klass->is_loaded() && tkls->klass_is_exact() && tkls->offset() == in_bytes(Klass::java_mirror_offset())) {\n+          assert(adr->Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n+          assert(Opcode() == Op_LoadP, \"must load an oop from _java_mirror\");\n+          return TypeInstPtr::make(klass->java_mirror());\n+        }\n+      }\n+    } else {\n+      \/\/ Check for a load of the default value offset from the InlineKlassFixedBlock:\n+      \/\/ LoadI(LoadP(inline_klass, adr_inlineklass_fixed_block_offset), default_value_offset_offset)\n+      intptr_t offset = 0;\n+      Node* base = AddPNode::Ideal_base_and_offset(adr, phase, offset);\n+      if (base != NULL && base->is_Load() && offset == in_bytes(InlineKlass::default_value_offset_offset())) {\n+        const TypeKlassPtr* tkls = phase->type(base->in(MemNode::Address))->isa_klassptr();\n+        if (tkls != NULL && tkls->is_loaded() && tkls->klass_is_exact() && tkls->isa_inlinetype() &&\n+            tkls->offset() == in_bytes(InstanceKlass::adr_inlineklass_fixed_block_offset())) {\n+          assert(base->Opcode() == Op_LoadP, \"must load an oop from klass\");\n+          assert(Opcode() == Op_LoadI, \"must load an int from fixed block\");\n+          return TypeInt::make(tkls->klass()->as_inline_klass()->default_value_offset());\n+        }\n@@ -1908,1 +1983,1 @@\n-    if (klass->is_loaded() && tkls->klass_is_exact()) {\n+    if (tkls->is_loaded() && tkls->klass_is_exact()) {\n@@ -1935,1 +2010,1 @@\n-    if (klass->is_loaded() ) {\n+    if (tkls->is_loaded()) {\n@@ -2140,1 +2215,2 @@\n-Node* LoadKlassNode::make(PhaseGVN& gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at, const TypeKlassPtr* tk) {\n+Node* LoadKlassNode::make(PhaseGVN& gvn, Node* ctl, Node* mem, Node* adr, const TypePtr* at,\n+                          const TypeKlassPtr* tk) {\n@@ -2227,1 +2303,1 @@\n-      return TypeKlassPtr::make(TypePtr::NotNull, ik, 0\/*offset*\/);\n+      return TypeKlassPtr::make(TypePtr::NotNull, ik, Type::Offset(0), tinst->flatten_array());\n@@ -2233,1 +2309,1 @@\n-  if( tary != NULL ) {\n+  if (tary != NULL) {\n@@ -2240,1 +2316,1 @@\n-      ciArrayKlass *ak = tary->klass()->as_array_klass();\n+      ciArrayKlass* ak = tary_klass->as_array_klass();\n@@ -2243,2 +2319,2 @@\n-      if( ak->is_obj_array_klass() ) {\n-        assert( ak->is_loaded(), \"\" );\n+      if (ak->is_obj_array_klass()) {\n+        assert(ak->is_loaded(), \"\");\n@@ -2246,2 +2322,2 @@\n-        if( base_k->is_loaded() && base_k->is_instance_klass() ) {\n-          ciInstanceKlass* ik = base_k->as_instance_klass();\n+        if (base_k->is_loaded() && base_k->is_instance_klass()) {\n+          ciInstanceKlass *ik = base_k->as_instance_klass();\n@@ -2258,3 +2334,2 @@\n-        return TypeKlassPtr::make(TypePtr::NotNull, ak, 0\/*offset*\/);\n-      } else {                  \/\/ Found a type-array?\n-        assert( ak->is_type_array_klass(), \"\" );\n+        return TypeKlassPtr::make(TypePtr::NotNull, ak, Type::Offset(0));\n+      } else if (ak->is_type_array_klass()) {\n@@ -2269,2 +2344,1 @@\n-    ciKlass* klass = tkls->klass();\n-    if( !klass->is_loaded() )\n+    if (!tkls->is_loaded()) {\n@@ -2272,0 +2346,2 @@\n+    }\n+    ciKlass* klass = tkls->klass();\n@@ -2281,1 +2357,5 @@\n-      return TypeKlassPtr::make(tkls->ptr(), elem, 0\/*offset*\/);\n+      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0));\n+    } else if (klass->is_flat_array_klass() &&\n+               tkls->offset() == in_bytes(ObjArrayKlass::element_klass_offset())) {\n+      ciKlass* elem = klass->as_flat_array_klass()->element_klass();\n+      return TypeKlassPtr::make(tkls->ptr(), elem, Type::Offset(0), \/* flatten_array= *\/ true);\n@@ -2489,0 +2569,1 @@\n+  case T_INLINE_TYPE:\n@@ -2549,1 +2630,1 @@\n-  {\n+  if (phase->C->get_adr_type(phase->C->get_alias_index(adr_type())) != TypeAryPtr::INLINES) {\n@@ -2567,0 +2648,1 @@\n+             (Opcode() == Op_StoreL && st->Opcode() == Op_StoreN) ||\n@@ -2652,2 +2734,1 @@\n-  if (result == this &&\n-      ReduceFieldZeroing && phase->type(val)->is_zero_type()) {\n+  if (result == this && ReduceFieldZeroing) {\n@@ -2655,1 +2736,3 @@\n-    if (mem->is_Proj() && mem->in(0)->is_Allocate()) {\n+    if (mem->is_Proj() && mem->in(0)->is_Allocate() &&\n+        (phase->type(val)->is_zero_type() || mem->in(0)->in(AllocateNode::DefaultValue) == val)) {\n+      assert(!phase->type(val)->is_zero_type() || mem->in(0)->in(AllocateNode::DefaultValue) == NULL, \"storing null to inline type array is forbidden\");\n@@ -2668,1 +2751,9 @@\n-          result = mem;\n+          if (phase->type(val)->is_zero_type()) {\n+            result = mem;\n+          } else if (prev_mem->is_Proj() && prev_mem->in(0)->is_Initialize()) {\n+            InitializeNode* init = prev_mem->in(0)->as_Initialize();\n+            AllocateNode* alloc = init->allocation();\n+            if (alloc != NULL && alloc->in(AllocateNode::DefaultValue) == val) {\n+              result = mem;\n+            }\n+          }\n@@ -2977,1 +3068,1 @@\n-    return new ClearArrayNode(in(0), in(1), in(2), in(3), true);\n+    return new ClearArrayNode(in(0), in(1), in(2), in(3), in(4), true);\n@@ -2992,1 +3083,1 @@\n-  Node *zero = phase->makecon(TypeLong::ZERO);\n+  Node *val = in(4);\n@@ -2994,1 +3085,1 @@\n-  mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+  mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -2999,1 +3090,1 @@\n-    mem = new StoreLNode(in(0),mem,adr,atp,zero,MemNode::unordered,false);\n+    mem = new StoreLNode(in(0), mem, adr, atp, val, MemNode::unordered, false);\n@@ -3033,0 +3124,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3043,1 +3136,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != NULL) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == NULL, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -3050,1 +3149,1 @@\n-  return clear_memory(ctl, mem, dest, phase->MakeConX(offset), end_offset, phase);\n+  return clear_memory(ctl, mem, dest, raw_val, phase->MakeConX(offset), end_offset, phase);\n@@ -3054,0 +3153,1 @@\n+                                   Node* raw_val,\n@@ -3076,1 +3176,4 @@\n-  mem = new ClearArrayNode(ctl, mem, zsize, adr, false);\n+  if (raw_val == NULL) {\n+    raw_val = phase->MakeConX(0);\n+  }\n+  mem = new ClearArrayNode(ctl, mem, zsize, adr, raw_val, false);\n@@ -3081,0 +3184,2 @@\n+                                   Node* val,\n+                                   Node* raw_val,\n@@ -3095,1 +3200,1 @@\n-    mem = clear_memory(ctl, mem, dest,\n+    mem = clear_memory(ctl, mem, dest, val, raw_val,\n@@ -3102,1 +3207,7 @@\n-    mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    if (val != NULL) {\n+      assert(phase->type(val)->isa_narrowoop(), \"should be narrow oop\");\n+      mem = new StoreNNode(ctl, mem, adr, atp, val, MemNode::unordered);\n+    } else {\n+      assert(raw_val == NULL, \"val may not be null\");\n+      mem = StoreNode::make(*phase, ctl, mem, adr, atp, phase->zerocon(T_INT), T_INT, MemNode::unordered);\n+    }\n@@ -3241,1 +3352,1 @@\n-Node *MemBarNode::match( const ProjNode *proj, const Matcher *m ) {\n+Node *MemBarNode::match(const ProjNode *proj, const Matcher *m, const RegMask* mask) {\n@@ -3527,1 +3638,3 @@\n-  if (init == NULL || init->is_complete())  return false;\n+  if (init == NULL || init->is_complete()) {\n+    return false;\n+  }\n@@ -4285,0 +4398,2 @@\n+                                              allocation()->in(AllocateNode::DefaultValue),\n+                                              allocation()->in(AllocateNode::RawDefaultValue),\n@@ -4344,0 +4459,2 @@\n+                                            allocation()->in(AllocateNode::DefaultValue),\n+                                            allocation()->in(AllocateNode::RawDefaultValue),\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":171,"deletions":54,"binary":false,"changes":225,"status":"modified"},{"patch":"@@ -129,0 +129,4 @@\n+#ifdef ASSERT\n+  void set_adr_type(const TypePtr* adr_type) { _adr_type = adr_type; }\n+#endif\n+\n@@ -548,1 +552,0 @@\n-\n@@ -1127,0 +1130,1 @@\n+  bool _word_copy_only;\n@@ -1128,2 +1132,3 @@\n-  ClearArrayNode( Node *ctrl, Node *arymem, Node *word_cnt, Node *base, bool is_large)\n-    : Node(ctrl,arymem,word_cnt,base), _is_large(is_large) {\n+  ClearArrayNode( Node *ctrl, Node *arymem, Node *word_cnt, Node *base, Node* val, bool is_large)\n+    : Node(ctrl, arymem, word_cnt, base, val), _is_large(is_large),\n+      _word_copy_only(val->bottom_type()->isa_long() && (!val->bottom_type()->is_long()->is_con() || val->bottom_type()->is_long()->get_con() != 0)) {\n@@ -1141,0 +1146,1 @@\n+  bool word_copy_only() const { return _word_copy_only; }\n@@ -1147,0 +1153,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -1151,0 +1159,2 @@\n+                            Node* val,\n+                            Node* raw_val,\n@@ -1155,0 +1165,1 @@\n+                            Node* raw_val,\n@@ -1205,1 +1216,1 @@\n-  virtual Node *match( const ProjNode *proj, const Matcher *m );\n+  virtual Node *match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":15,"deletions":4,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+#include \"opto\/idealKit.hpp\"\n+#include \"opto\/inlinetypenode.hpp\"\n@@ -53,0 +55,17 @@\n+Node* Parse::record_profile_for_speculation_at_array_load(Node* ld) {\n+  \/\/ Feed unused profile data to type speculation\n+  if (UseTypeSpeculation && UseArrayLoadStoreProfile) {\n+    ciKlass* array_type = NULL;\n+    ciKlass* element_type = NULL;\n+    ProfilePtrKind element_ptr = ProfileMaybeNull;\n+    bool flat_array = true;\n+    bool null_free_array = true;\n+    method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+    if (element_type != NULL || element_ptr != ProfileMaybeNull) {\n+      ld = record_profile_for_speculation(ld, element_type, element_ptr);\n+    }\n+  }\n+  return ld;\n+}\n+\n+\n@@ -56,1 +75,0 @@\n-  bool big_val = bt == T_DOUBLE || bt == T_LONG;\n@@ -60,2 +78,127 @@\n-  pop();                      \/\/ index (already used)\n-  Node* array = pop();        \/\/ the array itself\n+  Node* idx = pop();\n+  Node* ary = pop();\n+\n+  \/\/ Handle inline type arrays\n+  const TypeOopPtr* elemptr = elemtype->make_oopptr();\n+  const TypeAryPtr* ary_t = _gvn.type(ary)->is_aryptr();\n+  if (ary_t->is_flat()) {\n+    C->set_flattened_accesses();\n+    \/\/ Load from flattened inline type array\n+    Node* vt = InlineTypeNode::make_from_flattened(this, elemtype->inline_klass(), ary, adr);\n+    push(vt);\n+    return;\n+  } else if (ary_t->is_null_free()) {\n+    \/\/ Load from non-flattened inline type array (elements can never be null)\n+    bt = T_INLINE_TYPE;\n+  } else if (!ary_t->is_not_flat()) {\n+    \/\/ Cannot statically determine if array is flattened, emit runtime check\n+    assert(UseFlatArray && is_reference_type(bt) && elemptr->can_be_inline_type() && !ary_t->klass_is_exact() && !ary_t->is_not_null_free() &&\n+           (!elemptr->is_inlinetypeptr() || elemptr->inline_klass()->flatten_array()), \"array can't be flattened\");\n+    IdealKit ideal(this);\n+    IdealVariable res(ideal);\n+    ideal.declarations_done();\n+    ideal.if_then(is_non_flattened_array(ary)); {\n+      \/\/ non-flattened\n+      assert(ideal.ctrl()->in(0)->as_If()->is_non_flattened_array_check(&_gvn), \"Should be found\");\n+      sync_kit(ideal);\n+      const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);\n+      Node* ld = access_load_at(ary, adr, adr_type, elemptr, bt,\n+                                IN_HEAP | IS_ARRAY | C2_CONTROL_DEPENDENT_LOAD);\n+      ideal.sync_kit(this);\n+      ideal.set(res, ld);\n+    } ideal.else_(); {\n+      \/\/ flattened\n+      sync_kit(ideal);\n+      if (elemptr->is_inlinetypeptr()) {\n+        \/\/ Element type is known, cast and load from flattened representation\n+        ciInlineKlass* vk = elemptr->inline_klass();\n+        assert(vk->flatten_array() && elemptr->maybe_null(), \"never\/always flat - should be optimized\");\n+        ciArrayKlass* array_klass = ciArrayKlass::make(vk);\n+        const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)->isa_aryptr();\n+        Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, arytype));\n+        Node* casted_adr = array_element_address(cast, idx, T_INLINE_TYPE, ary_t->size(), control());\n+        \/\/ Re-execute flattened array load if buffering triggers deoptimization\n+        PreserveReexecuteState preexecs(this);\n+        jvms()->set_should_reexecute(true);\n+        inc_sp(2);\n+        Node* vt = InlineTypeNode::make_from_flattened(this, vk, cast, casted_adr)->buffer(this, false);\n+        ideal.set(res, vt);\n+        ideal.sync_kit(this);\n+      } else {\n+        \/\/ Element type is unknown, emit runtime call\n+        Node* kls = load_object_klass(ary);\n+        Node* k_adr = basic_plus_adr(kls, in_bytes(ArrayKlass::element_klass_offset()));\n+        Node* elem_klass = _gvn.transform(LoadKlassNode::make(_gvn, NULL, immutable_memory(), k_adr, TypeInstPtr::KLASS));\n+        Node* obj_size  = NULL;\n+        kill_dead_locals();\n+        \/\/ Re-execute flattened array load if buffering triggers deoptimization\n+        PreserveReexecuteState preexecs(this);\n+        jvms()->set_bci(_bci);\n+        jvms()->set_should_reexecute(true);\n+        inc_sp(2);\n+        Node* alloc_obj = new_instance(elem_klass, NULL, &obj_size, \/*deoptimize_on_exception=*\/true);\n+\n+        AllocateNode* alloc = AllocateNode::Ideal_allocation(alloc_obj, &_gvn);\n+        assert(alloc->maybe_set_complete(&_gvn), \"\");\n+        alloc->initialization()->set_complete_with_arraycopy();\n+\n+        \/\/ This membar keeps this access to an unknown flattened array\n+        \/\/ correctly ordered with other unknown and known flattened\n+        \/\/ array accesses.\n+        insert_mem_bar_volatile(Op_MemBarCPUOrder, C->get_alias_index(TypeAryPtr::INLINES));\n+\n+        BarrierSetC2* bs = BarrierSet::barrier_set()->barrier_set_c2();\n+        \/\/ Unknown inline type might contain reference fields\n+        if (false && !bs->array_copy_requires_gc_barriers(false, T_OBJECT, false, BarrierSetC2::Parsing)) {\n+          \/\/ FIXME 8230656 also merge changes from 8238759 in\n+          int base_off = sizeof(instanceOopDesc);\n+          Node* dst_base = basic_plus_adr(alloc_obj, base_off);\n+          Node* countx = obj_size;\n+          countx = _gvn.transform(new SubXNode(countx, MakeConX(base_off)));\n+          countx = _gvn.transform(new URShiftXNode(countx, intcon(LogBytesPerLong)));\n+\n+          assert(Klass::_lh_log2_element_size_shift == 0, \"use shift in place\");\n+          Node* lhp = basic_plus_adr(kls, in_bytes(Klass::layout_helper_offset()));\n+          Node* elem_shift = make_load(NULL, lhp, TypeInt::INT, T_INT, MemNode::unordered);\n+          uint header = arrayOopDesc::base_offset_in_bytes(T_INLINE_TYPE);\n+          Node* base  = basic_plus_adr(ary, header);\n+          idx = Compile::conv_I2X_index(&_gvn, idx, TypeInt::POS, control());\n+          Node* scale = _gvn.transform(new LShiftXNode(idx, elem_shift));\n+          Node* adr = basic_plus_adr(ary, base, scale);\n+\n+          access_clone(adr, dst_base, countx, false);\n+        } else {\n+          ideal.sync_kit(this);\n+          ideal.make_leaf_call(OptoRuntime::load_unknown_inline_type(),\n+                               CAST_FROM_FN_PTR(address, OptoRuntime::load_unknown_inline),\n+                               \"load_unknown_inline\",\n+                               ary, idx, alloc_obj);\n+          sync_kit(ideal);\n+        }\n+\n+        \/\/ This makes sure no other thread sees a partially initialized buffered inline type\n+        insert_mem_bar_volatile(Op_MemBarStoreStore, Compile::AliasIdxRaw, alloc->proj_out_or_null(AllocateNode::RawAddress));\n+\n+        \/\/ Same as MemBarCPUOrder above: keep this unknown flattened\n+        \/\/ array access correctly ordered with other flattened array\n+        \/\/ access\n+        insert_mem_bar_volatile(Op_MemBarCPUOrder, C->get_alias_index(TypeAryPtr::INLINES));\n+\n+        \/\/ Prevent any use of the newly allocated inline type before it is fully initialized\n+        alloc_obj = new CastPPNode(alloc_obj, _gvn.type(alloc_obj), true);\n+        alloc_obj->set_req(0, control());\n+        alloc_obj = _gvn.transform(alloc_obj);\n+\n+        const Type* unknown_value = elemptr->is_instptr()->cast_to_flatten_array();\n+        alloc_obj = _gvn.transform(new CheckCastPPNode(control(), alloc_obj, unknown_value));\n+\n+        ideal.sync_kit(this);\n+        ideal.set(res, alloc_obj);\n+      }\n+    } ideal.end_if();\n+    sync_kit(ideal);\n+    Node* ld = _gvn.transform(ideal.value(res));\n+    ld = record_profile_for_speculation_at_array_load(ld);\n+    push_node(bt, ld);\n+    return;\n+  }\n@@ -67,2 +210,1 @@\n-\n-  Node* ld = access_load_at(array, adr, adr_type, elemtype, bt,\n+  Node* ld = access_load_at(ary, adr, adr_type, elemtype, bt,\n@@ -70,4 +212,6 @@\n-  if (big_val) {\n-    push_pair(ld);\n-  } else {\n-    push(ld);\n+  if (bt == T_INLINE_TYPE) {\n+    \/\/ Loading a non-flattened inline type from an array\n+    assert(!gvn().type(ld)->maybe_null(), \"inline type array elements should never be null\");\n+    if (elemptr->inline_klass()->is_scalarizable()) {\n+      ld = InlineTypeNode::make_from_oop(this, ld, elemptr->inline_klass());\n+    }\n@@ -75,0 +219,5 @@\n+  if (!ld->is_InlineType()) {\n+    ld = record_profile_for_speculation_at_array_load(ld);\n+  }\n+\n+  push_node(bt, ld);\n@@ -81,2 +230,1 @@\n-  bool big_val = bt == T_DOUBLE || bt == T_LONG;\n-  Node* adr = array_addressing(bt, big_val ? 2 : 1, elemtype);\n+  Node* adr = array_addressing(bt, type2size[bt], elemtype);\n@@ -84,0 +232,1 @@\n+  Node* cast_val = NULL;\n@@ -85,1 +234,2 @@\n-    array_store_check();\n+    cast_val = array_store_check();\n+    if (stopped()) return;\n@@ -87,8 +237,6 @@\n-  Node* val;                  \/\/ Oop to store\n-  if (big_val) {\n-    val = pop_pair();\n-  } else {\n-    val = pop();\n-  }\n-  pop();                      \/\/ index (already used)\n-  Node* array = pop();        \/\/ the array itself\n+  Node* val = pop_node(bt); \/\/ Value to store\n+  Node* idx = pop();        \/\/ Index in the array\n+  Node* ary = pop();        \/\/ The array itself\n+\n+  const TypeAryPtr* ary_t = _gvn.type(ary)->is_aryptr();\n+  const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);\n@@ -98,0 +246,142 @@\n+  } else if (bt == T_OBJECT) {\n+    elemtype = elemtype->make_oopptr();\n+    const Type* tval = _gvn.type(cast_val);\n+    \/\/ We may have lost type information for 'val' here due to the casts\n+    \/\/ emitted by the array_store_check code (see JDK-6312651)\n+    \/\/ TODO Remove this code once JDK-6312651 is in.\n+    const Type* tval_init = _gvn.type(val);\n+    \/\/ Based on the value to be stored, try to determine if the array is not null-free and\/or not flat.\n+    \/\/ This is only legal for non-null stores because the array_store_check always passes for null, even\n+    \/\/ if the array is null-free. Null stores are handled in GraphKit::gen_inline_array_null_guard().\n+    bool not_inline = !tval->isa_inlinetype() &&\n+                      ((!tval_init->maybe_null() && !tval_init->is_oopptr()->can_be_inline_type()) ||\n+                       (!tval->maybe_null() && !tval->is_oopptr()->can_be_inline_type()));\n+    bool not_flattened = not_inline || ((tval_init->is_inlinetypeptr() || tval_init->isa_inlinetype()) && !tval_init->inline_klass()->flatten_array());\n+    if (!ary_t->is_not_null_free() && not_inline) {\n+      \/\/ Storing a non-inline type, mark array as not null-free (-> not flat).\n+      ary_t = ary_t->cast_to_not_null_free();\n+      Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));\n+      replace_in_map(ary, cast);\n+      ary = cast;\n+    } else if (!ary_t->is_not_flat() && not_flattened) {\n+      \/\/ Storing a non-flattened value, mark array as not flat.\n+      ary_t = ary_t->cast_to_not_flat();\n+      Node* cast = _gvn.transform(new CheckCastPPNode(control(), ary, ary_t));\n+      replace_in_map(ary, cast);\n+      ary = cast;\n+    }\n+\n+    if (ary_t->is_flat()) {\n+      \/\/ Store to flattened inline type array\n+      C->set_flattened_accesses();\n+      if (!cast_val->is_InlineType()) {\n+        inc_sp(3);\n+        cast_val = null_check(cast_val);\n+        if (stopped()) return;\n+        dec_sp(3);\n+        cast_val = InlineTypeNode::make_from_oop(this, cast_val, ary_t->elem()->inline_klass());\n+      }\n+      \/\/ Re-execute flattened array store if buffering triggers deoptimization\n+      PreserveReexecuteState preexecs(this);\n+      inc_sp(3);\n+      jvms()->set_should_reexecute(true);\n+      cast_val->as_InlineType()->store_flattened(this, ary, adr, NULL, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n+      return;\n+    } else if (ary_t->is_null_free()) {\n+      \/\/ Store to non-flattened inline type array (elements can never be null)\n+      if (!cast_val->is_InlineType() && tval->maybe_null()) {\n+        inc_sp(3);\n+        cast_val = null_check(cast_val);\n+        if (stopped()) return;\n+        dec_sp(3);\n+      }\n+    } else if (!ary_t->is_not_flat() && tval != TypePtr::NULL_PTR) {\n+      \/\/ Array might be flattened, emit runtime checks (for NULL, a simple inline_array_null_guard is sufficient).\n+      assert(UseFlatArray && !not_flattened && elemtype->is_oopptr()->can_be_inline_type() &&\n+             !ary_t->klass_is_exact() && !ary_t->is_not_null_free(), \"array can't be flattened\");\n+      IdealKit ideal(this);\n+      ideal.if_then(is_non_flattened_array(ary)); {\n+        \/\/ non-flattened\n+        assert(ideal.ctrl()->in(0)->as_If()->is_non_flattened_array_check(&_gvn), \"Should be found\");\n+        sync_kit(ideal);\n+        gen_inline_array_null_guard(ary, cast_val, 3);\n+        inc_sp(3);\n+        access_store_at(ary, adr, adr_type, cast_val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY, false);\n+        dec_sp(3);\n+        ideal.sync_kit(this);\n+      } ideal.else_(); {\n+        Node* val = cast_val;\n+        \/\/ flattened\n+        if (!val->is_InlineType() && tval->maybe_null()) {\n+          \/\/ Add null check\n+          sync_kit(ideal);\n+          Node* null_ctl = top();\n+          val = null_check_oop(val, &null_ctl);\n+          if (null_ctl != top()) {\n+            PreserveJVMState pjvms(this);\n+            inc_sp(3);\n+            set_control(null_ctl);\n+            uncommon_trap(Deoptimization::Reason_null_check, Deoptimization::Action_none);\n+            dec_sp(3);\n+          }\n+          ideal.sync_kit(this);\n+        }\n+        \/\/ Try to determine the inline klass\n+        ciInlineKlass* vk = NULL;\n+        if (tval->isa_inlinetype() || tval->is_inlinetypeptr()) {\n+          vk = tval->inline_klass();\n+        } else if (tval_init->isa_inlinetype() || tval_init->is_inlinetypeptr()) {\n+          vk = tval_init->inline_klass();\n+        } else if (elemtype->is_inlinetypeptr()) {\n+          vk = elemtype->inline_klass();\n+        }\n+        Node* casted_ary = ary;\n+        if (vk != NULL && !stopped()) {\n+          \/\/ Element type is known, cast and store to flattened representation\n+          sync_kit(ideal);\n+          assert(vk->flatten_array() && elemtype->maybe_null(), \"never\/always flat - should be optimized\");\n+          ciArrayKlass* array_klass = ciArrayKlass::make(vk);\n+          const TypeAryPtr* arytype = TypeOopPtr::make_from_klass(array_klass)->isa_aryptr();\n+          casted_ary = _gvn.transform(new CheckCastPPNode(control(), casted_ary, arytype));\n+          Node* casted_adr = array_element_address(casted_ary, idx, T_OBJECT, arytype->size(), control());\n+          if (!val->is_InlineType()) {\n+            assert(!gvn().type(val)->maybe_null(), \"inline type array elements should never be null\");\n+            val = InlineTypeNode::make_from_oop(this, val, vk);\n+          }\n+          \/\/ Re-execute flattened array store if buffering triggers deoptimization\n+          PreserveReexecuteState preexecs(this);\n+          inc_sp(3);\n+          jvms()->set_should_reexecute(true);\n+          val->as_InlineType()->store_flattened(this, casted_ary, casted_adr, NULL, 0, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n+          ideal.sync_kit(this);\n+        } else if (!ideal.ctrl()->is_top()) {\n+          \/\/ Element type is unknown, emit runtime call\n+          sync_kit(ideal);\n+\n+          \/\/ This membar keeps this access to an unknown flattened\n+          \/\/ array correctly ordered with other unknown and known\n+          \/\/ flattened array accesses.\n+          insert_mem_bar_volatile(Op_MemBarCPUOrder, C->get_alias_index(TypeAryPtr::INLINES));\n+          ideal.sync_kit(this);\n+\n+          ideal.make_leaf_call(OptoRuntime::store_unknown_inline_type(),\n+                               CAST_FROM_FN_PTR(address, OptoRuntime::store_unknown_inline),\n+                               \"store_unknown_inline\",\n+                               val, casted_ary, idx);\n+\n+          sync_kit(ideal);\n+          \/\/ Same as MemBarCPUOrder above: keep this unknown\n+          \/\/ flattened array access correctly ordered with other\n+          \/\/ flattened array accesses.\n+          insert_mem_bar_volatile(Op_MemBarCPUOrder, C->get_alias_index(TypeAryPtr::INLINES));\n+          ideal.sync_kit(this);\n+        }\n+      }\n+      ideal.end_if();\n+      sync_kit(ideal);\n+      return;\n+    } else if (!ary_t->is_not_null_free()) {\n+      \/\/ Array is not flattened but may be null free\n+      assert(elemtype->is_oopptr()->can_be_inline_type() && !ary_t->klass_is_exact(), \"array can't be null-free\");\n+      ary = gen_inline_array_null_guard(ary, cast_val, 3, true);\n+    }\n@@ -99,3 +389,3 @@\n-  const TypeAryPtr* adr_type = TypeAryPtr::get_array_body_type(bt);\n-\n-  access_store_at(array, adr, adr_type, val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n+  inc_sp(3);\n+  access_store_at(ary, adr, adr_type, val, elemtype, bt, MO_UNORDERED | IN_HEAP | IS_ARRAY);\n+  dec_sp(3);\n@@ -201,0 +491,120 @@\n+  \/\/ This could be an access to an inline type array. We can't tell if it's\n+  \/\/ flat or not. Speculating it's not leads to a much simpler graph\n+  \/\/ shape. Check profiling.\n+  \/\/ For aastore, by the time we're here, the array store check should\n+  \/\/ have already taken advantage of profiling to cast the array to an\n+  \/\/ exact type reported by profiling\n+  const TypeOopPtr* elemptr = elemtype->make_oopptr();\n+  if (elemtype->isa_inlinetype() == NULL &&\n+      (elemptr == NULL || !elemptr->is_inlinetypeptr() || elemptr->maybe_null()) &&\n+      !arytype->is_not_flat()) {\n+    assert(is_reference_type(type), \"Only references\");\n+    \/\/ First check the speculative type\n+    Deoptimization::DeoptReason reason = Deoptimization::Reason_speculate_class_check;\n+    ciKlass* array_type = arytype->speculative_type();\n+    if (too_many_traps_or_recompiles(reason) || array_type == NULL) {\n+      \/\/ No speculative type, check profile data at this bci\n+      array_type = NULL;\n+      reason = Deoptimization::Reason_class_check;\n+      if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(reason)) {\n+        ciKlass* element_type = NULL;\n+        ProfilePtrKind element_ptr = ProfileMaybeNull;\n+        bool flat_array = true;\n+        bool null_free_array = true;\n+        method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+      }\n+    }\n+    if (array_type != NULL) {\n+      \/\/ Speculate that this array has the exact type reported by profile data\n+      Node* better_ary = NULL;\n+      Node* slow_ctl = type_check_receiver(ary, array_type, 1.0, &better_ary);\n+      { PreserveJVMState pjvms(this);\n+        set_control(slow_ctl);\n+        uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n+      }\n+      replace_in_map(ary, better_ary);\n+      ary = better_ary;\n+      arytype  = _gvn.type(ary)->is_aryptr();\n+      elemtype = arytype->elem();\n+    }\n+  } else if (UseTypeSpeculation && UseArrayLoadStoreProfile) {\n+    \/\/ No need to speculate: feed profile data at this bci for the\n+    \/\/ array to type speculation\n+    ciKlass* array_type = NULL;\n+    ciKlass* element_type = NULL;\n+    ProfilePtrKind element_ptr = ProfileMaybeNull;\n+    bool flat_array = true;\n+    bool null_free_array = true;\n+    method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+    if (array_type != NULL) {\n+      record_profile_for_speculation(ary, array_type, ProfileMaybeNull);\n+    }\n+  }\n+\n+  \/\/ We have no exact array type from profile data. Check profile data\n+  \/\/ for a non null free or non flat array. Non null free implies non\n+  \/\/ flat so check this one first. Speculating on a non null free\n+  \/\/ array doesn't help aaload but could be profitable for a\n+  \/\/ subsequent aastore.\n+  elemptr = elemtype->make_oopptr();\n+  if (!arytype->is_not_null_free() &&\n+      elemtype->isa_inlinetype() == NULL &&\n+      (elemptr == NULL || !elemptr->is_inlinetypeptr()) &&\n+      UseArrayLoadStoreProfile) {\n+    assert(is_reference_type(type), \"\");\n+    bool null_free_array = true;\n+    Deoptimization::DeoptReason reason = Deoptimization::Reason_none;\n+    if (arytype->speculative() != NULL &&\n+        arytype->speculative()->is_aryptr()->is_not_null_free() &&\n+        !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {\n+      null_free_array = false;\n+      reason = Deoptimization::Reason_speculate_class_check;\n+    } else if (!too_many_traps_or_recompiles(Deoptimization::Reason_class_check)) {\n+      ciKlass* array_type = NULL;\n+      ciKlass* element_type = NULL;\n+      ProfilePtrKind element_ptr = ProfileMaybeNull;\n+      bool flat_array = true;\n+      method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+      reason = Deoptimization::Reason_class_check;\n+    }\n+    if (!null_free_array) {\n+      { \/\/ Deoptimize if null-free array\n+        BuildCutout unless(this, is_nullable_array(ary), PROB_MAX);\n+        uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n+      }\n+      Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype->cast_to_not_null_free()));\n+      replace_in_map(ary, better_ary);\n+      ary = better_ary;\n+      arytype = _gvn.type(ary)->is_aryptr();\n+    }\n+  }\n+\n+  if (!arytype->is_not_flat() && elemtype->isa_inlinetype() == NULL) {\n+    assert(is_reference_type(type), \"\");\n+    bool flat_array = true;\n+    Deoptimization::DeoptReason reason = Deoptimization::Reason_none;\n+    if (arytype->speculative() != NULL &&\n+        arytype->speculative()->is_aryptr()->is_not_flat() &&\n+        !too_many_traps_or_recompiles(Deoptimization::Reason_speculate_class_check)) {\n+      flat_array = false;\n+      reason = Deoptimization::Reason_speculate_class_check;\n+    } else if (UseArrayLoadStoreProfile && !too_many_traps_or_recompiles(reason)) {\n+      ciKlass* array_type = NULL;\n+      ciKlass* element_type = NULL;\n+      ProfilePtrKind element_ptr = ProfileMaybeNull;\n+      bool null_free_array = true;\n+      method()->array_access_profiled_type(bci(), array_type, element_type, element_ptr, flat_array, null_free_array);\n+      reason = Deoptimization::Reason_class_check;\n+    }\n+    if (!flat_array) {\n+      { \/\/ Deoptimize if flat array\n+        BuildCutout unless(this, is_non_flattened_array(ary), PROB_MAX);\n+        uncommon_trap_exact(reason, Deoptimization::Action_maybe_recompile);\n+      }\n+      Node* better_ary = _gvn.transform(new CheckCastPPNode(control(), ary, arytype->cast_to_not_flat()));\n+      replace_in_map(ary, better_ary);\n+      ary = better_ary;\n+      arytype = _gvn.type(ary)->is_aryptr();\n+    }\n+  }\n+\n@@ -1490,1 +1900,1 @@\n-      adjust_map_after_if(btest, c, prob, branch_block, next_block);\n+      adjust_map_after_if(btest, c, prob, branch_block);\n@@ -1510,2 +1920,1 @@\n-    adjust_map_after_if(BoolTest(btest).negate(), c, 1.0-prob,\n-                        next_block, branch_block);\n+    adjust_map_after_if(BoolTest(btest).negate(), c, 1.0-prob, next_block);\n@@ -1516,1 +1925,1 @@\n-void Parse::do_if(BoolTest::mask btest, Node* c) {\n+void Parse::do_if(BoolTest::mask btest, Node* c, bool new_path, Node** ctrl_taken) {\n@@ -1605,2 +2014,2 @@\n-      if (C->eliminate_boxing()) {\n-        \/\/ Mark the successor block as parsed\n+      if (C->eliminate_boxing() && !new_path) {\n+        \/\/ Mark the successor block as parsed (if we haven't created a new path)\n@@ -1612,1 +2021,1 @@\n-      adjust_map_after_if(taken_btest, c, prob, branch_block, next_block);\n+      adjust_map_after_if(taken_btest, c, prob, branch_block);\n@@ -1614,1 +2023,9 @@\n-        merge(target_bci);\n+        if (new_path) {\n+          \/\/ Merge by using a new path\n+          merge_new_path(target_bci);\n+        } else if (ctrl_taken != NULL) {\n+          \/\/ Don't merge but save taken branch to be wired by caller\n+          *ctrl_taken = control();\n+        } else {\n+          merge(target_bci);\n+        }\n@@ -1623,1 +2040,1 @@\n-  if (stopped()) {\n+  if (stopped() && ctrl_taken == NULL) {\n@@ -1625,1 +2042,1 @@\n-      \/\/ Mark the successor block as parsed\n+      \/\/ Mark the successor block as parsed (if caller does not re-wire control flow)\n@@ -1631,2 +2048,202 @@\n-    adjust_map_after_if(untaken_btest, c, untaken_prob,\n-                        next_block, branch_block);\n+    adjust_map_after_if(untaken_btest, c, untaken_prob, next_block);\n+  }\n+}\n+\n+void Parse::do_acmp(BoolTest::mask btest, Node* a, Node* b) {\n+  if (!EnableValhalla) {\n+    Node* cmp = CmpP(a, b);\n+    cmp = optimize_cmp_with_klass(cmp);\n+    do_if(btest, cmp);\n+    return;\n+  }\n+\n+  \/\/ Allocate inline type operands and re-execute on deoptimization\n+  if (a->is_InlineType()) {\n+    PreserveReexecuteState preexecs(this);\n+    inc_sp(2);\n+    jvms()->set_should_reexecute(true);\n+    a = a->as_InlineType()->buffer(this)->get_oop();\n+  }\n+  if (b->is_InlineType()) {\n+    PreserveReexecuteState preexecs(this);\n+    inc_sp(2);\n+    jvms()->set_should_reexecute(true);\n+    b = b->as_InlineType()->buffer(this)->get_oop();\n+  }\n+\n+  \/\/ First, do a normal pointer comparison\n+  const TypeOopPtr* ta = _gvn.type(a)->isa_oopptr();\n+  const TypeOopPtr* tb = _gvn.type(b)->isa_oopptr();\n+  Node* cmp = CmpP(a, b);\n+  cmp = optimize_cmp_with_klass(cmp);\n+  if (ta == NULL || !ta->can_be_inline_type() ||\n+      tb == NULL || !tb->can_be_inline_type()) {\n+    \/\/ This is sufficient, if one of the operands can't be an inline type\n+    do_if(btest, cmp);\n+    return;\n+  }\n+  Node* eq_region = NULL;\n+  if (btest == BoolTest::eq) {\n+    do_if(btest, cmp, true);\n+    if (stopped()) {\n+      return;\n+    }\n+  } else {\n+    assert(btest == BoolTest::ne, \"only eq or ne\");\n+    Node* is_not_equal = NULL;\n+    eq_region = new RegionNode(3);\n+    {\n+      PreserveJVMState pjvms(this);\n+      do_if(btest, cmp, false, &is_not_equal);\n+      if (!stopped()) {\n+        eq_region->init_req(1, control());\n+      }\n+    }\n+    if (is_not_equal == NULL || is_not_equal->is_top()) {\n+      record_for_igvn(eq_region);\n+      set_control(_gvn.transform(eq_region));\n+      return;\n+    }\n+    set_control(is_not_equal);\n+  }\n+\n+  \/\/ Pointers are not equal, check if first operand is non-null\n+  Node* ne_region = new RegionNode(6);\n+  inc_sp(2);\n+  Node* null_ctl = top();\n+  Node* not_null_a = null_check_oop(a, &null_ctl, !too_many_traps(Deoptimization::Reason_null_check), false, false);\n+  dec_sp(2);\n+  ne_region->init_req(1, null_ctl);\n+  if (stopped()) {\n+    record_for_igvn(ne_region);\n+    set_control(_gvn.transform(ne_region));\n+    if (btest == BoolTest::ne) {\n+      {\n+        PreserveJVMState pjvms(this);\n+        int target_bci = iter().get_dest();\n+        merge(target_bci);\n+      }\n+      record_for_igvn(eq_region);\n+      set_control(_gvn.transform(eq_region));\n+    }\n+    return;\n+  }\n+\n+  \/\/ First operand is non-null, check if it is an inline type\n+  Node* is_value = is_inline_type(not_null_a);\n+  IfNode* is_value_iff = create_and_map_if(control(), is_value, PROB_FAIR, COUNT_UNKNOWN);\n+  Node* not_value = _gvn.transform(new IfFalseNode(is_value_iff));\n+  ne_region->init_req(2, not_value);\n+  set_control(_gvn.transform(new IfTrueNode(is_value_iff)));\n+\n+  \/\/ The first operand is an inline type, check if the second operand is non-null\n+  inc_sp(2);\n+  null_ctl = top();\n+  Node* not_null_b = null_check_oop(b, &null_ctl, !too_many_traps(Deoptimization::Reason_null_check), false, false);\n+  dec_sp(2);\n+  ne_region->init_req(3, null_ctl);\n+  if (stopped()) {\n+    record_for_igvn(ne_region);\n+    set_control(_gvn.transform(ne_region));\n+    if (btest == BoolTest::ne) {\n+      {\n+        PreserveJVMState pjvms(this);\n+        int target_bci = iter().get_dest();\n+        merge(target_bci);\n+      }\n+      record_for_igvn(eq_region);\n+      set_control(_gvn.transform(eq_region));\n+    }\n+    return;\n+  }\n+\n+  \/\/ Check if both operands are of the same class.\n+  Node* kls_a = load_object_klass(not_null_a);\n+  Node* kls_b = load_object_klass(not_null_b);\n+  Node* kls_cmp = CmpP(kls_a, kls_b);\n+  Node* kls_bol = _gvn.transform(new BoolNode(kls_cmp, BoolTest::ne));\n+  IfNode* kls_iff = create_and_map_if(control(), kls_bol, PROB_FAIR, COUNT_UNKNOWN);\n+  Node* kls_ne = _gvn.transform(new IfTrueNode(kls_iff));\n+  set_control(_gvn.transform(new IfFalseNode(kls_iff)));\n+  ne_region->init_req(4, kls_ne);\n+\n+  if (stopped()) {\n+    record_for_igvn(ne_region);\n+    set_control(_gvn.transform(ne_region));\n+    if (btest == BoolTest::ne) {\n+      {\n+        PreserveJVMState pjvms(this);\n+        int target_bci = iter().get_dest();\n+        merge(target_bci);\n+      }\n+      record_for_igvn(eq_region);\n+      set_control(_gvn.transform(eq_region));\n+    }\n+    return;\n+  }\n+\n+  \/\/ Both operands are values types of the same class, we need to perform a\n+  \/\/ substitutability test. Delegate to ValueBootstrapMethods::isSubstitutable().\n+  Node* ne_io_phi = PhiNode::make(ne_region, i_o());\n+  Node* mem = reset_memory();\n+  Node* ne_mem_phi = PhiNode::make(ne_region, mem);\n+\n+  Node* eq_io_phi = NULL;\n+  Node* eq_mem_phi = NULL;\n+  if (eq_region != NULL) {\n+    eq_io_phi = PhiNode::make(eq_region, i_o());\n+    eq_mem_phi = PhiNode::make(eq_region, mem);\n+  }\n+\n+  set_all_memory(mem);\n+\n+  kill_dead_locals();\n+  ciMethod* subst_method = ciEnv::current()->ValueBootstrapMethods_klass()->find_method(ciSymbol::isSubstitutable_name(), ciSymbol::object_object_boolean_signature());\n+  CallStaticJavaNode *call = new CallStaticJavaNode(C, TypeFunc::make(subst_method), SharedRuntime::get_resolve_static_call_stub(), subst_method, bci());\n+  call->set_override_symbolic_info(true);\n+  call->init_req(TypeFunc::Parms, not_null_a);\n+  call->init_req(TypeFunc::Parms+1, not_null_b);\n+  inc_sp(2);\n+  set_edges_for_java_call(call, false, false);\n+  Node* ret = set_results_for_java_call(call, false, true);\n+  dec_sp(2);\n+\n+  \/\/ Test the return value of ValueBootstrapMethods::isSubstitutable()\n+  Node* subst_cmp = _gvn.transform(new CmpINode(ret, intcon(1)));\n+  Node* ctl = C->top();\n+  if (btest == BoolTest::eq) {\n+    PreserveJVMState pjvms(this);\n+    do_if(btest, subst_cmp);\n+    if (!stopped()) {\n+      ctl = control();\n+    }\n+  } else {\n+    assert(btest == BoolTest::ne, \"only eq or ne\");\n+    PreserveJVMState pjvms(this);\n+    do_if(btest, subst_cmp, false, &ctl);\n+    if (!stopped()) {\n+      eq_region->init_req(2, control());\n+      eq_io_phi->init_req(2, i_o());\n+      eq_mem_phi->init_req(2, reset_memory());\n+    }\n+  }\n+  ne_region->init_req(5, ctl);\n+  ne_io_phi->init_req(5, i_o());\n+  ne_mem_phi->init_req(5, reset_memory());\n+\n+  record_for_igvn(ne_region);\n+  set_control(_gvn.transform(ne_region));\n+  set_i_o(_gvn.transform(ne_io_phi));\n+  set_all_memory(_gvn.transform(ne_mem_phi));\n+\n+  if (btest == BoolTest::ne) {\n+    {\n+      PreserveJVMState pjvms(this);\n+      int target_bci = iter().get_dest();\n+      merge(target_bci);\n+    }\n+\n+    record_for_igvn(eq_region);\n+    set_control(_gvn.transform(eq_region));\n+    set_i_o(_gvn.transform(eq_io_phi));\n+    set_all_memory(_gvn.transform(eq_mem_phi));\n@@ -1662,2 +2279,1 @@\n-void Parse::adjust_map_after_if(BoolTest::mask btest, Node* c, float prob,\n-                                Block* path, Block* other_path) {\n+void Parse::adjust_map_after_if(BoolTest::mask btest, Node* c, float prob, Block* path) {\n@@ -1873,0 +2489,4 @@\n+        if (obj->is_InlineType()) {\n+          assert(obj->as_InlineType()->is_allocated(&_gvn), \"must be allocated\");\n+          obj = obj->as_InlineType()->get_oop();\n+        }\n@@ -2720,14 +3340,19 @@\n-    if (!_gvn.type(b)->speculative_maybe_null() &&\n-        !too_many_traps(Deoptimization::Reason_speculate_null_check)) {\n-      inc_sp(1);\n-      Node* null_ctl = top();\n-      b = null_check_oop(b, &null_ctl, true, true, true);\n-      assert(null_ctl->is_top(), \"no null control here\");\n-      dec_sp(1);\n-    } else if (_gvn.type(b)->speculative_always_null() &&\n-               !too_many_traps(Deoptimization::Reason_speculate_null_assert)) {\n-      inc_sp(1);\n-      b = null_assert(b);\n-      dec_sp(1);\n-    }\n-    c = _gvn.transform( new CmpPNode(b, a) );\n+    if (b->is_InlineType()) {\n+      \/\/ Return constant false because 'b' is always non-null\n+      c = _gvn.makecon(TypeInt::CC_GT);\n+    } else {\n+      if (!_gvn.type(b)->speculative_maybe_null() &&\n+          !too_many_traps(Deoptimization::Reason_speculate_null_check)) {\n+        inc_sp(1);\n+        Node* null_ctl = top();\n+        b = null_check_oop(b, &null_ctl, true, true, true);\n+        assert(null_ctl->is_top(), \"no null control here\");\n+        dec_sp(1);\n+      } else if (_gvn.type(b)->speculative_always_null() &&\n+                 !too_many_traps(Deoptimization::Reason_speculate_null_assert)) {\n+        inc_sp(1);\n+        b = null_assert(b);\n+        dec_sp(1);\n+      }\n+      c = _gvn.transform( new CmpPNode(b, a) );\n+    }\n@@ -2744,3 +3369,1 @@\n-    c = _gvn.transform( new CmpPNode(b, a) );\n-    c = optimize_cmp_with_klass(c);\n-    do_if(btest, c);\n+    do_acmp(btest, a, b);\n@@ -2801,1 +3424,1 @@\n-    do_anewarray();\n+    do_newarray();\n@@ -2812,0 +3435,6 @@\n+  case Bytecodes::_defaultvalue:\n+    do_defaultvalue();\n+    break;\n+  case Bytecodes::_withfield:\n+    do_withfield();\n+    break;\n","filename":"src\/hotspot\/share\/opto\/parse2.cpp","additions":684,"deletions":55,"binary":false,"changes":739,"status":"modified"},{"patch":"@@ -2159,0 +2159,10 @@\n+  if (AMD64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypePassFieldsAsArgs)) {\n+    FLAG_SET_CMDLINE(InlineTypePassFieldsAsArgs, false);\n+    warning(\"InlineTypePassFieldsAsArgs is not supported on this platform\");\n+  }\n+\n+  if (AMD64_ONLY(false &&) !FLAG_IS_DEFAULT(InlineTypeReturnedAsFields)) {\n+    FLAG_SET_CMDLINE(InlineTypeReturnedAsFields, false);\n+    warning(\"InlineTypeReturnedAsFields is not supported on this platform\");\n+  }\n+\n@@ -3081,0 +3091,18 @@\n+  if (EnableValhalla) {\n+    \/\/ create_property(\"valhalla.enableValhalla\", \"true\", InternalProperty)\n+    const char* prop_name = \"valhalla.enableValhalla\";\n+    const char* prop_value = \"true\";\n+    const size_t prop_len = strlen(prop_name) + strlen(prop_value) + 2;\n+    char* property = AllocateHeap(prop_len, mtArguments);\n+    int ret = jio_snprintf(property, prop_len, \"%s=%s\", prop_name, prop_value);\n+    if (ret < 0 || ret >= (int)prop_len) {\n+      FreeHeap(property);\n+      return JNI_ENOMEM;\n+    }\n+    bool added = add_property(property, UnwriteableProperty, InternalProperty);\n+    FreeHeap(property);\n+    if (!added) {\n+      return JNI_ENOMEM;\n+    }\n+  }\n+\n@@ -4170,0 +4198,5 @@\n+  if (!EnableValhalla || (is_interpreter_only() && !is_dumping_archive())) {\n+    \/\/ Disable calling convention optimizations if inline types are not supported\n+    InlineTypePassFieldsAsArgs = false;\n+    InlineTypeReturnedAsFields = false;\n+  }\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -765,0 +765,18 @@\n+  notproduct(bool, PrintInlineLayout, false,                                \\\n+          \"Print field layout for each inline type\")                        \\\n+                                                                            \\\n+  notproduct(bool, PrintFlatArrayLayout, false,                             \\\n+          \"Print array layout for each inline type array\")                  \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxSize, -1,                                \\\n+          \"Max size for flattening inline array elements, <0 no limit\")     \\\n+                                                                            \\\n+  product(intx, InlineFieldMaxFlatSize, 128,                                \\\n+          \"Max size for flattening inline type fields, <0 no limit\")        \\\n+                                                                            \\\n+  product(intx, FlatArrayElementMaxOops, 4,                                 \\\n+          \"Max nof embedded object references in an inline type to flatten, <0 no limit\")  \\\n+                                                                            \\\n+  product(bool, InlineArrayAtomicAccess, false,                             \\\n+          \"Atomic inline array accesses by-default, for all inline arrays\") \\\n+                                                                            \\\n@@ -780,1 +798,1 @@\n-  product(bool, UseBiasedLocking, false,                                    \\\n+  product(bool, UseBiasedLocking, true,                                     \\\n@@ -2455,0 +2473,20 @@\n+  product(bool, EnableValhalla, true,                                       \\\n+          \"Enable experimental Valhalla features\")                          \\\n+                                                                            \\\n+  product_pd(bool, InlineTypePassFieldsAsArgs,                              \\\n+          \"Pass each inline type field as an argument at calls\")            \\\n+                                                                            \\\n+  product_pd(bool, InlineTypeReturnedAsFields,                              \\\n+          \"Return fields instead of an inline type reference\")              \\\n+                                                                            \\\n+  develop(bool, StressInlineTypeReturnedAsFields, false,                    \\\n+          \"Stress return of fields instead of an inline type reference\")    \\\n+                                                                            \\\n+  develop(bool, ScalarizeInlineTypes, true,                                 \\\n+          \"Scalarize inline types in compiled code\")                        \\\n+                                                                            \\\n+  diagnostic(ccstrlist, ForceNonTearable, \"\",                               \\\n+          \"List of inline classes which are forced to be atomic \"           \\\n+          \"(whitespace and commas separate names, \"                         \\\n+          \"and leading and trailing stars '*' are wildcards)\")              \\\n+                                                                            \\\n@@ -2461,0 +2499,1 @@\n+\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":40,"deletions":1,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -50,0 +50,1 @@\n+#include \"oops\/inlineKlass.hpp\"\n@@ -997,0 +998,1 @@\n+    ResourceMark rm;\n@@ -998,2 +1000,25 @@\n-    bool return_oop = nm->method()->is_returning_oop();\n-    Handle return_value;\n+    Method* method = nm->method();\n+    bool return_oop = method->is_returning_oop();\n+\n+    GrowableArray<Handle> return_values;\n+    InlineKlass* vk = NULL;\n+\n+    if (return_oop && InlineTypeReturnedAsFields) {\n+      SignatureStream ss(method->signature());\n+      while (!ss.at_return_type()) {\n+        ss.next();\n+      }\n+      if (ss.type() == T_INLINE_TYPE) {\n+        \/\/ Check if inline type is returned as fields\n+        vk = InlineKlass::returned_inline_klass(map);\n+        if (vk != NULL) {\n+          \/\/ We're at a safepoint at the return of a method that returns\n+          \/\/ multiple values. We must make sure we preserve the oop values\n+          \/\/ across the safepoint.\n+          assert(vk == method->returned_inline_type(thread()), \"bad inline klass\");\n+          vk->save_oop_fields(map, return_values);\n+          return_oop = false;\n+        }\n+      }\n+    }\n+\n@@ -1006,1 +1031,1 @@\n-      return_value = Handle(thread(), result);\n+      return_values.push(Handle(thread(), result));\n@@ -1015,1 +1040,4 @@\n-      caller_fr.set_saved_oop_result(&map, return_value());\n+      assert(return_values.length() == 1, \"only one return value\");\n+      caller_fr.set_saved_oop_result(&map, return_values.pop()());\n+    } else if (vk != NULL) {\n+      vk->restore_oop_results(map, return_values);\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":32,"deletions":4,"binary":false,"changes":36,"status":"modified"},{"patch":"@@ -162,0 +162,13 @@\n+#define CHECK_THROW_NOSYNC_IMSE(obj)  \\\n+  if ((obj)->mark().is_always_locked()) {  \\\n+    ResourceMark rm(THREAD);                \\\n+    THROW_MSG(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n+#define CHECK_THROW_NOSYNC_IMSE_0(obj)  \\\n+    if ((obj)->mark().is_always_locked()) {  \\\n+    ResourceMark rm(THREAD);                  \\\n+    THROW_MSG_0(vmSymbols::java_lang_IllegalMonitorStateException(), obj->klass()->external_name()); \\\n+  }\n+\n+\n@@ -456,0 +469,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -506,1 +520,1 @@\n-\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -564,0 +578,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -609,0 +624,4 @@\n+  if (EnableValhalla && mark.is_always_locked()) {\n+    return;\n+  }\n+  assert(!EnableValhalla || !object->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -672,0 +691,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -686,0 +706,1 @@\n+  assert(!EnableValhalla || !obj->klass()->is_inline_klass(), \"monitor op on inline type\");\n@@ -708,0 +729,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -727,0 +749,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -770,0 +793,1 @@\n+  CHECK_THROW_NOSYNC_IMSE_0(obj);\n@@ -794,0 +818,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -809,0 +834,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -826,0 +852,1 @@\n+  CHECK_THROW_NOSYNC_IMSE(obj);\n@@ -1000,0 +1027,4 @@\n+  if (EnableValhalla && obj->klass()->is_inline_klass()) {\n+    \/\/ VM should be calling bootstrap method\n+    ShouldNotReachHere();\n+  }\n@@ -1132,6 +1163,0 @@\n-\/\/ Deprecated -- use FastHashCode() instead.\n-\n-intptr_t ObjectSynchronizer::identity_hash_value_for(Handle obj) {\n-  return FastHashCode(Thread::current(), obj());\n-}\n-\n@@ -1141,0 +1166,3 @@\n+  if (EnableValhalla && h_obj->mark().is_always_locked()) {\n+    return false;\n+  }\n@@ -1801,0 +1829,4 @@\n+  if (EnableValhalla) {\n+    guarantee(!object->klass()->is_inline_klass(), \"Attempt to inflate inline type\");\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":39,"deletions":7,"binary":false,"changes":46,"status":"modified"},{"patch":"@@ -1045,1 +1045,1 @@\n-  k = ik->array_klass_or_null();\n+  k = k->array_klass_or_null();\n","filename":"src\/hotspot\/share\/services\/heapDumper.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -543,0 +543,9 @@\n+\/\/----------------------------------------------------------------------------------------------------\n+\/\/ Prototyping\n+\/\/ \"Code Missing Here\" macro, un-define when integrating back from prototyping stage and break\n+\/\/ compilation on purpose (i.e. \"forget me not\")\n+#define PROTOTYPE\n+#ifdef PROTOTYPE\n+#define CMH(m)\n+#endif\n+\n@@ -628,6 +637,7 @@\n-  T_VOID        = 14,\n-  T_ADDRESS     = 15,\n-  T_NARROWOOP   = 16,\n-  T_METADATA    = 17,\n-  T_NARROWKLASS = 18,\n-  T_CONFLICT    = 19, \/\/ for stack value type with conflicting contents\n+  T_INLINE_TYPE = 14,\n+  T_VOID        = 15,\n+  T_ADDRESS     = 16,\n+  T_NARROWOOP   = 17,\n+  T_METADATA    = 18,\n+  T_NARROWKLASS = 19,\n+  T_CONFLICT    = 20, \/\/ for stack value type with conflicting contents\n@@ -648,0 +658,1 @@\n+    F(JVM_SIGNATURE_INLINE_TYPE, T_INLINE_TYPE, N) \\\n@@ -673,1 +684,1 @@\n-  return (t == T_OBJECT || t == T_ARRAY);\n+  return (t == T_OBJECT || t == T_ARRAY || t == T_INLINE_TYPE);\n@@ -702,1 +713,2 @@\n-  T_VOID_size        = 0\n+  T_VOID_size        = 0,\n+  T_INLINE_TYPE_size = 1\n@@ -732,0 +744,1 @@\n+  T_INLINE_TYPE_aelem_bytes = 8,\n@@ -735,0 +748,1 @@\n+  T_INLINE_TYPE_aelem_bytes = 4,\n@@ -821,1 +835,1 @@\n-  vtos = 9,             \/\/ tos not cached\n+  vtos = 9,             \/\/ tos not cached,\n@@ -838,1 +852,2 @@\n-    case T_ARRAY  : \/\/ fall through\n+    case T_INLINE_TYPE: \/\/ fall through\n+    case T_ARRAY  :   \/\/ fall through\n@@ -1210,0 +1225,6 @@\n+\/\/ TEMP!!!!\n+\/\/ This should be removed after LW2 arrays are implemented (JDK-8220790).\n+\/\/ It's an alias to (EnableValhalla && (FlatArrayElementMaxSize != 0)),\n+\/\/ which is actually not 100% correct, but works for the current set of C1\/C2\n+\/\/ implementation and test cases.\n+#define UseFlatArray (EnableValhalla && (FlatArrayElementMaxSize != 0))\n","filename":"src\/hotspot\/share\/utilities\/globalDefinitions.hpp","additions":31,"deletions":10,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -314,0 +314,5 @@\n+        \/**\n+         * Used for instances of {@link WithFieldTree}.\n+         *\/\n+        WITH_FIELD(WithFieldTree.class),\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/tree\/Tree.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -218,0 +218,12 @@\n+    \/**\n+     * {@inheritDoc} This implementation calls {@code defaultAction}.\n+     *\n+     * @param node {@inheritDoc}\n+     * @param p {@inheritDoc}\n+     * @return  the result of {@code defaultAction}\n+     *\/\n+    @Override\n+    public R visitWithField(WithFieldTree node, P p) {\n+        return defaultAction(node, p);\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/util\/SimpleTreeVisitor.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -285,0 +285,14 @@\n+    \/**\n+     * {@inheritDoc} This implementation scans the children in left to right order.\n+     *\n+     * @param node  {@inheritDoc}\n+     * @param p  {@inheritDoc}\n+     * @return the result of scanning\n+     *\/\n+    @Override\n+    public R visitWithField(WithFieldTree node, P p) {\n+        R r = scan(node.getField(), p);\n+        r = scanAndReduce(node.getValue(), p, r);\n+        return r;\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/source\/util\/TreeScanner.java","additions":14,"deletions":0,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -223,0 +223,5 @@\n+        \/**\n+         * Warn about issues related to migration of JDK classes.\n+         *\/\n+        MIGRATION(\"migration\"),\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Lint.java","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -99,0 +99,1 @@\n+    private final boolean allowValueBasedClasses;\n@@ -139,1 +140,1 @@\n-\n+        allowValueBasedClasses = options.isSet(\"allowValueBasedClasses\");\n@@ -500,1 +501,1 @@\n-\/* *************************************************************************\n+    \/* *************************************************************************\n@@ -606,0 +607,5 @@\n+        } else {\n+            if (found.hasTag(CLASS)) {\n+                if (inferenceContext != infer.emptyContext)\n+                    checkParameterizationWithValues(pos, found);\n+            }\n@@ -612,0 +618,3 @@\n+            if (found.hasTag(BOT) && types.isValueBased(req)) {\n+                log.warning(pos, Warnings.SuspiciousMixOfNullWithValueBasedClass(req));\n+            }\n@@ -634,0 +643,7 @@\n+            if (types.isValueBased(req)) {\n+                if (found.hasTag(BOT)) {\n+                    log.warning(pos, Warnings.SuspiciousMixOfNullWithValueBasedClass(req));\n+                } else if (!types.isValueBased(found)) {\n+                    log.warning(pos, Warnings.PotentialNullPollution(found));\n+                }\n+            }\n@@ -736,0 +752,43 @@\n+    void checkConstraintsOfInlineSuper(DiagnosticPosition pos, ClassSymbol c) {\n+        for(Type st = types.supertype(c.type); st != Type.noType; st = types.supertype(st)) {\n+            if (st == null || st.tsym == null || st.tsym.kind == ERR)\n+                return;\n+            if  (st.tsym == syms.objectType.tsym)\n+                return;\n+            if (!st.tsym.isAbstract()) {\n+                log.error(pos, Errors.ConcreteSupertypeForInlineClass(c, st));\n+            }\n+            if ((st.tsym.flags() & HASINITBLOCK) != 0) {\n+                log.error(pos, Errors.SuperClassDeclaresInitBlock(c, st));\n+            }\n+            \/\/ No instance fields and no arged constructors both mean inner classes cannot be inline supers.\n+            Type encl = st.getEnclosingType();\n+            if (encl != null && encl.hasTag(CLASS)) {\n+                log.error(pos, Errors.SuperClassCannotBeInner(c, st));\n+            }\n+            for (Symbol s : st.tsym.members().getSymbols(NON_RECURSIVE)) {\n+                switch (s.kind) {\n+                case VAR:\n+                    if ((s.flags() & STATIC) == 0) {\n+                        log.error(pos, Errors.SuperFieldNotAllowed(s, c, st));\n+                    }\n+                    break;\n+                case MTH:\n+                    if ((s.flags() & SYNCHRONIZED) != 0) {\n+                        log.error(pos, Errors.SuperMethodCannotBeSynchronized(s, c, st));\n+                    } else if (s.isConstructor()) {\n+                        MethodSymbol m = (MethodSymbol)s;\n+                        if (m.getParameters().size() > 0) {\n+                            log.error(pos, Errors.SuperConstructorCannotTakeArguments(m, c, st));\n+                        } else {\n+                            if ((m.flags() & (GENERATEDCONSTR | EMPTYNOARGCONSTR)) == 0) {\n+                                log.error(pos, Errors.SuperNoArgConstructorMustBeEmpty(m, c, st));\n+                            }\n+                        }\n+                    }\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n@@ -738,2 +797,2 @@\n-    Type checkConstructorRefType(DiagnosticPosition pos, Type t) {\n-        t = checkClassOrArrayType(pos, t);\n+    Type checkConstructorRefType(JCExpression expr, Type t) {\n+        t = checkClassOrArrayType(expr, t);\n@@ -742,1 +801,1 @@\n-                log.error(pos, Errors.AbstractCantBeInstantiated(t.tsym));\n+                log.error(expr, Errors.AbstractCantBeInstantiated(t.tsym));\n@@ -745,1 +804,1 @@\n-                log.error(pos, Errors.EnumCantBeInstantiated);\n+                log.error(expr, Errors.EnumCantBeInstantiated);\n@@ -748,1 +807,10 @@\n-                t = checkClassType(pos, t, true);\n+                \/\/ Projection types may not be mentioned in constructor references\n+                if (expr.hasTag(SELECT)) {\n+                    JCFieldAccess fieldAccess = (JCFieldAccess) expr;\n+                    if (fieldAccess.selected.type.isValue() &&\n+                            (fieldAccess.name == names.ref || fieldAccess.name == names.val)) {\n+                        log.error(expr, Errors.ProjectionCantBeInstantiated);\n+                        t = types.createErrorType(t);\n+                    }\n+                }\n+                t = checkClassType(expr, t, true);\n@@ -752,1 +820,1 @@\n-                log.error(pos, Errors.GenericArrayCreation);\n+                log.error(expr, Errors.GenericArrayCreation);\n@@ -783,0 +851,1 @@\n+     *  @param valueOK       If false, a value class does not qualify\n@@ -784,2 +853,2 @@\n-    Type checkRefType(DiagnosticPosition pos, Type t) {\n-        if (t.isReference())\n+    Type checkRefType(DiagnosticPosition pos, Type t, boolean valueOK) {\n+        if (t.isReference() && (valueOK || !types.isValue(t)))\n@@ -793,0 +862,9 @@\n+    \/** Check that type is a reference type, i.e. a class, interface or array type\n+     *  or a type variable.\n+     *  @param pos           Position to be used for error reporting.\n+     *  @param t             The type to be checked.\n+     *\/\n+    Type checkRefType(DiagnosticPosition pos, Type t) {\n+        return checkRefType(pos, t, true);\n+    }\n+\n@@ -801,1 +879,1 @@\n-            l.head = checkRefType(tl.head.pos(), l.head);\n+            l.head = checkRefType(tl.head.pos(), l.head, false);\n@@ -837,0 +915,48 @@\n+    void checkParameterizationWithValues(DiagnosticPosition pos, Type t) {\n+        valueParameterizationChecker.visit(t, pos);\n+    }\n+\n+    \/** valueParameterizationChecker: A type visitor that descends down the given type looking for instances of value types\n+     *  being used as type arguments and issues error against those usages.\n+     *\/\n+    private final Types.SimpleVisitor<Void, DiagnosticPosition> valueParameterizationChecker = new Types.SimpleVisitor<Void, DiagnosticPosition>() {\n+\n+        @Override\n+        public Void visitType(Type t, DiagnosticPosition pos) {\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitClassType(ClassType t, DiagnosticPosition pos) {\n+            for (Type targ : t.allparams()) {\n+                if (types.isValue(targ)) {\n+                    log.error(pos, Errors.GenericParameterizationWithValueType(t));\n+                }\n+                visit(targ, pos);\n+            }\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitTypeVar(TypeVar t, DiagnosticPosition pos) {\n+             return null;\n+        }\n+\n+        @Override\n+        public Void visitCapturedType(CapturedType t, DiagnosticPosition pos) {\n+            return null;\n+        }\n+\n+        @Override\n+        public Void visitArrayType(ArrayType t, DiagnosticPosition pos) {\n+            return visit(t.elemtype, pos);\n+        }\n+\n+        @Override\n+        public Void visitWildcardType(WildcardType t, DiagnosticPosition pos) {\n+            return visit(t.type, pos);\n+        }\n+    };\n+\n+\n+\n@@ -985,1 +1111,38 @@\n-        return types.upward(t, types.captures(t));\n+        Type varType = types.upward(t, types.captures(t));\n+        if (varType.hasTag(CLASS)) {\n+            checkParameterizationWithValues(pos, varType);\n+        }\n+        return varType;\n+    }\n+\n+    public void checkForSuspectClassLiteralComparison(\n+            final JCBinary tree,\n+            final Type leftType,\n+            final Type rightType) {\n+\n+        if (lint.isEnabled(LintCategory.MIGRATION)) {\n+            if (isInvocationOfGetClass(tree.lhs) && isClassOfSomeInterface(rightType) ||\n+                    isInvocationOfGetClass(tree.rhs) && isClassOfSomeInterface(leftType)) {\n+                log.warning(LintCategory.MIGRATION, tree.pos(), Warnings.GetClassComparedWithInterface);\n+            }\n+        }\n+    }\n+    \/\/where\n+    private boolean isClassOfSomeInterface(Type someClass) {\n+        if (someClass.tsym.flatName() == names.java_lang_Class) {\n+            List<Type> arguments = someClass.getTypeArguments();\n+            if (arguments.length() == 1) {\n+                return arguments.head.isInterface();\n+            }\n+        }\n+        return false;\n+    }\n+    \/\/where\n+    private boolean isInvocationOfGetClass(JCExpression tree) {\n+        tree = TreeInfo.skipParens(tree);\n+        if (tree.hasTag(APPLY)) {\n+            JCMethodInvocation apply = (JCMethodInvocation)tree;\n+            MethodSymbol msym = (MethodSymbol)TreeInfo.symbol(apply.meth);\n+            return msym.name == names.getClass && msym.implementedIn(syms.objectType.tsym, types) != null;\n+        }\n+        return false;\n@@ -1183,1 +1346,1 @@\n-            else\n+            else {\n@@ -1185,0 +1348,4 @@\n+                if (types.isValue(sym.owner.type) && (flags & STATIC) == 0) {\n+                    implicit |= FINAL;\n+                }\n+            }\n@@ -1212,1 +1379,3 @@\n-                mask = MethodFlags;\n+                \/\/ instance methods of value types do not have a monitor associated with their `this'\n+                mask = ((sym.owner.flags_field & VALUE) != 0 && (flags & Flags.STATIC) == 0) ?\n+                        MethodFlags & ~SYNCHRONIZED : MethodFlags;\n@@ -1248,2 +1417,2 @@\n-                \/\/ enums can't be declared abstract, final, sealed or non-sealed\n-                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED);\n+                \/\/ enums can't be declared abstract, final, sealed or non-sealed or value type\n+                mask &= ~(ABSTRACT | FINAL | SEALED | NON_SEALED | VALUE);\n@@ -1287,1 +1456,1 @@\n-                               FINAL | NATIVE | SYNCHRONIZED)\n+                               FINAL | NATIVE | SYNCHRONIZED | VALUE)\n@@ -1297,1 +1466,1 @@\n-                 checkDisjoint(pos, flags,\n+                 checkDisjoint(pos, (flags | implicit), \/\/ complain against volatile & implcitly final entities too.\n@@ -1471,1 +1640,2 @@\n-                tree.selected.type.isParameterized()) {\n+                tree.selected.type.isParameterized() &&\n+                    (tree.name != names.ref || !tree.type.isReferenceProjection())) {\n@@ -1475,0 +1645,2 @@\n+                \/\/ Tolerate the pseudo-select V.ref: V<T>.ref will be static if V<T> is and\n+                \/\/ should not be confused as selecting a static member of a parameterized type.\n@@ -1801,0 +1973,9 @@\n+        if (origin.isValue() && other.owner == syms.objectType.tsym && m.type.getParameterTypes().size() == 0) {\n+            if (m.name == names.clone || m.name == names.finalize) {\n+                log.error(TreeInfo.diagnosticPositionFor(m, tree),\n+                        Errors.InlineClassMayNotOverride(m.name));\n+                m.flags_field |= BAD_OVERRIDE;\n+                return;\n+            }\n+        }\n+\n@@ -2113,1 +2294,2 @@\n-                (env.info.isAnonymousDiamond && !m.isConstructor() && !m.isPrivate());\n+                (env.info.isAnonymousDiamond && !m.isConstructor() && !m.isPrivate() &&\n+                        (!m.owner.isValue() || (tree.body.flags & SYNTHETIC) == 0));\n@@ -2239,0 +2421,39 @@\n+    \/\/ A value class cannot contain a field of its own type either or indirectly.\n+    void checkNonCyclicMembership(JCClassDecl tree) {\n+        Assert.check((tree.sym.flags_field & LOCKED) == 0);\n+        try {\n+            tree.sym.flags_field |= LOCKED;\n+            for (List<? extends JCTree> l = tree.defs; l.nonEmpty(); l = l.tail) {\n+                if (l.head.hasTag(VARDEF)) {\n+                    JCVariableDecl field = (JCVariableDecl) l.head;\n+                    if (cyclePossible(field.sym)) {\n+                        Type fieldType = field.sym.type;\n+                        checkNonCyclicMembership((ClassSymbol) fieldType.tsym, field.pos());\n+                    }\n+                }\n+            }\n+        } finally {\n+            tree.sym.flags_field &= ~LOCKED;\n+        }\n+\n+    }\n+    \/\/ where\n+    private void checkNonCyclicMembership(ClassSymbol c, DiagnosticPosition pos) {\n+        if ((c.flags_field & LOCKED) != 0) {\n+            log.error(pos, Errors.CyclicValueTypeMembership(c));\n+            return;\n+        }\n+        try {\n+            c.flags_field |= LOCKED;\n+            for (Symbol fld : c.members().getSymbols(s -> s.kind == VAR && cyclePossible((VarSymbol) s), NON_RECURSIVE)) {\n+                checkNonCyclicMembership((ClassSymbol) fld.type.tsym, pos);\n+            }\n+        } finally {\n+            c.flags_field &= ~LOCKED;\n+        }\n+    }\n+        \/\/ where\n+        private boolean cyclePossible(VarSymbol symbol) {\n+            return (symbol.flags() & STATIC) == 0 && types.isValue(symbol.type);\n+        }\n+\n@@ -2487,0 +2708,4 @@\n+\n+        if (c.isValue() && types.asSuper(c, syms.identityObjectType.tsym, true) != null) {\n+            log.error(pos, Errors.InlineTypeMustNotImplementIdentityObject(c));\n+        }\n@@ -3045,0 +3270,7 @@\n+        if (a.annotationType.type.tsym == syms.valueBasedType.tsym) {\n+            if (s.isInterface() || s.isEnum()) {\n+                log.error(a.pos(), Errors.BadValueBasedAnno);\n+            } else if (allowValueBasedClasses) {\n+                s.flags_field |= VALUEBASED;\n+            }\n+        }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":252,"deletions":20,"binary":false,"changes":272,"status":"modified"},{"patch":"@@ -44,0 +44,1 @@\n+import com.sun.tools.javac.jvm.Target;\n@@ -681,0 +682,1 @@\n+            final boolean isValueType = (tree.mods.flags & Flags.VALUE) != 0;\n@@ -732,0 +734,9 @@\n+            if (ct.isValue()) {\n+                ClassSymbol cSym = (ClassSymbol) ct.tsym;\n+                if (cSym.projection != null) {\n+                    ClassType projectedType = (ClassType) cSym.projection.type;\n+                    projectedType.supertype_field = ct.supertype_field;\n+                    projectedType.interfaces_field = ct.interfaces_field;\n+                    projectedType.all_interfaces_field = ct.all_interfaces_field;\n+                }\n+            }\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/TypeEnter.java","additions":11,"deletions":0,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -399,0 +399,4 @@\n+# 0: symbol\n+compiler.err.cyclic.value.type.membership=\\\n+    cyclic inline type membership involving {0}\n+\n@@ -1778,0 +1782,3 @@\n+compiler.warn.get.class.compared.with.interface=\\\n+    return value of getClass() can never equal the class literal of an interface\n+\n@@ -2937,0 +2944,3 @@\n+compiler.misc.feature.inline.type=\\\n+    inline type\n+\n@@ -3718,0 +3728,74 @@\n+\n+# 0: name (of method)\n+compiler.err.inline.class.may.not.override=\\\n+    Inline classes may not override the method {0} from Object\n+\n+# 0: name (of method)\n+compiler.err.value.does.not.support=\\\n+    Inline types do not support {0}\n+\n+compiler.err.value.may.not.extend=\\\n+    Inline type may not extend another inline type or class\n+\n+compiler.err.value.instance.field.expected.here=\\\n+    withfield operator requires an instance field of an inline class here\n+\n+compiler.err.bad.value.based.anno=\\\n+    Unexpected @ValueBased annotation\n+\n+# 0: type\n+compiler.warn.suspicious.mix.of.null.with.value.based.class=\\\n+    Suspicious mix of null with value based class {0}\n+\n+# 0: type\n+compiler.warn.potential.null.pollution=\\\n+    Potential null pollution from nullable type {0}\n+\n+compiler.err.with.field.operator.disallowed=\\\n+    WithField operator is allowed only with -XDallowWithFieldOperator\n+\n+compiler.err.this.exposed.prematurely=\\\n+    Inine type instance should not be passed around before being fully initialized\n+\n+compiler.warn.this.exposed.prematurely=\\\n+    value based type instance should not be passed around before being fully initialized\n+\n+# 0: type\n+compiler.err.generic.parameterization.with.value.type=\\\n+    Inferred type {0} involves generic parameterization by an inline type\n+\n+# 0: type\n+compiler.err.inline.type.must.not.implement.identity.object=\\\n+    The inline type {0} attempts to implement the incompatible interface IdentityObject\n+\n+# 0: symbol, 1: type\n+compiler.err.concrete.supertype.for.inline.class=\\\n+    The concrete class {1} is not allowed to be a super class of the inline class {0} either directly or indirectly\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.method.cannot.be.synchronized=\\\n+    The method {0} in the super class {2} of the inline type {1} is synchronized. This is disallowed\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.constructor.cannot.take.arguments=\\\n+    The super class {2} of the inline type {1} defines a constructor {0} that takes arguments. This is disallowed\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.field.not.allowed=\\\n+    The super class {2} of the inline type {1} defines an instance field {0}. This is disallowed\n+\n+# 0: symbol, 1: symbol, 2: type\n+compiler.err.super.no.arg.constructor.must.be.empty=\\\n+    The super class {2} of the inline type {1} defines a nonempty no-arg constructor {0}. This is disallowed\n+\n+# 0: symbol, 1: type\n+compiler.err.super.class.declares.init.block=\\\n+    The super class {1} of the inline class {0} declares one or more non-empty instance initializer blocks. This is disallowed.\n+\n+# 0: symbol, 1: type\n+compiler.err.super.class.cannot.be.inner=\\\n+    The super class {1} of the inline class {0} is an inner class. This is disallowed.\n+\n+compiler.err.projection.cant.be.instantiated=\\\n+    Illegal attempt to instantiate a projection type\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/compiler.properties","additions":84,"deletions":0,"binary":false,"changes":84,"status":"modified"},{"patch":"@@ -212,0 +212,3 @@\n+javac.opt.Xlint.desc.migration=\\\n+    Warn about issues related to migration of JDK classes.\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/resources\/javac.properties","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -781,0 +781,12 @@\n+    public void visitWithField(JCWithField tree) {\n+        try {\n+            print(\"__WithField(\");\n+            printExpr(tree.field);\n+            print(\", \");\n+            printExpr(tree.value);\n+            print(\")\");\n+        } catch (IOException e) {\n+            throw new UncheckedIOException(e);\n+        }\n+    }\n+\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/tree\/Pretty.java","additions":12,"deletions":0,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -2574,1 +2574,1 @@\n-        return isKind(doctree, VALUE);\n+        return isKind(doctree, Kind.VALUE);\n","filename":"src\/jdk.javadoc\/share\/classes\/jdk\/javadoc\/internal\/doclets\/toolkit\/util\/Utils.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -65,0 +65,77 @@\n+# Valhalla\n+compiler\/arguments\/CheckCICompilerCount.java                        8205030 generic-all\n+compiler\/arguments\/CheckCompileThresholdScaling.java                8205030 generic-all\n+compiler\/codecache\/CheckSegmentedCodeCache.java                     8205030 generic-all\n+compiler\/codecache\/cli\/TestSegmentedCodeCacheOption.java            8205030 generic-all\n+compiler\/codecache\/cli\/codeheapsize\/TestCodeHeapSizeOptions.java    8205030 generic-all\n+compiler\/codecache\/cli\/printcodecache\/TestPrintCodeCacheOption.java 8205030 generic-all\n+compiler\/whitebox\/OSRFailureLevel4Test.java                         8205030 generic-all\n+\n+compiler\/aot\/cli\/DisabledAOTWithLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/SingleAOTOptionTest.java 8226295 generic-all\n+compiler\/aot\/cli\/MultipleAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileClassWithDebugTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileModuleTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/AtFileTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionWrongFileTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ClasspathOptionUnknownClassTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileDirectoryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/ListOptionNotExistingTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileClassTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileJarTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/IgnoreErrorsTest.java 8226295 generic-all\n+compiler\/aot\/cli\/jaotc\/CompileAbsoluteDirectoryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/NonExistingAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/SingleAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/cli\/IncorrectAOTLibraryTest.java 8226295 generic-all\n+compiler\/aot\/RecompilationTest.java 8226295 generic-all\n+compiler\/aot\/SharedUsageTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/ClassSearchTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/SearchPathTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/module\/ModuleSourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/ClassSourceTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/directory\/DirectorySourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/collect\/jar\/JarSourceProviderTest.java 8226295 generic-all\n+compiler\/aot\/jdk.tools.jaotc.test\/src\/jdk\/tools\/jaotc\/test\/NativeOrderOutputStreamTest.java 8226295 generic-all\n+compiler\/aot\/verification\/vmflags\/TrackedFlagTest.java 8226295 generic-all\n+compiler\/aot\/verification\/vmflags\/NotTrackedFlagTest.java 8226295 generic-all\n+compiler\/aot\/verification\/ClassAndLibraryNotMatchTest.java 8226295 generic-all\n+compiler\/aot\/DeoptimizationTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeInterface2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeDynamic2CompiledTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeStatic2NativeTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromAot\/AotInvokeSpecial2InterpretedTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromNative\/NativeInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromCompiled\/CompiledInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeDynamic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeStatic2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeVirtual2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeSpecial2AotTest.java 8226295 generic-all\n+compiler\/aot\/calls\/fromInterpreted\/InterpretedInvokeInterface2AotTest.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SelfChanged.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SelfChangedCDS.java 8226295 generic-all\n+compiler\/aot\/fingerprint\/SuperChanged.java 8226295 generic-all\n+\n@@ -89,0 +166,22 @@\n+# Valhalla TODO:\n+runtime\/CompressedOops\/CompressedClassPointers.java 8210258 generic-all\n+runtime\/RedefineTests\/RedefineLeak.java 8205032 generic-all\n+runtime\/SharedArchiveFile\/BootAppendTests.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/CdsDifferentCompactStrings.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/CdsDifferentObjectAlignment.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/NonBootLoaderClasses.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/PrintSharedArchiveAndExit.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedArchiveFile.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedStringsDedup.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedStringsRunAuto.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SharedSymbolTableBucketSize.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/SpaceUtilizationCheck.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/TestInterpreterMethodEntries.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformInterfaceAndImplementor.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformSuperAndSubClasses.java 8210258 generic-all\n+runtime\/SharedArchiveFile\/serviceability\/transformRelatedClasses\/TransformSuperSubTwoPckgs.java 8210258 generic-all\n+runtime\/appcds\/ClassLoaderTest.java 8210258 generic-all\n+runtime\/appcds\/HelloTest.java 8210258 generic-all\n+runtime\/appcds\/sharedStrings\/SharedStringsBasic.java 8210258 generic-all\n+\n+\n@@ -102,0 +201,26 @@\n+# Valhalla TODO:\n+serviceability\/sa\/ClhsdbCDSCore.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbCDSJstackPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbFindPC.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbInspect.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJdis.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbJstack.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAll.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintAs.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbPrintStatics.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSource.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbSymbol.java 8190936 generic-all\n+serviceability\/sa\/ClhsdbWhere.java 8190936 generic-all\n+serviceability\/sa\/JhsdbThreadInfoTest.java 8190936 generic-all\n+serviceability\/sa\/TestClassDump.java 8190936 generic-all\n+serviceability\/sa\/TestClhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestCpoolForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForInvokeDynamic.java 8190936 generic-all\n+serviceability\/sa\/TestHeapDumpForLargeArray.java 8190936 generic-all\n+serviceability\/sa\/TestIntConstant.java 8190936 generic-all\n+serviceability\/sa\/TestJhsdbJstackLock.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCore.java 8190936 generic-all\n+serviceability\/sa\/TestJmapCoreMetaspace.java 8190936 generic-all\n+serviceability\/sa\/TestPrintMdo.java 8190936 generic-all\n+serviceability\/sa\/jmap-hprof\/JMapHProfLargeHeapTest.java 8190936 generic-all\n+\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":125,"deletions":0,"binary":false,"changes":125,"status":"modified"}]}