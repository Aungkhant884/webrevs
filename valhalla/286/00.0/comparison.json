{"files":[{"patch":"@@ -20,1 +20,1 @@\n-    runs-on: \"ubuntu-latest\"\n+    runs-on: \"ubuntu-20.04\"\n@@ -84,1 +84,1 @@\n-        run: sh make\/build-all.sh ${JAVA_HOME}\n+        run: sh make\/build-all.sh ${JAVA_HOME_8_X64}\n@@ -102,1 +102,1 @@\n-    runs-on: \"ubuntu-latest\"\n+    runs-on: \"ubuntu-20.04\"\n@@ -112,3 +112,0 @@\n-          - build hotspot no-pch\n-          - build hotspot minimal\n-          - build hotspot optimized\n@@ -119,9 +116,0 @@\n-          - flavor: build hotspot no-pch\n-            flags: --enable-debug --disable-precompiled-headers\n-            build-target: hotspot\n-          - flavor: build hotspot minimal\n-            flags: --enable-debug --disable-precompiled-headers --with-jvm-variants=minimal\n-            build-target: hotspot\n-          - flavor: build hotspot optimized\n-            flags: --with-debug-level=optimized --disable-precompiled-headers\n-            build-target: hotspot\n@@ -181,1 +169,4 @@\n-        run: sudo apt-get install libxrandr-dev libxtst-dev libcups2-dev libasound2-dev\n+        run: |\n+          sudo apt-get update\n+          sudo apt-get install gcc-10=10.2.0-5ubuntu1~20.04 g++-10=10.2.0-5ubuntu1~20.04 libxrandr-dev libxtst-dev libcups2-dev libasound2-dev\n+          sudo update-alternatives --install \/usr\/bin\/gcc gcc \/usr\/bin\/gcc-10 100 --slave \/usr\/bin\/g++ g++ \/usr\/bin\/g++-10\n@@ -199,1 +190,1 @@\n-        run: make CONF_NAME=linux-x64 ${{ matrix.build-target }}\n+        run: make CONF_NAME=linux-x64\n@@ -209,1 +200,0 @@\n-        if: matrix.build-target == false\n@@ -213,1 +203,1 @@\n-    runs-on: \"ubuntu-latest\"\n+    runs-on: \"ubuntu-20.04\"\n@@ -474,2 +464,2 @@\n-          Start-Process -FilePath 'C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vs_installer.exe' -Wait -NoNewWindow -ArgumentList \n-          'modify --installPath \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\" --quiet \n+          Start-Process -FilePath 'C:\\Program Files (x86)\\Microsoft Visual Studio\\Installer\\vs_installer.exe' -Wait -NoNewWindow -ArgumentList\n+          'modify --installPath \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Enterprise\" --quiet\n@@ -500,1 +490,1 @@\n-          & make CONF_NAME=windows-x64 ${{ matrix.build-target }}\n+          & make CONF_NAME=windows-x64\n@@ -511,1 +501,0 @@\n-        if: matrix.build-target == false\n@@ -805,1 +794,1 @@\n-        run: make CONF_NAME=macos-x64 ${{ matrix.build-target }}\n+        run: make CONF_NAME=macos-x64\n@@ -815,1 +804,0 @@\n-        if: matrix.build-target == false\n@@ -1004,1 +992,1 @@\n-    runs-on: \"ubuntu-latest\"\n+    runs-on: \"ubuntu-20.04\"\n","filename":".github\/workflows\/submit.yml","additions":14,"deletions":26,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -13,1 +13,2 @@\n-files=.*\\.cpp|.*\\.hpp|.*\\.c|.*\\.h|.*\\.java|.*\\.cc|.*\\.hh|.*\\.m|.*\\.mm\n+files=.*\\.cpp|.*\\.hpp|.*\\.c|.*\\.h|.*\\.java|.*\\.cc|.*\\.hh|.*\\.m|.*\\.mm|.*\\.gmk|.*\\.m4|.*\\.ac|Makefile\n+ignore-tabs=.*\\.gmk|Makefile\n","filename":".jcheck\/conf","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -1773,0 +1773,5 @@\n+int MachCallNativeNode::ret_addr_offset() {\n+  ShouldNotReachHere();\n+  return -1;\n+}\n+\n@@ -13932,0 +13937,28 @@\n+instruct absdF_reg(vRegF dst, vRegF src1, vRegF src2) %{\n+  match(Set dst (AbsF (SubF src1 src2)));\n+\n+  ins_cost(INSN_COST * 3);\n+  format %{ \"fabds   $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ fabds(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+\n+  ins_pipe(fp_uop_s);\n+%}\n+\n+instruct absdD_reg(vRegD dst, vRegD src1, vRegD src2) %{\n+  match(Set dst (AbsD (SubD src1 src2)));\n+\n+  ins_cost(INSN_COST * 3);\n+  format %{ \"fabdd   $dst, $src1, $src2\" %}\n+  ins_encode %{\n+    __ fabdd(as_FloatRegister($dst$$reg),\n+             as_FloatRegister($src1$$reg),\n+             as_FloatRegister($src2$$reg));\n+  %}\n+\n+  ins_pipe(fp_uop_d);\n+%}\n+\n@@ -17910,123 +17943,0 @@\n-\/\/ --------------------------------- ABS --------------------------------------\n-\n-instruct vabs8B(vecD dst, vecD src)\n-%{\n-  predicate(n->as_Vector()->length() == 4 ||\n-            n->as_Vector()->length() == 8);\n-  match(Set dst (AbsVB src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (8B)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T8B, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical64);\n-%}\n-\n-instruct vabs16B(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 16);\n-  match(Set dst (AbsVB src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (16B)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T16B, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-instruct vabs4S(vecD dst, vecD src)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AbsVS src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (4H)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T4H, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical64);\n-%}\n-\n-instruct vabs8S(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 8);\n-  match(Set dst (AbsVS src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (8H)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T8H, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-instruct vabs2I(vecD dst, vecD src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AbsVI src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical64);\n-%}\n-\n-instruct vabs4I(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AbsVI src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-instruct vabs2L(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AbsVL src));\n-  ins_cost(INSN_COST);\n-  format %{ \"abs  $dst, $src\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ absr(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vlogical128);\n-%}\n-\n-instruct vabs2F(vecD dst, vecD src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AbsVF src));\n-  ins_cost(INSN_COST * 3);\n-  format %{ \"fabs  $dst,$src\\t# vector (2S)\" %}\n-  ins_encode %{\n-    __ fabs(as_FloatRegister($dst$$reg), __ T2S, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp64);\n-%}\n-\n-instruct vabs4F(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 4);\n-  match(Set dst (AbsVF src));\n-  ins_cost(INSN_COST * 3);\n-  format %{ \"fabs  $dst,$src\\t# vector (4S)\" %}\n-  ins_encode %{\n-    __ fabs(as_FloatRegister($dst$$reg), __ T4S, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp128);\n-%}\n-\n-instruct vabs2D(vecX dst, vecX src)\n-%{\n-  predicate(n->as_Vector()->length() == 2);\n-  match(Set dst (AbsVD src));\n-  ins_cost(INSN_COST * 3);\n-  format %{ \"fabs  $dst,$src\\t# vector (2D)\" %}\n-  ins_encode %{\n-    __ fabs(as_FloatRegister($dst$$reg), __ T2D, as_FloatRegister($src$$reg));\n-  %}\n-  ins_pipe(vunop_fp128);\n-%}\n-\n","filename":"src\/hotspot\/cpu\/aarch64\/aarch64.ad","additions":33,"deletions":123,"binary":false,"changes":156,"status":"modified"},{"patch":"@@ -3127,1 +3127,0 @@\n-  __ maybe_isb();\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_LIRAssembler_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -83,1 +83,0 @@\n-  maybe_isb();\n","filename":"src\/hotspot\/cpu\/aarch64\/c1_Runtime1_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -223,1 +223,0 @@\n-  ExternalAddress cardtable((address) ct->byte_map_base());\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/g1\/g1BarrierSetAssembler_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -322,6 +322,3 @@\n-    \/\/ Create mask of live registers\n-    RegMask live = stub->live();\n-\n-    while (live.is_NotEmpty()) {\n-      const OptoReg::Name opto_reg = live.find_first_elem();\n-      live.Remove(opto_reg);\n+    RegMaskIterator rmi(stub->live());\n+    while (rmi.has_next()) {\n+      const OptoReg::Name opto_reg = rmi.next();\n","filename":"src\/hotspot\/cpu\/aarch64\/gc\/z\/zBarrierSetAssembler_aarch64.cpp","additions":3,"deletions":6,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -1654,1 +1654,1 @@\n-    stop(\"InterpreterMacroAssembler::call_VM_leaf_base:\"\n+    stop(\"InterpreterMacroAssembler::call_VM_base:\"\n","filename":"src\/hotspot\/cpu\/aarch64\/interp_masm_aarch64.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1393,1 +1393,0 @@\n-  maybe_isb();\n@@ -4455,4 +4454,9 @@\n-  InstructionMark im(this);\n-  code_section()->relocate(inst_mark(), rtype);\n-  ldrw(zr, Address(r, 0));\n-  return inst_mark();\n+  address mark;\n+  {\n+    InstructionMark im(this);\n+    code_section()->relocate(inst_mark(), rtype);\n+    ldrw(zr, Address(r, 0));\n+    mark = inst_mark();\n+  }\n+  verify_cross_modify_fence_not_required();\n+  return mark;\n@@ -4493,12 +4497,3 @@\n-  if (is_valid_AArch64_address((address)byte_map_base)) {\n-    \/\/ Strictly speaking the byte_map_base isn't an address at all,\n-    \/\/ and it might even be negative.\n-    uint64_t offset;\n-    adrp(reg, ExternalAddress((address)byte_map_base), offset);\n-    \/\/ We expect offset to be zero with most collectors.\n-    if (offset != 0) {\n-      add(reg, reg, offset);\n-    }\n-  } else {\n-    mov(reg, (uint64_t)byte_map_base);\n-  }\n+  \/\/ Strictly speaking the byte_map_base isn't an address at all, and it might\n+  \/\/ even be negative. It is thus materialised as a constant.\n+  mov(reg, (uint64_t)byte_map_base);\n@@ -4523,0 +4518,1 @@\n+  verify_cross_modify_fence_not_required();\n@@ -5722,0 +5718,26 @@\n+\n+void MacroAssembler::safepoint_isb() {\n+  isb();\n+#ifndef PRODUCT\n+  if (VerifyCrossModifyFence) {\n+    \/\/ Clear the thread state.\n+    strb(zr, Address(rthread, in_bytes(JavaThread::requires_cross_modify_fence_offset())));\n+  }\n+#endif\n+}\n+\n+#ifndef PRODUCT\n+void MacroAssembler::verify_cross_modify_fence_not_required() {\n+  if (VerifyCrossModifyFence) {\n+    \/\/ Check if thread needs a cross modify fence.\n+    ldrb(rscratch1, Address(rthread, in_bytes(JavaThread::requires_cross_modify_fence_offset())));\n+    Label fence_not_required;\n+    cbz(rscratch1, fence_not_required);\n+    \/\/ If it does then fail.\n+    lea(rscratch1, CAST_FROM_FN_PTR(address, JavaThread::verify_cross_modify_fence_failure));\n+    mov(c_rarg0, rthread);\n+    blr(rscratch1);\n+    bind(fence_not_required);\n+  }\n+}\n+#endif\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.cpp","additions":39,"deletions":17,"binary":false,"changes":56,"status":"modified"},{"patch":"@@ -1352,2 +1352,3 @@\n-  \/\/ ISB may be needed because of a safepoint\n-  void maybe_isb() { isb(); }\n+\n+  \/\/ Place an ISB after code may have been modified due to a safepoint.\n+  void safepoint_isb();\n@@ -1429,0 +1430,5 @@\n+\n+private:\n+  \/\/ Check the current thread doesn't need a cross modify fence.\n+  void verify_cross_modify_fence_not_required() PRODUCT_RETURN;\n+\n","filename":"src\/hotspot\/cpu\/aarch64\/macroAssembler_aarch64.hpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -462,1 +462,4 @@\n-  __ maybe_isb();\n+\n+  \/\/ Explicit isb required because fixup_callers_callsite may change the code\n+  \/\/ stream.\n+  __ safepoint_isb();\n@@ -1420,1 +1423,0 @@\n-    __ maybe_isb();\n@@ -1463,1 +1465,1 @@\n-  } else if (iid == vmIntrinsics::_invokeBasic) {\n+  } else if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n@@ -2129,1 +2131,1 @@\n-  \/\/ check for safepoint operation in progress and\/or pending suspend requests\n+  \/\/ Check for safepoint operation in progress and\/or pending suspend requests.\n@@ -2353,1 +2355,1 @@\n-    __ maybe_isb();\n+\n@@ -3059,1 +3061,0 @@\n-  __ maybe_isb();\n@@ -3166,2 +3167,0 @@\n-  __ maybe_isb();\n-\n@@ -3289,1 +3288,2 @@\n-  __ maybe_isb();\n+  \/\/ handle_exception_C is a special VM call which does not require an explicit\n+  \/\/ instruction sync afterwards.\n@@ -3446,0 +3446,7 @@\n+\n+BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n+                                           int shadow_space_bytes,\n+                                           const GrowableArray<VMReg>& input_registers,\n+                                           const GrowableArray<VMReg>& output_registers) {\n+  return NULL;\n+}\n","filename":"src\/hotspot\/cpu\/aarch64\/sharedRuntime_aarch64.cpp","additions":16,"deletions":9,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -5647,1 +5647,0 @@\n-    __ maybe_isb();\n","filename":"src\/hotspot\/cpu\/aarch64\/stubGenerator_aarch64.cpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -1367,1 +1367,0 @@\n-  __ maybe_isb();\n@@ -1420,1 +1419,0 @@\n-    __ maybe_isb();\n","filename":"src\/hotspot\/cpu\/aarch64\/templateInterpreterGenerator_aarch64.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -1342,1 +1342,1 @@\n-  __ ld(return_pc, _abi(lr), R1_SP);\n+  __ ld(return_pc, _abi0(lr), R1_SP);\n","filename":"src\/hotspot\/cpu\/ppc\/c1_LIRAssembler_ppc.cpp","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -775,1 +775,1 @@\n-    ld(return_pc, _abi(lr), Rscratch1); \/\/ LR\n+    ld(return_pc, _abi0(lr), Rscratch1); \/\/ LR\n@@ -852,1 +852,1 @@\n-    ld_ptr(R11_scratch1, _abi(callers_sp), R1_SP); \/\/ Load frame pointer.\n+    ld_ptr(R11_scratch1, _abi0(callers_sp), R1_SP); \/\/ Load frame pointer.\n","filename":"src\/hotspot\/cpu\/ppc\/interp_masm_ppc_64.cpp","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -1899,0 +1899,14 @@\n+\n+void C2_MacroAssembler::genmask(Register dst, Register len, Register temp) {\n+  if (ArrayCopyPartialInlineSize <= 32) {\n+    mov64(dst, 1);\n+    shlxq(dst, dst, len);\n+    decq(dst);\n+  } else {\n+    mov64(dst, -1);\n+    movq(temp, len);\n+    negptr(temp);\n+    addptr(temp, 64);\n+    shrxq(dst, dst, temp);\n+  }\n+}\n@@ -1945,0 +1959,9 @@\n+void C2_MacroAssembler::evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len) {\n+  MacroAssembler::evmovdqu(type, kmask, dst, src, vector_len);\n+}\n+\n+void C2_MacroAssembler::evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len) {\n+  MacroAssembler::evmovdqu(type, kmask, dst, src, vector_len);\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/c2_MacroAssembler_x86.cpp","additions":23,"deletions":0,"binary":false,"changes":23,"status":"modified"},{"patch":"@@ -350,0 +350,5 @@\n+\n+  if (jfa->saved_rbp_address()) {\n+    update_map_with_saved_link(map, jfa->saved_rbp_address());\n+  }\n+\n","filename":"src\/hotspot\/cpu\/x86\/frame_x86.cpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"utilities\/debug.hpp\"\n@@ -269,0 +270,2 @@\n+  \/\/ Generated code assumes that buffer index is pointer sized.\n+  STATIC_ASSERT(in_bytes(SATBMarkQueue::byte_width_of_index()) == sizeof(intptr_t));\n@@ -319,12 +322,7 @@\n-  __ cmpl(queue_index, 0);\n-  __ jcc(Assembler::equal, runtime);\n-  __ subl(queue_index, wordSize);\n-  __ movptr(tmp2, buffer);\n-#ifdef _LP64\n-  __ movslq(rscratch1, queue_index);\n-  __ addq(tmp2, rscratch1);\n-  __ movq(Address(tmp2, 0), card_addr);\n-#else\n-  __ addl(tmp2, queue_index);\n-  __ movl(Address(tmp2, 0), card_addr);\n-#endif\n+  __ movptr(tmp2, queue_index);\n+  __ testptr(tmp2, tmp2);\n+  __ jcc(Assembler::zero, runtime);\n+  __ subptr(tmp2, wordSize);\n+  __ movptr(queue_index, tmp2);\n+  __ addptr(tmp2, buffer);\n+  __ movptr(Address(tmp2, 0), card_addr);\n@@ -480,0 +478,3 @@\n+  \/\/ Generated code assumes that buffer index is pointer sized.\n+  STATIC_ASSERT(in_bytes(SATBMarkQueue::byte_width_of_index()) == sizeof(intptr_t));\n+\n","filename":"src\/hotspot\/cpu\/x86\/gc\/g1\/g1BarrierSetAssembler_x86.cpp","additions":13,"deletions":12,"binary":false,"changes":25,"status":"modified"},{"patch":"@@ -485,2 +485,3 @@\n-    while (live.is_NotEmpty()) {\n-      const OptoReg::Name opto_reg = live.find_first_elem();\n+    RegMaskIterator rmi(live);\n+    while (rmi.has_next()) {\n+      const OptoReg::Name opto_reg = rmi.next();\n@@ -489,2 +490,0 @@\n-      live.Remove(opto_reg);\n-\n","filename":"src\/hotspot\/cpu\/x86\/gc\/z\/zBarrierSetAssembler_x86.cpp","additions":3,"deletions":4,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -754,14 +754,0 @@\n-void MacroAssembler::reset_last_Java_frame(bool clear_fp) {\n-  \/\/ we must set sp to zero to clear frame\n-  movptr(Address(r15_thread, JavaThread::last_Java_sp_offset()), NULL_WORD);\n-  \/\/ must clear fp, so that compiled frames are not confused; it is\n-  \/\/ possible that we need it only for debugging\n-  if (clear_fp) {\n-    movptr(Address(r15_thread, JavaThread::last_Java_fp_offset()), NULL_WORD);\n-  }\n-\n-  \/\/ Always clear the pc because it could have been set by make_walkable()\n-  movptr(Address(r15_thread, JavaThread::last_Java_pc_offset()), NULL_WORD);\n-  vzeroupper();\n-}\n-\n@@ -2055,4 +2041,0 @@\n-void MacroAssembler::fld_x(AddressLiteral src) {\n-  Assembler::fld_x(as_Address(src));\n-}\n-\n@@ -2266,0 +2248,4 @@\n+void MacroAssembler::fld_x(AddressLiteral src) {\n+  Assembler::fld_x(as_Address(src));\n+}\n+\n@@ -2880,0 +2866,4 @@\n+void MacroAssembler::reset_last_Java_frame(bool clear_fp) {\n+  reset_last_Java_frame(r15_thread, clear_fp);\n+}\n+\n@@ -2886,1 +2876,3 @@\n-  movptr(Address(java_thread, JavaThread::last_Java_sp_offset()), NULL_WORD);\n+  movslq(Address(java_thread, JavaThread::last_Java_sp_offset()), NULL_WORD);\n+  \/\/ must clear fp, so that compiled frames are not confused; it is\n+  \/\/ possible that we need it only for debugging\n@@ -2888,1 +2880,1 @@\n-    movptr(Address(java_thread, JavaThread::last_Java_fp_offset()), NULL_WORD);\n+    movslq(Address(java_thread, JavaThread::last_Java_fp_offset()), NULL_WORD);\n@@ -2890,3 +2882,2 @@\n-\n-  movptr(Address(java_thread, JavaThread::last_Java_pc_offset()), NULL_WORD);\n-\n+  movslq(Address(java_thread, JavaThread::last_Java_pc_offset()), NULL_WORD);\n+  movslq(Address(java_thread, JavaThread::saved_rbp_address_offset()), NULL_WORD);\n@@ -8697,0 +8688,50 @@\n+\n+void MacroAssembler::evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+      evmovdqub(dst, kmask, src, false, vector_len);\n+      break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evmovdquw(dst, kmask, src, false, vector_len);\n+      break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evmovdqul(dst, kmask, src, false, vector_len);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evmovdquq(dst, kmask, src, false, vector_len);\n+      break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+void MacroAssembler::evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len) {\n+  switch(type) {\n+    case T_BYTE:\n+    case T_BOOLEAN:\n+      evmovdqub(dst, kmask, src, true, vector_len);\n+      break;\n+    case T_CHAR:\n+    case T_SHORT:\n+      evmovdquw(dst, kmask, src, true, vector_len);\n+      break;\n+    case T_INT:\n+    case T_FLOAT:\n+      evmovdqul(dst, kmask, src, true, vector_len);\n+      break;\n+    case T_LONG:\n+    case T_DOUBLE:\n+      evmovdquq(dst, kmask, src, true, vector_len);\n+      break;\n+    default:\n+      fatal(\"Unexpected type argument %s\", type2name(type));\n+      break;\n+  }\n+}\n+\n+\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.cpp","additions":64,"deletions":23,"binary":false,"changes":87,"status":"modified"},{"patch":"@@ -877,0 +877,1 @@\n+  void call(Address addr) { Assembler::call(addr); }\n@@ -931,3 +932,0 @@\n-  void fld_x(Address src) { Assembler::fld_x(src); }\n-  void fld_x(AddressLiteral src);\n-\n@@ -938,0 +936,3 @@\n+  void fld_x(Address src) { Assembler::fld_x(src); }\n+  void fld_x(AddressLiteral src);\n+\n@@ -1154,0 +1155,3 @@\n+  void evmovdqu(BasicType type, KRegister kmask, Address dst, XMMRegister src, int vector_len);\n+  void evmovdqu(BasicType type, KRegister kmask, XMMRegister dst, Address src, int vector_len);\n+\n@@ -1158,0 +1162,1 @@\n+  void evmovdqub(Address dst, KRegister mask, XMMRegister src, bool merge, int vector_len) { Assembler::evmovdqub(dst, mask, src, merge, vector_len); }\n","filename":"src\/hotspot\/cpu\/x86\/macroAssembler_x86.hpp","additions":8,"deletions":3,"binary":false,"changes":11,"status":"modified"},{"patch":"@@ -223,0 +223,7 @@\n+  \/\/ No need in interpreter entry for linkToNative for now.\n+  \/\/ Interpreter calls compiled entry through i2c.\n+  if (iid == vmIntrinsics::_linkToNative) {\n+    __ hlt();\n+    return NULL;\n+  }\n+\n@@ -334,1 +341,4 @@\n-  if (iid == vmIntrinsics::_invokeBasic) {\n+  if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n+    if (iid == vmIntrinsics::_linkToNative) {\n+      assert(for_compiler_entry, \"only compiler entry is supported\");\n+    }\n@@ -535,0 +545,6 @@\n+    \/\/ Note: We want to allow trace_method_handle from any call site.\n+    \/\/ While trace_method_handle creates a frame, it may be entered\n+    \/\/ without a PC on the stack top (e.g. not just after a call).\n+    \/\/ Walking that frame could lead to failures due to that invalid PC.\n+    \/\/ => carefully detect that frame when doing the stack walking\n+\n@@ -543,6 +559,0 @@\n-      \/\/ Note: We want to allow trace_method_handle from any call site.\n-      \/\/ While trace_method_handle creates a frame, it may be entered\n-      \/\/ without a PC on the stack top (e.g. not just after a call).\n-      \/\/ Walking that frame could lead to failures due to that invalid PC.\n-      \/\/ => carefully detect that frame when doing the stack walking\n-\n@@ -552,28 +562,29 @@\n-      \/\/ Robust search of trace_calling_frame (independant of inlining).\n-      \/\/ Assumes saved_regs comes from a pusha in the trace_calling_frame.\n-      assert(cur_frame.sp() < saved_regs, \"registers not saved on stack ?\");\n-      frame trace_calling_frame = os::get_sender_for_C_frame(&cur_frame);\n-      while (trace_calling_frame.fp() < saved_regs) {\n-        trace_calling_frame = os::get_sender_for_C_frame(&trace_calling_frame);\n-      }\n-\n-      \/\/ safely create a frame and call frame::describe\n-      intptr_t *dump_sp = trace_calling_frame.sender_sp();\n-      intptr_t *dump_fp = trace_calling_frame.link();\n-\n-      bool walkable = has_mh; \/\/ whether the traced frame shoud be walkable\n-\n-      if (walkable) {\n-        \/\/ The previous definition of walkable may have to be refined\n-        \/\/ if new call sites cause the next frame constructor to start\n-        \/\/ failing. Alternatively, frame constructors could be\n-        \/\/ modified to support the current or future non walkable\n-        \/\/ frames (but this is more intrusive and is not considered as\n-        \/\/ part of this RFE, which will instead use a simpler output).\n-        frame dump_frame = frame(dump_sp, dump_fp);\n-        dump_frame.describe(values, 1);\n-      } else {\n-        \/\/ Stack may not be walkable (invalid PC above FP):\n-        \/\/ Add descriptions without building a Java frame to avoid issues\n-        values.describe(-1, dump_fp, \"fp for #1 <not parsed, cannot trust pc>\");\n-        values.describe(-1, dump_sp, \"sp for #1\");\n+      if (cur_frame.fp() != 0) {  \/\/ not walkable\n+\n+        \/\/ Robust search of trace_calling_frame (independent of inlining).\n+        \/\/ Assumes saved_regs comes from a pusha in the trace_calling_frame.\n+        assert(cur_frame.sp() < saved_regs, \"registers not saved on stack ?\");\n+        frame trace_calling_frame = os::get_sender_for_C_frame(&cur_frame);\n+        while (trace_calling_frame.fp() < saved_regs) {\n+          trace_calling_frame = os::get_sender_for_C_frame(&trace_calling_frame);\n+        }\n+\n+        \/\/ safely create a frame and call frame::describe\n+        intptr_t *dump_sp = trace_calling_frame.sender_sp();\n+        intptr_t *dump_fp = trace_calling_frame.link();\n+\n+        if (has_mh) {\n+          \/\/ The previous definition of walkable may have to be refined\n+          \/\/ if new call sites cause the next frame constructor to start\n+          \/\/ failing. Alternatively, frame constructors could be\n+          \/\/ modified to support the current or future non walkable\n+          \/\/ frames (but this is more intrusive and is not considered as\n+          \/\/ part of this RFE, which will instead use a simpler output).\n+          frame dump_frame = frame(dump_sp, dump_fp);\n+          dump_frame.describe(values, 1);\n+        } else {\n+          \/\/ Stack may not be walkable (invalid PC above FP):\n+          \/\/ Add descriptions without building a Java frame to avoid issues\n+          values.describe(-1, dump_fp, \"fp for #1 <not parsed, cannot trust pc>\");\n+          values.describe(-1, dump_sp, \"sp for #1\");\n+        }\n","filename":"src\/hotspot\/cpu\/x86\/methodHandles_x86.cpp","additions":46,"deletions":35,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -93,3 +93,4 @@\n-#define DEF_XMM_OFFS(regnum) xmm ## regnum ## _off = xmm_off + (regnum)*16\/BytesPerInt, xmm ## regnum ## H_off\n-#define DEF_YMM_OFFS(regnum) ymm ## regnum ## _off = ymm_off + (regnum)*16\/BytesPerInt, ymm ## regnum ## H_off\n-#define DEF_ZMM_OFFS(regnum) zmm ## regnum ## _off = zmm_off + (regnum-16)*64\/BytesPerInt, zmm ## regnum ## H_off\n+#define DEF_XMM_OFFS(regnum)       xmm ## regnum ## _off = xmm_off + (regnum)*16\/BytesPerInt, xmm ## regnum ## H_off\n+#define DEF_YMM_OFFS(regnum)       ymm ## regnum ## _off = ymm_off + (regnum)*16\/BytesPerInt, ymm ## regnum ## H_off\n+#define DEF_ZMM_OFFS(regnum)       zmm ## regnum ## _off = zmm_off + (regnum)*32\/BytesPerInt, zmm ## regnum ## H_off\n+#define DEF_ZMM_UPPER_OFFS(regnum) zmm ## regnum ## _off = zmm_upper_off + (regnum-16)*64\/BytesPerInt, zmm ## regnum ## H_off\n@@ -106,4 +107,6 @@\n-    zmm_high = xmm_off + (XSAVE_AREA_ZMM_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n-    zmm_off = xmm_off + (XSAVE_AREA_UPPERBANK - XSAVE_AREA_BEGIN)\/BytesPerInt,\n-    DEF_ZMM_OFFS(16),\n-    DEF_ZMM_OFFS(17),\n+    zmm_off = xmm_off + (XSAVE_AREA_ZMM_BEGIN - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_ZMM_OFFS(0),\n+    DEF_ZMM_OFFS(1),\n+    zmm_upper_off = xmm_off + (XSAVE_AREA_UPPERBANK - XSAVE_AREA_BEGIN)\/BytesPerInt,\n+    DEF_ZMM_UPPER_OFFS(16),\n+    DEF_ZMM_UPPER_OFFS(17),\n@@ -141,1 +144,1 @@\n-  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors = false);\n+  static OopMap* save_live_registers(MacroAssembler* masm, int additional_frame_words, int* total_frame_words, bool save_vectors);\n@@ -166,3 +169,2 @@\n-  if (save_vectors) {\n-    assert(UseAVX > 0, \"Vectors larger than 16 byte long are supported only with AVX\");\n-    assert(MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n+  if (save_vectors && UseAVX == 0) {\n+    save_vectors = false; \/\/ vectors larger than 16 byte long are supported only with AVX\n@@ -170,0 +172,1 @@\n+  assert(!save_vectors || MaxVectorSize <= 64, \"Only up to 64 byte long vectors are supported\");\n@@ -171,1 +174,1 @@\n-  assert(!save_vectors, \"vectors are generated only by C2 and JVMCI\");\n+  save_vectors = false; \/\/ vectors are generated only by C2 and JVMCI\n@@ -263,1 +266,1 @@\n-  if(UseAVX > 2) {\n+  if (UseAVX > 2) {\n@@ -276,0 +279,1 @@\n+    \/\/ Save upper half of YMM registers(0..15)\n@@ -277,1 +281,1 @@\n-    int delta = ymm1_off - off;\n+    delta = ymm1_off - ymm0_off;\n@@ -283,0 +287,10 @@\n+    if (VM_Version::supports_evex()) {\n+      \/\/ Save upper half of ZMM registers(0..15)\n+      off = zmm0_off;\n+      delta = zmm1_off - zmm0_off;\n+      for (int n = 0; n < 16; n++) {\n+        XMMRegister zmm_name = as_XMMRegister(n);\n+        map->set_callee_saved(STACK_OFFSET(off), zmm_name->as_VMReg()->next(8));\n+        off += delta;\n+      }\n+    }\n@@ -790,1 +804,1 @@\n-      OopMap* map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+      OopMap* map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ false);\n@@ -1887,1 +1901,1 @@\n-  } else if (iid == vmIntrinsics::_invokeBasic) {\n+  } else if (iid == vmIntrinsics::_invokeBasic || iid == vmIntrinsics::_linkToNative) {\n@@ -2872,0 +2886,3 @@\n+  if (UseAVX > 2) {\n+    pad += 1024;\n+  }\n@@ -2877,1 +2894,1 @@\n-  CodeBuffer buffer(\"deopt_blob\", 2048+pad, 1024);\n+  CodeBuffer buffer(\"deopt_blob\", 2560+pad, 1024);\n@@ -2919,1 +2936,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -2937,1 +2954,1 @@\n-  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  (void) RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -2956,1 +2973,1 @@\n-    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+    RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -3003,1 +3020,1 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ true);\n@@ -3605,1 +3622,2 @@\n-  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words);\n+  \/\/ No need to save vector registers since they are caller-saved anyway.\n+  map = RegisterSaver::save_live_registers(masm, 0, &frame_size_in_words, \/*save_vectors*\/ false);\n@@ -3665,0 +3683,210 @@\n+static const int native_invoker_code_size = MethodHandles::adapter_code_size;\n+\n+class NativeInvokerGenerator : public StubCodeGenerator {\n+  address _call_target;\n+  int _shadow_space_bytes;\n+\n+  const GrowableArray<VMReg>& _input_registers;\n+  const GrowableArray<VMReg>& _output_registers;\n+public:\n+  NativeInvokerGenerator(CodeBuffer* buffer,\n+                         address call_target,\n+                         int shadow_space_bytes,\n+                         const GrowableArray<VMReg>& input_registers,\n+                         const GrowableArray<VMReg>& output_registers)\n+   : StubCodeGenerator(buffer, PrintMethodHandleStubs),\n+     _call_target(call_target),\n+     _shadow_space_bytes(shadow_space_bytes),\n+     _input_registers(input_registers),\n+     _output_registers(output_registers) {}\n+  void generate();\n+\n+  void spill_register(VMReg reg) {\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ push(reg->as_Register());\n+    } else if (reg->is_XMMRegister()) {\n+      if (UseAVX >= 3) {\n+        __ subptr(rsp, 64); \/\/ bytes\n+        __ evmovdqul(Address(rsp, 0), reg->as_XMMRegister(), Assembler::AVX_512bit);\n+      } else if (UseAVX >= 1) {\n+        __ subptr(rsp, 32);\n+        __ vmovdqu(Address(rsp, 0), reg->as_XMMRegister());\n+      } else {\n+        __ subptr(rsp, 16);\n+        __ movdqu(Address(rsp, 0), reg->as_XMMRegister());\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+  void fill_register(VMReg reg) {\n+    assert(reg->is_reg(), \"must be a register\");\n+    MacroAssembler* masm = _masm;\n+    if (reg->is_Register()) {\n+      __ pop(reg->as_Register());\n+    } else if (reg->is_XMMRegister()) {\n+      if (UseAVX >= 3) {\n+        __ evmovdqul(reg->as_XMMRegister(), Address(rsp, 0), Assembler::AVX_512bit);\n+        __ addptr(rsp, 64); \/\/ bytes\n+      } else if (UseAVX >= 1) {\n+        __ vmovdqu(reg->as_XMMRegister(), Address(rsp, 0));\n+        __ addptr(rsp, 32);\n+      } else {\n+        __ movdqu(reg->as_XMMRegister(), Address(rsp, 0));\n+        __ addptr(rsp, 16);\n+      }\n+    } else {\n+      ShouldNotReachHere();\n+    }\n+  }\n+\n+private:\n+#ifdef ASSERT\n+bool target_uses_register(VMReg reg) {\n+  return _input_registers.contains(reg) || _output_registers.contains(reg);\n+}\n+#endif\n+};\n+\n+BufferBlob* SharedRuntime::make_native_invoker(address call_target,\n+                                               int shadow_space_bytes,\n+                                               const GrowableArray<VMReg>& input_registers,\n+                                               const GrowableArray<VMReg>& output_registers) {\n+  BufferBlob* _invoke_native_blob = BufferBlob::create(\"nep_invoker_blob\", native_invoker_code_size);\n+  if (_invoke_native_blob == NULL)\n+    return NULL; \/\/ allocation failure\n+\n+  CodeBuffer code(_invoke_native_blob);\n+  NativeInvokerGenerator g(&code, call_target, shadow_space_bytes, input_registers, output_registers);\n+  g.generate();\n+  code.log_section_sizes(\"nep_invoker_blob\");\n+\n+  return _invoke_native_blob;\n+}\n+\n+void NativeInvokerGenerator::generate() {\n+  assert(!(target_uses_register(r15_thread->as_VMReg()) || target_uses_register(rscratch1->as_VMReg())), \"Register conflict\");\n+\n+  MacroAssembler* masm = _masm;\n+  __ enter();\n+\n+  Address java_pc(r15_thread, JavaThread::last_Java_pc_offset());\n+  __ movptr(rscratch1, Address(rsp, 8)); \/\/ read return address from stack\n+  __ movptr(java_pc, rscratch1);\n+\n+  __ movptr(rscratch1, rsp);\n+  __ addptr(rscratch1, 16); \/\/ skip return and frame\n+  __ movptr(Address(r15_thread, JavaThread::last_Java_sp_offset()), rscratch1);\n+\n+  __ movptr(Address(r15_thread, JavaThread::saved_rbp_address_offset()), rsp); \/\/ rsp points at saved RBP\n+\n+    \/\/ State transition\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native);\n+\n+  if (_shadow_space_bytes != 0) {\n+    \/\/ needed here for correct stack args offset on Windows\n+    __ subptr(rsp, _shadow_space_bytes);\n+  }\n+\n+  __ call(RuntimeAddress(_call_target));\n+\n+  if (_shadow_space_bytes != 0) {\n+    \/\/ needed here for correct stack args offset on Windows\n+    __ addptr(rsp, _shadow_space_bytes);\n+  }\n+\n+  assert(_output_registers.length() <= 1\n+    || (_output_registers.length() == 2 && !_output_registers.at(1)->is_valid()), \"no multi-reg returns\");\n+  bool need_spills = _output_registers.length() != 0;\n+  VMReg ret_reg = need_spills ? _output_registers.at(0) : VMRegImpl::Bad();\n+\n+  __ restore_cpu_control_state_after_jni();\n+\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_native_trans);\n+\n+  \/\/ Force this write out before the read below\n+  __ membar(Assembler::Membar_mask_bits(\n+          Assembler::LoadLoad | Assembler::LoadStore |\n+          Assembler::StoreLoad | Assembler::StoreStore));\n+\n+  Label L_after_safepoint_poll;\n+  Label L_safepoint_poll_slow_path;\n+\n+  __ safepoint_poll(L_safepoint_poll_slow_path, r15_thread, true \/* at_return *\/, false \/* in_nmethod *\/);\n+  __ cmpl(Address(r15_thread, JavaThread::suspend_flags_offset()), 0);\n+  __ jcc(Assembler::notEqual, L_safepoint_poll_slow_path);\n+\n+  __ bind(L_after_safepoint_poll);\n+\n+  \/\/ change thread state\n+  __ movl(Address(r15_thread, JavaThread::thread_state_offset()), _thread_in_Java);\n+\n+  __ block_comment(\"reguard stack check\");\n+  Label L_reguard;\n+  Label L_after_reguard;\n+  __ cmpl(Address(r15_thread, JavaThread::stack_guard_state_offset()), StackOverflow::stack_guard_yellow_reserved_disabled);\n+  __ jcc(Assembler::equal, L_reguard);\n+  __ bind(L_after_reguard);\n+\n+  __ reset_last_Java_frame(r15_thread, true);\n+\n+  __ leave(); \/\/ required for proper stackwalking of RuntimeStub frame\n+  __ ret(0);\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ L_safepoint_poll_slow_path\");\n+  __ bind(L_safepoint_poll_slow_path);\n+  __ vzeroupper();\n+\n+  if (need_spills) {\n+    spill_register(ret_reg);\n+  }\n+\n+  __ mov(c_rarg0, r15_thread);\n+  __ mov(r12, rsp); \/\/ remember sp\n+  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n+  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n+  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, JavaThread::check_special_condition_for_native_trans)));\n+  __ mov(rsp, r12); \/\/ restore sp\n+  __ reinit_heapbase();\n+\n+  if (need_spills) {\n+    fill_register(ret_reg);\n+  }\n+\n+  __ jmp(L_after_safepoint_poll);\n+  __ block_comment(\"} L_safepoint_poll_slow_path\");\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ block_comment(\"{ L_reguard\");\n+  __ bind(L_reguard);\n+  __ vzeroupper();\n+\n+  if (need_spills) {\n+    spill_register(ret_reg);\n+  }\n+\n+  __ mov(r12, rsp); \/\/ remember sp\n+  __ subptr(rsp, frame::arg_reg_save_area_bytes); \/\/ windows\n+  __ andptr(rsp, -16); \/\/ align stack as required by ABI\n+  __ call(RuntimeAddress(CAST_FROM_FN_PTR(address, SharedRuntime::reguard_yellow_pages)));\n+  __ mov(rsp, r12); \/\/ restore sp\n+  __ reinit_heapbase();\n+\n+  if (need_spills) {\n+    fill_register(ret_reg);\n+  }\n+\n+  __ jmp(L_after_reguard);\n+\n+  __ block_comment(\"} L_reguard\");\n+\n+  \/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\/\n+\n+  __ flush();\n+}\n","filename":"src\/hotspot\/cpu\/x86\/sharedRuntime_x86_64.cpp","additions":250,"deletions":22,"binary":false,"changes":272,"status":"modified"},{"patch":"@@ -584,20 +584,0 @@\n-  \/\/ Support for intptr_t get_previous_fp()\n-  \/\/\n-  \/\/ This routine is used to find the previous frame pointer for the\n-  \/\/ caller (current_frame_guess). This is used as part of debugging\n-  \/\/ ps() is seemingly lost trying to find frames.\n-  \/\/ This code assumes that caller current_frame_guess) has a frame.\n-  address generate_get_previous_fp() {\n-    StubCodeMark mark(this, \"StubRoutines\", \"get_previous_fp\");\n-    const Address old_fp(rbp, 0);\n-    const Address older_fp(rax, 0);\n-    address start = __ pc();\n-\n-    __ enter();\n-    __ movptr(rax, old_fp); \/\/ callers fp\n-    __ movptr(rax, older_fp); \/\/ the frame for ps()\n-    __ pop(rbp);\n-    __ ret(0);\n-\n-    return start;\n-  }\n@@ -6902,1 +6882,0 @@\n-    StubRoutines::x86::_get_previous_fp_entry = generate_get_previous_fp();\n","filename":"src\/hotspot\/cpu\/x86\/stubGenerator_x86_64.cpp","additions":0,"deletions":21,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -1365,0 +1365,1 @@\n+\n@@ -1402,0 +1403,32 @@\n+#ifdef COMPILER2\n+    if (UseAVX > 2) {\n+      if (FLAG_IS_DEFAULT(ArrayCopyPartialInlineSize) ||\n+          (!FLAG_IS_DEFAULT(ArrayCopyPartialInlineSize) &&\n+           ArrayCopyPartialInlineSize != 0 &&\n+           ArrayCopyPartialInlineSize != 32 &&\n+           ArrayCopyPartialInlineSize != 16 &&\n+           ArrayCopyPartialInlineSize != 64)) {\n+        int inline_size = 0;\n+        if (MaxVectorSize >= 64 && AVX3Threshold == 0) {\n+          inline_size = 64;\n+        } else if (MaxVectorSize >= 32) {\n+          inline_size = 32;\n+        } else if (MaxVectorSize >= 16) {\n+          inline_size = 16;\n+        }\n+        if(!FLAG_IS_DEFAULT(ArrayCopyPartialInlineSize)) {\n+          warning(\"Setting ArrayCopyPartialInlineSize as %d\", inline_size);\n+        }\n+        ArrayCopyPartialInlineSize = inline_size;\n+      }\n+\n+      if (ArrayCopyPartialInlineSize > MaxVectorSize) {\n+        ArrayCopyPartialInlineSize = MaxVectorSize >= 16 ? MaxVectorSize : 0;\n+        if (ArrayCopyPartialInlineSize) {\n+          warning(\"Setting ArrayCopyPartialInlineSize as MaxVectorSize\" INTX_FORMAT \")\", MaxVectorSize);\n+        } else {\n+          warning(\"Setting ArrayCopyPartialInlineSize as \" INTX_FORMAT, ArrayCopyPartialInlineSize);\n+        }\n+      }\n+    }\n+#endif\n","filename":"src\/hotspot\/cpu\/x86\/vm_version_x86.cpp","additions":33,"deletions":0,"binary":false,"changes":33,"status":"modified"},{"patch":"@@ -460,0 +460,5 @@\n+int MachCallNativeNode::ret_addr_offset() {\n+  int offset = 13; \/\/ movq r10,#addr; callq (r10)\n+  offset += clear_avx_size();\n+  return offset;\n+}\n@@ -12524,0 +12529,12 @@\n+  ins_pipe(pipe_slow);\n+%}\n+\n+\/\/\n+instruct CallNativeDirect(method meth)\n+%{\n+  match(CallNative);\n+  effect(USE meth);\n+\n+  ins_cost(300);\n+  format %{ \"call_native \" %}\n+  ins_encode(clear_avx, Java_To_Runtime(meth));\n","filename":"src\/hotspot\/cpu\/x86\/x86_64.ad","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -422,0 +422,2 @@\n+  if(_matrule->find_type(\"CallNative\",idx))       return Form::JAVA_NATIVE;\n+  idx = 0;\n@@ -782,0 +784,1 @@\n+       !strcmp(_matrule->_rChild->_opType,\"VectorMaskGen\")||\n@@ -1135,0 +1138,3 @@\n+  else if( is_ideal_call() == Form::JAVA_NATIVE ) {\n+    return \"MachCallNativeNode\";\n+  }\n@@ -3488,1 +3494,1 @@\n-    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\",\n+    \"StoreVector\", \"LoadVector\", \"LoadVectorGather\", \"StoreVectorScatter\", \"LoadVectorMasked\", \"StoreVectorMasked\",\n@@ -4180,1 +4186,1 @@\n-    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\",\n+    \"VectorMaskWrapper\", \"VectorMaskCmp\", \"VectorReinterpret\",\"LoadVectorMasked\",\"StoreVectorMasked\",\n","filename":"src\/hotspot\/share\/adlc\/formssel.cpp","additions":8,"deletions":2,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -4522,0 +4522,3 @@\n+  case vmIntrinsics::_linkToNative:\n+    break; \/\/ TODO: NYI\n+\n","filename":"src\/hotspot\/share\/c1\/c1_GraphBuilder.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -255,0 +255,1 @@\n+    bool is_opt_native = false;\n@@ -258,1 +259,1 @@\n-                             reexecute, rethrow_exception, is_method_handle_invoke, return_oop, return_vt,\n+                             reexecute, rethrow_exception, is_method_handle_invoke, is_opt_native, return_oop, return_vt,\n","filename":"src\/hotspot\/share\/c1\/c1_IR.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -45,1 +45,0 @@\n-  ciArray(    arrayHandle h_a) : ciObject(h_a), _length(h_a()->length()) {}\n@@ -50,2 +49,0 @@\n-  ciArray(ciKlass* klass, int len) : ciObject(klass), _length(len) {}\n-\n","filename":"src\/hotspot\/share\/ci\/ciArray.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -51,0 +51,1 @@\n+class     ciNativeEntryPoint;\n@@ -102,0 +103,1 @@\n+friend class ciNativeEntryPoint;       \\\n","filename":"src\/hotspot\/share\/ci\/ciClassList.hpp","additions":3,"deletions":1,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -290,1 +290,0 @@\n-    _dtrace_monitor_probes  = true;\n@@ -294,1 +293,0 @@\n-    _dtrace_monitor_probes  = DTraceMonitorProbes;\n@@ -371,15 +369,0 @@\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciEnv::array_element_offset_in_bytes\n-int ciEnv::array_element_offset_in_bytes(ciArray* a_h, ciObject* o_h) {\n-  VM_ENTRY_MARK;\n-  objArrayOop a = (objArrayOop)a_h->get_oop();\n-  assert(a->is_objArray(), \"\");\n-  int length = a->length();\n-  oop o = o_h->get_oop();\n-  for (int i = 0; i < length; i++) {\n-    if (a->obj_at(i) == o)  return i;\n-  }\n-  return -1;\n-}\n-\n-\n@@ -998,1 +981,2 @@\n-                            RTMState  rtm_state) {\n+                            RTMState  rtm_state,\n+                            const GrowableArrayView<BufferBlob*>& native_invokers) {\n@@ -1087,1 +1071,2 @@\n-                               compiler, task()->comp_level());\n+                               compiler, task()->comp_level(),\n+                               native_invokers);\n@@ -1156,8 +1141,0 @@\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciEnv::find_system_klass\n-ciKlass* ciEnv::find_system_klass(ciSymbol* klass_name) {\n-  VM_ENTRY_MARK;\n-  return get_klass_by_name_impl(NULL, constantPoolHandle(), klass_name, false);\n-}\n-\n","filename":"src\/hotspot\/share\/ci\/ciEnv.cpp","additions":4,"deletions":27,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -81,1 +81,0 @@\n-  bool  _dtrace_monitor_probes;\n@@ -364,1 +363,0 @@\n-  bool  dtrace_monitor_probes()  const { return _dtrace_monitor_probes; }\n@@ -389,1 +387,2 @@\n-                       RTMState                  rtm_state = NoRTM);\n+                       RTMState                  rtm_state = NoRTM,\n+                       const GrowableArrayView<BufferBlob*>& native_invokers = GrowableArrayView<BufferBlob*>::EMPTY);\n@@ -428,1 +427,0 @@\n-  ciKlass*  find_system_klass(ciSymbol* klass_name);\n@@ -438,4 +436,0 @@\n-  \/\/ Return the machine-level offset of o, which must be an element of a.\n-  \/\/ This may be used to form constant-loading expressions in lieu of simpler encodings.\n-  int       array_element_offset_in_bytes(ciArray* a, ciObject* o);\n-\n","filename":"src\/hotspot\/share\/ci\/ciEnv.hpp","additions":2,"deletions":8,"binary":false,"changes":10,"status":"modified"},{"patch":"@@ -90,1 +90,0 @@\n-  bool can_be_primary_super();\n","filename":"src\/hotspot\/share\/ci\/ciKlass.hpp","additions":0,"deletions":1,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -262,9 +262,0 @@\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciMethod::compressed_linenumber_table\n-u_char* ciMethod::compressed_linenumber_table() const {\n-  check_is_loaded();\n-  VM_ENTRY_MARK;\n-  return get_Method()->compressed_linenumber_table();\n-}\n-\n-\n@@ -291,28 +282,0 @@\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciMethod::native_entry\n-\/\/\n-\/\/ Get the address of this method's native code, if any.\n-address ciMethod::native_entry() {\n-  check_is_loaded();\n-  assert(flags().is_native(), \"must be native method\");\n-  VM_ENTRY_MARK;\n-  Method* method = get_Method();\n-  address entry = method->native_function();\n-  assert(entry != NULL, \"must be valid entry point\");\n-  return entry;\n-}\n-\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciMethod::interpreter_entry\n-\/\/\n-\/\/ Get the entry point for running this method in the interpreter.\n-address ciMethod::interpreter_entry() {\n-  check_is_loaded();\n-  VM_ENTRY_MARK;\n-  methodHandle mh(THREAD, get_Method());\n-  return Interpreter::entry_for_method(mh);\n-}\n-\n-\n@@ -913,13 +876,0 @@\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciMethod::interpreter_call_site_count\n-int ciMethod::interpreter_call_site_count(int bci) {\n-  if (method_data() != NULL) {\n-    ResourceMark rm;\n-    ciProfileData* data = method_data()->bci_to_data(bci);\n-    if (data != NULL && data->is_CounterData()) {\n-      return scale_count(data->as_CounterData()->count());\n-    }\n-  }\n-  return -1;  \/\/ unknown\n-}\n-\n@@ -1172,31 +1122,0 @@\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciMethod::set_not_compilable\n-\/\/\n-\/\/ Tell the VM that this method cannot be compiled at all.\n-void ciMethod::set_not_compilable(const char* reason) {\n-  check_is_loaded();\n-  VM_ENTRY_MARK;\n-  ciEnv* env = CURRENT_ENV;\n-  if (is_c1_compile(env->comp_level())) {\n-    _is_c1_compilable = false;\n-  } else {\n-    _is_c2_compilable = false;\n-  }\n-  get_Method()->set_not_compilable(reason, env->comp_level());\n-}\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciMethod::can_be_osr_compiled\n-\/\/\n-\/\/ Have previous compilations of this method succeeded?\n-\/\/\n-\/\/ Implementation note: the VM does not currently keep track\n-\/\/ of failed OSR compilations per bci.  The entry_bci parameter\n-\/\/ is currently unused.\n-bool ciMethod::can_be_osr_compiled(int entry_bci) {\n-  check_is_loaded();\n-  VM_ENTRY_MARK;\n-  ciEnv* env = CURRENT_ENV;\n-  return !get_Method()->is_not_osr_compilable(env->comp_level());\n-}\n-\n@@ -1209,8 +1128,0 @@\n-int ciMethod::comp_level() {\n-  check_is_loaded();\n-  VM_ENTRY_MARK;\n-  CompiledMethod* nm = get_Method()->code();\n-  if (nm != NULL) return nm->comp_level();\n-  return 0;\n-}\n-\n@@ -1356,2 +1267,0 @@\n-bool ciMethod::is_empty_method() const {         FETCH_FLAG_FROM_VM(is_empty_method); }\n-bool ciMethod::is_vanilla_constructor() const {  FETCH_FLAG_FROM_VM(is_vanilla_constructor); }\n@@ -1366,1 +1275,1 @@\n-  if (holder()->is_box_klass()) {\n+  if (intrinsic_id() != vmIntrinsics::_none && holder()->is_box_klass()) {\n@@ -1385,1 +1294,1 @@\n-  if (holder()->is_box_klass()) {\n+  if (intrinsic_id() != vmIntrinsics::_none && holder()->is_box_klass()) {\n@@ -1421,1 +1330,1 @@\n-  Arena *arena = CURRENT_ENV->arena();\n+    Arena *arena = CURRENT_ENV->arena();\n","filename":"src\/hotspot\/share\/ci\/ciMethod.cpp","additions":3,"deletions":94,"binary":false,"changes":97,"status":"modified"},{"patch":"@@ -205,1 +205,0 @@\n-  int comp_level();\n@@ -220,1 +219,0 @@\n-  u_char* compressed_linenumber_table() const;   \/\/ not preserved by gc\n@@ -226,2 +224,0 @@\n-  address       native_entry();\n-  address       interpreter_entry();\n@@ -262,1 +258,0 @@\n-  int           interpreter_call_site_count(int bci);\n@@ -309,2 +304,0 @@\n-  bool can_be_osr_compiled(int entry_bci);\n-  void set_not_compilable(const char* reason = NULL);\n@@ -348,2 +341,0 @@\n-  bool is_empty_method() const;\n-  bool is_vanilla_constructor() const;\n","filename":"src\/hotspot\/share\/ci\/ciMethod.hpp","additions":0,"deletions":9,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"ci\/ciNativeEntryPoint.hpp\"\n@@ -81,2 +82,10 @@\n-                                 int expected_size) {\n-\n+                                 int expected_size)\n+                                 : _arena(arena),\n+                                   _ci_metadata(arena, expected_size, 0, NULL),\n+                                   _unloaded_methods(arena, 4, 0, NULL),\n+                                   _unloaded_klasses(arena, 8, 0, NULL),\n+                                   _unloaded_instances(arena, 4, 0, NULL),\n+                                   _return_addresses(arena, 8, 0, NULL),\n+                                   _symbols(arena, 100, 0, NULL),\n+                                   _next_ident(_shared_ident_limit),\n+                                   _non_perm_count(0) {\n@@ -86,5 +95,0 @@\n-  _non_perm_count = 0;\n-\n-  _next_ident = _shared_ident_limit;\n-  _arena = arena;\n-  _ci_metadata = new (arena) GrowableArray<ciMetadata*>(arena, expected_size, 0, NULL);\n@@ -93,2 +97,1 @@\n-\n-    _ci_metadata->appendAll(_shared_ci_metadata);\n+    _ci_metadata.appendAll(_shared_ci_metadata);\n@@ -97,8 +100,0 @@\n-\n-  _unloaded_methods = new (arena) GrowableArray<ciMethod*>(arena, 4, 0, NULL);\n-  _unloaded_klasses = new (arena) GrowableArray<ciKlass*>(arena, 8, 0, NULL);\n-  _unloaded_instances = new (arena) GrowableArray<ciInstance*>(arena, 4, 0, NULL);\n-  _return_addresses =\n-    new (arena) GrowableArray<ciReturnAddress*>(arena, 8, 0, NULL);\n-\n-  _symbols = new (arena) GrowableArray<ciSymbol*>(arena, 100, 0, NULL);\n@@ -151,2 +146,0 @@\n-  _ci_metadata = new (_arena) GrowableArray<ciMetadata*>(_arena, 64, 0, NULL);\n-\n@@ -172,2 +165,2 @@\n-  for (int len = -1; len != _ci_metadata->length(); ) {\n-    len = _ci_metadata->length();\n+  for (int len = -1; len != _ci_metadata.length(); ) {\n+    len = _ci_metadata.length();\n@@ -175,1 +168,1 @@\n-      ciMetadata* obj = _ci_metadata->at(i2);\n+      ciMetadata* obj = _ci_metadata.at(i2);\n@@ -200,2 +193,0 @@\n-\n-\n@@ -210,1 +201,1 @@\n-  _shared_ci_metadata = _ci_metadata;\n+  _shared_ci_metadata = &_ci_metadata;\n@@ -223,1 +214,1 @@\n-  _symbols->push(s);\n+  _symbols.push(s);\n@@ -229,2 +220,2 @@\n-  for (int i = 0; i < _symbols->length(); i++) {\n-    ciSymbol* s = _symbols->at(i);\n+  for (int i = 0; i < _symbols.length(); i++) {\n+    ciSymbol* s = _symbols.at(i);\n@@ -282,1 +273,1 @@\n-  int index = _ci_metadata->find_sorted<Metadata*, ciObjectFactory::metadata_compare>(key, found);\n+  int index = _ci_metadata.find_sorted<Metadata*, ciObjectFactory::metadata_compare>(key, found);\n@@ -287,1 +278,1 @@\n-  return _ci_metadata->at(index)->as_metadata();\n+  return _ci_metadata.at(index)->as_metadata();\n@@ -303,2 +294,2 @@\n-    for (int j = 0; j< _ci_metadata->length(); j++) {\n-      Metadata* o = _ci_metadata->at(j)->constant_encoding();\n+    for (int j = 0; j < _ci_metadata.length(); j++) {\n+      Metadata* o = _ci_metadata.at(j)->constant_encoding();\n@@ -310,1 +301,1 @@\n-  int len = _ci_metadata->length();\n+  int len = _ci_metadata.length();\n@@ -312,1 +303,1 @@\n-  int index = _ci_metadata->find_sorted<Metadata*, ciObjectFactory::metadata_compare>(key, found);\n+  int index = _ci_metadata.find_sorted<Metadata*, ciObjectFactory::metadata_compare>(key, found);\n@@ -315,2 +306,2 @@\n-    for (int i=0; i<_ci_metadata->length(); i++) {\n-      if (_ci_metadata->at(i)->constant_encoding() == key) {\n+    for (int i = 0; i < _ci_metadata.length(); i++) {\n+      if (_ci_metadata.at(i)->constant_encoding() == key) {\n@@ -330,1 +321,1 @@\n-    if (len != _ci_metadata->length()) {\n+    if (len != _ci_metadata.length()) {\n@@ -333,1 +324,1 @@\n-      index = _ci_metadata->find_sorted<Metadata*, ciObjectFactory::metadata_compare>(key, found);\n+      index = _ci_metadata.find_sorted<Metadata*, ciObjectFactory::metadata_compare>(key, found);\n@@ -336,1 +327,1 @@\n-    _ci_metadata->insert_before(index, new_object);\n+    _ci_metadata.insert_before(index, new_object);\n@@ -339,1 +330,1 @@\n-  return _ci_metadata->at(index)->as_metadata();\n+  return _ci_metadata.at(index)->as_metadata();\n@@ -358,0 +349,2 @@\n+    else if (jdk_internal_invoke_NativeEntryPoint::is_instance(o))\n+      return new (arena()) ciNativeEntryPoint(h_i);\n@@ -433,2 +426,2 @@\n-  for (int i = 0; i < _unloaded_methods->length(); i++) {\n-    ciMethod* entry = _unloaded_methods->at(i);\n+  for (int i = 0; i < _unloaded_methods.length(); i++) {\n+    ciMethod* entry = _unloaded_methods.at(i);\n@@ -458,1 +451,1 @@\n-  _unloaded_methods->append(new_method);\n+  _unloaded_methods.append(new_method);\n@@ -481,2 +474,2 @@\n-  for (int i=0; i<_unloaded_klasses->length(); i++) {\n-    ciKlass* entry = _unloaded_klasses->at(i);\n+  for (int i = 0; i < _unloaded_klasses.length(); i++) {\n+    ciKlass* entry = _unloaded_klasses.at(i);\n@@ -532,1 +525,1 @@\n-  _unloaded_klasses->append(new_klass);\n+  _unloaded_klasses.append(new_klass);\n@@ -544,2 +537,2 @@\n-  for (int i=0; i<_unloaded_instances->length(); i++) {\n-    ciInstance* entry = _unloaded_instances->at(i);\n+  for (int i = 0; i < _unloaded_instances.length(); i++) {\n+    ciInstance* entry = _unloaded_instances.at(i);\n@@ -557,1 +550,1 @@\n-  _unloaded_instances->append(new_instance);\n+  _unloaded_instances.append(new_instance);\n@@ -624,2 +617,2 @@\n-  for (int i=0; i<_return_addresses->length(); i++) {\n-    ciReturnAddress* entry = _return_addresses->at(i);\n+  for (int i = 0; i < _return_addresses.length(); i++) {\n+    ciReturnAddress* entry = _return_addresses.at(i);\n@@ -634,1 +627,1 @@\n-  _return_addresses->append(new_ret_addr);\n+  _return_addresses.append(new_ret_addr);\n@@ -700,3 +693,2 @@\n-  if (_ci_metadata == NULL) return;\n-  for (int j = 0; j< _ci_metadata->length(); j++) {\n-    Metadata* o = _ci_metadata->at(j)->constant_encoding();\n+  for (int j = 0; j < _ci_metadata.length(); j++) {\n+    Metadata* o = _ci_metadata.at(j)->constant_encoding();\n@@ -710,1 +702,1 @@\n-  int len = _ci_metadata->length();\n+  int len = _ci_metadata.length();\n@@ -712,2 +704,2 @@\n-  for (int i=0; i<len; i++) {\n-    _ci_metadata->at(i)->print();\n+  for (int i = 0; i < len; i++) {\n+    _ci_metadata.at(i)->print();\n@@ -732,3 +724,3 @@\n-             _non_perm_count, _ci_metadata->length(), _unloaded_methods->length(),\n-             _unloaded_instances->length(),\n-             _unloaded_klasses->length());\n+             _non_perm_count, _ci_metadata.length(), _unloaded_methods.length(),\n+             _unloaded_instances.length(),\n+             _unloaded_klasses.length());\n","filename":"src\/hotspot\/share\/ci\/ciObjectFactory.cpp","additions":53,"deletions":61,"binary":false,"changes":114,"status":"modified"},{"patch":"@@ -40,1 +40,2 @@\n-ciSignature::ciSignature(ciKlass* accessing_klass, const constantPoolHandle& cpool, ciSymbol* symbol) {\n+ciSignature::ciSignature(ciKlass* accessing_klass, const constantPoolHandle& cpool, ciSymbol* symbol)\n+  : _symbol(symbol), _accessing_klass(accessing_klass), _types(CURRENT_ENV->arena(), 8, 0, NULL) {\n@@ -44,2 +45,0 @@\n-  _accessing_klass = accessing_klass;\n-  _symbol = symbol;\n@@ -48,2 +47,0 @@\n-  Arena* arena = env->arena();\n-  _types = new (arena) GrowableArray<ciType*>(arena, 8, 0, NULL);\n@@ -65,2 +62,2 @@\n-    _types->append(type);\n-      \/\/ Done processing the return type; do not add it into the count.\n+      \/\/ don't include return type in size calculation\n+      _return_type = type;\n@@ -70,0 +67,1 @@\n+    _types.append(type);\n@@ -71,1 +69,0 @@\n-    count++;\n@@ -74,39 +71,0 @@\n-  _count = count;\n-}\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciSignature::ciSignature\n-ciSignature::ciSignature(ciKlass* accessing_klass, ciSymbol* symbol, ciMethodType* method_type) :\n-  _symbol(symbol),\n-  _accessing_klass(accessing_klass),\n-  _size( method_type->ptype_slot_count()),\n-  _count(method_type->ptype_count())\n-{\n-  ASSERT_IN_VM;\n-  EXCEPTION_CONTEXT;\n-  ciEnv* env =  CURRENT_ENV;\n-  Arena* arena = env->arena();\n-  _types = new (arena) GrowableArray<ciType*>(arena, _count + 1, 0, NULL);\n-  for (int i = 0; i < _count; i++) {\n-    _types->append(method_type->ptype_at(i));\n-  }\n-  _types->append(method_type->rtype());\n-}\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciSignature::return_type\n-\/\/\n-\/\/ What is the return type of this signature?\n-ciType* ciSignature::return_type() const {\n-  return _types->at(_count);\n-}\n-\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciSignature::type_at\n-\/\/\n-\/\/ What is the type of the index'th element of this\n-\/\/ signature?\n-ciType* ciSignature::type_at(int index) const {\n-  assert(index < _count, \"out of bounds\");\n-  \/\/ The first _klasses element holds the return klass.\n-  return _types->at(index);\n@@ -122,1 +80,1 @@\n-  ciType* ret_type = _types->at(_count);\n+  ciType* ret_type = return_type();\n@@ -139,1 +97,3 @@\n-  if (!this->as_symbol()->equals(that->as_symbol()))  return false;\n+  if (!this->as_symbol()->equals(that->as_symbol())) {\n+    return false;\n+  }\n@@ -141,2 +101,7 @@\n-  for (int i = 0; i < _count; i++) {\n-    if (this->type_at(i) != that->type_at(i))         return false;\n+  if (_types.length() != that->_types.length()) {\n+    return false;\n+  }\n+  for (int i = 0; i < _types.length(); i++) {\n+    if (this->type_at(i) != that->type_at(i)) {\n+      return false;\n+    }\n@@ -145,1 +110,3 @@\n-  if (this->return_type() != that->return_type())     return false;\n+  if (this->return_type() != that->return_type()) {\n+    return false;\n+  }\n","filename":"src\/hotspot\/share\/ci\/ciSignature.cpp","additions":19,"deletions":52,"binary":false,"changes":71,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1999, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1999, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -42,1 +42,2 @@\n-  GrowableArray<ciType*>* _types;\n+  GrowableArray<ciType*> _types; \/\/ parameter types\n+  ciType* _return_type;\n@@ -44,1 +45,0 @@\n-  int _count;  \/\/ number of parameter types in the signature\n@@ -51,1 +51,0 @@\n-  ciSignature(ciKlass* accessing_klass,                           ciSymbol* signature, ciMethodType* method_type);\n@@ -59,2 +58,2 @@\n-  ciType*   return_type() const;\n-  ciType*   type_at(int index) const;\n+  ciType*   return_type() const                  { return _return_type; }\n+  ciType*   type_at(int index) const             { return _types.at(index); }\n@@ -64,1 +63,1 @@\n-  int       count() const                        { return _count; }\n+  int       count() const                        { return _types.length(); }\n","filename":"src\/hotspot\/share\/ci\/ciSignature.hpp","additions":6,"deletions":7,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -146,2 +146,0 @@\n-  bool has_optional_appendix() { return Bytecodes::has_optional_appendix(cur_bc_raw()); }\n-\n","filename":"src\/hotspot\/share\/ci\/ciStreams.hpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -34,2 +34,0 @@\n-\/\/\n-\/\/ Preallocated symbol variant.  Used with symbols from vmSymbols.\n@@ -41,10 +39,1 @@\n-  assert(sid_ok(), \"must be in vmSymbols\");\n-}\n-\n-\/\/ Normal case for non-famous symbols.\n-ciSymbol::ciSymbol(Symbol* s)\n-  : _symbol(s), _sid(vmSymbolID::NO_SID)\n-{\n-  assert(_symbol != NULL, \"adding null symbol\");\n-  _symbol->increment_refcount();  \/\/ increment ref count\n-  assert(sid_ok(), \"must not be in vmSymbols\");\n+  assert(sid_ok(), \"sid must be consistent with vmSymbols\");\n","filename":"src\/hotspot\/share\/ci\/ciSymbol.cpp","additions":1,"deletions":12,"binary":false,"changes":13,"status":"modified"},{"patch":"@@ -56,2 +56,1 @@\n-  ciSymbol(Symbol* s);  \/\/ normal case, for symbols not mentioned in vmSymbols\n-  ciSymbol(Symbol* s, vmSymbolID sid);   \/\/ for use with vmSymbols\n+  ciSymbol(Symbol* s, vmSymbolID sid = vmSymbolID::NO_SID);\n","filename":"src\/hotspot\/share\/ci\/ciSymbol.hpp","additions":1,"deletions":2,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -104,15 +104,0 @@\n-\/\/ ------------------------------------------------------------------\n-\/\/ ciType::box_klass\n-\/\/\n-ciKlass* ciType::box_klass() {\n-  assert(basic_type() != T_INLINE_TYPE, \"inline type boxing not supported\");\n-  if (!is_primitive_type())  return this->as_klass();  \/\/ reference types are \"self boxing\"\n-\n-  \/\/ Void is \"boxed\" with a null.\n-  if (basic_type() == T_VOID)  return NULL;\n-\n-  VM_ENTRY_MARK;\n-  return CURRENT_THREAD_ENV->get_instance_klass(SystemDictionary::box_klass(basic_type()));\n-}\n-\n-\n","filename":"src\/hotspot\/share\/ci\/ciType.cpp","additions":0,"deletions":15,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -63,6 +63,0 @@\n-  \/\/ Get the class which \"boxes\" (or \"wraps\") values of this type.\n-  \/\/ Example:  short is boxed by java.lang.Short, etc.\n-  \/\/ Returns self if it is a reference type.\n-  \/\/ Returns NULL for void, since null is used in such cases.\n-  ciKlass*  box_klass();\n-\n","filename":"src\/hotspot\/share\/ci\/ciType.hpp","additions":0,"deletions":6,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -59,8 +59,4 @@\n-ciTypeFlow::JsrSet::JsrSet(Arena* arena, int default_len) {\n-  if (arena != NULL) {\n-    \/\/ Allocate growable array in Arena.\n-    _set = new (arena) GrowableArray<JsrRecord*>(arena, default_len, 0, NULL);\n-  } else {\n-    \/\/ Allocate growable array in current ResourceArea.\n-    _set = new GrowableArray<JsrRecord*>(4, 0, NULL);\n-  }\n+\n+\/\/ Allocate growable array storage in Arena.\n+ciTypeFlow::JsrSet::JsrSet(Arena* arena, int default_len) : _set(arena, default_len, 0, NULL) {\n+  assert(arena != NULL, \"invariant\");\n@@ -69,0 +65,3 @@\n+\/\/ Allocate growable array storage in current ResourceArea.\n+ciTypeFlow::JsrSet::JsrSet(int default_len) : _set(default_len, 0, NULL) {}\n+\n@@ -73,1 +72,1 @@\n-  jsrs->_set->clear();\n+  jsrs->_set.clear();\n@@ -75,1 +74,1 @@\n-    jsrs->_set->append(_set->at(i));\n+    jsrs->_set.append(_set.at(i));\n@@ -162,1 +161,1 @@\n-      _set->at_put(pos, record);\n+      _set.at_put(pos, record);\n@@ -174,2 +173,2 @@\n-    temp = _set->at(pos);\n-    _set->at_put(pos, swap);\n+    temp = _set.at(pos);\n+    _set.at_put(pos, swap);\n@@ -178,1 +177,1 @@\n-  _set->append(swap);\n+  _set.append(swap);\n@@ -192,2 +191,2 @@\n-      for (int j = i+1; j < len ; j++) {\n-        _set->at_put(j-1, _set->at(j));\n+      for (int j = i + 1; j < len ; j++) {\n+        _set.at_put(j - 1, _set.at(j));\n@@ -195,1 +194,1 @@\n-      _set->trunc_to(len-1);\n+      _set.trunc_to(len - 1);\n@@ -243,1 +242,1 @@\n-      _set->at(i)->print_on(st);\n+      _set.at(i)->print_on(st);\n@@ -246,1 +245,1 @@\n-    _set->at(i)->print_on(st);\n+    _set.at(i)->print_on(st);\n@@ -384,1 +383,1 @@\n-    JsrSet* jsrs = new JsrSet(NULL, 16);\n+    JsrSet* jsrs = new JsrSet(4);\n@@ -1642,1 +1641,1 @@\n-                         ciTypeFlow::JsrSet* jsrs) {\n+                         ciTypeFlow::JsrSet* jsrs) : _predecessors(outer->arena(), 1, 0, NULL) {\n@@ -1647,1 +1646,0 @@\n-  _predecessors = new (outer->arena()) GrowableArray<Block*>(outer->arena(), 1, 0, NULL);\n@@ -1980,1 +1978,1 @@\n-  if (_predecessors == NULL) {\n+  if (_predecessors.is_empty()) {\n@@ -1983,1 +1981,1 @@\n-    int num_predecessors = _predecessors->length();\n+    int num_predecessors = _predecessors.length();\n@@ -1986,1 +1984,1 @@\n-      Block* predecessor = _predecessors->at(i);\n+      Block* predecessor = _predecessors.at(i);\n@@ -2040,4 +2038,0 @@\n-  _methodBlocks = method->get_method_blocks();\n-  _max_locals = method->max_locals();\n-  _max_stack = method->max_stack();\n-  _code_size = method->code_size();\n@@ -2050,3 +2044,3 @@\n-  _ciblock_count = _methodBlocks->num_blocks();\n-  _idx_to_blocklist = NEW_ARENA_ARRAY(arena(), GrowableArray<Block*>*, _ciblock_count);\n-  for (int i = 0; i < _ciblock_count; i++) {\n+  int ciblock_count = _method->get_method_blocks()->num_blocks();\n+  _idx_to_blocklist = NEW_ARENA_ARRAY(arena(), GrowableArray<Block*>*, ciblock_count);\n+  for (int i = 0; i < ciblock_count; i++) {\n@@ -2056,1 +2050,0 @@\n-  _jsr_count = 0;\n@@ -2126,1 +2119,1 @@\n-  ciBlock* ciblk = _methodBlocks->block_containing(bci);\n+  ciBlock* ciblk = _method->get_method_blocks()->block_containing(bci);\n@@ -2154,1 +2147,1 @@\n-                                                           _jsr_count,\n+                                                           2,\n@@ -2698,2 +2691,2 @@\n-  ciBlock* dummy = _methodBlocks->make_dummy_block();\n-  JsrSet* root_set = new JsrSet(NULL, 0);\n+  ciBlock* dummy = _method->get_method_blocks()->make_dummy_block();\n+  JsrSet* root_set = new JsrSet(0);\n@@ -2772,1 +2765,1 @@\n-  JsrSet* temp_set = new JsrSet(NULL, 16);\n+  JsrSet* temp_set = new JsrSet(4);\n@@ -2900,1 +2893,1 @@\n-  Block* new_block = new (a) Block(this, _methodBlocks->block(ciBlockIndex), jsrs);\n+  Block* new_block = new (a) Block(this, _method->get_method_blocks()->block(ciBlockIndex), jsrs);\n@@ -2965,3 +2958,3 @@\n-  JsrSet* jsrs = new ciTypeFlow::JsrSet(NULL);\n-  int        index = _methodBlocks->block_containing(bci)->index();\n-  int    dom_index = _methodBlocks->block_containing(dom_bci)->index();\n+  JsrSet* jsrs = new ciTypeFlow::JsrSet();\n+  int        index = _method->get_method_blocks()->block_containing(bci)->index();\n+  int    dom_index = _method->get_method_blocks()->block_containing(dom_bci)->index();\n@@ -3049,1 +3042,1 @@\n-  ciMethodBlocks  *mblks = _methodBlocks;\n+  ciMethodBlocks* mblks = _method->get_method_blocks();\n","filename":"src\/hotspot\/share\/ci\/ciTypeFlow.cpp","additions":37,"deletions":44,"binary":false,"changes":81,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2000, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2000, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -39,1 +39,0 @@\n-  ciMethodBlocks* _methodBlocks;\n@@ -42,4 +41,0 @@\n-  \/\/ information cached from the method:\n-  int _max_locals;\n-  int _max_stack;\n-  int _code_size;\n@@ -65,4 +60,4 @@\n-  int       max_locals() const { return _max_locals; }\n-  int       max_stack() const  { return _max_stack; }\n-  int       max_cells() const  { return _max_locals + _max_stack; }\n-  int       code_size() const  { return _code_size; }\n+  int       max_locals() const { return method()->max_locals(); }\n+  int       max_stack() const  { return method()->max_stack(); }\n+  int       max_cells() const  { return max_locals() + max_stack(); }\n+  int       code_size() const  { return method()->code_size(); }\n@@ -107,1 +102,1 @@\n-    GrowableArray<JsrRecord*>* _set;\n+    GrowableArray<JsrRecord*> _set;\n@@ -110,1 +105,1 @@\n-      return _set->at(i);\n+      return _set.at(i);\n@@ -122,0 +117,1 @@\n+    JsrSet(int default_len = 4);\n@@ -135,1 +131,1 @@\n-    int size() const { return _set->length(); }\n+    int size() const { return _set.length(); }\n@@ -529,1 +525,1 @@\n-    GrowableArray<Block*>*           _predecessors;\n+    GrowableArray<Block*>            _predecessors;\n@@ -620,2 +616,1 @@\n-      assert(_predecessors != NULL, \"must be filled in\");\n-      return _predecessors;\n+      return &_predecessors;\n@@ -801,2 +796,0 @@\n-  \/\/ count of ciBlocks\n-  int _ciblock_count;\n@@ -878,1 +871,0 @@\n-  int _jsr_count;\n","filename":"src\/hotspot\/share\/ci\/ciTypeFlow.hpp","additions":11,"deletions":19,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -3840,0 +3840,59 @@\n+int jdk_internal_invoke_NativeEntryPoint::_addr_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_shadow_space_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_argMoves_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_returnMoves_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_need_transition_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_method_type_offset;\n+int jdk_internal_invoke_NativeEntryPoint::_name_offset;\n+\n+#define NEP_FIELDS_DO(macro) \\\n+  macro(_addr_offset,            k, \"addr\",           long_signature, false); \\\n+  macro(_shadow_space_offset,    k, \"shadowSpace\",    int_signature, false); \\\n+  macro(_argMoves_offset,        k, \"argMoves\",       long_array_signature, false); \\\n+  macro(_returnMoves_offset,     k, \"returnMoves\",    long_array_signature, false); \\\n+  macro(_need_transition_offset, k, \"needTransition\", bool_signature, false); \\\n+  macro(_method_type_offset,     k, \"methodType\",     java_lang_invoke_MethodType_signature, false); \\\n+  macro(_name_offset,            k, \"name\",           string_signature, false);\n+\n+bool jdk_internal_invoke_NativeEntryPoint::is_instance(oop obj) {\n+  return obj != NULL && is_subclass(obj->klass());\n+}\n+\n+void jdk_internal_invoke_NativeEntryPoint::compute_offsets() {\n+  InstanceKlass* k = SystemDictionary::NativeEntryPoint_klass();\n+  NEP_FIELDS_DO(FIELD_COMPUTE_OFFSET);\n+}\n+\n+#if INCLUDE_CDS\n+void jdk_internal_invoke_NativeEntryPoint::serialize_offsets(SerializeClosure* f) {\n+  NEP_FIELDS_DO(FIELD_SERIALIZE_OFFSET);\n+}\n+#endif\n+\n+address jdk_internal_invoke_NativeEntryPoint::addr(oop entry) {\n+  return (address)entry->long_field(_addr_offset);\n+}\n+\n+jint jdk_internal_invoke_NativeEntryPoint::shadow_space(oop entry) {\n+  return entry->int_field(_shadow_space_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::argMoves(oop entry) {\n+  return entry->obj_field(_argMoves_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::returnMoves(oop entry) {\n+  return entry->obj_field(_returnMoves_offset);\n+}\n+\n+jboolean jdk_internal_invoke_NativeEntryPoint::need_transition(oop entry) {\n+  return entry->bool_field(_need_transition_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::method_type(oop entry) {\n+  return entry->obj_field(_method_type_offset);\n+}\n+\n+oop jdk_internal_invoke_NativeEntryPoint::name(oop entry) {\n+  return entry->obj_field(_name_offset);\n+}\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.cpp","additions":59,"deletions":0,"binary":false,"changes":59,"status":"modified"},{"patch":"@@ -78,0 +78,1 @@\n+  f(jdk_internal_invoke_NativeEntryPoint) \\\n@@ -878,1 +879,1 @@\n-  static inline void set_referent_raw(oop ref, oop value);\n+  static inline void clear_referent(oop ref);\n@@ -1011,0 +1012,45 @@\n+\/\/ Interface to java.lang.invoke.NativeEntryPoint objects\n+\/\/ (These are a private interface for managing adapter code generation.)\n+\n+class jdk_internal_invoke_NativeEntryPoint: AllStatic {\n+  friend class JavaClasses;\n+\n+ private:\n+  static int _addr_offset;  \/\/ type is jlong\n+  static int _shadow_space_offset;\n+  static int _argMoves_offset;\n+  static int _returnMoves_offset;\n+  static int _need_transition_offset;\n+  static int _method_type_offset;\n+  static int _name_offset;\n+\n+  static void compute_offsets();\n+\n+ public:\n+  static void serialize_offsets(SerializeClosure* f) NOT_CDS_RETURN;\n+\n+  \/\/ Accessors\n+  static address    addr(oop entry);\n+  static jint       shadow_space(oop entry);\n+  static oop        argMoves(oop entry);\n+  static oop        returnMoves(oop entry);\n+  static jboolean   need_transition(oop entry);\n+  static oop        method_type(oop entry);\n+  static oop        name(oop entry);\n+\n+  \/\/ Testers\n+  static bool is_subclass(Klass* klass) {\n+    return SystemDictionary::NativeEntryPoint_klass() != NULL &&\n+      klass->is_subclass_of(SystemDictionary::NativeEntryPoint_klass());\n+  }\n+  static bool is_instance(oop obj);\n+\n+  \/\/ Accessors for code generation:\n+  static int addr_offset_in_bytes()            { return _addr_offset;            }\n+  static int shadow_space_offset_in_bytes()    { return _shadow_space_offset;    }\n+  static int argMoves_offset_in_bytes()        { return _argMoves_offset;        }\n+  static int returnMoves_offset_in_bytes()     { return _returnMoves_offset;     }\n+  static int need_transition_offset_in_bytes() { return _need_transition_offset; }\n+  static int method_type_offset_in_bytes()     { return _method_type_offset;     }\n+  static int name_offset_in_bytes()            { return _name_offset;            }\n+};\n","filename":"src\/hotspot\/share\/classfile\/javaClasses.hpp","additions":47,"deletions":1,"binary":false,"changes":48,"status":"modified"},{"patch":"@@ -175,0 +175,1 @@\n+  do_klass(NativeEntryPoint_klass,                      jdk_internal_invoke_NativeEntryPoint                  ) \\\n","filename":"src\/hotspot\/share\/classfile\/systemDictionary.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -977,0 +977,1 @@\n+  do_intrinsic(_linkToNative,             java_lang_invoke_MethodHandle, linkToNative_name,     star_name, F_SN)        \\\n@@ -1052,1 +1053,1 @@\n-    LAST_MH_SIG_POLY     = _linkToInterface,\n+    LAST_MH_SIG_POLY     = _linkToNative,\n","filename":"src\/hotspot\/share\/classfile\/vmIntrinsics.hpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -278,0 +278,1 @@\n+  template(linkToNative_name,                         \"linkToNative\")                             \\\n@@ -352,2 +353,5 @@\n-                                                                                                                                      \\\n-  \/* Support for JVMCI *\/                                                                                                             \\\n+  \/* Panama Support *\/                                                                                          \\\n+  template(jdk_internal_invoke_NativeEntryPoint,                 \"jdk\/internal\/invoke\/NativeEntryPoint\")           \\\n+  template(jdk_internal_invoke_NativeEntryPoint_signature,       \"Ljdk\/internal\/invoke\/NativeEntryPoint;\")         \\\n+                                                                                                  \\\n+  \/* Support for JVMCI *\/                                                                         \\\n@@ -527,0 +531,1 @@\n+  template(long_array_signature,                      \"[J\")                                       \\\n","filename":"src\/hotspot\/share\/classfile\/vmSymbols.hpp","additions":7,"deletions":2,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -384,0 +384,1 @@\n+      if (ssd.is_optimized_linkToNative()) return; \/\/ call was replaced\n","filename":"src\/hotspot\/share\/code\/compiledMethod.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -290,0 +290,1 @@\n+                                              bool        is_optimized_linkToNative,\n@@ -309,0 +310,1 @@\n+  last_pd->set_is_optimized_linkToNative(is_optimized_linkToNative);\n","filename":"src\/hotspot\/share\/code\/debugInfoRec.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -107,0 +107,1 @@\n+                      bool        is_optimized_linkToNative = false,\n","filename":"src\/hotspot\/share\/code\/debugInfoRec.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -68,0 +68,1 @@\n+#include \"utilities\/copy.hpp\"\n@@ -70,0 +71,1 @@\n+#include \"utilities\/globalDefinitions.hpp\"\n@@ -499,1 +501,2 @@\n-  int comp_level\n+  int comp_level,\n+  const GrowableArrayView<BufferBlob*>& native_invokers\n@@ -521,0 +524,1 @@\n+      + align_up(checked_cast<int>(native_invokers.data_size_in_bytes()), oopSize)\n@@ -536,1 +540,2 @@\n-            comp_level\n+            comp_level,\n+            native_invokers\n@@ -624,1 +629,2 @@\n-    _handler_table_offset    = _dependencies_offset;\n+    _native_invokers_offset     = _dependencies_offset;\n+    _handler_table_offset    = _native_invokers_offset;\n@@ -726,1 +732,2 @@\n-  int comp_level\n+  int comp_level,\n+  const GrowableArrayView<BufferBlob*>& native_invokers\n@@ -803,1 +810,2 @@\n-    _handler_table_offset    = _dependencies_offset  + align_up((int)dependencies->size_in_bytes (), oopSize);\n+    _native_invokers_offset  = _dependencies_offset  + align_up((int)dependencies->size_in_bytes(), oopSize);\n+    _handler_table_offset    = _native_invokers_offset + align_up(checked_cast<int>(native_invokers.data_size_in_bytes()), oopSize);\n@@ -828,0 +836,4 @@\n+    if (native_invokers.is_nonempty()) { \/\/ can not get address of zero-length array\n+      \/\/ Copy native stubs\n+      memcpy(native_invokers_begin(), native_invokers.adr_at(0), native_invokers.data_size_in_bytes());\n+    }\n@@ -1002,0 +1014,4 @@\n+    if (printmethod && native_invokers_begin() < native_invokers_end()) {\n+      print_native_invokers();\n+      tty->print_cr(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \");\n+    }\n@@ -1065,0 +1081,6 @@\n+void nmethod::free_native_invokers() {\n+  for (BufferBlob** it = native_invokers_begin(); it < native_invokers_end(); it++) {\n+    CodeCache::free(*it);\n+  }\n+}\n+\n@@ -2697,0 +2719,8 @@\n+void nmethod::print_native_invokers() {\n+  ResourceMark m;       \/\/ in case methods get printed via debugger\n+  tty->print_cr(\"Native invokers:\");\n+  for (BufferBlob** itt = native_invokers_begin(); itt < native_invokers_end(); itt++) {\n+    (*itt)->print_on(tty);\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/code\/nmethod.cpp","additions":35,"deletions":5,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -214,0 +214,1 @@\n+  int _native_invokers_offset;\n@@ -319,1 +320,2 @@\n-          int comp_level\n+          int comp_level,\n+          const GrowableArrayView<BufferBlob*>& native_invokers\n@@ -367,1 +369,2 @@\n-                              int comp_level\n+                              int comp_level,\n+                              const GrowableArrayView<BufferBlob*>& native_invokers = GrowableArrayView<BufferBlob*>::EMPTY\n@@ -416,1 +419,3 @@\n-  address dependencies_end      () const          { return           header_begin() + _handler_table_offset ; }\n+  address dependencies_end      () const          { return           header_begin() + _native_invokers_offset ; }\n+  BufferBlob** native_invokers_begin() const         { return (BufferBlob**)(header_begin() + _native_invokers_offset) ; }\n+  BufferBlob** native_invokers_end  () const         { return (BufferBlob**)(header_begin() + _handler_table_offset); }\n@@ -535,0 +540,2 @@\n+  void free_native_invokers();\n+\n@@ -671,0 +678,1 @@\n+  void print_native_invokers();\n","filename":"src\/hotspot\/share\/code\/nmethod.hpp","additions":12,"deletions":4,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -42,7 +42,8 @@\n-    PCDESC_reexecute               = 1 << 0,\n-    PCDESC_is_method_handle_invoke = 1 << 1,\n-    PCDESC_return_oop              = 1 << 2,\n-    PCDESC_rethrow_exception       = 1 << 3,\n-    PCDESC_has_ea_local_in_scope   = 1 << 4,\n-    PCDESC_arg_escape              = 1 << 5,\n-    PCDESC_return_vt               = 1 << 6\n+    PCDESC_reexecute                 = 1 << 0,\n+    PCDESC_is_method_handle_invoke   = 1 << 1,\n+    PCDESC_return_oop                = 1 << 2,\n+    PCDESC_rethrow_exception         = 1 << 3,\n+    PCDESC_has_ea_local_in_scope     = 1 << 4,\n+    PCDESC_arg_escape                = 1 << 5,\n+    PCDESC_is_optimized_linkToNative = 1 << 6,\n+    PCDESC_return_vt                 = 1 << 7\n@@ -92,0 +93,3 @@\n+  bool     is_optimized_linkToNative()     const { return (_flags & PCDESC_is_optimized_linkToNative) != 0;     }\n+  void set_is_optimized_linkToNative(bool z)     { set_flag(PCDESC_is_optimized_linkToNative, z); }\n+\n","filename":"src\/hotspot\/share\/code\/pcDesc.hpp","additions":11,"deletions":7,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -42,0 +42,1 @@\n+  bool _is_optimized_linkToNative;\n@@ -47,0 +48,2 @@\n+    \/\/ save this here so we only have to look up the PcDesc once\n+    _is_optimized_linkToNative = pc_desc->is_optimized_linkToNative();\n@@ -55,0 +58,1 @@\n+  bool is_optimized_linkToNative() { return _is_optimized_linkToNative; }\n","filename":"src\/hotspot\/share\/code\/scopeDesc.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -28,0 +28,1 @@\n+#include \"memory\/iterator.hpp\"\n@@ -77,3 +78,0 @@\n-  static uintptr_t mark_barrier_on_root_oop_slow_path(uintptr_t addr);\n-\n-  static uintptr_t relocate_barrier_on_root_oop_slow_path(uintptr_t addr);\n@@ -116,1 +114,0 @@\n-  static void mark_barrier_on_root_oop_field(oop* p);\n@@ -119,3 +116,0 @@\n-  \/\/ Relocate barrier\n-  static void relocate_barrier_on_root_oop_field(oop* p);\n-\n@@ -133,0 +127,6 @@\n+class ZLoadBarrierOopClosure : public BasicOopIterateClosure {\n+public:\n+  virtual void do_oop(oop* p);\n+  virtual void do_oop(narrowOop* p);\n+};\n+\n","filename":"src\/hotspot\/share\/gc\/z\/zBarrier.hpp","additions":7,"deletions":7,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -63,1 +63,2 @@\n-    accessor,                                                   \/\/ accessor method (code: _aload_0, _getfield, _(a|i)return)\n+    getter,                                                     \/\/ getter method\n+    setter,                                                     \/\/ setter method\n@@ -136,9 +137,3 @@\n-  static address entry_for_cds_method(const methodHandle& m) {\n-    MethodKind k = method_kind(m);\n-    assert(0 <= k && k < number_of_method_entries, \"illegal kind\");\n-    return _cds_entry_table[k];\n-  }\n-\n-  static void       update_cds_entry_table(MethodKind kind) NOT_CDS_RETURN;\n-\n-  static address    get_trampoline_code_buffer(AbstractInterpreter::MethodKind kind) NOT_CDS_RETURN_(0);\n+  static address    entry_for_cds_method(const methodHandle& m) NOT_CDS_RETURN_(NULL);\n+  static address    entry_for_cds_method(AbstractInterpreter::MethodKind kind) NOT_CDS_RETURN_(NULL);\n+  static void       generate_entry_for_cds_method(MethodKind kind) NOT_CDS_RETURN;\n","filename":"src\/hotspot\/share\/interpreter\/abstractInterpreter.hpp","additions":5,"deletions":10,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -185,1 +185,1 @@\n-    Interpreter::update_cds_entry_table(Interpreter::kind); \\\n+    Interpreter::generate_entry_for_cds_method(Interpreter::kind); \\\n@@ -192,1 +192,2 @@\n-  method_entry(accessor)\n+  method_entry(getter)\n+  method_entry(setter)\n@@ -410,1 +411,2 @@\n-  case Interpreter::accessor               : break;\n+  case Interpreter::getter                 : break;\n+  case Interpreter::setter                 : break;\n","filename":"src\/hotspot\/share\/interpreter\/templateInterpreterGenerator.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -1193,0 +1193,1 @@\n+  const bool is_opt_native         = false;\n@@ -1195,1 +1196,1 @@\n-  _debug_recorder->describe_scope(pc_offset, method, NULL, bci, reexecute, throw_exception, is_mh_invoke, return_oop, false,\n+  _debug_recorder->describe_scope(pc_offset, method, NULL, bci, reexecute, throw_exception, is_mh_invoke, is_opt_native, return_oop, false,\n","filename":"src\/hotspot\/share\/jvmci\/jvmciCodeInstaller.cpp","additions":2,"deletions":1,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -290,2 +290,0 @@\n-    allocate_method_trampoline_info();\n-    allocate_method_trampolines();\n","filename":"src\/hotspot\/share\/memory\/archiveBuilder.cpp","additions":0,"deletions":2,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -39,0 +39,1 @@\n+#include \"interpreter\/abstractInterpreter.hpp\"\n@@ -66,0 +67,1 @@\n+#include \"runtime\/sharedRuntime.hpp\"\n@@ -87,1 +89,0 @@\n-size_t MetaspaceShared::_i2i_entry_code_buffers_size = 0;\n@@ -344,4 +345,0 @@\n-  \/\/ We don't want any valid object to be at the very bottom of the archive.\n-  \/\/ See ArchivePtrMarker::mark_pointer().\n-  MetaspaceShared::misc_code_space_alloc(16);\n-\n@@ -515,11 +512,4 @@\n-address MetaspaceShared::i2i_entry_code_buffers(size_t total_size) {\n-  if (DumpSharedSpaces) {\n-    if (_i2i_entry_code_buffers == NULL) {\n-      _i2i_entry_code_buffers = (address)misc_code_space_alloc(total_size);\n-      _i2i_entry_code_buffers_size = total_size;\n-    }\n-  } else if (UseSharedSpaces) {\n-    assert(_i2i_entry_code_buffers != NULL, \"must already been initialized\");\n-  } else {\n-    return NULL;\n-  }\n+void MetaspaceShared::init_misc_code_space() {\n+  \/\/ We don't want any valid object to be at the very bottom of the archive.\n+  \/\/ See ArchivePtrMarker::mark_pointer().\n+  MetaspaceShared::misc_code_space_alloc(16);\n@@ -527,1 +517,8 @@\n-  assert(_i2i_entry_code_buffers_size == total_size, \"must not change\");\n+  size_t trampoline_size = SharedRuntime::trampoline_size();\n+  size_t buf_size = (size_t)AbstractInterpreter::number_of_method_entries * trampoline_size;\n+  _i2i_entry_code_buffers = (address)misc_code_space_alloc(buf_size);\n+}\n+\n+address MetaspaceShared::i2i_entry_code_buffers() {\n+  assert(DumpSharedSpaces || UseSharedSpaces, \"must be\");\n+  assert(_i2i_entry_code_buffers != NULL, \"must already been initialized\");\n@@ -738,0 +735,4 @@\n+  MetaspaceShared::init_misc_code_space();\n+  builder.allocate_method_trampoline_info();\n+  builder.allocate_method_trampolines();\n+\n@@ -790,2 +791,0 @@\n-  memset(MetaspaceShared::i2i_entry_code_buffers(), 0,\n-         MetaspaceShared::i2i_entry_code_buffers_size());\n@@ -803,2 +802,1 @@\n-  mapinfo->set_i2i_entry_code_buffers(MetaspaceShared::i2i_entry_code_buffers(),\n-                                      MetaspaceShared::i2i_entry_code_buffers_size());\n+  mapinfo->set_i2i_entry_code_buffers(MetaspaceShared::i2i_entry_code_buffers());\n@@ -1725,1 +1723,0 @@\n-  _i2i_entry_code_buffers_size = static_mapinfo->i2i_entry_code_buffers_size();\n","filename":"src\/hotspot\/share\/memory\/metaspaceShared.cpp","additions":19,"deletions":22,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -2733,0 +2733,1 @@\n+#if INCLUDE_JVMTI\n@@ -2739,0 +2740,4 @@\n+    \/\/ First fix any default methods that point to a super class that may\n+    \/\/ have been redefined.\n+    bool trace_name_printed = false;\n+    adjust_default_methods(&trace_name_printed);\n@@ -2742,0 +2747,1 @@\n+#endif\n@@ -3134,21 +3140,0 @@\n-\/\/ Returns true iff super_method can be overridden by a method in targetclassname\n-\/\/ See JLS 3rd edition 8.4.6.1\n-\/\/ Assumes name-signature match\n-\/\/ \"this\" is InstanceKlass of super_method which must exist\n-\/\/ note that the InstanceKlass of the method in the targetclassname has not always been created yet\n-bool InstanceKlass::is_override(const methodHandle& super_method, Handle targetclassloader, Symbol* targetclassname, TRAPS) {\n-   \/\/ Private methods can not be overridden\n-   if (super_method->is_private()) {\n-     return false;\n-   }\n-   \/\/ If super method is accessible, then override\n-   if ((super_method->is_protected()) ||\n-       (super_method->is_public())) {\n-     return true;\n-   }\n-   \/\/ Package-private methods are not inherited outside of package\n-   assert(super_method->is_package_private(), \"must be package private\");\n-   return(is_same_class_package(targetclassloader(), targetclassname));\n-}\n-\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.cpp","additions":6,"deletions":21,"binary":false,"changes":27,"status":"modified"},{"patch":"@@ -620,3 +620,0 @@\n-  \/\/ method override check\n-  bool is_override(const methodHandle& super_method, Handle targetclassloader, Symbol* targetclassname, TRAPS);\n-\n","filename":"src\/hotspot\/share\/oops\/instanceKlass.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -83,2 +83,1 @@\n-    assert(methods->at(i)->is_method(), \"must be a Method*\");\n-    methodHandle mh(THREAD, methods->at(i));\n+    Method* method = methods->at(i);\n@@ -86,2 +85,2 @@\n-    if (needs_new_vtable_entry(mh, super, classloader, classname, class_flags, major_version, THREAD)) {\n-      assert(!methods->at(i)->is_private(), \"private methods should not need a vtable entry\");\n+    if (needs_new_vtable_entry(method, super, classloader, classname, class_flags, major_version)) {\n+      assert(!method->is_private(), \"private methods should not need a vtable entry\");\n@@ -202,2 +201,0 @@\n-      HandleMark hm(THREAD);\n-      assert(methods->at(i)->is_method(), \"must be a Method*\");\n@@ -206,1 +203,1 @@\n-      bool needs_new_entry = update_inherited_vtable(ik(), mh, super_vtable_len, -1, checkconstraints, CHECK);\n+      bool needs_new_entry = update_inherited_vtable(mh, super_vtable_len, -1, checkconstraints, CHECK);\n@@ -210,1 +207,1 @@\n-        mh()->set_vtable_index(initialized); \/\/ set primary vtable index\n+        mh->set_vtable_index(initialized); \/\/ set primary vtable index\n@@ -228,5 +225,9 @@\n-          HandleMark hm(THREAD);\n-          assert(default_methods->at(i)->is_method(), \"must be a Method*\");\n-          methodHandle mh(THREAD, default_methods->at(i));\n-          assert(!mh->is_private(), \"private interface method in the default method list\");\n-          bool needs_new_entry = update_inherited_vtable(ik(), mh, super_vtable_len, i, checkconstraints, CHECK);\n+          bool needs_new_entry;\n+          {\n+            \/\/ Reduce the scope of this handle so that it is fetched again.\n+            \/\/ The methodHandle keeps it from being deleted by RedefineClasses while\n+            \/\/ we're using it.\n+            methodHandle mh(THREAD, default_methods->at(i));\n+            assert(!mh->is_private(), \"private interface method in the default method list\");\n+            needs_new_entry = update_inherited_vtable(mh, super_vtable_len, i, checkconstraints, CHECK);\n+          }\n@@ -236,1 +237,4 @@\n-            put_method_at(mh(), initialized);\n+            \/\/ Refetch this default method in case of redefinition that might\n+            \/\/ happen during constraint checking in the update_inherited_vtable call above.\n+            Method* method = default_methods->at(i);\n+            put_method_at(method, initialized);\n@@ -275,0 +279,19 @@\n+\/\/ Returns true iff super_method can be overridden by a method in targetclassname\n+\/\/ See JLS 3rd edition 8.4.6.1\n+\/\/ Assumes name-signature match\n+\/\/ Note that the InstanceKlass of the method in the targetclassname has not always been created yet\n+static bool can_be_overridden(Method* super_method, Handle targetclassloader, Symbol* targetclassname) {\n+   \/\/ Private methods can not be overridden\n+   assert(!super_method->is_private(), \"shouldn't call with a private method\");\n+\n+   \/\/ If super method is accessible, then override\n+   if ((super_method->is_protected()) ||\n+       (super_method->is_public())) {\n+     return true;\n+   }\n+   \/\/ Package-private methods are not inherited outside of package\n+   assert(super_method->is_package_private(), \"must be package private\");\n+   return(super_method->method_holder()->is_same_class_package(targetclassloader(), targetclassname));\n+}\n+\n+\n@@ -290,2 +313,6 @@\n-InstanceKlass* klassVtable::find_transitive_override(InstanceKlass* initialsuper, const methodHandle& target_method,\n-                            int vtable_index, Handle target_loader, Symbol* target_classname, Thread * THREAD) {\n+InstanceKlass* klassVtable::find_transitive_override(InstanceKlass* initialsuper,\n+                                                     const methodHandle& target_method,\n+                                                     int vtable_index,\n+                                                     Handle target_loader,\n+                                                     Symbol* target_classname) {\n+\n@@ -297,3 +324,0 @@\n-      \/\/ get the class holding the matching method\n-      \/\/ make sure you use that class for is_override\n-      InstanceKlass* supermethodholder = super_method->method_holder();\n@@ -306,1 +330,1 @@\n-      if (supermethodholder->is_override(methodHandle(THREAD, super_method), target_loader, target_classname, THREAD)) {\n+      if (can_be_overridden(super_method, target_loader, target_classname)) {\n@@ -308,1 +332,1 @@\n-          ResourceMark rm(THREAD);\n+          ResourceMark rm;\n@@ -313,1 +337,1 @@\n-                       supermethodholder->internal_name(),\n+                       super_method->method_holder()->internal_name(),\n@@ -363,1 +387,1 @@\n-bool klassVtable::update_inherited_vtable(InstanceKlass* klass, const methodHandle& target_method,\n+bool klassVtable::update_inherited_vtable(const methodHandle& target_method,\n@@ -368,1 +392,2 @@\n-  assert(klass->is_instance_klass(), \"must be InstanceKlass\");\n+\n+  InstanceKlass* klass = ik();\n@@ -381,1 +406,1 @@\n-    assert(!target_method()->is_private(), \"private interface method flagged as default\");\n+    assert(!target_method->is_private(), \"private interface method flagged as default\");\n@@ -385,1 +410,1 @@\n-    assert(klass == target_method()->method_holder(), \"caller resp.\");\n+    assert(klass == target_method->method_holder(), \"caller resp.\");\n@@ -388,1 +413,1 @@\n-    target_method()->set_vtable_index(Method::nonvirtual_vtable_index);\n+    target_method->set_vtable_index(Method::nonvirtual_vtable_index);\n@@ -392,2 +417,2 @@\n-  if (target_method()->is_private() || target_method()->is_static() ||\n-      (target_method()->name()->fast_compare(vmSymbols::object_initializer_name()) == 0)) {\n+  if (target_method->is_private() || target_method->is_static() ||\n+      (target_method->name()->fast_compare(vmSymbols::object_initializer_name()) == 0)) {\n@@ -413,2 +438,2 @@\n-    if ((!is_default || !target_method()->has_itable_index())) {\n-      target_method()->set_vtable_index(Method::pending_itable_index);\n+    if ((!is_default || !target_method->has_itable_index())) {\n+      target_method->set_vtable_index(Method::pending_itable_index);\n@@ -429,2 +454,2 @@\n-  Symbol* name = target_method()->name();\n-  Symbol* signature = target_method()->signature();\n+  Symbol* name = target_method->name();\n+  Symbol* signature = target_method->signature();\n@@ -432,1 +457,2 @@\n-  Klass* target_klass = target_method()->method_holder();\n+  Klass* target_klass = target_method->method_holder();\n+  assert(target_klass != NULL, \"impossible\");\n@@ -437,0 +463,1 @@\n+  HandleMark hm(THREAD);\n@@ -455,1 +482,1 @@\n-        (!_klass->is_interface() ||\n+        (!klass->is_interface() ||\n@@ -466,8 +493,7 @@\n-          (is_default\n-          || ((super_klass->is_override(methodHandle(THREAD, super_method), target_loader, target_classname, THREAD))\n-          || ((klass->major_version() >= VTABLE_TRANSITIVE_OVERRIDE_VERSION)\n-          && ((super_klass = find_transitive_override(super_klass,\n-                             target_method, i, target_loader,\n-                             target_classname, THREAD))\n-                             != (InstanceKlass*)NULL)))))\n-        {\n+          (is_default ||\n+           can_be_overridden(super_method, target_loader, target_classname) ||\n+           (klass->major_version() >= VTABLE_TRANSITIVE_OVERRIDE_VERSION &&\n+             (super_klass = find_transitive_override(super_klass,\n+                                                     target_method, i, target_loader,\n+                                                     target_classname)) != NULL))) {\n+\n@@ -476,1 +502,1 @@\n-        if (!target_method()->is_package_private()) {\n+        if (!target_method->is_package_private()) {\n@@ -480,0 +506,5 @@\n+        \/\/ Set the vtable index before the constraint check safepoint, which potentially\n+        \/\/ redefines this method if this method is a default method belonging to a\n+        \/\/ super class or interface.\n+        put_method_at(target_method(), i);\n+\n@@ -482,1 +513,1 @@\n-        if (checkconstraints && !target_method()->is_overpass()) {\n+        if (checkconstraints && !target_method->is_overpass()) {\n@@ -501,1 +532,1 @@\n-              target_method()->print_external_name(&ss),\n+              target_method->print_external_name(&ss),\n@@ -517,1 +548,0 @@\n-        put_method_at(target_method(), i);\n@@ -520,1 +550,1 @@\n-          target_method()->set_vtable_index(i);\n+          target_method->set_vtable_index(i);\n@@ -547,0 +577,1 @@\n+  JVMTI_ONLY(assert(!m->is_old() || ik()->is_being_redefined(), \"old methods should not be in vtable\"));\n@@ -579,1 +610,1 @@\n-bool klassVtable::needs_new_vtable_entry(const methodHandle& target_method,\n+bool klassVtable::needs_new_vtable_entry(Method* target_method,\n@@ -584,2 +615,1 @@\n-                                         u2 major_version,\n-                                         TRAPS) {\n+                                         u2 major_version) {\n@@ -598,1 +628,1 @@\n-      (target_method()->is_private()) ||\n+      (target_method->is_private()) ||\n@@ -600,1 +630,1 @@\n-      (target_method()->is_static()) ||\n+      (target_method->is_static()) ||\n@@ -602,1 +632,1 @@\n-      (target_method()->name()->fast_compare(vmSymbols::object_initializer_name()) == 0)\n+      (target_method->name()->fast_compare(vmSymbols::object_initializer_name()) == 0)\n@@ -610,4 +640,4 @@\n-  if (target_method()->method_holder() != NULL &&\n-      target_method()->method_holder()->is_interface()  &&\n-      !target_method()->is_abstract()) {\n-    assert(target_method()->is_default_method(),\n+  if (target_method->method_holder() != NULL &&\n+      target_method->method_holder()->is_interface()  &&\n+      !target_method->is_abstract()) {\n+    assert(target_method->is_default_method(),\n@@ -625,1 +655,1 @@\n-  if (target_method()->is_package_private()) {\n+  if (target_method->is_package_private()) {\n@@ -631,3 +661,2 @@\n-  ResourceMark rm(THREAD);\n-  Symbol* name = target_method()->name();\n-  Symbol* signature = target_method()->signature();\n+  Symbol* name = target_method->name();\n+  Symbol* signature = target_method->signature();\n@@ -646,1 +675,0 @@\n-    \/\/ make sure you use that class for is_override\n@@ -654,3 +682,3 @@\n-    if ((!super_method->is_static()) &&\n-       (!super_method->is_private())) {\n-      if (superk->is_override(methodHandle(THREAD, super_method), classloader, classname, THREAD)) {\n+    if (!super_method->is_static() &&\n+        !super_method->is_private()) {\n+      if (can_be_overridden(super_method, classloader, classname)) {\n@@ -658,1 +686,1 @@\n-      \/\/ else keep looking for transitive overrides\n+        \/\/ else keep looking for transitive overrides\n@@ -721,2 +749,1 @@\n-  Klass* method_holder = m->method_holder();\n-  InstanceKlass *mhk = InstanceKlass::cast(method_holder);\n+  InstanceKlass* holder = m->method_holder();\n@@ -725,1 +752,1 @@\n-  if (mhk->is_interface()) {\n+  if (holder->is_interface()) {\n@@ -727,1 +754,1 @@\n-    assert(ik()->implements_interface(method_holder) , \"this class should implement the interface\");\n+    assert(ik()->implements_interface(holder) , \"this class should implement the interface\");\n@@ -891,1 +918,1 @@\n-    InstanceKlass *ik = InstanceKlass::cast(local_interfaces->at(i));\n+    InstanceKlass *ik = local_interfaces->at(i);\n@@ -1110,1 +1137,1 @@\n-      Klass* interf = ioe->interface_klass();\n+      InstanceKlass* interf = ioe->interface_klass();\n@@ -1112,1 +1139,1 @@\n-      initialize_itable_for_interface(ioe->offset(), InstanceKlass::cast(interf), checkconstraints, CHECK);\n+      initialize_itable_for_interface(ioe->offset(), interf, checkconstraints, CHECK);\n","filename":"src\/hotspot\/share\/oops\/klassVtable.cpp","additions":101,"deletions":74,"binary":false,"changes":175,"status":"modified"},{"patch":"@@ -112,1 +112,1 @@\n-  static bool needs_new_vtable_entry(const methodHandle& m,\n+  static bool needs_new_vtable_entry(Method* m,\n@@ -117,6 +117,9 @@\n-                                     u2 major_version,\n-                                     TRAPS);\n-\n-  bool update_inherited_vtable(InstanceKlass* klass, const methodHandle& target_method, int super_vtable_len, int default_index, bool checkconstraints, TRAPS);\n- InstanceKlass* find_transitive_override(InstanceKlass* initialsuper, const methodHandle& target_method, int vtable_index,\n-                                         Handle target_loader, Symbol* target_classname, Thread* THREAD);\n+                                     u2 major_version);\n+\n+  bool update_inherited_vtable(const methodHandle& target_method,\n+                               int super_vtable_len,\n+                               int default_index,\n+                               bool checkconstraints, TRAPS);\n+ InstanceKlass* find_transitive_override(InstanceKlass* initialsuper,\n+                                         const methodHandle& target_method, int vtable_index,\n+                                         Handle target_loader, Symbol* target_classname);\n","filename":"src\/hotspot\/share\/oops\/klassVtable.hpp","additions":10,"deletions":7,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -1577,0 +1577,3 @@\n+  if (iid == vmIntrinsics::_linkToNative) {\n+    m->set_interpreter_entry(m->adapter()->get_i2c_entry());\n+  }\n","filename":"src\/hotspot\/share\/oops\/method.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -194,1 +194,1 @@\n-      PhaseIterGVN *igvn = phase->is_IterGVN();\n+      PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -630,1 +630,1 @@\n-      PhaseIterGVN *igvn = phase->is_IterGVN();\n+      PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -782,7 +782,7 @@\n-     Node* lshift = in(1)->in(2);\n-     Node* rshift = in(2)->in(2);\n-     Node* shift = rotate_shift(phase, lshift, rshift, 0x1F);\n-     if (shift != NULL) {\n-       return new RotateLeftNode(in(1)->in(1), shift, TypeInt::INT);\n-     }\n-     return NULL;\n+    Node* lshift = in(1)->in(2);\n+    Node* rshift = in(2)->in(2);\n+    Node* shift = rotate_shift(phase, lshift, rshift, 0x1F);\n+    if (shift != NULL) {\n+      return new RotateLeftNode(in(1)->in(1), shift, TypeInt::INT);\n+    }\n+    return NULL;\n@@ -792,6 +792,6 @@\n-     Node *rshift = in(1)->in(2);\n-     Node *lshift = in(2)->in(2);\n-     Node* shift = rotate_shift(phase, rshift, lshift, 0x1F);\n-     if (shift != NULL) {\n-       return new RotateRightNode(in(1)->in(1), shift, TypeInt::INT);\n-     }\n+    Node* rshift = in(1)->in(2);\n+    Node* lshift = in(2)->in(2);\n+    Node* shift = rotate_shift(phase, rshift, lshift, 0x1F);\n+    if (shift != NULL) {\n+      return new RotateRightNode(in(1)->in(1), shift, TypeInt::INT);\n+    }\n","filename":"src\/hotspot\/share\/opto\/addnode.cpp","additions":15,"deletions":15,"binary":false,"changes":30,"status":"modified"},{"patch":"@@ -775,0 +775,2 @@\n+  } else if (mb->trailing_partial_array_copy()) {\n+    return true;\n@@ -825,0 +827,13 @@\n+\n+\/\/ As an optimization, choose optimum vector size for copy length known at compile time.\n+int ArrayCopyNode::get_partial_inline_vector_lane_count(BasicType type, int const_len) {\n+  int lane_count = ArrayCopyPartialInlineSize\/type2aelembytes(type);\n+  if (const_len > 0) {\n+    int size_in_bytes = const_len * type2aelembytes(type);\n+    if (size_in_bytes <= 16)\n+      lane_count = 16\/type2aelembytes(type);\n+    else if (size_in_bytes > 16 && size_in_bytes <= 32)\n+      lane_count = 32\/type2aelembytes(type);\n+  }\n+  return lane_count;\n+}\n","filename":"src\/hotspot\/share\/opto\/arraycopynode.cpp","additions":15,"deletions":0,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -185,0 +185,3 @@\n+\n+  static int get_partial_inline_vector_lane_count(BasicType type, int const_len);\n+\n","filename":"src\/hotspot\/share\/opto\/arraycopynode.hpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -83,0 +83,4 @@\n+  product(intx, ArrayCopyPartialInlineSize, -1, DIAGNOSTIC,                 \\\n+          \"Partial inline size used for array copy acceleration.\")          \\\n+          range(-1, 64)                                                     \\\n+                                                                            \\\n","filename":"src\/hotspot\/share\/opto\/c2_globals.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -44,0 +44,2 @@\n+#include \"ci\/ciNativeEntryPoint.hpp\"\n+#include \"utilities\/debug.hpp\"\n@@ -991,0 +993,25 @@\n+class NativeCallGenerator : public CallGenerator {\n+private:\n+  ciNativeEntryPoint* _nep;\n+public:\n+  NativeCallGenerator(ciMethod* m, ciNativeEntryPoint* nep)\n+   : CallGenerator(m), _nep(nep) {}\n+\n+  virtual JVMState* generate(JVMState* jvms);\n+};\n+\n+JVMState* NativeCallGenerator::generate(JVMState* jvms) {\n+  GraphKit kit(jvms);\n+\n+  Node* call = kit.make_native_call(tf(), method()->arg_size(), _nep); \/\/ -fallback, - nep\n+  if (call == NULL) return NULL;\n+\n+  kit.C->print_inlining_update(this);\n+  address addr = _nep->entry_point();\n+  if (kit.C->log() != NULL) {\n+    kit.C->log()->elem(\"l2n_intrinsification_success bci='%d' entry_point='\" INTPTR_FORMAT \"'\", jvms->bci(), p2i(addr));\n+  }\n+\n+  return kit.transfer_exceptions_into_jvms();\n+}\n+\n@@ -1103,0 +1130,14 @@\n+    case vmIntrinsics::_linkToNative:\n+    {\n+      Node* nep = kit.argument(callee->arg_size() - 1);\n+      if (nep->Opcode() == Op_ConP) {\n+        const TypeOopPtr* oop_ptr = nep->bottom_type()->is_oopptr();\n+        ciNativeEntryPoint* nep = oop_ptr->const_oop()->as_native_entry_point();\n+        return new NativeCallGenerator(callee, nep);\n+      } else {\n+        print_inlining_failure(C, callee, jvms->depth() - 1, jvms->bci(),\n+                               \"NativeEntryPoint not constant\");\n+      }\n+    }\n+    break;\n+\n","filename":"src\/hotspot\/share\/opto\/callGenerator.cpp","additions":41,"deletions":0,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -49,0 +49,1 @@\n+#include \"code\/vmreg.hpp\"\n@@ -400,0 +401,12 @@\n+\/\/---------------------print_method_with_lineno--------------------------------\n+void JVMState::print_method_with_lineno(outputStream* st, bool show_name) const {\n+  if (show_name) _method->print_short_name(st);\n+\n+  int lineno = _method->line_number_from_bci(_bci);\n+  if (lineno != -1) {\n+    st->print(\" @ bci:%d (line %d)\", _bci, lineno);\n+  } else {\n+    st->print(\" @ bci:%d\", _bci);\n+  }\n+}\n+\n@@ -404,2 +417,1 @@\n-    _method->print_short_name(st);\n-    st->print(\" @ bci:%d \",_bci);\n+    print_method_with_lineno(st, true);\n@@ -539,3 +551,1 @@\n-    if (!printed)\n-      _method->print_short_name(st);\n-    st->print(\" @ bci:%d\",_bci);\n+    print_method_with_lineno(st, !printed);\n@@ -1317,0 +1327,65 @@\n+\/\/=============================================================================\n+uint CallNativeNode::size_of() const { return sizeof(*this); }\n+bool CallNativeNode::cmp( const Node &n ) const {\n+  CallNativeNode &call = (CallNativeNode&)n;\n+  return CallNode::cmp(call) && !strcmp(_name,call._name)\n+    && _arg_regs == call._arg_regs && _ret_regs == call._ret_regs;\n+}\n+Node* CallNativeNode::match(const ProjNode *proj, const Matcher *matcher, const RegMask* mask) {\n+  switch (proj->_con) {\n+    case TypeFunc::Control:\n+    case TypeFunc::I_O:\n+    case TypeFunc::Memory:\n+      return new MachProjNode(this,proj->_con,RegMask::Empty,MachProjNode::unmatched_proj);\n+    case TypeFunc::ReturnAdr:\n+    case TypeFunc::FramePtr:\n+      ShouldNotReachHere();\n+    case TypeFunc::Parms: {\n+      const Type* field_at_con = tf()->range_sig()->field_at(proj->_con);\n+      const BasicType bt = field_at_con->basic_type();\n+      OptoReg::Name optoreg = OptoReg::as_OptoReg(_ret_regs.at(proj->_con - TypeFunc::Parms));\n+      OptoRegPair regs;\n+      if (bt == T_DOUBLE || bt == T_LONG) {\n+        regs.set2(optoreg);\n+      } else {\n+        regs.set1(optoreg);\n+      }\n+      RegMask rm = RegMask(regs.first());\n+      if(OptoReg::is_valid(regs.second()))\n+        rm.Insert(regs.second());\n+      return new MachProjNode(this, proj->_con, rm, field_at_con->ideal_reg());\n+    }\n+    case TypeFunc::Parms + 1: {\n+      assert(tf()->range_sig()->field_at(proj->_con) == Type::HALF, \"Expected HALF\");\n+      assert(_ret_regs.at(proj->_con - TypeFunc::Parms) == VMRegImpl::Bad(), \"Unexpected register for Type::HALF\");\n+      \/\/ 2nd half of doubles and longs\n+      return new MachProjNode(this, proj->_con, RegMask::Empty, (uint) OptoReg::Bad);\n+    }\n+    default:\n+      ShouldNotReachHere();\n+  }\n+  return NULL;\n+}\n+#ifndef PRODUCT\n+void CallNativeNode::print_regs(const GrowableArray<VMReg>& regs, outputStream* st) {\n+  st->print(\"{ \");\n+  for (int i = 0; i < regs.length(); i++) {\n+    regs.at(i)->print_on(st);\n+    if (i < regs.length() - 1) {\n+      st->print(\", \");\n+    }\n+  }\n+  st->print(\" } \");\n+}\n+\n+void CallNativeNode::dump_spec(outputStream *st) const {\n+  st->print(\"# \");\n+  st->print(\"%s \", _name);\n+  st->print(\"_arg_regs: \");\n+  print_regs(_arg_regs, st);\n+  st->print(\"_ret_regs: \");\n+  print_regs(_ret_regs, st);\n+  CallNode::dump_spec(st);\n+}\n+#endif\n+\n@@ -1329,0 +1404,34 @@\n+void CallNativeNode::calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const {\n+  assert((tf()->domain_sig()->cnt() - TypeFunc::Parms) == argcnt, \"arg counts must match!\");\n+#ifdef ASSERT\n+  for (uint i = 0; i < argcnt; i++) {\n+    assert(tf()->domain_sig()->field_at(TypeFunc::Parms + i)->basic_type() == sig_bt[i], \"types must match!\");\n+  }\n+#endif\n+  for (uint i = 0; i < argcnt; i++) {\n+    switch (sig_bt[i]) {\n+      case T_BOOLEAN:\n+      case T_CHAR:\n+      case T_BYTE:\n+      case T_SHORT:\n+      case T_INT:\n+      case T_FLOAT:\n+        parm_regs[i].set1(_arg_regs.at(i));\n+        break;\n+      case T_LONG:\n+      case T_DOUBLE:\n+        assert((i + 1) < argcnt && sig_bt[i + 1] == T_VOID, \"expecting half\");\n+        parm_regs[i].set2(_arg_regs.at(i));\n+        break;\n+      case T_VOID: \/\/ Halves of longs and doubles\n+        assert(i != 0 && (sig_bt[i - 1] == T_LONG || sig_bt[i - 1] == T_DOUBLE), \"expecting half\");\n+        assert(_arg_regs.at(i) == VMRegImpl::Bad(), \"expecting bad reg\");\n+        parm_regs[i].set_bad();\n+        break;\n+      default:\n+        ShouldNotReachHere();\n+        break;\n+    }\n+  }\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.cpp","additions":114,"deletions":5,"binary":false,"changes":119,"status":"modified"},{"patch":"@@ -35,0 +35,1 @@\n+#include \"utilities\/growableArray.hpp\"\n@@ -51,0 +52,1 @@\n+class     CallNativeNode;\n@@ -308,0 +310,1 @@\n+  void      print_method_with_lineno(outputStream* st, bool show_name) const;\n@@ -845,0 +848,36 @@\n+\/\/------------------------------CallNativeNode-----------------------------------\n+\/\/ Make a direct call into a foreign function with an arbitrary ABI\n+\/\/ safepoints\n+class CallNativeNode : public CallNode {\n+  friend class MachCallNativeNode;\n+  virtual bool cmp( const Node &n ) const;\n+  virtual uint size_of() const;\n+  static void print_regs(const GrowableArray<VMReg>& regs, outputStream* st);\n+public:\n+  GrowableArray<VMReg> _arg_regs;\n+  GrowableArray<VMReg> _ret_regs;\n+  const int _shadow_space_bytes;\n+  const bool _need_transition;\n+\n+  CallNativeNode(const TypeFunc* tf, address addr, const char* name,\n+                 const TypePtr* adr_type,\n+                 const GrowableArray<VMReg>& arg_regs,\n+                 const GrowableArray<VMReg>& ret_regs,\n+                 int shadow_space_bytes,\n+                 bool need_transition)\n+    : CallNode(tf, addr, adr_type), _arg_regs(arg_regs),\n+      _ret_regs(ret_regs), _shadow_space_bytes(shadow_space_bytes),\n+      _need_transition(need_transition)\n+  {\n+    init_class_id(Class_CallNative);\n+    _name = name;\n+  }\n+  virtual int   Opcode() const;\n+  virtual bool  guaranteed_safepoint()  { return _need_transition; }\n+  virtual Node* match(const ProjNode *proj, const Matcher *m, const RegMask* mask);\n+  virtual void  calling_convention( BasicType* sig_bt, VMRegPair *parm_regs, uint argcnt ) const;\n+#ifndef PRODUCT\n+  virtual void  dump_spec(outputStream *st) const;\n+#endif\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/callnode.hpp","additions":39,"deletions":0,"binary":false,"changes":39,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 1997, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 1997, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -62,0 +62,1 @@\n+macro(CallNative)\n@@ -412,0 +413,3 @@\n+macro(LoadVectorMasked)\n+macro(StoreVectorMasked)\n+macro(VectorMaskGen)\n","filename":"src\/hotspot\/share\/opto\/classes.hpp","additions":5,"deletions":1,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -542,0 +542,1 @@\n+                  _native_invokers(comp_arena(), 1, 0, NULL),\n@@ -840,0 +841,1 @@\n+    _native_invokers(),\n@@ -3319,0 +3321,1 @@\n+  case Op_CallNative:\n@@ -3770,0 +3773,3 @@\n+  case Op_VectorMaskGen:\n+  case Op_LoadVectorMasked:\n+  case Op_StoreVectorMasked:\n@@ -5145,0 +5151,3 @@\n+void Compile::add_native_invoker(BufferBlob* stub) {\n+  _native_invokers.append(stub);\n+}\n","filename":"src\/hotspot\/share\/opto\/compile.cpp","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"},{"patch":"@@ -393,0 +393,1 @@\n+  GrowableArray<BufferBlob*>    _native_invokers;\n@@ -958,0 +959,4 @@\n+  void add_native_invoker(BufferBlob* stub);\n+\n+  const GrowableArray<BufferBlob*>& native_invokers() const { return _native_invokers; }\n+\n","filename":"src\/hotspot\/share\/opto\/compile.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -30,0 +30,3 @@\n+#include \"ci\/ciNativeEntryPoint.hpp\"\n+#include \"ci\/ciObjArray.hpp\"\n+#include \"asm\/register.hpp\"\n@@ -54,0 +57,1 @@\n+#include \"utilities\/growableArray.hpp\"\n@@ -2675,0 +2679,122 @@\n+\/\/ i2b\n+Node* GraphKit::sign_extend_byte(Node* in) {\n+  Node* tmp = _gvn.transform(new LShiftINode(in, _gvn.intcon(24)));\n+  return _gvn.transform(new RShiftINode(tmp, _gvn.intcon(24)));\n+}\n+\n+\/\/ i2s\n+Node* GraphKit::sign_extend_short(Node* in) {\n+  Node* tmp = _gvn.transform(new LShiftINode(in, _gvn.intcon(16)));\n+  return _gvn.transform(new RShiftINode(tmp, _gvn.intcon(16)));\n+}\n+\n+\/\/-----------------------------make_native_call-------------------------------\n+Node* GraphKit::make_native_call(const TypeFunc* call_type, uint nargs, ciNativeEntryPoint* nep) {\n+  uint n_filtered_args = nargs - 2; \/\/ -fallback, -nep;\n+  ResourceMark rm;\n+  Node** argument_nodes = NEW_RESOURCE_ARRAY(Node*, n_filtered_args);\n+  const Type** arg_types = TypeTuple::fields(n_filtered_args);\n+  GrowableArray<VMReg> arg_regs(C->comp_arena(), n_filtered_args, n_filtered_args, VMRegImpl::Bad());\n+\n+  VMReg* argRegs = nep->argMoves();\n+  {\n+    for (uint vm_arg_pos = 0, java_arg_read_pos = 0;\n+        vm_arg_pos < n_filtered_args; vm_arg_pos++) {\n+      uint vm_unfiltered_arg_pos = vm_arg_pos + 1; \/\/ +1 to skip fallback handle argument\n+      Node* node = argument(vm_unfiltered_arg_pos);\n+      const Type* type = call_type->domain_sig()->field_at(TypeFunc::Parms + vm_unfiltered_arg_pos);\n+      VMReg reg = type == Type::HALF\n+        ? VMRegImpl::Bad()\n+        : argRegs[java_arg_read_pos++];\n+\n+      argument_nodes[vm_arg_pos] = node;\n+      arg_types[TypeFunc::Parms + vm_arg_pos] = type;\n+      arg_regs.at_put(vm_arg_pos, reg);\n+    }\n+  }\n+\n+  uint n_returns = call_type->range_sig()->cnt() - TypeFunc::Parms;\n+  GrowableArray<VMReg> ret_regs(C->comp_arena(), n_returns, n_returns, VMRegImpl::Bad());\n+  const Type** ret_types = TypeTuple::fields(n_returns);\n+\n+  VMReg* retRegs = nep->returnMoves();\n+  {\n+    for (uint vm_ret_pos = 0, java_ret_read_pos = 0;\n+        vm_ret_pos < n_returns; vm_ret_pos++) { \/\/ 0 or 1\n+      const Type* type = call_type->range_sig()->field_at(TypeFunc::Parms + vm_ret_pos);\n+      VMReg reg = type == Type::HALF\n+        ? VMRegImpl::Bad()\n+        : retRegs[java_ret_read_pos++];\n+\n+      ret_regs.at_put(vm_ret_pos, reg);\n+      ret_types[TypeFunc::Parms + vm_ret_pos] = type;\n+    }\n+  }\n+\n+  const TypeFunc* new_call_type = TypeFunc::make(\n+    TypeTuple::make(TypeFunc::Parms + n_filtered_args, arg_types),\n+    TypeTuple::make(TypeFunc::Parms + n_returns, ret_types)\n+  );\n+\n+  address call_addr = nep->entry_point();\n+  if (nep->need_transition()) {\n+    BufferBlob* invoker = SharedRuntime::make_native_invoker(call_addr,\n+                                                             nep->shadow_space(),\n+                                                             arg_regs, ret_regs);\n+    if (invoker == NULL) {\n+      C->record_failure(\"native invoker not implemented on this platform\");\n+      return NULL;\n+    }\n+    C->add_native_invoker(invoker);\n+    call_addr = invoker->code_begin();\n+  }\n+  assert(call_addr != NULL, \"sanity\");\n+\n+  CallNativeNode* call = new CallNativeNode(new_call_type, call_addr, nep->name(), TypePtr::BOTTOM,\n+                                            arg_regs,\n+                                            ret_regs,\n+                                            nep->shadow_space(),\n+                                            nep->need_transition());\n+\n+  if (call->_need_transition) {\n+    add_safepoint_edges(call);\n+  }\n+\n+  set_predefined_input_for_runtime_call(call);\n+\n+  for (uint i = 0; i < n_filtered_args; i++) {\n+    call->init_req(i + TypeFunc::Parms, argument_nodes[i]);\n+  }\n+\n+  Node* c = gvn().transform(call);\n+  assert(c == call, \"cannot disappear\");\n+\n+  set_predefined_output_for_runtime_call(call);\n+\n+  Node* ret;\n+  if (method() == NULL || method()->return_type()->basic_type() == T_VOID) {\n+    ret = top();\n+  } else {\n+    ret =  gvn().transform(new ProjNode(call, TypeFunc::Parms));\n+    \/\/ Unpack native results if needed\n+    \/\/ Need this method type since it's unerased\n+    switch (nep->method_type()->rtype()->basic_type()) {\n+      case T_CHAR:\n+        ret = _gvn.transform(new AndINode(ret, _gvn.intcon(0xFFFF)));\n+        break;\n+      case T_BYTE:\n+        ret = sign_extend_byte(ret);\n+        break;\n+      case T_SHORT:\n+        ret = sign_extend_short(ret);\n+        break;\n+      default: \/\/ do nothing\n+        break;\n+    }\n+  }\n+\n+  push_node(method()->return_type()->basic_type(), ret);\n+\n+  return call;\n+}\n+\n","filename":"src\/hotspot\/share\/opto\/graphKit.cpp","additions":126,"deletions":0,"binary":false,"changes":126,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2001, 2019, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2001, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -830,0 +830,6 @@\n+\n+  Node* sign_extend_byte(Node* in);\n+  Node* sign_extend_short(Node* in);\n+\n+  Node* make_native_call(const TypeFunc* call_type, uint nargs, ciNativeEntryPoint* nep);\n+\n@@ -929,1 +935,0 @@\n-\n@@ -931,0 +936,5 @@\n+\n+  \/\/ Vector API support (implemented in vectorIntrinsics.cpp)\n+  Node* box_vector(Node* in, const TypeInstPtr* vbox_type, BasicType elem_bt, int num_elem, bool deoptimize_on_exception = false);\n+  Node* unbox_vector(Node* in, const TypeInstPtr* vbox_type, BasicType elem_bt, int num_elem, bool shuffle_to_vector = false);\n+  Node* vector_shift_count(Node* cnt, int shift_op, BasicType bt, int num_elem);\n","filename":"src\/hotspot\/share\/opto\/graphKit.hpp","additions":12,"deletions":2,"binary":false,"changes":14,"status":"modified"},{"patch":"@@ -1625,1 +1625,17 @@\n-  set_req(1, igvn->intcon(br == tb ? 1 : 0));\n+  bool is_always_true = br == tb;\n+  set_req(1, igvn->intcon(is_always_true ? 1 : 0));\n+\n+  \/\/ Update any data dependencies to the directly dominating test. This subsumed test is not immediately removed by igvn\n+  \/\/ and therefore subsequent optimizations might miss these data dependencies otherwise. There might be a dead loop\n+  \/\/ ('always_taken_proj' == 'pre') that is cleaned up later. Skip this case to make the iterator work properly.\n+  Node* always_taken_proj = proj_out(is_always_true);\n+  if (always_taken_proj != pre) {\n+    for (DUIterator_Fast imax, i = always_taken_proj->fast_outs(imax); i < imax; i++) {\n+      Node* u = always_taken_proj->fast_out(i);\n+      if (!u->is_CFG()) {\n+        igvn->replace_input_of(u, 0, pre);\n+        --i;\n+        --imax;\n+      }\n+    }\n+  }\n","filename":"src\/hotspot\/share\/opto\/ifnode.cpp","additions":17,"deletions":1,"binary":false,"changes":18,"status":"modified"},{"patch":"@@ -715,0 +715,1 @@\n+        case Op_StoreVectorMasked:\n@@ -890,0 +891,6 @@\n+    case Op_CallNative:\n+      \/\/ We use the c reg save policy here since Panama\n+      \/\/ only supports the C ABI currently.\n+      \/\/ TODO compute actual save policy based on nep->abi\n+      save_policy = _matcher._c_reg_save_policy;\n+      break;\n@@ -903,1 +910,8 @@\n-  bool exclude_soe = op == Op_CallRuntime;\n+  \/\/\n+  \/\/ Also, native callees can not save oops, so we kill the SOE registers\n+  \/\/ here in case a native call has a safepoint. This doesn't work for\n+  \/\/ RBP though, which seems to be special-cased elsewhere to always be\n+  \/\/ treated as alive, so we instead manually save the location of RBP\n+  \/\/ before doing the native call (see NativeInvokerGenerator::generate).\n+  bool exclude_soe = op == Op_CallRuntime\n+    || (op == Op_CallNative && mcall->guaranteed_safepoint());\n","filename":"src\/hotspot\/share\/opto\/lcm.cpp","additions":15,"deletions":1,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -360,3 +360,0 @@\n-  Node* box_vector(Node* in, const TypeInstPtr* vbox_type, BasicType bt, int num_elem);\n-  Node* unbox_vector(Node* in, const TypeInstPtr* vbox_type, BasicType bt, int num_elem, bool shuffle_to_vector = false);\n-  Node* shift_count(Node* cnt, int shift_op, BasicType bt, int num_elem);\n","filename":"src\/hotspot\/share\/opto\/library_call.hpp","additions":0,"deletions":3,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -659,0 +659,1 @@\n+      _igvn._worklist.push(mm);\n","filename":"src\/hotspot\/share\/opto\/loopnode.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -848,0 +848,17 @@\n+uint MachCallNativeNode::size_of() const { return sizeof(*this); }\n+bool MachCallNativeNode::cmp( const Node &n ) const {\n+  MachCallNativeNode &call = (MachCallNativeNode&)n;\n+  return MachCallNode::cmp(call) && !strcmp(_name,call._name)\n+    && _arg_regs == call._arg_regs && _ret_regs == call._ret_regs;\n+}\n+#ifndef PRODUCT\n+void MachCallNativeNode::dump_spec(outputStream *st) const {\n+  st->print(\"%s \",_name);\n+  st->print(\"_arg_regs: \");\n+  CallNativeNode::print_regs(_arg_regs, st);\n+  st->print(\"_ret_regs: \");\n+  CallNativeNode::print_regs(_ret_regs, st);\n+  MachCallNode::dump_spec(st);\n+}\n+#endif\n+\/\/=============================================================================\n","filename":"src\/hotspot\/share\/opto\/machnode.cpp","additions":17,"deletions":0,"binary":false,"changes":17,"status":"modified"},{"patch":"@@ -34,0 +34,1 @@\n+#include \"utilities\/growableArray.hpp\"\n@@ -42,0 +43,1 @@\n+class MachCallNativeNode;\n@@ -919,0 +921,1 @@\n+  bool         _guaranteed_safepoint; \/\/ Do we need to observe safepoint?\n@@ -924,3 +927,4 @@\n-  void set_tf(const TypeFunc* tf) { _tf = tf; }\n-  void set_entry_point(address p) { _entry_point = p; }\n-  void set_cnt(float c)           { _cnt = c; }\n+  void set_tf(const TypeFunc* tf)       { _tf = tf; }\n+  void set_entry_point(address p)       { _entry_point = p; }\n+  void set_cnt(float c)                 { _cnt = c; }\n+  void set_guaranteed_safepoint(bool b) { _guaranteed_safepoint = b; }\n@@ -945,0 +949,2 @@\n+  bool guaranteed_safepoint() const { return _guaranteed_safepoint; }\n+\n@@ -1044,0 +1050,19 @@\n+class MachCallNativeNode: public MachCallNode {\n+  virtual bool cmp( const Node &n ) const;\n+  virtual uint size_of() const;\n+  void print_regs(const GrowableArray<VMReg>& regs, outputStream* st) const;\n+public:\n+  const char *_name;\n+  GrowableArray<VMReg> _arg_regs;\n+  GrowableArray<VMReg> _ret_regs;\n+\n+  MachCallNativeNode() : MachCallNode() {\n+    init_class_id(Class_MachCallNative);\n+  }\n+\n+  virtual int ret_addr_offset();\n+#ifndef PRODUCT\n+  virtual void dump_spec(outputStream *st) const;\n+#endif\n+};\n+\n","filename":"src\/hotspot\/share\/opto\/machnode.hpp","additions":28,"deletions":3,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -236,2 +236,4 @@\n-          assert(ac != NULL && ac->is_clonebasic(), \"Only basic clone is a non escaping clone\");\n-          return ac;\n+          if (ac != NULL) {\n+            assert(ac->is_clonebasic(), \"Only basic clone is a non escaping clone\");\n+            return ac;\n+          }\n","filename":"src\/hotspot\/share\/opto\/macro.cpp","additions":4,"deletions":2,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -132,0 +132,5 @@\n+\n+  void generate_partial_inlining_block(Node** ctrl, MergeMemNode** mem, const TypePtr* adr_type,\n+                                       RegionNode** exit_block, Node** result_memory, Node* length,\n+                                       Node* src_start, Node* dst_start, BasicType type);\n+\n@@ -188,1 +193,1 @@\n-  void generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n+  bool generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n","filename":"src\/hotspot\/share\/opto\/macro.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"opto\/vectornode.hpp\"\n@@ -177,0 +178,92 @@\n+\/\/\n+\/\/ Partial in-lining handling for smaller conjoint\/disjoint array copies having\n+\/\/ length(in bytes) less than ArrayCopyPartialInlineSize.\n+\/\/  if (length <= ArrayCopyPartialInlineSize) {\n+\/\/    partial_inlining_block:\n+\/\/      mask = Mask_Gen\n+\/\/      vload = LoadVectorMasked src , mask\n+\/\/      StoreVectorMasked dst, mask, vload\n+\/\/  } else {\n+\/\/    stub_block:\n+\/\/      callstub array_copy\n+\/\/  }\n+\/\/  exit_block:\n+\/\/    Phi = label partial_inlining_block:mem , label stub_block:mem (filled by caller)\n+\/\/    mem = MergeMem (Phi)\n+\/\/    control = stub_block\n+\/\/\n+\/\/  Exit_block and associated phi(memory) are partially initialized for partial_in-lining_block\n+\/\/  edges. Remaining edges for exit_block coming from stub_block are connected by the caller\n+\/\/  post stub nodes creation.\n+\/\/\n+\n+void PhaseMacroExpand::generate_partial_inlining_block(Node** ctrl, MergeMemNode** mem, const TypePtr* adr_type,\n+                                                       RegionNode** exit_block, Node** result_memory, Node* length,\n+                                                       Node* src_start, Node* dst_start, BasicType type) {\n+  const TypePtr *src_adr_type = _igvn.type(src_start)->isa_ptr();\n+  Node* inline_block = NULL;\n+  Node* stub_block = NULL;\n+\n+  int const_len = -1;\n+  const TypeInt* lty = NULL;\n+  uint shift  = exact_log2(type2aelembytes(type));\n+  if (length->Opcode() == Op_ConvI2L) {\n+    lty = _igvn.type(length->in(1))->isa_int();\n+  } else  {\n+    lty = _igvn.type(length)->isa_int();\n+  }\n+  if (lty && lty->is_con()) {\n+    const_len = lty->get_con() << shift;\n+  }\n+\n+  \/\/ Return if copy length is greater than partial inline size limit or\n+  \/\/ target does not supports masked load\/stores.\n+  int lane_count = ArrayCopyNode::get_partial_inline_vector_lane_count(type, const_len);\n+  if ( const_len > ArrayCopyPartialInlineSize ||\n+      !Matcher::match_rule_supported_vector(Op_LoadVectorMasked, lane_count, type)  ||\n+      !Matcher::match_rule_supported_vector(Op_StoreVectorMasked, lane_count, type) ||\n+      !Matcher::match_rule_supported_vector(Op_VectorMaskGen, lane_count, type)) {\n+    return;\n+  }\n+\n+  Node* copy_bytes = new LShiftXNode(length, intcon(shift));\n+  transform_later(copy_bytes);\n+\n+  Node* cmp_le = new CmpULNode(copy_bytes, longcon(ArrayCopyPartialInlineSize));\n+  transform_later(cmp_le);\n+  Node* bol_le = new BoolNode(cmp_le, BoolTest::le);\n+  transform_later(bol_le);\n+  inline_block  = generate_guard(ctrl, bol_le, NULL, PROB_FAIR);\n+  stub_block = *ctrl;\n+\n+  Node* mask_gen =  new VectorMaskGenNode(length, TypeLong::LONG, Type::get_const_basic_type(type));\n+  transform_later(mask_gen);\n+\n+  unsigned vec_size = lane_count *  type2aelembytes(type);\n+  if (C->max_vector_size() < vec_size) {\n+    C->set_max_vector_size(vec_size);\n+  }\n+\n+  const TypeVect * vt = TypeVect::make(type, lane_count);\n+  Node* mm = (*mem)->memory_at(C->get_alias_index(src_adr_type));\n+  Node* masked_load = new LoadVectorMaskedNode(inline_block, mm, src_start,\n+                                               src_adr_type, vt, mask_gen);\n+  transform_later(masked_load);\n+\n+  mm = (*mem)->memory_at(C->get_alias_index(adr_type));\n+  Node* masked_store = new StoreVectorMaskedNode(inline_block, mm, dst_start,\n+                                                 masked_load, adr_type, mask_gen);\n+  transform_later(masked_store);\n+\n+  \/\/ Convergence region for inline_block and stub_block.\n+  *exit_block = new RegionNode(3);\n+  transform_later(*exit_block);\n+  (*exit_block)->init_req(1, inline_block);\n+  *result_memory = new PhiNode(*exit_block, Type::MEMORY, adr_type);\n+  transform_later(*result_memory);\n+  (*result_memory)->init_req(1, masked_store);\n+\n+  *ctrl = stub_block;\n+}\n+\n+\n@@ -629,0 +722,1 @@\n+  bool is_partial_array_copy = false;\n@@ -635,4 +729,4 @@\n-    generate_unchecked_arraycopy(&local_ctrl, &local_mem,\n-                                 adr_type, copy_type, disjoint_bases,\n-                                 src, src_offset, dest, dest_offset,\n-                                 ConvI2X(copy_length), dest_uninitialized);\n+    is_partial_array_copy = generate_unchecked_arraycopy(&local_ctrl, &local_mem,\n+                                                         adr_type, copy_type, disjoint_bases,\n+                                                         src, src_offset, dest, dest_offset,\n+                                                         ConvI2X(copy_length), dest_uninitialized);\n@@ -791,0 +885,6 @@\n+  if (is_partial_array_copy) {\n+    assert((*ctrl)->is_Proj(), \"MemBar control projection\");\n+    assert((*ctrl)->in(0)->isa_MemBar(), \"MemBar node\");\n+    (*ctrl)->in(0)->isa_MemBar()->set_trailing_partial_array_copy();\n+  }\n+\n@@ -797,1 +897,1 @@\n-  if (dest_t->is_known_instance()) {\n+  if (dest_t->is_known_instance() && !is_partial_array_copy) {\n@@ -1138,1 +1238,1 @@\n-void PhaseMacroExpand::generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n+bool PhaseMacroExpand::generate_unchecked_arraycopy(Node** ctrl, MergeMemNode** mem,\n@@ -1145,1 +1245,1 @@\n-  if ((*ctrl)->is_top()) return;\n+  if ((*ctrl)->is_top()) return false;\n@@ -1160,0 +1260,8 @@\n+  Node* result_memory = NULL;\n+  RegionNode* exit_block = NULL;\n+  if (ArrayCopyPartialInlineSize > 0 && is_subword_type(basic_elem_type) &&\n+    Matcher::vector_width_in_bytes(basic_elem_type) >= 16) {\n+    generate_partial_inlining_block(ctrl, mem, adr_type, &exit_block, &result_memory,\n+                                    copy_length, src_start, dest_start, basic_elem_type);\n+  }\n+\n@@ -1165,0 +1273,20 @@\n+\n+  \/\/ Connecting remaining edges for exit_block coming from stub_block.\n+  if (exit_block) {\n+    exit_block->init_req(2, *ctrl);\n+\n+    \/\/ Memory edge corresponding to stub_region.\n+    result_memory->init_req(2, *mem);\n+\n+    uint alias_idx = C->get_alias_index(adr_type);\n+    if (alias_idx != Compile::AliasIdxBot) {\n+      *mem = MergeMemNode::make(*mem);\n+      (*mem)->set_memory_at(alias_idx, result_memory);\n+    } else {\n+      *mem = MergeMemNode::make(result_memory);\n+    }\n+    transform_later(*mem);\n+    *ctrl = exit_block;\n+    return true;\n+  }\n+  return false;\n","filename":"src\/hotspot\/share\/opto\/macroArrayCopy.cpp","additions":135,"deletions":7,"binary":false,"changes":142,"status":"modified"},{"patch":"@@ -1278,3 +1278,4 @@\n-    mcall->set_tf(         call->tf());\n-    mcall->set_entry_point(call->entry_point());\n-    mcall->set_cnt(        call->cnt());\n+    mcall->set_tf(                  call->tf());\n+    mcall->set_entry_point(         call->entry_point());\n+    mcall->set_cnt(                 call->cnt());\n+    mcall->set_guaranteed_safepoint(call->guaranteed_safepoint());\n@@ -1307,0 +1308,7 @@\n+    else if( mcall->is_MachCallNative() ) {\n+      MachCallNativeNode* mach_call_native = mcall->as_MachCallNative();\n+      CallNativeNode* call_native = call->as_CallNative();\n+      mach_call_native->_name = call_native->_name;\n+      mach_call_native->_arg_regs = call_native->_arg_regs;\n+      mach_call_native->_ret_regs = call_native->_ret_regs;\n+    }\n@@ -1341,0 +1349,2 @@\n+  if( call != NULL && call->is_CallNative() )\n+    out_arg_limit_per_call = OptoReg::add(out_arg_limit_per_call, call->as_CallNative()->_shadow_space_bytes);\n@@ -1500,5 +1510,7 @@\n-  for( i = 0; i < NUM_OPERANDS; i++ ) {\n-    if( s->valid(i) &&                \/\/ valid entry and\n-        s->_cost[i] < cost &&         \/\/ low cost and\n-        s->_rule[i] >= NUM_OPERANDS ) \/\/ not an operand\n-      cost = s->_cost[mincost=i];\n+  for (i = 0; i < NUM_OPERANDS; i++) {\n+    if (s->valid(i) &&               \/\/ valid entry and\n+        s->cost(i) < cost &&         \/\/ low cost and\n+        s->rule(i) >= NUM_OPERANDS) {\/\/ not an operand\n+      mincost = i;\n+      cost = s->cost(i);\n+    }\n@@ -1515,1 +1527,1 @@\n-  MachNode *m = ReduceInst( s, s->_rule[mincost], mem );\n+  MachNode *m = ReduceInst(s, s->rule(mincost), mem);\n@@ -1883,1 +1895,1 @@\n-void Matcher::ReduceInst_Chain_Rule( State *s, int rule, Node *&mem, MachNode *mach ) {\n+void Matcher::ReduceInst_Chain_Rule(State* s, int rule, Node* &mem, MachNode* mach) {\n@@ -1888,1 +1900,1 @@\n-  int opnd_class_instance = s->_rule[op];\n+  unsigned int opnd_class_instance = s->rule(op);\n@@ -1893,1 +1905,1 @@\n-  int newrule = s->_rule[catch_op];\n+  unsigned int newrule = s->rule(catch_op);\n@@ -1895,1 +1907,1 @@\n-  if( newrule < NUM_OPERANDS ) {\n+  if (newrule < NUM_OPERANDS) {\n@@ -1897,2 +1909,1 @@\n-    assert( 0 <= opnd_class_instance && opnd_class_instance < NUM_OPERANDS,\n-            \"Bad AD file: Instruction chain rule must chain from operand\");\n+    assert(opnd_class_instance < NUM_OPERANDS, \"Bad AD file: Instruction chain rule must chain from operand\");\n@@ -1902,1 +1913,1 @@\n-    ReduceOper( s, newrule, mem, mach );\n+    ReduceOper(s, newrule, mem, mach);\n@@ -1905,1 +1916,1 @@\n-    assert( newrule >= _LAST_MACH_OPER, \"Do NOT chain from internal operand\");\n+    assert(newrule >= _LAST_MACH_OPER, \"Do NOT chain from internal operand\");\n@@ -1943,1 +1954,1 @@\n-    int opnd_class_instance = newstate->_rule[op];\n+    int opnd_class_instance = newstate->rule(op);\n@@ -1948,1 +1959,1 @@\n-    int newrule = newstate->_rule[catch_op];\n+    int newrule = newstate->rule(catch_op);\n@@ -1950,1 +1961,1 @@\n-    if( newrule < NUM_OPERANDS ) { \/\/ Operand\/operandClass or internalOp\/instruction?\n+    if (newrule < NUM_OPERANDS) { \/\/ Operand\/operandClass or internalOp\/instruction?\n@@ -1954,1 +1965,1 @@\n-      ReduceOper( newstate, newrule, mem, mach );\n+      ReduceOper(newstate, newrule, mem, mach);\n@@ -1957,1 +1968,1 @@\n-      if( newrule < _LAST_MACH_OPER ) { \/\/ internal operand or instruction?\n+      if (newrule < _LAST_MACH_OPER) { \/\/ internal operand or instruction?\n@@ -1960,1 +1971,1 @@\n-        num_opnds = ReduceInst_Interior( newstate, newrule, mem, mach, num_opnds );\n+        num_opnds = ReduceInst_Interior(newstate, newrule, mem, mach, num_opnds);\n@@ -2012,1 +2023,1 @@\n-  for( uint i=0; kid != NULL && i<2; kid = s->_kids[1], i++ ) {   \/\/ binary tree\n+  for (uint i = 0; kid != NULL && i < 2; kid = s->_kids[1], i++) {   \/\/ binary tree\n@@ -2014,4 +2025,5 @@\n-    if( i == 0)\n-      newrule = kid->_rule[_leftOp[rule]];\n-    else\n-      newrule = kid->_rule[_rightOp[rule]];\n+    if( i == 0) {\n+      newrule = kid->rule(_leftOp[rule]);\n+    } else {\n+      newrule = kid->rule(_rightOp[rule]);\n+    }\n@@ -2019,1 +2031,1 @@\n-    if( newrule < _LAST_MACH_OPER ) { \/\/ Operand or instruction?\n+    if (newrule < _LAST_MACH_OPER) { \/\/ Operand or instruction?\n@@ -2021,1 +2033,1 @@\n-      ReduceOper( kid, newrule, mem, mach );\n+      ReduceOper(kid, newrule, mem, mach);\n@@ -2248,0 +2260,1 @@\n+    case Op_LoadVectorMasked:\n@@ -2350,0 +2363,6 @@\n+    case Op_StoreVectorMasked: {\n+      Node* pair = new BinaryNode(n->in(3), n->in(4));\n+      n->set_req(3, pair);\n+      n->del_req(4);\n+      break;\n+    }\n@@ -2862,1 +2881,1 @@\n-State::State(void) {\n+State::State(void) : _rule() {\n@@ -2867,3 +2886,0 @@\n-  \/\/memset(_cost, -1, sizeof(_cost));\n-  \/\/memset(_rule, -1, sizeof(_rule));\n-  memset(_valid, 0, sizeof(_valid));\n@@ -2891,1 +2907,1 @@\n-  for( int j = 0; j < depth; j++ )\n+  for (int j = 0; j < depth; j++) {\n@@ -2893,0 +2909,1 @@\n+  }\n@@ -2896,1 +2913,1 @@\n-  for( i = 0; i < _LAST_MACH_OPER; i++ )\n+  for (i = 0; i < _LAST_MACH_OPER; i++) {\n@@ -2898,2 +2915,2 @@\n-    if( valid(i) ) {\n-      for( int j = 0; j < depth; j++ )\n+    if (valid(i)) {\n+      for (int j = 0; j < depth; j++) {\n@@ -2901,4 +2918,6 @@\n-        assert(_cost[i] != max_juint, \"cost must be a valid value\");\n-        assert(_rule[i] < _last_Mach_Node, \"rule[i] must be valid rule\");\n-        tty->print_cr(\"%s  %d  %s\",\n-                      ruleName[i], _cost[i], ruleName[_rule[i]] );\n+      assert(cost(i) != max_juint, \"cost must be a valid value\");\n+      assert(rule(i) < _last_Mach_Node, \"rule[i] must be valid rule\");\n+      tty->print_cr(\"%s  %d  %s\",\n+                    ruleName[i], cost(i), ruleName[rule(i)] );\n+    }\n+  }\n@@ -2908,3 +2927,5 @@\n-  for( i=0; i<2; i++ )\n-    if( _kids[i] )\n-      _kids[i]->dump(depth+1);\n+  for (i = 0; i < 2; i++) {\n+    if (_kids[i]) {\n+      _kids[i]->dump(depth + 1);\n+    }\n+  }\n","filename":"src\/hotspot\/share\/opto\/matcher.cpp","additions":66,"deletions":45,"binary":false,"changes":111,"status":"modified"},{"patch":"@@ -313,1 +313,1 @@\n-      phase->is_IterGVN()->_worklist.push(this);\n+      igvn->_worklist.push(this);\n@@ -325,1 +325,1 @@\n-    phase->is_IterGVN()->_worklist.push(this);\n+    igvn->_worklist.push(this);\n@@ -356,1 +356,1 @@\n-    phase->is_IterGVN()->_worklist.push(this);\n+    igvn->_worklist.push(this);\n@@ -1765,1 +1765,1 @@\n-        phase->is_IterGVN()->_worklist.push(this);\n+        igvn->_worklist.push(this);\n@@ -2718,1 +2718,3 @@\n-        phase->igvn_rehash_node_delayed(use);\n+        if (phase->is_IterGVN()) {\n+          phase->is_IterGVN()->rehash_node_delayed(use);\n+        }\n@@ -2841,1 +2843,2 @@\n-  if (result != this && phase->is_IterGVN() != NULL) {\n+  PhaseIterGVN* igvn = phase->is_IterGVN();\n+  if (result != this && igvn != NULL) {\n@@ -2848,1 +2851,0 @@\n-      PhaseIterGVN* igvn = phase->is_IterGVN();\n@@ -4068,1 +4070,4 @@\n-  phase->igvn_rehash_node_delayed(this);\n+  PhaseIterGVN* igvn = phase->is_IterGVN();\n+  if (igvn) {\n+    igvn->rehash_node_delayed(this);\n+  }\n","filename":"src\/hotspot\/share\/opto\/memnode.cpp","additions":13,"deletions":8,"binary":false,"changes":21,"status":"modified"},{"patch":"@@ -1204,1 +1204,2 @@\n-    LeadingLoadStore\n+    LeadingLoadStore,\n+    TrailingPartialArrayCopy\n@@ -1241,0 +1242,2 @@\n+  void set_trailing_partial_array_copy() { _kind = TrailingPartialArrayCopy; }\n+  bool trailing_partial_array_copy() const { return _kind == TrailingPartialArrayCopy; }\n","filename":"src\/hotspot\/share\/opto\/memnode.hpp","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -660,7 +660,7 @@\n-static int getShiftCon(PhaseGVN *phase, Node *shiftNode, int retVal) {\n-  const Type *t = phase->type(shiftNode->in(2));\n-  if (t == Type::TOP) return retVal;       \/\/ Right input is dead.\n-  const TypeInt *t2 = t->isa_int();\n-  if (!t2 || !t2->is_con()) return retVal; \/\/ Right input is a constant.\n-\n-  return t2->get_con();\n+static bool const_shift_count(PhaseGVN* phase, Node* shiftNode, int* count) {\n+  const TypeInt* tcount = phase->type(shiftNode->in(2))->isa_int();\n+  if (tcount != NULL && tcount->is_con()) {\n+    *count = tcount->get_con();\n+    return true;\n+  }\n+  return false;\n@@ -669,5 +669,8 @@\n-static int maskShiftAmount(PhaseGVN *phase, Node *shiftNode, int nBits) {\n-  int       shift = getShiftCon(phase, shiftNode, 0);\n-  int maskedShift = shift & (nBits - 1);\n-\n-  if (maskedShift == 0) return 0;         \/\/ Let Identity() handle 0 shift count.\n+static int maskShiftAmount(PhaseGVN* phase, Node* shiftNode, int nBits) {\n+  int count = 0;\n+  if (const_shift_count(phase, shiftNode, &count)) {\n+    int maskedShift = count & (nBits - 1);\n+    if (maskedShift == 0) {\n+      \/\/ Let Identity() handle 0 shift count.\n+      return 0;\n+    }\n@@ -675,3 +678,8 @@\n-  if (shift != maskedShift) {\n-    shiftNode->set_req(2, phase->intcon(maskedShift)); \/\/ Replace shift count with masked value.\n-    phase->igvn_rehash_node_delayed(shiftNode);\n+    if (count != maskedShift) {\n+      shiftNode->set_req(2, phase->intcon(maskedShift)); \/\/ Replace shift count with masked value.\n+      PhaseIterGVN* igvn = phase->is_IterGVN();\n+      if (igvn) {\n+        igvn->rehash_node_delayed(shiftNode);\n+      }\n+    }\n+    return maskedShift;\n@@ -679,2 +687,1 @@\n-\n-  return maskedShift;\n+  return 0;\n@@ -685,1 +692,6 @@\n-  return ((getShiftCon(phase, this, -1) & (BitsPerJavaInteger - 1)) == 0) ? in(1) : this;\n+  int count = 0;\n+  if (const_shift_count(phase, this, &count) && (count & (BitsPerJavaInteger - 1)) == 0) {\n+    \/\/ Shift by a multiple of 32 does nothing\n+    return in(1);\n+  }\n+  return this;\n@@ -793,1 +805,6 @@\n-  return ((getShiftCon(phase, this, -1) & (BitsPerJavaLong - 1)) == 0) ? in(1) : this;\n+  int count = 0;\n+  if (const_shift_count(phase, this, &count) && (count & (BitsPerJavaLong - 1)) == 0) {\n+    \/\/ Shift by a multiple of 64 does nothing\n+    return in(1);\n+  }\n+  return this;\n@@ -898,17 +915,22 @@\n-  int shift = getShiftCon(phase, this, -1);\n-  if (shift == -1) return this;\n-  if ((shift & (BitsPerJavaInteger - 1)) == 0) return in(1);\n-\n-  \/\/ Check for useless sign-masking\n-  if (in(1)->Opcode() == Op_LShiftI &&\n-      in(1)->req() == 3 &&\n-      in(1)->in(2) == in(2)) {\n-    shift &= BitsPerJavaInteger-1; \/\/ semantics of Java shifts\n-    \/\/ Compute masks for which this shifting doesn't change\n-    int lo = (-1 << (BitsPerJavaInteger - ((uint)shift)-1)); \/\/ FFFF8000\n-    int hi = ~lo;               \/\/ 00007FFF\n-    const TypeInt *t11 = phase->type(in(1)->in(1))->isa_int();\n-    if (!t11) return this;\n-    \/\/ Does actual value fit inside of mask?\n-    if (lo <= t11->_lo && t11->_hi <= hi) {\n-      return in(1)->in(1);      \/\/ Then shifting is a nop\n+  int count = 0;\n+  if (const_shift_count(phase, this, &count)) {\n+    if ((count & (BitsPerJavaInteger - 1)) == 0) {\n+      \/\/ Shift by a multiple of 32 does nothing\n+      return in(1);\n+    }\n+    \/\/ Check for useless sign-masking\n+    if (in(1)->Opcode() == Op_LShiftI &&\n+        in(1)->req() == 3 &&\n+        in(1)->in(2) == in(2)) {\n+      count &= BitsPerJavaInteger-1; \/\/ semantics of Java shifts\n+      \/\/ Compute masks for which this shifting doesn't change\n+      int lo = (-1 << (BitsPerJavaInteger - ((uint)count)-1)); \/\/ FFFF8000\n+      int hi = ~lo;               \/\/ 00007FFF\n+      const TypeInt* t11 = phase->type(in(1)->in(1))->isa_int();\n+      if (t11 == NULL) {\n+        return this;\n+      }\n+      \/\/ Does actual value fit inside of mask?\n+      if (lo <= t11->_lo && t11->_hi <= hi) {\n+        return in(1)->in(1);      \/\/ Then shifting is a nop\n+      }\n@@ -917,1 +939,0 @@\n-\n@@ -1102,2 +1123,5 @@\n-  int shift = getShiftCon(phase, this, -1);\n-  if ((shift & (BitsPerJavaInteger - 1)) == 0) return in(1);\n+  int count = 0;\n+  if (const_shift_count(phase, this, &count) && (count & (BitsPerJavaInteger - 1)) == 0) {\n+    \/\/ Shift by a multiple of 32 does nothing\n+    return in(1);\n+  }\n@@ -1286,1 +1310,6 @@\n-  return ((getShiftCon(phase, this, -1) & (BitsPerJavaLong - 1)) == 0) ? in(1) : this;\n+  int count = 0;\n+  if (const_shift_count(phase, this, &count) && (count & (BitsPerJavaLong - 1)) == 0) {\n+    \/\/ Shift by a multiple of 64 does nothing\n+    return in(1);\n+  }\n+  return this;\n@@ -1464,0 +1493,15 @@\n+Node* RotateLeftNode::Identity(PhaseGVN* phase) {\n+  const Type* t1 = phase->type(in(1));\n+  if (t1 == Type::TOP) {\n+    return this;\n+  }\n+  int count = 0;\n+  assert(t1->isa_int() || t1->isa_long(), \"Unexpected type\");\n+  int mask = (t1->isa_int() ? BitsPerJavaInteger : BitsPerJavaLong) - 1;\n+  if (const_shift_count(phase, this, &count) && (count & mask) == 0) {\n+    \/\/ Rotate by a multiple of 32\/64 does nothing\n+    return in(1);\n+  }\n+  return this;\n+}\n+\n@@ -1480,1 +1524,1 @@\n-    \/\/ Shift by zero does nothing\n+    \/\/ Rotate by zero does nothing\n@@ -1484,1 +1528,0 @@\n-\n@@ -1499,1 +1542,1 @@\n-    \/\/ Shift by zero does nothing\n+    \/\/ Rotate by zero does nothing\n@@ -1503,1 +1546,0 @@\n-\n@@ -1513,2 +1555,2 @@\n-  const Type *t1 = phase->type(in(1));\n-  const Type *t2 = phase->type(in(2));\n+  const Type* t1 = phase->type(in(1));\n+  const Type* t2 = phase->type(in(2));\n@@ -1519,1 +1561,1 @@\n-    } else {\n+    } else if (t1 != Type::TOP) {\n@@ -1528,0 +1570,15 @@\n+Node* RotateRightNode::Identity(PhaseGVN* phase) {\n+  const Type* t1 = phase->type(in(1));\n+  if (t1 == Type::TOP) {\n+    return this;\n+  }\n+  int count = 0;\n+  assert(t1->isa_int() || t1->isa_long(), \"Unexpected type\");\n+  int mask = (t1->isa_int() ? BitsPerJavaInteger : BitsPerJavaLong) - 1;\n+  if (const_shift_count(phase, this, &count) && (count & mask) == 0) {\n+    \/\/ Rotate by a multiple of 32\/64 does nothing\n+    return in(1);\n+  }\n+  return this;\n+}\n+\n@@ -1544,1 +1601,1 @@\n-    \/\/ Shift by zero does nothing\n+    \/\/ Rotate by zero does nothing\n@@ -1553,1 +1610,0 @@\n-\n@@ -1562,1 +1618,1 @@\n-    \/\/ Shift by zero does nothing\n+    \/\/ Rotate by zero does nothing\n","filename":"src\/hotspot\/share\/opto\/mulnode.cpp","additions":106,"deletions":50,"binary":false,"changes":156,"status":"modified"},{"patch":"@@ -2295,5 +2295,0 @@\n-\/\/ Clear all entries in _nodes to NULL but keep storage\n-void Node_Array::clear() {\n-  Copy::zero_to_bytes( _nodes, _max*sizeof(Node*) );\n-}\n-\n","filename":"src\/hotspot\/share\/opto\/node.cpp","additions":0,"deletions":5,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -31,0 +31,1 @@\n+#include \"utilities\/copy.hpp\"\n@@ -53,0 +54,1 @@\n+class CallNativeNode;\n@@ -96,0 +98,1 @@\n+class MachCallNativeNode;\n@@ -163,0 +166,2 @@\n+class LoadVectorMaskedNode;\n+class StoreVectorMaskedNode;\n@@ -637,0 +642,1 @@\n+          DEFINE_CLASS_ID(CallNative,       Call, 5)\n@@ -660,0 +666,1 @@\n+            DEFINE_CLASS_ID(MachCallNative,       MachCall, 2)\n@@ -701,2 +708,2 @@\n-    DEFINE_CLASS_ID(Mem,   Node, 4)\n-      DEFINE_CLASS_ID(Load,  Mem, 0)\n+    DEFINE_CLASS_ID(Mem, Node, 4)\n+      DEFINE_CLASS_ID(Load, Mem, 0)\n@@ -705,0 +712,1 @@\n+          DEFINE_CLASS_ID(LoadVectorMasked, LoadVector, 1)\n@@ -708,0 +716,1 @@\n+          DEFINE_CLASS_ID(StoreVectorMasked, StoreVector, 1)\n@@ -823,0 +832,1 @@\n+  DEFINE_CLASS_QUERY(CallNative)\n@@ -865,0 +875,1 @@\n+  DEFINE_CLASS_QUERY(MachCallNative)\n@@ -1498,5 +1509,3 @@\n-  Node_Array(Arena* a) : _a(a), _max(OptoNodeListSize) {\n-    _nodes = NEW_ARENA_ARRAY(a, Node*, OptoNodeListSize);\n-    for (int i = 0; i < OptoNodeListSize; i++) {\n-      _nodes[i] = NULL;\n-    }\n+  Node_Array(Arena* a, uint max = OptoNodeListSize) : _a(a), _max(max) {\n+    _nodes = NEW_ARENA_ARRAY(a, Node*, max);\n+    clear();\n@@ -1514,1 +1523,5 @@\n-  void clear();                 \/\/ Set all entries to NULL, keep storage\n+  \/\/ Clear all entries in _nodes to NULL but keep storage\n+  void clear() {\n+    Copy::zero_to_bytes(_nodes, _max * sizeof(Node*));\n+  }\n+\n@@ -1523,2 +1536,2 @@\n-  Node_List() : Node_Array(Thread::current()->resource_area()), _cnt(0) {}\n-  Node_List(Arena *a) : Node_Array(a), _cnt(0) {}\n+  Node_List(uint max = OptoNodeListSize) : Node_Array(Thread::current()->resource_area(), max), _cnt(0) {}\n+  Node_List(Arena *a, uint max = OptoNodeListSize) : Node_Array(a, max), _cnt(0) {}\n@@ -1537,0 +1550,8 @@\n+  void copy(const Node_List& from) {\n+    if (from._max > _max) {\n+      grow(from._max);\n+    }\n+    _cnt = from._cnt;\n+    Copy::conjoint_words_to_higher((HeapWord*)&from._nodes[0], (HeapWord*)&_nodes[0], from._max * sizeof(Node*));\n+  }\n+\n","filename":"src\/hotspot\/share\/opto\/node.hpp","additions":31,"deletions":10,"binary":false,"changes":41,"status":"modified"},{"patch":"@@ -38,0 +38,1 @@\n+#include \"memory\/allocation.hpp\"\n@@ -1049,0 +1050,1 @@\n+  bool is_opt_native = false;\n@@ -1068,0 +1070,2 @@\n+    } else if (mcall->is_MachCallNative()) {\n+      is_opt_native = true;\n@@ -1191,4 +1195,17 @@\n-    C->debug_info()->describe_scope(safepoint_pc_offset, null_mh, scope_method, jvms->bci(),\n-                                    jvms->should_reexecute(), rethrow_exception, is_method_handle_invoke,\n-                                    return_oop, return_vt, has_ea_local_in_scope, arg_escape,\n-                                    locvals, expvals, monvals);\n+    C->debug_info()->describe_scope(\n+      safepoint_pc_offset,\n+      null_mh,\n+      scope_method,\n+      jvms->bci(),\n+      jvms->should_reexecute(),\n+      rethrow_exception,\n+      is_method_handle_invoke,\n+      is_opt_native,\n+      return_oop,\n+      return_vt,\n+      has_ea_local_in_scope,\n+      arg_escape,\n+      locvals,\n+      expvals,\n+      monvals\n+    );\n@@ -1574,0 +1591,1 @@\n+        bool observe_safepoint = is_sfn;\n@@ -1586,4 +1604,1 @@\n-          if (mcall->is_MachCallLeaf()) {\n-            is_mcall = false;\n-            is_sfn = false;\n-          }\n+          observe_safepoint = mcall->guaranteed_safepoint();\n@@ -1593,2 +1608,1 @@\n-        if (is_sfn || is_mcall) {\n-\n+        if (observe_safepoint) {\n@@ -1739,1 +1753,3 @@\n-\n+#if 0 \/\/ new assert, since moved below \"if (C->failing())\", but always triggers in Valhalla\n+      assert(!is_mcall || (call_returns[block->_pre_order] <= (uint) current_offset), \"ret_addr_offset() not within emitted code\");\n+#endif\n@@ -2912,5 +2928,4 @@\n-      RegMask rm = n->out_RegMask();\/\/ Make local copy\n-      while( rm.is_NotEmpty() ) {\n-        OptoReg::Name kill = rm.find_first_elem();\n-        rm.Remove(kill);\n-        verify_do_def( n, kill, msg );\n+      RegMaskIterator rmi(n->out_RegMask());\n+      while (rmi.has_next()) {\n+        OptoReg::Name kill = rmi.next();\n+        verify_do_def(n, kill, msg);\n@@ -3103,5 +3118,4 @@\n-      RegMask rm = n->out_RegMask();\/\/ Make local copy\n-      while( rm.is_NotEmpty() ) {\n-        OptoReg::Name kill = rm.find_first_elem();\n-        rm.Remove(kill);\n-        anti_do_def( b, n, kill, is_def );\n+      RegMaskIterator rmi(n->out_RegMask());\n+      while (rmi.has_next()) {\n+        OptoReg::Name kill = rmi.next();\n+        anti_do_def(b, n, kill, is_def);\n@@ -3122,5 +3136,4 @@\n-          RegMask rm = use->out_RegMask();\/\/ Make local copy\n-          while( rm.is_NotEmpty() ) {\n-            OptoReg::Name kill = rm.find_first_elem();\n-            rm.Remove(kill);\n-            anti_do_def( b, n, kill, false );\n+          RegMaskIterator rmi(use->out_RegMask());\n+          while (rmi.has_next()) {\n+            OptoReg::Name kill = rmi.next();\n+            anti_do_def(b, n, kill, false);\n@@ -3478,1 +3491,2 @@\n-                              C->rtm_state());\n+                              C->rtm_state(),\n+                              C->native_invokers());\n","filename":"src\/hotspot\/share\/opto\/output.cpp","additions":41,"deletions":27,"binary":false,"changes":68,"status":"modified"},{"patch":"@@ -693,1 +693,2 @@\n-PhaseValues::PhaseValues( Arena *arena, uint est_max_size ) : PhaseTransform(arena, GVN), _table(arena, est_max_size) {\n+PhaseValues::PhaseValues( Arena *arena, uint est_max_size )\n+  : PhaseTransform(arena, GVN), _table(arena, est_max_size), _iterGVN(false) {\n@@ -699,2 +700,2 @@\n-PhaseValues::PhaseValues( PhaseValues *ptv ) : PhaseTransform( ptv, GVN ),\n-  _table(&ptv->_table) {\n+PhaseValues::PhaseValues(PhaseValues* ptv)\n+  : PhaseTransform(ptv, GVN), _table(&ptv->_table), _iterGVN(false) {\n@@ -935,4 +936,4 @@\n-PhaseIterGVN::PhaseIterGVN( PhaseIterGVN *igvn ) : PhaseGVN(igvn),\n-                                                   _delay_transform(igvn->_delay_transform),\n-                                                   _stack( igvn->_stack ),\n-                                                   _worklist( igvn->_worklist )\n+PhaseIterGVN::PhaseIterGVN(PhaseIterGVN* igvn) : PhaseGVN(igvn),\n+                                                 _delay_transform(igvn->_delay_transform),\n+                                                 _stack(igvn->_stack ),\n+                                                 _worklist(igvn->_worklist)\n@@ -940,0 +941,1 @@\n+  _iterGVN = true;\n@@ -944,2 +946,2 @@\n-PhaseIterGVN::PhaseIterGVN( PhaseGVN *gvn ) : PhaseGVN(gvn),\n-                                              _delay_transform(false),\n+PhaseIterGVN::PhaseIterGVN(PhaseGVN* gvn) : PhaseGVN(gvn),\n+                                            _delay_transform(false),\n@@ -950,2 +952,2 @@\n-                                              _stack(C->comp_arena(), 32),\n-                                              _worklist(*C->for_igvn())\n+                                            _stack(C->comp_arena(), 32),\n+                                            _worklist(*C->for_igvn())\n@@ -953,0 +955,1 @@\n+  _iterGVN = true;\n@@ -963,1 +966,3 @@\n-      assert( false, \"Parse::remove_useless_nodes missed this node\");\n+      \/\/ If remove_useless_nodes() has run, we expect no such nodes left.\n+      assert(!UseLoopSafepoints || !OptoRemoveUseless,\n+             \"remove_useless_nodes missed this node\");\n","filename":"src\/hotspot\/share\/opto\/phaseX.cpp","additions":17,"deletions":12,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -338,3 +338,0 @@\n-  \/\/ Delayed node rehash if this is an IGVN phase\n-  virtual void igvn_rehash_node_delayed(Node* n) {}\n-\n@@ -372,1 +369,1 @@\n-\n+  bool      _iterGVN;\n@@ -374,4 +371,4 @@\n-  PhaseValues( Arena *arena, uint est_max_size );\n-  PhaseValues( PhaseValues *pt );\n-  NOT_PRODUCT( ~PhaseValues(); )\n-  virtual PhaseIterGVN *is_IterGVN() { return 0; }\n+  PhaseValues(Arena* arena, uint est_max_size);\n+  PhaseValues(PhaseValues* pt);\n+  NOT_PRODUCT(~PhaseValues();)\n+  PhaseIterGVN* is_IterGVN() { return (_iterGVN) ? (PhaseIterGVN*)this : NULL; }\n@@ -380,4 +377,4 @@\n-  bool   hash_delete(Node *n)     { return _table.hash_delete(n); }\n-  void   hash_insert(Node *n)     { _table.hash_insert(n); }\n-  Node  *hash_find_insert(Node *n){ return _table.hash_find_insert(n); }\n-  Node  *hash_find(const Node *n) { return _table.hash_find(n); }\n+  bool   hash_delete(Node* n)     { return _table.hash_delete(n); }\n+  void   hash_insert(Node* n)     { _table.hash_insert(n); }\n+  Node*  hash_find_insert(Node* n){ return _table.hash_find_insert(n); }\n+  Node*  hash_find(const Node* n) { return _table.hash_find(n); }\n@@ -394,2 +391,2 @@\n-  virtual const Type* saturate(const Type* new_type, const Type* old_type,\n-                               const Type* limit_type) const\n+  const Type* saturate(const Type* new_type, const Type* old_type,\n+                       const Type* limit_type) const\n@@ -466,2 +463,2 @@\n-  PhaseIterGVN( PhaseIterGVN *igvn ); \/\/ Used by CCP constructor\n-  PhaseIterGVN( PhaseGVN *gvn ); \/\/ Used after Parser\n+  PhaseIterGVN(PhaseIterGVN* igvn); \/\/ Used by CCP constructor\n+  PhaseIterGVN(PhaseGVN* gvn); \/\/ Used after Parser\n@@ -473,2 +470,0 @@\n-  virtual PhaseIterGVN *is_IterGVN() { return this; }\n-\n@@ -532,4 +527,0 @@\n-  void igvn_rehash_node_delayed(Node* n) {\n-    rehash_node_delayed(n);\n-  }\n-\n","filename":"src\/hotspot\/share\/opto\/phaseX.hpp","additions":13,"deletions":22,"binary":false,"changes":35,"status":"modified"},{"patch":"@@ -195,6 +195,4 @@\n-        PreserveReexecuteState prs(&kit);\n-\n-        kit.jvms()->set_should_reexecute(true);\n-\n-        const TypeInstPtr* vbox_type = vec_box->box_type();\n-        const TypeVect* vect_type = vec_box->vec_type();\n+        const TypeInstPtr* vbox_type = vec_box->box_type();\n+        const TypeVect* vt = vec_box->vec_type();\n+        BasicType elem_bt = vt->element_basic_type();\n+        int num_elem = vt->length();\n@@ -203,8 +201,1 @@\n-        VectorBoxAllocateNode* alloc = new VectorBoxAllocateNode(C, vbox_type);\n-        kit.set_edges_for_java_call(alloc, \/*must_throw=*\/false, \/*separate_io_proj=*\/true);\n-        kit.make_slow_call_ex(alloc, C->env()->Throwable_klass(), \/*separate_io_proj=*\/true, \/*deoptimize=*\/true);\n-        kit.set_i_o(gvn.transform( new ProjNode(alloc, TypeFunc::I_O) ));\n-        kit.set_all_memory(gvn.transform( new ProjNode(alloc, TypeFunc::Memory) ));\n-        Node* ret = gvn.transform(new ProjNode(alloc, TypeFunc::Parms));\n-\n-        new_vbox = gvn.transform(new VectorBoxNode(C, ret, vect, vbox_type, vect_type));\n+        new_vbox = kit.box_vector(vect, vbox_type, elem_bt, num_elem, \/*deoptimize=*\/true);\n@@ -370,6 +361,6 @@\n-                                                            vec_field,\n-                                                            vec_adr_type,\n-                                                            arr,\n-                                                            TypeOopPtr::make_from_klass(field->type()->as_klass()),\n-                                                            T_OBJECT,\n-                                                            IN_HEAP));\n+                                                        vec_field,\n+                                                        vec_adr_type,\n+                                                        arr,\n+                                                        TypeOopPtr::make_from_klass(field->type()->as_klass()),\n+                                                        T_OBJECT,\n+                                                        IN_HEAP));\n","filename":"src\/hotspot\/share\/opto\/vector.cpp","additions":11,"deletions":20,"binary":false,"changes":31,"status":"modified"},{"patch":"@@ -3520,0 +3520,19 @@\n+JVM_ENTRY(void, JVM_ReferenceClear(JNIEnv* env, jobject ref))\n+  JVMWrapper(\"JVM_ReferenceClear\");\n+  oop ref_oop = JNIHandles::resolve_non_null(ref);\n+  \/\/ FinalReference has it's own implementation of clear().\n+  assert(!java_lang_ref_Reference::is_final(ref_oop), \"precondition\");\n+  if (java_lang_ref_Reference::unknown_referent_no_keepalive(ref_oop) == NULL) {\n+    \/\/ If the referent has already been cleared then done.\n+    \/\/ However, if the referent is dead but has not yet been cleared by\n+    \/\/ concurrent reference processing, it should NOT be cleared here.\n+    \/\/ Instead, clearing should be left to the GC.  Clearing it here could\n+    \/\/ detectably lose an expected notification, which is impossible with\n+    \/\/ STW reference processing.  The clearing in enqueue() doesn't have\n+    \/\/ this problem, since the enqueue covers the notification, but it's not\n+    \/\/ worth the effort to handle that case specially.\n+    return;\n+  }\n+  java_lang_ref_Reference::clear_referent(ref_oop);\n+JVM_END\n+\n","filename":"src\/hotspot\/share\/prims\/jvm.cpp","additions":19,"deletions":0,"binary":false,"changes":19,"status":"modified"},{"patch":"@@ -432,0 +432,1 @@\n+  case vmIntrinsics::_linkToNative:     return vmSymbols::linkToNative_name();\n@@ -454,0 +455,1 @@\n+  case vmIntrinsics::_linkToNative:     return 0;\n@@ -477,0 +479,1 @@\n+  case VM_SYMBOL_ENUM_NAME(linkToNative_name):     return vmIntrinsics::_linkToNative;\n","filename":"src\/hotspot\/share\/prims\/methodHandles.cpp","additions":3,"deletions":0,"binary":false,"changes":3,"status":"modified"},{"patch":"@@ -102,0 +102,1 @@\n+#include \"gc\/g1\/heapRegionManager.hpp\"\n@@ -510,0 +511,7 @@\n+WB_ENTRY(jboolean, WB_G1HasRegionsToUncommit(JNIEnv* env, jobject o))\n+  if (UseG1GC) {\n+    return G1CollectedHeap::heap()->has_uncommittable_regions();\n+  }\n+  THROW_MSG_0(vmSymbols::java_lang_UnsupportedOperationException(), \"WB_G1HasRegionsToUncommit: G1 GC is not enabled\");\n+WB_END\n+\n@@ -2345,0 +2353,19 @@\n+WB_ENTRY(void, WB_VerifyFrames(JNIEnv* env, jobject wb, jboolean log))\n+  intx tty_token = -1;\n+  if (log) {\n+    tty_token = ttyLocker::hold_tty();\n+    tty->print_cr(\"[WhiteBox::VerifyFrames] Walking Frames\");\n+  }\n+  for (StackFrameStream fst(JavaThread::current(), true, true); !fst.is_done(); fst.next()) {\n+    frame* current_frame = fst.current();\n+    if (log) {\n+      current_frame->print_value();\n+    }\n+    current_frame->verify(fst.register_map());\n+  }\n+  if (log) {\n+    tty->print_cr(\"[WhiteBox::VerifyFrames] Done\");\n+    ttyLocker::release_tty(tty_token);\n+  }\n+WB_END\n+\n@@ -2400,0 +2427,1 @@\n+  {CC\"g1HasRegionsToUncommit\",  CC\"()Z\",              (void*)&WB_G1HasRegionsToUncommit},\n@@ -2585,0 +2613,1 @@\n+  {CC\"verifyFrames\",                CC\"(Z)V\",            (void*)&WB_VerifyFrames },\n","filename":"src\/hotspot\/share\/prims\/whitebox.cpp","additions":29,"deletions":0,"binary":false,"changes":29,"status":"modified"},{"patch":"@@ -524,9 +524,9 @@\n-  { \"UseBiasedLocking\",             JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingStartupDelay\",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"PrintBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingBulkRebiasThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingBulkRevokeThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"BiasedLockingDecayTime\",              JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"UseOptoBiasInlining\",                 JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"PrintPreciseBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(16), JDK_Version::jdk(17) },\n-  { \"CriticalJNINatives\",                  JDK_Version::jdk(16), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+  { \"CriticalJNINatives\",           JDK_Version::jdk(16), JDK_Version::jdk(17), JDK_Version::jdk(18) },\n+  { \"UseBiasedLocking\",             JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingStartupDelay\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"PrintBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingBulkRebiasThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingBulkRevokeThreshold\",    JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"BiasedLockingDecayTime\",              JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"UseOptoBiasInlining\",                 JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n+  { \"PrintPreciseBiasedLockingStatistics\", JDK_Version::jdk(15), JDK_Version::jdk(18), JDK_Version::jdk(19) },\n@@ -572,10 +572,0 @@\n-#ifndef COMPILER2\n-  \/\/ These flags were generally available, but are C2 only, now.\n-  { \"MaxInlineLevel\",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MaxRecursiveInlineLevel\",      JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"InlineSmallCode\",              JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MaxInlineSize\",                JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"FreqInlineSize\",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-  { \"MaxTrivialSize\",               JDK_Version::undefined(), JDK_Version::jdk(15), JDK_Version::jdk(16) },\n-#endif\n-\n@@ -1681,1 +1671,0 @@\n-#ifndef ZERO\n@@ -1702,1 +1691,0 @@\n-#endif \/\/ ZERO\n@@ -1709,1 +1697,0 @@\n-#ifndef ZERO\n@@ -1737,1 +1724,0 @@\n-#endif \/\/ !ZERO\n@@ -1756,1 +1742,0 @@\n-#ifndef ZERO\n@@ -1767,1 +1752,0 @@\n-#endif \/\/ !ZERO\n@@ -3958,0 +3942,4 @@\n+  if (ReplayCompiles) {\n+    FLAG_SET_ERGO_IF_DEFAULT(UseDebuggerErgo, true);\n+  }\n+\n@@ -4226,2 +4214,0 @@\n-  LP64_ONLY(FLAG_SET_DEFAULT(UseCompressedOops, false));\n-  LP64_ONLY(FLAG_SET_DEFAULT(UseCompressedClassPointers, false));\n","filename":"src\/hotspot\/share\/runtime\/arguments.cpp","additions":13,"deletions":27,"binary":false,"changes":40,"status":"modified"},{"patch":"@@ -989,0 +989,1 @@\n+    assert(loc != NULL, \"missing register map entry\");\n","filename":"src\/hotspot\/share\/runtime\/frame.cpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -2534,1 +2534,6 @@\n-                \"Make nmethod barriers deoptimise a lot.\")\n+                \"Make nmethod barriers deoptimise a lot.\")                  \\\n+                                                                            \\\n+  develop(bool, VerifyCrossModifyFence,                                     \\\n+          false AARCH64_ONLY(DEBUG_ONLY(||true)),                           \\\n+             \"Mark all threads after a safepoint, and clear on a modify \"   \\\n+             \"fence. Add cleanliness checks.\")                              \\\n","filename":"src\/hotspot\/share\/runtime\/globals.hpp","additions":6,"deletions":1,"binary":false,"changes":7,"status":"modified"},{"patch":"@@ -39,0 +39,2 @@\n+#include \"prims\/universalNativeInvoker.hpp\"\n+#include \"runtime\/globals.hpp\"\n","filename":"src\/hotspot\/share\/runtime\/init.cpp","additions":2,"deletions":0,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -385,0 +385,8 @@\n+  \/\/ Mark all threads\n+  if (VerifyCrossModifyFence) {\n+    JavaThreadIteratorWithHandle jtiwh;\n+    for (; JavaThread *cur = jtiwh.next(); ) {\n+      cur->set_requires_cross_modify_fence(true);\n+    }\n+  }\n+\n","filename":"src\/hotspot\/share\/runtime\/safepoint.cpp","additions":8,"deletions":0,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -553,0 +553,5 @@\n+  static BufferBlob* make_native_invoker(address call_target,\n+                                         int shadow_space_bytes,\n+                                         const GrowableArray<VMReg>& input_registers,\n+                                         const GrowableArray<VMReg>& output_registers);\n+\n","filename":"src\/hotspot\/share\/runtime\/sharedRuntime.hpp","additions":5,"deletions":0,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -230,2 +230,8 @@\n-#define NINFLATIONLOCKS 256\n-static volatile intptr_t gInflationLocks[NINFLATIONLOCKS];\n+static const int NINFLATIONLOCKS = 256;\n+static os::PlatformMutex* gInflationLocks[NINFLATIONLOCKS];\n+\n+void ObjectSynchronizer::initialize() {\n+  for (int i = 0; i < NINFLATIONLOCKS; i++) {\n+    gInflationLocks[i] = new os::PlatformMutex();\n+  }\n+}\n@@ -358,1 +364,1 @@\n-    Thread* const owner = (Thread *) m->_owner;\n+    Thread* const owner = (Thread *) m->owner_raw();\n@@ -780,7 +786,1 @@\n-    \/\/ Avoid live-lock\n-    \/\/ TODO: consider calling SafepointSynchronize::do_call_back() while\n-    \/\/ spinning to see if there's a safepoint pending.  If so, immediately\n-    \/\/ yielding or blocking would be appropriate.  Avoid spinning while\n-    \/\/ there is a safepoint pending.\n-    \/\/ TODO: add inflation contention performance counters.\n-    \/\/ TODO: restrict the aggregate number of spinners.\n+    \/\/ Avoid live-lock.\n@@ -806,2 +806,3 @@\n-        \/\/ This is conceptually similar to muxAcquire-muxRelease, except that muxRelease\n-        \/\/ wakes at most one thread whereas we need to wake the entire list.\n+\n+        \/\/ Index into the lock array based on the current object address.\n+        static_assert(is_power_of_2(NINFLATIONLOCKS), \"must be\");\n@@ -811,2 +812,1 @@\n-        assert((NINFLATIONLOCKS & (NINFLATIONLOCKS-1)) == 0, \"invariant\");\n-        Thread::muxAcquire(gInflationLocks + ix, \"gInflationLock\");\n+        gInflationLocks[ix]->lock();\n@@ -814,1 +814,1 @@\n-          \/\/ Beware: NakedYield() is advisory and has almost no effect on some platforms\n+          \/\/ Beware: naked_yield() is advisory and has almost no effect on some platforms\n@@ -823,1 +823,1 @@\n-        Thread::muxRelease(gInflationLocks + ix);\n+        gInflationLocks[ix]->unlock();\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.cpp","additions":16,"deletions":16,"binary":false,"changes":32,"status":"modified"},{"patch":"@@ -32,0 +32,1 @@\n+#include \"runtime\/os.hpp\"\n@@ -117,0 +118,3 @@\n+  \/\/ Initialize the gInflationLocks\n+  static void initialize();\n+\n","filename":"src\/hotspot\/share\/runtime\/synchronizer.hpp","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -295,1 +295,0 @@\n-  _MuxEvent    = ParkEvent::Allocate(this);\n@@ -443,1 +442,0 @@\n-  ParkEvent::Release(_MuxEvent); _MuxEvent    = NULL;\n@@ -1586,0 +1584,3 @@\n+\n+  set_requires_cross_modify_fence(false);\n+\n@@ -3564,0 +3565,1 @@\n+  ObjectSynchronizer::initialize();\n@@ -4586,4 +4588,1 @@\n-\/\/ Internal SpinLock and Mutex\n-\/\/ Based on ParkEvent\n-\n-\/\/ Ad-hoc mutual exclusion primitives: SpinLock and Mux\n+\/\/ Ad-hoc mutual exclusion primitives: SpinLock\n@@ -4594,8 +4593,0 @@\n-\/\/ The mux construct provides a spin-then-block mutual exclusion\n-\/\/ mechanism.\n-\/\/\n-\/\/ Testing has shown that contention on the ListLock guarding gFreeList\n-\/\/ is common.  If we implement ListLock as a simple SpinLock it's common\n-\/\/ for the JVM to devolve to yielding with little progress.  This is true\n-\/\/ despite the fact that the critical sections protected by ListLock are\n-\/\/ extremely short.\n@@ -4654,144 +4645,0 @@\n-\/\/ muxAcquire and muxRelease:\n-\/\/\n-\/\/ *  muxAcquire and muxRelease support a single-word lock-word construct.\n-\/\/    The LSB of the word is set IFF the lock is held.\n-\/\/    The remainder of the word points to the head of a singly-linked list\n-\/\/    of threads blocked on the lock.\n-\/\/\n-\/\/ *  The current implementation of muxAcquire-muxRelease uses its own\n-\/\/    dedicated Thread._MuxEvent instance.  If we're interested in\n-\/\/    minimizing the peak number of extant ParkEvent instances then\n-\/\/    we could eliminate _MuxEvent and \"borrow\" _ParkEvent as long\n-\/\/    as certain invariants were satisfied.  Specifically, care would need\n-\/\/    to be taken with regards to consuming unpark() \"permits\".\n-\/\/    A safe rule of thumb is that a thread would never call muxAcquire()\n-\/\/    if it's enqueued (cxq, EntryList, WaitList, etc) and will subsequently\n-\/\/    park().  Otherwise the _ParkEvent park() operation in muxAcquire() could\n-\/\/    consume an unpark() permit intended for monitorenter, for instance.\n-\/\/    One way around this would be to widen the restricted-range semaphore\n-\/\/    implemented in park().  Another alternative would be to provide\n-\/\/    multiple instances of the PlatformEvent() for each thread.  One\n-\/\/    instance would be dedicated to muxAcquire-muxRelease, for instance.\n-\/\/\n-\/\/ *  Usage:\n-\/\/    -- Only as leaf locks\n-\/\/    -- for short-term locking only as muxAcquire does not perform\n-\/\/       thread state transitions.\n-\/\/\n-\/\/ Alternatives:\n-\/\/ *  We could implement muxAcquire and muxRelease with MCS or CLH locks\n-\/\/    but with parking or spin-then-park instead of pure spinning.\n-\/\/ *  Use Taura-Oyama-Yonenzawa locks.\n-\/\/ *  It's possible to construct a 1-0 lock if we encode the lockword as\n-\/\/    (List,LockByte).  Acquire will CAS the full lockword while Release\n-\/\/    will STB 0 into the LockByte.  The 1-0 scheme admits stranding, so\n-\/\/    acquiring threads use timers (ParkTimed) to detect and recover from\n-\/\/    the stranding window.  Thread\/Node structures must be aligned on 256-byte\n-\/\/    boundaries by using placement-new.\n-\/\/ *  Augment MCS with advisory back-link fields maintained with CAS().\n-\/\/    Pictorially:  LockWord -> T1 <-> T2 <-> T3 <-> ... <-> Tn <-> Owner.\n-\/\/    The validity of the backlinks must be ratified before we trust the value.\n-\/\/    If the backlinks are invalid the exiting thread must back-track through the\n-\/\/    the forward links, which are always trustworthy.\n-\/\/ *  Add a successor indication.  The LockWord is currently encoded as\n-\/\/    (List, LOCKBIT:1).  We could also add a SUCCBIT or an explicit _succ variable\n-\/\/    to provide the usual futile-wakeup optimization.\n-\/\/    See RTStt for details.\n-\/\/\n-\n-\n-const intptr_t LOCKBIT = 1;\n-\n-void Thread::muxAcquire(volatile intptr_t * Lock, const char * LockName) {\n-  intptr_t w = Atomic::cmpxchg(Lock, (intptr_t)0, LOCKBIT);\n-  if (w == 0) return;\n-  if ((w & LOCKBIT) == 0 && Atomic::cmpxchg(Lock, w, w|LOCKBIT) == w) {\n-    return;\n-  }\n-\n-  ParkEvent * const Self = Thread::current()->_MuxEvent;\n-  assert((intptr_t(Self) & LOCKBIT) == 0, \"invariant\");\n-  for (;;) {\n-    int its = (os::is_MP() ? 100 : 0) + 1;\n-\n-    \/\/ Optional spin phase: spin-then-park strategy\n-    while (--its >= 0) {\n-      w = *Lock;\n-      if ((w & LOCKBIT) == 0 && Atomic::cmpxchg(Lock, w, w|LOCKBIT) == w) {\n-        return;\n-      }\n-    }\n-\n-    Self->reset();\n-    Self->OnList = intptr_t(Lock);\n-    \/\/ The following fence() isn't _strictly necessary as the subsequent\n-    \/\/ CAS() both serializes execution and ratifies the fetched *Lock value.\n-    OrderAccess::fence();\n-    for (;;) {\n-      w = *Lock;\n-      if ((w & LOCKBIT) == 0) {\n-        if (Atomic::cmpxchg(Lock, w, w|LOCKBIT) == w) {\n-          Self->OnList = 0;   \/\/ hygiene - allows stronger asserts\n-          return;\n-        }\n-        continue;      \/\/ Interference -- *Lock changed -- Just retry\n-      }\n-      assert(w & LOCKBIT, \"invariant\");\n-      Self->ListNext = (ParkEvent *) (w & ~LOCKBIT);\n-      if (Atomic::cmpxchg(Lock, w, intptr_t(Self)|LOCKBIT) == w) break;\n-    }\n-\n-    while (Self->OnList != 0) {\n-      Self->park();\n-    }\n-  }\n-}\n-\n-\/\/ Release() must extract a successor from the list and then wake that thread.\n-\/\/ It can \"pop\" the front of the list or use a detach-modify-reattach (DMR) scheme\n-\/\/ similar to that used by ParkEvent::Allocate() and ::Release().  DMR-based\n-\/\/ Release() would :\n-\/\/ (A) CAS() or swap() null to *Lock, releasing the lock and detaching the list.\n-\/\/ (B) Extract a successor from the private list \"in-hand\"\n-\/\/ (C) attempt to CAS() the residual back into *Lock over null.\n-\/\/     If there were any newly arrived threads and the CAS() would fail.\n-\/\/     In that case Release() would detach the RATs, re-merge the list in-hand\n-\/\/     with the RATs and repeat as needed.  Alternately, Release() might\n-\/\/     detach and extract a successor, but then pass the residual list to the wakee.\n-\/\/     The wakee would be responsible for reattaching and remerging before it\n-\/\/     competed for the lock.\n-\/\/\n-\/\/ Both \"pop\" and DMR are immune from ABA corruption -- there can be\n-\/\/ multiple concurrent pushers, but only one popper or detacher.\n-\/\/ This implementation pops from the head of the list.  This is unfair,\n-\/\/ but tends to provide excellent throughput as hot threads remain hot.\n-\/\/ (We wake recently run threads first).\n-\/\/\n-\/\/ All paths through muxRelease() will execute a CAS.\n-\/\/ Release consistency -- We depend on the CAS in muxRelease() to provide full\n-\/\/ bidirectional fence\/MEMBAR semantics, ensuring that all prior memory operations\n-\/\/ executed within the critical section are complete and globally visible before the\n-\/\/ store (CAS) to the lock-word that releases the lock becomes globally visible.\n-void Thread::muxRelease(volatile intptr_t * Lock)  {\n-  for (;;) {\n-    const intptr_t w = Atomic::cmpxchg(Lock, LOCKBIT, (intptr_t)0);\n-    assert(w & LOCKBIT, \"invariant\");\n-    if (w == LOCKBIT) return;\n-    ParkEvent * const List = (ParkEvent *) (w & ~LOCKBIT);\n-    assert(List != NULL, \"invariant\");\n-    assert(List->OnList == intptr_t(Lock), \"invariant\");\n-    ParkEvent * const nxt = List->ListNext;\n-    guarantee((intptr_t(nxt) & LOCKBIT) == 0, \"invariant\");\n-\n-    \/\/ The following CAS() releases the lock and pops the head element.\n-    \/\/ The CAS() also ratifies the previously fetched lock-word value.\n-    if (Atomic::cmpxchg(Lock, w, intptr_t(nxt)) != w) {\n-      continue;\n-    }\n-    List->OnList = 0;\n-    OrderAccess::fence();\n-    List->unpark();\n-    return;\n-  }\n-}\n-\n@@ -4806,0 +4653,6 @@\n+\n+#ifndef PRODUCT\n+void JavaThread::verify_cross_modify_fence_failure(JavaThread *thread) {\n+   report_vm_error(__FILE__, __LINE__, \"Cross modify fence failure\", \"%p\", thread);\n+}\n+#endif\n","filename":"src\/hotspot\/share\/runtime\/thread.cpp","additions":11,"deletions":158,"binary":false,"changes":169,"status":"modified"},{"patch":"@@ -831,2 +831,2 @@\n-  ParkEvent * _ParkEvent;                     \/\/ for Object monitors and JVMTI raw monitors\n-  ParkEvent * _MuxEvent;                      \/\/ for low-level muxAcquire-muxRelease\n+  ParkEvent * _ParkEvent;                     \/\/ for Object monitors, JVMTI raw monitors,\n+                                              \/\/ and ObjectSynchronizer::read_stable_mark\n@@ -841,2 +841,1 @@\n-  \/\/ Low-level leaf-lock primitives used to implement synchronization\n-  \/\/ and native monitor-mutex infrastructure.\n+  \/\/ Low-level leaf-lock primitives used to implement synchronization.\n@@ -846,2 +845,0 @@\n-  static void muxAcquire(volatile intptr_t * Lock, const char * Name);\n-  static void muxRelease(volatile intptr_t * Lock);\n@@ -1102,0 +1099,1 @@\n+  NOT_PRODUCT(bool      _requires_cross_modify_fence;) \/\/ State used by VerifyCrossModifyFence\n@@ -1333,0 +1331,2 @@\n+  void set_requires_cross_modify_fence(bool val) PRODUCT_RETURN NOT_PRODUCT({ _requires_cross_modify_fence = val; })\n+\n@@ -1612,0 +1612,1 @@\n+  NOT_PRODUCT(static ByteSize requires_cross_modify_fence_offset()  { return byte_offset_of(JavaThread, _requires_cross_modify_fence); })\n@@ -1901,0 +1902,2 @@\n+\n+  static void verify_cross_modify_fence_failure(JavaThread *thread) PRODUCT_RETURN;\n","filename":"src\/hotspot\/share\/runtime\/thread.hpp","additions":9,"deletions":6,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -115,0 +115,1 @@\n+  template(JvmtiPostObjectFree)\n","filename":"src\/hotspot\/share\/runtime\/vmOperations.hpp","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -868,3 +868,2 @@\n-  nonstatic_field(ciObjectFactory,             _ci_metadata,                                  GrowableArray<ciMetadata*>*)           \\\n-  nonstatic_field(ciObjectFactory,             _symbols,                                      GrowableArray<ciSymbol*>*)             \\\n-  nonstatic_field(ciObjectFactory,             _unloaded_methods,                             GrowableArray<ciMethod*>*)             \\\n+  nonstatic_field(ciObjectFactory,             _ci_metadata,                                  GrowableArray<ciMetadata*>)            \\\n+  nonstatic_field(ciObjectFactory,             _symbols,                                      GrowableArray<ciSymbol*>)              \\\n@@ -1526,0 +1525,1 @@\n+  declare_c2_type(CallNativeNode, CallNode)                               \\\n@@ -1643,0 +1643,1 @@\n+  declare_c2_type(MachCallNativeNode, MachCallNode)                       \\\n@@ -2560,0 +2561,1 @@\n+  declare_constant(vmIntrinsics::_linkToNative)                           \\\n","filename":"src\/hotspot\/share\/runtime\/vmStructs.cpp","additions":5,"deletions":3,"binary":false,"changes":8,"status":"modified"},{"patch":"@@ -129,0 +129,17 @@\n+  const static GrowableArrayView EMPTY;\n+\n+  bool operator==(const GrowableArrayView<E>& rhs) const {\n+    if (_len != rhs._len)\n+      return false;\n+    for (int i = 0; i < _len; i++) {\n+      if (at(i) != rhs.at(i)) {\n+        return false;\n+      }\n+    }\n+    return true;\n+  }\n+\n+  bool operator!=(const GrowableArrayView<E>& rhs) const {\n+    return !(*this == rhs);\n+  }\n+\n@@ -300,1 +317,5 @@\n-  void print() {\n+  size_t data_size_in_bytes() const {\n+    return _len * sizeof(E);\n+  }\n+\n+  void print() const {\n@@ -310,0 +331,3 @@\n+template<typename E>\n+const GrowableArrayView<E> GrowableArrayView<E>::EMPTY(nullptr, 0, 0);\n+\n","filename":"src\/hotspot\/share\/utilities\/growableArray.hpp","additions":25,"deletions":1,"binary":false,"changes":26,"status":"modified"},{"patch":"@@ -164,1 +164,1 @@\n- *     Object Serialization Specification, Section 2, Object Output Classes<\/a>\n+ *      <cite>Java Object Serialization Specification,<\/cite> Section 2, \"Object Output Classes\"<\/a>\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectOutputStream.java","additions":1,"deletions":1,"binary":false,"changes":2,"status":"modified"},{"patch":"@@ -80,1 +80,1 @@\n- *     Object Serialization Specification, Section 4.6, Stream Unique Identifiers<\/a>.\n+ *    <cite>Java Object Serialization Specification,<\/cite> Section 4.6, \"Stream Unique Identifiers\"<\/a>.\n@@ -86,1 +86,1 @@\n- *     Object Serialization Specification, Section 4, Class Descriptors<\/a>\n+ *      <cite>Java Object Serialization Specification,<\/cite> Section 4, \"Class Descriptors\"<\/a>\n","filename":"src\/java.base\/share\/classes\/java\/io\/ObjectStreamClass.java","additions":2,"deletions":2,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -3853,10 +3853,0 @@\n-    \/** java.lang.Record.class *\/\n-    private static final Class<?> JAVA_LANG_RECORD_CLASS = javaLangRecordClass();\n-    private static Class<?> javaLangRecordClass() {\n-        try {\n-            return Class.forName0(\"java.lang.Record\", false, null, null);\n-        } catch (ClassNotFoundException e) {\n-            throw new InternalError(\"should not reach here\", e);\n-        }\n-    }\n-\n@@ -3879,1 +3869,1 @@\n-        return getSuperclass() == JAVA_LANG_RECORD_CLASS && isRecord0();\n+        return getSuperclass() == java.lang.Record.class && isRecord0();\n","filename":"src\/java.base\/share\/classes\/java\/lang\/Class.java","additions":1,"deletions":11,"binary":false,"changes":12,"status":"modified"},{"patch":"@@ -30,0 +30,1 @@\n+import jdk.internal.invoke.NativeEntryPoint;\n@@ -1777,0 +1778,5 @@\n+            @Override\n+            public MethodHandle nativeMethodHandle(NativeEntryPoint nep, MethodHandle fallback) {\n+                return NativeMethodHandle.make(nep, fallback);\n+            }\n+\n","filename":"src\/java.base\/share\/classes\/java\/lang\/invoke\/MethodHandleImpl.java","additions":6,"deletions":0,"binary":false,"changes":6,"status":"modified"},{"patch":"@@ -103,1 +103,1 @@\n-     *                            clear\n+     *                            clear [2]\n@@ -106,1 +106,1 @@\n-     *          |                                 | enqueue [2]\n+     *          |                                 | enqueue\n@@ -117,1 +117,1 @@\n-     *          | poll\/remove                     |\n+     *          | poll\/remove                     | + clear [4]\n@@ -143,2 +143,2 @@\n-     * [pending\/enqueued] and [pending\/dequeued] unreachable, and\n-     * [inactive\/registered] terminal.\n+     * [pending\/enqueued], [pending\/dequeued], and [inactive\/registered]\n+     * unreachable.\n@@ -149,0 +149,2 @@\n+     *\n+     * [4] The queue handler for FinalReferences also clears the reference.\n@@ -345,16 +347,0 @@\n-    \/**\n-     * Load referent with strong semantics. Treating the referent\n-     * as strong referent is ok when the Reference is inactive,\n-     * because then the referent is switched to strong semantics\n-     * anyway.\n-     *\n-     * This is only used from Finalizer to bypass the intrinsic,\n-     * which might return a null referent, even though it is not\n-     * null, and would subsequently not finalize the referent\/finalizee.\n-     *\/\n-    T getInactive() {\n-        assert this instanceof FinalReference;\n-        assert next == this; \/\/ I.e. FinalReference is inactive\n-        return this.referent;\n-    }\n-\n@@ -386,0 +372,35 @@\n+        clear0();\n+    }\n+\n+    \/* Implementation of clear(), also used by enqueue().  A simple\n+     * assignment of the referent field won't do for some garbage\n+     * collectors.\n+     *\/\n+    private native void clear0();\n+\n+    \/* -- Operations on inactive FinalReferences -- *\/\n+\n+    \/* These functions are only used by FinalReference, and must only be\n+     * called after the reference becomes inactive. While active, a\n+     * FinalReference is considered weak but the referent is not normally\n+     * accessed. Once a FinalReference becomes inactive it is considered a\n+     * strong reference. These functions are used to bypass the\n+     * corresponding weak implementations, directly accessing the referent\n+     * field with strong semantics.\n+     *\/\n+\n+    \/**\n+     * Load referent with strong semantics.\n+     *\/\n+    T getFromInactiveFinalReference() {\n+        assert this instanceof FinalReference;\n+        assert next != null; \/\/ I.e. FinalReference is inactive\n+        return this.referent;\n+    }\n+\n+    \/**\n+     * Clear referent with strong semantics.\n+     *\/\n+    void clearInactiveFinalReference() {\n+        assert this instanceof FinalReference;\n+        assert next != null; \/\/ I.e. FinalReference is inactive\n@@ -416,1 +437,1 @@\n-        this.referent = null;\n+        clear0();               \/\/ Intentionally clear0() rather than clear()\n","filename":"src\/java.base\/share\/classes\/java\/lang\/ref\/Reference.java","additions":43,"deletions":22,"binary":false,"changes":65,"status":"modified"},{"patch":"@@ -2,1 +2,1 @@\n- * Copyright (c) 2015, 2018, Oracle and\/or its affiliates. All rights reserved.\n+ * Copyright (c) 2015, 2020, Oracle and\/or its affiliates. All rights reserved.\n@@ -28,0 +28,2 @@\n+import jdk.internal.invoke.NativeEntryPoint;\n+\n@@ -124,0 +126,11 @@\n+\n+    \/**\n+     * Returns a native method handle with given arguments as fallback and steering info.\n+     *\n+     * Will allow JIT to intrinsify.\n+     *\n+     * @param nep the native entry point\n+     * @param fallback the fallback handle\n+     * @return the native method handle\n+     *\/\n+    MethodHandle nativeMethodHandle(NativeEntryPoint nep, MethodHandle fallback);\n","filename":"src\/java.base\/share\/classes\/jdk\/internal\/access\/JavaLangInvokeAccess.java","additions":14,"deletions":1,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -166,1 +166,2 @@\n-        java.naming;\n+        java.naming,\n+        jdk.incubator.foreign;\n@@ -353,0 +354,2 @@\n+    exports jdk.internal.invoke to\n+        jdk.incubator.foreign;\n","filename":"src\/java.base\/share\/classes\/module-info.java","additions":4,"deletions":1,"binary":false,"changes":5,"status":"modified"},{"patch":"@@ -403,13 +403,15 @@\n-        AccessFlags           = PUBLIC | PROTECTED | PRIVATE,\n-        LocalClassFlags       = FINAL | ABSTRACT | STRICTFP | ENUM | SYNTHETIC | VALUE,\n-        StaticLocalFlags      = LocalClassFlags | STATIC | INTERFACE,\n-        MemberClassFlags      = LocalClassFlags | INTERFACE | AccessFlags,\n-        MemberRecordFlags     = MemberClassFlags | STATIC,\n-        ClassFlags            = LocalClassFlags | INTERFACE | PUBLIC | ANNOTATION,\n-        InterfaceVarFlags     = FINAL | STATIC | PUBLIC,\n-        ConstructorFlags      = AccessFlags,\n-        InterfaceMethodFlags  = ABSTRACT | PUBLIC,\n-        MethodFlags           = AccessFlags | ABSTRACT | STATIC | NATIVE |\n-                                SYNCHRONIZED | FINAL | STRICTFP,\n-        RecordMethodFlags     = AccessFlags | ABSTRACT | STATIC |\n-                                SYNCHRONIZED | FINAL | STRICTFP;\n+        AccessFlags                       = PUBLIC | PROTECTED | PRIVATE,\n+        LocalClassFlags                   = FINAL | ABSTRACT | STRICTFP | ENUM | SYNTHETIC  | VALUE,\n+        StaticLocalFlags                  = LocalClassFlags | STATIC | INTERFACE,\n+        MemberClassFlags                  = LocalClassFlags | INTERFACE | AccessFlags,\n+        MemberStaticClassFlags            = MemberClassFlags | STATIC,\n+        ClassFlags                        = LocalClassFlags | INTERFACE | PUBLIC | ANNOTATION,\n+        InterfaceVarFlags                 = FINAL | STATIC | PUBLIC,\n+        VarFlags                          = AccessFlags | FINAL | STATIC |\n+                                            VOLATILE | TRANSIENT | ENUM,\n+        ConstructorFlags                  = AccessFlags,\n+        InterfaceMethodFlags              = ABSTRACT | PUBLIC,\n+        MethodFlags                       = AccessFlags | ABSTRACT | STATIC | NATIVE |\n+                                            SYNCHRONIZED | FINAL | STRICTFP,\n+        RecordMethodFlags                 = AccessFlags | ABSTRACT | STATIC |\n+                                            SYNCHRONIZED | FINAL | STRICTFP;\n@@ -417,10 +419,9 @@\n-        ExtendedStandardFlags       = (long)StandardFlags | DEFAULT | SEALED | NON_SEALED | VALUE,\n-        ExtendedMemberClassFlags    = (long)MemberClassFlags | SEALED | NON_SEALED,\n-        ExtendedClassFlags          = (long)ClassFlags | SEALED | NON_SEALED,\n-        ModifierFlags               = ((long)StandardFlags & ~INTERFACE) | DEFAULT | SEALED | NON_SEALED,\n-        InterfaceMethodMask         = ABSTRACT | PRIVATE | STATIC | PUBLIC | STRICTFP | DEFAULT,\n-        AnnotationTypeElementMask   = ABSTRACT | PUBLIC,\n-        LocalVarFlags               = FINAL | PARAMETER,\n-        VarFlags              = AccessFlags | FINAL | STATIC |\n-                                VOLATILE | TRANSIENT | ENUM,\n-        ReceiverParamFlags          = PARAMETER;\n+        ExtendedStandardFlags             = (long)StandardFlags | DEFAULT | SEALED | NON_SEALED | VALUE,\n+        ExtendedMemberClassFlags          = (long)MemberClassFlags | SEALED | NON_SEALED,\n+        ExtendedMemberStaticClassFlags    = (long) MemberStaticClassFlags | SEALED | NON_SEALED,\n+        ExtendedClassFlags                = (long)ClassFlags | SEALED | NON_SEALED,\n+        ModifierFlags                     = ((long)StandardFlags & ~INTERFACE) | DEFAULT | SEALED | NON_SEALED,\n+        InterfaceMethodMask               = ABSTRACT | PRIVATE | STATIC | PUBLIC | STRICTFP | DEFAULT,\n+        AnnotationTypeElementMask         = ABSTRACT | PUBLIC,\n+        LocalVarFlags                     = FINAL | PARAMETER,\n+        ReceiverParamFlags                = PARAMETER;\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/code\/Flags.java","additions":24,"deletions":23,"binary":false,"changes":47,"status":"modified"},{"patch":"@@ -174,0 +174,1 @@\n+        allowRecords = Feature.RECORDS.allowedInSource(source);\n@@ -215,0 +216,4 @@\n+    \/** Are records allowed\n+     *\/\n+    private final boolean allowRecords;\n+\n@@ -5478,3 +5483,4 @@\n-            if (c.owner.kind != PCK &&\n-                ((c.flags() & STATIC) == 0 || c.name == names.empty) &&\n-                (TreeInfo.flags(l.head) & (STATIC | INTERFACE)) != 0) {\n+            if (!allowRecords &&\n+                    c.owner.kind != PCK &&\n+                    ((c.flags() & STATIC) == 0 || c.name == names.empty) &&\n+                    (TreeInfo.flags(l.head) & (STATIC | INTERFACE)) != 0) {\n@@ -5484,2 +5490,2 @@\n-                    sym.kind != VAR ||\n-                    ((VarSymbol) sym).getConstValue() == null)\n+                        sym.kind != VAR ||\n+                        ((VarSymbol) sym).getConstValue() == null)\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Attr.java","additions":11,"deletions":5,"binary":false,"changes":16,"status":"modified"},{"patch":"@@ -1376,1 +1376,1 @@\n-            if (sym.isLocal()) {\n+            if (sym.owner.kind.matches(KindSelector.VAL_MTH)) {\n@@ -1380,0 +1380,1 @@\n+                \/\/ local statics are allowed only if records are allowed too\n@@ -1382,6 +1383,2 @@\n-                if (staticOrImplicitlyStatic) {\n-                    if (sym.owner.kind == TYP) {\n-                        log.error(pos, Errors.StaticDeclarationNotAllowedInInnerClasses);\n-                    }\n-                }\n-                mask = (flags & RECORD) != 0 ? MemberRecordFlags : ExtendedMemberClassFlags;\n+                \/\/ statics in inner classes are allowed only if records are allowed too\n+                mask = ((flags & STATIC) != 0) && allowRecords ? ExtendedMemberStaticClassFlags : ExtendedMemberClassFlags;\n@@ -1390,1 +1387,1 @@\n-                    (sym.owner.flags_field & STATIC) != 0)\n+                    (sym.owner.flags_field & STATIC) != 0) {\n@@ -1392,1 +1389,1 @@\n-                else if ((flags & ENUM) != 0 || (flags & RECORD) != 0) {\n+                } else if (!allowRecords && ((flags & ENUM) != 0 || (flags & RECORD) != 0)) {\n","filename":"src\/jdk.compiler\/share\/classes\/com\/sun\/tools\/javac\/comp\/Check.java","additions":6,"deletions":9,"binary":false,"changes":15,"status":"modified"},{"patch":"@@ -455,0 +455,4 @@\n+            \/\/ Panama\n+            add(toBeInvestigated,\n+                    \/\/ Native method handle intrinsics\n+                    \"java\/lang\/invoke\/MethodHandle.linkToNative*\");\n","filename":"src\/jdk.internal.vm.compiler\/share\/classes\/org.graalvm.compiler.hotspot.test\/src\/org\/graalvm\/compiler\/hotspot\/test\/CheckGraalIntrinsics.java","additions":4,"deletions":0,"binary":false,"changes":4,"status":"modified"},{"patch":"@@ -167,0 +167,1 @@\n+runtime\/ReservedStack\/ReservedStackTestCompiler.java 8256359 linux-aarch64\n","filename":"test\/hotspot\/jtreg\/ProblemList.txt","additions":1,"deletions":0,"binary":false,"changes":1,"status":"modified"},{"patch":"@@ -180,0 +180,1 @@\n+  public native boolean g1HasRegionsToUncommit();\n@@ -466,0 +467,5 @@\n+  \/\/ Collectors supporting concurrent GC breakpoints that do reference\n+  \/\/ processing concurrently should provide the following breakpoint.\n+  public final String AFTER_CONCURRENT_REFERENCE_PROCESSING_STARTED =\n+    \"AFTER CONCURRENT REFERENCE PROCESSING STARTED\";\n+\n@@ -646,0 +652,3 @@\n+  \/\/ Walk stack frames of current thread\n+  public native void verifyFrames(boolean log);\n+\n","filename":"test\/lib\/sun\/hotspot\/WhiteBox.java","additions":9,"deletions":0,"binary":false,"changes":9,"status":"modified"}]}